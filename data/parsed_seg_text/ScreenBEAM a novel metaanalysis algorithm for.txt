Motivation: Functional genomics (FG) screens, using RNAi or crisp r technology, have become a standard tool for systematic, genome wide loss of function studies for therapeutic target discovery. As in many large scale assays, however, off target effects, variable reagents potency and experimental noise must be accounted for appropriately control for false positives. Indeed, rigorous statistical analysis of high throughput FG screening data remains challenging, particularly when in-tegrative analyses are used to combine multiple shs grn as targeting the same gene in the library. Method: We use large RNAi and crisp r repositories that are publicly available to evaluate a novel meta analysis approach for FG screens via Bayesian hierarchical modeling, Screening Bayesian Evaluation and Analysis Method screen beam. Results: Results from our analysis show that the proposed strategy, which seamlessly combines all available data, robustly outperforms classical algorithms developed for microarray data sets as well as recent approaches designed for next generation sequencing technologies. Remarkably, the screen beam algorithm works well even when the quality of FG screens is relatively low, which accounts for about 80â€“95% of the public datasets. Availability and implementation: R package and source code are available at: https://github.com/

introduction recent technological advances have significantly improved our ability to perform systematic and informative functional genomics (FG) studies in mammalian cells. Specifically, during the past decade, RNA interference (RNAi) has become a standard technique for studying phenotype specific gene function via suppression of gene specific mRNA expression or translation (). More recently, the CRISPR/Cas9 system () has emerged as an even more effective tool to implement complete gene knock-out. As a result, loss of function genome scale screens have become popular, especially in pooled shRNA library format (). These have been widely used not only to identify essential genes in a specific context (), but also genes that are differentially essential in different contexts () or synthetic lethal genes (). Results from these screens may ultimately inform discovery of novel therapeutic targets in tissue specific subtype specific or mutation specific contexts, not only in cancer but in many other diseases and physiologic contexts. FG screen design has also been extended to identify tumor suppressors that increase cell growth upon repression () or genes that modulate drug sensitivity (). Complementing direct knock out methodologies, the CRISPR/Cas9 gene editing technology has also been scaled up for high throughput FG screens to study the effect of specific mutations on cellular phenotypes (). However, progress in large scale FG screens has been hampered by a nontrivial modelling of false positives (). For example, many candidate therapeutic targets identified from shRNA screens have failed validation in independent assays (). Among the possible reasons for lack of robustness, one must consider RNAi off target effects, variable potency and knockdown out efficiency of RNAi and crisp r reagents, biological and technical noise in high throughput screens (), cell line specific efficiency of viral pool infection and toxicity from additional viral vector expression cassettes (e.g. fluorescence reporter proteins). This suggests that sophisticated statistical methods may be required to model the complexity of these experiments, thus reducing false positive and negative rates and leading to improved, more robust interpretation of FG screen results. A key computational challenge, in genome scale FG screens, is to score gene level activity from individual reagents. Whole genome FG libraries normally include multiple optimally designed shrna s hairpins or crisp r sg rnas targeting the same gene to increase the likelihood of an effective gene knockdown out. For instance, on average 23 or 5 hairpins per gene were used with gip z () and TRC () shRNA libraries, respectively. Similarly 4 and 10 sg rnas per gene were used in the Zhang () or sabatini lander () crisp r libraries, respectively. It is thus critical that such diverse evidence from multiple shs grn as targeting a gene is integrated when assessing its contribution to a specific endpoint phenotype. In addition, both microarray () and next generation sequencing technologies (NGS) () technologies have been used to quantitatively assess shs grn as representation or abundance in pooled FG screens, each one introducing bias and measurement noise. Traditional methods to summarize gene level activity usually rely on single probe level analysis. Specifically, shRNA are first individually scored and then the scores of representative (e.g. high scoring shrna s or of all shrna s targeting a specific gene are combined. Several algorithms have been proposed to select or combine shrna level evidence, including choosing the second best or most depleted shRNA () riger sb averaging the two shrna s that produced the largest scores () riger ws performing enrichment analysis of all shrna s targeting one gene against all shrna s in the library () riger ks comparing rank distributions of effective size of all shrna s per gene () (RSA) and more recent model based mage ck () and hit select (). An intrinsic limitation with all of these approaches is that they rely on the accurate assessment of an individual shs grn a activity, which is difficult to achieve in large scale screens that typically have a relatively small number of replicate samples. Moreover, off target effects, variable silencing efficiency, differences among shs grn as targeting the same gene, and experimental technical noise make heuristic selection of representative shs grn as problematic, causing significant false discovery rates. To overcome these limitations, we propose a novel screen beam (Screening Bayesian Evaluation and Analysis Method) algorithm via Bayesian hierarchical modeling to directly assess gene level activity from all relevant measurements. Due to its robustness, hierarchical modeling (), also known as multilevel modeling, has been increasingly valuable in large scale d 'omics studies (). In this context, screen beam algorithm analyses all shs grn as targeting the same gene as a set, instead of one at the time, and then fits a linear mixture model that directly models the potential activity variability of different hairpins, as a random effect. This multi probe analysis strategy improves parameter estimation, by increasing sample size, and reduces prediction error and false positive rate, by integrating information from multiple shrna s. Use of Bayesian inference with Markov chain Monte Carlo (MCMC) techniques, in this analysis, further improves accuracy and robustness of scoring metrics. Systematic benchmark assays, using large scale publicly available shRNA (RNAi) and sg rna crisp r screens designed to profile gene essentiality by microarray () or NGS (), suggest that the screen beam method robustly outperforms existing single probe analysis algorithms. The screen beam algorithm improvements are especially significant with assays with lower data quality, which accounts for about 80-95% of the FG screens considered in this manuscript.

discussion meta analysis of shRNA screening data increase gene level inference robustness remains difficult. We proposed a novel multi probe analysis strategy, screen beam (Screening Bayesian Evaluation and screen beam analysis Method), implemented via a Bayesian hierarchical modeling, to address this problem. The evaluation results demonstrated that the screen beam method outperformed traditional single probe analysis approaches (RIGER and RSA) and recent model based methods mage ck and hit select. This was especially relevant when the screen data was in relatively low quality which account for about 8095% cases. Hierarchical modelling, also known as partial pooling, can be viewed as a compromise between two extremes. One extreme, complete pooling, assumes the equal knock-down effect across all shRNA classes targeting the same gene. The other extreme, no pooling, ignores the similarity of the replicates within one shRNA group and treat each hairpin replicate separately. The assumptions of these two extreme methods are too strong for shRNA screening design to be considered for integration of multiple shRNA evidences because different shrna s targeting the same gene in the library might have significantly different silencing efficiencies. Hierarchical modeling comprises two extremes by allowing between group variance and considering within group effects, thus making an appropriate solution to this question. The problem of multiple comparisons can also disappear in Bayesian hierarchical models (). Partial pooling in hierarchical models shifts estimates toward each other whereas classical procedures for multiple comparison correction typically adjust p values corresponding to intervals of fixed width. Thus screen beam fitting results in reliable and conservative estimates for main effects or gene level effects in this context. For single probe analysis strategy, a few other possible algorithms might be considered to integrate shrna level scores for the same gene, for example, Fisher's method () to combine signed p values or stouffer s method to combine z statistics (). However, these integrating p values or z scores methods easily over-estimate the significance of gene level activity and generate a long list of significant candidates. Also, they ignore the magnitude of knock-down effects for each hairpin by only considering the statistical significance of how the effect is away from zero, and require strong assumptions. Thereby, these methods might not be comparable to this screen beam algorithm, or could be even worse than the other single probe analysis methods. Additionally, other enrichment analysis algorithms such as GSA () have been used in this context () and might perform better than ks based g sea method; however, these algorithms still bear the drawbacks of single probe analysis strategy, making them less powerful than screen beam. The valuable point from enrichment type methods that might improve screen beam is to borrow information from all shrna s or genes in the library because current screen beam algorithm only considers shrna s corresponding to one gene. Looking at entire list of candidates might produce more robust statistics for cut off based hits selection, but probably would not change the rank of a gene as a potential candidate. NGS has dominated as a cost effective technology for quantitatively measuring the abundance of short length DNA or RNA in a short time, and this multiplexing parallel technology has been used in genome wide FG shRNA and crisp r sg rna screens. Compared to microarray based approaches, NGS offers several potential advantages in terms of coverage of targeting genes, flexibility of input library, scalability and dynamic range, which will possibly replace microarray for FG screens in the near future, however, the data quality of ngs based genome wide FG screens still has a big room to improve as only 6% of over 250 Achilles screens are in good category, compared to 22% of microarray based data (Supplementary). The two existing best algorithms mage ck and hit select were specifically designed for ngs based count data; however, screen beam can handle both microarray based intensity data and ngs based count data. Using conserved housekeeping genes or RNAi screen identified essential genes as the gold standard of essential genes identified by loss of function screens, we demonstrated that the screen beam algorithm improves the sensitivity by up to 50% of that by classical approaches without loss of precision. Overall, screen beam demonstrated the most robust and consistent performance identifying true hits in all scenarios, even from small sized noisy high throughput screens which accounts for about 8095% of the public datasets. High quality data in high throughput loss of function screens is rarely achieved (22% in microarray based and 6% in ngs based data), due to a variety of error and variability sources. For high quality screens, method selection is less relevant as all of the tested methods had small difference performance. Yet, for the lower quality shs grn as within a high quality dataset, screen beam would still produce significant improvements. As a result, there would be potential advantages even in this kind of datasets. In summary, we developed a novel hierarchical modelling algorithm within Bayesian framework for meta analysis of large scale FG screens. This novel multi probe approach performs more robustly than previously established analysis methods, especially with noisy high throughput data.
