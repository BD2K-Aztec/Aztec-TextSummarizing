Motivation: Many new methods have recently been proposed for detecting epistatic interactions in g was data. There is, however, no in depth independent comparison of these methods yet. Results: Five recent methods team BOOST, snp harvester snp ruler and Screen and Clean (SC)—are evaluated here in terms of power, type 1 error rate, scalability and completeness. In terms of power, TEAM performs best on data with main effect and BOOST performs best on data without main effect. In terms of type 1 error rate, TEAM and BOOST have higher type 1 error rates than snp ruler and snp harvester. SC does not control type 1 error rate well. In terms of scalability, we tested the five methods using a dataset with 100 000 SNPs on a 64 bit Ubuntu system, with Intel (R) xeon r CPU 2.66 GHz, 16 GB memory. TEAM takes ∼36 days to finish and snp ruler reports heap allocation problems. BOOST scales up to 100 000 SNPs and the cost is much lower than that of TEAM. SC and snp harvester are the most scalable. In terms of completeness, we study how frequently the pruning techniques employed by these methods incorrectly prune away the most significant epistatic interactions. We find that, on average, 20% of datasets without main effect and 60% of datasets with main effect are pruned incorrectly by BOOST, snp ruler and snp harvester. Availability: The software for the five methods tested are available from the URLs below.

introduction a genome wide association study g was examines the association between phenotypes and genotypes in a study group. The first exciting finding was on age related macular degeneration (AMD) (), which uncovers a disease allele tyrosine histidine polymorphism) with an effect size of 4.6 in 100 000 single nucleotide polymorphisms (SNPs). Since then, over 600 gw ass have been conducted for 150 diseases and traits; * To whom correspondence should be addressed. and 800 associated SNPs have been reported. The methodologies of these studies are similar: a quality control criteria is first defined to filter the genotype data; then the remaining genotypes are each tested for association with the disease phenotypes. Finally, the significant SNPs are reported after multiple testing correction. Most of these gw ass could only identify disease alleles with moderate effect size. Thus, single SNP association studies could explain very limited heritability of these diseases (). Consequently, researchers have started exploring multi snp interactions in the hope of discovering more significant associations. multi snp interactions are also called 'epistatic interactions'. This term originated from bateson s definition of epistasis 100 ago (). It was defined as the change of segregation ratio and the interaction of genes. However, in the current literature, there is a debate on the exact definition of epistasis (). Our article focuses on evaluating epistatic interaction detection methods in their computational aspect and all the experiments are based on simulation data. Thus, we consider epistatic interactions as the statistically significant associations of k snp interaction (k  2) with phenotypes. There are mainly two types of epistatic interaction detection methods: model based methods and model free methods. In general, model based methods () predefine a statistical model between phenotypes and genotypes; then they fit the data to the model; and finally they output the significant SNPs. They work well for only a small number of important and filtered candidate SNPs; but they often fail when the number of SNPs grows to hundreds of thousands. To make model based methods more efficient, researchers have proposed a variety of heuristic and filtering techniques. For example 2010a develop an upper bound of the likelihood ratio test statistic for two locus epistatic interaction to prune the search space and a Boolean transformation of data to make collection of contingency table information faster. As another example devise a two stage analysis so that the overall analysis is more efficient. As a third example use a stochastic search to identify only 4050 (set by the user) groups of candidate epistatic interactions for follow-up model fitting analysis. In contrast, model free methods () have no prior assumption on the data and the model. Given the genotype data, these methods only examine the test statistic of each possible epistatic interaction with phenotypes propose a minimum spanning tree (MST) structure to represent the data; by traversing this MST, exhaustive compare only approaches based on neural networks while our selected methods cover both data mining and statistical methods. second evaluate multifactor dimensionality reduction (MDR) (), grammatical evolution neural networks (GENN) (), focused interaction testing framework fit f (), random forests (RF) () and logistic regression (LR) () methods. They show that MDR is superior in all settings. After 2 years of advancement, most methods selected in this article have demonstrated that their performance is better than that of MDR; we therefore omit discussing methods mentioned in mot singer compare AMBIENCE (with MDR, restricted partitioning method (RPM) () and logistic regression. They conclude that the performance of AMBIENCE is equivalent to that of logistic regression for two locus models and better than that of RPM and MDR. However, according to, the performance of BOOST is better than that of PLINK (), which uses a pure logistic regression model. Therefore, we omit the evaluation of AMBIENCE and RPM in our study. lastly have shown that their overall performance is much better than that of BEAM (). We thus omit BEAM. In this article, we give an independent empirical comparison of five methods for detecting epistatic interactions namely TEAM (), BOOST (), snp ruler (), snp harvester () and Screen and Clean ()to help users better understand which method is more suitable for their data, which method is good for detecting epistatic interactions with and without main effect and which method is scalable to larger datasets. We also analyze why combining several of these methods can not enhance power. Their basic characteristics are given in. The organization of this article is as follows. We first formulation the problem in Section 2. Then we briefly introduce each of the five methods in Section 3. We describe how the evaluation data is simulated in Section 4 and the detailed setting of each experiment in Section 5. After that, we present the results under each setting in Section 6. Finally, we discuss the performance of each method and provide advice to users in Section 7.

discussion the five methods all demonstrate respective utilities through the experiments results above. No single method is simultaneously the most powerful, the most scalable and has the lowest type 1 error rate in every setting. When users want powerful results and are not concerned with computation cost, we recommend using TEAM and BOOST. Compared with TEAM, BOOST uses a model fitting procedure. If the data fits the model well, the result is usually good page 2942 29362943 the four methods on data with and without main effect. In (a), there are in total 1800 datasets for 18 settings of the simulated datasets, which corresponds to 1800 ground truth. Among these ground truth only 800 of them can be detected by at least one of the four methods, while the best method team identifies 787 ground truth out of 800. This explains why using ensemble methods can not outperform TEAM. Similar observation is illustrated in (b). otherwise, a model free method may be the alternative choice. When users expect moderate running time and power, we recommend using snp ruler. Its pruning technique helps reduce running time albeit at the risk of losing power. If users are conscious of computation cost and have to run very large datasets, we recommend using snp harvester because it only identifies a small number (4050) of groups for the model fitting procedure. Our evaluations are based on simulation results. In a real study, users usually have no idea of the ground truth in the dataset. Hence, it may not be sufficient to rely only on one method to obtain results. We suggest that, if time and computation resources permit, users try both the recommended model free (i.e. TEAM) and model fitting (i.e. BOOST) methods. It is tempting to consider taking a 'majority vote' of the results of two or more methods. For example, let every algorithm report their top three predictions. An SNP pair receives k votes if it is reported by k methods. We select the one with the highest vote as the final prediction. When there is a tie, we choose the one with the lowest p value. Unfortunately, for both types of data tested, we find that an ensemble using such a strategy can not increase power over using solely BOOST or TEAM. In, we see that for data without main effect, BOOST's ground truth predictions highly overlap with the other three methods, so any ensemble can not contribute a significant number of new ground truth predictions. Specifically, the proportion of BOOST's ground truth predictions that are not predicted by the other three methods is 4.1%, while the proportion of the other methods' ground truth predictions not predicted by BOOST is 0.2%. Similarly, for data with main effect, no ensemble can outperform TEAM. Our evaluations above only focus on two locus epistatic interaction. recently provide a general model that can be extended to n locus epistasis. They also provide mathematical details of dissecting the  2 test into different epistatic components. For example, two way epistatic interaction can be partitioned into four epistatic components: additive  additive, additive  dominant, dominant  additive and dominant  dominant. This helps characterize epistatic interactions in a more specific way and provides more physiological insights.
