Motivation: Comparing time courses of gene expression with time courses of phenotypic data may provide new insights in cellular mechanisms. In this study, we compared the performance of five pattern recognition methods with respect to their ability to relate genes and phenotypic data: one classical method k means and four methods especially developed for time series [Short time series Expression Miner (STEM), Linear Mixed Model mixtures, Dynamic Time Warping for omics and linear modeling with r bioconductor limma package]. The methods were evaluated using data available from toxicological studies that had the aim to relate gene expression with phenotypic end-points (i.e. to develop biomarkers for adverse outcomes). Additionally, technical aspects (influence of noise, number of time points and number of replicates) were evaluated on simulated data. Results: None of the methods outperforms the others in terms of biology. Linear modeling with limma is mostly influenced by noise. STEM is mostly influenced by the number of biological repli-cates in the dataset, whereas k means and linear modeling with limma are mostly influenced by the number of time points. In most cases, the results of the methods complement each other. We therefore provide recommendations to integrate the five methods.

introduction comparing time courses from different types of measurements is an important topic in biological research (), because it contributes toward understanding the response of complex cellular systems to perturbations. In particular in toxicogenomics (which stands for the application of omics technologies to toxicology), comparing time courses of gene expression with time courses of phenotypic endpoints (i.e. biomarkers for the adverse outcomes induced by a chemical compound) may help to distinguish gene expression changes related to toxicity from changes not related to toxicity (). the present study focuses on comparing time courses of gene expression with time courses of phenotypic data, also called phenotypic anchoring of gene expression data. Phenotypic anchoring may provide additional insight in the response to perturbations that can not be generated by analyzing gene expression alone. Various statistical tools can be used for phenotypic anchoring (), including pattern recognition. Pattern recognition includes clustering (e.g. k means classification (e.g. support vector machines) and model reduction (e.g. principal component analysis) (). Biological entities belonging to the same cluster are assumed to be functionally related (). In this study, five representative pattern recognition methods were chosen. First, we included a clustering method that is able to remove random patterns, called Short time series Expression Miner (STEM). Removing random patterns is important for datasets with a high number of variables compared with the number of time points (). Secondly, Dynamic Time Warping for omics (DTW4omics), a method that takes into account time delays in biological processes (), is considered. In contrast to clustering methods (which treat all variables in the dataset as equivalent entities), DTW4omics treats the phenotypic data as predefined profiles and searches for genes matching these profiles using a distance metric. Thirdly, Linear Mixed Model (LMM) mixtures, a clustering method correcting for variability between replicates (), is discussed. Furthermore, we applied k means a classical clustering method for static data. Finally, we used a regression method [linear modeling with the r bioconductor package limma (, to find relationships between gene expression and phenotypic endpoints. The five methods were compared with respect to their ability to extract functionally related groups of genes, their sensitivity to measurement noise, the influence of the number of time points and the influence of the number of biological replicates. The technical aspects (influence of noise, number of time points and number of replicates) were evaluated on simulated data, mimicking real expression and phenotypic data. The biological outcome was evaluated exploiting two public datasets from toxicogenomics.

discussion applying pattern recognition methods to toxicogenomics time series of both microarrays and phenotypic endpoints can provide new hypotheses about interactions of the genome with the adverse outcome of exposure to a toxicant. These new hypotheses will guide wet laboratory experiments (e.g. knock down experiments) that aim to verify such new relationships. In this study, we evaluated five pattern recognition methods. The main focus is on methods developed for time series methods, except k means which we added to the study in order to assess the impact of time dependencies on pattern recognition. Another method for static data, that has been frequently applied to time series, is Weighted Correlation Network Analysis wgc na (), which combines correlation analysis with hierarchical clustering (). Clusters obtained by applying static based methods on time series are often less biologically coherent than clusters determined with time series methods (). However, this could not be observed from this study. STEM, LMM mixtures and k means treat all the genes and endpoints as equivalent entities and cluster them all together. As a consequence several endpoints may end up in the same cluster and some clusters will have no endpoints. In our study, having several endpoints within the same cluster was found upon applying STEM, LMM mixtures and k means. Having two or more endpoints within the same cluster has the advantage that similarity between the two endpoints is explicitly known. A drawback of having two endpoints in the same cluster is that one can not really assess whether any particular gene in the cluster is more strongly associated with one endpoint than the other. Another drawback is that one can have only certainty that the gene expressions really match the profile of the endpoint if the endpoint is at the center of the cluster. DTW4omics treats the endpoints as profiles and matches each of the genes to these profiles. Limma uses the endpoints as fixed effects in a regression model. As a consequence, for DTW4omics and limma, each cluster has only one endpoint and a gene can match more than one endpoint or none. Clustering methods that do not correct for random patterns, like LMM mixtures and k means divide the datasets into large clusters. This mostly leads to a large amount of pathways related to a large number of biological processes. Correcting for random patterns (like STEM) results in smaller gene lists, which has the advantage that these lists are mostly easier to interpret. A disadvantage is that if two variables are highly correlated to one of the model profiles by coincidence, the two variables would also be in the same cluster, which leads to false positives. Another drawback is that in cases when the variable is not correlated to one of the model profiles, it is not taken into account for further analysis. In this way information may be lost. While STEM, LMM mixtures, k means and limma find gene expression modifications that covary simultaneously with the investigated endpoints, DTW4omics allows time lags and delays. Because of this property results from applying the DTW4omics approach are more influenced by the number of time points than the two other time series methods (). Limma is more sensitive to noise than the other methods (). LMM mixtures and limma need biological replicates (for modeling the random effects), while STEM, DTW4omics and k means in principle can be applied without having replicates. However, this is not recommended because it decreases the accuracy of STEM, and to a lesser extent, of DTW4omics and limma (). STEM and DTW4omics both use a permutation test for calculating significance. Permutation tests assume independence between subsequent time points, which can be disadvantageous in case clear trends are observed in the data (). LMM mixtures clustering and limma take into account variability between replicates. The consequence of having a low number (23) of replicates is that variability (the random effect in the model) can be overestimated or underestimated. For LMM mixtures, underestimation (respectively, overestimation) of the variability between replicates leads to clustering too strictly (respectively, not strict enough), and as a consequence, may generate false negatives (respectively, false positives). Another disadvantage of LMM mixtures, and of model based clustering in general, is that the algorithm is slow compared with other methods. For limma, underestimation (respectively, overestimation) of the variability between replicates has influence on variance shrinkage and leads to decreased (respectively, increased) sensitivity to detect relationships between genes and phenotypic endpoints, which in its turn leads to false negatives (respectively, false positives for all five methods studied, pathway and GO analysis of these gene lists provided pathways and GO terms that have been previously related with exposure to the particular toxicant or with one of its adverse outcomes (see Supplementary Material). The hallmarks of cancer () review biological processes related to all types of cancer, and the signaling pathways involved in those biological processes. Those hallmarks are: (1) sustaining proliferative signaling; (2) evading growth suppressors; (3) avoiding immune destruction; (4) enabling replicative immortality; (5) tumor promoting inflammation; (6) activating invasion and metastasis; (7) inducing angiogenesis; (8) genome instability and mutation; (9) resisting cell death and (10) deregulating cellular energetics. Because B(a)P is a carcinogen and menadione causes hepatocellular carcinoma, pathways known to be involved in the hallmarks of cancer provide biologically relevant hypotheses to test in follow-up experiments. For B(a)P, in particular signaling pathways related to DNA damage response are relevant (). Examples are signaling pathways involving p53, NFkB and MYC (). For menadione, pathways related to oxidative stress provide relevant hypotheses. Signaling pathways influenced by oxidative stress given in Martindale and Holbrook (2002) include pathways involved in growth arrest, cell proliferation, senescence and apoptosis. All five methods provide biologically relevant pathways and GO terms that are related to the exposure to the toxicant or its adverse outcomes (e.g. cancer, oxidative stress) (see Figs. 25 and Supplementary Material, Section 3). Therefore, in terms of retrieving biologically relevant information, there is no method that outperforms the others. If we compare the results of limma, the only regression based model in the study, with the results for the other correlation and distance based methods, we observe the following. LMM mixtures positively relate the pathway 'direct p53 effectors' to DNA adducts, while limma finds a negative relationship. Four genes of 'direct p53 effectors' are in both the genes lists resulting from LMM mixtures and limma analysis (PCNA, TNFRSF10B, LIF and BAX), which means that these four genes have a positive correlation with DNA adducts, but a negative regression coefficient. This can be explained as follows. The regression coefficient of the limma model gives the relationship between gene expression and DNA adducts, when all other variables in the model (treatment, time) are held constant. This means that the positive relationship observed by determining similarities between the time profiles was due to another (confounding) variable. This shows an advantageous property of limma, namely correcting for confounding factors. For the menadione dataset (dataset), limma can not find any pathways related to oxidative DNA damage, while all other methods generate a pathway list. For this dataset, applying DTW4omics results in detecting some pathways that can not be found without time warping. One of these pathways is related to the hallmarks of cancer (). This shows the relevance of having a method taking into account time delays. Applying the methods for phenotypic anchoring described in this article results in poorly overlapping gene lists. This is a general problem of clustering algorithms. There are several reasons for the lack of consistency between methods. First, parameters (optimal number of clusters, thresholds) are determined by statistical means and not on biological properties (). Second, differences in output are due to different intrinsic properties of these methods. Limma is a regression method, while the other methods are based on similarity measures (correlation, distance). Other differences in intrinsic properties (taking into account time dependencies, delays, variance; correcting for random patterns) are shown in. For static based methods, several attempts have already been undertaken to address these issues. wgc na selects thresholds based on scale free topology, a network property previously observed in biological networks (). Consensus clustering attempts to combine the different approaches, capturing the advantageous properties of each methods (). However, to our knowledge, similar attempts have not been undertaken for methods developed for time series, taking into account time dependencies and delays. In summary, we conclude that all five methods are suitable for extracting new hypotheses concerning gene phenotypic endpoint relationships and none of the five methods outperforms the others in terms of biology. Furthermore, all methods have their limitations. Because these methods provide complementary results, we recommend developing a method that integrates the results from the different methods. A possible way to do this is to calculate a weighted score for the probability of each gene endpoint relationship based on the accuracy of the methods. Simulation experiments can guide the choice of the weight for each method. For example, because STEM was highly influenced by the number of biological replicates, we decrease the weight for STEM when having less replicates. In a similar way, we can adapt the weight of k means and limma according to the number of time points. We can then multiply the false discovery rate for each pathway with this probability score in order to correct for inaccuracies due to the low number of replicates and or time points.
