Motivation: Calculating the edit distance (i.e. minimum number of insertions, deletions and substitutions) between short DNA sequences is the primary task performed by seed and extend based mappers, which compare billions of sequences. In practice, only sequence pairs with a small edit distance provide useful scientific data. However, the majority of sequence pairs analyzed by seed and extend based mappers differ by significantly more errors than what is typically allowed. Such error abundant sequence pairs needlessly waste resources and severely hinder the performance of read mappers. Therefore, it is crucial to develop a fast and accurate filter that can rapidly and efficiently detect error abundant string pairs and remove them from consideration before more computationally expensive methods are used. Results: We present a simple and efficient algorithm, Shifted Hamming Distance (SHD), which accelerates the alignment verification procedure in read mapping, by quickly filtering out error abundant sequence pairs using bit parallel and simd parallel operations. SHD only filters string pairs that contain more errors than a user defined threshold, making it fully comprehensive. It also maintains high accuracy with moderate error threshold (up to 5% of the string length) while achieving a 3-fold speed up over the best previous algorithm (Gene myers s bit-vector algorithm). SHD is compatible with all mappers that perform sequence alignment for verification. Availability and implementation: We provide an implementation of SHD in C with Intel SSE instructions at: https://github.com/CMU-SAFARI/SHD.

introduction the emergence of massively parallel sequencing technologies, commonly called high throughput sequencing platforms, during the past decade triggered a revolution in the field of genomics. These platforms enable scientists to sequence mammalian sized genomes in a matter of days, which has created new opportunities for biological research. For example, it is now possible to investigate human genome diversity between populations 1000 Genomes Project), find genomic variants likely to cause disease () and ancient hominids () to better understand human evolution. However, these new sequencing platforms drastically increase the computational burden of genome data analysis. In the first step of data analysis, billions of short DNA segments (called reads) are aligned to a long reference genome. Each read is mapped to one or more sites in the reference based on similarity with a process called read mapping. Read mappers typically fall into one of two main categories: suffix array and backtracking based (; Langmead and Salzberg 2012; Li and Durbin 2010) or seed and extend based (). suffix array based mappers use the burrows wheeler transformation () and are efficient at finding the best mappings of a read. Mappers in this category use aggressive algorithms to build their candidate pools, which may miss potentially correct mappings. Although mappers in this category can also be configured to achieve higher sensitivity by systematically inspecting all possible error scenarios of a read, such configuration increases their execution times super linearly (; Langmead and Salzberg 2012; Li and Durbin 2010). Alternatively, seed and extend based mappers build comprehensive but overly large candidate pools and rely on filters and local alignment techniques to remove incorrect mappings (i.e. potential mappings with more errors than allowed) from consideration in the verification step. Mappers in this category are comprehensive (find all correct mappings of a read) and accurate (do not provide incorrect mappings), but waste computational resources identifying and rejecting incorrect mappings. As a result, they are slower than suffix array based mappers. Fast and accurate filters, which detect and reject incorrect mappings using cheap heuristics can increase the speed of seed and extend mappers (by speeding up the verification procedure,) while maintaining their high accuracy and comprehensiveness. An ideal filter should be able to quickly verify the correctness of a mapping, yet require much less computation than rigorous local alignment, which precisely calculates the number of errors between the read and reference using dynamic programming methods. More importantly, a filter should never falsely remove a correct mapping from consideration, as this would reduce the comprehensiveness of the mapper. Recent work has shown the potential of using single instruction multiple data (SIMD) vector execution units including general purpose GPUs and Intel SSE Intel (2012) to accelerate local alignment techniques (). However, these publications only apply SIMD units to existing scalar algorithms, which do not exploit the massive bit parallelism provided by SIMD platforms. In this article, we present shifted hamming distance (SHD), a fast and accurate simd friendly bit-vector filter to accelerate the local alignment (verification) procedure in read mapping. The key idea of SHD is to avoid wasting computational resources on incorrect mappings by verifying them with a cheap, simd friendly filter before invoking canonical complex local alignment methods. Our studies show that SHD quickly identifies the majority of the incorrect mappings, especially ones that contain far more errors than allowed, while permitting only a small fraction of incorrect mappings to pass SHD which are later filtered out by more sophisticated and accurate filters or by local alignment techniques. This article makes the following contributions: @BULLET We show that for seed and extend based mappers, most potential mappings contain far more errors than what is typically allowed (Section 2). @BULLET We introduce a fast and accurate simd friendly bit-vector filter, SHD, which approximately verifies a potential mapping with a small set of simd friendly operations (Section 3). @BULLET We prove that SHD never removes correct mappings from consideration; hence, SHD never reduces the accuracy or the comprehensiveness of a mapper (Section 3). @BULLET We provide an implementation of SHD with Intel SSE (Section 3) and compare it against three previously proposed filtering and local alignment implementations (Section 4), including an SSE implementation of the smith waterman algorithm, swps3 (); an implementation of Gene myers s bit-vector algorithm, seq an (D ring et al., 2008) and an implementation of our Adjacency Filtering algorithm, fast hash (). Our results on a wide variety of real read sets show that SHD SSE is both fast and accurate. SHD SSE provides up to 3 speed up against the best previous state of the art edit distance implementation (D ring et al., 2008) with a maximum false positive rate of 7% (the rate of incorrect mappings passing SHD).
