We present a new C implementation of an advanced Markov chain Monte Carlo (MCMC) method for the sampling of ordinary differential equation (ODE) model parameters. The software mcmc clib uses the simplified manifold metropolis adjusted Langevin algorithm sm mala which is locally adaptive; it uses the parameter manifolds geometry (the Fisher information) to make efficient moves. This adaptation does not diminish with MC length, which is highly advantageous compared with adaptive Metropolis techniques when the parameters have large correlations and or posteriors substantially differ from multivariate Gaussians. The software is standalone (not a toolbox), though dependencies include the GNU scientific library and sundials libraries for ODE integration and sensitivity analysis. Availability and implementation: The source code and binary files are freely available for download at http://a-kramer.github.io/mcmc_clib/. This also includes example files and data. A detailed documentation, an example model and user manual are provided with the software.

introduction modeling intracellular reaction networks by ordinary differential equations (ODES) has become a standard approach in systems biology. ODEs provide a quantitative and dynamic description of the underlying biochemical processes. However, parameter estimation for these models is a challenging task, as typically only few data points are available, and the respective optimization problem is ill posed. That is, the data do not contain sufficient information to identify parameter values uniquely. In a statistical Bayesian framework, this results in high correlations of parameters and or multiple modes in the posterior distribution. Standard sampling algorithms frequently fail when facing those problems. The Metropolis algorithm in its original form (), for example, is elegant and easy to implement but uses an isotropic distribution to suggest the next set of parameters and struggles with complicated posteriors. In the case of strongly correlated parameters, some directions are highly prohibitive because of low likelihoods, whereas others are permissive because of low sensitivity of the model output in these directions, i.e. flat likelihoods. This results in highly auto-correlated samples and extremely slow convergence rates. Adaptive variants of Metropolis that try to amend this problem do exist; they use diminishing adaptation that can deal with strong correlations of sampling variables in some cases. One such implementation is described in. The adaptive Metropolis algorithm adapts to the posterior by estimating its covariance from previously sampled points. While this can drastically increase sampling efficiency for densities that are similar to Gaussians, it struggles with more complex cases. To date, sampling techniques that put more computational effort into the proposal step are often implemented in high level programming languages only and so are not efficient computationally. This prompted our efforts to provide a highly efficient specialized tool that spends most of its running time on the solution of initial value problems. We introduce mcmc clib an implementation of sm mala (simplified manifold metropolis adjusted Langevin algorithm), a sampling algorithm, described in Girolami and calder head 2011 that has been shown to outperform simpler sampling algorithms.
