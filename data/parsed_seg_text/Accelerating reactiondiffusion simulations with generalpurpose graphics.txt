We present a massively parallel stochastic simulation algorithm (SSA) for reaction diffusion systems implemented on Graphics Processing Units (GPUs). These are designated chips optimized to process a high number of floating point operations in parallel, rendering them well suited for a range of scientific high performance computations. Newer GPU generations provide a high level programming interface which turns them into general purpose Graphics Processing Units gp gpus. Our SSA exploits gp gpu architecture to achieve a performance gain of two orders of magnitude over the fastest existing implementations on conventional hardware. Availability: The software is freely available at

introduction treating chemical reaction systems as spatially homogeneous is insufficient for many applications in a biological context. Often, spatial distributions play an important role in the dynamic evolution of biomolecular systems. The analysis of such systems requires accurate yet highly performant simulation algorithms that can handle spatially inhomogeneous reaction diffusion (). Unfortunately, stochastic simulation methods for this problem are computationally extremely expensive and it thus becomes necessary to build parallel versions of existing algorithms (). gp gpus can potentially provide high performance computing resources to a broad audience and are consequently becoming increasingly popular for scientific computing. In the present article, we present a data parallel gp gpu implementation of an SSA, which achieves significant performance gains over the fastest conventional implementations. To the best of our knowledge, this is the first time that a data parallel gp gpu implementation of a quantitative SSA for spatially heterogeneous reaction diffusion networks is reported. Several approaches to compute the stochastic time evolution of reaction diffusion networks can be found in the literature, such as agent based models (), first passage kinetic * To whom correspondence should be addressed. Monte Carlo algorithms () or, on a mesoscopic level, compartment based models, such as the next sub volume Method (NSM) (). Not all these methods lend themselves equally well to a data parallel implementation on gp gpus. The standard algorithms, based on gillespie s next reaction method (), perform an event based simulation in which global communication is required to compute the next event time as well as to determine the corresponding reaction. Due to the high cost of global synchronization and inter-node communication, attempts to implement the Gillespie SSA directly on gp gpus could only yield moderate performance gains (). Petzold and pursue a different approach by running many instances of the same model in parallel on a gp gpu. This technique allows immediate parallelization of sequential algorithms but can not speed up individual runs and can thus only exploit the full hardware potential if a large number of simulations are required. For a full parallelization, methods that treat diffusion seperately from reactions appear to be more promising. Such methods are termed hybrid. One can distinguish between deterministic stochastic algorithms, where diffusion is handled in a deterministic manner (), and stochastic stochastic methods, which are preferable for cases where the diffusive species is not necessarily present in high densities. Two prominent examples of the latter type of hybrid algorithms are the Gillespie Multiparticle Method (GMP), first presented by, and the Multinomial Simulation Algorithm (MSA) (). In this article, we report a gp gpu implementation of GMP. Hybrid stochastic reaction diffusion algorithms are an active and relatively recent field of research and no clear champion has emerged yet. Cellular automata methods are widely used to simulate reaction diffusion systems for a comprehensive review]. In particular, the multiparticle lattice gas algorithm underlying GMP () has been successfully applied, for example, to problems in electrochemistry (). Its applicability to biochemical pathways has been shown in a number of studies, e.g. for the phosphoenolpyruvate dependent phosphotransferase (PTS) pathway in Escherichia coli (). We believe that MSA should in principle be just as well suited for a data parallel implementation. However, the free availability of the source code made GMP our first choice. A detailed comparison of computational methods for reaction diffusion networks is given by. For completeness, we point out that the deterministic treatment of reaction diffusion equations with gp gpus has a long history in the context of computer graphics. The driving motivation behind

discussion we have described an implementation of the Gillespie Multiparticle Method (GMP) on gp gpus. We report performance gains of two orders of magnitude compared with standard implementations of the (exact) inhomogeneous stochastic simulation algorithm and the (hybrid) serial implementation of GMP. Like any other hybrid method, GMP sacrifices some numerical accuracy for performance gains. This trade-off can in principle be arbitrarily adjusted through the choice of the diffusion time step. For a more detailed discussion, we refer the reader to Section 2.2.7 of the Supplementary Material. We provide a full simulation system inch man that allows the user to run their models without any coding (on the Monash Sun Grid GPU cluster). Access to this system is via an easy to use web interface 3 that understands systems biology markup language (SBML) specifications, the lingua franca of systems biology. In addition, we provide a full implementation of the algorithm on our website. Researchers may use the C++ interface to construct their own reaction diffusion model from scratch. The application programming interface (API) is designed to mimic the structure of SBML models, allowing the user to easily convert their models into gpg mp without having to deal with the internal details of the simulation algorithm. A variety of test problems that can be used as templates are part of the package. The full source code is included so the user can easily add the relevant GPU implementation into their own projects. Most scientific applications require a reasonable sample size to extract statistic information from the simulations. It is therefore necessary to perform multiple runs of the same problem, possibly with varying input parameters. We pursue a 2-fold approach to tackle this requirement. First, the standard implementation of gpg mp distributes the total number of runs over all available gp gpu cards. This works best if the host machine provides a one to one ratio of CPU cores to gp gpu cards. Second, we are integrating inch man with Nimrod, 4 a toolkit to allow users to run parameter sweeps and parameter optimization and distribute runs over gp gpu clusters. This will become an integral part of the next release of inch man
