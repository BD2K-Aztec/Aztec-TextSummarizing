Motivation: Supervised machine learning is widely applied to transcript omic data to predict disease diagnosis, prognosis or survival. Robust and interpretable classifiers with high accuracy are usually favored for their clinical and translational potential. The top scoring pair (TSP) algorithm is an example that applies a simple rank based algorithm to identify rank altered gene pairs for classi-fier construction. Although many classification methods perform well in cross validation of single expression profile, the performance usually greatly reduces in cross study validation (i.e. the prediction model is established in the training study and applied to an independent test study) for all machine learning methods, including TSP. The failure of cross study validation has largely diminished the potential translational and clinical values of the models. The purpose of this article is to develop a meta analytic top scoring pair metak tsp framework that combines multiple transcript omic studies and generates a robust prediction model applicable to independent test studies. Results: We proposed two frameworks, by averaging TSP scores or by combining p values from individual studies, to select the top gene pairs for model construction. We applied the proposed methods in simulated data sets and three large scale real applications in breast cancer, idiopathic pulmonary fibrosis and pan cancer methylation. The result showed superior performance of cross study validation accuracy and biomarker selection for the new meta analytic framework. In conclusion , combining multiple omics data sets in the public domain increases robustness and accuracy of the classification model that will ultimately improve disease understanding and clinical treatment decisions to benefit patients.

introduction high throughput experimental techniques, including microarray and massively parallel sequencing, have been widely applied to discover underlying biological processes and to predict the multi causes of complex diseases (e.g. cancer diagnosis,), prognosis (van de) and therapeutic outcomes,). The associated data analysis has brought new statistical and bioinformatic challenges and many new methods have been developed in the past 15 years. In particular, methods for classification and prediction analysis (a.k.a. supervised machine learning) are probably the most relevant tools towards translational and clinical applications. Take breast cancer as an example, many expression based biomarker panels have been developed [e.g. mamma print (van 't), on co type DX (), Breast Cancer Index BCI () and PAM50 (for classification prediction of survival, recurrence, drug response and disease subtype. Reproducibility analysis of these markers and classification models has been a major concern and has drawn significant attention to ensure clinical applicability of these panels (). Many articles have focused on normalization, reproducibility of marker detection, inter lab or inter platform correlation concordance. For direct clinical utilities, more attention have shifted towards cross study validation or inter study prediction (i.e. a prediction model is established in one study and validated independently in a test study (). Such an issue is critical for translating models from transcript omic studies into a practical clinical tool. For example, the training cohort may have utilized an old Affymetrix U133 platform. A biomarker panel and a model are constructed and a test study from a different medical center using an rnase q platform is available. A successful machine learning model should retain high prediction accuracy in such inter lab and inter platform validation. We note that many normalization methods have been developed to adjust for systematic biases across studies, including distance weighted discrimination (), cross platform normalization () and k norm correlation (). But the normalization performance largely depends on whether the observed data structure fits the model assumptions. In most applications, researchers have applied meta analysis methods and have avoided relying on effectiveness of normalization (). To compare the meta analysis methods with mega analysis (i.e. normalize across studies and directly merge data for inference) in this article, we only perform simple quantile normalization within each study and then standardize each sample to mean zero and unit SD before we adopt mega analysis. In addition to the issue of cross study validation, it's critical to select a robust and accurate machine learning method. In the literature, many supervised machine learning methods have been proposed and applied to high throughput experimental data. For example, the CMA package allows easy implementation of 21 popular classification methods such as linear or quadratic discriminant analysis, lasso, elastic net, support vector machines (SVMs), random forest, PAM etc (). In addition to these popular methods, the top scoring pair (TSP) method () is a straightforward prediction rule utilizing building blocks of rank altered gene pairs in case and control comparison (see Section 2.1 for more details). The method is mostly rank based without any model parameter. It is invariant to monotone data transformation and the feature selection and the model are more transparent for biological interpretation. Although TSP and its variant are robust methods that do not require normalization in cross study validation, we have found that some of the selected TSPs from the training study may not reproduce in the test study possibly due to platform differences illustrates the expression levels of a good TSP gene pair, it gax and XBP1, identified from the first IPF (idiopathic pulmonary fibrosis) training study embl om (see data descriptions in Supplementary). XBP1 is over-expressed than it gax in control samples but under expressed in cases. If we use this TSP to validate in the test study Konishi, we find that XBP1 is over-expressed than it gax in both cases and controls and we obtain 0% sensitivity and 100% specificity (i.e. you den index  sensitivity  specificity  1  0). We found similar poor performance in two other studies Tedrow B and Pardo, showing that the TSP is likely a false positive. In, GPR160 is over-expressed than COMP in controls and under expressed in cases for all three studies embl om Tedrow B and Pardo. It is a more reliable TSP across three studies and conceptually is less likely a false positive. Indeed, the cross study validation in Konishi shows good performance with 80% you den index. The two real examples in argue the potential of a meta analytic approach by combining multiple training trans crito mic studies to identify reliable TSPs so the resulting model has enhanced cross study validation performance. In this article, we propose three meta analytic approaches for TSP method meta tsp by combining information across multiple training studies using (i) averaged TSP scores (ii) combining p values via Fisher's method () (iii) combining p values via stouffer s method (). To decide the number of TSPs used for model construction, a classical cross validation (CV) method and a variance optimization (VO) () method are applied and compared. Simulations and three real omics data sets (two gene expression data on breast cancer and IPF, and. Two TSP examples from real data to show advantage of meta tsp. x axis and Y-axis refer to sample indices and gene expression levels, respectively. (A) Gene pair ITGAX/XBP1 has high TSP score (XBP1  it gax in controls but it gax  XBP1 in cases) in the training embl om study but fail to replicate in the testing 'Konishi' study as well as the other two Tedrow B and Pardo studies. (B) Gene pair GPR160/COMP has high TSP scores (GPR160  COMP in controls and COMP  GPR160 in cases) in all three training studies embl om 'Tedrow B' and 'Pardo'. The gene pair is successfully validated in the testing 'Konishi' study one pan cancer methylation data) are used to benchmark the cross study validation performance.
