Motivation: Optical flow is a key method used for quantitative motion estimation of biological structures in light microscopy. It has also been used as a key module in segmentation and tracking systems and is considered a mature technology in the field of computer vision. However, most of the research focused on 2D natural images, which are small in size and rich in edges and texture information. In contrast, 3D time-lapse recordings of biological specimens comprise up to several terabytes of image data and often exhibit complex object dynamics as well as blurring due to the point spread function of the microscope. Thus, new approaches to optical flow are required to improve performance for such data. Results: We solve optical flow in large 3D time-lapse microscopy datasets by defining a Markov random field (MRF) over super voxels in the foreground and applying motion smoothness constraints between super voxels instead of voxel wise. This model is tailored to the specific characteristics of light microscopy datasets: super voxels help registration in texture less areas, the MRF over super voxels efficiently propagates motion information between neighboring cells and the background subtraction and super voxels reduce the dimension-ality of the problem by an order of magnitude. We validate our approach on large 3D time-lapse datasets of Drosophila and zebrafish development by analyzing cell motion patterns. We show that our approach is, on average, 10 Ã‚ faster than commonly used optical flow implementations in the Insight Tool-Kit (ITK) and reduces the average flow end point error by 50% in regions with complex dynamic processes, such as cell divisions. Availability: Source code freely available in the Software section at

introduction automated computational techniques are essential for the quantitative analysis of cellular dynamics using time-lapse light microscopy. For example, to quantitatively reconstruct the development of large multi-cellular organisms such as entire Drosophila and zebrafish embryos, tens of thousands of cells need to be segmented and tracked at high spatial resolution () (). Such analyses are of fundamental importance to understanding the development of biological tissues, to reconstructing functional defects in mutants and disease models and to quantitatively dissecting the mechanisms underlying the cellular building plan of entire complex organisms (). However, many computational challenges are encountered when performing key tasks, such as image registration, cell segmentation and cell tracking, in complex microscopy datasets (). Optical flow computation is one of the central tasks used to perform quantitative motion estimation of biological structures in time-lapse light microscopy, from the subcellular level to the tissue scale (). Optical flow is defined as the vector field capturing the motion of brightness patterns between adjacent volumes in time (; since our examples are 3D images, we use the term 'volume' to refer to the datasets used in optical flow computation. However, our approach and code work also for 2D images). On the cellular level, optical flow information can theoretically be obtained from single cell tracking data. However, comprehensive and accurate cell tracking in complex multicellular organisms is currently an open research problem (). Here, optical flow methods can be useful for analyses of group dynamics, which do not require single cell resolution, or, conversely, as the first module in a larger cell tracking framework. In this latter scenario, the flow information informs the tracking algorithm and helps improving results for regions exhibiting complex or fast cell dynamics. Optical flow computation has been the object of decades of research, and it is considered a mature technology in many computer vision applications (). However, most approaches have been tested in relatively small 2D natural images, which are dense and rich in edges and texture information. The Middlebury database () used as a benchmark in the computer vision community is a good example of these types of images. Fluorescence microscopy volumes of biological structures are qualitatively very different from natural images (). They are sparse (in datasets similar to, 8095% of voxels are background; throughout the text, we use the term 'voxel' to generically refer to each intensity value in a dataset independent of the dimensionality of the data) and contain relatively texture less objects, which typically appear blurred *To whom correspondence should be addressed.  The Author 2012. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. owing to the point spread function of the microscope and the characteristics of commonly used fluorescent labeling strategies. Moreover, neighboring objects with similar appearance and multiple motions in the same volume are very common. Finally, microscopy volumes tend to be much larger than natural images, which demands computationally efficient approaches. Here, we present a new algorithm for optical flow estimation tailored to large fluorescence light microscopy 3D time-lapse datasets as the one shown in. The key idea is to define a model that takes into account the specific characteristics of time-lapse microscopy data. In particular, we define a Markov random field (MRF) over super voxels to improve registration in texture less areas, propagate motion information efficiently between neighboring structures and speed up computations by reducing the complexity of the problem.

discussion we developed and tested a new model for optical flow tailored to microscopy volumes, in which a large fraction of the objects are texture less and similar in appearance. Moreover, the information in the volume tends to be sparse because many voxels do not contain any information and cellular dynamics can be very variable. A key idea in our approach is to generate a volume partition graph over the foreground voxels, and to perform optical flow directly on that model instead of computing it at the voxel level. This model is tailored to the specific characteristics of time-lapse light microscopy datasets, as it provides the regularization needed to solve optical flow robustly for these types of volumes. At the same time, our method reduces the complexity of the problem by an order of magnitude, which is an invaluable advantage when working with large 3D datasets. In Section 4.1, we showed that the method might fail in some extreme cases for $1% of the nuclei, when neighboring nuclei move in opposite directions. In those scenarios, we are left only with the data term to determine the correct flow. Thus, a possible future direction would be to use different features or point descriptors in the volume intensity to increase robustness of the data term (). It is also possible to constrain the flow field to a diffeomorphism, as two objects can not originate from the same source point. Finally, if a faster implementation is required, it is straightforward to parallelize the computation of the data term in Equation (3) for each super voxel using GPU technology. At the moment, this operation takes $40% of the time for each function evaluation in the quasi newton method, and it is thus a primary candidate for code optimization.
