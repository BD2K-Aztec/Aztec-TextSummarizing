Motivation: term enrichment analysis facilitates biological interpretation by assigning to experimentally computationally obtained data annotation associated with terms from controlled vocabularies. This process usually involves obtaining statistical significance for each vocabulary term and using the most significant terms to describe a given set of biological entities, often associated with weights. Many existing enrichment methods require selections of (arbitrary number of) the most significant entities and or do not account for weights of entities. Others either mandate extensive simulations to obtain statistics or assume normal weight distribution. In addition, most methods have difficulty assigning correct statistical significance to terms with few entities. Results: Implementing the well known lugana nni rice formula, we have developed a novel approach, called saddle sum that is free from all the aforementioned constraints and evaluated it against several existing methods. With entity weights properly taken into account, saddle sum is internally consistent and stable with respect to the choice of number of most significant entities selected. Making few assumptions on the input data, the proposed method is universal and can thus be applied to areas beyond analysis of microarrays. Employing asymptotic approximation, saddle sum provides a term size dependent score distribution function that gives rise to accurate statistical significance even for terms with few entities. As a consequence, saddle sum enables researchers to place confidence in its significance assignments to small terms that are often biologically most specific. Availability: Our implementation, which uses Bonferroni correction to account for multiple hypotheses testing, is available at

introduction a major challenge of contemporary biology is to ascribe interpretation to high throughput experimental or computational results, * To whom correspondence should be addressed where each considered entity (gene or protein) is assigned a value. Biological information is often summarized through controlled vocabularies such as Gene Ontology (GO;), where each annotated term includes a list of entities. Let w denote a collection of values, each associated with an entity. Given w and a controlled vocabulary, enrichment analysis aims to retrieve the terms that by statistical inference best describe w, that is, the terms associated with entities with a typical values. Many enrichment analysis tools have been developed primarily to process microarray data (). In terms of biological relevance, the performance assessment of those tools is generally difficult. It requires a large, comprehensive 'gold standard' vocabulary together with a collection of w's processed from experimental data, and with true false positive terms corresponding to each w correctly specified. This invariably introduces some degree of circularity because the terms often come from curating experimental results. Before declaring efficacy in biological information retrieval that is non-trivial to assess, an enrichment method should pass at least the statistical accuracy and internal consistency test. In their recent survey list 68 distinct bioinformatic enrichment tools introduced between 2002 and 2008. Most tools share a similar workflow: given w obtained by suitably processing experimental data, they sequentially test each vocabulary term for enrichment to obtain its p value (the likelihood of a false positive given the null hypothesis). Since many terms are tested, a multiple hypothesis correction, such as Bonferroni () or false discovery rate (FDR;), is applied to p value of each to obtain the final statistical significance. The results are displayed for the user in a suitable form outlining the significant terms and possibly relations between them. Note that the latter steps are largely independent from the first. To avoid confounding factors, we will focus exclusively on the original enrichment p values. Based on the statistical methods employed, the existing enrichment tools can generally be divided into two main classes. The singular enrichment analysis (SEA) class contains numerous tools that form the majority of published ones (). By ordering values in w, these tools require users to select a number of top ranking entities as input and mostly use hypergeometric distribution (or equivalently Fisher's exact test) to obtain the term p values. After the selection is made, SEA treats all entities equally, ignoring their value differences. The gene set analysis (GSA) class was pioneered by the gene set enrichment analysis g sea tool (). Tools from this class use all values (entire w) to

discussion approximating the distribution of sum of weights by saddle point method, our saddle sum is able to adapt itself equally well to Page: 2758 27522759
