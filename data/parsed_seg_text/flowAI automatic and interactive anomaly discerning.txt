Motivation: Flow cytometry (FCM) is widely used in both clinical and basic research to characterize cell phenotypes and functions. The latest FCM instruments analyze up to 20 markers of individual cells, producing high dimensional data. This requires the use of the latest clustering and dimen-sionality reduction techniques to automatically segregate cell sub-populations in an unbiased manner. However, automated analyses may lead to false discoveries due to inter sample differences in quality and properties. Results: We present an R package, flow a i containing two methods to clean FCM files from un-wanted events: (i) an automatic method that adopts algorithms for the detection of anomalies and (ii) an interactive method with a graphical user interface implemented into an R shiny application. The general approach behind the two methods consists of three key steps to check and remove suspected anomalies that derive from (i) abrupt changes in the flow rate, (ii) instability of signal acquisition and (iii) outliers in the lower limit and margin events in the upper limit of the dynamic range. For each file analyzed our software generates a summary of the quality assessment from the aforementioned steps. The software presented is an intuitive solution seeking to improve the results not only of manual but also and in particular of automatic analysis on FCM data. Availability and implementation: R source code available through Bioconductor: http://bioconduc tor org packages flow a i Contacts:

introduction flow cytometry (FCM) is a laser based methodology designed to capture the physical and biochemical characteristics of a cell or a particle in a stream of fluid. fluorescence conjugated antibodies are used to target antigens expressed inside or at the surface of the cells of interest. As cells pass through the laser (excitation), the fluorochrome will change its state of energy and emit a light (emission) that is captured by a series of detectors. FCM applications have been developed mainly for both research and clinical settings in medicine but also for other non biomedical domains such as marine and plant biology. The most common application is the immune phenotyping of blood samples and thus the quantification of the number and frequency of various immune cell populations. In hematology, FCM is the technology of choice, as, for example, it requires only few drops of blood to diagnose leukemia through the detection of the perturbation of normal cell frequencies (). Moreover, FCM helped increase our understanding of cellular functions of the immune system and is widely used in cell cycle analysis, pre transplant cross matching cell sorting, apoptosis, vaccine development and other applications that scrutinize cellular properties(). The data are stored in Flow Cytometry Standard (FCS) files that include the fluorescence and scattered light levels for each cell that passed through the laser beams. Nowadays it is possible to analyze up to 20 markers at a time in a single staining panel by using an equal number of different fluorochromes detected in separate channels. The common approach used to analyze the data produced by FCM is to visually select cells of interest through 1 or 2 markers known to be highly specific. However, to delineate the high heterogeneity of immune cell populations, it is necessary to look simultaneously at the whole staining panel. Principal component analysis has been used to detect the complexity in CD8 T cell populations characterized by intermediate phenotypes that show a continuum of expression of different combinations of cytokines and surface markers (). Another dimensionality reduction technique called t distributed Stochastic Neighbor Embedding tsn e () was successfully applied to identify ambiguous cell populations, including monocyte macrophage intermediates and granulocyte variants in a mass cytometry experiment based on a 38 antibody panel (). Several computational tools that aim to automatically characterize cell populations without losing multi-dimensional information are constantly developed and periodically benchmarked by the flow cap consortium (). Undoubtedly, the widest range of tools has been distributed by the BioConductor platform based on the R programming language. The root package for FCM data is flow core since it defines the container class and it enables to perform essential manipulations such as compensation and transformation (). In addition, a series of complementary packages has been developed for further operations, such as visualization, quality assessment, statistical analysis and automated gating (). To accompany and support the large development of automatic methods to define populations, it is crucial to use high quality FCM data as input in order to optimize the robustness of the results. This is especially true since research is looking deeper into the complexity of cell distribution. For instance, target cell sub-populations may represent as low as 0.05% of the total cell population suggesting that minute variation in the quality of the data may lead to false positive results or loss of signal. Standardization, calibration and quality control guidelines using beads have been defined to ensure that the signal acquired is the most accurate and with the least variation (). Nonetheless, these procedures are not always carefully monitored and even having the FCM instrument at optimal conditions before sample processing does not exclude electronic drifts or fluidic instability issues at the time of data recording. An R package, flow q (), creates concise reports of quality checks on single and multi panel experiments to highlight issues that can be encountered in data acquisition. The reports indicate the number of cells, percentage of boundary events and anomalies on the fluidics and signal acquisition over time. Another package, flow clean (), determines and marks low quality cells using compositional data analysis. In brief, it splits the time in equally sized bins and flags the events that are within time frames containing unusual ratios of cell populations. However, flow q does not actively detect and remove the anomalies and flow clean is poorly intuitive and thus it does not allow to infer the source of the anomalies. We present our package called flow a i that provides two solutions, one automatic and one interactive, to discard cells from FCM data that do not reach appropriate quality standards. Our workflow adapts and expands previous ideas with methods never implemented before to provide a more objective, efficient and intuitive solution for the quality control of FCM data.

conclusion over the last few years, we have seen increasing efforts in automati zing pipelines of biomedical data analysis through computational algorithms. FCM is still one technique that hardly abandons the concept of manual analysis since usually the data produced has high variability that requires human interpretation. Often, the analysis demands high expertise and the results are still conditioned by a subjective evaluation. Our idea was born from the intention of removing the technical variability of FCM data in an objective way, thus reducing subjective ness in interpretations and improving the performance of downstream computational analyses. This is especially the case when a high number of files is analyzed and when anomalies are generated by multiple sources. We defined an approach and created an R package, flow a i to automatically or interactively detect anomalies in FCM data. First, anomalous patterns and peaks are removed from the flow rate automatically by a method built upon time series decomposition and the 1 0 5 0 1 0 0 1 5 0 2 0 0 3 1 5 3 0 4 5 6 0. Running time of a quality control analysis with the automatic method of flow a i. The graphics' creation for the full report, that is fundamental for an accurate examination, takes a considerable amount of time. Alternatively, a mini report containing only the percentages of anomalies is produced without significant running time increase flow a i generalized ESD test. Second, the tool checks the stability of the signal over time for each channel; here the automatic method uses a change point algorithm to detect durable shifts in the mean or variance of the acquisition values. Lastly, the dynamic range of the values acquired for each channel is refined. The upper limit is cleared of the margin events and the lower limit is cleared of the negative outliers. From the use of the flow a i package, we expect a general improvement in the quality of research that employs FCM instruments. Removing events with erratic intensity values will facilitate different aspects of FCM analysis such as: (i) more effective compensation since the overlap signal is subtracted only from real values; (ii) more accurate detection of rare cells due to the removal of background noise; (iii) easier characterization of the nature of an ambiguous cell population (either as undefined cell type or as technical issue). When using the automatic method for the quality control of a dataset of FCS files, it is preferable to infer the optimal settings for a dataset using a sample of few FCS files. In fact, because of the intuitiveness of the flow a i report, it is easy to infer the source of recurrent anomalies in a FCM experiment. Subsequently, the automatic method of flow a i can be run on the entire dataset with customized settings. Lastly, because the automatic quality control might still not meet the expectations for certain FCS files, the checking of the full reports reveals where it is necessary to intervene manually with the interactive method of flow a i or with another method. This last point is a limitation of flow a i that could be overcome by the dynamic adjustment of the settings of the automatic method, but for now it remains an open question that warrants further investigation. An additional consideration is that flow a i is designed to detect anomalies within a single FCS file, hence, other tools are necessary to check for anomalies between batches of FCS files. Also, another challenging task is the designing of a complete automatic pre-processing pipeline. In conclusion, our quality control approach produces a comprehensive check of the FCM data implementing algorithms never employed before. We recommend the usage of flow a i as a first preprocessing step of the data right after they are obtained from the FCM instrument so that all the downstream analyses, from compensation to detection or rare cells, will benefit from it.
