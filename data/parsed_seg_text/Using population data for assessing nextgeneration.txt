Motivation: During the past 4 years, whole exo me sequencing has become a standard tool for finding rare variants causing Mendelian disorders. In that time, there has also been a proliferation of both sequencing platforms and approaches to analyse their output. This requires approaches to assess the performance of different methods. Traditionally, criteria such as comparison with microarray data or a number of known polymorphic sites have been used. Here we expand such approaches, developing a maximum likelihood framework and using it to estimate the sensitivity and specificity of whole exo me sequencing data. Results: Using whole exo me sequencing data for a panel of 19 individuals, we show that estimated sensitivity and specificity are similar to those calculated using microarray data as a reference. We explore the effect of frequency misspecification arising from using an inappropriately selected population and find that, although the estimates are affected, the rankings across procedures remain the same. Availability and implementation: An implementation using Perl and R can be found at busson clac uk (Username: igm101; Password: Z1z1nts).

introduction the identification of sequence variants predisposing to diseases that follow Mendelian inheritance patterns is a common application of next generation sequencing technologies (). A key step in these approaches is the identification of variants shared among affected relatives (, b, c). Usually a variant is defined as a deviation from a reference sequence. next generation sequencing of material enriched for exonic sequences has been successful in many cases, but has failed to identify the causative variants in others (). Such apparent failures may have many causes but also focus attention on the desirability of simple measures to assess the results of the sequencing and analysis pipelines used. In disease mapping efforts, it is clearly desirable to have a high probability of identifying a true variant while the number of falsely identified variants remains low. This will reduce the amount of work needed for validation of candidate variants, which is typically undertaken using Sanger sequencing or genotyping approaches. Our objective is to develop a simple and flexible approach for assessing the performance of a whole exo me or genome sequencing experiment. It should allow assessing the whole process, from sample preparation to variant calling. The focus is on the detection of single base sequence variants as opposed to changes in copy number or large rearrangements. One approach is to compare the identified variants with variants known to be present or absent. For this purpose, variants are commonly compared with the results of genotyping microarrays (e.g.). This allows for the probability of a specific variant at a given position in an individual to be considered as either 0 or 1. The price of this certainty is additional experimental costs. An alternative is to use variants where the probability of occurrence in a specific sample can be ascertained, thus allowing the probability of a variant present at a specific position to assume values other than 0 or 1. Here we formalize the second approach using sites known to be polymorphic in the human population. This approach can be seen as an extension of methods that rely on quality criteria such as the number of variants found in sites known to be polymorphic in the human population (e.g.). We compare our results with those obtained using microarray data and use our method to assess different analysis pipelines and to explore the importance of analysis parameters and coverage depth. As we are using known polymorphisms, we also investigate the influence of the population that was used to characterize the polymorphisms on the results. The use of microarrays to assess the accuracy of variant identification is likely to lead to biased results, as the polymorphisms present on microarrays usually exclude variants such as small insertion deletions (indels). Such variants also represent a challenge for variant calling in next generation sequencing. In the last paragraph, we therefore explore different analysis pipelines for in del calling. The results of such comparisons can be summarized in many ways. Commonly used metrics include, for example, the number or proportion of previously reported variants among the detected deviations from the reference sequence. As our focus is on a *To whom correspondence should be addressed.  The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. dichotomous outcome, i.e. the presence or absence of a variant at a particular position, we use here the probabilities of identifying the variant at a site that carries a variant and of identifying no variant at a site where only the reference sequence is present. We refer to these probabilities as sensitivity and specificity.

discussion the approach we presented here estimates two parameters, the sensitivity and the specificity of variant calls in a next generation sequencing experiment, by comparing the observed variants with population allele frequency data in a maximum likelihood framework. We illustrated some of its potential applications by comparing analysis pipelines and variant calling parameters and exploring the effects of differences in coverage. As both sensitivity and specificity are influenced by various experimental factors, including sample preparation, the sequencing itself and the bioinformatic pipelines used to analyse data, the procedure could be used to assess the performance of a sequencing experiment globally and could complement other commonly used approaches, such as the assessment of base call quality or of coverage metrics.
