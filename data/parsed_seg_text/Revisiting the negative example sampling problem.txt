Motivation: A number of computational methods have been proposed that predict protein protein interactions pp is based on protein sequence features. Since the number of potential non-interacting protein pairs (negative pp is is very high both in absolute terms and in comparison to that of interacting protein pairs (positive pp is computational prediction methods rely upon subsets of negative pp is for training and validation. Hence, the need arises for subset sampling for negative pp is. Results: We clarify that there are two fundamentally different types of subset sampling for negative pp is. One is subset sampling for cross validated testing, where one desires unbiased subsets so that predictive performance estimated with them can be safely assumed to generalize to the population level. The other is subset sampling for training, where one desires the subsets that best train predictive algorithms, even if these subsets are biased. We show that confusion between these two fundamentally different types of subset sampling led one study recently published in Bioinformatics to the erroneous conclusion that predictive algorithms based on protein sequence features are hardly better than random in predicting pp is. Rather, both protein sequence features and the hub bin ess of interacting proteins contribute to effective prediction of pp is. We provide guidance for appropriate use of random versus balanced sampling. Availability: The datasets used for this study are available at

introduction protein protein interactions pp is underlie many processes essential to living organisms. Years of small scale experimental work, along with genome wide studies powered by high throughput techniques (e.g.) have generated significant numbers of known pp is which provide a good foundation on which to learn protein * To whom correspondence should be addressed. sequence features that distinguish interacting protein pairs from noninteracting ones. In general, this has been a difficult and largely unsolved computational problem, ex as cer bated by strong biases in available datasets, including redundant interactions and skewed amino acid compositions in well represented protein complexes (e.g. the ribosome). none th less diverse computational methods have been developed that predict pp is using protein sequence features (Ben). As with all computational prediction methods, improvements to datasets used for testing and training can strongly affect the quality of the predictions. It is thus critical that protein sequence feature based PPI prediction methods be validated with appropriate positive and negative datasets. Since the numbers of high confidence positive pp is are still relatively modest, especially in comparison to the numbers of potential negative examples, most studies have used as much of the positive PPI data as possible. high quality negative PPI data are equally important for learning and validation processes. Unfortunately, such data are not widely available, although a new database has begun to archive such data (). Therefore, a typical strategy has been to employ protein pairs that are not previously known to interact as the set of negative pp is. This is generally a reasonable assumption given that negative pp is out number positive ones by a factor of hundreds to thousands. More specifically, let us say that we have P protein pairs known to interact and the P protein pairs involve K different proteins. Then, there are K(K 1)/2 possible protein pairs. The P pairs known to interact serve as positive examples for predicting new interactions. The remaining N protein pairs, dominated by true negative interactions, are assumed not to interact (in general) and serve as negative examples, where N = K(K 1)/2P. Usually, P N and P is of a manageable magnitude whereas N is not. For many algorithms, cross validating predictive algorithms on the complete set of K(K 1)/2 protein pairs (consisting of P positive pp is and N negative ones) is not feasible simply because it is too immense. Thus, sampling subsets, especially of negative pp is is routine practice. Typically, one might want an unbiased subset of negative pp is of size n, where n is of a manageable magnitude. cross validated test results on the set combining P positive pp is and n negative ones are then assumed to generalize to the whole set of K(K 1)/2 protein pairs because the negative subset used for cross validation is an unbiased representative of the N negative pp is. This type

conclusion in this study we clarified a critical distinction between subset sampling for algorithm training and for cross validated estimates of predictive performance. We showed that a balanced sampling technique, recently proposed by to prevent representational bias driven learning of protein protein interactions, is suitable for subset sampling during training but not for cross validated testing, and that its use for cross validation leads to significant underestimates of predictive performance and to erroneous conclusions regarding the value of protein sequence features for predicting pp is. In contrast, when used only for training, use of the balanced sampling technique allows for estimates of the relative contributions of representational bias driven learning as compared to learning based on protein sequence features. We observe both to contribute significantly to the prediction of pp is. Funding: National Institutes of Health (GM067779, GM088624, to E.M.); Welch (F1515) and Packard Foundations; and U.S. Army Research (58343-MA). Deutsche Forschungsgemeinschaft dfg forschungs stipend ium to Y.P.).
