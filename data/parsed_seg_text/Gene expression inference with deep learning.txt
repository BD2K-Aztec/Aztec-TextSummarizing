Motivation: large scale gene expression profiling has been widely used to characterize cellular states in response to various disease conditions, genetic perturbations, etc. Although the cost of whole genome expression profiles has been dropping steadily, generating a compendium of expression profiling over thousands of samples is still very expensive. Recognizing that gene expressions are often highly correlated, researchers from the NIH LINCS program have developed a cost effective strategy of profiling only $1000 carefully selected landmark genes and relying on computational methods to infer the expression of remaining target genes. However, the computational approach adopted by the LINCS program is currently based on linear regression (LR), limiting its accuracy since it does not capture complex nonlinear relationship between expressions of genes. Results: We present a deep learning method (abbreviated as dg ex to infer the expression of target genes from the expression of landmark genes. We used the microarray based Gene Expression Omnibus dataset, consisting of 111K expression profiles, to train our model and compare its performance to those from other methods. In terms of mean absolute error averaged across all genes, deep learning significantly outperforms LR with 15.33% relative improvement. A gene-wise comparative analysis shows that deep learning achieves lower error than LR in 99.97% of the target genes. We also tested the performance of our learned model on an independent rnase q based g tex dataset, which consists of 2921 expression profiles. Deep learning still outperforms LR with 6.57% relative improvement, and achieves lower error in 81.31% of the target genes. Availability and implementation: dg ex is available at https://github.com/uci-cbcl/D-GEX.

introduction a fundamental problem in molecular biology is to characterize the gene expression patterns of cells under various biological states. Gene expression profiling has been historically adopted as the tool to capture the gene expression patterns in cellular responses to diseases, genetic perturbations and drug treatments. The Connectivity Map (CMap) project was launched to create a large reference collection of such patterns and has discovered small molecules that are functionally connected using expression pattern matching (e.g. HDAC inhibitors and estrogen receptor modulators) (). Although recent technological advances, whole genome gene expression profiling is still too expensive to be used by typical academic labs to generate a compendium of gene expression over a large number of conditions, such as large chemical libraries, genome wide RNAi screening and genetic perturbations. The initial phase of the CMap project produced only 564 genome wide gene V C The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals permission soup com expression profiles using Affymetrix GeneChip microarrays (). Despite the large number of genes ($22 000) across the whole human genome, most of their expression profiles are known to be highly correlated. Systems biologists have leveraged this idea to construct gene regulatory networks and to identify regulator and target genes (). Researchers from the LINCS program (http://www.lincsproject.org/) analyzed the gene expression profiles from the CMap data using principal component analysis. They found that a set of $1000 carefully chosen genes can capture $80% of the information in the CMap data (http://support.lincscloud.org/hc/en-us/ articles 202092616 the landmark genes. Motivated by this observation, researchers have developed the L1000 Luminex bead technology to measure the expression profiles of these $1000 genes, called the landmark genes (http://support.lincscloud.org/hc/en-us/articles/ 202092616 the landmark genes with a much lower cost ($$5 per profile) (). Therefore, researchers can use the expression signatures of landmark genes to characterize the cellular states of samples under various experimental conditions. If researchers are interested in the expression of a specific gene other than landmark genes, the expression profiles of the remaining $21 000 genes, called the target genes, can be then computationally inferred based on landmark genes and existing expression profiles. With the L1000 technology, the LINCS program has generated $1.3 million gene expression profiles under a variety of experimental conditions. However, computationally inferring the expression profiles of target genes based on landmark genes is challenging. It is essentially a large scale multi-task machine learning problem, with the target dimension ($21 000) significantly greater than the feature dimension ($1000). The LINCS program currently adopts linear regression (LR) as the inference method, which trains regression models independently for each target gene based on the Gene Expression Omnibus (GEO) () data. While LR is highly scalable, it inevitably ignores the nonlinearity within gene expression profiles that has been observed (). Kernel machines can represent dexterous nonlinear patterns and have been applied to similar problems (). Unfortunately, they suffer from poor scalability to growing data size. Thus, a machine learning method enjoying both scalability and rich represent ability is ideal for large scale multi-task gene expression inference. Recent successes in deep learning on many machine learning tasks have demonstrated its power in learning hierarchical nonlinear patterns on large scale datasets (). Deep learning in general refers to methods that learn a hierarchical representation of the data through multiple layers of abstraction (e.g. multi-layer feedforward neural networks). A number of new techniques have been developed recently in deep learning, including the deployment of general purpose Computing on Graphics Processing Units (), new training methodologies, such as dropout training () and momentum method (). With these advances, deep learning has achieved state of the art performances on a wide range of applications, both in traditional machine learning tasks such as computer vision (), natural language processing (), speech recognition () and in natural science applications such as exotic particles detection (), protein structure prediction (), RNA splicing prediction () and pathogenic variants identification (). Here, we present a deep learning method for gene expression inference dg ex. dg ex is a multi-task multi-layer feedforward neural network. We evaluated the performances of dg ex LR (with and without different regularization s and k nearest neighbor (KNN) regression on two types of expression data, the microarray expression data from the GEO and the rnase q expression data from the genotype tissue Expression g tex project (). GPU computing was used to accelerate neural network training so that we were able to evaluate a series of neural networks with different architectures. Results on the GEO data show that dg ex consistently outperforms other methods in terms of prediction accuracy. Results on the g tex data further demonstrate dg ex combined with the dropout regularization technique, achieves the best performance even where training and prediction were performed on datasets obtained from different platforms (microarray versus rnase q. Such cross platforms generalizability implies the great potential of dg ex to be applied to the LINCS program where training and prediction were also done separately on the microarray data and the L1000 data. Finally, we attempted to explore the internal structures of the learned neural networks with two different strategies and tried to interpret the advantages of deep learning compared with LR.

discussion revealing the complex patterns of gene expression under numerous biological states requires both cost effective profiling tools and powerful inference frameworks. While the L1000 platform adopted by the LINCS program can efficiently profile the $1000 landmark genes, the linear regression based inference does not fully leverage the nonlinear features within gene expression profiles to infer the $21 000 target genes. We presented a deep learning method for gene expression inference that significantly outperforms LR on the GEO microarray data. With dropout as regularization, our deep learning method also preserves cross platforms generalizability on the g tex rnase q data. In summary, deep learning provides a drop out rate 0% 10% 25%. The overall error decreasing curves of D-GEX-9000  2 on g texte with different dropout rates. The x axis is the training epoch and the y-axis is the overall error. The overall error of LR is also included for comparison better model than LR for gene expression inference. We believe that it achieves more accurate predictions for target gene expressions of the LINCS dataset generated from the L1000 platform. Interpreting the internal representation of deep architectures is notoriously difficult. Unlike other machine learning tasks such as computer vision, where we can visualize the learned weights of hidden units as meaningful image patches, interpreting the deep architectures learned by biological data requires novel thinking. We attempted to interpret the internal structures of the neural networks learned from gene expression data using strategies that were inspired by linear model. Yet, more systematic studies may require advanced computational frameworks that are specifically designed for deep learning. Unsupervised feature learning methods, such as auto encoder () and restricted Boltzmann machine () may provide some insights on this problem. In the current setting, target genes were randomly partitioned into multiple sets, and each set was trained separately using different GPUs due to hardware limitations. Alternatively, we could first cluster target genes based on their expression profiles, and then partition them accordingly rather than randomly. The rationale is that target genes sharing similar expression profiles share weights in the context of multi-task neural networks. Ultimately, the solution is to jointly train all target genes, either by using GPUs with larger memory such as the more recent Nvidia Tesla K80, or by exploiting multi gpu techniques ().
