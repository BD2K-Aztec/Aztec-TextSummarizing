Motivation: The current molecular data explosion poses new challenges for large scale phylo genomic analyses that can comprise hundreds or even thousands of genes. A property that characterizes phylo genomic datasets is that they tend to be gap py i.e. can contain tax a with (many and disparate) missing genes. In current phylo genomic analyses, this type of alignment gap py ness that is induced by missing data frequently exceeds 90%. We present and implement a generally applicable mechanism that allows for reducing memory footprints of likelihood based [maximum likelihood (ML) or Bayesian] phylo genomic analyses proportional to the amount of missing data in the alignment. We also introduce a set of algorithmic rules to efficiently conduct tree searches via subtree pruning and re grafting moves using this mechanism. Results: On a large phylo genomic DNA dataset with 2177 tax a 68 genes and a gap py ness of 90%, we achieve a memory footprint reduction from 9 GB down to 1 GB, a speed up for optimizing ML model parameters of 11, and accelerate the Subtree Pruning re grafting tree search phase by factor 16. Thus, our approach can be deployed to improve efficiency for the two most important resources, CPU time and memory, by up to one order of magnitude. Availability: Current open source version of ra xml v7.2.6 available at

introduction in this article, we study the time and memory efficient execution of subtree pruning and re grafting moves for conducting tree searches on gap py phylo genomic multi-gene alignments (also known as super matrices under the maximum likelihood (ML,) model by example of ra xml (). While we use ra xml to prove our concept, the mechanisms presented here can easily be integrated into all bayesian and ml based programs that conduct tree searches and are hence predominantly limited by the time and space efficiency of likelihood computations on trees. Typically, likelihood computations account for 8595% of overall execution time in Bayesian and ML programs (). Moreover, the space required to hold the probability vectors of the likelihood model (the ancestral probability vectors that are assigned to the inner nodes of the tree) also largely dominates the memory consumption of likelihood based programs. While space and time requirements can be reduced by using the CAT approximation of rate heterogeneity () and or single precision instead of double precision floating point arithmetics (Berger and stam a takis * To whom correspondence should be addressed 2009 there exists an urgent need to further improve the computational efficiency of the likelihood function because of the bio gap, i.e., the fact that molecular data accumulates at a faster pace than processor architectures are becoming faster see in. As Bioinformatics is coming off age and because the community is facing unprecedented challenges regarding the scalability and computational efficiency of widely used Bioinformatics functions, we believe that work on algorithmic engineering aspects will become increasingly important to ensure the success of the field. The largest published ml based phylo genomic study in terms of CPU hours and memory requirements already required 2.25 million CPU hours and 15 GB of main memory on an IBM blue genel supercomputer (). Moreover, we are receiving an increasing number of reports by ra xml users that intend to conduct phylo genomic analyses on datasets that require up to 181 GB of main memory under the standard model of rate heterogeneity () and double precision arithmetics. Memory consumption is, therefore, becoming a limiting factor for phylo genomic analyses, especially at the whole genome scale. Initial work by stam a takis and Ott (2008b) on methods for efficiently computing the likelihood on phylo genomic alignments with missing data focused on computing the likelihood and optimizing branch lengths on a single, fixed tree topology using pointer meshes. Here, we address the conceptually more difficult extension of this approach to likelihood model parameter optimization (for parameters other than branch lengths) and tree searches that entail dynamically changing trees. We describe and make available as open source code, a generally applicable framework to efficiently compute the likelihood on dynamically changing tree topologies during a Subtree Pruning re grafting spr based tree search. Search algorithms that rely on SPR moves represent the most widely used tree search technique in state of the art programs for phylogenetic inference. In addition, we implement full ML model parameter optimization under the proposed mechanism and also take advantage of the memory footprint reduction potential that was only mentioned as a theoretical possibility by stam a takis and Ott (2008b) without providing an actual implementation.
