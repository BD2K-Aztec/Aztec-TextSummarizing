Liquid chromatography coupled to mass spectrometry (LC/MS) has become widely used in Metabolomics. Several artefacts have been identified during the acquisition step in large LC/MS metabolomics experiments, including ion suppression, carryover or changes in the sensitivity and intensity. Several sources have been pointed out as responsible for these effects. In this context, the drift effects of the peak intensity is one of the most frequent and may even constitute the main source of variance in the data, resulting in misleading statistical results when the samples are analysed. In this article, we propose the introduction of a methodology based on a common variance analysis before the data normalization to address this issue. This methodology was tested and compared with four other methods by calculating the Dunn and Silhouette indices of the quality control classes. The results showed that our proposed methodology performed better than any of the other four methods. As far as we know, this is the first time that this kind of approach has been applied in the metabolomics context. Availability and implementation: The source code of the methods is available as the R package intc or at http://b2slab.upc.edu/software-and-downloads/intensity-drift-correction/.

introduction metabolomics aims to asses the metabolic changes in a global way to infer biological functions and provide the detailed biochemical responses of cellular systems (). Liquid chromatography mass spectrometry (LC/MS) devices are among the most used experimental set-ups in metabolomics. LC/MS analyses of biological samples such as urine or plasma give high throughput data having a three index scheme: retention time, mass charge ratio and intensity values (). In meta bolo mic data, as in other types of high dimensional data such as gas sensor arrays or microarray data, the intensity values of the variables might be biased or might suffer from variations owing to external factors. Among these factors is a contribution from the drift of the experimental devices, owing to various causes such as column ageing in the case of LC/MS, temperature variations or contamination effects (). The presence of peak intensity drift in the data is an important issue, as its effects can be important enough to mask the real statistical behaviour of the data and may indeed be the largest source of variance in the data (). In most LC/MS protocols, quality control (QC) samples are regularly injected to ensure good analytical device performance (). In LC/MS metabolomics studies, the quality controls have been carried out using pools of biological samples, spikes with standards or mill iq water samples (). These quality control samples consist either of a pooling of all the samples in the study or of a spike in of some known metabolites (several classes having different types of QC samples might be injected). In the data preprocessing stage, one may distinguish two different steps: data normalization and data equalization. We understand the data normalization step as the mathematical process that makes the variables in the dataset comparable, whereas the data equalization step makes the samples from the dataset comparable. In the literature, many normalization and equalization methods, based on several different approaches and scopes, may be found. Regarding equalization methods, a methodology using certain internal known metabolites as quality standards to normalize the whole dataset has been reported (). Another approach is to use the injected samples for internal control (i.e. QCs) to fit a smoothed model for the intensity levels of certain features, and then to correct all the biological samples accordingly (). The R package sva includes the ComBat function, which compensates the batch effects on microarray data using an empirical Bayes approach (). This method has been applied to normalize gene expression and methylation data (). Equalization methods based on a sample wise correction for LC/ MS meta bolo mic data have also been tested and compared by. Their results suggest that a variance stabilization transformation of the data, followed by a median fold change normalization, gives the best performance as compared *To whom correspondence should be addressed. with three other methods. Their method performs a normalization and an equalization step to give a robust output when having urine samples with different concentration values. Among the equalization methods, the one proposed by arturs son et al., based on component correction (CC), was developed in the sensor array field (). This method is based on the assumption that, in multivariate data, the drift direction is the first principal component (PC) of a pc a decomposition for a class consisting of measurements of the same samples. Such samples are known as technical replicates (i.e. there is no biological or chemical variation in addition to the variability of the technical replication of the measure). Once the drift direction is computed, the drift is removed from the data by subtracting the data projection on the drift direction from the original data. However, if some between class variability is aligned with the drift direction, it will also be subtracted, and some non drift variability will be removed. A natural extension of the CC method is the one proposed by ziya tdi nov et al., which is based on a common principal component analysis cpc a decomposition (). This method proposes modelling the drift contribution in the data as the direction capturing maximum variance that simultaneously diagonalize s the covariance matrices of a set of classes. All the variability of the samples in that particular direction is considered to be drift induced variability, and the projection of the data on that direction is subtracted from the data as in the CC method. In this article, to find the drift model, we state the hypothesis that the intensity drift of the chromatograms is the common variance direction of all the QC classes that captures the maximum variance. In this context, we propose a preprocessing method based on a two step approach by first equalizing the data through a cpc a and then normalizing the data using a median fold change step.
