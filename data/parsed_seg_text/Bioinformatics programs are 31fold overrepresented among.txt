Motivation: To analyze the relative proportion of bioinformatics papers and their non bioinformatics counterparts in the top 20 most cited papers annually for the past two decades. Results: When defining bioinformatics papers as encompassing both those that provide software for data analysis or methods underlying data analysis software, we find that over the past two decades , more than a third (34%) of the most cited papers in science were bioinformatics papers, which is approximately a 31-fold enrichment relative to the total number of bioinformatics papers published. More than half of the most cited papers during this span were bioinformatics papers. Yet, the average 5 year j if of top 20 bioinformatics papers was 7.7, whereas the average j if for top 20 non bioinformatics papers was 25.8, significantly higher (P  4.5 Â 10 À29). The 20 year trend in the average j if between the two groups suggests the gap does not appear to be significantly narrowing. For a sampling of the journals producing top papers, bioinformatics journals tended to have higher Gini coefficients, suggesting that development of novel bioinformatics resources may be somewhat hit or miss. That is, relative to other fields, bioinformatics produces some programs that are extremely widely adopted and cited, yet there are fewer of intermediate success.

discussion the higher Gini coefficients for bioinformatics journals suggest that development of novel bioinformatics resources may be somewhat 'hit or miss'. That is, some approaches become widely adopted and produce a disproportionate number of extremely highly cited papers, while most are not widely adopted and, at least relative to some of the other journals analyzed here, there are not as many papers that fall between the two extremes. This may also provide a potential explanation for the j if gap: Methods developed to solve biological problems, whether novel ones or significant improvements on prior methods, may be technically sound but if it is difficult to know a priori which ones will be widely adopted or sorely needed, then it would be understandable for that to diminish enthusiasm. There is a degree of subjectivity when classifying papers strictly into 'bioinformatics' versus non bioinformatics as some cases are not clear (e.g. should a minor permutation of an existing method be counted as a new method?). But the magnitude of the differences found suggests that the main conclusions are not likely to be altered by a few differences of opinion regarding paper classification.

conclusion this study highlights the disproportionate impact bioinformatics has had on science in the past two decades. The Gini coefficient analysis of citations by journal suggests a greater gap between citation rich and citation poor bioinformatics papers, which suggests that it may be worth examining in greater depth why some of the less cited methods fared so poorly were they simply not needed or was the right audience simply not aware of their existence? Are researchers reluctant to adopt new methods, even if better, if a solution already exists? It suggests bioinformatics, as a field is somewhat 'hit or miss' or high risk high reward relative to other fields. As researchers, bioinformatic ians face challenges in being recognized for their work that are somewhat unique to their field. It's tempting to suggest a change to the system is in order, but outside of bioinformatics there seems little incentive to do so. The use of alt metrics may be one immediate solution, but that presumes that others will officially recognize and accept their use. Another solution is for authors of superstar papers to invest in bioinformatics as a field by publishing substantial updates and improvements to their programs in bioinformatics related journals. Awareness of the underestimated impact of bioinformatics is only part of the problem, the other part is finding effective solutions.
