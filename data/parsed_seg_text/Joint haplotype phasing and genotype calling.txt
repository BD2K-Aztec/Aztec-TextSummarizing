Motivation: Hidden Markov model, based on Li and Stephens model that takes into account chromosome sharing of multiple individuals, results in mainstream haplotype phasing algorithms for genotyping arrays and next generation sequencing (NGS) data. However, existing methods based on this model assume that the allele count data are independently observed at individual sites and do not consider haplo-type informative reads, i.e. reads that cover multiple heterozygous sites, which carry useful haplotype information. In our previous work, we developed a new hidden Markov model to incorporate a two site joint emission term that captures the haplotype information across two adjacent sites. Although our model improves the accuracy of genotype calling and haplotype phasing, haplotype information in reads covering non-adjacent sites and or more than two adjacent sites is not used because of the severe computational burden. Results: We develop a new probabilistic model for genotype calling and haplotype phasing from NGS data that incorporates haplotype information of multiple adjacent and or non-adjacent sites covered by a read over an arbitrary distance. We develop a new hybrid Markov Chain Monte Carlo algorithm that combines the Gibbs sampling algorithm of hap seq and metropolis hastings algorithm and is computationally feasible. We show by simulation and real data from the 1000 Genomes Project that our model offers superior performance for haplotype phasing and genotype calling for population NGS data over existing methods.

introduction low coverage sequencing of multiple samples is an efficient strategy to profile genetic variations in a population () because low sequencing depth makes it affordable to sequence a larger number of samples. The high accuracy of genotype calling and haplotype phasing of such a design strategy is achieved by many innovative developments in the field of bioinformatics and statistical genetics. As demonstrated by the 1000 Genomes Project (), for common variants, the accuracy of genotype calling from low coverage sequencing is comparable with that from genotyping arrays. Although haplotype phasing was not the primary goal of the 1000 Genomes Project, the linkage disequilibrium ld based refinement method, Thunder (), used in the project to refine genotype calls from individual subgroups, also phases genotypes into haplotypes. Thunder, and most ld based genotype refinement algorithms, is based on the Li and Stephens model (). This model takes into account chromosome sharing among multiple individuals, and can be efficiently optimized by hidden Markov model hmm based algorithms. This model was traditionally applied to array based genotype data in which, at each site, it only observed the un phased genotype. hmm based methods can phase the haplotypes of multiple individuals simultaneously through a population genetics model that models the chromosome sharing among these individuals. With a modification of single site emission probability, Thunder extended this approach to phase population next generation sequencing (NGS) genotype data. By comparing with the Illumina Omni 2.5 M genotyping array data that were phased by additional family samples, Thunder was reported to make one switch error in about every 300400 kilobytes (KB). However, Thunder assumes that the allele count data are independently observed at each site and does not consider haplotype informative reads, i.e. reads that cover multiple heterozygous sites, which carry useful haplotype information. In our previous work (), we developed the HMM based on the Li and Stephens model to incorporate a two site joint emission probability that can capture the haplotype information across two adjacent sites. Our method, which is implemented in the software package hap seq has achieved a 912% reduction of error rates compared with Thunder for genotype calling of the sequencing data from the 1000 Genomes Project. Still, haplotype information in sequencing reads was not fully used in our previous work. Haplotype information in reads that cover more than two adjacent sites is not used because of severe computational burden of higher order HMMs. This throws away valuable haplotype information, especially because newer sequencing technologies can offer longer reads. In addition, paired end reads can cover non-adjacent sites and thus offer haplotype information over multiple adjacent and or nonadjacent sites. paired end reads are routinely used in sequencing projects in aiding read mapping and assembly (). It would be important to develop advanced statistical methods that can fully use the haplotype information in reads. *To whom correspondence should be addressed. Notably, a probabilistic haplotype phasing model, HASH, was proposed by for a single individual using whole genome sequencing reads. Their approach was termed 'haplotype assembly' because of its resemblance to the traditional fragment assembly problem. Traditional fragment assembly generates a single consensus sequence out of a set of reads from a single individual, ignoring the diploid nature of the human genome. Bansal et al.'s haplotype assembly was to generate a pair of consensus sequences out of a set of reads from a diploid individual. Their model is based on the haplotype likelihood of sequencing reads the probability of a haplotype pair given the sequencing reads. With the assumption of the uniform prior on the space of haplotypes, this probability is proportional to the probability of reads given the haplotype pair. A metropolis hastings (MH) algorithm was proposed to sample haplotype pairs in which 'moves' are flipping of substrings of the haplotypes. They estimated the switch error rate of haplotypes inferred for a genome () sequenced by 7.5X Sanger reads was $1.1%. However, their method assumes that genotypes are readily known, and it requires high sequencing coverage; thus, it is not applicable to low coverage sequencing in which read counts are sparse and joint genotype calling and haplotype phasing are essential for high accuracy. In addition, with the assumption of the uniform prior, their method ignores the haplotype information contained by other individuals and or reference haplotypes. Another notable work is by. Their hap seq (not our program hap seq method extended the haplotype assembly approach by incorporating population information. Their haplotype likelihood was divided into two independent parts: the probability of sequencing of reads given the haplotype pair, which is similar to that used in HASH (), and the probability of the haplotype pair given the set of reference haplotypes, which can be calculated using the HMM similar to the HMM in thunder hap seq designed a dynamic programming algorithm to find a haplotype pair to maximize the haplotype likelihood. Their simulation results showed that the haplotype inferred from such model had lower switch error rates than those obtained from IMPUTE v1.0 (). The method of can be used for low coverage sequencing but still assumes that the genotypes at each site are already known. Essentially, they extended the Li and Stephens model into higher order Markov models, and thus their method incurs a computational complexity of O4 V , for just running a Viterbi pass for phasing one individual, where V is the maximum number of sites spanned by reads. Their approach is impractical if V is large. Unfortunately, paired end reads are commonly used in real sequencing projects, as such reads generally span a large number of sites. To avoid this potential problem had to split a long read to the multiple reads that each span only three heterozygote sites. Obviously, this approach is not optimal, as it does not fully use the haplotype information of reads that cover a large number of sites. In this work, we develop a fully probabilistic model for joint genotype calling and haplotype phasing that incorporates the joint distribution of two or more sites covered by a read over an arbitrary distance. Our model integrates elements of the population haplotype likelihood in thunder hap seq and the read haplotype likelihood in HASH (), each capturing complementary haplotype information. Because both methods are Markov Chain Monte Carlo mcmc based we develop a combined MCMC method that embeds a MH procedure into a Gibbs sampling algorithm. Specifically, in each iteration, we first use the thunder hap seq HMM to jointly perform genotype calling and haplotype phasing, and then use the MH algorithm to sample haplotypes of each individual according to the likelihood based on sequencing reads and reference haplotypes. Our method is implemented in the HapSeq2 program, and is evaluated together with Thunder and hap seq by using simulation and real data.

discussion we developed a new approach for haplotype phasing and genotype calling from sequencing data of a set of population samples. We designed an mh flipping algorithm that can be embedded into traditional Gibbs sampling algorithms based on the Li and Stephens HMM model. Using simulated and real datasets, we showed that our new method can greatly improve the accuracy of haplotype phasing over current state of the art methods. In the 1000 Genomes Project phase 1 data, our HapSeq2 method produces 6080% longer SEF haplotype blocks than Thunder. Although the primary goal of introducing the mh flipping procedure is to improve haplotype phasing, we found that this technique also improves genotype calling accuracy. Accurate haplotype phasing will have broad impacts on genomic and genetic research areas. First, reconstructing long haplotype blocks in reference panel will improve the accuracy of genotype imputation. Second, long haplotype blocks will help haplotype based genetic association studies. Third, accurate haplotype phasing will produce more insights into population genetics inferences. This work is one of the first to prove the feasibility of incorporating haplotype information over multiple sites in ultra long reads and long insert paired end reads for phasing sequencing data with improved accuracy. This provides additional methodological support for the ultra low coverage sequencing design (). In our simulation studies, we only used the read length of 36 and 100 bp and the fixed insert size of 250, 500 and 1000 bp. For the 1000 Genomes Project chromosome 20 data, the insert size varies and the portion of the proportion of R 2 and R 3 reads also varies across different regions. For the chromosome 20, the proportions of reads covering two sites and at least three sites are 28.0% and 24.8% for the CEU samples and 27.3% and 24.1% for the yr i samples, respectively. For the major histocompatibility complex region, the proportions of reads covering two sites and at least three sites are higher: 25.4% and 34.6%% for the CEU samples and 25.5% and 31.5% for the yr i samples, respectively. The performance. Read cover and span distributions in the 1000 Genomes Project datasets of the proposed method for such regions is expected to be further improved. Therefore, more studies are needed to show how the accuracy of haplotype phasing and genotype calling is affected by the length of reads, the length of inserts and the proportion of R 2 and R 3 reads using our newly developed method. It will be future work to conduct extensive simulations including the simulation of reads with varied insert sizes to investigate the optimal design strategies. In the MH sampling, we proposed the new haplotype pair as a single crossover of the current haplotype pair and chose the recombinant point with the probability that is proportional to a weight. We defined the weight as the function of the difference of the number of sequencing reads that are in conflict with the current haplotype pair and the proposed haplotype pair. Although we also used the uniform weight and found the results from the uniform weight to be just slightly worse than the proposed weight, it is not clear whether the proposed weight is optimal. We will investigate this with more simulations in the future. To investigate whether the single crossover is sufficient for convergence of the MH sampling, we ran HapSeq2 5c, 10c and 20c iterations for the MH sampling, where c is the number of heterozygote sites of that individual. We found the results from 5c are similar to those obtained from 10c and 20c. In addition, we found the acceptance ratios from 5c, 10c and 20c are similar, indicating it is sufficient for convergence.
