Motivation: Advancements in high throughput technology have allowed researchers to examine the genetic etiology of complex human traits in a robust fashion. Although genome wide association studies have identified many novel variants associated with hundreds of traits, a large proportion of the estimated trait heritability remains unexplained. One hypothesis is that the commonly used statistical techniques and study designs are not robust to the complex etiology that may underlie these human traits. This etiology could include non-linear gene Â gene or gene Â environment interactions. Additionally, other levels of biological regulation may play a large role in trait variability. Results: To address the need for computational tools that can explore enormous datasets to detect complex susceptibility models, we have developed a software package called the Analysis Tool for Heritable and Environmental Network Associations (ATHENA). ATHENA combines various variable filtering methods with machine learning techniques to analyze high throughput categorical (i.e. single nucleotide polymorphisms) and quantitative (i.e. gene expression levels) predictor variables to generate multivariable models that predict either a categorical (i.e. disease status) or quantitative (i.e. cholesterol levels) outcomes. The goal of this article is to demonstrate the utility of ATHENA using simulated and biological datasets that consist of both single nucleotide polymorphisms and gene expression variables to identify complex prediction models. Importantly, this method is flexible and can be expanded to include other types of high throughput data (i.e. rnase q data and biomarker measurements). Availability: ATHENA is freely available for download. The software, user manual and tutorial can be downloaded from http://ritchielab.psu. edu ritchie lab software
introduction the sequencing of the human genome and significant advancements in high throughput technology allow for exploratory analyses, which have the goal of interrogating variation at different levels of biological regulation (). These technologies generate a massive amount of various types of data and are steadily becoming less expensive and more efficient (). One major bottleneck in making full use of these data is the analysis strategy. First, because of the massive amount of data being generated, analysts must have access to computers with adequate resources. Second, computational techniques must be used that can analyze datasets with hundreds of thousands to millions of predictor variables in a feasible amount of time. Finally, to incorporate the potential complexity of these predictor variables, statistical methods must be used that can detect non-linear interactions and handle various types of data appropriately. Thus far, the most commonly used analytical techniques have focused on the first two requirements. For example, genome wide association studies g was calculate the association of each individual single nucleotide polymorphism (SNP) from a high throughput genotyping platform with the trait of interest. The p value is then corrected for all of the statistical tests that were done (). Inherently, this type of analysis is only going to find associations with strong enough main effects to pass the significance threshold. Therefore, g was will not find SNPs with phenotypic effects that rely on variation at another predictor variable (gene  gene or gene  environment interactions). This could be a factor in one of the major criticisms of g was much of the trait variability estimated to be due to genetic factors remains unexplained by the thousands of novel variants identified by these studies (). To address this criticism, various statistical methods have been developed that allow for the discovery of gene gene and gene environment interactions (). For example, multifactor dimensionality reduction performs an exhaustive analysis of all n wise interacting loci to generate multilocus predictor models (). Here, we assess several methods that have capacity to perform a meta dimensional analysis. A meta dimensional study is defined as one that integrates different types of data that represent different levels of biological regulation to predict a given outcome (). The Analysis Tool for Heritable and Environmental Network Associations, or ATHENA, is a software package that combines various statistical methods as a filtering modeling pipeline to identify complex prediction models (*To whom correspondence should be addressed.). The overall goal of ATHENA is to provide the user with a platform to flexibly apply the statistical techniques to identify models that may be missed by other methods or any single method alone. The statistical methods in ATHENA are selected based on a number of criteria, including robustness to non-linear interactions, which will allow us to assess the role of these types of genetic effects on phenotypic variation in complex human traits shows a schematic of the ATHENA methodology. ATHENA includes filtering and modeling components to generate the complex prediction models. In this analysis, we assess the modeling methods' abilities to identify complex genetic models using simulated data. Owing to the substantial increase in noise that is inherent to high throughput data, we apply the ATHENA filtering method Random Jungle (RJ) to the biological dataset before generating the prediction models. The filtering and modeling methods have been previously tested with various inputs, including SNPs and expression data. Future work will assess other components of ATHENA, such as the inclusion of environmental factors and the impact of certain characteristics of genetic data such as sample size, missing data points and minor allele frequency.
