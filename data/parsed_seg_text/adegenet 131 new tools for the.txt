While the R software is becoming a standard for the analysis of genetic data, classical population genetics tools are being challenged by the increasing availability of genomic sequences. Dedicated tools are needed for harnessing the large amount of information generated by next generation sequencing technologies. We introduce new tools implemented in the ade genet 1.3-1 package for handling and analyzing genome wide single nucleotide polymorphism (SNP) data. Using a bit level coding scheme for SNP data and parallelized computation, ade genet enables the analysis of large genome wide SNPs datasets using standard personal computers. Availability: ade genet 1.3-1 is available from CRAN: http://cran.r-project.org/web/packages/adegenet/. Information and support including a dedicated forum of discussion can be found on the ade genet website: http://adegenet.r-forge.r-project.org/. ade genet is released with a manual and four tutorials totalling over 300 pages of documentation, and distributed under the GNU General Public Licence (â‰¥2).

introduction the free software R (R Development Core) is becoming a standard for the analysis of genetic data, offering a wealth of packages dedicated to population genetics (), phylogenetics () or genome wide association studies (). Until recently, classical genetic marker data such as microsatellites could be analyzed using standard tools and personal computers. However, the increasing availability of genomic sequence data has challenged both the tools and the ressources needed to carry such analyses. While some specific packages have been developed for human association studies (), more general tools for the analysis of the genetic structure of biological populations are needed. In this article, we introduce new tools implemented in the R package ade genet () which * To whom correspondence should be addressed. allow large genomic datasets (e.g. hundreds of individuals typed for hundreds of thousands SNPs) to be analyzed using standard personal computers. As an illustration, we show how a new implementation of the discriminant analysis of principal components da pc () can be used to identify structuring alleles from genomic data with minimum computing resources.

description the sheer size of genomic sequence data often precludes their analysis using standard personal computers. While studies focusing on genetic diversity can reduce the size of the analyzed datasets by considering bi allelic SNPs only, the subsequent amount of data often remains considerable and can require prohibitive amounts of random access memory (RAM). To address this issue, we implemented a new data representation which codes each bi allelic SNP using a single bit. While such coding is not readily possible in R, the new class gen light internally codes chunks of 8 SNPs using a single byte, resulting in drastic compression of the data. For instance, 50 individuals genotyped for 1 000 000 SNPs classically coded as characters would require 380 MB of RAM, as opposed to 6 MB using gen light objects. This new coding scheme is also about eight times more compact than other available classes for representing SNP data such as dna bin () or snp matrix (). A further advantage of gen light is the ability to accomodate any ploidy in the data, even allowing for the ploidy to vary across individuals. The features of the class gen light are fully documented in a tutorial accessible from R by typing vignette ade genet genomics. While the bit level coding of SNP data is undoubtedly memory efficient, it also makes the internal structure of the objects far more complex. Considerable efforts have been made to simplify the handling and analysis of gen light objects, whose manipulation is very close to matrices of individual allele frequencies. The entire gen light class has been replicated in C, which allowed for optimizing recurrent operations such as conversions from and to integers. Dedicated functions ('accessors') facilitate the access and modification of information while preventing the user from interacting directly with the complex internal structure of the objects. As a result, gen light objects act as 'black boxes' which resemble matrices of individual allele frequencies, albeit storing the information more efficiently. Basic functions such as mean and variance of SNP frequencies have also been implemented in order to facilitate the development of future dedicated tools beyond the need for efficient data storage, the analysis of genome wide SNP data also requires significant computing power. Fortunately, most computers now possess processors with multiple cores, which can be used to partition important tasks into several smaller operations executed simultaneously by the different cores. This approach can lead to appreciable reductions in computational time and is most useful for analyzing large datasets. By default, most procedures implemented for gen light objects achieve parallelization using the package multicore (currently available on linux and MacOSX systems), although this can be disabled by the user. For instance, the new implementations of pc a (function glp ca and da pc da pc see example) by default use compiled C code and parallelized computations, while never requiring more than two genomes to be represented as integers at a time. In some cases, this approach turns out to be even faster than other classical implementations of pc a (Supplementary). Data interoperability can be a critical issue when large datasets are considered. Therefore, we made sure that genome wide SNP data could be imported from standard formats into gen light objects as simply as possible. First, gen light objects can be created from lists or matrices of individual allele frequencies. Data can also be imported from the widely used software PLINK (), which has defined a standard format for storing diploid SNP data. Alternatively, data can also be imported from a degen ets own format ('.snp' files), which can accomodate any degree of ploidy and can store any meta-information such as individual group membership or positions of the SNPs. Finally, SNPs can also be directly extracted from aligned DNA sequences stored as fast a files. Importantly, all these functions allow for processing the data by chunks of a few individuals, which allows for minimizing the RAM required for reading the data in.

CONCLUSION
