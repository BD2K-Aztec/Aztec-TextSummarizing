Motivation: high throughput meta genomic sequencing has revolutionized our view on the structure and metabolic potential of microbial communities. However, analysis of meta genomic composition is often complicated by the high complexity of the community and the lack of related reference genomic sequences. As a start point for comparative meta genomic analysis, the researchers require efficient means for assessing pairwise similarity of the meta genomes beta diversity. A number of approaches were used to address this task, however, most of them have inherent disadvantages that limit their scope of applicability. For instance, the reference based methods poorly perform on meta genomes from previously unstudied niches, while composition based methods appear to be too abstract for straightforward interpretation and do not allow to identify the differentially abundant features. Results: We developed meta fast an approach that allows to represent a shotgun meta genome from an arbitrary environment as a modified de Bruijn graph consisting of simplified components. For multiple meta genomes the resulting representation is used to obtain a pairwise similarity matrix. The dimensional structure of the meta genomic components preserved in our algorithm reflects the inherent subspecies level diversity of microbiota. The method is computationally efficient and especially promising for an analysis of meta genomes from novel environmental niches. Availability and Implementation: Source code and binaries are freely available for download at https://github.com/ctlab/metafast. The code is written in Java and is platform independent (tested on Linux and Windows x86_64).

introduction recently computational life scientists have witnessed an astounding increase in the volume of available shotgun meta genomic datasets. The challenge of reducing dimensionality of the data analysis is of primary demand for statistical analysis of meta genomes. This includes taxonomic and functional profiling, assessing richness and similarity. Technological advances and cost reduction of high throughput sequencing allow to examine microbiota from previously unexplored ecological niches. The degree of detail has increased in an unprecedented way: the average coverage depth has increased by several orders of magnitude since the first meta genomic studies (). Vast genomic data obtained in studies of microbial isolates served as a cornerstone for developing reference based approaches. Subsequently, there was a boom of such methods based on more elaborate techniques than direct alignment of each read with a reference genome, e.g. Kraken (), CLARK (), FOCUS (), MetaPhlAn2 (). However, a real challenge for reference based methods is represented by the communities from novel unexplored niches that contain a large fraction of uncultured bacteria. Accordingly, there is a lack of representative genomes for many clades of microbes and viruses that could serve as a reference. This problem is of significant weight even for the environments that have been thoroughly studied for decades: e.g. human gut microbiota where unknown genomes form a lion's share of the total DNA reads (). One of the approaches for measuring meta genomic similarity that was developed in order to cope with the rapidly accumulating volume of data is based on an adaptive subsampling (). Another one is an alignment free approach that appears to be attractive to meta genomic researchers due to the sparseness of available reference genome sets. Among such methods there are abstract composition based methods km er spectrum analysis (), neural networks (), Markov models () that are computationally efficient and can be run in parallel sections. However, there are certain limitations of these methods: the differentially abundant features between two or more groups of meta genomes turn out to be concealed within the method or provide little information. An alternative idea for assessing similarity is a de novo assembly of the meta genomes (similar to the process applied to individual genomes) followed by an analysis of the yielded contigs (classification, differential abundance analysis based on coverage depth). Here each individual feature is meaningful; however, the assembly is complicated due to a wide range of typical abundance of bacterial species and significant intra-species genomic variability. Special algorithms intended for meta genomic assembly have been developed that address these issues (). Particularly, combined assembly of meta genomic reads was proposed for estimating pairwise similarity (crAss) (). However, complete assembly from reads to contigs is computationally and memory intense especially due to the rapid increase of publicly available meta genomic data. We have developed the meta fast algorithm for compact representation of meta genomes using an adaptive segmentation of meta genomic de Bruijn graph, essentially based on a simplified meta genomic de novo assembly. Our method lies between the km er spectrum analysis and assembly and combines the best of these two alignment free approaches: the speed of the former with the precision of the latter. Its independence of the reference allows to perform efficiently for both extensively studied and novel microbiota types. The performance of meta fast was compared with several taxonomic profilers (Kraken, CLARK, FOCUS, MetaPhlAn2), as well as with a cross assembly based algorithm crAss on simulated data and real meta genomes of gut microbiota, new york subway and viruses of lake water. Comparative analysis showed that meta fast is highly efficient and the results of its work are in agreement with the existing methods.

discussion dramatic rates of accumulation of publicly available meta genomic data can be illustrated by a 45 times increase in the number of. Spearman correlation between the pairwise dissimilarity matrices obtained using meta fast and other algorithms. The correlation values were obtained using Mantel test (P  0.001). The label meta fast sp' denotes a modified version of meta fast analysis when the step of pseudo assembly is replaced with the assembly using SPAdes, meta fast nb' when it was replaced with the assembly using new bler datasets in some of the largest online meta genomic resources during the last two years; the sequencing depth also grows rapidly, reaching more than a hundred of tera base pairs per sample (). Such explosion of meta genomic Big Data makes comparative meta genomic studies an even more challenging area demanding new efficient algorithms () and visualization approaches (). Issues of speed, accuracy and memory efficiency become the key factors for novel approaches in meta genomic data processing, especially when the methods are intended to be applied to the broad spectrum of environmental datasets available. Bearing in mind the special nature of meta genomic datasets, we developed a hybrid algorithm that combines the principles of de novo pseudo assembly with the km er spectrum analysis allowing to perform computationally and memory efficient accurate analysis for a large number of meta genomes in a reference independent way. The domain of 'shotgun' meta genomic sequences currently contains two large niches. The first one encompasses projects that target moderate coverage for a large number of monotypic samples, e.g. human gut microbiota consortia (). The second category includes the projects mostly oriented towards de novo assembly of novel genomic sequences basing on high coverage sequencing of a small number of samples typically coming from various unique environments (e.g.). Most meta genomic datasets can be placed in between of these two extremes by containing a fraction of data from unknown organisms and a fraction of genetic material already contained in the public reference databases. A researcher chooses the approach basing on the understanding of the proportions between those two fractions in the current dataset. Interestingly, even in a seemingly well understood meta genomes the combination of the accumulated data even from multiple projects allows for the discovery of novel species (). The two described groups of datasets imply the choice of considerably different types of algorithms: alignment against a reference base is a fast and easily parallelized algorithm, while assembly algorithms are hardware demanding. Typical reference based approaches imply the selection of a similarity criterion to create a non-redundant catalogue normally selecting a sequence (of a gene or a genome) from a group having a high percent identity over a high percent of length. This step creates further biases in mapping: the more the difference between the analyzed sequence and the reference, the fewer reads are mapped (). The assembly based approaches for meta genomic datasets are using the same paradigm producing long reference sequences. For estimating the relative abundance of the sequences in a meta genome the mapping is used again this time against the sequences assembled from meta genomes that are considered to be more appropriate for mapping. Although one uses several meta genomic samples to increase the coverage, the intrinsic presence of mutations in bacterial genomes leads to selection of only the one variant of a path in the graph out of all available variants. Therefore, the variants are underrepresented in the final obtained sequence the genomic diversity is thus 'flattened'. The presented algorithm meta fast is an intermediate solution allowing to work with the speed of mapping and at the same time to gain benefits of de novo assembly particularly yielding novel genetic sequences. Moreover, one of the ideas implemented in the feature representation allows to avoid the mapping bias and to use un flattened references. Technically, meta fast has several differences from the traditional meta genomic assembly approaches. Firstly, meta fast does not perform a complete de novo assembly (e.g. used in the global human microbio me catalog construction (), but rather an incomplete version of assembly pseudo assembly. This greatly improves the performance of the algorithm in terms of speed. To assess whether the precision is affected negatively, we replaced the pseudo assembly step with a conventional assembler the results were highly similar. Second, while q in et al. performed the pairwise alignment of the combined pool of sequences and select a single representative per each cluster basing on high percent identity and alignment length, we do not drop the other similar variants but rather connect all of them into a single subgraph. This allows to capture the genomic details of each meta genome individually and then combine the individual results together for the comparison task. Thirdly, we do not perform the final 'flattening' step, instead preserving the branching nature of the graph components meta fast features). Thus, information about the variation of the same species between different samples is not lost and can be used for further analysis of gene variations. This also allows to avoid the mapping biases, as the calculation of feature representation in each separate meta genome is performed via km er counting for a branched meta fast feature. Finally, in the spirit of meta genome based research, meta fast allows to identify the features differentiating the groups and concentrate the researcher's attention on them. Advantages of our approach in terms of speed, accuracy, memory efficiency and independence of reference base were demonstrated using both simulated and real meta genomes the performance was compared with a variety of tools widely used in meta genomics. Simulations showed high correlation with the results of read mapping confirming basic accuracy of meta fast. However, it should be kept in mind that the provided simulated datasets are a primitive model of real data; particularly, genomic polymorphisms and gene content variations are ignored in these simulations. A high degree of correlation was shown in experiments with real data, where the results of meta fast were compared with two versions of mapping to a reference genome and gene catalog. High correlation with the results obtained via mapping to a genome catalog reflects the correct functioning of the algorithm: it means that the most part of genetic information is mappable to genomes and is also assembled to yield the features. Noteworthy, the comparison of meta fast with the combined assembly demonstrated memory efficiency of meta fast. While in conventional assembly the memory usage increases approximately linearly with the number of the samples, in meta fast it tends to achieve saturation at a certain number of samples (e.g. around 20 for gut meta genomes see Supplementary) and does not increase further. This fact is likely associated with the effect of component cutter module (see Methods) that limits the size of the total graph: as soon as the number of meta genomes is sufficiently high to encompass the major diversity of community structures, an addition of new meta genomes does not increase the size of the graph thus does not demand extra memory. Overall, our approach provides a more economic memory usage accompanied with significant speed improvement at the expense of only slight decrease in accuracy. Applicability of the approach for a wide range of problems was demonstrated for meta fast. It has shown good correlation with the adopted methods in human gut microbio me datasets and comparative accuracy in case of novel microbiota types and reference based approaches. Interestingly, the only tool comparable to meta fast in the terms of applicability to a set of meta genomes without well described reference set is the crAss algorithm designed specifically to assemble species from multiple meta genomes. The results of the comparative viral profiling showed that meta fast is an adequate tool for dissimilarity analysis of novel microbiota meta genomes due to the independence of the reference base that might also contain poorly annotated sequences (unclassified at various levels of taxonomy). Our results showed that on viral datasets it outreaches crAss in the terms of both speed and memory consumption, allowing to work with hundreds of meta genomes. While obviously even in well studied datasets there is a chance to find novel genes, we suggest meta fast is a very useful tool for exploratory data analysis. The features and their quantification across meta genomes can be obtained rapidly and the technical implementation allows to work with a high number of meta genomes in a robust manner. The settings help to orient the algorithm towards obtaining the features of desired length comparable to the typical microbial gene length making it convenient for primary analysis.
