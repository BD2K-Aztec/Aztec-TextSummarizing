Motivation: Animal models are important tools in drug discovery and for understanding human biology in general. However, many drugs that initially show promising results in rodents fail in later stages of clinical trials. Understanding the commonalities and differences between human and rat cell signaling networks can lead to better experimental designs, improved allocation of resources and ultimately better drugs. Results: The sbv IMPROVER species specific Network Inference challenge was designed to use the power of the crowds to build two species specific cell signaling networks given phospho proteomics transcript omics and cytokine data generated from nh be and nr be cells exposed to various stimuli. A common literature inspired reference network with 220 nodes and 501 edges was also provided as prior knowledge from which challenge participants could add or remove edges but not nodes. Such a large network inference challenge not based on synthetic simulations but on real data presented unique difficulties in scoring and interpreting the results. Because any prior knowledge about the networks was already provided to the participants for reference, novel ways for scoring and aggregating the results were developed. Two human and rat consensus networks were obtained by combining all the inferred networks. Further analysis showed that major signaling pathways were conserved between the two species with only isolated components diverging, as in the case of ribosomal S6 kinase RPS6KA1. Overall, the consensus between inferred edges was relatively high with the exception of the downstream targets of transcription factors, which seemed more difficult to predict.

introduction unveiling the inner workings of cell signaling networks is one of the long-standing challenges of systems biology. small scale versions of these networks have been built edge by edge using classic laboratory techniques such as immunoprecipitation, which has resulted in a large body of literature describing various gene and protein interactions. Although successful in their initial scope, these methods do not scale up to the genome level and are difficult to combine into a larger network, because of the different contexts in which they were originally reported. Organism, cell type, experiment timing and other conditions are crucial for determining whether an edge exists in a signaling network. The advent of large scale assays that can simultaneously measure the activity of thousands of genes has circumvented these aforementioned issues by enabling purely data driven methods to infer large scale networks. Various algorithms have been developed, including models based on Bayesian networks (), mutual information (), regression (), neural networks (), Boolean networks () and differential equations (). Despite these advances, there is no clear best method. Each method has strengths and limitations influenced by how the methodology addresses the fact that network inference is inherently an underdetermined problem in the majority of cases (). However, it has been observed that the aggregation of different network inference methods generates high quality robust results (). Efforts to catalog and compare network inference algorithms have occurred in the form of data prediction competitions such as the ones organized by the Dialogue for Reverse Engineering Assessments and Methods (DREAM) consortium (). DREAM challenges participants to reconstruct cell signaling networks from gene expression datasets. Predicted networks are then evaluated based on a subset of known interactions, or the complete network in cases where the corresponding gene expression data were generated in silico (i.e. simulated). *To whom correspondence should be addressed. y The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors. z A list of the challenge participants is available in the Supplementary information.  The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. DREAM is part of a larger group of successful crowd sourcing initiatives in systems biology alongside CASP [critical assessment of protein structure prediction (, CAFA [critical assessment of function annotation (, CAPRI [critical assessment of prediction of interactions (, flow cap [critical assessment of automated flow cytometry data analysis techniques (and fold it [predicting protein structure with a multiplayer online game (. In the same spirit as these academic initiatives, sbv IMPROVER is a crowd sourcing based methodology for the verification of research in an industrial setting (). In its second installment, it challenges the research community to solve four problems related to the translation of molecular biology findings between rat and human model systems (). Here we present the analysis of the species specific Network Inference challenge, part of the sbv IMPROVER Species Translation set of challenges (https://www.sbvimprover.com). For this challenge, participants were asked to infer human and rat specific networks given phosphoprotein, gene expression and cytokine data (). The organizers also provided a common reference network from which participants had to generate the two networks by adding and removing edges. The purpose of this challenge was to augment and refine the reference map in a species specific manner using data driven approaches.

discussion the scope of sbv IMPROVER Species Translation challenges was to assess the limits of using rat models to predict human biology in the specific context of bronchial epithelial cells exposed to various stimuli. Along these lines, the rationality behind the Network Inference challenge was to build two species specific cell signaling networks starting from a generic literature inspired network and using high throughput proteomics and transcript omics data to add or reject edges. This challenge differed from other challenges because it did not come with a gold standard (i.e. the true human and rat networks are unknown) and this posed difficulties in scoring and interpreting the results. The current work details how the aforementioned issues were addressed together with the lessons learned from organizing and curating such a challenge. Despite the apparent top down organization of the reference network, some feedback loops were present consistent with the structure of known pathways. However, the challenge experiments were designed to capture a broad area of the signaling network and not feedback mechanisms. The latter would have required a different experimental setup with more samples collected at later time points, as feedback loops tend to be more prominent at longer time scales. Without a gold standard, individual scoring criteria can potentially be useful in separating poor performers from good performers, but can also have flaws. The silver standard is biased by the choice of algorithm used to generate it, and the quality of the write-ups does not always predict the best performing algorithms. It is thus advisable to combine the rankings resulting from individual scoring methods to reduce bias. The best performers obtained in this manner were the same as the ones obtained by comparing predictions with a consensus network built by aggregating the submissions from all participants. This result suggests that consensus scoring could be used as a legitimate scoring strategy for future challenges where a gold standard is absent. The network aggregation procedure described in this article provides a statistically sound way of merging predicted networks or any other binary predictions given a sufficiently large sample space. This is especially useful when a clear way of assessing the best performing method is absent. However, even when one can accurately determine the best algorithm for performing a specific task, the result might be context dependent. It has been shown that disease classifiers vary greatly in performance when applied to different datasets (). Aggregating multiple predictions has been proven to generate a more robust outcome on par with the best performing methods (). The generation of a consensus prediction can potentially have benefits beyond that of robustness and performance, particularly in the absence of a gold standard. The data shown in supplementary suggest that predictions can be scored against a consensus network instead of using a silver standard, with similar top rankings when an appropriate threshold is used. Consensus scoring can thus avoid any bias caused by the choice of algorithm for the silver standard; however, it could be sensitive to outliers (e.g. predictions that are much better than 489 the rest), or multiple correlated predictions caused by collaborating teams or the use of similar methods. The predicted networks were aggregated using a mixture of two beta binomial distributions as shown in Section 2. To find the optimal threshold for determining the existence of an edge, a two step process was used. First, the distribution in Equation 3 was fitted to the consensus data; then the minimum number of teams k was determined for which Pr(Y = 1jX = k) 4 Pr(Y = 0jX = k). From the first step, the value of the mixture constant Pr(Y = 1) (Equation 7) can give an indication of the proportion of true edges in the reference network which in this case was 16%. Despite this, the solution to the second step resulted in consensus networks with 7.4% edges for human and 6.7% edges for rat out of all the reference network edges. This result suggests that less than half of the potential regulatory connections were discovered and more challenge participants were needed to increase statistical power and reconcile the two estimates of the number of true edges. Despite these limitations, the consensus network shown in supplementary displays some interesting patterns, some of which are shown in and B. Overall, the camp responsive element binding protein 1, also known as CREB1, showed the best consensus for the edges upstream of it (Supplementary) but with a couple of differences between human and rat: the connection from RPS6KA1 was present only in the human consensus network (), whereas the connection from prk aca was present only in the rat consensus network (). The prevalence of RPS6KA1 (a.k.a. RSK1) interactions in human (Supplementary) might be explained by the fact that human isoforms of RSK1 have functional redundancy (i.e. RPS6KA3; RPS6KA2; and RPS6KA6). In contrast, this is most likely not the case in rodents reported that the mouse RSK1 and RSK3 genes may not be able to fully compensate for the lack of RSK2 function. The consensus results also suggest a preference for JAK1 activation through EGFR for human and the PDGFR complex for rat. Direct interaction between JAK1 and IRS1 has been reported in cultured human peripheral blood T cells (). In rat, however, the interaction seems to be indirect through proteins SOCS2, SOCS3 and JAK2 (). Other conserved interactions include IFNGR1 to JAK2 and JAK2 to STAT5A, which are parts of the interferon gamma pathway known to be conserved across vertebrate species (). Additional references are provided for the majority of edges from the consensus networks and are available as Supplementary Material. These references are categorized by organism and tissue context as follows: airway cells, non lung cells and lung cancer epithelial cells. Although numerous pathway databases are widely available, they are too generic and lack specific context when displaying an interaction. The purpose of this challenge was to fine tune one of these generic networks based on data collected from bronchial primary cells exposed to specific stimuli (compounds). When comparing the resulting consensus network to networks obtained from the Ingenuity Pathway Analysis tool (IPA: www ingenuity com we observe a steady increase in precision as the number of votes required for an edge increases (Supplementary), culminating at eight votes as predicted by the model in Equation 6. The maximum precision obtained is 0.33 for the human network and 0.09 for the rat network. However, this could be explained by the relatively few edges identified in IPA for human (69) and especially rat (26) (the number of edges drastically decreased if a filter on cell tissue type was applied), as well as the lack of proper context provided by tissue specificity and stimuli. The IPA networks as well as the consensus networks are available as Supplementary Material.
