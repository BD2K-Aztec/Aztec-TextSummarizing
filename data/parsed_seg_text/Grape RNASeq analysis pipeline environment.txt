Motivation: The avalanche of data arriving since the development of NGS technologies have prompted the need for developing fast, accurate and easily automated bioinformatic tools capable of dealing with massive datasets. Among the most productive applications of NGS technologies is the sequencing of cellular RNA, known as rnase q. Although rnase q provides similar or superior dynamic range than microarrays at similar or lower cost, the lack of standard and user friendly pipelines is a bottleneck preventing rnase q from becoming the standard for transcriptome analysis. Results: In this work we present a pipeline for processing and analyzing rnase q data, that we have named Grape (Grape rnase q Analysis Pipeline Environment). Grape supports raw sequencing reads produced by a variety of technologies, either in fast a or fast q format, or as pre aligned reads in samba m format. A minimal Grape configuration consists of the file location of the raw sequencing reads, the genome of the species and the corresponding gene and transcript annotation. Grape first runs a set of quality control steps, and then aligns the reads to the genome, a step that is omitted for pre aligned read formats. Grape next estimates gene and transcript expression levels, calculates exon inclusion levels and identifies novel transcripts. Grape can be run on a single computer or in parallel on a computer cluster. It is distributed with specific mapping and quantification tools, but given its modular design, any tool supporting popular data interchange formats can be integrated. Availability: Grape can be obtained from the Bioinformatics and Genomics website at: http://big.crg.cat/services/grape.

introduction the development of ultra sequencing technologies during the recent years has started a major revolution in Biology. The ability to directly survey the cell's RNA content by applying NGS technologies to cDNA sequencing rnase q has provided insights of unprecedented depth on the transcription landscape of many species () such as Homo sapiens (), Mus musculus (), Arabidopsis thaliana (), Saccharomyces cerevisiae () and Schizosaccharomyces pombe (). rnase q has proven particularly powerful on tasks such as identifying novel genes and novel splice forms, detecting low abundance transcripts and finding sequence variations, such as SNPs (). It is gradually substituting microarrays as the technology of choice for transcriptome analyses, providing access to a greater dynamic range of RNA expression levels (). The throughput of NGS technologies is continuously accelerating, and the cost per sequenced nucleotide is rapidly falling. As a consequence, an unprecedented amount of data are being produced, pressing for the development of fast and efficient methods of analysis, as the bottleneck for scientific discovery is gradually shifting from data production to data analysis. In the analysis of NGS data, processing efficiency is governed predominantly by two factors: first, the sheer size of the individual datasets, and second, the vast number of datasets to be analyzed. The current generation of sequencing machines, for example, Illumina high seq can produce the equivalent of 20 the coverage of the human genome in a single run, delivering $600 million reads with a length of 4100 nt. This has spawned a new generation of aligners optimized for aligning short sequences to the genome, for example, Bowtie (), BWA (), b fast () and GEM (), which are much faster than previous tools such as Basic Local Alignment Search Tool, fast a or s search (see, for a short review). Additionally, an increasing number of projects involve large sample sizes to be analyzed, often under complex experimental designs. In the specific case of rnase q mapping of reads is only the first step of a complex data processing schema, the final goal of which is to produce accurate gene and transcript quantifications, and to delineate novel transcript structures. The lack of easy to use pipelines to perform such a processing out of the box in a transparent and streamlined fashion is actually a bottleneck that prevents the expansion of rnase q and prompts users with little access to sophisticated bioinformatic resources to prefer microarrays, for which standard ready to use processing pipelines and user friendly bioinformatic analysis tools exist. To address this need, specific pipelines have recently been developed for analyzing rnase q data, such as the pipeline developed by), an analysis pipeline developed in R within the context of the array express Database. These and other tools facilitate the analysis of rnase q data, but still require the user to have a significant bioinformatics background, specifically when complex experiments with a large number of datasets need to be analyzed. *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited here we describe Grape, a workflow for the analysis of rnase q data that automates all the steps from rnase q reads to transcript quantification and discovery. Its user friendly interface provides the necessary overview of all the data, and is therefore particularly suited for processing numerous files, produced in complex experimental setups. The results, both intermediate and final, are stored in an MySQL database, allowing for access through the database interface, but can also be visualized through Raisin, a user friendly web application. The same html interface that is used for standalone local analysis is easily deployed on a web server for remote access in collaborative projects, or data dissemination. Grape takes three types of input files. First, the read files, which may be aligned or not, the reference genome sequence file and the corresponding gene annotation file. Alternatively, Grape can also take read alignment files as input, rather than raw read files. Grape produces a number of output files in tabular format, so they can be easily loaded into most statistical packages. While this is the case for quantifications, which are made available individually at the gene, transcript and exon level, the BAM format is used as an output format for alignments. More specifically, processing of rnase q reads by Grape involves the following steps: (i) sequence read evaluation, and trimming if required; (ii) mapping to the genome, and the transcriptome; (iii) assembly of reads in absence of a reference genome, or before genome mapping; (iv) identification of novel exons, and splice junctions and modeling of transcript structures and (v) gene and transcript quantification. Grape pays special attention to quality controls (QCs), which trace quality scores and uncalled bases along the reads, look for biased nucleotide composition and inspect the distribution of reads along transcripts. These can be used for QC, although Grape leaves any decision to modify the data, such as trimming and filtering, to the user. Grape is based on the PIP pipeline management system (). The current Grape distribution uses sam tools (), the GEM mapper (), the Flux Capacitor () and Cufflinks (), but any tool compliant with popular data interchange formats like GFF, bams am and BED can be used. Grape can be run locally or on a computer cluster. speed up of the analyses is achieved by parallelizing certain steps and taking advantage of multithreading where possible. The Grape implementation conserves a copy of the exact software and configuration used for a given set of analyses, guaranteeing forward reproducibility.

discussion here we presented and discussed Grape, an architecture for a computational pipeline for the analysis of millions or billions of short reads obtained from (potentially many) high throughput rnase q experiments. This is a general and flexible pipeline that combines contributions of previous studies with our own experience dealing with rnase q data. Grape attempts to address the challenges both from the processing and management standpoints associated to the analysis of sheer amounts of data. It automates the processing and analysis steps, while at the same
