Motivation: The area under the receiver operating characteristic (ROC) curve (AUC), long regarded as a golden measure for the predictive ness of a continuous score, has propelled the need to develop auc based predictors. However, the auc based ensemble methods are rather scant, largely due to the fact that the associated objective function is neither continuous nor concave. Indeed, there is no reliable numerical algorithm identifying optimal combination of a set of biomarkers to maximize the AUC, especially when the number of biomarkers is large. Results: We have proposed a novel auc based statistical ensemble methods for combining multiple biomarkers to differentiate a binary response of interest. Specifically, we propose to replace the non continuous and non-convex AUC objective function by a convex surrogate loss function, whose minimizer can be efficiently identified. With the established framework, the lasso and other regularization techniques enable feature selections. Extensive simulations have demonstrated the superiority of the new methods to the existing methods. The proposal has been applied to a gene expression dataset to construct gene expression scores to differentiate elderly women with low bone mineral density (BMD) and those with normal BMD. The a ucs of the resulting scores in the independent test dataset has been satisfactory. Conclusion: Aiming for directly maximizing AUC, the proposed auc based ensemble method provides an efficient means of generating a stable combination of multiple biomarkers, which is especially useful under the high dimensional settings.

introduction given that there are multiple biomarkers and a binary response of interest (e.g. case and control), it is often of substantial interest to combine the biomarkers to form a 'strong' scoring system for the differentiation of cases from controls. While the choice of the predictive measure is not unique, the most appealing choice is the area under the receiver operating characteristic (ROC) curve (AUC) in the case control study (). * To whom correspondence should be addressed. For finite samples, AUC is simply the non-parametric two sample mann whitney U test statistics. Unlike the measures such as misclassification rate, the AUC reflects the intrinsic predictive value of a score in that it does not depend on the prevalence of the cases and thus is invariant under the case control sampling. Therefore, it is natural to combine biomarkers by maximizing the AUC under ROC curve (). However, it is notoriously difficult to maximize the AUC numerically since the objective function is neither continuous nor convex. Ad hoc methods have been proposed to tackle the numerical problem. For example, sigmoid function has been used to approximate the indicator function used in calculating AUC (). However, the smoothed objective function may still have multiple local maximums, with no guarantee of locating the global maximizer by using the commonly used numerical algorithms. In view of these challenges, we propose a class of ensemble methods aiming for maximizing AUC with multiple biomarkers. Specifically, we introduce a class of convex surrogate loss functions to approximate the non-convex AUC, greatly facilitating computation and optimization.

discussion motivated by recent advances in data mining, we have proposed a class of methods combining biomarkers to construct a scoring system, boosting the resulting AUC under the ROC curve, a prevalence free summarization of intrinsic predictive values of a continuous score. The method is easily adapted to high dimensional cases, wherein one may need to identify informative features from thousands of candidate biomarkers. In high dimensional case, we propose to apply lasso regularization to yield a parsimonious combination maximizing the AUC. On the other hand, lasso is neither the unique nor the universally optimal regularization method for analyzing high dimensional data. Due to the convexity of the proposed loss function, it is straightforward to couple M j () with other penalty functions such as elastic net, adaptive lasso and SCAD, which may have superior performance to simple lasso in specific settings (). The key proposal is to target a convex surrogate loss function instead of a discontinuous mann whitney rank statistic. While in this article, we have focused on the hinge loss function (corresponding to the 1 norm support vector machine), our results can be extended to accommodate other versions of SVM loss
