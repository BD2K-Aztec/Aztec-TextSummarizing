precision recall (PR) and receiver operating characteristic (ROC) curves are valuable measures of classifier performance. Here, we present the r package pr roc which allows for computing and visualizing both PR and ROC curves. In contrast to available r packages pr roc allows for computing PR and ROC curves and areas under these curves for soft labeled data using a continuous interpolation between the points of PR curves. In addition, pr roc provides a generic plot function for generating publication quality graphics of PR and ROC curves.

introduction the assessment of classifier performance is a recurring task in machine learning and data mining, and in particular in bioinformatics applications. It assists researchers in identifying the most promising approach for the classification problem at hand. For binary classification tasks, the receiver operating characteristic (ROC) curve and the area under this curve au croc are widely accepted as a general measure of classifier performance. In many bioinformatics applications, however, positive examples are substantially less abundant than negative examples, resulting in a highly imbalanced class ratio. For instance, the number of target genes of a microRNA is substantially smaller than the number of non-target genes. In such cases, the precision recall (PR) curve and AUC au cpr is better suited for comparing the performance of individual classifiers than the ROC curve and au croc (). Often, the decision for the true class labels of a given data point is arguable and, for instance, based on an arbitrary threshold for some continuous measurement or based on multiple, possibly contradictory, expert labelings. However, the choice of this threshold decisively influences classifier training and assessment. One solution to this problem is the transition from hard labeling to soft labeling where each data point is assigned to both classes with a certain probability that reflects confidence in the labeling (). Although soft labeling has been used extensively for classifier training in the past, it has been neglected for classifier assessment (). Computing empirical au cpr and au croc values from a limited set of test data points requires interpolation between discrete supporting points corresponding to a series of classification threshold affecting the classification result. au croc can be computed by linear interpolation between the supporting points of the curve for hard labeled and soft labeled data. In contrast, Davis and show that for au cpr an interpolation along the true positives is more accurate than linear interpolation for hard

discussion we present pr roc an r package for computing PR and ROC curves as well as their a ucs for soft labeled and hard labeled data, which may be beneficial for typical bioinformatics applications. Additionally, pr roc provides a function for plotting PR and ROC curves within R. The pr roc package provides R documentation files and a vignette conflict of Interest: none declared.. Plots of ROC (left) and PR (right) curves generated by pr roc. For the ROC curve, we consider hard labeled data and show the plotting variant with a color scale that indicates classification thresholds yielding the points on the curve. For the PR curve, we consider soft labeled data and show a comparative plot for two classifiers as solid and dashed lines. We also include the maximal and minimal possible curves and the curve of a random classifier for the given soft labels
