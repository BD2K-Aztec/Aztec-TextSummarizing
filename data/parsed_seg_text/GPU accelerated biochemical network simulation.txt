Motivation: Mathematical modelling is central to systems and synthetic biology. Using simulations to calculate statistics or to explore parameter space is a common means for analysing these models and can be computationally intensive. However, in many cases, the simulations are easily parallelizable. Graphics processing units (GPUs) are capable of efficiently running highly parallel programs and outperform CPUs in terms of raw computing power. Despite their computational advantages, their adoption by the systems biology community is relatively slow, since differences in hardware architecture between GPUs and CPUs complicate the porting of existing code. Results: We present a Python package, cuda sim that provides highly parallelized algorithms for the repeated simulation of biochemical network models on NVIDIA CUDA GPUs. Algorithms are implemented for the three popular types of model formalisms: the l soda algorithm for ODE integration, the euler maruyama algorithm for SDE simulation and the Gillespie algorithm for MJP simulation. No knowledge of GPU computing is required from the user. Models can be specified in SBML format or provided as CUDA code. For running a large number of simulations in parallel, up to 360-fold decrease in simulation runtime is attained when compared to single CPU implementations. Availability: http://cuda-sim.sourceforge.net/

introduction mathematical modelling is an integral part of systems and synthetic biology. Ordinary differential equations (ODEs) are the most commonly used methodology, but due to increasing appreciation of the importance of stochasticity in biological processes, stochastic differential equations (SDEs) and Markov jump processes mj ps are also applied. Since most models are non-linear, they generally can not be solved analytically and therefore require numerical treatment. Furthermore, in order to understand behaviour across high dimensional parameter space or to perform simulation based inference (), a very large number * To whom correspondence should be addressed.  Present address: Apoptosis and Proliferation Control Laboratory, Cancer Research UK, London Research Institute, London, UK. of simulations is required, making analysis of even the simplest models extremely time consuming. For computationally expensive calculations, graphics processing units (GPUs) can be used. GPUs are many core, multi-threaded chips that are capable of several hundred GFLOPS (). In terms of raw computing power, a single GPU in a desktop PC is comparable to a CPU cluster, but is much cheaper. However, due to their single instruction multiple data (SIMD) architecture, only highly parallelized processes can be efficiently run on GPUs. Even though platforms for general purpose GPU computing like CUDA  (Compute Unified Device Architecture) from NVIDIA  which provides a CUDA API exist, it remains difficult and time consuming to port existing algorithms that were designed for execution on CPUs. There have been developments in porting biochemical network simulators to GPUs (reviewed in) but there does not currently exist a general purpose simulation tool that integrates multiple algorithms within the same interface. Here, we present a new Python package called cuda sim which provides highly parallelized algorithms for large scale simulations of biochemical network models. It is compatible with all NVIDIA GPUs that support CUDA. Absolutely no knowledge of CUDA and GPU computing is needed for the user to access the simulation algorithms: (1) The integration of ODEs is carried out using a GPU implementation of l soda (, (2) SDE simulations are provided via the euler maruyama algorithm () and (3) simulations from a MJP (or Master equation) are performed using the Gillespie algorithm (). All functionality can be accessed via a Python interface that hides the implementation details.
