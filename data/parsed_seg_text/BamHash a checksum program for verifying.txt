Large resequencing projects require a significant amount of storage for raw sequences, as well as alignment files. Because the raw sequences are redundant once the alignment has been generated, it is possible to keep only the alignment files. We present bam hash a checksum based method to ensure that the read pairs in fast q files match exactly the read pairs stored in BAM files, regardless of the ordering of reads. bam hash can be used to verify the integrity of the files stored and discover any discrepancies. Thus, bam hash can be used to determine if it is safe to delete the fast q files storing raw sequencing read after alignment, without the loss of data.

introduction resequencing projects, where individuals are sequenced from a species with a known reference genome, generate a significant amount of raw sequences that are then aligned to the reference genome. Data storage becomes an issue as the cost of sequencing decreases and the throughput of current sequencing technologies keeps increasing. Raw sequencing reads are generally stored in fast q file format, usually compressed. After read mapping the resulting alignment is stored in a BAM file (). This BAM file is then sorted and processed further, but most importantly it contains all the original information of the fast q file. Sorted BAM files yield a better compression, compared with unsorted BAM files, as well as allowing random lookup over genomic regions. For this reason almost all post alignment analysis, e.g. variant calling, realignment, and local assembly are done on the sorted BAM file, rather than the original fast q file. Because the BAM file contains all the information of the fast q file it is justifiable to delete the fast q file after alignment. After all, the contents of the fast q file can be regenerated from BAM file. However, before deleting the fast q file, we need to be sure that there is no loss of data, i.e. that the sequences in the fast q file are exactly the same as the sequences in the BAM file. The two files could differ due to a number of reasons. Any errors in the alignment pipeline could generate inconsistent files. Although the alignment pipelines are based on well tested tools, they are meant to operate under normal conditions and their behavior can be unpredictable in the presence of hardware failure or running out of disk space. Thus, it is important to be able to independently verify the output of the entire pipeline. We present bam hash a tool for verifying the data integrity between a fast q and a BAM file. The program computes a 64-bit fingerprint from the sequences and read names for both fast q and BAM files. The method is highly sensitive to changes in the input so a change in a single nucleotide will result in different fingerprints; the probability of generating the same fingerprint by chance is astronomically small. The role of this tool is to flag any fast q and BAM files that have different fingerprints and mark the fast q files as unsafe for deletion. bam hash plays the same role as the md5sum program, which computes a fingerprint of files. Comparing md5sum fingerprints () of fast q and BAM files would not yield a comparable result, since the formatting and ordering are different. Our method is fast and memory efficient; it can compute the fingerprint of a BAM file from 30-fold coverage human sequencing experiment in 30 min.

discussion the role of bam hash is to detect differences between the read sets of raw fast q and aligned BAM files. This discrepancy can arise due to mistakes in the pipeline, bugs in alignment code or disk failures. When the data integrity has been verified, the original fast q files can be safely discarded, thus freeing up storage space. Additionally, bam hash will be useful when porting alignments to a new reference genome. Such a pipeline would create intermediate fast q files, which would then be aligned to the new reference. The old BAM file can be removed only if the bam hash signature agrees with the newly created alignment. bam hash can only detect differences between exact matches of set of reads, not how they differ. In many scenarios, low quality reads are discarded before alignment, or reads that do not map are discarded from the BAM file. In this case the set of reads in the final BAM file is a subset of the original set of reads. Unfortunately, no fingerprinting method can detect if the BAM reads are a subset of the fast q reads. This is because fingerprinting is a restricted form of communication between two parties, the BAM has her and the fast q has her and lower bounds on the communication complexity of the set disjointness problem () dictate a lower bound of Xn bits of communication to simply answer the question of whether two sets are disjoint, namely the set of BAM reads and the complement of the set of fast q reads.
