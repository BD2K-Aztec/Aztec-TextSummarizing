Motivation: The detection of genomic structural variation (SV) has advanced tremendously in recent years due to progress in high throughput sequencing technologies. Novel sequence insertions , insertions without similarity to a human reference genome, have received less attention than other types of SVs due to the computational challenges in their detection from short read sequenc-ing data, which inherently involves de novo assembly. De novo assembly is not only computation-ally challenging, but also requires high quality data. Although the reads from a single individual may not always meet this requirement, using reads from multiple individuals can increase power to detect novel insertions. Results: We have developed the program pop ins which can discover and characterize non reference insertions of 100 bp or longer on a population scale. In this article, we describe the approach we implemented in pop ins. It takes as input a reads to reference alignment, assembles unaligned reads using a standard assembly tool, merges the contigs of different individuals into high confidence sequences, anchors the merged sequences into the reference genome, and finally genotypes all individuals for the discovered insertions. Our tests on simulated data indicate that the merging step greatly improves the quality and reliability of predicted insertions and that pop ins shows significantly better recall and precision than the recent tool mind the gap. Preliminary results on a dataset of 305 Icelanders demonstrate the practicality of the new approach. Availability and implementation: The source code of pop ins is available from http://github.com/ b kehr pop ins
introduction the latest version of the human reference genome (), GRCh38, is of a remarkable quality. However, the sequence of a single individual is inherently different from the reference due to sequence diversity. Some sequences are missing in the reference as they are not present in the individuals from whom the reference was constructed. Alternate haplotypes have been added to the reference genome () to account for highly variable regions, but they cover only a small part of the variation. The variable regions are of great biological and medical interest since their sequence diversity is known to affect phenotypes including numerous diseases (). Thus, the characterization of differences to the reference genome is a major task. Differences between human genomes include single nucleotide polymorphisms (SNPs), small indels and structural variants (SVs). One type of SVs, which affect a larger piece of sequence than indels, V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals permission soup com are insertions. Insertions can be further classified into duplications and novel sequence insertions. Duplications are insertions of sequence also present elsewhere in the genome, e. g. mobile elements. The focus of this work is on novel sequence insertions, insertions of unique sequence that is not similar to other regions of the reference genome. The evolutionary origin of a novel sequence insertion may be explained by two types of events. On the one hand, it may be an addition of sequence to the genome of a sequenced individual, e. g. lateral transfer or viral genome insertion. On the other hand, it may as well be a deletion of sequence in the individuals used to contruct the reference. In order to successfully associate genetic differences with phenotypes, large numbers of individuals are necessary. With the enormous improvements in sequencing technology, recent years have seen a marked increase in large scale efforts that aim at discovering variation at a population level, e.g. the HapMap project (), the 1000 genomes projects (1000 Genomes) and the Genome of the Netherlands project (). The achievements of these efforts have been the characterization of a great number of SNPs, indels, and deletions, but comparatively fewer novel insertions. For example reported only 128 novel insertions in contrast to 22 025 deletions in their release set. One reason for a smaller number of insertions discovered is the fact that their detection from short read sequencing data is challenging (). Unlike detection of other types of variation, insertion detection requires a de novo assembly. Typical genotype callers, such as g atk () or free bayes (), use only reference aligned read pairs and, therefore, are not suitable for calling insertions longer than the reads. Sequencing technologies that yield longer reads () show promise in simplifying insertion detection (), but they are still not commonplace nor cost effective on a large scale. Thus, insertions remain one of the most challenging types of variation to detect. Strategies for detecting insertions incorporate either a local assembly of unknown sequence not present in the reference genome () or a whole genome assembly (). A whole genome assembly needs to be followed by a comparison step of the assembled contigs to the reference genome for identifying the insertions. In the local assembly strategy, the positions of the insertions need to be identified either before or after assembly. For example, the strategy implemented in the program mind the gap () first identifies candidate insertion sites without a read alignment before initiating local assemblies, whereas the novel seq approach () first assembles unaligned reads before anchoring them in the genome. Both the whole genome and the local assembly strategies face difficulties when integrating the results of many individuals. This issue is most pronounced in de novo whole genome assembly strategies and, thus, has previously been addressed suggested a reference guided whole genome assembly approach that makes the results of several samples more compatible developed Cortex, a program that rigorously assembles the whole genomes of several individuals at the same time based on colored de bruijn graphs. However, the tests in the Cortex paper were limited to relatively few individuals or to pooled data. Furthermore, all whole genome assembly strategies commonly suffer from a considerable demand for computational resources. In addition, the assembly problem demands high coverage data (). Assemblies from low coverage data are typically incomplete, i.e. fragmented and with significant portions of the sequences missing (). Hence, the application of any of the mentioned approaches on a dataset from a single individual sequenced at insufficient coverage, results in a largely incomplete set of insertions. Polymorphic insertions with low frequency in a population are particularly hard to detect as they are likely to appear only at heterozygous loci. Additionally, incomplete assemblies lead to greater difficulties in comparing and integrating sets of insertions across multiple individuals. If not carefully considered at the population level, all this can add to an underestimation of allele frequencies, less power to detect rare insertions, and may eventually impede association with phenotypes. Despite the caveats mentioned, the task of analyzing large numbers of individuals can also aid in the detection of insertions. Insertions that occur within many individuals have an increased total coverage across the whole dataset. If used in the assembly step, this may reduce fragmentation and fill in gaps of the insertion sequences. The larger the number of individuals, the more likely it is that we can capture low frequency insertions. Thus, instead of merging insertions detected from many individuals, we can take advantage of all individuals during the detection of insertions. We have developed an approach for characterizing insertions across a large number of individuals simultaneously using a local assembly strategy. We start by assembling per individual reads that do not align to the reference genome. Subsequently, we merge the assemblies into a multi individual contig set of higher quality. Each contig in this set is then placed into the reference genome using read pair and split read information. Finally, we propose a genotyping procedure that determines for each individual the number of copies it carries of an insertion in its diploid genome. We have implemented the approach in a program called pop ins. Our tests on simulated data indicate that merging of single individual assemblies increases the quality of insertion sequences by 20%. A comparison to mind the gap () confirms that we greatly benefit in recall from the merging step and that our approach is precise. An additional test on data from 305 whole genomes obtained with Illumina sequencers demonstrates its practicality on real data.

discussion we have introduced pop ins a method for discovering and genotyping novel sequence insertions. pop ins takes advantage of the information provided by many individuals, increasing the quality of the insertion sequences and significantly improving on our ability to determine the correct insertion position. Our local assembly approach reduces computational requirements as compared to whole genome assembly (). On the downside, our approach depends on a read alignment and, thus, will be biased against the reference. The major novelty of our approach is the addition of a merging step to a local assembly strategy. The merging subproblem is per se an assembly problem but significantly different from the classical genome assembly problem. The input sequences of the merging subproblem are themselves assembled contigs and, hence, can contain artifacts from mis assemblies. In addition, they vary in length and we expect them in the best case not to be much shorter than the supercontig s. Similar to transcriptome assembly, the coverage is uneven depending on the number of individuals that are carriers of an insertion and, finally, more than two haplotypes are possible for each insertion locus as the contigs originate from many individuals. Nevertheless, our solution to the merging subproblem is similar to the overlap layout consensus (OLC) approach for genome assembly (). The use of the union find data structure is similar to the graph used in the overlap phase of OLC approaches; our sets of contigs correspond to connected components in this graph. Our approach differs from the OLC approach in the layout phase by allowing for branching components when constructing supercontig s. When finding insertion positions, pop ins greedily clusters anchoring read pairs by location, while other SV detection methods solve a maximum clique problem (). Our approach can lead to very long intervals for a single location. But since we cluster the anchoring read pairs only per contig and not over the whole dataset, we observe only very few abnormally long intervals. We discard these applying a length threshold as they are unlikely to lead to a clear insertion position. In our evaluation, we were not always able to find the insertion position for both contig ends, which can have several reasons. If we find a single location with anchoring read pairs but no clear position with split reads, the contig is likely not to contain the whole insertion. The split alignment algorithm we used penalizes all gaps in the reference. Allowing for a large gap in both the reference and the reads may help in narrowing down the position of these insertions. Another reason may be non unique sequence being inserted together with the novel sequence. The set of unaligned reads will not assemble into contigs of non unique sequence (e.g. mobile elements), thus, these are missing in our approach. In many cases, this leads to many low scoring locations suggested by read pairs that anchor to known occurrences of the repeated sequence. Finally, we observe read pairs connecting several contigs, suggesting insertions of novel sequence interspersed with non unique sequence. An additional scaffolding step of supercontig s would be necessary to fully characterize these cases. In many cases, we observe the same short sequence repeated at the two ends of an insertion (often referred to as target site duplications). If the repeated sequences become too long, our genotyping approach has difficulties in distinguishing the reference allele from the alternate allele. This may potentially be improved by focusing the computation on the unique part of the sequence. Our results on simulated data do not reflect all of these limitations of pop ins that are due to the complex structure of real genomic sequences. Still, we could show the practicality of the approach on real data, where it yields many novel sequence insertions. Therefore, we are expecting a rich set of polymorphic insertion when applying pop ins to a larger number of individuals, which will open up the door to include novel sequence insertions in genome wide association studies. Conflict of Interest: none declared.
