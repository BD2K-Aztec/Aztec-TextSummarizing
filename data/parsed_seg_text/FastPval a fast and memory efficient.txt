Motivation: Resampling methods, such as permutation and bootstrap, have been widely used to generate an empirical distribution for assessing the statistical significance of a measurement. However, to obtain a very low p value a large size of resampling is required, where computing speed, memory and storage consumption become bottlenecks, and sometimes become impossible, even on a computer cluster. Results: We have developed a multiple stage p value calculating program called fast pval that can efficiently calculate very low (up to 10 âˆ’9) p values from a large number of resampled measurements. With only two input files and a few parameter settings from the users, the program can compute p values from empirical distribution very efficiently, even on a personal computer. When tested on the order of 10 9 resampled data, our method only uses 52.94% the time used by the conventional method, implemented by standard quicksort and binary search algorithms, and consumes only 0.11% of the memory and storage. Furthermore, our method can be applied to extra large datasets that the conventional method fails to calculate. The accuracy of the method was tested on data generated from Normal, Poison and Gumbel distributions and was found to be no different from the exact ranking approach. Availability: The fast pval executable file, the java GUI and source code, and the java web start server with example data and introduction, are available at

introduction permutation and bootstrap are resampling procedures to assess the statistical significance of a measurement. They are non-parametric statistical tests that can convert a measurement (score) into an empirical p value even when the distribution of the measurements is unknown. Since resampling does not assume known distribution of the data, and biological data are usually complex, it has been widely used in the bioinformatics field, such as transcription factor binding site searching, pathway analysis and genome wide association studies. * To whom correspondence should be addressed finding transcription factor binding sites tfbs s in the promoter region of a gene is important to understand gene regulation (). TFBS of a particular transcription factor are usually represented by a computational model known as the position weight matrix (PWM) (). To search for a putative binding site, we use the PWM to score DNA sequences with a sliding window approach. For each window, we obtain a score. By comparing this score with the distribution of the scores from the background, we can obtain the statistical significance (empirical p value of this score. The empirical background score distribution is obtained by scoring a large set of random sequences from the intergenic regions in the genome with the same PWM. We then sort the background scores and save them for later usage. When we convert a new score into a p value we load the background into the memory and search for the score. The ranking of the score is then converted to a p value (). This empirical approach of calculating p values is very powerful since it does not assume any distribution of the data. However, the significance of the p value is limited by the size of the background we sample. To obtain a very low p value we have to sample a very large dataset from the background. The large dataset causes three limitations: (i) sorting and searching in a large dataset are time consuming; (ii) storage of the sorted background scores requires a large amount of hard disk space; and (iii) processing of the sorted array requires a great deal of memory, which is not usually feasible on a personal computer. Efficient methods have been developed to relieve the computational burden resulting from large scale resampling. For example developed a Bayesian approach to dynamically assign re samples for multiple testing problems. For microarray expression data, they assume that each gene has a different null distribution, and allocate more re samples to the genes with p values close to the classification threshold. But for the p values that are far lower or far higher than the threshold and the decisions that are easy to make, they allocate much fewer re samples than the traditional method. The dynamic resampling allocation strategy has improved the computing efficiency, particularly when the number of tests is large. While the above mentioned method deals with the efficiency of multiple tests, assuming each test has a different null distribution, p value calculation from resampling based on a single test, or multiple tests assuming the same null distribution, is still hampered by computing, memory and storage limitations. We have developed an efficient program to calculate the empirical p value for a single test, or multiple tests assuming the same null
