Genotype imputation is now commonly performed following genome wide genotyping experiments. Imputation increases the density of analyzed genotypes in the dataset, enabling fine mapping across the genome. However, the process of imputation using the most recent publicly available reference datasets can require considerable computation power and the management of hundreds of large intermediate files. We have developed gen ipe a complete genome wide imput-ation pipeline which includes automatic reporting, imputed data indexing and management, and a suite of statistical tests for imputed data commonly used in genetic epidemiology (Sequence Kernel Association Test, Cox proportional hazards for survival analysis, and linear mixed models for repeated measurements in longitudinal studies). Availability and Implementation: The gen ipe package is an open source Python software and is freely available for non-commercial use (CC by nc 4.0) at https://github.com/pgxcentre/genipe. Documentation and tutorials are available at

introduction genome wide association studies g was are usually performed on datasets containing over 1 million genetic markers. Those markers are typed using high throughput genotyping arrays that target a small fraction of all possible genetic variants. Imputation is a low cost and popular statistical method to infer genotypic information at up to 80 million known genetic variants (including single nucleotide variants and insertions deletions. Imputation is often used to boost statistical power and it can be used to infer missing data and standardize variant sets for meta analysis (). Large sequencing projects spanning multiple human populations greatly increase the availability and quality of public imputation panels, but the statistical methods needed for haplotype phasing and imputation at the genome wide level are computationally intensive. In order to streamline this process, we have developed a genome wide imputation pipeline that automates all necessary computational steps including quality control and reporting while providing support for high performance computing environments and statistical tests for imputed data.

application the pipeline's documentation provides a typical imputation analysis tutorial along with required files. Those files includes a dataset of 2 278 357 markers genotyped on 90 HapMap samples. Using the 1000 Genomes Phase 3 reference panels, the dataset was imputed on two different systems: a computing server (10 nodes of 8 intel v R xeon v R E5620 CPUs 2.40 GHz, 48G of RAM per node) using the DRMAA API for automatic task submission and a desktop computer intel v R Core TM i7-3770 CPU 3.40 GHz, 16G of RAM). Using a maximum of 50 simultaneous tasks, the pipeline took a total of 4.25 h on the computing server (including a waiting period of 0.08 h in queue). Using a maximum of four simultaneous tasks, the pipeline took 10.62 h to complete on the desktop computer.

conclusion although online imputation pipeline exists (e.g. the Michigan Imputation Server that uses Minimac3; https://imputationserver.sph. umich edu and the Sanger Imputation Service that uses pb wt https://imputation.sanger.ac.uk/), gen ipe is advantageous for the users who can not upload genotypic data on an off-site server for ethical or legal restrictions. Also, as public servers gain in popularity, the high workload can add significant time to the imputation analysis (queue time). The gen ipe pipeline can be efficiently executed on a local high performance computing server or on a single desktop computer. Finally, gen ipe provides a unified interface to statistical analysis packages that did not have existing tools to automate the use of dosage data (e.g. linear mixed models from stats models Cox proportional hazards from lifelines and SKAT).
