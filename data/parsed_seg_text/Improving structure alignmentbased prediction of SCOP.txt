Motivation: The slow growth of expert curated databases compared to experimental databases makes it necessary to build upon highly accurate automated processing pipelines to make the most of the data until curation becomes available. We address this problem in the context of protein structures and their classification into structural and functional classes, more specifically, the structural classification of proteins (SCOP). Structural alignment methods like vor ol ign already provide good classification results, but effectively work in a 1 nearest Neighbor mode. model based (in contrast to instance based approaches so far have been shown to be of limited values due to small classes arising in such classification schemes. Results: In this article, we describe how kernels defined in terms of vor ol ign scores can be used in SVM learning, and explore variants of combined instance based and model based learning, up to exclusively model based learning. Our results suggest that kernels based on vor ol ign scores are effective and that model based learning can yield highly competitive classification results for the prediction of SCOP families. Availability: The code is made available at: http://wwwkramer.in. tum de research applications vor ol ign kernel
introduction with the ever increasing number of known protein structures, the assignment of individual domains to structural classes has become a crucial task in computational biology. For this purpose, several protein databases like SCOP () and CATH () have been created over the past few years, trying to categorize protein structures into various (hierarchical) classes that reflect certain common evolutionary or structural properties. Ranging from manual inspection of protein topologies and sequences to fully automatic assignment methods, they are built upon diverse approaches and employ various criteria and orders of generality to assign the class of a target protein. One of the most important and best regarded databases is SCOP, Structural Classification of Proteins, an originally completely * To whom correspondence should be addressed. manually built hierarchical class structure. Although a certain degree of automation has been introduced since its first release in order to cope with the heavily increasing number of newly discovered protein structures, it still features the highest degree of human expert knowledge (). This has ambivalent effects: on the one hand, it has made SCOP become a point of reference for comparing the quality of protein classification methods in a variety of research areas, and it also comes with the disadvantage of leading to a slow update process; since its publication, SCOP followed about an annual release cycle so that novel protein structures are not available for prediction efforts relying on protein structure classifications. With the introduction of structural alignment algorithms like vor ol ign () and PPM (), it was recently shown for comprehensive test sets that automatic predictions solely relying on structure alignment scores can achieve classification accuracies beyond 90% for the higher levels of SCOP and around 85% on the family level. Another recent method, auto scop (), directly aims at predicting the future SCOP classification by employing a sequence pattern based filter and vor ol ign as a plug-in and achieved 92% accuracy also on the family level. In the cases those protein similarity measures have been used as classifiers so far, it has always been in an instance based way, i.e. the structure with the highest similarity was determined and its respective class assigned to the target protein. model based machine learning methods were assumed not to be suitable, as classes with only one or a few members would have to be generalized. This is why recently introduced a simple classification scheme called punting, which combines models and instance based learning by trying to use models for larger classes and a best hit approach otherwise. In the following, we not only show how punting can be improved, but also introduce a variety of alternatives, including one that discards instance based learning altogether. Their subsequent evaluation leads to classification accuracies representing statistically highly significant improvements over any previous approach used for the same datasets so far. It should still be noted that although this article exclusively uses vor ol ign as an alignment algorithm and SCOP families as the prediction target, the proposed methods can be applied to basically any structural similarity measure and classification problems with small class sizes (e.g. protein function prediction, comparison of SCOP and CATH). vor ol ign was only chosen for its good performance and comparably low computational requirements,

conclusion in the context of structure based SCOP domain classification, we have presented a new practical approach to dealing with indefinite similarity measures, several new ways to integrate both model and instance based learning and showed that even the exclusive use of models is not only possible but also preferable to combinations with a best hit approach. Our results for the latter pose statistically highly significant increases in accuracy compared to any other method evaluated on the same data so far. Future work could further investigate the whole new class of transformations of possibly indefinite similarity measures into SVM compatible kernels. The generality of the methods also allows to largely extend their scope of application to e.g. protein function prediction. Furthermore, while we can not rule out the influence of bias arising from the redundancy reduction of the datasets, our results indicate that the performance of best hit on real world SCOP test data will substantially and unpredictably change if structural classes up to a certain size are excluded. Thus, even if models show better accuracy than best hit for a certain minimal class size, this might no longer be the case if this size or the dataset is changed. As schemes integrating best hit and models highly depend on the superiority of models over best hit for a given minimum class size, we argue that their performance in comparison to the exclusive use of best hit can only be evaluated by shifting this size and using multiple datasets.
