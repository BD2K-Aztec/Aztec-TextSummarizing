Motivation: rnase q co-expression analysis is in its infancy and reasonable practices remain poorly defined. We assessed a variety of rnase q expression data to determine factors affecting functional connectivity and topology in co-expression networks. Results: We examine rnase q co-expression data generated from 1970 rnase q samples using a guilt by association framework, in which genes are assessed for the tendency of co-expression to reflect shared function. Minimal experimental criteria to obtain performance on par with microarrays were 20 samples with read depth 10 M per sample. While the aggregate network constructed shows good performance (area under the receiver operator characteristic curve $0.71), the dependency on number of experiments used is nearly identical to that present in micro-arrays, suggesting thousands of samples are required to obtain gold standard co-expression. We find a major topological difference between rnase q and microarray co-expression in the form of low overlaps between hub like genes from each network due to changes in the correlation of expression noise within each technology.

introduction while rnase q offers major advantages over microarrays, including higher dynamic range and whole transcriptome assessment, it is not free of technical and biological biases. These include dependencies on library preparation, sequencing depth, gene lengths, GC content and transcript lengths, as well as other laboratory specific practices (). In the absence of careful experimental design, distinguishing gene expression variability due to technical artifacts and biological signal is challenging (). In addition, the downstream impact of biases in rnase q analysis will depend on the purpose to which it is being put. Our focus is on the development of appropriate standards and controls for rnase q co-expression analysis. Co-expression networks use the correlation (or related measures) of gene expression profiles across multiple samples to ascertain common regulation and thus common functions (). Co-expression network analysis in microarrays exists in broadly two discrete categories. In the first case, descended from the first coexpression analyses, there are studies which are highly targeted toward conditions of interest with networks derived from relatively small numbers of samples (dozens to the low hundreds) and often focusing on broad network changes in some condition of interest (). With increasing data, meta analysis across many datasets became more common, with samples numbering in the many hundreds or thousands (). Typically, the quality of co-expression networks is measured using some variant of the guilt by association (GBA) principle (). GBA states that genes with similar functional properties will tend to interact or exhibit similar profiles in network data, such as co-expression. Even gold standard expression datasets perform relatively poorly under gba when assessed in benchmarking exercises (e.g. the mouse func competition for genome wide gene function prediction pena. However, meta analysis across many datasets often improves performance dramatically (). Very few analyses to date have been performed on co-expression networks from rnase q data (although see, e.g.), with fewer conclusions drawn about their utility, nor has their presumed novelty been fully assessed. In the following, we attempt to provide a better understanding of appropriate standards for rnase q co-expression analysis. Methodologically, we begin with estimating expression from raw data, move to constructing individual networks, examining aggregate properties and then finally consider a variety of machine learning methods applied to the network. At each stage, we are concerned with what factors drive variation in constructed coexpression networks. First, we are concerned with the functional connectivity in the networks, which we measure as a GBA function prediction task, using the cross validation results to assess performance. Second, we wish to assess network features which may be important but not map to previously characterized function, and for this we focus on node degree. Node degree is central to network topology and a major factor in numerous other properties (). At each stage of our analysis, we define methods that yield reasonable results for the downstream method. Our intent is not to re characterize e.g. normalization methods in rnase q data, nor to claim that we have identified an ideal means for future rnase q coexpression analysis. Rather, we attempt to define a habitable zone of methods which may be reasonably used without introducing major artifacts and which will allow the field to progress as individual researchers interpret their own data or conduct meta analyses. We observe a particularly strong role for number of samples and aggregation (Sections 3.2 and 3.3) in GBA assessments while mapping and machine learning methods (Sections 3.1 and 3.4) affect primarily topology and not GBA. We explain the discrepancy by finding topologically important genes vary readily (Section 3.5), but primarily due to noise in the data (Section 3.6).

discussion the appropriate way to assemble and assess rnase q data is still a topic of considerable controversy. While it might seem that these methodological discussions would need to be resolved to put rnase q data to use in co-expression analysis, we suggest that is not so. Co-expression has frequently relied on the aggregation of diverse data and so many of the problems that affect rnase q as a pure measure of transcript omic activity may not have downstream importance in co-expression use. Our results give a perhaps surprisingly consistent message: simple, basic approaches were among the highest performing, from measuring network connectivity (Spearman correlation) to functional inference (neighbor voting). Similarly, a simple rank and sum mate aggregation across multiple datasets generates a more robust network, capturing known biology with high efficacy. In addition, we have demonstrated that individual rnase q networks exhibit a sample size dependency very similar to microarray data, suggesting that technical issues are not at the heart of the no is iness of co-expression data. Also important is the dependence on read depth in rnase q co-expression. Our study suggests that 1 M reads per sample (with many samples) is sufficient to build a network that is slightly divergent from random and adding such networks has no negative impact on the performance of the aggregate network. Thus, when aggregating data, it appears sensible to be extremely lenient in constructing inclusionary criteria. Recent suggestions for best rnase q practices in differential expression () highlight a power improvement in adding biological samples in a tradeoff with read depth. Users of co-expression data can not naively apply those recommendations because the minimum number of samples is already relatively high, and robustly measuring correlations may require an even greater increase. In co-expression analysis, increasing depth past 100 M aligned reads per sample and even thousands of samples continue to add value if our focus is on genome wide functional inference for a given dataset. So profound is the performance difference between aggregate and individual networks that it is difficult to recommend any minimum depth or sample count which is adequate; certainly none in our case come close to producing the same apparent performance. However, more 'focused' uses (e.g. studying changes in expression across brain development) may be permitted by more narrowly constructed datasets. While our analysis does not find evidence to support the view that such uses will be higher performing in any way, this may reflect our reliance on GO as a reference, even for narrowly defined functions. Since we have principally been concerned with measuring our network data in ways which generalize broadly, our use of the GO as a way of defining 'function' is perhaps the most easily critiqued, albeit hard to avoid and common. While it is very encouraging that many of the methodological variations in rnase q analysis do not negatively affect functional inference or render it less robust, it is natural to ask whether our measure of function is adequate. Since our results were virtually identical using KEGG and Reactome as references, we suggest our results are likely robust to most choice of reference data. Further to this, the machine learning algorithm selected has little influence on the results, which also implies that the features being selected to make predictions, determine connectivity and assess the networks are adequate for the task at hand. In addition, we think it is important to keep in mind that our evaluation of co-expression GBA is intended to be a proxy for comparative estimates of functional properties within the network in general. It would have been relatively easy for us to inflate our performance by incorporating a stronger prior based on semantic data or GO itself, for example. Instead we used methods that we think are strongly likely to generalize to novel tasks at some cost to absolute performance. Disease studies that use a co-expression network to derive interaction partners and likely disease gene candidates typically do so through measures such as node degree and modularity (for instance, see). Our interpretation of the topological shuffling we see between rnase q and microarray is not that they are robustly different (even though the significance is high), but rather that the measurements are easily influenced by weak biases (e.g. gene size). The question is whether the bias is specific to one technology, and if so, which one. Our analysis suggests that the reordering reflects the tendency for low expressing genes to be correlated in microarray data, but that rnase q allows us to identify which genes are 'too' low to be trusted with much greater specificity. Further, the low impact of variation in node degree on semi supervised learning (e.g. through GBA) suggests that even without the appropriate filtering, many methods adequately identify the absence of learnable features in noisy expression. Beyond simple read depth and sample size cut-offs, we suggest a few 'bright line' rules would likely advance network analysis. First, any single dataset analysis intended to present targeted biological results should provide comparative assessment on an aggregate network as a control. This would help disentangle data and methodological dependencies when presenting results. Second, the guidelines provided by seq c should be applied as a default for individual datasets to diminish noise and ensure stability. In meta analyses we suggest using an approximation of the seq c guidelines as a uniform filter; e.g. all transcripts with expression in the bottom third for 80% or more of the samples be removed from the experiment. Third, for smaller sample sized experimental data, more cautious statistical control can help better guard against artifacts; we particularly recommend the use of non-parametric statistics and resampling as baseline methods when an argument in favor of robustness can not rest on meta analysis. In summary, rnase q offers unique virtues but is not a technical panacea. Co-expression analyses will still require many samples and a reliable quality reference network as a control and comparative measure. Because of our reliance on pre-existing knowledge (GO) or data (microarray) to provide reference knowledge, we can not readily assess rnase q where its application is likely to prove most novel and exciting, e.g. novel or more diverse transcript assessment. Unsupervised interpretation of rnase q data connectivity is unlikely to be robust to underlying methodological choices without careful filtering, while methods that extract signals using training data (supervised or semi supervised methods) appear to safely recover known information. We make our networks available as a resource for other researchers at http://gillislab.labsites.cshl.edu/ supplements rnase q networks
