Motivation: In developmental biology, quantitative tools to extract features from fluorescence microscopy images are becoming essential to characterize organ morphogenesis at the cellular level. However, automated image analysis in this context is a challenging task, owing to perturbations induced by the acquisition process, especially in organisms where the tissue is dense and opaque. Results: We propose an automated framework for the segmentation of 3D microscopy images of highly cluttered environments such as developing tissues. The approach is based on a partial differential equation framework that jointly takes advantage of the nuclear and cellular membrane information to enable accurate extraction of nuclei and cells in dense tissues. This framework has been used to study the developing mouse heart, allowing the extraction of quantitative information such as the cell cycle duration; the method also provides qualitative information on cell division and cell polarity through the creation of 3D orientation maps that provide novel insight into tissue organization during organogenesis. Availability: The proposed framework is free, open source and available on the Icy platform (http://www.icy.bioimageanalysis.org/).

introduction the advent of modern 3D optical imaging techniques has impacted numerous areas of life sciences, giving novel insight into various aspects of cell behavior, notably during tissue development (). Typical images are obtained by labeling the cell membrane and nuclear DNA with fluorescent dyes, yielding two-channel image volumes where cells appear as a dense matrix of contiguous surfaces, while nuclei appear as pseudo elliptic blobs in close vicinity (cf.). However, in the context of dense tissues, 3D microscopy images of developing tissues still suffer from rather poor spatial resolution in the axial direction. Analysis is therefore still restricted to the upper section (typically 50 microns) of the specimen, beyond which substantial light scattering occurs in non-transparent tissues, thus hindering precise segmentation at the nuclear and cellular level. This is especially true in models such as the mouse (), where the tissue is much less transparent than that of zebrafish or Drosophila (). Alternative solutions have been proposed to improve the imaging process by combining complementary enhancements in the biology and the optics fields. For example, in, transgenic quail lines were generated, where only endothelial cells express a fluorescent marker, thus simplifying the quantification of multi-cellular movements in an embryo that is amenable to live imaging, but without real improvement of the resolution. A promising solution certainly lies in recent advanced imaging setups such as single plane illumination microscopy or SPIM (). There, only a thin sample plane is illuminated, while the light emitted by the entire plane is collected at once in the normal direction, thereby reducing exposure time, bleaching and toxicity. Such systems are, however, not or only recently commercially available, although open access prototypes are currently being developed (). It is also not clear whether SPIM images suffer from distortion resolution problems, due in particular to the registration and stitching of multi-view images (). In this context, and with the exponential increase in imaging datasets produced, digital image processing and analysis tools have become indispensible to make the most of 3D imaging techniques and data for biological applications. To quantify and then understand the mechanisms governing morphogenesis and organogenesis, quantitative measures such as cell cycle durations or cell orientations must be revisited if one wants to make full use of 3D stacks of the sample. Until recent years, extraction of cell parameters for the characterization of tissue growth has been limited to 2D () or multi 2d () analysis, or limited by the subjectivity and time constraints of manual intervention for 3D analysis (). Because 3D cell behavior is not stereotyped, analyses over a large number of 3D samples are required to extract relevant statistics. Hence, systematic analysis of developing tissues composed of several thousands of cells calls for robust and automated tools to *To whom correspondence should be addressed. y the authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors. segment cells, nuclei and other subcellular structures from 3D fluorescence images. A substantial amount of research in the image processing field is dedicated to the problem of multi-cellular segmentation in 3D. In particular, recent attempts have been reported to tackle the problem of dense tissue analysis in 3D. These contributions can be declined in two families: (1) image filtering approaches, aiming to remove the imaging artifacts by reducing the noise, smoothing heterogeneous structures and enhancing the contrast (; (2) segmentation techniques, aiming to extract nuclei or cells individually, either by means of the watershed transform () or via energy minimizing deformable models (). While watershed based approaches usually suffer from noise and over segmentation issues, deformable models offer a more flexible approach by allowing the incorporation of image and geometry based information into a robust mathematical framework based on Partial Differential Equations (PDE). for instance in (), the cell membrane signal is first de noised using a geodesic curvature filter (), then a generalized 3D Hough transform approach is used on the nuclear channel to estimate the location of the nuclei (), finally a subjective surface based technique is used to segment the cell membranes (). Such an approach yields promising results; however, it is restricted to the upper section of the specimen, illustrating the difficulty of processing deeper slices of the tissue, despite the transparency of the zebrafish as compared with the mouse. Also, the cellular and nuclear fluorescence signals are processed separately, which may impair the extraction performance. The present work introduces a new and alternative pde based framework to automatically de noise and jointly segment nuclei and cells from 3D images of dense and opaque tissues, and to extract quantitative measures including proliferation rates and cell orientations. We propose that combining the nuclear and cellular fluorescence information can significantly improve segmentation of both signals, even in highly non-transparent tissue such as that of mouse. We first use a filtering technique specifically designed to enhance the cellular membrane signal, and then subtract this signal from the nuclear signal to separate touching nuclei, thus improving their detection. Finally, we develop a two step deformable model approach to (i) segment the nuclei starting from their initial detection using local region homogeneity, and (ii) segment the cells starting from the extracted nuclei using dual region edge information from the filtered membrane signal. We use the proposed approach to study the development of the mouse heart and provide new quantitative parameters characterizing the morphogenetic process (e.g. number of cells and divisions, duration of the cell cycle), as well as 3D orientation maps to facilitate visual inspection and enable further statistical and geometrical analysis of the observed tissue. Quantitative and qualitative evaluations are provided, indicating a substantial gain in performance and analysis time compared with current approaches.

discussion while this work has been tailored for imaging data produced via standard confocal microscopy techniques, we believe the proposed approach is directly amenable to larger samples with future imaging systems, and will be of great value when studying tissues with complex geometry (). In the described workflow, the major source of segmentation error is the low intensity in deep tissue sections. One of the direct consequences is that the nucleus pre detection step is not always able to capture the nucleus as a whole (notably due to the heterogeneous labeling), therefore yielding more than one object per nucleus, and hence over segmentation. This problem is also described for watershed based processes, and solutions to reduce such artifacts using prior knowledge are currently in development (). On a similar note, we stress that the proposed workflow enforces a strong semantic relation between the segmentation of the nuclei and that of the cells, based on the assumption that cells are mono nucleated. While this assumption holds for the current development stage of the observed tissue, analysis at later stages of development with the appearance of multi-nucleated cells would require similar care to ensure that a single cell can be extracted from a subset of detected nuclei.

conclusion we have presented a comprehensive framework for automatic extraction of nuclei and cells from dense and highly cluttered environments in 3D microscopy of biological tissue. The proposed framework combines a number of robust pde derived approaches that jointly exploit nucleus and cell fluorescence information, and provides an efficient toolset for robust quantification of complex features. The approach was applied to study the developing mouse heart and was validated on three different applications, illustrating how developmental biology can benefit from computational approaches to facilitate the understanding of tissue development and morphogenesis.
