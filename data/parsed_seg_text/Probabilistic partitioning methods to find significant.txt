Motivation: We have witnessed an enormous increase in chips eq data for histone modifications in the past few years. Discovering significant patterns in these data is an important problem for understanding biological mechanisms. Results: We propose probabilistic partitioning methods to discover significant patterns in chips eq data. Our methods take into account signal magnitude, shape, strand orientation and shifts. We compare our methods with some current methods and demonstrate significant improvements, especially with sparse data. Besides pattern discovery and classification, probabilistic partitioning can serve other purposes in chips eq data analysis. Specifically, we exemplify its merits in the context of peak finding and partitioning of nucleosome positioning patterns in human promoters. Availability and implementation: The software and code are available in the supplementary material.

introduction chips eq (immunoprecipitation combined with high throughput DNA sequencing) experiments allow to characterize in vivo transcription factor binding events and local chromatin organization on a genome wide scale (). Within the past few years, chips eq has become a widely used and indispensable technology in the study of transcriptional regulation. Other epigenetic profiling assays are also starting to have a similar impact on the research field (). A chips eq experiment produces a large number of sequence tags that are mapped to the genome, resulting in a genome wide profile of tag counts. A high tag count at a location on the chromosome indicates the presence of a particular protein at that location. This protein may be a sequence specific transcription factor, a post translationally modified histone or some other chromatin associated protein. The regions enriched in chips eq tags are diverse in terms of magnitude, shape and orientation (). sequence specific transcription factors typically produce uniform narrow Gaussian peaks, while regions enriched in histone modifications tend to show complex multimodal signal distributions. The term 'chromatin signature' has been coined to designate recurrent patterns found in chips eq based histone modification maps and other types of chromatin profiling data (). A chromatin signature is usually represented by a vector of average tag counts in bins of certain sizes (typically 50500 bp) in a collection of larger genomic regions of sizes 110 kb. Chromatin signatures can be detected by so called aggregation plots (APs) (), if precisely mapped experimentally defined anchor points [e.g. transcription start sites tss s are available for selection and delineation of the genomic regions of interest. A basic assumption in chips eq data analysis is that specific chromatin signatures are associated with specific functions. For instance, human promoters are characterized by a nucleosome free region of $150 bp and a rigidly positioned h3k4me3 marked +1 nucleosome centered 120 bp downstream from the TSS (). Discovering a chromatin signature is difficult, especially when anchor points are not available. An effective algorithm must be capable to cope with the following obstacles. Biological inhomogeneity of the samples: The set of analyzed genomic regions often consists of multiple unknown subclasses, in which case, a plot derived from all samples shows the superposition of several different chromatin signatures alignment uncertainty: Precise anchor points are rarely available for delineating genomic regions. Selected chromatin regions first need to be optimally shifted (registered) with respect to each other before an AP can reveal a high resolution chromatin signature. Asymmetry: Chromatin signatures associated with directional molecular mechanisms (such as transcription) are usually asymmetrical. However, the orientation of the genomic regions is often unknown. The input count vectors should then be compared with each other in both orientations sparse count data: Certain bins may have very low tag counts, leading to high sampling errors. The problem of inhomogeneity can be tackled by off the shelf clustering and partitioning algorithms. In fact, hierarchical clustering and k means have been incorporated in several *To whom correspondence should be addressed. multipurpose computational platforms for chips eq data analysis. seq miner () offers an in built k means function, while chip seeker () is interfaced with a third party hierarchical clustering software. However, shifting and flipping are only implemented in specialized programs like chroma sig (), arch align (), catch profiles () and ca gt (). arch align performs only shifting and flipping and can find only one single signature. ca gt supports flipping but not shifting. (The problem of optimal shifting is typically solved by exhaustive comparison of all overlapping subregions of a given size from two genomic regions, possibly in both orientations.) chroma sig arch align and catch profiles use progressive multiple alignment strategies to assemble similar tag profiles. Because these algorithms have to carry out a large number of pairwise comparisons, they tend to be slow. To overcome this drawback, ca gt applies a two step divide and conquer approach. It first uses the k median algorithm (a variant of k means to define top level classes and then runs a hierarchical clustering algorithm on each of these classes in turn. The shifting and clustering functions require some type of distance measure. All of these programs, except chroma sig use non probabilistic measures such as the Euclidean distance or the Pearson correlation coefficient, neither of which does well with low counts per bin. chroma sig assesses similarity between samples and class membership assuming position specific Gaussian distributions of the normalized chips eq signal within a chromatin signature. The use of Gaussian distributions, which seems unnatural for count data, is explained by the fact that chroma sig was originally designed for chip chip data. In this article, we propose an alternative approach for finding recurrent patterns in chips eq data by probabilistic partitioning. The underlying principle of this general method is to optimize a mixture model by an expectation maximization (EM) algorithm, a strategy that has already proved effective in finding recurrent DNA motifs in selected genomic regions (). A key difference in this method compared with the other clustering methods mentioned is that samples are not deterministically assigned to a single class: rather, their classification status is defined by a vector of class membership probabilities. While EM has long been a standard tool in machine learning, it is a general purpose method, whose convergence rates and running times depend on the exact formulation of the objective function and the updating formulae. The purpose of this article is to demonstrate the merits of EM when applied to chips eq data and to explain by examples how it can be applied to classification and motif discovery problems in research on chromatin structures. The probabilistic partitioning approach offers the following advantages 1 The use of probabilistic distance functions naturally takes into account random sampling variation in low count data 2 Probabilistic class assignment allows accurate characterization of classes even in situations where the classification of individual samples is uncertain 3 Probabilistic class assignment is flexible and can combine goals, for instance, the ranking and prioritizing of chips eq signal enriched regions based on peak shape 4 Shifting and flipping can be implemented in the EM framework via hidden variables 5 The implementation of probabilistic partitioning is straightforward with existing programming platforms. All algorithms used in this work can be implemented by 530 lines of R code 6 Flexibility: Methods are readily customized to meet the needs of a particular application. For instance, the switching from a Poisson probabilistic model to a negative binomial model requires only one change in the corresponding R code 7 Efficiency: In contrast to most existing methods, the EM algorithm does not require exhaustive pairwise comparisons, so that each iteration runs in time linear in the number of samples 8 Transparency and Reproducibility: Methods can be accurately described in a research paper by reproducing a few lines of R code (for example, see the R code given in the Supplementary Material). Section 2 presents in detail several variants of the probabilistic partitioning algorithms. Section 3 analyses the performance of these algorithms on carefully chosen examples based on simulated and real chips eq data and compares its performance with k means clustering and ca gt
conclusion we presented a probabilistic partitioning method to find significant patterns in chips eq data. The corresponding algorithm runs in O(n) time given a fixed number of classes and EM iterations. It is capable of processing large datasets (tens of thousands of samples) in minutes. The method is conceptually simple yet flexible, and has been implemented in a few lines of R code. The basic partitioning algorithm is readily adjusted to handling flips and shifts following standard principles of EM. With low data coverage, the probabilistic partitioning method gives excellent model accuracy, superior to k means or ca gt when tested on the same data examples. We have further shown that probabilistic partitioning can serve other purposes than pattern discovery and classification, like partitioning of nucleosome positioning patterns in human promoters, and shape based evaluation and re-focusing of chips eq peaks from published peak lists.. shape based peak evaluation with shifting. The figure illustrates the effects of probabilistic partitioning on a CTCF peak list provided by ENCODE in terms of motif enrichment. (a) Probabilistic partitioning with shifting. (b) Partitioning based on original p values. Method details: CTCF binding motifs where identified by scanning the DNA sequence around peak centers with the JASPAR matrix MA0139.1 at a p value threshold of 10 5. The percentage of sequences containing a CTCF motif is plotted in a sliding window of 50 bp. The numbers in parentheses indicate the sizes of the peak lists. For fair comparison, the threshold for partitioning with the original p values was chosen such as to match the numbers of good and bad peak obtained with probabilistic partitioning. The motif enrichment profile for the complete peak list (dotted line) is included in both graphs
