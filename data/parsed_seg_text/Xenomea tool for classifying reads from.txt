Motivation: Shotgun sequence read data derived from xenograft material contains a mixture of reads arising from the host and reads arising from the graft. Classifying the read mixture to separate the two allows for more precise analysis to be performed.

introduction xenograft models are an important tool for many areas of biomedical research, including oncology, immunology and HIV pathology. A typical scenario, drawn from oncology research, is that of a human prostate cancer grown in an immunocompromised mouse model. Doing so allows researchers to investigate aspects of the cancer that are not necessarily preserved in cell lines, and it allows investigations into the interactions between the cancer and the surrounding stromal tissue. The mouse may be biopsied or harvested and samples of cancer and or stroma collected at various time points during an experiment. Difficulties arise, when sequencing the genome or transcriptome of the samples because host (mouse) material (i.e. dna rna will inevitably coming le with the graft (human) material. If a sufficiently careful section is taken, it has been generally assumed that the level of host contamination is low enough that it may be ignored. This may be a dangerous assumption, however, since the level of gene expression is non-uniform. If the overall level of host contamination in a graft sample is measured to be 10% overall, it may still be the case for a given gene that the host homologue accounts for most or all of the expression. Contamination may be minimized by physical or biochemical techniques such as conservative sectioning, cell sorting or laser capture micro-dissection, but these techniques can be a significant source of technical bias, or in some cases may require in feasibly large amounts of starting material. Further, in the case of transcript omic investigation, classifying host and graft in vitro may fail to adequately capture the interactions between them. An alternative strategy is to sequence an acknowledged mixture of host and graft, then use in silico methods to classify the individual sequence reads. This is the approach discussed here. We demonstrate a simple technique, based on an analysis of sequence * To whom correspondence should be addressed. reads using top hat and a more precise technique based on a km er decomposition of the host and graft reference sequences, xeno me. In both cases, the primary goal of the analysis is to classify reads into four classes: reads attributable to the host, reads attributable to the graft, reads which could be attributed to both and reads which are attributable to neither. To the best of our knowledge, there are no results in the literature examining the classification of high throughput sequencing short reads from xenograft models. The studies we know of are concerned with microarray expression profiles or alternative methods for estimating the amount of host material or cell types in the samples. For example investigate the use of species specific variation in gene length and a multiplex PCR to ascertain the relative amount of mouse and human dna use microarray gene profiling data and in silico techniques to estimate the quantity of various tissue components. In, there is an analysis of a mouse xenograft model using microarray data. They conclude that if there is more than 90% human DNA then the expression profiles are not unduly skewed. They also describe an experimental method for removing homologous genes based on cross hybridization analysis of the probes use short read sequencing to study a cancer genome and identify mutations deletions. They estimate tumour cellularity using pathological assessment, and state that their xenograft is 90% tumour cells. They also map nods cid (mouse) genomic data to human and mouse genomes, reporting 3.17% and 95.85% mapping rates, respectively, and so apply no correction for the murine cells. We note that in the context of non-uniform rnase q data ignoring the contribution of the murine expression can lead to biases. Tools such as top hat serve a different purpose than that of xeno me. The former aligns reads to a reference, and we can use those alignments for a variety of purposes, including the classification task we present here. In contrast, xeno me only performs the classification task itself. This is an important distinction, since an alignment must assign the read to zero or more positions in the genome; the classification merely has to decide if the read was more likely to arise from the genome than not. For the remainder of the article, we will assume, unless otherwise stated, that sequence reads arise from rnase q. However, the techniques we present are applicable to genomic DNA sequences (including chips eq and me dip seq and also to other mixtures of DNA species.

discussion we have presented a simple read classification method based on top hat and our refined classification approach, xeno me. xeno me can be used to efficiently and effectively partition the read set for subsequent processing by tools such as top hat. What is not apparent from the results above is the relative behaviour at the level of a single gene. It should be expected that the distribution of ambiguously mapped reads (classed as both) should be non-uniform, since some genes in the two genomes are more highly conserved than others the first result we present in on this point is an in silico analysis showing the proportion of each human gene (ignoring introns) covered by km ers that are not classed as human. It is clear that the vast majority of genes contain few or no km ers that are not classed as human. The fraction of km ers which are ambiguous gives a worst case view of how xeno me might be expected to perform. In order for a read to be classified as both, all of its km ers must be of the both class, or there must be at least one km er from each of the two genomes (which happens less than 2% of the time in the samples we have tried). Conversely, a single host or graft km er is sufficient to classify the read into the respective class. Therefore for a read to be classified as both, the reference must contain a sufficiently long run of consecutive km ers of class both and or SNPs and sequencing errors must eliminate all the distinctively host or graft km ers. The second result we report on this point, presented in is the relative proportion of reads which are classified as both on a per gene basis. What is evident in this figure is that although there are many genes for which the proportion of both reads is tightly correlated between top hat and xeno me there are a large number of genes for which the top hat based analysis has significantly more both reads. There are 15 591 genes for which there were at least 20 mapped reads in the BM18 xenograft sample. Of these, there were 65 for which xeno me assigned both or ambiguous to at least half the reads mapping to the gene; there were 498 for which the top hat based analysis assigned both to at least half the reads mapped to the gene. For the most highly conserved genes, there is not much that can be done with this data directly further signal processing or other data would be required to determine the relative expression in the host and graft. While we have developed xeno me with rnase q on human/ mouse xenografts in mind, we anticipate it will be an effective tool for other similar mixtures. For example, capturing the differential methylation around genes between host and graft using me dip seq may shed light on the in terr action between the two.. A plot showing the distribution of human genes with respect to the proportion of xenograft reads which are classed as both by the top hat based analysis and the xeno me analysis. The reads considered are only those mapped by top hat since xeno me does not yield mappings, so can not be used to assign reads to genes. Only genes for which at least 20 reads mapped were considered. The horizontal axis corresponds to the number of reads classified as both or ambiguous by xeno me as a proportion of all the reads that might possibly be human (i.e. both, ambiguous or human). The vertical axis corresponds to the number of reads classified as both by the top hat based analysis, once again, as a proportion of all the reads that might possibly be human
