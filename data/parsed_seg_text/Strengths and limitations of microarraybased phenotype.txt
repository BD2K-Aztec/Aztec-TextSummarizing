Motivation: After more than a decade since microarrays were used to predict phenotype of biological samples, real life applications for disease screening and identification of patients who would best benefit from treatment are still emerging. The interest of the scientific community in identifying best approaches to develop such prediction models was reaffirmed in a competition style international collaboration called IMPROVER Diagnostic Signature Challenge whose results we describe herein. Results: fifty four teams used public data to develop prediction models in four disease areas including multiple sclerosis, lung cancer, psoriasis and chronic obstructive pulmonary disease, and made predictions on blinded new data that we generated. Teams were scored using three metrics that captured various aspects of the quality of predictions, and best performers were awarded. This article presents the challenge results and introduces to the community the approaches of the best overall three performers, as well as an R package that implements the approach of the best overall team. The analyses of model performance data submitted in the challenge as well as additional simulations that we have performed revealed that (i) the quality of predictions depends more on the disease endpoint than on the particular approaches used in the challenge; (ii) the most important modeling factor (e.g. data preprocessing, feature selection and classifier type) is problem dependent; and (iii) for optimal results datasets and methods have to be carefully matched. Biomedical factors such as the disease severity and confidence in diagnostic were found to be associated with the misclassification rates across the different teams. Availability: The lung cancer dataset is available from Gene Expression Omnibus (accession, GSE43580). The ma predict dsc R package implementing the approach of the best overall team is available at www. bioconductor org or http://bioinformaticsprb.

introduction microarrays were introduced in life science research as a practical means to measure whole genome expression levels (). Typical experiments involving microarray technologies were designed to gain biological insights into various conditions but also to discover new, and predict predefined, disease phenotypes. For instance, breast tumors were classified based on their molecular profiles more than a decade ago (), and progress has been steady and promising; yet, practical applications of microarrays in patient care are only emerging. A recent comparison of three microarray based classifiers for breast cancer subtyping, BluePrint, mamma print and target print concluded that multigene assays were more reliable than clinicopathological criteria alone for the clinical management of breast cancer patients (). Pharmacogenetic (PGx) testing is an essential part of personalized medicine, which aims to predict an individual's risk for adverse drug response or treatment outcome. recently reviewed how PGx tests are accepted in the US in terms of coverage by the largest health insurance companies. Although there is no US Food and Drug Administration fda approved test available for on co type dx [a 21-gene assay that can predict 10 year distant breast cancer recurrence (, it is covered by most major health insurances. all omap gene test that can assess the risk of cardiac allograft rejection following a heart transplant (, similarly lacks FDA approval, but it is considered beneficial by a number of health insurances. In contrast, although the mamma print test *To whom correspondence should be addressed 70gene profile for prognostic and predictive tumor analysis (is approved by FDA, it has rather limited insurance coverage. Apparently, FDA approval is neither a prerequisite nor sufficient for the acceptance of a given test; rather, independent review by insurance companies and confidence by the clinicians (and patients) may be the main factors that influence the uptake of a new PGx test. We postulate that better and more standard methods to verify diagnostic PGx tests would facilitate acceptance by regulatory agencies and healthcare providers and hasten deployment to the public. Recently, the Industrial Methodology for PROcess VErification in Research (IMPROVER) was designed as a methodology to validate industrial research processes related to systems biology (). As a first initiative of the IMPROVER project, the Diagnostic Signature Challenge (DSC) () was designed to determine to what extent transcript omic data can be used for phenotype prediction and to test which computational approach works best for this end. Participants in the challenge were asked to produce a prediction model (classifier) that can infer the phenotype of biological samples from gene expression data for five different endpoints. The teams were ranked based on the prediction performance on test datasets generated by the organizers (for details see the Methods section). The purpose of this article is threefold: one, to describe the IMPROVER DSC results including classification performance on each endpoint, scoring methodology and overall ranking of the teams as well as ranking stability with respect to the composition of the test datasets; two, to introduce the methods of the top three overall performers and discuss the performance of an ensemble classifier that aggregates the predictions from best models submitted in the challenge; and three, to identify some of the sources of variability in the classification performance, including biomedical factors, and point toward the best alternatives at each step in the classification pipeline. Performance data from the models submitted to the IMPROVER DSC and from post challenge computational studies are used to support our findings. We conclude this article with a summary of the main observations and discuss their relevance.
