Motivation: genome wide haplotype reconstruction from sequence data, or haplotype assembly, is at the center of major challenges in molecular biology and life sciences. For complex eukaryotic organisms like humans, the genome is vast and the population samples are growing so rapidly that algorithms processing high throughput sequencing data must scale favorably in terms of both accuracy and computational efficiency. Furthermore, current models and methodol-ogies for haplotype assembly (i) do not consider individuals sharing haplotypes jointly, which reduces the size and accuracy of assembled haplotypes, and (ii) are unable to model genomes having more than two sets of homologous chromosomes (polyploidy). Polyploid organisms are increasingly becoming the target of many research groups interested in the genomics of disease, phylogenetics, botany and evolution but there is an absence of theory and methods for polyploid haplotype reconstruction. Results: In this work, we present a number of results, extensions and generalizations of compass graphs and our hap compass framework. We prove the theoretical complexity of two haplotype assembly optimizations , thereby motivating the use of heuristics. Furthermore, we present graph theory based algorithms for the problem of haplotype assembly using our previously developed hap compass framework for (i) novel implementations of haplotype assembly optimizations (min-imum error correction), (ii) assembly of a pair of individuals sharing a haplotype tract identical by descent and (iii) assembly of polyploid genomes. We evaluate our methods on 1000 Genomes Project, Pacific Biosciences and simulated sequence data.

introduction the genome sequence of a human individual can be modeled as 23 pairs of sequences of four nucleotide bases, A, C, G and T, representing the 22 pairs of autosomes and the sex chromosomes. However, $99.5% of any two individuals' genome sequences is shared within a population. The $0.5% of the nucleotide bases varying within a population range from single nucleotide polymorphisms (SNPs) to more complex structural changes, for example, deletions or insertions of genomic material. A sequence of genomic variants, typically SNPs, with the non varying DNA removed is referred to as a haplotype standard genome sequencing workflows produce contiguous DNA segments of an unknown chromosomal origin. De novo assemblies for genomes with two sets of chromosomes (diploid) or more (polyploid) produce consensus sequences in which the relative haplotype phase between variants is undetermined. The set of sequencing reads can be mapped to the phase ambiguous reference genome and the diploid chromosome origin can be determined but, without knowledge of the haplotype sequences, reads can not be mapped to the particular haploid chromosome sequence. As a result, reference based genome assembly algorithms also produce un phased assemblies. However, sequence reads are derived from a single haploid fragment and thus provide valuable phase information when they contain two or more variants. The haplotype assembly problem aims to compute the haplotype sequences for each chromosome given a set of aligned sequence reads to the genome and variant information. The haplotype phase of variants is inferred from assembling overlapping sequence reads [; hall do rss on. The input to the haplotype assembly problem is a matrix M whose rows correspond to aligned read fragments and columns correspond to SNPs (). The quality of M's construction depends on the parameters of the sequencing workflow and the accuracy of the read alignment algorithms. Misaligned read fragments can introduce erroneous base calls or sampling biases so the careful alignment of sequence reads is necessary for high quality haplotype assemblies. Without read alignment or sequencing errors, the haplotype assembly problem can be solved in time linear in the size of M by partitioning the fragments in two sets whereby no fragments internal to a set share an SNP and differ in the allele called. To address erroneous base calls or misplaced alignments, three primary haplotype assembly optimizations have been developed: minimum error correction (MEC), minimum SNP removal (MSR) and minimum fragment removal (MFR). The goal is to convert M into a state such that the fragments (rows of M) can be distributed into two sets corresponding to the two haplotypes. All fragments in a set must agree on the allele at each SNP site and this is accomplished using the minimum number of SNP allele flips (0 to 1 or vice versa mec SNP (columns of M) removals (MSR) or fragment (rows of M) removals mfr provide a theoretical foundation for the MFR and MSR optimizations and describe the fundamental SNP and fragment conflict graph structures. The first widely available haplotype assembly software package was presented in in which the authors describe the Fast Hare algorithm, which optimizes the 'Min Element Removal' problem., which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals permission soup com a set of likely haplotypes under the MEC optimization. In a follow-up, the authors present a much faster algorithm on a related graph model that relates maximum cuts to SNP allele flips (in the MEC model) [. Still other authors have suggested reductions to the well known maximum satisfiability problem the Levy et al. (2007) algorithm is a well known heuristic that was used to haplotype assemble the hu ref genome; it assigns fragments to haplotypes in a greedy fashion and iteratively refines the solution by comparing the set of fragments to the assembled haplotypes using majority rule phasing s. In a recent survey, Geraci (2010) describes the algorithm as, arguably, the best performing algorithm tested. The first extension of the haplotype assembly problem that addressed the simultaneous assembly of multiple diploid chromosomes was presented in; however, the benefits of multi haplotype assembly are not clear for a set of unrelated individuals continued development of this theory by describing methods for assembling individuals who share a haplotype identical by descent (IBD) using relationships among the reads. Aguiar and is trail (2012) introduced a new graph data structure, algorithmic framework and the minimum weighted edge removal m wer optimization, which together have several advantages over existing methods. Recall that the rows of M correspond to sequence read fragments with the non polymorphic bases removed such that only SNPs remain. The hap compass model defined in is composed of the compass graph G C core data structure, which summarizes the rows of M using edges weights and the m wer optimization that aims to remove a minimum weighted set of edges from G C such that a unique phasing may be constructed. The algorithm operates on the spanning tree cycle basis of G C to iteratively remove errors that are manifested through a particular type of simple cycle; Mac. In this work, we prove a number of theoretical results for the previously described m wer optimization on compass graphs. The main result proves m wer is np hard and motivates the use of our heuristic algorithms. Further, we demonstrate how extensions to the generalized diploid hap compass model can enable (i) usage of different optimizations, for example, MEC and m wer to be used in the local optimization step, (ii) simultaneous assembly of two individuals sharing a haplotype tract IBD and (iii) haplotype assembly of a single polyploid organism. Finally, we evaluate our methods on 1000 Genomes Project, Pacific Biosciences and simulated data.

discussion diploid haplotype inference is still a difficult task, in part due to the exponentially many solutions given the input genotype or sequence reads. hap compass is a proven framework for haplotype assembly but there are a number of extensions that may improve results. For instance, we did not mention the usage of base call or read mapping quality scores in our computations. hap compass can filter based on user defined thresholds but a more elegant solution would be to convert the base call quality score for a particular allele call into a probability the base was called correctly. This probability can then define the contribution of weight to the edges of G C rather than the current weight contribution of 1 for each SNP allele called. Also we demonstrated in the Pacific Biosciences experiments that the choice of assembly method should be informed by the sequencing technology and desired result. The Levy et al. (2007) method mapped more fragments error free than hap compass but contained many more single base changes in fragments required to reproduce the inferred haplotypes. Considering the Pacific Biosciences data has high error rates and generating an error free read is unlikely, a solution with the minimum number of corrected errors is likely preferred over a solution that successfully maps more fragments without errors. The size of the haplotype blocks produced and, ultimately, the quality of the assembled haplotypes is a function of several factors. The primary difficulty for obtaining large haplotype blocks is the small nature and lack of diversity of insert lengths. We demonstrated a novel modeling and computational method that begins to address this difficulty by exploiting shared IBD haplotype structure. In general, assembling the haplotypes of related individuals has considerable benefits, which help overcome undesirable properties of the sequencing data. The first benefit comes from the extra coverage on the shared haplotype, which helps in differentiating actual phasing s from sequencing errors. However, the most notable advantage is being able to include more SNPs into the haplotype assembly, which helps extend the assembly (past regions of low read coverage for example). But, the major advances in block sizes will likely be the result of novel experimental procedures and technologies; for instance, not only do the single molecule sequencers promise larger read lengths, they also enable the inclusion of multiple and large insert lengths. Organisms having more than two sets of homologous chromosomes are becoming the target of many research groups interested in studying the genomics of disease, phylogenetics and evolution;. Polyploidy occurs in human disease usually due to the duplication of a particular chromosome, for example, in Edwards, pat au and Down syndrome. While far fewer mammalian organisms are polyploid, specific mammalian cells may undergo polyploid ization for example, in human liver hepatocytes. In addition, polyploid organisms are ubiquitous in the Plant and Fungi clades, present in crops that we ingest, convert into bioenergy and feed to livestock. Understanding the genomics of both the desirable eg. increased crop yield and undesirable eg. susceptibility to disease properties of plants may lead to critical advances in many research areas but requires untangling the polyploid genome and its variation. As more polyploid data becomes available, our approach may be used to infer haplotypes and begin to understand what effects haplotype variation may influence.
