Currently, the Gene Expression Omnibus (GEO) contains public data of over 1 million samples from more than 40 000 microarray based functional genomics experiments. This provides a rich source of information for novel biological discoveries. However, unlocking this potential often requires retrieving and storing a large number of expression profiles from a wide range of different studies and platforms. The compendium db R package provides an environment for down-loading functional genomics data from GEO, parsing the information into a local or remote database and interacting with the database using dedicated R functions, thus enabling seamless integration with other tools available in r bioconductor. Availability and Implementation: The compendium db package is written in R, MySQL and Perl. Source code and binaries are available from CRAN (http://cran.r-project.org/web/packages/compen dium db for all major platforms (Linux, MS Windows and OS X) under the GPLv3 license.

introduction public repositories such as the Gene Expression Omnibus (GEO) () and array express () provide a large amount of functional genomics data from a wide range of studies performed in different organisms and on different (microarray) platforms. However, retrieving and systematically storing these datasets to extract novel biological information is often challenging. Several tools and web based resources have been developed (expression data, sample and probe annotation to the relational database and (iii) convert experimental data from the database to an r bioconductor expression set
description the compendium db package has been developed around a MySQL database designed for storing data from GEO. The database schema is provided with compendium db and is described in detail at http:// wiki bioinformatics laboratory nl fos wiki bin view biolab compen dium db. After creating an empty database, one connects to it and loads the database schema: conn connect database (user " user " , password " passwd " , dbname " compendium " ) load database schema conn update schema  true by default, this establishes a connection to a database running on a local machine but using the argument host of connect database one can also connect to a database on a remote server. This way the database can be conveniently deployed in a multi-user environment. Functional genomics datasets in the form of Simple Omnibus Format in Text (SOFT) files can be downloaded from GEO by specifying the GEO series record (GSE) identifier. The downloaded preprocessed expression data, sample and probe annotation can then be loaded into the database: download geodata gse id " GSE18290 " ) load data to compendium conn gse id " GSE18290 " ) Probe annotation is automatically retrieved from GEO platform records (GPL) and updated to the most recent annotation for those platforms listed on http://ftp://ftp.ncbi.nlm.nih.gov/pub/geo/DATA/ annotation/. Sample annotation is retrieved from the information provided in each GEO sample record (GSM). For those experiments that have been curated by GEO staff into a GEO dataset (GDS), the sample annotation is retrieved automatically from the GDS. Sample annotation as stored in the compendium database can be further curated and updated using the function update pheno data. Experimental data stored in the database can be extracted as an r bioconductor expression set enabling straightforward integration with other tools available in r bioconductor e sets create e set conn " GSE18290 " )The function create e set conveniently parses the metadata provided for each sample into separate columns for each of the variables and stores them in the pheno data slot of the expression set facilitating down-stream analysis. Using these functions, downloading 39 GSEs from GEO and loading the corresponding 7970 samples in the compendium database took 5.5 h on a single core of a Linux (Red Hat 4.4.7-9, 64-bit) server containing 10 intel r xeon r CPU E52690 v2 @ 3.00GHz processors having 64 GB of random access memory. Subsequent extraction as expression sets took 0.3 h. For each GSE, a detailed breakdown of the time to download, load and extract data is given in Supplementary File S1. Next to the main functions described earlier, one can also tag experiments using keywords tag experiment enabling easy extraction of a set of related experiments from the database, and extract a succinct overview of the experiments contained in the database gse in db. Note that while the package conveniently shields the user from having to write SQL queries, the database can also be queried directly to extract information that is not easily accessible via the functions provided with the package. Further information on how to install compendium db other functionalities and more detailed examples are provided in the package vignette (Supplementary File S2).
