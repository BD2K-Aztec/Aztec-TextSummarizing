Background: The statistical power or multiple Type II error rate in large scale multiple testing problems as, for example, in gene expression microarray experiments, depends on typically unknown parameters and is therefore difficult to assess a priori. However, it has been suggested to estimate the multiple Type II error rate post hoc, based on the observed data. Methods: We consider a class of post hoc estimators that are functions of the estimated proportion of true null hypotheses among all hypotheses. Numerous estimators for this proportion have been proposed and we investigate the statistical properties of the derived multiple Type II error rate estimators in an extensive simulation study. Results: The performance of the estimators in terms of the mean squared error depends sensitively on the distributional scenario. Estimators based on empirical distributions of the null hypotheses are superior in the presence of strongly correlated test statistics. Availability: r code to compute all considered estimators based on p values and supplementary material is available on the authors web page

introduction in genomic and proteomic research thousands of hypotheses are tested simultaneously. Numerous procedures have been proposed to control multiple Type I error rates, e.g. the false discovery rate (FDR) or the family wise error rate. The multiple Type II error rate or the statistical power, in contrast, have received less attention so far. The power of a multiple testing procedure can be defined in several ways (). For example, one can consider the probability to reject at least one alternative hypothesis or the probability to reject all alternative hypotheses. We consider an intermediate approach, the average power, defined as the arithmetic mean of the elementary power values of all alternative hypotheses. The average power can be interpreted as the expectation of the proportion of rejected alternative hypotheses among all alternative hypotheses and corresponds to the so called false negative * To whom correspondence should be addressed. rate (FNR) (e.g.). The FNR is defined as the expectation of the false negative proportion (FNP), the proportion of retained true alternative hypotheses among all true alternative hypotheses and is related to the average power by Average Power = 1FNR. The FNR depends on a number of parameters as the sample size, the effect sizes and the proportion of true null hypotheses among all hypotheses. Therefore, the FNR of an experiment is unknown a priori and can only be guessed based on preliminary assumptions. However, if data have already been observed, the FNR can be estimated based on the observed test statistics. This concept of 'post hoc power analysis' has been criticized for the case of a single hypothesis test (e.g.), where the post hoc power is just a 1:1 function of a single p value. However, in experiments with a large number of hypotheses one can utilize the empirical distribution of the test statistics to estimate the FNR. Under suitable assumptions (e.g. if the elementary test statistics are sufficiently independent), the FNR is asymptotically equivalent to the FNP such that an estimator for the FNR can also be used to estimate the FNP. An essential element in the estimation of the FNR is the estimation of the proportion of true null hypotheses among all null hypotheses, denoted by  0. Numerous estimators for  0 have been proposed in the literature and we assess their performance in the estimation of the FNR. The FNR is a measure for the fraction of undetected alternative hypotheses and is therefore a crucial parameter to interpret negative findings in experiments where a large number of hypotheses is investigated. In addition, in large scale multiple testing problems, FNR estimates can be used to define stopping rules for sequential testing. For example, one could continue sampling until the estimated FNR falls below a prespecified threshold. As shown in under suitable assumptions such sequential testing asymptotically does not inflate the FDR if the sample size is increased for all hypotheses simultaneously and only the test at the final interim analysis determines which hypotheses are rejected. The nomenclature for the FNR is not consistent in literature: we label the expected proportion of retained true alternatives under all alternatives 'FNR' according to and Norris and Kahn 2006 label this quantity 'fraction of genes not selected', cr aiu and Sun (2008) non discovery rate. Additionally, the term FNR has also been used to denote the proportion of false negatives among all retained hypotheses (), a quantity that has also been labeled, e.g. 'false non discovery rate fn dr (). In Section 2.1, we introduce a family of estimators of the FNR that depend on the data only through the number of
