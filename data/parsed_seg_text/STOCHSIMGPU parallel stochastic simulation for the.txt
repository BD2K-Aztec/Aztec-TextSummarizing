Motivation: The importance of stochasticity in biological systems is becoming increasingly recognized and the computational cost of biologically realistic stochastic simulations urgently requires development of efficient software. We present a new software tool stoch sim gpu that exploits graphics processing units (GPUs) for parallel stochastic simulations of biological chemical reaction systems and show that significant gains in efficiency can be made. It is integrated into MATLAB and works with the Systems Biology Toolbox 2 (SBTOOLBOX2) for MATLAB. Results: The gpu based parallel implementation of the Gillespie stochastic simulation algorithm (SSA), the logarithmic direct method (LDM) and the next reaction method (NRM) is approximately 85 times faster than the sequential implementation of the NRM on a central processing unit (CPU). Using our software does not require any changes to the users models, since it acts as a direct replacement of the stochastic simulation software of the SBTOOLBOX2. Availability: The software is open source under the GPL v3 and available at http://www.maths.ox.ac.uk/cmb/STOCHSIMGPU. The web site also contains supplementary information.

introduction decision making in biological systems may depend on single molecular reaction events making it necessary to develop, and carefully investigate, stochastic simulations of such events. A classic example is the pathway bifurcation in -phage infected in Escherichia coli cells (). Three exact stochastic simulation algorithms of chemical reaction systems are commonly used in Systems Biology: (i) the stochastic simulation algorithm (SSA) of; the efficient and exact reformulations (ii) the next reaction method (NRM) of and (iii) the logarithmic direct method (LDM) of Li and Petzold (2006). To accurately approximate the statistical distribution of the molecular populations at any given point in time, large ensembles of realizations are needed empha z ising the need for efficient * To whom correspondence should be addressed. computation. Unlike existing efficient simulation tools like, we use NVIDIA CUDA to transform GPUs of modern PCs into massively parallel co-processors. CUDA is supported by many of nvidia s current GPUs and is available in many off the shelf computers. 1 We present an implementation of these algorithms which computes ensembles of many realizations 85 times faster on a GPU than on a CPU assuming no specialized knowledge about GPUs by the user.
