Motivation: Mixtures of factor analyzers enable model based clustering to be undertaken for high dimensional microarray data, where the number of observations n is small relative to the number of genes p. Moreover, when the number of clusters is not small, for example, where there are several different types of cancer, there may be the need to reduce further the number of parameters in the specification of the component covariance matrices. A further reduction can be achieved by using mixtures of factor analyzers with common component factor loadings (MCFA), which is a more parsimonious model. However, this approach is sensitive to both non normality and outliers, which are commonly observed in microarray experiments. This sensitivity of the MCFA approach is due to its being based on a mixture model in which the multivariate normal family of distributions is assumed for the component error and factor distributions. Results: An extension to mixtures of t factor analyzers with common component factor loadings is considered, whereby the multivariate t family is adopted for the component error and factor distributions. An EM algorithm is developed for the fitting of mixtures of common t factor analyzers. The model can handle data with tails longer than that of the normal distribution, is robust against outliers and allows the data to be displayed in low dimensional plots. It is applied here to both synthetic data and some microarray gene expression data for clustering and shows its better performance over several existing methods. Availability: The algorithms were implemented in Matlab. The Matlab code is available at http://blog.naver.com/aggie100.

introduction model based methods have been widely used for both clustering and classifying high dimensional microarray data ().compared various clustering techniques and showed that model based method performed well for microarray gene clustering. * To whom correspondence should be addressed the finite normal mixture model with unrestricted component covariance matrices is a highly parameterized model (). Banfield and introduced a parameterization of the component covariance matrix based on a variant of the standard spectral decomposition, and its program mc lust () has been often used. But if the number of genes p is large relative to the sample size n, it may not be possible to use this decomposition to infer an appropriate model for the component covariance matrices. Even if it were possible, the results may not be reliable due to potential problems with near singular estimates of the component covariance matrices when p is large relative to n. In this case, mixtures of factor analyzers (MFA) is a useful model to reduce the number of parameters by allowing factor analytic representation of the component covariance matrices proposed the MFA adopting a finite mixture of factor analysis models, which was considered for the purposes of clustering by) and).) applied MFA to tissue samples with microarray gene expression data for clustering used MFA to classify microarray data successfully. recently proposed a penalized MFA to allow both selection of effective genes and clustering of high dimensional data simultaneously has proposed another penalized model based clustering method with unconstrained covariance matrices. In practice, for example, where there are several different types of cancer, there is often the need to reduce further the number of parameters in the specification of the component covariance matrices by factor analytic representations introduced some parsimonious MFA models, which include various MFA models with fewer parameters proposed another parsimonious factor mixture model to allow both dimension reduction and variable selection. Baek and McLachlan (2008) and proposed the use of mixtures of factor analyzers with common component factor loadings (MCFA) and applied it to a microarray dataset for clustering. The method considerably reduces further the number of parameters, and allows the data to be displayed in low dimensional plots in a straightforward manner in contrast to MFA. Several analyses of many real datasets, however, have suggested that the empirical distribution of gene expression levels is approximately log-normal or sometimes with a slightly heavier tailed t distribution depending on the biological samples under investigation (). In particular applied the shapiro wilks test to Affymetrix microarray expression data and concluded that page 1270 12691276

discussion for clustering high dimensional data such as microarray gene expressions, MFA is a useful technique since it can reduce the number of parameters through its factor analytic representation of the component covariance matrices. However, this approach is not provide a sufficient reduction in the number of parameters, particularly when the number of clusters (subpopulations) is not small. In this article, we proposed a new mixture model which can reduce the number of parameters further in such instances and cluster the data containing outliers simultaneously by introducing a mixture of t distributions with both component mean and component covariance represented by common factor loadings. We call this approach mixtures of common t factor analyzers m ctfa. We describe the implementation of an EM algorithm for fitting the m ctfa. This approach also has the ability to portray the results of a clustering in low dimensional space. We can plot the estimated posterior means of the factors factors factors j as defined by(13) with the implied cluster labels. On the other hand, the approaches mc lust MFA and mtf a can not project high dimensional objects in low dimensional space. The applications of m ctfa to two cancer microarray datasets have demonstrated the usefulness and its relative superiority in clustering performance over mc lust MFA and MCFA. It has shown that our method works well for clustering data containing outliers. Moreover, it provides information on the distribution structure of each subpopulation by displaying the estimated factor scores in low dimensional space. We observed also that the proposed approach fitted the experimental datasets better than the other approaches, and the performance difference between m ctfa and the others becomes even greater when the number of clusters is not small, such as in the case of second dataset (Section 1.1 of Supplementary Material). Often BIC is used to provide a guide to the choice of the number of factors q and the number of components g to be used. However, it did not always lead to the correct choice of the best model. That is, BIC can lead to too simple or too complex model in practice, depending on the problem at hand. Simulation studies reported in and McLachlan and Peel (2000a) show that BIC will over rate the number of clusters under misspecification of the component density, whereas several alternative criteria such as the a we and ICL criterion are able to identify the correct number of clusters even when the component densities are misspecified frh wirth. In both of our real data applications, we observed that BIC did not choose the best q. An apparent explanation for this is that BIC tries to choose more complex model since some of the subpopulations of the datasets have skewed distributions and have several extreme outliers. On the other hand, a we leads to the best or almost the best model with smallest error rate since it is more robust against misspecification of the component densities for the experimental datasets. Recently, frh wirth sch natter and Pyne (2010) reported that a we picked the correct model for both skew t and skew normal mixture distributions. Also a small simulation study confirms the better performance of the a we over the BIC when the distribution of the data has skewed heavy tails due to some extreme observations (Section 1.2 of Supplementary Material). In future work, we wish to investigate the use of various model selection criteria on choosing the number of factors q and the number of components g in mixtures of t or skewed distributions.
