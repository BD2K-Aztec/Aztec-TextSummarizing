Motivation: Despite their success in identifying genes that affect complex disease or traits, current genome wide association studies gw ass based on a single SNP analysis are too simple to elucidate a comprehensive picture of the genetic architecture of phenotypes. A simultaneous analysis of a large number of SNPs, although statistically challenging, especially with a small number of samples, is crucial for genetic modeling. Method: We propose a two stage procedure for multi snp modeling and analysis in gw ass by first producing a preconditioned response variable using a supervised principle component analysis and then formulating Bayesian lasso to select a subset of significant SNPs. The Bayesian lasso is implemented with a hierarchical model, in which scale mixtures of normal are used as prior distributions for the genetic effects and exponential priors are considered for their variances, and then solved by using the Markov chain Monte Carlo (MCMC) algorithm. Our approach obviates the choice of the lasso parameter by imposing a diffuse hyper prior on it and estimating it along with other parameters and is particularly powerful for selecting the most relevant SNPs for gw ass where the number of predictors exceeds the number of observations. Results: The new approach was examined through a simulation study. By using the approach to analyze a real dataset from the Framingham Heart Study, we detected several significant genes that are associated with body mass index (BMI). Our findings support the previous results about bmi related SNPs and, meanwhile, gain new insights into the genetic control of this trait.

introduction recent genotyping technologies allow the fast and accurate collection of genotype data throughout the entire genome for many subjects. By genome wide association studies gw ass the genetic variants associated with a complex disease or trait, their chromosomal distribution and individual effects, can be identified. gw ass are based on either case control cohorts to test the * To whom correspondence should be addressed. associations between SNPs and diseases or population cohorts to estimate genetic effects of SNPs on traits. In both cases, there are hundreds of thousands of SNPs genotyped on samples involving thousands of subjects. This typical problem, having the number of predictors far exceeding the number of observations, makes it impossible to analyze the data using traditional multivariate regression. In current gw ass simple univariate linear regression that analyzes one SNP at a time is usually used and, by adjusting for multiple comparisons, the significance levels of the detected genes are then calculated (). These single snp based gw ass have been instrumental for reproducibly detecting significant s genes for various complex diseases or traits (). However, such strategies have three major disadvantages, limiting the future applications of g was. First, because most complex traits are polygenic, a single SNP analysis can only detect a very small portion of genetic variation and, also, may not be powerful for identifying weaker associations (). Second, different genes may interact with each other to form a complex network of genetic interactions, which can not be characterized from a single SNP analysis. Third, many gw ass analyze genetic associations separately for different environments, such as males and females, and then make an across environment comparison in genetic effects. This analysis is neither powerful nor precise for the identification of gene environment interactions. Because of these limitations, many authors have developed various approaches for simultaneously analyzing multiple SNPs for gw ass (), although most approaches focus on case control cohorts. There is a daunting need on the development of a variable selection model to identify SNPs with significant effects on quantitative traits in population cohorts and estimate all selected predictors simultaneously. Traditionally, a subset of predictors in a regression model is obtained by forward selection, backward elimination and stepwise selection, but these approaches are computationally expensive and unstable even when the number of predictors is not large. Recently, alternative approaches have been developed, including ridge regression, bridge regression (), least absolute shrinkage and selection operator (LASSO) (), elastic net () and the smoothly clipped absolute deviation (SCAD) penalty (). For the number of variables much larger than that of subjects, as commonly seen in gw ass proposed a two stage procedure for variable selection by first suppressing the high dimensionality of response into its low dimensional representation and then finding a subset of predictors that can predict the suppressed response. A similar two stage approach was also developed by page 517 516523

discussion when the number of predictors p is much larger than the number of observations n, highly regularized approaches, such as penalized regression models, are needed to identify non-zero coefficients, enhance model predictability and avoid over-fitting (). The L 1 penalized regression or lasso is such one of the most popular techniques. In this article, we presented a Bayesian hierarchical model with lasso penalties to simultaneously fit and estimate all possible genetic effects associated with all SNPs in a g was adjusting for both discrete and continuous covariates. Lasso penalties are imposed on the additive and dominant effects, and implemented by assigning double exponential priors to their regression coefficients. It shrinks small effects toward zero and produces sparse solutions. In this framework, SNPs with significant genetic effects can be identified more accurately. We fit the model in a fully Bayesian approach, employing the MCMC algorithm to generate posterior samples from the joint posterior distribution, which can be used to make various posterior inferences. Although computationally intensive, it is easy to implement and provides not only point estimates but also interval estimates of all parameters. The Bayesian lasso treats tuning parameters as unknown hyperparameters and generates their posterior samples when estimating other parameters. This technique avoids the choice of tuning parameters, and automatically accounts for the uncertainty in its selection that affects the estimation of the final model. In contrast, standard lasso algorithms usually select tuning parameters by k fold cross validation which involves partitioning the whole dataset and refitting the model many times. This process may result in unstable tuning parameter estimates. In order to improve the performance of lasso when p is greater than n, preconditioning is considered before variable selection. Preconditioning encourages the principal components of a reduced design matrix to be highly correlated with the response, and thus in most cases only the first or first few components tend to be useful for prediction. It de noises the response variable so that variable selection becomes more efficient. Our simulation demonstrated that when p greatly exceeds n, preconditioned Bayesian lasso could successfully identify almost all the SNPs with true genetic effects. By analyzing real data, our approach is shown to produce biologically relevant results. For example, the approach detected a significant SNP ss66171460 at position 22580931 of chromosome 20 associated with BMI. It is interesting to note that this SNP is within 500 kb of the FOXA2 (Forkhead Box A2) gene, an important genetic variant that regulates obesity (). One simulation example of implies that, in the context of gw ass SNPs that are marginally independent of the phenotype could be screened out by preconditioning, but can be identified by standard variable selection techniques such as lasso or Bayesian lasso. In theory, if SNPs are correlated with the phenotype through marginal correlations, we believe the preconditioning step is worthwhile to identify more important SNPs. However, in reality, since different SNPs may display interactions, this approach may not work perfectly. In any case, this two step variable selection procedure should always be advantageous over a single SNP analysis, because we are always testing the marginal correlation between the predictor and response when one SNP is analyzed at a time. Motivated by, Park and developed the Bayesian lasso and demonstrated the diabetes data () with p = 10 and n = 442. We applied the Bayesian lasso to the high dimensional regression problem, and improved it by preconditioning. We have concentrated on the preconditioned Bayesian lasso method for continuous trait in gw ass. The proposed preconditioning procedure and MCMC algorithm can be readily extended to survival data analysis and lasso penalized logistic regression in case control disease gene mapping. Also, we may look for gene gene interaction effects after identifying main effects, as suggested by. The model with a capacity to identify epistatic interactions will enables geneticists to decipher a detailed picture of the genetic architecture of a complex trait. Funding: nsf nih Mathematical Biology grant (No. 0540745); NIDA; NIH grants (R21 DA024260 and R21 DA024266). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIDA or the NIH.
