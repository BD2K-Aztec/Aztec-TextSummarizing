In any data quality workflow, data publishers must become aware of issues in their data so these can be corrected. User feedback mechanisms provide one avenue, while global assessments of datasets provide another. To date, there is no publicly available tool to allow both biodiversity data institutions sharing their data through the Global Biodiversity Information Facility network and its potential users to assess datasets as a whole. Contributing to bridge this gap both for publishers and users, we introduce BIoDiversity DataSets Assessment Tool, an online tool that enables selected diagnostic visualizations on the content of data publishers and or their individual collections. Availability and implementation: The online application is accessible at

introduction established in 2001 as an outcome of the OECD 'Mega Science Forum Working Group' with the aim of 'making the world's primary data on biodiversity freely and universally available via the Internet', the Global Biodiversity Information Facility (GBIF, http://www gbif org is currently considered to be the largest initiative in providing access to collections of biodiversity records (). It is defined as a network of biodiversity data institutions (data publishers) that own and manage digital collections of primary biodiversity data (PBD) () and make them publicly available on the Internet. Coordinated at the International Secretariat in Copenhagen, Denmark, GBIF acts as a worldwide proxy for PBD owned and shared by participant institutions. In order to optimize information query and retrieval and to serve as a common gateway to the data, GBIF builds a searchable index (http://www.gbif.org/informatics/ infrastructure indexing. The institutions that join the GBIF network remain the owners of their own records' intellectual property rights and host the authoritative version of the records. Therefore, GBIF does not modify the original data, it being the data publishers' responsibility for any data quality issue that might appear in their

application this application visualizes and assesses several aspects of the content of the data publishers, which are based on recent advances in data quality and fitness for use analyses as well as on previous work developed by the authors. The application is focused on assessing the status of the three aspects of the PBD: geospatial, temporal and taxonomic information, but some metadata issues are also addressed, such as the volume of the collection publisher or the distribution of types of record. The visualizations make it possible to detect patterns either 'good' (natural) or 'wrong' (artifactual) and issues, and in most cases the discovery of 'wrong' trends leads to unveiling methodological issues in the datasets. When processed by gbif s internal mechanisms, a data publisher's records pass through a standardization process and some information is codified for performance reasons. If the original data are not structured according to the standard schema, some inconsistencies might appear in the process, leading to interoperability issues. The content of a publisher is assessed as it is once the records have gone through these processes, thus detecting the final status of the records as available to end users. Although there are other tools to assess the quality of a set of data, the collection centric perspective of this tool allows for the effective detection of patterns that would not arise when records are checked one by one.

conclusion our online application tries to contribute to bridge biodiversity data quality researchers and data managers in the GBIF network, by allowing visual exploration of a data publisher's collection of records. Being a web based openly available application, everyone can access the assessments and, thus, anyone can contribute spotting issues to the improvement of the available biodiversity data quality. Our future roadmap points to the development of new quality assessments and the establishment of an effective communication channel with the data publishers themselves.
