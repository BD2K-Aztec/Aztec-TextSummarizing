Motivation: Implementation and development of statistical methods for high dimensional data often require high dimensional Monte Carlo simulations. Simulations are used to assess performance, evaluate robustness, and in some cases for implementation of algorithms. But simulation in high dimensions is often very complex, cumbersome and slow. As a result, performance evaluations are often limited, robustness minimally investigated and dissemination impeded by implementation challenges. This article presents a method for converting complex, slow high dimensional Monte Carlo simulations into simpler, faster lower dimensional simulations. Results: We implement the method by converting a previous Monte Carlo algorithm into this novel Monte Carlo, which we call a roh il Monte Carlo. a roh il Monte Carlo is shown to exactly or closely match pure Monte Carlo results in a number of examples. It is shown that computing time can be reduced by several orders of magnitude. The confidence bound method implemented using a roh il outperforms the pure Monte Carlo method. Finally, the utility of the method is shown by application to a number of real microarray datasets. Availability: The R computer program for forming confidence bounds is freely available for download at the URL http://dobbinke my web ugaedurprogramarohil lower accuracy bound txt
introduction this article presents a novel approach to Monte Carlo simulations in high dimensions. The approach permits routines to be written in simpler and faster code using mathematical modeling. The savings comes from reducing the computational dimension of the Monte Carlo simulation from very high dimension to a much lower dimensional space. As we will show, this computational savings makes it possible to provide R functions to perform statistical analyses that previously required a compiled language such as C++. Moreover, the R programs are significantly faster and more transparent (enhancing reproducibility) than the compiled programs, because the underlying models have been streamlined. We make * To whom correspondence should be addressed. available such a program with this publication. More generally, this approach, by providing a faster method for performing simulations, can enable method developers to consider the robustness of novel procedures across a wider range of simulation scenarios than would otherwise be feasible. Monte Carlo simulations are commonly encountered in papers on high dimensional methodologies. Perhaps the most common use of Monte Carlo simulations is to evaluate the performance characteristics of novel statistical procedures, such as the performance of classifiers based on partial least squares (), regularization methods for variable selection () or evaluation of multiple hypothesis testing error control methods (). The advantages of Monte Carlo investigations are that the truth can be known exactly, and model assumptions can be violated in systematic ways to explore the limits of robustness. Some other methodologies also use Monte Carlo simulations as part of their algorithms. This new simulation procedure is called Adequate Representation Of High dimensions In Low dimensions a roh il Monte Carlo. There are two types of a roh il Monte Carlo. The first type does not involve any resampling. The basic idea behind this type of Monte Carlo is to split the Monte Carlo simulation into two sub simulations. One simulation represents the dimension reducing feature selection step. The second simulation represents the conditional distribution of the features given that they were selected, and can typically be carried out in a space with dimension similar to the number of features selected. The second type of a roh il Monte Carlo does involve resampling, such as bootstrap or cross validation. In this case, resampling creates complex inter-relationships among the resampled datasets. To capture these inter-relationships, we propose a relatively simple hierarchical model that requires generation of a single high dimensional vector, and then a series of low dimensional vectors conditionally generated given the high dimensional vector. To our knowledge, there has not been work to develop a general methodology along the lines presented here. Work with a similar spirit can be seen in the high dimensional literature. For example, Venkatraman and ol shen (2007) developed a faster version of their earlier method () for performing circular binary segmentation. Monte Carlo methods for estimating the distribution of functionals in complex statistical models have a longer history, and include rejection sampling, importance sampling (e.g.), Markov chain Monte Carlo (e.g.) and related algorithms such as the Gibbs sampler (). But these methods do not achieve the reduction in the

discussion we have presented a mathematical modeling approach to speed up high dimensional Monte Carlo simulations by reducing the effective dimension of the space in which the simulations are performed. We have described in a general way how this approach can be used in the case of simple Monte Carlo simulations, and also Monte Carlo simulations that require resampling, such as bootstrap or cross validation. The modification for the resampling setting is achieved by constructing a hierarchical model for which the distributions of the functionals of interest match (or approximately match) the pure Monte Carlo distributions. This new method is called a roh il and can enable complex and slow high dimensional simulations to be converted into simpler and much faster low dimensional simulations. We have discussed how this method can be used to improve robustness evaluations and to disseminate software. As an example, we are disseminating an a roh il program with this article, and have presented a robustness evaluation of this previously published method. In the discussion below, we discuss a roh il Monte Carlo generally first, and then the implementation program provided in this article. We have discussed one detailed example of how high dimensional leave one out cross validation Monte Carlo can be converted into an a roh il Monte Carlo. Generalizing this to other cross validations such as 10-fold cross validation is straightforward. Bootstrapping by a roh il would require a further modification. We showed in this article that a roh il for cross validation is performed by calculating the distribution of a backbone vector of statistics is the effect size for individual differentially expressed features.  is the correlation parameter for CS and AR(1). ' a" is the mean true accuracy over all simulations. '90% LB Coverage' is the coverage probability of 90% lower confidence bound, using either a roh il or an exact binomial confidence interval constructed naively incorrectly from the loo cv accuracy estimate applications to real datasets used in.  a loo cv is the leave one out cross validation accuracy. Dim is the number of features, n 1 and n 2 are the number from each class. '90% LB' is the 90% lower confidence bound computed by a roh il Monte Carlo; and similarly '97.5% LB' is a 97.5% LB, comparable to the 95% two sided intervals used in. For the dataset the outcome is survival status at 3 years. For the van tdataset outcome is 5 year metastases free survival. For the dataset outcome is survival status. For the dataset outcome is survival status. For the dataset outcome is survival status. For all datasets, the significance level for gene selection was  = 0.001. that represents the full dataset, then calculating the conditional distribution of key cross validation statistics when a sample is left out. For bootstrapping, an extra level would need to be added to the hierarchical model that would represent the overlap pattern between the bootstrap samples. This pattern could be represented by a simple multinomial model with probability 1/n on each of the n samples for each of the bootstrap draws (sampling with replacement). Then the conditional distribution given the backbone vector and the pattern can be derived in a straightforward way and used to generate the bootstrap sample. We have discussed that sometimes a roh il models will require approximations to the pure Monte Carlo distribution. Importantly, such approximations must be checked carefully to ensure that they are true to the original model. On the other hand, it does not seem reasonable to 'throw the baby out with the bathwater' and abandon a roh il Monte Carlo when any approximations are required. In many cases, these approximations are straightforward to check over the range of simulation settings that are of interest. We have termed the dimension reduction step of a roh il as adequate, and not attempted here to define this idea exactly. Dimension reduction could be based on more general notions such as sufficiency. A potential area of future research is to find a more formal approach to the dimension reduction step which would establish that the statistics used by the a roh il Monte Carlo are capturing all the key aspects of the pure Monte Carlo. A potential critique of the a roh il approach is that it requires some work to build the mathematical models used to reduce dimension. While it is true that this method requires some extra work, which is not generally worth the trouble in lower dimensional settings, the computational savings in high dimensions is so large that it can not only be worthwhile but also critical. Furthermore, very complex high dimensional procedures can be challenging to implement, and thoroughly checking for coding bugs, information leak or inadvertent neglect of specification of all parameters and assumptions, can be fraught with difficulties. An important aspect of a roh il is that implementation is simplified, i.e. the added complexity of the mathematics is often more than compensated for by the greater simplicity and transparency of the computer code. We argue that this results in a cleaner and overall simpler procedure than traditional brute force Monte Carlo, where any errors are often buried in long computer code scripts. We have found that the a roh il Monte Carlo approach results in very short and simple code compared with pure Monte Carlo. For example, the R script we are providing with this publication is much shorter and simpler than the original code from Dobbin (2009), consisting of multiple C++ programs and steps to integrate the outputs together. The resulting simplification of the code is likely to greatly enhance reproducibility of high dimensional studies, which has been a continuing challenge to this area. The accompanying a roh il program is implemented with one informative feature, which was used in all the coverage probability simulations in this article. The program is also available with a user selected number of features. The number of informative features has relatively small effect on the confidence interval bound, and the number of informative features is unknown. Hence, it is preferable to have a program in which the user does not have to come up with this unknown quantity. See Section 6 in Supplementary Material for the table of simulation results showing the stability of bounds across different numbers of informative features. An alternative approach would be to search over different possible numbers of informative features to find a worst case scenario setting, resulting in more conservative confidence bounds. The accompanying a roh il program is implemented with a diagonal covariance matrix. This is done not because the true covariance for high dimensional data is likely to be diagonal, but because it is generally not possible to estimate the covariance matrix
