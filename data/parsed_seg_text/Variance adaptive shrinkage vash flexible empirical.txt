Motivation: Genomic studies often involve estimation of variances of thousands of genes (or other genomic units) from just a few measurements on each. For example, variance estimation is an important step in gene expression analyses aimed at identifying differentially expressed genes. A common approach to this problem is to use an Empirical Bayes (EB) method that assumes the variances among genes follow an inverse gamma distribution. This distributional assumption is relatively inflexible; for example, it may not capture outlying genes whose variances are considerably bigger than usual. Here we describe a more flexible EB method, capable of capturing a much wider range of distributions. Indeed, the main assumption is that the distribution of the variances is uni-modal (or, as an alternative, that the distribution of the precisions is unimodal). We argue that the unimodal assumption provides an attractive compromise between flexibility, computational tract-ability and statistical efficiency. Results: We show that this more flexible approach provides competitive performance with existing methods when the variances truly come from an inverse gamma distribution, and can outperform them when the distribution of the variances is more complex. In analyses of several human gene expression datasets from the Genotype Tissues Expression consortium, we find that our more flexible model often fits the data appreciably better than the single inverse gamma distribution. At the same time we find that in these data this improved model fit leads to only small improvements in variance estimates and detection of differentially expressed genes. Availability and Implementation: Our methods are implemented in an R package vash r available from

introduction genomic studies often involve estimation of variances of thousands of genes (or other genomic units) from just a few measurements on each. For example, variance estimation is an important step in gene expression analyses aimed at identifying differentially expressed genes. The small number of measurements on each gene mean that simple estimates of the variance at each gene (e.g. the sample variance) can be quite unreliable. A common solution to this problem is the use of Empirical Bayes (EB) methods, which combine information across all genes to improve estimates at each gene. In particular they have the effect of 'shrinking' the variance estimates towards a common mean value, which has a stabilizing effect, avoiding unusually large or small outlying estimates that may have high error. A key question is, of course, how much to shrink. While all EB methods aim to learn the appropriate shrinkage from the data, existing EB approaches make relatively inflexible modelling assumptions that could limit their effectiveness. Here we propose a new, more flexible, EB approach, which can improve variance estimation accuracy in some settings perhaps the most commonly encountered example of the use of EB methods is in gene expression analyses that aim to identify differences in gene expression among conditions. A typical pipeline for identifying differentially expressed genes computes a p value for each gene using a t test (two condition experiments) or f test (multiple condition experiments), both of which require an estimate of the variance in expression of each gene among samples. In the classical t test or f test sample variances are used as plug-in estimates of gene specific variances. However, when the sample size is small, sample variances can be inaccurate, resulting in loss of power (). Hence, many methods have been proposed to improve variance estimation. For example, several papers () suggested adding an offset standard deviation to stabilize small variance estimates. A more sophisticated approach () used parametric hierarchical models to combine information across genes, using an inverse gamma prior distribution for the variances, and a Gamma likelihood to model the observed sample variances. This idea was further developed by L nn st edt and Speed (2002) and smyth (2004) into an Empirical Bayes (EB) approach that estimates the parameters of the prior distribution from the data. This improves performance by making the method more adaptive to the data. Smyth (2004) also introduces the 'moderated t test which modifies the classical t test by replacing the gene specific sample variances with estimates based on their posterior distribution. This pipeline, implemented in the software limma, is widely used in genomics thanks to its adaptivity, computational efficiency and ease of use. While assuming an inverse gamma distribution for the variances yields simple procedures, the actual distribution of variances may be more complex. Motivated by this, p hips on et al. (2016) (limma with robust option, denoted by lim mar modified the procedures from Smyth (2004) to allow for some small proportion of 'outlier' genes that have higher variability than expected under the inverse gamma assumption. Specifically, the lim mar procedure changes the moderated t statistics from limma by decreasing their degrees of freedom (df) in a way that varies for each gene, depending on whether the gene looks like an outlier. Genes that look like an outlier have their df reduced appreciably, making them less significant, whereas other genes have their df unchanged or reduced very little. They showed that, in the presence of such outliers, this procedure could improve on the standard limma pipeline. Here we consider a more formal EB approach to this problem, which generalizes previous EB methods by replacing the usual inverse gamma prior distribution with a substantially more flexible family of distributions. The main constraint we place on this prior is that the distribution of the variances (or, alternatively, the precisions) is unimodal. This unimodal assumption not only seems likely to be plausible in many settings, but also provides an attractive compromise between flexibility, statistical stability and computational convenience. Specifically it provides more flexibility and generality than many parametric models while avoiding potential over-fitting issues of fully non-parametric methods. (An alternative approach would be to use some kind of regularization to prevent over-fitting; see Efron (2016) for example.) We use a mixture of (possibly a large number of) inverse gamma distributions to flexibly model this unimodal distribution, and provide simple computational procedures to fit this model by maximum likelihood of the mixture proportions. Our procedure provides a posterior distribution on each variance or precision, as well as point estimates (posterior mean). The methods are an analogue of the 'adaptive shrinkage' methods for mean parameters introduced in, and are implemented in the R package vash r (for 'variance adaptive shrinkage in R'). We compare our method with both limma and lim mar in various simulation studies, and also assess its utility on real gene expression data.

discussion we have presented a flexible empirical Bayes approach ('variance adaptive shrinkage', or 'vash') to shrinkage estimation of variances the method makes use of a mixture model to allow for a flexible family of unimodal prior distributions for either the variances or precisions, and uses an accelerated em based algorithm to efficiently estimate the underlying prior by maximum likelihood. Although slower than limma, vash is computationally tractable for large datasets: for example, for data with 10 000 genes, vash typically takes about 30 s (limma takes just a few seconds). Our results demonstrate that vash provides a robust and effective approach to variance shrinkage, at least in settings where the distribution of the variances (or precisions) is unimodal. When the true variances come from a single inverse gamma prior, vash is no less accurate than the simpler method. When the variances come from a more complex distribution vash can be more accurate than simpler methods if the sample sizes to estimate each variance are sufficiently large. In the gene expression datasets we examined here, the gains in accuracy of vash versus limma are small, and likely not practically important. While this could be viewed as disappointing, it nonetheless seems useful to show this, since it suggests that in many gene expression contexts the simpler approaches will suffice. At the same time, it remains possible that our method could provide practically useful gains in accuracy for other datasets, and as we have shown, it comes at little cost. In addition, our work provides an example of a general approach to empirical Bayes shrinkage use of mixture components with a common mode to model unimodal prior distributions that could be useful more generally. Our method is implemented in an R package vash r available from http://github.com/mengyin/vashr. Codes for reproducing analyses and figures in this paper are at https://github.com/mengyin/vash.
