Results: Here, we present a comprehensive analysis on the reproducibility of computational characterization of genomic variants using high throughput sequencing data. We reanalyzed the same datasets twice, using the same tools with the same parameters, where we only altered the order of reads in the input (i.e. fast q file). Reshuffling caused the reads from repetitive regions being mapped to different locations in the second alignment, and we observed similar results when we only applied a scatter gather approach for read mapping without prior shuffling. Our results show that, some of the most common variation discovery algorithms do not handle the ambiguous read mappings accurately when random locations are selected. In addition, we also observed that even when the exact same alignment is used, the g atk haplotype caller generates slightly different call sets, which we pinpoint to the variant filtration step. We conclude that, algorithms at each step of genomic variation discovery and characterization need to treat ambiguous mappings in a deterministic fashion to ensure full replication of results. Availability and Implementation: Code, scripts and the generated VCF files are available at

introduction the advancements in high throughput sequencing (HTS) technologies have increased the demand on producing genome sequence data for many research questions and prompted pilot projects to test its power in clinical settings (). Any 'medical test' to be reliably used in the clinic has to be proven to be both accurate and reproducible. However, the fast evolving nature of HTS technologies make it difficult to achieve full reproducibility. We recently showed that resequencing the same DNA library with the same model HTS instrument twice and analyzing the data with the same algorithms may lead to different variation call sets (). Aside from the potential problems in the 'wet lab' side, there may be additional complications in the 'dry lab' analysis due to alignment errors and ambiguities due to genomic repeats. The repetitive nature of the human genome causes ambiguity in read mapping when the read length is short (). A 100 bp read generated by the Illumina platform may align to hundreds of genome locations with similar edit distance. The bwa mem () mapper's approach to handle such ambiguity is randomly selecting one location and assigning the mapping quality to zero to inform the variant calling algorithms that the alignment may not be accurate. Although many algorithms exist for HTS data analysis, only a handful of computational pipelines for read mapping and variant calling may considered a 'standard' such as those that are commonly used in large scale genome projects such as the 1000 Genomes Project (). Recently, the Genome in a Bottle Project () was started to set standards for accurate HTS data analysis for both research and clinical uses by addressing the differences in detection performances of different algorithms and different sequencing platforms. In this study, we investigated whether some of the commonly used variant discovery algorithms make use of this mapping quality information, and how they react to genomic repeats. Briefly, we aligned two whole genome shotgun (WGS) datasets, one low and one high coverage genome sequenced as part of the) to the human reference genome (GRCh37) twice using the same parameters. In the second mapping, we shuffled the order of reads to make sure that the same random numbers are not used for the same reads. We then generated two single nucleotide variant (SNV) and in del call sets each from each genome. We observed substantial differences in the call sets generated by all of the variant discovery tools we tested except variation hunter common law. However, variation hunter explicitly requires a deterministic read mapper, therefore we removed it from further comparisons. gat ks haplotype caller showed discord an cies of 1.061.7% in snv in del call sets, where free bayes showed the most concord ancy (up to 99.2%). Genome STRiP showed the greatest discrepancy in structural variation calls (up to 25%). Our results raise questions about reproducibility of call sets generated with several commonly used genomic variation discovery tools.

discussion in this article, we documented the effects of different approaches to handle ambiguities in read mapping due to genomic repeats. We focused on more widely used computational tools for read mapping and variant calling and observed that random placement of ambiguously mapping reads have an effect on called variants. Although discord an cies within repeats are less of a concern due to their relatively negligible effects to phenotype, we also discovered hundreds to thousands variants differently detected within coding exons. haplotype caller showed the most discrepancies, where the discordant calls were less pronounced in free bayes and Platypus results. Using the same alignments twice, we found that the callers themselves are deterministic, however, they return different call sets when the same data is remapped. Interestingly, we observed differences in call sets generated using haplotype caller even when the same alignments and variant filtration training datasets were provided. Although we could not fully characterize the reasons of this observation with g atk since haplotype caller algorithm is yet unpublished, we observed that the differences were mainly due to differences in calculation of the vqs lod score by the v qsr filter (Section 3). Therefore, a second source of randomness we observed is within the training step of the v qsr filter, which is specific to g atk. Recommendations. We, point out that randomized algorithms may achieve better accuracy in practice, albeit without 100% reproducibility. Full reproducibility could only be achieved through using deterministic methods. Therefore, for full reproducibility, we recommend to opt for a deterministic read mapper, such as RazerS3 mr fast etc., and a deterministic variant caller, such as Platypus or free bayes for SNV and indels. We note that all SV calling algorithms we surveyed in this article are deterministic algorithms; therefore, the SV call sets can be fully reproducible when they are used together with a deterministic mapper. Another approach may be more strict filtering of variants that map to repeats and duplications, however, this may result in lower detection power in functionally important duplicated genes such as the MHC and KIR loci. It may be possible to work around the gat ks vqs lod calculation problem outlined above either by analyzing multiple samples simultaneously, or by setting the max num training data parameter and other downsampling parameters to high values, however, we recommend disabling these randomization s by default to be a better practice for uninformed users. In our tests, changing only the max num training data parameter did not fully resolve the variant filtration problem, which points that there may be other downsampling and or randomization step within the v qsr filter. Conclusion. Mapping short reads to repetitive regions accurately still remains an open problem (). RazerS3 and mr fast use edit distance and paired end span distance to deterministically assign a single 'best' map location to ambiguously mapping reads, where bwa mem selects a random map location all mapping properties are calculated the same. bwa mem assigns a zero mapping quality to such randomly selected alignments. This approach is still valid since it informs the downstream analysis tools for problematic alignments, however, as we have documented in this article, several variant discovery tools do not fully utilize this information. Complete analysis of the reasons for these discrepancies may warrant code inspection and full disclosure of every algorithmic detail. The differences in call sets we observed in this study have similar accuracy when compared to 1000 Genomes data (Supplementary Tables S28 and S29). In addition a recent study did not find any significant difference between deterministic and non-deterministic mappers in terms of accuracy (). It is still expected to have differences between different algorithms and or parameters but obtaining different results should not be due to the order of independently generated reads in the input file. We may simply count these discord an cies as false positives and negatives, and such discord an cies may not have any adverse effects in practice, however, we argue that computational predictions should not be affected by luck, and inaccuracies in computational results should be deterministic so they can be better understood and characterized. We are in exciting times in biological research thanks to the development of HTS technologies. However, under the shining lights of the discoveries we make in this 'big biology' revolution, it can be easy to overlook that the methods matter. No genomic variant characterization algorithm achieves 100% accuracy yet, even with simulation data, but it is only possible to analyze and understand the shortcomings of deterministic algorithms, and impossible to fully understand how an algorithm performs if it makes random choices.
