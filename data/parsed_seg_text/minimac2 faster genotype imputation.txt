Genotype imputation is a key step in the analysis of genome wide association studies. Upcoming very large reference panels, such as those from The 1000 Genomes Project and the Haplotype Consortium, will improve imputation quality of rare and less common variants, but will also increase the computational burden. Here, we demonstrate how the application of software engineering techniques can help to keep imputation broadly accessible. Overall, these improvements speed up imputation by an order of magnitude compared with our previous implementation. Availability and implementation: minimac2, including source code, documentation, and examples is available at

introduction genotype imputation is routinely used to increase the power of genome wide association studies g was. The approach works by finding haplotype segments that are shared between study individuals, which are typically genotyped on a commercial array with 300 0005 000 000 SNPs, and a reference panel of more densely typed individuals, such as those studied by The 1000 Genomes Project (). In this way, the approach can accurately assign genotypes at markers that have not been directly examined, facilitating comparison of results across samples genotyped using different marker panels and easing fine mapping efforts. To reduce the computational burden of this procedure, we introduced an approach called pre phasing (). In brief, this approach works in two steps. First, haplotypes are estimated for each of the g was individuals. Second, the estimated haplotypes are used for imputation. This two step approach reduces the computational cost of imputation in two ways. First, the g was samples can be decomposed into haplotypes once, and these haplotypes can then be re-used many times. With standard methods () likely haplotypes for each sample are estimated every time imputation is repeated with a new or updated reference panel. Second, because we restrict searches for matching haplotypes to the most likely haplotype for each sample (or a small set of likely haplotype configurations), comparisons between study samples and reference panels proceed much faster. Previous implementations accounted for haplotype uncertainty and sought a pair of matching haplotypes (a process for which computation costs increase quadratically with sample size). Ongoing whole genome sequencing studies will contribute to reference panels much larger than currently available (). Based on our computer simulations (), we expect substantial gains in imputation accuracy (measured as the r 2 between imputed genotypes and the true simulated genotypes) and in association information (which increases with imputation accuracy) using these panels. This is particularly pertinent for rare variants for which imputation based on current panels (which typically have 1000 samples) is relatively poor. Since the complexity of imputation increases linearly with the number of markers and individuals in the reference panel, further improvements in computational efficiency are needed to keep imputation broadly accessible. Here, we describe and evaluate a collection of improvements that speed up imputation by 10100-fold while maintaining the accuracy of our current method. we compare the running times of our well established pre phasing method, mini mac (), with its tuned version, minimac2 (). Compared with Impute2 () and Beagle (), minimac2 is 8 and 100, respectively, faster and requires less memory (1.1 GB compared with 2.4 GB for Impute2 and 10 GB for Beagle,). To maximize efficiency of our code, we used vector and matrix operation functions from the highly optimized open blas library (http:// www open blas net $30% faster than the standard functions). We note that, due to overlapping effects, the overall speed up is lower than the product of the speed ups measured for each single optimization.
