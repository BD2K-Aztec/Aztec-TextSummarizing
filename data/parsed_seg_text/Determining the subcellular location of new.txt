Motivation: Evaluation of previous systems for automated determination of subcellular location from microscope images has been done using datasets in which each location class consisted of multiple images of the same representative protein. Here, we frame a more challenging and useful problem where previously unseen proteins are to be classified. Results: Using cd tagging we generated two new image datasets for evaluation of this problem, which contain several different proteins for each location class. Evaluation of previous methods on these new datasets showed that it is much harder to train a classifier that generalizes across different proteins than one that simply recognizes a protein it was trained on. We therefore developed and evaluated additional approaches, incorporating novel modifications of local features techniques. These extended the notion of local features to exploit both the protein image and any reference markers that were imaged in parallel. With these, we obtained a large accuracy improvement in our new datasets over existing methods. Additionally, these features help achieve classification improvements for other previously studied datasets. Availability: The datasets are available for download at http://murphy lab web cmu edu data. The software was written in Python and Cþþ and is available under an open source license at http://murphylab. web cmu edu software. The code is split into a library, which can be easily reused for other data and a small driver script for reproducing all results presented here. A step by step tutorial on applying the methods to new datasets is also available at that address.

introduction generation of images of cells and tissues is increasingly easy. With the advent of automated microscopes, the capability for data generation has out-stripped the capability for visual data analysis. This has led to extensive work on automated methods for interpreting microscope images. The problem of classification of subcellular patterns has received particular attention, and a number of datasets and classifiers have been described. These datasets typically feature one different protein for each class of interest, with multiple images for the same tagged protein. On these datasets, better than human performance has been reported (). This previous work implicitly assumed that results obtained in those datasets can be generalized to the problem of classifying previously unseen proteins. In this work, we test this assumption using two new datasets where there are multiple proteins in each location class (and multiple images per protein). These datasets were created using NIH 3T3 cell lines expressing green fluorescent protein gfp tagged proteins created by cd tagging (). We tested classifiers using a cross validation protocol whereby images from the same protein are never present in both the training and testing sets. This is a stricter proxy for cross protein generalization than randomizing by image, and guards against the possibility that learning is based on properties of the tagging method (e.g. intensity) or too specific to the protein in question (e.g. a particular subpattern of an organelle). With this protocol and existing methods, generalization accuracy was only 60% for our new datasets. We therefore investigated whether improved generalization could be obtained using alternative feature representations of the images. Many previous systems use image level features such as texture features (), but some specialized features for cell images have also been proposed (), including features for single cell regions [in fact, historically, classification on cell segmented images was reported first (In the computer vision literature, local features, such as the scale invariant feature transform, introduced by Lowe (1999), have shown good results in many settings. They have not been widely used in bio image analysis [there are a few uses of patch based methods, a basic form of these features (. object level features, which can be seen as a form of local features, were used for subcellular location un mixing both in supervised and unsupervised modes (). Local features, as presented in the literature, are generally defined on a gray-scale image and do not take advantage of the multiple image channels frequently acquired by fluorescent microscopy. There is some work on natural scene color images (van de), but it does not directly apply to fluorescence microscopy images for analyzing subcellular patterns where one channel is privileged (depicting the protein distribution of interest) and others serve as references. Naturally, the simplest protocol is to ignore all but the primary channel. However, the use of a reference channel can provide additional important information, particularly at the local level. For example, we could distinguish between two vesicle classes that appear similar in the primary (protein) channel but differ in distance from the nucleus because the region containing vesicles will appear differently in the reference nuclear channel. We present a simple protocol to take these reference channels into account. Using these features, we obtain a large accuracy gain on our datasets. We also use other datasets to further validate the value of the features and find that they lead to good results in all tested datasets. widefield confocal on the left, and nucleoli on the right), second row of confocal images (cytoplasmic pattern on the left, mitochondrial pattern on the right). Images are false color: the red channel shows the nuclear marker Hoechst, the green channel is the gfp tagged protein. Images shown are the first image in their classes and have not been manually chosen. The widefield images were automatically acquired and the quality is lower than if they had been manually acquired. Images have been contrast stretched for publication

discussion this work frames the subcellular location problem as recognizing different proteins in the same class. While this may have been implicit in previous work, it was not directly tested by datasets with a single representative protein per location class. We introduce two new datasets, which contain multiple proteins per class (and multiple images per protein). We observed that when cross validation was performed over proteins, the resulting accuracy was much lower than when it was performed over images (where it is comparable with other datasets). This is intuitive as it is an easier problem to recognize proteins that are in the training set than proteins that are only in the same class (in particular, in the first case, it is possible that the system distinguishes the proteins by artifacts of the tagging or variation in subpatterns). Our data show that it is incorrect to assume that the high accuracy values obtained in datasets composed of multiple images of the same protein imply that the system would generalize well to other proteins in the same location class. Our datasets are publicly available. There is still a lot of room for improvement in accuracy and we hope that other researchers will test their methods on this harder problem. We also introduce a new methodology for classification of subcellular location patterns, which is based on interest point detection and local feature analysis. We developed a protocol to integrate the information in reference channels (which are typically acquired in parallel to the protein of interest). We implemented this method based on SURF, but the protocol is a generic method and could be applied to other local feature sets, such as scale invariant feature transform () or any combination of detector and descriptor. On our new datasets, these methods performed better than the traditional whole field features by 10 percentage points (a difference that is highly statistically significant). We tested these features on traditional datasets as well. On these, the baseline methods already perform well and there was less room for improvement. In four cases, the results are statistically indistinguishable from the baseline. It should be noted, though, that in no dataset did we observe that adding the local features lead to a statistically distinguishable worse outcome. These features have the further advantage that they are computed on the raw images without any pre-processing such as background correction or contrast enhancement. No tuning is necessary for adapting to new datasets and it is flexible for application to large datasets. Therefore, we recommend that local features with reference information be added to the standard toolkit for bio image classification.
