Motivation: A vast literature from the past decade is devoted to relating gene profiles and subject survival or time to cancer recurrence. Biomarker discovery from high dimensional data, such as transcript omic or single nucleotide polymorphism profiles, is a major challenge in the search for more precise diagnoses. The proportional hazard regression model suggested by Cox (1972), to study the relationship between the time to event and a set of covariates in the presence of censoring is the most commonly used model for the analysis of survival data. However, like multivariate regression, it supposes that more observations than variables, complete data, and not strongly correlated variables are available. In practice, when dealing with high dimensional data, these constraints are crippling. Collinearity gives rise to issues of over-fitting and model misidentification. Variable selection can improve the estimation accuracy by effectively identifying the subset of relevant predictors and enhance the model interpretability with parsimonious representation. To deal with both collinearity and variable selection issues, many methods based on least absolute shrinkage and selection operator penalized Cox proportional hazards have been proposed since the reference paper of Tibshirani. Regularization could also be performed using dimension reduction as is the case with partial least squares (PLS) regression. We propose two original algorithms named spls dr and its non-linear kernel counterpart dks pls dr by using sparse PLS regression (sPLS) based on deviance residuals. We compared their predicting performance with state of the art algorithms on both simulated and real reference benchmark datasets. Results: spls dr and dks pls dr compare favorably with other methods in their computational time, prediction and selectivity, as indicated by results based on benchmark datasets. Moreover, in the framework of PLS regression, they feature other useful tools, including bi plots representation, or the ability to deal with missing data. Therefore, we view them as a useful addition to the toolbox of estimation and prediction methods for the widely used Coxs model in the high dimensional and low sample size settings. Availability and implementation: The r package pls r cox is available on the CRAN and is maintained by Fr ed eric Bertrand. http://cran.r-project.org/web/packages/plsRcox/index.html.

INTRODUCTION

discussion overall dks pls dr and, even more, spls dr compare favorably with the benchmark methods on both simulated and real data sets in the simulation study, spls dr turned out to be the best method to recover the linear link according to the is sw performance measure and for the three simulation schemes (, Linear link row panel). More generally in that setting, the models featuring components had better performance measures than the LASSO and elastic net based ones. Similar results can be observed for the iauc surv roc criterion (Supplementary, Linear link row panel) with lesser advantage to spls dr and dks pls dr. In both cases, simulations study show that neither spls dr or dks pls dr tend to wrongly recover a link between the response and the explanatory variable when there is none (Supplementary Figs S1 and S8, No link row panel), whereas LASSO and elastic net based methods do for the factorial simulation scheme and the iauc surv roc criterion (Supplementary, no link row panel). Whatever the real dataset, the overall patterns of the spls dr and dks pls dr algorithms follow the general patterns of predictability of the benchmark methods, e.g. a low increase in predictability for the Metzeler dataset or a global step-wise decrease on the Romain datasets. These patterns suggest that the performances of the different methods may depend on the real but unknown data dimension. The spls dr or dks pls dr almost always rank among the 1 to 4 best methods with higher predictability, often being even 1st or 2nd, both on short and long term predictions (see Tables 2 and 3). This is particularly true in cases where a large predictability heterogeneity is to be noted among the benchmark algorithms, such as for the Garber and the Wang datasets. Last but not least, spls dr and dks pls dr not only automatically handle missing data, the study of the robustness of these two algorithms to the amount and type of missing data being beyond the scope of this article, but also provide nice data exploration tools such as bi plots representation of individuals and descriptors, by projecting the dataset on the first sPLS components (see). In a word, we view spls dr and dks pls dr as a useful addition to the toolbox of estimation and prediction methods for the widely used Cox's model in the high dimensional and low sample size settings.
