Motivation: high content screening (HCS) technologies have enabled large scale imaging experiments for studying cell biology and for drug screening. These systems produce hundreds of thousands of microscopy images per day and their utility depends on automated image analysis. Recently, deep learning approaches that learn feature representations directly from pixel intensity values have dominated object recognition challenges. These tasks typically have a single centered object per image and existing models are not directly applicable to microscopy datasets. Here we develop an approach that combines deep convolutional neural networks cnn s with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. Results: We introduce a new neural network architecture that uses MIL to simultaneously classify and segment microscopy images with populations of cells. We base our approach on the similarity between the aggregation function used in MIL and pooling layers used in cnn s. To facilitate aggre-gating across large numbers of instances in CNN feature maps we present the noisy and pooling function, a new MIL operator that is robust to outliers. Combining cnn s with MIL enables training cnn s using whole microscopy images with image level labels. We show that training end to end MIL cnn s outperforms several previous methods on both mammalian and yeast datasets without requiring any segmentation steps. Availability and implementation: to rch7 implementation available upon request.

introduction high content screening (HCS) technologies that combine automated fluorescence microscopy with high throughput biotechnology have become powerful systems for studying cell biology and for drug screening (). These systems can produce more than 10 5 images per day, making their success dependent on automated image analysis. Previous analysis pipelines heavily rely on hand tuning the segmentation, feature extraction and classification steps for each assay. Although comprehensive tools have become available () they are typically optimized for mammalian cells and not directly applicable to model organisms such as yeast and Caenorhabditis elegans. Researchers studying these organisms often manually classify cellular patterns by eye (). Recent advances in deep learning have proven that deep neural networks trained end to end can learn powerful feature representations and outperform classifiers built on top of extracted features (). Although object recognition models have been successfully trained using images with one or a few objects of interest at the center of the image, microscopy images often contain hundreds of cells with a phenotype of interest, as well as outliers. Training similar recognition models on HCS screens is challenging due to the lack of datasets labeled at the single cell level. In this work, we describe a convolutional neural network (CNN) that is trained on full resolution microscopy images using multiple instance learning (MIL). The network is designed to produce feature maps for every output category, as proposed for segmentation tasks in. We pose cellular phenotype classification as a MIL problem in which each element in a class specific feature map (approximately representing the area of a single cell in the input space) is considered an instance an entire class specific feature map (representing the area of the entire image) is considered a bag of instances annotated with the whole image label. Typically binary MIL problems assume that a bag is positive if at least one instance within the bag is positive. This assumption does not hold for HCS images due to heterogeneities within cellular populations and V C The Author 2016. Published by Oxford University Press.
