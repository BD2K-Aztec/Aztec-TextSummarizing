Motivation: Sources of neuroscience data in Drosophila are diverse and disparate making integrated search and retrieval difficult. A major obstacle to this is the lack of a comprehensive and logically structured anatomical framework and an intuitive interface. Results: We present an online resource that provides a convenient way to study and query fly brain anatomy, expression and genetic data. We extended the newly developed brain name nomenclature for the adult fly brain into a logically structured ontology that relates a comprehensive set of published neuron classes to the brain regions they innervate. The Virtual Fly Brain interface allows users to explore the structure of the Drosophila brain by browsing 3D images of a brain with subregions displayed as coloured overlays. An integrated query mechanism allows complex searches of underlying anatomy, cells, expression and other data from community databases. Availability: Virtual Fly Brain is freely available online at www. virtual fly brain org Contact:

introduction with its relatively simple architecture and unparalleled level of genetic tractability, the brain of Drosophila is an ideal model for fundamental neuroscience research. However, in practice, navigating the Drosophila neurobiology literature and the various community databases is a real challenge. The literature's long history and diversity have resulted in a variety of often conflicting terminologies. Information about useful research reagents is scattered across a number of databases that are not interoperable and rarely even cross referenced. Consequently, finding, for example, data about the connectivity between two brain regions, or where genes are expressed or what resources exist is an arduous and difficult task. To realize the value of the scientific investment in Drosophila neuroscience, the community requires a robust anatomical framework with the supporting data structures and computational tools to exploit it. The first challenge is to agree on a common framework for gross anatomy. This has been addressed, for the first time by the brain name consortium, who proposed a revised nomenclature for the insect brain k submitted for * To whom correspondence should be addressed. publication) with each term defined both textually and as a volume in a reference Drosophila brain. Next we need to be able to construct and solve useful searches and integrate data from disparate sources. Using the web ontology language OWL 2 (http://www.w3.org/TR/owl2-primer/), it is possible to store complex relationships between terms and, with the help of reasoning software, to use those relationships to automate classification and drive queries. For example, the relationship between a class of neurons and a structure that it innervate s can provide both a substrate for useful queries (what neurons innervate region X) and a criterion for classification (all neurons in class A innervate some region X). An ontology also provides a mechanism for common annotation of neuroanatomical data, allowing easy integration of data from disparate resources. Aligned serial images, such as those from confocal microscopy, are a key tool for visualizing anatomical structures or regions of gene expression in the Drosophila nervous system [e.g. (. Demarcation (or 'painting') of known neuropil domains on top of such image stacks provides a powerful tool for research and study of the brain structure (). Processing and viewing such data locally can be done using graphics software such as Amira () or image j fiji (). There are also powerful specialist desktop based systems for interactively exploring the Drosophila nervous system in 3D (). However, such datasets are also large and viewing them requires high specification workstation hardware and a lot of storage rather than commodity computing. Another characteristic of such image data is that it is expensive to produce and therefore its sharing and distribution is of paramount importance. Obviously sharing such bulky data imposes serious requirements on data storage and data transfer bandwidth. The ideal way of distributing and sharing image data is via web interfaces. Most existing projects in the community use ad hoc solutions such as downsized, pre-compiled QuickTime movies or representative reconstructions [e.g. Flytrap (); brain trap (. Some of the more recent solutions also provide interactive 3D browsing functions such as volume rotation although the reduction of resolution from raw dataset to that observed on the browser still remains an issue. To more fully exploit these 3D images, mechanisms are required to display the boundaries and extent of defined structures, such
