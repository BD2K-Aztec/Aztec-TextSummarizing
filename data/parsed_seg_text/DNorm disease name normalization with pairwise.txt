Motivation: Despite the central role of diseases in biomedical research, there have been much fewer attempts to automatically determine which diseases are mentioned in a text the task of disease name normalization d norm compared with other normalization tasks in biomedical text mining research. Methods: In this article we introduce the first machine learning approach for d norm using the NCBI disease corpus and the MEDIC vocabulary, which combines MeSH Ã• and OMIM. Our method is a high performing and mathematically principled framework for learning similarities between mentions and concept names directly from training data. The technique is based on pairwise learning to rank, which has not previously been applied to the normalization task but has proven successful in large optimization problems for information retrieval. Results: We compare our method with several techniques based on lexical normalization and matching, meta map and Lucene. Our algorithm achieves 0.782 micro averaged f measure and 0.809 macro averaged f measure an increase over the highest performing baseline method of 0.121 and 0.098, respectively. Availability: The source code for d norm is available at http://www. ncbinlmnihgovcbb research lude mod norm along with a web based demonstration and links to the NCBI disease corpus. Results on PubMed abstracts are available in pub tator http://www.ncbi.nlm. nih gov cbb research lu demo pub tator
introduction diseases are central to many lines of biomedical research, and enabling access to disease information is the goal of many information extraction and text mining efforts islam aj Dog an and). The task of disease normalization consists of finding disease mentions and assigning a unique identifier to each. This task is important in many lines of inquiry involving disease, including etiology (e.g. gene disease relationships) and clinical aspects (e.g. diagnosis, prevention and treatment). Disease may be defined broadly as 'any impairment of normal biological function' (). Given the wide range of concepts that may thus be categorized as diseases their respective etiologies, clinical presentations and their various histories of diagnosis and treatment disease names naturally exhibit considerable variation. This variation presents not only in synonymous terms for the same disease, but also in the diverse logic used to create the disease names themselves. Disease names are often created by combining roots and affixes from Greek or Latin (e.g. 'hemochromatosis'). A particularly flexible way to create disease names is to combine a disease category with a short descriptive modifier, which may take many forms, including anatomical locations ('breast cancer'), symptoms ('cat-eye syndrome'), treatment dopa responsive dystonia'), causative agent ('staph infection'), biomolecular etiology ('G6PD deficiency'), heredity x linked agammaglobulinemia') or eponyms schwartz jam pel syndrome'). Modifiers are also frequently used to provide description not part of the name (e.g. 'severe malaria'). When diseases are mentioned in text, they are frequently also abbreviated, exhibit morphological or orthographic al variations, use different word orderings or use synonyms. These variations may involve more than single word substitutions. For example, because affixes are often composed, a single word o culo cerebro renal may correspond to multiple words ('eye, brain and kidney') in another form. The disease normalization task is further complicated by the overlap between disease concepts, forcing systems that locate and normalize diseases in natural language text to balance handling name variations with differentiating between concepts to achieve good performance. Previous works addressing disease name normalization d norm typically use a hybrid of lexical and linguistic approaches islam aj Dog an and Lu, 2012b;). While string normalization techniques (e.g. case folding, stemming) do allow some generalization, the name variations in the lexicon always impose some limitation. Machine learning may enable higher performance by modeling the language that authors use to describe diseases in text; however, there have been relatively few attempts to use machine learning in normalization, and none for disease names. In this work we use the NCBI disease corpus islam aj Dog an and), which has recently been updated to include concept annotations islam aj dog an et al., unpublished data), to consider the task of disease normalization. We describe the task as follows: given an abstract, return the set of disease concepts mentioned. Our current purpose is to support entity specific semantic search of the biomedical literature () and computer assisted bio curation especially document triage (In this article we introduce d norm the first machine learning method to normalize disease names in biomedical text. Our technique learns the similarity between mentions and concept names directly from the training data, thereby focusing on the candidate generation phase of normalization. Our technique can learn arbitrary mappings between mentions and names, including synonymy, polysemy and relationships that are not 1-to-1. Moreover, our method specifically handles abbreviations and word order variations. Our method is based on pairwise learning to rank p ltr which has been successfully applied to large optimization problems in information retrieval (), but to the best of our knowledge has not previously been used for concept normalization.

discussion though the NLM Lexical Normalization method has higher recall than any method besides d norm the precision remains the remaining methods use separate stages for NER and normalization; because all use BANNER for NER, the errors caused by the NER component are the same. The remaining methods also use abbreviation resolution, significantly reducing the number of false positives caused by ambiguous abbreviations. The Inference method handles term variations by using string similarity and Lucene search, though it tends to select highly specific concepts, such as mapping 'inherited disorders' to Blood Coagulation Disorders, Inherited (MESH:D025861). Analyzing the errors made by BANNER  Lucene but not by BANNER  cosine similarity shows that most are due to the Lucene scoring function insufficiently penalizing lexicon names containing tokens not present in the mention. The majority of the errors made by BANNER  cosine similarity but not by d norm are due to term variation. Because BANNER  Lucene, BANNER  cosine similarity and d norm (BANNER  p ltr use the same processing pipeline, the performance difference between these methods is solely due to the normalization methodology. In addition, because the scoring function for cosine similarity is equivalent to the one used by d norm before training, the performance difference between these methods is solely due to the weights learned during training. To further isolate the effect of p ltr training on performance, we performed a normalization experiment comparing Lucene, cosine similarity and p ltr using the gold standard mentions from the NCBI disease corpus test subset as input instead of the mentions found by BANNER. We again used the p ltr model trained using  10 4. In this comparison, we count a result as correct if the concept associated with the lexicon name scored highest by d norm matched the annotated concept for the mention. Out of the 960 mentions, Lucene found 674 (70.2%), cosine similarity found 687 (71.6%) and p ltr found 789 (82.2%). This experiment confirms the effectiveness of the novel learning procedure used by d norm. We performed an experiment to demonstrate the effect that varying the learning rate () has on training time and performance. We varied exponentially between 10 2 and 10 8 , and report the results in. The best performance was achieved with  10 4 , which required a training time of 48.8 min and resulted in a micro averaged f measure of 0.782. While the final performance is similar over a wide range of values for , the training time varied widely, ranging from 511 min to 477 h, with smaller values requiring longer training times.

conclusion we have shown that p ltr successfully learns a mapping from disease name mentions to disease concept names, resulting in a significant improvement in normalization performance. We have also shown that the training time requirements are modest and that inference time is fast enough for use online. Our approach models many kinds of term variations, learning the patterns directly from training data. Our error analysis showed that NER is a continued concern, and the analysis of the learned weight matrix showed that morphological analysis is important for this problem. Our technique primarily addresses the candidate generation step in normalization, and could be paired with more sophisticated techniques for disambiguation. We believe that p ltr may prove to be sufficiently useful and flexible to be applicable to normalization problems in general while general applicability should be verified in future work, the present article represents an attempt to move toward a unified framework for normalizing biomedical entity mentions with machine learning.
