Motivation: whole genome high coverage sequencing has been widely used for personal and cancer genomics as well as in various research areas. However, in the lack of an unbiased whole genome truth set, the global error rate of variant calls and the leading causal artifacts still remain unclear even given the great efforts in the evaluation of variant calling methods. Results: We made 10 single nucleotide polymorphism and in del call sets with two read mappers and five variant callers, both on a haploid human genome and a diploid genome at a similar coverage. By investigating false heterozygous calls in the haploid genome, we identified the erroneous realignment in low complexity regions and the incomplete reference genome with respect to the sample as the two major sources of errors, which press for continued improvements in these two areas. We estimated that the error rate of raw genotype calls is as high as 1 in 10–15 kb, but the error rate of post filtered calls is reduced to 1 in 100–200 kb without significant compromise on the sensitivity. Availability and implementation: bwa mem alignment and raw variant calls are available at http://bit.ly/1g8XqRt scripts and miscellaneous data at https://github.com/lh3/varcmp.

introduction since the sequencing of the first personal genome (), and in particular the first genomes sequenced with the Illumina technologies (), resequencing has been widely used for personal and cancer genomics (), for the discovery of de novo mutations associated with Mendelian diseases (), for the reconstruction of human population history () and for the understanding of mutation processes (). In most of these studies, mapping based single nucleotide polymorphism snp insertion deletion in del calling plays a central role. The accuracy of the calls has a fundamental impact on the biological interpretation. In this context, various research groups have attempted to evaluate the performance of variant calling. The simplest approach to the evaluation of variant calling is to simulate variants and reads from a reference genome (). However, we are unable to simulate various artifacts such as the non-random distribution of variants, dependent errors, incomplete reference genome and copy number variations. An improved version is to incorporate real variants instead of using simulated variants (), but it does not address the artifacts caused by large scale effects either. A better simulation is to take the reads sequenced from one sample with a finished genome, map them to another finished genome, call variants and then compare the calls to the differences found by genome to genome alignment (). However, this approach is limited to small haploid genomes. There are attempts to apply a similar idea to mammalian genomes (), but as the mammalian reference genomes are frequently incomplete and the whole genome alignment is imperfect, such a simulation is still different from realistic scenarios. The difficulties in simulation have motivated us to focus more on real data. One simple approach is to thoroughly sequence a small target region with mature technologies, such as the Sanger sequencing technology, and take the resultant sequence as the ground truth (). It does not capture large scale artifacts, though. Another more commonly used method is to measure accuracy either by comparing variant calls from different pipelines, or by comparing calls to variants ascertained with array genotyping or in another study (). However, array genotyping is biased to easier portions of the genome and may have a higher error rate per assayed site than the variant calling error rate (); simply comparing call sets would only give us an estimate of the relative accuracy if two pipelines are affected by the same artifact that a third pipeline does not have, then the third pipeline will appear worse even though it is in fact better. In addition, comparative studies usually measure the accuracy with summary statistics such as the fraction of calls present in dbSNP or the transition to transversion ratio. They do not tell us the wrong sites. Many studies also experimentally validated typically up to a few hundred variants with mi seq or Sanger sequencing or Sequenom genotyping. Nonetheless, such experiments are biased toward easier regions and may also be subjected to other artifacts such as on primer variants and non-specific amplification (the 1000 Genomes Project analysis subgroup, personal communication). Calling heterozygotes from Sanger sequence data are also challenging by itself. In the author's view, it is better to evaluate variant calling by comparing samples from a pedigree (), or from the same individual (), including cancer samples (L  ower et al., 2012). Because we expect to see only tens to hundreds of somatic mutations or Mendelian errors per genome (), most other inconsistencies are likely to be errors. However, this method is insensitive to systematic errors. If at a locus, a caller finds erroneous heterozygotes in all samples, the errors would not be identified. After these efforts, we are still not clear about a basic question: the error rate of SNP and in del calling. Although a few papers give an estimate of one error per 100200 kb, it is either estimated on easy sites () or not sufficiently backed with published data (). In addition, only a few works () have attempted to identify the sources of errors. Analyzing systematic errors is even rarer, as most existing evaluation methods hide them. In this article, we use an exceptional dataset, sequencing data from a haploid human cell line, to evaluate the accuracy of variant calling. As the vast majority of heterozygous calls are supposed to be errors, we almost know the ground truth unbiased ly across the whole genome. We are able to pinpoint errors, investigate their characteristics, experiment filters and get a reasonable estimate of the error rate, not limited to non systematic errors. In addition to the unique dataset, our study also differs from many previous ones in the use of multiple read mappers, unpublished but well developed variant callers and caller oblivious genotyping and filtering.
