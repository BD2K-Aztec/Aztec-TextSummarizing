Motivation: Alignment of similar whole genomes is often performed using anchors given by the maximal exact matches (MEMs) between their sequences. In spite of significant amount of research on this problem, the computation of MEMs for large genomes remains a challenging problem. The leading current algorithms employ full text indexes, the sparse suffix array giving the best results. Still, their memory requirements are high, the parallelization is not very efficient, and they can not handle very large genomes. Results: We present a new algorithm, efficient computation of MEMs e mem that does not use full text indexes. Our algorithm uses much less space and is highly amenable to parallelization. It can compute all MEMs of minimum length 100 between the whole human and mouse genomes on a 12 core machine in 10 min and 2 GB of memory; the required memory can be as low as 600 MB. It can run efficiently gen-omes of any size. Extensive testing and comparison with currently best algorithms is provided. Availability and implementation: The source code of e mem is freely available at:

introduction maximal exact matches (MEMs) are exact matches between two sequences that can not be extended either way without introducing mismatches. MEM computation is a fundamental problem in string ology () and has important applications in sequence alignment. Closely related genomes are often aligned by using local similarities as anchors () and sufficiently long MEMs have been quite successfully used in this respect (). A theoretically optimal solution, in linear time and space, for the MEM computation problem is easily obtained using suffix trees (). However, suffix trees require large memory and practical implementations use highly engineered suffix trees (). Suffix arrays were introduced by Manber and Myers (1993) as a space efficient alternative to suffix trees and have replaced them in most applications. Enhanced suffix arrays were shown to solve all problems suffix trees could solve with the same theoretical complexity (). Suffix arrays still use a significant amount of memory, especially with the additional tables required to match the complexity of suffix trees (). When whole genomes are aligned, the memory required by the computation of all MEMs may become prohibitively high. The large popularity of whole genome alignment programs, most notably that of the MUMmer software (), attracted a lot of attention to the MEM computation problem, with the purpose of enabling the alignment of larger genomes within reasonable amount of memory. For example, one of the most reliable such programs, v match (), uses enhanced suffix arrays and its memory usage is very high. The idea of sparseness has been already used for suffix trees (K ark k ain en and) and it has been successfully employed for suffix arrays by in their sparse mem program. Their approach relies on indexing only every kth suffix of the given genome sequence (k is called sparseness factor) and is able to find MEMs faster and using less memory than previous approaches. It can serve as a drop in replacement for the MUMmer3 software package (). The approach of sparse mem has been enhanced by with a sparse child array for large sparseness factors and implemented in their es same m software. Our tests show that es same m is currently the best program for MEM computation in large genomes. Compressed indexes () have been used as well developed backward mem that uses a backward search method over a compressed suffix array. Recently, Fernandes and Freitas (2013) employed in slam em a new sampled representation of the longest common prefix (LCP) array that works with the backward search method of the fm index (). In spite of these advances, MEM computation remains a challenging problem for large genomes. The memory requirements of the current approaches remain high and very large genomes can not be effectively handled. We present a new algorithm, e mem that targets large genome sequences. e mem does not use full text indexes. Instead, hash tables are efficiently used in combination with several ideas to speed up the search. Our algorithm uses much less space and is highly amenable to parallelization. For example, it can compute all MEMs of *To whom correspondence should be addressed.  The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals permission soup com minimum length 100 between the whole human and mouse genomes on a 12-core machine in 10 min and 2 GB of memory; the required memory can be as low as 600 MB. It can run efficiently on genomes of any size. Extensive testing and comparison with currently best algorithms is provided. We have used for comparison traditional datasets, such as whole human versus mouse genomes and whole human versus chimp genomes, but also introduced a new test where two species of wheat, Triticum aestivum and Triticum durum are used. It turns out that only e mem and v match could handle these genomes. However, v match requires 57 GB whereas e mem can use less than 1 GB while being also faster. Our e mem software is implemented in C++ and OpenMP, is freely available, and can be used as a stand-alone program or as a drop in replacement for the MUMmer3 software package ().

conclusion e mem provides a practical solution for finding MEMs between arbitrarily large genomes. It uses much less memory than the currently available programs. It is freely available and it can be used as a stand-alone program or as a drop in replacement for the MUMmer3 software package (). MEMs are good anchors for closely related genomes. Otherwise, approximate matches are more suitable. The approach of e mem can be generalized to work with spaced seeds () in order to search efficiently for approximate matches. Highly sensitive multiple spaced seeds () of large weight are necessary and they can be designed using the approach of i lie and i lie (2007) by the SpEED program (). The exact matching procedure of index based algorithms is not well suited for finding approximate matchings.
