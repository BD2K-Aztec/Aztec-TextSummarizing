Motivation: The distribution of allele frequencies across polymorphic sites, also known as the site frequency spectrum (SFS), is of primary interest in population genetics. It is a complete summary of sequence variation at unlinked sites and more generally, its shape reflects underlying population genetic processes. One practical challenge is that inferring the SFS from low coverage sequencing data in a straightforward manner by using genotype calls can lead to significant bias. To reduce bias, previous studies have used a statistical method that directly estimates the SFS from sequenc-ing data by first computing site allele frequency (SAF) likelihood for each site (i.e. the likelihood a site has each possible allele frequency conditional on observed sequence reads) using a dynamic programming (DP) algorithm. Although this method produces an accurate SFS, computing the SAF likelihood is quadratic in the number of samples sequenced. Results: To overcome this computational challenge, we propose an algorithm, score limited DP algorithm, which is linear in the number of genomes to compute the SAF likelihood. This algorithm works because in a lower triangular matrix that arises in the DP algorithm, all non negligible values of the SAF likelihood are concentrated on a few cells around the best guess allele counts. We show that our score limited DP algorithm has comparable accuracy but is faster than the original DP algorithm. This speed improvement makes SFS estimation practical when using low coverage NGS data from a large number of individuals. Availability and implementation: The program will be available via a link from the Novembre lab website (http://jnpopgen.org/).

introduction a site frequency spectrum (SFS) describes the distribution of allele frequencies across sites in the genome of a particular species. The SFS is of primary interest in population genetics, as it is a complete summary of sequence variation at unlinked sites and its shape reflects underlying population genetic processes, such as growth, bottlenecks and selection. Moreover, a number of population genetic inferences can proceed directly from the SFS. For example, demographic history (e.g. evidence for population expansions, bottlenecks or migrations) can be directly inferred from the SFS [using, for example, dadi () or (. The SFS can also be compressed down to univariate summary statistics that form the basis of popular neutrality tests () that underlie many empirical genome wide selection scans (e.g.). Hence, inferring the precise SFS from genetic data is crucial in many population genetic analyses with the recent rapid progress in sequencing techniques, obtaining large scale genomic data from thousands to tens of thousands of individuals is practical (e.g. 1000) and this increased sample size enables us to conduct more accurate population genetic inference. However, current massively parallel short read sequence technologies also pose many inherent challenges for example, reads have high error rates, read mapping is sometimes uncertain and coverage is variable and in many cases low or completely absent. These challenges make accurate individual level genotype calls difficult and make some downstream analysis based on the inferred genotypes problematic. In a previous study (), we showed that the SFS computed from genotype calls (a call based estimation approach) is biased at low to medium coverage ( 10), whereas the SFS directly inferred from aligned short read sequencing data (a direct estimation approach) is unbiased even at low coverage. The direct estimation approach infers the maximum likelihood estimate (MLE) of the SFS by an EM algorithm () or a b royden fletcher goldfarb shan no (BFGS) algorithm (), assuming independence across all individuals and sites. Both of these algorithms are implemented in the an gsd software package (). Both of these algorithms require computation of the site allele frequency (SAF) likelihood for all sites. These vectors contain the likelihood that an allele for each possible allele frequency at a site (regardless whether monomorphic or polymorphic) conditional on observed sequence reads. Based on the precomputed SAF likelihoods, the MLE of the SFS is obtained by optimization, using either the EM () or the BFGS algorithm (). The bottleneck in obtaining the MLE of the SFS is computing the SAF likelihoods, rather than optimization. In fact, the maximization of the likelihood either by the EM or the BFGS algorithm takes only a small fraction of time compared with the computation of the SAF likelihood. This is because computation of the SAF likelihood at each site requires a summation over all possible genotype combinations for n individuals and naive computation of this sum has a runtime complexity of O3 n . To overcome this computational burden, Li (2011) proposed a dynamic programming (DP) algorithm to effectively compute the SAF likelihood for each site in On 2  and implemented this algorithm in the an gsd software. However, this algorithm is still not practical to use if there are large numbers of individuals, because it is quadratic in the number of genomes see for runtime). Moreover, this algorithm is numerically unstable for a large sample (). To solve this problem of computational inefficiency and numerical instability, we compute the SAF likelihood in a more efficient way that still retains the accuracy of the original DP algorithm. Our new method uses a combination of rescaling and sensible approximation to compute the SAF likelihood.

discussion a large sample size enables us to infer more precise summary statistics and parameters in many population genetic analyses. However, at the same time, we confront computational challenges with large samples and in many cases, we have to deal with these challenges to make the method practical with large sample sizes. We showed that although the direct estimation approach for computing the SFS can provide the unbiased SFS even at low coverage, it does not scale up to large sample sizes because the computation time for running this method is quadratic in a number of diploid individuals. To overcome this problem, we developed a new algorithm, called the score limited DP algorithm, and showed that the computation time for running this algorithm is linear in the number of genomes. This algorithm exploits the observation that for most sites the SAF likelihood's non negligible values are all concentrated on a few elements around the element corresponding to the best guess allele count. Therefore, we approximate this vector by curtailing computation to only a few components of the DP update vectors. More importantly be polymorphic, we only considered polymorphic sites for the SFS inferred from the BAM files and rescaled it so that all elements sum to 1. (B) Relative deviation of a fraction of sites with the derived allele count of 120. We computed the relative deviation of the SFS inferred from the BAM files compared with the SFS computed from the VCF file in each derived allele frequency bin i=2n. (C) tajima s D comparison this algorithm can adaptively choose the bandwidth d during updating the SAF likelihood for each site. We showed that the bandwidth change is robust to sequencing coverage and the variation of the SAF likelihood. We also showed that the EM combined this new algorithm has comparable accuracy but is 8-fold faster than the original DP combined with the EM algorithm when analysing the data from 1000 individuals. Our new algorithm's improvement in speed makes it possible to directly estimate the SFS from very large samples of low coverage short read sequencing data. Our score limited DP algorithm could be applied to other DP algorithm whose runtime is quadratic in a sample size. For example proposed an empirical Bayes approach to estimate a posterior probability of a minor allele frequency (MAF). They used a DP algorithm to effectively compute summation over all possible genotype configurations for n diploid individuals, and therefore this algorithm has a runtime complexity of On 2  similar to the DP algorithm introduced here. Furthermore, similar to the distribution of the SAF likelihood, the distribution of the posterior probabilities of the MAF is unimodal and most of the probabilities are close to 0. Therefore, we can apply our score limited DP algorithm for this DP algorithm to reduce runtime complex it iy to be O(dn) rather than original On 2  where d is the maximum bandwidth. Our score limited DP algorithm can also be directly applied to speed up estimation of the 2D sfs derived the EM algorithm to get the MLE of the 2D SFS as an extension to the 1D SFS estimation, and this requires precomputation of the SAF likelihoods for all sites for each population independently. This implies that we can make this method faster with the score limited DP algorithm compared with the original DP algorithm. The computation time for running the original algorithm is On 2 1  n 2 2 , whereas the runtime of the score limited DP algorithm becomes Od 1 n 1  d 2 n 2 , where n 1 , n 2 represent a sample size for each population and d 1 , d 2 are the maximum bandwidth. One might argue that uncertainty associated with genotype calls can be overcome by simply increasing sequencing coverage and there is therefore little need for algorithms that handle low coverage data. However, cost constraints require difficult choices between increasing sample size and increasing coverage. There are certain cases where one prefers a large sample of low coverage sequencing data over a smaller sample size with high coverage. For example, in genome wide association studies, one can obtain more power by sequencing a large number of individuals at low coverage (). As another example, identification of rare variants always requires large sample sizes, and moderately rare loci will be detectable even with low coverage data. Finally, even though sequencing cost keeps dropping, cost constraints will not disappear because users will continue to work with limited budgets and push these limits with applications involving very large numbers of individuals; thus we expect low coverage sequencing will remain an attractive approach for many investigators and that methods like ours will retain their appeal for the foreseeable future.
