Computational pipelines are common place in scientific research. However, most of the resources for constructing pipelines are heavyweight systems with graphical user interfaces. ruff us is a library for the creation of computational pipelines. Its lightweight and unobtrusive design recommends it for use even for the most trivial of analyses. At the same time, it is powerful enough to have been used for complex workflows involving more than 50 interdependent stages. Availability and implementation: ruff us is written in python. Source code, a short tutorial, examples and a comprehensive user manual are freely available at

introduction large scale computational analyses are now integral to many biological studies. 'Workflow' management systems have accordingly proliferated, including Taverna (), bio pipe () and Pegasys (). These are highly featured, designed for automated and robust operation even by non expert users, managed using graphics user interfaces and specified in XML or proprietary domain specific languages. However, these workflow systems can be too cumbersome for explorative and empirical studies with novel datasets. The appropriate scientific approach can not always be determined a priori. On the other hand, the advantages of computational pipelines over ad hoc scripts, even for simple tasks, are all more apparent with increasingly complex datasets and the use of parallel processing. The standard Unix build (software construction) system 'make' has been widely used to keep track of dependencies in scientific pipelines. makefiles specify the files names of data for the input and output of each stage of a pipeline as well as the 'rules' (commands) for generating each type of output from its corresponding input. The entire pipeline is represented by a statically inferred dependency (directed acyclic) graph for the succession of data files. The same 'rule' can be applied to multiple data files at the same time, for example, to run BLAST searches on many sequence files in parallel. Automatic data tracking in pipelines allows only the out of date parts of the analyses to be rescheduled and recalculated, with minimal redundancy. This is necessary when parts of the pipeline are subject to rapid cycles of development or where the underlying data is being generated continually. Unfortunately, 'make' is not a good fit for the design of scientific pipelines. 'Make' specifications are written in an obscure and limited language. (This is mitigated in 'make' replacements such as 'scons' or Ruby 'rake'). Pipeline dependencies are not specified directly but inferred by the 'make' program by linking together 'rules' in the right order. This means that scientific pipelines can be difficult to develop, understand and debug. so called 'embarrassingly parallel' problems are particularly common in bioinformatics; examples include BLAST and HMMer searches of sequence databases, or region by region genome annotation. The number of parallel operations needed varies at 'runtime' with the presented data: a larger sequence file might be split up into smaller fragments to be processed in parallel. However, 'make' systems and their kin require all operations in a pipeline to be determined when the build script is analysed, because of the reliance on static, pre-calculated dependency graphs. They can not easily deal with, for example, the splitting up of large problems into smaller fragments to be computed in parallel, if the number of such fragments depends on the input data and runtime conditions, and can only be determined in the middle of running the pipeline. In this article, we present a new lightweight library for computational pipelines that explicitly supports these programming tasks. Some of its main advantages of ruff us are bullet ruff us configuration files are normal Python scripts. Python is a modern dynamically typed programming language known for its elegance, simplicity, and that is already widely used in the bioinformatics community (). Standard Python tools can be used to develop and debug ruff us scripts bullet Like 'makefiles', ruff us scripts can run only the out of date parts of the pipeline, using parallel processing if appropriate bullet Pipeline dependencies are specified explicitly for maximal clarity and ease of documentation. @BULLET A flowchart of the pipeline can be printed out in a variety of graphical formats. Detailed trace output is available, documenting which operations are up-to-date or will be run ().

conclusion ruff us is a python library for programming computational pipelines with lightweight, unobtrusive syntax. It provides all the power of traditional build systems such as automatic data tracking, but in a modern package suited to the needs of bioinformatics. Sample flowcharts of ruff us pipelines, a tutorial, a detailed manual as well as source code are freely available from http://www.ruffus.org.uk and http://code.google.com/p/ruffus.
