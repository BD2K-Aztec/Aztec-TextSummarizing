Motivation: In complex disorders, independently evolving locus pairs might interact to confer disease susceptibility, with only a modest effect at each locus. With genome wide association studies on large cohorts, testing all pairs for interaction confers a heavy computational burden, and a loss of power due to large bonferroni like corrections. Correspondingly, limiting the tests to pairs that show marginal effect at either locus, also has reduced power. Here, we describe an algorithm that discovers interacting locus pairs without explicitly testing all pairs, or requiring a marginal effect at each locus. The central idea is a mathematical transformation that maps statistical correlation between locus pairs to distance between two points in a Euclidean space. This enables the use of geometric properties to identify proximal points (correlated locus pairs), without testing each pair explicitly. For large datasets (âˆ¼ 10 6 SNPs), this reduces the number of tests from 10 12 to 10 6 , significantly reducing the computational burden, without loss of power. The speed of the test allows for correction using permutation based tests. The algorithm is encoded in a tool called RAPID (RApid Pair IDentification) for identifying paired interactions in case control g was. Results: We validated RAPID with extensive tests on simulated and real datasets. On simulated models of interaction, RAPID easily identified pairs with small marginal effects. On the benchmark disease, datasets from The Wellcome Trust Case Control Consortium, RAPID ran in about 1 cpu hour per dataset, and identified many significant interactions. In many cases, the interacting loci were known to be important for the disease, but were not individually associated in the genome wide scan.

introduction recent technological developments in sequencing and genotyping have made it feasible to conduct genome wide scans of large population cohorts to find genetic markers for common diseases (The Wellcome). Nevertheless, significant challenges remain. Many genome wide association * To whom correspondence should be addressed studies gw ass seek to associate each marker with the disease phenotype. As multiple hypotheses are generated, individual associations must have large effect to show up as significant. In complex disorders, many independently evolving loci might interact to confer disease susceptibility, with only a modest effect at each locus. Here, we focus on detecting such interactions. Detecting k locus interactions in g was on large populations is computationally and statistically challenging, even when k = 2. A test involving all pairs of m markers, with a case control population of n individuals, involves on m 2 ) computations. For g was it is not a typical to have n  10 3 , m  10 6 making these computations, especially with permutation based tests of significance, intractable. A straightforward bonferroni like correction for the multiple tests would result in significant loss of sensitivity. Therefore, many strategies for two locus interaction testing are based on a two stage filtering approach. In the first stage (the filter stage), the objective is to discard the vast majority of locus pairs, while retaining the truly interacting pairs. If the filtering stage is fast and efficient (only a small fraction of all pairs are retained), then computationally intensive tests of association can be performed on the few remaining candidate pairs in a second, scoring, stage. For a filtering algorithm to be effective, it must have (a) speed, in that the number of computations scale linearly with the size of the data; (b) sensitivity power (truly interacting pairs are retained); and, (c) efficiency (most pairs are discarded). Fast and efficient filters allow non-parametric permutation tests to be employed to assess significance. With the advent of deep sequencing, the number of variants considered will grow far beyond 10 6 markers, and designs of filters will be critical to g was analysis of interactions. While many approaches to detecting interactions have been proposed (see, for an excellent review), the design of filters has not been investigated explicitly. A recent approach, both pragmatic and effective for filtering, is based on the assumption that interacting pairs of loci should also show a marginal effect at each locus (). Here, the filtering stage consists of single marker tests at each locus. The scoring stage is then limited to pairs in which either one, or both loci, are individually associated. In either strategy, the filter speed is high, as single marker analysis scales linearly with the number of loci and individuals. Empirical results show that only a small fraction of the loci show a marginal effect, leading to high efficiency. However, as Marchini et al. point out, there is some loss of power in employing these filters, particularly in interaction models where the marginal effects of the individual loci are small provides a cartoon into the same bin with higher probability, relative to non-interacting pairs x,z. (d) Pairs that fall in the same bin K consecutive times in one of L trials are selected. illustration of such confounding interactions. Here, compensating mutations in coding SNPs (T and G, or A and A) allow the encoded proteins to interact, but individual mutations destroy the lock and key mechanism. Therefore, the locus pair (x,y) will show strong association, but there is no marginal effect at either locus. We tackle this case. In this article, we describe a filtering strategy, Rapid (RApid Pair IDentification). Under certain assumptions, the algorithm provides explicit guarantees on speed, efficiency and sensitivity. To formalize the argument, we parametrize the total computation for n individuals and m markers. Let input parameter  denote the desired false negative rate of detecting interactions. Rapid performs at most  1 m 1.07 tests, and allows no more than  2 m 1.07 ln(1/) pairs by chance, while capturing a fraction 1 of the truly interacting pairs. The surviving pairs can be tested for interaction using a total of on m 1.07 ln(1/)) computations. This can be compared with the time of on m 2 ) when no filtering is employed. For g was where m 10 6 , this results in several orders of magnitude speed up. Additionally, increasing desired sensitivity 1 incurs only modest increases in running time. Extensive power simulations demonstrate the power of our approach. We also used Rapid to reanalyze data from The Wellcome Trust Case Control Consortium wtc cc dataset, a benchmark g was. The filtering using Rapid on either dataset only took about 45 min on a 1.8 GHz, 16 GB RAM computer and identified many significant interactions.
