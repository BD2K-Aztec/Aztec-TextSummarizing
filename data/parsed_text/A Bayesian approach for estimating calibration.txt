Motivation: Immunoassays are primary diagnostic and research tools throughout the medical and life sciences. The common approach to the processing of immunoassay data involves estimation of the calibration curve followed by inversion of the calibration function to read off the concentration estimates. This approach, however, does not lend itself easily to acceptable estimation of confidence limits on the estimated concentrations. Such estimates must account for uncertainty in the calibration curve as well as uncertainty in the target measurement. Even point estimates can be problematic: because of the non-linearity of calibration curves and error heteroscedasticity, the neglect of components of measurement error can produce significant bias. Methods: We have developed a Bayesian approach for the estimation of concentrations from immunoassay data that treats the propagation of measurement error appropriately. The method uses Markov Chain Monte Carlo (MCMC) to approximate the posterior distribution of the target concentrations and numerically compute the relevant summary statistics. Software implementing the method is freely available for public use. Results: The new method was tested on both simulated and experimental datasets with different measurement error models. The method outperformed the common inverse method on samples with large measurement errors. Even in cases with extreme measurements where the common inverse method failed, our approach always generated reasonable estimates for the target concentrations.
INTRODUCTIONImmunoassays are measurement techniques based on the interaction between a selective antibody and its target antigen. The basic principles of immunoassays were introduced in 1945 * To whom correspondence should be addressed.(), and the first application of immunologically based technology (radioimmunoassay) was reported in the late 1950s (). Since then, immunoassays have become a primary diagnostic and research tool within the medicine and life sciences. Compared to other analytical methods, immunoassays provide a rapid, simple, economic, highly specific and sensitive analysis with high throughput and adaptability to field use [reviewed in (. Immunoassays do, however, have limitations. These include interference from matrix compounds used to stabilize the samples, cross reactivity to structural analogs and poor scalability for many multi-analyte applications. Several different types of labels have been used in immunoassays, including radiolabels, enzymes, fluorescent, luminescent and phosphorescent labels. The most common labels for clinical and research studies are enzymes and colorimetric substrates. The approach used most frequently for the analysis of immunoassay data is performed in two steps on two sets of samples, the standards and the target samples. In the first step, standard analyte samples are prepared at known concentrations, and used to estimate a calibration curve, typically by non-linear least squares, relating concentrations to measurements in the system. In the second step, the unknown concentrations are determined by inverting the calibration curvefinding the concentration on the standard curve that produces the same response as that obtained from the unknown sample (). The calibration curve itself is only estimated with error: a limited number of samples can be used in an assay, and the true curve must be inferred from a limited number of noisy responses. This task is accomplished by selecting a family of mathematical functions, parameterized by a small number of parameters that is capable of fitting the variety of calibration curves encountered. Previous work has shown that the five-parameter logistic family provides a very good fit under most practical conditions (). The parameters of the function are fitted to assay data, assuming some model for the variance of the measurement error, using non-linear least squares. Contemporary computers handle such computationally intensive algorithms very easily, although issues of convergence to false minima and failure of convergence altogether cannot be ignored. Most fitting algorithms will fail with injudicious initial guesses or in cases where the variance of the measurement error is large or modeled improperly. Upon reading off unknown concentrations by inverting the calibration model, however, serious challenges can arise.Page: 708 707712The common methods widely implemented by many commercial software products do not account for calibration uncertainty. This neglect can lead to significant underestimation of error in the estimated target concentrations, and to bias in the point estimates, particularly at concentrations at the ends of the calibration range. Response data in immunoassays are generally heteroscedastic: their variances are not constant across the range of concentrations measured. It is common for the variances of standards at the upper end of the response curve to be 3 or 4 order of magnitude larger than those at the lower end. Heteroscedasticity is typically incorporated into the statistical model by assuming that the variance is proportional to some power of the mean response. Denoting the variance by  2 and the mean by , we have
F.Feng et al.where  is a scale parameter and a function of magnitudes of the response, the exponent  is usually a number between 1.0 and 2.0 (). Variances in response measurements at the extreme ends of the calibration curve can place sample measurements above or below detection limits; these measurements are typically discarded.(and Supplementary) illustrates some of the challenges encountered when using the common inverse method for estimating concentrations of unknown samples. It shows data on interferon  (IFN-) concentrations measured by enzyme-linked immunosorbent assay (ELISA). The first part is standards data, which were used to fit a five-parameter logistic calibration curve by the non-linear least squares regression. Then the sample measurement data were used to estimate unknown concentrations by inverting the calibration function. The unknown sample data contain three samples of unknown concentration of interferon- (IFN-). Each sample was measured either undiluted or 1:10 diluted in duplicates. Undiluted sample 1 and 2 contains about 32 and 22 pg/ml IFN-, respectively. The 10-time diluted sample 1 and 2 were recorded as 'ND*' (nondetectable) and no estimation of concentration was given, even though samples generated optical density (ODs) larger than the lowest value in the system. In case of sample 3, one replicate of the sample was measured to contain about 2 pg/ml IFN-, while all other three measurements gave no estimation of concentrations, even though OD values consistently showed decline from undiluted samples to 1/10 diluted ones and were higher than the lowest OD values in the system. As can be seen in our experimental data, sample 3 is not an extreme case, but rather is typical of the data for some cytokines, especially those of important functions such as tumor necrosis factor- (TNF-), interferon- (IFN-), etc. This is also true for other types of analytes. For example, in measurements of allergens or carcinogens, even low concentrations can be important (). Furthermore, some of 'the low extreme cases' are not biologically low, but rather low relative to the machine or kit reagent detection limits. Moreover, the extreme cases with high or low concentration of target analytes are usually associated with abnormal states of the system, such as diseases or activation/inactivation of cells, and are of great research interests. For example, during a septic shock, the concentration of the proinflammatory cytokine interleukin-6 (IL-6) can go up to more than 12 000 pg/ml in the blood (), but the Bio-Plex Pro 23-plex Assay [low photomultiplier tube (PMT) setting] (BioRad) can only detect up to 2100 pm/ml of this cytokine, which is about 6-fold lower (Supplementary). Clearly, a better strategy is necessary to gain more information from those extreme values of samples. In Bayesian statistical modeling, inference about unknown parameters model is based on the fact that their uncertainty of them is described by the posterior density conditional on observed data. Before data collection, a prior distribution is used to describe parameter uncertainty. After obtaining data, this prior information is combined with information present in the data through the likelihood function and Bayes' rule to obtain the posterior distribution, from which parameter estimate summary statistics are computed. Bayesian methods have been widely used in many biomedical applications and have proven useful for accounting for multiple sources of uncertainties arising from experimental variation, instrumental noise, etc. In addition, they do not require point estimation or linearization of variations, either of which can underestimate the uncertainties in non-linear models (). They have been employed successfully for data analysis in microarray studies, PCR amplification curves, serial dilution assays and fluorescence chemistry (). In the case of immunoassay data analysis, the likelihood function and posterior distribution automatically incorporate suitable variations arising from the use of multiple hybridization probes of different lengths and composition. For serial dilution assays, the Bayesian approach has been shown to generate reasonable estimates at very low and very high concentrations of the calibration curve, without discarding extreme data as being below or above the detection limits.
Page: 709 707712
Bayesian approach for immunoassay data analysisIn thisarticle, we report the use of a Bayesian approach to generate calibration curves and estimate unknown concentrations in immunoassays such as ELISA and Luminex assays. The Markov Chain Monte Carlo (MCMC) method is used to generate samples from the posterior distribution for the parameters and unknown concentrations jointly. Compared to the common approach, our proposed approach allows (i) an acceptable estimation of uncertainty in the concentration estimates via credible intervals; (ii) a better use of data points with large variances (especially the very low and very high concentrations) without discarding those as being 'beyond detection limits'. The proposed Bayesian approach is validated using both simulated and experimental data. We have also implemented the method in simple-to-use software, which is freely available to the research community.
METHODS
The modelThe model relating the expectation of measured values to the underlying concentrations is the five-parameter logistic function family (),where x denotes the unknown sample concentration,  is the vector of parameters with components A, B, C, D and E. This model has been shown to improve performance on assays with asymmetric calibration curves, over the simpler and widely used symmetric four-parameter logistic function (). For the error model, we assume that the log transformation regularizes the variance. This assumption is borne out by analysis of both Luminex and ELISA data for 22 murine cytokines; a constant variance model provides a good approximation with the transformed data. (Supplementary). The error model, therefore, is,2,....n; j = 1,2,...k;where y ij is the j-th observed measurement of the i-th sample, x i is the i-th concentration,  is the parameter vector and f (x i , ) is the five-parameter logistic function as in Equation(2),  2 is the constant random variance, n is the number of calibration points and k is the number of replicates in each calibration point. The following diffuse prior distributions are used: A,B,C  Log-N(0,10 2 ), D  Log-N(0,10), E  Log-N(0,10),the log-normal distribution (Log-N) is used here to keep parameters A, B and C positive. D is a negative number usually larger than 1. When E is 1, the five-parameter logistic function becomes the four-parameter function, which is a good model for many symmetric calibration curves. The variances for the log-normal are set so to make the prior distribution diffuse/non-informative. Other diffuse distributions (such uniform or inverse gamma distribution) can be used as well. Given the amount of standards data in a typical immunoassay, the posterior distributions of these parameters can be well identified.
Estimation by MCMCWe use MCMC to draw samples approximating those drawn from the true posterior distribution, and in particular use the MetropolisHastings algorithm implemented as follows.(1) Choose starting valuesStarting values are set by rough estimation from the standards data. A 0 is set to be the maximum observed measurement, B 0 to be the minimum one and C 0 to be the mean concentration value from sample data (), D 0 is a negative small number (1.0) and E 0 and  0 are positive small numbers (1.0 and 0.1, respectively). x 0 is selected using crude estimates based on observed measurements and standards data.(2) Based on current parameters from previous steps, generate new candidate parameters,and x*, from appropriate proposal distributions. A simple random-walk algorithm is used to generate new candidate parameters from the normal distribution centered on the current value of  as the proposal distribution. To generate new candidate parameters,where  2  and  2 x are proposal variances. An important practical issue in this step is the scaling of the random walk density. If the proposal variance of the algorithm is too large, most steps will move into tails of the distribution and will be rejected. On the other hand, if the variance is too small, the autocorrelation in the sequence of accepted draws will be high and convergence to the target distribution will be slow. So in our implementation, small MCMC trials with different values of  are applied to search for an appropriate proposal variance until the acceptance rate is approximately 1550% ().,2,...n+k.where Xs and Ys are calibration data, y is the response measurement whose concentration is to be estimated, K is a constant, n is the number of calibration data points, k is the number of replicates for the response measurement.((5) Return to step 2. Following a sufficient burn-in period, the chain approaches its stationary distribution and samples from the MCMC closely approximate ones from the posterior distribution of parameters and unknown concentrations. Finally, the posterior means and independent 95% credible intervals from the posterior marginal densities are computed.
ImplementationThedistribution. The Windows version of the program has a simple and intuitive graphical interface.shows a screenshot of the software, Baesc, and illustrates its various components. The input of the program is through data files. The fitted calibration curve as well as the diagnostic trace plot and validation plot are displayed on the interface. The results are written to files with parameters and estimated concentrations. The Linux and Macintosh version of the program are run in command line and generate output files allowing further analysis such as MCMC diagnostics, hypothesis testing and the fitting of models for biological processes that regulate the concentration of the assayed analytes.
RESULTS
Simulated dataIn order to validate the approach and test the software implementation, we first ran tests on simulated data. Two types of simulated data following either the equal variance or unequal variance model were generated. To simulate data with equal variance, we followed the model below,, n = 8, and k = 4. The parameters were chosen based on experimental data of IL-1 cytokine measured in a Luminex assay in our lab (see Supplementary). Ten concentrations were selected starting at 1.0 to represent levels typical for the assay(c),  = 0.5; (d), (e) and (f),and (g), the curve fitting using the Bayesian approach. The black dotted line is the real logistic function used to simulate the data. The gray dashed lines are the fitted calibration curves by the implemented software using the Bayesian approach. The calibration curves were fitted 25 times and plotted on the same graph. The open circles are the simulated standard data points used for the calibration curve estimation. (b), (e) and (h), the validation of unknown concentration estimation using the Bayesian approach. The graph is on a logarithmic scale, and the dotted line displays the true concentrations. The circle points are the estimated unknown concentrations with 95% error.(i), the validation of unknown concentration estimation using the common inverse approach. The triangle points are the estimated unknown concentrations by the common inverse approach. ('NA' means no estimation because below/above detection limits.). The Bayesian estimate were closer to the line as the data variance went bigger and also gave reasonable estimates at the extreme low measurements, with the common inverse method failing by giving no estimate. (See Supplementaryfor results on simulated data with  of 0.95 and 0.001). The non-linear least squares regression was done in R software (R Development Core Team, 2006). data. For each concentration, there were four replicates of simulated measurements. The constant variance  2 with different values was used to test the robustness of the proposed algorithm. As shown inand Supplementary, different values of variance  2 were used for simulation, and data were used for analyses by our approach as well as the common inverse approach for comparison purpose. The variances used for simulation were 0.95 2 , 0.5 2 , 0.1 2 , 0.01 2 and 0.001 2 with the real variance value at a level of 0.01(0.1 2 ) as determined from experimental data. The results showed that with low measurement errors (small  2 )Page: 711 707712The standards data were simulated with equal variance models based on a five-parameter logistic function with different variance levels as in. The Bayesian approach and the non-linear least squares regression were used to estimate the five-parameter calibration curve, and SSEs were calculated for comparison. The non-linear least squares regression was done using the R software (R Development Core Team, 2006). both approaches worked well on estimation of the calibration curve and unknown concentrations. With a small variance, although the common inverse method generated a more precise calibration curve with smaller sum square errors (SSE;), it failed on estimation of extreme measurements. When the variance became bigger, our Bayesian approach had a better performance on estimation of the calibration curve (smaller SSEs) and unknown concentrations (closer to their true values and no 'below/above detection limit' values at ends of the curve with extreme concentrations). The Bayesian approach was also applied to simulated data with an unequal variance model. The model to generate data was similar to Equation (7), but following an unequal variance function (),
Bayesian approach for immunoassay data analysiswhere  is a scale factor,  is the power of the mean responses,, n = 12 and k = 4. The parameters were based on the experiment data of an ELISA assay in. The simulated data contained 12 concentrations, each with 4 replicated measurements representing levels typical for assay data.  is the average noise level. In the simulation, it was set to be 0.1 [the actual  value in the example data (, 0.3 and 0.5.  usually is very nearly 1 for most immunoassays (). When  = 0, the variance model [] reduces to an equal-variance model as we tested in the above section; When  = 1, the variance is proportional to the response; When  = 2, the coefficient of variation of the response is constant (). In the simulation, different values of  (1.0, 1.5, 2.0 and 4.0) were tested to compare the proposed approach with the common inverse approach.displays the results of the Bayesian analysis and the common inverse approach on simulated data generated by the unequal variance model. The two panels show results for data generated using  of 0.3 and 0.5 (see Supplementaryfor  = 0.1). For each , different 's were used to test the performance of the two approaches. We found that the Bayesian procedure was able to produce very good estimates for the unknown concentrations even on the data with unequal variances, indicating that the equalvariance approximation in this context was reasonable. Furthermore, compared to the common inverse approach, it worked betterTwelve concentrations starting at 0.1025 were used, and four replicated measurements were simulated for each concentration. Different values of  and  were used to compare the performance of two approaches, with panel (i)  = 0.3 and panel (ii)  = 0.5 (see supplementaryfor extreme measurements. On all simulated data we tested, the common procedure gave no estimates ('NA' as below detection limits) at either very high or very low responses, whereas the Bayesian estimates were reasonable and provided appropriately large uncertainties.
Experimental dataThe Bayesian inference approach was also applied on experimental data generated from ELISA and Luminex assays.shows results for two cytokines, TNF- by Luminex and IFN- by ELISA. The results showed the curve fitting of estimated parameters and validation of estimated concentrations by the Bayesian approach. From the graph, we can see that our approach worked very well with fitted calibration curves and good estimations of unknowns. We also compared the Bayesian inference with the common inverse approach on 20 other cytokines measured by ELISA or Luminex assays (Supplementary). These results consistently indicated that the Bayesian estimates were more reliable than those of the Page: 712 707712common inverse approach (Supplementary), especially for samples with very high and very low concentrations. In summary, our Bayesian method produced better results than the common inverse approach on both equal and unequal variance simulated data and biological experimental data. The Bayesian method was especially good at processing noisy data. This is significant considering the prolific use of immunoassays and the fact that even realistic experimental concentrations can carry high variances. The experimentally relevant variance values for the logarithmic transformed data are 0.01 ( 2 = 0.1 2 ) based on our observations as well as others (). This level of variance is equivalent to the coefficient of variation (CV) of 10% for the non-transformed data. The commonly accepted reliability criteria for immunoassays is set as an intraassay CV <20% (). A dataset with this CV value has a variance of about 0.2 2 ( 2 = 0.2 2 ) after the natural logarithmic transformation. As shown in, at the level of  2 = 0.2 2 and above, our approach outperforms the non-linear least squares with a smaller SSE. Furthermore, depending on the type of assays and the manufacturer of kit reagents, the proportion of measurements with an intraassay CV >20% can go up to 25% (). Clearly methods such as our Bayesian approach are necessary to those data with high variances, where the normal approach could fail. Furthermore, the proposed Bayesian approach can be easily extended for a wide range of applications. For example, the proposed model by the Bayesian approach with its estimated uncertainty in calibration curves and target measurements can be used as a lower level in the hierarchical Bayesian models () that integrate a sampling likelihood to compare cytokine concentrations across treatment groups, measurements on different experiment days or even with different assays. Such a model would correctly incorporate the calibration uncertainties and benefit the following inference. Another possible application is the Bayesian non-parametrics (such as mixtures of Polya trees) () to further relax assumptions on the prior distributions of parameters of the model.
F.Feng et al.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
