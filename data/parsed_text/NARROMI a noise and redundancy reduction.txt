Motivation: Reconstruction of gene regulatory networks (GRNs) is of utmost interest to biologists and is vital for understanding the complex regulatory mechanisms within the cell. Despite various methods developed for reconstruction of GRNs from gene expression profiles, they are notorious for high false positive rate owing to the noise inherited in the data, especially for the dataset with a large number of genes but a small number of samples. Results: In this work, we present a novel method, namely NARROMI, to improve the accuracy of GRN inference by combining ordinary differential equation-based recursive optimization (RO) and information theory-based mutual information (MI). In the proposed algorithm, the noisy regulations with low pairwise correlations are first removed by using MI, and the redundant regulations from indirect regulators are further excluded by RO to improve the accuracy of inferred GRNs. In particular, the RO step can help to determine regulatory directions without prior knowledge of regulators. The results on benchmark datasets from Dialogue for Reverse Engineering Assessments and Methods challenge and experimentally determined GRN of Escherichia coli show that NARROMI significantly outperforms other popular methods in terms of false positive rates and accuracy. Availability: All the source data and code are available at: http://csb.
INTRODUCTIONA major issue in systems biology is to construct and understand the gene regulatory networks (GRNs), which explicitly characterize regulatory processes in the cell (). The development of high throughput technologies has produced tremendous amounts of gene expression data, which provide insights into the underlying regulatory mechanism of cellular machines (). The reconstruction or 'reverse engineering' of GRNs, which aims to dissect the underlying network of gene-gene interactions from the measurement of gene expression, is still a challenging task (). For this reason, the Dialogue for Reverse Engineering Assessments and Methods (DREAM) project was established to encourage researchers to develop new efficient computation methods to infer robust GRNs (). Recently, various approaches have been developed to infer GRNs from gene expression data with the motivation of improving the accuracy and scalability of network inference (). In general, these GRN inference methods fall into two categories, namely model-based approaches and machine learning-based approaches (). For the model-based methods, chemical reaction of transcription and translation, as well as other cellular processes are described as linear or non-linear differential equations, in which the parameters represent the regulation strengths of the regulators. Representative algorithms in this category include multiple linear regression (), singular value decomposition method (di), network component analysis () and linear programming (LP) (). For the machine learning-based approaches, the network is inferred through measuring the dependences or causalities between transcriptional factors (TFs) and target genes (). Popular methods in this category include partial correlation coefficient (), Bayesian network analysis (), mutual information (MI) () and conditional mutual information (CMI) (). As one of the most popular methods, MI has been widely used to construct GRNs because it provides a natural generalization of correlation owing to its capability of characterizing non-linear dependency (). Furthermore, MI is able to deal with thousands of variables (genes) in the presence of a limited number of samples (). Despite these advantages, MI fails to distinguish indirect regulators from direct ones, i.e. it tends to overestimate the number of regulators targeting the gene. In a GRN, the indirect regulations are the main source of false positives. Although some methods have been developed recently to remove these redundant indirect regulations, such as CMI () and CMI-based path consistensy algorithm (PCA-CMI) (), the high computational complexity makes them infeasible while calculating the high order MIs. Another limitation of MI is that it only describes the correlation between two genes but is unable to determine the regulatory directions. Different from the methods based on information theory, the model-based methods have the advantage of describing the regulatory dynamics and detecting the direction of regulations (). Furthermore, prior information, such as experimentally verified regulations, can be easily included in these models to improve the accuracy of network inference (). Moreover, model-based methods are found useful to remove possible redundant indirect regulations by forcing sparseness on the model (), such as the shortcut removing technique that has been proved to be efficient in GRN inference (). In this work, we propose a novel method, namely NARROMI, to improve the accuracy of GRN inference from gene expression data using a noise and redundancy (NAR)reduction technology by combining ordinary differential equation (ODE)-based recursive optimization (RO) and informationtheory based MI, and therefore it has the advantages of both model-based and machine learning-based methods. Specifically, the noisy regulations and partial significant indirect regulations can be firstly deleted and filtered using MI as a measure of dependence, and the redundant (indirect) regulations are subsequently removed gradually by the RO algorithm, thereby reducing both false positives and false negatives. In addition, our method can determine regulatory directions without prior information of regulators. The results on simulation datasets from DREAM challenge () and experimentally confirmed network () in Escherichia coli with real gene expression data () show that our method significantly outperforms other popular methods in terms of false positives and accuracy.
METHODSIn general, the transcription process can be described by a mathematical model with differential equations based on mass action kinetics and MichaelisMenten kinetics. However, the noise inherited in the data can decrease the performance of these models. Therefore, we present a new method NARROMI, which first reduces noisy regulations with MI and then uses RO technique to reduce redundant and indirect regulations gradually in the optimization model. The details of NARROMI can be found below.
Mathematic model of transcription procedureDuring transcription, TF(s) binds to DNA sequences so as to recruit RNA polymerase II onto promoter region of DNA to initiate the transcription procedure (), which can described as follows.where c is the number of TFs that are regulators of gene i (i  1,2,. .. , n), the stoichiometric coefficient j i , j  1,2,. .. , c, represents the effective abundance of TF j involved in the regulation of gene i, DNA i is the sequence of gene i, and k 1 , k 1 , respectively, denotes the rate constant of forward reaction and reverse action. DNA i TF 1  1 iwhere k s , s  1, 1, 2, 3, are the rate constants of reactions. According to the mass action law, the concentration changes ofRPII and mRNA i can be described with following differential equations.Assuming that (4) and (5) quickly reach an equilibrium state, i.e.RPII=dt  0 and dmRNA i =dt  0, we can get, 2,. .. , m, and y i t / Q c j1 A j t j i. With a logarithm transformation, the above model can be described as a log-linear model logy i t=y i 0  j i P c j1 log A j t=A j 0   . Let y t i  logy i t=y i 0 and X t j  log A j t=A j 0   where y t i represents the expression level of gene i at time t, and X t j represents the activity of TF j at time t, we get a linear model below by dropping t for simplicity. y i  i X, i  1, 2,. .. , n,, n is the number of target genes, c is the number of TFs and m is number of samples.
ROFor a target gene with expression level y, we intend to define a regulation matrix that fits well with the experimental data. can be resolved by minimizing the error between inferred and observed expressions, i.e.where X is the expression matrix of candidate TFs, and is a positive parameter that balances the error and sparse term in the objective function. As TF activity can be approximated by the expression level of the gene encoding the TF, we suppose the gene expression level as the TF activity here. The model (6) is equivalent toi  1, 2,. .. , m, j  1, 2,. .. , c, where u i , v i , j , j ! 0. Then model (7) can be written as a standard LP model as follows. min ui, vi, j, jThe above LP model (8) can be solved efficiently by any LP software such as GLPK LP/MIP solver (). The parameter in model (8) is a positive value used to balance fitting and sparseness since GRNs are known to be sparse. The method of inferring GRNs simply by model (8) is called LP method in this article. LP is different from regression model-based LASSO, which reaches a least squares solution (). Although the sparseness can be controlled by the parameter in model (8) to some extent, it is non-trivial to obtain an optimal network structure owing to the noise in the expression data. To ensure sparseness and reduce false positives, we set the variables with low regulation strengths to zero and re-estimate only the non-zero variables using model (8) in the next step. In this way, the accuracy of the network inferred by the second optimization step is improved with the strengthened sparsity by removing NAR regulations. The above procedure is repeated until there are no more non-zero variables. As this technique is composed of a series of optimization procedures, we call it RO. The technique to infer GRNs through solving model (8) recursively is called RO method in this article.
MIThe gene expression data can be described as vectors, in which the elements denote the expression values of genes under different conditions (samples). MI measuring the dependency between two genes X and Y can be defined as below ().px, y log px, y pxpy : 9With the widely adopted hypothesis of Gaussian distribution for gene expression data, the formula (9) can be easily calculated using the following equivalent formula (). IX, Y  1 2 log jCXj  jCYj jCX, Yj , 10 where C is the covariance matrix of variables, and jCj is the determinant of matrix C. If genes X and Y are independent of each other, I(X, Y)  0.
NARROMI algorithm
Algorithm (NARROMI)Step 1: Noisy regulation detection As is well known, the co-expressed genes are more possible to be regulated each other. For a target gene, the genes with high MI scores are co-expressed genes and more possible the true regulators. The MIs between all possible genegene (or regulator-target) pairs are firstly computed by formula (10). Given a threshold parameter for deciding independence between variables, the regulations with MIs below the threshold are regarded as noisy regulations and removed from further analysis (). Note that in our algorithm, we select the TFs for each target gene, rather than select targets for each TF. In addition, those regulations with very large MIs will be kept as putative real regulations and integrated into the final GRN. If TFs are known in advance, the possible regulations of genes by these TFs are inferred. Otherwise, all genes are regarded as possible regulators, and all possible regulations are detected. Step 2: Redundant regulation elimination In this step, only the candidate regulators selected from Step 1 are used in the subsequent optimization for further inference of the network structure. In this way, the redundant regulators will be removed from the candidate regulators gradually using the RO algorithm for each gene. Usually, a gene is targeted by more than one TF. The regression model in RO can detect these combinatorial regulations simultaneously by selecting those regulators with high coefficients, while the regulators with low regulatory coefficients are eliminated.gives the overview of the above procedure of RO, where nodes represent target or regulator genes, and arrows represent regulations from regulators to target genes. In more detail, the regulations are divided into three classes: non-regulations, indirect regulations and direct (true) regulations. The first two classes are redundant regulations, which can be removed by RO algorithm, and the real regulations will be kept until algorithm finished. Take target Gi as an example, edge G5Gi is a non-regulation, and edges R3Gi, R4Gi are two indirect regulations. All of them are redundant and will be removed by RO algorithm. Finally, edges G1Gi and G2Gi are kept as the two potential direct regulations of target Gi. Step 3: Integration of networks To combine the linear and non-linear correlations between regulators and targets, the regulatory strengths inferred from RO algorithm, and the MI correlations are integrated in a linear combination way as follows.where MI is the MI correlation, which is positive, RO is the regulatory strength (positive or negative) inferred by RO algorithm, sign RO  is the sign (AE) of RO , RO is the absolute of RO and parameter ! is the weighting coefficient for MI and RO (). The final regulatory strength is decided by the weight parameter , and the network topology is then determined () (Supplementary Material).
RESULTSTo validate our method, NARROMI was applied to several simulation datasets and a real gene expression dataset. As for simulation data, the method was tested on the simulated benchmark GRNs with synthetic linear expression data and the widely used reference network in Yeast with synthetic non-linear expression data from DREAM3 challenge (). As for real gene expression data, we applied our method to the experiment confirmed network () in E. coli with real gene expression data (). The predictive results were evaluated by following measures, i.e. sensitivity or true positive rate (TPR), false positive rate (FPR), positive predictive value (PPV), accuracy (ACC) and Matthews Coefficient Constant (MCC). Mathematically, they are defined aswhere TP, FP, TN and FN are the numbers of true positives, false positives, true negatives and false negatives, respectively. TPR and FPR are also used to plot the receiver operating characteristic (ROC) curves, and the area under ROC curve (AUC) is calculated. To evaluate the performance of NARROMI, we compared it with several popular methods including LP, RO, regression model-based LASSO (), MI-based ARACNE () and random forest-based GENIE3 (Huynh), where the two alternatives with parameters 'sqrt' and 'all' in GENIE3 were considered here, as they performed best in the DREAM challenges (Supplementary Material). For all the methods in comparison, the default values of parameters were set to run the algorithms. For example, the regularization parameter of methods LP, RO and NARROMI was set to 1; the ensemble parameter of method GENIE3 was set to 1000; the threshold of MI filtering in method NARROMI was set to 0.05.
Evaluation on simulation dataIn this section, we show computational results of our method on two types of simulation datasets, i.e. linear and non-linear expression dataset. For linear expression data, we generated the benchmark networks and related expression datasets using the simple conventional method in statistics. For non-linear expression data, we performed our method on the widely used reference network in Yeast with synthetic non-linear expression data from DREAM3 challenge ().
Artificial linear expression dataFor linear expression data, the benchmark networks and corresponding gene expression data were generated according to the network size, degree of sparseness and rate of noise. First, the benchmark network was generated according to the degree of network, number of target genes and number of candidate regulators. Second, the expression data of the regulators were generated randomly using the Gaussian distribution function. Third, the expression data of the target genes were generated by linear combination with the expression data of regulators. Last, the Gaussian noise was added to the expression data of target genes. In the experiments, we generated different networks with 10, 100, 500, 1000 and 5000 regulators and expression datasets under 5, 10, 15, 20 and 25 samples, respectively (). The average input degree for each target was set to $2, and the noise rate was set to 10%.shows the ROC curves by different methods on datasets of sizes 10, 100 and 1000. For the networks with sizes 500 and 5000, the ROC curves are showed in Supplementary. From the figures, we can clearly see that the performance of our NARROMI method is superior to other methods with AUC score $0.90.summarizes the results obtained by different methods with respect to distinct performance indices. From, we can see that RO performs better than LP and LASSO, both ARACNE and GENIE3 have good performance on large-scale networks and our method NARROMI performs best with the highest AUC values of 0.992, 0.928 and 0.937 on all three datasets. The results show that NARROMI is more robust than other methods on different network sizes. When the network size is large enough with thousands of genes, the accuracy of NARROMI is still high enough, whereas the large network size degrades the performance of other methods significantly. For the networks with sizes 500 and 5000, the results with respect to other performance indexes are given in Supplementary Tables S1 and S2, where NARROMI performs best.
Artificial non-linear expression dataFor non-linear expression data, the widely used benchmark networks with expression datasets from DREAM challenge were adopted here to evaluate our method. The gold standard networks were generated with the non-linear ODE systems in which the network structures were determined with detailed dynamics of both transcriptional and translational processes (). In this work, the DREAM3 datasets about Yeast knock-out genes with sizes 10 and 50 were used (). Firstly, NARROMI was applied to the Yeast gene expression data with network sizes 10 and 10 samples.shows the structure of our inferred network and the ROC curves obtained by different methods.shows the true network with 10 genes and 10 edges, andshows the network inferred by NARROMI. From the figure, we can see that most edges were recovered by NARROMI, although some regulations were missed, such as G6-G4 and G9-G4 with dashed lines. In addition, five of eight inferred edges (62.5%) were detected correctly with respect to regulatory directions. This indicates that NARROMI can detect most regulatory directions without the information of TFs. The comparison of NARROMI with other methods was shown in, where NARROMI outperforms other methods significantly with an AUC score of 0.938. The performances of NARROMI and other methods with
.937The best performer for the relative item is noted in bold. LASSO, regression-based method; LP, linear programming-based method; RO, recursive optimization-based method; ARACNE, MI-based method; GENIE3, random forests-based methods; NARROMI, method based on RO and MI.
Identification of gene regulatory interactions in E. coliExcept the above simulation datasets, NARROMI was also applied to construct regulatory networks from real gene expression data. We evaluated our NARROMI on the experimentally verified reference network in E. coli (). The expression data was drawn from the well known E. coli data bank (). In the experimentally verified networks, there are 2675 edges between 160 regulators and 1258 targets that can be found in the expression dataset. For each target, there are $2 regulators on average, which is consistency with the setting for the regulation degrees of simulation dataset in Section 3.1.1. To evaluate the performance of our method, the AUC scores were computed. Moreover, the number and proportion of TFs and target genes that were predicted correctly were also recorded. We do not compare NARROMI against GENIE3 with parameter 'all' that is time consuming in this case. From the results in, we can see that NARROMI performs better than other methods with the highest average AUC scores for both TFs and target genes of 0.754 and 0.735, respectively.and Supplementaryshow our inferred network structures, which indicate high overlap with the reference network. In, the inferred target genes of TF AppY were shown, and those overlapped with the reference network were marked in gray.shows the inferred regulators of target gene gadB, and the regulators that were predicted correctly were marked in gray.The best performer for the relative item is noted in bold. LASSO, regression-based method; LP, linear programming-based method; RO, recursive optimization-based method; ARACNE, MI-based method; GENIE3, random forests-based methods; NARROMI, method based on RO and MI.
A noise and redundancy reduction techniqueIn this article, we proposed a novel method NARROMI to infer GRNs from gene expression data by combining ODE-based RO and information theory-based MI. From results on the benchmark datasets, NARROMI is effective and outperforms other methods significantly. The good performance of NARROMI may be contributed by following factors. First, it reduces the NAR regulation through two steps, i.e. MI filtering and RO sparseness. As the first step, MI removes the noisy regulations and thus provides clear preliminary structure to the following optimizations (RO). The subsequent RO procedure reduces the redundant (indirect) regulations gradually, thereby improving the performance of network inference. Second, the regulatory networks inferred by NARROMI consist of both linear and non-linear correlations between regulators and targets. The RO technique detects the regulators for target genes using linear systems, which describe the chemical reactions of transcription and translation as linear differential equations. The integration with MI in the last step of the algorithm takes into account the non-linear correlations between regulators and targets, which makes NARROMI superior to general linear model based methods. Despite the advantages of NARROMI, there is still room to improve it. For example, as a popular correlation measure, MI can identify most linear and non-linear correlations, but there are also some special non-linear correlations such as sinusoidal that MI cannot detect. Recently, a meaningful measurement, maximal information coefficient, has been proposed to detect associations from large dataset (), which may help to improve the performance of NARROMI. Although the RO step in NARROMI is able to determine regulatory directions, other popular techniques for causal regulations may obtain better results and will be considered in NARROMI in the future.
CONCLUSIONWe proposed a novel method NARROMI to improve the accuracy of GRN inference by simultaneously implementing the NAR regulation reduction. In this algorithm, the noisy regulations with low pair-wise correlations and the redundant regulations from indirect regulators are removed with MI and RO, respectively. Moreover, the dimension shrinking of the technique improves the efficiency of optimization and further increases the accuracy of network inference. The method was validated on the simulated benchmark GRNs from DREAM challenge and the experimentally verified network in E. coli with real gene expression data. The cross-validation results confirmed the effectiveness of our method (NARROMI), which outperformed previous methods.
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
A noise and redundancy reduction technique at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from respect to PPV, ACC, MCC and AUC are shown in Table 2, where NARROMI is superior to other methods. Secondly, the Yeast gene expression data with network size 50 was used to evaluate NARROMI and other methods. Table 2 shows the results obtained by different methods with respect to distinct performance indexes. The ROC curves by these methods can be found in Supplementary Figure S2. From the results, we can observe that NARROMI performs better than most methods except the method GENIE3 with parameter 'sqrt' for one case. This is also consistent with the analysis that no single inference method performs optimally across all datasets (Marbach et al., 2012). To evaluate the effect of Step 2 (RO) on the performance of NARROMI, we compared the results of NARROMI with or without RO. The results can be found in Supplementary Tables S3 and S4, from which we can see that Step 2 of NARROMI can indeed remove most indirect regulations, and the false positives can be reduced significantly from 0.188 to 0.037 and from 0.109 to 0.032, respectively.
