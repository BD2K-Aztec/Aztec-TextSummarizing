Motivation: Only a few large systematic studies have evaluated the impact of copy number variants (CNVs) on common diseases. Several million individuals have been genotyped on single nucleotide variation arrays, which could be used for genome-wide CNVs association studies. However, CNV calls remain prone to false positives and only empirical filtering strategies exist in the literature. To overcome this issue, we defined a new quality score (QS) estimating the probability of a CNV called by PennCNV to be confirmed by other software. Results: Out-of-sample comparison showed that the correlation between the consensus CNV status and the QS is twice as high as it is for any previously proposed CNV filters. ROC curves displayed an AUC higher than 0.8 and simulations showed an increase up to 20% in statistical power when using QS in comparison to other filtering strategies. Superior performance was confirmed also for alternative consensus CNV definition and through improving known CNV-trait associations. Availability and Implementation: http://goo.gl/T6yuFM
IntroductionGenetic variations range from single nucleotide variations (SNPs) to large chromosomal rearrangement (aneuploidy). Within this spectrum deleted, inserted and duplicated stretches of nucleotides longer than 1 kb (sometimes 500 bp with the use of deep coverage NextGeneration Sequencing) are referred to as copy number variants (CNVs) (). CNVs have been found genome-wide in both disease and healthy populations (). Their function has been widely studied, in the context of the rare diseasesrare variant paradigm () or as motor of evolution (). Association with complex traits such as BMI has been shown in the case of the 16p11.2 rearrangement (), but also with cognitive functions in several general population cohorts [Decode () and Estonia (. Most successful CNV association studies are based on candidate gene approaches () andunlike SNPstheir genome-wide impact has not yet been fully elucidated.Consequently, large genome-wide CNV studies would be instrumental to decipher the impact of genetic rearrangements underlying complex traits and disease susceptibility. Initially, extremely large copy number alterations (>35 megabases) were detected using karyotyping (). Then, fluorescence in situ hybridization increased the resolution enabling the detection of sub-microscopic events (). Nowadays, CNVs can be detected using different molecular technologies and methods. NGS technologies allow sequencing millions of reads in parallel and new methods for structural variants analysis have been developed, including paired-end mapping, read-depth analysis, split-read strategies and sequence assembly comparisons (). The other main methods to detect CNVs are based on micro-array technologies, either Comparative Genome Hybridization (CGH) arrays () or SNP genotyping arrays (). We focused on CNV detection based on SNP genotyping arrays, as millions of individuals have already been genotyped on SNP arrays and many of these samples were used in meta-analysis of Genome-Wide Association Studies (GWAS) (). Thus, a wealth of unexploited information remains available in these cohorts and could be re-analyzed for genome-wide CNVs association. The flip side of using genotyping arrays is the lower reliability of the CNV detection, as these platforms were not initially designed to detect such genomic events. However, more recent ones can contain CNV probes. Despite this limitation, several algorithms have been developed for CNV detection. At each probe, a relative copy number ratio can be obtained by combining the intensities of the two alleles and normalizing this quantity with respect to a reference (log R ratio LRR). Deviation from the copy number ratio baseline will correspond to either a loss or gain. Several publicly available software () improve copy number calls by exploiting the ratio of allelic intensities (normalized measure of the signal intensity ratio of the B and A allelesB Allele FrequencyBAF). In this article, we focus on the PennCNV software (), currently the most widely used software for Illumina chips (PennCNV: 955 citationsQuantiSNP: 432 citations). This software, based on a Hidden Markov Model (HMM), is extensively used for CNV detection on SNP. Its speed is a key advantage as number of available samples increase at an unprecedented scale. Nevertheless, CNV detection remains prone to false positives, which adds noise when such calls are used for trait association. There is a need to develop a new quality score (QS) for CNVs detected by PennCNV, prior to performing CNV-based association studies. Our contribution can be viewed as a post-processing step of PennCNV calls, whereby various CNV metrics are combined to estimate the probability of a called CNV to be a likely consensus call. This probability could then be used as copy number dosage for trait associations. We chose to improve CNV detection in a way that is directly applicable for large meta-analytic GWAS, where analysts preferably want to run only a single and fast CNV calling pipeline and provide association summary statistics from various platforms.
Methods
CohortsHYPERGENES is a case/control cohort of 4206 individuals, where controls were selected based on the absence of hypertension while cases were hypertensive (). Genotyping was done on Illumina 1M-Duo BeadChips capturing 1 199 187 SNPs and was performed in two different centers, one in Geneva and one in Milano; leading to two sub cohorts: HYPERGENES Geneva with 1995 individuals and HYPERGENES Milano with 2,211 individuals. The GenomeStudio software produced final reports with LRR and BAF values. The Swiss Hepatitis C Cohort Study (SCCS) is a prospective multicentre study carried out in Switzerland and recruiting HCVpositive patients (). A total of 1152 patients were genotyped on the same Illumina platform as HYPERGENES individuals. The GenomeStudio software produced final reports with LRR and BAF values. The Swiss Kidney Project on Genes Hypertension (SKIPOGH) is a population-based cross-sectional family study that examines the genetic determinants of blood pressure. The study population included 1128 participants from 271 nuclear families. In our project we used genetic data from 169 trios genotyped on Illumina 2.5. (). The UK BioBank is a study of 500 000 individuals from the UK aged between 37 and 73 years and genotyped on Affymetrix Axiom (http://www.ukbiobank.ac.uk/). Data from 119 873 individuals, with genetics and BMI information, were used in the scope of this project.
CNV callingCNVs were called using three different software: PennCNV (), QuantiSNP () and CNVpartition (http://www.illumina.com/documents/products/technotes/technote_ cnv_algorithms.pdf). PennCNV is a HMM based software developed to call CNVs using LRR and BAF values for each sample genotyped on Illumina platform. A 'population BAF' (PFB) file was created for each cohort based on 200 randomly selected final reports. The clean_cnv.pl script was called with default parameters to merge adjacent CNVs with small gaps. Samples with more than 200 CNVs were excluded from further analysis. QuantiSNP is also a HMM-based software developed to call CNVs using LRR and BAF values. CNVpartition, developed by Illumina, defines 14 different copy number states and for each of them, jointly models the LRRs and BAFs as a bivariate Gaussian distribution. Based on these distributions, it calculates the likelihood of each of the 14 states for a given LRR and BAF. For all three software, CNVs were called using default parameters.
Consensus CNVFor each CNV detected by PennCNV, we looked at the fraction detected by the two other software, a percentage of agreement for each CNV is then calculated. Zero percent agreement means that none of the CNV probes called by PennCNV is detected by the two other software, 50% means that half of the CNV probes are detected by all the other software and 100% means that all the probes within the CNV are retrieved by both CNVpartition and QuantiSNP. We considered a CNV to be a consensus call if its percentage of agreement is above 70%, meaning that the two other software detect at least 70% of it. We used this working definition of a consensus CNV. Other definitions could be imagined (see Section 4), but we chose this mainly due to data availability in large samples.
Modeling consensus callsFor each CNV detected by PennCNV we would like to predict whether the two other software would confirm it, i.e. whether it is a consensus call. To this end, we modeled the dichotomized overlap percentage, as a function of various PennCNV parameters using a logistic model (see Equation 1). Ten available parameters were considered: confidence score, CNV length, number of probes, LRR mean, LRR standard deviation, BAF mean, BAF standard deviation, waviness factor (WF) and the total number of CNVs per individual. For more information regarding the definition of the quality metrics, please refer to the Supplementary, to the PennCNV description () and the associated website (http:// penncnv.openbioinformatics.org/en/latest/). The first three parameters characterize each CNV in a specific sample, while the others correspond to the global signal quality for each individual.Variable Y was defined as 1 if the CNV was confirmed by the two other software and zero otherwise. It is the collection of values for all probes and all samples. Variables V i represent the various CNV/ sample parameters provided by the PennCNV software. Step-wise logistic regression using the R function step was performed separately for deletions and duplications. Coefficients b i with a corresponding P-value below 10 5 were considered as significant and were set to zero otherwise. Coefficients were estimated separately for each test cohort and used for cross-validation purposes. In the future, the mean of these coefficients can be used for new cohorts. Furthermore, as the coefficients are correlated, we are less interested in their actual values but rather in their combination.
QS calculationThe coefficients from the logistic model obtained from one/some cohort(s) can be used to estimate the probability of a CNV being a consensus call in other cohorts. We termed this quantity as QS, hence its value indicates the probability of a CNV called by PennCNV parameters being a consensus call.These values are multiplied by 1 in case of deletions to retain both quality and copy number information. Note that the variables used in the formula are only the ones retained after stepwise selection (in the independent data set).
Previous measures of CNV qualityAs PennCNV calls admittedly contain many false positives, popular filtering criteria have been recommended and applied in many studies (). We tested different quality metrics filtering combinations to compare with our QS ().
Quality metric comparison through correlationTo evaluate the performance of our newly proposed CNV QS and previously applied metrics, we compared how well the different CNV quality metrics agree with the consensus calls defined by software overlap. First, for each cohort, Spearman correlation between the consensus CNV status and CNV quality metrics were calculated. We compared the confidence score, the different filters and the QS. The QS coefficients were based on the average coefficients leaving out the test cohort.
Quality metric comparison through receiver operating characteristic curveTo evaluate the discriminatory power of the proposed QS, we computed the receiver operating characteristic (ROC) curve and estimated the area under the curve (AUC). The QS (based on the leave-one (cohort)-out cross-validation) was used as the predictor and the consensus CNV status as the response. Two different definitions of the consensus CNV status were used. The first one considers all the CNVs and defines a consensus CNV as one detected by the three software and false CNV all the others. The second definition was the same as the first, but ignored all CNVs that were called by two software only.
Quality metric comparison through simulated CNV-phenotype associationSimulations were done at the probe level. When two probes have the same profile across all samples, we kept only one representative. Then, for each cohort, we assessed the performance of the QS. We first converted the CNVs metrics into (no. of probes  no. of samples) tables in order to overcome the problem of different CNVs boundaries across samples. We then simulated association between an in silico phenotype and: (i) PennCNV raw CNV calls, (ii) PennCNV confidence score, (iii) the different filters, (iv) the QS based on the average coefficients leaving out one cohort. Then simulations were done for each probe separately. For a specific probe, an in silico phenotype is simulated based on the consensus CNV status (defined as the overlap between the three software), an effect size and noise (Equation 3). The effect sizes (b) ranged from 0 to 3 by a step of 0.05 and the noise (e) was set to follow a standard Gaussian distribution (mean  0, variance  1):Linear regressions were then performed to derive association between this in silico phenotype and the estimated CNV status (based on filtered CNVs, confidence score or QS). We ran thousand simulations for each effect size, and we estimated the statistical power to detect an association at a  10 3. Simulations were done separately for deletions and duplications. Within each cohort, we calculated, for each probe, the CNV frequency (Equation 4) and the precision (Prec) (Equation 5).These filters were used to evaluate the performance of our QS in comparison to what is usually used in the literature: filters A (), B (), C (), D () and E ().
New CNV quality measure for SNP arrayCNVs probes were classified according to their precision and frequency. Power computations are presented for 30 (5  6) different bins of frequency (5 bins) and precision (6 bins) combinations. CNV frequency bins boundaries were set at 0, 1, 5, 10, 15, 20 and 100%. Precision bins boundaries were set at 0, 10, 20, 30, 40, 50 and 100%.
QS validation for other consensus definitionWe used pennCNV to call CNV on the 169 trios from the SKIPOGH study. We defined consensus CNVs as those called by pennCNV both for the proband and at least one of its parents. For all CNVs called for the probands we calculated the QS and also applied the different filters. To assess the agreement between consensus CNV status and the different measures we used logistic regression with consensus status as outcome and(i) QS value, (ii) confidence score, (iii) the different filters as predictors.
Recovering the known 16p11.2 CNV-BMI associationWe called CNVs in the 16p11.2 region in 119 873 UK BioBank participants using pennCNV. For each CNV a QS was estimated and the different filters were applied. Then for the entire cohort, we calculated the association between the inverse quantile normalized BMI and (i) QS, (ii) the confidence score, (iii) the raw copy number state and (iv) the different filters.
Results
Percentage of agreementThe percentage of CNVs detected by PennCNV and confirmed by the two other software is between 20 and 30% (Supplementary, Supplementary Figs. S1S3). The results are consistent across the three cohorts with a slightly better percentage of agreement for the duplications than for the deletions. These results mean that three quarters of the PennCNV calls may be false positives, adding noise to downstream analyses. It confirms the necessity to develop a new quality measure that estimates the probability of a CNV call to be a consensus call, in order to increase detection power and avoid spurious associations due to systematic artifacts.
QS coefficientsFor each CNV (called by PennCNV), its QS is computed to estimate the probability of being a consensus call (see Section 2). The QS is derived from a logistic model, whose coefficients (for each CNV and sample characteristic) were estimated separately for deletions and duplications using three cohorts. Coefficients with significant P-value (<10 5 ) were kept for the final model (Supplementary Tables S3S5). As expected, the confidence score provided by PennCNV is the parameter with the strongest contribution (coefficient ranging from 2.21 to 4.77, P < 10 300 ). It confirms that CNVs with high confidence scores are more likely to be consensus calls. The number of CNVs per individual has a negative coefficient (ranging from 0.57 to 0.17), which means that CNVs called from sample with few CNVs are most probably consensus calls. Interestingly, the coefficients of the mean LRR have opposite values between deletions and duplications. This behavior is consistent across the three cohorts and is unlikely by chance. This is due to the fact that, for a deletion, it is easier to detect a drop in the intensity signal if the global LRR mean value is high. The contrary applies for duplications. The negative coefficients for the number of probes might appear counterintuitive. But in the case of multivariate regression, the estimates of correlated variables (e.g. the correlation between PennCNV confidence score and the number of probes was 0. 56) are difficult to interpret. Furthermore, in a univariate model, the number of probes has a significant positive estimate for the duplications in all the three cohorts. Regarding the deletions, estimates are either positive or not significant.
QS distributionQS values have been computed separately for deletions and duplications on the three samples groups coming from two cohorts. The distribution of the QSs (Panels A and B Supplementary Figs. S4S6) shows a bimodal distribution: most of the CNVs are either of bad or good quality, and only few stand in between. As seen for the percentage of agreement, the majority of CNVs are most likely false positive. If one prefers to work with dichotomized CNV calls, we recommend to declare CNVs with QS > 0.5 as consensus CNVs (). The CNV frequency distribution (Panels CD Supplementary Figs. S4S6) reveals that the majority of deletions with low frequency ( 3%) are of bad quality (QS < 0.5). On the contrary, most of the duplications with a frequency lower than 0.4% have a highQS (QS ! 0.9). A large part of the deletions with frequency !3% have intermediate (0.5 QS < 0.9) or high (QS ! 0.9) QS, likewise for duplications with frequency ! 10%. Since CNVs are called per sample, frequency might be a predictor. These results show that using our QS to filter CNVs may be particularly useful in the case of rare deletions. In the case of duplications, the advantage is less apparent and would be more relevant for intermediate frequencies (between 0.4 and 10%). Regarding the length (Panels E and F Supplementary Figs. S4 S6), almost all the CNVs with high QS are longer than 10 kb. It confirms the difficulty to detect small CNVs on SNP array platforms. When applied to CNV-phenotype associations, our QS has the potential to reduce the noise created by false calls especially for CNVs with length <75 kb. It would increase the power to detect associations with short CNVs, which have not yet been implicated with any complex traits.
Quality metric comparison through correlationThe correlation of the consensus CNV status (defined by the overlap between the three software) with the QS (based on the leave-one (cohort)-out cross-validation) is twice as high as with the classical filters for all types of CNVs and all cohorts (e.g. 0.53 versus 0.26 for Hypergenes GVA and all CNV types; 0.45 versus 0.22 for SCCS and all CNV types; seeand Supplementary Tables S6S7). This score has also a $20% higher correlation than the confidence score for the deletions and has similar performance for the duplications. The correlations are consistent over the three cohorts and are slightly higher for deletions than for duplications.points out the unexpectedly low performance of the classical filters, which perform much worse than the confidence score provided by PennCNV. To summarize, in case of deletions, our QS is a better proxy for the consensus calls than the classical filtering or the PennCNV confidence score. Although the above table reports only average performance for the whole genome, we give a graphical overview of the distribution of correlations according to CNV frequency and detectability (precision). The box plots () show detailed performance for CNVs with frequency 15% and detectability 1020% in the Hypergenes Geneva samples. Results were comparable for other frequency ranges and other cohorts (Supplementary Figs. S7S9). In summary, classical filters perform worse than our QS and the confidence score from PennCNV. In general, our QS performs discernably better than the confidence score mainly for low frequency CNVs ( 5%) and poor detectability ( 30%). When the frequency and detectability increase, the performances of these two quality metrics become more and more similar. These results are concordant with the frequency distribution figure (Supplementary Figs. S4S6) and correlation table ().
Quality metric comparison through ROC curveTo estimate the discrimination power of our QS to retrieve consensus calls, we computed the ROC curves for all the CNVs, only deletions and only duplications for the Hypergenes Geneva samples (for the other cohorts are presented in the Supplementary Figs. S13S14). AUC are respectively equal to 0.845, 0.871 and 0.774 confirming that the QS recovers well the consensus calls. A threshold of 0.8 will give a specificity of $99% with sensitivity between 25 and 30%, while a threshold of 0.5 will have specificity around 96% for sensitivity between 40 and 50%. Based on these results, we recommend using a QS threshold between 0.5 and 0.8 to filter CNVs, if necessary. As comparison, the others filters stand all below the ROC curves (), showing that our QS offers better sensitivity and specificity.
Quality metric comparison through simulated CNV-phenotype associationThe previously reported comparisons only reflect how different filters compare to each other, but do not reveal how much power improvement they could offer in association studies relative to each other or to no filtering. To this end, we performed simulation studies for deletions and duplications separately. Exhaustively sampling CNVs of different characteristics shows an increase up to 20% in statistical power of our QS in comparison to the other quality metrics, for probes with low frequency and detectability (CNVs frequency 5%; detectability 30%).illustrates power curves for CNVs with frequency between 1 and 5% and precision 10-20% for samples of the Hypergenes Geneva cohort As these two parameters increase, all the CNV quality metrics start to perform similarly and the power curves overlap. Results for other frequency ranges and other cohorts are shown in Supplementary Figures S15S17. Surprisingly, for most scenarios, classical filters have inferior performance compared with keeping all CNVs without any filtering. It seems that classical filters also remove too many consensus calls and hence decrease power (this explains why the detection power reaches a plateau below 100% in some cases). These simulations show that our QS offers considerable advantage over other quality metrics in particular for rare deletions overlapping poor quality), B (), C (), D () and E ().. Boxplots corresponding to the correlations between the consensus CNV status (defined by the overlap between the three software) and quality metrics such as QS, PennCNV confidence score and classical filters: A (), B (), C (), D () and E (), as defined in the method section. Calculations were done for deletions on the Hypergenes Geneva samples. CNVs were classified according to their precision and frequency. The frequency range for this boxplot is between 1 and 5% while the precision range is between 10 and 20%. The N number corresponds to the number of unique probes being in the precision and CNV frequency window. ROC curve using the QS (based on the leave-one (cohort)-out cross-validation) as predictor and the consensus CNV status as the response. The consensus CNVs are the ones detected by the three software, all the others are defined as false. The plot is based on the Hypergenes Geneva individuals. In black are the results for all the CNVs, in blue for the deletions only and in red for the duplications only. The cross and the star dots give the specificity and sensitivity using a QS threshold of 0.8 and 0.5 respectively. Other symbols correspond to the different filters: A (), B (), C (), D () and E (New CNV quality measure for SNP arrayprobes. Comparable simulations have been made for duplications (see Supplementary Figs. S18S20) and, in accordance with the correlation analysis, our QS performs similarly to the confidence score or the raw copy number. Here again, the classical filters perform the worst. Note that our simulations were based on small samples (n < 2000), hence large simulated effect sizes were necessary to reach high meaningful power.
QS validation for other consensus definitionWe estimated the performance of the QS by using a different definition of the consensus CNV status. A CNV detected in an offspring was defined to be consensus if it was also detected in at least one of the two parents. This definition doesn't take into account de novo CNVs but their occurrence is relatively low (). Using this consensus definition, our QS (P  4*10 80 ) clearly outperforms all classical filters (P > 2*10 40 ) and the confidence score (P  7*10 60 ) from pennCNV, considering all the CNVs together (Supplementary) as well as when looking at deletions and duplications separately (Supplementary Tables S9 and S10).
Recovering the known 16p11.2 CNV-BMI associationTwo CNVs in the 16p11.2 region are robustly associated with BMI (). Therefore, they can be used to benchmark the performance of the different quality measures: Stronger association of these CNVs with BMI is an indicator of performance. We computed the association between BMI and (i) the QS, (ii) the confidence score, (iii) the raw copy number state and (iv) the different filters for CNVs detected in the 16p11.2 region using 119 873 individuals from the UK BioBank. The association P-values for QS were on average >10-fold smaller than for any that of the other CNV measures. The QQplot (Supplementary) clearlyshows inflation for low P-values in this region. However, this inflation is stronger when using the QS as genotypic data compared with using any raw data or filters. Furthermore, the fraction of probes, in this region, that pass the genome-wide significance level at 2*10 7 is clearly higher when using our QS (44.4%) than any of the other CNV measures (39.6% at best, Supplementary).
DiscussionOur QS has been built in order to estimate the probability of a CNV to be a consensus call based on the fact that consensus CNV is defined as the overlap of CNV calls from three distinct software applied to Illumina genotyping arrays. We have demonstrated through ROC, correlation and power analyses that our QS can better recover consensus CNVs than other CNV quality metrics. Naturally, many other consensus definitions could be used. For example, CNVs called by only one other software may not necessarily be false and hence could have been classified as neither false, nor true calls. This definition of consensus, however, did not change the conclusions (Supplementary Figs. S22S24). Using trio data, we have also explored a definition where CNV calls confirmed in (at least) one of the parents are deemed as consensus CNVs. Notably, our QS recovered these consensus calls significantly better than other quality measures and filters. Finally, we demonstrated the advantage of the QS through (re-)discovering the known 16p11.2 CNV-BMI associations in the UK Biobank. Here again, association P-values for the QS were >10-fold smaller than those of any other CNV quality metric. We thus recommend the use of this metric, as a probabilistic CNV dosage for CNV association studies. This metric has been used to search association between CNV load and cognitive phenotypes in unselected populations (). Our CNV calls reliably led to stronger association results and retrieved the same CNV frequencies as in the discovery cohort [where some CNVs have been manually confirmed (. It would have been possible to define the consensus as the overlap between CNV calls from multiple genotyping technologies [e.g. genotyping arrays, array CGH (aCGH) or whole genome sequencing (WGS)] applied for the same study participants. Unfortunately, even though aCGH is widely used for CNVs detection in clinical settings, there is no gold standard software () for genome-wide CNV calling in large population samples. Similarly, algorithms calling CNVs from WGS are in early stages (). Another problem is data availability: there are over hundred-fold more population-based samples available with genotyping chip data than those with aCGH or WGS. An additional problem for WGS is that the coverage is usually below 10, which insufficient for reliable CNV calling (http:// www.haplotype-reference-consortium.org/). In the future, when such data become available on larger scale one can apply our approach to other consensus CNV definitions. Over the past years, many GWAS based on Illumina SNP array data have been performed for different traits (). All these data could be reanalyzed to perform CNV association studies using our QS as CNV allele dosage for associations just like the currently used imputed genotype dosages (). This would allow a better filtering and would increase statistical power especially for rare deletions as it has been demonstrated in the Results. Such rare variants 0.0 0.5 1.0 1.5 2.. CNV-phenotype association simulation based on deletions detected in the Hypergenes Geneva samples. Associations were done with different quality metrics such as the QS, the confidence score, the classical filters: A (), B (), C (), D () and E (), as defined the method section, and the raw CNV calls. CNVs were classified according to their precision and frequency. The frequency range for this boxplot is between 1 and 5% while the precision range is between 10 and 20%. This plot shows the statistical power as a function of the effect size for the different quality metrics. N corresponds to the number of unique probes being in the precision and CNV frequency window have to be meta-analyzed in a way such that the imputation quality is taken into account in the meta-analysis. As shown in our simulations, the power advantage offered by the QS may not be remarkable for individual cohorts, but much more so in the context of meta-analysis facilitating the collection of large samples. Although larger and larger association studies of common/rare single nucleotide variants reveal increasing proportions of the 'missing heritability', rare CNVs are relatively neglected apart from a few successful examples (). Therefore, as a future work, we will apply this quality measure in the context of large meta-analytic CNV-association studies on anthropometric traits. In particular, for BMI, the heritability of which is estimated to be 4070%, but common variants seem to account for <25% (). To this purpose, we wrapped up the QS calculation in a pipeline designed to run CNV trait associations. This pipeline has been tested with 18 analysts (on 70 000 samples) and is available online (http://goo.gl/T6yuFM).
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
A.Mac et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
