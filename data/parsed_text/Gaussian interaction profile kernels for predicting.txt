Motivation: The in silico prediction of potential interactions between drugs and target proteins is of core importance for the identification of new drugs or novel targets for existing drugs. However, only a tiny portion of all drug–target pairs in current datasets are experimentally validated interactions. This motivates the need for developing computational methods that predict true interaction pairs with high accuracy. Results: We show that a simple machine learning method that uses the drug–target network as the only source of information is capable of predicting true interaction pairs with high accuracy. Specifically, we introduce interaction profiles of drugs (and of targets) in a network, which are binary vectors specifying the presence or absence of interaction with every target (drug) in that network. We define a kernel on these profiles, called the Gaussian Interaction Profile (GIP) kernel, and use a simple classifier, (kernel) Regularized Least Squares (RLS), for prediction drug–target interactions. We test comparatively the effectiveness of RLS with the GIP kernel on four drug–target interaction networks used in previous studies. The proposed algorithm achieves area under the precision–recall curve (AUPR) up to 92.7, significantly improving over results of state-of-the-art methods. Moreover, we show that using also kernels based on chemical and genomic information further increases accuracy, with a neat improvement on small datasets. These results substantiate the relevance of the network topology (in the form of interaction profiles) as source of information for predicting drug–target interactions. Availability: Software and Supplementary Material are available at
INTRODUCTIONThe in silico prediction of interaction between drugs and target proteins is a core step in the drug discovery process for identifying new drugs or novel targets for existing drugs, in order to guide and speed up the laborious and costly experimental determination of drugtarget interaction (). * To whom correspondence should be addressed. Drugtarget interaction data are available for many classes of pharmaceutically useful target proteins including Enzymes, Ion Channels, G-protein-coupled receptors (GPCRs) and Nuclear Receptors (). Several publicly available databases have been built and maintained, such as KEGG BRITE (), DrugBank (), GLIDA (), SuperTarget and Matador (), BRENDA () and ChEMBL () containing drugtarget interaction and other related sources of information, like chemical and genomic data. A property of the current drugtarget interaction databases is that they contain a rather small number of drugtarget pairs which are experimentally validated interactions. This motivates the need for developing methods that predict true interacting pairs with high accuracy. Recently, machine learning methods have been introduced to tackle this problem. They can be viewed as instances of the more general link prediction problem, seefor a recent survey of this topic. These methods are motivated by the observation that similar drugs tend to target similar proteins (). This property was shown, for instance, for chemical () and side effect similarity (), and motivated the development of an integrated approach for drugtarget interaction prediction (). A desirable property of this approach is that it does not require the 3D structure information of the target proteins, which is needed in traditional methods based on docking simulations (). The current state-of-the-art for the in silico prediction of drug target interaction is formed by methods that employ similarity measures for drugs and for targets in the form by kernel functions, like;;;). By using kernels, multiple sources of information can be easily incorporated for performing prediction (). In, different settings of the interaction prediction problem are explored. The authors make the distinction between 'known' drugs or targets, for which at least one interaction is in the training set, and 'new' drugs or targets, for which there is not. There are then four possible settings, depending on whether the drugs and/or targets are known or new. In this article, we focus on the setting where both the drugs and targets are known. That is, we use known interactions for predicting novel ones.
GIP kernelWe want to analyze the relevance of the topology of drug target interaction networks as source of information for predicting interactions. We do this by introducing a kernel that captures the topological information. Using a simple machine learning method, we then compare this kernel to kernels based on other sources of information. Specifically, we start from the assumption that two drugs that interact in a similar way with the targets in a known drugtarget interaction network, will also interact in a similar way with new targets. We formalize this property by describing each drug with an interaction profile, a binary vector describing the presence or absence of interaction with every target in that network. The interaction profile of a target is defined in a similar way. From these profiles, we construct the Gaussian Interaction Profile kernel. We show that interaction profiling can be effectively used for accurate prediction of drugtarget interaction. Specifically, we propose a simple regularized least square algorithm incorporating a product of kernels constructed from drug and target interaction profiles. We test the predictive performance of this method on four drugtarget interaction networks in humans involving Enzymes, Ion Channels, GPCRs and Nuclear Receptors. These experiments show that using only information on the topology of the drugtarget interaction, in the form of interaction profiles, excellent results are achieved as measured by the area under the precisionrecall curve (AUPR) (). In particular, on three of the four considered datasets the performance is superior to the best results of current state-of-the-art methods that use multiple sources of information. We further show that the proposed method can be easily extended to also use other sources of information in the form of suitable kernels. Results of experiments where also chemical and genomic information on drugs and targets is included show excellent performance, with AUPR score of 91.5, 94.3, 79.0 and 68.4 on the four datasets, achieving an improvement of 7.4, 13.0, 12.3 and 7.2 over the best results reported in Bleakley and Yamanishi (2009). A thorough analysis of the results enable us to detect several new putative drugtarget interactions, see http://cs.ru.nl/~tvanlaarhoven/drugtarget2011/new-interactions/.
MATERIALSWe used four drugtarget interaction networks in humans involving Enzymes, Ion Channels, GPCRs and Nuclear Receptors, first analyzed by. We worked with the datasets provided by these authors, in order to facilitate benchmark comparisons with the current state-of-the-art algorithms that do the same. These datasets are publicly available at http://web.kuicr.kyotou.ac.jp/supp/yoshi/drugtarget/.lists some properties of the datasets. Drugtarget interaction information was retrieved from the KEGG BRITE (), BRENDA (), SuperTarget () and DrugBank () databases. Chemical structures of the compounds was derived from the DRUG and COMPOUND sections in the KEGG LIGAND database (). The chemical structure similarity between compounds was computed using SIMCOMP (). This resulted in a similarity matrix denoted by S c , which represents the chemical space. Amino acid sequences of the target (human) proteins were obtained from the KEGGGENES database (). Sequence similarity between proteins was computed using a normalized version of SmithWaterman score (), resulting in a similarity matrix denoted S g , which represents the genomic space.
METHODS
Problem formalizationWe consider the problem of predicting new interactions in a drugtarget interaction network. Formally, we are given a set X d ={d 1 ,d 2 ,...,d n d } of drugs and a set X t ={t 1 ,t 2 ,...,t nt } of target proteins. There is also a set of known interactions between drugs and targets. If we consider these interactions as edges, then they form a bipartite network. We can characterize this network by the n d n t adjacency matrix Y. That is, y ij = 1 if drug d i interacts with target t j and y ij = 0 otherwise. Our task is now to rank all drugtarget pairs (d i ,t j ) such that highest ranked pairs are the most likely to interact.
Gaussian interaction profile kernelOur method is based on the assumption that drugs exhibiting a similar pattern of interaction and non-interaction with the targets of a drugtarget interaction network are likely to show similar interaction behavior with respect to new targets. We use a similar assumption on targets. We, therefore, introduce the (target) interaction profile y di of a drug d i to be the binary vector encoding the presence or absence of interaction with every target in the considered drug target network. This is nothing more than row i of the adjacency matrix Y. Similarly, the (drug) interaction profile y T tj of a target protein t j is a vector specifying the presence or absence of interaction with every drug in the considered drugtarget network. The interaction profiles generated from a drugtarget interaction network can be used as feature vectors for a classifier.
T.van Laarhoven et al.Following the current state-of-the-art for the drugtarget interaction prediction problem, we will use kernel methods, and hence construct a kernel from the interaction profiles. This kernel does not include any information beyond the topology of the drugtarget network. One of the most popular choices for constructing a kernel from a feature vector is the Gaussian kernel, also known as the radial basis function (RBF) kernel. This kernel is, for drugs d i and d j ,A kernel for the similarities between target proteins, K GIP,t , can be defined analogously. We call these kernels Gaussian Interaction Profile (GIP) kernels. The parameter  d controls the kernel bandwidth. We setThat is, we normalize the parameter by dividing it by the average number of interactions per drug. With this choice, the kernel values become independent of the size of the dataset. In principle, the new bandwidth parameterparameter parameter d could be set with cross-validation, but in this article, we simply useuse use d = 1.There are other ways to construct a kernel from interaction profiles. For example, Basilico and Hofmann (2004) propose using the correlation of interaction profiles. We have performed brief experiments with these other kernels, which show that GIP kernels consistently outperform kernels based on correlation or inner products. The detailed results of these experiments are included in Supplementary Table S1.
Integrating chemical and genomic informationWe construct kernels containing information about the chemical and genomic space from the similarity matrices S d and S g. Since these similarity matrices are neither symmetric nor positive definite, we apply a simple transformation to make them symmetric with S sym = (S +S T )/2 and add a small multiple of the identity matrix to enforce the positive definite property. We denote the resulting kernels for drugs and targets by K chemical,d and K genomic,t , respectively. To combine the interaction profile kernel with these chemical and genomic kernels, we use a simple weighted average,For the reported results of our evaluation, we use simply the unweighted average, for both drugs and targets, i.e.  d =  t = 0.5. In Section 4.2, we further analyze the effect of these parameters on the predictive performance of the method.
RLS-avg classifierIn principle, we could use the GIP kernels with any kernel-based classification or ranking algorithm. We choose to use a very basic classifier, the (kernel) Regularized Least Squares (RLS) classifier. While Least Squares is primarily used for regression, when a good kernel is used it has classification accuracy similar to that of Support Vector Machines (). Our own experiments confirm this finding. In the RLS classifier, the predicted valuesyvalues valuesy with a given kernel K have a simple closed form solution,where  is a regularization parameter. Higher values of  give a smoother result, while for  = 0 we getyget gety = y, and hence no generalization at all. The valu y is a real-valued score, which we can interpret as a confidence. The RLS classifier is sensitive to the encoding used for y. Here, we use 1 for encoding interacting pairs and 0 for non-interacting ones. Brief experiments have shown that the classifier is not sensitive to this choice, as long as the value used for non-interactions is close to 0. Using a value very different from 0, like 1, would place too much weight on noninteractions. The classifier would then try to avoid predicting pairs that look like non-interactions, rather than predicting pairs that look like interactions. In the previous sections, we defined kernels on drugs and kernels on target proteins. There are several ways in which we can use kernels in both these dimensions. Following other works, like Bleakley and Yamanishi (2009); Zheng Xia and Wong (2010), a simple and effective approach is to apply the classifier for each drug independently using only the target kernel, and also for each target independently using only the drug kernel. Then the final score for a drugtarget pair is a combination of the two outputs. Here we use the average of the output values, and denote the resulting method by RLS-avg. Observe that in the formulation of the RLS classifier that we use, performing independent prediction amounts to replacing the vector y with the matrix Y , and hence the prediction of RLS-avg isYNote this model is slightly different from using the Kronecker sum kernel (). Since regularization is performed for drugs and targets separately in the RLS-avg method, rather than jointly.
RLS-Kron classifierA better alternative is to combine the kernels into a larger kernel that directly relates drugtarget pairs. This is done with the Kronecker product kernel (). The Kronecker product K d K t of the drug and target kernels isWith this kernel, we can make predictions for all pairs at once,where vec(Y T ) is the a vector of all interaction pairs, created by stacking the columns of Y T. We call this method RLS-Kron. Using the Kronecker product kernel directly would involve calculating the inverse of an n d n t n d n t matrix, which would take O((n d n t ) 3 ) operations, and would also require too much memory. We use a more efficient implementation based on eigen decompositions, previously presented in Raymond and Kashima (2010).be the eigen decompositions of the two kernel matrices. Since the eigenvalues (vectors) of a Kronecker product are the Kronecker product of eigenvalues (vectors), for our Kronecker product kernel we have simplyThe matrix that we want to invert, K +I has these same eigenvectors V , and eigenvalues +I. HenceTo efficiently multiply this matrix with vec(Y T ), we can use a further property of the Kronecker product, namely that (AB)vec(X) = vec(BXA T ). Combining these facts, we get that the RLS prediction isYSo, to make a RLS prediction using the Kronecker product kernel we only need to perform the two eigen decompositions and some matrix multiplications, bringing the runtime down to O(n d 3 +n t 3 ). The efficiency of this computation could be further improved yielding a quadratic computational complexity by applying recent techniques for large-scale kernel methods for computing the two kernel decompositions ().
GIP kernel
Comparison methodsIn order to assess globally the performance of our method, we compare it against current state-of-the-art algorithms. To the best of our knowledge, the best results on these datasets obtained so far are those reported by, where the Bipartite Local Models (BLM) approach was introduced. These results were achieved by combining the output scores of the Kernel Regression Method (KRM) () and BLM by taking their maximum value. We briefly recall these methods here. In the KRM method, drugs and targets are embedded into a unified space called the 'pharmacological space'. A regression model is learned between the chemical structure (respectively, genomic sequence) similarity space and this pharmacological space. Then new potential drugs and targets are mapped into the pharmacological space using this regression model. Finally, new drugtarget interactions are predicted by connecting drugs and target proteins that are closer than a threshold in the pharmacological space. The BLM method is similar to our RLS-avg method. In the BLM method, the presence or absence of a drugtarget interaction is predicted as follows. First, the target is excluded, and a training set is constructed consisting of two classes: all other known targets of the drug in question, and the targets not known to interact with that drug. Second, a Support Vector Machine that discriminates between the two classes is constructed, using the available genomic kernel for the targets. This model is then used to predict the label of the target, and hence the interaction or non-interaction of the considered drugtarget pair. A similar procedure is applied with the roles of drugs and targets reversed, using the chemical structure kernel instead. These two results are combined by taking the maximum value.
EVALUATIONIn order to compare the performance of the methods, we performed systematic experiments simulating the process of bipartite network inference from biological data on four drugtarget interaction networks. These experiments are done by full leave-one-out crossvalidation (LOOCV) as follows. In each run of the method, one drugtarget pair (interacting or non-interacting) is left out by setting its entry in the Y matrix to 0. Then we try to recover its true label using the remaining data. Note that when leaving out a drugtarget pair the Y matrix changes, and therefore the GIP kernel has to be recomputed. We also performed a variation of these experiments using five trials of 10-fold cross-validation. We recomputed the GIP kernels for each fold, also for 10-fold cross-validation. So no information about the removed interactions was leaked in this way. The results can be found in Supplementary Table S2; we observed no large differences compared with the results obtained using LOOCV. In all experiments, we have chosen the values for the parameters in an uninformative way. In particular, we set the regularization parameter  = 1 for both RLS methods; and as stated before, we set the kernel bandwidthsbandwidths bandwidths d =   t = 1 for both the drug and target interaction profile kernels. We assessed the performance of the methods with the following two quality measures generally used in this type of studies: AUC and AUPR. Specifically, we computed the ROC curve of true positives as a function of false positives, and considered the AUC as quality measure (see for instance). Furthermore, we considered the the precisionrecall curve (), that is, the plot of the ratio of true positives among all positive predictions for each given recall rate. The area under this curve (AUPR) provides a quantitative assessment of how well, on average, predicted scores of true interactions are separated from predictedscores of true non-interactions. For this task, because there are few true drugtarget interactions, the AUPR is a more significant quality measure than the AUC, as it punishes much more the existence of false positive examples found among the best ranked prediction scores ().contains the results for the two RLS-based classifiers, RLS-avg and RLS-Kron, each with three different kernel combinations: @BULLET GIP: using only the GIP kernels, i.e.Page: 3040 30363043@BULLET chem/gen: using only the chemical structure and genomic sequence similarity, so
T.van Laarhoven et al.@BULLET avg: using the average of the two types of kernels, corresponding toFor comparison, we have also included in the table as BY09 (auc) and BY09 (aupr), the best results from the combined BML and KRM methods from Bleakley and Yamanishi (2009). For the GPCR and nuclear receptor datasets, the method with the highest AUC is the same as the one with the highest AUPR, therefore it is included only once, as BY09.
AnalysisUsing only the GIP kernel, our Kronecker product RLS method has AUPR scores of 88.5, 92.7, 71.3 and 61.0 on the Enzyme, Ion Channel, GPCR and nuclear receptor datasets, respectively. These results are superior to the results from using only the chemical and genomic kernels. Overall, the RLS-Kron and RLS-avg methods have comparable AUC scores. However, the RLS-Kron has a better AUPR when using the GIP kernel, and a worse AUPR when using the chemical and genomic kernels. We believe that this problem is due to the poor quality of the chemical similarity kernel, to which the RLS-Kron method is more sensitive. Note also that the RLS-avg method is comparable to Bleakley and Yamanishi's bipartite local model (BLM) approach. The differences are that whereas we use a RLS classifier, they use Support Vector Machines; and whereas we use the average to combine results, they use the maximum value. It is therefore not surprising that when using the chemical and genomic kernels, the results of the RLS-avg method are very similar to their results. In all cases, the best results are obtained when the GIP kernels are combined with the chemical and genomic kernels. With the RLSKron method, we then obtain AUPR scores of 91.5, 94.3, 79.0 and 68.4 on the four datasets, which is an improvement of 7.4, 13.0, 12.3 and 7.2 over the best results reported by Bleakley and Yamanishi (2009).shows the precisionrecall curves for the RLSKron method. Compared with other methods, the RLS-Kron method with the average kernels achieves a good precision also at higher recall values, especially on the larger datasets (Enzyme and Ion Channel).
Kernels' relevanceIn the previous section, we have shown that using a mix of the GIP kernels and the chemical and genomic kernels gives results superior to either type of kernel alone. In order to determine the relative importance of the network topology compared with chemical and sequence similarity, we have investigated the change in prediction performance when varying the parameters  d and  t between 0 (chemical/genomic kernels only) and 1 (interaction profiles kernels only). For computational reasons, we have used 10-fold cross-validation instead of leave-one-out. In, we have plotted the AUPR and AUC scores on the GPCR dataset for the different parameter values. Lighter colors correspond to higher values. Because of space limitations, plots for the other datasets are included in Supplementary Figures S1 and S2. For all datasets, the optimal AUPR is obtained using a mix of the drug and target kernels. Using the parameters  d =  t = 0.5, as we did in the previous section, seems to be a good choice across the datasets. Also note that the choice of  d is more important than the choice of  t. This seems to indicate that the sequence similarity for targets is more informative than the chemical similarity for drugs. A similar observation was also made in Bleakley and Yamanishi (2009). The poor performance of the RLS-Kron method when using only chemical and genomic kernels that we observed in the previous section appears to be due entirely to this uninformative chemical similarity. On the larger datasets (Enzyme and Ion Channel), the optimal AUC is obtained with  d = 1, while that choice gives the worst results on the smaller datasets. This can be explained by noting that when there are few drugs, there is less information available for each entry of GIP target kernel, and hence this kernel will be of a lower quality. We have confirmed this hypothesis by testing different sizedInteractions that appear in the ChEMBL database are marked with '', interactions in Drugbank are marked with '', and interactions in Kegg are marked with ''. The NN column gives the similarity to the nearest drug interacting with the same target, and to the nearest target interacting with the same drug. subsets of the Ion Channel dataset, where we observe the same effect on small subsets. The full results of that experiment are available in Supplementary.
GIP kernel
New predicted interactionsIn order to analyze the practical relevance of the method for predicting novel drugtarget interactions, we conducted an experiment similar to that described by Bleakley and Yamanishi (2009). We ranked the non-interacting pairs according to the scores computed for LOOCV experiments. We estimate the most highly ranked drugtarget pairs as most likely to be putative interactions. A list of the top 20 new interactions predicted for each of the four datasets can be found in Supplementary Tables S3S6.lists the top 10 new interactions predicted for the GPCR dataset. We have looked up these predicted interactions in ChEMBL version 9 (), DrugBank () and the latest online version of KEGG DRUG (). A significant fraction of the predictions (4 out of 10) is found in one or more of these databases. One should bear in mind that a large fraction of the interactions in these databases are already included in the training data, and hence are not counted
T.van Laarhoven et al.In general, the two methods seem to differ in the type of new predictions made. While there is always an overlap of new interactions between the two methods, there is also always a subset of new interactions which RLS-Kron-avg can successfully predict but BY09 fails to predict and vice versa. Moreover, there seems to be a slight tendency of BY09 to generate new successful predictions that are less diverse than those generated by RLSKron-avg. However, we were not able to identify any differential biological bias of the methods toward the detection of specific types of interactions.
Surprising interactionsA closer inspection shows that many of the predicted interactions are not very surprising. For example, the GPCR dataset contains the interaction between clozapine and dopamine receptor D1. The drug loxapine is very similar to clozapine, and it is therefore to be expected that our method also predicts loxapine to interact with dopamine receptor D1. An analogous thing happens with very similar target proteins. In order to provide a quantitative measure of how surprising these predictions are, we computed the similarity of a the drug and target in an interaction pair to their Nearest Neighbor (NN), that is, the most similar drug (with respect to chemical structure similarity) and target (with respect to sequence similarity) in the training set, respectively. These similarities, which we call surprise scores, are listed in the NN column of. An inspection of the surprise scores shows that the majority of the drug target pairs predicted by our method consist of a drug and a target very similar to a drug and a target already known to interact, and therefore they are not very surprising. This phenomenon is common to any computational approach that uses similarity between objects for inferring interaction. To assess the ability of our method to also predict more surprising interactions, we have looked specifically at the predicted interactions where there is no similar drug interacting with the same target or similar target interacting with the same drug in the dataset. We pick a threshold value and consider drugs (targets) to be dissimilar if their chemical (genomic) similarity is less than this threshold. We have used the threshold 0.5 for the chemical similarity and 0.25 for the genomic similarity. When only these 'surprising' pairs are considered, we find, as expected, that fewer of them are present in the ChEMBL, DrugBank and KEGG databases. But we still find more interactions among the highly ranked 'surprising' pairs compared with those that are ranked lower. For example, on the GPCR dataset, 89 of the 500 highest ranked pairs were surprising, and 10 of them (11%) were found in one of the databases (see Supplementary Material for details).
DISCUSSIONWe have presented a new kernel that leads to good predictive performance as measured by AUPR on the task of predicting interactions between drugs and target proteins. An interesting aspect of our GPI kernel is that it uses no properties beyond the interactions themselves. This means that knowing the sequence of proteins and chemical structure of drugs is perhaps not as important for this task as previously thought. For example, on the Ion Channel dataset our method with only the GIP kernel has an AUC score of 98.6 and an AUPR score of 92.7, which improves upon the state-of-the-art, while using less prior information. Besides the GIP kernel, we have also introduced the RLS-Kron algorithm that combines a kernel on drugs and a kernel on targets using the Kronecker product. Compared with previous methods that do prediction with the two kernels independently and then combine the results, this new method represents a small but consistent improvement. By combining the GIP kernel with chemical and genomic information, we get a method with excellent performance. This method has AUPR scores of 91.5, 94.3, 79.0 and 68.4 on four datasets of drugtarget interaction networks in humans, representing an average improvement of 10 points over previous results. The AUPR is a particularly relevant metric for this problem, because it is very sensitive to the correctness of the highest ranked predictions. The large improvement in AUPR suggests that the top ranked putative drugtarget interactions found by our method are more likely to be correct than those found in previous methods. A limitation of all machine learning methods for finding new drugtarget interactions is that they are sensitive to inherent biases contained in the training data. It would be interesting to try and analyze the bias of existing datasets of drugtarget interaction, but this is out of the scope of this article. Note also that the datasets byused in this article do not include any singletons: each drug interacts with at least one target, and each target interacts with at least one drug. This property could affect the cross-validation results, by allowing a limited form of cheating. However, the experiments in Section 4.3 show that our method also works when tested in other ways. A further limitation of the approach used in this article is that it can only be applied to detect new interactions for a target or a drug for which at least one interaction has already been established. Therefore, biologists can use the method as guidance for extending their knowledge about the interaction of a drug or of a target, not for discovering interactions of a new drug or target (that is, one for which no interaction is known). In particular, our method is useful for experimentalist to aid in experimental design and interpretation, especially in solving problems related to drugtarget selectivity and polypharmacology (). There are several ways in which the result might further be improved. So far we have used uninformative choices of the parameters:   = 1,  = 1 and  = 0.5. Of these choices, we have only investigated the last one. Perhaps with tuning of the other parameters better predictions are possible, although one has to be careful not to over-fit them to the data. Another avenue for improvement is in using more information about drugs and targets. Since combining the GIP kernel with chemical and genomic kernels leads to a better predictive performance, perhaps adding different information in the form of additional kernels would yield further improvements. These kernels could be interaction profile kernels based on other types data, such as proteinprotein interaction networks. Similarly, for each pair of interacting drug and target more information is known beyond the fact they interact. For example, the type of interaction, the binding strength, the mechanism of discovery and its uncertainty might all be known. In this article, we have made no use of this additional information, nor did we attempt to predict the type or strength of interactions.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
(28) as new interactions. Moreover, these databases are incomplete, so if a predicted interaction is not present in one of the used databases, this does not necessarily mean it does not exist. For this dataset, we started with only 635 known drugtarget interactions and 20 550 drugtarget pairs not known to interact. Of these 20 550 pairs, we selected 10 as putative drugtarget interaction, and found that at least 4 of them are experimentally verified. These findings support the practical relevance of the proposed method. We compared the newly predicted interactions generated by RLSKron-avg and those generated by Bleakley and Yamanishi (2009), here referred to as BY09. Specifically, given a dataset, for each method we extracted from its top x new predictions those that have been experimentally validated (that is, that could be found in ChEMBL, DrugBank or KEGG DRUG). Table 4 contains a summary of the results for x = 20,50,80. Looking at the top 20 predictions, it seems that the two methods perform best on different datasets. For the top 50 and top 80 predictions, the results indicate the capability of RLS-Kron-avg to predict successfully more new interactions than BY09. We then compared the resulting two sets of confirmed new predictions among the top 50, by looking at common predictions and at interactions uniquely predicted by only one of the two methods. The results for the four datasets can be found in Supplementary Tables S7S10. On the Enzyme dataset, BY09 and RLS-Kron-avg successfully predicted 15 new interactions, with 10 common predictions. On the Ion Channel dataset, BY09 and RLS-Kron-avg successfully predicted 14 and 12 new interactions, respectively, of which only 1 interaction was predicted by both methods. Although BY09 found slightly more confirmed interactions they were less diverse, since 11 of them involve interactions between (different types of) the voltage-gated sodium channel alpha subunit target and only 2 drugs: prilocaine and tocainide. On the other hand, RLS-Kron-avg found interactions of 4 different classes of targets and 10 different drugs. On the GPCR dataset, BY09 and RLS-Kron-avg successfully predicted 22 and 28 new interactions, respectively, with 14 common predictions. Finally, on the Nuclear Receptor dataset, BY09 and RLS-Kron-avg successfully predicted 15 and 20 new interactions, respectively. Among them, 13 were in common.
