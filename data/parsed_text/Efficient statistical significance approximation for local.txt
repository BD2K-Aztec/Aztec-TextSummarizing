Motivation: Local similarity analysis of biological time series data helps elucidate the varying dynamics of biological systems. However, its applications to large scale high-throughput data are limited by slow permutation procedures for statistical significance evaluation. Results: We developed a theoretical approach to approximate the statistical significance of local similarity analysis based on the approximate tail distribution of the maximum partial sum of independent identically distributed (i.i.d.) random variables. Simulations show that the derived formula approximates the tail distribution reasonably well (starting at time points 410 with no delay and 420 with delay) and provides P-values comparable with those from permutations. The new approach enables efficient calculation of statistical significance for pairwise local similarity analysis, making possible all-to-all local association studies otherwise prohibitive. As a demonstration, local similarity analysis of human microbiome time series shows that core operational taxonomic units (OTUs) are highly synergetic and some of the associations are body-site specific across samples. Availability: The new approach is implemented in our eLSA package, which now provides pipelines for faster local similarity analysis of time series data. The tool is freely available from eLSA's website: http:// meta.usc.edu/softs/lsa.
INTRODUCTIONUnderstanding how genes regulate each other and when the regulations are active is an important problem in molecular biological research. Similarly, in ecological studies, it is important to understand how different organisms and environmental factors, such as food resources, temperature, etc., regulate each other to affect the whole community. For generality, we will refer to either genes in gene regulation studies or organisms or environmental factors in ecological studies as factors. Time series data can give significant insights about the regulatory relationships among different factors. Many computational or statistical approaches have been developed to cluster the genes into different groups so that the expression profiles of genes in each cluster are highly correlated (). Most of these methods consider the correlation of expression patterns across the entire time interval of interest. For many gene regulation relationships, the regulation may be active in certain subintervals. Methods based on the global associations of the gene expression profiles may fail to detect these relationships. Several local association-based methods have been developed to address this problem (). Borrowing the idea from local alignment for molecular sequences,proposed to identify local and potential time-delayed (lagged) associations between gene expression profiles. Here, local indicates the two factors are only associated within some time subinterval, and time-delayed indicates there is time shift in the associated profiles. The strength of local association is measured by local similarity (LS) score and the statistical significance of LS score is evaluated by a large number of permutations. The authors showed that such analysis can identify associated pairs that are not detectable through global analysis.used a similar approach to study local associations of microbial organisms in the ocean over a 4-year period, and this approach has been used in several other recent ecological studies ().recently extended the approach to deal with replicated time series where not only statistical significance of LS score can be evaluated, but also a bootstrap confidence interval can be obtained. One of the major limitations of the local similarity analysis is the time-consuming permutation procedure used to evaluate the statistical significance (P-value) of the LS score. When a large number of (G) genes are considered, GG  1=2 gene pairs need to be evaluated. For a type I error , in order to adjust for multiple testing, the Bonferroni corrected threshold is 2=GG  1. For G  5000, the threshold is 4  10 9 when  0:05, which will need over 2:5  10 8 permutations that are computationally prohibitive. Although in practice false discovery rate (Q-value) is used to correct for the multiple comparison problem, still, thousands of *To whom correspondence should be addressed. y The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors. permutations are needed for estimating P-values that were used for Q-value calculation. A fast and efficient theoretical approximation for the statistical significance of the LS score is urgently needed. Recently,provided an upper bound for the p-value corresponding to a LS score. However, the upper bound is not tight. We make the following contributions in this article. First, Feller (1951) developed an approximation theory for the range of partial sums for independent identically distributed (i.i.d.) random variables with mean zero, andextended the results to Markovian random variables. Although the theory developed by Feller (1951) was later further extended by others, it has not been applied to the field of computational biology. We are the first to use Feller's theory to approximate the distribution of LS scores. On the other hand, the theory corresponding to the scenario that the expectation of each random variable is negative was used byand Karlin and Altschul (1993) to derive the statistical significance for local sequence alignment. Such a development was crucial for the wide use of BLAST () in computational biological research. Second, the theory by Feller (1951) and others are valid only when the number of summands (time points) is large. However, it is not clear how large the number of time points should be so that the approximation is reasonable for the LS score. We show through simulations that the approximation from Feller (1951) is reasonable as long as the number of time points is at least 10 for LS score without time delay. In addition, we show how we can adapt Feller's approximation to calculate statistical significance of LS score with time delays. Simulations showed that the resulting approximation is appropriate when the number of time points is above 20. Finally, we applied the developed theory to the analysis of real datasets from gene expression profiles to metagenomics communities, where interesting biological results were obtained. The organization of the article is as follows. In the 'Methods' section, we provide the theoretical bases for deriving the approximate tail probability that the LS score is above a threshold. In the 'Results' section, we use simulations to study the number of data points n needed for the theoretical approximation to be valid. We also use the theoretical formula to study three real datasets arising from different high-throughput experiments: microarray, molecular finger printing and NGS tag-sequencing. The article concludes with some discussion on further applications and future research directions.
METHODSConsider time series data for two factors with levels X 1 , X 2 ,    , X n and Y 1 , Y 2 ,    , Y n , respectively. The first step is to normalize the expression levels of each time series so that they can be regarded as normally distributed. Without loss of generality, we assume that they are already normally distributed. Second, dynamic programming algorithm is used to find intervals I  i, i  l  1 and J  j, j  l  1 of the same length l such that the absolute value of S  P l1 k0 X ik Y jk is maximized, which is referred to as local similarity (LS) score (). Here the starting positions of the subintervals i and j, and the length of the intervals l are not pre-specified and are all derived from the data. In most practical problems, investigators may only be interested in local associations with short delays, for example, the starting positions of the intervals in the two time series i and j are at most D units apart, i.e. ji  jj D. We denote the LS score with time delay at most D units by LSD. In the third step, statistical significance for the LS score corresponding to the null hypothesis that the two factors are not associated is approximated by permuting one of the time series data many times and calculating the fraction of times that the LS score for the permuted data is higher than that for the real data (). With such a permutation approach for P-value, the authors implicitly assumed that the observations for the samples at the different time points are independent under the null model. However, in many practical problems, in particular, time series data, the observations for each factor may depend on each other and the permutation-based approach may not work well. Another drawback of the permutation-based approach is that computational time scales linearly with the inverse of the P-value precision and is computationally expensive for large dataset of long series. Here, we provide theoretical formulas to approximate the P-value overcoming both problems.
Maximumabsolute partial sums of i.i.d. and Markovian random variablesTo derive theoretical formulas to approximate the P-value related to the local similarity score, we resort to classical theoretical studies on the range of partial sums for i.i.d. random variables with zero mean (). The results from such studies when the expectation of the random variables is negative played key roles in the derivation of statistical significance for local sequence alignment, e.g. BLAST (), which forms a milestone in the field of computational biology (). On the other hand, the theoretical results on the approximate distributions when the mean is zero have not been used in the computational biology community. Based on these previous theoretical studies, we present some theoretical results regarding the range of partial sums for either i.i.d. or Markovian random variables.studied the approximate distribution of the range of the sum of n random variables with mean 0. Let Z i be i.i.d. random variables such that EZ i   0 and VarZ i   2. LetThe range is defined as R n  M n  m n. It is shown in:VarR n =  4nlog2  2=. Using the theory of BachelierWiener processes, Feller (1951) approximated the density function of R n = by (equations 3.7 and 3.8 in that article) n; r,where,Thus,Since the summation in equation 3 is an infinite sum, we need to decide when to stop for numerical approximations. To achieve this objective, we next give an upper bound for the tail in equation (3). This upper bound can be used to determine when we stop the summation inThus, for an error threshold , we can choose K so thatThen we approximate PR n = ffiffi ffi n p  ! x byfor the approximation in equation (7). Similarly, we can define L n   min 0 i5j n ; S j  S i . Since EZ i   0, L n has the same limiting distribution as H n. It can also be seen easily that R n  maxH n , L n . When x is large, the probability of fH n 4xg \ fL n 4xg will be small andThe approximation works well when x ! 2. However, when x is small, the approximation does not work well and actually the above quantity can be larger than 1.
Statistical significance for local similarity scoresWe next use the theory outlined in subsection 2.1 to approximate the statistical significance in local similarity analysis. For time series data of two factors X 1 , X 2 ,    , X n and Y 1 , Y 2 ,    , Y n that have been normalized as in, we use the dynamic programming algorithm to calculate the LS score with maximum delay D denoted as s D. Corresponding to the null hypothesis that the two time series data are not related, the statistical significance is given byLSD  max i, j, l;jijj D j P l1 k0 X ik Y jk j: First consider the case that, 2,    , n. Assuming that both X i and Y i are independent standard normally distributed, we have EZ i   0 and 2  EZ 2 i   1. Therefore, we can directly use the theory developed above in equations (6) to calculate the P-value. Next let us assume D40. Let S d n be the LS score with no time delay for the pair of series (d  0, AE 1, AE 2,    ,where we consider the data as missing when the subscript is outside the range 1, n and the pair is not considered when the LS score is calculated. When n is sufficiently large, S d n for d  0, AE 1, AE 2,    , AE D can be considered as approximately identically distributed because S d n is the LS score for n  d pairs of i.i.d. normal random variables. The tail distribution function of S d n = ffiffi ffi n p  can be approximated by equation (6). Note LSD  max D dD S d n : To derive an approximate cumulative distribution function of LSD, we pretend that S d n , d  0, AE 1, AE 2,    , AE D are independent although they are not. Then,Thus, the tail probability of LSD can be approximated byIn the following numerical calculations shown in, we only use the first 200 terms to approximate the infinite series in the above equation. From equation (10), we can obtain the approximate density function of R D n = ffiffi ffi n p  by. The histogram of local similarity scores LSD= ffiffi ffi n p for n  200 and D  0, 1, 2, 3 together with the theoretical approximate density function given in equation (11)
Dealing with replicatesTo reduce the effect of biological and/or technical variation on the LSA results, replicate experiments are frequently carried out (). An extended LSA (eLSA) approach was developed for time series data with replicates (). First, for each sample the replicate data at each time point were summarized by a function, for example, the average over the replicates. Second, the local similarity score is calculated using the averages for the sample pairs. Third, statistical significance for testing the hypothesis that the two sequences are related is obtained by randomly shuffling the data along the different time points. Finally, the bootstrap confidence interval for the LS score is obtained by bootstrapping the data at each time point by sampling from the observed data with replacement. With the theory developed above, we can significantly speed up the process of evaluating the statistical significance of the LS score in the third step. Let X m  X m 1 ,    , X m n  and Y m  Y m 1 ,    , Y m n  be the m-th replicate for the time series data, m  1, 2,    , M. The essence of eLSA is to calculate the local similarity score of U i  FX 1 i ,    , X M i  and V i  FY 1 i ,    , Y M i , where F is the summarizing function. Then by replacing X and Y in non-replicated case with U and V, respectively, similar approaches can be used to obtain the P-value. In particular, ifwhere the function L is defined in equation (10).
Data normalizationIn reality, normality may not be satisfied by the raw data. Through normalization, the normality of the data can be ensured for subsequent analysis. To accommodate possible nonlinear associations and the variation of scales within the raw data, we apply the following approach to normalize the raw data before any LS score calculations as described in Li (2002). We use x i to denote the original raw data of the i-th time spot of a factor X. First, we take r k  rank of x k in fx 1 , x 2 , :::, x n g. Then, we take s k   1 r k =n  1   , where  is the cumulative distribution function of the standard normal distribution. In case of small n, we find that the above transformed data S  s 1:n do not necessarily follow a standard normal distribution closely. When the variance is not 1 and mean is not zero, it will cause the LS scores calculated to be smaller than that expected from the theory and can lead to unexpected high P-values. To overcome this difficulty, we further scale and shift S  s 1:n using the Z-score transformation, such that z i  s i  " S= S. We will take Z  z 1:n as the standardized normalization of X.
Simulation studies and applications to real datasetsIn deriving the approximate P-values for local similarity analysis in subsection 2.2, we made several simplifying assumptions, whose effects on the accuracy of the approximations were evaluated by simulations. We first study the accuracy of the approximation for the tail probability of R n = ffiffi ffi n p  in equation (10) using simulations for local similarity analysis. Firstly, for given number of time points n, we generate n pairs of i.i.d. standard normal random variables X i , Y i , i  1, 2,    , n, where X i and Y i are independent. Secondly, the dynamic programming algorithm implemented in eLSA () package is used to calculate the local similarity score with at most time delay D, LSD. Thirdly, we repeat the first two steps 10,000 times and obtain the empirical distribution of LSD= ffiffi ffi n p . We compare the empirical distributions with the theoretical approximation given in equation (10) with  1. We then apply our method to analyze three real datasets. The first one is a microarray yeast gene expression dataset, synchronized by the cdc-15 gene, from Spellman et al.
RESULTS
SimulationsThe approximate P-value for the local similarity score given in subsection 2.2 is only applicable when the P-value is small and the number of time points is large. Thus, it is important to know the range of applicability for the approximation.gives the theoretical tail probability based on equation (10) (2nd column) and the simulated probability PLS0= ffiffi ffi n p ! x (3rd to 9th columns) for different number of time points when D  0. It can be seen that the theoretical tail probability is very close to the simulated probability when the theoretical P-value is less than 0.01. The approximation is even reasonable when the number of time points is just 10. In general, the theoretical tail probability is slightly larger than the simulated values when D  0 (and Supplementary). When D  1, 2, 3, the theoretical approximation is close to the simulated tail probability when n ! 20 and the theoretical P-value is less than 0.01 (for D  3 seeand also see Supplementary Tables S2S4 in Supplementary Results). Thus, if we use the theoretical approximate distribution to calculate the P-value, we will be slightly conservative in declaring significant associations. For relatively small value of x, the theoretical approximation can be much larger than the simulated tail probability. One potential explanation is that R D n = ffiffi ffi n p  is stochastically increasing with respect to n and that the theoretical approximation becomes closer to the simulated distribution of LSD= ffiffi ffi n p  as n increases. We also tested if PLSD= ffiffi ffi n p  ! x  1  1  PR 0 n = ffiffi ffi n p  ! x 2D1 is generally true using the simulated tail probabilities in, and it can be clearly seen from Supplementary Tables S1S4 that this relationship is indeed reasonable, indicating that S d n , d  0, AE 1,    AE D can effectively be considered as independent. In equation (11), we derive the approximate density function of R D n = ffiffi ffi n p . We superimpose this approximate density function to the histograms of the simulated LSD= ffiffi ffi n p  at n  200 and D  0, 1, 2, 3 in. Several observations can be made from the figure. First, the values of LSD= ffiffi ffi n p  increase as a function of D as expected. Second, the approximate theoretical density function is slightly lower than the simulated frequency when x is lower than the mode of the theoretical distribution and is slightly higher than the simulated frequency when x is larger than the mode of the theoretical distribution, thus the tail probability based on the theoretical approximation is slightly higher than the simulated value. We next see how P-values (P theo ) derived from theoretical approximation compare with that of permutation (P perm ) given the same data (Supplementary) in simulation. Starting from D  0 and n  20, points in scatter plots become concentrated on the diagonal line (where P perm  P theo ) and they become more aligned as n increases. This indicates an increasing rate of agreement between the theoretical and permutation P-values, representing their reasonable approximation to the null distribution in spite of the inherent variance associated with the permutation procedures. The same is true with D40, and the theoretical approximation become significantly closer to the permutation one as n increase. Though, when D40, the variation seems more substantial and close alignment only starts at n  30. In summary, we can see that if we are interested in statistical significance given some type I error threshold, the theoretical approach shall provide results comparable with that from permutations starting from n  20.
The CDC datasetThe CDC dataset consists of the expression profiles of 6177 genes at 24 time points. It is extremely time consuming to approximate the P-values for all the gene pairs using permutations. Thus, we only randomly selected 25 genes and estimated the P-value for each of the 300 gene pairs by permuting the original data 1000 times. We then compared P theo s from our theoretical approximation to P perm s from the permutation approach, shown in. It can be seen from the figure that P theo is highly positively correlated with P perm , but P theo is slightly higher than P perm , indicating that it is conservative when we declare statistical significance using P theo. In particular, we compare the gene pairs declared as significant by either P theo or P perm for the type-I error threshold 0.05 in Supplementary Table S5. For all the situations considered, none of P theo is less than 0.05 when P perm 40:05. Among the gene pairs with P perm 0:05, over half of them are declared as significant by P theo. For the local similarity analysis, using D  0, we have 233 (78%) out of 300 found to be non-significant by both theoretical approximation and permutations. Among the remaining, 48 (16%) are found significant by both methods, and in total 281 (94%) are in agreement. The results are similar with D  1,2,3, with 262 (88%), 262 (88%) and 262 (88%) in agreement, respectively. Moreover, all-to-all pairwise analysis of the whole CDC dataset with D  3 and permutation 1000 times cannot be completed in 100 hours on a 'Dell, PE1950, Xeon E5420, 2.5 GHz, 12010 MB RAM' computing node, while, using the theoretical approach, it finishes in 10 hours on the same node.
The SPOT datasetThe SPOT dataset consists of 10-year monthly (114 time points) sampled operational taxonomic unit (OTU) abundance data. As above, we selected 40 abundant OTUs from the SPOT dataset with the criteria 'the OTU occurs at least 20 times with minimum relative abundance 1% and has less than 10 missing values'. We summarize P-value comparison for local similarity analysis in Supplementary Table S6 and. With D  0 and type-I error 0.05, we have 488 (63%) out of 780 found non-significant and 261 (33%) significant by both methods. In total, 685 (96%) are in agreement. All of the remaining 31 (4%) pairs are significant by P perm but non-significant by P theo. The results are similar with D  1,2,3, where 733 (94%), 723 (93%) and 727 (93%) are in concordance, respectively. ThereNote: The theoretical approximate probability based on equation (10) with  1 is given in the 2nd column and the simulated probability that LSD= ffiffi ffi n p ! x is given in the 3rd to the 9th columns. D  0. are about 6-7% associations significant by P perm but non-significant by P theo , showing that P theo is more conservative. The agreement of the significant results between P theo and P perm for the SPOT dataset is better than that for the CDC dataset. This can be explained by the fact that the number of time points for the SPOT data (114) is much higher than that for the CDC dataset (24) and the approximation is better when the number of time points is large.
The MPH datasetThe MPH dataset consists of 130, 133 and 135 daily sequenced samples from feces, palm and tongue sites of a female ('F4'), and 332, 357 and 372 samples from a male ('M3'), respectively (). The genus level OTU abundance is used in our analysis. There are 335, 1295 and 373 unique OTUs from feces, palm and tongue sites of 'F4' and 'M3', respectively. With D  3, we analysed the MPH dataset with local similarity analysis. Because of the intra-person variability (both time and site) of the human microbiota, one important step in analysing human microbiota datasets is to identify the core (persisting) group of microbes for a specific body site of a person. Based on the discussion in, we consider core OTUs as those showing in at least 60% of samples from the same body site of one person. Using this criteria, we identified 45, 252 and 41 core OTUs for the feces, palm and tongue sites of 'F4', and 59, 269 and 56 core OTUs for the corresponding sites of 'M3', respectively. Subsequent analysis showed these symbiotic core microbes are highly synergetic. We used local similarity analysis as our main approach and report significant local associations with P-value 0.05, Q-value 0.05 and Aligned Length ! 80% time points (). We found 194 significant associated pairs within the subset formed by the 45 core OTUs of the 'F4' feces samples and the intra association rate (the average degree divided by the number of OTUs minus one in an association subnetwork) is 20%. The rates are 32% and 20% for 'F4' tongue and palm samples, whereas 53%, 55% and 72% for 'M3' feces, tongue and palm samples, respectively. These percentages translate into a picture of high connectivity between these OTUs, supporting their role as crucial players in the corresponding microbiota. However, are these site-specific significant local associations shared across individuals? We used Sorensen index Q s to measure the similarity between significant set of local associations for any two samples (). We consider only the OTUs common to the two samples. Suppose the subsets of significant local associations between their common OTUs are S 1 and S 2 for the two samples. Then the Sorensen index is defined asNote: The theoretical approximate probability based on equation (10) with  1 is given in the 2nd column and the simulated probability that LSD= ffiffi ffi n p ! x is given in the 3rd to the 9th columns. D  3.. The comparison of P theo and P perm for all-to-all pairwise local similarity analysis of 25 factors from the CDC dataset ('cdc25') and 40 factors from the SPOT dataset ('spot40'). Columns D0 to D3 are for D  0, 1, 2, 3, respectively for local similarity analysis. The tool is freely available from eLSA's website: http://meta.usc.edu/softs/lsa.
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
L.C.Xia et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Fast local similarity statistical significance approximation at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
DISCUSSION In this article, we provide theoretical formulas to approximate the statistical significance of local similarity analysis for time series data, which make it possible to evaluate the P-values of comparisons of time series data for a large number of factors such as genes in gene expression analysis or OTUs in metagenomic studies, originally impractical to carry out using the permutation-based approach. The theoretical approximation is mathematically sound with specified assumptions of data distributions verifiable before the analysis. The permutation test, however, heavily depends on data-specific empirical distributions and can be biased by the numerical properties of specific data as well as its intrinsic variability. In addition, if we are interested in the tail distribution as in most applications, the permutation and theoretical methods are mostly in agreement with each other in predictions given the same type-I error threshold. We have results from setting threshold to lower values (0.01, 0.005, 0.001, etc.) showing high overall agreement rate (data not shown). Therefore, from the practical point of view, we can substitute permutations with the theoretical method in such applications. Moreover, from the simulations and our real analysis, P theo is more conservative than P perm a property particularly useful in biological applications prone to substantial number of false positives, such as the microarray analysis (Pawitan et al., 2005). The most important reason for us to embrace the theoretical method is computational efficiency. As shown in Xia et al. (2011b), for a given type-I error, , the time complexity of computing P prem , is ODMN=, where D is the delay limit, N is the sample number and M the replicate number. With P theo , we may compute and store (LS score, P-value) pairs into a hash table, before any pairwise comparison. Then, for each comparison, it only costs constant time O1 to read out P theo and is independent of D, M, N and , a strongly desired feature for large scale analysis. The superiority of efficiency is evident from Supplementary Figure S3, in which, the averaged time cost of analysing four sets of 40 factors, 114 time points series was compared between theoretical approach and 1000 times permutation. The per-pair time cost is about 40 seconds for P perm while negligible for P theo and is independent of sample size, which is a big saver of computing resource, energy and research time. 5 CONCLUSIONS The recent advent of high-throughput technologies made possible large scale time-resolved omics studies (proteomics, transcriptomics, metagenomics), tracking hundreds, thousands or even tens of thousands of molecules simultaneously. Time-series generated from these studies provide an invaluable opportunity to investigate the varying dynamics of biological systems. However, to make full use of huge datasets, accurate and efficient statistical and computational methods are urgently needed at all levels of analysis, from accurate estimation of abundance and expression levels, to pairwise association and network analysis. The theoretical statistical significance approximation we proposed in this work can serve as an efficient alternative for calculating P-values in local similarity analysis. Its time cost is always constant, which reduces the computational burden in a large scale pairwise analysis. For example, in metagenomics, after short read assignment and abundance estimation (Xia et al., 2011a; He and Xia, 2007), profiles of thousands of microbial OTUs are available. Before this work, pairwise local association analysis with this number of factors was hardly tractable using permutation procedures, if not impossible. Parallel computation and hardware acceleration or some pre-clustering and filtering approaches were required, increasing the difficulty of analysis. With the new method, researchers can quickly compute the statistical significance for all OTU pairs on desktop computers, allowing on-the-fly network mining and analysis. After analysing the MPH dataset with the new method, we found body-site-specific human microbiota core OTUs are highly coordinated. There exist robust site-specific associations across individuals. We implemented the new method in the eLSA package (Xia et al., 2011b), which now provides faster pipelines
