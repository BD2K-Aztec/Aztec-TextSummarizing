Motivation: In searching for genetic variants for complex diseases with deep sequencing data, genomic marker sets of high-dimensional genotypic data and sparse functional variants are quite common. Existing sequence association tests are incapable of identifying such marker sets or individual causal loci, although they appeared powerful to identify small marker sets with dense functional variants. In sequence association studies of admixed individuals, cryptic relatedness and population structure are known to confound the association analyses. Method: We here propose a unified marker wise test (uFineMap) to accurately localize causal loci and a unified high-dimensional set based test (uHDSet) to identify high-dimensional sparse associations in deep sequencing genomic data of multi-ethnic individuals with random relatedness. These two novel tests are based on scaled sparse linear mixed regressions with L p (0 < p < 1) norm regularization. They jointly adjust for cryptic relatedness, population structure and other confounders to prevent false discoveries and improve statistical power for identifying promising individual markers and marker sets that harbor functional genetic variants of a complex trait. Results: With large scale simulation data and real data analyses, the proposed tests appropriately controlled Type I error rates and appeared to be more powerful than several prominent methods. We illustrated their practical utilities by the applications to DNA sequence data of Framingham Heart Study for osteoporosis. The proposed tests identified 11 novel significant genes that were missed by the prominent famSKAT and GEMMA. In particular, four out of six most significant pathways identified by the uHDSet but missed by famSKAT have been reported to be related to BMD or osteoporosis in the literature. Availability and implementation: The computational toolkit is available for academic use:
IntroductionDeep sequencing technologies have been generating huge amounts of data of rare and common DNA sequence variants. A number of sequence association tests have been developed to identify marker sets, e.g. a group of SNPs or CNVs (copy-number variations), that contain functional genetic variants. Most of these tests, however, do not jointly model cryptic relatedness, population structure and other covariates. With the growing demand of analyzing next generation sequencing data of multi-ethnic individuals, linear mixed models have become popular because of their demonstrated effectiveness in accounting for sample relatedness () and population structure which occurs when there are large-scale systematic differences in genetic ancestry among individuals in a sample. Typical examples include individuals with various levels of immigrant ancestry and more recent shared ancestors than one would expect in a homogenies population. Cryptic relatedness, refers to the presence of relatives in a sample of ostensibly unrelated individuals, could pose more serious confounding than population structure (), especially for samples from small and isolated populations (). Accounting for population structure is more challenging when family structure or cryptic relatedness is also present (). We paved the way to correct for the effects of both confounders jointly. Within the framework of linear mixed models, famSKAT () and GEMMA (Genome-wide Efficient Mixed Model Association) () appeared as two powerful sequence association tests for identifying small marker sets that harbor dense functional genetic variants. FamSKAT is a set based test which is an extension of SKAT to be applicable to family data. GEMMA is a computationally efficient method for fitting multivariate linear mixed models. These prominent tests require that the number of markers in a testing set is much smaller than the sample size. However, in deep sequencing studies, one encounters quite often high-dimensional data sets (HDS), where the number of marker loci is larger than the sample size and the number of functional variants is very small. The aforementioned tests are incapable of identifying such sparse HDS and the functional variants. Some sparse regression methods were developed to localize individual functional markers from high-dimensional marker sets, jointly modeling pedigree structure and population structure. They include Lasso (), Ridge regression (, Elastic-net () and the USR that we proposed recently (). However, these methods yield biased solutions and are ineffective to prevent false discoveries of random markers and high-dimensional marker sets irrelevant to functional variants. In this article, we first present a unified test (uFineMap) for accurately localizing individual causal loci. The uFineMap is a marker wise test under a scaled sparse linear mixed regression, which jointly models marker wise effect, relatedness and population stratification. It applies scaled L p (0 < p < 1) norm regularization to generate a debiased solution. Next, we present an additional significant test (unified high-dimensional set based test, uHDSet) for identifying highdimensional sparse associations in deep sequencing genomic data of related individuals. The uHDset integrates the marker wise statistics of the uFineMap to identify susceptible high-dimensional marker sets. In the uHDSet, the dependence among markers is modeled to appropriately control set-based Type I error rates. Under extensive simulations, the uFineMap outperformed the GEMMA () and a Scaled Lasso based method (). The uHDSet yields higher statistical power than famSKAT and GEMMA. Applications to Framingham Heart Study also show that our methods yield novel interesting candidate genes and pathways for follow-up studies, showing its advantages over the two compared prominent alternative methods. Finally, caveats of the proposed methods and perspective future efforts are discussed.
MethodsWe focus on constructing statistical tests for high-dimensional genetic data with cryptic relatedness. We propose two significance tests: uFineMap test (single marker/variant test) and uHDSet test (unified high-dimensional set test or whole regional test). Similar to B hlmann (2013) and Javanmard and Montanari (2014), we develop uFineMap significance test for single variants based on the scaled sparse regression (), which is a generalization of ordinary sparse regression. Furthermore, we build new statistics for the uHDSet test based on a combination of marker wise statistics. The uHDSet test facilitates us to identify susceptible genes or genetic regions instead of single variants.
Unified scaled L p norm regularized regressionAt first, we need to define some basic notations. Let n denote the number of subjects; m denotes the number of independent variables (SNPs); and L represents the number of covariates. Suppose we have dependent variable Y  y 1 ; y 2 ;. .. ; y n  T , which stands for phenotype for each subject. X  x 1 ; x 2 ;. .. ; x n  is a nxm matrix where the row x i  x i1 ; x i2 ; ::; x im  T represents genotype data for the ith subject. Typically, genotypes are coded as 0, 1 or 2 which denote the number of copies the minor allele. U nn  u i;j  is the kinship matrix or IBD (identity-by-descent) matrix. The kinship coefficient u i;j measures the relatedness between individual i and j. W  w 1 ; w 2 ;. .. ; w n  is an nxL matrix, where w i  w i1 ; w i2 ;. .. ; w iL  T represents the covariates, e.g. age, sex, height and weight. We assume that the phenotypes, genotypes and covariates are associated with the following linear mixed model:where e $ N0;b  b 1 ; b 2 ;. .. ; b m  T are the corresponding regression coefficients. Both Emma and Gemma methods can evaluate the variance component ratio r 2 U =r 2 e of covariant matrix R. In this article, we use Gemma method to evaluate the r 2 U =r 2 e ratio. In model (1), the regression coefficients b  b 1 ; b 2 ;. .. ; b m  T represent the effect of variants which are the most important variables we are interested in. However, the high-dimensionally of genetic data will easily lead to over-fitting problem under regular regression model. To overcome this issue, a general form of the unified sparse regression model with L p (0 < p < 1) norm regularization was proposed by USR paper with the following minimization problem (where the L p (0 < p < 1) norm regularization is defined byAs is well-known () that L p (0 < p < 1) norm regularization results in a sparser solution than L1 norm regularization, which was widely popularized by the Lasso (least absolute shrinkage and selection operator)Unified tests for fine-scale mapping and identifying sparse(). In particular, previous simulation results insuggest that the use of the L 0.3 norm regularization, in order to achieve a proper sparsity level of the solution with great computational efficiency. To keep the method flexible, we also offer users different choices for the L p (0 < p < 1) norm in our R code. In addition to the selection of the L p norm, the regularization (tuning) parameter k largely affects the solution of Equation (2) as well. In general, the choice of k is regarded as a difficult problem. Popular methods for this purpose include the minimization of either the Bayesian information criterion (BIC) or the Akaike information criterion (AIC) as a function of k, cross-validation, and stability selection (Meinshausen and B hlmann, 2010) to select k. However, none of these methods can be applied to control the Type I error, especially for a region-based significance test. By adopting the idea of scaled sparse linear regression (), which jointly estimates the regression coefficients and the noise level of the data, we avoid the regularization parameter selection problem. The estimated noise level is used for bias correction. The obtained de-biased estimator is applied to perform marker wise significance tests for each variant. The scaled L p norm based sparse regression model is given byIn the unified scaled sparse regression the tuning parameter k is updated iteratively, which requires an initial value k 0. However, the sensitivity of the results to the selection of k 0 is low. Moreover, debiased estimators can be constructed to balance out the bias in the estimated noise level ^ r and the bias caused by the L p norm regularization, which are both proportional to the initial k 0. The asymptotic distribution of the de-biased estimators can then be derived without major difficulties. To solve the optimization problem (3), we combine the algorithm for unified L p norm based sparse regression with that for the general scaled sparse regression () and propose the following algorithm.The algorithm for unified scaled sparse regression (3)Step 1: Data centralization:Lasso, Ridge regression, and many other popular regression methods utilize a regularization term, in order to obtain a stable solution on an HDS. The L 1 norm regularization term used in Lasso typically shrinks many regression coefficients to zero. This, however, introduces a bias making the non-zero regression coefficients smaller in magnitude. Adopting the idea of unbiased estimation (), we develop a unbiased estimator to recover the unbiased regression coefficients, and to assess the corresponding asymptotic Gaussian distribution. A detailed algorithm is presented below.
The algorithm for unbiased estimatorStep 1: Set c  ^ k ^ r , where ^ k and ^ r are the estimated parameters of the unified scaled sparse regression (3)Step 2: Set Z  X T R 1 X=n Step 3: For i  1,2,. .. ,m, solve u i by the following constraint convex program:Because the calculation of each u i is independent. To increase the computation speed, we parallelize the calculation.If any of the above problems is not feasible, then set M  I mmStep 5 : Define the unbiased estimator bywhere ^ b is the solution of formula (3).
Hypothesis tests and confidence intervalsTo clarify the problem, we assume Y is the covariates adjusted phenotype. After ignoring the covariates, the true model becomes:where b 0 is the ground truth regression coefficients and stands for true signal. We define the sparse level of b 0 as S 0  fi 2 f1; 2;. .. ; mgj b 0;i 6  0g. In this article, we apply a weak assumption for the sparse model, which is s 0  jS 0 j  o ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi n=logm p . Without any further notice, we always assume that this assumption holds. Although the sparse ground truth is preferred, our method is also robust for the non-sparse setting, according to the simulation result in Supplementary Figs 5.8S and 5.9S in the Appendix.
uFineMap testFor each predictor i, we need to develop a significance test to determine whether the corresponding regression coefficient b i is significant or not. For a specific i 2 f1; 2;. .. ; mg, we define the null hypothesis H 0: b i  0 versus the alternative hypothesis H 1 : b i 6  0 Supposing the model (6) stands and considering the unbiased estimator (5), we prove that the following asymptotic distribution holdswhere M is defined by formula (4). The detailed proof is given in Theorem 1 inWith this theorem, we can directly derive the significance test for each marker, e.g. uFineMap test. The p-value for each variable can be calculated by the following:where U is the cumulative distribution function of a standard normal distribution.
uHDSet testThe next major question is how to control the family-wise error rates (FWER) to claim the whole significant genetic region. Besides BonferroniHolm correction or some existing multiple testing correction methods to control the FWER or false discovery rate (). We are commitment to developing a powerful and efficient multiple testing adjustment, taking dependence into consideration, which would be more powerful than uncorrelated adjustment. For uHDSet test, the null hypothesis isFor an arbitrary z 2 R, the following equation holdsPS zjX  P max i2f1;2; ... ;mgwhere W $ N0; ^ r 2 MX T R 1 XM T . The proof is presented in Theorem 2 in Appendix. Under null hypothesis H 0: b 1  b 2 . ..  b m  0, statistic S is asymptotically equivalent to the maximum of a series of dependent v 2 1 variables, whose distribution relies on the design matrix X T R 1 X. For any fixed matrix X T R 1 X, we simulate its distribution and use its quantile to estimate the p-value of the uHDSet statistic S.
ResultsTo validate our proposed tests, we conducted simulations under various types of pedigree structures to demonstrate their performances comprehensively, in terms of both Type I error rates control and statistical power.
Nuclear family simulationWe use the following linear model to generate simulation data with nuclear family structure (each family consists of two children and their parents): Y  bXb 0  e; e $ N0; Rwhere b is the effect size for causal marker; R  1=3U  2=3I. We randomly assign 30% of variables to be rare variants [minor allele frequency (MAF) < 1%], 20% of variables to be low frequency variants (1% < MAF < 5%) and the rest variables to be common variants (5% < MAF < 50%).
Data generationThe basic procedure of performing nuclear family simulation is as follows:Step 1: Given MAF for each variable, set the ground truth b 0 with 10 causal variants (five of them are rare variants); set the correlation matrix K ij  q jijj , where i; j 2 f1; 2;. .. ; mg and the coefficient q determines the correlation for each pair of variables. We set q  0:6 throughout the simulation.Step 4: Generate the vector of trait values of n subjects according to model (9) for a given b. The selection of b is discussed at Section 3.1.3.
Type I error rates evaluationTo validate if the proposed significant tests can control the Type I error rates, we generated genotype data by the procedure in Section 3.1.1, setting n  500 and m  1000. The trait value is generated by Y  e $ N0; R. We replicated this simulation 1000 times and recorded the corresponding p-values to draw quantilequantile (Q-Q) plots. Under null hypothesis, the quantile of the p-value should follow the uniform distribution U(0,1).illustrates most points are aligned near the diagonal line, which is expected. The two dashed curves represent 95% concentration band (CB). With all the points concentrated within the 95% CB, we concluded that the observed p-values follow the uniform distribution over interval (0,1). The Q-Q plot assures that the Type I error rates of uFineMap test is appropriately controlled.shows that the distribution of uHDSet test's p-values agrees with the uniform distribution, indicating the validity of the adjustment of multiple testing. Therefore, we can draw a conclusion that both of our uFineMap test and uHDSet test can control the Type I error rates appropriately.
Statistical power analysisThe design matrix is simulated by the same procedure as in Section 3.1.1. As typical, we set the nominal significance level at 0.05 and generated the trait values with respect to various values of heritability H. We define the heritability H to be the ratio of variance between true signal and the total variance of trait value, which can be explicitly written as:Then we have b  ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiHVare 1HVarXb 0  qcovered. We set two of the causal variants to be rare variants and the other four as common variants. We increased the heritability H from 0 to 1 and calculated its power at each point. For the sake of saving computational time, we only repeated the procedure 2000 times for each given H. The statistical power for the uFineMap test is defined as:05=T, where T is the simulation replicates; Pi is the p-value from uFineMap test of ith marker and I() is the indicator function. For uHDSet test, Pt represents the p-value calculated at t-th simulation. We define the empirical statistical power to beTo evaluate our method, we compare the uFineMap test with other high-dimensional inference methods [e.g. Scaled Lasso (), single marker v 2 test and Gemma (. For the uHDSet test comparison, we additionally consider a popular regional based association test, famSKAT (). The results are shown inand 4, respectively. In, the uFineMap test performs uniformly better than Scaled Lasso test, Gemma and the single marker test. It indicates that the uFineMap test has a noticeable power gain to identify both common and rare causal variants.evaluates different methods' performance with respect to sample size changes. It illustrates that our uFineMap test overall outperforms other two methods especially when the sample size are small. Meanwhile, all the competing methods show a similar pattern for a large sample problem. Similar to Figs 3, 4, 5 and 6 indicate that the statistical power of all regional tests will increase with the growth of sample size and heritability, which is consistent with our expectation. In addition, at the lower sample size area, our uHDSet test performs much better than famSKAT and Gemma. With the increase of the sample size, the powers of the three methods converge to the same value. In conclusion, our proposed tests have higher power than competing existing methods regardless of heritability. Meanwhile, it performs almost equally well for large sample size data.
Complex family simulationTo further compare different methods fairly, instead of using our own or over-simplified simulation data, we used the software SeqSIMLA2. SeqSIMLA2 can simulate sequence data in families under quantitative disease models. Using SeqSIMLA2, we generate quantitative traits for 8 large families with 67 individuals (the family tree for each family is shown in Supplementary Appendix.1S) with 1000 SNPs in total.
Type I error rates evaluationTo verify the validity of our proposed tests, we need to evaluate if the Type I error is well controlled under the null hypothesis. Supplementary Figs 5.1S and 5.2S (in Appendix) show the Q-Q plots for uFineMap test and uHDSet test, respectively. The resultsindicate that the Type I error rates is appropriately controlled in complex family structure.
Power comparisonWe randomly assign 50 causal variants (25 common, 25 rare) to generate the continuous phenotype. Additionally, we proposed two simulation setting for markers effects. We assign all causal markers to be positively related to the trait value for the same causal direction setting. For the different causal direction setting, half of the causal markers are randomly given a negative relationship with the trait value. Figures 7 and 8 present the comparison of three competing methods under same direction and different direction settings, respectively. The similar patterns also occurred at a marker wise tests comparison. To make the presentation concise, we only show the result of regional tests, and the result of marker wise tests can be found in the Appendix (Supplementary Figs 5.3S and 5.4S). We can draw the conclusion that all three methods are robust with respect to causal variants direction. But our uHDSet test is almost uniformly more powerful than Gemma and famSKAT for SeqSIMLA simulation data.
Analysis of sequence data from Framingham Heart StudyTo demonstrate the effectiveness of our methods for real genetic variants detection, we applied them to the analysis of sequence data of Framingham Heart Study. This dataset contains both GWAS and next generation sequencing (NGS) data from 4229 subjects with HipBMD data. We used the FISH () method for genotype imputation and selected HipBMD as the phenotype data. After quality control, we obtained 3322 individuals with 6 500 475 SNPs in total. We apply two kinds of data analysis strategies: whole genome analysis and pathway-based analysis.
Whole genome analysisWe separate each chromosome into several genetic windows and then apply our uFineMap and uHDSet tests in each window. We set the window size to be 100 kb base pairs. After the separation, the whole genome is separated by a total number of 16 514 sets of markers. The phenotype is adjusted by the covariates and the top 10 principle components of the genotype before the application of the proposed method. Following the same process as in the simulation studies, we obtain the results and draw the Manhattan plots for 22 chromosomes, as shown inand 10, respectively. Additional results of Manhattan plots for the whole genome (i.e. from chromosome 1 to 22) with higher resolution are presented in Appendix. By combining the overlapped region ofand 10, the uHDSet test report 68 regions of highest susceptibility that exceed a p-value threshold of 0.001. The reported p-value is based on the whole regional test. According to GeneCards websites, there are 11 genes () within the selected regions that are associated with BMD or osteoporosis disease, which further confirms our findings. However, these 11 genes are missed by the use of famSKAT and Gemma method. The reported p-value of Gemma is generated by the minimal p-value after Bonferroni correction for the SNPs within the region. For the marker wise test, the uFineMap test report 82 susceptible SNPs that exceed a p-value threshold of 10 5 .shows the six reported SNPs that are associated with BMD or osteoporosis disease according to GeneCards websites.
Pathway analysisTo further illustrate the benefit of the uHDSet test, we collect 880 pathways from KEGG, REACTOME and BIOCARTA pathway analysis databases. We first extract genes belonging to eachUnified tests for fine-scale mapping and identifying sparsepathway, then select the corresponding SNPs. The selected SNPs of a specific pathway are combined to form the design matrix for association tests. We list six most significant pathways that pass p-value cut-off 10 3 infor which the prominent famSKAT methods fails to detect. The two P38/MAPK pathways were previously found to play a critical role by other publications (). Endogenous Sterols pathway is also related with BMD reported by another study (). Chemokines pathway is important regulator in development, homeostasis and pathophysiological processes associated with osteoporosis (). Each p-value inis generated based on a whole pathwaybased region. It can be seen that, our uHDSet method is more powerful than famSKAT in identifying significant pathways which contain a relatively large number of genetic markers.
ConclusionSome promising association tests with the adjustment of family structure have been established on the LDSs (low dimensional sets). However, these tests would suffer power loss in high dimensional data. To overcome the limitations of these tests, we propose the uFineMap and uHDSet tests for assessing the significance of the HDSs with cryptic relatedness, which are based on novel scaled linear mixed sparse regressions. The proposed tests are designed to address the challenge of variants detection under complex pedigree structures, which implement an explicit way to properly control the Type I error rates at both single marker level and SNPs set level. The promising results of testing on both simulated and real data indicate that the uFineMap and uHDSet tests yield considerably higher statistical power gains in comparison to other competing methods, especially for high dimensional data with cryptic relatedness. The uFineMap test can pinpoint single susceptible variants with higher resolutions, even for rare functional variants. In addition, our methods also maintain substantial power for detecting susceptibility variants in low dimensional data of large samples. Last but not least, our methods can identify both rare and common variants efficiently. One limitation of the proposed methods is that we assume linear mixed relationship between phenotype and genotype, which might not be true in the real world. Therefore, non-linear regression models with adjustment of relatedness and population stratification may be more suitable. In addition, the overall computational complexity is On 2 m 3 , which is much higher than simply solving the sparse linear mixed model or other efficient methods designed for LDSs, particularly for extremely large data. To solve this issue, parallel computing is implemented to reduce the total computational time for large scale genetic data analyses.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
S.Cao et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
