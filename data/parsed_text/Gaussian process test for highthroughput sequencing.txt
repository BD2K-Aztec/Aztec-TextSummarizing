Motivation: Recent advances in high-throughput sequencing (HTS) have made it possible to monitor genomes in great detail. New experiments not only use HTS to measure genomic features at one time point but also monitor them changing over time with the aim of identifying significant changes in their abundance. In population genetics, for example, allele frequencies are monitored over time to detect significant frequency changes that indicate selection pressures. Previous attempts at analyzing data from HTS experiments have been limited as they could not simultaneously include data at intermediate time points, replicate experiments and sources of uncertainty specific to HTS such as sequencing depth. Results: We present the beta-binomial Gaussian process model for ranking features with significant non-random variation in abundance over time. The features are assumed to represent proportions , such as proportion of an alternative allele in a population. We use the beta-binomial model to capture the uncertainty arising from finite sequencing depth and combine it with a Gaussian process model over the time series. In simulations that mimic the features of experimental evolution data, the proposed method clearly outperforms classical testing in average precision of finding selected alleles. We also present simulations exploring different experimental design choices and results on real data from Drosophila experimental evolution experiment in temperature adaptation.
IntroductionMost biological processes are dynamic and analysis of time series data is necessary to understand them. Recent advances in highthroughput sequencing (HTS) technologies have provided new experimental approaches to collect genome-wide time series. For example, experimental evolution now uses a new evolve and resequencing (ER) approach to understand which genes are targeted by selection and how (). Such experiments enable phenotypic divergence to be forced in response to changes in only few environmental conditions in the laboratory while other conditions are kept constant. The evolved populations are then subjected to HTS. Experimental evolution in microorganisms has focused on the fate new mutations. For example, in Escherichia coli () and Saccharomyces cerevisae () new mutations were studied. In contrast, ER experiments with sexually reproducing multicellular organisms address selection on standing variation and allele frequency changes (AFCs) in small populations where drift plays an important role. For example, for Drosophila melanogaster (Dmel), several phenotypic traits, such as accelerated development (), body size variation (), hypoxia-tolerance () and temperature adaptation () have been investigated. Motivated by these experimental studies, we believe that experimental evolution combined with HTS supplies a good basis for studying AFC through time series molecular data. To perform allele frequency comparisons, pairwise statistical tests between base and evolved populations were typically carried out.combined Fisher's exact tests with a slidingwindow approach to identify genomic regions that show allele frequency differences between populations selected for accelerated development and controls without direct selection.developed a pairwise summary statistic, called 'diff-Stat' to estimate the observed distribution of allele frequency differences and compared this to the expected distribution without selection.identify single nucleotide polymorphisms (SNPs) with a consistent AFC among replicates by performing a Cochran-Mantel-Haenszel test (CMH) (). The latter is an extension of the Fisher's exact test to multiple replicates. All aforementioned statistical methods are based on pairwise comparisons between the base and evolved populations and they do not take full advantage of the time series data now available.developed a method to analyze time series data based on population genetic models and estimated the effective population size N e of a bacteriophage from a single locus.derived a model for time series data from large populations of microorganisms (N e % 10 8 ) where drift can be ignored and the population allele frequencies evolve 'quasi-deterministically'. Here, we propose an alternative Gaussian process (GP) based approach to study AFCs over the entire time series experiment genome-wide for small populations (N e % 10 2  10 3 ). GP is a non-parametric statistical model that is extremely well suited for modelling HTS time series data, which usually have relatively few time points that may be irregularly sampled. Recently, there have been some works applying GP models with parameters describing the process of evolution (e.g. Jones and Moriarty, 2013 account for phylogenetic relationships, Palacios and Minin, 2013 for effective population size). GPs have also recently been applied to gene expression time series by a number of authors (A ). In differential analysis, GPs have been applied to detect differences in gene expression time series in a two-sample setting byand for detecting significant changes by Kalaitzis and Lawrence (2011). Although these methods provide a sensible basis for detecting the changing alleles, they fail to properly take into account all aspects of the available HTS data, such as differences in sequencing depth between different alleles and time points. These differences can have a huge impact in the reliability of different measured allele frequencies and taking them into account is vital for achieving good accuracy with the available short time series.
MethodsTo identify the candidate alleles which evolve under selection, we model the allele frequencies by GP regression. We fit time-dependent and time-independent GP models and rank the alleles according to their corresponding Bayes factors (BFs), i.e. the ratio of the marginal likelihoods under the different models. GPs provide a convenient approach for modelling short time series. However, when applying them to a large number of short parallel time series as in many genomic applications, naive application leads to overfitting or underfitting in some examples. Although these problems are rare, the bad examples can easily dominate the ranking. We overcome these challenges by excluding non-sensical parameter values, for example using a good variance model that can be incorporated into the GP models.
Data and preprocessingIn the following, we use the term SNP for the markers and alleles under study, but the methods can be applied to any features whose abundance can be quantified in a similar manner. We consider SNPs that are bi-allelic for a specific position of the genome in a population. Multi-allelic SNPs, however, exist but are rare and likely to be sequencing errors (). Multi-allelic cases can be treated by simply ignoring the least frequent allele or transformed to bi-allelic site by summing up the frequencies of the most infrequent alleles. Here, we assumed that only two of the alleles from (A, T, C, G) can be observed at each SNP position. After determining the abundances of these two specific alleles, we model the time dependency of the rising allele's frequency over several generations. We will refer to generations as time points for simplicity. We denote the replicate index of each observation by r j and the time point by t j , j  1,. .. , J, with J denoting the total number of observations. For each of these points, we assume HTS reads have been aligned to a reference genome with y ij reads with a specific allele at SNP position i. We use n ij to denote the total sequencing depth at the position.
Mean and variance inference: beta-binomial modelWe model y ij as a draw from a binomial distribution with parameters n ij and p ij : y ij jn ij ; p ij $ Binn ij ; p ij ;where p ij denotes the frequency of the specific allele in the population. We set a uniform Beta(1,1) prior on p ij : p ij ja; b $ Betaa; b;where a  1, b  1.
Gaussian process test for high-throughput sequencing time seriesSince beta prior is conjugate to the binomial likelihood, the posterior distribution will also be a beta distribution:a  b  n ij  2 a  b  n ij  1 :The inferred posterior means and posterior variances are used to fit the GP models as described in the following sections. As the results will show, this step is very important for incorporating the available uncertainty information into the GP models by taking into account different sequencing depths. For example, beta-binomial model assigns larger variances to the alleles with lower sequencing depths (). Moreover, the Beta(1,1) prior on p ij leads to a symmetry in the posterior mean and variance. Therefore, the result of our method is not affected whichever allele is chosen from the alternative alleles.
GP regressionA GP is a collection of random variables, any finite number of which has a joint Gaussian distribution. We write f t $ GPmt; Kt; t 0 to denote that f(t) follows a GP with mean function mt  Ef t and covariance function Kt; t 0   Ef t  mtf t 0   mt 0 . We let y  y i  N i1 be a vector of the noisy observations measured at points t  t i  N i1 satisfying y i  f t i   ;where is Gaussian observation noise with zero mean and a diagonal covariance matrix R. To simplify the algebra, we assume the mean function m(t)  0 and subtract the mean of y.Gaussian processes allow marginalizing the latent function to obtain a marginal likelihood. The covariance function K and the noise covariance R depend on hyperparameters h that can be estimated by maximizing the log marginal likelihood: logpyjt; h   1 2 y T Kt; t  R  1 y  1 2 logjKt; t  R j  N 2 log2p;where Kt; t denotes the covariance matrix constructed by evaluating the covariance function at points t. It is also possible to compute the posterior mean and covariance at non-sampled time points t  , given the noisy observations y at sampled time points t. This is often useful for visualization purposes. We obtain ():whereIn our GP models, we use the squared exponential covariance matrix to model the underlying smooth function. The squared exponential covariancehas two parameters: the length scale, l, and the signal variance, r 2 f .Length scale specifies the distance beyond which any two inputs become uncorrelated. A small length scale means that the function fluctuates very quickly, whereas a large length scale means that the function behaves like a constant function. Three example realizations generated with squared exponential covariance matrix can be seen in. In the standard GP model, the observation noise is assumed to be white: the noise at different time points is independent and identically distributed. The corresponding covariance matrixis an identity matrix multiplied by the noise variance parameter, r 2 n. Three example realizations generated with white noise covariance matrix can be seen in.
Beta-binomial Gaussian processThe beta-binomial Gaussian process (BBGP) method combines betabinomial model with the GP model in the sense that the posterior means and posterior variances of the frequencies, which are inferred by beta-binomial model, are used to fit the GP model by means of F BB. Example realizations from GPs and noise processes with different covariance structures an additional noise covariance matrix which we call fixed betabinomial (FBB) covariance matrix. Returning to Section 2.2, let us denote the posterior mean and variance of p ij by m ij and s 2 ij , respectively. That is, m ij  Ep ij jy ij ; n ij ; a; bs 2 ij  Varp ij jy ij ; n ij ; a; b:To fit the BBPG model, we assume m ij  f i t j   l mi  ;where f i t $ GP0; K SE t; t 0  and $ N0; R W  R FBB . The mean l mi is eliminated by subtracting the mean from m ij. Because of R FBB this is an approximation that may fail if n ij vary significantly, but it speeds up inference significantly. The additional covarianceis a diagonal FBB covariance matrix which is used to include known variance information for each observation in the GP model. The elements of R FBB are determined by the posterior variances which are inferred from beta-binomial model in Section 2.2. Three example realizations generated with FBB covariance matrix can be seen in, where larger variance values were inferred for the later time points.
BBGP-based testWe fit the 'time-dependent' BBGP model of Equation (14) and a 'time-independent' model without the GP term f i t j  for each SNP i. As can be seen from the graphical models in, 'time-independent' model assumes that the observations are randomly generated around a constant mean with no temporal dependency, whereas 'time-dependent' model captures the dependency between the observations by the function f i t, which follows a GP with the squared exponential covariance function. Thereby the parameters of the squared exponential covariance [K SE ,] in the timedependent model and the white noise covariance [R W , Equation(11)] in both models are fitted by maximizing the marginal likelihood. The FBB covariance [R FBB ,] does not contain any free hyperparameters. If the model is actually time independent, the length scale in the squared exponential covariance is estimated to be very large, which makes the maximum likelihood of the timedependent model equivalent to that of time-independent model.shows an example of the time-dependent (left) and timeindependent (right) BBGP models. We maximize the log marginal likelihood functions for the models by scaled conjugate gradient method using the 'gptk' R package by Kalaitzis and Lawrence (2011). We use a grid search over the parameter space and initialize the parameters to the grid value with highest likelihood. We also set a lower bound equal to the shortest spacing between observations for the length scale parameter to avoid overfitting. We compute the BF for SNP i as (BF i  pm i j ^ h 1 ; ''time-dependent model'' pm i j ^ h 2 ; ''time-independent model'' ;where ^ h 1 and ^ h 2 contain the maximum likelihood estimates of the hyperparameters in the corresponding BBGP models. BFs indicate the degree of the models to be 'time dependent' rather than 'time independent'.
CMH testWe compare BBPG against the CMH test, which was used by Orozco-terWengel et al. (2012) to identify alleles with consistent AFC across replicates. The CMH test has been proven to be the best-performing test statistic applied on HTS evolutionary data so far (Kofler and Schl tterer, 2014). Therefore, we take it as the basis of comparison with BBGP. CMH allows to test whether the joint odds ratio of replicated (r  1;. .. ; R) allele counts in a 2  2  R contingency table (to their null expected values and it follows a chi-squared distribution with one degree of freedom X 2 df 1. We performed CMH tests on the simulated and real data for each SNP position independently, using the implementation of the software PoPoolation2 ().
SimulationsTo evaluate the performances of the BBGP and the CMH tests, we simulated data that mimic the dynamics of evolving Dmel fi(t1)Gaussian process test for high-throughput sequencing time seriespopulations at the genomic level. For this aim, we first simulated three sets of genome-scale data to evaluate the overall performances of the methods under the experimental design which is close to the natural settings. Additionally, we also carried out smaller size simulations on one chromosome arm to investigate the further influences of different parameter settings on the methods.
Whole-genome simulationsWe carried out forward Wright-Fisher simulations of genome-wide allele frequency trajectories of populations using the MimicrEE simulation tool (Kofler and Schl tterer, 2014). The initial haplotypes were taken from Kofler and Schl tterer (2014), and they capture the natural variation of Dmel population. By sampling from the initial set, we established r  5 replicated base populations using H  200 founder haplotypes and let each of them evolve for g  60 generations at a constant census size of N  1000. We used the spatially varying recombination rate defined for Dmel by Fiston-Lavier et al.. Low recombining regions were excluded from the simulations because of the elevated false-positive rate in these regions (Kofler and Schl tterer, 2014). We followed the evolution of the total number of 19 39 941 autosomal SNPs among which 100 were selected with selection coefficient of s  0.1 and semi-dominance (h  0.5). Furthermore, we required the selected SNPs to have a starting frequency in the range 0:12; 0:8, not to lose the minor allele in the course of time due to drift. We recorded the nucleotide counts for every second generation and performed Poisson sampling with k  45 (overall mean coverage in) on the count data to produce coverage information (see Supplementary Text Section S2). We repeated the whole simulation experiment three times, each time using a different set of selected SNPs.
Single-chromosome-arm simulationsFor experimental design, additional simulations were carried out on a single chromosome arm ($16 Mb) with 25 selected SNPs to assess the performance under various parameter combinations, such as population size (N), number of founder haplotypes (H), selection coefficient (s), level of dominance (h), number of generations (g) and number of replicates (r). We defined a basic set up with parameter space close to that of the whole-genome simulations, i.e. N  1000; H  200; r  5; g  60; s  0:1; h  0:5, and investigated the effect on the performance when only one parameter is perturbed from its basic value.
Evaluation metricsThe methods were evaluated based on precision, recall and average precision (AP) (). Precision and recall are commonly used metrics to measure the fraction ofThe curve obtained by plotting the precision at every position in the ranked sequence of items as a function of recall is called the precision-recall curve. The area under the curve can be summarized using AP (), which is defined as the average of prefor a graphical visualization of the scores). To investigate the effect of the number of replicates (r), we chose up to five replicates at each sampled time point. We first performed CMH tests with all possible r-replicate combinations. We then applied BBGP only to the best performing replicate combinations of each size according to AP in the CMH evaluations. This strategy ensures a fair comparison between the methods as BBGP is always evaluated against the best CMH results. We also compared BBGP to the standard GP of Kalaitzis and Lawrence (2011) that does not use the FBB model variances using the same replicate combinations as BBGP with 6 time points. As shown in(see also Supplementary Figs. S2 and S3), BBGP achieves a higher AP than the standard GP and the CMH. Somewhat surprisingly, CMH seems to benefit very little from more replicates while the performance of the GP methods improves noticeably. The CMH is sensitive to the specific replicates included, as including the fifth replicate in the optimal sequence actually leads to worse performance than four replicates (Supplementaryand d). We did not observe similar behaviour with the GP methods. On average over all possible r-replicate combinations, adding more replicates helps the CMH as well (mean AP in). The performance of the standard GP approaches that of BBGP as the number of replicates increases, which is consistent with the view that the stronger prior information from sequencing depth is most important when the data are otherwise scarce, as is often the case in real experiments. In contrast to more replicates, adding more time points improved BBGP's performance very little (). We also investigated whether the two methods identify different types of selected SNPs. We calculated AFC for each SNP based on the average difference between the base and end populations acrossP n iBr n iEr n i:r replicates. The CMH is sensitive to large AFCs, while the candidates detected by the BBGP have a much more uniform distribution of AFCs (Supplementary). In general, we would expect a uniform distribution of AFCs, as very large AFCs are only possible for SNPs with low starting frequency giving them the potential to rapidly increase. BBGP is much more accurate than CMH in all AFC classes as demonstrated by the performance breakdown in Supplementary. Furthermore, we performed a generalized CMH test (gCMH) that can be applied to more than two time points but requires a weighting scheme (Supplementary Text Section S1.1). As there is no straightforward way to find weights that accurately reflects natural selection, we used mid-ranks assigned to time points. The performance of the gCMH drops rapidly with increasing the number of time points and replicates (Supplementary), which might be due to a poor weighting scheme. The performance of the methods can vary noticeably between different experiments depending on their difficulty. For example, there is a 10-fold difference in AP between Experiment 1 and Experiment 3 for both methods (Supplementary
Influence of parameter choiceFor the purpose of experimental design, we investigated further parameter settings on the single chromosome arm of 2L.
Population size and number of founder haplotypesIn finite populations, genetic drift has a large impact on shaping the population allele frequencies. We studied the effect of census populations size (N) and the number of founder haplotypes (H). H can be thought as the number of different individuals (isofemale lines) in the base population. The populations were established by randomly choosing N individuals with replacement out of the H founders. The simulation results show that AP increases with increasing N (). This has also been observed by Kofler and Schl tterer (2014) for the CMH test. The AP is the highest with the ratio of H= N  0:5 in all cases (, Supplementary Figs. S8S10) and the BBGP consistently outperforms the CMH test. Kofler and Schl tterer (2014) reported that the true-positive rate for CMH test increases with H but the increment levels off with H=N  0:5 for N  1000. Baldwindetected a constant increase in the power to localize a candidate SNP; however, they used a different method and investigated different parameter settings not comparable to ours. We hypothesize that as more low-frequency variants are present in the population with H=N > 0:5, the selected SNPs with multiple linked backgrounds are competing with each other, resulting in an AP drop.
Selection strength and level of dominanceWe investigated the performance using various selection coefficients (s) and fixed semidominance (h  0.5). For moderate and strong selection (s > 0.01), the BBGP outperforms the CMH test (, Supplementary). The BBGP reaches the highest precision at s  0.1, whereas the CMH test is the most precise at s  0.05 which is consistent with Kofler and Schl tterer (2014). For strong selection (s  0.2) the precision drops for both methods. The performance decay is presumably due to interference between selected sites, known as the HillRobertson effect, i.e. linkage between sites under selection will reduce the overall effectiveness of selection in finite populations (). Also, we hypothesize that long-range associations become more apparent as the strength of selection increases (Supplementary) resulting in larger blocks rising in frequency together, which was also observed by. For weak selection (s 0:01), it becomes hard to distinguish between selection and drift in small populations. Thus, for low s, both methods perform rather poorly and the CMH has a slightly higher AP in these cases. However, for a more ideal parameter choice of N  5000; H  2500 and a long runtime of the experiment (g  120), the BBGP gains a large performance improvement over the CMHBBGP, t=9 BBGP, t=6 BBGP, t=3 GP, t=6 CMH CMH (mean AP) RandomBBGP, t=9 BBGP, t=6 BBGP, t=3 CMH Time points and spacing10 5. Log scale was used on both axes for (a), (b), (d) and on the y-axis for (c). Other parameters are as in the basic setup in Section 2.7 test for s  0.01 (see Supplementary Figs. S13 and S14) even in the difficult scenario of weak selection. We also simulated evolving populations using different levels of dominance (h). The following relative fitness values were used on genotypes AA, Aa and aa: w AA  1  s; w Aa  1  hs, w aa  1, where s  0.1. As h varies, we observed different behaviour of the methods. The AP of the CMH test increases as we are moving from complete recessivity (h  0, recessive phenotype is selected) to complete dominance (h  1, dominant phenotype is selected) (Supplementary Figs. S15 and S16). Selection on completely recessive allele results in a gradual initial change in AF with more rapid change in later generations and eventual fixation. In contrast, the change in AF of a completely dominant allele is initially rapid but never reaches fixation as the recessive allele is shielded from natural selection in the heterozygote. When the fitness of the heterozygote is intermediate between the two homozygotes (additivity, h  0.5) the allele frequency trajectory is the combination of the aforementioned ones, i.e. rapid initial change and quick fixation. BBGP reaches the highest AP with the additive scenario and relatively high AP in the recessive case (Supplementary). When the dominant phenotype is selected (h $ 1) and the unfavoured allele stays present in the population at low frequency, it is likely to result in an inconsistent behaviour of replicates, which lower the power of the BBGP.
Number of replicatesIn addition to the whole-genome experiments with a maximum of five replicates, we simulated up to r  15 replicates for the single chromosome arm. We observed a constant increase in performance for the BBGP up to r  6 (, Supplementary). The AP kept increasing up to r  12 but rather in a fluctuating manner and then dropped with adding even more replicates. Consistently with the whole-genome simulations, we did not observe a large performance improvement with increasing the number of replicates for the CMH test.
Length of the experiment and spacing of the samplesWe also examined the performance with increasing the length of the experiments up to g  120 generations. For longer experiments, more recombination events can happen, which uncouples linked sites letting them evolve independently. The AP rises rapidly for longer experiments (, Supplementary). Thereby the performance gain is noticeably higher for the BBGP. We also investigated the spacing of the sampled time points (t 2 f3; 6; 9g) for the BBGP and observed similar pattern that of the whole-genome simulations, i.e. an intermediate number of sample time points is sufficient as shape of selected trajectories is simple.
Real data applicationOrozco-terWengel et al. (2012) applied ER methods on Dmel populations adapting to elevated temperature regime. They established base populations from isofemale lines collected in Portugal. The populations were propagated at a constant size of 1000 for 37 generations under fluctuating temperature regime (12h at 18 C and 12h at 28 C). DNA pools of 500 females (Pool-Seq) were sequenced at the following time points: three replicates at the base generation 0 (B); two replicates at generation 15, an additional replicate at generation 23 and 27; three replicates at the end generation 37 (E). CMH tests were performed on a SNP-wise basis to identify significant AFCs between the B and E populationsof the CMH and the BBGP was rather small (609 SNPs). However, the peaks of both methods covered the same regions (). The difference between the methods is illustrated with some example allele trajectories in Supplementary Figures S23S25. BBGP emphasizes between-replicate consistency and sometimes picks candidate SNPs that start already at high frequency and go rapidly to fixation. On the other hand, CMH test assigns high ranks to SNPs with large frequency change and fails to detect between-replicate consistency if the fold change is otherwise low. Using a gene set enrichment analysis (see Supplementary Text Section S5), we also found that the top ranked significantly enriched Gene Ontology categories were similar for both tests (Supplementary Tables S3 and S4, Supplementary). Furthermore,shows how well the posterior beta-binomial variance inference can handle false signals resulting from uneven coverage. While the CMH test is misled by strong signal coming from high coverage of the chorion cluster with high copy number variation, the BBGP test does not falsely indicate signatures of selection (, green region on 3L). Although Dmel generally has rather small levels of linkage, linkage disequilibrium (LD) might have built up during the course of theshows how well the beta-binomial variance control can handle high coverage problem of the excluded region on 3L experiment. In fact, LD had a major effect on the number of candidate SNPs identified by the CMH as well as the BBGP test. As the flanking SNPs showed signs of hitchhiking, the observed AFC of the flanking SNPs were also significant (see also Manhattan plot for the simulated SNPs Supplementary), and this made it difficult to narrow down functionally important regions for thermoadaptation.
DiscussionOur results in detecting SNPs that are evolving under selection using a GP model clearly demonstrate the importance of careful modelling of the measurement uncertainty through a good noise model, in our case using the beta-binomial model of sequencing data. Especially when data are scarce, the BBGP approach leads to much higher accuracy than standard maximum likelihood estimation of noise variances. Incorporating the non-Gaussian likelihood directly to the GP would also be possible, but it would lead to computationally more demanding inference. In terms of experimental design, the most effective way to improve performance is to use a larger population (N) and a larger number of founder haplotypes (H). As expected, alleles under moderate to strong selection (s  0.050.1) are easier to detect than alleles changing under weak selection (s 0:01). However, for very strong selection (s ! 0:2), it is again hard to detect the causal SNPs. In a real experiment, the strength of selection might also not be known and often cannot be changed for the trait of interest. Adding more replicates can also help improve performance up to some point. Compared with the CMH test, the BBGP is clearly superior in utilizing additional replicates. We suspect this is because CMH assumes all replicates should have similar odds ratios between the two time points and this is not sufficiently satisfied by the noisy data. Longer experiments can help significantly (Supplementary), but the benefit of adding more intermediate time points seems smaller. This may be because the shape of selected trajectories is a simple sigmoid, and adding more points provides limited help in estimating them. The presented GP-based test is sensitive to SNPs with a consistent time-varying profile. A statistically more accurate model could be derived by assuming each replicate to follow an independent GP, but this would require different kind of constraints to differentiate between selection and drift, which may be difficult to formulate for multiple interacting SNPs. Exploring hierarchical GP models to capture the correct dependence structure is an interesting avenue of future research. In a whole-genome experiment, LD between nearby markers and interactions between nearby selected SNPs are important confounders in identifying the selected markers. Especially for moderate-sized populations, the interactions can be problematic, leading to very large segments in the genome raising together in frequency (Supplementary). The issue does not appear when simulating only a single selected SNP (Supplementary), which strongly suggests it is caused by the interactions. The issue can be most effectively mitigated by using larger populations (Supplementary). An artificially high recombination rate (Supplementaryand b) could also break the interactions. Working with larger fixed window sizes might not improve the performance as a substantial number of hitchhikers can still be found hundreds of kilobases from the selected SNPs (See Supplementary: The removal of nearby hitchhikers did not improve the AP noticeably). It is possible to extend the GP models for joint analysis of multiple SNPs, and this is clearly an important avenue of future research. This is potentially a further advantage of the GP, because it is much more difficult to similarly extend the frequentist tests.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
H.Topa et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Conclusion In this article, we developed a new test that is based on combining GP models with a beta-binomial model of sequencing data, and compared it with the CMH test that allows the pairwise comparison of base and evolved populations across several replicates. Our results demonstrate that GP models are well suited for analyzing quantitative genomic time series data because they can effectively utilize the available data, making good use of additional time points and replicates unhindered by uneven sampling and consistently show performance superior to the CMH test. The GP framework is very flexible, which enables extensions utilizing for example LD over nearby alleles. As GP models can easily incorporate additional information on the data, we envisage that further promising combinations of the GP approach with evolutionary models will emerge.
