Motivation: Accurately predicting and genotyping indels longer than 30 bp has remained a central challenge in next-generation sequencing (NGS) studies. While indels of up to 30 bp are reliably processed by standard read aligners and the Genome Analysis Toolkit (GATK), longer indels have still resisted proper treatment. Also, discovering and genotyping longer indels has become particularly relevant owing to the increasing attention in globally concerted projects. Results: We present MATE-CLEVER (Mendelian-inheritance-AtTEntive CLique-Enumerating Variant findER) as an approach that accurately discovers and genotypes indels longer than 30 bp from contemporary NGS reads with a special focus on family data. For enhanced quality of indel calls in family trios or quartets, MATE-CLEVER integrates statistics that reflect the laws of Mendelian inheritance. MATE-CLEVER's performance rates for indels longer than 30 bp are on a par with those of the GATK for indels shorter than 30 bp, achieving up to 90% precision overall, with 480% of calls correctly typed. In predicting de novo indels longer than 30 bp in family contexts, MATE-CLEVER even raises the standards of the GATK. MATE-CLEVER achieves precision and recall of $63% on indels of 30 bp and longer versus 55% in both categories for the GATK on indels of 10–29 bp. A special version of MATE-CLEVER has contributed to indel discovery, in particular for indels of 30–100 bp, the 'NGS twilight zone of indels', in the Genome of the Netherlands Project. Availability and implementation:
INTRODUCTIONMore than 6 years after its introduction, next-generation sequencing (NGS) has become standard technology. Read length is steadily increasing and so is sequencing speed, at an overall still decreasing sequencing cost. One of the most evident advantages of NGS over array-based approaches is that it has enabled studying genetic variation beyond single nucleotide polymorphisms (SNPs) at both a larger scale and finer resolution. Several large-scale projects addressing this are under way [e.g. The 1000, The Genome of the Netherlands (GoNL), which have accumulated tera-scale amounts of NGS data. The goal is to discover and genotype variants in thousands of individuals at single basepair resolution, and, in a second step, to classify them according to population structure and phenotype, such as susceptibilities for diseases. For simplicity, we will refer to all insertion and deletion variants as indel variants, or simply indelswe are aware of the occasional clash with nomenclature for structural variants. We will refer to indel discovery as prediction of indels without predicting the zygosity status of indel alleles, and to genotyping indels as determining (e.g. computationally predicting) this zygosity status. Motivation. As one particular example of a nationwide directed effort, the GoNL Project puts particular emphasis on drawing links between population structure and inheritability. In the frame of this project, 769 Dutch individuals, consisting of 231 motherfatherchild trios, 11 monozygotic-and 8 dizygotic-twin quartets, have been sequenced. In the analysis, indels play a major rolethe obvious reason is that only NGS has made large-scale discovery of indels truly possible. Also for other large-scale projects (The 1000 Genomes Project), mapping and categorizing indels is of utmost relevance. However, both indel discovery and genotyping technology still lag considerably behind the advances made in sequencing technology itself (). Existing indel discovery tools still leave much room for improvement. On top of that, with only very few exceptions, they do not offer genotyping as an option. An analysis of existing state-of-the-art trio variant callsets (e.g. that of the 'platinum genome trio' issued by Illumina, see Appendix A.2 in the Supplementary Material for more details) points out that a surprisingly large fraction of indel calls violate the Mendelian laws. This decisively differs from SNPs, which have been genotyped soundly and reliably. In fact, genotyping SNPs has been standard for many years. Since 2011, smaller indels can also be reliably handled. The Unified Genotyper (UG), a tool from the Genome Analysis ToolKit (GATK) (), has been providing the corresponding technology. We will demonstrate the GATK-UG genotypes between 80 and 90% of indels correctly in the Results section. However, its performance sharply drops for indels of 30 bp and longer. The reason is that one commonly runs the GATK on standard read alignments, e.g. as delivered by BWA (), Bowtie2 () or Stampy (). *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.comFor indels longer than 30 bp, principled, statistically and algorithmically sound approaches have not been described. Our Contribution. We present a novel approach, MATE-CLEVER (Mendelian-inheritance-AtTEntive CLiqueEnumerating Variant findER) for sound discovery and genotyping of indels longer than 30 bp from NGS reads that were generated through contemporary library protocols [For old or non-standard protocols, we claim that we can discover and genotype indels longer than two times the standard deviation (stddev) of the fragment length distribution, which amounts to 30 on current protocols.]. MATE-CLEVER provides a novel (Bayesian) probabilistic framework to compute the probabilities that an indel allele is homozygous, heterozygous or not present. In case of a family, it integrates prior probabilities that reflect the laws of Mendelian inheritance, which yields enhanced performance rates when combinedly genotyping family members. Overall, MATE-CLEVER achieves performance rates on longer indels that are as favorable as those of the GATK-UG on small indels. Thus, our approach considerably raises the limits of sound indel genotyping. For accomplishing this, we have combined the two most recent approaches of ours, CLEVER () and LASER (Marschall and SchonhuthSchonhuth, 2013), into a hybrid approach that specifically targets indels longer than 30 bp. While CLEVER has proven to be able to discover indels of 30100 bpsometimes referred to as the (NGS) twilight zone of indelsat highly favorable recall and precision rates, LASER allows us to re-evaluate calls and adds split-read alignment information, which leads to enhanced genotyping and high breakpoint resolution. Related Work. Structural variant (SV) discovery tools can be divided into four large classes of approaches, for each of which we restrict ourselves to naming a few state-of-the-art tools. 1. Internal segment size (also: insert size)-based approaches identify groups of paired-end reads whose alignments exhibit abnormal internal segment lengths with respect to a background distribution. That is, they consider the distance between the two alignments of a read pair (called internal segment size or insert size). Groups of alignment pairs with deviating distance suggest the presence of indel breakpoints in the internal segment. We will refer to such alignment pairs as spanning alignments (see, top). Examples of methods using this type of signal are Breakdancer (), VariationHunter (), HYDRA (), PEMER (), MoDIL () as well as our tool CLEVER (). It is characteristic for these approaches to successfully predict indels longer than 100 bp. However, methods that impose a hard threshold and only work on 'discordant' reads, like BreakdancerMax, VariationHunter, HYDRA and PEMER cannot detect smaller indels. [Note that the initial Breakdancer release consisted of BreakdancerMini and BreakdancerMax. Maintenance/development of BreakdancerMini has been stopped, and current releases only containMoDIL and BreakdancerMini can, in principle, detect shorter indels, but the former is prohibitively slow (see discussion in), and the implementation of the latter is no longer maintained. CLEVER was designed to process all alignments in a short time and thus achieves good performance also for indels in the 'twilight zone' (30100 bp). For insert sizebased approaches, placement of breakpoints is commonly rather little accurate. 2. Split-read aligners aim at aligning reads across the breakpoints of insertions and deletions. When the alignment of a read end contains an indel breakpoint, we refer to it as breakpointcovering alignment (see, bottom). Examples for split-read methods are PINDEL (), SplazerS () as well as our tool LASER (Marschall and SchonhuthSchonhuth, 2013). Split-read aligners predict breakpoints at single-base-pair resolution. However, most of them apply predominantly for indels up to 30 bp. Longer indels can be challenging for split-read aligners if the alignment of split parts of reads is not properly guided. 3. Coverage-based approaches aim at detecting deletions and duplications by measuring amounts of reads mapped to locations. Examples are CNVer () and CNVnator (). Although coverage-based approaches are the only reliable technique to predict large duplications, they only work for very large deletions and duplications. 4. De novo assembly methods focus on reconstructing sequences without using a reference genome. A few more wellknown examples are ALLPATHS (), SOAPDenovo () and VELVET (). An approach that focuses exclusively on novel sequence insertions is NovelSeq (). Our method, MATE-CLEVER, falls among the so-called hybrid methods, as it makes use of both insert size signal and split-read information. Such hybrid methods have established a new class of approaches and have arisen in the literature only from 2012 onward. Examples are DELLY (), SVSeq2 () and PRISM (). The only discovery method for larger indels currently available that addresses family settings is CommonLAW (), which draws from VariationHunter () as a core approach. CommonLAW collects information on frequencies of variants that are supported by combinations of family members in a preprocessing step. It uses this information in the form of prior weights in a combinatorial algorithm to predict variants parsimoniously.Although approaches that aim at genotyping indels have rarely been described, there have been reliable techniques for shorter indels since 2011. Examples for processing indels of length up to 30 bp are the above-mentioned UG () from the GATK () and the earlier approach DINDEL (), whose core ideas initially inspired the GATK-UG. An option for indels from 125 bp or longer is GASV-Pro (), which reportedly achieves sufficiently reliable classification rates on very long indels. Reliable pipelines for genotyping indels that are $30100 bp long, in particular in the context of family settings, have not been described in the literature so far.
METHODS
Laws of Mendelian inheritanceAccording to Mendel's laws, a child inherits exactly one allele from each parent. Egg and sperm cells each contain one set of chromosomes, representing a recombination of the two sets of chromosomes present in each parent. During recombination, it is determined which alleles are passed on to the child. Let 0,1,2 be placeholders for 'variant not present', 'heterozygous variant' and 'homozygous variant', respectively. We write X gh with g, h 2 f0, 1, 2g and g h to refer to variants that are 'g' in one parent and 'h' in the other one. For example, X 01 refers to variants that are heterozygous in either the mother or father, but not present in the other parent. Analogously, we write Y j with j 2 f0, 1, 2g to denote the event that the child has genotype j. Assuming that each allele is equally likely to be transmitted to the child, the Mendelian laws can be cast statistically asWhen discovering genetic variations in a trio rather than a single individual, one can take advantage of Mendel's laws. A variant found in one of the parents has (at least) a 50% probability of being present in the child. This translates to the conditional probability of a variant being present in the child, given its presence in one of the parents, being higher than the a priori probability, which is not conditioned on any prior knowledge.
MATE-CLEVER workflowStep 1: Running CLEVER. We run our tool CLEVER () on each individual independently. CLEVER processes all alignments, including also concordant ones, which allows it to also detect indels shorter than 100 bp. The output of this step is a set of deletions D clever .Step 2: Defining Regions of Interest. At this stage, deletions still may have remained undiscovered in single individuals. So, for each d 2 D clever , we declare a window of AE1000 bp around d, a region of interest in every individual, independently of in which individual d was originally discovered.Step 3: Extracting Reads of Interest. We extract all paired-end reads where one end aligns in a region of interest. Owing to pooling deletions from all family members when determining these regions, this may also include paired-end reads from individuals who do not have a CLEVER deletion in the region of interest themselves. The goal of this is to discover breakpoint-covering reads, where one end has to be splitaligned and therefore has remained unaligned by the (standard) read aligner in use (). Let AE  {A, C, G, C} be the DNA alphabet and let ' be the read length. That is, each paired-end read can be considered a pair of sequences of length ', i.e. an element of AE '  AE '. Correspondingly, we write R & AE '  AE ' for the set of all extracted read pairs, from all individuals.Step 4: Generating (Split) Alignments with LASER. We align all reads r 2 R using our read aligner LASER (Marschall and SchonhuthSchonhuth, 2013). LASER determines both normal alignments, containing only short indels and split alignments, indicating long indels. We report up to 50 alignments per read end. In case of ambiguous indel placements, we only report the leftmost one. We write A 1 r and A 2 r to denote the set of alignments of the first and second read end of r 2 R. We define Ar  A 1 r [ A 2 r and AR  S r2R Ar. For each alignment A 2 Ar, LASER estimates the probability of it indicating the correct placement of r, written PA, based on phred scores and empirical indel statistics; see Appendix D for details.Step 5: Refining the List of Putative Deletions. We now refine the set of putative deletions D clever to create a list of candidate deletions D cand that are supported by both spanning and breakpoint-covering alignments, i.e. are supported by both CLEVER and split alignments from LASER. Here, we again aim at a high sensitivity: we prefer to err on the side of including too many rather than too few candidates. We will purge bad candidates in a later step. Let D split be the set of all deletions supported by split alignments generated in Step 4. We compute the expected support S R d of a deletion d 2 D split as follows:where I d A is an indicator that is 1 when alignment A contains deletion d and 0 otherwise. To be rather permissive, we retain all deletions with an expected support of 0.5 and above and thus set D 0 split : fd 2 D split : S R d ! 0:5g Next, we filter out deletions that are not similar to any deletion from D clever. Formally, we define the set of candidate deletions as follows:D cand : fd 2 D 0 split : there exists d 0 2 D clever such thatwhere  L d, d 0  is the length difference between d and d 0 and  O d, d 0  is the offset, i.e. the distance of their center points. CLEVER predictions are based on internal segment statistics rather than on alignments. Therefore, position and length can differ from the true deletion. The thresholds T L and T O have to allow for enough flexibility to take that into account without creating too many spurious hits. We found that setting T L  20, just slightly above the insert size distribution's stddev, and T O  100, to a distance that is unlikely to produce random hits, works well in practice.Step 6: Recalibrating Alignment Scores. Because of empirical indel statistics, the probability PA tends to be small if A is an alignment that supports a deletion (either through too long insert size, in case of a spanning alignment, or through a split, in case of a breakpoint-covering alignment). Because we are ready to believe in deletions d 2 D cand , we increase the probabilities PA for alignments supporting deletions d 2 D cand as follows. All deletions d 2 D cand now incur only the minimum phred-scaled cost of 1, whereas all other deletions retain their original costs. To be more precise, a deletion d 0 = 2D cand retains a cost of C del Ld 0  as defined in Appendix D. Using the updated deletion costs, we re-compute the posterior distribution over all alternative alignments (as described inAppendix D). This systematically increases PA for alignments A indicating deletions d 2 D cand , but not for A indicating deletions d not in D cand. From a Bayesian point of view, this procedure corresponds to updating our prior belief in alignments A into posterior probabilities by incorporation of the additional evidence provided by D cand. We then compute the most likely alignment pair:where PjIA 1 , A 2 j is the empirical probability (determined from uniquely mappable reads) to observe an internal segment of size IA 1 , A 2 . We discard all other alignments. We also discard alignments where PA51  0:001, equivalent to a phred-scaled mapping quality of at least 30.Step 7: Genotyping each Individual. For each deletion, we predict the genotype of each individual based on a prior belief p prior , evidence from covering alignments, and evidence from spanning alignment pairs. The prior belief is a global user-specified input parameter. It can be used to adjust the trade-off between precision and recall. We process all d 2 D cand ordered (decreasingly) by expected support S R d. In the following, let C(d) be the arithmetic mean of start and end position of d. Spanning alignment pairs: We assume insert sizes to be normally distributed with mean and stddevr is the set of positions that constitute the internal segment between the two alignments. That is, deletion d lies in the internal segment and the internal segment length is closer to  jd j than to. Owing to the symmetry of the null distribution N , , the latter is equivalent to that the deletion is more likely to be present than absent relative to r. Read r contradicts the deletion d ifCd 2 IA  1 r, A  2 r and jIA  1 r, A  2 rj  jd j=2: That is, the center point of d lies in the internal segment, whereas in this case d is more likely to be absent than present relative to r. Note that for contradicting reads d itself does not necessarily lie in the internal segment, which is an obvious requirement. Because a deletion reduces to a single breakpoint in the donor genome, considering only center points for contradicting reads is analogous to considering the entire deletion for supporting reads. For accurate genotyping, we have to take 'crosstalk' between supporting and contradicting reads into account. Therefore, we determine p insert FP : R 1 jdj N , xdx as the probability of a false positive (a contradicting read being misclassified as supporting) and p insert FN  p insert FP as the probability of a false negative (a supporting read misclassified as contradicting). Let n S and n C be the number of supporting and contradicting reads, respectively, and let n : n S  n C. Let B n, p k be the probability that out of n samples, each of which, with probability p, has a special label, k samples have the label. This reflects a common binomial distribution. We then determine (0 for indel not present, 1 for heterozygous and 2 for homozygous)which corresponds to the genotype with the highest posterior probability. Recall that we process deletions d ordered by expected support S R d. When processing subsequent deletions, all alignments already in use for genotyping a higher-ranked deletion d will be ignored.Step 8: Finding De Novo Deletions. De Novo deletions, i.e. deletions present only in the child, but not in the parents, are rare but usually of utmost interest. Their detection is difficult for two reasons. On one hand, they are absent in the parents and heterozygous in the child, i.e. only one out of six alleles represents them. This results in considerably less power for detecting them. On the other hand, inherited deletions that are heterozygous in only one parent are prone to be mistaken as de novo, if local coverage in the respective parent is low. To avoid such spurious calls, we further filter all deletions that were genotyped as present only in the child, by not only requiring strong evidence for its presence in the child, but also strong evidence that it is absent in the parents. Let T de-novo  10 5 ; we recall that p 0 is the probability (from Step 7) that a deletion is not present in an individual. All deletions with p 0 5T denovo in the child and with 1  p 0 5T denovo in both parents are reported as de novo. All other deletions are passed on to the next processing step.Step 9: Family-Structure-Aware Genotyping. Finally, we combine individual probability distributions p 0 , p 1 , p 2  (0 for not present, 1 for heterozygous and 2 for homozygous) from all family members into a combined probability distribution p ghj ; g, h, j 2 f0, 1, 2g. For example,, where we index with mo , fa , ch for the different family members, is the probability that the deletion is not present in the mother, homozygous in the father and heterozygous in the child. We combine these probabilities with a Mendelian prior q ghj ; g, h, j 2 f0, 1, 2g where
EVALUATION
'Venter's Family'a Trio BenchmarkWe derive Mendelian-inheritance-compliant annotations for a virtual family from the full set of Craig Venter's variants (). We opt for proceeding this way for three reasons.(i) For indels, there are no trio benchmark datasets available (see also the discussion in Appendix A.2).In particular, we only have to simulate reads, but not variantsDividing these variants into three (overlapping) subsets, one each for a mother, a father and the child, does not lead to a significant reduction of quantities of variants in one of the single individuals because Mendel's laws imply that the vast majority of annotations are shared by at least two individuals. Formally, let be the entire set of annotations. We divide (see section 'Laws of Mendelian inheritance' for notation)We also set aside a certain amount of de novo variants X 00. We assume that fractions of variants of equal zygosity are the same in both mother and father. Similarly, we divide  Y 0 _ [The (computational) problem is to partition a given set of annotations into subsetswithout violating Mendel's laws and such that the resulting callset makes a reasonable SV discovery and genotyping benchmark. Refer to Appendix A.1 for how we solve this problem geometrically. Owing to the large number of heterozygous deletions and because heterozygous deletions are harder to discover than homozygous deletions, the resulting benchmark is relatively difficult. We included (unrealistically) large amount of de novo deletions in the benchmark because we need a statistically sufficient mass of de novo annotations for benchmarking properly. Using the resulting trio benchmark annotations, which include all SNPs, indels, mixed variants and inversions, i.e. all variants one can download from, we simulated reads using the read simulator SimSeq (). Mean fragment size was set to  500 and stddev to  15, which reflects common standards and was chosen as it resembles the data in the GoNL project (). We generated two different datasets of reads, one of which amounts to 12 coverage (which meets the GoNL Project standards) and the other one has 30 coverage. We then aligned all reads with BWA (), with default parameters in the 'aln' step and parameters '-n25-N25' in the 'sampe' step to allow for up to 25 alternative alignments per read.
Results: Venter simulated readsFor comparing MATE-CLEVER with state-of-the-art approaches, we selected the following three tools: (i) Unified Genotyper (abbreviated UG or simply GATK), which sets the de facto standard for both population-and multi-sample-aware genotyping (); (ii) PINDEL as a most prominent, state-of-the-art split-read approach that sets the de facto standard in split-aligning reads (); and (iii) CommonLAW as the only indel discovery tool available, apart from the GATK, that is distinctly trio-aware (). We have furthermore evaluated DELLY () and PRISM (), both of which, like MATECLEVER, are hybrid approaches. However, DELLY does not address discovery of indels in the length range considered here (Tobias Rausch, personal communication). Moreover, both tools address neither genotyping of indels nor the integration of family information during discovery. See Appendix B for corresponding results. We furthermore refer to the CLEVER article () for performance statistics for Breakdancer (), GASV (), HYDRA (), VariationHunter (), SVSeq2 () and MoDIL (). Because CommonLAW is internal segment size-based, we evaluate its calls with relaxed distance thresholds and compare its results with MATE-CLEVER calls evaluated in the same way in a separate table to avoid confusion and/or unfair comparisons. The comparison of MATE-CLEVER, the GATK and PINDEL (with strict criteria) is shown in, whereas the comparison of MATE-CLEVER and CommonLAW (with relaxed criteria) is displayed in; the precise criteria and an explanation of evaluation metrics are provided in the next section. A detailed overview of MATE-CLEVER's genotyping performance is given in.shows the performance of MATE-CLEVER, UG and PINDEL in terms of making de novo predictions. De novo deletions only exist in the child, hence cannot be inherited, but must have come into existence during mating. De novo variants, including SNPs, are rare, but are also of great interest, because they can help to explain the mechanisms behind creation of new genetic variation. We recall that we included amounts of de novo calls in our benchmark that overestimate true amounts because we need a statistically sufficient mass for evaluation.
Evaluation metricsIn Table 1, we count a prediction as true positive if it matches a true annotation at most 20-bp distance, with at most 10 bp difference in length. For a relaxed evaluation of CommonLAW (), a true positive is a prediction that matches a true annotation at a distance of at most 100-bp, with at most 100 bp difference in length. Recall is determined as the number of true positives over the number of true annotations. Precision is the number of true positives over the number of predictions. In Tables 1 and 2, Family Precision refers to pooling all predictions and annotations into one 'family pool' and determining precision accordingly. Recall is also evaluated by pooling. Individual Precision refers to not pooling calls and annotations, but to evaluating precision in each individual separately and taking the average. Genotype Precision is the fraction of (individual) predictions that are (not only true positive, but also) correctly genotyped. In Table 2, we have replaced Genotype Precision by Length Difference, due to that CommonLAW does not genotype and to reflect differences between split-read-driven and insertsize based approaches in terms of breakpoint accuracy.
Results: real data (platinum genome)We also evaluated MATE-CLEVER on chromosome 1 of the platinum genome trio provided by Illumina, as downloaded from http://www.illumina.com/platinumgenomes, together with the computational annotations, generated through Illumina inhouse-software (Eland and CASSAVA, personal communications with Ole Schulz-Trieglaff, Illumina, available at ftp://ftp. platinumgenomes.org/trio). The platinum trio consists of individuals NA12878 (mother), NA12877 (father) and NA12882 (son). We then aligned the reads using BWA (with the same setting as for the simulated reads) and ran MATE-CLEVER as well as PINDEL on the alignments. Note first that the standard deviation (stddev) of the fragment length distribution is extremely high (%65 bp), due to the outdated library protocols, which explains the small amount of deletions of length 65129 bp MATECLEVER predicts (We virtually claim that we can discover and genotype indels longer than two times the stddev of the fragment length distribution, which amounts to 30 on current protocols., CASSAVA 0, PINDEL 157 (93), with 64 shared by the two Although CASSAVA genotypes can be in conflict with the Mendelian laws (see Appendix A.2), none of the MATECLEVER calls are (PINDEL does not genotype).shows that the GATK's overall recall and precision as well as its genotyping performance are excellent for deletions of 1029 bp, with recall between 60 and 70%, depending on coverage, and with precision and genotyping rates at $90%.shows that CommonLAW's contribution starts at $5060 bp, where it achieves excellent recall and family-pooled precision. Its performance relative to single individuals falls behind MATE-CLEVER and it cannot genotype. Moreover, its accuracy in determining breakpoints is not competitive with that of split-read aligners. Overall, MATE-CLEVER is able to genotype and achieves highly favorable performance rates in terms of assigning and genotyping calls in individuals and in terms of breakpoint accuracy.displays performance rates of MATE-CLEVER, the GATK and PINDEL when discovering de novo deletions. For PINDEL, amounts of predictions being typed as 'child only' are seemingly too largethe majority of such calls exist in the child, but are inherited, possibly because de novo calling has not yet (personal communication Kai Ye) been implemented in the officially downloadable PINDEL as a special feature. The GATK achieves excellent de novo prediction rates on 30 read data, in all size ranges. MATE-CLEVER makes nearly no calls below 30 bp, but outperforms the other tools for deletions larger than 30 bp, keeping stable prediction rates also for 12 data. As is evident from, the majority of MATE-CLEVER calls is correctly typed (as already displayed in). If MATE-CLEVER mistypes, then it rather over-than under calls deletions. That is, for example, it tends to predict heterozygous calls as homozygous rather than not present, if it fails to genotype correctly. When running MATE-CLEVER on the platinum trio, one can assume that MATE-CLEVER yields too little predictions 5130 bp because this reflects two times the stddev of the insert size distribution (We recall that we claim that we can discover and genotype indels longer than two times the stddev of the fragment length distribution, which amounts to 30 on current protocols.). PINDEL, which, as a split-read mapper, should be much less affected by the large stddev, delivers amounts of predictions, which, in comparison with Venter's genome, are too large. CASSAVA delivers a reasonable amount of predictions. Between 130 and 194 bp, CASSAVA seems to make too many predictions, when relating numbers to the Venter genome. Both MATE-CLEVER and PINDEL deliver reasonable amounts in this size range in this respect. This picture does not change also for deletions longer than 194 bp, for both MATE-CLEVER and PINDEL, but numbers for CASSAVA drastically decrease. Beyond 325 bp (6 stddev), CASSAVA makes no predictions. Across all size ranges, MATE-CLEVER delivers a substantial fraction of predictions that the other tools do not predict. As a general trend, the agreement between MATE-CLEVER and PINDEL (in relative numbers) is higher than between MATECLEVER and CASSAVA or between PINDEL and CASSAVA (see Venn diagrams in Appendix E). Also note that, as discussed in Appendix A.2, the CASSAVA indel calls are often in disagreement with the Mendelian laws of inheritance, which potentially translates into relatively high false-positive prediction rates. Without further wet-lab validations, however, we cannot reach a final conclusion about how to interpret the Venn diagrams in Appendix E.
DISCUSSION
CONCLUSIONWe have described a novel combinedly insert size-and split-readalignment-based (hybrid) approach by which to discover and genotype indels longer than 30 bp. Although the GATK has set the standards for indels of size up to 30 bp, approaches for indels larger than 30 bp had not been available. Here, we close this gap. Our tool MATE-CLEVER discovers and genotypes deletions larger than 30 bp at performance rates that are on apar with those of the GATK for deletions smaller than 30 bp. In doing this, MATE-CLEVER also integrates statistics reflecting the laws of Mendelian inheritance, for enhanced performance rates when dealing with ancestry-related contexts. We focus exclusively on results for deletions here. With some minor modifications, however, MATE-CLEVER also applies for insertionsboth its core engines (, CLEVER); (Marschall and SchonhuthSchonhuth, 2013, LASER) have been designed for also reliably handling insertions (note that the usual limitations owing to read and fragment length do not allow to discover insertions larger than 80 bp). Extrapolating CLEVER's and LASER's performance rates for insertions, which largely agree with those for deletions, may yield reasonable guesses on MATE-CLEVER's performance on insertions. Still, challenges remain. Neither the GATK nor MATECLEVER achieves recall of 470%. Future work will be concerned with raising sensitivity even further, by using improved alignment scores, and also by integrating elements that allow for further improved recalibration of read alignments, such as constructing local haplotypes. For further results on real data, we refer the interested reader to the GoNL Project (http://www.nlgenome.nl), where MATECLEVER contributed to predicting indels in all 231 trios and 19 quartets.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Donor genome Reference genome Donor genome Reference genome Breakpoint 1 Breakpoint 2 Deletion Breakpoint 1 Breakpoint 2 Deletion
T.Marschall et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
MATE-CLEVER at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
2 x , 1 0-2 9 3 0 x , 1 0-2 9 1 2 x , 3 0-2 4 9 3 0 x , 3 0-2 4 9 1 2 x , 1 0-2 9 3 0 x , 1 0-2 9 1 2 x , 3 0-2 4 9 3 0 x , 3 0-2 4 9 1 2 x , 1 0-2 9 3 0 x , 1 0-2 9 1 2 x , 3 0-2 4 9 3 0 x , 3 0-2 4 9
Note: Total: Number of de novo deletions predicted. Recall: Percentage of true de novo deletions that are predicted as such. Precision: Percentage of de novo deletion predictions that match true de novo deletions. Inherited: Percentage of predicted de novo deletions that are true deletions in the child, but are mistyped, i.e. inherited. Best values in each category are typeset in bold face.
