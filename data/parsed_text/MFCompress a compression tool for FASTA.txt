Motivation: The data deluge phenomenon is becoming a serious problem in most genomic centers. To alleviate it, general purpose tools, such as gzip, are used to compress the data. However, although pervasive and easy to use, these tools fall short when the intention is to reduce as much as possible the data, for example, for medium-and long-term storage. A number of algorithms have been proposed for the compression of genomics data, but unfortunately only a few of them have been made available as usable and reliable compression tools. Results: In this article, we describe one such tool, MFCompress, specially designed for the compression of FASTA and multi-FASTA files. In comparison to gzip and applied to multi-FASTA files, MFCompress can provide additional average compression gains of almost 50%, i.e. it potentially doubles the available storage, although at the cost of some more computation time. On highly redundant datasets, and in comparison with gzip, 8-fold size reductions have been obtained. Availability: Both source code and binaries for several operating systems are freely available for non-commercial use at
INTRODUCTIONSaying that the volume of genomic data produced every day is large is clearly a euphemism. With the dramatic drop in price of the sequencing machines (the $1000 limit for sequencing a human genome will be history shortly), virtually everyone will want to sequence everything. Unfortunately, the pace at which storage and communication resources are evolving is not enough, and the genomic data centers are being flooded with data. It is a data deluge (). The interest for DNA compression was started with the Biocompress algorithm of. The subsequent two decades have seen the publication of a considerable number of algorithms for compressing DNA sequences and several other forms of genomic data (e.g.), although usually aiming more at proving the concept than at providing usable compression tools. For example, the majority of these algorithms assume data drawn from the four-letter alphabet, ACGT, ignoring other letters that can be found in DNA data sequences. No doubt that for the purpose of showing the potentialities of the algorithms, this is often a fair approach, because those letters outside the main alphabet are usually rare and, therefore, represent only a small fraction of the bits required to represent the sequence. However, a usable lossless compression tool needs to be capable of handling every letter that it finds in the file and to reproduce it exactly during decompression. Moreover, genomic files rarely contain only sequence information. Usually, they also include additional data, such as headers, quality scores and alignment information. Therefore, the compression tools need to compress these data as well in an efficient way. In this article, we describe MFCompress, a tool for compressing FASTA and multi-FASTA files. Recently,proposed DELIMINATE, also a compression method for FASTA and multi-FASTA files, which relies on a preprocessing stage, where header and sequence data are separated and transformed, followed by a general purpose compressor (7-Zip). The MFCompress tool described here provides better compression than DELIMINATE for the large majority of the files used in the benchmarking dataset, at a similar compression and decompression time. This dataset is an extended version of the benchmarking dataset used by, to which we added some larger files, due to its increasing importance and commonness. MFCompress relies on multiple competing finite-context models and arithmetic coding, a powerful approach for DNA data compression ().
METHODSThe compression tool that we describe in this article relies on probabilistic models (finite-context models) that comply to the Markov property, i.e. that estimate the probability of the next symbol of the information source using the k40 immediate past symbols (order-k context) to select the probability distribution. MFCompress uses single finite-context models for encoding the header text, as well as multiple competing finite-context models for encoding the main stream of the DNA sequences (). The compression algorithm divides the data source into two separate sub-sources: one containing the headers of the FASTA records, the other one the sequences. The sub-source that deals with the sequences may be further divided into two or three streams (Supplementaryof the Supplementary Material): the main stream, the extra stream and the case stream. The main stream is a four-symbol information source, conveying *To whom correspondence should be addressed.This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits noncommercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com most of the information of the four DNA bases. Both upper and lower case characters representing the four DNA bases are converted to this four-symbol alphabet. If characters other than the four DNA bases are also present, they are all mapped to the '0' symbol in the main stream. When the sequences contain other characters besides the DNA bases, another coding stream must be present to disambiguate the occurrences of the '0' symbol in the main stream. This extra stream is responsible for representing all non-acgt/ACGT characters that have been found in the sequences, as well as to indicate when the '0' in the main stream is an a/A DNA base. If the sequences contain both DNA bases in upper and lower case, an additional binary symbol is associated to each symbol in the main stream, indicating the respective case type (the case stream). A more detailed description of the methods is provided in the Supplementary Material.
RESULTS AND DISCUSSIONIn the Supplementary Material, we provide compression results obtained using several popular general purpose compression methods, namely gzip, bzip2, ppmd and lzma (the last two using the versions implemented in the 7z archiver), as well as by the recent special purpose compressor DELIMINATE () and by the compressor that we describe in this article. Supplementaryin the Supplementary Material shows the total compressed file size, in bytes, obtained with gzip in the FFN and FNA datasets (composed of all bacteria in the NCBI), as well as the compressing gains attained by the other methods in relation to gzip. We can see that MFCompress provides a compression gain of $3.5% in relation to DELIMINATE for the FFN dataset and of $4% for the FNA dataset. Compared with gzip, the compression gain of MFCompress is $25%. In Supplementaryof the Supplementary Material, we present the compression results for the human genome dataset (HG19). The gain of the default mode of MFCompress is marginal in comparison with DELIMINATE (only 1.8%). For the more complex coding mode, the gain is $3.3%. In relation to gzip, the gain is 434%. Regarding the CAMERA dataset, in Supplementaryof the Supplementary Material, we provide compression results regarding the 26 files that have been used in this dataset, showing significant gains over DELIMINATE for most of them. To give a wide range of examples, we chose files with sizes from $5  10 5 to 43:5  10 10 characters, i.e. covering five orders of magnitude. For three of these files, DELIMINATE was not able to provide reliable results: in two cases the decoded file was different from the original file and in one case the encoder crashed. In relation to gzip, the size was reduced to almost half. In Supplementaryof the Supplementary Material, we show the compression results of two highly redundant datasets (all Escherichia and Salmonella genomes of the FNA dataset). In this case, MFCompress attained an 8-fold file size reduction over gzip and 444% gain in relation to DELIMINATE.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
CONCLUSION For daily use, general purpose compression tools, such as gzip, may continue to play an important role in the context of genomic data processing, mainly due to its pervasiveness and relatively good speed. However, as shown in this article, special purpose compression tools can sometimes attain additional file reductions as large as 50% or even more, in relation to gzip. In our opinion, the possibility to virtually double the amount of sequence data that can be stored in a given space, exclusively by means of software compression tools, is an opportunity worthy of consideration by the genomic laboratories. Higher compression can only be obtained using more complex algorithms, often requiring some more time and memory to run. However, these additional requirements are compensated by the relief attained in terms of storage requirements. In conclusion, we believe that the compression tool reported in this article is a relevant contribution to slow down the negative impact of the data deluge that we are facing nowadays. Funding: European Fund for Regional Development (FEDER) through the Operational Program Competitiveness Factors (COMPETE) and by the Portuguese Foundation for Science and Technology (FCT), in the context of projects FCOMP-010124-FEDER-022682 (FCT reference PEst-C/EEI/UI0127/2011) and Incentivo/EEI/UI0127/2013. Conflict of Interest: none declared.
A.J.Pinho and D.Pratas at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
