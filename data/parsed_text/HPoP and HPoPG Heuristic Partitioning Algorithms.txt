Motivation: Some economically important plants including wheat and cotton have more than two copies of each chromosome. With the decreasing cost and increasing read length of next-generation sequencing technologies, reconstructing the multiple haplotypes of a polyploid genome from its sequence reads becomes practical. However, the computational challenge in polyploid haplotyping is much greater than that in diploid haplotyping, and there are few related methods. Results: This paper models the polyploid haplotyping problem as an optimal poly-partition problem of the reads, called the Polyploid Balanced Optimal Partition (PBOP) model. For the reads sequenced from a k-ploid genome, the model tries to divide the reads into k groups such that the difference between the reads of the same group is minimized while the difference between the reads of different groups is maximized. When the genotype information is available, the model is extended to the Polyploid Balanced Optimal Partition with Genotype constraint (PBOPG) problem. These models are all NP-hard. We propose two heuristic algorithms, H-PoP and H-PoPG, based on dynamic programming and a strategy of limiting the number of intermediate solutions at each iteration, to solve the two models, respectively. Extensive experimental results on simulated and real data show that our algorithms can solve the models effectively, and are much faster and more accurate than the recent state-of-the-art polyploid haplotyping algorithms. The experiments also show that our algorithms can deal with long reads and deep read coverage effectively and accurately. Furthermore, H-PoP might be applied to help determine the ploidy of an organism. Availability: https://github.com/MinzhuXie/H-PoPG Contact:
Methods
Formulation and ProblemThe input of the polyploid haplotyping problem consists of aligned DNA reads sequenced from a k-ploid organism. In our approach, we try to divide the reads into k different groups according to their original haplotypes. Since it is trivial to determine the alleles of the k-haplotypes at homozygous loci, and only loci where the reads have different alleles can be used to partition the reads into different groups, we will only keep alleles of the aligned reads on heterozygous SNP loci. The input aligned reads are denoted by an m  n SNP matrix M as in previous work (), where m is the number of reads and n the number of heterozygous SNP loci. M, the entry of M at the ith row and jth column, encodes the allele of the ith read at the jth heterozygous SNP loci. Mtakes a value from {0, 1, }, where '0' (or '1') represents the major allele (or the minor allele, respectively) at the locus in the population and '' represents an unknown allele. The ith row (read) of M is denoted as r i and the jth allele of r is denoted as r. Similarly, a haplotype is denoted as a sequence of '0', '1' and '', and the jth allele of a haplotype H is denoted as H. For two alleles a 1 , a 2  {0, 1, }, we define a similarity functionGiven a set R = {r 1 , ..., rp} of p rows (reads), a k-partition function P of R is defined as a map P : {1, ..., p}  {1, ..., k}, which means that r i is put into the P (i)th group (subset) G P (i) according to the function P. Since every row in R has a unique index, the row with the smallest index in a group is called the representative row of the group, and the smallest index of the rows in a group G is denoted by I(G). If G = , let I(G) = p + 1. Let the groups obtained by applying P on R be G P 1 , ..., G P k. A k-partition function P is called a canonical k-partition function if the following condition holds: for any two groupsThe consensus haplotype H i of the ith group G i is defined as the haplotype that maximizes the sum of similarities between the reads in the group G i and the haplotype, i.e., H).Assume that the consensus haplotypes are the original haplotypes, and the difference between the consensus haplotypes and the reads can be regarded as sequencing errors. Given a k-partition function P on a set of reads (rows), the corrected error measure C(P ) is defined as the total difference between the reads and the consensus haplotypes of their groups,Since we only consider heterozygous loci, any two of the k haplotypes should not be identical when several consecutive heterozygous loci are considered together, and it is desirable that the k consensus haplotypes are distinctively different. We introduce another measure D(P ) as follows, which is called the diversity measure:We would like to find an ideal partition P that makes the difference between the reads of a same group minimized and the difference between the reads of different groups maximized, i.e. one that minimizes C(P ) and maximizes D(P ). However, this may be impossible in most cases, since a partition function P minimizing C(P ) may not ensure that D(P ) is maximized and vice versa. Therefore, we combine both measures into a weighted partition score:where w is a weighting parameter with 0  w  1. In the following, we propose a new optimization model for the polyploid haplotyping problem. Polyploid Balanced Optimal Partition (PBOP): Given an SNP matrix M and weight w, find a k-partition function P of the rows in M such thatis maximized. Note that when w = 1 and k = 2, PBOP becomes the MEC model for the diploid haplotype assembly problem. MEC is known to be NPhard (). In fact, it has been recently shown not to be in APX under the Unique Games Conjecture (). Therefore, PBOP is also NP-hard, and not in APX under the Unique Games Conjecture. In the next subsection, we introduce a heuristic algorithm called H-PoP. When the genotype G of the polyploid is known, we will also consider the genotype constrained version of PBOP. Since we do not consider homozygous loci, for each locus j, G {1, ..., k  1}. G= t means that at the jth locus, there are t haplotypes taking the allele '1' and the other k  t haplotypes taking the allele '0'. Let I i (x) be an indicator function, i.e. I i (x) = 1 if x = i; otherwise 0. Given a k-partition function P on a set of rows R = {r 1 , ..., rp}, the consensus haplotypes H  1 , ..., H  k with genotype constraint G are the haplotypes that satisfy the following conditions: (i) H  i=  when there are no reads in group G i covering the jth locus (i.e. the alleles at locus j of the reads in group G i are all unknown), (ii))  k  Gfor each locus j  {1, ..., n} and (iii) n j=1 s(r, H  i) is maximized.The genotype constrained corrected error measure C  (P ) and partition score s  (P ) are defined as:Similarly, the genotype constrained diversity measure D  (P ) and partition score s  (P ) are defined as follows:Polyploid Balanced Optimal Partition with Genotype constraint (PBOPG): Given an SNP matrix M , the genotype G of the polyploid and weight w, find a k-partition function P of the rows in M such thatis maximized.
AlgorithmGiven an m  n SNP matrix M , the number of ways to partition m different rows r 1 , ..., rm into k non-empty groups is a Stirling number of the second kind, which is denoted as S(m, k).when m is large, it is impractical to enumerate all possible partitions and choose one with the maximum partition score. To solve the PBOP model of M efficiently, we propose a heuristic dynamic programming algorithm in the subsection. In other words, we will consider solutions for a number of rows of M then extend the solutions to the next row, and so on until all rows of M have been considered. We first introduce some definitions and notations similar to those in (), but some of which have different meanings. Let b(i) (e(i)) denote the first (the last) column at which the ith row of M takes non-'' values. If and only if b(i)  j  e(i), row i spans column j. R(j) denotes the set of rows that contain the rows in M spanning the jth column. In the following, we assume that M has been sorted such that for two). Let P be a canonical k-partition function on a set of rows R and P  a canonical k-partition function on a subset R  of R. If for any two rowsif and only if P (i) = P (j), P  is called the projection of P on R  and P an extension of P  on R. It is easy to verify that given a partition P of R and a subset R  , the projection of P on R  is unique, but not vice verse. The projection of P on R  is denoted by Pfor convenience. Let P be a canonical k-partition function of the subset R = { r i 1 , ..., r iq } of the rows of M with iq as the largest row index in R,the set of all rows from the first row to row r iq ). P  is an optimal extension of P if the following conditions hold: (i) P  is an extension of P on R  and (ii) for any possible extension P  ofSimilarly, when the genotype G is available, P  is a genotype constrained optimal extension of P if the following conditions hold: (i) P  is an extension of P on R  and (ii) for any possible extension P  ofdenote an optimal extension of P and E  (P ) a genotype constrained optimal extension of P. We call)) the global (or the genotype constrained global)score of P and denote it as se(, respectively) for convenience. The following theorem is straightforward.We consider the set of canonical k-partition functions that partition a set of i rows into at most k groups, and denote the function set as F(i, k). Let S(p, q) denote the set of canonical functions that partition p rows into q non-empty groups. It is obvious that F(i, k) =  q=1..t S(i, q), where t is the maximum of i and k. Let p and q be positive integers. To enumerate all canonical functions that partition p rows into q non-empty groups, we consider the following cases: @BULLET p < q: Such functions do not exist, i.e. S(p, q) = . @BULLET p = q:It is easy to verify that S(p, q) contains only one partition function, i.e. P (i) = i for i = 1 to p (denoted by P (1..p) = 1..p). @BULLET p > q: If q = 1, there is only one partition function in S(p, q), i.e. P (i) = 1 for i = 1 to p (denoted by P (1..p) = 1). If q > 1, we may construct S(p, q) using the following recursive process. Considering the last row p, the group containing row p either has only one row, i.e. row p, or two or more rows. We denote the set of partition functions that put row p into a group by itself (labeled as group q) and partition the first p1 rows into the other q 1 non-empty groups as)}, and denote the the set of partition functions that partition the first p  1 rows into q non-empty groups and put row p into one of the q groups as {(. Then, we have the following recurrence:Figure 2 illustrates F(4, 3), the set of all 15 different functions partitioning 4 rows into at most 3 groups. In the graph, the values S(p, q) with p = q or q = 1 are represented as the leaf nodes and a partition function is represented by a path from the root node to a leaf node. Please note that there may be more than one path from the root to a leaf node. For example, there are three different paths from the root F(4, 3) to the node S(3, 3), corresponding to three different functions:Given an m  n SNP matrix M , our algorithm considers the set R(1) of rows spanning column 1 first. To make the algorithm scalable, we will be able to enumerate all the partition functions on a small number of rows. Let q be the maximum integer such that | F(q, k) | 1000 and q | R(1) |. Let R f be the set of the first q rows in R(1) and R b contain the rest of the rows in R(1). When R(1) contains no more than q rows, R f = R(1) and R b = . Since the number of rows in R f is at most q and | F(q, k) | 1000, it is practical to enumerate all partition functions of R f by the above method. For each group G obtained by partitioning R f according to some function P , let b(G) = min rG b(r) and e(G) = max rG e(r). We use a 2  n matrix to record a profile P(G) for G, where the element P(G)counts the number of rows of G whose values at column j is v for v = 0, 1 and j = b(G), ..., e(G). The set of the profiles for all groups incurred by P is denoted as P P. Based on P(G), we obtain a consensus haplotype H G of G easily:(10) Using equations (4)-(6) and (10), the score s(P ) of a kpartition function P on R f can be calculated in time O(lmthat at the very beginning of the algorithm, R f = {r 1 , ..., rq}, and both the optimal extension and the genotype constrained optimal extension of a partition function P of R f are P itself,For an optimal partition function P of the set of the rows in M , the projection of P on R f is likely a suboptimal partition function of R f. In the following extension from R f to rows in R b , we will only consider the top 10k 2 partition functions of R f , which is denoted by F , based on empirical experience. If R b is not empty, let r be the row with the smallest index in R b and R  f = R f  {r}. We construct all possible extensions of the functions in F to R  f and record (at most) 10k 2 extensions with the highest global scores in F . For a partition function P on R f , there are at most k extensions of P on R  f. Let the number of rows in R f be q f and g = max i=1..q f P (i), i.e. P partitions the q f rows of R f into g nonempty groups G 1 , ..., Gg. Since the row r can be put into any one of the g groups, there are at leastWhen g < k, r can be put into a new group and hence there is an additional extensionLet the nonempty groups obtained by applyingSince the difference s between the global scores of P  t and P is due to putting r in G  t , it is easy to compute by considering two cases below.where Ir= 1 when r takes value v at column j; otherwise Ir= 0. Use Equation (10) to compute@BULLET t > g: In this case, g < k and g  = t = g + 1. For i = 1, ..., g,= Irfor v = 0, 1 and j = b(r), .
.., e(r),where Ir= 1 when r takes value v at column j; otherwise Ir= 0.can be obtained easily using Equation (10). Then)The global score ofwhich can be calculated in time O(lk),The above process is repeated until R b becomes empty and R f = R(1). After obtaining the top 10k 2 partition functions of R(j) for some j, which are again stored in F , we consider the next column jWe first compute the projections of the functions in F on Rr, and then extend them to R(j + 1). Let F  be the set of the projections of all functions in F on Rr. It is obvious that | F  || F |. For a function P in F , we can easily compute its projection P  on Rr.otherwise, we compute its projection P  as follows. Let the rows in Rr be r i 1 , r i 2 , .
.., and r iz , and P  be such a partition function of Rr
.., iz. Suppose that P  partitions Rr into t non-empty groups G 1 , .
.., G t. Sort these groups by their representative row indices in the ascending order and let rank(g) be the rank of G  g in the sorted groups, i.e. if the representative row index of G  g is the p smallest then rank(g) = p., iz, and then P  is the projection of P on Rr. For each function P  in F  , we can calculate its global score se(P  ) using the equation below:The time complexity of computing F  and the scores isthe corresponding scores have been computed, set, and extend the functions in F to R(j + 1) by deleting a row from R b and adding it to R f , one at a time, until R f = R(j + 1) as done above by using Equation (11). The above iteration continues until R(j) contains the last row of M. Finally, an extension of the function in F with the highest global score is output as a solution to the PBOP problem of M. A pseudo code for this algorithm, called H-PoP, is presented atin the Supplementary Materials. For the PBOPG model, a similar heuristic algorithm H-PoPG can be easily devised. All we need is a simple modification of H-PoP to make use of the provided genotype information. Please see the Supplementary Materials for the details of H-PoPG.
ResultsWe use both real data and simulated data to compare the performance of our algorithms H-PoP, H-PoPG and three recent single individual polyplotyping algorithms HapCompass (), HapTree () and SDhaP (). Besides aligned SNP reads, all algorithms except H-PoP and SDhaP require genotype information as an additional input. The weight w is set as 0.9 for H-PoP and H-PoPG unless otherwise specified. All tests are conducted on some 64 bit nodes with 2.6GHz CPU and 128GB RAM of a Linux cluster, and each result on simulated data is the average of 100 repeated tests with the same parameters.
Results on Real DataUsing 454 GS FLX Titanium sequencing, Curtin et al. () obtained a 12.7 Mb assembly of AWRI1499, a prevalent wine spoilage strain of the yeast species Dekkera bruxellensis. The assembly is comprised of 324 contigs (N50 = 68 kb) in 99 scaffolds, at median read coverage of 26-fold and it was found that AWRI1499 is a triploid (). We downloaded the read data from the SRA database of NCBI under the accessions SRX327045 and SRX327033, and the 14 contigs of the first scaffold from the Assembly database of NCBI under the accession AHIQ01. After cleaning adapters and low quality bases from the reads, BWA-MEM () was used to align the reads against the contigs with default parameters, and the SAMtools package (,b) was used to call SNPs based on the aligned reads. The genotype of an SNP locus is determined by the proportion of the alleles 0 and 1 on the locus. Keeping only alleles at the heterozygous SNP loci of the aligned reads, we obtained 14 SNP matrices, one for each contig. We tested H-PoPG, H-PoP, HapTree, HapCompass and SDhaP on these real data. AWRI1499 is a triploid, but its three true haplotypes are unavailable. Instead, there are only consensus contigs. Since the true haplotypes are unknown, we use the MEC score () to evaluate the accuracy of the reconstructed haplotypes. More precisely, given an m  n SNP matrix M , let the reconstructed k haplotypes be H = (H 1 ,..., H k ). The MEC score sc(H, M ) is the minimum number of sequencing errors in the SNP matrix if H is considered as the true haplotypes. That is,,...,n d(M, Hp) ) ,where d(., .) is the dissimilarity function given in Equation 2. The MEC rate ec(H, M ) is the minimum sequencing error rate of the corresponding DNA reads at the SNP loci if H is considered as the true haplotypes, i.e. ec(H, M ) = sc(H, M )/ the number of non-'-' elements of M. The detailed test results on all 14 individual contigs are given in Tables S1-S14 of the Supplementary Materials. H-PoPG, H-PoP, HapCompass and SDhaP were able to reconstruct the haplotypes from the SNP matrices for all contigs, but the performance of HapCompass was clearly inferior to the other algorithms. H-PoPG and HapTree achieved similar MEC rates. Without the genotype constraint, SDhaP had less MEC rates while H-PoP obtained the least MEC rates. However, HapTree aborted with run-time errors on the data of contigs 6, 8, 15, 17, and 21, and failed to terminate in seven days on the data of contig 19. The SNP matrices of contigs 6, 8, 15, 17, 19 and 21 consist of 64223 rows and 12226 columns (i.e. SNPs).shows that when regarding AWRI1499 as a diploid (i.e. set k = 2), the MEC rate of H-PoP was 4.33%, which is much larger than the raw single base sequencing error rate of 2.23% shown in the Supplementaryof. This suggests that we could perhaps use H-PoP to help determine the ploidy of an organism by trying different k and comparing the MEC rate and DNA sequencing error rate. When regarding AWRI1499 a triploid, without applying the genotype constraint, the MEC rate 0.43% achieved by H-PoP was the least, about a half of that of SDhaP. With the genotype constraint, the MEC rate 1.28 of H-PoPG was a little better than that of HapTree. The MEC rate 3.25 of HapCompass was the largest, which suggests that the reconstructed haplotypes of HapCompass may be inaccurate. The phased SNPs of HapTree, HapCompass and SDhaP are 4096, while two of these SNPs were not phased by H-PoPG since it does not perform phasing at loci that are not covered by reads in the corresponding groups. As for running time, H-PoP and H-PoPG were more than 40 times faster than HapTree, HapCompass and SDhaP. The maximum run-time (resident) memory used by HapCompass and SDhap was more than 20GB, while the other algorithms needed only less than 3GB memory.
Results on Simulated DataWe generated aligned SNP reads of a polyploid genome as follows. First, k genomes were generated based on the real contigs and VCF files of AWRI1499. Given a contig as the haplotype template and a corresponding VCF file, we generated k copies of the contig as the initial k genomes. For each heterozygous SNP in the VCF file, a genotype g (the number of alternative alleles) of the SNP was generated randomly following a uniform distribution from 1 to k  1. Then g genomes were randomly selected from the k genomes and their alleles at the SNP locus were set as the alternative alleles, while the other genomes were set as the reference alleles. The generated k genomes were saved in a FASTA format file named k-ploid.fa. Second, we used ART (), a next-generation sequencing read simulator, to generate simulated reads from the the k genomes. To simulate the real data of AWRI1499, we ran ART with the 454 GS FLX Titanium platform profile that came with the simulator to generate single-end reads and paired-end reads. ART requires a parameter, the coverage c of each haplotype, to generate single-end reads, and three parameters, the coverage c of each haplotype, the mean insert length f and the standard deviation  of insert length, to generate paired-end reads. In the following tests without explicit specification, f was set as 800 and  was set as 150 according to the distribution of the reads in the real data. The single-end and paired-end reads in the same dataset were generated by ART with the same coverage parameter. Correct phasing rate (Rc), and perfect solution rate (Rp) will be used to measure the phasing accuracy of the k haplotypes reconstructed by an algorithm. When the genotype of the reconstructed haplotypes equals to the original genotype, another measure vector error rate (Rv) () is used too. Let the set of k haplotypes reconstructed by an algorithm be H = {H 1 , H 2 , ..., H k } and the set of true haplotypes bebe a one-to-one mapping from H to), where s is the similarity function given in Equation (1). The correct phasing rate Rc is defined as follows:where n is the number of phased SNPs. For the example, in, the correct phasing rate Rc(H) = 10/12. The perfect solution rate is Rp = nc/k, where nc is the number of haplotypes correctly reconstructed (i.e. they are exactly the same as the true ones) by the algorithm. For example, the perfect solution rate of H inis 1/3. The vector error measure is a generalization of the switch error measure for diploid haplotype assembly to polyploid phasing. The vector errors in k reconstructed haplotypes are defined in () as the minimum number of segments on all chromosomes for which a switch must occur. To make it easy to understand, we give another equivalent definition of the measure here. A one-to-one mapping H from H to H * is called a matching at locus j if), where I is an indicator function (i.e. I(a) = 1 if a is a true statement and I(a) = 0 otherwise). When the genotypes of H and H * are equal, there exist a series of one-to-one mappings M = {H 1 , ..., Hn} such that H j is a matching at locus j for j = 1, ..., n, and such a sequence is called a matching sequence. For a matching sequence M, the total number of changes between adjacent matchings is Tc(The number of vector errors ev in H against H * are defined as:The number of vector errors ev can be calculated by a dynamic programming algorithm in time, which is faster than the method used in () with time complexity O(kn 2 ), when k is small and n is big. Please seeof the Supplementary Materials for the the pseudocode of the dynamic programming algorithm. The vector error rate Rv is defined as ev/n. For example, in, there is a matching sequenceIt is easy to see that Tc(M) = 2, the number of vector errors in H is 2 and the vector error rate Rv = 2/4 = 0.5. To choose an appropriate weight w for H-PoPG, we tested its performance with different w from 0.8 to 1.0, and compared it with HapTree and HapCompass. We used the first contig of AWRI1499 as the haplotype template and ran ART with c = 2 to generate 100 triploid read data sets (each consisting of a set of single-end reads and a set of paired-end reads). After alignment to the contig and deleting alleles at homozygous SNP loci and reads that cover fewer than 2 heterozygous SNP loci, we obtained 100 SNP matrices, each of which has 449 columnsOnly 1 of 3 haplotypes of H * is phased by H with no error:. When the weight w was set as 0.9, H-PoPG reached the best performance among the three algorithms according to(a) in vector error rate,(b) in perfect solution rate and(c) in correct phasing rate.(d) shows that the rate of phased SNPs (i.e. the phased SNPs to total SNPs ratio) of HapTree and HapCompass is the best at 99.3%, while the phased SNP rates of HPoPG with different weights are near 98.5%. Figures 4 (e) and (f) show that the running time and memory of H-PoPG varied little as the weight changes and H-PoPG used much less time and memory than HapTree and HapCompass. In the following experiments, w was set as 0.9 for H-PoPG and H-PoP as the default value. Since HapCompass ran very slow and its performance was clearly inferior to H-PoPG and HapTree, it was not included in the tests.genome.illustrates the test results on simulated data generated by ART with c = 6. When k = 5, H-PoPG was superior to the other algorithms in terms of vector error rate, perfect solution rate and correct phasing rate. When k = 4 and 6, HapTree was the best in terms of vector error rate and correct phasing rate, but H-PoPG was not far behind. On the other hand, the running time and memory requirement of HapTree increased at a significantly faster rate than those of the other algorithms when k increased. When k = 6, HapTree ran for 1301 seconds and used 63 GB memory, while H-PoPG used only 23 seconds and 4 GB memory. As for the phased SNP rate, there is very little difference between the algorithms, and it was above 99.3% for all algorithms.shows the test results on triploid data when we changed the haplotype template from the first contig of AWRI1499 to the concatenations of the first two contigs or the first four contigs. The number of heterozygous SNPs of the haplotype template increased from 449 to 1145 and 1739, respectively.illustrates that H-PoPG had the best performance in terms of vector error rate, perfect solution rate and correct phasing rate, while SDhaP was the worst in terms of perfect solution rate and correct phasing rate. The phased SNP rates of HapTree and SDhaP are a little higher than those of H-PoPG. The running time of HapTree increased significantly with the increased haplotype template length, while the running time of H-PoPG and H-PoP increased slowly. The running times and memories of H-PoPG and H-PoP are much less than those of HapTree and SDhaP. The length of reads generated by ART is limited by the buildin sequencing platform quality profile. To test the performance of the algorithms on long reads that future sequencing technologies might produce, we concatenated multiple copies of the Illumina HiSeq 2500 platform quality profile contained in the ART package and generated a simulated future sequencer quality profile file to avoid the read length limit of ART. We concatenated all 14 contigs of the first scaffold of AWRI1499 into a template haplotype consisting of 22178 heterozygous SNPs, and using the new quality profile, we ran ART to generate reads with parameters r (the length of reads to be simulated), f (the mean length of inserts for paired-end reads),  (the standard deviation of DNA fragment sizes), and c (the read coverage of each haplotype). We fixed c as 12,  as 50, and varied (r, f ) from (500, 2000) to (1000, 3000) and (2000, 6000), and the average length l of the generated SNP reads changed from 40 to 80 and 160.shows the test results. Since HapTree ran slowly when tested on the data withLinux cluster, each with a subset. As for the test with l = 80, since HapTree could only finish 4 subsets in 7 days, the results of HapTree inare the averages of its results on the 4 subsets. As for the test with l = 160, HapTree was unable to terminate on any subset in 7 days and hence its results are missing in.shows again that H-PoPG is the best in terms of vector error rate and perfect phasing rate. The correct phasing rates of H-PoPG, H-PoP and HapTree were all more than 99.8%, while those of SDhaP were less than 94%. With regard to running time and memory, H-PoPG and H-PoP were clearly more efficient than the other two algorithms.
ConclusionWith the rapid development of sequencing technologies, reconstructing the multiple haplotypes of a polyploid from DNA sequencing reads is becoming more and more practical. In this paper, we modeled polyploid haplotyping as a combinatorial optimization problem to partition the input reads, called the Polyploid Balanced Optimal Partition (PBOP) problem. Since the problem is NP-hard, we developed a heuristic algorithm HPoP for it. When the genotype information is available, we also proposed a genotype constrained version, called PBOPG, of the problem and designed a corresponding heuristic algorithm H-PoPG. Note that these methods are very different from our previous methods for dealing with diploids () since they consider the distance between the consensus haplotypes of different groups while the previous methods for diploids calculates the distance between reads belonging to different groups. We compared our algorithms with three recent state-of-the-art polyploid haplotyping algorithms SDhaP, HapTree and HapCompass on both simulated and real data. Our extensive test results showed that HPoPG was generally more accurate in reconstructing haplotypes than SDhaP, HapTree and HapCompass, and H-PoP was able to achieve comparable (though slightly worse) performance without the genotype information. Furthermore, H-PoPG and H-PoP ran much faster than SDhaP, HapTree and HapCompass, and could effectively handle long reads and deep read coverage. Our experiments on real data also showed that H-PoP could be used to infer the number of chromosomes of an organism (i.e. its ploidy), since when the parameter k is set smaller than the ploidy of the organism, the MEC rate of H-PoP would be much larger than the sequencing error rate.
FundingThis work has been supported in part by the National Natural Science Foundation of China under grant NO. 61370172 and US National Science Foundation grant DBI-1262107.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
3 15 F(4, 3) 1 S(4, 1) 7 S(4, 2) 1 S(3, 1) 3 S(3, 2) 1 S(2, 1) 1 S(2, 2) 6 S(4, 3)
We increased c from 2 to 4, 6 and 8, and generated SNP matrices with SNP read coverage changing from 11.7 to 23.7, 35.4 and 47.1 to test H-PoPG, H-PoP, HapTree and SDhaP. Figure 5 presents the test results. Without genotype information, the genotypes of the k haplotypes reconstructed by SDhaP and H-PoP were often different from that of the real k-haplotypes and hence vector error rate could not be used to measure the performance of SDhaP and H-PoP. When the coverage increased, the vector error rates, the perfect solution rates and the correct phasing rate of all algorithms improved. The vector error rates of H-PoPG are less than a half of those of HapTree, and the perfect solution rates of H-PoPG and H-PoP are clearly higher than those of HapTree and SDhaP. In the test with SNP read coverage 47.1, HapTree reached the highest correct phasing rate, while in the other tests H-PoPG performed best in term of correct phasing rate. HapTree and SDhaP phased the most SNPs, while the phased SNPs of H-PoPG were a little fewer than those of HapTree and SDhaP. In the test with SNP read coverage 11.7, the phased SNP rate of H-PoP was the lowest. However, even in the worst case, H-PoP phased more than 96% of the SNPs. In terms of efficiency, the average running times of H-PoPG and H-PoP were less than 2 seconds, which is obviously less than those of HapTree and SDhaP. H-PoPG and H-PoP used much less memory than HapTree and SDhaP when the coverage was 11.7, and HapTree used the least amount of memory in the other three cases. The memory requirement of SDhaP was about 26 GB, and it did not change much in different tests (including the tests below), while the memory required by H-PoPG and H-PoP was less than 3 GB in all four cases. It is interesting to observe that HapTree spent much more time and memory to handle the test data with coverage 11.7 than other data with deeper coverages. We varied k from 4 to 6 to test the performance of the algorithms on reconstructing the haplotypes of a tetraploid, pentaploid or hexaploid at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
