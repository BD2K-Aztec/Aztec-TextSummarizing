Motivation: Protein–protein interactions (PPIs) are pivotal for many biological processes and similarity in Gene Ontology (GO) annotation has been found to be one of the strongest indicators for PPI. Most GO-driven algorithms for PPI inference combine machine learning and semantic similarity techniques. We introduce the concept of inducers as a method to integrate both approaches more effectively, leading to superior prediction accuracies. Results: An inducer (ULCA) in combination with a Random Forest classifier compares favorably to several sequence-based methods, semantic similarity measures and multi-kernel approaches. On a newly created set of high-quality interaction data, the proposed method achieves high cross-species prediction accuracies (Area under the ROC curve ≤ 0.88), rendering it a valuable companion to sequence-based methods. Availability: Software and datasets are available at
INTRODUCTIONA major challenge in systems biology is the accurate mapping of the interactomethe set of all protein-protein interactions (PPIs) within a cell. Understanding the interactome is essential in deciphering protein function and cell behavior (). Large-scale interaction maps have been experimentally determined but are incomplete and show high error rates (von). Consequently, in silico methods have been developed to infer PPIs from various sources of information including sequence features such as n-gram composition, phylogenetic relationships, e.g. interologs, and Gene Ontology (GO) annotation.provide an excellent overview of features indicative for PPIs. Several studies have recognized similarity in GO annotation as one of the strongest predictors for protein interaction (). GO annotation-driven interaction inference is based on the observation that proteins localized to the same cellular compartment are more * To whom correspondence should be addressed. likely to interact than are proteins that reside in spatially distant compartments (). Similarly, proteins that share a common biological process or molecular function have been found to be predictive for PPI (). GO is organized as a graph with terms as nodes and edges describing relationships (). The literature distinguishes two fundamentally different approaches to exploit GO annotation for the prediction of protein interactions: (i) the semantic similarity measure (SSM) approach and (ii) the machine learning (ML) approach. SSMs are unsupervised methods that operate on a hierarchical graph (DAG) of relationships to measure similarities between entities. For instance, similarity between GO terms can be expressed by the shortest path between terms within the GO DAG. ML approaches for PPI inference, on the other hand, are supervised and the GO annotation of a protein pair is encoded by a feature vector, indicating assigned or shared GO terms, which is subsequently evaluated by an ML classifier. The ML approach has the advantage that advanced classification algorithms such as Support Vector Machines or Random Forests () can be applied, which are usually more accurate predictors than unsupervised methods. However, the traditional encoding of shared GO terms within the feature vector ignores the relationships between GO terms and therefore hides important information from the classifier. The SSM approach, on the other hand, explicitly exploits topological relationships between GO terms but is typically limited to comparatively simple predictors, e.g. term probabilities. These competing properties of the SSM and the ML approach have been recognized by many authors, and hybrid methods have been developed, in which the output of a SSM method serves as input (among others) to an ML classifier. However, the hybrid approach still does not allow the classifier to exploit term relationships directly. We hypothesized that a better integration of SSMs with ML algorithms may lead to improved prediction accuracies and we propose the concept of inducers to achieve such integration. In the following, we first discuss the various hybrid ML approaches and SSMs, before explaining inducers in Section 2.2. Patil and Nakamura (2005) trained a Naive Bayes classifier using input features such as shared GO terms, PFAM domains and sequence similarity to infer PPI. Shared GO terms were also exploited byto identify novel interactions in human., Lin (1998) and many others utilize the information content of the most informative common ancestor to measure term similarity. Edge-based methods, on the other hand, exploit the lengths of the paths between terms (). Only a few authors have utilized SSMs to infer PPIs.defined a similarity measure that is composed of three components, such as overlap of induced term subgraphs, term generality and term distances to lowest common ancestors.compared five SSMs to predict human PPIs and found Resnik's measure () to perform best. Finally, Jain and Bader (2010) introduced a novel SSM that attempts to compensate for the unequal depths of different branches of the GO DAG. In an evaluation on a yeast PPI dataset, the prediction performance (Area under the ROC curve) was on par with Resnik's similarity metric. Applications of SSMs to other prediction problems are referenced in Section 11 of the Supplementary Material.
METHODSIn this section, we first describe GO, then present inducers, and close with a description of the datasets employed for their evaluation.
GOGO is a hierarchically organized, controlled vocabulary to characterize gene products (). It is composed of the three subontologies: biological process (BP), cellular component (CC), molecular function (MF). Each subontology is represented by a rooted DAG with nodes referring to GO terms and edges defining relationships between terms. The inducers, described in the following, use only is_a and part_of edges and ignore all other relationships.
Term inducersTerm inducers define sets of GO terms that are induced within the DAG by the GO annotation of protein pairs. Inducers are motivated by the assumption that an induced term set is richer in information, and can be a more accurate predictor of protein interaction, than the original annotation. For instance, the terms along the shortest path between two GO terms within the DAG may be better indicators of protein interaction than the two GO terms alone. In the following, we first establish a general framework before describing individual inducers in detail. Let a GO DAG be given as a graph G(T ,R) with term set T , where terms represent nodes within the graph, and a relationship or edge set R  T T. Furthermore, let two proteins p 1 and p 2 be annotated by term sets S 1  T and S 2  T , respectively. From the two original term sets S 1 and S 2 a new,over the GO DAG and maps two term sets S 1 and S 2 , assigned to two proteins, onto a feature vector that serves as input to an ML classifier. Section 10 within Supplementary Material provides a pseudocode description of the inducer approach. induced term set S is constructed by applying an inducer I as follows:The induced term set is subsequently projected onto a feature vector v by associating each GO term t  T with an arbitrary but unique index idx(t)  {1,...,|T |} and setting v idx(t) = 1 if t  S, or 0 otherwise. The resulting binary feature vector is typically high-dimensional (|T | is large) but sparse (S << T ) and serves as input to a standard ML classifier, either to predict whether two proteins are interacting or to train the classifier.depicts the architecture of the system. While inducers can generate term sets in various ways, we are particularly interested in mappings that express the relationships between terms as given by the ontology graphsimilar to the way SSMs exploit topological information. We distinguish three classes of inducers. Basic inducers ignore term relationships, serve as controls and represent the traditional ML approach. Ancestral inducers are based on ancestor terms derived from a set of protein annotations and resemble node-based SSMs. Shortest pathinducers, which include terms along the shortest path or paths between two term sets, are similar to edge-based SSMs.
Basic inducersThe AL (All Labels) inducer computes the union of the term sets S 1 and S 2 , which annotate protein p 1 and p 2 , respectively:Equally simple is the AC (All Common terms) inducer, which is defined as the intersection of the two term sets S 1 and S 2 :Note that basic inducers do not induce an enriched term set. They represent the common approach, in which the annotation of a protein pair is described by an indicator vector that encodes either all assigned GO terms (AL) or the GO terms shared (AC) by the two proteins.
Ancestral inducerCommon ancestors of terms within the GO DAG are generalized concepts (subsumers) of their descendants, and form the basis of many SSMs. Ancestral inducers aim to take advantage of this information by generating sets that include ancestral terms of the original GO protein annotation. Let the set of parent terms of an individual GO term t be denoted as P(t). Also, let the set of parent terms P(S) over a set of terms S be defined as the union of the corresponding ancestor sets:With this definition, the set of ancestor terms can be written as A(S) = S A(P(S)), with A() =. Note that this recursive definition of ancestors includes the original term set S and all its ancestral terms up to the root term r. We furthermore define the depth D(t) of a term within the GO DAG as the longest path from the root r to term t, which can easily be calculated as D(t) = max{D(u)|u  P(t)}+1, with D(r) = 0. Equipped with the definitions above we now describe several ancestral inducers.Page: 71 6975 GO2PPIThe AA (All Ancestors) inducer computes the union of all ancestors of two term sets S 1 and S 2 :It is an extension of the AL inducer that includes the ancestral terms. Similarly, the ACA (All Common Ancestors) inducer extends the AC inducer by computing the intersection of the ancestor sets:The lowest common ancestor of two term sets is the shared ancestor with the largest depth D(). The OLCA (Only Lowest Common Ancestors) inducer generates this set. Note that there can be multiple lowest common ancestor terms (LCATs), all with the same depth.The LCA (Lowest Common Ancestors) inducer extends the OLCA set with the original term sets S 1 and S 2 :However, the LCA set still does not contain terms along the paths from the original term sets S 1 and S 2 to the lowest common ancestors. The ULCA (Up to Lowest Common Ancestors, see) extends the LCA set by incorporating those terms:with d lca being the depth of the lowest common ancestors. To assess the importance of the lowest common ancestor for PPI prediction, we also compute the WLCA (Without Lowest Common Ancestors) set, which is the ULCA set without the lowest common ancestors or equivalently, the AA set without the ACA set:
Shortest-path inducersThe length of the shortest path between two terms within the GO DAG is a measure for their relatedness. Shortest-path inducers strive to take advantage of this property by generating sets that include the terms along the shortest paths between two term sets. The shortest path within a graph is, however, defined only between two individual terms but not between sets of terms. A natural generalization for term sets would be the k-minimum spanning tree (k-MST) but is known to be NP-hard although there are fast approximations (). We employ a very simple heuristic to approximate the k-MST for proteins annotated with more than one GO term. For the following definitions, we treat the edges between nodes within the GO DAG as undirected and of constant weight. Let sp(t 1 ,t 2 ) be the set of terms along a shortest path between t 1 and t 2. We define the shortest path set sp(t,S) between a single term t and a term set S, based on the shortest shortest path set between t and any term in S:{|sp(t,u)| | u  S},with |sp(t,u)| being the number of terms along a shortest path between t and u. Note that sp(t,S) can be computed efficiently by terminating the algorithm as soon as a term in S is encountered. To compute the shortest path set between two term sets S 1 and S 2 , we first select two arbitrary terms t 1  S 1 and t 2  S 2. In the second step, a remainder set R is constructed, which is the union of the original term sets S 1 , S 2 and the shortest path set sp(t 1 ,t 2 ) but without t 1 and t 2 :Finally, the union of the shortest path sets between any term u  R and R without u is constructed:We call SPS(S 1 ,S 2 ) the Single Shortest Path inducer because only one shortest path is taken into account by sp(t,S). Within a DAG, however, there can be many shortest paths and we analogously define an All Shortest Pathswith sp (t,S) being the union of all shortest path sets between a term t and a term set S.
DataWe used data from Uniprot, GO, the STRING database and other authors to evaluate the prediction accuracies of the inducers presented above.
UniprotThe Uniprot () database (version 18, 2011-06-28) was downloaded and stored within an XML database (Berkeley DB). GO annotations for the proteins within the interaction datasets were extracted from this database. Annotations derived from physical (IPI) or genetic (IGI) interactions were excluded to avoid giving the inducer approach an advantage over other methods evaluated), and Section 7 of Supplementary Material].
GOThe GO database (Revision 1.1551) without cross-products, inter-ontology links and has_part relationships was downloaded. We also filtered out all regulatory relationships, and maintain only the is_a and part_of relationships.
Benchmark datasetsTo create a comprehensive benchmark set with high-quality interactions, seven PPI networks () were extracted from the STRING database (). We downloaded the database (version 9.0) and filtered for experimentally validated interactions tagged as binding with a confidence score 0.9) have shown that this introduces a bias, rendering the classification task significantly easier, and protein localization was therefore not taken into account. A possible alternative for high-quality negative data, the Negatome ()a database of non-interacting protein pairsdid not contain enough samples for our purposes. For further evaluations and comparison with other methods, we downloaded yeast datasets created by Park (2009) and Ben-Hur and Noble (2005) (for details see Section 2 of the Supplementary Material). The YP dataset is marginally different from the original set because four protein identifiers could not be mapped to Uniprot accession numbers (required by our method), but remains very similar with 3844 compared with 3867 interactions. Ben-Hur and Noble (2005) extracted two PPI datasets from the BIND database: the larger AB dataset and the smaller AB-rel dataset with reliable interactions only for which we successfully mapped all identifiers to Uniprot accession numbers.
RESULTSIf not stated otherwise, for all evaluations 10-fold cross-validation was performed by splitting the dataset into 10 parts, training on 9 parts, testing on the remaining part and repeating this procedure for each part. Sample sets were balanced with an equal number of positives and negatives. Prediction accuracy was measured by the Area under the ROC curve (AUC) or the AUC up to the first 50 false positives (AUC 50 ). We calculate AUC, where X k is the false positive rate and Y k is the true positive rate for the k-th output in the ranked list of predicted confidence or similarity scores generated by the classifier or SSM. To reduce computation time, ontology terms that are obsolete or unused were removed from the DAG, provided they were not part of the sub-DAG induced by used terms. First, we evaluated the prediction accuracy of the inducers introduced in Section 2.2. As described there, induced term sets were projected onto a feature vector and processed by a classifier. Naive Bayes was chosen as the underlying classifier, since no optimization of parameter settings is required and training is fast. Performance was measured on the SC (yeast) dataset, due its large size and highquality interactions (see Section 3 of Supplementary Material for results on other datasets).shows the prediction accuracies of all inducers for the three ontologies.Strikingly, all inducers that compute common ancestors (CA) show higher prediction accuracies than shortest path (SPS, SPA) and basic inducers (AC, AL), with the ULCA method being the top performer. But the results also reveal that it is not the lowest common ancestor terms (LCATs) alone that are responsible for the superior performance. First, the accuracy of the OLCA inducer (which generates LCATs only) is lower than that of the ULCA method. Second, terms along the paths from the original term sets up to, but without, the LCATs are not sufficient for top performance either, as the lower accuracy for the WLCA inducer (which excludes LCATs) indicates. Finally, the combination of the original term sets and LCATs as generated by the LCA inducer is still inferior to the ULCA method. The prediction accuracy of the shortest-path methods (SPS, SPA) is slightly better than that of the basic inducer AC, comparable to AL but inferior to all common ancestor methods (CA). Note that within a tree topology and for proteins annotated with single GO terms, the shortest path inducer and the ULCA inducer would be essentially equivalent. In agreement with Jain and Bader (2010), we find that the predictive power of the BP and CC ontologies is similar, with a slight advantage for the BP ontology, while the predictive power of the MF ontology is considerably lower. As stated previously, shortest path and common ancestor inducers resemble many SSMs. The main difference between inducers and SSMs is that the former map induced terms on a (high-dimensional) feature vector to be evaluated by a supervised classifier, while the latter compute a single similarity value using an unsupervised approach., maximum (MAX) and average (AVG) strategies were found to be inferior (see Section 4 of Supplementary Material).found Random Forests (RF) superior to NB classifiers, and to achieve peak accuracies we combined the ULCA inducer Page: 73 6975 GO2PPI. Comparison of the ULCA inducer (last three bars), using an RF classifier, with semantic similarity measures (JIA,  , SP) on the SC dataset for all three ontologies (BP, CC, MF). Results are 10-fold cross-validated. Error bars show SD. with an RF. To avoid possible bias, we optimized the RF parameters (#trees=200, depth=max, #features=200) on an independent dataset of Chlamydia trachomatis interactions, extracted from the BioGrid database and used nowhere else in this study. The results show substantially higher AUCs of the inducer approach for all three ontologies compared with all SSMs. Within the suite of SSMs, the GEN and SP methods performed best, closely followed by other SSMs, with the exception of the JIA methods. Section 4 of Supplementary Material provides more detailed data. In addition to SSMs, we furthermore compared the prediction performance of the ULCA inducer to state-of-the-art machine learning approaches.lists the AUC and AUC 50 scores of five sequence-based methods, a hybrid approach and a GO-kernel in comparison to the ULCA inducer with an RF classifier. The inducer used an integration of the three ontologies to achieve the best performances (see Section 1 of Supplementary Material for details). Note that methods M1-M4 and C exploit sequence information only and use SVMs as classifiers. Method M1 byutilizes trigram signatures as features, M2 byrelies on the co-occurrence of subsequences, M3 byevaluates trigrams over a reduced amino acid alphabet and M4 bycomputes auto-correlation over seven physicochemical properties to predict interactions. Method C byis a consensus over the methods M1-M4. The prediction accuracies of all five methods were evaluated byon the YP dataset. Ben-Hur and Noble (2005) employed a SVM with a combination of various kernels derived from sequence data, GO annotation, network properties and interolog information to predict PPIs. Method AK indicates the case where all kernels were combined, while method GOK means that only the GO kernel was used. The latter measured the similarity between two proteins by computing the maximum log likelihood over the common ancestors of the GO term annotations. The inducer approach achieves substantially higher AUCs than all sequence-based methods (M1-M4), including the consensus method(C). In comparison to Ben-Hur's multi-kernel method (AK), the inducer approach is inferior on the set of reliable interactions AB-rel and slightly inferior to the GO kernel alone (GOK) on the same dataset. On the full dataset (AB), the inducer performs substantially better than the GO kernel (GOK). Section 2 of the Supplementary Material describes the comparisons above in more detail. Park (2009) also evaluated the cross-species accuracy by training a classifier on one species and predicting interactions for a different species. He found the cross-species accuracy of the sequence-based predictors to be low. For instance, a 4-fold cross-validation AUC of 0.85 was achieved on the yeast dataset, and an AUC of 0.90 on the human dataset. However, when trained on yeast and applied to human, the prediction accuracy dropped from 0.90 to 0.68.displays the cross-species and self-test accuracies (AUC) of the ULCA inducer with an NB classifier on the BP ontology over seven species (results for other ontologies can be found in the Section 5 of the Supplementary Material). Dark colors indicate low prediction accuracies (AUCs) and the values along the diagonal are the AUCs of the self-test (training and test on the same dataset). Self-test accuracy is not very useful in general, but in case of an NB classifier (which has a low VC dimension) provides an optimistic but reasonable approximation of its maximum cross-validation accuracy. Apart from the three smallest PPI datasets (DM, AT, MM) the cross-species accuracies of the GO-driven approach are good, with AUCs between 0.78 up to 0.88. The highest cross-species AUC of 0.88 was achieved for a predictor trained on the yeast (SC) and tested on Escherichia coli (EC). There is a clear trend for AUCs below the diagonal of the matrix to be higher than the corresponding AUCs above the diagonal, indicating that the prediction accuracy largely depends on the test dataset (target species) and only to a lesser degree on the training dataset (source species). Consequently, datasets with high self-test accuracies lead to high test accuracies for all training datasets, while datasets linked to low self-test accuracies (e.g. MM = 0.73) result in low cross-species accuracies. For example, a classifier trained on human (HS) and tested on E. coli (EC) achieves an AUC of 0.87, while a predictor trained on E. coli and applied to human reaches an AUC of only 0.80. Error rates on the target species can be contributed to false interactions or false GO annotations.estimated error rates as high as 49% for ISS evidence codes, and 18% for GO Page: 74 6975annotation from experimental evidence. High self-test accuracies of an NB classifier indicate highly consistent datasets, on which a classifier can perform well. Since GO annotation is essentially designed to be species-independent (), a model trained on one species can be transferred and successfully be applied to a different species.
S.R.Maetschke et al.
DISCUSSIONInducers encompass the traditional ML approach, in which only the assigned GO terms are mapped onto a feature vector (ignoring the GO topology), and also SSMs. For instance, Resnik's SSM is effectively an OLCA inducer with a simple classifier, utilizing information content as term weights. Numerous variants of Resnik's method with different aggregation strategies have been developed, but for many applications do not achieve higher accuracies.reviewed SSMs applied to biomedical ontologies and in 5 of 11 studies Resnik's method with BMA or MAX as aggregation strategy was identified as the best performer. The ULCA inducer presented here significantly outperforms Resnik's method with BMA/MAX aggregation because the latter (and most other SSMs) are unsupervised methods, limited to simple estimators (e.g. term probabilities), while machine learning methods are able to model higher-order statistics. To confirm this, we replaced the classifier component of the ULCA inducer by the average or the maximum information content over the induced term set. The resulting prediction accuracies drop to the level of SSMs (Section 4 of Supplementary Material). The inducer approach outperformed the sequence-based method evaluated (), but it is noteworthy that Patil and Nakamura (2005) found sequence similarity and GO annotation to have low correlation (r = 0.13), implying that a combination of GO and sequence-based methods could lead to further improvements in prediction accuracy. While the cross-species accuracy of sequencebased methods is low, they have the advantage of being applicable in cases where sequence data but no further annotation is available, e.g. newly sequenced genomes. On the other hand, annotation software such as Blast2Go () can be employed to transfer GO terms to unannotated gene products. Since annotation transfer is largely based on sequence similarity as well, it remains an open question whether the superior accuracy of the inducer approach can be maintained in this case. The computational burden of the inducer-based approach can be alleviated by using a reduced term set, a so-called GO slim. While slims lead to much shorter feature vectors and therefore shorter prediction times, they also reduce the prediction accuracy considerably (Section 6 of Supplementary Material). Furthermore, the mapping of GO annotations to slim terms via map2slim.pl (http://search.cpan.org/~cmungall/go-perl/scripts/ map2slim) is algorithmically more complex than the ULCA inducer and also requires the selection of a suitable slim. Here, we utilized a binary encoding to indicate the presence or absence of shared GO terms in an induced term set. However, the binary encoding cannot distinguish between the case in which a GO term is assigned to only one protein, and that in which it is assigned to none of the two proteins. This loss of information can be avoided by using a ternary encoding, e.g. 1 for GO terms assigned to one of the two proteins, 2 for GO terms assigned to both proteins and 0 otherwise. We found the ternary encoding not beneficial for the ULCA inducer, but it considerably improved the accuracy of the AL inducer (Section 8 of Supplementary Material). It is known that PPI networks contain many more non-interactions (negatives) than interactions (positives).estimate a ratio of 600:1 but as classifiers generally cannot be trained on sample sets of this size, balanced datasets are used instead (Ben). Performance is frequently measured by the AUC to compare methods and by the AUC 50 as a practically relevant measure for experimental validation of top-ranking predictions. We found the AUC stable for different ratios but the AUC 50 highly volatile and less reliable (Section 9 of Supplementary Material).
CONCLUSIONIn this work, we introduce the concept of inducers to better integrate ML methods and SSMs for the inference of PPIs. The inducer approach outperformed a suite of sequenced-based methods and SSMs, and achieved accuracies close to a multi-kernel method that exploits information beyond mere GO annotation. On a high-quality yeast PPI dataset, a peak prediction accuracy of 0.91 (AUC) was achieved by the ULCA inducer in combination with a RF classifier. We also showed that the cross-species prediction accuracy of the inducer approach is high (AUC  0.88). When comparing the three individual ontologies of the GO we found, in agreement with other studies (), similarities in biological process and cellular component annotation to be stronger indicators for protein interaction than similar molecular function annotation. It is noteworthy that the proposed method is not specifically designed for the prediction of PPIs and can be applied to other domains described by ontological data. Considering the growing number of ontologies () and their improving coverage, formality and integration (), we expect
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
