Method: Dynamic Bayesian networks (DBNs) have been applied widely to reconstruct the structure of regulatory processes from time series data, and they have established themselves as a standard modelling tool in computational systems biology. The conventional approach is based on the assumption of a homogeneous Markov chain, and many recent research efforts have focused on relaxing this restriction. An approach that enjoys particular popularity is based on a combination of a DBN with a multiple changepoint process, and the application of a Bayesian inference scheme via reversible jump Markov chain Monte Carlo (RJMCMC). In the present article, we expand this approach in two ways. First, we show that a dynamic programming scheme allows the changepoints to be sampled from the correct conditional distribution, which results in improved convergence over RJMCMC. Second, we introduce a novel Bayesian clustering and information sharing scheme among nodes, which provides a mechanism for automatic model complexity tuning. Results: We evaluate the dynamic programming scheme on expression time series for Arabidopsis thaliana genes involved in circadian regulation. In a simulation study we demonstrate that the regularization scheme improves the network reconstruction accuracy over that obtained with recently proposed inhomogeneous DBNs. For gene expression profiles from a synthetically designed Saccharomyces cerevisiae strain under switching carbon metabolism we show that the combination of both: dynamic programming and regularization yields an inference procedure that outperforms two alternative established network reconstruction methods from the biology literature. Availability and implementation: A MATLAB implementation of the algorithm and a supplementary paper with algorithmic details and further results for the Arabidopsis data can be downloaded from: http://www.statistik.tu-dortmund.de/
INTRODUCTIONTwo paradigm shifts have revolutionized molecular biology in the second half of this decade: systems biology, where the objective is to model the whole complexity of cellular processes in a holistic sense, and synthetic biology, which enables biologists to build new molecular pathways in vivo, i.e. in living cells. The combination of both concepts allows the viability of machine learning approaches for network reconstruction to be tested in a rigorous way. As an alternative to mechanistic models (), which provide a powerful approach to the modelling of small systems composed of a few components, and correlation/mutual information based approaches, which do not distinguish between direct and indirect interactions (), dynamic Bayesian networks (DBNs) have emerged as a promising tradeoff between over-simplicity and loss of computational tractability (). The standard assumption underlying DBNs is that of homogeneity: temporal processes and the time-series they generate are assumed to be governed by a homogeneous Markov relation. However, regulatory interactions and signal transduction processes in the cell are usually adaptive and change in response to external stimuli. Following earlier approaches aiming to relax the homogeneity assumption for undirected graphical models (), various recent research efforts have therefore addressed the homogeneity assumption for DBNs. An approach that has become popular recently is based on a combination of a DBN with a multiple changepoint process, and the application of a Bayesian inference scheme via reversible jump Markov chain Monte Carlo (RJMCMC). Robinson andproposed a discrete inhomogeneous DBN, which allows for different structures in different segments of the time series, with a regularization term penalizing differences among the structures.proposed a continuous inhomogeneous DBN, in which the parameters are allowed to vary, while a common network structure provides information sharing among the time series segments. Lbre (2007) andproposed an alternative continuous inhomogeneous DBN, which is more flexible in that it allows the network structure to vary among the segments. The model proposed inis a close cousin of an inhomogeneous DBN. As opposed to the first three approaches, (hyper-)parameters are not consistently inferred within
M.Grzegorczyk and D.Husmeierthe Bayesian context, though, and these methods will therefore not be further considered here. Instead, we will focus on the Bayesian inference scheme common to the first three approaches. All three methods adopt an RJMCMC scheme for inferring the number and location of changepoints, based on changepoint birth, death and relocation moves. In the present article we show that the number and location of changepoints can be sampled from the proper conditional distribution. This is effected by a modification of the dynamic programming scheme proposed inin the context of Bayesian mixture models. We discuss the trade-off between computational up-front costs and improvement in mixing and convergence, and we empirically quantify the net gain in computational efficiency in dependence on certain features of the prior distribution. The above mentioned inhomogeneous DBNs can be divided into two classes according to whether changepoints are common to the whole network (class 1), or varying from node to node (class 2). The approach of class 1, pursued in, Robinson and Hartemink (2009) 1 and, is over-restrictive, as it does not allow for individual nodes to be affected by changing processes in different ways. The approach of class 2, pursued in Grzegorczyk and Husmeier (2009), Lbre (2007) andis potentially over-flexible, as it does not provide any information sharing among the nodes. When an organism undergoes transitional changes, e.g. morphogenic transitions during embryogenesis, one would expect the majority of genes to be affected by these transitions in identical ways. However, there is no mechanism in the fully flexible model that incorporates this prior notion of commonality. In the present article, we explore a Bayesian clustering scheme akin to the weight sharing principle in neural computation (), by which we assign nodes to clusters that are characterized by common changepoints. We demonstrate that our scheme subsumes the aforementioned approaches as limiting cases, and that it automatically identifies the right trade-off between them in a data-driven manner.
METHOD
Review of time-dependent DBNsDBNs are flexible models for representing probabilistic relationships among interacting variables (nodes) X 1 ,...,X N via a directed graph G. The parent node set of node X n in G,  n =  n (G), is the set of all nodes from which an edge points to node X n in G. Consider a dataset D, where D n,t and D (n,t) are the t-th realizations X n (t) and  n (t) of X n and  n , respectively, and 1  t  m represents time. A DBN is based on a (first-order) Markov process, which is determined by the conditional probabilities P(X n (t) = D n,t | n (t  1) = D (n,t1) , n ). Common choices are a multinomial distribution, as used in Robinson and Hartemink (2009), or a linear Gaussian distribution, as in Grzegorczyk and Husmeier (2009), with corresponding (node-specific) parameter vectors  n. An inhomogeneous generalization of the standard firstorder homogeneous DBN was proposed (e.g. see) and is given by,k is the Kronecker delta, V is a matrix of latent variables V n (t), V n (t) = k indicates that the realization of node X n at time t, X n (t), has been generated by the k-th component of a mixture with K n components, and K = (K 1 ,...,K n ). Let P( |G,K) = N n=1(2010), the following integral can be solved analytically:which yields a closed-form expression for the marginal likelihood:The objective of Bayesian inference is to sample the network structure G, the latent variables V = (V 1 ,.
..,VIn Grzegorczyk and Husmeier (2009) and Lbre (2007), a truncated Poisson prior is chosen for P(K n ), and a multiple changepoint process prior for P(V n |K n ). The approach inis similar, except that the allocations of time points to components are not node-specific (i.e. K n and V n do not depend on n); see above (class 1 vs. 2).
Improved Gibbs sampling based on dynamic programmingTo sample from the posterior distribution, P(G,V,K|D), all previous studies () follow the same procedure: to sample the network structure G, they follow Madigan and York (1995) and apply MetropolisHastings (MH) structure Markov chain Monte Carlo (MCMC), based on single-edge operations; to sample the latent variables (V,K), they follow Green (1995) and apply RJMCMC, based on changepoint birth, death and reallocation moves. In the present study, we propose an improved scheme based on dynamic programming. The idea is to adapt the method proposed byin the context of Bayesian mixture models to inhomogeneous DBNs of the form defined in Equation (1).assumes that the changepoints occur at discrete time points, and he considers two priors for the changepoints. The first prior is based on a prior for the number of changepoints, and then a conditional prior on their positions. This corresponds exactly to P(K n ) and P(V n |K n ), as discussed above. The second prior is obtained from a point process on the positive and negative integers. The point process is specified by the probability mass function g(t)for the time between two successive points, for which a natural choice is the negative binomial distributionwhose form is defined by two hyperparameters, a and p. The choice of this prior immediately imposes a prior distribution on the latent variablesPage: 695 693699
Time-varying dynamic Bayesian networksV n without any conditioning on K n , P(V n |K n )  P(V n ); hence the terms K and K n in Equations (14) become obsolete. For the remainder of this section, we use the generic notatioto denote the latent variables induced by the changepoint prior. Depending on the form of the latter, we either haveVhave haveV = (V,K) orVor orV = V. Given a Bayesian mixture model for which the latent variables are of the form of one of the two changepoint processes discussed above, and the parameters can be integrated out in the likelihood, as in Equation (2),shows that the changepoints can be sampled from the proper posterior distribution exactly, with a dynamic programming scheme. The computational complexity is quadratic in the number of observations m., for all nodes X n , n = 1,...,N, new parent configurations { n } from) has been defined in Equation (3). Equation(6) entails a complete enumeration over all parent configurations, which is computationally expensive. In Grzegorczyk and Husmeier (2009) it was found that this sampling scheme is computationally inefficient when applied to inhomogeneous DBNs. We now demonstrate that this scheme is only inefficient when combined with the RJMCMC scheme for samplingVsampling samplingV, but that in combination with the dynamic programming scheme for exact sampling ofVof ofV from P(  V|G,D), an overall gain in computational efficiency can be achieved. We empirically corroborate this conjecture in Section 5.1. 2 For the specific class 2 model employed in this study () we provide the technical details of the traditional RJMCMC and the novel Gibbs sampling procedures in the Supplementary Material.
Information coupling between nodes based on Bayesian clusteringWe instantiate the model from Equation (4) by following Fearnhead (2006) and employing the point process prior for the changepoint locations defined in Equation (5), i.e. the terms K and K n in Equations (14) become obsolete. We extend the model by introducing a cluster function C(.) that allocates the nodes X 1 ,...,X n to c (1  c  N) non-empty clusters, each characterized by its own changepoint vector, where c is the number of non-empty node clusters induced by C. We assume for P(C) a uniform distribution on all functions C that give c (1  c  N) clusters. The key idea behind the model of Equation (7) is to encourage information sharing among nodes with respect to changepoint locations. Moreover, nodes that are in the same cluster i (1  i  c) share the same allocation vector V C i and will be 'penalized' only once. 3 Note that the novel model is a generalization that subsumes both class 1 and class 2 models as limiting cases. It corresponds to class 1 for c = 1 and to class 2 for c = N. Inference can follow a slightly extended Gibbs sampling procedure, where we iteratively sample the latent variables from P(The first two steps follow the procedure discussed in Section 2.2. For the third step, sampling from P(C|V C i ,D,G), we adopt an RJMCMC scheme () based on cluster birth (b), death (d) and re-clustering (r) moves. 4 In a cluster birth move we randomly select a node cluster i that contains at least 2 nodes, and we randomly choose a node contained in it. The move tries to re-cluster this node from the i-th cluster to a new cluster c+1. Denote by C the new cluster formation thus obtained. For the i-th cluster and for the new (c+1)-th cluster we propose new changepoint allocation vectors V C i and V C c+1 by sampling them from thewith the dynamic programming (DP) scheme proposed in, as discussed in Section 2.2. In a cluster death move we randomly select one of the clusters that contain only a single node, and we re-allocate this node to one of the other existing clusters, chosen randomly. The first cluster disappears and for cluster j, which absorbs the node, we propose a new changepoint allocation vector V C j from P(V C j |G,D,C ) with DP, where C denotes the proposed cluster formation. In a re-clustering move we randomly choose two clusters i and j (i = j) as follows. First, cluster i is randomly selected among those that contain at least 2 nodes. Next, cluster j is randomly selected among the remaining clusters. We then randomly chose one of the nodes from cluster i and re-allocate the selected node to cluster j. Denote by C the new cluster formation obtained. (Since cluster i contains at least 2 nodes, this does not affect c.) For both clusters i and j we propose new changepoint allocation vectors V C i and V C j from P(V C i |G,D,C ) and P(V C j |G,D,C ) with DP. The acceptance probabilities of these three RJMCMC moves are given by the product of the likelihood ratio (LR), the prior ratio (PR), the inverse proposal probability ratio or Hastings factor (HR) and the Jacobian (J) in the standard way (): A (b,d,r) = min{1,R (b,d,r) }, where R (b,d,r) = LRPRHRJ. Since this is a discrete problem, the Jacobian is J = 1, and for the chosen uniform prior on C, the prior ratio is PR = 1. For a cluster birth move (b), symbolically (C,V C )  (C ,V C ), we thus get: R (b) = LRHRwhere c  is the number of clusters induced by C with at least two nodes, c  is the number of nodes in the i-th cluster (that was selected), and c is the number of clusters induced by C that contain only a single node. In our extended model the DP scheme described in Section 2.2 can be employed to sample the j-th (1  j  c) allocation vector V C j , and we have:and the sum in Equation (9) is over all valid allocation vectors V C j for the variables in the j-th cluster of C. It follows from Equations (78) that all factors except for the (c+1)-th in the nominator and the i-th ones cancel out in the likelihood ratio:(
M.Grzegorczyk and D.HusmeierHence, R (b) = LRHR in Equation (8) reduces to:where the terms Q j (D,C,,C,G,V C j ) can be computed effectively with DP. The acceptance probabilities for death and re-clustering moves can be derived analogously as shown in the Supplementary Material.
DATA
Synthetic RAF-pathway dataThe RAF protein signalling transduction pathway, shown in, plays a pivotal role in the mammalian immune response and has hence been widely studied in the literature [e.g.. For our simulation study we followed Grzegorczyk and Husmeier (2009) and generated synthetic network data from a slightly modified version of the pathway, in which an extra feedback loop has been added to node 'PIP3': PIP3(t +1) = 1 2 PIP3(t)+ PIP3 (t +1). The realizations of the other nodes are linear combinations of the realizations of their parents at the preceding time points plus iid standard Normally distributed noise injections. Example for 'PIP2':, where the variables . (.) are iid standard Gaussian distributed, and the coefficient c. can be used to vary the signal-to-noise ratio (SNR). The regression coefficients are sampled from continuous uniform distributions on the intervalwith a random sign. We focus on the medium autocorrelation strength  = 0.25, the SNRs 3 and 10, and we generate time series of length m = 21. Unlikewe do not only focus on class 2 data, but distinguish four different scenarios: (i) homogeneous DBN data with regression coefficients that are constant in time, e.g.  PIP3 (t) = const.; (ii) inhomogeneous class 1 DBN data where all regression coefficients of the domain are re-sampled after t = 11; (iii) inhomogeneous class 2 DBN data with each node having one or two node-specific changepoints, where the corresponding regression coefficients are re-sampled; (iv) inhomogeneous regularized class 2 data generated from a DBN where the coefficients of five nodes are re-sampled after t = 11, and the coefficients of the other 5 nodes are re-sampled twice independently, after t = 8 and after t = 13. We also consider scenario (v): inhomogeneous regularized class 2 data without any autocorrelation:  = 1. For SNR=3 and SNR=10 we generated 10 independent data instantiations for each scenario (i)(v).
Gene expression time series from Arabidopsis thalianaThe Arabidopsis data stem from a study related to circadian regulation in plants. To this end, A.thaliana seedlings grown under four different artificially controlled light/dark cycles were transferred to constant light and harvested at 1213 time points in 2/4-hour intervals. From these seedlings, RNA was extracted and assayed on Affymetrix GeneChip oligonucleotide arrays. Aswe focus on N = 9 genes, LHY, TOC1, CCA1, ELF4, ELF3, GI, PRR9, PRR5 and PRR3, which from previous studies are known to be involved in circadian regulation (). Details about the data and their preprocessing are available from Grzegorczyk and Husmeier (2009).
Synthetically generated network in Saccharomyces cerevisiae (yeast)
RESULTS
Convergence diagnostics on gene expression time series from A.thalianaThe objective of the first study was to assess the improvement in convergence and mixing achieved with the dynamic programming scheme of Section 2.from previous studies are known to be involved in circadian regulation (). Our model and simulation setup matched the one described in. We compared the standard MCMC scheme applied in previous work, MH/RJMCMC (), which is based on RJMCMC () and structure MCMC (), with the Gibbs sampling/dynamic programming scheme discussed in Section 2.2. For the latter, we compared three different subschemes, which differ with respect to the prior distribution on the changepoints. The first subscheme imposes a Poisson prior with truncation threshold K n  10 on the number of components, P(K n ), and the same even-numbered order statistics prior as applied in) andon the segmentations, P(V n |K n ). The second subscheme is identical, except that the truncation threshold has been lowered to K n  5. The third subscheme follows Fearnhead (2006) and uses the prior imposed by the point process prior of Equation (5) with hyperparameters p = 0.05 and a = 2. We refer to these four schemes as MH/RJMCMC, Gibbs(K max = 10), Gibbs(K max = 5) and Gibbs-NBIN, respectively. To assess the degree of convergence, we repeated the MCMC simulations from five different initializations and computed the PSRFs for all potential edges, as described in the Supplementary Material. Recall that PSRF = 1 indicates perfect convergence, and PSRF1.1 is usually taken as an indication of sufficient convergence. Ideally, we would like to plot the PSRF values against the MCMC iteration number. However, due to different computational costs of the individual steps of the MCMC simulationsa Gibbs step based on dynamic programming is substantially more expensive than an MH/RJMCMC stepwe plotted the PSRF scores against the simulation time, measured in terms of conventional MH/RJMCMC steps. 5 The results are shown in. The proposed Gibbs sampling scheme based on dynamic programming significantly outperforms the conventional MH/RJMCMC scheme. When comparing the different dynamic programming schemes, Gibbs-NBIN performs slightly better than Gibbs(K max = 10) and Gibbs(K max = 5), in agreement with the Page: 698 693699shows the mean area under the precision-recall curves (AUC) in dependence on the hyperparameter p of the negative binomial point process prior of Equation (5). For the RAF pathway (bottom right panel) we implemented 5 scenarios of inhomogeneity as explained in Section 5.2. For each scenario there is a panel for SNR=3 and SNR=10; 'noAC' stands for 'no autocorrelation'. The following models were applied to the data, each representing a particular class: (i) homogeneous model: the standard DBN model based on the BGe score, (ii) the class 1 model was taken from, (iii) the class 2 model was taken fromand (iv) the regularized class 2 model was generated from the class 2 model inas explained in Section 3.1. The mean AUC scores were computed from 10 independent data instantiations. the autocorrelation of node PIP3 to zero ( = 1, no AC), noticeably increases the mean AUC values. In summary, this study shows that the proposed regularized class 2 model, which implements the method of Section 2.3, is always among the best-scoring models. It shows more robustness than the competing schemes both with respect to a variation of the type of data, and a variation of the prior knowledge (inherent in Equation (5) via p).
Time-varying dynamic Bayesian networks
M.Grzegorczyk and D.Husmeier
Synthetic biology in S.cerevisiaeIn the final application we compare the proposed model with other state-of-the art techniques on a topical dataset from synthetic biology. We used a synthetically generated network of five genes in S.cerevisiae (yeast), depicted in, which was used into evaluate two state-of-the-art network reconstruction methods: BANJO, a conventional DBN, trained with simulated annealing; and TSNI, an approach based on ordinary differential equations. Both methods, which are described in more detail in, were applied to gene expression time series obtained from synthetically designed yeast cells grown with different carbon sources: galactose ('switch on') or glucose ('switch off'). BANJO and TSNI were then applied to infer a network, from which, by comparison with the known gold standard, the precision (proportion of correctly predicted interactions out of the total number of predicted interactions) and recall (percentage of true interactions that have been correctly identified) scores were determined. In our study, we used the data described in Section 3.3, applied the proposed regularized class 2 model as described in Sections 2.3, and sampled networks from the posterior distribution with the Gibbs sampling scheme described in Section 2.2. This gives us an ordering of interactions, ranked by their marginal posterior probability, and by plotting precision against recall scores for different thresholds, we obtain the precision-recall (PR) curves () shown in. Larger areas under the PR curve are indicative of a better reconstruction accuracy; hence in agreement withwe find that the 'switch on' data are more informative than their 'switch off' counterpart. The scores for BANJO and TSNI, which we took from, lie clearly and consistently below the 'switch on' PR curve, for different choices of the changepoint process priordefined by p in Equation (5). This suggests that the proposed method achieves a genuine and significant improvement over state-of-the-art schemes reported in the recent systems biology literature.
Page: 699 693699
Time-varying dynamic Bayesian networks
CONCLUSIONWe have proposed two improvements for time-varying DBNs: a Gibbs sampling (GS) scheme based on dynamic programming (DP) as an alternative to RJMCMC, and information coupling between nodes based on Bayesian clustering. The evaluation on a real gene expression dataset from A.thaliana suggests that GS-DP shows faster mixing and convergence than MH/RJMCMC. A comparative evaluation on synthetic data demonstrates that the new model based on information coupling between nodes compares favourably with earlier models that either employ network-wide (class 1) or nodespecific (class 2) changepoints. On gene expression time series from a recent study of synthetic biology in S.cerevisiae the proposed model has outperformed two state-of-the-art network reconstruction methods. These findings suggest that the proposed method makes important contributions both to inference and performance of network reconstruction methods, and hence adds a valuable new tool to the kit of computational systems biology. In our future work we will investigate different choices for the prior on node cluster formations, introduced in Section 2.3, exploring methods from Bayesian non-parametrics based on Dirichlet process priors.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Changepoints in Robinson and Hartemink (2009) apply, in the first instance, to the whole network (class 1), with changepoints that render parent configurations invariant removed for the respective nodes. While this imbues the model with aspects of a class 2 approach, it suffers from the fact that changepoints are inextricably associated with changes in the presence/absence status of interactions, rather than changes in the interaction strengths, resulting in a loss of model flexibility.
For the study in Section 5.1, we used the commonly applied fan-in restriction of 3. When relaxing the fan-in restriction, the computational costs related to Equation (6) increase. However, a set of effective heuristic techniques for approximate computation at controlled computational complexity are available, as discussed in Friedman and Koller (2003).
While systems biology aims to develop a formal understanding of biological processes via the development of quantitative mathematical models, synthetic biology aims to use such models to design unique biological circuits (synthetic networks) in the cell able to perform specific tasks. Conversely, data from synthetic biology can be utilized to assess the performance of models from systems biology. We used a synthetically generated network of five genes in S.cerevisiae (yeast), devised in Cantone et al. (2009) and depicted in Figure 3, which was obtained from synthetically designed yeast cells grown with different carbon sources: galactose ('switch on') or glucose ('switch off'). We took the data from Cantone et al. (2009), which were obtained with quantitative RT-PCR in intervals of 20 min up to 5 h for the first, and in intervals of 10 min up to 3 h for the second condition. In our study, we standardized the data via a log and a z-score transformation. 4 SIMULATION DETAILS The two improvements proposed in Section 2 can be applied to any of the inhomogeneous DBNs recently proposed in the literature (Grzegorczyk and Husmeier, 2009; Lbre, 2007; Lbre et al., 2010; Robinson and Hartemink, 2009). In our empirical simulation study we use the model presented in Grzegorczyk et al. (2010) as class 1 representant. The class 2 model representant is taken from Grzegorczyk and Husmeier (2009). The novel model can be thought of as a regularized consensus of both models: It is effectively a class 1 model if it infers only one cluster, and it becomes a class 2 model if it infers N clusters such that each node has its own nodespecific changepoints. In our simulation study we also include a standard homogeneous dynamic Bayesian network model based on the standard BGe score (Geiger and Heckerman, 1994). As in earlier studies (Grzegorczyk and Husmeier, 2009; Grzegorczyk et al., 2010) we employ a uniform graph prior subject to a maximum fan-in of 3, and we chose the prior parameter distributions in Equations (1) and (2) maximally uninformative subject to the regularity conditions in Geiger and Heckerman (1994). We demonstrate in Section 5.1 that inference based on Gibbs sampling/dynamic programming substantially improves convergence and mixing. Thus, in the cross-method comparison (see Section 5.2) the inhomogeneous DBN models have been inferred by Gibbs sampling/dynamic programming rather than employing the less effective RJMCMC sampling schemes. As is standard, we discarded a burn-in phase, and tested for convergence (PSRF  1.1) based on potential scale reduction factors (PSRF), see Gelman and Rubin (1992), resulting in 200 Gibbs steps per dataset and method.
1100k MH/RJMCMC (5500 Gibbs-NBIN) steps take 45 min with our MATLAB code on a SunFire X4100M2 machine. findings in Fearnhead (2006). For the reconstructed network topology and the inferred changepoint locations, which in the absence of a true gold standard cannot be evaluated properly, we refer to our Supplementary Material. 5.2 Comparative evaluation on simulated data For our simulation study we employ the synthetically generated RAF-pathway data from Section 3.1 to cross-compare the network reconstruction accuracy of the proposed regularized class 2 model with three other models: a standard homogeneous Bayesian network model, a class 1 model with changepoints that are common to all nodes (Grzegorczyk et al., 2010), and a class 2 model with nodespecific changepoints (Grzegorczyk and Husmeier, 2009). In our study we evaluated the network reconstruction accuracy with the area under the precision-recall curve (AUC) (Davis and Goadrich, 2006); see Section 5.3 for more details. This is standard in systems biology, with larger scores indicating a better performance. Figure 2 summarizes the empirical results of our simulation study. (1) Homogeneous data: Except for the highest setting of the hyperparameter p, the three inhomogeneous DBNs never perform worse than the homogeneous model, while on the other hand for inhomogeneous data, the homogeneous model is inappropriate and performs substantially worse. (2) class 1 data: The class 1 model and the proposed regularized class 2 model perform equally well. Both outperform the class 2 model, except for high values of p. 6 (3) class 2 data: The class 1 model cannot accommodate the node-specific changepoints and is outperformed by the proposed regularized class 2 model (the 'NEW' model). Interestingly, the latter also shows more stability than the class 2 model with respect to a variation of the hyperparameter p, indicating increased robustness as a consequence of the node clustering. (4) Regularized class 2 data: The results are comparable to those for the class 2 data. The class 1 model is consistently inferior to the class 2 model, and the class 2 model is, once again, substantially more susceptible to a variation of p. The mean AUC values areoveralllower than for the previous case, the class 2 data. This seems to be a consequence of spurious interactions resulting from chance correlations. Setting 6 Recall that a high value of the hyperparameter p implies a low prior penalty for changepoints.
