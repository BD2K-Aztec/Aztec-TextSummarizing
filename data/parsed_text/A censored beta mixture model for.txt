Motivation: The proportion of non-differentially expressed genes (π 0) is an important quantity in microarray data analysis. Although many statistical methods have been proposed for its estimation, it is still necessary to develop more efficient methods. Methods: Our approach for improving π 0 estimation is to modify an existing simple method by introducing artificial censoring to P-values. In a comprehensive simulation study and the applications to experimental datasets, we compare our method with eight existing estimation methods. Results: The simulation study confirms that our method can clearly improve the estimation performance. Compared with the existing methods, our method can generally provide a relatively accurate estimate with relatively small variance. Using experimental microarray datasets, we also demonstrate that our method can generally provide satisfactory estimates in practice.
INTRODUCTIONMicroarray technology is a powerful tool for studying complex diseases () and for assessing the effects of drugs () at the molecular level. It is an experimental method by which thousands of genes can be printed on a small chip and their expression can be measured simultaneously (). It can be used to detect changes in gene expression between normal and abnormal cells, which enables scientists to detect novel disease-related genes (). Many statistical methods have been developed for this purpose (). Although other advanced genomics technologies, such as RNA sequencing (), have been developed, microarrays have been continuously used for broad biomedical studies (). Furthermore, since the structures of data from different genomics technologies are basically * To whom correspondence should be addressed. similar, methods for analyzing microarray data can also be useful for analyzing other similar genomics data. Performing statistical tests for a large number of genes raises the need for an adjustment for multiple hypothesis testing (MHT). A widely used method to address this issue is the false discovery rate (FDR;) that evaluates the proportion of false positives among claimed positives. FDR control is less stringent than the traditional family-wise error rate (FWER) control such as the Bonferroni correction, and provides more power for discovering differentially expressed genes. However, estimating FDR involves the estimation of  0 , the proportion of non-differentially expressed (null) genes [(1 0 ) corresponds to the proportion of differentially expressed genes]. A reliable estimate of  0 is also of great importance to the sample size calculation for microarray experiment design (). A variety of methods have been proposed for estimating  0 .proposed qvalue. This method uses the ordered P-values and a cubic spline, and estimates  0 as the value of the fitted spline at a value close to 1.suggested BUM, a 'beta-uniform' mixture model with the estimate of  0 being the value of the fitted model at 1. convest, a method introduced by, utilizes a non-parametric convex decreasing density estimation method and gives the value of the density at 1 as an estimate of  0. A histogram-based method has also been proposed (). The above methods usually provide conservative estimates of  0 ; in other words, they are expected to give positively biased  0 estimates. This has been considered an advantage, since it protects against overestimating the number of differentially expressed genes. Many other methods have also been proposed for estimating  0 .proposed a non-parametric moment-based method coupled with sample-splitting to achieve the identifiability and obtained a closed-form formula for  0 .presented the successive exclusion procedure (SEP), which successively excludes genes until the remaining u-values (transformed P-values) are sufficiently close to a uniform distribution U. SEP estimates  0 by J/m, where J is the estimated number of null genes, and m is the total number of genes.estimated the marginal density of P-values using a Bernstein polynomial density estimation, and gave a closed-form expression for their  0 estimator.obtained an estimate of  0 through Bayesian inference from a mixture model, which requires the distribution of P-values from non-null genes to be stochastically smaller than that from null genes. In addition to the above methods, there are still many other proposed methodsPage: 641 640646
Proportion of non-differentially expressed genesfor estimating  0 (). Furthermore,  0 can also be estimated through a normal mixture model based on the z-scores obtained from P-values (). In this study, to improve  0 estimation, we propose a simple method, which is a modification of BUM. The novelty of our method is the introduction of artificial censoring to P-values so that an improved estimation can be achieved. Our motivation is based on the observation that a well-fitted BUM curve for the empirical P-value distribution may not be optimized for estimating  0. In the following sections, we first introduce the statistical background and our method; then, we present the evaluation and comparison results from our simulation and application studies. Finally, we give some brief discussion to conclude our study.
METHODS
Detection of differential expressionIn a typical microarray experiment, the gene expression in two groups of cells can be compared. On a microarray chip, a large number of genes can be monitored simultaneously, which provides researchers with measurement for each gene in each group. For example, to assess genes' involvement in tumor growth, the expression of tens of thousands of genes can be measured in normal and cancerous cells. Depending on the number of microarray chips available, multiple measurements for the expression of each gene are obtained. For each gene, let  1 and  2 be the true mean intensities, in groups 1 and 2, respectively. To determine whether the gene is differentially expressed, the null and alternative hypotheses are:A commonly used test statistic is the Student's t-test (assuming equal variances). A positive is claimed when H 0 is rejected in favor of H a , and a negative when H 0 is not rejected. A positive means that the gene is declared differentially expressed; a negative means that the gene is declared nondifferentially expressed. If we knew the true state of each gene (i.e. whether it is truly differentially expressed or not), then the results of testing m genes simultaneously could be classified into four categories (each denoted by the random variable in parentheses): true positives (S), false positives (V ), true negatives (U) and false negatives (T ).gives an illustration. Ideally, one would like to minimize V and T , and maximize S and U. The probability Pr V > 0 is called the FWER. In MHT, strong control is defined as maintaining the FWER below a specified level . The traditional strong-control method is the Bonferroni procedure; that is, rejecting each H 0 corresponding to a P-value less than /m. However, in microarray studies, /m is typically so small that it is unlikely that many null hypotheses will be rejected. A widely used alternative is to control the FDR, the expected proportion of false positives (V ) among the claimed positives (R = V +S)():Other versions of FDR have also been proposed:considers the estimation of four other FDR versions. In general, controlling FDR provides higher statistical power for discovering differentially expressed genes. Let m 0 = U +V denote the total number of true null hypotheses, and  0 = m 0 /m denote the proportion of true null hypotheses (i.e. the proportion of non-differentially expressed genes; so the proportion of differentially expressed genes is 1 0 ). Suppose that a researcher rejects H 0 for each gene with a P-value less than a prespecified level . To estimate the corresponding FDR in this situation, Storey (2002) proposed FDR() =wher  0 is an estimate of  0 , and r() is the observed number of positives. From this equation, it is clear that the accuracy of an FDR estimate depends on the estimation of  0 , which is the parameter of interest in this study.
The beta-uniform mixture modelPoundswher  andand and are the MLE estimates.
Our approachTo represent the marginal distribution of P-values, BUM uses a mixture of the uniform distribution U(also Beta(1,1)) and a Beta distribution Beta(,1) with 0 <<1. However, BUM is too simplistic to achieve a robust performance in practice. Let p ={p 1 ,p 2 ,.
..,p m } be the observed P-values.Under the independence assumption, the log-likelihood is given byBUM estimates the fitted model curve by maximizing this log-likelihood. As p  0, f (p) . Clearly, the smaller a p i is, the larger its contribution will be to the log-likelihood. Therefore, to optimize the fitted curve, BUM places more weight on smaller P-values. However,  0 is our focus and is estimated byfby byf (1), which depends more on the P-values close to 1. To solve this problem, we propose the following censored beta mixture model.
A censored beta mixture modelTo improve BUM, we artificially censor the P-values that are less than a cut-off point . These P-values are considered 'indistinguishable'. In other words, even though the actual P-values less than  are available, we do not use those values; our model only uses the number of such P-values. (We do not consider P-values<  as missing data). In this way, we aim to reduce the effect of very small P-values. Then, we have the mixture model:is a left-censored uniform distribution Uand,is a left-censored Beta(,1) distribution (0 <  < 1).), and a censored Beta(,1). Therefore, we can use the ExpectationMaximization (EM) algorithm () to estimate the parameters  and . Following, we augment the data by introducing the latent indicator variables z i , 1  i  m (where m is the total number of genes) defined as: z i = 0 if p i belongs to the component g 1 , 1 if p i belongs to the component g 2 .
A.Markitsis and Y.LaiThe log-likelihood of our model given the 'complete' data {p,z}, is:To maximize the log-likelihood with respect to  and , given the 'complete' data, we take the partial derivative of the above equation with respect to  and set it equal to zero, and then do the same for . Solving these two equations, we obtain the following maximum likelihood estimates of  and  to be used in the M-step of the EM algorithm:In the E-step of the EM algorithm, we need to update the expected values of the {z i }. Given the current estimates of  and , we can compute). Since each z i is an indicator variable, z i is the conditional probability (at each iteration of the algorithm) that p i belongs to component g 2. Hence, we have the following formulas:@BULLET For each censored P-value, that is, if 0  p i <,@BULLET For each non-censored P-value, that is, if   p i  1,To start the EM algorithm, we select an initial value for ; in general, we can use  (0) = 0.5, unless we have some empirical estimate of  0 to use instead. Then, we initialize {z i } by setting zi }, we can obtain  (1) and  (1) , the estimates of  and  after the first iteration. The convergence of EM algorithm is declared whenis the estimate of  at the end of the k-th iteration, and  is a prespecified threshold ( = 110 6 in this study). When the EM algorithm converges, letlet let andand and be the estimates of  and , respectively. Then, the estimate of  0 is given by:
Confidence intervalSince the above EM algorithm does not provide us with any closed formulas of estimates, it is difficult to derive the theoretical confidence interval (CI) for the estimated  0. Therefore, we use the bootstrap procedure () to obtain a CI for  0 (we set B = 500 for both application studies):(1) Select a random sample of m P-values from {p 1 ,p 2 ,.
..,p m } with replacement and equal probabilities;(2) Apply the EM algorithm to the sample generated in Step 1 and obtain a resampling estimate of  0 ;(3) Repeat Steps 1 and 2 B times to obtain the resampling distribution ofof of 0 ;(4) For a 100(1)% CI for  0 , find the (/2)-th and (1/2)-th quantiles of the resampling distribution.
RESULTS
Simulation studies
Simulation configurationWe simulate gene expression data to evaluate the performance of our method. We also select several existing methods for a comparison study. BUM () has to be included since it is the foundation of our method. Based on the consideration of the popularity and research history of the statistical methods for estimating  0 , the following methods are selected (notation in parentheses):Given a value of  0 (0.1,0.2,...,0.9), a corresponding number of blocks are set to consist entirely of differentially expressed genes, with the remaining blocks consisting entirely of non-differentially expressed genes. For example, to generate a dataset with  0 = 0.7 for the {b = 100,g b = 50} configuration, we simulate 30 blocks with differentially expressed genes, and 70 blocks with non-differentially expressed genes. For each block, we use the covariance matrix = (1)I+E of size g b g b , where I is the identity matrix and E is a matrix of ones. (Note that is also the correlation matrix since all genes have unit variances.) Then, for each configuration mentioned above, we perform the following:(1) Simulate a gene expression dataset with 5000 genes.(a) For a block of non-differentially expressed genes, generate observations from a multivariate normal distribution N(0,,) for both sample groups.(b) For a block of differentially expressed genes, generate observations from a multivariate normal distribution N(for one sample group. Then, generate observations from a multivariate normal distribution N(,) for the other group (where  is a random vector, with elements coming from a uniform distribution U).(2) Apply the two-sample Student's t-test to the profile of each gene and obtain 5000 theoretical P-values.(3) Use different methods to estimate  0 .
Criteria for evaluation and comparisonWe repeat the above steps B = 100 times for different values of  0 (0.1,0.2,...,0.9). For each value of  0 and each method, we compute the bias, standard deviation (SD) and root mean squared error (RMSE) as follows:wher  0 i is the i-th estimate of  0. These criteria are used to evaluate the estimation performance of different methods and the impact of different .
Comparison of different methodsIn all the results, the patterns in RMSE, bias and SD are very similar for all cases sharing the same sample size and correlation strength. In other words, the block size g b in our configuration does not substantially affect the patterns in RMSE, bias and SD. In the Supplementary Materials, we present the simulation results based on 200 blocks with 25 genes in each block and different correlation values (). In the following, we discuss the simulation results based on the simple independence structure ( = 0), which is representative of the other results. The simulation results are presented for samples sizes 6+6, Page: 644 640646
A.Markitsis and Y.Lai18+18 and 30+30. [In order to show a clear comparison among different methods, we use a log-scale for the y-axis in RMSE and SD graphs (with the option 'log = " y " ' in the R-function 'plot'), and the cube root of Bias is actually used as the y-axis in the Bias graphs. All these comparison plots are given in the Supplementary Materials. However, in the following, we only give the RMSE-based comparison plots due to the page limit.] When n 1 = n 2 = 6 (), all the  0 estimation methods show an overall decreasing pattern of RMSE as the value of  0 increases. BUM gives the lowest RMSE when  0 > 0.4; but its RMSE is among the worst when  0 < 0.3, where RDM gives the lowest RMSE. Our method always gives a competitive low RMSE when  0 > 0.1. When the sample size increases to n 1 = n 2 = 18 (), BUM shows an unstable performance: it gives a relatively high RMSE for all the values of  0 , except at  0 = 0.2 and 0.9. The benefit of using our method is more apparent: its RMSE is lower than those of all the other methods, for all the values of  0 except for  0 = 0.2 (where BUM's RMSE is the lowest). For n 1 = n 2 = 30 (), BUM's RMSE displays a concave parabola pattern, and is always relatively high. Our method has the lowest RMSE for all  0. The figures in the Supplementary Materials also confirm a satisfactory performance in Bias and SD from our method. In general, most methods' bias decreases as the sample sizes and the value of  0 increase. However, BUM quickly becomes the most negatively biased (which explains the observed large RMSE of BUM although the SD of BUM is among the smallest). A strongly negative bias leads to an undesirable overestimation of the number of truly differentially expressed genes. On the other hand, our method's bias becomes negligible as the sample sizes increase. Most methods' SD increases as the value of  0 increases and decreases as the sample sizes increase. In general, when the simulation results based on different dependent structure (independent, weakly/strongly dependent) are compared (Supplementary Materials), the higher the correlation, the higher becomes the SD. (The bias, on the other hand, remains mostly unaffected by the increase in correlation.) However, our results show that the increase in SD induced by positive correlation among test statistics does not render the existing  0 estimation methods inappropriate.
Choice of The above reported simulation configuration can also be used to understand the effect of . We simulate data with different sample sizes 6+6, 18+18 and 30+30 and compare the performance of our model for  in the set {0.01,0.03,0.05,...,0.25}. The figures in the Supplementary Materials shows that no single value of  can be identified to minimize RMSE in a wide range of  0. Furthermore, the RMSE patterns can change significantly when the sample sizes are changed. It is clear that a relatively large  (e.g.  = 0.25) is not a good choice. However, a relatively small  (e.g.  = 0.01) is also not an appropriate choice. In our simulation study, we have observed that  = 0.05 is always a reasonable choice to achieve an overall satisfactory performance.
Applications to experimental dataWe first consider the following two published experimental microarray datasets for our applications. The first dataset containscalculated based on three experimental datasets: the renal data (upper panel), the T-cell data (middle panel) and the smoke data (lower panel). In the histograms (left panel), the gray curves represent the fitted censored beta mixture models (the dashed parts are artificially censored). The zoomed-in histograms (middle panel) are also shown to compare the estimate of  0 from different methods. The gray solid, dashed and dotted lines represent the estimates from our method, BUM and convest, respectively. In the boxplots (right panel), N = our method, B = BUM and C = convest. The numbers in gray color are the estimates of  0 based on the original data.Therefore, in practice, we suggest to check the histogram shape before applying any statistical methods for estimating  0. If the histogram shape is roughly decreasing, then we expect satisfactory estimation performance from our method (and BUM in certain situations). If the histogram shape is not regular, then we may consider some non-parametric method like convest or the momentbased method ().
DISCUSSIONMicroarrays have been widely used in biological and medical studies. An accurate estimate of the proportion of differentially expressed genes is important in false positive control and experiment design. Therefore, the improvement of existing estimation methods still remains important. Our proposed method for estimating  0 provides an effective solution. Although it is arbitrary, the choice of  = 0.05 provides an overall satisfactory performance. In our simulation study, the advantage of using our method is clear in the cases of moderate and large sample size (18+18 and 30+30). In these cases, our method outperforms (w.r.t. RMSE) the other methods considered in this study. In the case of small sample, BUM has a satisfactory performance. Our method may be improved if an efficient method for the automatic selection of  can be developed. This issue will be pursued in our future research. Although none of the  0 estimation methods mentioned above considers the effect of gene networks and interactions, dependence among genes is still a difficult issue in microarray data analysis (). However, as investigated by, methods that are based on the independence assumption perform quite well in general situations of weak positive dependence, and a positive dependency structure is common in many situations. A satisfactory performance under weak positive dependence has also been confirmed in our simulation studies.
The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
283 gene expression profiles from kidney biopsies of 19 kidney transplant subjects with cyclosporine-based immuno-suppression and 22 kidney transplant subjects with sirolimus-based immunosuppression. The second dataset consists of 12 488 gene expression profiles from pancreatic T regulatory (three subjects) and T effector cells (five subjects). Both datasets are publicly available in the Gene Expression Omnibus (GEO) database (Barrett et al., 2007) with accession numbers GSE1743 (Flechner et al., 2004) for the first (renal) dataset and GSE1419 (Chen et al., 2005) for the second (T cell) dataset. Theoretical P-values based on the corresponding t-distributions are calculated for each dataset (two-sample Student's t-test is used for detecting differential expression). The true value of  0 is unknown in the applications. Therefore, to compare different methods in each application, we obtain B = 500 bootstrap estimates of  0 (see Section 2.3.3 for details) and construct a boxplot for the estimate from each method. Such a boxplot is useful to understand general CIs for an estimate. Based on our simulation study, convest has consistently showed a relatively low RMSE. BUM should be considered since it is the foundation of our method. Therefore, for simplicity, we use boxplots to compare our method with BUM and convest. (The exclusion of other methods does not change our conclusion.) Figure 3 shows the P-value histograms and the estimates from these three different methods. For both datasets, the P-value distribution curves fitted by our method are close to the corresponding P-value histograms. Theoretically,  0 cannot be higher than the marginal P-value distribution. This has been briefly discussed in one of our previous publications (Lai, 2007). For the renal dataset, our method gives an estimate of  0 0.256 with a relatively tight CI (95% CI: 0.2520.261). convest gives a higher estimate 0.278 with a wider CI (95% CI: 0.2630.293), whereas BUM gives the highest estimate 0.321 although a slightly tighter CI (95% CI: 0.3180.325). Notice that only the estimate from our method is under the whole P-value histogram. For the T-cell dataset, our method gives an estimate of  0 0.605 with relatively tight CI (95% CI: 0.5860.626), whereas BUM gives a slightly lower estimate 0.598 and slightly tighter CI (95% CI: 0.5830.616). Both estimates are under the whole P-value histogram. However, convest still gives a higher estimate 0.638 and wider CI (95% CI: 0.6090.671). We also use another experimental dataset to illustrate that our method (also BUM) does not always yield satisfactory estimation results. The third application is based on a dataset with 22 283 gene expression profiles from small airway tissues (five non-smokers versus six smokers). This dataset is also publicly available in GEO with accession number GSE3320 (Harvey et al., 2007). The estimation results are also given in Figure 3. A clear 'bumped' shape can be observed in the P-value range [0.15, 0.35], which causes the problematic estimation results from our method and BUM (these beta distribution based models do not allow any 'bumped' shapes). Our fitted model curve is not close to the P-value histogram. Although the CI from our method (95% CI: 0.8990.921) and BUM (95% CI: 0.8970.935) are clearly tighter (the one from our method is the tightest) than that from convest (95% CI: 0.8500.902), both estimates from our method (0.909) and BUM (0.907) are clearly higher than the right end portion of P-value histogram. convest provides a more reasonable estimate 0.878 for this application, although the difference among the estimates from different methods is quite small.
