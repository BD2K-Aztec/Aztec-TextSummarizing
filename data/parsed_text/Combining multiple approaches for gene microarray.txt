Motivation: The microarray report measures the expressions of tens of thousands of genes, producing a feature vector that is high in dimensionality and that contains much irrelevant information. This dimensionality degrades classification performance. Moreover, datasets typically contain few samples for training, leading to the 'curse of dimensionality' problem. It is essential, therefore, to find good methods for reducing the size of the feature set. Results: In this article, we propose a method for gene microarray classification that combines different feature reduction approaches for improving classification performance. Using a support vector machine (SVM) as our classifier, we examine an SVM trained using a set of selected genes; an SVM trained using the feature set obtained by Neighborhood Preserving Embedding feature transform; a set of SVMs trained using a set of orthogonal wavelet coefficients of different wavelet mothers; a set of SVMs trained using texture descriptors extracted from the microarray, considering it as an image; and an ensemble that combines the best feature extraction methods listed above. The positive results reported offer confirmation that combining different features extraction methods greatly enhances system performance. The experiments were performed using several different datasets, and our results [expressed as both accuracy and area under the receiver operating characteristic (ROC) curve] show the goodness of the proposed approach with respect to the state of the art. Availability: The MATHLAB code of the proposed approach is publicly available at bias.
INTRODUCTIONDNA microarray technology has proven to be an important breakthrough in molecular biology. This rapidly maturing technology is providing scientists with a means of monitoring the expression of genes on a genomic scale (). One important application area is disease prognostication (). Benefits include the potential for identifying individual genes responsible for disease () and for providing scientists with a more accurate means of diagnosis * To whom correspondence should be addressed. and prognosis (). Largescale profiling of gene expression can reveal, for example, normal versus malignant cells and the genetic and cellular changes in the progression of tumor metastasis (). The benefits offered by simultaneously monitoring tens of thousands of genes, however, depend on developing tools capable of handling not only the sheer size of this data but also the small number of samples usually available for analysis. Machine learning systems are well suited for this problem, but they must be designed to handle high levels of noise, as only a small minority of genes is typically relevant for any given problem. The small sample size compared to the large number of features means that these systems must also contend with the dreaded 'curse of dimensionality' (). It would be very beneficial, therefore, if good methods for identifying these small sets of relevant genes could be developed. In the literature, gene selection methods have been organized into three categories: filter, wrapper and embedded methods (). Filter methods reveal dependencies without using classifiers and are based on statistical methods of ranking genes, e.g. t-statistics (), class separability () and Fisher's criterion (). Wrapper and embedded methods consider the mutual information among genes as well as its relevance (). Example classifiers used in wrapper methods include Bayesian classifier (), K-nearest neighbor () and support vector machines (SVMs) (). Wrapper methods are much slower than filter methods because they search for optimal combinations of features/genes, but filter methods may not select the most optimal set of features. Examples of embedded methods include one-norm SVM (), logistic regression (), sparse logistic regression () and methods based on regularization (). An interesting embedded method is that developed by. They devised a Genetic Algorithm with Fisher's Linear Discriminant Analysis (LDA) as the fitness function that performed well across a number of databases using a small number of selected genes. Most of these filter, wrapper and embedded methods are comparable in accuracy (). Several recent advances include reducing the sample set (), using classifier ensembles (), rather than single classifiers and using hybrid or multiple sets of different type of
L.Nanni et al.feature selection and transformation methods (). Chen and Lin (2011) have improved classifier performance by extracting significant samples that are located only on support vectors.improve performance using decision forest for classification of gene expression data, anduse rotation forests for robust and improved classification accuracy.have developed an ensemble that combines both filter and wrapper methods: a ranking method performs a fast reduction in dimensionality and a wrapper method refines the search. Their method has demonstrated comparable performance with wrapper methods while providing significant reduction in the computational burden. In this article, we propose to classify DNA microarray data using an ensemble of SVM classifiers, with each SVM trained on a different set of features. SVM is selected because it is considered to be one of the most powerful classifiers in microarray classification of cancers () and in several other bioinformatic problems (). Even though SVM is a strong learner and thus not typically suitable for ensembles, it actually performs well in ensembles if coupled with the random subspace technique (). In our experiments, we specifically investigate approaches: (i) that compare standard feature selection methods, where only a subset of the whole gene set is retained and then used to train an SVM; (ii) that compare several feature transform methods, where the dimension of the feature vector is reduced and then used to train an SVM; (iii) that train a set of SVMs using a set of orthogonal wavelet coefficients of different wavelet mothers-these sets of coefficients are selected via Sequential Forward Floating Selection (SFFS) using the leaveone-dataset-out validation protocol, such that when a given dataset is classified, the sets of coefficients are selected by SFFS using the others datasets as validation set; and (iv) that consider the microarray as an image, where the texture descriptors are extracted from the image and used to train an SVM. Experiments are carried out on several datasets, and experimental results show that the proposed method performs well when considering both accuracy and the area under the ROC curve (AUC) as the performance indicators.
METHODSIn this section, we briefly describe the feature selection, feature transform and classification and fusion methods, including the tree wavelet and texture descriptors used in our approach.
Feature selectionThe feature selection methods we explore are the following:In most cases, the code for the above methods was taken from the MATLAB Feature Selection Package available at http://featureselection.asu.edu/ In addition to the above listed feature selection methods, we also examine: @BULLET FFacsa2 1 (): a forward feature selection algorithm that is based on the aggregation of classifiers generated by a single attribute; @BULLET SVMrfe1 (): the famous SVM-based recursive feature elimination method; @BULLET SFFS () 2 : an exhaustive search procedure that has been studied extensively and shown to perform well compared to competing methods (). To reduce computation time, SFFS starts from the 500 genes selected by Fi; then the best set is extracted. SVM is used as the objective performance method.See the Supplementary Material for a fuller discussion of Fisher score and SFFS.
Feature transformWe explore the following feature transform techniques:@BULLET Locally Linear Embedding (LLE), as proposed in@BULLET Neighborhood Preserving Embedding (NPE), as proposed in (). Unlike principal component analysis (PCA), which aims at preserving the global Euclidean structure of the data, NPE preserves the local neighborhood structure on the data manifold. As a result, NPE is less sensitive to outliers than is PCA. We used the MATLAB code freely available at http://www.zjucadcg.cn/dengcai/Data/data.htmlSee the Supplementary Material for a fuller discussion of NPE.
Tree waveletIn the case of one dimensional wavelet decomposition, the first step produces two sets of coefficients from the signal: (i) approximation coefficients, or scaling coefficients; and (ii) detail coefficients, or wavelet coefficients. The approximation coefficients are split into two parts repeating the same algorithm, being thereby replaced by approximation coefficients and detail coefficients. This decomposition process is repeated until a required level is reached (). In this article, we examine the following wavelets (until the sixth decomposition level): Haar, Daubechies order 7, Symmlet order 2, Coiflets order 2, Biorthogonal order for reconstruction 2 and for decomposition 2, Reverse Biorthogonal order for reconstruction 2 and for decomposition 2. For each set of coefficients (both approximation coefficients and detail coefficients) of a given decomposition level, a different classifier is trained. The decomposition is applied both on the original data and on the set of genes selected by Fisher score. SFFS is used to select a set of subbands. The testing protocol was the leave-one-dataset-out validation protocol. When a given dataset is classified, the sets of coefficients are selected using as the validation set the other datasets. A fuller discussion of wavelet decomposition and the set of subbands selected by SFFS considering all the datasets are reported in the Supplementary Material.
Gene microarray classification
Texture descriptorsIn this approach, we consider the microarray as an image from which a set of texture descriptors is extracted. First, we select a set of 900 genes using the Fisher criterion feature selection method. Then this 900-dimensional feature vector is reshaped as a matrix using random assignment. A total of 50 different random reshapings are performed. For each reshaping, a different SVM is trained, with results combined using a fusion rule. In this article, we examine the following image texture feature transforms: @BULLET Lu is a concatenation of the uniform bins extracted using local binary patterns (LBPs) () with P = 8 and P = 16. If x = 8 then R = 1, if x = 16 then R = 2. The length of the feature vector is 59 in the case x = 8 and 243 in the case x = 16; @BULLET Lr is rotation invariant uniform bins extracted using LBP with P = 8 and P = 16. If x = 8 then R = 1, if x = 16 then R = 2. The length of the feature vector is 10 in the case x = 8 and 18 in the case x = 16; @BULLET LP(x) is local phase quantization () with radius x = 3 or x = 5. The length of the feature vector is 256 in both cases;@BULLET LQPu is different local quinary patterns () with uniform bins and with 1 = {1,3,5,7,9} and 2 = { 1+2, 1+4,, 1+11}. These are combined by a fusion rule (see the 'Results' section for details). See the Supplementary Material for a fuller discussion of local phase quantization.
Classification and fusionIn this approach, we use SVM as the stand-alone classifier. SVM is a general purpose binary classifier based on statistical learning. It performs classification in two steps. In the first step, it maps the sample data vector into a higher dimensional data space by means of polynomial kernels or radial basis function kernels. In the second step, the algorithm finds a hyperplane in this space that has the largest margin separating the classes. The fusion step is performed by means of the sum rule or the majority voting (vote) rule. The first consists in summing the scores of all the classifiers of the ensemble and selecting the class with the highest score; the second simply selects the class with the higher number of votes (see the Supplementary Material for a fuller discussion of SVM and the sum and vote rules).@BULLET Medulloblastoma (M) (): the researchers analyze 60 similarly treated patients from whom biopsies were obtained before receiving treatment. Using this dataset,show that the clinical outcome of children with medulloblastomas is predictable on the basis of the gene expression profiles of their tumors at diagnosis; @BULLET Colon (C) (): the colon dataset contains 62 samples: 40 are tumor samples and 22 are normal controls. In this dataset, 2000 genes with highest intensity across the samples are considered; @BULLET Duke (D) (): this is a dataset that contains 44 patterns described by 7129 genes; @BULLET ALML (A) (): this leukemia dataset was derived from a study of gene expression in two types of acute leukemia: acute lymphoblastic leukemia (ALL) and acute myeloid-leukemia (AML). The dataset includes 47 cases of ALL and 25 cases of AML, together with 7129 genes; @BULLET DLBCL (DL) (): the goal of this dataset is to distinguish diffuse large B-cell lymphoma (DLBCL) from follicular lymphoma (FL) morphology. This dataset contains 58 DLBCL samples and 19 FL samples.In our first experiment, we compare several feature selection methods using a stand-alone SVM as the classifier for the function of the number of g genes retained: 150, 300 and 450, respectively. In, we report the average performance of the different approaches across all datasets (the performance for each dataset is reported in Supplementary Table S1 in the Supplementary Material).It is interesting to note that the best performance is obtained by the old Fisher criterion, which slightly outperforms the more recent FFacsa2, SVMrfe and the computationally heavy SFFS method. This advantage in performance is obtained using 450 genes. SVMrfe and SFFS performed best when fewer genes/features are retained. In our experiments, we choose the best kernel and the best parameters for each dataset using 10-fold cross validation on the training data. In the second experiment, we compare several feature transform methods using the stand-alone SVM as the classifier. To reduce the computation time, 1000 genes are first selected by Fisher and then PCA is used to decorrelate the data. Inthe average accuracy on all the datasets obtained using different feature transform methods is reported as a function of the dimension k of the projection space (k {20,30,45}) (the accuracy obtained in each dataset is reported in Supplementary Table S2 in the Supplementary Material). The best performance is obtained by NPE that only slightly improves the performance obtained by Fi in the previous test reported in. In the third experiment, we evaluate the performance obtained by varying the image descriptors used to represent the microarray patterns (as described in Section 2.4). Inwe report the accuracy obtained: (i) by methods based on different descriptors; (ii) by the tree wavelet (TW ) approach (where the classifiers are combined by vote rule); (iii) by the ensemble FUS (which is the fusion by vote rule of TW, NPE and Fi) and, as a reference; (iv) by the best approaches previously tested (Fi and NPE). It is interesting to note inthat not only does the fusion approach obtain the best average performance but also FUS closely matches the performance of the best approach for any given dataset: @BULLET In the prostate dataset (P), the best single approach is TW, which FUS matches; @BULLET In the breast dataset (B), NPE outperforms TW and F. FUS obtains a performance only slightly lower than NPE but higher than either Fi and TW ;We tried combining LQPr in FUS, but performance remained the same. The most advanced methods based on image descriptors (i.e. LQPr and LQPu) perform much better than do simple Lu, Lr and LP (we believe, however, that combinations of different texture descriptors with the simple methods would probably obtain performances closer to those obtained by standard approaches). In the fourth experiment, we compare the performance of FUS with several state-of-the art approaches: LI (), CN (), GH (), LU (), PA (), HU (), BO (), CH (), OR () and PO (). This comparison shows the goodness of the proposed approach with respect to the state of the art. The only dataset where our results are lower is with the Colon dataset (C). In several of the papers used in, the feature selection was performed using the training data, but system performance was measured with the testing set, where varying numbers of the features were retained (seefor the performance of PO using the original code tested in our datasets). In, we give the best results reported for each method using the testing set. Our method, in contrast, used the same number offeatures both in training and testing as well as across all datasets. Our method is thus very suitable for general practitioners. In Tables 69, we report results obtained in the previous experiments using a more reliable performance indicator: the AUC. AUC can be interpreted as the probability that the classifier will assign a lower score to a randomly picked positive sample than to a randomly picked negative sample. In Table 6, we compare several feature selection methods using AUC (cf.where we used accuracy as the performance indicator). FFacsa2 provides the best performance. It should be noted that this difference is mainly due to the lower performance obtained by the other methods in the M dataset (see Supplementaryin the Supplementary Material for results of each dataset). In, we compare the different feature transform techniques using AUC. The best performance, as inusing accuracy, is obtained by NPE. In, we report the performance obtained in the third experiment. In this Table a new ensemble is evaluated, WF, which is the fusion by weighted sum rule of TW, NPE, Fi and LP(5).In the weighted sum rule, each classifier is weighted by a value between 0 and 1. The scores are then summed. Optimal weights are obtained using the leave-one-dataset-out validation protocol. In other words, when a given dataset is classified, the sets of weights are selected using as the validation set the others datasets. Our fusion approach WF obtains the best overall average performance using AUC. Moreover, fusion results for each dataset closely approximate the performance of the best methods reported for the individual datasets. In Table 9, we compare our best approach WF with the performance obtained by a random subspace of SVM trained using the original genes, LIU2 (), and OldTW (). Random subspace of SVM has been shown to be very effective (). The random subspace creates an ensemble such that each classifier is trained with a different subset of the original features. In our experiments, we combine results with sum rule using 50 classifiers, each trained with K features. In, K = 50% means that each classifier is trained with a subset that contains 50% of the original features, whereas K = x means that each classifiers is trained with x randomly selected genes. PO inrefers to the results obtained using the original code shared by (with the following setting: we ran their approach starting from the 500 genes selected by Fi (in this way a more fair approach with our method is provided). It is interesting to note that now the performance on the Colon dataset (C) is lower than that obtained by our ensemble. WF outperforms the other methods. The advantage of using a combination of approaches is also demonstrated by the use of the Wilcoxon Signed-Rank test () developed for comparing the results of stand-alone methods with ensembles. The null hypothesis (that is there is no difference between the accuracies of the stand-alone methods and the ensemble) is rejected with a level of significance of 0.10. As an additional experiment, we investigated the relationship among the different approaches by evaluating the error independence between the classifiers trained using those features.reports the average Yule's Q-statistic () in the tested datasets. For two classifier G i and G j the Q-statistic, a posteriori measure, is defined as: where N ab is the number of instances in the test set, classified correctly (a = 1) or incorrectly (a = 0) by the classifier G i , and correctly (b = 1) or incorrectly (b = ) by the classifier G j. Q Copyedited by: SD MANUSCRIPT CATEGORY: ORIGINAL PAPERThe bold values are the highest performance, the italic values are the values of parameters. and Q i,j = 0 for statistically independent classifiers. Classifiers that tend to recognize the same patterns correctly will have Q > 0, and those that commit errors on different patterns will have Q < 0. In this problem, the Q-statistic values are low enough to validate the idea of combining the different approaches. As a final experiment, in, we report the results of our ensemble on two other recent datasets from (). The first is a breast cancer dataset (WB) that contains a subset of ER-positive, lymphnode-negative patients who did not received adjuvant treatment. The raw intensity Affymetrix CEL files and normalized data by RMA procedures using Bioconductor packages are used for obtaining a final expression matrix comprising 22 283 features and 209 samples. The 71 patients who developed distant metastases or died within 5 years are classified as poor prognosis subjects, and the 139 patients who remained healthy for >5 years are classified as good prognosis subjects. The second dataset (LA) contains gene expressions of 86 patients with primary lung ADCA; 62 patients were still alive, and 24 patients had died. Notice that all the parameters of WF are obtained using the nine datasets previously used throughout this article. In this test, we arrive at the same main conclusion of the previous test: the fusion, WF, obtains the best average performance.
Gene microarray classification
CONCLUSIONThe goal of this study was to develop a robust ensemble of SVM classifiers based on feature perturbation for microarray classification. The reported results of our experiments, expressed as both accuracy and AUC, show that our approach performs very well across several datasets. Our study examined an SVM trained using a set of selected genes by Fisher criterion, an SVM trained using the feature set obtained by NPE, a set of SVMs trained using a set of orthogonal wavelet coefficients of different wavelet mothers and a set of SVMs trained using texture descriptors extracted from the microarray, considering it as an image. The positive results we obtain compare well with those reported in the literature and provide further confirmation that ensembles of classifiers obtain more reliable results.In future studies, we plan on testing our approach using more datasets. We will also study combining additional methods in ensemble construction (e.g. combining our feature perturbation approaches with a pattern perturbation approach).
Conflict of Interest: none declared.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
The MATLAB code was shared by the original authors of FFacsa2, which also shared the code of SVMrfe. 2 Implemented as in PRTools (prtools.org/prtools.html).
RESULTS To assess the performance of our approach, we have conducted several experiments on a number of publicly available datasets. Below we provide a brief description of each dataset (the salient features of each dataset are summarized in Table 1):  Breast dataset (B) (van 't Veer et al., 2002): the goal of this experiment is to identify patients who might benefit from adjuvant chemotherapy. Two classes are considered: patients who continued to be disease free after 5 years (44 samples) and patients who developed metastases within 5 years (34 samples);  Ovarian dataset (O) (Petricoin et al., 2002): the goal of this experiment is to identify proteomic patterns in serum that distinguish between ovarian cancer and normal non-cancer groups. Two classes are considered: 91 controls (Normal) and 162 ovarian cancers;
Publically available at http://www.chestsurg.org.
