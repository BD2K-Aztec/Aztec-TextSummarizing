Motivation: Protein abundance in quantitative proteomics is often based on observed spectral features derived from liquid chromatography mass spectrometry (LC-MS) or LC-MS/MS experiments. Peak intensities are largely non–normal in distribution. Furthermore, LC-MS-based proteomics data frequently have large proportions of missing peak intensities due to censoring mechanisms on low-abundance spectral features. Recognizing that the observed peak intensities detected with the LC-MS method are all positive, skewed and often left-censored, we propose using survival methodology to carry out differential expression analysis of proteins. Various standard statistical techniques including non-parametric tests such as the Kolmogorov–Smirnov and Wilcoxon–Mann– Whitney rank sum tests, and the parametric survival model and accelerated failure time-model with log-normal, log-logistic and Weibull distributions were used to detect any differentially expressed proteins. The statistical operating characteristics of each method are explored using both real and simulated datasets. Results: Survival methods generally have greater statistical power than standard differential expression methods when the proportion of missing protein level data is 5% or more. In particular, the AFT models we consider consistently achieve greater statistical power than standard testing procedures, with the discrepancy widening with increasing missingness in the proportions.
INTRODUCTIONProteomics is a growing field that deals with the determination of gene and cellular function at the protein level (). It is often of interest to the protein researcher to identify as well as quantify the amount of protein in a given biological sample. Several methods and instruments are available for both the identification and quantitation of peptides within proteins, including the bottom-up liquid chromatography mass spectrometry (LC-MS) and LC-MS/MS or the tandem mass spectrometry approaches. In the LC-MS approach, proteins are extracted from the biological sample, digested into peptides and ionized (). Following the ionization step, the ionized * To whom correspondence should be addressed. sample is introduced to the mass spectrometer for scanning where the mass to charge (m/z) and observed peak intensities are obtained. Once the peak intensities are obtained, the observed features of the peptides are matched to a database for peptide identification. Following the identification step, the peptide level information is rolled up to the protein level (). In LCMS/MS, a precursor ion is picked after the first MS step for fragmentation prior to the identification step (). It is often of interest to measure the abundance of proteins from the identified peptides in the sample; this is the quantitation step of the analysis. In bottom-up MS-based quantitation, the estimation of protein abundances in a sample is typically carried out on the basis of one of three quantities (): (i) spectral counts; (ii) label-free methods or (iii) isotopic labeling experiments. Spectral counts are simply the number of peak intensities for a given peptide/protein. Labelfree intensity-based quantitation uses peak intensities (heights or areas under the peaks) to estimate peptide or protein abundance. Other label-free methods are based on the unlabeled peak intensities associated with the mass spectrum of the extracted ions. Label-based methods of quantitation, which are viewed as the 'gold-standard' for measuring protein abundance, involve the ratio of the observed peak intensities of two isotopically labeled samples. Once the protein abundances have been obtained, it is often of interest to assess differentially expressed proteins across comparison groups. The goal of differential analysis is to differentiate features across groups which can be subsequently used for biomarker discovery or for providing additional clues for studying the causal pathways of the disease or the biological condition of interest (). One of the characteristics of peak intensity data from LC-MS based proteomics is large quantities of missing data. The missing data patterns are often not independent of the peak intensities of the peptides, which is likely due to censoring of the peak intensities for low-abundance peptides/proteins (). To assess differentially expressed proteins across treatment groups, the observed peak intensities are often normalized (), imputed () and transformed (;). Various imputation techniques are available for the imputation step. These include the row mean imputation, K nearest neighbor (KNN) (), singular value decomposition (), Bayesian principal components analysis (), Gaussian mixture clustering () and a convex combination of these methods (LinCmb) ()
Detecting differential protein expressionsis the probabilistic PCA (PPCA) approach which is based on a combination of the expectation maximization (EM) algorithm with a probability model (). Once the data are transformed and imputed, standard statistical techniques such as the two-sample t-tests or linear regression methods are often applied to detect any significant differences in the protein expressions across the groups under the assumption that the data are normally distributed. However, the assumption of normality can be violated even for the transformed data. The protein-specific t-test may also have insufficient power in detecting group differences due to the small sample sizes within each treatment group (). To deal with missing values in practice, one of two basic strategies is generally used. The simplest strategy is to work only with the complete intensities. That is the data used for a particular peptide/protein would be based on the observed peak intensity; the missing values are excluded from the analysis. Alternatively, the missing values are imputed. There are many imputation algorithms (). However, none of these approaches is strictly appropriate when the missing values have been censored, as they can result in biased estimates and statistical inference (). Standard alternatives to the parametric t-test are non-parametric tests such as the WilcoxonMannWhitney rank sum or the KolmogorovSmirnov tests. These tests are more desirable than their parametric counterpart since they do not make any strong distributional assumptions. As with the t-test, these tests are carried out by either deleting the missing peak intensities or imputing the data. Standard statistical techniques such as the t-test or linear regression methods do not naturally accommodate the positive nature of the data, nor the presence of widespread censoring. To address these issues, we propose the use of existing statistical methodology that is designed specifically for non-negative, censored data. The field of survival analysis generally deals with such data, and there is a wide variety of survival methodologies that could be adapted to the quantitative proteomics setting. In particular, the accelerated failure time (AFT) model fits the quantitative proteomics setting well. An AFT model essentially; involves regression under assumed parametric models, in the presence of censored observations. Distributions available in AFT modeling include the log-normal, log-logistic and Weibull. As discussed above, standard testing procedures in the quantitative proteomics setting are not ideal, particularly with regard to the widespread censoring that is typically present. A simple scenario highlights the value of survival methods in the presence of censored data. Consider a single protein for which we have intensity measurements from 10 control samples and 10 treatment samples. Of the 20 attempted measurements, suppose 6 are missing due to censoring: 2 from the control group and 4 from the treatment group. For these six censored observations, we can only say that the protein was not present for those samples, or it peak intensities were too low to be detected by the instrument. In our data file, the entries for these 6 observations might simply read 'NA.' The challenge is dealing with this situation that the 14 observed intensities will tend to the 14 'largest' values out of the 20. Thus, for example, if we were to base our analysis on just the 14 observed intensities, we would 'overestimate' the means and 'underestimate' the standard deviations in each group, resulting in biased inference. Meanwhile, standard imputation routines assume that missing values are 'completely at random' (), which in our context would mean that the fact a particular intensity is missing is independent of the value of its actual peak intensity or other peak intensities in the data. With censoring, observations tend to go missing only when they are really small (in our left censoring contexts). In other words, the missing completely at random mechanism does not generally apply to quantitative proteomics data. As such, standard imputation techniques will suffer from the same limitations of the complete-data analysis, namely, biased statistical inference. Furthermore, most imputation techniques that are applied in practice to quantitative proteomics data are 'single imputation' techniques (). It is known that single imputation can result in biased inference due to overfitting the data. Survival methodology, of which AFT models are an example, is specifically designed to handle censored observations. They work by correctly representing a censored observation as one that in reality fell at or below a known threshold. As a result, the issues of overestimated group means and underestimated standard deviations are avoided, and valid statistical inference is maintained. The main contribution of this article is to adapt well-known benefits of survival methodology to the quantiative proteomics setting. Our proposed approach to detecting differential expressions can be applied to any proteomics data generated using either the LC-MS or tandem MS approaches since these data are all non-negative and prone to missing observations due to censoring regardless of the instrument technology. The advantage of using the survival approach is that it allows a likelihood-based inference of the LC-MS or LC-MS/MS proteomics data in the presence of missingness due to censored observations.
METHODS
Data preprocessingOne of the challenges in proteomic analysis is determining how the peptide level information obtained for each peak height can be rolled up to the protein level. Analysis conducted at the peptide level for each protein is often desirable; however, such analysis is not always feasible due to the level of missing data at the peptide-level. In a peptide-level analysis, the proteinlevel abundance is expressed in terms of the peptide-level intensities, and methods such as mixed effects models are used in the analysis (). Several options are available for the peptide to protein rollup in LC-MS-based bottom-up proteomics. These options include the RRollup, ZRollup and QRollup (). In the RRollup method, all peptides from a given protein are scaled based on a reference peptide and averaged to obtain a protein abundance for that given protein (). The ZRollup method involves standardizing at the peptide level using a method comparable to the z-scores prior to averaging to obtain the proteinlevel abundance (). For the QRollup method, a user specified cutoff value is used to select the peptides for a given protein, and the selected peptides are averaged across peptide-level peak intensities to obtain protein-level abundances (). Another approach to the peptide to protein rollup problem is a principal components based approach (ProPCA) for label-free LC-MS/MS proteomics data (). The ProPCA method combines the spectral counts from the label-free LC-MS/MS data with the peptide peak attributes to obtain estimates of the relative protein abundance (). For simplicity, we accomplished peptide-to-protein rollup by averaging peptide peak intensities by protein. In addition to the AFT models, we considered the following strategies for dealing with missing intensities at
C.D.Tekwe et al.the protein level: (i) complete data analysis, row-mean imputation, KNN imputation (), and PPCA imputation (). As discussed above, these and related techniques, while simple to implement in practice, have important limitation in the quantitative proteomics setting that can result in invalid statistical inference.
Data
Diabetes studyFor our first application, we apply the various tests to the diabetes data studied by (). The diabetes dataset is based on frozen human serum samples from the DASP between 2000 and 2009 (). The data consist of 10 healthy control subjects and 10 subjects with a recent diagnosis of type I diabetes mellitus. Six highabundant plasma proteins that constitute 85% of the total protein mass of human plasma were removed prior to extracting the serum. The samples were analyzed using the accurate mass and tag method (Pasa). The final LC-FTICR MS datasets were processed using the PRISM Data Analysis system (). For the diabetes data, any observations within a given sample below the lowest observable peak intensity within that sample is considered censored. Therefore, we define the detection limit to be sample specific for the diabetes data.
Simulation studyWe simulated 100 datasets from the log-normal, Weibull and log-logistic distributions. Each simulated dataset was composed of 10 samples in each of two comparison groups with 5000 proteins, 40% of which were differentially expressed. Differential expression was created in terms of differences in log means between the two comparison groups; this difference was allowed to vary from 1.05 to 1.50. We varied the percent missing (censored) observations over the values 0, 5, 15, 25, 35, and 45%. Five approaches were used to handle the censored data. The approaches include no imputation (NI), row mean, KNN and PPCA imputations. We also considered the missing data as left-censored observations by applying survival models. The knn.impute function in the impute package in R () with k = 3 nearest neighbors was used for the KNN imputation, while the pca function of the pcaMethods package () was used to impute the data with the PPCA approach. The detection limit for our simulation study is defined as the minimum observable peak intensity within the whole dataset. Therefore, the detection limit is data specific for the simulation study.
Statistical methods considered
T-tests and related techniquesThe standard statistical technique used for differential expression analysis in a two-class setting is the twosample t-test. Under the assumption that the variances are equal for both treatment groups within a given protein and the sampled from a normal population, the data are log 2 transformed and the following test statisticis calculated where S p is the pooled standard deviation, while C and D index the first and second comparison groups, respectively; M is the total number of proteins in the data and n is the total number of samples associated with each protein. It is assumed that under the null hypothesis, TS i follows a t distribution with 2n2 degrees of freedom. When the number of comparison groups exceeds two, the two-sample t-test can be generalized by the F-test.
Non-parametric alternativesTwo non-parametric methods were considered for testing the null hypothesis that the distributions of the comparison groups are identical. Non-parametric tests are performed under mild distributional assumptions regarding the distribution of the populations from which the data are sampled (). It has been shown that by relaxing the normality assumption when the normality assumption holds in favor of non-parametric methods, the nonparametric methods are minimally less efficient than standard methods based on normality assumptions (). Also, the nonparametric tests are more robust to outlying observations even when the normality assumption is valid (). The first distribution-free method we considered was the Kolmogorov Smirnov test. This tests the null hypothesis that the distributions for the two comparison groups are equivalent against the alternative hypothesis that they differ (). Let F i () and G i () be continuous distributions for the populations being compared for the ith protein, and C i1 ,C i2 ,.
..,C in. Our objective is to test if there are any differences in the protein expressions between the two groups. The hypotheses under consideration are,for at least one t, where t is the observed peak intensity. The first step in obtaining the KolmogorovSmirnov test statistic is to calculate the empirical distributions of F inThe KolmogorovSmirnov test statistic J i for the ith protein is defined aswhere d is the greatest common divisor of n. To test at level , we compare J i to j  , rejecting the null hypothesis if J i  j . The above test statistic was calculated under the assumption that there are equal samples in both groups; however, the test can also be generalized to the unequal sample size case (). The term j  is chosen from a table or computed through software such that the probability of Type I error is equal to . The WilcoxonMannWhitney rank-sum test is a distribution-free twosample test under the assumption that the populations only differ by location and are independent (). A location-shift model defined as G i (t) = F i (t  i ) for every t is used to define the null hypothesis. Under the null, it is assumed that the comparison groups come from identical populations, for the ith protein. The alternative hypothesis is that the two distributions differ by i for the ith protein. More formally,which states that the distribution of D i and C i differ by i , the locationshift parameter or treatment effect. Thus, the WilcoxonMannWhitney hypothesis is stated asThe WilcoxonMannWhitney rank-sum test statistic, W i , is computed by first combining the comparison groups (each of size n). The combined sample of size 2n observations is ranked and the test statistic for the ith protein is based on the sum of the ranks assigned to the observations from one of the comparison groups in the ordered combined group. Thus, W i is calculated aswhere S ij is the rank associated with the jth sample from one selected comparison group treatment sample for the ith protein. For this two-sided test, W i is rejected if W i   /2 or if W i  n(2n+1) /2 where the nominal values of  /2 can be found through software. Ties are treated separately (). Similar to the two-sample t-test, a limitation of the non-parametric tests considered here is that they are restricted to two samples and do not allow for the adjustment of covariates.
Detecting differential protein expressions
AFT models Let t ijbe the observed peak intensity for the ith protein in sample j, Z ij is an indicator variable indicating the group membership (1 if sample j is in the treatment group, 0 if in control) while S i (t|Z ij ) is the survival function. The survival function is defined as the probability that the ith protein peak intensity is greater than some value t|Z ij. Under the assumption that the missing data are censored, the parametric AFT model can be applied to compare protein-level expressions across comparisons groups of interest. The AFT model,defines the relationship between the survival function S i (t|Z ij ) and the acceleration factor exp( i Z ij ) for the ith protein. The baseline survival function, S i0 , is the survival function at the baseline levels of all the covariates included in the model. In the current application, the baseline survivor function is the survivor function for the control group. The acceleration factor indicates how the survivor function for the ith protein changes from the baseline survival function as the covariate changes, while  i indicates the effect of the ith peak intensity on its predicted survival peak, S i (t). In applying the AFT model to peak intensity data, we assume that the effect of a covariate is multiplicative on the predicted survival function of the peak intensity. Therefore, the AFT model can be expressed in terms of a linear relationship between the log intensities and the group indicator variable:where  i and  i are the mean and scale parameters associated with the ith protein, respectively, while W ij is the error term in the model for the ith protein. The regression coefficient,  i , is the effect of the treatment compared to the control group of the log-transformed peak intensity in our current application. Several assumptions can be made about the distribution of Y ij including the Weibull, log-logistic,  and log-normal distributions. The name of a given AFT model is based on the assumed distribution of T rather than the assumed distribution for either W ij or log(T ) (). The lognormal, Weibull and log-logistic distributions are commonly used with AFT models ().
Estimation and inferenceIn this section, we discuss the maximum-likelihood estimation of the AFT model with left censoring for the ith protein. We first define an indicator function  ij = 1 if T ij is observed or 0 if censored. Under the assumption that the missing protein peak intensity data are due to left censoring where the mass spectrometer is unable to detect peak intensities below a given minimum detectable threshold, the likelihood function is defined asis the density function. In adjusting for the left censoring in the protein peak intensity data, we assume for each sample there is a minimum detectable threshold and any observed peak intensity below the given threshold is assumed to be censored at the given threshold, t ij. The value for the minimum detectable threshold associated with each protein is plugged into the likelihood. The contribution of the left-censored observation is from F(t ij , i ) 1 ij while the contribution of the non-missing peak intensity to theTo maximize the likelihood, we maximizeThe maximum-likelihood estimates can be found using an algorithm such as the NewtonRaphson procedure or the EM algorithm or with readily available software such as the survreg function in R. The likelihood ratio test can be used to test for the differential expressions between the groups under considerations. Specifically, to test for any differential protein expressions, the likelihood ratio test can be used to test H 0 :  i = 0. The number of proteins determined to be differentially expressed can be based on the proteins for which FDR   ().compares the number of proteins called differentially expressed at an estimated FDR of 5%. Overall, we find that applying the KolmogorovSmirnov test with KNN imputation had the least power to detect the differential expressions, while the AFT models had the highest power. From our analysis of the diabetic data, it appears that treating the missing data as left-censored is beneficial. We also find that the t-test applied to the transformed data performed as equally well as the non-parametric tests. The AFT model with the Weibull distribution outperformed all the other tests under consideration. Our findings from the diabetes data based on the AFT model with the log-logistic distribution indicated that 131 of the proteins present in the sample were differentially expressed while about 79 proteins were found to be differentially expressed under the t-test with row mean imputation. Previous methods that also study the differential expressions of the proteins in the diabetes data also found 75 of the proteins to be differentially expressed at an estimated FDR rate of 0.05% (). Therefore, the AFT model with log-logistic distribution found 40% more differential expressions than previous findings. Based on manually searching through the list of proteins called differentially expressed by the AFT log-logistic model but not the t-test with row mean imputation, we found a few with known relevance to diabetes: IPI00291262.3 (), IPI00021842.1 () and IPI00298994.3 (). The latter protein, talin-1, has been linked to diabetes in rats, while the first two have been noticed in humans. These results indicate that the use of the more powerful AFT models has the potential to increase our number of biologically relevant discoveries.provides the number of differential expressions detected at a true FDR rate of 5%. We find that when there are no missing data, and there appears to be no difference between the number of differential expressions detected by the t-test under all the imputation methods considered and the t-test performs equally well as the AFT model under the log-normal distribution. The rank-sum test also performs well in detecting differential expressions when none of the data are missing. However, as the proportion of missing data increases, we find that the AFT models outperforms the standard tests in detecting differential expressions. Overall, the AFT model tends to outperform all the tests considered, and the non-parametric tests had the least power to detect any differentially expressed proteins. The AFT model had the highest power under all the levels of missingness considered. The AFT model with the Weibull distribution had the least power to detect true differential expressions when compared with the models under either the log-normal or loglogistic distributions. We therefore recommend the use of either the log-normal or log-logistic distribution-based AFT model which treat missing peak intensities as left-censored. Our results also illustratethat treating left-censored data as randomly missing data and using imputation techniques developed for randomly missing data can lead to a reduction in the power to detect differential expressions. Interestingly, the 'NI' tended to perform well across the board. This is somewhat surprising since they are not taking advantage of the censored nature of the data. Still, the proper survival-based techniques clearly outperform all others considered. Furthermore, the simulation results strongly indicate that classical imputation techniques perform poorly in the context of censored data.
RESULTS
Diabetes data
Simulation study
DISCUSSIONIn quantitative proteomics, it is often of interest to determine how proteins obtained from subjects under various treatment conditions differ. In this article, we focused on various techniques for detecting such differential expressions at the protein level. We recognize the nature of peak intensity data as positive data prone to missingness due mostly to left censoring. We propose using methods from survival analysis to detect any differences at the protein level. Based on our application of the various techniques to the diabetes data, we find that applying the AFT models under with left censoring had the highest power to detect any group differences. Tests applied under the assumption of left censoring had the highest ability to detect differentially expressed proteins when compared with tests based on the assumption that the missing data are randomly missing. Our simulation study also confirms the benefit of treating the missing data as left-censored and applying the AFT models. Overall, we would recommend treating raw peak intensity data as positive and left-censored data and apply survival methods such as the AFT model with the log-logistic distribution to determine any differentially expressed proteins. Many-omics technologies will be expected to give rise to censored data to one degree or another. For example, array-based data are fluorescence intensity measurements, nuclear magnetic resonance data are spectral intensity measurements, etc; each of these are strictly positive
Detecting differential protein expressionsmeasurements, susceptible to left censoring. Thus, the proposed use of survival methods has potential application to a variety of-omics data types. However, MS-based proteomics data are exceptional in their extreme proportions of censoring, so it is unclear how large of an impact the proposed techniques would have outside of the proteomics context. Our current analyses were based on detecting differential expressions at the protein level following a peptide-to-protein rollup. As a follow-up to the study, we plan to study methods from survival analysis to detect differential expressions at the peptide level where the missing data are treated as left-censored observations.
CONCLUSIONIn this article, we applied methods from survival analysis to detect differentially expressed proteins based on LC-MS proteomics data. We find that applying the AFT model with left-censored data leads to more proteins being considered as differentially expressed when compared with other standard statistical techniques which assume that the missing data are randomly missing.
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
