Motivation: The most common RNA-Seq strategy consists of random shearing, amplification and high-throughput sequencing of the RNA fraction. Methods to analyze transcription level variations along the genome from the read count profiles generated by the RNA-Seq protocol are needed. Results: We developed a statistical approach to estimate the local transcription levels and to identify transcript borders. This transcrip-tional landscape reconstruction relies on a state-space model to describe transcription level variations in terms of abrupt shifts and more progressive drifts. A new emission model is introduced to capture not only the read count variance inside a transcript but also its short-range autocorrelation and the fraction of positions with zero counts. The estimation relies on a particle Gibbs algorithm whose running time makes it more suited to microbial genomes. The approach outper-formed read-overlapping strategies on synthetic and real microbial datasets.
INTRODUCTIONSequencing technologies play an increasing role in the investigation of gene expression [RNA sequencing (. The most common RNA-Seq strategy is based on random shearing, amplification and high-throughput sequencing of the RNAs, yielding millions of sequence reads that serve to characterize wholegenome transcriptional profiles (). Current protocols provide strand-specific data (). After mapping onto a reference genome sequence, the number of reads found at each position of the genome is recorded and those counts can be used to derive estimates of gene expression up to the isoform level () under the assumption that read counts are proportional to transcript length and transcription level. The read coverage along the genome also provides a rich information that is often used to map new transcriptionally active regions (). Despite the amount of data collected in the past decade, initially with microarrays and now with sequencing, for most of the organisms, there are still no or incomplete annotations of their transcripts. Even the most studied model organisms are lacking a full characterization of their transcriptome architecture. Not only the complete condition-dependent repertoire of transcripts proves difficult to establish but also the biological meaning of important transcripts' categories, such as pervasive transcription in eukaryotes () and antisense RNAs in bacteria (), remains elusivehence, the importance of developing new computational approaches that could help to extract more information from RNA-Seq datasets. A major research direction toward the identification of transcript structures is based on read assembling (). Reference-based methods () begin with the alignment of reads on the genome. Fragments are constructed by joining reads on the basis of paired-end or fragment length information. Fragment overlapping is then examined to build a connection graph. At the end, the connected reads are predicted to belong to the same transcript. Isoform structure can be inferred from the path of fragment contigs (), and expression levels can be estimated after allocation of the reads to the inferred transcripts. Although this approach provides insightful results at a computationally affordable cost and can use reads overlapping exon junctions as direct evidence for splicing (), it has also some intrinsic limitations. The most obvious is that limited depth of sequencing combined with technical biases may cause gaps that lead to artificial splits in transcript structure. Irrespective of the sequencing depth, this approach is also unable to point to overlapping transcripts caused by promoter multiplicity and incomplete termination. However, these two mechanisms contribute substantially to the transcriptome's complexity in organisms with compact-sized genomes (). Our aim in this study is to develop a principled strategy for analyzing changes in expression levels whose output could help to identify the variety of mechanisms shaping the transcriptional landscape. The task is complicated because of the existence of several types of protocol-induced biases that cause longitudinal variability of coverage along the chromosome. Part of these artifacts can be explained by the influence of the local nucleotide *To whom correspondence should be addressed.
yThe authors wish it to be known that, in their opinion, the last two authors should be regarded as joint Last Authors. composition on the priming step () and by other pre-sequencing procedures that can introduce biases in read coverage (). To tackle these issues, we present a probabilistic model of RNA-Seq count data, which integrates transcription level variation as well as a generic description of the longitudinal variability induced by the sequencing protocol. This modeling approach builds on previous works, originally motivated by the analysis of comparative genomic hybridization and transcription tiling array data that aimed at segmenting the signal into regions of piecewise constant expression. In this context, two major issues are the choice of the correct number of breakpoints () and the assessment of uncertainty on breakpoint position (). The alternative adopted here consists of extending the probabilistic model to account for the full dynamics of the transcription signal (). Transcriptional landscape reconstruction is then conducted in the framework of hidden Markov models (HMMs) with hidden process in continuous state space, also known as state-space models (SSMs). We developed here procedures to estimate the model parameters, reconstruct local transcription levels, call transcribed regions and identify coverage breakpoints based on this framework.
A PROBABILISTIC MODEL FOR TRANSCRIPTION LEVELS AND READ COUNTS
The SSM frameworkThroughout this work, we refer to the transcription level at position t of the genome as u t. This level is scaled such that it corresponds to the expectation of the count y t of reads whose 5 0-ends map at position t: it is thus also proportional to the total number of reads sequenced. It cannot be directly equated to the read count y t because of the randomness of the selection of the sequenced reads and to local variability artifacts. Our aim is to reconstruct the trajectory u  u t  t!1 from the sequence of read counts y  y t  t!1. For this purpose, we consider an SSM where u t is a hidden variable taking values on the real half line 0; 1 whose distribution depends on u t1 via a Markov transition kernel and y t is an observation whose emission distribution depends on u t. This framework allows accounting for the longitudinal dependency between the u t 's and provides great flexibility in the modeling of y t given u t .
Longitudinal model of transcriptional levelThe Markov transition kernel ku t1 ; u t  that we use distinguishes expressed (u t 40) and non-expressed (u t  0) regions and assigns a positive probability for unchanged transcription level between t and t  1. The allowed changes of transcription levels between t and t  1 breaks down into distinct types: jump from between expressed and non-expressed regions as well as changes of transcription level within transcribed regionsaccounting for transcription initiation and termination sites in presence of overlapping transcription units. Following the work on tiling array data (), changes within transcribed regions further subdivide into two types that differ by their amplitudes and are referred as shifts (large amplitude) and drifts (small amplitude). Coexistence of shifts and drifts is designed to pull apart well-defined initiation or termination sites internal to transcribed regions from smoother changes in measured transcriptional levels that can have a biological origin (e.g. random termination events) or can reflect technical artifacts (e.g. longitudinal bias caused by messenger RNA capture and fragmentation protocols). The Markov transition kernel ku t ; u t1  for transcriptional level writes 1 fut10g 1   0 u t   fu t   1 fut140g  ut1 u t   fu t   0 0 u t   u g u u t ; u t1 ,   d g d u t ; u t1 , , where 1 denotes the indicator function that serves to indicate whether t  1 is an expressed or non-expressed position, and x denotes the Dirac delta function with mass at point x that gives a non-zero probability for unchanged transcription level and for jumping to 0 between t  1 and t. The parameters 2 0, 1 and , , 0 , u , d  2 0, 1 5 with   0  u  d  1 define the probabilities of the different types of moves. The terms fu t ; , g u u t ; u t1 ,  and g d u t ; u t1 ,  are probability densities for the transcription level u t , at the beginning of a transcribed region (occurring with probability when u t1  0) or after a shift (probability when u t1 40), after an upward drift (probability u when u t1 40) and after a downward drift (probability d when u t1 40), respectively. The density fu t ;  corresponds to an exponential distribution of rate (mean 1=) and the parameter 40 defines the average relative change caused by drifts: u t  u t1 =u t1 if upward drift or u t1  u t =u t if downward drift.
Distribution of read counts in real datasetsThe variability of read counts observed when resequencing the same library has been described as almost compatible with a Poisson distribution (). However, when compared between samples (or even replicate libraries), it exhibits overdispersion, and the negative binomial (NB) distribution is often used to accommodate this behavior (). Initially, we planned to rely also on the NB to account for read counts overdispersion between positions inside each transcript. It seems required to involve a mixed Poisson distribution to account simultaneously for the incompressible variance of the final sampling by sequencing (Poisson) and for the extra-variability introduced by randomness in library preparation and by position-specific biases that can be introduced at all steps of the protocols. In this context, the NB is viewed as a gammaPoisson mixture [y t $; Poissonu t z t , where z t follows a gamma distribution with mean 1 and variance ] stands as the most tractable model (). Based on two real datasets, we examined the distribution of read counts inside regions expected to be homogeneous in terms of expression level. Namely, we asked whether the NB could capture the relationships between mean and variance and simultaneously account for the fraction of positions with zero-counts (). Both the characteristics are expected to impact directly on the decision to predict read counts at distant positions as originating from the same transcript. The most obvious discrepancy between the data and the NB is with respect to the zero counts: given the mean and the variance of the empirical distribution, the fraction of positions with zero counts under the NB assumption tends to be too low for low expression levels and too high for high expression levels. The usual parametrization of the NB with overdispersion parameter mentioned above is also contradicted by the data. The variance increases markedly faster than the mean u even for low expression level, in sharp contrast with the prediction that the variance should write u  u 2. In the Poisson-mixture context, breaking these relationships that arise from law of total variance implies that the relationship between the mixing distribution and u is more subtle than a simple scaling. This prompted us to search for a more accurate model that would make sense from a mechanistic perspective.
Read count emission modelWe developed a new RNA-Seq read count emission model that fits much better the characteristics of the real data than the simple NB (). Its construction intends to account for the three main steps of the experimental protocol: (i) initial molecule sampling and fragmentation, (ii) amplification and (iii) final sampling by sequencing. Namely, we write y t $; Poissonx t a t , where a t is distributed over 0,  1 with mean a and x t follows a discrete distribution over f0, 1,. .. ,  1g with mean u t = a ; hence Ey t   u t. The term x t is aimed at representing the number of molecules with 5 0-end mapping to position t after initial sampling; a t wishes to capture the effect of randomness in amplification and position-specific biases in amplification and sequencing, a should be interpreted as an amplification coefficient corresponding to the average number of reads per initial molecule sampled; the Poisson distribution accounts for the final sampling. For simplicity, we choose a gamma distribution for a t and an NB distribution for x t. In practice, the parameters of the gamma distribution for a t (size , scale , a  ) are obtained by examining the distribution of counts in regions of low expression, i.e. where x t is expected to be 1 if a count is observed. The NB for x t is obtained by writing x t $; Poissonu t s t = where s t follows a gamma distribution with mean 1 and variance s (i.e. size s and scale 1= s ), the parameter s is estimated on the variance versus mean and fraction of zero counts versus mean plots (). Decomposing the NB for x t as Poisson-mixture allows to account for the pattern of short-range autocorrelation between counts (Supplementary) by making s  s t  t!0 a piecewise constant Markov chain. Integrating out these three sources of variability and the possibility of outliers, the density y t ; u t , s t  of our complete read count emission model writes the following:The parameters " b , " 0  2 0, 1 2 account for the possibility of background noise outside transcribed regions and outliers (" b  " 0 1), respectively. The NB density term within the sum arises after integration over all possible values of a t. A complete description of the relationships between the variables y, u, s and the parameters (hereafter referred collectively as ) is found in Supplementary Sections S1 and S3.
TRANSCRIPTIONAL LANDSCAPE RECONSTRUCTION
Markov chain Monte Carlo with particle GibbsIn SSMs, the reconstruction of the hidden trajectory, given the parameter values and the observed data (here the characterization of ujy, ), is more challenging than in a classical HMM where only discrete values are considered for the hidden variable. The forwardbackward recursions that provide exact answers in the context of classical HMMs need to be substituted by particle filtering algorithms build on sequential Monte Carlo (SMC) principles whose results are only approximate for finite numbers of particles (). Parameter inference that relies heavily on hidden trajectory reconstruction in this category of models is also directly impacted. Here, the existence of a second hidden variable s t and the sequence lengths ranging in millions of base pairs increase the difficulty. To circumvent these problems, we used a recently described SMC method known as particle Gibbs (PG) that makes it possible to obtain exact (but correlated) joint samples of the hidden trajectory and parameters, given the data (). PG is based on a modified SMC step, the conditional SMC (CSMC), that is integrated into more general Markov chain Monte Carlo (MCMC) algorithms for Bayesian inference of the parameters. In this setup, this also allowed to combine the reconstructions of ujs, y,  and sju, y,  to obtain a jointreconstruction of u, sjy,  and to extract the marginal of interest ujy, . We also implemented an additional PG step intended to preserve su by rescaling s when updating u. The problem posed by sequence length was properly handled within the PG framework by successive partial (block) CSMC updates of the hidden trajectories. To validate the implementation of our PG algorithm, we extended the algorithm to sample the joint s, u, y,  distribution and verified that we could retrieve the priors. Detailed descriptions of the parameter priors, MCMC and validation procedures used in this work are provided in Supplementary Sections S2 and S3.
The Parseq workflowIn theory, our PG algorithm permits to tackle parameter estimation and transcriptional landscape reconstruction simultaneously, but our software Parseq subdivides the problem in three successive steps for practical reasons (). The parameters of the read count emission model are estimated, and the emission density corresponding to the different values of u t s t are tabulated (step 1). PG iterations are too time-consuming to be performed on a single CPU for genomes of moderate sizes such as the yeast Saccharomyces cerevisiae ($12 Mb). To distribute computation on independent CPUs, we decided to subdivide each chromosome in fragments ($1 Mb each), to perform parameter estimation separately on these fragments, and then to select a common set of parameters based of the obtained results (step 2). Posterior sampling of transcriptional landscape trajectories u is then carried out on a different CPU for each genome fragment, but with common parameters (step 3). With an Intel Core i7-3610QM CPU @ 2.30 GHz, each complete sweep of the MCMC algorithm was recorded to take $1 min for 1 Mb using 150 particles in each CSMC update. In this study, we used 2200 sweeps, including 200 burn-in sweeps, for parameter estimation (step 2), and 2200 sweeps for making predictions at fixed parameters (step 3). Thus, on multi-CPU computers, the complete procedure takes slightly 53 days for each dataset with this algorithm setup, which we currently recommend for applications. The output of the algorithm is a sample of transcriptional landscape trajectories drawn from uy,  that conveys rich information about the actual transcriptional landscape. Here, these trajectories served to estimate the expected value of u t , the 95% credibility interval of u t and the probability of u t 4 0 (transcribed position), together with the probability of the different types of breakpoints along the sequence. Because of the posterior uncertainty on the exact position of each breakpoint, we further aggregated the breakpoint probabilities at adjacent positions into small regions with high cumulative probabilities using a localscore approach. The weighted center of each small region was taken as a point estimate of the position of the breakpoint and the cumulative probability served as a confidence measure. According to the direction of the change in expression level, the breakpoints were identified as upshifts or downshifts. To better distinguish genuinely expressed regions from (biological or technological) background noise, we also realized the relevance of computing the probability for u t to be above a selected cutoff and to predict the breakpoints that lead the trajectory u above this cutoff. Details on the workflow, including parameter estimation and post-processing, are provided in Supplementary Section S4. Transcriptional landscape reconstruction is illustrated on.
RESULTS AND DISCUSSION
Evaluation on synthetic dataThe difficulty to find a reference annotation that could be considered as a gold standard motivated the idea of starting our analysis with a synthetic dataset. Strand-specific datasets of increasing sequencing depth (between 0.025 and 0.4 reads/bp after mapping) were simulated with the Flux simulator v1.2 () using the sequence and annotation of the S.cerevisiae S288C chromosome IV (Supplementary Section S4). The 50 bp-long reads were aligned on the reference sequence with Bowtie 1 v0.12.7 (), allowing only one mismatch in a 5 bp seed (-n 1), and discarding multiple alignments (-m 1). The accuracy of transcriptional landscape reconstruction was assessed from two different standpoints: the number of transcribed positions that can be correctly called based on the estimated value of u t , and the number of transcript 5 0-and 3 0-ends at 550 bp of an identified upshift and downshift, respectively. To establish the lists of predictions, we used a probability cutoff set to 0.5 for both the probability of u t 4 0 and the cumulative probability of shift in the small region delineated by local-score approach. When comparing the predictions with a reference annotation, we needed to take into account that Parseq models the distribution of the 5 0-end of the reads. For this reason, the regions predicted as transcribed by Parseq were extended of l 3 bp on their 3 0-ends, and the same correction needs to be applied to the predicted downshifts before comparing with transcript 3 0ends (adjusted to 50 bp for the simulated dataset). To report results in terms of sensitivity and positive predictive values (PPV) we computed the fraction of the true positives that could be matched to a prediction and the fraction of the predictions that could be matched to a true positive. Parseq predictions were systematically compared with the results of Cufflinks v2.1.1 (), a method for transcript assembly that is based on read overlapping.The results obtained on synthetic data are summarized in. While both Parseq and Cufflinks perform well when the depth of sequencing exceeds an average of 0.12 reads/bp, below this level the differences between the two methods become evident. Even though they do not have the same sensitivity-specificity trade-off, it appears clearly that the results obtained by Parseq are better. The model-based approach adopted in Parseq makes it possible to extrapolate transcription across coverage gaps and this results in a better calling of transcribed positions (not shown) and transcript borders. The mechanistic interpretation of our new emission model is also well supported by the results: Parseq estimation of the amplification coefficient ( a ) distinguishes remarkably well the two scenarios considered in our simulations where sequencing depth increases either as a consequence of higher amplification or as a consequence of higher number of initial molecules sampled.
Evaluation on real dataOn synthetic data, both the model-based approach of Parseq and the read-overlapping approach of Cufflinks perform well at detecting transcribed positions and transcript borders once the sequencing depth becomes high enough (0.12 reads/bp in our simulations). However, despite the efforts made on the simulation pipeline to mimic the different types of artifacts, the synthetic data do not have the complexity of a real dataset. For evaluation on real data, we chose strand-specific singleend datasets from two major model microorganisms: the yeast S.cerevisiae and the bacterium Escherichia coli. The S.cerevisiae dataset was sequenced on a SOLiD platform (Short Read Archive identifier SRR121907) and published in a study on regulatory non-coding RNAs (van). It has a read length of 50 bp and a sequencing depth of 1.6 reads/bp after mapping. The E.coli dataset (SRR794838) was sequenced on an Illumina platform and published together with thepresentation of the Rockhopper workflow for bacterial RNASeq data processing (). It has a read length of 100 bp and a sequencing depth of 2.4 reads/bp after mapping. As a reference annotation for the transcribed positions in S.cerevisiae, we relied on the 5874 coding sequences (CDSs) found in the S.cerevisiae database SGD () and lists of untranslated regions (UTRs) mapped from RNASeq experiments in(5200 5 0 UTRs and 5295 3 0 UTRs). To better assess the accuracy of the prediction of transcripts 5 0-and 3 0-ends, we also included comparison with experimental data that aimed at mapping precisely these sites: 4393 transcriptional start sites (TSSs) (), and 7977 polyadenylation sites (pAs) (). For E.coli, we used annotations available in the RegulonDB database () (2438 promoters and 2647 operons) and also the sequence-based predictions of 2260 rho-independent transcription terminators obtained with Petrin software (d').presents a detailed breakdown of the results according to the different sets of reference annotations, which could be considered to assess accuracy. In this context, we found that the probability of u t 4 0 (expression cutoff 0  ) is not necessarily the most relevant to compare the prediction of transcribed positions with a reference annotation. The best trade-offs are obtained near 0.1 reads/bp on the S.cerevisiae dataset, and 0.25 reads/bp on the E.coli dataset. These values are in agreement with the presence of a large number of positions associated with low expression level, resembling a background noise (Supplementary Figs S6 and S7). The accuracy of the detection of transcribed position is remarkable (e.g. 83% sensitivity, 90% PPV with the 0.1 reads/bp expression cutoff on S.cerevisiae), but similar to Cufflinks (). In keeping with our observations on synthetic data, this suggests that detecting transcribed positions is easy at high sequencing depth, and consequently, the model-based approach implemented in Parseq provides only small benefits.The accurate identification of transcript borders is by far more challenging. For instance, on S.cerevisiae 5 0-ends, with the same 0.1 reads/bp expression cutoff, the sensitivity reaches 64% and the PPV 48%. On E.coli, PPVs remain acceptable, but sensitivity values are much lower. This could be due to a combination of the following: lower quality of the data ( a estimated to 6.15 in E.coli versus 1.18 in S.cerevisiae, adjusted l 3 is 50 bp for S.cerevisiae versus 160 bp for E.coli); lower quality of the annotation taken as reference (e.g. Petrin predictions are expected to contain substantial numbers of false positives and false negatives); higher proportion of genes with low or no expression and thus for which promoters and terminators cannot be detected (with the 0  expression cutoff, sensitivity for detection of transcribed regions is only 0.81 in E.coli versus 0.91 in S.cerevisiae). On both datasets and for 5 0-ends and 3 0-ends alike, Parseq results are consistently better than the ones obtained by Cufflinks, particularly in terms of sensitivity. This confirms our expectations, as Cufflinks reconstruction ignores the possibility of overlapping transcripts and thus overlooks transcript-ends in these configurations. We also included in our comparison the predictions made on E.coli by Rockhopper (). As we were interested here in de novo predictions but this software could not run without annotations, we discarded successively the annotation on one-tenth of the genome and recorded the predictions on it. Parseq and Cufflinks provide results markedly better than Rockhopper in this comparison setup.
Importance of drift and local scalingTranscript borders are detected on the basis of significant changes in read counts. Therefore, high variability in read counts can lead to breakpoint overpredictions resulting in a loss of specificity when not properly incorporated in the model. We palliated this need by introducing two different components in our model: a drift term on the transition kernel for progressive variations as opposed to the abrupt changes modeled by shifts,Predictions and reference data were matched based on a AE50 bp distance cutoff (for a AE25 bp distance cutoff, see Supplementary). Outside parentheses: results obtained after applying a stricter expression cutoff. S.cerevisiae: 0.1 reads/bp for Parseq, 100 fragments per transcript for Cufflinks. Escherichia coli: 0.25 reads/bp cutoff for Parseq, 200 fragments per transcript for Cufflinks, z  0:2 for Rockhopper. Between parentheses: 0  reads/bp for Parseq, 5 fragments per transcript for Cufflinks and z  0:01 for Rockhopper. and a local scaling Markov-dependent variable s intended to capture short-range autocorrelations. By monitoring the accuracy in terms 5 0-and 3 0-ends detection, we assessed the effect of these two model components on the quality of the inference. The results are reported inand confirm that taken individually the drift and the local scaling improve the results. Moreover, the results also demonstrate that the two terms are complementary rather than redundant, as their combination leads to further improvements.
CONCLUSIONThis article presents a model-based approach for analyzing the RNA-Seq read count profiles along the genome. The model aims for an account of artifactual longitudinal variability's sources, via a new model of overdispersion able to capture not only the variance versus mean relationships but also the fraction of zero counts and the short-range autocorrelations. From a methodological standpoint, our work also demonstrates the feasibility of analyzing genome-scale data within the framework of SSMs. The recently described PG algorithm () was instrumental in this success. Running time does not depend on the depth of the sequencing, but is proportional to genome length, which makes it more suited to microbial genomes. The method outperforms a read assembly approach at low sequencing depth, and shows a clear improvement on real data even for high sequencing depth. We believe that the availability of such a tool will become increasingly useful as the use of RNASeq becomes more popular. In particular, the availability of confidence scores and credibility intervals will be relevant to build a reference annotation from a compendium of experiments as done from tiling array data () and also to compare global RNA-Seq profiles with the results of protocols targeting more specifically the sequencing of transcript ends (). In principle, one could also envision to extend the model for situations where data would be collected with distinct RNA-Seq protocols on the same biological sample.
The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
B.Mirauta et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
State-space models for RNA-Seq data at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
