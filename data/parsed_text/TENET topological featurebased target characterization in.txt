Motivation: Target characterization for a biochemical network is a heuristic evaluation process that produces a characterization model that may aid in predicting the suitability of each molecule for drug targeting. These approaches are typically used in drug research to identify novel potential targets using insights from known targets. Traditional approaches that characterize targets based on their molecular characteristics and biological function require extensive experimental study of each protein and are infeasible for evaluating larger networks with poorly understood proteins. Moreover, they fail to exploit network connectivity information which is now available from systems biology methods. Adopting a network-based approach by characterizing targets using network features provides greater insights that complement these traditional techniques. To this end, we present TENET (Target charactErization using NEtwork Topology), a network-based approach that characterizes known targets in signalling networks using topological features. Results: TENET first computes a set of topological features and then leverages a support vector machine-based approach to identify predictive topological features that characterizes known targets. A characterization model is generated and it specifies which topological features are important for discriminating the targets and how these features should be combined to quantify the likelihood of a node being a target. We empirically study the performance of TENET from a wide variety of aspects, using several signalling networks from BioModels with real-world curated outcomes. Results demonstrate its effectiveness and superiority in comparison to state-of-the-art approaches.
IntroductionComplex intra-and inter-cellular signalling drives various biological processes, such as growth, proliferation and apoptosis within systems. In systems biology, these molecular interactions are typically modelled as signalling networks () that provide a holistic view of the various interactions between different molecular players in the system. As signalling networks become an increasingly acceptable way for representing biological systems, various network-based computational techniques have been developed to analyze these networks with the goal ofanswering biological needs, such as target characterization () and target discovery (). In this article, we focus on the target characterization problem for signalling networks. Target characterization identifies characteristics (e.g. topological features) that distinguishes targets (i.e. nodes) from other nodes in the network. These characteristics can be summarized as models which we refer to as characterization models. Traditionally, targets are characterized based on their molecular characteristics [e.g. structure and binding sites of targets (] and biological function [e.g. regulation of apoptosis (. These traditional approaches focus primarily on the target alone and are oblivious to the presence of other interacting molecules in the system. However, understanding how a target interacts with other molecules in a biological system may provide valuable and holistic insights for superior target characterization. For example, the degree centrality of a target may be leveraged to assess potential toxicity of targets as high degree nodes tend to be involved in essential proteinprotein interactions () and are potentially toxic as a result. In particular, network-based target characterization techniques can exploit such topological features for superior characterization of targets. Recently, there have been increasing efforts toward devising network-based target characterization techniques (). These methods focus on using topological features to characterize targets of protein protein interaction (PPI) networks. Specifically,performed characterization of targets in protein coabundance networks [The protein co-abundance networks are essentially proteinprotein interaction (PPI) networks constructed by identifying highly differentially regulated proteins from proteomics data using specific filters.] using several topological features such as degree centrality. Although this study suggests that multiple topological features can be combined for superior target characterization, it did not explore how these topological features should be combined towards this goal. In contrast,concluded that bridging centrality is useful in identifying targets in PPI networks. However, the complexity and diversity of biological networks make target characterization using a single feature challenging as in some networks the chosen feature may perform poorly.showed that bridging centrality performs well in the MAPK-PI3K network, but not in the glucose metabolism network.proposed the use of machine learning techniques such as support vector machines (SVM) and logistic regression for characterizing known targets in a manually curated human PPI network using 15 topological features. In contrast to, their goal was to identify topological characteristics of drug targets in general, instead of for specific diseases. However, characterizing targets in general assumes that targets of different diseases share similar target characteristics, which may not always be true. Indeed, as we shall see in Section 3, known targets in signalling networks tend to be characterized by different sets of topological features. Consequently, target characterization based on individual disease-specific networks may yield better characterization that is specific to the disease. A common thread running through the aforementioned target characterization techniques is their focus on PPI networks. Surprisingly, similar systematic study in curated signalling networks has been lacking in the literature. Compared to signalling networks, PPI networks may contain many false-positive PPI in the sense that although these proteins can truly physically bind they may never do so inside cells due to different localization or they are not simultaneously expressed. Furthermore, PPI networks are static. That is, the edges in PPI networks are undirected; there is neither flow of information nor mass between nodes. Hence, they lack of knowledge of the underlying mechanism (i.e. actual signal flow) causing the disease. As network quality directly affects the results of network-based target characterization, the aforementioned limitations of PPI networks may adversely impact the search for superior characteristics of targets. Signalling networks, however, model the dynamic interaction of the biological systems and present an attractive alternative to PPI networks. In our recent work (), we took the first step to demonstrate how signalling networks can be effectively leveraged to identify topological features that are discriminative of targets using the Wilcoxon test. However, similar to, this work does not shed any insight on a predictive model to combine these features for identifying potential targets. In this article, we address this limitation by presenting TENET (Target charactErization using NEtwork Topology), a network-based approach that characterizes known targets in signalling networks using topological features. Specifically, we use an SVM-based approach to identify the set of topological features (referred to as predictive topological features) that characterizes known targets and to generate a characterization model using these features. The model specifies which topological features are important for discriminating the targets and how these features should be combined to produce a quantitative score that identifies the likelihood of a node being a target. In particular, TENET uses feature selection to select predictive topological features and weighted misclassification cost (WMC) to handle SVM training issues such as noisy labels and imbalanced data. Our empirical study on four real-world curated signalling networks demonstrates the effectiveness and superiority of TENET.
Materials and methods
TerminologyA biological signalling network can be modelled as a directed hypergraph G  V; E () where the nodes V represent molecules (e.g. proteins) and the hyperedges E represent biochemical reactions and processes. A hyperedge connects one node set U to another W, where U; W V. For instance, in the activation of ERK, the set U in the hyperedge consists of ERK and its kinase, phosphorylated MEK whereas W contains the phosphorylated ERK (ERKPP). Analysis of directed hypergraphs is generally more complex than graphs and many graph algorithms cannot be used directly on hypergraphs. Hence, they are often transformed into graphs containing simple edges for analysis. Methods (e.g. bipartite and substrate graph representation) exist for such transformation (). In this article, we use the bipartite graph representation as it retains the original information of the hypergraph (). Signalling networks generally contain characteristics such as feedback and feedforward loops, which are common in complex regulatory control (). These loops in turn give rise to graph characteristics, such as strongly connected components (SCC). The activity of nodes in the signalling network is generally governed by complex interconnectivity of various nodes in the same network. We refer to a node as a candidate target if when perturbed, it modulates the activity of a specific node (referred to as output node). An output node is a protein that is either involved in some biological processes which may be deregulated, resulting in manifestation of a disease, or be of interest due to its potential role in the disease. For instance, in the MAPK-PI3K network () that is often implicated in cancer, ERKPP can be considered as an output node due to its role in proliferation. Given a signalling network G  V; E and an output node x 2 V, let the set of nodes having a path leading to x be denoted as V x V. Then, the set of candidate target nodes in G relevant to x is denoted as T x V x. Network-based analysis can be applied to signalling networks to study the characteristics and properties of these networks. In this article, we examine a total of 16 topological features that are summarized in. These features are selected based on their role in measuring relative importance of a node in a signalling network. The formal definitions as well as motivation for selecting these features are given in(also detailed in Supplementary Material S1.1).
Topological feature-based target characterizationIntuitively, the goal of topological feature-based target characterization is to use a set of predictive topological features to characterize known targets in a network. Hence, the topological featurebased target characterization problem can be formulated as a supervised learning problem. In a supervised learning problem, a training set fhx i ; f x i ig is given where f x i  is the predictor of x i and the goal is to learn some target function f : X ! Y which can be applied to predict unseen data w. The problem can be subdivided into two categories: regression when the predictor yields a continuous outcome and classification when the outcome is discrete. A regression problem can be converted into a binary classification problem by specifying a threshold h and assigning x i with f greater than h to one class and the remaining to the other class. We advocate that the topological feature-based target characterization problem is best represented as a regression problem. In this problem, we are interested in finding out how likely one node is a target relative to another node based on a set of predictive topological features. This is different from the target classification problem where we want to find out the class membership of a node. Note that the regression problem can be converted into a classification problem by specifying a threshold h and assigning nodes having target function greater than h to the target class and the rest to the non-target class. Although we examine 16 topological features, as we shall see later, not all features are relevant to a given signalling network. In fact, incorporating irrelevant features may adversely impact the performance of the prediction model. Hence, it is important to learn a set of predictive topological features that best characterizes targets (referred to as topological feature selection) for a given network. Formally, it is defined as follows.
Definition 1:Given a signalling network G  V; E and an output node x 2 V, let T x V and X all denote the set of known targets in G relevant to x, and the set of topological features of G, respectively. Then, the goal of 'topological feature selection' is to find a set of 'predictive topological features' F X all that maximizes the prediction accuracy for f nu; F  subject to the following conditions: f nu; F   1 when u 2 T x ; f nu; F   0 otherwise:Then the topological feature-based target characterization problem is formally defined as follows.
Definition 2:Given a signalling network G  V; E, an output node x 2 V, T x , and X all , let F denote the set of predictive topological features. Then, for a threshold h, the goal of the 'topological feature-based target characterization problem' is to identify a set of predictive topological features F X all using topological feature selection and learn a 'characterization model' gnu; F  subject to the conditions gnu; F  2 <; gnu; F !h when u 2 T x ;gnu; F  < h otherwise;that maximizes the target prediction for gnu; F .depicts a pictorial overview of the topological featurebased target characterization problem. For example, given the MAPKPI3K signalling network, its associated output node ERKPP, the set of known targets in this network and the topological features in, the goal of this problem is to produce the followings: (i) identify the set of predictive topological features F  fd; p; h in ; h out g and (ii) learn a characterization model g(n(ERKPP, F . Note that in Definition 2, there is no need to explicitly specify a threshold h if we are only interested in obtaining the relative rankings of the nodes. The threshold is required if we want to assign class labels (e.g. target class) to the nodes.
SVM-based target characterizationWe employ support vector classification (SVC) to select predictive topological features and support vector regression (SVR) to generate the characterization model. The SVC and SVR are typically formulated as constrained optimization problems and solved using the Lagrangian multiplier method. In general, SVM models contain multiple parameters, such as the cost parameter C and parameters related to the kernel function, that affect the learning and performance of the models (). We follow the method infor training the SVM. The feature values are scaled linearly to the range offor each signalling network to avoid features with larger ranges dominating those with smaller ranges. We use stratified (The training data were sampled from the original data such that the ratio of the targets to non-targets is similar to that of the original data.) cross-validation (Supplementary Material S1. 3) and grid-search () on the training data to identify the best values of the model parameters. Note that cross-validation helps us to avoid the issue of overfitting the data whereas stratification enables us to keep the percentage of targets in the different folds similar to the original dataset. The best parameter is the one that yields the best average prediction accuracy for the cross-validation process. Wherever possible (In our study, we set a lower bound ofDegree centrality of node u. The in, out and total degree centralities are denoted as h inu ; h outu and h totalu , respectively a u Eigenvector centrality of node u b u Closeness centrality of node u c u Eccentricity centrality of node u d u Betweenness centrality of node u p u Bridging coefficient of node u f u Bridging centrality of node u j u Clustering coefficient of node u. The undirected, in, out, cycle and middleman clustering coefficients are denoted as j undiru ; j inu ; j outu ; j cycu and j midu , respectively l u Proximity prestige of node u x u Target downstream effect of node u one target in all our test sets.), we use a 10-fold stratified crossvalidation as larger fold numbers reduce pessimistic bias and 10-folds generally give good performances (). Several non-trivial issues, namely, irrelevant or redundant features, noisy labels and imbalanced dataset, need to be addressed in training the SVM model for characterizing targets. In particular, we use feature selection to select for appropriate features to be used in the SVM model and cost-sensitive learning to handle the issue of noisy labels and imbalanced dataset. We examine three feature selection approaches, namely, backward stepwise elimination (BSE) (), Wilcoxon-ROC based elimination (WRE) and WRE-BSE. BSE is classifier-aware whereas WRE is classifierindependent. WRE-BSE which performs WRE followed by BSE is a hybrid approach. Note that compared to classifier-independent methods, classifier-aware methods interact with the classifiers and such interaction can lead to better classification results (). However, they are typically computationally expensive and run the risk of model-overfitting. Cost sensitive learning is an algorithmic approach that chooses an appropriate strategy specific to the classifier to overcome the bias introduced by imbalanced data and the noise caused by uncertainty in labelling. We use WMC, an approach that proportionates the misclassification cost of the training data according to class. In particular, we use a variable C i as the cost parameter C:subject to the constraints C   C   1; C  > 0 and C  > 0 where y i is the class predictor and C  and C  denote the misclassification cost of the target and non-target classes, respectively.
The TENET algorithmGiven a signalling network G  V; E, an output node x 2 V, a known target set T x V, a set of topological features X all and a step-size of the misclassification cost s, TENET identifies the set of predictive structural features and a characterization model that best characterizes these known targets. Note that X all and s are optional inputs and are set to default values (X all is set to the 16 topological features given inwhereas s is set to 0.1.) if they are not given. The known targets T x can be extracted by following the curation process described in(Supplementary Material S1.2). The TENET algorithm comprised three phases, namely, the pruning phase, the feature extraction phase and the model training phase. First, the pruning phase identifies relevant nodes (denoted as V candidate ) that shall be used for training the SVM. Then, the feature extraction phase extracts all the topological features (denoted as X all ) of each candidate node and stores them in a jV candidate j  jX all j matrix H. Finally, in the model training phase, TENET learns the optimal set of predictive topological features F and the best model parameters of the characterization model M.We shall now describe these phases in turn. The formal algorithm is given in Supplementary Material S1.4.
Phase 1: PruningIn this phase, TENET prunes nodes that do not have paths leading to the output node x. This phase yields a set of potential candidate nodes V candidate & V and is used to reduce the subsequent computation. In the pruning process, the given network G is first preprocessed into a bipartite graph and then converted into a directed acyclic graph (DAG), a graph with consistent topological ordering, to facilitate indexing of nodes. Note that the node indices shall be used subsequently to perform reachability check to identify the nodes to be pruned. We adopt the method infor bipartite graph conversion. In order to convert the bipartite graph into its DAG representation, we adopt the approach into identify SCCs and replace each SCC with a representative node (referred to as meta node). Then, we adopt the indexing approach ofto index the DAG. This indexing approach performs depth-first traversal to assign each node v a preorder index (when v is first visited) and a postorder index (when all descendent nodes of v are visited). Finally, an index-based reachability algorithm is used to determine whether there exists a path from each node v to the output node x (denoted as v ! x). Given a node v and x, let w be the descendent of v that is not in the spanning tree (referred to as non-spanning tree node) and v.preorder and v.postorder denote the preorder and postorder indexes of v, respectively. A path v ! x exists if any of the following conditions are satisfied (): 1. v:preorder x:preorder and v:postorder ! x:postorder. 2. w:preorder x:preorder and w:postorder ! x:postorder.Note that the pruning step is beneficial in improving execution time for larger sparsely connected networks and for output node that are positioned further upstream. For instance, in the MAPK-PI3K network, no nodes are pruned when we select ERKPP (downstream) as the output node whereas 17 nodes (47.2%) are pruned when activated Ras (RasGTP) (upstream) is selected.
Phase 2: Feature extractionIn this phase, for all nodes in V candidate , TENET extracts all the topological features infor characterizing the known targets.
Phase 3: Model trainingGiven a matrix of topological feature values H, a target set T x and a step-size of the misclassification cost s, this phase identifies a set of predictive topological features F and the best parameters for configuring the characterization model M. First, the misclassification cost of the target class C  is initialized to a default value of 0.5. Then, feature selection is used to obtain the predictive topological feature set F. We iterate over three different feature selection approaches (BSE, WRE and WRE-BSE). Next, the step-size s is used to step through the range of misclassification cost (01). In each iteration, the misclassification cost of the target class C  is incremented according to the number of iterations completed, before the SVM training is performed to obtain the parameter settings of the characterization model M with the best accuracy. The BSE approach is a well-known greedy approach that progressively removes features from the navenave SVM model (built using all topological features) and trains a new best model after each feature removal. The elimination process stops when removal of additional features results in a worse average accuracy of the validation setprediction. In contrast, the WRE approach performs two statistical tests, namely, one-tailed Wilcoxon Rank-Sum (referred to as Wilcoxon) and receiver operating characteristics (referred to as ROC). The results are used to eliminate features that do not discriminate between targets and non-targets in a significant manner (based on Wilcoxon) and that do not classify targets well (based on ROC). Note that we perform two 1-tailed Wilcoxon tests and for each test; P-values smaller than 0.05 are considered significant. Hence, we take the difference of the P-values for both test hypotheses (referred to as P-value difference) and remove features with P-value difference less than 0.9. For the ROC analysis, features with AUC less than 0.7 () are considered poor performers and are removed. The best characterization model is found by training the SVM using the remaining features.
Results and discussionTENET is implemented using Java. We shall now present the experiments conducted to study the performance of TENET and report some of the results here (additional results are given in Supplementary Material). The experiments are performed on a computer system using a 64-bit operating system with 8 GB RAM and a dual core processor running at 3.60 GHz. We characterize four signalling networks (referred to as individual networks) in BioModels (I 1 I 4 in) and a combined network that is generated by iteratively performing a union of the nodes and edges in individual networks. The resulting combined network is a graph consisting of four disconnected (The node and edge sets of the individual networks are disjoint.) subgraphs, each representing one individual network. For the combined network, we use each of the signalling network as the test set in turn (C 1 C 4 in) and examine the effects of generating characterization models from individual networks and from the combined network. Pruning in TENET is performed on each individual network within the combined network. Supplementary Material S1.3 describes the generation of the training and test data. Note that in all our experiments, we use the linear kernel as it yielded the same accuracy as other kernels but is faster to train (Supplementary Material S1.7.1). We study different variants of TENET () by varying the SVM training approach.
Performance metricsWe evaluate the performance of TENET based on prediction accuracy [The accuracy for the validation and test sets are denoted as / X val and / X test, respectively, where X indicates the method used for training the SVM model. Average prediction accuracy is denoted as /](/), sensitivity (TPR), specificity (TNR) and precision (PPV) of the generated characterization models using the same training and test set. The definitions are as follows: / tptn tptnfpfn , TPR tp tpfn , TNR tn fptn and PPV tp tpfp where tp; tn; fp and fn denote true positive, true negative, false positive and false negative prediction, respectively. Note that PPV is set to 0 when the classifier did not make any positive prediction. We include an additional metric feature reduction factor (FRF) to compare the performance of the feature selection methods. Formally, FRF  1 jF j X all where X all is the entire set of features considered in the study. The performance of different characterization models is compared using an integrated performance score (This score can be modified according to the needs of the application.) P  X m2M val m where M  f/val; /test; TPR, TNR, PPV} and val m is the value of metric m. Note that a larger score indicates better performance.
Feature selectionFirst, we examine the performance of different feature selection approaches (TENET-B, TENET-R and TENET-H) and compare it with TENET-navenave for different signalling networks. Note that in this set of experiments, we study the effect of the feature selection approaches in isolation. The effect of incorporating WMC into theNo
TENET
Effect of varying WMCIntuitively, when we vary the WMC, we expect that as the target misclassification cost C  increases, the prediction accuracy, sensitivity, specificity and precision would display a negative skewed, increasing, decreasing and positive skewed distribution, respectively. This is because a large C  eventually results in a model that is likely biased towards classifying data as targets. We noted the following when the WMC was varied. First, amongst the individual networks, only I 3 () displays the expected trends. This could be due to the extreme small target size (1 or 2) in the test set that resulted in extreme fluctuations in the performance metrics and deviation from the expected trends. Hence, the target size of the test set can have significant impact on the observed results. Second, the performance of the combined networks C 1 , C 2 and C 4 (Supplementary Material S1.7.2) resembles that of I 3 , possibly due to the large size of I 3 dominating over other networks used for training. This implies large training networks can have undue influence on the characterization model. Third, sensitivity generally improves whereas specificity generally deteriorates when the target misclassification cost is set higher than the non-target misclassification cost (C  > C  ). The choice of an appropriate model depends on the application. Fourth, the prediction accuracy tends to display a skewed distribution where accuracy initially increases (or remains constant) with increasing C  , and then decreases with increasing C . Fifth, individual networks and combined networks behave differently. In individual networks, prediction accuracy, sensitivity and precision generally improve when C  is set larger than C . However, in combined networks, sensitivity improves whereas other performance criteria deteriorate when C  is set larger than C . Hence, there is no single universal best value of C  and the choice of C  depends on the network.
Best TENET variantWe identify the best TENET variant () using the integrated performance score P. We note the following. First, the best TENET variant is network dependent. Second, variants incorporating both WMC and feature selection generally perform well. Specifically, setting C  greater than C  led to better results. Third, TENET variants based on individual networks (I 1 to I 4 ) outperform that based on combined networks (C 1 C 4 ). The poorer performance of the combined networks may be due to insufficient number of training networks, inappropriate or insufficient features used for training or that signalling networks by nature have distinct characteristics and it is just not possible to have a generalized model. Finally, the predictive topological features differ across networks (Tables 4 and 5). Hence, as we mentioned in Section 1, a single set of predictive topological features may not effectively characterize known targets in all signalling networks. When we compare the results with that in our previous work, we note that the set of predictive topological features is different from the discriminative topological features (DTF) identified inalthough there was an overlap of at least 50% of the features (We consider only I 1 to I 3 and exclude I 4 from this comparison as no DTF was found at P-value less than 0.05). The difference is due to the different approach used to identify the features. The characterization models (We use SVM with WMC and WRE to generate the characterization models.) generated by these DTFs also yielded poorer average ROC (0.873) than that generated using TENET (0.913) (Approach DIFFER in).0.820.7470.90.7340.7110.5610.757/test10.90.80310.6940.780.7240.609TPR110.90510.40.50.6020.313TNR10.8890.7510.8080.8110.7880.767PPV10.50.65510.4440.2310.5930.471Note:To the best of our knowledge, there does not exist any target characterization technique for signalling networks. However, one way to investigate the performance of TENET is to examine how well the characterization model generated by it prioritizes known targets. Intuitively, target prioritization aims to rank the nodes according to their potential of being a target based on some importance measures (e.g. gene expression level;). A more detailed exposure to the target prioritization problem as well as how TENET is used to prioritize known targets is given in Supplementary Material S1.6. For our study, we compare TENET with several network-aware target prioritization approaches, namely, random prioritization, LSA () and NetworkPrioritizer (). Comparison with network-unaware techniques as well as PPI network-based techniques is reported in the Supplementary Material S1.7.3 and S1.7.4, respectively. In random prioritization, the nodes were randomly assigned a rank in the rangewhere jVj is the number of nodes in the network and we assume that no ranking ties are present. LSA was performed using Copasi () with the following configuration: {tasksensitivities; subtasktime series; functionall variables of the model; and variableall parameter values}. We consider both Weighted Borda Fuse (WBF) and Weighted AddScore Fuse (WASF) in NetworkPrioritizer and consider all features provided. Note that uniform weights were used for rank aggregation as we do not have prior knowledge of the best weights or features to consider. For TENET, we use the characterization model to generate prioritization ranks of known targets. Specifically, we apply the SVM models to obtain these ranks. The SVM type is set to-SVR [In-SVR, the error function is an-insensitive loss function and error smaller than is ignored (with default value (1  10 3 ) and the SVM parameters are set according to the best models for each network (and Supplementary Material S1.7). Note that the nodes are ranked in decreasing order of the regression score and higher ranked nodes are more likely to be targets. The experimental results reveal that the normalized ranks (The normalized rank of a node u for a particular approach x is defined as W normx:u  Wx:u maxi2VWx:i .) of a given node vary widely using different approaches (Supplementary Material S1.7.5). Hence, an approach that performs better for one particular network can perform poorly in another. We further perform ROC analysis based on the rankings of the nodes in the test set for each network. From, we observe that TENET outperforms other approaches in terms of the quality of the prioritization results, particularly for individual networks, and is comparable in terms of runtime performance when SVM training is performed offline
ConclusionsWe propose TENET, an SVM-based approach that characterizes known targets in signalling networks using topological features by identifying a set of predictive topological features and using them to generate a characterization model. TENET uses feature selection to remove redundant features, thereby improving prediction accuracy of the characterization models and WMC to improve other performance criteria (e.g. sensitivity). Our empirical study reveals that the characterization models generated by TENET outperform state-ofthe-art approaches in prioritizing signalling and PPI networks. In summary, the contribution of this work is a machine learning-based framework that affords flexibility in characterizing signalling networks of different sizes and with different number of known targets. Although TENET is evaluated on a small (Manual target curation, a time-intensive process, is needed to identify known targets of signalling networks for validating our experimental results.) number of signalling networks, it can easily incorporate additional signalling networks without any modification to the framework. As part of future work, we intend to explore how the characterization models learnt by TENET can be leveraged for target prioritization of signalling networks with unknown targets.
FundingThis work was supported in part by a Singapore MOE AcRF Tier 1 Grant RGC 1/13 to SSB and by a Duke-NUS block grant to LTK. Conflict of Interest: none declared.Approach TENET TENET (Regression only) Random LSA WBF WASF DIFFER DIFFER (Regression only)
References
Fig. 4. Performance of different prioritization approachesTENET
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
H.E.Chua et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
SVM shall be investigated later. Table 4 reports the predictive feature sets for each network using different approaches. In total, 24 experiments were conducted as there are three feature selection methods and eight networks (I 1 I 4 and C 1 C 4 ). Amongst these 24 experiments, 25% of the predictive feature sets consist of only one feature whereas the remaining had multiple features (ranging from 4 to 15 features). This supports our previous observation (Chua et al., 2014) that multiple features result in better prediction of known targets. Observe that in Table 4, bridging centrality is not always in the predictive feature set (e.g. I 2 ). Figure 2 plots the performances of different feature selection approaches. We can make several observations. First, no single approach performs consistently well on all performance metrics. In fact, network topology plays an important role in feature selection. For instance, I 4 has extremely high density of edges (ratio of edges to nodes) compared to other networks. The connectivity features of such networks become less informative and other features such as target downstream effect become more important. Hence, the most appropriate feature selection approach is dependent on the signalling network. However, we note that for larger sized networks, a larger number of features are informative (regardless of feature selection approach). This is perhaps because larger networks provide greater richness of context and diversity of structure in the sub-networks. As network sizes are growing and network analysis demands applicability to larger networks, future methods might benefit particularly from the use of multiple features. Second, feature selection generally led to an improvement in prediction accuracy (87.5% for validation dataset and 50% in test dataset) over the navenave approach. An exception is C 4 in which feature selection resulted in poorer performance. In C 4 , the characterization model is generated using I 1 , I 2 and I 3 as training data whereas I 4 is used as the test data. The characteristics of the known targets in the training data may be quite different from that of the test data. Indeed, from Table 4, we observe that bridging coefficient p is included in the predictive topological feature set of C 4 , but not in I 4. Including redundant features may lead to poorer performance. Third, the models generally have high specificity due to imbalanced dataset. Fourth, TENET-R has the best runtime performance, followed by TENET-H and TENET-B. The poorer performance of TENET-B is due to the interaction of the feature selection approach with the classifier (classifier-aware approach) which is different from TENET-R where the feature selection approach is a wrapper layer that sits on top of the classifier. Finally, the size of the networks used for training affects the runtime performance. In general, larger size networks require longer runtime. In the Supplementary Material S1.7.6, we report TENET's performance on the human cancer signalling network containing more than 2500 nodes.
