Motivation: Determining the fraction of the diversity within a microbial community sampled and the amount of sequencing required to cover the total diversity represent challenging issues for metagenomics studies. Owing to these limitations, central ecological questions with respect to the global distribution of microbes and the functional diversity of their communities cannot be robustly assessed. Results: We introduce Nonpareil, a method to estimate and project coverage in metagenomes. Nonpareil does not rely on high-quality assemblies, operational taxonomic unit calling or comprehensive reference databases; thus, it is broadly applicable to metagenomic studies. Application of Nonpareil on available metagenomic datasets provided estimates on the relative complexity of soil, freshwater and human microbiome communities, and suggested that $200 Gb of sequencing data are required for 95% abundance-weighted average coverage of the soil communities analyzed.
INTRODUCTIONMetagenomics have provided important new insights into the diversity, dynamics and functional potential of natural microbial communities during the past decade, but several critical issues remain unresolved. Many metagenomic surveys to date have sampled only a small fraction of the total community DNA; this is particularly the case for soil and sediment communities. Furthermore, the amount of sequencing required to cover the whole community remains speculative (). The fraction of the genomes recovered in a sequencing dataset is termed coverage (Supplementary Box S1), and depends on the sequencing effort applied and the diversity of the community. When the coverage of a metagenome is unknown, results and conclusions about species richness, the evenness of the corresponding community, differences between communities and the extent and importance of rare community members are limited. Moreover, differences between sequencing technologies and continuously changing sequence read lengths make it challenging to establish a universal approach for coverage estimation. Determining the total number of unique species or operational taxonomic units (OTUs) present in a sample is frequently challenging due to the unknown number of non-sampled species and requires either complete coverage or knowledge of the species abundance curve, which typically remains elusive. The coverage achieved by a dataset can be calculated more efficiently, as it does not depend on a priori knowledge of the species abundance curve, and can be directly related to assembly quality (). The level of coverage is typically assessed by identifying and counting OTUs and generating rarefaction curves (). Empirical and analytical models have also been applied to coverage estimation using read binning () if assembly is not limiting or by targeting specific taxa () when genome size and abundance are known. However, these approaches and their variations () require either the use of a reference genome database or the clustering of reads in contigs or OTUs. The former is severely limited by the shortage of representative genome sequences from most habitats (). The latter is limited by the quality of the assemblies, especially for highly complex communities, and the use of genes that are much more conserved than the genome average to be sufficiently similar to allow clustering of reads in OTUs such as the ribosomal RNA genes. These genes, however, are known to miss important levels of ecological differentiation among closely related, yet distinct, OTUs (). Therefore, a method to estimate the coverage of a metagenomic dataset that is applicable to communities of varied diversity and does not depend on the quality of the assembly and the completeness of reference databases is highly desirable. Here we introduce Nonpareil ('having no match or equal', referring to the count of unmatched reads in a dataset), a novel method that aims to fulfill this critical gap in contemporary metagenomic research. Nonpareil examines the degree of overlap among individual sequence reads of a whole-genome shotgun (WGS) metagenome to compute the fraction of reads with no match, which is used to estimate the abundance-weighted average coverage (i.e. not the arithmetic mean based on all species in the sample but the average when the abundance of species is considered). Subsequently, it fits a projection line to the estimated values to determine the amount of sequencing required for almost complete diversity coverage. The fraction of unmatched *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com elements in a given subset of a finite collection (singletons in clustering terms) can be used to efficiently estimate the coverage of the collection, i.e. the fraction of the collection captured in the subset (). This observation has been previously applied to metagenomic datasets to estimate species richness (), functional coverage () and coverage of gene amplicons () based on ribosomal RNA or other individual genes. To the best of our knowledge, Nonpareil is the first method directly applying this concept to the whole-genome level, without using reference markers. Further, we propose that Nonpareil projection curves serve as a semi-quantitative proxy to the diversity of the communities. This feature is explored to rank natural communities in terms of the degree of their diversity.
METHODSOur method relies on the observation that datasets with higher coverage are more redundant because the sequencing reads are nearly random, although some systematic biases have been noted for specific sequencing protocols (). Redundancy is defined here as the portion of reads in a dataset that match with at least one other read (redundant reads; redundant portion is denoted ). Calculating this value is computationally expensive because it requires a number of paired comparisons asymptotically equal to a quadratic growth (in the worst case, where no two reads match). This is a prohibitive calculation, even for powerful computers, for real-size sequencing datasets that are composed of millions of sequencing reads. Instead, Nonpareil estimates the redundancy value by generating a sample of query reads from the entire dataset (query subset), after which the number of matches per query read in the entire dataset is calculated. For each query read, the total number of matches in the complete dataset is calculated and stored (match-vector;). Based on the concept of the collector's curve, a saturation function of the redundancy is subsequently produced (), by iteratively sampling the match-vector in two steps. First, a subset of query reads is selected with a Bernoulli trial per read (with parameter equal to the sampling portion). Next, for each selected query read, the probability of matching another read in the sample is estimated following a binomial distribution, i.e. the number of expected matches of the read in the sample decreases proportionally to the size of the sample, as described in Equation (1).Where m is the number of redundant reads in the subsample, n is the number of reads in the sample, p is the probability of finding a redundant read in the entire dataset, M is the number of redundant reads in the entire dataset, N is the total number of reads in the entire dataset and portion is the sampling portion of the entire dataset used for the estimation. This technique prevents redundant comparisons between reads because all comparisons are precomputed once, allowing the calculation of a Nonpareil curve with high resolution (i.e. with sampling portions close to each other). More importantly, it allows multiple replications at each sampling portion (1024 times by default), reducing the effect of randomness in sampling. The resulting function is next summarized (calculating the average, median and standard deviation at each sequencing effort) to estimate the average coverage (). Finally, a log-gamma regression is fit to the calculated redundancy values with the weighted NL2SOL algorithm (). The projected regression line allows for calculation of the sequencing effort required to reach a fixed average coverage. Nonpareil includes additional optimizations to further decrease the running time and required resources for estimating the redundancy values of datasets of several million of reads on a personal computer, as described later in the text.
Pairwise read comparisonNonpareil performs ungapped alignments between reads using a sliding sequence approach that is included in the source code. The alignment strategy aims to match a prefix of the first sequence to a suffix of the second and vice versa. The search space is constrained by the minimum read overlap, excluding comparisons too short to satisfy the threshold, and by minimum identity (default is 95% nucleotide identity; see later in the text), discarding comparisons once the number of allowed mismatches is exceeded. Two sequences are considered redundant (matching pair) if they have at least one alignment satisfying both the minimum overlap and the minimum identity in any strand orientation. Ungapped alignments were preferred because the search space is much smaller than that of gapped alignments, with significant improvements in computation, whereas insertions and deletions between highly identical sequences (i.e. 95% nucleotideThe gray arrow indicates the point where the fitted Nonpareil curve reaches 95% average coverage identity or higher) occur at a low frequency. Further, the new sequencers such as the Illumina MiSeq and HiSeq platforms show low rates of insertion and deletion sequencing errors, i.e. 50.01% (). Finally, sliding sequences are meant to detect overlapping sequencing reads originating from the same genomic region (), as opposed to reads with high overall similarity (global alignments) or sharing regions that are not necessarily terminal (local alignments).
Simulated datasets used in this studyTo benchmark our method and resolve the numeric relationship between the redundancy value () calculated by Nonpareil and the average coverage (C) of a dataset, we generated 120 training datasets by sampling publicly available complete bacterial and archaeal genomes from NCBI's GenBank database uniformly at random (independently of their length and nature). For each dataset, we selected a variable number of genomes, ranging from 1 to 1262. We generated 13 additional datasets using only 282 genomes from Escherichia coli, Yersinia pestis, Helicobacter pylori and Staphylococcus aureus to simulate environments with low species richness and phylogenetic diversity, but high intraspecies diversity (termed hereafter 'Low richness'). Finally, we produced 10 datasets using 130 genomes from the genus Escherichia, simulating environments with extremely low phylogenetic diversity (termed 'Escherichia'). We randomly assigned an abundance value to each genome in the sample from an exponential distribution (  1) and produced a number of reads from each genome relative to that value. To produce Illumina-like reads, we randomly selected positions in the genome from a uniform distribution and generated a 101 bp-long read from either strand with randomly introduced sequencing errors from a binomial distribution (P  0.01, n  101). We used the resulting training datasets to evaluate the correlations between Nonpareil indices ( and R*) and estimate the average coverage and required sequencing effort for nearly complete coverage (Supplementary) in log-log space.
Sequencing depth and coverage estimationTo estimate the coverage of a genome within a training metagenome (generated in silico), we backtracked the reads generated from the genome, regardless of the amount of error or the orientation of the reads, and divided the number of covered positions by the genome length. Note that coverage (C) and sequencing depth (; see Supplementary Box S1) share a close relationship, generally approximated through the LanderWaterman equations (Lander and), Equation (2).Where LR is the average read length times the number of reads (i.e. the sequencing effort), is the abundance of the target genome, is the length of the genome and is the sequencing depth. To estimate the sequencing depth of a given genome], we simply divided the added length of the reads originating from the genome (T) by its length (). Note that Equation (2) implies that the number of reads (T) equals the abundance times the number of reads in the dataset (R).Accordingly, we defined average sequencing coverage of a sample as the sum of the sequencing depth of each genome ( i ) multiplied by its sequence probability [ i ;].For simplicity, this estimation does not take into account nonobserved species because no assumptions about the distribution of abundances of those can be made without additional information. However, species under the detection level are expected to only marginally affect the estimation of both the average coverage and the average genome size because the contribution of each species (i) depends on its abundance ( i ). In cases where the coverage is extremely low, the contribution of non-observed species to the total community can be relatively high, causing unreliable estimates. Nonpareil automatically identifies datasets with estimated coverage below 10 5 or with median redundancy of zero in 20% of the subsample and reports them as insufficient data. Although available approximations might provide marginally better estimations of the average sequencing depth (), they rely on assumptions about the shape of the distribution of abundance, which may be unrealistic.
Estimation of sequencing efforts for nearly complete coverageTo estimate the amount of reads needed to attain a nearly complete coverage of a simulated community/sample, we used Equation 1 to estimate the number of reads necessary to cover 95% of every target genomeWe define here the sequencing effort required for nearly complete coverage of a community (R * ) as the expected number of reads necessary to produce an average coverage of at least 95% of the genomes in all sampled cells.
Nonpareil curve construction and model fittingFor any given dataset, the Nonpareil curve is defined as the average coverage (estimated from the portion of reads that is similar to at least one other read in the sample; ) as a function of the sample size (LR). Two reads are assumed to be similar if their ungapped alignment shows similarity and length coverage above user-defined thresholds. Here, we used 95% nucleotide sequence identity, intended to reflect natural discrete populations and current species demarcation standards (Caro) and exceed typical sequencing error (); and three values of alignment length: 25, 50 and 75% of the length of the shortest read. Although we observed that 50% overlap is generally optimal for most datasets, comparisons with 25% overlap should be preferred in extremely low coverage datasets that may be challenging to analyze with 50% overlap. On the other hand, comparisons with 75% overlap may produce fast preliminary results, suitable for high coverage datasets (the longer the overlap, the faster the computation of ). The Nonpareil curve has a dual purpose. First, it shows the portion of redundant reads in the entire dataset, reflecting the coverage of the dataset. Second, it allows a projection from the data in hand to the sequencing effort required to achieve any user-defined portion of redundancy, reflecting the complexity of the sample. To perform the projection, the Nonpareil curve is fitted to the cumulative probability function of the gamma distribution [with log-transformed values of the sequencing effortWhere  is the gamma function, is the lower incomplete gamma function (both explicitly noted in the rightmost part of the expression), is the redundant portion (coordinate axis in the curve), R is the sample size (ordinate axis in the curve) and a and b are parameters that determine the shape and rate of the curve, respectively, estimated using the weighted NL2SOL algorithm ().
ImplementationWe implemented the Nonpareil algorithm in C with an ancillary R script for model fitting and plotting, using only standard C and R libraries. The software parallelizes the read comparisons and sampling steps with an arbitrary number of threads. To reduce the number of hard drive access requests without compromising memory efficiency, blocks of reads are loaded into memory with a maximum random-access memory (RAM) usage defined by the user. This allows the software to run with modest minimal requirements, while ensuring scalability in highperforming computers.
Real metagenomic datasetsWe generated Nonpareil curves for a collection of metagenomic datasets from different environments and levels of diversity. In all cases, we used Nonpareil with default parameters: sequence identity of 95% and read overlap of 50%. We considered the acid mine drainage (AMD) dataset as an example of a community with extremely low phylogenetic diversity (). The sample from site C75 (July 2011), was composed of only Leptospirillum sp. group II genotype III, and 5% and 1% subsets of this sample were used to calculate the Nonpareil curves. The genome length of Leptospirillum sp. was assumed to be 2.6 megabase (Mb; added length of the scaffolds from GenBank entry AIJM00000000) to calculate both the expected coverage and the expected number of reads required to achieve nearly complete coverage. We analyzed six selected datasets from the Human Microbiome Project, or HMP (), for which both WGS and amplified 16S ribosomal RNA gene (16S) sequencing data were available (Supplementary). To compare Nonpareil results with a 16S-based estimation, we employed COVER with default parameters () to predict the abundance (corrected by 16S copy number) and the genome size of the OTUs in the community from the 16S amplicon data, and used this information to calculate the average sequencing depth and the required effort for nearly complete coverage of the community (Supplementary). COVER reports the sequencing effort required to achieve a given coverage or a given sequencing depth in the top-n OTUs, but we employed the estimation of R* on Equation (6) (based on abundance and genome length predicted by COVER) to allow comparisons with our method. We also used OTU tables () based on 16S data from http://www.hmpdacc.org/ () to independently assess abundance distributions and Chao1 indexes (). All datasets were trimmed using Solexa QA () with maximum expected error of 1% and minimum length of 50 bp. In paired-end samples, only the forward reads were used.
RESULTSNonpareil curves were calculated for 143 short-read simulated metagenomes of various size and diversity levels, generated from publicly available bacterial genomes. Nonpareil estimates of the average coverage of each metagenome correlated strongly (Pearson's R 2  0.93, n  126) with the independently calculated coverage values based on the known composition of each metagenome. Further, the amount of sequencing that was required to nearly cover the total diversity predicted by Nonpareil (abundance-weighted average coverage of 95% for the genomes in the sample) corresponded tightly to the actual values for each metagenome (Supplementaryand S2 and Supplementary; Pearson's R 2 40.65). The estimated abundanceweighted average coverage may also serve as an indicator for the expected quality of the metagenome assembly. Although several factors other than the coverage are critical for assembly, our results show that the average coverage provides a lowerbound estimation of the fraction of assembled reads (Supplementary), while the assembly N50 of samples with coverage below 60% rarely surpasses twice the read length for Illumina datasets (Supplementary). It is important to note that the precision of the algorithm was reduced at values of redundancy () lower than 1% and higher than 90%. These values approximately correspond to50.01X and 4400X sequencing depth, respectively (Supplementary). Because datasets with lower sequencing depth than 0.01X (i.e. too few sequences obtained) are strongly influenced by random variability and thereby subject to spurious results, Nonpareil estimates are not reliable at this range and such datasets are flagged accordingly in the output of the algorithm. Conversely, datasets with sequencing depth above maximum saturation (4400X) are best assessed by read recruitment (mapping), as high-quality assemblies should be achievable in these cases.
Influence of sequencing errorHigh frequency of sequencing errors can affect the estimations of the number of redundant reads and thus, Nonpareil curves. It is strongly recommended to filter reads with a stringent cutoff for expected error (e.g. resulting in reads with51% error rate) prior to applying Nonpareil. The distribution of sequencing error is not always uniform across the length of the reads, depending on the sequencing platform used, and this uneven distribution may affect Nonpareil estimates. In order to evaluate the latter, we analyzed a $61 Mb dataset generated in silico from 33 reference genomes, dominated by Aeromonas salmonicida subsp. salmonicida (14%), in which randomly introduced sequencing errors were distributed uniformly, increasing linearly, and increasing as a polynomial of order 4 across the read length (based on). These involved only wrong-base substitution errors, the dominant source of error in Illumina. The resulting curves (Supplementary) indicated that the estimates of Nonpareil are not affected by the distribution of errors when the total error is $1% or less, but can be strongly biased when sequencing error approaches 5%. For other types of sequencing errors such as artificial duplicates, a common artifact in 454 sequencing, it is recommended to detect and remove sequences with these errors (e.g.) prior to applying Nonpareil.
Coverage estimation of various natural communitiesApplication of Nonpareil curves to publicly available metagenomes revealed, as expected, that the soil samples required the highest sequencing effort for nearly complete coverage. The seasonally thawed active soil layer from a black-spruce forest in the discontinuous permafrost zone of Alaska at Hess Creek required the highest sequencing effort (, 0.2 Tb) for nearly complete coverage. The freshwater samples were predicted to require $10 times less sequencing than soil but more sequencing compared with all evaluated human microbiota (e.g.480X more than posterior fornix;and). The AMD sequences mapping to Leptospirillum sp. covered 99.99% of the genome, and the 1% subset covered 73%. Using Nonpareil, a sequencing coverage of 70% was estimated for the 1% subset, which corresponds to 17 Mb of the complete dataset, whereas an expected coverage of 94% was obtained using the LanderWaterman expression [Lander and]. In addition to WGS metagenomes, the HMP samples included amplified 16S ribosomal RNA gene (16S) sequencing data (Supplementary). Estimation of the abundance and genome size of 16S-defined OTUs by COVER () displayed larger variability (cf.and Supplementary) compared with Nonpareil estimates based on metagenomes from the same samples, possibly reflecting the influence of sequencing errors or polymerase chain reaction artifacts () or variations on the assumed number of 16S copies (VetrovskyndVetrovskynd Baldrian 2013). The largest difference between COVER and Nonpareil was observed in the posterior fornix, an environment known to be largely dominated by Lactobacillus (). Quality-checked 16S data showed that the most abundant OTU accounted for $90% of the community and only nine of 37 OTUs identified showed abundance 40.1%. Assuming a typical vaginal lactobacilli genome size of 2.4 Mb, $8 Mb are predicted by the Lander Waterman expressions () to be required to cover 95% of the dominant OTU. Nonpareil estimated that 12 Mb of sequence data provide an average coverage of 91%, and $40 Mb would be necessary to cover the community almost entirely. In contrast, COVER estimated a total of 226 OTUs and 160 Gb to be necessary for the same level of coverage. These results suggest that 16S analysis can frequently inflate diversity, resulting in large underestimations of the sequencing depth. They also reveal that Nonpareil produces estimations closer to those of other genome-wide approximations such as the LanderWaterman model. We limited our evaluation to COVER because alternative methods for coverage estimation () were either not available for online or standalone computation, do not scale with large metagenomiccate the size and estimated average coverage of the datasets, and the lines after that point are projections of the fitted model. The curves cluster in four groups, reflecting different levels of diversity. The leftmost group, including posterior fornix, buccal mucosa, anterior nares and AMD, represents samples largely dominated by a single species. A second group, composed by tongue dorsum, stool and supragingival plaque, represents low to medium diversity samples. Next, freshwater samples, which are typically characterized by moderate to high diversity, cluster together. Finally, the curves for the high-diversity soil samples display the lowest slopes datasets or provide results like longest contig expected per taxon that are not directly comparable with those of Nonpareil.
Diversity rankingAn interesting feature of the Nonpareil curves is that the shape of the curves reflects the level of diversity of the communities sampled. The Nonpareil curve saturates faster, i.e. complete coverage is achieved with fewer sequences sampled, on datasets with lower diversity and shorter genomes (). Because the average genome sizes differ by no more than one order of magnitude between most microbial communities, the velocity of saturation of Nonpareil curves is mostly determined by the sample diversity rather than differences in genome size or gene duplications and repetitive regions. However, deviations from this expectation are possible when comparing metagenomes with large differences in average genome size, as it is often the case when the proportions of viral, bacterial/archaeal and eukaryotic DNA differ substantially. In such cases, separation of the different fractions (e.g.) before applying Nonpareil is recommended and the efficiency of this technique needs to be assessed on a case by case basis.revealed clustering of curves from samples with decreasing levels of diversity. Nonpareil curves from samples of communities characterized by low diversity, like posterior fornix, anterior nares and AMD, rapidly saturated. In contrast, Nonpareil curves from soil samples, known to possess comparatively high diversity, continued growing after projecting to millions of reads. Intermediate inare Nonpareil curves from freshwater samples, stool and tongue dorsum, expected to have a higher diversity than the first group of samples but lower than soil datasets. This property of the Nonpareil curves allows fast assessment of the level of diversity inherent to an unknown sample compared with reference communities. In addition, the shape of the Nonpareil curves can reveal distinctive features of the samples such as skewed distribution of species abundances. For example, the Nonpareil curve for the anterior nares sample () showed a rapid growth phase at low sequencing effort that does not saturate as rapidly as other low-complexity samples. Further examination indicated that this pattern was due to an unusual distribution of abundances (as revealed by 16S profiling; Human Microbiome Project), following an extreme broken-stick model. In all, 74 species were observed and $99 species were estimated to coexist in this sample (Chao1, IC 95% : 32.98239.7) but the most abundant species had an abundance of 36%, and the 9 most abundant species represented 95% of the community.
Computing performanceWe tested Nonpareil with datasets of various sizes (101 bp-long reads) and evaluated its performance in terms of central processing unit (CPU) time, running time and RAM usage (Supplementary). All tests were performed on cluster architecture with 64 CPUs (2.2 GHz) per node,440 GB of available RAM, running on Red Hat Enterprise Linux 6. Both the running time and the RAM usage grow linearly with the size of the dataset, as anticipated. The RAM use in GB was $0.1 times the size of the dataset (in millions of reads) plus 2. This relationship might vary on different computers, operating systems and future versions of the code, but it offers an indication of the RAM requirement of the algorithm without parceling. Note that the maximum RAM usage can be set on each run by the user, and Nonpareil can parcel the data to adapt to less powerful computers as needed. Both the running time and the CPU time are strongly affected by the stringency (cutoffs) of the read comparison (Supplementaryand c). However, the algorithm scaled up equally well with all the parameters (Supplementary).
CONCLUSIONSThe results presented here highlight the usefulness of the Nonpareil curve as a tool for both study design and exploratory comparisons of community diversity. This tool increases the range of samples for which coverage can be computed relative to existing tools. It is important to point out that existing approaches for coverage estimation require prior knowledge about the abundance distribution of the members of the community () and/or assume that the diversity distribution can be effectively modeled by known probability distributions (), or require the use of reference molecular markers (Daley and Smith, 2013;). These properties of a metagenome are frequently not available. The relationship between sequencing effort and average coverage of the community can be alternatively approximated by visual inspection of rarefaction when binning is feasible (). A recent development improved on this traditional approach by providing a mathematical generalization for any molecular marker and an accurate projection of the rarefaction curve (). However, the level of coverage remains inaccessible and sequence binning is a required step, which is typically limiting in WGS metagenomic studies. In contrast, Nonpareil does not require abundance distributions, models or reference databases and is based on the redundancy of the reads, an intrinsic characteristic of any metagenomic dataset. The complement of redundancy is the number of reads without matches in a given sample divided by the sample size, which we denoted as the Nonpareil fraction (). When expressed in terms of non-matching reads (i.e. one minus the Nonpareil fraction) the redundancy essentially takes the same form as the Good's coverage estimator (), a widely applied estimator of coverage of a sample (). Nonpareil applies this estimation directly on shotgun sequencing reads, even in datasets composed of millions of reads, with modest computational requirements. Application of Nonpareil estimates on available metagenomes revealed, as expected, that the largest sequence efforts were required for soil datasets, where up to 200 Gb and 1 Tb of sequence data were predicted to be necessary to achieve 95 and 99% abundance-weighted average coverage, respectively. These estimates are well below the 10 Tb estimate ofrequired to cover a typical soil metagenome, which emphasizes on coverage of all species, including rare ones. For example, Nonpareil predicts an increase in average coverage from 99.9 to 99.99% with 110 Tb of data (in Hess Creek), a marginal difference in abundance-weighted average coverage for 10 times more data. These results agree with previous findings based on single target species (), supporting that the estimations of Nonpareil are practical and robust. The soil dataset of Hess Creek represents a permafrost soil incubated under warm temperatures, which likely stimulated specific taxa, affecting the diversity of the community. However, the Manu Park sample represents a temperate soil, estimated to contain close to 9000 species based on 16S data (from 5347 observed 97% OTUs;). In fact, the estimate provided by Nonpareil for 99% average coverage (95 Gb) translates to complete coverage of any genome of $5 Mb with abundance40.07 with 90% confidence (). This corresponds to the top 312 most abundant species, or 90% of the observed community, based on 16S (). Note that these 312 species likely represent only $5% of the number of species present in the community. However, Nonpareil estimate is not meant to reflect the captured richness of the community (i.e. how many different species were captured), but the portion of the total community captured, taking abundance into consideration. Finally, we evaluated the robustness of Nonpareil estimates by both decreasing the sequencing effort on a community with high coverage (AMD) and increasing it on a community with medium coverage (Lake Lanier). In both cases the estimates were consistent with the expectations (and), indicating that Nonpareil analysis is robust to variations in the size of the query dataset, and variations arising from independently collected samples or different sequencing protocols (Lake Lanier samples). In summary, Nonpareil curves offer an estimation of average coverage of metagenomic datasets (for profiling studies and other community-wide analyses), a prediction of coverage in increased sequencing efforts (for study design) and a comparative framework for diversity exploration, allowing for fast diversity rankings of metagenomes before assembly or taxonomic classification.
AVAILABILITYNonpareil is free software licensed under the terms of the Artistic license 2.0. The source code and binaries are available at https:// github.com/lmrodriguezr/nonpareil/. An online server is available at http://enve-omics.ce.gatech.edu/nonpareil/. Sequences of Lake Lanier (LL_1007B) were deposited in the NCBI Sequence Read Archive, with accession number SRR948155.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
L.M.Rodriguez-R and K.T.Konstantinidis at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Nonpareil at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
