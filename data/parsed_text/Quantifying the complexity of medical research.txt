Motivation: A crucial phenomenon of our times is the diminishing marginal returns of investments in pharmaceutical research and development. A potential reason is that research into diseases is becoming increasingly complex, and thus more burdensome, for humans to handle. We sought to investigate whether we could measure research complexity by analyzing the published literature. Results: Through the text mining of the publication record of multiple diseases, we have found that the complexity and novelty of disease research has been increasing over the years. Surprisingly, we have also found that research on diseases with higher publication rate does not possess greater complexity or novelty than that on less-studied diseases. We have also shown that the research produced about a disease can be seen as a differentiated area of knowledge within the wider biomedical research. For our analysis, we have conceptualized disease research as a parallel multi-agent search in which each scientific agent (a scientist) follows a search path based on a model of a disease. We have looked at trends in facts published for diseases, measured their diversity and turnover using the entropy measure and found similar patterns across disease areas.
INTRODUCTIONDiseases are complex problems investigated by myriads of scientists working in parallel. Most of these scientists work on narrow niches to produce pieces of knowledge that contribute to our overall understanding of diseases. This understanding then enables the test of therapeutic interventions that might be better alternatives to existing treatments. To investigate this process, we have used the analogy of a multi-agent system throughout this study. We compare disease research with a search performed by a multi-agent system in which the agents (scientists) explore a space (a disease) to enable the selection of the best solutions (interventions) to a problem. This analogy has limitations, but it aids in delving into the intrinsic properties of the problem (the metaproblem). There are similar motivations in intra-human modeling that can be seen in projects such as the Virtual Physiological Human () or ApiNATOMY (). The search agents in our multi-agent system use models of reality to guide their path. These models represent the models that scientists use to guide their research. An important part of disease research involves building models that recapitulate some of the main properties of diseases. The best known of these models are in vitro and in vivo proxies that are lower-cost lower-risk alternatives to clinical studies (e.g. the unilateral ureteral obstruction mouse is an animal model for human kidney disease). There are also disease models of a mathematical nature that represent diseases at the systems or epidemiological level. Another type of model is based on the knowledge available for a disease (), such as the models used in knowledge-based clinical decision support systems. Biomedical researchers use knowledge models of diseases () based on knowledge acquired from textbooks, scientific literature and experimental and clinical experience. They are made up of multiple elements, which can be clinical, cellular, molecular and public health relatedto name a few. These models are the focus of this study. For each disease, researchers pay more attention to different sets of elements. For example, clinicians may use a patient's symptoms, demographics, clinical history and laboratory reports to evaluate disease progression. Biologists, on the other hand, may use genes, pathways, organelles and other elements to generate hypotheses about the mechanism of action of a drug or the activity of signaling pathways. In a disease such as psoriasis, a clinician may focus on the relationship between psoriasis area and severity index (PASI) scores and different immunosuppressive drugs, whereas a biologist may investigate the interplay of cutaneous and immune cells. In diabetic nephropathy, on the other hand, the interest may fall on the biology of podocytes and myofibroblast proliferation or on a patient's glomerular filtration rate and arterial blood pressure. Thus, different elements are combined by each scientist to construct a model of reality that enables reasoning about the disease. We incorporate such scientific models in our multi-agent system analogy by postulating that each scientific agent has a model of a disease built into its internal state. This model helps the agent navigate its path and is based on inputs produced by other agents, such as scientific publications, compounds or tools. These models are crucial because the agents cannot perform their search through brute-force exploration. They need to choose a path based on the likelihood of success. Thus, disease models facilitate decision making. We were interested in learning how the structure of these disease models can affect the task of the search agents. We started with the hypothesis that some disease models might be more complex than others for several reasons. One of the reasons could come from the number of articles published about a disease per year, as scientific publishing has been increasing exponentially across many areas of medical research (). Another reason could come from anatomy. For example, psoriasis is a fairly localized disease of the skin; *To whom correspondence should be addressed. however, a disease such as diabetes involves multiple organs and tissues. Yet another reason could come from the multiplicity of signaling pathways involved in a disease. Thus, a greater multiplicity of elements in a disease could mean a greater search space to investigate. A theoretical disease model can further illustrate this latter point. This theoretical model involves a non-existent animal species called bigenes, which has two genes in its genome: A and B. Bigenes suffers a species-specific disease called X, which is known to be driven by a mutation in A. Up to the year t, the literature on X comprised five articles focused on gene A. The publication record about X at time t could be represented as X t  {AAAAA}. Thus, X t is a simplified representation of what was known about X up to time t. The genes belonging to X t may not be disease genes in a traditional sense, but they represent the scientific conversation taking place about X, even in cases when negative results are reported, which may be contradicted later on. Defining 'disease genes' is in itself a complicated task as the relationship between a gene and a disease can range from strong and firmly established to tenuous, depending on the weight of the existing evidence. A breakthrough in the research of X occurred in the year t  1, when a mutation in B was newly associated with X. New articles appeared investigating this association; however, other articles still focused on A, leading to X t1  {AAAAABABBA}, where the subsequence {BABBA} corresponds to publications for the year t  1. Thus, the discovery of a mutation in B made the scientific model of the disease X more complex, and this is reflected in the publication record. This change in complexity can be quantified using the entropy measure from information theory, which is a common measure of statistical complexity () used in biomedical applications such as monitoring heart rates (PerkiomakiPerkioma) and brain electrical activity () or in evolutionary biology (). The entropy for X t is H(X t )  0, but the introduction of B in year t  1 leads to H(X t1 )  0.88 (see Section 2). H(X t1 )4H(X t ) reflects the increase in complexity over time. A number of works have been devoted to analyzing the growth and evolution of publications on gene and protein interactions outside the context of disease by analyzing the accumulated published record (). However, there is a divergence between the published record and the focus of active research, as older works fade in influence (on average). We believe that practical disease models do not involve every piece of knowledge published about a disease. Defining boundaries, nonetheless, is not straightforward. In the case of the disease X, publications were initially only about gene A, but that changed after an important discovery. Realizing this requires specific knowledge of the disease and a scientific consensus that may not be found. To generalize, we have used a time window. A model containing the state of the art in year t  1 for a 1-year time window would be X 0 t1  {BABBA}. We call this a fading memory model, and it reflects that the older a finding is, the less relevant it becomesjust like a fading memory. This decay can be observed in the evolution of citation counts of published literature over time. One shortcoming of the fading memory approach is that some diseases have much higher publication rate than others. However, memories may fade faster for diseases with higher publication rate owing to the finite memory of the scientists that study them. A finite memory approach would consider the latest n publications rather than a time window. In the case of X, this would mean a disease model X 0 t1  {BA} for a memory size of n  2. We have centered our analysis on the finite memory approach because publication rates change widely over time and between diseasesand thus comparing fixed time windows would require some type of normalization, which could introduce distortions. Nonetheless, the fading memory approach is also discussed, as will be shown later in the text. Another important aspect of disease models is their evolution in time. A rapid pace of change may signify, for example, that the principles of a disease are not properly defined. A disease model whose elements have a high turnover rate requires a greater effort at understanding and leaves less time to devote to its details. In the case of the disease X, the appearance of B in the publication record was unexpected, which in Bayesian probability terms can be expressed as p(B2X 0 t1 j X 0 t )  0. On the other hand, articles about A were fully anticipated, p(A2X 0 t1 j X 0 t )  1. Thus, conditional probabilities can be used to gauge the rate of change in a disease model and the novelty of a finding. The bigenes example is about an organism with only two genes (like some simple viruses), but a similar case could have been made about an organism with only two cell types because research emphasis on cell types also changes over time. For example, much immunological research has been focused on the T-cell subsets Th 1 and Th 2 , but, recently, there has been increased emphasis on Th 17 and T reg cells, whereas new cell types, such as Th 9 and Th 22 , are regularly proposed. In this analysis, we have considered disease models not only involving genes (as in the bigenes example) but also cell types, drugs and chemicals, and we have looked at how they influence each other.
METHODSDisease literature data came from Medline 2012 release abstracts annotated with at least one disease MeSH term (branch C of the MeSH Tree Structures, which covers human and animal diseases) and published between 1970 and 2010. Disease groups were based on the main subbranches of the disease MeSH tree. Gene, cell type, drug and chemical annotations came from GeneView [(); download. GeneView uses the GNAT () algorithm for gene recognition, which showed 82% precision and 82% recall for abstracts in the BioCreative challenge, and which has been extended to 20 model species. Chemical entity annotations in GeneView come from ChemSpot (), which achieves 68% precision and 69.5% recall. Cell types and drugs are based on the AliBaba () dictionaries of regular expressions and spelling variations. For each disease in the MeSH Tree Structures, an ordered sequence was created X k  x k, 1 , x k, 2 , x k, 3 ,. ..   , where each x k, i is the name of a gene mentioned in an abstract annotated with the MeSH term corresponding to disease k. Each sequence X k was ordered by publication time. That is, for every x k, i , there is an associated time stamp t k, i for which t k, i t k, j if i j. The time stamp was based on the publication date of the abstract. For publication dates that only specify month and/or year, the earliest possible date was assigned (e.g. the first day of the month). For publications appearing on the same date, the PubMed ID value was used to decide order. The X k sequences are, therefore, time series that can be analyzed and compared. To apply the finite memory approach, we considered every possible ordered sequence X j k 2 X k of length n, X j k  x k, j , x k, j1 ,. .. , x k, jn1   . Thus, each X j k is a disease model of disease k under the finite memory approach for a memory of size n. The initial value of n chosen was 100. Overall conclusions did not change for other values of n tested. Entropy was computed for each X j k , following Shannon's theorem:where p j k A l   is the frequency of gene A l within the sequence X j k orwhere I xk, i Al is a binary function that returns one when x k,i is equal to A l , and zero otherwise. Compare this with the log-entropy models for information retrieval in (). Each H X j k   was associated to a time stamp t j k , which is the average of the time stamps associated to the x k, j components of X j k. The publication rate for each X j k was computed as follows:To assess the evolution of H X j k   over time and publication rate,two methods were used, which produced similar overall picture. The first method involved computing for each disease k, the multiple linear regression between the entropy and the publication time and publication ratefor all j values. The second method involved creating a random sample of values picked among all thetriplets. Randomization followed these steps: a disease k was randomly picked and then a random value of j for that disease was selected. This sampling method was implemented to make sure that diseases with longer sequences did not dominate the results. The random sample had size 100 000. To measure the novelty of new findings, the conditional probability of an element x k, jn for each sequence X j k was computed as follows:and then compared with the time and rate of publication,the results, the average of a forward window of w 0  10 elements was used:Control sequences similar to X k were created by shuffling the disease annotations across the corpus (FisherYates random permutation). Using this method, many of the properties of the dataset, such as the overall frequency of genes and diseases, are preserved. This represents a higher bar than alternatives such as generating random disease and/or gene annotations from a uniform distribution. The same process was followed with the annotations of chemicals and drugs. For cell types, however, the data were insufficient to construct X j k memory sequences of length 100, and thus length 20 was used instead. Thus, some of the results presented for cell types are not completely comparable with the rest. Correlations between the H X j k   of genes, chemicals, drugs and cell types for each disease k were performed using entropy sequences with monthly values based on linear interpolation of the values of
RESULTSThe complexity of disease models made of genes has been increasing over time, as can be seen in. This is reflected in the r 2 and the multiple linear regression coefficients in. To test the robustness of the result, we changed the value of the time window (originally n  100) to n 2 25, 50, 75, 100, 125, f 150, 175, 200g and found that the relation persisted and even became stronger with increasing n. The r 2 fit increased with the size n of the window (r 2 $ 3.4  10 2 ln(n)  2.8  10 2 ), as did the coefficients for time (r 2 $ 2.3  10 2 ln(n)  4.2  10 2 ) and publication rate (r 2 $ 1.1  10 5 ln(n)  3.4  10 5 ). Choosing the value of n is a trade-off between resolution and coverage, as diseases with less than n published facts are not included in the analysis. We also looked within disease groups and found similar patterns (seeand), with, for example, cardiovascular diseases and nervous system diseases increasing in complexity at a faster pace over the period involved, and neoplasms and substance-related disorders growing slower. An illustrative example is the disease retinitis pigmentosa (RP), a retinal degenerative disease. The entropy of its disease model over time fits a linear regression with r 2  0.89 and a positive slope of 0.13, indicating that its complexity has been increasing over time (see). The lower early entropy is illustrated by one of the main genes studied in RP: rhodopsin. Owing to the early discovery of a rhodopsin mutation associated to RP (), rhodopsin was important in publications about RP, leading to initial low entropy in the RP disease model. However, rhodopsin has faded relatively in importance as many other mutations and genes have been associated to RP in recent times. The current multiplicity of genes studied has led to higher entropy in the disease model of RP. For disease models of chemicals and drugs, we can see a milder increase in complexity (see Section 2). Thus, the increase incomplexity is not homogeneous across all categories of elements. This is seen in models of RP as well. The linear regression for the disease model of chemicals has r 2 of 0.54 and slope of 0.06, and for drugs r 2 of 0.80 and slope of 0.05. The low entropy in chemical models in the earlier studies of RP is illustrated by the relatively higher prominence of fluorescein, whose use tended to be highlighted in the abstract [e.g. (, a practice which has faded since. Fluorescein is counted both as a chemical and as a drug (FDA approved in this case). Thus, the drug and chemical categories overlap. The control disease models created by random permutation of disease annotations (see Section 2) do not show any of these properties (see). Moreover, control disease models do not show the heterogeneity of entropy values seen in actual disease models, suggesting that entropy differences are significant between disease models. For example, the linear regression that fits the control gene disease model for RP has r 2 and slope close to 0 and does not show dependence with time. Moreover, the entropy values are high and close to what a discrete uniform distribution with sufficient cardinality would produce. Actual disease models have lower entropy than control disease models because they are concentrated around certain elements such as popular genes or drugs and form differentiated areas of knowledge, as the RP example shows. An implication is that 100 randomly selected articles about a disease should, on average, cover less unique facts (e.g. genes) than 100 articles picked at random from the overall literature. This means that the focus of a disease's research is narrower and there is more repetition, which gives it more coherence and makes it more understandable to humans. When the focus of a disease becomes too broad it could be an indication that the disease definition has become too inclusive. As seen in the disease models of RP, the slope of the linear regression between entropy and time tends to be positive,all diseases, we found these values to be unrelated to the average publication rate, showing that disease models with high average publication rates are no more complex than those of diseases with low average publication rates. This is similarly reflected in, where we show that a small fraction of the increase in complexity is driven by higher publication rates. For example, in gene disease models, the linear regression coefficients indicate that a 5000-fold publication rate increase would increase the complexity as little as 1 year of time would. By looking at the RP example alone, we could not have known whether the increase in entropy of its disease models was somehow related to the increase in the rate of publications about RP that happened over the same time period. Our analysis, however, allows us to say that these two variables are generally unrelated. Instead, diseases with high publication rates would seem to have a 'fast forward' behavior in which findings are brought up faster but without an increase in associated complexity. Thus, the finite memory approach chosen here (as described in Section 2) seems more appropriate to study this phenomenon than the fading memory approach. As can be seen inand, the novelty in disease models made of genes has been increasing over time as well. This can be seen in the negative relation between time and the probability of a publication mentioning a gene that is already in a disease model. For chemicals, this relationship is barely significant, and for drugs, it is not significant. The linear regression for disease models of genes has a median slope of 0.00942 and an interquartile range of(here, negative slope means increased novelty). Increased novelty could be one of the main drivers of increased entropy, as they are related. In the gene disease model of RP, novelty increases noticeably with time, and fits a linear regression of slope 0.07 and r 2 of 0.63. From the complexity and novelty of the disease models of RP, we postulate that RP has become harder to study over time. RP is not a unique case, as can be seen infor two disease groups and multiple sclerosis. As shown in, we found that publication rates do not correlate with novelty. Thus, a slower pace of publication does not entail a lower appetite for novelty in less-explored diseases. Control disease models show a more stable and much higher rate of novelty, as would be expected from a randomly shuffled set. To further study the drivers of complexity in disease models we measured the correlations between the entropies of disease models for genes, chemicals and drugs (see Section 2). These correlations were found to be positive (seeand), meaning that increases in one category were correlated with increases in another category, even controlling for the common increase of entropy over time already described. In the case of RP, for example, the entropies for the disease models of genes and chemicals were correlated, with a slope of 0.50 and r 2 of 0.58. This shows that changes in complexity of disease models are not independent for each category and that it would be reasonable to consider disease models in a multidimensional fashion, with different categories of elements interacting with each other rather than studying them separately. It should also be noted that variations in complexity for each category may have different practical impact. For example, an increase in cell type complexity could be more relevant than an increase in gene complexity because a gene can be associated to different functions in different cell types.
CONCLUSIONSOur study shows quantitatively that the complexity of studying diseases has been increasing over time. A resulting implication is that selecting molecular targets in target-based drug discovery becomes a more arduous task as the search space grows,Note: P-values for time coefficients are not significant for drugs, and P-values for publication rate coefficients are only significant for cell types. Adjusted r 2 is shown for the overall regression. As explained in Section 2, values for the cell category are not directly comparable with the rest. especially given the limitations of existing therapeutic tools (). Pharmaceutical companies need to scrutinize and triage more genes to find the best candidate for development. The effort increases if the set of genes being studied changes quickly over timeand the same applies to cells, tissues and compounds. Further studies are necessary to ascertain the link between this complexity and increased R&D costs. The larger the diversity also means the harder the problem becomes for the limited human cognitive abilities. This can be seen in a more simplified multi-agent search example. In this setting, scientific production about a disease comes from agents that only study and publish about a single gene, without consideration of other genes. These agents publishall of themat exactly the same rate. Some diseases have higher publicationNote: All coefficients have associated P-values510 15 , except for the coefficient for time when comparing chemicals and drugs, which is not significant. The correlation values are between category 1 and category 2.conclusions that are unsupported by the available data, as well as heterogeneity in the quality of the data, could interplay with the complexity we are measuring or add another layer to the problem. Beyond these scientific factors, non-scientific ones such as regulatory and legislative problems or patenting issues can loom large for certain diseases. Ultimately, complexity should be considered primarily as causing a tangible impact to the input factors necessary for scientific research (time, money, patients, etc.). In this light, the need for better understanding is highly relevant, considering the stagnating pace of pharmaceutical research despite the abundance of incentives to improve existing therapies.
The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Quantifying the complexity of medical research at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
R.Rodriguez-Esteban and W.T.Loging at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
rates, but this is as a result of a larger number of agents working on them owing to greater perceived significance. In this scenario, it would be possible for those diseases with higher publication rate to have more complex models because each agent can specialize in a different gene and create a separate research niche. Thus, having more agents at work would allow for more bandwidth on the production side, particularly 'brain bandwidth'. However, we have shown that diseases with higher publication rate do not have more complex disease models. One explanation could be that scientists are also consumers of the research produced by other scientists, and therefore they naturally tend to follow the path that others have opened (Cokol et al., 2005)in some cases because it is the only path being funded. Another explanation is that individual scientists can only process a certain level of complexity within the limits of their cognitive abilities and the technologies available to them. Hence, there would be a limitation on the consumption side of science, and scientific production would tend to adapt its output to this consumption 'bandwidth'. These explanations would leave the open question of why disease complexity and novelty have, nonetheless, been increasing over time, as we have shown. A potential reason is that technological progress has brought forward high-throughput experimental and in silico technologies that enhance the ability of scientists to produce, process and understand large datasets. Although genetic screens and other unbiased high-throughput techniques are less affected by an increase in the multiplicity of prior knowledge, these experiments usually produce extensive new results that need to be validated with low-throughput methods by researchers grappling with them (Mons and Velterop, 2009). We should also note that many high-throughput techniques are not completely unbiased and depend on prior knowledge. For example, the therapeutic usefulness of a cell-based screen will depend on the choice of cell type. Repeated failure in clinical trials has led to increased efforts at patient stratification, using such techniques as genotyping or gene expression analysis. Under the framework presented here, stratification could be understood as a way of drawing more convenient boundaries to a problem to reduce its complexity. For example, the diversity found in cancer has led to the proposition that it should be considered a constellation of different diseases classified by organs, cell types, molecular profiles, driver somatic mutations, active pathways and so forth, which could be addressed with computational and text mining approaches (Clancy et al., 2011). Slicing a problem can be an effective way to simplify it. Besides the factors considered here, there are other reasons why some diseases should be more difficult to investigate, such as experimental limitations (e.g. lack of satisfactory animal models or cell cultures such as in neurological disorders, imprecise data from high-throughput techniques) or clinical constrains (e.g. frequent comorbidities, inadequate biomarkers, uncertain diagnostic tools). Genetic or phenotypic heterogeneity or multiple associated genetic loci, may hinder the understanding of a disease's genetic underpinnings. Other difficulties could be driven by disease-protective mechanisms, such as compensatory feedbacks, fast mutation rates or redundant pathways that make diseases robust against therapeutic intervention. Moreover, literature biases such as unpublished negative results or published
