The large amount of data produced by proteomics experiments requires effective bioinformatics tools for the integration of data management and data analysis. Here we introduce a suite of tools developed at Vanderbilt University to support production proteomics. We present the Backup Utility Service tool for automated instrument file backup and the ScanSifter tool for data conversion. We also describe a queuing system to coordinate identification pipelines and the File Collector tool for batch copying analytical results. These tools are individually useful but collectively reinforce each other. They are particularly valuable for proteomics core facilities or research institutions that need to manage multiple mass spectrometers. With minor changes, they could support other types of biomolecular resource facilities. Availability and Implementation: Source code and executable versions are available under Apache 2.0 License at http://www.vicc .org/jimayersinstitute/data/ Contact:
INTRODUCTIONMass spectrometry (MS)-based proteomics offers a remarkably powerful technology for identification of proteins in complex biological samples. Bioinformatics tools are essential to this process (). Proteomics services are often provided through shared MS instrumentation with the support of external computing resources. Core facilities often struggle to manage the volume of data that these instruments can generate, resulting in irregular or non-existent backup plans and long delays separating sample receipt and information release for end-users. Existing freely available tools such as TPP (), CPAS () and CPFP () focus only on data analysis by providing a set of tools for peptide identification and validation. A Laboratory Information Management System may offer some capabilities for integration of instrument data backup and data analysis, but these services usually catalog samples and bench procedure more effectively than they manage bioinformatics workflows, with little support for proteomics studies. We addressed * To whom correspondence should be addressed. these challenges by developing a suite of tools to support production proteomics. These tools are in daily use at the Vanderbilt Mass Spectrometry Research Center and the Jim Ayers Institute for Precancer Detection and Diagnosis. They are now freely available with source code to commercial, government and academic users.
SOFTWARE OVERVIEWThe workflow of these supporting tools is illustrated in. The Backup Utility Service (BUS) tool offers automated backup of raw data to file servers. The ScanSifter tool reads these proprietary format files and converts them to open format files, which are submitted to a queuing system and identified by database search engines such as SEQUEST () and MyriMatch (). The identification results can be retrieved using the File Collector tool, enabling batch copying search results to local computer or network drives. We also provide an instrument file naming utility to quickly generate filenames in a standard consistent fashion as opposed to manually entering each filename into the instrument control software. Each tool can be used separately to fulfill its function. Combining these tools offers an integrated solution for production proteomics.
Backup utility service (BUS)The BUS tool automates file backup from instruments to sets of file servers. It operates as a configurable, scheduled Windows service,
Supporting tool suiteseeking file system changes and copying updated files on a regular basis. A graphical user interface facilitates the configuration process. BUS is a Windows application written in C# and should be installed in each computer that controls a mass spectrometer. It can be used in either a standalone desktop or web service-coordinated capacity. In the latter case, the metadata of archived files are stored in an Oracle database or a free Oracle database Express Edition; a script to initiate the Oracle database is provided in the distribution package. This database can then assist the ScanSifter for data conversion to forestall additional file copy steps.
ScanSifterScanSifter is a data conversion tool to transcode and filter mass spectra. It reads and writes a variety of formats via use of the ProteoWizard () library. Currently, it supports spectral data in proprietary formats from Bruker and Thermo; adding other formats supported by ProteoWizard requires few changes. It exports data in mzML (), mzXML (), mzData, MGF and DTA formats. It can also translate files from MGF or XML-based formats to the others. ScanSifter implements several algorithms for recognizing mass spectra that can be filtered prior to export. By default, the software will output all mass spectra, but users can, for example, export only MS/MS/MS scans. Noise spectra can be filtered by imposing a minimum required peak count or total ion current (TIC). In special cases, a researcher may be interested in scans that correspond to a narrow range of precursor m/z values, and this filter is also implemented. Two versions of ScanSifter are included in the distribution package: ScanSifter Web and ScanSifter Desktop. The former is installed in a Microsoft IIS server to provide web services that read input files from designated network directories. Alternatively, it can be configured to read a BUS database and find archived raw files automatically. The converted files are stored in file servers and subsequently processed by identification tools. ScanSifter Web can coordinate the use of shared file servers among multiple labs. If multiple ScanSifter jobs are submitted at the same time, they will be queued for processing. ScanSifter Desktop is a standalone Windows application written in C#/.NET. Besides the filtering features described above, it provides three algorithms to enable the removal of duplicate spectra during data conversion. The first algorithm adapts the scoring approach for MyriMatch () to recognize similar spectra. The second algorithm computes a normalized dot product for spectral comparison, as is typical in spectral library search. The third algorithm treats m/z values of two spectra as two groups, and calculates the distance between the distributions of these two groups through the KolmogorovSmirnov test. If duplicate spectra are observed during data conversion, only the spectrum with the highest TIC is retained and exported to the output file.
Identification pipeline and queuing systemA queuing system and web interfaces to run peptide identification pipelines are included in the distribution package and should be installed in a Linux server. The queuing system is written in Perl and coordinates with the TORQUE resource manager or Moab Cluster Manager. Web interfaces to run database search by SEQUEST () and MyriMatch () are provided. Sequence tagging-based modification search by TagRecon () is also enabled. A FASTA database maintenance tool is provided to upload new sequence databases and view the status of current databases. The queuing system can separate LC-MS/MS experiments to many tasks, maintaining a target number of running jobs for a cluster. Status queries and error logs are fielded by provided support tools.
File CollectorThe File Collector tool enables batch copying search results and spectral files from file servers to local computer or network drives. It is a Windows application written in C#/.NET. Filters such as file type or file name are enabled. A configuration file is used to specify the source file locations. Network resources are not required to be mounted as drive letters; the system supports UNC path description.
SUMMARYHandling data for multiple mass spectrometers requires support tools. We developed these tools to enable analysis of data from several instruments operating continuously in our laboratories. We hope that these systems for data transport and computing coordination will be broadly useful to others in their present form or with slight modifications. All applications are released under an open source license to accommodate both academic and commercial users. The queue management and data archival tools could easily be applied in other biotechnologies with minimal modification. As high-throughput instrumentation becomes ubiquitous, the challenges of managing these data flows will only increase. Software systems such as these will only grow in importance to shared instrument facilities.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
