Motivation: In developmental biology, quantitative tools to extract features from fluorescence microscopy images are becoming essential to characterize organ morphogenesis at the cellular level. However, automated image analysis in this context is a challenging task, owing to perturbations induced by the acquisition process, especially in organisms where the tissue is dense and opaque. Results: We propose an automated framework for the segmentation of 3D microscopy images of highly cluttered environments such as developing tissues. The approach is based on a partial differential equation framework that jointly takes advantage of the nuclear and cellular membrane information to enable accurate extraction of nuclei and cells in dense tissues. This framework has been used to study the developing mouse heart, allowing the extraction of quantitative information such as the cell cycle duration; the method also provides qualitative information on cell division and cell polarity through the creation of 3D orientation maps that provide novel insight into tissue organization during organogenesis. Availability: The proposed framework is free, open-source and available on the Icy platform (http://www.icy.bioimageanalysis.org/).
INTRODUCTIONThe advent of modern 3D optical imaging techniques has impacted numerous areas of life sciences, giving novel insight into various aspects of cell behavior, notably during tissue development (). Typical images are obtained by labeling the cell membrane and nuclear DNA with fluorescent dyes, yielding two-channel image volumes where cells appear as a dense matrix of contiguous surfaces, while nuclei appear as pseudo-elliptic blobs in close vicinity (cf.). However, in the context of dense tissues, 3D microscopy images of developing tissues still suffer from rather poor spatial resolution in the axial direction. Analysis is therefore still restricted to the upper section (typically 50 microns) of the specimen, beyond which substantial light scattering occurs in non-transparent tissues, thus hindering precise segmentation at the nuclear and cellular level. This is especially true in models such as the mouse (), where the tissue is much less transparent than that of zebrafish or Drosophila (). Alternative solutions have been proposed to improve the imaging process by combining complementary enhancements in the biology and the optics fields. For example, in, transgenic quail lines were generated, where only endothelial cells express a fluorescent marker, thus simplifying the quantification of multi-cellular movements in an embryo that is amenable to live imaging, but without real improvement of the resolution. A promising solution certainly lies in recent advanced imaging setups such as single plane illumination-microscopy or SPIM (). There, only a thin sample plane is illuminated, while the light emitted by the entire plane is collected at once in the normal direction, thereby reducing exposure time, bleaching and toxicity. Such systems are, however, not or only recently commercially available, although open-access prototypes are currently being developed (). It is also not clear whether SPIM images suffer from distortion/resolution problems, due in particular to the registration and stitching of multi-view images (). In this context, and with the exponential increase in imaging datasets produced, digital image processing and analysis tools have become indispensible to make the most of 3D imaging techniques and data for biological applications. To quantify and then understand the mechanisms governing morphogenesis and organogenesis, quantitative measures such as cell cycle durations or cell orientations must be revisited if one wants to make full use of 3D stacks of the sample. Until recent years, extraction of cell parameters for the characterization of tissue growth has been limited to 2D () or multi-2D () analysis, or limited by the subjectivity and time-constraints of manual intervention for 3D analysis (). Because 3D cell behavior is not stereotyped, analyses over a large number of 3D samples are required to extract relevant statistics. Hence, systematic analysis of developing tissues composed of several thousands of cells calls for robust and automated tools to *To whom correspondence should be addressed. yThe authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors. segment cells, nuclei and other subcellular structures from 3D fluorescence images. A substantial amount of research in the image processing field is dedicated to the problem of multi-cellular segmentation in 3D. In particular, recent attempts have been reported to tackle the problem of dense tissue analysis in 3D. These contributions can be declined in two families: (1) image filtering approaches, aiming to remove the imaging artifacts by reducing the noise, smoothing heterogeneous structures and enhancing the contrast (; (2) segmentation techniques, aiming to extract nuclei or cells individually, either by means of the watershed transform () or via energy-minimizing deformable models (). While watershed-based approaches usually suffer from noise and over-segmentation issues, deformable models offer a more flexible approach by allowing the incorporation of image-and geometry-based information into a robust mathematical framework based on Partial Differential Equations (PDE). For-instance in (), the cell membrane signal is first denoised using a geodesic curvature filter (), then a generalized 3D Hough transform approach is used on the nuclear channel to estimate the location of the nuclei (), finally a subjective surface-based technique is used to segment the cell membranes (). Such an approach yields promising results; however, it is restricted to the upper section of the specimen, illustrating the difficulty of processing deeper slices of the tissue, despite the transparency of the zebrafish as compared with the mouse. Also, the cellular and nuclear fluorescence signals are processed separately, which may impair the extraction performance. The present work introduces a new and alternative PDE-based framework to automatically denoise and jointly segment nuclei and cells from 3D images of dense and opaque tissues, and to extract quantitative measures including proliferation rates and cell orientations. We propose that combining the nuclear and cellular fluorescence information can significantly improve segmentation of both signals, even in highly non-transparent tissue such as that of mouse. We first use a filtering technique specifically designed to enhance the cellular membrane signal, and then subtract this signal from the nuclear signal to separate touching nuclei, thus improving their detection. Finally, we develop a two-step deformable-model approach to (i) segment the nuclei starting from their initial detection using local region homogeneity, and (ii) segment the cells starting from the extracted nuclei using dual region-edge information from the filtered membrane signal. We use the proposed approach to study the development of the mouse heart and provide new quantitative parameters characterizing the morphogenetic process (e.g. number of cells and divisions, duration of the cell cycle), as well as 3D orientation maps to facilitate visual inspection and enable further statistical and geometrical analysis of the observed tissue. Quantitative and qualitative evaluations are provided, indicating a substantial gain in performance and analysis time compared with current approaches.
APPROACHA general overview of the proposed approach is illustrated in, while detailed steps of the analysis are given in the following subsections. In the 'Anisotropic filtering' step, a novel PDE-based filtering technique is used to denoise the membrane signal (cf. Section 2.1). In the 'Nucleus initialization' block, the filtered membrane signal is subtracted from the nuclear signal to improve their detection (cf. Section 2.3). The detection results are then used to initialize our deformable model approach to achieve accurate 'nuclear segmentation' (cf. Section 2.4). Once all nuclei are segmented, the resulting boundaries are used to initialize the subsequent 'Cell segmentation' block, conducted on the filtered membrane data. Once nuclei and cells are segmented, additional subcellular structures are used to determine quantitative measures and orientations to characterize the observed tissue.
Anisotropic filtering for membrane enhancementThe cellular membrane can be represented by a structure of co-dimension 2, i.e. a continuous two-dimensional surface in 3D space. However, due to the imaging and staining conditions, the observed surfaces appear discontinuous and exhibit a highly variable contrast, thus impairing precise extraction (). To recover continuity and contrast, image filtering approaches based on anisotropic diffusion are particularly well suited, as they propagate spatial information from the local neighborhood to recover both signal intensity and structure orientation, e.g. through the use of diffusion tensors (). Recently, we introduced a model for cell membrane denoising and enhancement that takes explicitly into account the directions of diffusion thanks to structure tensors (). The general equation reads as follows:where I is the 3D data and D is the diffusivity matrix given as follows:where g K is an edge detector function, e.g. rational function from the Perona-Malik model () (see Supplementary Data for more details). Here K indicates a threshold between background and edge structures and should take higher values as the noise level increases (in our experiments, we chose K  5). Here h  is a fuzzy threshold function between 0 and 1 that allows a better control of the transition between co-2D structures and other regions (). The eigenvalue 2 depends continuously on the confidence measure and takes values between 1 and 3. The max function prevents 2 from taking negative values and thus avoids oscillations.summarizes the behavior of the proposed model with respect to the possible eigenvalue combinations. In the average gradient direction (~ v 1 ), contrast enhancement is achieved alongside the diffusion process, by letting 1 take negative values. To ensure that the model remains well posed, the enhancement is similar to the Perona-Malik model. It can be shown that in the gradient direction, the diffusivity in the Perona-Malik model is implicitly modulated by the flux derivative function x  gx 0 (). When 1 4K, this function takes negative values, inducing an enhancing behavior along ~ v 1 (). In membrane regions, the fuzzy function h C plane  ! 1 implies 2 ! 3  1; thus, diffusion is applied along the membrane tangential plane, i.e. orthogonally to ~ v 1. The regions where h C plane  ! 0 are either isotropic or exhibit 1D homogeneous structures, and are therefore processed differently. In regions with 1D structures, 2 tends toward 1 because h C plane  ! 0 and both are close to zero. Hence, diffusion will take place along the smallest variation of contrast ~ v 3 with an intensity equal to one. In the orthogonal directions, two possible events can occur: if 1 and 2 are both positive, a weak diffusion is applied, and hence our model comes down to the classical model proposed in, which considers all structures as 1D structures; if 1 is negative and 2 is positive, the signal is enhanced along ~ v 1 and smoothed along ~ v 2. It is interesting to note that at membrane extremities or at junctions, the model is able to enhance the membrane continuity even if the diffusion acts predominantly in the most homogeneous direction (~ v 3 ). Membrane continuity can be further enhanced by increasing the size of the neighborhood where the structure tensor is computed, or by computing an anisotropic structure tensor (). Finally in homogeneous regions, 1 tends toward 1. Hence, our model diffuses in an isotropic manner to denoise the background (cf.), whereas classical tensor-based approaches create false anisotropic structures in such regions (). Comparisons with the classical model as well as with other models dedicated to membrane filtering on synthetic and real data are given in Supplementary Data. To summarize, the proposed model is able to (a) smooth the signal along planar structures while enhancing their contrast; (b) enhance the continuity of the structures, enabling the recovery of incomplete signal; (c) provide a strong isotropic diffusion in
Data fusion for nuclei detectionThe high tissue density implies that nuclei are close to each other, and are sometimes difficult to distinguish by eye. We ensure that nuclei are well separated by subtracting the cell membrane signal from the nucleus data. In this step, all the voxels belonging to the cell membrane [determined using an Otsu threshold (are replaced in the nucleus data by the background value. To initialize the segmentation model described below, a fast detection method is used to detect automatically the approximate shape and location of the nuclei in the tissue. The original images are first denoised using classical filtering (see Supplementary Data). However owing to the important intensity variations across the tissue, the filtered data still exhibit nuclei with different intensities. We thus apply a multi-level threshold approach based on Hierarchical K-Means (HK-Means), which has been developed to separate clusters of confluent cells with varying intensities (cf. Supplementary Data). An illustration of this detection step is given in: on the raw data (A,D), the proposed algorithm yields over segmentation; on the filtered data (B,E), some nuclei are recovered, while others are missing or merged. Finally, after membrane subtraction (C,F), almost all nuclei are recovered, although their size and boundary may be inaccurate. The next section presents a solution to the latter problem.
SegmentationA drawback of the previous detection step is that nuclear boundary localization may have been impaired during the membrane subtraction process. A specific segmentation step is thus required to accurately recover the boundary of each nucleus. Likewise, each individual cell has to be extracted from the enhanced membrane signal. The former problem is known as a region-based segmentation problem (nuclei have similar homogenous intensity as compared with the background), while the latter is known as an edge-based segmentation problem (the interior of each cell is unknown and bounded by its membrane). Deformable models are well suited for these tasks, as they allow integration of both region-based and edge-based information into a single formalism, and allow the incorporation of geometrical constraints that permit the distinction of objects in contact. In particular, the 3D Active Mesh framework () provides such a flexible formalism and provides a polygonal description of the extracted objects, thus facilitating geometrical measurements and allowing real-time 3D visualization of the deformation process. This technique relies on an energy minimizing framework, where the simultaneous evolution of n surfaces S 1::n within an image I is expressed as follows:where ^ I is a contrast-enhanced version of I that reduces the lightscattering effect along the depth axis (cf. Supplementary Data), c i out is the average background intensity of ^ I around S i (noted R i 0 ), c i in is the average intensity of ^ I inside the segmented region R i bounded by S i , d is the elementary 3D space, g is a positive non-increasing edge detector function, ds is the elementary surface and , , , are empirical weights. The Erst two terms (weighted by ) express region homogeneity, dramatically improvingDiffusion quantitiesNote: i ! 1: strong diffusion along ~ v i ; i ! 0  : weak diffusion along ~ v i ; i ! 0  : enhancement along ~ v i ; K: threshold of the Perona-Malik edge function (). Diffusion quantities respect 0  1 2 3  1.) in three aspects: firstly, the multi-phase implementation is robust to heterogeneity of the fluorescent signal; secondly, following () background intensity computation is restricted to a local neighborhood of each contour to cope for uneven sample illumination; finally, we propose a novel scheme that automatically adjusts the parameter for each contour according to local image statistics by setting i  1 ci. This setting automatically increases detection sensitivity for dim objects, while reverting to the original model for bright objects. The third term (weighted by and ) regularizes this ill-posed problem by minimizing either the euclidean surface length (when ! 0) or the geodesic surface length (when ! 1), depending on whether edge information is available (see below). The Enal term (weighted by ) couples the evolution of all surfaces and prevents them from overlapping during their deformation, thus handling objects in contact. Because this is a hard (topological) constraint, the weight is set arbitrarily very large ( ! 1) to ensure its predominance over the other energy terms. To summarize, the only free parameter is , which is adjusted on a trial-and-error basis (in our experiments, we chose 0.05 for nuclei and 0.1 for cells). This value should typically increase with the level of noise data. To initialize the segmentation of the nuclei, triangular meshes are created from the pre-detected nuclei with the Marching Tetrahedra algorithm (). Meshes are then deformed on the nuclear signal. Because no edge information is available, we set  0.illustrates the results obtained on typical 3D stacks. Cell segmentation is achieved using the same approach, although here the input meshes are given by the segmented nuclei, and the input image is the filtered membrane signal. Here, we set  1 such that the meshes are attracted by intensity gradients. A well-known limitation of edge-based models is their local spatial support, requiring that the contours must be initialized close to the target boundaries to perform efficiently. In our model, however, we formulate the cell extraction problem as a dual segmentation task, based on the fact that the membrane signal can also be interpreted as piecewise constant (cell membranes versus cell interior or background). As a result, the localized region-based term allows segmentation of the interior of each cell regardless of the distance from the mesh to the membrane, while the edge-based term takes over when intensity gradients are locally available, thus improving the localization accuracy of the membranes (). While the cell membranes are accurately recovered in most cases, the remaining errors are due to two main factors: (i) no initialization owing to nuclei that have not been correctly segmented; (ii) cells in anaphase, where two nuclei are detected and initialized within the same cell, thus disturbing the segmentation process. Another illustration of the cell segmentation result on a full scan of an embryonic mouse heart is presented in Supplementary Data along with the corresponding nucleus segmentation (Supplementary). cell division axes, to build 3D orientation maps of the tissue that can be used for further statistical analyses (Le).
Computation of the cell cycle durationAn important quantitative descriptor of tissue growth is the duration of the cell cycle in different regions. To compute this duration, we perform two additional scans of the specimen with overlapping subpopulation of cells stained with IddU  BrdU or BrdU markers (cf. Supplementary). The goal is to quantify the proportion of cells in each subpopulation. Segmentation is first carried out on the entire population of nuclei (Hoechst channel) and is followed by computing an intensity-related measure for each nucleus within the two other scans. Owing to the inhomogeneous fluorescence labeling for each subpopulation and the variability between experiments, automatic distinction using a simple intensity threshold fails. Instead, we compute a threshold on the total variation of the signal. Finally, the cell cycle duration is given by the ratio of stained nuclei:where t is the time interval between IddU and BrdU injections, N total is the total number of nuclei (on the Hoechst channel), N IddUBrdu is the number of nuclei in the first population and N Brdu is the number of nuclei in the second population. With this setup, we obtain a consistent mean cycle time of 22.7 h. (standard deviation: 2.7 h.) over four different samples at the looped heart tube stage. This type of application can be adapted for more advanced studies to quantify cell proliferation. By measuring such ratio in various regions of the tissue, cell proliferation maps can be computed, thus providing a deeper insight into tissue growth underlying shape changes.
Extraction of centrosomenucleus axesCell polarity is an important feature characterizing organ morphogenesis. Oriented deformation is the outcome of oriented cell behavior, which in turn reflects intrinsic cell polarity (). One typical polarity marker is the position of the centrosome with respect to the nucleus of the cell (). To study this orientation, we acquired an additional scan of the specimen (cf. Supplementary Data Biological and imaging protocol), in which the centrosomes are fluorescently stained and appear in the images as small bright isotropic spots (cf. Supplementary). Identification of the centrosomes is performed using a wavelet-based approach () that consists in a multi-scale decomposition of the input signal using un-decimated wavelets, followed by an adaptive extraction of spot-like structures. After the extraction, each centrosome is paired with the nearest neighboring nucleus, and the resulting axis of cell polarity is considered valid if it is located within a cell. We validated this procedure by randomly selecting 90 pairs from three different experiments. Our algorithm obtains a correct rate of 28 of 30 pairs for the first scan, 25 of 30 pairs for the second and 28 of 30 for the third, yielding a global accuracy of 90%. The remaining errors are due to the inexact segmentation of nuclei and cells mostly present in deeper Z sections, and were removed for subsequent analyses.illustrates such a map computed on a real dataset.
Extraction of cell division axesThe orientation of cell division is also of interest to characterize tissue growth. In any given scan of a heart specimen, the number of cells in mitosis is limited (e.g. 51% are in anaphase). To increase this number, we perform an additional scan of the specimen in which cytoplasmic bridges are fluorescently stained. The cytoplasmic bridge links recently divided sister cells, totalizing between 12 and 17% of the total cell population. The division orientation of interest is defined by the axis linking the centroids of sister cells (see Supplementary Data for the detailed identification algorithm). We evaluate the performance of the proposed algorithm by manually counting the number of correctly associated sister cells over three different scans. Out of 160 cells considered in division by an expert, 139 were correctly identified as sister cells, i.e. 87% accuracy. The remaining errors are due to cells that were missed during the segmentation process and to poorly stained bridgesthat are not well segmented. We stress that this automated annotation process dramatically decreases the analysis time compared with manual analysis (from several hours to a few minutes). An illustrative map of extracted cell division axes is shown in, where each axis indicates the direction joining the newly divided sister cells.
DISCUSSIONWhile this work has been tailored for imaging data produced via standard confocal microscopy techniques, we believe the proposed approach is directly amenable to larger samples with future imaging systems, and will be of great value when studying tissues with complex geometry (). In the described workflow, the major source of segmentation error is the low intensity in deep tissue sections. One of the direct consequences is that the nucleus pre-detection step is not always able to capture the nucleus as a whole (notably due to the heterogeneous labeling), therefore yielding more than one object per nucleus, and hence over-segmentation. This problem is also described for watershed-based processes, and solutions to reduce such artifacts using prior knowledge are currently in development (). On a similar note, we stress that the proposed workflow enforces a strong semantic relation between the segmentation of the nuclei and that of the cells, based on the assumption that cells are mono-nucleated. While this assumption holds for the current development stage of the observed tissue, analysis at later stages of development with the appearance of multi-nucleated cells would require similar care to ensure that a single cell can be extracted from a subset of detected nuclei.
CONCLUSIONWe have presented a comprehensive framework for automatic extraction of nuclei and cells from dense and highly cluttered environments in 3D microscopy of biological tissue. The proposed framework combines a number of robust PDE-derived approaches that jointly exploit nucleus and cell fluorescence information, and provides an efficient toolset for robust quantification of complex features. The approach was applied to study the developing mouse heart and was validated on three different applications, illustrating how developmental biology can benefit from computational approaches to facilitate the understanding of tissue development and morphogenesis.
The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
, 2, 3 represent the amount of diffusivity along ~ v 1 , ~ v 2 , ~ v 3 , which are the eigenvectors of the structure tensor defined as follows: J rI   G  rI rI   3 where each component of the resulting matrix of the tensor product is convolved with a Gaussian G of standard deviation. The structure tensor captures the contrast and orientation of the structures (in a radius defined by the integration scale ) Fig. 1. Overview of the proposed workflow for nucleus and cell extraction from 3D fluorescence images of dense tissues (cf. Supplementary Fig. S1 for a detailed view and associated parameter values)
Extracting 3D cell parameters from dense tissue environments at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
S.Pop et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
IMPLEMENTATION The presented framework is developed in Java and is available on the free open-source Icy platform (de Chaumont et al., 2012; http://icy.bioimageanalysis.org/). Computations are conducted on a 1.7 GHz quad core processor with 8 GigaBytes of RAM. The total processing time per scan is $40 min, depending on the total number of nuclei/cells in the scan. All PDE-based approaches are implemented using an explicit time-stepping scheme with forward and backward finite difference approximations. It is worth noting that the current implementation is software-based (although it exploits multiple cores), while graphics hardware is used for real-time viewing of the 3D scene during its evolution. Hardware implementation of the workflow could further decrease the computation time, although iterative processes such as energy-minimization techniques benefit less from hardware implementation than single-pass processes. 4 RESULTS Our approach was validated for efficiency and robustness on both generated and real imaging data (cf. Supplementary Data). We report here three applications of the proposed framework dedicated to the quantitative analysis of the developing mouse heart. We first present results on measuring the duration of the cell cycle using differential fluorescence labeling. We then focus on the extraction of two descriptors of tissue anisotropy, namely the orientation of the centrosome-nucleus axes and the Fig. 5. Nuclei segmentation result in 2D axial and orthogonal views. (A) Raw data (red: membranes; blue: nuclei). (B) Segmented nuclei shown in false colors
