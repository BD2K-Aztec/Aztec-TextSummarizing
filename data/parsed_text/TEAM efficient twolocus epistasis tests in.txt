As a promising tool for identifying genetic markers underlying phenotypic differences, genome-wide association study (GWAS) has been extensively investigated in recent years. In GWAS, detecting epistasis (or geneâ€“gene interaction) is preferable over single locus study since many diseases are known to be complex traits. A brute force search is infeasible for epistasis detection in the genome-wide scale because of the intensive computational burden. Existing epistasis detection algorithms are designed for dataset consisting of homozygous markers and small sample size. In human study, however, the genotype may be heterozygous, and number of individuals can be up to thousands. Thus, existing methods are not readily applicable to human datasets. In this article, we propose an efficient algorithm, TEAM, which significantly speeds up epistasis detection for human GWAS. Our algorithm is exhaustive, i.e. it does not ignore any epistatic interaction. Utilizing the minimum spanning tree structure, the algorithm incrementally updates the contingency tables for epistatic tests without scanning all individuals. Our algorithm has broader applicability and is more efficient than existing methods for large sample study. It supports any statistical test that is based on contingency tables, and enables both family-wise error rate and false discovery rate controlling. Extensive experiments show that our algorithm only needs to examine a small portion of the individuals to update the contingency tables, and it achieves at least an order of magnitude speed up over the brute force approach.
INTRODUCTIONGenetic association analysis examines the statistical correlation between an organism's genotype with its phenotype. With the development of high-throughput genotyping technologies, genetic variation of human and other model organisms has been measured at genome-wide scale. As the most abundant source of genetic variation, the number of single nucleotide polymorphism (SNPs) in public databases (dbGaP, JAX) is up to millions. Genome-wide association study (GWAS) has been shown to be a promising tool to locate the genetic factors that cause phenotypic differences (). Epistasis, or genegene interaction detection, has received increasing attention in complex trait analysis. Different from singlelocus approach, the goal of two-locus epistasis detection is to identify interacting SNP pairs that have strong association with the phenotype. Please refer to, Hirschhorn and, Hoh and Ott (2003) andfor reviews of current progress and challenges in epistasis detection in GWAS. * To whom correspondence should be addressed.There are two grand challenges in epistasis detection. The first is to develop statistical tests that can effectively capture the interaction between SNPs. Various tests have been proposed for two-locus association study, such as the chi-square test, likelihood ratio test and entropy-based test (). Another crucial challenge in two-locus association study is the intensive computational burden imposed by the enormous search space. Suppose that there are N SNPs for M individuals. The overall search space of pairwise interactions is MN(N 1)/2. The large number of tests also causes the multiple testing problem (). Controlling the familywise error rate (FWER) and false discovery rate (FDR) are standard ways to control the error rate (). In the FWER and FDR controlling, permutation test is preferred over simple Bonferroni correction since many SNPs are correlated (). The correlation structure among genotype profiles is preserved across permutations and is incorporated into permutation P-value estimation. The idea of permutation test is to randomly shuffle the phenotype values among the individuals and recalculate the test statistics. The distribution of these test values are used to estimate the null distribution. Permutation test dramatically increases the search space. With K permutations, the entire search space of two-locus association mapping is KMN(N 1)/2. Consider a moderate GWAS setting, in which M = 1000, N = 100 000 and K = 1000. The size of the search space is about 510 15. Apparently, a brute force enumeration of the search space is infeasible and thus efficient algorithms are in demand. Although the computational challenge of epistasis detection has been well recognized, the algorithmic development is still very limited. For a small number of SNPs, e.g. from tens to a few hundreds, exhaustive algorithms that explicitly enumerate all possible SNP combinations have been developed (). These methods are not scalable for genome-wide computing. Genetic algorithm () has been proposed. This approach is heuristic, which does not guarantee to find the optimal solution. To avoid explicitly exploring the entire search space, a common heuristic used in epistasis detection is a two-step approach (). First, a subset of SNPs are selected according to certain criteria. Then the selected SNPs are used for subsequent epistatic analysis. However, the SNP screening process suffers from the same problem as the single-locus approach. SNPs with strong epistasis but low marginal effects are likely to be filtered out (). Recently, the approach based on search space pruning has been shown to be able to dramatically speed up the process of epistasis detection without compromising the optimality of the results. FastANOVA () and FastChi () are specifically designed for ANOVA test and chi-square test,respectively. The COE algorithm () is a more general approach that is applicable to all convex tests. Utilizing an upper bound derived for the test being used, these algorithms only need to examine a small number of promising SNP pairs and prune the SNP pairs that are proven to have no strong association with the phenotype. Unlike heuristic approaches, these algorithms are guaranteed to find the optimal solution. Although these methods provide promising alternatives for GWAS, there are two major drawbacks that limit their applicability. First, they are designed for relatively small sample size and only consider homozygous markers (i.e. each SNP can be represented as a {0,1} binary variable). In human study, however, the sample size is usually large and most SNPs contain heterozygous genotypes and are coded using {0,1,2}. These make existing methods intractable. Second, although the FWER and the FDR are both widely used for error controlling, existing methods are designed only to control the FWER. From a computational point of view, the difference in the FWER and the FDR controlling is that, to estimate FWER, for each permutation, only the maximum two-locus test value is needed. To estimate the FDR, on the other hand, for each permutation, all two-locus test values must be computed. Further details of the FWER and the FDR controlling are described in Section 2. In this article, we propose an exhaustive algorithm, TEAM (Tree-based Epistasis Association Mapping), for efficient epistasis detection in human GWAS. TEAM has several advantages over previous methods. @BULLET It supports to both homozygous and heterozygous data.@BULLET By exhaustively computing all two-locus test values in permutation test, it enables both FWER and FDR controlling.@BULLET It is applicable to all statistics based on the contingency table. Previous methods are either designed for specific tests or require the test statistics to satisfy certain property. @BULLET Experimental results demonstrate that TEAM is more efficient than existing methods for large sample study. TEAM incorporates permutation test for proper error controlling. The key idea is to incrementally update the contingency tables of two-locus tests. We show that only four of the 18 observed frequencies in the contingency table need to be updated to compute the test value. In the algorithm, we build a minimum spanning tree () on the SNPs. The nodes of the tree are SNPs. Each edge represents the genotype difference between the two connected SNPs. This tree structure can be utilized to speed up updating process for the contingency tables. A majority of the individuals are pruned and only a small portion are scanned to update the contingency tables. This is advantageous in human study, which usually involves thousands of individuals. Extensive experimental results demonstrate the efficiency of the TEAM algorithm.
THE PROBLEM OF TWO-LOCUS EPISTASIS DETECTION IN HUMAN GWASSuppose that the genotype dataset consists of N SNPs {X 1 ,...,X N } for M individuals {S 1 ,...,S M }. We adopt the convention of using 0 and 2 to represent the homozygous majority and homozygous minority genotypes, respectively, and 1 to represent the heterozygous case. Let Y 0 {0,1} be the phenotype of interest (0 for controls and 1 for cases). Let Y ={Y 1 ,...,Y K } be the set of K permutations of Y 0. In each permutation Y k , the phenotype labels are randomly reassigned to individuals with no replacement.shows an example dataset of SNPs and phenotype permutations. The genotype dataset consists of six SNPs {X 1 ,...,X 6 } for 24 individuals {S 1 ,...,S 24 }. Individuals {S 1 ,...,S 12 } are cases and {S 13 ,...,S 24 } are controls. The phenotype is permuted five times, i.e. Y ={Y 1 ,...,Y 5 }. Let T denote the statistical test to be used. Specifically, we represent the test value of SNP X i and phenotype Y k (0  k  K) as T (X i ,Y k ), and represent the test value of SNP pair (X i X j ) and Y k as T (X i X j ,Y k ). A contingency table that records the observed values of certain events, is the basis of many statistical tests. Tables 24 show contingency tables for the single-locus tests T (X i ,Y k ) and T (X j ,Y k ), genotype relationship between SNPs X i and X j and two-locus test T (X i X j ,Y k ), respectively. Due to the large number of hypotheses being tested, multiple testing problem has received considerable attention in GWAS. Controlling the FWER and FDR are two widely used approaches to control the error rate. The FWER is the probability of having i218Page: i219 i217i227 TEAMat least one false positive. The FDR is the expected proportion of false positives among rejected hypotheses. Permutation test is the standard way to estimate the null distribution in both approaches. Next, we briefly describe the typical procedures of the FWER and FDR control. For statistical background of these approaches, refer tois used as the null distribution. Given an error rate threshold , the critical value T  is the K-th largest value inis considered significant if its test value with the original phenotype Y 0 exceeds the critical value, i.e.The FDR controlling procedure: let PV represent the set of the pooled test values of all permutation tests,|t  PV }|/|PV |, i.e. the proportion of the values in PV that are no less thanIn the FWER controlling, we only need the maximum test value of each permutation. To control the FDR, all test values need to be computed to estimate the P-value of the original tests. The existing algorithms, such as FastChi () and COE (), prune the SNP pairs having weak associations. Thus they cannot be used to control the FDR. Our algorithm, TEAM, exhaustively computes the test values of all SNP pairs for every permutation. It can be used for both the FWER and FDR controlling. In this article, we mainly focus on the problem of permutation test, since it is the most computationally intensive procedure. Testing SNP pairs using original phenotype can be treated as a special case of permutation test.
X.Zhang et al.contingency tables. For any test T based on the contingency table, to calculate the two-locus test value T (X i X j ,Y k ), one needs all 18 observed frequencies for the events in the two-locus contingency table shown in. The following theorem shows that we only need four of the 18 values to calculate the two-locus test value given the three contingency tables in Tables 2 and 3.
Theorem 3.1. For SNPs X i , X j and permutation Y k , given the observed frequencies in Tables 2 and 3, specifically, the values of, all of the observed frequencies in
can be determined if the values of
Proof. See Appendix.Suppose that we have all the single-locus contingency tables, i.e.. Given a SNP pair (X i ,X j ),can be calculated accordingly. In the following, we show that these values can be computed incrementally utilizing a minimum spanning tree built on SNPs. We focus on the incremental process for
BUILDING THE MINIMUM SPANNING TREE ON THE SNPSTo build a minimum spanning tree () on the SNPs, let the SNPs {X 1 ,X 2 ,...,X N } be the nodes and SNP pairs (X i X j ) (i = j) be the (undirected) edges. For each edge (X i X j ), we denote its weight (the number of individuals having different genotypes in the two SNPs) as w(X i X j ). A spanning tree T is a tree that spans (connects) all SNPs. Let V (T ) be its node set and E(T ) be its edge set. A minimum spanning tree is a spanning tree whose weight, is no greater thanany other spanning tree.shows the minimum spanning tree built using the example dataset in. The number on each edge represents its weight. For example, in X 3 and X 2 , there are six individuals, {S 2 ,S 8 ,S 10 ,S 12 ,S 15 ,S 20 }, having different genotypes. For any individual, the genotype difference from X i to X j can be any one of the six combinations, i.e. 0  1 (indicating that the genotype in X i is 0, and the genotype in X j is 1), 1  0, 0  2, 2  0, 1  2 and 2  1. Using the example dataset in,shows the genotype differences between the connected two SNPs in the minimum spanning tree in. We use (X i X j ) {uv} (u,v {0,1,2}) to represent the set of individuals whose genotype in X i is u and genotype in X j is v. For example,
INCREMENTALLY UPDATING OBSERVED FREQUENCY O d 2In this section, we discuss how to update O d 2 by utilizing the minimum spanning tree. For clarity, from now on, we useNext, we show that for any SNP pair (X i X j ) and an edge, how to update the value for). From the contingency tables in4, it is easy to see thatThe following theorem shows that, given, using the genotype difference associated with edge (X j X j ), we can get the value ofTheorem 5.1. For any SNP pair
Proof. See Appendix.Example 5.2. Using the example dataset in, let i = 3, j = 2, j = 5, and k = 4, i.e. we consider SNP pair (X 3 X 2 ),. Genotype difference between the connected SNPs in the minimum spanning tree shown in0Page: i221 i217i227 TEAM
permutation Y 4 and the edge (XSo far, we have discussed the procedure to update the valuefor a specific phenotype permutation Y k. This procedure can be easily extended to handle all the permutations. From Theorem 5.1, for any permutation Y k , to update the value of, we need the value of D(X i ,Y k ) and the genotype difference associated with edge (X j X j ). Note that the genotype difference is fixed once the minimum spanning tree is built. Next, we discuss how to computein a batch mode in detail. Let D K (X i ) be a list of M entries, with each entry corresponding to an individual. For each individual S m , we record in D K (X i )the set of phenotypes satisfying (X i = 1Y k = 1). For example, consider the dataset in, we have that D K (X 3 )={Y 2 ,Y 3 }.shows the entries of D K (X 3 ). Only non-empty entries, i.e.=, are shown in the table. It is easy to see that, for any X i and Y k , we can getis the set of individuals whose corresponding entries in D K (X i ) contain Y k as an element, i.e.For example, using the example dataset in, from, we know that D() and the genotype difference information associated with edge (X j X j ). First,), which can be defined in a similar way to that of D K (X i ): for each individual S m , we record in F K (X i )the set of phenotypes satisfying (X i = 2Y k = 1).
THE TEAM ALGORITHMTEAM examines SNP pairs through a double loop, where the outer loop visits a leaf node at a time, and the inner loop traverse the rest of the tree, starting from the parent node of the leaf. Let. Let L(T )  V (T ) be the set of leaf nodes of the minimum spanning tree T. For any leaf node X i  L(T ), let AP(The overall algorithm is summarized in Algorithm 1. Given the SNPs, we first enumerate and store all single-locus contingency tables. We then build the minimum spanning tree T , with genotype difference associated with each edge. For leaf node X i , we compute), we delete X i from T and repeat the procedure for the remaining leaf nodes. Time complexity: the time complexity on generating all singlelocus contingency tables and building the minimum spanning tree is O(MNK) and O(MN 2 ), respectively. The time complexity toThus, the overall time complexity of TEAM is O(MNK +MN 2 +W T NK). Note that the complexity of the brute force approach is O(MN 2 K). The number of SNPs N is the dominant factor. Space complexity: the dataset size is O(M(N +K)). The space needed to store all single-locus contingency tables is O(NK). The size of tree T is O(W T ). The size ofThus, the total space complexity of TEAM is O(M(N +K)+ K(N +M)+W T ). Note that we can do incremental computation using any exploration order. TEAM utilizes minimum spanning tree to update the contingency tables. The reason is that the cost of such update depends on the difference between the SNPs. The more similar they are, the lower the cost. Since minimum spanning tree has the minimum weight W T over all spanning trees, using it to guide the computation leads to optimal efficiency. It is not absolutely necessary to use a minimum spanning tree. As long as the tree is close to a minimum spanning tree, we should expect good performance. An implementation issue in building the minimum spanning tree is that we need O(N 2 ) space to store all pairwise differences between the SNPs. In practise, we divide the SNPs into sub groups of equal size. A minimum spanning tree is built for each group. Then the sub trees are merged to a larger tree by randomly connecting leave nodes. The tree built in this way is an approximate minimum spanning tree. Our focus in this article is not to build an optimal minimum spanning tree, but to use the tree structure for efficient updating. Refer to Eisner (1997) and Graham and Hell (1985) for surveys on minimum spanning tree construction. In the experiments, we show the performance evaluation using different spanning trees.
EXPERIMENTAL RESULTSIn this section, we present extensive experimental results on the performance of the TEAM algorithm. TEAM is implemented in C++. We first evaluate the efficiency of TEAM. Then, we present the findings of epistasis detection in simulated human genome-wide study.
Efficiency evaluationWe use both simulated human and real mouse for the efficiency evaluation experiments. The experiments are performed on a 2.6 GHz PC with 8G memory running Linux system.
Human dataThe human datasets are generated by the simulator Hapsample (), which is publicly accessible from the web site http://www.hapsample.org. We evaluate the performance of TEAM by comparing it with the brute force approach since there is no previous algorithm readily applicable to human datasets. Note that the brute force approach is very time consuming, we use a moderate number of SNPs and permutations in the experiments so that the brute force approach can finish in a reasonable amount of time. Unless otherwise specified, the default experimental setting is the following: #individuals = 400, #SNPs = 10 000, #permutations = 100, and the case/control ratio is 1. These experimental settings are chosen to demonstrate the efficiency gain offered by TEAM over the brute force implementation. TEAM can handle much larger datasets. The performance of TEAM is expected to follow the same trends presented in this section. TEAM contains three major components: building the minimum spanning tree, updating the contingency tables, and calculating the actual test values. Note that TEAM can be applied to any statistics defined on the contingency table. With different statistics, the only difference in runtime would be caused by the last component calculating the statistics. In the experiments, we choose chi-square test as our statistic.shows the running time comparison of TEAM and the brute force approach using different experimental settings. The y-axis is in logarithm scale. In these figures, we also show the detailed runtime of these three components.shows the percentage of individuals pruned by TEAM under different experimental settings. Since in theory we can update the contingency tables in any exploration order, in the table, we also show the pruning effect of using a random spanning tree and a linear spanning tree to guide the updating process. The random spanning tree is generated by starting from a randomly picked SNP and growing edges that connect the remaining SNPs in a random order. The linear tree is a single path connecting all SNPs sequentially. From the table, we can see that TEAM prunes more effectively than the other two updating methods. In the table, we also show the ratio of the tree weights and the size of the SNP dataset, i.e. W T /(M N), which is a determining factor of the pruning ratio. Note that varying i222depicts the runtime comparison when varying the number of SNPs. TEAM is more than an order of magnitude faster than the brute force approach. Among the three components of TEAM, the procedures on building the minimum spanning tree and calculating test values only take a small portion of the total runtime of TEAM. The runtime of TEAM is dominated by the cost of updating the contingency tables. As will be shown later, TEAM prunes most of the individuals when updating the contingency tables. Ind, we can also observe a similar one to two orders of magnitude speed up of TEAM over the brute force approach when varying the number of individuals, the number of permutations and the case/control ratio.
Mouse dataThe mouse datasets is extracted from a set of combined SNPs from the 10 K GNF (http://www.gnf.org/) mouse dataset and the 140 K Broad/MIT mouse dataset (). This merged dataset has 1 56 525 SNPs for 71 mouse strains. The missing values in the dataset are imputedPage: i224 i217i227using NPUTE (). We compare TEAM and the recently proposed COE algorithm (), which is specifically designed for association study in mouse datasets. The default experimental setting is as follows: #individuals = 70, #SNPs = 10 000, #permutations = 100, and the case/control ratio is 1.shows the comparison results. In the figure, we also plot the runtime of the brute force approach.shows the runtime of the three approaches when varying the number of SNPs. It is clear that both TEAM and COE are orders of magnitude faster than the brute force approach. TEAM is about twice faster than COE.shows the runtime comparison when varying the number of individuals. From the figure, COE is more suitable for datasets having small number of individual. As the number of individuals increases, the TEAM algorithm becomes more efficient than COE. Note that in human study, the number of individuals usually ranges up to thousands, much larger than that in typical mouse datasets.
X.Zhang et al.
100
Epistasis detection in simulated human GWASIn this section, we report the results of epistasis detection using simulated human GWAS data generated by Hapsample. In total, we generate four datasets, each of which has 112 036 SNPs for 250 cases and 250 controls. In each dataset, a disease causal interacting SNP pair is embedded. The embedded SNP pairs are: (rs768529, rs3804940) in dataset 1, (rs10495728, rs521882) in dataset 2, (rs1016836, rs2783130) in dataset 3 and (rs648519, rs1012273) in dataset 4. We use standard chi-square test with 500 permutations. Similar results can be found by using likelihood ratio test.With an overall FDR threshold of 0.005,shows the identified significant SNP pairs using TEAM. TEAM successfully identified the embedded SNP pairs in all simulated datasets. The embedded SNP pairs are labelled with stars '*'. The table shows the SNP loci on the genome. For example, in dataset 1, we embed SNP pair rs768529 and rs3804940, which are located on chromosome 1 at position 51 946 762 bp and chromosome 3 at 7 520 545 bp, respectively. The FWER for each reported SNP pair is also shown. Note that, for a SNP pair, an FDR (or FWER) value of 0 indicates that permutation tests do not generate any test value larger than value of the reported SNP pair. In dataset 1, except for the embedded SNP pair (rs768529, rs3804940), five other SNP pairs are also reported. One of the embedded SNP, rs768529, is involved in all the five pairs. A closer look at the other SNPs in the reported SNP pairs shows that they are all adjacent to the embedded SNP rs3804940. The normalized linkage disequilibrium () between rs3804940 and the other five SNPs are D (rs3804940, rs756084)= 1, D (rs3804940, rs779742)= 0.477, D (rs3804940, rs1872393)= 0.442, D (rs3804940, rs779744)= 0.442 and D (rs3804940, rs6764561)= 0.454, indicating there is strong linkage disequilibrium between them.Page: i225 i217i227
CONCLUSION AND FUTURE WORK
TEAMmakes the problem computationally even more intensive. In this article, we propose an efficient algorithm, TEAM, for epistasis detection human GWAS. TEAM has the same strength as the recently developed epistasis detection methods, i.e. it guarantees to find the optimal solution. Compared with existing methods, TEAM is more efficient in large sample study, and offers broader applicability. Existing methods designed for homozygous SNPs cannot be used for human data where most SNPs are heterozygous. TEAM, on the other hand, can handle both homozygous and heterozygous SNPs. Since it exhaustively enumerate all SNP pairs, TEAM can be used to control the FWER and FDR, both of which are widely used in controlling error in GWAS; while previous methods only control the FWER. Existing methods need to exam the formulation of the statistic. TEAM is focused on efficiently updating contingency tables rather than any specific statistic. It can, therefore, be used for any statistical test based on contingency table regardless of its formulation. In this artcile, we focus on the disease phenotypes that can be represented as binary variables. Many association studies involve phenotypes measured as continuous variables. We will investigate how to apply the idea of the current algorithm to quantitative phenotypes in the future study. Funding: National Science Foundation (awards IIS0448392, IIS0812464, partially).
Conflictof Interest: none declared.
X.Zhang et al.
APPENDIX
Proof of Theorem 3.1Proof. From the four contingency tables shown in Tables 24, it is easy to get the following linear equation system:1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 00 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1The rank of the above linear system is 14. We thus take 14 rows {4,6,10,11,12,13,14,15,16,17,18,19,20,21}, which form a full rank matrix. The row reduced echelon form of this non-redundant linear system is 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 O S O W +O D +O F 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 O P O V 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 O G O U 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 O T O D 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 O Q 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 O H 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 O W O D O F 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 O V 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 O U 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 O D 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 O R O F 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 O O 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 O L 0 0 0 0 0 0 0 0 0 0 0Thus, we have the following solution:
Proof of Theorem 5.1Proof. It suffices to show thatThis is the same as to show thatThis is clearly true, hence completes the proof.
i227
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
FREE VARIABLES IN THE CONTINGENCY TABLE OF TWO-LOCUS TEST Let E event and O event denote the expected frequency and observed frequency of an event in Tables 24. Note that each event represents a subset of individuals. For example, event D is a subset of individuals satisfying (X i = 1Y k = 1), and O D represents its observed frequency, i.e. O D =|D|. Using the dataset in Table 1, consider X 3 and Y 4 (i.e. i = 3 and k = 4), we have D ={S 10 ,S 13 ,S 19 }, and O D = 3. Many statistics, such as chi-square test and likelihood ratio test are defined as functions of the observed frequencies in i219 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
i225 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
