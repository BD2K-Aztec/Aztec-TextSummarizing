Motivation: Metabolite identification from tandem mass spectrometric data is a key task in metabolomics. Various computational methods have been proposed for the identification of metabolites from tandem mass spectra. Fragmentation tree methods explore the space of possible ways in which the metabolite can fragment, and base the me-tabolite identification on scoring of these fragmentation trees. Machine learning methods have been used to map mass spectra to molecular fingerprints; predicted fingerprints, in turn, can be used to score candidate molecular structures. Results: Here, we combine fragmentation tree computations with kernel-based machine learning to predict molecular fingerprints and identify molecular structures. We introduce a family of kernels capturing the similarity of fragmentation trees, and combine these kernels using recently proposed multiple kernel learning approaches. Experiments on two large reference datasets show that the new methods significantly improve molecular fingerprint prediction accuracy. These improvements result in better metabolite identification, doubling the number of metabolites ranked at the top position of the candidates list.
INTRODUCTIONMetabolomics deals with the analysis of small molecules and their interactions in living cells. A central task in metabolomics experiments is the identification and quantification of the metabolites present in a sample. This is mandatory for subsequent analysis steps such as metabolic pathway analysis and flux analysis (). Mass spectrometry (MS) is one of the two predominant analytical technologies for metabolite identification. Identification is done by fragmenting the metabolite, for example, by tandem MS (MS/MS), and measuring the massto-charge ratios of the resulting fragment ions. The measured mass spectra contain information about the metabolite, but extracting the relevant information is a highly non-trivial task. Several computational methods have been suggested to identify the metabolites from MS/MS spectra. Mass spectral databases (spectral libraries) have been created (e.g.), which allow us to search measured mass spectra. Unfortunately, this approach can only identify 'known unknowns' where a reference measurement is available. Fragmentation trees are combinatorial models of the MS/MS fragmentation process. B  ocker and Rasche (2008) suggested fragmentation trees for identifying the molecular formula of an unknown compound. Later, fragmentation trees were shown to contain valuable structural information about the compound (). The relation between spectral and structural similarities has been studied by. A kernel-based machine learning approach for metabolite identification was recently introduced by, relying on predicting the molecular fingerprints as an intermediate step. Molecular fingerprints are given as bit vectors with each bit describing the existence of certain molecular property such as substructures in the molecule. After the prediction, imposing some scoring strategy, the predicted molecular fingerprints are used for searching some chemical database and finally the ranked list of candidates are generated (). Besides these two approaches, methods have been suggested for predicting MS/MS spectra from molecular structures (); commercial software packages also exist for this task. Such simulated spectra can be used to replace the notoriously incomplete spectral libraries by molecular structure databases (). Combinatorial fragmentation of molecular structure serves the same purpose (). Finally, we can search spectral libraries for similar compounds, by comparing either MS/ MS spectra () or fragmentation trees (). Seefor recent reviews. We propose a joint strategy that combines fragmentation trees and multiple kernel learning (MKL) to improve molecular fingerprint prediction and, subsequently, the metabolite identification. We first outline the metabolite identification framework and introduce fragmentation trees and their computation. Next, we introduce a family of kernels for fragmentation trees, consisting of simple node and edge statistics kernels as well as path and subtree kernels that use dynamic programming (DP) for efficient computation. We then describe state-of-the-art methods for MKL. In these experiments, we evaluate different MKL algorithms with regards to the fingerprint prediction and the metabolite identification.gives an overview for our metabolite identification framework through MKL. Fragmentation trees are computed first, followed by the computation of kernels. MKL approaches are used to integrate different kernels for molecular fingerprint prediction. The final step of the framework is to query molecular structure databases with the predicted molecular fingerprint using a probabilistic scoring function. *To whom correspondence should be addressed.  The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by/ 3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com.
METHODSThe advantages of the kernel-based machine learning framework are: that it easily allows incorporating the combinatorial fragmentation trees by kernelizing the model; that it can query molecular structure databases which are much larger than MS/MS spectral libraries; and that molecular fingerprints can help to characterize the unknown metabolite and may shed light for de novo identification.
Fragmentation treesB  ocker and Rasche (2008) introduced fragmentation trees to predict the molecular formula of an unknown compound using its MS/MS spectra. A fragmentation tree annotates the MS/MS spectra of a compound via assumed fragmentation processes. Nodes are molecular formulas, representing the unfragmented molecule and its fragments. Edges represent fragmentation reactions between fragments, or the unfragmented molecule and a fragment. Details on the computation can be found in B  ocker and Rasche (2008) and; here, we quickly recapitulate the method. We assume that MS/MS spectra recorded at different collision energies have been amalgamated into a single spectrum, as described in Section 3. We decompose all peaks in the amalgamated spectrum, finding all molecular formulas that are within the mass accuracy of the measurement. For each decomposition of the parent peak, we build a fragmentation graph which contains all possible explanations for each peak, where nodes are colored by the peaks they originate from. We insert all edges between nodes that are not ruled out by the molecular formulas: that is, a product fragment can never gain atoms of any element through the fragmentation. Edges of this graph are then weighted, taking into account the intensity and mass accuracy of the product fragment, the mass of the loss and prior knowledge about the occurrence of certain losses.Under the parsimony assumption, we then compute a colorful subtree of this graph with maximum weight. Unfortunately, finding this tree is an NP-hard problem (). Nevertheless, we can compute optimal trees in a matter of seconds using Integer Linear Programming (). For each peak, this tree implicitly decides whether it is noise or signal and, in the later case, assigns the molecular formula of the corresponding fragments and the fragmentation reaction it resulted from. The score of the tree is the sum of its edge weights. Candidate molecular formulas of the parent peak are ranked by this score, which is the maximum score of any tree that has this molecular formula as its root. Different from B ocker and Rasche (2008) and Rasche et al. (2011), we used a modified weighting function for the edges of the fragmentation graph. With these new weights, the above optimization can be interpreted as a maximum a posteriori estimator of the observed data. We weight edges by the logarithmic likelihood that a certain fragmentation reaction occurs: for this, we consider the intensity and mass deviation of the product fragment peak, the loss mass and chemical properties of the molecular formula as proposed in Kind and Fiehn (2007): namely, the ring double bond equivalent and the hetero atoms and carbon atoms ratio. Furthermore, we favor a few common losses that were learned from the data, and penalize implausible losses and radicals. Such weights have already been used in B  ocker and Rasche (2008) and Rasche et al.; different from there, we did not choose parameters ad hoc but rather learned them from the data. Details about these new weights will be published elsewhere.
Kernels for fragmentation trees and MS/MS spectra
Probability product kernel Heinonen et al. (2012) comparedseveral kernels that can be computed directly from the MS/MS spectra without the knowledge of the fragmentation trees. In their studies, simple peak and loss matching kernels were found inferior to the probability product kernel (PPK). Thus, we use the PPK as the baseline comparison with the fragmentation tree kernels. The idea of the PPK is the following: each peak in a spectrum is modeled by a 2D Gaussian distribution with the mass-to-charge ratio as one dimension, and the intensity as the other. All-against-all matching between the Gaussians is performed to avoid problems arising from alignment errors. Formally, a spectrum is defined as =f1;. .. ; ' g, a set of ' peaks k= k; k  2R 2 ; k=1;. .. ; '  consisting of the peak mass (k) and the normalized peak intensity (k). The k-th peak of the mass spectrum is represented by p k =N k; S centered around the peak measurement and with covariance shared with all peakswhere the variances 2 for the mass is estimated from data and 2 is tuned by cross-validation. No covariance is assumed between peak distributions. The spectrum is finally represented as a mixture of its peakThe PPK K peaks () between the peaks of two spectra , 0 is given by:k  0 k 0  T S 1 k  0 k 0 :The precursor ion is the compound selected in the first round of MS/ MS and further fragmented in the second round. As a result, the difference (loss) between the peak (k) and the precursor ion prec() = ((p),0) is also important, where (p) is the mass of the precursor ion. We can model the difference with distribution p ^ k =N  ^ k; S, where ^ k=jprec  kj. This feature is denoted as loss and corresponding kernel matrix as K loss. Experiments inshowed that the combined kernel K peaks + K loss achieved best accuracy and computational efficiency among the spectral kernels.In the following, we define a set of kernels for fragmentation trees that will allow us to transfer the power of the fragmentation tree approach to the kernel-based learning algorithms for molecular fingerprint prediction and metabolite identification. A fragmentation tree T = (V, E) consists of a nodes set V of molecular formulas (corresponding to the fragments) and an edges set E V  V (corresponding to the losses). Let r denote the root of T.LB: Loss binary, indicates the presence of a loss l in a fragmentation tree T x , that is, LB l x=1 l2Ex. LC: Loss count, counts the number of occurrences of a loss l in a fragmentation tree T x , that is, LC l x=N x l. LI: Loss intensity, uses the average intensity of the terminal nodes with loss l in a fragmentation tree T x , that is,Node-based kernels: the nodes in the fragmentation tree explain peaks in the MS/MS by some chemical formula of the hypothetical fragment. The nodes are unique in a fragmentation tree T, and so are the root losses. To this end, we can omit root losses from the feature vectors. NB: Nodes binary, indicates the presence of a node v in a fragmentation tree T x , that is, NB v x=1 v2Vx. NI: Nodes intensity, uses the intensity of the node if it is presented in a fragmentation tree T x ; that is, NI v x= x v for v 2 V x , and NI v x=0 otherwise. Path-based kernels: these kernels are count common path between two fragmentation treeshere, 'common path' refers to an identical sequence of losses in the two trees. We use DP to efficiently count the number of common paths, that is, the dot product of two feature vectors which are not explicitly constructed. For two fragmentation trees T 1 = (V 1 ,E 1 ) and T 2 = (V 2 ,E 2 ) we compute a DP table Dfor all u 2 V 1 and v 2 V 2. In all cases, the number of common paths is DCommon path counting (CPC). The DP table entry D[u,v] records the count of common path for the subtrees rooted in u and v, respectively. This leads to the following recurrence:Common path with K peaks (CPK). Instead of simply counting the common paths, we use the PPK K peaks to score the terminal peaks. We omit the straightforward but somewhat tedious details.
Fragmentation tree kernelsCommon subtree counting (CSC). In this case, we count the number of 'common subtrees' between T 1 and T 2 , which can be defined analogously to the common paths above. Entry Dnow counts the number of common subtrees for the two subtrees rooted in u of T 1 , and v of T 2. We have to consider three cases: for each pair of children a 2 Cu and b 2 Cv with (u,a) = (v,b) we can either attach the subtrees rooted in a and b; we can use solely the edges (u, a) and (v, b) as a common subtree; or, we can attach no common subtree for this pair of children. But if we choose no subtree for all matching pairs of children, the result would be a tree without edges and, hence, not a valid common subtree. Thus, we have to correct for this case by subtracting one. Hence, the recurrence is:In practice, it is often difficult for MKL algorithms to outperform the uniform combination of the kernels (UNIMKL) where the weights for kernels are equal. However, in some cases, some methods have seen improvements over the uniform combinations. Three algorithms coupled with SVM are considered in the following: centered alignment-based algorithms
i159Metabolite identification through MKL (), quadratic combination of the kernels () and ' p-norm P41 for the kernel weights (). For all the three algorithms, the input will be a set of kernels K=fK k jK k 2 R nn ; k=1;. .. ; qg computed from n data points. The output is a set of m fingerprint properties Y 2 f1; +1g nm which is a multi-label prediction task and each label is trained independently in the experiments.
Centered alignment-based MKL The centered alignmentbased MKL algorithms are based on the observation that the centered alignment score with the target kernel K Y =yy T correlates very well with the performance of the kernel, where y is a single label. Experiments byshow consistent improvements over the uniform combination. In the molecular fingerprint prediction setting, the target kernel is defined as K Y =YY T. Two-stage model are considered in which the kernel weights are learned first and then can be applied to all kernel-based learning algorithms (SVM in this work). The centered kernel matrices are defined by Equation (1):where I is the identity matrix and e is the vector with all ones.The simple independent centered alignment-based algorithm (ALIGN) () computes the alignment score between each kernel matrix K i and the target kernel matrix K Y and combine the kernels asThe alignment maximization algorithm (ALIGNF) () jointly seeks the weight i to maximize the alignment score defined byEquation(2) between the convex combination of the kernel in K and the target kernel K Y =yy T , that is, the following optimization problem:where M= : jjjj 2 =1; ! 0.
Quadratic combination MKLIn this setting, the quadratic combination of kernels (QCMKL) is included in the formulation and the MKL problem is solved by semidefinite programming (). The kernels in K are enriched to a new set ~ K=f ~ K t jt=1;. .. ; qq+1=2g by the following transformation:where i,j = 1,. .. ,q and * denotes the Hadamard product.s:t:! 0; e T =1; ! 0; ! 0: Many standard SDP solvers can be used to find the optimal solutions such as cvx (http://cvxr.com/).
' p-norm MKL While ' 1 norm on the kernel weightsproduces sparse solutions, higher norms p41 produces nonsparse solutions which may be beneficial. A general framework for ' p-norm MKL (' p-MKL) was proposed by. The q kernels correspond to q feature mappings  k : ! H k ; k=1;. .. ; q and l is some convex loss function and the primal problem is then:when the optimization is coupled with hinge loss, the problem has a simple dual form ():where all the variables are all as defined before but p  = p p1. The optimization problem can be solved by alternating the dual variables and the kernel weights via the squared norm on w by the following equations:Based on the above equations, a simple alternating algorithm has been proposed byThe optimization conditions can be the difference of objective function or the duality gap between two subsequent iterations. More detailed, theoretical results and a faster chunking-based algorithm are also presented in Kloft et al. (2011).
Probabilistic scoring of candidate metabolitesGiven a predicted fingerprint associated with a mass spectrum, for metabolite identification, we need to retrieve metabolites with similar fingerprints from a molecular database. Assume ^ y 2 f1; +1g m is a predicted fingerprint and an arbitrary fingerprint y 2 f1; +1g m for some molecule in some molecular database, one can score the y by the following equation as used in FingerID ():is, the Poisson binomial probability for the fingerprint vector y where the cross-validation accuracies  j  m j=1 2 0:5; 1 m of the fingerprints prediction are taken as the reliability scores.
RESULTSTwo MS/MS datasets, 978 compounds downloaded from METLIN () and 402 compounds from MassBank (), both measured by QTOF MS/MS instruments are tested. For each compound, mass spectra recorded at different collision energies were amalgamated before further processing: we normalize MS/MS spectra such that intensities sum up to 100%. We merge peaks from different collision energies with m/z difference at most 0.1, using the m/z of the highest peak and summing up intensities. We discard all but the 30 highest peaks, as well as peaks with relative intensity 50.5%. Next, we compute the fragmentation tree. We assume that we can identify the correct molecular formula from the data: limiting candidate molecular formulas to those present in KEGG (), which is used for searching molecular structures below, the best scoring fragmentation tree identified the correct molecular formula of the compound in 97.1% (96.0%) of the cases for the METLIN (MassBank) dataset. Integrating other sources of information such as MS1 isotope patterns (B  ocker et al., 2009) or retention times would reach even better identification rates. To allow for a meaningful comparison of the power of the different kernels, we therefore use the best scoring fragmentation tree of the correct compound molecular formula. All 11 fragmentation tree kernels proposed in the previous section were computed, along with PPK used incomputed directly from MS/MS, resulting in 12 kernels to be evaluated. Molecular fingerprints were generated using OpenBabel (O') which contains four types of fingerprints (http://openbabel.org/wiki/Tutorial:Fingerprints). FP3, FP4 and MACCS fingerprints (528 bits in total) were generated based on the software predefined SMARTS patterns. In our dataset, more than half of the fingerprint properties have high-class bias rate, with a large majority of the dataset belonging to the positive class (most compounds match the property) or respectively the negative class (most compounds do not match the property). For such fingerprints, the default classifier, one that always predicts the majority class, has high accuracy, although the model is not meaningful. For our performance comparisons, we opted to only include fingerprints with class bias rate 50.9. For each fingerprint property, we separately trained a SVM; for all properties, we used identical training and testing compounds. Five-fold cross-validation was performed and the SVM margin softness parameter (C 2 f2 3 ; 2 2 ;. .. ; 2 6 ; 2 7 g) was tuned based on the training accuracy.
Fingerprint prediction performanceThe micro-average (simultaneous average over fingerprint properties and compounds) accuracy and F1 of the individual kernels on the predictions of fingerprint properties with bias rate 50.9 are shown inwith the SDs computed from different cross-validation folds. The kernel NB achieves the best accuracy and F1 on both METLIN and MassBank. Compared with the PPK, the fragmentation tree kernels are markedly more accurate on average. The improvement of MKL approaches over single kernel SVMs are clear. The t-test between NB and ALIGNF shows the differences of mean accuracy and F1 are indeed very significant with P-values of 4  10 6 and 1.7  10 3 , respectively. The kernel weights learned by different MKL algorithms are shown in the supplementary file. The micro-average accuracy and F1 of the MKL algorithms on the fingerprint properties predictions are shown in, where it can be concluded that averaged overall fingerprints of the MKL methods are quite close. We conducted further pairwise difference testing, where the performance difference of each method on each individual fingerprint property is evaluated.shows the significance level of the sign test on the
i161Metabolite identification through MKL accuracy and F1 on the METLIN and MASSBANK datasets using the different MKL methods. The sign test describes whether one of the methods has higher probability of success (better than the other on a fingerprint) than the other (alternative hypothesis) or not (null hypothesis). From the table, we can deduce that ALIGN and ALIGNF rise slightly above the competition whereas ' 2-MKL and QCMKL are slightly inferior to the rest. The performance of UNIMKL is also respectable. The scatter plots of accuracy and F1 between every pair of the MKL algorithms are shown in the supplementary file.
Metabolite identification performanceThe molecular fingerprint prediction can serve as an intermediate step for metabolites identification, and can be used to search a molecular structure database (). We want to evaluate whether improvements in fingerprint prediction propagate to better metabolites identifications. We will search for molecular structures from the KEGG database. As we assume to know the correct molecular formula, we may filter based on this information to generate our candidate lists. But it turns out that this filter is too strict for a meaningful evaluation, as the number of candidates for each MS/MS spectrum becomes very small and, hence, all kernels show good performance. For amore discriminative evaluation of the kernels, we artificially enlarge the set of candidates: we use all molecular structures in KEGG with mass accuracy window  M  "; M +" as candidates, where M is the true mass of the unknown molecule. For sufficiently large mass accuracy ", this results in candidate lists that allow a meaningful comparison of the kernels. For identification, we want the true molecular structure to be ranked as high as possible in the candidates list.and b shows the fraction of compounds that were ranked higher than certain rank for the two datasets, when searching KEGG with 300 ppm mass inaccuracy to generate the candidates for the two datasets. We notice that the NB kernel is consistently more accurate than PPK. In addition, MKL clearly improves the identification performance, especially the number of top-ranked identifications increases significantly. T-test between the ranks of the ALIGNF and PPK shows a P-value of 0.06 which verifies the improvements in identification by ALIGNF over the PPK is indeed significant. ALIGNF comes on top of the MKL approaches, which is in line with its good fingerprint prediction accuracy and F1 score. The effect of mass accuracy windows during the database retrieval are shown inand d. A narrower 20-ppm mass search window filters out many false candidates, and thus significantly elevates the identification accuracies to 60% on METLIN dataset and 40% on MassBank dataset. However, the effect of improved molecular fingerprint prediction is softened due to the fewer but possibly more similar candidates. An extreme case is observed inin which all the methods shrink to the same result when searching with 20-ppm mass accuracy window.Fig. 2. (a and b) show the performance for identification when searching KEGG using 300-ppm mass window with predicted molecular fingerprints, with fingerprints trained with METLIN and MassBank datasets, respectively. NUM denotes the number of candidate molecules returned per query. (c and d) show the proportion of data that were correctly identified in the top 1 rank against a series of mass windows i163Metabolite identification through MKL
DISCUSSIONThe present work combines the combinatorial fragmentation tree approach with machine learning through a kernel-based approach. We suggest several kernels for fragmentation trees, and show how to fuse their information through MKL. The result significantly enhances molecular fingerprint prediction and metabolite identification. The closest analogs to our fragmentation tree kernels in literature are those defined for parse trees in natural language processing (); our fragmentation trees can be seen as parses of the MS/MS spectra. DP techniques similar to ours are used there for computing kernels between trees (). However, fragmentation trees have important differences to the trees defined between parses of natural language and to kernels comparing molecular structures (Mah e and Vert, 2009). Differently from natural language parses, the node labels have partial order (via their molecular weights) and also the edges have labels. Differently from kernels for molecular graphs, the label spaces of both nodes and edges are vast (subsets of molecular formulae). The comparison with the PPK employed by the FingerID () software shows that the fragmentation tree kernels are able to extract more information out of the MS/ MS spectra. Improvements are seen in both the prediction accuracy and the F1 score. Comparing with FingerID (PPK), the uniform combination of the kernels (UNIMKL) improves the molecular fingerprint prediction significantly in accuracy and F1. As witnessed by many MKL applications, the UNIMKL algorithm is hard to beat. In our result, several MKL algorithms such as ALIGNF and ' 3-norm can give slightly better result than UNIMKL. The improvements in the molecular fingerprint prediction translate to improved metabolite identification. There are several possible routes forward with the current metabolite identification framework. First, post-processing on the candidates list, such as the one proposed by, is necessary when searching a large compound database such as PubChem, because the returned candidates (hundreds to thousands) may share the same fingerprints and there is no way to differ them based only on molecular fingerprints. Second, training a separate SVM for each fingerprint property is clearly an aspect that can be improved upon, for example, by a multi-label classification approach. A still more tempting yet challenging direction would be to replace the two-step identification by an integrated prediction approach. Such an approach would potentially learn to predict the fingerprint properties that are important for discriminating metabolites from each other.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
