Motivation: The field of phylodynamics focuses on the problem of reconstructing population size dynamics over time using current genetic samples taken from the population of interest. This technique has been extensively used in many areas of biology but is particularly useful for studying the spread of quickly evolving infectious diseases agents, e.g. influenza virus. Phylodynamic inference uses a coalescent model that defines a probability density for the genealogy of randomly sampled individuals from the population. When we assume that such a genealogy is known, the coalescent model, equipped with a Gaussian process prior on population size trajectory, allows for nonpara-metric Bayesian estimation of population size dynamics. Although this approach is quite powerful, large datasets collected during infectious disease surveillance challenge the state-of-the-art of Bayesian phylodynamics and demand inferential methods with relatively low computational cost. Results: To satisfy this demand, we provide a computationally efficient Bayesian inference framework based on Hamiltonian Monte Carlo for coalescent process models. Moreover, we show that by splitting the Hamiltonian function, we can further improve the efficiency of this approach. Using several simulated and real datasets, we show that our method provides accurate estimates of population size dynamics and is substantially faster than alternative methods based on elliptical slice sampler and Metropolis-adjusted Langevin algorithm. Availability and implementation: The R code for all simulation studies and real data analysis conducted in this article are publicly available at
IntroductionPopulation genetics theory states that changes in population size affect genetic diversity, leaving a trace of these changes in individuals' genomes. The field of phylodynamics relies on this theory to reconstruct past population size dynamics from current genetic data. In recent years, phylodynamic inference has become an essential tool in areas like ecology and epidemiology. For example, a study of human influenza A virus from sequences sampled in both hemispheres pointed to a sourcesink dynamics of the influenza evolution ().Phylodynamic models connect population dynamics and genetic data using coalescent-based methods (). Typically, such methods rely on Kingman's coalescent model, which is a probability model that describes formation of genealogical relationships of a random sample of molecular sequences. The coalescent model is parameterized in terms of the effective population size, an indicator of genetic diversity (). While recent studies have shown promising results in alleviating computational difficulties of phylodynamic inference (), existing methods still lack the level of computational efficiency required to realize the potential of phylodynamics: developing surveillance programs that can operate similarly to weather monitoring stations allowing public health workers to predict disease dynamics to optimally allocate limited resources in time and space. To achieve this goal, we present an accurate and computationally efficient inference method for modeling population dynamics given a genealogy. More specifically, we concentrate on a class of Bayesian nonparametric methods based on Gaussian processes (). Following Palacios and Minin (2012) and, we assume a log-Gaussian process prior on the effective population size. As a result, the estimation of effective population size trajectory becomes similar to the estimation of intensity of a log-Gaussian Cox process (LGCP;), which is extremely challenging since the likelihood evaluation becomes intractable: it involves integration over an infinite-dimensional random function. We resolve the intractability in likelihood evaluation by discretizing the integration interval with a regular grid to approximate the likelihood and the corresponding score function. For phylodynamic inference, we propose a computationally efficient Markov chain Monte Carlo (MCMC) algorithm using Hamiltonian Monte Carlo (HMC;) and one of its variants, called Split HMC (), which speeds up standard HMC's convergence. Our proposed algorithm has several advantages. First, it updates all model parameters jointly to avoid poor MCMC convergence and slow mixing rates when there are strong dependencies among model parameters (Knorr). Second, unlike a recently proposed Integrated Nested Laplace Approximation method (INLA,), which approximates the posterior distribution of model parameters given a fixed genealogy, our approach can be extended to more general settings where we observe genetic data (as opposed to the genealogy of sampled individuals) that provide information on genealogical relationships. Third, we show that our method is up to an order of magnitude more efficient than alternative MCMC algorithms, such as Metropolis-adjusted Langevin algorithm (MALA;), adaptive MALA (aMALA; Knorr) and Elliptical Slice Sampler (ES 2 ;) that are commonly used in the field of phylodynamics. Finally, although in this article we focus on phylodynamic studies, our proposed methodology can be easily applied to more general point process models. The remainder of the article is organized as follows. In Section 2, we provide a brief overview of coalescent models and HMC algorithms. Section 3 presents the details of our proposed sampling methods. Experimental results based on simulated and real data are provided in Section 4. Section 5 is devoted to discussion and future directions.
Preliminaries
CoalescentAssume that a genealogy with time measured in units of generations is available. The coalescent model allows us to trace the ancestry of a random sample of n genomic sequences: two sequences or lineages merge into a common ancestor as we go back in time until the common ancestor of all samples is reached. Those 'merging' times are called coalescent times. The coalescent with variable population size is an inhomogeneous Markov death process that starts with n lineages at present time, t n  0, and decreases by one at each of the consequent coalescent times, t n1 <    < t 1 , until reaching their most recent common ancestor (). Suppose we observe a genealogy of n individuals sampled at time 0. Under the standard (isochronous) coalescent model, given the effective population size trajectory, N e t, the joint density of coalescent times t n  0 < t n1 <    < t 1 iswhere A k   k 2  and I k  t k ; t k1 . Note that the larger the population size, the longer it takes for two lineages to coalesce. Further, the larger the number of lineages, the faster two of them meet their common ancestor. For rapidly evolving organisms, we may have different sampling times. When this is the case, the standard coalescent model can be generalized to account for such heterochronous sampling (). Under the heterochronous coalescent, the number of lineages changes at both coalescent times and sampling times. Let ft k g n k1 denote the coalescent times as before, but now let s m  0 < s m1 <    < s 1 denote sampling times of n m ;. .. ; n 1 sequences respectively, where P m j1 n j  n. Further, let s and n denote the vectors of sampling times fs j g m j1 and numbers of sequences fn j g m j1 sampled at these times, respectively. Then we can modify density (1) aswhere the coalescent factor A i;k   l i;k 2  depends on the number of lineages l i;k in the interval I i;k defined by coalescent times and sampling times. For k  2;. .. ; n, we denote half-open intervals that end with a coalescent event byfor s j < t k1 and half-open intervals that end with a sampling event by (i > 0)for t k < s ji1 s j < t k1. In density (2), there are n  1 intervals fI i;k g i0 and m  1 intervals fI i;k g i > 0 for all (i, k). Note that only those intervals satisfying I i;k & t k ; t k1  are non-empty. Seefor more details. We can think of isochronous coalescence as a special case of heterochronous coalescence when m  1; A 0;k  A k ; I 0;k  I k ; I i;k  ; for i > 0. Therefore, in what follows, we refer to density (2) as the general case. We assume the following log-Gaussian Process prior on the effective population size, N e t: N e t  expf t; f t $ GP0; Ch;where GP0; Ch denotes a Gaussian process with mean function 0 and covariance function Ch. A priori, N e t is a log-Gaussian process. For computational convenience, we use a Gaussian process with inverse covariance function C 1 in j   j C 1 in , where C 1 in corresponds to a modified inverse covariance matrix of Brownian motion (C 1 BM ) that starts with an initial Gaussian distribution with mean 0 and large variance. This corresponds to an intrinsic autoregression model (). The computational complexity of computing the density of this prior is OD since the inverse covariance matrix is tri-diagonal (). The precision parameter j is assumed to have a Gammaa; b prior.
HMCBayesian inference typically involves intractable models that rely on MCMC algorithms for sampling from the corresponding posterior distribution, ph. HMC () is a stateof-the-art MCMC algorithm that suppresses the random walk behavior of standard Metropolis-based sampling methods by proposing states that are distant from the current state but nevertheless have a high probability of being accepted. These distant proposals are found by numerically simulating Hamilton dynamics, whose state space consists of position, denoted by the vector h, and momentum, denoted by the vector p. It is common to assume p $ N 0; M, where M is a symmetric, positive-definite matrix known as the mass matrix, often set to the identity matrix I for convenience. For Hamiltonian dynamics, the potential energy, Uh, is defined as the negative log density of h (plus any constant); the kinetic energy, Kp for momentum variable p, is set to be the negative log density of p (plus any constant). Then the total energy of the system, the Hamiltonian function, is defined as their sum: Hh; p  Uh  Kp.The system of h; p evolves according to the following set of Hamilton's equations:_ p  r h Hh; p  r h Uh:In practice, we use a numerical method called leapfrog to approximate the Hamilton's equations () when the analytical solution is not available. We numerically solve the system for L steps, with some step size, e, to propose a new state in the Metropolis algorithm and accept or reject it according to the Metropolis acceptance probability (see Neal, 2010, for more discussions).
Method
DiscretizationAs discussed above, the likelihood function (2) is intractable in general. We can, however, approximate it using discretization. To this end, we use a fine regular grid, x  fx d g D d1 , over the observation window and approximate N e t by a piecewise constant function as follows:Note that the regular grid x does not coincide with the sampling coalescent times, except for the first sampling time s m  x 1 and the last coalescent time t 1  x D. To rewrite (2) using the approximation (7), we sort all the time points ft; s; xg to create new D  m  n  4 half-open intervals fI  a g with either coalescent time points, sampling time points or grid time points as the end points (). For each a 2 f1;    ; D  m  n  4g, there exists some i, k and d such that I  a  I i;k \ x d ; x d1 . Each integral in density (2) can be approximated as a sum:where D a is the length of the interval I  a. This way, the joint density of coalescent times (2) can be rewritten as a product of the following terms:where y a is an auxiliary variable set to 1 if I  a ends with a coalescent time and to 0 otherwise. Then, density (2) can be approximated as follows:where the coalescent factor A i;k on each interval I  a is determined by the number of lineages l i;k in I  a. We denote the expression on the righthand side of Equation (9) by Coalescentf, where f : ff x  d g D1 d1 .
Sampling methodsOur model can be summarized asfjj $ N 0;j $ Gammaa; b:ObservedAfter transforming the coalescent times, sampling times and grid points into fy a ; A i;k ; D a g, we condition on these data to generate posterior samples for f  logN e x   and j, where x   fx  d g is the set of the middle points in (7). We use these posterior samples to make inference about N e t. For sampling f using HMC, we first compute the discretized loglikelihoodand the corresponding gradient (score function)based on (9). Because the prior on j is conditionally conjugate, we could directly sample from its full conditional posterior distribution, j jy; s; n; f $ Gammaa  D  1=2; b  f T C 1 in f=2:However, updating f and j separately is not recommended in general because of their strong interdependency (Knorr): large value of precision j strictly confines the variation of f, rendering slow movement in the space occupied by f. Therefore, we update f; j  jointly in our sampling method. In practice, of course, it is better to sample h : f; s, where s  logj  is in the same scale as f  logN e x  . Note that the log-likelihood of h is the same as that of f because density (2) does not involve s. The log-density prior on h is defined as follows:logPh / D  1=2  as  f T C 1 in f=2  be s : (12)
Speed up by splitting HamiltonianThe speed of HMC could be increased by splitting the Hamiltonian into several terms such that the dynamics associated with some of these terms can be solved analytically (). For these analytically solvable parts (typically in quadratic forms), simulation of the dynamics does not introduce a discretization error, allowing for faster movements in the parameter space. For our model, we split the Hamiltonian Hh; p  Uh  Kp as follows:We further split the middle part into two dynamics involving fjs and sjf, respectively,where the subindex ' D' means all but the Dth element. Using the spectral decomposition C 1 in  UKU 1 and denoting f  : ffiffiffi ffiD , we can analytically solve the dynamics (14a) as follows () (more details are provided in the Supplementary Material):where diagonal matrix ffiffiffi ffi K p scales different dimensions. We then use the standard leapfrog method to solve the dynamics (14b) and the residual dynamics in (13). Note that we only need to diagonalize C 1 in once prior to sampling and then calculate f T C 1 in fe s  f T f  ; therefore, the overall computational complexity of the integrator is OD 2 . Algorithm 1 shows the steps for this approach, which we refer to as splitHMC.
ExperimentsWe illustrate the advantages of our HMC-based methods using four simulation studies. We also apply our methods to analysis of a real dataset. We evaluate our methods by comparing them to INLA in terms of accuracy and to several sampling algorithms, MALA, aMALA and ES 2 , in terms of sampling efficiency. We measure sampling efficiency with time-normalized effective sample size (ESS). Given B MCMC samples for each parameter, we define the corresponding ESS  B1  2 P K k1 ck 1 and calculate it using the 'effectiveSize' function in R Coda. Here, P K k1 ck is the sum of K monotone sample autocorrelations (). We use the minimum ESS over all parameters normalized by the CPU time, s (in seconds), as the overall measure of efficiency: minESS=s. We tune the stepsize and number of leapfrog steps for our HMCbased algorithm, such that their overall acceptance probabilities are in a reasonable range (close to 0.70). In all experiments, we use Gamma hyper prior parameters a  b  0:1.Accept or reject the proposal according to a for the next state h 0
Efficient Bayesian phylodynamicsSince MALA () and aMALA (Knorr) can be viewed as variants of HMC with one leapfrog step for numerically solving Hamiltonian dynamics, we implement MALA and aMALA proposals using our HMC framework. MALA, aMALA and HMC-based methods update f and s jointly. aMALA uses a joint block-update method designed for Gaussian Markov Random Field (GMRF) models: it first generates a proposal j  jj from some symmetric distribution independently of f and then updates f  jf; j  based on a local Laplace approximation. Then, f  ; j   is either accepted or rejected. It can be shown that aMALA is equivalent to Riemannian MALA (;, also see Supplementary Material). In addition, aMALA closely resembles the most frequently used MCMC algorithm in Gaussian process-based phylodynamics (). ES 2 () is another commonly used sampling algorithm designed for models with Gaussian process priors. Palacios and Minin (2013) used ES 2 for phylodynamic inference. ES 2 implementation relies on the assumption that the target distribution is approximately normal. This, of course, is not a suitable assumption for the joint distribution of f; s. Therefore, we alternate the updates fjj and j jf when using ES 2. Note that we are sampling j in ES 2 to take advantage of its conjugacy.
SimulationsWe simulate four genealogies for n  50 individuals with the following true trajectories: 1. logistic trajectory:0:1; t 2 0:5; 1:0; 1; t!1:0:To simulate data under heterochronous sampling, we selected 10 of our samples to have sampling time 0. The sampling times for the remaining 40 individuals were selected uniformly at random. Our four simulated genealogies were generated using the thinning algorithm detailed in Palacios and Minin (2013) and implemented in R. Simulated genealogies are displayed in the Supplementary File. We use D  100 equally spaced grid points in the approximation of likelihood when applying INLA and MCMC algorithms (HMC, splitHMC, MALA, aMALA and ES 2 ).compares the estimates of N e t using INLA and MCMC algorithms for the four simulations. In general, the results of MCMC algorithms match closely with those of INLA. It is worth noting that MALA and ES 2 are occasionally slow to converge. Also, INLA fails when the number of grid points is large, e.g. 10 000, while MCMC algorithms can still perform reliably. For each experiment, we run 15 000 MCMC iterations with the first 5000 samples discarded. We repeat each experiment 10 times.The results provided inare averaged over 10 repetitions. As we can see, our methods substantially improve over MALA, aMALA and ES 2. Note that due to high computational cost of Fisher information, aMALA is much worse than MALA in terms of time-normalized ESS.compares different sampling methods in terms of their convergence to the stationary distribution when we increase the size of grid points to D  1000. As we can see in this more challenging setting, Split HMC has the fastest convergence rate. HMC, ES 2 and MALA take longer time (around 500 s, 1000 s and 2000 s, respectively) to converge, while aMALA does not reach the stationary distribution within the given time-frame. In, we show the estimated population size trajectory for the four simulations using our splitHMC, Bayesian Skyline Plot () and Bayesian Skyride (). Comparison of recovered estimates from these three methods show that our Gaussian-process-based method (using splitHMC algorithm) performs better than the other two: our point estimates are closer to the truth and our credible intervals cover the truth almost everywhere. Bayesian Skyride and splitHMC perform very similar; however, the BCIs recovered with splitHMC cover entirely the two peaks in the logistic simulation, the peak in the boombust simulation and the entire bottleneck phase in the bootleneck simulation. A direct comparison of efficiency of these three methods is not possible since Bayesian Skyline Plot and Bayesian Skyride assume different prior distributions over N e t. Additionally, Bayesian Skyline Plot and Bayesian Skyride are implemented in BEAST () using a different language (Java). Supplementaryin the Supplementary File shows the trace plots of the posterior distributions of the results displayed into assess convergence of the posterior estimates.
20
Human influenza A in New YorkNext, we analyze a real dataset previously used to estimate influenza seasonal dynamics (). The data consist of a genealogy estimated from 288 human influenza H3N2 sequences sampled in New York state from January 2001 to March 2005. The key feature of the influenza A virus epidemic in temperate regions like New York is the epidemic peaks during winters followed by strong bottlenecks at the end of the winter season. We useThe true population trajectories are (I) logistic, (II) exponential growth, (III) boombust and (IV) bottleneck. AP, acceptance probability; s/iter, seconds per sampling iteration; 'spdup', speedup of efficiency measurement minESS/s using ES 2 as baseline.based on intrinsic precision matrix, C 1 in , are quite comparable to that of INLA. However, estimates using splitHMC with different covariances show that using C 1 in is more conservative than C 1 BM in estimating the variation of population size trajectory. In Table 2, we can see that the speedup by HMC and splitHMC over other MCMC methods is substantial.
0
DiscussionPhylodynamic inference has become crucial in conservation biology, epidemiology and other areas. Bayesian nonparametric methods coupled with coalescent models provide a powerful framework to infer changes in effective population sizes with many advantages. One of the main advantages of Bayesian nonparametric methods over traditional parametric methods that assume fixed functional form of N e t, such as exponential growth (), is the ability of Bayesian nonparametric methods to recover any functional form without any prior knowledge about N e t. With the technological advance of powerful tools for genotyping individuals, it is crucial to develop efficient methodologies that can be applied to large number of samples and multiple genes. In this article, we have proposed new HMC-based sampling algorithms for phylodynamic inference. We have compared our methods to several alternative MCMC algorithms and showed that they substantially improve computational efficiency of GP-based Bayesian phylodynamics. (More results are provided in the Supplementary Document.) Further, our analysis shows that our results are not sensitive to the prior specification for the precision parameter j. This is inline with previously published results for similar models (see Supplementary Material of). To obtain the analytical solution of (14a) in splitHMC, we Eigen-decompose the precision matrix C 1 in , sacrificing sparsity. One can, however, use the Cholesky decomposition instead C 1 in  R T R and transform f   Rf. This way, the dynamics (14a) would be much simpler with the solution as a rotation (). Because R is also tridiagonal similar to C 1 in , in theory the computational cost of splitHMC could be reduced to OD. In practice, however, we found that this approach would work well when the Hamiltonian (13) is mainly dominated by the middle term. This condition does not hold for the examples discussed in this article. Nevertheless, we have provided the corresponding splitHMC method with Cholesky decomposition in the Supplementary File, since it can still be used for situations where the middle term does in fact dominate the overall Hamiltonian. There are several possible future directions. One possibility is to use ES 2 as a proposal generating mechanism in updating f as opposed to using it for sampling from the posterior distribution. Finding a good proposal for j (or s), however, remains challenging. Another possible direction it to allow j to be time dependent. When there is rapid fluctuation in the population, one single precision parameter j may not well capture the corresponding change in the latent vector f. Our future work will include time-varying precision j t or more informative covariance structure in modeling Gaussian prior. Also, we can extend our existing work by allowing irregular grids, which may be more suitable for rapidly changing population dynamics. Another important extension of the methods presented here is to allow for multiple genes and genealogical uncertainty. The MCMC methods proposed here can be incorporated into a hierarchical framework to infer population size trajectories from sequence data directly. In contrast, INLA cannot be adapted easily to perform inference from sequence data. This greatly limits its generality.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
S.Lan et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
2001 2002 2003 2004 2005 influenza INLA HMC splitHMCin MALA aMALA ES 2 splitHMCBM Fig. 5. Population dynamics of influenza A in New York (20012005): shaded region is the 95% credible interval calculated with samples given by splitHMC with C 1 in. SplitHMC with C 1 in (red) is more conservative than splitHMC with C 1 BM (dark green) in estimating the variation of population size trajectory
