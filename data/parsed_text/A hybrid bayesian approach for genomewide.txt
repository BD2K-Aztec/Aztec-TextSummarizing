Motivation: Both single marker and simultaneous analysis face challenges in GWAS due to the large number of markers genotyped for a small number of subjects. This large p small n problem is particularly challenging when the trait under investigation has low heritability. Method: In this article, we propose a two-stage approach that is a hybrid method of single and simultaneous analysis designed to improve genomic prediction of complex traits. In the first stage, we use a Bayesian independent screening method to select the most promising SNPs. In the second stage, we rely on a hierarchical model to analyze the joint impact of the selected markers. The model is designed to take into account familial dependence in the different subjects, while using local-global shrinkage priors on the marker effects. Results: We evaluate the performance in simulation studies, and consider an application to animal breeding data. The illustrative data analysis reveals an encouraging result in terms of prediction performance and computational cost.
IntroductionGenome-wide association studies (GWAS) have been widely conducted in humans with the goal of identifying genetic factors predictive of disease. GWAS chips collect data on single nucleotide polymorphisms (SNPs) across the genome, focusing on common variants in which the minor allele frequency is at least 5%. The dominant focus in GWAS has been on independent screening methods, which consider the association between disease and each SNP separately while adjusting for false discoveries. This strategy tends to produce a small number of SNPs having modest effect sizes, failing to explain a substantial proportion of the known heritability in disease. Given the size of the multiple testing problems in which the number of SNPs (p) is dramatically larger than the number of individuals under study (n), it is not surprising that independent screening has failed to identify much signal in the data. As the identified SNPs typically explain a small proportion of the variability in the phenotype, GWAS has been unsuccessful at producing accurate predictive models in humans (see, e.g.; Diabetes Genetics Initiative of Broad Institute of). Dramatic reduction in cost has driven the increased use of GWAS beyond humans to animal breeding studies. In animal breeding a major focus is on prediction of genetic merit (breeding value) when the pedigree structure is taken into account. Based on predictions early in life, animals having a high probability of developing desired traits will be differentially selected. When the focus is on prediction of traits instead of identification of the top individual variants, it has been suggested that all markers should be included instead of attempting variable selection (). Because in GWAS the number of SNPs exceeds the number of samples, simultaneous analysis requires using penalized or shrinkage approaches. The most popular approach is the Lasso (Tibshirani,, which includes an L 1 penalty on the coefficients to induce simultaneous variable selection and shrinkage. However, a rich variety of alternative penalties have been proposed (selection, such methods have computational advantages (avoid an intractable search over all possible subsets) and better accommodate lots of small but non-zero coefficients. In Bayesian analyses of animal breeding, it has been common to rely on mixture priors that include a mass at zero for zero coefficients (see, e.g.). Such priors are tabulated in Supplementary Appendix A,. Although the aforementioned simultaneous approaches have been applied to p ) n problems, there are some clear limitations in scaling computation to very large p, as well as issues in obtaining reliable results when n is too small relative to p. In sparse signal processing problems involving large p small n linear regression, it has been discovered that there is often a phase transition that depends on the relative values of n and p and the true sparsity level. When n is too small, so that one is on the wrong side of the phase transition, results are very unreliable. Such transitions have been characterized only in idealized cases, making assumptions on the design matrix that are not appropriate in genomic studies due to strong correlations that arise given the linkage disequilibrium (LD) structure. We hope to push back the phase transition by using a carefully structured Bayesian approach. To combat the computational intractability of variable selection in massive dimensions, multistage approaches are recommended (see, e.g.). For family based studies,proposed two-stage screening based on a Bayesian non-parametric regression model. Here, we instead propose a two-stage approach for a polygenic mixed model to predict phenotypic variation in the trait of interest from genomic information for data collected on genetically related individuals. In the first stage, we apply a Bayesian independent screening method, which takes into account familial dependence while examining SNPs one at a time. This Bayesian screening method has better performance than competitors in our experience, and is expected to select a superset of the important predictors (). In the second stage, we implement a Bayesian hierarchical model to control the level of sparsity and amount of shrinkage relative to the size of signals. We use the generalized double Pareto (GDP) prior () within a polygenic mixed model, extending previous implementations of the GDP to problems in which the samples are related. We evaluate the predictive performance and computational efficiency of the proposed approach called two-stage-GDP by conducting a simulation and real data analysis.
ModelThe overwhelming majority of the literature on analysis of GWAS data focuses on unrelated individuals, while our interest is in animal breeding data from pedigrees. It is important to take the familial dependence structure into account in the analysis to avoid finding spurious associations (see for e.g.). A common model-based approach to incorporate familial dependence is random effects modeling. In particular, we let y  X b  u  ;  $ N0; s 1 R:Here, y is an n vector of a quantitative trait measured on n subjects (animals), b is a p vector of additive genetic effects and X is an n  p matrix of genotypes measured at genetic markers, such that each SNP is coded as 2 if the genotype of the SNP is BB 1 if the genotype of the SNP is Bb 0 if the genotype of the SNP is bb;where B represents the allele with lower frequency. In model (1), R is an n  n diagonal matrix accommodating heterogenous residual variance, which is estimated in a preliminary data preprocessing step, and u is an n random vector such that u $ N0; s 1 u K;where K is an n  n relatedness matrix. Entries of K are in (0, 1) and correspond to the degree of relationship between pairs of subjects, ranging from 0 for unrelated individuals to 1 for self-kinship. This matrix is calculated based on the pedigree measuring genetic similarity between subjects as P h :5 Lh , with the sum being over all paths h connecting two subjects with unique common ancestors and L(h) is the length of path h. If the pedigree is incomplete or not available, K can be estimated based on genotype data (see for e.g.).
First-stageIn this stage, we select a set of promising SNPs by testing the effect of each marker individually. By far the most common approach used in the literature relies on independent testing for association between each SNP and the phenotype using frequentist methods. This produces P-values for each SNP, and the set of significant SNPs can be obtained by choosing a small threshold on these P-values. This threshold is often chosen to maintain a desired false discovery rate (FDR). We instead rely on Bayes factors (BFs) measuring the weight of evidence in the data against the local null hypothesis H 0j of no association between a given SNP and the phenotype. In this initial screening stage, we rely on Bayes factors in favor of the model with only the jth SNP included against the global null model that has no SNPs included. These BFs can be defined under;where h kj  kb j ; s; s u  is the set of parameters under H kj for k 2 f0; 1g; ph kj jH kj  is its prior density, and fy; ujH kj ; h kj  is the probability density of y; u given h kj. The separate analysis of each SNPs makes it appropriate to specify the usual conjugate prior on the set of parameters h kj. In particular, we consider b j js $ N0; s 1 ; j  1;. .. ; p; s $ Gammaa 1 ; b 1 ; s u $ Gammaa 2 ; b 2 :A Hybrid Bayesian Approach for GWASTo calculate the BF j s, we first integrate out the parameters b j s and the random effects u and obtainwhere A k  R  kx j x T j  corresponding to H kj for k  0, 1 in the denominator and numerator, respectively. These integrals are analytically intractable. Hence, we approximate the integrals by applying Laplace transformation. To avoid having the mode on the boundary due to the constraints s > 0 and s u > 0, the precision parameters are reparameterized with log transformation. The calculated BF j s provide a list of ranked SNPs for selecting the most promising markers. In the screening stage, our goal is to reduce the number of SNPs under consideration to a manageable number, while erring on the side of including too many SNPs. Usual thresholds on BFs, such as the common value of 10 recommended in (), are too small due to the massive multiple comparisons problem. On the other hand, thresholds that are fully adjusted for multiple comparisons, such as those recommended by Ball (2011) and Stephens and Balding (2009), will tend to select too few SNPs. Motivated by our goal of building a model for prediction, we instead rely on cross validation for threshold choice.
Second-stageIn this stage, we simultaneously include all SNPs selected in the first stage, while incorporating a shrinkage prior on their coefficients. In building a predictive model, it is necessary to characterize the simultaneous impact of the different SNPs on the phenotype. We find that including the first stage instead of incorporating all the SNPs in the simultaneous analysis improves performance in two respects. The first is a considerable computational speedup as the number of SNPs grows. The second is an improvement in accuracy of the resulting predictive model. This second improvement is due to the fact that most shrinkage priors are insufficiently flexible to handle truly massive-dimensional predictors that are not highly sparse in their effects. Shrinkage priors are designed to have separate parameters controlling concentration around zero and tail heaviness, but such control is insufficient in GWAS. In the second stage, model (1) is rewritten aswhere vector ~ b represents the effects of p s selected SNPs and ~ X is the corresponding design matrix.
Prior specificationWe incorporate a local-global shrinkage prior into polygenic mixed model (3) as ~ b $ N0; s 1 R~ b ;where R~ b  diagfg j g. The variance of each coefficient, ~ b j , includes two parameters, s and g j , representing global and local shrinkage effects, respectively. In GWAS settings, s 1 is expected to be close to zero, corresponding to a high degree of overall shrinkage to stabilize estimation and incorporate the expectation that most coefficients are close to zero. To avoid over-shrinkage of the most influential SNPs, the prior on g j is designed to have heavy tails. To obtain a flexible prior with the desired behavior, which also leads to computational advantages, we let g j $ expn 2 j =2:Instead of presetting values for n j s, it is appealing to assign a prior distribution to these parameters as n j $ Gammac; d; which induces a heavy-tailed marginal on g j. The above hierarchical shrinkage prior on the SNP coefficients corresponds to a representation of the GDP introduced by. To complete a specification of the prior, the precision parameters s and s u are given gamma priors as in (2). The GDP has substantial advantages over simpler shrinkage priors, such as ridge and Bayesian Lasso, in terms of limiting over-shrinkage of the larger coefficients.
Posterior interpretationUnder the proposed model, the total phenotypic variance for the trait can be decomposed aswhere s and s u are the mean of diagonal elements in R and K, respectively; i.e.i1 k ii where r ij and k ij are the ijth elements of matrices R and K. In the case that K is calculated from a pedigree, s u is one. The proportion of the phenotypic variance explained by total genetic variance is called heritability, denoted by h 2. As is clear from(5), h 2 accounts for the covariance between markers as well. If we ignore the contribution from the covariance (), the proportion of the phenotypic variance explained by each marker is approximatelyBy relying on MCMC samples from the posterior for the parameters in our model, we can obtain posterior summaries for both total heritability h 2 and individual h 2 j contributions.
MCMC algorithmThe joint posterior distribution iswhere pyj: is the probability density of y given all parameters in the model. From this joint posterior, we obtained full conditional posterior densities for Gibbs sampling ass u ju $ Gammaa 2  n=2; u T K 1 u  b 2 ; n j j ~ b j ; s $ Gammac  1; s 1=2 j ~ b j j  d;Gibbs sampling alternates sampling from these simple conditional distributions, with the draws converging to samples from the joint posterior. From these samples, posterior summaries for any marginal of interest can be calculated; e.g. the posterior mean provides the optimal point estimate under squared error loss.
Simulation studyTo evaluate the prediction performance of two-stage-GDP, we conducted a simulation study. We first generated a pedigree based on a non-random mating scheme using the R package synbreed. This pedigree structure was then utilized in simuPOP (), which generated genotype data for each individual taking into account their relatedness. To mimic our motivating real data, we selected the subset of individuals having the same gender for analysis. We then applied Rpackage kinship2 to calculate the relatedness matrix based on the pedigree. We considered four different scenarios for the effect sizes:The first two models are designed for dense problems in which most of the predictors have small effects on the complex trait. The last two models are designed for sparse problems with different level of sparsity. We used cross validation (CV) to assess performance. CV is intrinsically a frequentist idea, but has become routinely used in assessing the frequentist operating characteristics of Bayesian methods (). For each scenario, we generated 20 datasets as training sets and 20 as validation sets. Evaluation is based on mean square prediction errors, MSPEs and correlations between observed values and predictive values. The predictions of future values are obtained fromIndex f and o denote the future data and observed data, respectively. To evaluate the predictive performance of the model and its computational efficiency, we made a comparison between twostage-GDP and the widely applied method, SSVS, as well as some well-known shrinkage priors on ~ b j including Bayesian Lasso, Student-t and one-stage GDP. SSVS places a mixture of two normals on ~ b j as 1  c j  N0; 2 j   c j N0; c 2 j 2 j , where c j 2 f0; 1g. Bayesian Lasso (BL) assigns a double-exponential prior to g j in (4) as g j $ expn 2 =2, with n 2 =2 $ Gammac 0 ; d 0  following Park and Casella (2008). The student-t can be expressed as a scale mixture of normal distributions ~ b $ N0; R~ b , with R~ b  diagfg j g and g j $ Inv-gammac 00 ; d 00 . To set the hyperparameters for SSVS, we let  2 j ; c 2 j 2 j   :001; 10, with pc j  1  0:5 in Model-1 and Model-2 and to 0.1 in Model-3 and Model-4. In BL, the posterior is relatively insensitive to the prior on n 2 as long as c 0 and d 0 are small (), and we set these hyperparameters to 0.1. For the student-t prior, we fixed c 00  3 as a small value greater than 2 as suggested by Fr hwirth-Schnatter and Wagner (2011). We considered different values for d 00 as 0.001; 0.01; 0.1 and found 0.01 as the best choice. For GDP hyperparameters, we considered d  ffiffiffiffiffiffiffiffiffiffiffi c  1 p , since this choice ensures the continuity property and creates a trade-off between sparsity and tail-robustness. We increased c from 1 in Model1 and Model-2 to 3 in Model-3 and Model-4 in order to allow more shrinkage for sparse models. We sent hyperparameters of s and s u equal to 10 3 .shows that the t-prior performs better than the other approaches in dense problems, Model-1 and Model-2. For the sparse cases, Model-3 and Model-4, two-stage-GDP outperforms the other competitors. Although in Model-3 two-stage-GDP is slightly better than SSVS, by increasing the sparsity level in Model-4, two-stageGDP shows noticeably better predictive performance. In addition, its computational cost makes feasible the use of two-stage-GDP in GWAS. The effect of sparsity level on prediction performance is presented in. The figure shows mean of correlation between observed values and predicted values in 20 validation sets versus number of predictors in the model, while the number of predictors with non-zero effects in the model is 100 and n  100. The performance of one-stage approaches are highly related to the p/n ratio. The correlations among observed values and predicted values are less than 0.7 for p!2000. The computational time of these approaches versus the number of predictors in the model is presented in. Our programming code for t-priors, BL, GDP and two-stage-GDP is based on C in order to speed up the MCMC algorithm. The SSVS implemented in JAGS is also based on C programming. Figures 1 and 2 represent one line corresponding to t-prior, BL and GDP since they almost have the same performance or running time with comparison to SSVS and two-stage-GDP. This line that is depicted using the average point of t-prior, BL and GDP quantities, provides better visualization for the comparison. Available packages using frequentist approaches for linear mixed model with p > n are restricted to specific cases, such as group structure. As those packages do not allow general linear mixed effect structure, such as that induced by familial dependence, we could not provide comparison with frequentist approaches. We applied two-stage-GDP on a GWAS dataset from an animal breeding study. The aim of study is to improve quantity and quality of milk production through investigating milk protein yield. The data contain 707, 962 SNPs genotyped for 607 Holstein Bulls. After quality control, excluding SNPs with minor allele frequency below 5%, samples with low genotyping efficiency, and violating HardyWeinberg Equilibrium test, the dataset contains 555, 651 SNPs. We further reduced the dimensionality of the set of SNPs by considering the fact that SNPs in the genome have groups of neighbors such that they are all nearly perfectly correlated with each other. Hence, the genotype of one SNP can perfectly predict those of correlated neighboring SNPs; i.e. one SNP can thereby serve as proxy for many others in the analysis. As the segments of SNPs in high linkage disequilibrium in cattle is longer than human because of inbreeding, we reduced the number of SNPs down to 135, 545 via a hierarchical clustering approach. In this agglomerative clustering, we defined the distance between two SNPs as 1  r 2 , where r 2 , the square of correlation between two SNPs, is 0.85. After the preliminary analysis, we first evaluated the impact of each SNP by BF and selected 878 top-ranking SNPs using the algorithm in Supplementary Appendix B. In the second-stage, we first ran a 5-fold cross validation in order to set the hyperparameters. For hyperparameters of marker effects, we considered d  ffiffiffiffiffiffiffiffiffiffiffi c  1 p , since this choice ensures the continuity property and creates a trade-off between sparsity and tail-robustness (). We ran 5-fold cross validation for different values of c: 1; 2:5; 3; 3:5. Generally, the rate of shrinkage increases along this path. For the other hyperparameters of the model, we set a 1 ; b 1   a 2 ; b 2  as 0:001; 0:001; 0:01; 0:01; 0:1; 0:1; 0:3; 0:3.presents average of MSPEs for different sets of hyperparameters for 5fold cross validation and the standard deviation from 50 bootstrap samples in subscript. It shows c  3 and a 1 ; b 1   a 2 ; b 2   0:01 ; 0:01 provides smallest MSPE. In addition, we considered two other prior specifications for the second-stage analysis, t-priors and BL, in order to compare their predictive performance. The hyperparameters of t-priors and BL were chosen the same as in the simulation study.represents average of MSPEs of 10-fold cross validation. The index numbers are the average standard errors of MSPEs obtained by averaging 100 bootstrap samples of 10 MSPEs. We also calculated average of correlation between predicted and observed values in 10-fold cross validation. Although two-stage GDP shows slightly better predictive performance in terms of mean of MSPEs in 10-fold cross validation shown in, the variation of 10-fold cross validation result based on two-stage-GDP is smaller than twostage-BL and two-stage-t-priors. The calculated total phenotypic variance from(5) for two-stageGDP is 1.700. The total genetic variance contributed by the additive effects of the markers calculated from the first term of the right hand side in (5) is 0.483. Although the aim of this study is prediction, if one is interested in selecting the set of SNPs with the most contribution, heritability is a good criteria. To select a set SNPs based on heritability, Hoti and Sillanp (2006) suggested presenting a threshold value, t, such that one SNP is included in the final model if the heritability explained by this SNP is greater than t.Under such an approach, the heritability for milk protein yield is expected to be small based on previous studies. Hence, instead of setting a threshold on heritability of each SNP, we considered a threshold on total heritability of a set of top SNPs ranked based on calculated h 2 j s. To this end, we first calculated heritability for each SNP by substituting the mean of posterior samples of b j s in (5). This provided a list of ranked SNPs. We then selected a set of top SNPs with total heritability above 0.2. The estimated effect sizes and marginal heritabilities of 32 selected SNPs as well as their chromosomes' numbers are tabulated in. Among these selectedSNPs out of 32 have been found in known genes or nearby them.shows pieces ofchromosome 1 and 10 as examples. The red regions in these pictures indicate the locations of the genes associated with milk protein yield that have been found through previous studies. The two vertical red lines represent the locations of two selected markers in our study. As it shows, the selected SNP in Chromosome 1 is in gene PPP2R3A and the one in Chromosome 10 is between genes SAV1 and NIN. We further examined the correlations between the SNPs that are selected from the same chromosome. The correlation matrices of these markers presented in Supplementary Appendix C reveal detected SNPs in most of the Chromosomes are weakly correlated. Although, the correlation matrix for chromosome 3 shows two markers closely link to each other. Hence, selecting those two markers might be due to linkage disequilibrium.
DiscussionIn p ) n problems, current variable selection and mixture priors face problems in scaling to very large p when n in small relative to p.These problems include computational bottlenecks and insufficient flexibility. To solve these problems, multistage approaches have been proposed, but not yet in the case in which the subjects under study are related. We address this gap via new two-stage Bayesian approaches that account for familial dependence. The method is a hybrid of single marker and simultaneous analyses. In the first-stage, we select a superset of the most promising SNPs by evaluating the impact of each SNP individually while accounting for related samples. In the second stage, we simultaneously select and estimate the parameters of the model by placing a GDP prior on the SNP coefficients, again accounting for relatedness. Our simulation analyses revealed that two-stage-GDP improves predictive performance in comparison to one-stage analysis when n is too small relative to p. The computational cost of this proposed approach also makes it feasible for large scale problems like GWAS. In the real data analysis, we made a comparison among different prior specifications in the second stage of analysis. This comparison represented that two-stage-GDP performs better than two-staget-priors and two-stage-BL. We then estimated breeding value for protein yield based on two-stage-GDP. Although the prediction accuracy was sufficient for the small sample size that we had, a small proportion of phenotypic variation is explained by SNPs. In problems that the sample size is not severely limited, splitting the data in two subsets and applying each stage on a subset of data(0.001,0.001) 0:698 0:018 0:539 0:012 0:526 0:013 0:529 0:010 (0.01, 0.01) 0:686 0:019 0:528 0:011 0:519 0:011 0:523 0:015 (0.1,0.1) 0:736 :028 0:564 0:018 0:551 :022 0:557 0:023 (0.3,0.3) 0:845 0:028 0:576 0:018 0:572 0:058 0:569 0:023(see for e.g.) may better recover this missing heritability, which may also arise from interactions.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
A.Yazdani and D.B.Dunson at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
