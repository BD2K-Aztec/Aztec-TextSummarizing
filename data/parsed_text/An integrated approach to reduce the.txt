Motivation: There is growing momentum to develop statistical learning (SL) methods as an alternative to conventional genome-wide association studies (GWAS). Methods such as random forests (RF) and gradient boosting machine (GBM) result in variable importance measures that indicate how well each single-nucleotide polymorphism (SNP) predicts the phenotype. For RF, it has been shown that variable importance measures are systematically affected by minor allele frequency (MAF) and linkage disequilibrium (LD). To establish RF and GBM as viable alternatives for analyzing genome-wide data, it is necessary to address this potential bias and show that SL methods do not significantly under-perform conventional GWAS methods. Results: Both LD and MAF have a significant impact on the variable importance measures commonly used in RF and GBM. Dividing SNPs into overlapping subsets with approximate linkage equilibrium and applying SL methods to each subset successfully reduces the impact of LD. A welcome side effect of this approach is a dramatic reduction in parallel computing time, increasing the feasibility of applying SL methods to large datasets. The created subsets also facilitate a potential correction for the effect of MAF using pseudocovariates. Simulations using simulated SNPs embedded in empirical data— assessing varying effect sizes, minor allele frequencies and LD pat-terns—suggest that the sensitivity to detect effects is often improved by subsetting and does not significantly under-perform the Armitage trend test, even under ideal conditions for the trend test.
INTRODUCTIONGenome-wide association studies (GWAS) have successfully detected numerous single-nucleotide polymorphisms (SNPs) associated with a variety of phenotypes, but the identified loci at best explain a modest proportion of the heritable variance estimated by twin and family studies (). Recent estimates of the heritable variance explained by all SNPs, however, indicate that genome-wide SNP data does offer substantial explanatory power (). This gap of 'missing heritability' between heritability estimates and the SNPs detected by GWAS has led to increasing concern over the performance of GWAS, with attention focused on low power due to the multiple testing burden and small effect sizes, as well as the omission of rare disease alleles and epistatic effects, among other issues (). These shortcomings of GWAS have encouraged the application of statistical learning (SL) methods as an alternative for analyzing genome-wide data (). SL methods are designed specifically for the task of identifying meaningful predictors in high-dimensional data, relying on data-driven algorithms rather than conventional parametric modeling. Numerous SL methods have been proposed for use with SNP dataincluding random forests (RF;), multifactor dimensionality reduction () and the lasso ()generally with encouraging results. RF has received significant attention in the genetics literature () with surprisingly less attention given to gradient boosting machine (GBM;) despite its similarity to RF. Both RF and GBM build an ensemble of non-parametric prediction models, with each model constructed iteratively using all available SNPs. GBM additionally applies boosting to build each model with a focus of improving model fit for cases fit poorly in the previous iteration. Importantly, the iterative tree-building approach of RF and GBM accounts for conditional relationships and complex causal mechanisms, including epistasis and covariate effects, without a priori specification. Individual SNPs are then evaluated using variable importance measures, which quantify each SNP's total contribution to the prediction of the phenotype (). Such variable importance measures can be used to rank-order SNPs by importance, identifying potentially informative SNPs among genome-wide data. Studies of RF with SNP data have yielded promising results. Simulations suggest that RF's power to detect causal SNPs exceeds Fisher's exact test when epistasis is present and is still comparable with Fisher's exact test when detecting main effects only *To whom correspondence should be addressed.(). RF maintains this advantage even if many noise SNPs are present (). Applying RF to genome-wide data is feasible, though computationally burdensome. With empirical genome-wide data, RF is capable of replicating GWAS results and identifying additional candidate SNPs (). Although these results are encouraging, further study is necessary to establish RF and GBM as viable alternatives to GWAS methods. Few studies of SL methods account for linkage disequilibrium (LD), utilize realistic effect sizes or compare the sensitivity of the SL method to GWAS.considered more realistic LD and effect sizes but only focused on RF as a second-stage analysis. Meanwhile, GBM merits further consideration based on its strong performance relative to RF. Studies show GBM performs even better than RF for many data types () but evaluation of its performance with genome-wide SNP data is still needed. In addition, concerns have been raised about the impact of minor allele frequency (MAF) and LD on the variable importance measures used by RF and GBM to rank-order SNPs. With respect to LD, importance scores for correlated functional SNPs are inflated when using variable importance measures based on the Gini criterion (), whereas importance scores for functional SNPs correlated with uninformative predictors are deflated (). Correlated predictors do not induce bias in permutation-based importance measures, though the variability of importance scores is decreased (). MAF may also influence importance scores, with higher MAF being associated with higher Gini importance values for all SNPs, and higher permutation importance values for functional SNPs (). The influence of MAF may be attributed, at least in part, to the tendency of the RF algorithm to prefer predictors with higher variability (). Taken together, such effects may increase the difficulty of detecting disease-causing variants located in LD blocks or with low MAF, especially when using Gini-based importance measures. Methods for controlling the impact of MAF and LD on variable importance have been proposed. To address the effect of LD,introduced a modified RF algorithm and accompanying importance measure that account for the competition between correlated SNPs for inclusion in RF models.developed a conditional permutation scheme for the variable importance that successfully addresses the impact of correlated predictors. Alternatively, pseudocovariates (PCVs) may be added to the data to simultaneously address the effect of all structure in the data that are unrelated to the phenotype (). Although each of these methods have been demonstrated to potentially reduce the impact of LD and MAF, all three increase the computational burden beyond what is feasible for genome-wide data.specifically note that their method does not scale to be feasible with genome-wide data. The current implementation of the conditional methods proposed byalso have substantially larger memory requirements than conventional RF. Correction with PCVs is similarly infeasible, effectively doubling the size of the data and requiring a number of replications of the analysis to establish stable estimates. In sum, to establish RF and GBM as viable methods for genome-wide SNP data, it will be necessary (i) to address concerns over the impact of LD and MAF while maintaining computational feasibility and (ii) to provide a direct comparison with conventional GWAS methods under realistic conditions. In this study, we propose and evaluate a procedure designed to reduce the impact of LD on RF, GBM or related SL methods for genome-wide data. The proposed method creates overlapping subsets of SNPs from a genome-wide dataset under the constraints that SNPs within a set are not in LD, and that each SNPs is represented in at least a user-specified number of subsets (see Methods). The SL method of choice can then be performed on the subsets without concern for LD, followed by an aggregation of results over subsets. Next, we show that the proposed subsetting procedure is computationally feasible for genomewide data. Dividing the data into subsets makes analysis of each piece more manageable and facilitates parallel computation across multiple cores or on a high-performance grid for a drastic reduction of computing time. Third, we evaluate a correction for the impact of MAF adapted from the methods proposed by), which is computationally feasible in combination with the subsetting procedure. Specifically, in each subset, we generate a small set of independent PCVs with zero association with the phenotype, coded as SNPs with MAF ranging from 0.01 to 0.50. Variable importance estimates for the PCVs in each subset are aggregated to provide a stable estimate of variable importance attributable to MAF. This estimate can then be used to correct the importances of the empirical SNPs. Finally, we provide a rigorous direct comparison of the sensitivity of RF and GBM to the Armitage trend test (ATT;), the test utilized most frequently in conventional GWAS analyses (), under realistic data conditions. Using simulated SNPs embedded in empirical genetic data, we show that the sensitivity of RF and GBM is broadly consistent with the ATT for SNPs explaining as little as 1% of the phenotypic variance even under conditions that do not leverage the advantages of RF and GBM (i.e. a linear additive model without dominance or epistatic effects;).
METHODS
RF/GBM analysis protocol2.1.1 Random forests RF is a machine learning algorithm that constructs classification or regression trees based on bootstrap samples of the data (). Samples not used to construct a given tree are the out-of-bag (OOB) sample. At each node A in a tree, a random subset of the predictors of size mtry is searched to find the predictor that partitions the data into the subsets that are most homogeneous with respect to the outcome variable. Thus for a casecontrol phenotype y, at a node A, the RF algorithm seeks the SNP with split s that maximizes the decrease in heterogeneity Is,A  IA  PA L IA L   PA R IA R , 1 where A L and A R are the left and right daughter nodes resulting from split s, P(A) is the probability of being placed in node A by split s, and I is the Gini criterion IA  2Py  0jAPy  1jA (). The probabilities may be weighted based on a user-specified vector of prior probabilities classwt (). On the basis of the ensemble of trees, RF provides two measures of the importance of each SNP. The Gini importance measures the average value of Equation (1) in nodes split using a given SNP. The mean decrease in accuracy (MDA) importance is the average decrease in accuracy in classifying the OOB sample after permuting the given SNP (). Analyses with RF were performed in R (R Development Core) using the randomForest package (). Forests were grown to 5000 trees. The number of predictors attempted at each node, mtry, was set to 0.1 p, where p is the number of predictors in the data. These settings are consistent with the recommendations offor genome-wide data. In addition, prior probabilities (classwt) and voting thresholds (cuttoffs) were set equal to the case/control proportions for the observed phenotype in each analysis. All settings were chosen based on performance in pilot testing with real and simulated data (not shown).
Gradient boosting machineGBM, like RF, is an ensemble method based on classification and regression trees constructed using bootstrap samples of the data. Unlike RF, however, each tree is fit to weighted residuals based on the previous trees in the ensemble. The contribution of each newly added tree to the prediction is limited by a shrinkage parameter. Similar to RF, variable importances are computed based on the average improvement in prediction from nodes split using a given SNP (). Analyses with GBM were completed using the gbm package for R (). As with RF, the settings for GBM were based on pilot testing with empirical and simulated data. We used a 0.001 shrinkage parameter, 3000 trees and limited tree construction depth to first-order interactions.
LD subsetting algorithmTo reduce the effect of LD on variable importance, we propose an algorithm to select overlapping subsets of SNPs prior to analysis, such that the SNPs in each subset are in approximate linkage equilibrium and each SNP from the genome-wide data appears in at least a user-specified number of subsets. Subsequently, subsets are analyzed separately and results are aggregated. The proposed algorithm creates subsets of SNPs from each chromosome, then combines these subsets to create genome-wide subsets. First, for chromosome c, let D c be the N  p c data matrix of the p c SNPs on chromosome c ordered according to map location. To prevent order effects, begin by permuting the columns of D c within blocks of size b, where b is some small positive integer. In other words, randomly permute the order of columns 1 to b, columns b  1 to 2b ,. .. of D c to get the new data matrix D  c. To construct the zth subset for chromosome c, we first select the SNPs associated with columns z, z  k, z  2k,. .. of D  c , where z and k are positive integers. Selecting k subsets in this way guarantees that every SNP in D  c is selected once. Additional sets of k subsets can be constructed to ensure each SNP appears in a user-specified number of subsets, requiring s sets of k subsets to guarantee that each SNP is included in at least s subsets. The value of k is chosen by the researcher such that k  2b is greater than the size (in number of SNPs) of the largest anticipated LD block in order to ensure that the SNPs in columns z, z  k, z  2k,. .. of D  c will not be in LD. The selection of k should be guided by using Haploview () or other software to tag LD blocks in regions known to have the largest LD blocks (or the lowest recombination rate), and setting k slightly larger than the number of SNPs in the largest observed LD block. Next, the subsets are augmented by adding additional SNPs that are in approximate linkage equilibrium with the initially selected SNPs, where linkage equilibrium is operationally defined by a user-specified maximum pairwise correlation t. These additional SNPs are selected by searching the intervals between the selected SNPs (e.g. columns 1 to z  1, z  1 to z  k  1,. .. of D  c ). Within each interval, begin by removing from consideration SNPs that correlate above some correlation threshold t with the previously selected SNPs before or after the interval. For instance, for the interval from z  1 to z  k  1, SNPs correlated with the zth or z  kth SNPs, which have already been selected for subset z, are removed from consideration. For this study, we use a threshold of t  0.1. Of the remaining SNPs, one SNP is randomly selected to be added to the zth subset. Any additional SNPs in the interval that correlate with the newly selected SNP greater than the threshold t are then removed from consideration. Continue randomly selecting SNPs in this way until no SNPs remain below the correlation threshold to be considered. Once this procedure is finished, the zth subset for chromosome c is complete. The zth genome-wide subset is then defined by the union of the zth subset from each chromosome. Pseudocode summarizing the full algorithm is given in. The desired SL method may then be run on each subset, and the importance of a given SNP is computed as its mean observed importance across subsets containing the SNP.
Embedding simulated SNP in empirical dataFor this study of the impact of LD and MAF on variable importance, we simulate data for a SNP in LD with a range of MAF values. Specifically, we use an iterative procedure to simulate a SNP that correlates with an existing empirical SNP at a given correlation and with a specified MAF. By embedding the simulated SNP in empirical SNP data, we are able to maintain a realistic data structure for the simulation studies. A different option would be to use one of the empirical SNPs and generate a phenotype value, but such an approach gives less control on LD and MAF and would require different locations of the target SNP for the different simulation settings. To generate the simulated SNP, a continuous variable is generated first by adding noise drawn from N0, 2  to an existing empirical SNP with complete data. Quantile thresholds based on the desired MAF, under the assumption of HardyWeinberg equilibrium, are applied to the continuous variable to create discrete SNP data. The correlation between the generated SNP and the existing SNP is controlled by adjusting 2 for the noise. Decreasing 2 increases LD with the empirical SNP, whereas increasing 2 has the reverse effect. Adjustments to 2 are made iteratively until the observed LD and MAF are within 0.01 of the desired values. The possible correlation between a pair of SNPs is bounded by the difference in MAF. As a result, it is not possible to generate data for a wide range of values of MAF that still have a high correlation with a single empirical SNP. Using formulas from, it is possible to establish the upper bound for at the population level for two SNPs with given MAFs. In finite samples, it is possible to achieve correlations that are somewhat higher than these bounds, but limitations are still present (Supplementary Information). As a result, some combinations of MAF and LD are omitted from simulations involving correlation with the empirical SNP, which has MAF m  0.286, limiting the consideration of  0.9 to only simulated SNPs with MAF m  0.3.
RESULTS
Evaluation of LD subsetting algorithmAs a baseline measurement of the impact of LD and MAF on variable importance in RF and GBM, both RF and GBM were used to analyze data containing a simulated SNP embedded in a 3000 SNP region of empirical data on N  2235 individuals from a published study of hair morphology (). An LD map of the 3000 empirical SNPs is shown in Supplementary. The simulated SNP was generated with one of four levels of LD (i.e. correlation  0, 0.3, 0.6, 0.9 with the neighboring empirical SNP) and one of five levels of MAF (m  0.05, 0.1, 0.2, 0.3, 0.5). LD and MAF levels were fully crossed, excluding conditions where data generation is not possible (see Methods). A case/control phenotype unrelated to the SNPs was generated with a probability 0.36 of being a case. Resulting variable importance measures from RF and GBM were collected for 250 replications for each combination of LD and MAF. Replications with invalid data generation were discarded.Given a null phenotype, any observed systematic differences in variable importance can be attributed to MAF and to LD with the neighboring SNP. The effect of LD and MAF were tested using the non-parametric KruskalWallis analysis of variance due to the skewed distribution of variable importances (). Significant results imply that the variable importances from the tested conditions do not have the same population distribution. Replicating the findings of, a highly significant effect of MAF on the RF Gini importance of the simulated SNP is observed at each level of LD (). GBM produces very similar results. Although not previously established, the similarity of GBM importance measures to RF makes this result unsurprising. In addition, a highly significant effect of LD on the RF Gini importance is observed at each level of MAF. Strong effects for GBM and the RF MDA importance are also observed when m  0.3 (). The observed effect is likely stronger here due to the inclusion of the higher LD condition  0.9, which can only be considered for MAF m  0.3 due to the restrictions on correlation for binomial variables (see Methods). Plots of the median importance for GBM for each condition clearly suggest a trend toward a similar effect for other levels of MAF (), though the corresponding KruskalWallis tests are nonsignificant. Similar trends are observed for RF (Supplementary Figs S3a and S4a).
Improvement from LD subsetting algorithmApplying the proposed LD subsetting algorithm to the simulated data with s  1 set of k  300 subsets results in a drastic reduction in the effect of LD on the resulting aggregated importances for GBM and RF. Importantly, the process of aggregating results from the subsets does not favor any given SNPs based on the number of subsets containing the SNP (Supplementary Information). After correcting for multiple testing, the KruskalWallis test shows no significant effect of LD for GBM. Note also that large effects of MAF are still observed (). The improvement due to subsetting is especially evident at the m  0.30 level. Plots of the median variable importance in each condition similarly show no systematic trend related to LD (). Dramatic improvements are also observed for RF (Supplementaryand Figs S3b and S4b).
Impact on computational feasibilityIn addition to reducing the effect of LD, the LD subsetting algorithm facilitates distribution of the analysis across a grid environment. For example, using a single core on a server with Dual Six-Core AMD Opteron Model 2431 CPUs, RF requires over 19 h and 3.5 GB of RAM to complete an analysis of chromosome 22 from the complete empirical data (30 218 SNPs). In contrast, the subsets created by the subsetting algorithm can each be analyzed with RF with 1.3 GB of RAM in $44 min. Creating the subsets themselves requires 30 min and 1.8 GB of RAM, and negligible resources are required to aggregate the final results. If a grid environment is available to process 50 of the k  300Observed median importance is shown for GBM with (a) no correction, (b) LD subsetting and (c) LD subsetting and PCVs. The skewed distribution of importances makes SEs uninformative, so error bars instead indicate observed upper and lower quartiles. Differences within a value of MAF suggest an effect of LD, and differences at a correlation suggest an effect of MAF subsets in parallel, using LD subsets with RF yields a 75% reduction in the time required to complete the analysis, and a 49% reduction in the maximum RAM required. Even greater reductions are observed for GBM, shrinking the computational burden from 10 h and 4.3 GB of RAM for the full chromosome to 7 min and 0.5 GB of RAM per subset, yielding a 57% reduction in the maximum RAM requirement and a 89% reduction in total computing time in a grid environment with 50 parallel cores. Supplementarydetails these results.
Addition of PCVsThe subsets created by the LD subsetting algorithm offer an opportunity to include PCVs. Since there are $50 000 SNPs in each subset when 300 subsets are produced for genome-wide data containing $2 million SNPs, 491 PCVs are a modest addition with a negligible impact on the computational burden. Given the similar performance of RF and GBM, and the larger computational burden of RF, we focus on evaluating PCVs with GBM.reports the results of 250 replications of GBM with the PCV correction. Although a significant effect of MAF remains at  0 and  0.6, the magnitude of the effect is drastically reduced (). Note that the negative GBM importances are an artifact of the positively skewed distribution of importances; using PCVs to center the mean importance of a SNP with no effect at zero yields a negative median for the skewed distribution. SNPs with a true effect are still expected to have positive importances (see Section 3.4).
Sensitivity to functional SNPsThe results thus far show a reduction of the influence of LD and MAF on the variable importance for SNPs with no association with the phenotype. To model the effect of LD and MAF on variable importance for functional SNPs, three sets of 28 simulated SNPs were embedded in the 3000 SNP region used previously. The three sets were generated with MAF m  0.1, 0.3 and 0.5, respectively, and embedded avoiding disruption of LD blocks in the empirical data. Each set of 28 SNPs contains three LD blocks of four SNPs each with  0.9, three LD blocks with  0.5 and one block with  0. The LD and MAF conditions used here differ from the previous simulation to provide a less complex setting while still covering a full range of LD and MAF values. Among the 28 simulated SNPs, there are six functional SNPs, jointly explaining 9% of the variance in a continuous outcome variable, which is then dichotomized to a case/control phenotype. Specifically, within each set of SNPs, x 1 ,. .. , x 28 , SNPs x 1 , x 13 and x 25 , each explain 2% of the variance in the continuous outcome, and x 5 , x 17 and x 26 each explain 1% of the variance (Supplementary). This design fully crosses effect size by LD within each set of 28 SNPs, crossed by MAF for the three sets. We focus our analysis on the functional SNPs with the more realistic effect size of 1% variance explained (x 5 , x 17 and x 26 ). Results for tag SNPs and the remaining functional SNPs are available in the Supplementary Information. In addition to testing the effect of MAF and LD on the resulting variable importances, we also consider the sensitivity of each method to identify functional SNPs. Since RF and GBM do not include formal significance testing, we define the detection rate as the proportion of replications in which the observed importance for a given functional SNP exceeds the highest observed importance among the simulated non-effect SNPs.
Uncorrected RF and GBMTo again establish a baseline, variable importances from RF and GBM were collected for 250 replications without the LD subsetting algorithm or PCVs.illustrates the resulting median GBM importance values for the simulated SNPs (for RF see Supplementary Figs S6a and S7a). Comparing the three functional SNPs suggests a strong effect of LD, with lower importance given to the SNPs in strong LD. The effect of LD is significant for GBM and the RF Gini importance according to the Friedman test and approaches significance for the RF MDA importance (). The Friedman test, a non-parametric equivalent of the repeated measures analysis of variance, is applied here due to the skewed distribution of the importances and the dependence among the importances of SNPs together in a replication (). The results also seem to suggest a modest effect of MAF for each functional SNP, but the effect is only significant for the RF Gini importance. Unexpectedly, lower variable importance is observed for functional SNPs with high MAF () compared with the higher importance observed for null SNPs with high MAF (). Further analysis, however, suggests this is an artifact of the differing magnitude of the regression coefficients required to maintain equal effect sizes while varying MAF (Supplementary Information).reports the detection rates for GBM, along with exact 95% confidence intervals for the proportion as defined by. Corresponding results for RF are reported in Supplementary Table S3. The raw values are of little interest but yield a basis for comparison with other methods.
LD subsetting algorithm Asobserved for null SNPs, introducing LD subsetting reduces the impact of LD on variable importance for functional SNPs (). With LD subsetting, the effect of LD on variable importance is non-significant after). LD subsetting also increases the relative importance of tag SNPs in LD with a functional SNP, reducing the downward pressure on the importance of SNPs in a strong LD block (Supplementary). Similar results are observed for RF (Supplementary). Investigation of the detection rates for GBM with and without LD subsetting shows LD subsetting markedly improves detection of the functional SNPs in LD blocks. In exchange, there is a modest decrease in the detection rate for SNPs not in LD, especially at low MAF (). For RF, LD subsetting improves detection rates for the MDA importance but significantly impairs detection of functional SNPs with low MAF when using the Gini importance (Supplementary), likely due a strengthened effect of MAF.
PCV correctionAlthough the effect of MAF on the importance of effect SNPs after LD subsetting is non-significant (), the inclusion of PCVs to correct for MAF may still be desirable to at least partially address the impact of MAF on the importance of null SNPs. As before, the computational burden of RF leads us to focus on the results for GBM.depicts the resulting GBM variable importances after inclusion of PCVs. Although the effect of LD remains non-significant, there is a strong, significant effect of MAF on the importances (). This result is unsurprising given that the trend of GBM variable importances associated with MAF works in the opposite direction for functional SNPs compared with non-effect SNPs. By adjusting the importance to account for the inflated importance of non-effect SNPs with high MAF, the PCV correction strengthens the trend toward lower importance for functional SNPs with high MAF values. As before, the resulting trend in variable importances may be interpreted as reflecting the magnitude of regression coefficients rather than a direct effect of MAF (see Supplementary Information). The impact of including PCVs on the detection rate is more limited. Analyses using GBM with PCVs show slightly higher'Detection' in each replication is defined as importance (or test statistic) for a functional SNP greater than the highest observed importance among simulated SNPs unassociated with the phenotype. Results are given for the ATT, uncorrected GBM importance, GBM with LD subsetting, and GBM with PCVs, showing that in most cases the detection rate for GBM-based methods is within sampling error of the ATT. Proportions are out of 250 replications. Values in bold have confidence intervals that overlap the confidence interval for the detection rate of the ATT. detection rates for SNPs with low MAF, and a moderate decrease in detection rates for SNPs with higher MAF, but the difference is generally within sampling variation ().
Armitage trend test Toestablish the usefulness of SL methods for genome-wide data, it is important to compare their performance to conventional methods. Since the current simulations rely on the same additive genetic model assumed by the ATT, we do not anticipate that RF and GBM will provide any improvement over the detection rate of the ATT. Instead, we hope to show that even under ideal circumstances for the ATT, little sensitivity is lost by using RF and GBM, such that RF and GBM may improve sensitivity to epistatic and non-additive effects without substantial sacrifices of sensitivity to additive effects. Comparison of the detection rates for GBM with the ATT indicates that in most conditions the difference between the two methods is within the range of sampling variation, especially when LD subsetting is used (). Indeed, there is a strong visual similarity between the pattern of observed P-values for the ATT and the corresponding variable importances from GBM with LD subsetting (Supplementary Figs S8b and S9). Results for RF are somewhat weaker (Supplementary). Note that in order to maintain a fair comparison, we define detection for the ATT by treating the test statistic as an analog to the variable importance rather than requiring statistical significance. In sum, it appears GBM, with the aid of LD subsetting, does not substantially under-perform the ATT, even under ideal circumstances for the ATT.
DISCUSSIONSL methods such as RF and GBM are a viable alternative to conventional parametric testing of individual SNPs in a GWAS. However, there are valid concerns over the impact of LD and MAF on variable importance measures that must be addressed. In response, this study presents an integrated approach to meaningfully reduce the effect of LD and MAF on variable importance in RF and GBM. The results of this study show that the proposed subsetting algorithm can successfully reduce or eliminate the effect of LD on the variable importance measures of RF and GBM. The process of aggregating results over the subsets is not biased by the number of subsets containing a given SNP and, in many cases, may aid the detection of effect SNPs. In particular, the use of LD subsetting can be expected to aid RF and GBM is identifying effect SNPs within LD blocks. Since LD subsets are constructed prior to analysis, the procedure could also be applied to other SL methods. Importantly, GBM provides detection rates for the functional SNPs within sampling variation of detection rates for the ATT. This result for GBM is especially encouraging given that this study uses an additive genetic model that precisely matches the type of effect anticipated by the ATT. SL methods may be expected to provide substantial improvement over the ATT for detecting correlated effect SNPs and SNPs with non-additive and epistatic effects (). Alternatively, RF and GBM may act as an initial screen to reduce genome-wide data to a set of candidate SNPs small enough to make thorough modeling of their complex relationships feasible using penalized regression or other appropriate methods (). The LD subsetting approach also facilitates the introduction of PCVs, as proposed by, which may potentially be used to correct for the effect of MAF on variable importance measures. The proposed PCV correction evaluated in this study provides a marked reduction in the effect of MAF on non-effect SNPs. Caution is necessary in applying PCVs, however, given a moderate effect of MAF remains and the effect of MAF on the importance of functional SNPs may be magnified, with uncertain implications (Supplementary Information). Still, PCVs at minimum provide the option of emphasizing sensitivity to SNPs with low MAF, which may contain the majority of heritable variance for some phenotypes, such as high-density lipoprotein (HDL) cholesterol (), and can be difficult to detect with conventional methods (). Finally, in addition to PCVs numerous covariates for comorbid disorders, environmental factors and other influential variables may be included in the analysis with a much lower computational cost than for popular GWAS software (). A number of factors may be considered in seeking to improve the approaches evaluated by this study. More careful tuning of the metaparameters for the LD subsetting algorithm, including the selection of k, b and t, may enhance the effectiveness of the correction. Alternative methods to improve the use of PCVs to correct for the effect of MAF may also be explored. The correction proposed here is only one possible application of PCVs; other versions may improve the effectiveness of PCVs or carry different advantages tailored to the preferences of the researcher. Finally, these results show strong results for GBM that are consistent with the more widely known RF; additional work should be performed to evaluate GBM as a viable tool for analyzing genome-wide data, especially given its lighter computational burden. Although our approach does not fully eliminate the impact of LD and MAF on variable importance measures, the proposed corrections provide a satisfying improvement. Importantly, LD subsetting also facilitates analysis in a parallel environment, improving the computational feasibility of these methods for genome-wide data. Continuing efforts to establish the validity, reliability and feasibility of SL methods such as RF and GBM with genome-wide data will be crucial to establishing these methods as viable alternatives to conventional GWAS analyses.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
R.Walters et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Reduced impact of MAF and LD at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from 2.3 Correction of importances with PCVs Sandri and Zuccolotto (2010) proposed correcting variable importances by augmenting the data with PCVs, a second copy of the original predictor variables with the rows permuted to disrupt any association with the outcome variable while maintaining the structure among the predictors. The observed variable importance of the PCVs across a number of replications provides an estimate of the importance due to the structure of the predictors. The importance of each PCV can then be subtracted from the importance of the corresponding predictor to estimate the importance of the given predictor that is due to association with the outcome variable. The LD subsetting algorithm does not itself address the issue of MAF but it does provide an opportunity to adapt the approach of Sandri and Zuccolotto (2010) to estimate and correct for the importance due to MAF while maintaining computational feasibility for genome-wide data. For each subset from the LD subsetting algorithm, independent PCVs are generated from Bin 2, p i , where the p i are evenly spaced on [0.01, 0.50] at intervals of 0.001 to fully capture the range of MAF values in GWAS data. These 491 PCVs are then appended to the subset of SNP data and analyzed with the selected SL method. After all subsets are analyzed, the importances are averaged to produce a single variable importance for each PCV. Next, a loess regression curve is fit to the observed variable importances of the PCVs to estimate the expected importance at each MAF. The loess curve is selected to provide a smooth estimate without requiring specification of the non-linear relationship between MAF and variable importance (Supplementary Fig. S1). In this way, we obtain expected importances due to the effect of MAF only for MAF values in [0.01, 0.50]. The expected importance at each MAF can then be used to correct the importances that are observed when using RF or GBM. Specifically, for a given SNP with MAF m, subtract the expected importance at m, as estimated by the loess curve, from the observed importance for the SNP. The remaining importance for the SNP can be attributed to association with the phenotype. Finally, to account for differences in the variability of the importance measure attributable to MAF, the corrected importance of the SNP is scaled by the standard deviation across subsets of the importance of the PCV with p i closest to the MAF m. This is analogous to constructing a z statistic, with the PCVs providing an estimate of the mean and standard deviation for the null distribution of variable importances conditional on MAF. The resulting corrected variable importance may then be used to compare SNPs as usual. Note that our proposed implementation of PCVs differs from Sandri and Zuccolotto (2010) on two key points. First, we generate PCVs as a small number of random binomial variables with varying MAFs, rather than using permuted rows from the data. This modification is justifiable because after LD subsetting the only known problematic structure in the data is variation in MAF. Second, we profit from the fact that we can include the small set of PCVs in each LD subset instead of having to perform multiple replications with the full data to get a stable estimate of the effect of MAF, allowing us to maintain computational feasibility for genome-wide data.
Reduced impact of MAF and LD at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
