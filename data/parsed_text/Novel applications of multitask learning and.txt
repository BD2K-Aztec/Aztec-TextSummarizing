Given a set of biallelic molecular markers, such as SNPs, with genotype values encoded numerically on a collection of plant, animal or human samples, the goal of genetic trait prediction is to predict the quantitative trait values by simultaneously modeling all marker effects. Genetic trait prediction is usually represented as linear regression models. In many cases, for the same set of samples and markers, multiple traits are observed. Some of these traits might be correlated with each other. Therefore, modeling all the multiple traits together may improve the prediction accuracy. In this work, we view the multitrait prediction problem from a machine learning angle: as either a multitask learning problem or a multiple output regression problem, depending on whether different traits share the same genotype matrix or not. We then adapted multitask learning algorithms and multiple output regression algorithms to solve the multitrait prediction problem. We proposed a few strategies to improve the least square error of the prediction from these algorithms. Our experiments show that mod-eling multiple traits together could improve the prediction accuracy for correlated traits.
IntroductionWhole genome prediction of complex phenotypic traits using highdensity genotyping arrays has attracted lots of attention, as it is relevant to the fields of plant and animal breeding and genetic epidemiology (). Given a set of biallelic molecular markers, such as SNPs, with genotype values typically encoded as {0, 1, 2} on a collection of plant, animal or human samples, the goal is to predict the quantitative trait values by simultaneously modeling all marker effects. The problem is called genetic trait prediction or genomic selection. More specifically, the genetic trait prediction problem is defined as follows. Given n training samples, each with m ) n genotype values (we use 'feature', 'marker', 'genotype', 'SNP' interchangeably) and a trait value, and a set of n 0 test samples each with the same set of genotype values but without trait value, the task is to train a predictive model from the training samples to predict the trait value, or phenotype of each test sample based on their genotype values. Let Y be the trait value of the training samples. The problem is usually represented as the following linear regression model:where X i is the ith genotype value, m is the total number of genotypes and b i is the regression coefficient for the ith genotype, e l is the error term. There have been lots of work on predicting genetic trait values from genotype data, such as rrBLUP (Ridge regression BLUP) (), Elastic-Net, Lasso, Ridge Regression (), Bayes A, Bayes B (), Bayes C p () and Bayesian Lasso (), as well as other machine learning methods. Most of the work assumes that for each set of samples there is only one trait, and therefore, a single regression is conducted to predict the trait value. However, in reality, it is quite often the case that we could observe and measure multiple traits rather than one, especially for crops and animals. For example, for plant dataset, once we obtain a fruit, we could measure its weight, size, etc. This will give us multiple traits. Obviously some V C The Author 2016. Published by Oxford University Press.
i37This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com), Bayesian multivariate antedependence model (). GBLUP and multitrait BayesA are mainly based on the framework of linear regression. The Bayesian multivariate antedependence model considers nonstationary correlations between SNP markers through assuming a linear relationship between the effects of adjacent markers. These methods are shown to have superior performance compared with single trait prediction methods. In this work, we study the multitrait prediction problem from a machine learning angle. We consider the multitrait prediction problem as a multitask learning problem or a multiple output regression problem. When there are multiple sets of samples, each having a separate set of genotypes on the same set of markers as well as a corresponding trait, the multitrait prediction problem can be converted into a multitask learning problem. This is shown in. We can see that there are three sample sets and three different genotype matrices. These genotype matrices, however, share the same set of markers. Each sample set has a different trait. When there is only set of samples and one set of genotypes but multiple traits, the problem can be converted into a multiple output regression problem, as shown in. There is only one sample set and one genotype matrix. There are three different traits. Although lots of work have been done for the multitrait prediction problem, this is indeed the first time the problem is modeled as a multitask learning and a multiple output regression problem. We can see that for the multitask learning problem, if we learn each task independently, we only use a small portion of the samples.If we model all the tasks at the same time, we leveraged the information from the complete set of samples and the improvement could be significant when the number of tasks is large. In the multiple output regression problem, although all the tasks share the same set of samples and there is no advantage on the sample size, the prediction performance could still be improved by the modeling the correlations among the tasks. In this work, we adapt the state-of-the-art multitask learning algorithms and multiple output regression problems to solve the multiple trait prediction problem. For the multiple output regression problem, we conduct an iterative algorithm to learning the variable one at a time with others fixed. The objective function is convex when we only optimize one variable with others fixed, and therefore, efficient optimization is allowed. We observed that a direct application of these algorithms to the multiple trait prediction problem usually leads to poor least square error. We applied strategies such as centering the genotype matrix to improve the prediction performance. We showed that modeling all the traits together could improve the prediction compared with predicting each trait independently, especially for the correlated traits.
PreliminariesGiven the traditional encoding of genotypes as {0, 1, 2}, lots of techniques have been applied to the genetic trait prediction problem defined in Equation (1). Consider the typical situation for linear regression, where we have the training set y 2 R l ; x 2 R ln , in a standard linear regression, we wish to find parameters b 0 ; b such that the sum of square residuals, P l i1 y i  b 0  x > i; b 2 , is minimized. Many machine learning methods have been applied to the genetic single trait prediction problem, such as Elastic-Net, Lasso, Ridge Regression (), Bayes A, Bayes B (), Bayes C p () and Bayesian Lasso (). They could be applied to predict the multiple traits where each trait is predicted independently. In this work, we applied ridge regression () for single trait prediction, which aims to minimize the following objective function.The solution of ridge regression is given by:b  X T X  kI 1 X T ywhich is similar to the ordinal least square solution, but with the addition of a 'ridge' down the diagonal. Ridge regression has been shown to have certain bias as kX T X  kI 1 b. The unbiased version of rrBLUP (Ridge regression BLUP) () is one of the most popular methods for genetic trait prediction. rrBLUP simply is ridge regression with a specific choice of k in (2). Specifically, Meuwissen et al.), Bayesian multivariate antedependence model (Jiang). In multivariate models with m traits, marker effects on phenotypic traits were estimated from the mixed linear model below:where y is a n  m matrix with n samples and m traits, a j is a 1  m vector for the effects of the jth marker on all m traits which is assumed to be normally distributed a j $ N0; R aj ; R aj is m  m variance-covariance matrix for the jth marker, e is a n  m matrix for residual error that follows a normal distribution. In multitrait GBLUP (), unstructured covariance matrix among traits was assumed and the relationship matrix derived from SNPs were fit in ASReml (). The multitrait BayesA model () assumes the prior of R aj follows a scaled inverse-Wishart distribution, which were given a flat prior and estimated from the data using the Metropolis algorithm to sample from the joint posterior distribution. Gibbs sampling and MCMC are applied to estimate the parameters. In the Bayesian multivariate antedependence model (), it is assumed that the adjacent markers are correlated as below:where t j;j1 is the scalar antedependence parameter of a j on a j1. Again, the parameters are estimated via Gibbs sampling and MCMC.
Multitrait predictionAs we have discussed before, there are two types of multitrait prediction problem:@BULLET For each trait, the genotype matrix is different: the problem can be formalized as a multitask learning problem. @BULLET For each trait, the genotype matrix is the same: the problem can be formalized as a multiple output regression problem.
Multitask learningMany algorithms have been proposed () for the multitask learning problem. Here we mainly focused on four algorithms: Cluster-based MTL (CMTL) (), ' 1-norm regularized MTL, ' 2;1-norm regularized MTL () and Trace-norm Regularized MTL (). Lasso () is a well-known method that uses the ' 1-norm (or Lasso) regularizer to reduce model complexity and learn features. It can be easily extended for single task learning to multitask learning. The objective function for ' 1-norm regularized MTL is based on least square lasso:where X i denotes the input matrix of the ith task, Y i denotes the ith trait, W i is the coefficient matrix for task i, the regularization parameter q 1 controls sparsity and the optional q L2 regularization parameter controls the ' 2-norm penalty. Note that both ' 1-norm and ' 2-norm penalties are used in Elastic Net. Besides a simple ' 1-norm regularizer, we could constrain all coefficient matrices to share a common set of features. This motivates the group sparsity, i.e. the ' 1 =' 2-norm, or ' 2;1-norm, regularized learning (). The objective function for ' 2;1-norm regularized MTL is also based on least square lasso:where X i denotes the input matrix of the ith task, Y i denotes the ith trait, W i is the coefficient matrix for task i, the regularization parameter q 1 controls sparsity and the optional q L2 regularization parameter controls the ' 2-norm penalty. Notice the difference of the objective functions in Equations (6) (jjWjj 1 ) and(7) (jjWjj 2;1 ). We could also constrain the coefficient matrices from different tasks to share a low-dimensional subspace, i.e. W is of low rank. By replacing the rank of W with trace norm jjWjj   P i d i W, the objective function becomes:where the task coefficient matrices W is decomposed into two components: a sparse part P and a low-rank part Q. The advantage of CMTL is that prior knowledge on the cluster structure of the traits can be embedded into the objective function. For our multitrait problem setting, we always know what are the traits and what they measured. Thus it is very often we know which traits are more correlated with each other. For example, fruit weight and fruit size are known to be highly correlated. These more correlated traits should be in one cluster. By leveraging such cluster information, we could improve the multitrait prediction algorithm. The objective function for CMTL is based on the spectral relaxed kmeans clustering: min W;F:F T FI k LW  atrW T W  trF T W T WF  btrW T Wwhere k is the number of clusters and F captures the relaxed cluster assignment information. As the above objective function is not convex, a convex relaxation cCMTL is also proposed as below:Accelerated Projected Gradient () is applied to optimize the above objective function.
Multiple output regressionGiven a set of training data consisting of N samples, each sample is associated with a genotype matrix X of D-dimension and a trait matrix Y of C-dimension, the multioutput regression model is shown below:where B  B 1 ;. .. ; B c  is a D  C regression coefficient matrix, each element B j is the vector of the regression coefficient for the jth trait. E   1 ;. .. ; N  T is an N  C matrix, where i   i1 ;. .. ; iC  2 R C denotes the residual errors on each trait prediction introduced by the ith sample. Multiple output regression has been widely used in a variety of domains such as stock prices prediction, pollution prediction, etc. It was first noticed byand Friedman that through utilizing correlations between outputs the regression accuracy can be improved. In general there are two types of correlations: the task Novel applications of multitask learning i39 correlation and the noise correlation. Most of the work focus on modeling only one type of correlation, either task correlation or noise correlation. Some recent works (where j:j denotes the determinant of a matrix. The inverse covariance matrix X 1 couples the correlated noise across tags and similarly, R 1 obtained relationships among the multiple tasks' regression coefficients. Apparently, both X 1 and R 1 are learnt from the training data rather than pre-defined prior knowledge. The last two terms trX 1  and trR 1  are the regularizers, which impose the matrix variate Gaussian priors on both X 1=2 and R 1=2 to solve the overfitting issue. The objective function in Equation (12) of the multiple output regression model is not jointly convex in all variables but individually convex in each variable while others are fixed. Therefore, in order to optimize the objective function, an iterative algorithm is applied: (i) Fix X 1 and R 1 and estimate B, (ii) Fix X 1 and B and estimate R 1 and (iii) Fix R 1 and B and estimate X 1. The process iterates and stops when the value of the objective function does not change or when the number of iterations exceeds a pre-defined threshold. As the multiple output regression model is convex in each variable while others are fixed, when we optimize a variable, we can take the derivative of the variable to estimate its optimal value. To estimate B with fixed X 1 and R 1 , we set the derivative of B over the objective function as 0 and we obtain: 2X T XBX 1  2k 1 B  2k 2 BR 1  2X T YX 1) X T XB  k 1 BX  k 2 BR 1 X  X T YBoth works () applied the above algorithm. However, when optimizing B, the work () applies Kronecker product which generates a DC  DC matrix whose complexity might be high for large D and C. Then workMOR improved the complexity by applying Cholesky factorization and singular value decomposition and they showed that the efficiency of the optimization process can be significantly improved. Please refer tofor the details of the two approaches. As k 1 X  k 2 R 1 X is systemic and positive-definite, the Cholesky factorization is performed on it to produce lower triangular matrix P:be the SVD of X and P, respectively, we obtain the following:By setting ~ B  V T 1 BU 2 and S  V T 1 X T YU 2 , we could obtain B as:When optimize R 1 with fixed X 1 and B, we set the derivative of R 1 over the objective function as 0 and we obtain:where I C is an C  C identity matrix and M 1 denotes the inverse matrix of the matrix M. The k 1 ; k 2 ; k 3 are selected by cross-validation. In, dimensionality reduction is applied on both feature space and target (trait) space. Feature space is the space for all the features, which are the genotypes in our setting. Target space is the space for all the target variables, which are the multiple genetic traits in our setting. On feature space, PCA is applied to reduce the dimensionality. On target space, a regularizer is applied to reduce the dimensionality. In this work, we did not conduct dimensionality reduction as in the dataset we studied, the number of features (in thousands) and the number of traits (eight) are not very big. Notice the MOR method without the task correlations and noise correlations can be reduced to a standard ridge regression. We observed that a direct application of the MOR method usually leads to poor accuracy, as the predicted values are usually far off the true values. In order to address this issue, we centered the input data matrix X as XMeanX StdX , where Mean(X) computes the column-wise mean of X, Std(X) computes the column-wise standard deviation of X. We call it Centered MOR. It turns out that the centering strategy significantly improved the least square error of MOR.
Results
Simulated dataWe first simulate the data using the Equation (11). Recall that in this equation, B  B 1 ;. .. ; B c  is a D  C regression coefficient matrix, each element B j is the vector of the regression coefficient for the j-th trait. In order to add task correlation among all the B j 's, we sample B j 's from a standard normal distribution. Similarly, to add noise correlation, we sample the residual errors E from a standard normal distribution. The genotype matrix X is randomly sampled from the values. The traits Y are then computed as Y  XB  E. We simulated four traits for 200 samples, each with 2000 markers. We repeat all the experiments 10 times and computed the average performance. To evaluate the performance of the prediction methods, we used r 2 (r-square, the square of the person's correlation coefficient between the predicted trait values and the real trait values, a popular metric for genomic selection. For genomic selection, the r 2 is almost consistent with least square error). For r 2 , the larger the better. Notice we do not compare multitask learning and multiple output regression methods directly as they will be used in different scenarios. Multitask learning is used when we have unique set of samples for different traits. Multiple output regression is used when we have the same set of samples for all the traits.trait, we train ridge regression only on one subset of 50 samples. For CMTL, as we do not have specific clusters, we just randomly group two of the traits in one cluster and the other two in another cluster. We show the results in. We can see that the four multitask learning algorithms in general achieved much better results than that of the single trait ridge regression. This is reasonable as the single trait ridge regression only uses 50 samples for the prediction. The CMTL does not have any advantage over other methods as the traits are indeed not in clusters. The trace-norm MTL achieved the best results.
Multitask learning
Multiple output regressionHere we conducted 10-fold cross validation for each trait and we compare the performance of the the single trait prediction method: single trait ridge regression, the multiple output regression methods: the centered MOR method and the state-of-the-art multitrait prediction methods: the multitrait BayesA algorithm, the Bayesian multivariate antedependence model. We did not show the performance of MOR here as it in general has poor performance. The results are shown in. We can see that the multitrait algorithms have better performance than the single trait ridge regression does. The Bayesian multivariate antedependence model does not outperform BayesA in that we do not insert LD in our dataset. The centered MOR has the best performance. We also see that the multitrait prediction methods and multiple output regression methods made improvements on all four traits over the single trait prediction method. This is because all the four traits are correlated as they are sampled from the same standard normal distribution. As we will show later in the experiments on real data, when the traits are not correlated, multitrait prediction does not make obvious improvements.
Real dataNext we evaluate the performance of the multitrait prediction methods on a real plant dataset, the avocado dataset, which contains 8 traits, 160 samples and 2663 markers. The eight traits are: fruit weight, seed weight, fruit length, fruit width, fruit diameter, number of fruit (log), mesocarp weight and water loss percentage. From the name of the traits, we know which traits are more correlated with each other. We show the heat map of the correlation of these traits in. Notice in the Figure there are two more traits 'seed width' and 'seed length'. They are not included in the experiments. From the heat map, we can see that the first six traits are more correlated with each other and the last two traits are less correlated with the remaining traits.. The r 2 of the centered MOR method, the multitrait BayesA algorithm, the Bayesian multivariate antedependence model versus the single trait ridge regression algorithm on the simulated dataNovel applications of multitask learning i41
Multitask learningWe randomly divide the genotype matrix into eight subsets, each with 20 samples. Notice the eight genotype matrices share the same set of markers. For each subset, we keep only one trait for the corresponding samples in the subset. Therefore, we ended up with eight datasets, each with a single trait. For single trait prediction, to predict the j-trait, we first train a predictive model on the jth dataset. Then we take all the other datasets as input and apply the predictive model on the other datasets to predict the jth trait for them. The predictive model we used here is ridge regression. For the multitrait prediction, we used four algorithms: Cluster-based MTL (CMTL), L1-norm regularized MTL, L2,1-norm regularized MTL and Trace-norm Regularized MTL. For CMTL, we applied our prior knowledge on the structure of the clusters, namely the traits fruit weight, fruit length, fruit width, fruit diameter are highly correlated and they should be in one cluster. We compare the performance of the four multitask learning algorithms with the single trait prediction. We show the results in. We can see the obviously the multitrait prediction significantly outperforms the single trait prediction, as the single traitprediction used only one-eighth of the complete data to predict each trait. We also observed that CMTL and the TraceNormMTL achieved better results than the other two MTL methods, as they conducted more complicated strategies rather than simple regularization. The TraceNormMTL achieved slightly better results than CMTL, indicating that reducing the original problem into a lower dimensional subspace is indeed an effective strategy when the dimensionality of the original problem is high.
Multiple output regressionFor the multiple output regression methods, as there is only one dataset, we conducted 10-fold cross validation. We evaluated the performance of the single trait prediction method: single trait ridge regression, the multiple output regression methods: the centered MOR method and the state-of-the-art multitrait prediction methods: the multitrait BayesA algorithm, the Bayesian multivariate antedependence model. Again we do not include MOR here as it has poor performance. Notice we do not include the multitrait GBLUP algorithm here as the two multitrait prediction methods have been shown to have superior performance over the multitrait GBLUP algorithm. The performance is again evaluated by the two metrics: r 2 and the least square error. As we can see in, both the multitrait and multiple output regression methods outperform single trait ridge regression. The centered MOR method achieved better performance than the ridge regression does, indicating that the centering strategy is critical for the genetic trait prediction problem. The centered MOR method also shows competitive performance compared with the multitrait prediction methods on most of the traits. Also we can observe that the improvement are mainly made on the first six traits, which are highly correlated with each other. For the last two traits, the multitrait prediction does not show advantages.
Conclusions and future workIn this work, we studied the multitrait prediction problem where the multiple quantitative trait values of a set of samples are predicted from their corresponding genotypes. We modeled the problem from a machine learning perspective. We considered the problem as either a multitask learning problem or a multiple output regression problem. By adapting the state-of-the-art machine learning algorithms, we showed that the prediction accuracy can be improved by modeling all the traits together and we also showed that the machine learning methods are indeed very competitive with the existing statistical methods. We also observed that the MOR method without the task correlations and noise correlations can be reduced into a standard ridge regression. From our previous study on single genetic trait prediction (), we observed that rrBLUP (the unbiased version of ridge regression) achieves better performance than ridge regression does. In our future work, we would like to extend the MOR method to take the form of rrBLUP rather than ridge regression, which might improve its performance. Conflict of Interest: none declared.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
