Motivation: High-throughput molecular profiling has greatly improved patient stratification and mechanistic understanding of diseases. With the increasing amount of data used in translational medicine studies in recent years, there is a need to improve the performance of data warehouses in terms of data retrieval and statistical processing. Both relational and Key Value models have been used for managing molecular profiling data. Key Value models such as SeqWare have been shown to be particularly advantageous in terms of query processing speed for large datasets. However, more improvement can be achieved, particularly through better indexing techniques of the Key Value models, taking advantage of the types of queries which are specific for the high-throughput molecular profiling data. Results: In this paper, we introduce a Collaborative Genomic Data Model (CGDM), aimed at significantly increasing the query processing speed for the main classes of queries on genomic databases. CGDM creates three Collaborative Global Clustering Index Tables (CGCITs) to solve the velocity and variety issues at the cost of limited extra volume. Several benchmarking experiments were carried out, comparing CGDM implemented on HBase to the traditional SQL data model (TDM) implemented on both HBase and MySQL Cluster, using large publicly available molecular profiling datasets taken from NCBI and HapMap. In the microarray case, CGDM on HBase performed up to 246 times faster than TDM on HBase and 7 times faster than TDM on MySQL Cluster. In single nucleotide polymorphism (SNP) case, CGDM on HBase outperformed TDM on HBase by up to 351 times and TDM on MySQL Cluster by up to 9 times.
IntroductionMolecular profiling refers to the study of specific patterns or signatures, such as DNA polymorphism, mRNA gene expression profiling, RNA profiling, proteomics and metabolic polymorphism. Biomedical research is moving towards using more high-throughput molecular profiling data to improve disease understanding. A typical molecular profiling database contains values of features from individuals of interest or samples, to be used for several medical studies. A subject of study is usually a particular sample which we want to analyze for the specific study. At high level, queries on bioinformatics databases are meant to retrieve subjects based on their features as searching conditions. We investigated massive molecular profiling data based analysis applications, such as Van't, Cross and Burmester (2004),, and participated in popular European medical projects, such as U-BIOPRED (Unbiased BIOmarkers in PREDiction of respiratory disease outcomes) () and eTRIKS (European Translational Information and Knowledge Management Services) (). We found three most frequently used steps for disease understanding. The first step is the marker selection. The next step is to discover the relationship between the selected markers and a particular disease. If the relationship is validated, the last step is to detect potential patients with the disease
1Associate Editor: Dr. Jonathan Wren based on their markers. According to the three steps, we consider the three classes of queries for disease understanding: In the first step, multiple cohorts with all markers in the database are collected for a particular study, for example "asthma". select * from table where subjects in {the cohorts} and study = 'asthma';
Query 1In the second step, the selected markers of all the samples in related studies are retrieved to discover the relationship between the markers and the disease. For example, we may want to retrieve the samples genotyped at a particular DNA position in a "asthma" study. select * from table where markers in {the DNA positions} and study = 'asthma';
Query 2If a relationship between features and diseases is validated, all the samples with these markers in the database are selected to detect potential patients for a particular disease. For example, we may want to retrieve all the samples genotyped at a particular DNA position. select * from table where markers in {the DNA position};
Query 3Many management systems can enable scientists to do that, such as tranSMART (), NCBI () and SeqWare (O'). The storage of the first two platforms uses an SQL model and the last one uses a Key Value model. TranSMART is a biomedical data warehouse and analytics software platform that integrates clinical and genomics data using SQL models. The NCBI dbSNP () individual genotype data schema is a widely used relational data model for SNP data. The SeqWare implements a Key Value model based on HBase with secondary indices. In the big data era, molecular profiling data size increases sharply due to new biological techniques, such as next generation sequencing. None of the existing databases work well whilst considering the three "V" features of big data (Volume, Variety, and Velocity). An alternative solution, and what forms the contribution described in this paper, is to take advantage of emerging NoSQL techniques with high speed indices to speed up queries over molecular profiling data. Google Bigtable () is a NoSQL database to store large volumes of structured data in the range of petabytes across thousands of machines. The database model of Bigtable is a set of processors known as clusters. Each cluster controls a set of table partitions. A table in Bigtable is a sparse, distributed, persistent and dynamic sorted tree, known as Logstructured merge-tree (LSM-tree) (), and the data is organized into three dimensions: rows, columns, and timestamps. Many open source projects are implemented based on the Bigtable design, such as Accumulo (), Cassandra (), HBase (), Hypertable (), Druid () and Open Neptune (). Other NoSQL databases, such as MongoDB (), Couchbase (), Redis () and Memcached (), MemcacheDB () and ClusterPoint () have also become a popular solution for managing large volumes of data. For example, MongoDB is a cross-platform document-oriented database, which avoids the traditional relational database structure in favor of JSON-like documents withdynamic schemas (BSON), making the integration of data in certain types of applications easier and faster. Moreover, range scan query in Bigtable can perform even faster than indices of other NoSQL databases for molecular profiling data. For example,indicates HBase data query performs up to 7x faster than MongoDB for microarray data. Yet queries by non-row-key columns in Bigtable can be extremely slow due to random read operations usually being slower than range scan operations. Thus, in Bigtable the secondary index () has a smaller space requirement but performs slow; the clustering index () has larger storage overhead but performs fast. The global index has high network traffic but is easy to implement; the local index has low network traffic but is difficult to implement.did a performance test on all those indices. The global clustering index performs best with a reasonable high storage overhead. However, none of existing molecular profiling data models work well for Bigtable. The distinctive characteristic of our approach is to create a collaborative genomic data model (CGDM), which uses three complementary global clustering index tables (CGCITs) for each of the classes of queries described above. Each CGCIT uses vertical partitions to further speed up the queries and increase the data availability. Thus, CGDM can solve the velocity and variety issues with limited extra volume cost. We index and order each table based on the specific selection criteria of the query (i.e. study, subject, DNA position) and then distribute the queries to the right table based on the specific class or selection criteria it belongs to. Two benchmarks for gene expression and SNP are used to test. The experiments show CGDM implemented in HBase greatly outperforms the traditional model implemented in both HBase and MySQL Cluster.
Methods
Traditional secondary index for the queriesA typical traditional molecular profiling data model (TDM) used in tranSMART includes a main table and three secondary index tables, as shown in. The pk is a unique id. Main table stores data ordered by the id. Three secondary indices are created to speed up the three typical queries above. The subject id is usually associated with its study, so study and subject together can be a unique id for Query 1. The combination of study and DNA position is the fastest index to locate a DNA postion in a specific study for Query 2. The position alone can be used to search information on a specific DNA position in the database for Query 3. There are two types of secondary indices that can be used for this purpose. One stores pk values in the main table, while the pk column in the other index stores pointers linking to the physical location in the main table. In a distributed database, it is very difficult to maintain the second type of index. For example, if the distributed table blocks are mergedor split, all the related physical locations in the pk column will be recalculated. Thus, the pk in the index table usually contains the pk value in the main table. That means that if we sequentially search the index table to find the pk, we need to randomly search the pk in the main table to find the data. The random search leads to a big challenge to design a multi-dimension index for a large range query in Bigtable.
An optimized cluster index for BigtableA clustering index may be introduced to solve the random search problem from the secondary index. But the clustering index leads to a big storage overhead, as each index table is a full copy of the main table. In order to reduce the storage overhead, the backup copies in the database can be reused. Fortunately, in Bigtable there are usually three copies of each table to make sure the data consistence and fault toleration. A main table with two index tables does not increase any overhead. Further more, if the main table can be even re-used, three collaborating clustering index tables can be created for the 3 typical queries.
Collaborative global clustering index tableThe remaining work consists in presenting the design of the index for each query. From the analysis point of view, the study, subject and the DNA position are frequently used as search conditions; From the database point of view, Bigtable offers a hierarchical composite primary key, including row key (primary index) and column key (assistant index). Bigtable horizontally partitions a table by row key and and vertically partitions the table by column key. The row key is the primary index of the key, so the main index columns in this index table are stored here. The other index columns can be added in the column key. Based on the principles above, a collaborative data model for molecular profiling data is created, as shown in.
Column Family separating different types of dataExcept the usage of horizontal index, CGDM also considers utilizing the Bigtable vertical partition feature, i.e. Family, to further speed up data query, as shown in. Family is a special concept, related to a group of columns that contain the same type of data. The same type of data is usually stored together and retrieved together. For example, three different types of gene expression data may be stored, such as raw value, logarithm value and zscore value, and a normal query only focuses on one type of data. If three Families are used for the three types of data, the query could be speeded up by searching about 1/3 of the data only.
The space overhead estimationThe disadvantage of Clustering index is the space overhead. However, the CGDM design uses an even smaller space than the secondary index and that is due to the optimization. The secondary index space includes the mainWhere L pk is the length of primary key, L study is the length of study column, L position is the length of DNA position column, L inf o is the length of non-indexed columns and data replica factor is 3. The CGDM space Sc consists of the space of three CGCITs S c1 , S c2 ,Where N is the number of Family in each CGCIT.The overhead ratio of CGDM to TDM is:Assume pk, study, subject and position have the same length L then, the ratio of the info length to any other index column length R is:Then, the overhead ratio becomes:If N<5, there will not be any overhead. For N from 5 to 7, we plotted the. The overhead ratio drops significantly as the R increases and the N decreases, which indicates that CGDM should have less columns to index and all index columns should have small length to avoid big space overhead. If N changes from 5 to 7 and the R changes from 10 to 30, then the overhead changes from 7.14% to 52.94%.
Fault ToleranceIn CGDM, CGCITs will have no replica to avoid huge storage overhead, and cause the problem of fault tolerance. The basic idea is that CGCITs will replicate and recover each other at record level. As both CGCIT1 and CGCIT2 row keys begin with study column, rows in CGCIT1 and CGCIT2 are both ordered by study. When a region of a CGCIT1 is damaged, we can quarantine the regions of the studies involved and use regions containing the same studies in CGCIT2 to reconstruct the regions. For CGCIT2, the situation is similar. For CGCIT3, we can only isolate DNA positions involved and fetch corresponding information by scanning the whole CGCIT2. During the scan, we can use DNA position range to skip unnecessary regions.
Results
Experiment EnvironmentThere are many implementations of Bigtable, such as Hypertable (), Apache HBase () and Apache Cassandra Lakshman and Malik (2010). We chose the most popular oneHBase. A monolithic relational database is difficult to be compared to HBase clusters, but many relational database clusters can be used for this purpose, such as MySQL Cluster (), PostgreSQL XE () and SQL Server Cluster (). Compared to other database clusters, MySQL Cluster, supported by Oracle, is one of the most powerful and easy to deploy clusters. Both HBase and MySQL Cluster were running on a OpenStack platform. HBase was used to implement both the TDM and CGDM, while MySQL Cluster implemented TDM. Each database was configured as follows: HBase (Version 0.96.0 on Hadoop 1.0.3): One master server node and three slave nodes with HBase configured in fully distributed mode. The master server was configured as a virtual machine (VM) with 4 CPU cores and 8 GB memory, while each slave node was configured as VMs with 4 CPU cores and 8 GB memory. Each VM used a 100 GB disk. Three copies is the minimum number for the Hadoop Distributed File System to guarantee data consistency. MySQL Cluster (Version 5.6.11-ndb-7.3.2): Four VMs, with one as a manager node and three data nodes. The manager node consists of a MGM, a MySQL and a NDB using a VM with 4 CPU cores and 8 GB memory. Each VM used a 100 GB disk. Each data node consisted of a NDB. Two data copies were used to guarantee its data consistency.
Microarray benchmarkOur experiment was performed using a public Multiple Myeloma (MULTMYEL) () dataset(). The reason we chose MULTMYEL as our test dataset was that it is one of the largest datasets, consisting of 559 samples and 54,675 probesets for each sample, totalling approximately 30.5 million records. In each record there are three columns in the info part, the raw value and two normalized values (logarithm and zscore). These values are usually used separately for different purposes, so three data types (Family) are set for the three values.
Query 1 EvaluationWe refer to the use cases and part of the results from the paper () and add an new baseline test to see how TDM works for HBase. The searching conditions in these use cases are mostly related to the subject, so CGCIT1 is selected to perform the tests. In, CGDM in HBase demonstrates an average 5.24 and 73.89 times of increase compared to TDM implemented on MySQL Cluster and HBase. Compared to TDM on HBase, in 5/11 of cases, CGDM performs more than 80x faster than TDM on HBase. In 3/11 of cases, CGDM is more than 90x faster. With the subject number increasing, the CGDM's advantage is more obvious. In the last and biggest case, CGDM outperforms the traditional one by 101x. Compared to TDM on HBase, in 6/11 of cases, CGDM is more than 5x faster than traditional model on MySQL Cluster. In 10/11 of cases, CGDM is more than 4x faster than TDM on MySQL Cluster. In the worst case, A2, CGDM is more than 3.61 times faster than traditional model on MySQL Cluster.
Query 2 EvaluationA normal marker selection returns about 100 potential probe sets, which need to be verified by other datasets of similar studies. Based on the design CGCIT1 will perform sub-standard for this purpose, but CGCIT2 can perform much faster. We randomly generated 100 probes and test CGDM against the one. The query of Key Value model is based on the Random Read operation. CGDM demonstrates an average 174.52 times of increase compared to TDM implemented on HBase. In 4/10 of cases, CGDM on HBase is more than 170 times faster than TDM on HBase. In 9/10 of cases, CGDM on HBase performs 140 times faster than TDM on HBase.CGDM demonstrates an average 3.06 times of increase compared to TDM implemented on MySQL Cluster. In 6/10 of cases, CGDM is more than 3 times faster than traditional model on MySQL Cluster. In 9/10 of cases, CGDM is more than 2.5 times faster than TDM on MySQL Cluster. In the worst case, 20-thread, CGDM is more than 2.47 times faster than traditional model on MySQL Cluster. HBase performs as stable as MySQL Cluster in most of the cases, as show by the greater average result deviations in.
Query 3 EvaluationA further validation is performed using three GSE24080 studies. We copied GSE24080 dataset twice and arbitrarily named them GSE24081 and GSE24082 and re-used the 100 probe sets in the query by position experiment. MySQL Cluster failed to load these three datasets due to a memory limitation. We compared the query using both CGDM and TDM on HBase. CGDM demonstrates an average 246.48 times of increase compared to TDM, as shown in. In 6/10 of cases, CGDM is more than 220 times faster than TDM. In 3/10 of cases, CGDM is more than 250 times faster than TDM. In largest case, CGDM is more than 210 times faster than TDM.
SNP benchmarkThe large Microarray benchmark shows the performance of CGDM throughput, without considering the response time for small queries. If only one subject or a few DNA position are required, a large overhead may damage the users' experience. The SNP benchmark not only illustrates the throughput of CGDM but also its response time of small queries. Also, the TDM on HBase performs much worse than the other two implementations). This SNP dataset has only one type of data.
Query 1 EvaluationUsually, the first step of SNP based medical research is to find significant differential SNPs with clinical information in a study. All available SNPs of the specified subjects with typical features are loaded for further tests to find the expected SNPs. Thus, the first query is usually applied on the main cohorts (almost all subject) at the beginning of a study to find the most relevant SNPs. For this type of case, we searched all subjects in each dataset and as shown in, CGDM on HBase is on average 269.39 times faster than TDM on HBase. CGDM on HBase outperforms TDM on HBase by 351.33 times when tested with CHB dataset, while when using datasets ASW and CEU, TDM it performs 215.15 and 241.68 times faster than TDM on HBase. CGDM on HBase performed about 4 or more times faster for the data retrieval time than TDM on MySQL. Particularly in ASW, CGDM on HBase outperforms TDM on MySQL Cluster by 9.12 times. While in datasets CEU and CHB, CGDM respectively performed 5.12 and 4.51 times faster than TDM on MySQL Cluster. In the response time test of one subject queries over 119,487 SNPs, CGDM on HBase is 148.25 times faster than TDM on HBase on average, as shown in, while the queries over 317,462 SNPs using CGDM outperformed TDM on MySQL Cluster by 99.20 times. The response time of 119,487 SNPs queries with CGDM are 2.61 times faster than TDM on MySQL Cluster on average, while the queries over 317,462 SNPs using CGDM outperformed TDM on MySQL Cluster by 1.57 times.
Query 2 and 3 EvaluationAfter significant differential SNPs are calculated, the top hundred differential SNPs are usually tested using other datasets to confirm or further reduce the number of these SNPs. If SNPs associated with certain diseases are found, queries over several SNPs across datasets are generated to detect whether a patient is vulnerable to certain diseases based on his genotype information from the SNPs. While querying 100 discrete SNP by position, CGDM on HBase performs on average 15.40 times faster than TDM on HBase. But TDM on MySQL Cluster is 1.84 times faster than CGDM on HBase on average, as shown in, due to the slow HBase Random Read. However, with concurrent query thread number increasing, MySQL Cluster does not scale well, as shown in. CGDM on HBase demonstrates an average 4.66 times of increase in query processing speedcompared to TDM implemented on MySQL Cluster. In 6/10 of cases, CGDM is more than 5 times faster than TDM on MySQL Cluster. In the worst case, when using only 10 threads, CGDM is more than 3.07 times faster than TDM on MySQL Cluster. Compared to TDM on HBase, CGDM performs 105.40 times faster on average. Especially, in 6/10 of cases, CGDM is more than 100 times faster than TDM on HBase.
DiscussionThe most common queries for disease understanding do not cover all the commonly used queries, for example wildcard query. Generally, there are two main types of wildcard queries. One begins with a wildcard (%searchstring...). This query will perform a scan operation on a full or large range of the table. The other one starts with a search string (search-string%...). This query will perform a relatively small seek operation based on theprefix 'search-string'. Though tests for wildcard query are not specified, some of the results show some hints about how CGDM may perform. The last query in section 3.2.1, which performed a scan on the whole table, indicates the performance of a test similar to (%search-string...). The query tests in section 3.2.3 performed queries similar to queries with wildcard (GSE2408%) on HBase. Due to the hierarchical design of CGCIT, CGCIT has three types of wildcard queries, the wildcard query on primary index, the wildcard query on other indices and the wildcard query on content. The last query in section 3.2.1 shows a wildcard query on primary key and the queries in section 3.2.3 indicates wildcard queries on other indices. Any one of these three wildcard queries may not be the best choice for certain cases, while a mixed dynamically wildcard query plan may perform better than statically choosing one.
ConclusionIn this paper, CGDM has been created for high-throughput molecular profiling data to improve the query processing speed for the three main classes of queries on genomic databases. Multiple benchmarking experiments were carried out, comparing CGDM implemented on HBase to TDM implemented on both HBase and MySQL Cluster, using large publicly available molecular profiling datasets. In the microarray case, CGDM on HBase performed up to 246 times faster than TDM on HBase and 7 times faster than TDM on MySQL Cluster. In the SNP case, CGDM on HBase outperformed TDM on HBase by up to 351 times and TDM on MySQL Cluster by up to 9 times.
Funding
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
