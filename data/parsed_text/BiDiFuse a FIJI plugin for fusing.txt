Deep tissue imaging is increasingly used for non-destructive interrogation of intact organs and small model organisms. An intuitive approach to increase the imaging depth by almost a factor of 2 is to record a sample from two sides and fuse both image stacks. However, imperfect three-dimensional alignment of both stacks presents a computational challenge. We have developed a FIJI plugin, called BiDiFuse, which merges bi-directionally recorded image stacks via 3D rigid transformations. The method is broadly applicable, considering its compatibility with all optical sectioning microscopes and does not rely on fiducial markers for image registration.
IntroductionIncreasing interest in microscopic visualization of intact biological specimens has fueled a surge of methodological developments in recent years, including tissue clearing and optical sectioning microscopy. Parallel to the continuous improvements of tissue clearing methods aimed at increasing optical penetration depth (, the evolution of optical sectioning techniques, such as confocal, two-photon and, in particular light-sheet microscopy (), have enabled rapid, non-destructive imaging of thick tissue specimen. Despite the tremendous impact these methods have had in extending imaging depth, various constraints still exist, including the limited working distance of microscope objectives, the variable clearing performance between different tissue types, and the inevitable loss of signal quality in deeper tissue layers. A simple method to increase the imaging depth is to record the sample from opposite sides. As this action involves flipping and relocation of the sample, a method is required to computationally fuse both image stacks and generate a single stack with comparable image quality at the top and bottom. We present a method, called BiDiFuse, which is based on 3D rigid transformations to register corresponding landmark points in both image stacks (). This is the first open-source implementation that is compatible with all fluorescent labels, and is independent of the optical sectioning method used for image acquisition.
MethodsMicroscopic images can be provided as bi-directionally recorded image stacks containing one or more channels, as single or stitched image volumes. Both image stacks are imported in FIJI open-source freeware (), after which a reference stack is selected (stack A) and the other image stack (stack B) is mirrored and the order of the planes in the stack is reversed. The only user intervention that is required for registration, is the selection of three corresponding landmark points in both stacks. In stack A, the first two landmark points (P1 and P2) can be chosen freely, after which the third point (P3) should be indicated on the vector P1-P3, orthogonal to P1-P2. The same landmark points are subsequently indicated manually on the image stack B. For the registration process, the first landmark point (P1) is regarded as the image origin for both image volumes. First, the directed rotation () about the orthogonal axes, P1-P2 and P1-P3, is determined using an arctangent function with two arguments, atan2 (eq. 1, 2). The rotation about the third axis (i.e. z-axis, the axial imaging axis) is calculated as the angle between the projected vectors P1-P2 in the first (A) and second image stack (B, eq. 3).Given the angles of rotation in 3D, three rotation matrices are calculated and applied to the image using the rotate function in TransformJ. The transition point between image stacks can then be selected on the basis of the plane intensity and sharpness (derived from Sobel filtering), or set manually. A smooth transition between both image stacks can be achieved by blending a selected even number of planes (SZ) surrounding the transition point (TP). This can be done by means of various blending options, including linear weighted sum (eq. 4), maximum, minimum, mean, median, average, and sum blending.
The Author (2016). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com Associate Editor: Prof. Robert Murphy Bioinformatics Advance Access published August 8, 2016 at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Results Unidirectional recordings of a cleared brain slice with a nuclear counterstain lose nearly half their intensity when moving deeper in the tissue, together with a notable decrease in image contrast (Figure 1B, C). This loss is compensated for by fusing of bi-directionally recorded image stacks, resulting in a drop of less than 20% in the middle of the stack. Fusing can be done with high accuracy, as can be derived from the alignment of blood vessels in a XZ-view (Figure 1D). This is reflected in an increase in the Pearson correlation of two corresponding images from both stacks after registration (from 0.120.07 to 0.480.07, n=3). Fusion has been performed with multiple samples imaged on different optical sectioning imaging setups, including two-photon, confocal and Apotome.2 structured illumination (Zeiss) microscopes (Examples are available in the download package). 4 Discussion Although a two-view imaging approach has been described earlier (Susaki et al., 2014), we have developed a convenient image registration workflow that is made available as an open-source FIJI plugin. It is different from the powerful bead-based multi-view selective plane Figure 1: BiDiFuse workflow and results. (A) Fusing of bi-directionally recorded image stacks is done by rigid image transformations (3D translations and rotations). (B) a cleared brain slice with a nuclear counterstain shows the loss in image intensity in deep tissue layers, which is compensated for using BiDiFuse, as shown in (C). (D) An XZview of a cleared brain slice shows the misalignment before and after correct alignment of blood vessels after fusing. Fusion was done without blending to visualise the alignment of the image stacks. Scale bars: 100 m. illumination microscopy (SPIM) registration software (Preibisch et al., 2010) in several aspects. First, BiDiFuse is compatible with all sectioning microscope setups, and does not require registration of the stage position. Moreover, registration can be done without additional tissue preparation measures, such as mounting the sample in the presence of fluorescent beads or addition of nuclear counterstain. Since our method only accounts for rigid transformations, the specimen should be fixed and immobilized for microscopy for optimal results (e.g. mounted between coverslips, or on a rotatable stage). The dataset size for fusing is limited by the RAM required for the 3D rotation process, but can be extended by virtual loading and rotation of the image stacks. The time for fusing two 1Gb datasets in the order of a few minutes, using the nearest-neighbor interpolation algorithm for image rotation. The choice for manual landmark identification is driven by the lack of information on the sample position and the large size of 3D datasets. Increased precision can be achieved by a post-hoc automatic registration.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
