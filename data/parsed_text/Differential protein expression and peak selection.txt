Motivation: Proteomic mass spectrometry analysis is becoming routine in clinical diagnostics, for example to monitor cancer biomarkers using blood samples. However, differential proteomics and identification of peaks relevant for class separation remains challenging. Results: Here, we introduce a simple yet effective approach for identifying differentially expressed proteins using binary discriminant analysis. This approach works by data-adaptive thresholding of protein expression values and subsequent ranking of the dichotomized features using a relative en-tropy measure. Our framework may be viewed as a generalization of the 'peak probability contrast' approach of Tibshirani et al. (2004) and can be applied both in the two-group and the multi-group setting. Our approach is computationally inexpensive and shows in the analysis of a large-scale drug discovery test dataset equivalent prediction accuracy as a random forest. Furthermore, we were able to identify in the analysis of mass spectrometry data from a pancreas cancer study biological relevant and statistically predictive marker peaks unrecognized in the original study. Availability and implementation: The methodology for binary discriminant analysis is implemented in the R package binda, which is freely available under the GNU General Public License (version 3 or later) from CRAN at URL http://cran.r-project.org/web/packages/binda/. R scripts reproducing all described analyzes are available from the web page http://strimmerlab.org/software/binda/.
IntroductionMass spectrometry, a high-throughput technology commonly used in proteomics, enables the measurement of the abundance of proteins, metabolites, peptides and amino acids in biological samples. The study of changes in protein expression across subgroups of samples and through time provides valuable insights into cellular mechanisms and offers a means to identify relevant biomarkers, e.g. to distinguish among tissue types, or for predicting health status. In practice, however, there still remain many analytic and computational challenges to be addressed, especially in clinical diagnostics (). A recent overview of statistical issues in the analysis of proteomics mass spectrometry data is Morris (2012) who discusses a wide range of methods ranging from data preprocessing, i.e. removal of systematic bias, peak identification, peak alignment and quantification and calibration of relative peak intensities, to methods for high-level statistical analysis, such as peak ranking and classification. Of particular importance is the problem of differential protein expression and the identification of peaks informative for group separation and class prediction. A special characteristic of mass spectrometry data is their dualvalued nature, i.e. they contain both continuous as well as discreteinformation. Specifically, a protein may be differentially expressed if its intensity of expression varies among groups and is relatively up-or down-regulated, or if a corresponding peak is either absent or present in a specific group. Consequently, mass spectrometry intensity matrices typically contain very large amounts of missing values, which renders application of standard statistical methodology from other omics platforms, such as regularized t-scores, difficult and potentially suboptimal. Accordingly, this has initiated the development of new statistical methodology (). Two main strategies to address this issue in the high-level analysis of mass spectrometry data have emerged: 1. All data are treated as continuous, with missing intensity values set to zero or imputed. Subsequently, standard omics methods are employed, such as t-scores for feature selection (e.g.). 2. The absencepresence data are used for data analysis in conjunction with the intensity values.propose peak probability contrasts (PPCs), the absolute difference in frequency of occurrence of a peak, for ranking and feature selection, and also use PPC to improve absencepresence data by dichotomization of intensity values.propose a test based on the PPC statistic and propose to apply joint false discovery rate control of the union of intensity-based and PPCbased rankings.Here, we follow the second route and propose a novel coherent model for differential protein expression and prediction based on binary discriminant analysis (BinDA). Our approach may be viewed as a generalization ofand comprises the following: @BULLET The binary absencepresence data are explicitly modeled by a multivariate Bernoulli (MVB) distribution. @BULLET Multi-group binary discriminant analysis (BinDA) is employed for feature ranking, variable selection and prediction. @BULLET For ranking of peaks the natural relative entropy variable importance measure coherent with BinDA is used, rather than PPC. @BULLET Likewise, for dichotomization of the intensity data matrix containing missing values we employ the same entropy-based criterion.As a result, we obtain simple principled framework for analyzing dual-valued mass spectrometry data without the need for imputation, with a natural measure for variable ranking and for differential protein expression, and with coherent prediction rules. In contrast to many other methods this approach also allows multiple groups as response variable, and thus extends beyond simple pairwise comparisons. The remainder of the paper is structured as follows. Next, we describe in detail the statistical methodology underlying BinDA. Then, for validation we investigate the performance of the proposed approach in comparison with a random forest on a large-scale chemometric dataset. Subsequently, we present a detailed case study analyzing mass spectrometry data from a pancreas cancer study. For reproducibility, we provide the R package binda implementing our approach and R scripts for all analyzes described. Finally, we discuss applicability of the BinDA approach to other molecular data as well as further extensions.
Methods
Setup and notationOur analysis starts after the raw mass spectrometry data have been adequately preprocessed, i.e. transformed, smoothed, backgroundremoved, calibrated, aligned and peak-extracted (e.g.). We denote the resulting peak intensities by z ij ! 0, with spectrum index i 2 f1;. .. ; ng and peak index j 2 f1;. .. ; dg. The data matrix z ij typically contains missing values as not all of the registered d peaks will be present in all of the n spectra. In a classification setting each spectrum i also carries a class label y i 2 f1;. .. ; Kg that assigns it to one of K different groups, for instance health status, tissue type or treatment outcome. The label is known for training data and unknown for test data. The sample size in group with label y is n y with n  P K y1 n y. From the continuous data z ij we obtain binary peak intensities x ij by thresholding at peak-specific levels w  w 1 ;. .. ; w d . Specifically, we set x ij  1 if the peak is present in sample i and z ij ! w j. Conversely, if the peak is absent or z ij < w j then x ij  0. The methodology we present here uses the binary matrix x ij for prediction and variable ranking, rather than the original data z ij , and it also estimates the thresholds w.
Modeling binary dataStochastic models for multivariate binary data are well established (e.g.). A univariate binary random variable X $ Bel with two states x  0 and x  1 is completely described by a Bernoulli distribution Bel with expectation EX  l and variance VarX  l1  l. In the multivariate case this generalizes to X  X 1 ;. .. ; X d  $ Be d l; f where d denotes the dimension of the MVB distribution, l  l 1 ;. .. ; l d  is the vector of expectations EX  l, and f contains the 2 d  d  1 interaction parameters. As in the univariate case the variances VarX j   l j 1  l j  are fully determined by the means. In many cases it is useful to ignore the dependencies among the individual variables X j in order to reduce the number of parameters in the model. Despite, or perhaps because, of its simplicity the independence 'naive Bayes' assumption can be very effective, especially for prediction in high dimensions and small sample size, see Hand and Yu (2001) and Park (2009). For MVB with independent predictor variables the joint probability mass function is given bywith diagonal covariance matrix VarX  diagfl j 1  l j g.
Discriminant analysis with binary predictorsFor prediction of the class associated with an unlabeled spectrum we need to construct a prediction rule. Here, we employ a Bayesian prediction rule similar as in diagonal discriminant analysis (DDA) that is routinely and successfully used, e.g. in transcriptomics (). We first define group-specific models for each group with label y,For each group y we also specify a prior probability PrY  y  p y withyj we denote the pooled mean for each variable j, i.e. the mean we would assign if there was only a single category. The posterior probability of each group is then given by Bayes' theorem Pryjx  Prxjyp y =Prx which after taking the logarithm yields the discriminant function d y x  log Pryjx  log p y  log Prxjy  C :
Protein expression and peak selection by BinDAAs the purpose of d y x is only to compare among different groups we can drop all terms that do not depend on y, such as Prx, represented above by the constant C. Prediction of a label for test data x is carried out by choosing the group y that maximizes the discriminant function,This MVB independence prediction rule has shown to be highly effective (e.g.), even if there is correlation among predictors. Typically, the parameters of discriminant function are unknown themselves and have to be learned themselves from training data, i.e. from spectra with known group labels. The training is done by estimating the means l yj and the group probabilities p y in Equations (1)and (2). We suggest a flexible estimation strategy by employing maximum-likelihood estimation for large sample size, and otherwise using regularized estimation. For instance, to estimate the group probabilities we use observed frequencies ^ p y  n y =n if n is large, and for small n the Stein-type shrinkage estimator of proportions described in Hausser and Strimmer (2009).
Variable ranking and selectionClosely tied in with prediction is the question which variables are most important for successful assignment of a class label, and conversely, which variables are irrelevant. Especially in large-dimensional problems it is very important to remove the null features as the build-up of random noise from these variables can substantially degrade the overall prediction accuracy (cf. Ahdesm ki and). For ranking features in discriminant analysis with binary variables there have been many, in part contradictory, propositions. For the case of K  2 groups the following criteria, among others, have been used: @BULLET The v 2 statistic of independence between response and predictors (), @BULLET PPCs jl y1  l y2 j (), @BULLET Quinlan's information gain measure (), and @BULLET ratio of between-group and within-group covariance (). Seefor many other proposals for measuring associations between categorical outcomes and binary variables. Only some of the criteria above can also be applied to the multiple group case (K > 2). We use a principled approach to variable ranking relying on predictive information, seefor an overview. Conceptually, we use the expected log-predictive density as measure of model fit, and compare the fully specified joint model containing all predictors and the response with a 'no-effects' model where the response is independent of the predictors. The difference of expected log-likelihood between full and 'no-effects' model is given by the relative entropy or KullbackLeibler divergence D  KLF full jjF noeff . The relative contributions of each individual predictor to D then provides a measure of variable importance. This procedure applied to linear regression with independent predictors results in squared marginal correlations, and applied to DDA it yields squared t-scores, both of which are optimal measures for variable ranking in their respective settings ().This results inwhere r 2 j  l 0j 1  l 0j  is the variance of Bel 0j . For the special case of K  2 groups S j simplifies toBy construction, the score S j is a measure of variable importance of feature j where S j is a weighted sum of the squared z-scores that compare each group mean with the overall pooled mean. This is precisely analogous to the pooled-mean formulation of discriminant analysis described in Ahdesm ki and Strimmer (2010). If the variances r 2 j are similar across features, then S jK2 is apart from a scale factor the squared PPC. As above for learning the discriminant function, we use for estimation of the entropic ranking scores S j either maximum-likelihood or shrinkage estimates of proportions, depending on sample size. Noting that n^ p y =1  ^ p y   1=n y  1=n 1 we may also introduce squared t-scoresthat are properly scaled to allow to contrast the individual contributions of each class relative to each other, similar as in the methods described in Ahdesm ki and Strimmer (2010) and. The estimated ranking score may also be expressed in terms of a weighted sum of the t-scores viaAfter ranking variables according to the estimated scores ^ S j , with highest scores indicating the most relevant predictors, we use cross-validation to evaluate prediction accuracy for different numbers of included predictors to determine a suitable cutoff.
DichotomizationWith the above setup for BinDA it is straightforward to perform dichotomization. Specifically, we choose thresholds w  w 1 ;. .. ; w d  to discretize the continuous data z ij to maximize the entropy score D (Equation 3). As in our model assume the predictors are assumed to be independent we can optimize each threshold w j independently by maximizing the individual S j. Note that the same entropy measure is used both for determining the thresholds and for ranking the predictors, thus ranking and discretization is done in an integrative fashion.
Results
Implementation and reproducible researchWe have implemented our approach for multi-class discriminant analysis using binary predictors including functions for variable ranking and dichotomization in the R package binda that is freely available under the GNU General Public License (version 3 or later) from URL http://cran.r-project.org/web/packages/binda/. For reproducibility of the analyzes presented in this paper we provide corresponding R scripts at http://strimmerlab.org/software/ binda/.
Validation of bindaBinDA has been studied extensively and is well established in the literature (e.g.). More recently, it was demonstrated that BinDA with naive Bayes assumption can yield high rates of predictive accuracy even if the underlying assumption of independence of predictors is not met (). For validation of our implementation of BinDA in the R package binda we analyzed a large-scale chemometric test dataset. Specifically, we investigated the 'Dorothea' drug discovery dataset from the NIPS 2003 feature selection challenge (). The dataset contains d  100 000 binary features describing the 3-D properties of chemical compounds that either bind (response label  1) or not (label  1) to thrombin, an enzyme involved in blood clotting. We used the 'Dorothea' training data with n train  800 samples and corresponding class labels to learn a classifier with binda. Subsequently, we applied the resulting classification rule to the validation dataset with n val  350 samples and predicted the sample labels of the validation data. As for the validation data the true labels are known we were then able to compute the actual prediction accuracy, i.e. the proportion of correctly identified labels. Due to its algorithmic simplicity training the classifier and ranking variables with binda was computationally inexpensive. Applying class-balanced 5-fold cross-validation with 20 repetitions using the R package crossval on the training data alone we determined that the response can be predicted well with only very few top ranking predictors included in the classification rule. For instance, a binda classifier with three predictors yielded prediction accuracy on the validation set of 0.9371 and of 0.9429 if 10 predictors were used. The predictive accuracy without any variable selection including all 100 000 predictors was 0.9057. For comparison we also trained a random forest (), a tree-based machine learning approach that emerged as one of the overall best performing methods for classification in a recent systematic study (Fern ndez). Due to the high-dimensionality the running time for learning the random forest from the training data was two magnitudes slower than binda, taking 652 seconds on our workstation in comparison to 5 seconds for binda. The random forest yielded an accuracy of 0.94 for prediction of the labels of the independent validation dataset. This analysis confirms that BinDA, though very simple, is able, at least for this data, to perform prediction as accurately as random forest. Correspondingly, if variables in the random forest were ranked according to the Gini variable importance measure the topranking features were mostly identical to those ranked best by BinDA, which indicates that BinDA is indeed able to select the most relevant variables.
Analysis of pancreas cancer proteomics data
Pancreas cancer studyFor illustration of our proposed approach to classification and peak ranking in mass spectrometry data we also reanalyzed experimental proteomics data from a pancreas cancer study conducted in Leipzig and Heidelberg (). For the training dataset of this study 40 patients with diagnosed pancreas cancer as well as 40 healthy controls were recruited. Each participant of the study donated serum samples which provided the basis for MALDI/TOF measurements. For each sample four technical replicates were. Ranking of 166 peaks in the preprocessed spectra from the pancreas cancer study according to BinDA framework(2009) using (A) the original absencepresence data and (B) the optimized binary matrix. Filled circles indicate pancreas cancer samples, empty circles healthy controls. For clustering, we employed Ward's agglomerative hierarchical clustering based on a Jaccard distance matrix computed using R standard functions hclust() with method'ward.D2' and dist() with method'binary'
Most Differentially Expressed Peaksobtained. Due to the presence of strong batch effects in our analysis below we restrict ourselves to patients and controls from Heidelberg, leading to a raw dataset containing 160 spectra for 40 probands, The aim of the study was to determine biomarkers to discriminate patients with pancreas cancer from healthy persons.found marker peaks at m/z 3884 (double charged) and 7767 (single charged) and correspondingly supposed platelet factor 4 (PF4) as potential marker, arguing that PF4 is down-regulated in blood serum of patients with pancreatic cancer.
Preprocessing and dichotomizationFor preprocessing of the raw mass spectrometry data we employed the standard analysis pipeline implemented in the R package MALDIquant (). Specifically, the raw data were variance-stabilized, smoothed, baseline-corrected, TICstandardized and aligned. Technical replicates were then averaged, peaks were identified and corresponding intensities extracted from each averaged spectrum. Precise details on the preprocessing can be found in the R script. As a result a protein expression matrix of size 40 patients times 166 peaks was obtained. In total 26% of intensities in the matrix were missing, corresponding to about 44 missing peaks per spectrum. Subsequently, we performed dichotomization of the intensity matrix using the relative entropy criterion of Equation (3). To illustrate the improvement of the resulting binary data matrix over the original absencepresence matrix we conducted hierarchical clustering on the samples. As can be seen inthe clustering based on the optimized binary matrix almost perfectly separates pancreas cancer samples from healthy samples, indicating that there is a strong signal in the data.
Peak ranking and differential expression thresholdsIn order to identify features responsible for the separation of cancer versus healthy samples inwe applied peak ranking for binary data according to BinDA. The resulting ranking of the 30 best discriminating peaks is shown in. As a consequence of the discrete data, the first three top-ranking peaks with m/z values 4495, 8868 and 8989) achieved the same maximum score, followed by the next three peaks 1855, 4468 and 8937, that also achieved an identical score. We note that none of these peaks was identified in the original study. The two PF4 peaks with m/z 3884 and 7768 (the slight difference is due to the MALDIquant alignment procedure) rank on places 148151 and 157163, respectively.Using cross-validation, we estimated prediction errors for group separation from the binary data matrix. As for the 'Dorothea' dataset we employed class-balanced 5-fold cross-validation with 20 repetitions. Interestingly, using only five predictors was sufficient to achieve an accuracy of 0.96, sensitivity of 0.96, specificity of 0.97, positive predictive value of 0.97 and negative predictive value of 0.95. This indicates that the observed clear separation between cancer and control samples inis attributable to only very few features of the data. Visual inspection of the group of top-ranking differentially expressed peaks revealed a further pattern (). First, five of the peaks are all part of the same peak group. Second, the peak group appears both in a single charged (m/z 8868, 8937, 8989) version as well as in a mirrored double charge version (m/z 4468 and 4495). This affirms that there must an underlying biological marker driving the observed changes between cancer and control samples. To study this further, we inspected the intensities for the peaks belonging to the differentially expressed peak group.shows the overall density, as well as the sub-density for the cancer samples, along with the dichotomization threshold estimated by binda. For all five peaks the expression respectively the underlying protein abundance is up-regulated in the cancer samples compared with the controls. In addition, the estimated thresholds provide an effective means to separate the two groups.
8937
Biological relevanceFinally, we also tried to identify the biological molecules behind the differentially expressed peak group shown in. Specifically, we used the TagIdent tool () with settings Mw 8936.97, Mw range 0.05% and organism homo sapiens to query the UniProtKB/Swiss-Prot database (). This indicated a potential link of the central peak m/z 8937 to PDPFL_HUMAN, the pancreatic progenitor cell differentiation and proliferation factor-like protein, as well as to a fragment of C3adesArg, an acylation stimulating protein. The increased abundance of PDPFL_HUMAN in pancreas cancer tissue appears highly plausible, and the increased concentration of C3adesArg in serum of cancer patients has also been reported previously (e.g. Opstal-van). Another biologically relevant result of our analysis based on BinDA is that the originally proposed PF4 marker is not differentially expressed and hence cannot be used to distinguish between cancer and healthy samples.
DiscussionWe have presented a simple yet effective approach to differential expression and classification for mass spectrometry data using BinDA. Our approach may be viewed as generalization ofand can be applied also for multi-group discriminant analysis. A particular feature is the use of the same relative entropy criterion for peak ranking and selection and for dichotomization of the continuous protein intensity data. In addition, we obtain decision thresholds from the protein intensities that are biologically and diagnostically easy to interpret. In illustrative analysis of high-dimensional drug discovery data we showed that our approach implemented in the R package binda is computationally effective and yet competitive with a random forest. Furthermore, in reanalysis of proteomics data from a pancreas cancer study we found statistically predictive marker peaks to tumor cell growth unrecognized in the original analysis. This confirms the importance of reproducible research in proteomics, where it is unfortunately still not common to provide analysis scripts and software openly. In addition to mass spectrometry analysis, there are many bioinformatics applications in which binary data are collected, and hence, in which the present methodology and software will potentially be useful. Examples include meta-genomics, where the absence and presence of proteins and genes is compared with a pan-genome (), community analysis by DNA fingerprinting (), and chemometrics (). Exploring additional applications may also lead to further methodological extensions of the procedures currently implemented in binda, such as modeling overdispersion, e.g. by employing the BetaBernoulli rather than Bernoulli distribution, and to take account of interactions among predictors, e.g. by modeling pair-wise correlation.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
S.Gibb and K.Strimmer at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
