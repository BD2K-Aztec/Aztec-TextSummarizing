Motivation: Traditional models of systems biology describe dynamic biological phenomena as solutions to ordinary differential equations, which, when parameters in them are set to correct values, faithfully mimic observations. Often parameter values are tweaked by hand until desired results are achieved, or computed from biochemical experiments carried out in vitro. Of interest in this article, is the use of probabilistic modelling tools with which parameters and unobserved variables, modelled as hidden states, can be estimated from limited noisy observations of parts of a dynamical system. Results: Here we focus on sequential filtering methods and take a detailed look at the capabilities of three members of this family: (i) extended Kalman filter (EKF), (ii) unscented Kalman filter (UKF) and (iii) the particle filter, in estimating parameters and unobserved states of cellular response to sudden temperature elevation of the bacterium Escherichia coli. While previous literature has studied this system with the EKF, we show that parameter estimation is only possible with this method when the initial guesses are sufficiently close to the true values. The same turns out to be true for the UKF. In this thorough empirical exploration, we show that the non-parametric method of particle filtering is able to reliably estimate parameters and states, converging from initial distributions relatively far away from the underlying true values. Availability and implementation: Software implementation of the three filters on this problem can be freely downloaded from
INTRODUCTIONIn systems biology, sets of ordinary differential equations (ODEs) are often used to characterize biochemical reactions. The differential equations capture our knowledge of the underlying interactions in a quantitative way and solutions to such systems of equations help explain behaviour at an overall systems level. Much of the work in the area deals with deterministic differential equations, often non-linear (e.g. Hill kinetics). Unknown parameter values in their specification, such as reaction rates, are obtained from biochemical * To whom correspondence should be addressed. experiments conducted in vitro, or are set to specific values by elaborate hand-tuning, so that a set of observations from the system under study are best explained. Sometimes, such parameters may not have direct biological interpretations and are used as approximations (). The yeast cell cycle model of () is a good example of this. The parameter estimation problem has often been posed as a search and optimization problem in the literature. For example, () have explored a range of optimization methods including steepest descent gradient search techniques and methods suitable for global optimization, such as simulated annealing and genetic programming, in the parameter estimation of metabolic systems. An alternate method using spline approximation of the solution, using linear and non-linear programming is described in a recent paper (). These authors consider an enzyme kinetic system and a subset of a cell cycle model.show how parameters of a developmental gap gene circuit model may be estimated by extensive search methods. Such approaches to model-based explanation of biological phenomena, often do not take into account system and measurement noise in the modelling process. They also do not explicitly seek to infer parameter values or unobserved states from noisy measurements. Techniques using Bayesian inference are alternatives to optimization-based approaches, but having the added motivation of being able to capture uncertainties in parameter and state estimates. Examples of work along these lines include () who consider stochastic systems.and Vyshemirsky andaddress ODE-based systems for which parameter estimation is performed by Markov Chain Monte Carlo (MCMC) methods in a probabilistic inference framework. Some authors have recently studied the role of sequential estimation methods for state and parameter estimation from systems biology models, formulated as state-space models. Lillacci and Khammash (2010),fall into this category. The first three of these use parametric methods based on Kalman filtering, whereas the latter two use the non-parametric approach of particle filtering. The power of the tools we explore in this article have been demonstrated in other areas of application over many decades. These include the adaptive estimation of neural networks (), target tracking from bearing-only measurements (), modelling futures contracts in computational finance () and to find global minima of artificial neural networks (). In the context of biology,(2007) and Wilkinson (2009) are examples of using probabilistic dynamical systems models to characterize biological systems and to make parameter estimation and inferences from them. While most literature on the subject focuses on batch-based models, in which parameter estimation and inference are performed on all the available data, our attention is on sequential, or online, methods. The Kalman filter and its variants, and the particle filter (PF) belong to this family. The formulation of jointly estimating state and parameters by an extended state representation we pursue is due to, who applied unscented Kalman filter (UKF) to analyze two dynamical systems: the LotkaVolterra system () and the Lorenz system (). Unknown parameters are treated as states with their time variation set to zero. To motivate non-parametric particle filtering, with the argument that computation is sufficiently cheap to be able to do this,used an exceedingly large number of Monte Carlo samples to completely cover all the possible states and parameters space for a complex system such as the mammals circadian genetic control model () which has 45 unknown parameters. While this is an ambitious attempt, motivated under the term peta-computing, we do not believe the authors make a persuasive case for flooding the space with particles. Instead, as we find in this work, a modest number of particles, of the order of a few thousands, offer very attractive performance in parameter estimation. Additionally,applied extended Kalman filter (EKF) to simultaneously estimate the states and parameters of two real datasets [i.e. JAK/STAT signal transduction pathway () and Ras/Raf/MEK/ERK regulatory pathway (. The remainder of this article is organized as follows. In Section 2, we give the generic formulation of systems biology models cast in state-space form, in Section 3, we describe the three algorithms, in Section 4, we define the heat shock response model we use as our test problem, and in Section 5 we present our results and discuss them. Typical results needed to support our conclusions are presented in the main body of this article, and more detailed results, covering the estimation of various parameter combinations being estimated, are given as online Supplementary Material accompanying this article in the journal's website.
NON-LINEAR STATE-SPACE MODELS WITH ODESNon-linear state-space models of interest here consist of two sets of equations: a set of state equations describing the dynamics of the biological system under study, and a set of output equations that define how observations arise from the state at any time. In the class of systems we consider here, the dynamical system is deterministic, in that there is no process noise, and the observations are assumed to be corrupted by additive noise. Suppose a biological system consists of n state variables, denoted x = (x 1 ... x n ). In every time step, the states of the system are represented by vector x(t), which might consist of concentrations of chemical species of interest, e.g. mRNA, proteins or metabolites. Outputs, related to the state vector x through the function h(), denoted as y, quantify the observations. Dynamics of the system, characterized by ODEs, are in general written as follow:where the vector  =[ 1 .
..  k ]T represents the unknown parameters that are going to be estimated. The extended state representation treats the unknown parameters as constants and imposes zero dynamics on them. With this state extension, (), the system becomes:Here, we have a continuous-time underlying dynamical process which is observed at discrete times. Followingand other authors, the way to solve this problem is to numerically integrate the state dynamics between temporal points at which observations are made, using parameter values estimated in the previous point in time:By doing so, we are essentially discretizing the continuous-time process. Finally, it is possible to describe the partial observations of the system through the following equation:where  t represents the white Gaussian noise with covariance matrix R. h() is the output function of the system. While the constant unknown parameters ought to have zero dynamics, it often helps to impose a random walk model on them, in order to enable a tracking behaviour which helps convergence from some arbitrary initial guess to their true values. Several authors including () have suggested this. There is extensive discussion in the literature on the ratio between the assumed noise variance of the random walk and the noise variance of the measurements being the determinant of convergence in the Kalman filter setting [e.g..However, this random walk may sometimes result in divergence and posteriors will far away from the true values. To deal with this, the method proposed in Liu and West (2001) is adopted. The posteriors are guaranteed to converge, if the variance of the random walk model decay with time. Liu and West (2001) intended using kernel smoothing with shrinkage for parameter evolution as follows: is a discount factor that lies in,   t1 is mean of the particles in time instance t 1 and   t  N (0,m 2 V t1 ) is the additive noise to parameter evolution. m 2 = 1a 2 , V t1 is the variance matrix of the parameters at time t 1. This is a crucial aspect of implementing such sequential methods.
SEQUENTIAL ESTIMATION METHODSIn the Bayesian framework, we seek the joint posterior distribution of parameters and states, given the measurements, denoted as p( ,x t |y t ). the algorithms of interest here recursively estimate this posterior as data arrives one at a time. We first present the three algorithms of the EKF, UKF and PF.
Extended Kalman filterThe well-known Kalman filter () is an optimal state estimator in the case of linear, Gaussian systems. When either of these conditions is violated, the resulting probability density over the unknown states is no longer Gaussian. The EKF approximates the non-linearities by Taylor series expansion about the current operating point and truncates. When the truncation is to first-and second-order terms, closed form update equations are obtainable (). Truncating to the first-order (gradient) term is the most widely used form of EKF, which we pursue here. In order to recursively estimate, we assume the initial condition x + 0 and its error covariance matrix P + 0 are known. The current prior state distribution termed x  t , obtained by integrating the continuoustime state process in the time intervalwith the previous posterior estimate treated as initial condition. The current prior error covariance distribution termed P  t , obtained by integrating a differential Lyapunov equation and initial condition is the posterior error covariance of previous state (). We now define an extended state vector consisting of the states and unknown parameters, following Lillacci and Khammash (2010).where Q is the covariance matrix of noise in process model and A t is Jacobian matrix of state process f , define as:The Kalman gain iswhere R is the covariance matrix of noise in measurement and H t is Jacobian matrix of the measurement model h. The posterior state and covariances are updated as:The EKF algorithm is summarized as Algorithm 1:
Unscented Kalman filterThe UKF carries out a different approximation, in that it consists of a recipe to deterministically define a minimum number of state samples in the prior distribution and propagate them through the dynamical system. These propagated points, referred to as sigma points, are used to re-compute a prior distribution and its covariance () at the next time step. Thus, the UKF also propagates a Gaussian, but the approximation is formulated in a different way and is in fact equivalent to truncating the Taylor expansion of state non-linearity to the second-order term (). For more details on UKF implementations, including pseudocode, see).
Particle filterSequential Monte Carlo methods, more widely known as PFs, offer a more powerful approach to parameter estimation and inference in dynamical systems (). The family of Monte Carlo algorithms draw samples according to the probability density from which inference is to be made and approximate difficult integrals by sample averages. The core algorithmic step in particle filtering is importance sampling, that of generating identically and independently distributed samples from a proposal density of convenience, with associated weighting of these samples to account for the fact that they were not drawn from the density of interest. In the sequential setting, PF offers recursive ways of updating these weights in addition to propagating them through the dynamical system. A crucial issue in their implementation is the problem of sample degeneracy, that of all samples collapsing into just one position in the state space, and several tricks to circumvent these exist in the literature. A concise summary of these algorithms can be found in the tutorial paper by. A pseudocode description of the PF algorithm is given in Algorithm 2.
THE HEAT SHOCK MODELWe consider cellular response to heat shock as a model system to illustrate the relative performance of the three sequential algorithms. Eldescribe a heat shock response model in the bacterium Escherichia coli, with three differential equations. The model consists of genes encoding molecular chaperones, transcribed in response to a sudden change of environmental temperature, transcription factor  32 , which, via binding to RNA polymerase
X.Liu and M.NiranjanAlgorithm 2 Particle filter
Initialization, t = 0 for i = 1,...,N sample s i 0  p(s 0 ) and set t = 1 end for 2. Importance sampling for i = 1,...,N samplessample samples i t  p(s t |s i t1 ) and setsset sets i 0:t = (s i 0:t , s i t ) end for for i = 1,...,N evaluate the importance weightswweights weightsw i t = p(y t |s|s i t ) end for Normalize the importance weights 3. Selection step Resample with replacement N particles (s i 0:t ;i = 1,...,N) from the set ( s i 0:t ;i = 1,...,N) according to the importance weights Set t  t +1 and go to step 2. enables the transcriptional regulation of heat shock proteins.  32 , which is rarely present under normal temperatures in the range (30 @BULLET C37 @BULLET C), rapidly accumulates at elevated temperatures activating the transcription of heat shock genes, leading to a different equilibrium. The variation in total numbers of the relevant proteins are lumped in the model as two terms whose dynamics is described, along with the numbers of unfolded proteins as follows:Hereare constants assuming different values at different steady state temperatures. We simulated data from the heat shock model, making use of MATLAB's ODE45 function to integrate the differential equations, generating data over a time length of 200 s, sampled at regular intervals of 0.2 s, giving 1000 sample points for representing the observations. The true values of parameters used are given in Supplementary Table S1. We then applied the three filters to infer the unknown parameter and state. Subsets of the six parameters of the model are to be estimated from noisy subsets of the three states. In the evaluations we considered various combinations of knowns and unknowns (observed and estimated), as described in the following sections. The simplest scenario we considered is one in which two of the three states (D t and U f ) and five of the six parameters were assumed known. This corresponds to a case in of a well understood biological, some aspects of which are experimentally observable, subject to additive measurement noise, whereas others are inaccessible.Implementation details for this scenario, leading to the results inare as follows: of the EKF is set to start from the prior state vector s =, the last element is the initialization for parameter estimate. The diagonal elements in covariance matrix for measurement noise R are 0.01 times variance of synthetic state data x. The diagonal elements of initial error covariance matrix P 0 are 25, 25, 25 and 110 2 , respectively. The process noise covariance matrix was set to a small diagonal matrix, 510 6. The UKF is also initialized to start from the prior state vector s =, the last element being the initial guess of the unknown. The diagonal elements in covariance matrix for measurement noise R are 0.25 times variance of synthetic state date x. The first three diagonal elements (means the error covariance for states) of initial error covariance matrix P 0 are the same, leaving as 0.25 times variance of synthetic state data x. The last diagonal element in P 0 is 0.35, meaning this is for the parameter estimate. For the PF, the initial particles for states and parameter are generated from s 0  N (0,1). The diagonal elements in covariance matrix for measurement noise R were set as 0.001 times the variance of the synthesized time series. With additive Gaussian noise, the importance weight are updated aswas aswwhere, for example, H, the observation matrix, whose diagonal elements will take the form, if the state S t is unobserved. The discount factorwas set to  = 0.98 and we ran PFs with 50 and 1000 samples. Further, we also investigated a range of operating regimes with data lengths of 80s to 180s in steps of 20s, sampling intervals of 0.1s, 0.25s, 0.5s and 1s, and noise variance multipliers of 0.0001, 0.001, 0.01, 0.05, 0.1 and 1.
RESULTS AND DISCUSSIONWe carried out a thorough exploration of the capabilities of the three estimation methods on the heat shock system, at various levels of problem complexity, i.e. the numbers of parameters and states assumed unknown. Typical results obtained are described in the following sections, and results of all the combinations we tested are given as Supplementary Material accompanying this article.shows convergence of the three models on estimating a single parameter (K s ) from two noisy state observations. In these, we have included a simulation of PF with only 50 samples failing to correctly estimate the parameter. With 1000 samples, PF achieves convergence to the correct estimate. The EKF and UKF also converge to the correct underlying value, as seen in, but note that the starting points of these are set to be very close to the true value. When the initial conditions are set to be far away from the true value, however, the EKF and UKF fail to converge whereas the PF is able to find the correct solution. This is shown inwhere the initial conditions of the EKF and UKF are set to be the closest to the truth among all the particles used as initial samples of the PF. Hence even in the case of a comparison highly favourable to the EKF and UKF, they fail to recover the correct value of the unknown. We have observed similar behaviour for each of the unknown parameters of the heat shock model. Depending on the form of the interactions, some parameters are easier to identify than the others. Should the conditional posterior probabilities over them be unimodal, and close to Gaussian, parametric models (Kalman filters) have a good chance of finding the correct solutions. When the terms appear in complex non-linear settings, posterior probabilities are often multi-modal and nonparametric PFs are necessary. In Supplementary Table S2, we show in which of the cases of estimating a single unknown parameter from one and two noisy observations the PF clearly outperforms the other two. We explore all the possible combinations and find in 20 of the 42 cases, PF has an advantage over EKF and UKF, whereas in the remaining 22 it performs no worse than them. The difficulty of parameter estimation depends on the complexity of the formulation for the hidden state assumed to be unobserved. We also consider the case in which all the parameters are known, and a single state was to be inferred from the other two. Results of this are shown in Supplementary, and show broadly similar results in the rates of convergence. Other variations of estimating one of the six parameters from one and two observed states are shown in Supplementary Figures S3S8, and the summary in Supplementary Table S2 is obtained by studying these graphs. In all these simulations, similar to the results in, we set the initial guess of the unknown parameter at a value not too close to the true value, and gave the Kalman algorithms an unfair advantageby initializing all particles of the PF further away from the initial values to which EKF and UKF were set.
Estimating a single unknown
Estimating multiple parametersWe next examined the performances in multiple unknown parameter spaces, progressively making the problem harder. Results of convergence in estimating two parameters simultaneously, with all possible combinations of which parameters were left unknown, are shown in Supplementary Figures S9S17. We note the general trend of PF outperforming the other two. Naturally, for the initial conditions chosen, there are cases when all three methods fail to estimate the parameters correctly. This is to be expected because the problem has now been made significantly harder than the case of estimating a single parameter. In exploring different operating regimes, we found the influence due to data lengths to be negligible (Supplementary Figs S19S21). For the EKF and PF, faster sampling was found to be sometimes advantageous (Supplementary Figs S22S24).E shows the space of initial conditions from which convergence to the true solution of the three algorithms were compared. We find that the PF is more resilient than either EKF or UKF in converging to the true solution. Also see Supplementary, which shows the convergence regimes for two other sampling intervals. For completeness, we also considered the extreme case of all parameters being unknown. Supplementaryshows convergence of the three filters in the case of estimating all six parameters from two noisy observations (D t and U f ). Here, we find that the EKF correctly estimates the parameter  0 and UKF is able to successfully converge to  0 and K s , whereas the PF is able to correctly estimate five of the six unknowns. The PF fails only in the case of the parameter K d , which is probably because K d highly influences the temporal evolution of the system via the state S t , which was assumed unknown in this particular simulation.
The sequential approachThe Kalman and PF algorithms considered in this work are sequential algorithms. Their use should be considered in the context of Bayesian inference methods that operate on batch data [e.g.;, as in an example like the heat shock model, all the data are available. In such cases, sequential models, being one-pass algorithms offer a computational advantage. This is illustrated in, where we compare a MetropolisHastings sampler with PF. At similar levels of performance, we observed clear computational advantages with the sequential approach. The error bars inare obtained over 20 different runs of the algorithms. An alternate way of parameter estimation of such models, also considered by El, is via an optimization approach. We compared such an approach with the Bayesian sequential approach, implementing the optimization via MATLAB's fminsearch program. This can be viewed as a maximum likelihood estimation, under assumptions of Gaussian noise. We found that with Gaussian noise, the optimization approach often outperformed the sequential Bayesian methods. However, with nonGaussian noise, the PF gave substantial advantage. We illustrate this in, where in a two parameter estimation task, theoptimization approach repeatedly failed to find the correct solution, whereas the PF was successful in over half of the trials.
X.Liu and M.Niranjan
CONCLUSIONThis work demonstrates the effectiveness of the method of particle filtering in state and parameter estimation of deterministic systems biological models from noisy observations. We have shown this via a comparative study between extended Kalman, unscented Kalman and particle filtering applied to the heat shock response system using single and multiple parameter estimations. While previous authors have argued that the Kalman filter itself is capable of such estimations, our critical appraisal shows that this is only possible when the initial guess of the state and/or state parameters are very close to the true values. Convergence is not achieved when the initial conditions differ significantly from the corresponding true values. The PF, on the other hand, is able to converge to true values even when all the particles are initially set to values far away from the underlying true values, providing a powerful, yet simple to implement, way of tackling difficult inference problems in systems biology. We further showed in this work that when the complexity of the problem is gradually increased (i.e. the number unknown parameters/states to be inferred), the Kalman filter algorithms failed well before the PF did. Even in the extreme case of all parameters being unknown, the PF manages to find correct estimates of five of the six. This suggests that the non-parametric approach of the PF, by virtue of being able to systematically propagate uncertainties while exploring the space over a wide range, is a powerful methodology to tackle such difficult problems. Our current work concentrates on stretching such analyses to more difficult higher dimensional problems such as cell-cycle regulation, circadian rhythm and sino-atrial pace making in heart tissues.
Conflictof Interest: none declared.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from X.Liu and M.Niranjan
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from Parameter estimation in computational biology
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
