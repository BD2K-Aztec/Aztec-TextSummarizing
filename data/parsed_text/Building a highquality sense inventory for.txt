Motivation: The ultimate goal of abbreviation management is to disambiguate every occurrence of an abbreviation into its expanded form (concept or sense). To collect expanded forms for abbreviations, previous studies have recognized abbreviations and their expanded forms in parenthetical expressions of bio-medical texts. However, expanded forms extracted by abbreviation recognition are mixtures of concepts/senses and their term variations. Consequently, a list of expanded forms should be structured into a sense inventory, which provides possible concepts or senses for abbreviation disambiguation. Results: A sense inventory is a key to robust management of abbreviations. Therefore, we present a supervised approach for clustering expanded forms. The experimental result reports 0.915 F1 score in clustering expanded forms. We then investigate the possibility of conflicts of protein and gene names with abbreviations. Finally, an experiment of abbreviation disambiguation on the sense inventory yielded 0.984 accuracy and 0.986 F1 score using the dataset obtained from MEDLINE abstracts. Availability: The sense inventory and disambiguator of abbreviations are accessible at
INTRODUCTIONAbbreviations substitute for fully expanded terms (e.g. computed tomography) through the use of shortened term-forms (e.g. CT). In the bio-medical literature, abbreviations are used for various important terms including: genes, proteins, diseases and chemical names (). Results of our experiment (Section 3.2) show that 32.0% of UniProt entries include abbreviations in description and gene name fields.reported that abbreviations are used more frequently than expanded forms. Abbreviations present two major challenges to bio-medical text mining: term variation and ambiguity. We consider an information retrieval system that collects documents referring to polymerase chain reaction. Because polymerase chain reaction might be abbreviated as PCR, the system is expected to retrieve documents in * To whom correspondence should be addressed.
PCR
...... ... ........ pathologic complete
...... ... ........ phosphocreatine creatine phosphate principal component regression principal components regression
..... .....(Clustering Disambiguation Recognitionwhich PCR appears. At the same time, abbreviations are ambiguous: the same abbreviation might refer to different concepts (). Because PCR means other than polymerase chain reaction, the system should be able to perform abbreviation disambiguationto judge whether an occurrence of PCR actually means polymerase chain reaction or not (). In general, abbreviations are much more ambiguous than ordinary terms.report that 81.2% of abbreviations in Unified Medical Language System (UMLS) were ambiguous, with an average of 16.6 senses.presents problems of term variation and ambiguity of abbreviations. In all, 129 distinct expanded forms were extracted for the abbreviation PCR from all MEDLINE abstracts, including polymerase chain reaction, polymerization chain reaction and amplification reactions polymerized. Abbreviation recognition is a task of collecting expanded forms for abbreviations. It has been explored extensively using various approaches: through the use of heuristics and/or scoring rules (), machine learning () and co-occurrence statistics (). The 129 expanded forms inwere obtained using the abbreviation recognition method (),Page: 1247 12461253
Building a high-quality sense inventory for improved abbreviation disambiguationwhich is based on co-occurrence statistics. As depicted in, expanded forms extracted by abbreviation recognition are mixtures of concepts/senses and their term variations. The abbreviation PCR has 129 expanded forms that can be consolidated to 30 senses (e.g. polymerase chain reaction, pathologic complete response and phosphocreatine). In general, a single sense has more than one surface form (i.e. variant). The sense of pathologic complete response, for example, was actually described in MEDLINE abstracts by one of the 14 variation forms (e.g. pathologic complete response and pathologically complete responses). Clustering of expanded forms into a set of distinct senses, thereby creating a sense inventory for a given abbreviation, is a crucial step towards abbreviation disambiguation. Abbreviation disambiguation has been studied less intensively than abbreviation recognition, partly because clustering for creating sense inventories for numerous pairs of abbreviations and their surface expanded forms. As described in this article, we first formalize the task of creating sense inventories as an independent task of clustering in which similar expanded forms for an abbreviation are gathered into a cluster (sense). Because the quality of sense inventories has a significant effect on the performance of abbreviation disambiguation, we developed a new supervised method for clustering expanded forms. We constructed a dataset for the method and measured its performance. The effect of clustering on abbreviation disambiguation was also evaluated quantitatively. The main contributions of this article are 3-fold.(i) A sense inventory is key to robust management of abbreviations because it provides target senses for disambiguation that correspond to biomedical entities and concepts. Therefore, we present a supervised approach for clustering expanded forms, and evaluate the quality of the sense inventory. The experimental result reports a 0.915 F1 score in clustering expanded forms.(ii) We investigate the possibility of conflict of protein and gene names with abbreviations to estimate the importance of abbreviation disambiguation. Results showed that 32.0% of UniProt records include abbreviation terms and that 16.7% of records have ambiguous abbreviations with multiple definitions.(iii) We conduct an experiment of abbreviation disambiguation on the sense inventory whose quality was demonstrated by the Contribution (i). The proposed system achieves 0.984 accuracy on a dataset obtained from all of MEDLINE.
METHODSIn terms of abbreviation disambiguation, it is important to draw a clear distinction between local and global abbreviations (). By convention, a local abbreviation accompanies its expanded form at its first appearance in the document. Because abbreviation definitions are mostly consistent within a document, i.e. one-sense-per-discourse assumption (), we can identify the definitions of local abbreviation by reusing methods for abbreviation recognition (). In contrast, global abbreviations appear in documents without the expanded form explicitly stated. It is necessary to estimate the definitions of undefined global abbreviations based on their contexts in documents. This task is similar to word sense disambiguation (WSD) in natural language processing, where a sense of an ambiguous term is chosen from several predefined senses. The remainder of this article will specifically describe disambiguation of global abbreviations in the MEDLINE database.
with abbreviations disambiguatedSense inventoryshows the work flow of abbreviation management. The system first extracts abbreviation definitions from MEDLINE abstracts. Because expanded forms include variations (e.g. polymerase chain reaction and polymerization chain reaction for PCR), we apply a clustering method to compile a sense inventory. Using a collection of sentences including abbreviation definitions, we train a classifier for each abbreviation that predicts the sense for an occurrence of the abbreviation. Finally, the system predicts senses of global abbreviations in MEDLINE abstracts.
Abbreviation definitions
Collecting abbreviation definitions from MEDLINEThe first step for abbreviation disambiguation is to collect possible expanded forms for abbreviations. We used a state-of-the-art method for recognizing abbreviation definitions in MEDLINE abstracts (). The algorithm assumes parenthetical expressions to introduce abbreviation definitions in the following format: expanded form '(' abbreviation ')'For each inner expression of a parenthetical expression, the algorithm enumerates candidates of expanded forms that begin with any non-function word (e.g., a, and, of ) and end with any word immediately before the parenthetical expression. To choose correct expanded forms for each abbreviation a, the algorithm computes a score LH a (c) for a candidate of expanded form c,In Equation (2), the following variables are used: a is an abbreviation; c is a candidate of expanded form for the abbreviation a; freq(a,c) denotes the co-occurrence frequency of the candidate c with the abbreviation a; and T c is a set of nested candidates, each of which consists of a preceding word followed by the candidate c. We compile a list of candidates of expanded forms sorted in the descending order of their scores for each abbreviation. The algorithm extracts candidates out of the sorted list one by one. An expanded form is considered valid if all of the following are true: it has a score >2.0; the words in the expanded form can be rearranged so that all alphanumeric letters in the abbreviation appear in the same order; and it is not nested or an expansion of the previously chosen expanded forms.
Merging term variations in abbreviation definitionsThe list of abbreviation definitions elucidates the phenomena of term variation and ambiguity. For instance, the abbreviationThe key to success in clustering lies in the accuracy of the distance (similarity) measure between expanded forms. Various similarity measures including cosine similarity, Levenshtein distance (), Jaro Winkler similarity () and SoftTFIDF () have been applied to the term clustering. Nevertheless, we are unsure of the best choice, combination and threshold of these measures for use in recognizing term variations. Therefore, we use a machine learning technique to acquire a similarity metric by combining various features. More specifically, we build a binary classifier that, when given two terms s and t, decides whether the terms s and t present a term variation (r = +1) or not (r = 1). Although the support vector machine (SVM) is a popular method for binary classification, we model the conditional probability P(r|s,t) with the logistic regression, hoping that the probability P(r|s,t) reflects the distance between s and t. The probability distribution P(r|s,t) is given asdenotes a vector of feature functions: K is the number of feature functions; and w ={w 1 , ..., w K } presents a weight vector of the feature functions. We use the maximum a posteriori estimation to fit the feature weights w to the training set consisting of N instances,. We minimize the objective function with the L 2 norm of the weight vector w,Here, the first term presents the negative of the log-likelihood of the model for the training set, ||w|| 2 denotes the L 2 norm of the weight vector w and  is a parameter to control the effect of L 2 regularization. Equation(4) is minimized using the Limited-memory BroydenFletcherGoldfarbShanno method ().of constituent letters in s and t with n-gram cosine similarity, normalized Levenshtein distance and JaroWinkler similarity. Features #4#5 compute the similarity of constituent words 2 in s and t with n-gram cosine similarity and SoftTFIDF. Feature #6 corresponds to the bias term, which adjusts the decision boundary of classification. The column 'Weight' inpresents the optimal feature weights tuned for the training data (Section 3.1). Finally, we apply a hierarchical clustering algorithm () to the similarity metric. We define the distance measure d(s,t) = 1P(+1|s,t) even though the conditional probability P(+1|s,t) does not hold the properties of distance measures. In Section 3.1, we compare single-link, complete-link, centroid and group-average clustering algorithms.
Abbreviation disambiguation as a problem of WSDWe formalize abbreviation disambiguation as the following: given an occurrence of an abbreviation x and a set of possible senses Y x = {y 1 ,y 2 ,...,y n } corresponding to x, choose the most suitable sense y *  Y x for the abbreviation occurrence. This is a classification problem which assigns a label y *  Y x that is suitable for input x. Among various supervised machine learning techniques such as nave Bayes and SVM, this study employs maximum entropy modeling () for its efficiency in multi-class classification.
Building a high-quality sense inventory for improved abbreviation disambiguationy with observation events (uni-or bi-gram) occurring in a region (window). For example, given the sentence, Periplakin, a member of the plakin family of proteins, has been recently characterized by complementary deoxyribonucleic acid (cDNA) cloning, and the corresponding gene, .
..and the training instance of the abbreviation x in the sentence, (x,y) = ('cDNA','complementary deoxyribonucleic acid') then the region for local features is {'recently', 'characterized', 'by', 'cloning', 'and', 'the'}.Six uni-gram and five bi-gram features are extracted from the region. Features for local and sentence contexts estimate an expanded form based on word occurrences around the target abbreviation, and on features for the abstract context considering the global topics in the abstract 3 .
RESULTS AND DISCUSSIONWe applied the proposed methods to MEDLINE abstracts (9 635 599 abstracts as of March 2009). Abbreviation recognition (Section 2.1) recognized 467 402 distinct definitions for 68 007 abbreviations. We applied single-link clustering to the 467 402 expanded forms with the distance threshold 0.2, and obtained a sense inventory with 146 651 senses for 68 007 abbreviations 4. In other words, the clustering method identified 3.19 term variations per sense. An abbreviation has 2.16 senses on average.
Clustering of expanded formsTo train the similarity measure described in Section 2.2, we grouped 4158 expanded forms for 400 abbreviations that were sampled randomly from the abbreviation definitions. We asked a human expert to merge expanded forms if they refer to an almost identical concept. In this way, we obtained a dataset consisting of 2563 clusters (senses) of 4158 expanded forms for the 400 abbreviations.portrays an excerpt of the clusters for the abbreviation TTX and GRP: the abbreviation TTX has five expanded forms recognized; the expanded forms are grouped into three clusters. Assuming inner cluster pairs of expanded forms for each abbreviation to be positive (r = +1) and assuming inter-cluster pairs to be negative (r = 1), we obtained 3678 positive and 19 296 negative instances of the training data for the similarity measure 5. For example, two positive instances, tetanus toxin,tetanus toxoid and tetradotoxin,tetrodotoxin, and eight negative instances (other pairs of expanded forms) are generated for TTX in.reports the accuracy (A), precision (P), recall (R), and F1 (F1) scores of the similarity metric measured using the 10-fold cross validation on the training data. The row 'shows the performance when all features described in Section 2.2 were used; the best performance (0.892 F1 score) was obtained with all features. The first half of feature sets use only the specific feature(s) for training the similarity metric. Some examples are that 'Sim (ch)' shows the performance when only the character n-gram similarity was used. The last half of feature sets (with prefixes '-') remove the specific 3 In general, features for broader (e.g. abstract) contexts include words in narrower (e.g. neighbor and local) contexts, but drop the information of occurrence positions as 'bag of words.' 4 Refer to Section 3.1 for the clustering algorithm and threshold. 5 An expanded form s is required to be less than t in dictionary order. ! TTX tetrodotoxin; tetradotoxin tetanus toxoid; tetanus toxin thyrotoxicosis ! GRP glycine-rich protein; glycine-rich cell wall protein glucose-related protein; glucose-regulated protein grapes glial-restricted precursor gastrin-releasing peptide; gastrin-releasing polypeptide; gastrin-releasing peptide1-27; gastrin-related peptide glutamine/glutamic acid-rich proteins groupfeature(s) from the full feature set, e.g. '-Sim (ch+wd)' shows the performance when features for character and word n-gram similarity were removed. We can infer that the feature greatly contributes to the similarity metric if the performance decreases in the absence of a feature.shows that character n-gram similarity was among the most effective features for predicting term variations. In addition, the performance reductions (F1) inbut the former expanded form includes the abbreviation EGF, which should be expanded to epithelial growth factor. We were able to remedy these false instances by substituting abbreviations recursively into expanded forms. Still, we found some tricky instances, e.g.
1-deamino-8-D-AVP and 1-deamino-[D-Arg8]vasopressin as expanded forms of the abbreviation DDAVP; it is not straightforward to expand the substring 8-D-AVP intovasopressin. The similarity metric could not recognize 29 instances of synonymous expanded forms, e.g. baccalaureate nursing and bachelor's degree in nursing for the abbreviation BSN. It might also be effective to incorporate a feature of a synonym dictionary.presents a performance comparison of clustering algorithms with different distance thresholds on the same dataset. In this evaluation, we measured pairwise precision and recall. For every pair of expanded forms, a true positive is defined as a pair of expanded forms that are correctly located in the same clusters. False positives, true negatives and false negatives are defined analogously. We drew a precisionrecall curve by plotting the performance of each clustering algorithm when its distance threshold values range from 0.1 (high precision and low recall; bottom right) to 0.9 (low precision and high recall; top left). In, the single-link algorithm obtained the peak F1 score (0.915) with distance threshold 0.2 (the second point from the right on the red locus). This parameter is equivalent of merging two expanded forms s and t only if the probability of term variation P(+1|s,t) is >0.8. We can interpret that the best parameter tightens the decision boundary from the neutral threshold of 0.50.2 for alleviating the chaining effect of the algorithm 6. It is particularly interesting that other clustering algorithms were unable to outperform the single-link algorithm; in particular, these algorithms suffer from low recall. In these algorithms, two similar expanded forms cannot be merged solely according to their distance. For example, the complete-link algorithm refuses an expanded form that is similar to most of the expanded forms in a cluster but dissimilar to an expanded form in the cluster. Other clustering algorithms might be reluctant to form a cluster, but the single-linkalgorithm trusts the trained similarity measure and performs the best in this task.
Entity names conflicting with abbreviationsSome researchers have argued that gene symbols are often identical to ambiguous abbreviations (). For example, SCT represents the official gene symbol for the human gene secretin, but it also stands for stem cell transplantation, salmon calcitonin, sacrococcygeal teratoma, etc. (). How many protein and gene names actually conflict with abbreviations? To examine the importance of abbreviation disambiguation, we extracted entity names from databases and compared them with the sense inventory. We used entity names in the following resources: description (DE) and gene name (GE) fields in UniProtKB/SwissProt database (as of July 7, 2009); concept names with 'Gene or Genome' type in UMLS (2009AA release as of); and concept names with 'Amino Acid, Peptide, or Protein' type in UMLS. We assume a database record to have a possible conflict with an abbreviation if the record includes a name that also appears in the abbreviation list. A conflicting name is ambiguous when the sense inventory includes the name as an abbreviation with multiple senses.presents the number of database records including abbreviations with at least k senses in the sense inventory. The first row (k  0) represents the total number of records in each database. Results showed that 149 537 (32.0%) out of 466 739 UniProt records include names that also appear in the abbreviation list (k  1). Of UniProt records 77 833 (16.7%) have ambiguous abbreviations with multiple senses (k  2); similarly, 13.2% gene names and 6.4% acid/peptide/protein names in UMLS have possible conflicts with ambiguous abbreviations (k  2). Moreover, 4 841 (1.0%) of UniProt records are highly ambiguous with at least 30 senses in the abbreviation dictionary. These facts suggest that it is insufficient to identify gene or protein names simply by matching textual expressions with database records.
Abbreviation disambiguationWe implemented a system that resolves the definitions of abbreviations using the sense inventory. To process all MEDLINE abstracts efficiently, the WSD training and classification algorithms were implemented in C++. Furthermore, we used a grid computing environment, dividing the whole MEDLINE into sets of abstracts. A set of jobs was scattered on 21 cluster nodes, each of which runs on four Intel Xeon 5140 (2.33 GHz) processors with 8 GB main memory. It took about 616 h to finish 10-fold cross validation jobs on the cluster environment.The sentences with abbreviation definitions were used as training data for abbreviation disambiguation. For each definition of an abbreviation in a sentence, we assumed the expanded form to be the correct sense for the abbreviation, and removed the expanded form from the sentence: WSD classifiers were trained to predict the 'masked' expanded forms of the abbreviations. We applied 10-fold cross validation to assess the system performance. The system performance is measured by accuracy, macro-averaged precision, recall and F1 measures. We compute the accuracy, precision, recall and F1 scores for each abbreviation and sense, and take averages of these scores over every abbreviation and its sense.shows the system performance. In this evaluation, we did not include expanded forms that are defined <40 times throughout all of MEDLINE for hastening the cross validation 7 ; the total number of instances, abbreviations and senses in the dataset were reduced to, respectively, 5 521 074, 11 262 and 17 613 by this cut-off operation. These instances amount to 84.3% of the total (6 547 124) training instances. The proposed method using all the features inachieved 0.984 accuracy and a 0.986 F1 score. These scores were much better than those (0.789 accuracy and 0.636 F1 score) of the baseline system ('Majority'), which chooses the expanded form defined most frequently with the abbreviation. We also measured the performance when omitting the step for merging similar expanded forms ('w/o clustering'). Disambiguation without clustering is much worse (0.830 F1 score). In any case, senses without clustering are of little use. The rows starting with '+' present the performances only when the corresponding feature(s) are employed in the classifier. Classifiers using the neighbor contexts ('+ Neighbor') yielded 0.929 accuracy and 0.934 F1 score. The most effective features were obtained from abstract-level contexts, achieving 0.982 accuracy and 0.986 F1 score; this closely approximates the performance using all the features. The rows starting with '-' report the performances when the corresponding feature(s) are removed from the full feature set. For example, classifiers trained without using the abstract and sentence contexts ('-Abstract-Sentence') achieved 0.953 accuracy and 0.962 F1 score. These results were interesting in that broader contexts (e.g. abstracts and sentences) are much more useful than local contexts (e.g. neighbor words) for disambiguating abbreviations. This is) that is common for WSD. In, we used the clustering method (Section 3.1) to obtain the sense inventory for abbreviation disambiguation. This experimental setting has been used by the previous work (), but this evaluation might be lenient in that we did not consider the influence of errors in the sense inventory. That is, if a clustering method builds a sense inventory with a smaller number of senses, the disambiguation task may become less complicated. This might lead to the situation where a disambiguator seemingly yields a good performance value only because the sense inventory is coarse, i.e. expanded forms having distinct meanings are merged. Although we have demonstrated the quality of the sense inventory in Section 3.1, we analyze the influence of errors in the sense inventory.reports the performance of disambiguating the 400 abbreviations for which the sense inventory was built manually in Section 3.1. The first and second rows show the disambiguation performance when we trained and evaluated disambiguation systems with the sense inventory built manually (gold-standard) and by the clustering method (automatic). The third row presents the performance when we trained a disambiguation system with the sense inventory built by the clustering method (automatic) and measured the correctness of disambiguation results on the sense clusters built manually (gold-standard). We can infer that the evaluation result ofis reasonable because the sense inventories using manual and automatic clustering show comparable performance values in. The fourth row ofshows the performance when we trained a disambiguation system without a sense inventory, i.e. to predict the original expanded forms. We employ a lenient evaluation criterion: if the disambiguation system predicts an expanded form that is different from the original but in the same cluster of the manually built sense inventory, we regard this as a correct prediction. Although this experimental setting is unrealistic, the comparison between the fourth and other rows confirms that the sense inventory has a positive effect to refine training data of abbreviation disambiguation.) used UMLS Metathesaurus as a sense inventory for abbreviation disambiguation.prepared a sense inventory for abbreviation disambiguation by annotating senses of abbreviations of eight kinds in clinical notes at the Mayo Clinic. Involving human efforts to prepare a sense inventory and training data for disambiguation, the methods in these studies cannot keep pace with the increasing number of abbreviations and publications.applied their AbbRE algorithm () to obtain an abbreviation dictionary. Page: 1252 12461253
Page: 1251 12461253
Building a high-quality sense inventory for improved abbreviation disambiguation
RELATED WORK
N.Okazaki et al.Their performance was 95% precision and 82% coverage for disambiguating 60 kinds of abbreviations in MEDLINE.extracted training data from MEDLINE abstracts using a method for abbreviation recognition (). They reported 99.0% accuracy for abbreviation disambiguation, but the experiment was limited to 21 kinds of abbreviations. The most similar work is. Instead of implementing their own abbreviation recognition, they used the Simple and Robust Abbreviation Dictionary (), which was built automatically from MEDLINE abstracts. They performed clustering of expanded forms using similarities of two different kinds. One is cosine similarity of letter tri-grams. The other is the Dice similarity of context words (surrounding words) of expanded forms. Although it is much simpler, the former was intended to capture the similarities of expanded forms in the same manner as our clustering method does. The latter is designed to capture similarities of context in which expanded forms appear. As we discuss later, this would engender a problem in performance evaluation of abbreviation disambiguation. The WSD classifiers for abbreviation disambiguation were modeled using SVMs with linear kernels. Features for the classifiers consist of multi-word expressions. They excluded abbreviation definitions occurring <40 times from their evaluation set. They reported 0.985 accuracy, 0.989 precision, 0.982 recall and 0.985 F1 score on 7806 polysemic abbreviations with an average of 1.57 senses. This performance is comparable to that of this study (). Two issues are raised in their work, which should be examined carefully. One is that their work lacks independent evaluation of clustering. They might assume that the performance of clustering can be measured indirectly by the performance of abbreviation disambiguation. The problem of this indirect evaluation is closely linked with the other issue in their work. That is, their clustering of expanded forms uses the similarity of context in which expanded forms appear. They claimed the context similarity can detect synonym-like word substitution. However, because the context similarity is also used for abbreviation disambiguation, this might hide errors in clustering. In other words, their experimental setting might conceal difficult instances of abbreviation disambiguation because the clustering method might merge different senses of an abbreviation that share the similar context. In contrast, the clustering of expanded forms described in this article is based solely on the similarity among expanded forms with more refined similarity measure than letter tri-grams. This study evaluates the performance of the clustering method independently of abbreviation disambiguation. For reference, we implemented their clustering method. Their similarity measure (with the threshold parameters described in their article) performed worse on the evaluation corpus in Section 3.1 (0.890 accuracy, 0.977 precision, 0.311 recall and 0.471 F1 score); the performance of the clustering method was 0.971 precision, 0.562 recall and 0.712 F1 score. After we tuned the threshold of the letter tri-gram similarity from 0.8 (the original parameter) to 0.45, their clustering method reached the peak performance of 0.881 F1 score, which is still lower than that of our clustering method (0.915 F1 score). Therefore, we argue that, although the performances of the two systems on abbreviation disambiguation are similar, their sense inventories include more errors than ours. We also argue that the errors of the sense inventory were hidden in their evaluation of abbreviation disambiguation.
CONCLUSIONIn this article, we described an approach for building a sense inventory of abbreviations. Results showed that single-link clustering with the ML-based similarity measure contributed to abbreviation disambiguation. The proposed method obtained 0.984 accuracy and 0.986 F1 score on the training and test sets obtained from MEDLINE. Although the performance figure of abbreviation disambiguation is roughly comparable to the previous work, we specially demonstrated the quality of the sense inventory on which abbreviations are disambiguated into concepts or senses. Results also show that broader contexts (e.g. abstracts and sentences) were more useful than local contexts (e.g. neighbor words) for abbreviation disambiguation. A future direction of this study is to apply the methodology of abbreviation management for MEDLINE abstracts to full-paper articles. Because the proposed method can handle variation and ambiguity problems of abbreviations, we plan to explore the impact of abbreviation disambiguation to other textmining tasks such as information retrieval, named entity recognition and co-reference resolution.
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Features #1 and #4 introduce a feature function for each n-gram, where n is 1, 2 or 3. Consequently, the number of orthographic features is nine.
We tokenize expressions with non-alphanumeric letters. 1248 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
In the single-link algorithm, two distant expanded forms are merged only if another expanded form exists, which is closer to both expanded forms than it is to the threshold. This behavior is called a chaining effect and is regarded as a disadvantage of the single-link algorithm.
This experimental setting is similar to that of Gaudan et al. (2005).
