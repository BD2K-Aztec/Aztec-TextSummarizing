Motivation: Recent progress in DNA sequencing technologies calls for fast and accurate algorithms that can evaluate sequence similarity for a huge amount of short reads. Searching similar pairs from a string pool is a fundamental process of de novo genome assembly, genome-wide alignment and other important analyses. Results: In this study, we designed and implemented an exact algorithm SlideSort that finds all similar pairs from a string pool in terms of edit distance. Using an efficient pattern growth algorithm, SlideSort discovers chains of common k-mers to narrow down the search. Compared to existing methods based on single k-mers, our method is more effective in reducing the number of edit distance calculations. In comparison to backtracking methods such as BWA, our method is much faster in finding remote matches, scaling easily to tens of millions of sequences. Our software has an additional function of single link clustering, which is useful in summarizing short reads for further processing. Availability: Executable binary files and C++ libraries are available at
INTRODUCTIONDue to the dramatic improvement of DNA sequencing, it is required to evaluate sequence similarities among a huge amount of fragment sequences such as short reads. We address the problem of enumerating all neighbor pairs in a large string pool in terms of edit distance, where the cost of insertion, deletion and substitution is one. Namely, given a set of n sequences of equal length , s 1 ,...,s n , the task is to find all pairs whose edit distance is at most d,It is conventionally called all pairs similarity search. All pairs search appears in important biological tasks. For example, it is required in finding seed matches in all pairs alignment necessary in sequence clustering (). Such alignments can then be used to detect and correct errors in short reads (). In the first step of de novo genome assembly (), short * To whom correspondence should be addressed. reads are decomposed to k-mers, and suffixprefix matches of length k 1 are detected. In most cases, exact matches are employed due to time constraint. Using approximate matches, the length of contigs can be extended, which leads to final assembly of better quality. This problem reduces to all pairs similarity search by collecting all k 1 prefixes and suffixes into a sequence pool. From the output, only prefixsuffix pairs are reported. Basically, most popular methods solve the search problem by either of the following two approaches or a combination of them.(i) Finding a common k-mer and verify the match (). (ii) Backtracking in an index structure (i.e. suffix array and FM-index) (). The first type finds common k-mers in strings (i.e. seed match) and verify if two strings sharing the k-mer are neighbors indeed by extending the match with dynamic programming. It works perfectly well when the string is long enough. However, when strings are short and the threshold d is large, the length of shared k-mers falls so short that too many candidate pairs have to be verified. The second type stores the strings into an index structure, most commonly a suffix array. Then, similar strings are found by traversing nodes of the corresponding suffix tree. This approach works fine if d is small, e.g. d  2, and employed in state-of-the-art short read mapping tools such as BWA (), bowtie () and SOAP2 (). However, it becomes rapidly infeasible as d grows larger, mainly because the complexity is exponential to d and no effective pruning is known. ELAND and SeqMap () decompose sequences into blocks and use multiple indices to store all k-concatenations of blocks. Obviously, it requires much more memory compared with BWA, which would be problematic in many scenarios. Multisorting () uses multiple substring matches to narrow down the search effectively, but it can find neighbors in terms of Hamming distance only. Our method termed SlideSort finds a chain of common substrings by an efficient pattern growth algorithm, which has been successfully applied in data mining tasks such as itemset mining (). A pattern corresponds to a sequence of substrings. The space of all patterns is organized as a tree and systematically traversed. Our method does not rely on any index structure to avoid storage overhead. Instead, radix sort is employed to find equivalent strings during pattern growth. To demonstrate the correctness of our algorithm, the existence of a common substring chain in any neighbor pair is proved first. In addition, we deliberately avoid reporting the same pair multiple times by duplication checking. As a result, our method scales easily to 10 million sequences and isPage: 465 464470
SlideSortmuch faster than seed matching methods and suffix arrays for short sequences and large radius. The rest of this article is organized as follows. Section 2 introduces our algorithm. In Section 3, results of computational experiments are presented. Section 4 concludes the article.
METHODTwo similar strings share common substrings in series. Therefore, we can detect similar strings by detecting chains of common strings systematically. Before proceeding to the algorithm, let us describe fundamental properties first. Divide the interval 1,...,, into b blocks of arbitrary length w 1 ,...,w b , b i=1 w i =. The starting position of each block is defined as q i = 1+ i1 j=1 w j. The alphabet is denoted as. We assume that each string in the database {s i } n i=1 consists of letters, s i ||. Given two strings s, t, s = t holds if all letters are identical. The substring from positions i to j is described as s. A pattern of length k is defined as a sequence of strings and block indices,where/2 , k = 1,...,bd. Proof. There are multiple possible alignments of s i and s j. An alignment is characterized by the number of matches m, that of mismatches f , that of gaps g i in s i and that of gaps g j in s j .The length of s i is equal to m+f +g j and that of s j is m+f +g i , because any letter in s i is aligned to either a letter in s j or gap symbol in s j and vice versa. Thus, we obtain g i = g j d/2 by taking into account that the maximum number of gaps does not exceed d. Therefore, an aligned position of any letters is within a bound of d/2 letters from its original position. Let us divide s i into b blocks of length w 1 ,...,w b. Since the number of mismatches are at most d, at least bd blocks match exactly with their counterparts in s j in any alignment. Also, since aligned positions are bound within d/2 from their original positions, the matching counterpart of any block of s i can be found in s j within offset between d/2 and d/2.illustrates an example of patterns with b = 5,d = 3. This theorem implies that any neighbor pair has a chain of bd common blocks and the corresponding blocks lie close to each other. It serves as a foundation of our algorithm presented later on.. An example pattern for block size 5 and edit-distance threshold 3. s i matches to X with no offset in the first block and the third block. s j matches to X with no offset in the first block but with 1 offset in the third block.
Pattern growthIn our algorithm, all patterns X of |I(X)|2 are enumerated by a recursive pattern growth algorithm. In a pattern growth algorithm, a pattern tree is constructed, where each node corresponds to a pattern (). Nodes at depth k contain patterns of length k. At first, patterns of length 1 are generated as follows. For each block y 1 = 1,...,d +1, a string pool is made by collecting substring of {s i } n i=1 starting at q y 1 d/2,...,q y 1 ++d/2. Applying radix sort to the string pool and scanning through the sorted result, repetition of equivalent strings can be detected (). Each pattern of length 1, denoted as X 1 , is constructed as a combination of the repeated string x 1 and y 1 ,At the same time, all occurrences C(X 1 ) are recorded. If s i matches the same pattern X 1 by several different offsets, only the smallest offset is recorded. They form the nodes corresponding to depth 1 of the pattern tree. Given a pattern X t of length t, its children in the pattern tree are generated similarly as follows. For each y t+1 = y t +1,...,d +t +1, a string pool is made by collecting substrings of I(X t ) starting at q y t+1 d/2,...,q y t+1 ++d/2. Because the string pool is made from the occurrence set only, the size of the pool decreases sharply as a pattern grows. By sorting and scanning, a next string x t+1 is identified and the pattern is extended asand the occurrences C(X t ) are updated to C(X t+1 ) as well. To avoid generation of useless patterns, the pattern tree is pruned as soon as the support falls below 2. Also, the tree is pruned if there is no string in I(X) that matches X with zero offset. As pattern growth proceeds in a depth-first manner, memory is reserved as a pattern is extended, and then immediately released as the pattern is contracted to visit another branch. This dynamic memory management keeps peak memory usage rather small.
From patterns to pairsAs implied in Theorem 1, every neighbor pair () appears in index set I(X) of at least one pattern. Since one of the pair must have zero offset, the set of eligible pairs is described as P X ={(i,j)|i < j,i,j  I(X),s i matches X with zero offset}. Since not all members of P X correspond to neighbors, we have to verify if they are neighbors by actual edit-distance calculation. A problem here is that the same pair (i,j) possibly appears in the index set of many different patterns. It is also possible that pair (i,j) in the same index set is derived from different offsets. In most applications, it is desirable to ensure that no pair is reported twice. The straightforward solution of the problem is to check if a new pair is previously reported by storing all pairs, which requires huge amount of memory. We propose an alternative solution that rejects non-canonical pairs without using any extra memory as follows. A match of s i and s j can occur in various ways, each of which can be described as the tuple (y,p), where y = y 1 ,...,y bd describe the blocks in the pattern and p is the offset with which the pattern matches s j. We define the canonical match as the one with lexicographically smallest y and p, where priority is given to y. For example, consider the case s i = AATT , s j = ATAT , d = 2 and all block widths set to 1. There are 10 different (y,p) pairs as shown in, where matching residues are shown in red squares. In this case, (1) is canonical. Among them, the matches with overlapping squares do not have correct alignment. We do not exclude such pairs to avoid an extra run of dynamic programming. To judge if a given match (y,p) is canonical or not, it is sufficient to check if there exists another match that is lexicographically smaller. More precisely, the match represented by y,p is not canonical, iff there exists a block 1  z  max(y),z /  y and an offset d/2r d/2 such thatThis canonicity check can be done in O(d) time.(10), they do not correspond to correct alignment. Pseudocode of the overall algorithm is shown in Algorithm 1. In line 18, it suffices to compute diagonal stripe of width 2d +1 of DP matrix. Thus, the distance calculation is performed in O(d) time.
Page: 466 464470
K.Shimizu and K.Tsuda
RemarksWith small modification, SlideSort can deal with gap opening and gap extension penalties. Define the gap open and extension cost as  o and  e , respectively. Denote the number of mismatches, gap opens and gap extensions as f , g o and g e , respectively. Then our all pairs similarity search problem is reformulated as finding pairs such that f +g o  o +g e  e  d. Denote the number of gaps in each sequence as g i and g j. Then,Since the lengths of two sequences are equal, the number of gaps is also equal, g i = g j , leading to the following inequality,Therefore, the offsets p k , for k = 1,...,bd, are bounded byWhen g e = 0, we can find all pairs by zero offsets, hence the offset range (3) covers this case as well. Notice that the block size b must be larger than max(d,d/( o + e )). This modification is effective to reduce both computation time and memory space when  o and  e are larger than substitution cost. It is worthwhile to notice that SlideSort can handle sequences of slightly different lengths without any essential modification. See a Supplementary Method in Supplementary file 1 for details.
ComplexityDenote by  =|| the alphabet size. Space complexity of SlideSort is O((bd)dnlogn+nlog), because it requires an pointer array to describe the pattern tree, and the original strings must be retained. Denote by m the number of all pairs included in the index set I(X). Time complexity of SlideSort is O(b d1 d bd n+md), in which the first part is for sorting and the latter part is for edit-distance calculations. The time complexity depends on the effectiveness of pruning through m. The worst case of the latter part becomes O(n 2 d) when all the input short reads are identical. In most cases, however, short reads are quite diverse and m is expected to scale much better than O(n 2 ). The all pairs similarity search problem can be solved by finding approximate non-tandem repeats in the concatenated text of length n. An enhanced suffix array can solve it with O( d+1  d n) time and O(nlogn+ nlog) space (). This time complexity is essentially achieved by producing all variants within distance d of all sequences and finding identical pairs. The difference is that the time complexity of the suffix array depends on the alphabet size and that not of SlideSort. Thus, SlideSort can be applied to large alphabets (i.e. proteins) as well.
EXPERIMENTSFrom NCBI Sequence Read Archive (http://www.ncbi.nlm.nih .gov/sra/), we obtained two datasets: paired-end sequencing of
end if15.
if |y|=bd then
end if
21.
end if
22.
end for
23.
return
24.
end if25.
for
end for35.
end for 36. end functionHuman HapMap (ERR001081) and whole genome shotgun bisulfite sequencing of the IMR90 cell line (SRR020262). They will be referred to as dataset 1 and 2, respectively. Sequence length of dataset 1 is 51 and that of dataset 2 is 87. Both datasets were generated by Illumina Genome Analyzer II. Reads that do not include 'N' were selected from the top of the original fastq files. Our algorithm was implemented by C++ and compiled by g++. All the experiments were done on a Linux PC with Intel Xeon X5570 (2.93 GHz) and 32 GB RAM. Only a single core is used in all experiments. As competitors, BWA () and SeqMap () are selected among many alternatives, because the two methods represent two totally different methodologies, backtracking and block combination. BWA is among the best methods using index backtracking, while SeqMap takes an ELAND-like methodology of using multiple indexes for all block combinations. SlideSort is also compared to the naive approach that calculates edit distances of all pairs. BWA and SeqMap are applied to all pairs similarity search by creating an index from all short reads and querying it with the same set of reads. Notice that both BWA and SeqMap are not originally designed for all pairs similarity search but for read mapping, which requires a larger search space. Although fair comparison is difficult between tools of different purposes, we used mapping tools as competitors, because no tool is widely available for all pairs similarity search, to our knowledge. For our method, the number b of blocks has to be determined. In the following experiments, we set b relative to the distance threshold d as b = d +k. Here, k corresponds to the pattern size. In the following experiments, we tried k = 1,...,5 and reported the best result. The number of neighbor pairs for both datasets are shown in Supplementary. We confirmed that both SlideSort and the naive approach reported exactly the same number of neighbor pairs, which ensures correctness of our implementation of SlideSort.
Computation time and memory usageFigure 5 plots computation time against the distance threshold d. SlideSort is consistently faster in all configurations. As the number of sequences grows and the distance threshold is increased, the difference from BWA and SeqMap becomes increasingly evident. Not all results are obtained, because of the 30 GB memory limit and 300 000 s time limit.compares peak memory usage of SlideSort, SeqMap and BWA. We separately measured the memory usage of the indexing step and searching step for BWA, because BWA is designed to execute those steps separately. The peak memory of BWA for the search step is the smallest in most of the configurations, while that of SlideSort is comparable or slightly better than BWA's peak indexing memory. Detailed results for 100 000 short reads are shown in. BWA is most efficient in space complexity, because its index size does not depend on the distance threshold. Instead, BWA's time complexity rapidly deteriorates as the edit-distance threshold grows due to explosion of the number of traversed nodes in backtracking. In contrast, SeqMap indexes and hashes all the combination of key blocks, which leads to huge memory usage. SlideSort is similar to SeqMap in that it considers all block combinations, but is much more memory efficient. The difference is that SlideSort is an indexing free method, which dynamically generates the pattern tree by depth-first traversal. It allows us to maintain only necessary parts of tree in memory.
Effect of pattern sizeFigure 7 investigates the influence of pattern size k on the efficiency. Except for d = 1, the best setting was around k = 24. Our method k = 1 roughly corresponds to the single seed approach, so this result suggests the effectiveness of using chains. Overall, the computation time was not too sensitive to the choice of k.
Comparison to single seedOur algorithm employs a chain of common substrings to narrow down the search. Compared with the single seed approach that uses a k-mer to derive candidate pairs, the total length of substrings can be much larger than the k-mer without losing any neighbors. It yields higher specificity leading to a smaller number of candidate pairs. Instead of a chain, one can detect multiple k-mers and verify those pairs containing multiple matches (). However, this approach has lower specificity in comparison Page: 468 464470
K.Shimizu and K.Tsuda
SlideSortto the chain of the same total length, because the matching positions of each elements of the chain are strictly localized due to Theorem 1.compares the number of candidate pairs generated by our method and single seed (k-mer in plot). It corresponds to the number of edit-distance calculations. We have two variations of the single seed method: 'k-mer/nonredundant' stores previously reported pairs in memory, and does not include previously reported pairs in candidates. 'k-mer/redundant' does not use additional memory but counts the same pair multiple times. Here we set the length of the k-mer to /d so that no neighbors are lost. In the plot, one can see a significant reduction in the number of candidate pairs in our algorithm. Notice that the number of candidate pairs is shown in log scale. In our method, the number of candidates is minimum at the largest pattern size, because the total length of substrings is maximized and specificity becomes optimal. However, since the search space of patterns is expanded, the total computation time is not optimal in this case.
Clustering analysis of short readsA main application of SlideSort is hierarchical sequence clustering, which would be used in correcting errors in short reads and preprocessing for metagenome mapping, for example. SlideSort provides an undirected graph G, where vertices represent short reads and weighted edges represent edit distances of neighbor pairs. Among hierarchical clustering algorithms, single link is most scalable (). Since the dendrogram ofsingle link clustering is isomorphic to the minimum spanning tree (), one can perform single link clustering via minimum spanning trees (MSTs) construction by the Kruskal or Prim algorithm (). Since storing all edges can require a prohibitive amount of memory, we used a well-known online algorithm for building MSTs (). It creates MSTs from a stream of edges, discarding unnecessary edges along the way. It essentially maintains all cycle-free connected components and, if a cycle is made by a new edge, it removes the heaviest edge from the cycle. In our experiment, the additional computation time for finding MSTs was trivially small compared with that of SlideSort finding similar pairs ().
CONCLUSIONIn this study, we developed a novel method that enumerates all similar pairs from a string pool in terms of edit distance. The proposed method is based on a pattern growth algorithm that can effectively narrow down the search by finding chains of common k-mers. Using deliberate duplication checks, the number of edit distance calculations is reduced as much as possible. SlideSort was evaluated on large datasets of short reads. As a result, it was about 103000 times faster than other index-based methods. All these results demonstrate practical merits of SlideSort. One naturally arising question is if SlideSort can be used for mapping. In fact, it is possible by storing the pattern tree () in memory, and using it as an index structure. However, the index would cost too much memory for genome-scale data. What we learned from this study is that all pairs similarity search is essentially different from mapping in that one can employ pruning and dynamic memory management. Thus, all pairs similarity search is not a subproblem of mapping and deserves separate treatment. In future work, we would like to implement SlideSort with parallel computation techniques. Recent progress in hardware technology enables end-users to use many types of parallel computing scheme such as SSE and GPGPU. SlideSort would be further improved by using these technologies.
K.Shimizu and K.Tsuda
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
