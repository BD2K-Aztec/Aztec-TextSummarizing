Motivation: Transcriptional regulatory networks, which consist of linkages between transcription factors (TF) and target genes (TGene), control the expression of a genome and play important roles in all aspects of an organism's life cycle. Accurate prediction of transcriptional regulatory networks is critical in providing useful information for biologists to determine what to do next. Currently, there is a substantial amount of fragmented gene regulation information described in the medical literature. However, current related text analysis methods designed to identify proteinâ€“protein interactions are not entirely suitable for finding transcriptional regulatory networks. Result: In this article, we propose an automatic regulatory network inference method that uses bootstrapping of description patterns to predict the relationship between a TF and its TGenes. The proposed method differs from other regulatory network generators in that it makes use of both positive and negative patterns for different vector combinations in a sentence. Moreover, the positive pattern learning process can be fully automatic. Furthermore, patterns for active and passive voice sentences are learned separately. The experiments use 609 HIF-1 expert-tagged articles from PubMed as the gold standard. The results show that the proposed method can automatically generate a predicted regulatory network for a transcription factor. Our system achieves an F-measure of 72.60%. Availability: The software, training/test datasets and learned patterns are available at
INTRODUCTIONTranscription factors (TFs) play an important role in regulatory systems. A substantial amount of biological research is continuously being conducted, and the cumulative results obtained from the subsequent analyses are increasing rapidly. Many of these results are reported in the medical literature (). However, given this explosive growth, it is becoming more difficult for biologists to search, read and assemble the information they need. * To whom correspondence should be addressed.Therefore, many high-throughput techniques for extracting useful information from the literature have been proposed. Much research () has been conducted on predicting proteinprotein interactions (PPIs) through text mining. These methods aim to extract more information than what is currently contained in curated databases such as BIND (), KEGG (), SwissProt () and the Database of Interacting Proteins (). However, current-related text analysis methods designed for finding PPI are not entirely suitable for finding transcriptional regulatory networks, because the presence of two proteins in a PPI sentence does not necessarily indicate these proteins have a TF and Target gene (TGene) relationship or that one controls the gene activity of the other. The descriptive terms used for determining PPIs may be different from those necessary to determine gene regulation. For example, the words 'associate' and 'interact', which are descriptions that are useful for predicting PPIs, will cause a high-throughput automatic method to find substantial amounts of false positives in a regulatory network. Moreover, the regulatory descriptions could be different in articles written in passive versus active voice. Other existing systems () use manually defined patterns, a popular writing style for describing gene interactions. However, these systems have low recall values. Furthermore, existing methods rarely discuss how negative terms will cause false positives (Sanchez). Therefore, this study takes advantage of bootstrapping () to automatically learn patterns for describing gene regulation relationships and generating a transcriptional regulatory network.
SYSTEM OVERVIEWOur system architecture is composed of three tasks and is shown in. In our previous work (), we trained a set of initial patterns that included positive and negative patterns from manually tagged hypoxia inducible factor-1 (HIF-1)-related articles. However, this method required human judgment to decide whether a sentence indicated a relationship between a TF and a TGene. In this article, we develop an automatic method for learning patterns. Manually tagged sentences from our previous research (will be used as the gold standard. The proposed method includes three phases:
Bootstrapping patterns(1) Abstract retrieval and preprocessing phase: a TF of interest is added into the system, and TF-related abstracts are collected from PubMed (http://www.ncbi.nlm.nih.gov/pubmed/). The system parses all sentences containing a (TF, TGene)tuple. (A sentence is said to contain a tuple if a TF and TGene both appear in a sentence.) We use Sequence Retrieval Systems (SRS) from the European Molecular Biology Laboratory (EMBL) and HUGO Gene Nomenclature Committee (HGNC) databases to identify TFs and TGenes.(2) Initial pattern training phase: all sentences in the articles containing a (TF, TGene)-tuple are listed for the user. The user tags positive and negative sentences (an example is shown in), which are then used for training. If there is no feedback from the user, the system randomly selects n articles that contain tuples for training. Based on our evaluation of different values of n, an n of 5 is suggested. The system will first filter out sentences by negative patterns, if any negative patterns have been learned. Presently, we use negative patterns that were learned from the manually tagged 1048 negatively marked sentences. The rest of the sentences are used to train positive patterns. Each sentence containing a tuple is parsed into the '<Before> Entity1 <Middle> Entity2 <After>' format as shown in. This format includes three vectors, <Before>, <Middle> and <After>, which are then divided by the TF/TGene entity. Patterns are then trained from different vector combinations named <Before>, <Middle>, <After>, <Before+Middle>, <Before+After>, <Middle+After> and <Before+Middle+After>.I <Before>: the sub-sentence vector located to the left of Entity1. II Entity1: the TF or TGene that is between <Before> and <Middle>. III <Middle>: the sub-sentence vector located between Entity1 and Entity2. IV Entity2: the TGene or TF that is between <Middle> and <After>. For example, Entity1 is TF and Entity2 is TGene. V <After>: the sub-sentence vector located to the right of Entity2.(3) Bootstrapping phase: in Phase 2, patterns from initial selected articles are found. These patterns can then be used to search other, still unused, articles in the corpus dataset to determine if new (TF, TGene)-tuples can be found. If a new tuple is extracted from the dataset, the process goes back to Phase 2 to find new patterns. This process can be iterated until no new tuples are found in the tuple-finding step. The bootstrapping process is shown in. A real example is shown in.After these three tasks, relationships between genes can be determined, as shown by Ring 1 in. A simplified, hypothetical example of gene relationships is shown in. In this relationship, some of the TGenes could be also be TFs themselves. TFs found by the bootstrap search can then be used as inputs to continue the process and, in this way, a gene network can be constructed. The system interface allows the user to see the related genes and the corresponding sentences. Part of the HIF-1 gene network generated by this process is shown in.
EVALUATION
Data sourceAlthough there are several available benchmark datasets for PPI, such as AIMed, BioInfer, HPDR50, IEPA and LLL (), they are not suitable for evaluating transcriptional regulatory networks. The main reason is that PPI sentences do not necessarily indicate TFTGene relationships or whether one gene controls the gene activity of the other. Therefore, we manually tagged a benchmark dataset for evaluating transcriptional regulatory networks. This study used 'HIF-1' as a keyword to search articles from PubMed. A total of 5651 sentences in 602 studies were found. Not all sentences with a (TF, TGene) tuple, only 1578 sentence with tuple can be used to train patterns. Moreover, not all sentences withPage: 1424 14221428
H.-C.Wang et al.(b)tuple should be train as 'positive' pattern because some sentences do not directly indicate whether a TF regulates a TGene. When sentences did not directly indicate regulation, they were tagged with negative marks and used for training 'negative' patterns. After manually tagging these sentences, 531 positive marks and 1047 negative marks were obtained for experimental and benchmarking purposes. Sentences analyzed in this study were classified as either active or passive voice according to the location of the TF in the sentence. Active sentences were marked as TFTGene-style, and passive sentences were marked as TGeneTF-style. In the data, there were 847 TFTGene sentences composed of 316 positive sentences and 531 negative sentences. There were a total of 731 TGene TF sentences comprising 215 positive sentences and 516 negativesentences. Among these sentences, some included two TFs and one TGene (TFTGeneTF-style) or two TGenes and one TF (TGene TFTGene-style) in a sentence. These relationships were counted in both TFTGene and TGeneTF categories.
Results
Experiment 1How much initial training data should be used for training positive patterns? This experiment identified how many manually tagged initial abstracts should be used for our proposed approach to reach an acceptable performance. We evaluated the results of the overall method from different vector combinations of TFTGene and TGeneTF sentences. The results, shown in, indicate that three initial abstracts are the minimum requirement, and the F-measure reaches a stable condition when five abstracts are used. We also used error rates to evaluate performance. In this study, we define error rate as follows:(1) If genes in a tuple can sustain only one iteration and are then unable to proceed with bootstrap training, the identification of those genes is regarded as an error incident.(2) If genes in a tuple can sustain more than two iterations but the F-measure is <10%, it is treated as an error.Note that the error rate for TGeneTF-style sentences is higher than that for TFTGene-style sentences. The results also indicate that Fmeasures become acceptable when more initial abstracts are used for training.
Page: 1425 14221428
Bootstrapping patterns
Experiment 2 Initialdataset selection. Using the following three methods of selecting sentences to include in the dataset, we analyzed whether automatic processes for finding patterns are possible.(1) Manually selected positive sentences for pattern training (manual-marked).(2) A few manually selected abstracts that contain positive sentences for pattern training (semi-automatic).(3) Randomly selected abstracts that include either TFTGenestyle or TGeneTF-style sentences for bootstrapping pattern training (automatic). The results of this experiment, shown in, indicate that none of these three methods is clearly the best. This lack of consistent differences between the methods may be because the F-measures shown are the average values across 15 experiments. We compare averages because not every experiment is perfect and errors sometimes occur. If we observe just the averaged results, the difference between the three methods is not obvious. Additionally, if we randomly take a small number of abstracts as the initial dataset and proceed with iterative pattern learning through bootstrapping, the final patterns learned by the automatic or semi-automatic method are similar to those obtained from the manual method. In some cases, the semi-automatic or automatic methods were even better than the manual method. Therefore, the use of manual tagging instead of automatic or semi-automatic tagging does not dramatically influence the result of the gene network finding method. This result indicates that when choosing an initial dataset, it is not necessary to manually mark all of the sentences if the selected literature contains tuple sentences. This finding shows that it is possible to reduce the amount of human effort required to generate a regulatory network.has been shown to be effective (). However, those learned patterns have rarely been evaluated to determine if they are qualified. In this study, we adapted the negative patterns obtained in our previous work () because only qualified patterns should be used. This idea is based on the principle that a good pattern should cover sufficient correct sentences (). In other words, if too many positive sentences match a negative pattern, the negative pattern should not be considered. The error rate of each negative pattern is calculated by the following equation:
Experiment 3For negative pattern P k , Error(P k ) means the number of positive sentences matched to negative pattern P k , Correct(P k ) means the number of negative sentences matched to P k , and PRate(P k ) means the ratio of incorrectly predicted sentences to correctly predicted ones. The threshold, PRate(P k ), is between 0 and 1.0. The results of this experiment, which are shown in, indicate that taking advantage of negative patterns in the <Middle> or <Before+Middle> vectors when the threshold is 0.1 can result in better performances of the gene network finding method, especially for TGeneTF-style sentences.
Experiment 4Can we learn negative patterns automatically? Experiment 3 showed that using qualified negative patterns learned from manually marked sentences can improve the performance of the gene network finding method. Experiment 4 analyzed whether negative patterns can be learned automatically and whether negative patterns learned in this manner enhanced F-measures. Negative patterns are learned by excluding sentences matched to learned positive patterns. The comparison between using the gene network finding method with or without automatically learned negative patterns is shown in. After learning and filtering negative patterns, the precision corresponding to the <Middle>, <After> and <Before+Middle> vectors was slightly enhanced. However, the recall and F-measure values decreased. The results of this experiment show that it is not possible to automatically learn negative patterns. We determined that published articles rarely include negative sentences in the abstracts. Therefore, given the small number of negative sentences available for training, automatically learning negative patterns is difficult.
CONCLUSIONThis study introduced a pattern-learning method using bootstrapping. Based on our experimental results, we found that users do not need to manually mark sentences for pattern learning. In positive pattern training, data consisting of TFTGenestyle sentences resulted in better performance of the gene network finding method than data consisting of TGeneTF-style sentences. The difference may be due to the writing habits of biomedical researchers. The literature tends to record research achievements Page: 1427 14221428(that is, positive results), and therefore authors are likely to describe their findings using active phrasing. We also found that including only three to five abstracts for the initial training datasets generated acceptable results. This may be because many articles are published about the same TF and its specifically regulated genes; therefore, it is easy to collect such literature entries into an initial dataset. When a tuple is used for bootstrapping training, it is easy to find many sentences from which to learn new patterns. Based on the retrieval effects from the seven vector styles in Experiment 1, the recall value of the <Middle> vector is the highest at 92.58% for TFTGene-style sentences and 87.86% for TGeneTF-style sentences. The values of precision are 40.36% for TFTGene-style sentences and 33.64% for TGeneTF-style sentences. This result shows that patterns generated by the <Middle> vector are the most representative. This may be because the keywords related to 'certain TF regulates this particular gene' almost always appears in the <Middle> vector for phrases such as 'activation of,' 'induction of,' 'transactivation of,' 'activate' and other similar phrases. Experiment 2 indicated that the three methods for generating initial datasets do not result in obviously different performances of the gene network finding method. Performance using manually marked sentences is not always better than using automatically or semi-automatically marked sentences. In addition, the trained patterns were similar whether we manually marked results or used Page: 1428 14221428
Bootstrapping patterns
H.-C.Wang et al.a few abstracts to form the initial dataset and then adapted the bootstrapping method for pattern learning. Therefore, manually tagging the results does not greatly affect the performance of the gene network finding method. Rather, these results show that choosing the initial dataset does not necessarily involve manually marking sentences in advance or checking whether the literature contains positive sentences. Simply using an abstract that contains sentences with TFTGene or TGeneTF relationships is sufficient for automatic training for positive patterns. Creating an initial dataset this way could reduce expenditures of time and human effort. Moreover, learning negative patterns can also help improve the performance of the gene network discovery method. However, the bootstrapping method of selecting sentences to include in the dataset is not suitable for training based on negative patterns. Data that consist of negative patterns must thus be manually marked. In general, the bootstrapping method described in this study allows the gene network discovery method to effectively identify regulatory information regarding TFs and TGenes, thereby automatically finding positive patterns. Our results also indicate the <Before+Middle> and <Middle> vectors generate the most suitable positive patterns. Finally, our results indicate that if negative patterns are used to filter negative sentences, the precision of the gene network discovery method will be enhanced.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [15:40 19/4/2011 Bioinformatics-btr155.tex]
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
