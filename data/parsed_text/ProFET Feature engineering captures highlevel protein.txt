Motivation: The amount of sequenced genomes and proteins is growing at an unprecedented pace. Unfortunately, manual curation and functional knowledge lag behind. Homologous inference often fails at labeling proteins with diverse functions and broad classes. Thus, identifying high-level protein functionality remains challenging. We hypothesize that a universal feature engineering approach can yield classification of high-level functions and unified properties when combined with machine learning approaches, without requiring external databases or alignment. Results: In this study, we present a novel bioinformatics toolkit called ProFET (Protein Feature Engineering Toolkit). ProFET extracts hundreds of features covering the elementary biophysical and sequence derived attributes. Most features capture statistically informative patterns. In addition , different representations of sequences and the amino acids alphabet provide a compact, compressed set of features. The results from ProFET were incorporated in data analysis pipelines, implemented in python and adapted for multi-genome scale analysis. ProFET was applied on 17 established and novel protein benchmark datasets involving classification for a variety of binary and multi-class tasks. The results show state of the art performance. The extracted features' show excellent biological interpretability. The success of ProFET applies to a wide range of high-level functions such as subcellular localization, structural classes and proteins with unique functional properties (e.g. neuropeptide precursors, thermophilic and nucleic acid binding). ProFET allows easy, universal discovery of new target proteins, as well as understanding the features underlying different high-level protein functions. Availability and implementation: ProFET source code and the datasets used are freely available at https://github.com/ddofer/ProFET.
IntroductionThe most used approaches in protein classification rely on distance measures between sequences based on various alignment methods (e.g. Smith-Waterman, BLAST). With the growth in the amounts and diversity of protein sequences, more sophisticated methods have been introduced (e.g. PSSM, Profile-Profile, HMM-HMM) (). These methods are based on multiple sequence alignments for improving remote homologs detection (). Incorporating 3D-structure as a seed for the statistical models further improved the quality of protein domains and families (e.g. Pfam) (). Currently, there are $27 000 such models (InterPro,) that cover 83% of all sequences in UniProtKB (2014_10). Function assignment is gained from mapping InterPro models to). The assessment of large-scale automatic protein functional annotations () and the contribution of alternative approaches toward this task have been extensively discussed (e.g.). Despite the strength of the model-based methods, in many instances the local sequence-based methods fail to reliably assign a function (). This is best demonstrated by the limitation in classifying proteins by their 3D-folds (). Notably, the classification of some biological niches is especially suited for feature representation. For example, routine annotation tools fail to confidently assign function for bioactive peptides and short proteins (). A number of previous studies focus on feature extraction from whole protein sequences () as a starting input for machine learning (ML) approaches. Structural benchmark from SCOP and CATH () are frequently used to assess the predictive ML methods. Specialized predictors have been presented for structural tasks including secondary structure, solvent accessibility, stability, disordered regions, domains and more (). ML approaches have proven suitable to classify protein properties beyond their 3D-structure. SVMProt was tested on preselected 50 functional families from Pfam (). Naive biophysical features classification outperformed simple sequence-based methods for a number of protein families (). However, the most likely advantage of the feature and pattern-based ML approach is toward high-level functionality (e.g.). Examples for such predictions include proteinprotein interactions (), discriminating outer membrane proteins (), membrane topology (), subcellular localization () and more. The strongest features learned by the ML classifiers often expose biologically important motifs (). In this study, we focus on the ability of elementary biophysical features together with a rich set of engineered representation of proteins to classify high-level protein functions. These features are suited for both supervised and unsupervised classification. Our goal is to illustrate the importance of ProFET (Protein Feature Engineering Toolkit) as a 'one size fits all' framework for representing whole protein sequence. We present a universal, modular workflow for protein function classification: (i) feature generation and extraction from primary sequences (ProFET). (ii) Application of the extracted features in a ML framework for binary or multi-class partition. (iii) Presentation of discriminative classification power. (iv) Identification of patterns and features that underlie the successful classification ('Feature Selection').
Methods
Protein databases and datasetsIn gathering the protein sets in this study, we used datasets made available by (i) custom sets gathered from public databases such as UniProtKB () and SCOPe () and (ii) benchmarks extracted from publications. For both resources, we applied CD-Hit and USearch () to remove redundant sequences according to a predefined % of sequence identity. As a rule, we used only classes that contain a minimal number of samples per group (typically 40, after redundancy removal). Sequences with unknown amino acid (AA), errors or sequences that are shorter than 30 AA were removed. We included in the analysis the most recent SCOP classification (2.05, 71015 PDB entries pre-filtering) as some literature-based benchmarks from SCOP were outdated ().). Classes and folds were defined by SCOP, with 25% or 10% sequence identity filter (8514 and 6721 sequences, respectively). @BULLET SCOPe (Release 2.05, February 2015) 'selected class' defined by the SCOP class (marked ak), with classes c,d removed. We also apply as a benchmark classes 'a,b,f,g' at 25% sequence identity filter. Classes a,b,c,f,g were tested following redundancy removal at extremely low identity level (10%). The classes that were not included had small number of folds in each.
Specialized protein functions
Nucleic acids binding proteins@BULLET DNA-binding proteins. Benchmark dataset from DNA binder (). @BULLET RNA-binding proteins. Benchmark dataset from BindN ().
Viral properties and classes@BULLET Virus-host pairs: Acquired from SWP. The set include all viral proteins partitioned by the kingdom of the hosts. Redundancy filtration (at 40% identity) was performed on the viral proteins but not on the hosts.The datasets and sequences used are all freely provided online: https://github.com/ddofer/ProFET.
FeaturesAll features extracted by ProFET are directly derived from the protein sequence and do not require external input (). The software packages required for ProFET are part of the scientific Python distribution. Properties relying on external predictors (e.g. the 3D structural fold, secondary structure) are not included by default. However, users can trivially add additional features via the 'FeatureGen' script. ProFET can also generate a pre-defined set of default features for consistency in evaluation and ease of use, callable from the command-line. The features that are described below can be restricted to a segment of a protein (e.g. each individual third of a sequence). We support two versions for a subsequence analysis: (i) relative portions and (ii) fixed lengths. The activation of global feature extraction combined with segmental consideration is advantageous. It is motivated by the atypical composition of different segments of numerous protein classes, e.g. the signal peptides, flexible N-terminal linker regions, C-terminal portions of membranous kinases and GPCR receptors, disordered regions and more. The categories of features currently implemented in ProFET are as follows.
Biophysical quantitative propertiesi. Molecular weight (in Da) ii. Sequence length (in AA) iii. pH(I), the isoelectric point iv. Net Charge at various pH(I)s. v. Aromaticity the relative frequency of Phe, Trp, Tyr. vi. Instability index, an estimate for the stability of a protein in vitro (). vii. GRAVY (Grand Average of Hydropathy), the sum of hydropathy values of all AA, divided by the number of AA in the analyzed sequence (). viii. Aliphatic index, the relative volume occupied by aliphatic side chains (Ala, Val, Ile and Leu) (). Most of these properties were based on the Expasy proteomics collection (). The important of these elementary global features has been previously validated ().
Letter-based featuresi. AA composition (single or di-peptide) ii. Overlapping K-mers. iii. 'Mirror' K-mers. It accounts for K-mers of various combinations of 'grouped' AA. For example, lysine-arginine appearance (KR) is grouped together with RK. iv. Reduced AA alphabets. Grouping of AA secures a compact representation. We include a large number of such alphabets from various sources () and some novel alphabet representations of size 14 and 8 (Ofer_14 and Ofer_8, respectively). For the 14 AA representation, the grouping is for KR, TS and LIVM. For the 8 AA representation, the grouping is for FYW, ALIVM, RKH, DE and STNQ. The other AA remain in the uncompressed representation.
Local potential featuresi. Potential post-translational modification (PTM) sites. We included motifs implemented as regular expressions, including those for 'known short motif' dibasic cleavage model (X-X-Lys, X-X-Arg-Arg, Arg-X-X; where X denotes any AA (). Others include N-glycosylation and Asp or Asn hydroxylation sites. We included Cysteine spacer motif that captures the tendency of Cys to appear in a minimal window (). Additional PTM motifs collected from ELM () were not implemented. ii. Potential Disorder (FoldIndex). Local regions of disorder are predicted using the naive FoldIndex () and TDP-IDP methods (). FoldIndex predicts the disorder as a function of the hydrophobic potential and net charge.
Information-based statisticsThese features aim to capture the non-randomly distribution of each AA in the sequence, based on the concept of information entropy. The information-based features used are:i. Total entropy per letter, as a whole ii. The binary autocorrelation iii. Autocorrelation with Selected letters. For example, K, R or C is denoted as '1' and the rest as '0'. Lag is then computed. For details, see Ofer and Linial (2014).
AA scale-based featuresAA propensity scales map each AA to a quantitative value that represents physicochemical or biochemical properties, such as hydropathicity or size. These scales can then be used to represent the protein sequence as a time series, typically using sliding windows of different sizes and to extract additional features. ProFET includes a wide array of scales, ranging from the established propensities for hydrophobicity and flexibility/B-factors (acquired from Expasy), to 'optimal' and maximally independent derived scales (). Features derived from these scales include:i. Averages for the sequence as a whole, for different window sizes. ii. Quartile averages (e.g. top 25%). iii. Maximum and minimum values for a given scale and windowsize along the entire sequence. iv. Autocorrelation. 2.2.6 Transformed CTD features () We implemented the Dubchak and ProFEAT CTD features (hydrophobicity, normalized Van der Waals volume, polarity, polarizability, charge, secondary structure and solvent accessibility hydrophobicity, normalized Van der Waals volume, polarity, polarizability, charge, secondary structure and solvent accessibility) (). Code from Spice (van den) and () was also integrated. An additional subdivision of disorder propensity was adapted from Composition Profiler (
EvaluationThe power of any of the predictor proposed is tested by several routinely used evaluation methods. We measure the performance for the binary and multiclass tasks with the same metrics: F1 score (the weighted average of the precision and recall) and Accuracy (Acc). These parameters are defined as: @BULLET F1  2*TP/(2TP  FP  FN) @BULLET Ac  (TP  TN)/(TP  TN  FP  FN) TP represents the number of the correctly recognized proteins. FP, the number of proteins wrongly identified and FN the number of proteins missed. Performance is evaluated using cross-validation. Specifically, multiple rounds of randomized stratified cross validation ('Stratified Shuffle Split'), with 18% holdout for each iteration (unless mentioned otherwise). Features were filtered prior to cross validation and testing using a simple univariate filter for statistical significance (a 0.01, Bonferroni multiple testing family wise error rate corrected; analysis of variance one-way F-test). This prefiltering step at the cross validation phase had a negligible impact on the overall performance (not shown).
Feature selectionA wide array of methods for supervised and unsupervised feature selection can be applied to identify the best features, implemented with the superlative Scikit learn toolkit (). These include wrapper methodsRandom Feature Elimination (), model-based filtering [e.g. support vector machine (SVM) classifiers with a L1 Loss penalty, for sparse coefficients], statistical filtering, stability selection, PCA, etc. In the test cases, we used the RFE method, combined with an underlying non-linear ensemble of classifiers (Random forests). The underlying principle is iterative fitting of the classifier on the data, with the weakest features being pruned at each of the iterations (). We examined the selected features, and the model classification performance with the reduced set of features, and show novel, interpretable features, as well as excellent retained performance.
Results
ProFET outlineWe introduce two test cases to illustrate the potential of ProFET to provide a generic platform for analyzing the basis of high-level functionality in proteins. Classifying thermophile proteins was used as a test case for a binary classification of functionality that is not explicitly derived from the sequence. Classifying neuropeptide (NP) hormone precursors serves to assess the classification of poorly studied protein niche (). We generalize the approach to a range of from subcellular localization to viral phylogeny tasks (see Section 2.1.12.1.5). In all the illustrated cases, ProFET was used as a generic framework for feature extraction and prediction. External information that is often available (e.g. the family PSSM, GO annotation, structural prediction and disorder predictors) was not included. The workflow is composed of modular sections () 1. ProFET: Feature extraction from any protein sequences. Extracted features can be analyzed independently (suitable for ML analysis or unsupervised tasks) or discriminatively (i.e. seeking contrast between groups of proteins).2. Model Selection: The features are used to train and tune different ML models. For any given performance metric (e.g. precision), the optimal model and hyper-parameters are selected. 3. Performance Report: Classification performance is measured for a given model and dataset, using cross-validation. 4. Feature Selection: Informative features are selected and their importance measured using different methods. These methods include the statistical significance, wrapper methods, model-based selection, stability selection and more. 5. New sequences can be predicted using a trained ML model. This can be applied via the feature extraction pipeline or with a selected smaller subset of the selected features.
ProFET workflowcase studiesWe selected three datasets to illustrate the performance of ProFET and its workflow ().
Positivenegative protein setsSet 1: Thermophiles are proteins that function under high temperature. Given the extreme environmental conditions, we expect to detect biophysical signatures in these proteins underlying their thermostability. We used a benchmark dataset of 915 thermophilic and 793 non-thermophilic (Mesophile) proteins that were further filtered to insure < 40% sequence identity between sequences within each group (). Set 2: NPPs are pre-pro-polypeptide precursors of NPs. These are secreted proteins. Routine sequence alignment-based methods are insufficient to identify the immensely diverse NPs. In compiling a dataset, we used as a negative set a collection of proteins with Signal peptides, which lacked validated TMD (and therefore, most likely to be secreted). We keep the same (atypical) range of lengths to match the labeled NPPs. Both the positive and negative datasets have Signal peptides confirmed and cleaved using SignalP (). The negative (non-NPP) dataset was filtered using Usearch (), so that proteins in the negative set shared no sequence similarity (cutoff of 10% identity was applied). The final dataset held 2309 negatives and 1269 NPPs. Note that in the case of NPPs, we expect many unidentified NPP peptides among the proteins in the negative set. Set 3: Uncultured bacteria account for $250 K proteins in UniProtKB (). We restricted the test to those having GO annotations for 'ribosome', 'membrane' or 'cytoplasm'. Proteins were filtered for redundancy according to UniRef50 classification,
Classification resultsFor all three sets (as in Section 3.2.1), we obtained almost perfect classification. Classification was performed using a random forest classifier, implemented in Scikit learn (see Section 2).shows the results of the classifications for the set of the Thermophilic proteins and the NPPs as confusion matrices. Results were derived from 10-fold stratified cross validation. In both sets, the number of missed classified (FN and FP) is below 5% for the NPPs (63 and 110 proteins as FN and FP, respectively). For the set of the thermophiles, the missed classifications of the FN and FP reach 6% and 10%, respectively.shows the performance as receiver operating characteristics curves. Performance was measured using an automatically tuned SVM with a radial basis function (RBF) kernel, with 15-fold stratified cross validation. The performance was very high with a FP rate of 0.1 and the AUC for both tests reaching 0.97 (out of a maximum of 1.0). Uncultured bacteria comprise a set of poorly characterized proteins (Set 3). We trained proteins that mapped three main compartments in bacterium (membrane, cytoplasm, ribosome, total of 15 995 sequences). The localization performance for the multi-class task is very convincing (tested via 12 rounds of stratified shuffle split cross-validation). The F1 score is 0.917 (60.01 SD); accuracy is 0.916 (60.01 SD). We further used a combination of ML approach with naive PSIBlast search. We activated PSI-Blast (three iterations, default parameters) on sets 1 and set 2 (Thermophiles and NPPs sets). The most significant E-value was used for each sequence as an approximate distance matrix. We then trained a K-nearest-neighbors classifier and recorded the performance. We also used an unsupervised, clustering approach (spectral clustering and K-means) and compared these clusters to the 'true' labels. Clustering performance was significantly lower than reported (). The best results for the Psi-Blast test were obtained from Spectral clustering model. For the NPP set (total of 3370 proteins), the F1 score is 0.56. The similar analysis for the Thermophile/ Mesophile proteins reached F1 score of 0.29 (total of 1708 proteins). To make sure that the poor performance is not dependent on the choice of the ML methodology, we repeated the analysis for a classification by K-nearest neighbors classifier (k  1 or 2). The data were split 80/20 into evaluation and hold-out sets, and the best parameters on the evaluation set were determined by 4-fold cross validation. For the NPP and Thermophile sets, the accuracy on the 'evaluation set' was 62.8% (60.16 SD) and 48.9% (60.03 SD), respectively. The F1 score for the hold-out sets were 0.61 and 0.44 for sets 2 and 1, respectively.
Post-training feature selectionIn addition to the success of the predictors, interpretability of the features that best contributed to the performance is a crucial knowledge. Several methods for feature selection can be applied to identify a minimal set of such features. We applied a combination of Random Forests (an ensemble of decision tree classifiers) with the Random Feature Elimination wrapper method. In each of the iterations, the weakest features are removed and the model is then retrained with the remaining features, until the preselected desired amount of features remains. Performance of the reduced feature set is measured using new splits of the training data and cross validation. Recall that the initial set of (default) generated features included 771 features. The F-test filter reduced the number of features to 453 and 544 features for the Thermophiles and NPP sets, respectively.
Thermophilic proteinsinformative featuresWe note the importance of AA composition, particularly of charged and polar AA groups. Of further importance are features involving glutamic acid (E) and glutamine (Q), and the organizational entropy of E and Q. The relevance of these AA was reported (). We note that merely using the AA composition would not have captured many of these features. The classification performance (F1 score) with just 15 features reached 99.53% of that obtained using all statistically significant features (F1 score  0.906; 453 features).
NPPs featureinformative featuresAs opposed to the features dominating the test case of thermophilic proteins, in the case of the NPPs, a smaller set of features dominates, mainly relating to the normalized frequency of putative NPP cleavage sites, according to the 'known motif' model. Further properties of the basic residues Lys (K) and Arg (R) repeat themselves by virtue of entropy, binary autocorrelation (6/15 features) and more. Additional features include protein size (Mw and length) and to a lesser extent some 'structural' properties, such as flexibility ('Flex_min'), and secondary structural propensitiesreflecting the importance of availability of the putative cleavage sites and atypical composition of the putative peptides.validation. The number of FP and FP is shown for thermophiles (left) and NPs (right). (B) AUC (area under receiver operating characteristics curve)
Feature engineering workflowClassification performance: (F1 score of the positive class) with just 15 features was 95.85% of that obtained using all statistically significant featuresshows the types of the 15 strongest features for the two test cases. Selected features are ranked by relative importance to the classifier. Feature titles are self-explanatory. For example, 'ofer14KC' specifies the reduced AA alphabet ofer14 (see Section 2.2.2) for grouping of KC in the reduced representation.
Benchmarks' performanceThe workflow applied to our test cases (Section 3.2) was systematically applied to all the datasets. Each set was measured using 15-fold randomized stratified cross-validation. For each iteration, a fraction of the data (18%) is randomly set apart. The framework's automatically selected the performance of the classifier. The term 'Dummyby majority' applies to a classifier that always picks the majority class. Altogether, we present 15 additional datasets (in addition to the NPPs and Thermophilic proteins). For 76% of the datasets, the accuracy and F1 Scores are above 80%, while for 35%, the accuracy is > 90% (). The classification performance for DNA and RNA binding proteins meets the state of the art results obtained by special purpose predictors (). This specialized predictor for DNA and RNA binding proteins relies on the specific evolutionary information (e.g., PSSMs) combined with Support Vector Machine (SVM) (). 72.42% Accuracy is reported for DNA binding proteins using a random forest model and extensive feature selection (). We used the same benchmark data to directly assess the performance. We show () that our platform reaches a classification success of 0.72 and 0.79 for DNA and RNA binding proteins, respectively. We conclude that excellent performance is achieved by using the default setting of the ProFET workflow. Five of the benchmarks (Supplementary Table S1,) concern structural SCOP datasets, at the class or fold level. The classification success varies according to the tasks. For example, the success for the SCOP 'selected class' is very high (0.820.9), whereas the performance for the fold classification is much lower (0.620.65). Note that SCOP 25% and SCOP 10% tasks use the same dataset (SCOPe version 2.05). These sets differ only by the degree of redundancy removal. We found similar levels of accuracy for both sets. The performance (accuracy, F1 score) for all 17 analyzed datasets with respect to the Dummy-majority classifier is shown (Supplementary).
DiscussionThe main drawbacks in existing sequence-based methods are (i) some functions cannot be detected by sequence-based methods; (ii) current statistical models mostly capture local patterns rather than high-level function and (iii) rare sequences or those that have very few homologs cannot be successfully used for inference or construction of good statistical model.
Compact representationsIn this study, we introduce ProFET as a feature extraction platform that can serve many classification tasks. ProFET was compiled as a flexible tool for any size of protein sequence. Our platform adds to previous studies that use quantitative feature representations forsequences. The communality in these methods is the transformation step in which the protein sequences are converted to hundreds or thousands of features, many of them elementary biochemical and biophysical properties, while others are statistically derived (e.g. frequency of AA and dipeptides). ProFET includes many novel additions for the elementary representation. For example, features that are based on a reduced alphabets, entropy, high performance AA scales, binary autocorrelation, sequence segmentation, mirror k-mers and more. Many of these features not only improved performance while allowing a compact representation but also expose statistical importance properties in proteins (). The advantage of using reduced alphabet has been noted for 3D-structure representation () and more (). ProFET results were the input for ML approaches allowing a rigorous assessment of performance and reaches state of the art results. Recovering the classification success by a small set of top features argues for the power of a compact representation for understanding the features that dominate any specific tasks.
The user perspectiveSeveral conclusions can be drawn from the results of the classification tasks (): A. Protein centric analysis: Feature engineering methods presented in this study should be considered a baseline approach for whole protein rather than protein domains. Most of our knowledge from 3D structure and evolution relies on the properties of domains within proteins. We propose the feature engineering as a complementary approach to the domain-centric one. B. 'One size fits all': Features that are included in ProFET are highly relevant to a broad range of proteins. This is in contrast to methods that customize features for a specific task. The ProFET pipeline provides a default set of features that is suitable for many classification tasks. Therefore, ProFET eliminate the need to duplicate the effort for feature extraction. C. Flexibility of use: Our presented pipeline accepts a single sequence, combined files, multiple files or a directory. It automatically labels the input into classes (if desired) and normalizes the features (if desired). Thus, any user can use ProFET to set the desired combination of features, representations and normalization. From the point of view of the user, several considerations were taken: @BULLET Our pipeline handles FASTA files and stores them as labeled CSVs. @BULLET We use state of art, open source, freely available python data science tools (such as Pandas, scikit-learn, biopython) (). @BULLET Easy to add new features using a standardized format. @BULLET Our framework includes details on the features as part of the data pipeline so results are interpretable. @BULLET Our code is available for academic and non-commercial use, under the GNU 3 license.We provide a large collated resource for feature extraction. Thanks to the modular design of ProFET, adding and tinkering with features is trivial. Users of ProFET can decide to focus, remove or expand any subset of the features (e.g. k-mer lengths). ProFET allows tuning of any number of parameters in the feature generation pipeline, e.g. the AA scales to use and the elementary window size for extracting properties. In addition, features can be extracted locally from the N' terminals or the C'-terminals or from an arbitrary segment of the protein. In summary, the approach presented here is suitable and powerful for application towards modern approach for ML especially in the emerging field of Deep Learning and unsupervised learning of feature representations. These features can easily experimented with allowing additional applications of biological insight to the task of feature engineering.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
D.Ofer and M.Linial at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
