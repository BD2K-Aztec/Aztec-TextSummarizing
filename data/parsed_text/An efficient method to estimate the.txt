Motivation: The biomarker discovery process in high-throughput genomic profiles has presented the statistical learning community with a challenging problem, namely learning when the number of variables is comparable or exceeding the sample size. In these settings, many classical techniques including linear discriminant analysis (LDA) falter. Poor performance of LDA is attributed to the ill-conditioned nature of sample covariance matrix when the dimension and sample size are comparable. To alleviate this problem, regularized LDA (RLDA) has been classically proposed in which the sample covariance matrix is replaced by its ridge estimate. However, the performance of RLDA depends heavily on the regularization parameter used in the ridge estimate of sample covari-ance matrix. Results: We propose a range-search technique for efficient estimation of the optimum regulariza-tion parameter. Using an extensive set of simulations based on synthetic and gene expression microarray data, we demonstrate the robustness of the proposed technique to Gaussianity, an assumption used in developing the core estimator. We compare the performance of the technique in terms of accuracy and efficiency with classical techniques for estimating the regularization parameter. In terms of accuracy, the results indicate that the proposed method vastly improves on similar techniques that use classical plug-in estimator. In that respect, it is better or comparable to cross-validation-based search strategies while, depending on the sample size and dimensionality, being tens to hundreds of times faster to compute. Availability and Implementation: The source code is available at https://github.com/
IntroductionRidge estimation is a type of shrinkage and traces back to the pioneering work of,b) on estimating regression parameters. They considered the standard linear model y  Xb  e ;where y is the n-dimensional observation vector, X is a known n  p matrix, b  b 1 ; b 2 ;. .. ; b p  T is a p-dimensional parameter vector to be estimated, and e is the n-dimensional error vector with mean 0 and covariance matrix r 2 I p. If we assume X is a full (column) rank matrix (p < n), the ordinary least-square solution to this familiar linear model is given by b b  X T X 1 X T y:However, when p > n, the solution (2) does not exist because X T X becomes degenerate. Even the solution obtained by generalized inverse form of matrix X T X is not working well.,b) then formulated a problem in which the residual sum of squares is replaced by its ' 2-penalized form given by L 2 bjjy  Xbjj 2  kjjbjj 2 ;where k > 0 denotes a penalty factor controlling the length of b. Minimizing L 2 b results in the so-called ridge regression given by b b  X T X  kI p  1 X T y:In this way, the inverse of possibly ill-conditioned X T X is stabilized by adding the scalar matrix kI p. This idea was then used by Di Pillo (1976) to replace the estimate of the sample covariance matrix used in linear discriminant analysis (LDA) by its ridge estimate resulting in the so-called regularized LDA (RLDA). The goal is to improve the performance of LDA in situations where dimensionality of observations, p, is larger or comparable to the number of measurements, n. Di Pillo (1979) attempts to determine the optimum value of the optimum regularization parameter in RLDA. On this Di Pillo's study, Peck and Ness (1982) comment that 'He found the analytical solution to this problem intractable, and so used a simulation study to choose an optimum value for k [the regularization parameter]. He concluded that if an algorithm can be found which leads to a value of k near the optimum value, then considerable improvement in the PCC [probability of correct classification] should occur'.suggested the use of cross-validation in finding the optimum value of regularization parameter. In this procedure, cross-validation is used to estimate the true error of RLDA for each value of the regularization parameter selected from a pre-specified set of size 2550. The estimate of the optimum regularization parameter is then the one that results in the minimum cross-validation estimate of true error. Despite the computational complexity of cross-validation in such a search algorithm [e.g. see comments inand Tasjudin and, this approach has remained the most popular method in estimating the optimum value of regularization parameter in RLDAfor instance, seeand Ye and Xiong (2006) to cite just a few articles. Recently, we constructed a generalized consistent estimator of true error of RLDA. In this regard, we proposed an estimator that converges to true error in a double asymptotic sense. In this setting, the estimator converges to the actual parameter in an asymptotic scenario in which dimension and sample size increase in a proportional manner (n ! 1; p ! 1 and p=n ! J > 0) (). In developing this estimator, we assumed that the true distributions governing the data follow multivariate Gaussian model. However, the underlying mechanism to develop the estimator was based on double asymptotics and random matrix theory, both of which suggest applicability of the estimator in non-Gaussian settings as well [see p. xii in, p. 335 in Bai and Silverstein (2010) and. In this work, we employ this estimator of true error in a one-dimensional search to estimate the optimum regularization parameter of RLDA. As such, we employ data taken from seven gene expression microarray studies as well as synthetically generated Gaussian and non-Gaussian data. We compare the performance (in terms of accuracy and efficiency) of the search technique that uses this estimator with similar search schemes that use cross-validation or plug-in estimators. Using an extensive set of simulations, we observe that the proposed technique is an efficient method that can outperform cross-validation and plugin estimate-based schemes in estimating the optimum regularization parameter of RLDA. Throughout this work, we use boldface lower case letters to denote a column vector. A boldface upper case letter denotes a matrix and tr: is the trace operator. The identity matrix of p dimension is denoted by I p .
Systems and methods
RLDA classifierAssume a separate sampling scheme is employed: n  n 0  n 1 sample points are collected to constitute the sample S in R p , where n, n 0 and n 1 are non-random and pre-determined and where S 0  fx 1 ; x 2 ; .. . ; x n0 g and S 1  fx n01 ; x n02 ;. .. ; x n g are randomly selected from populations P 0 and P 1 , respectively. In this two-class problem, a classifier is a function w n : R p ! f0; 1g. If w n is given by w n x  0 if x 2 R 0 and w n x  1 if x 2 R 1 , where R 0 and R 1 are measurable sets partitioning the sample space, then the true error of w n , denoted by e, is defined to be the probability of misclassification,where a i is the prior probability for class i, e i is the error contributed by class i, and f xj0 and f xj1 are the class-conditional densities governing P 0 and P 1 , respectively. Separate sampling is very common in biomedical applications, where data from two classes are collected without reference to the other class, for instance, when discriminating two types of tumors or when distinguishing a normal from a pathological phenotype. With separate sampling, the prior probabilities a i cannot be estimated from the sample, an issue with a long history in the study of LDA (). Both classification rules () and error estimation rules () need to be adjusted for separate sampling rather than use their usual random-sampling definitions; otherwise, they suffer performance degradation. The adjustment requires that a 0 and a 1 be known, as assumption made in this study. In our case, the adjustment is straightforward because it simply means that we directly use a 0 and a 1 rather than their random-sampling estimates n0 n and n1 n : In practice, the salient point is that given n, n 0 and n 1 are chosen so that n0 n is as close to a 0 as possible (). Assuming P i follows a multivariate Gaussian distribution Nl i ; R, for i  0, 1, where R is the common non-singular covariance matrix of both class, replacing the unknown mean and the covariance matrix of classes in Bayes rule (optimum classifier) results in LDA, which is characterized by Anderson's statistics,are the sample means for classes 0 and 1, respectively, and C is the pooled sample covariance matrix,whereIn this work, we consider a form of RLDA classifier that is obtained by using ridge estimators of the inverse covariance matrix in W LDA ; that is, by using I  cC 1 and c > 0; in (6), which yieldswhere H  I p  cC 1 :The designed RLDA classifier is then given bywhere c  log 1a0 a0 .
RLDA true error, optimum regularization and their estimatesThe true error of w RLDA n is given by (5). Given sample S n , for i  0, 1,Under the multivariate Gaussian model, we havewhere U: denotes the cumulative distribution function of a standard normal random variable andD x 0 ;Given training data, the optimal choice of c is the value of c, which minimizes the overall true error e as defined by(5) and (13); to wit, c opt  argmin c e. However, true error depends on unknown population parameters l i and R, which must be estimated from training data. As such, the optimum regularization parameter depends on unknown distributional parameters and must be estimated from data as well. Even with the assumption of knowing the true distributional parameters, c opt is the solution of a non-linear equation that needs to be solved numerically. To see the latter statement and for simplicity of presentation, let a i  1 and a 1i  0, i  0, 1, which means c opt  argmin c e  argmin c e i. By taking the derivative of e i defined in (13) with respect to c, setting the derivative to zero, and after some tedious but straightforward algebraic manipulations we observe that c opt is the unique positive solution of the following equation:where dependency of equation on c is via H defined in (10). The non-linearity of the equation makes a closed form expression of c opt hopeless. As such, a range search strategy is a feasible path forward. The objective in the range search is to determine the c that minimizes the estimate of true error of RLDA. In this regard, a classical estimate of true error is obtained by replacing the unknown parameters by their sample estimate, resulting in standard plug-in estimator of true error, which is given by (It is straightforward to see that for fixed p, as n i ! 1, we have x i ! l i and C ! R, and therefore, b e P iwhereUsing random matrix theory and under double asymptotic conditions, the estimator (17) converges (almost surely) to true error. The double asymptotic conditions are mainly characterized by n 0 ! 1; n 1 ! 1; p ! 1, with the assumption that the following limits exist:Nevertheless, the readers are referred tofor the complete list of conditions used in developing (17). We use the following protocol to estimate c opt using a set of benchmark gene expression datasets and, at the same time, compare the performance of the proposed search strategy based on various estimators of error. The estimators that we use are 5-fold crossvalidation with five repetitions (CV5F-5R), leave-one-out (loo), plug-in (b e P ) available from(16) and our proposed doubleasymptotic estimator b e D i available from(17). The experiments on real data and synthetic data are essentially similar except that in real-data experiments we employ t-test feature selection to reduce the dimensionality to P  50 and P  150.
Protocol (Real Data):@BULLET Step I: Let r denote the ratio of the total number of sample points in class 0 to the total amount in class 1 in the full dataset. Let n Full denote the sample size in the full dataset. Fix a value n < n Full and let it be the number of training sample points that are randomly taken out of the whole dataset such that n  n 0 n 1 with n i being the number of training sample points in class i. We choose n 0  brn 1 c, where b:c is the floor function. This practice resembles a random sampling scheme in which a 0 % n0 n and a 1 % n1 n. Therefore, we use these values of a i to find the overall error rate from(5) and the held-out samples. In order to set aside enough sample points for testing (i.e. the n Full  n held-out sample), we restrict the training sample size to n 2 30; 100 (for synthetic data, we consider n 2 30; 300). @BULLET Step II: For a prescribed value of regularization parameter c in a prescribed range, design the RLDA classifier by (9). We discretize the range with the exponential function 1000 1 10 i for i  f10; 9; 8;. .. ; 10g that covers values from 0.001 to 1000. The above exponential function has been chosen to improve the efficiency of the search. This choice seems to be a reasonable one because a small perturbation in large values of c is a smaller relative change with respect to a similar perturbation in small Optimum regularization parameter: gene expression datavalues of c. This implies that the effect of the former perturbation in changing the true error of the classifier may not be as large as the latter perturbation (although in terms of magnitude both perturbations are the same). In other words, for large values of c having a fine discretization is not as critical as small values. @BULLET Step III: For each value of c in the prescribed set of points, estimate the error of the designed classifier using as estimator of error (CV5F-5R, loo, b e P and b e D ). Obtain the holdout estimate of the true error (taken as the true error) from the test data. @BULLET Step IV: The estimate of the optimum c is the c which results in the smallest error estimate on the prescribed range of c. For the estimated optimum c record the value of true error (available from Step III). @BULLET Step V: Repeat Steps IIV, 500 times for each n and determine the average expected error of RLDA.Optimum regularization parameter: gene expression dataand (r) correspond to Gaussian data and Bayes error  0.332, 0.239, 0.131, 0.066, respectively, whereas (s) and (t) correspond to skewed normal distribution with a 'distance' 2 and skewness factor a  2; 4, respectively (see Supplementary Section S4 for more information on simulations and parameters regarding skew-normal distribution)assumed the Gaussianity of the data, the underlying mechanism to develop the estimator is based on random matrix theory. The universality principle of random matrix theory though suggests applicability of developed estimators in non-Gaussian settings as well. In this work, we conducted an extensive set of simulations using both synthetic and gene expression microarray data to compare the performance of our technique in terms of expected error of the constructed RLDA and the compute time to similar search schemes that use classical error estimators (5-fold crossvalidation with five repetitions, leave-one-out and plug-in estimator). We observe that the proposed technique is tens to hundreds of times faster than cross-validation to compute, while at the same time results in a comparable or better classification accuracy of the constructed RLDA. The good accuracy of the proposed technique on non-Gaussian real data and synthetic data used in this study confirms robustness of the estimator to non-Gaussianity of data. The next natural step in this line of work is to estimate the RLDA regularization parameter that minimizes the area under the ROC curve.
D.Bakir et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Results and discussion Based on the protocols described in Section 2, we have performed a set of experiments employing both synthetic models and gene expression microarray data to examine the performance of the search scheme based on various estimators. First, we consider seven publicly available datasets on breast cancer (van de Vijver et al., 2002), pediatric acute lymphoblastic leukemia (Yeoh et al., 2002), hepatocellular carcinoma (Chen et al., 2004), toxicants response on rats (Natsoulis et al., 2005), diffuse large B-cell lymphoma (Rosenwald et al., 2002), node-negative breast cancer (Desmedt et al., 2007) and acute myeloid leukemia (Valk et al., 2004). Table 1 provides a summary of these datasets, including the total number of genes and sample size. For a description of the data preparation, the readers are referred to Supplementary Section 1. shows the expected true and estimate of error for RLDA classifier as a function of regularization parameter c for different number of sample points ranging from 30 to 100 chosen from datasets listed in Table 1 with p  50 and p  150, respectively. This leaves us with 8 (sample sizes)  7 (datasets)  2 (dimensionalities)112 experiments on real data. As seen in the far right column of these figures, for each sample size, the true error of classifier decreases as a function of c and then increases for increasing c with the optimal c corresponding to the minimum true error at the bottom of the valley. In this regard, in all experiments such a 'peaking phenomenon' occurs in the pre-specified range of c 2 0:001; 1000 with 75% of times (84 out of 112) happening in the range 0:1; 100. Notice that this peaking phenomenon is also observed in curves of estimated errors (columns 13 in Fig. 1 and Supplementary Fig. S1) except for the plug-in estimator, suggesting that plug-in is not a good estimator of the optimum c. Figure 2(an) shows the expected true error of RLDA classifier designed using the estimate of the optimum c (the c that results in the minimum estimated error in Fig. 1 and Supplementary Fig. S1) obtained from various estimators as a function of sample size on each dataset. We observe that an RLDA classifier designed by double asymptotic estimator b e D has a better or comparable performance to RLDA classifiers constructed using plug-in, CV5F-5R and loo estimators. At the same time, we have to note that to compute b e D , we only need to evaluate the closed-form expression presented in (17). Consequently, b e D is tens to hundreds of times faster to compute than cross-validation estimators. To illustrate this point, we have plotted the ratio of average time it takes to compute CV5F-5R and leave-one-out estimators to the time it takes to compute b e P and b e D estimators in experiments related to Chen et al. (2004) (see Fig. 3). The actual average compute time is presented in the Supplementary Section S6. Note that the pre-specified range of c is important to obtain a realistic view of the performance of estimators. For example, if we limit the search range of c to 0:1; 100, then in the Natsoulis' experiment, the classical plug-in estimator b e P , which is not expected to have a good performance in small-sample situations, outperforms all other estimators (see Supplementary Fig. S2). This behavior is because in this dataset for all examined sample sizes the optimum regularization parameter is larger than or close to the upper limit of the range of c 2 0:1; 100. This can be seen from the figure on the third row, fifth column in Figure 1. At the same time in all datasets, b e P points to the upper bound of the range as the estimate of the optimum regularization parameter, which in the Natsoulis' experiment happens to be closer to the actual optimum regularization parameter (see the plot in the third row, fourth column of Fig. 1). We also used synthetic data to compare the performance of estimators in estimating optimum c. Figure 2(ot) shows the results for a wide range of Bayes (optimum) error and p  20 for data taken from Gaussian and skew-normal distributions. For the complete set of results along with the protocol used for synthetic experiments, see Supplementary Sections S4 and S5. In most of experiments on synthetic data, b e D uniformly outperforms other estimators of c. The efficiency of the proposed procedure is a direct consequence of having a closed form for the core estimator that we use in the search. The good performance is due to convergence of the core estimator to true error in a double asymptotic regime. Classically, the notion of statistical consistency guarantees the performance of an estimator in situations where the number of measurements unboundedly increases for a fixed dimensionality (n ! 1, p fixed). In a finite sample operating regime, this implies that in order to expect an acceptable performance from an estimator, we need to have many more sample points than variables. However, in a double asymptotic regime the magnitude of p and n are kept comparable (p=n ! J > 0 with J being an arbitrary number) and, as a result, we generally expect an acceptable performance of developed estimators in a wide range of dimension and sample size. We note that both crossvalidation and plug-in estimators are statistically consistent in a classical sense whereas the core estimator that we use in the search is a consistent estimator in a double asymptotic sense. 4 Concluding remarks A recently proposed estimator of true error of RLDA based on double asymptotics is used in a one-dimensional search to optimize the performance of the classifier in terms of regularization parameter. While in developing the core estimator used in the search we have
