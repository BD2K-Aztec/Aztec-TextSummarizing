Motivation: Completing the genome sequence of an organism is an important task in comparative, functional and structural genomics. However, this remains a challenging issue from both a computational and an experimental viewpoint. Genome scaffolding (i.e. the process of ordering and orientating contigs) of de novo assemblies usually represents the first step in most genome finishing pipelines. Results: In this article we present MEDUSA (Multi-Draft based Scaffolder), an algorithm for genome scaffolding. MEDUSA exploits information obtained from a set of (draft or closed) genomes from related organisms to determine the correct order and orientation of the contigs. MEDUSA formalizes the scaffolding problem by means of a combinatorial optimization formulation on graphs and implements an efficient constant factor approximation algorithm to solve it. In contrast to currently used scaffolders, it does not require either prior knowledge on the microrganisms dataset under analysis (e.g. their phylogenetic relationships) or the availability of paired end read libraries. This makes usability and running time two additional important features of our method. Moreover, benchmarks and tests on real bacterial datasets showed that MEDUSA is highly accurate and, in most cases, outperforms traditional scaffolders. The possibility to use MEDUSA on eukaryotic data-sets has also been evaluated, leading to interesting results. Availability and implementation: MEDUSA web server:
IntroductionThe de novo assembly of short-read sequencing data usually leads to a fragmented set of genomic sequences (contigs). Ordering and orientating such contigs (scaffolding) represents the first, non-trivial step towards genome finishing and usually requires extensive processing and manual editing of large blocks of sequence (). The preferred approach to genome scaffolding is currently based on assembling the sequenced reads into contigs and then using paired-end information to join them into scaffolds. Most of the software based on such approach have several preparatory steps in which read and contig libraries are first converted to a specific format, then mapped against each other by means of an external aligner [e.g. BWA, () or BOWTIE, (and finally used to possibly join contigs together. At the end of this pipeline, a scaffolding graph is usually constructed and a plethora of different methods can be used to analyse the graph and produce the resulting scaffold structure. Currently available methods/software include SOPRA (), SCARPA (), MIP (), Opera (), GRASS () and SSPACE (). A recent survey () analyses and benchmarks most of these recent and sophisticated scaffolding software. The authors showed that, in general, they are not satisfying either in terms of usability or in terms of the quality of the solution, leading to the conclusion that there is still scope for improvements in this area. An alternative approach for scaffolding genomes relies on the use of a complete (closed) reference genome to guide the ordering and the orientating of the contigs. Many available methods exist for mapping (and then scaffolding) the generated draft contigs (). This approach is also used in some specific contexts, such as for ancient DNA fragments reconstruction (), where read information is not available or reliable. These software differ in terms of their overall strategy and implementation but, in general, (i) they allow for only a single reference genome (); (ii) when multiple genomes are allowed, generally these have to be closed and (iii) a reference phylogeny accounting for the evolutionary relationships among the selected taxa is to be provided to guide a multi-reference genomesbased scaffolding (). None of the aforementioned approaches is capable of ignoring all of these constraints that, taken together, represent important practical limitations. Indeed, with the exception of model organisms, reliable closed reference genomes are not always available. Moreover, especially in the case of bacteria, genomic rearrangements among closely related organisms may introduce important structural differences, hampering the scaffolding procedure based on a single genome as reference. Finally, the requirement of a reliable phylogenetic reconstruction can pose a significant challenge, since it is not always straightforward for some bacterial taxa for which the large genetic variability in gene content inside a same species can lead to different phylogenies depending on which molecular marker and/or approach is used. To overcome the difficulties that characterize currently available methods, we developed MEDUSA (Multi-Draft based Scaffolder), an algorithm for scaffolding draft genomes by ordering and orientating a set of de novo obtained contigs and thus speeding up genome finishing. Unlike most of the other software, MEDUSA: (i) formalizes the scaffolding problem by means of a combinatorial optimization formulation on graphs and implements an efficient constant factor approximation algorithm to solve it; (ii) allows for multiple reference genomes to be used during scaffolding; (iii) does not require prior knowledge on the evolutionary relationships (i.e. a phylogenetic tree) among the reference set of organisms and (iv) can handle both draft and complete reference genomes. This latter point is of great importance in practice since, in current public databases, the availability of draft genomes greatly exceeds that of completely sequenced ones (). Moreover, since retrieving the additional information needed by the aforementioned scaffolders can be a challenging task, an algorithm that does not rely on such prior knowledge is of great interest and allows the inclusion of a larger set of genomes for the scaffolding process. The strategy of MEDUSA is based on the intuition that a set of genomes related to the target one can be used for assigning a relative position to each contig, and that this kind of information is easily available in practice. Specifically, those contigs mapping on adjacent regions in these other genomes are considered to be neighbours in the resulting scaffold. MEDUSA formalizes such scaffolding problem as a path cover problem in a graph and solves it with ad hoc optimization techniques. The underlying algorithm has been implemented both in the form of a command line software and a web server. Testing MEDUSA on bacterial and eukaryotic datasets revealed that our software performs very well in comparison to others currently available and answers some of the implicit requests pointed out byin their review, i.e. usability and accuracy of the obtained results.
System and methods
Definitions and notationA contig is a fragment of a source target genome. Let T be the target genome consisting of a set of n contigs c 0 ; :::; c n1 of various lengths. An ordering of T corresponds to finding the true relative positions of the contigs c i in the source sequence. The orientation of a contig indicates which strand of the source sequence it belongs to. We denote the reverse and complement of a contig c by c. By duality, if c belongs to one strand, then c belongs to the other strand. Consecutive oriented contigs in the ordering can be joined into a longer (gapped) supercontig called a scaffold. Informally, the scaffolding problem consists in inferring the order and orientation of the contigs in T. The (ideal) solution of the problem is one scaffold per chromosome of the source DNA sequence. Therefore, if the source DNA sequence contains more chromosomes, then T contains contigs from more than one chromosome, and the solution consists in a set of scaffolds, i.e. in a partial ordering of the contigs of T. Moreover, due to possible errors in the assembly of the sequenced reads, even if the source DNA sequence contains one chromosome, the solution of the problem may be a set of scaffolds. Consider in addition a collection D  fD 0 ; :::; D k1 g of comparison genomes, where D 0 ; :::; D k1 are sets of contigs. Our algorithm is designed to determine a set of scaffolds on T and an orientation of its contigs by making use of the additional information provided by D. Let T and D be given. We map the contigs of T on the contigs of D h , for all D h in D. A contig c i 2 T hits a contig d 2 D h if c i or its reverse and complement c i aligns to d. We call hit the subsequence between the first and the last matching positions of c i on d. We use the software nucmer from MUMMER () to align the contigs of T on the contigs of D h , for all D h in D and recover similar hits. If c i hits more than once the contigs of D h , we call best hit of c i on D h the hit with maximum coverage, and we call first position of the best hit the minimum between the start and end coordinates of the best hit on the contig of D h as assessed by MUMMER. Let us denote the first position of the best hit of c i on D h by p i h. We also define two variables forw i h which is true if c i maps forward and back i h if it maps reverse (Obviously forw i h  :back i h ). Observe that the value p i h is defined if and only if the contig c i hits D h. We make use of two kinds of information in different steps: the first one to determine an order of the contigs and the second to assign an orientation to each of them. Our method is composed of three main computational steps: graph construction, order determination and orientation assignment.
Graph constructionIn the first step, we construct an undirected weighted graph G  V; E as follows. Let us associate a vertex to each contig, regardless of its orientation. Therefore, V  fv 1 ;. .. ; v n g, and we assume that every vertex has associated an index (from 1 to n). We list all the best hits for every contig of the target genome on each contig of any comparison genomes in increasing order of their first positions. If the best hit of c i and the best hit of c j are in the same contig of D h , then p i h and p j h are both defined, and they can be compared. In this case, if p i h < p j h , and there is no l 2 f0; :::; k  1g so that p i h < p l h < p j h , we say that c i and c j are h-adjacent. Let us define Ac i ; c j   fh : c i is h  adjacent to c j g. There is an edge between v i and v j if Ac i ; c j   ;, i.e. E  fv i ; v j  : c i is hadjacent to c j for some h 2 Ac i ; c j g. The weight of an edge is given as wv i ; v j   jAc i ; c j j; since the cardinality of D is k, the weights range from 1 to k. We call Scaffolding Graph the so obtained undirected weighted graph G  V; E.
Order determinationIn the second step, the Scaffolding graph is used to find an order of the contigs. A path in G is a finite sequence of edges which connect a sequence of distinct vertices. A path cover P of G is a set of vertexdisjoint paths P 1 ;. .. ; P s that cover all the vertices of G. In a weighted graph, cover P has total weight wP  P e2P we. From an optimization point of view, a cover can be characterized by two values: s (its cardinality) and w (its weight). The path cover having minimum cardinality in general does not coincide with the cover having maximum weight. This means that it is not possible to optimize both values at a same time. Since edges encode information about contiguity, and the weights support the existence of the edges, a natural choice is to find a path cover of maximum weight. We therefore formulate the problem as follows: given a scaffolding graph G, determine a maximum weight path cover of G. Unfortunately the problem is NP-complete since finding a Hamiltonian path can be seen as a sub-problem. We therefore opted for an approximation algorithm. In, three approximation algorithms are presented having a complexity-performance trade-off. We implemented the most efficient algorithm that gives an approximation of 1=2. The complexity of this method is OjEj  log jEj. The solution is unique if the weights of the edges are all different, but in general, more solutions are possible. This is due to the fact that the order in which the edges with same weight are processed influences the solution. MEDUSA uses a stable sorting for the edges of the graph to output the same solution at every run with same input. Let us consider a path cover solution. The traversal of any path starting from one of its endpoints establishes an increasing total order of the contigs of T in the path. Without loss of generality, we start the traversal of any path from the endpoint vertex with lower index. By duality, starting from the greater index corresponds to traversing the path in the opposite direction, and thus to reading the contigs on the other strand, where the order and orientations of the contigs are reversed. After the order assignment, the cover so constructed can be seen as a set P of directed paths.
Orientation assignmentIn the third step, we take the orientation of the contigs into consideration. Let us first consider any arc hv i ; v j i in a path of P meaning that v i < v j in the order. For every h 2 Ac i ; c j , several relative orientations for c i and c j can occur. Our goal is to determine, relatively to hv i ; v j i, unique orientations for the two vertices. This is done by a majority rule, taking into account the fact that each relative orientation on one strand has a dual on the other one. More precisely, let us define the following quantities: FFi; j  jfh :FBi; j  jfh :BFi; j  jfh :BBi; j  jfh :For the sake of simplicity, we assume that these four values are all distinct (in practice, this is almost always the case). However, it is easy to extend the following procedure to the case in which this assumption is not true (see Supplementary File S1). We denote the orientation of c i (respectively, c j ) relative to the arc hv i ; v j i by tailv i ; v j  (respectively, headv i ; v j ). We then have that tailv i ; v j  is forward if max f FFi; j; FBi; j; BFi; j; BBi; jg 2 fFFi; j; FBi; jg and it is backward otherwise. Analogously headv i ; v j  is then forward if max f FFi; j; FBi; j; BFi; j; BBi; jg 2 fFFi; j; BFi; jg and it is backward otherwise. Consider now two consecutive arcs hv 1 ; v 2 i and hv 2 ; v 3 i in a path. We say that the orientation assignment of c 2 is consistent if and only if headv 1 ; v 2   tailv 2 ; v 3 , that is, if the two arcs propose a consistent orientation for c 2. The orientation for the contigs of T in a same scaffold is given by consistent orientation assignments. In detail, we start to analyse any path in P. We initialize an empty scaffold. Then, if the orientation assignment for any two consecutive arcs is consistent, we add the contigs corresponding to the arcs in the scaffold with the orientation suggested; otherwise, if it is not consistent, we add the vertices of the first arc to the scaffold, then we cut the second arc, and start to traverse a new path. We refer the reader to the Supplementary File S1 for examples on the orientation assignment. Here we point out that in the case in which the maximum among FFi; j; FBi; j; BFi; j; BBi; j is not unique, we can have a multiple assignment for the orientation of v i or v j. In our method, both orientations are considered, thereby reducing possible inconsistency in the traversal of the path for the orientation assignment. This step can be easily carried out, since we treat separately the orientation and the ordering. The complexity of the entire procedure is linear in the number of vertices.
MEDUSA outputThe algorithm then produces a scaffold by merging the oriented contig sequences, using 100 undetermined bases (N) as a spacer. Accordingly, the final output of MEDUSA is a FASTA file, where each sequence represents a scaffold of ordered and oriented contigs separated by stretches of 100 'N's. Alternatively, MEDUSA can infer the distance among the joined contigs based on their distance on the comparison genomes set (see Supplementary File S1 for details on this step). The user can choose between these two options when launching MEDUSA.
Results and discussionIn this section, we present the results we obtained when applying our software to benchmarks (). Two of them were retrieved from the SRA archive database (ECOL, RSPH), the SAUR dataset was obtained from the GAGE benchmark study (), whereas the BCEN and MTUB datasets were obtained from in-house performed Illumina HiSeq sequencing runs with a fragment size of 500 bp. To assess the reliability of the in-house datasets, a quality check was performed using the FastQC suite (available at www.bioinformatics.babraham.ac.uk/projects/fastqc) and calculating the proportion of reads correctly mapping to the assembled contigs. The results obtained (reported in Supplementary File S1) revealed no major issues for these sequencing runs. Information on the main features of the publicly available GAGE reads dataset can be found in. More in detail, we first analysed how MEDUSA performs on real genome scale datasets in terms of errors, completeness and number of reconstructed scaffolds, and how the choice of the draft genomes used for scaffolding influences the results. Then, we compared the performance of MEDUSA with those of five other scaffolders. To evaluate the reliability of the solutions generated by our algorithm, we have chosen real bacterial datasets for which (at least) one whole genome had already been completed, that is 'closed', and used this as a positive reference. From now on we will refer to the following metrics to evaluate the results of our tests: (i) number of correct joins, i.e. the number of true positives (those joins correctly predicted according to the comparison with the corresponding reference genome); (ii) accuracy, the number of true positives divided by the number of proposed joins (i.e. all the joins in the computed solution). For the sake of completeness, it should be mentioned that, unlike the score introduced by, our accuracy index does not include the estimation of the distance among contigs. (iii) recovered information, the number of true positives divided by the expected number of joins; (iv) overall number of reconstructed scaffolds; (v) N50 and NG50 metrics and (vi) total length of joined fragments. Observe that the expected joins correspond to the number of contigs minus the number of chromosomes. Moreover a join between two contigs is considered correct if and only if (i) the contigs are directly consecutive in the genome (no other contig appears in between and they belong to the same replicon) and (ii) the orientation of the two fragments is correct.
Genome-scale datasetsMEDUSA was tested on datasets of genomes from five microbial representatives (), each of which is composed as follows:@BULLET a target genome (the draft genome to be scaffolded). @BULLET a set of draft genomes from (more or less) closely related strains (named comparison genomes) to be used in the scaffolding pipeline of MEDUSA.Except for the SAUR dataset for which we used the contigs from the benchmark work of, for each of the tested datasets, the target genome was obtained from the sequencing reads using ABySS V. 1.3.7 (). Several k-mer values were tried for each dataset. The one leading to the best assembly [as described inwas chosen and used as input for MEDUSA afterwards. Although genome assembly information is not necessary to use our method, we preferred building the target genome from reads to use exactly the same instance as input for the other programs during benchmarking (see Section 3.4). The results of these tests are summarized in. The general goal of reducing the fragmentation of the set of contigs is achieved well. The number of fragments obtained after MEDUSA is applied is significantly smaller than the initial number of contigs. Also, in most cases, the majority of the scaffolds is composed of more than one original contig, that is, is multi-contig. Remarkably, in the case of the MTUB dataset, for which a complete genome (that of Mycobacterium tuberculosis KZNV2475) was available among the comparison ones, the result is a single scaffold with an overall length close to the one of the input draft. It is to be noticed that, when referring to multi-contig scaffolds, we are referring to scaffolds generated by joining two or more original contigs together, without taking into consideration the possible presence of internal breakpoints (usually represented by 'Ns') inside a contig. In other words, the possible gaps in the input contigs (as a result of sequencing ambiguities and/or placed by the de novo assembler) have not been considered in the calculation of the number of multi-contig scaffolds. Finally, tofurther test the robustness of our approach, we also evaluated (i) the influence on the overall scaffolding procedure of contigs with multiple hits among the comparison set, (ii) the reliability of the estimated gap lengths, (iii) the possibility to integrate sequence similarity information between target and comparison contigs when giving a weight to the edges and (iv) the performances of our approach on two eukaryotic datasets, namely Saccharomyces cerevisiae S288c and Drosophila melanogaster. The results of this analysis are reported in Supplementary File S1 (Section 710) and revealed that MEDUSA is capable of producing good results even when trying to scaffold large and complex genomes.
Influence of the taxonomical distanceThe choice of a set of comparison genomes is left to the user and depends mostly on the organism under study. Nevertheless, some guidelines can be extracted from experimental analyses on the present datasets. The results displayed in Tables 37 clarify how the phylogenetic distance between target and comparison genomes influences the scaffolding procedure. We repeated the same test for five different target genomes: Escherichia coli (), M. tuberculosis (), Staphylococcus aureus (), Burkholderia cenocepacia () and Rhodobacter sphaeroides () For each target genome, we have created a series of different sets of comparison draft genomes, in increasing order of phylogenetic distance from the target (from stains belonging to the same species up to strains belonging to unrelated genera). After that, some sets of comparison genomes are created by merging the different groups. These results are interesting for many reasons. First, as expected, the information provided by the comparison drafts tends to decrease with the increase of the distance, and becomes totally insufficient after a certain taxonomical distance (roughly the genus level). The solutions at this level become very poor (the number of scaffolds is close to the initial number of contigs). On one hand, this means that the comparison drafts should be chosen as close as possible to the target. In microbial genomics, this is usually not a problem because some more or less closely related draft genomes are likely to be present for (virtually) each newly sequenced genome. On the other hand, this phenomenon means that the method is robust to noise (false positives are very rare). This aspect is confirmed by the secondset of experiments, where the set of comparison drafts does not belong to a single taxonomic group. Notably, the quality of the scaffolds obtained by adding the whole set of comparison genomes (distant and closer ones) is usually not too far from the one obtained with the closest possible genomes. This means that the user could potentially add many draft genomes, without the risk of introducing much misleading noise. Of course, in the case where the comparison drafts are numerous, the required contig mapping phase (nucmer in our implementation) will sensibly increase the algorithm running time.
Varying the number of draft and complete comparison genomesThe second parameter in the choice of the comparison dataset is the number of reference genomes to use. This aspect has been investigated using the ECOL, MTUB and SAUR datasets. This choice relies on the fact that, for these organisms, a considerable number of complete genomes are available to perform the tests described later. All the available draft and complete genomes from representatives of the M.tuberculosis species were retrieved from the NCBI database, in addition to 50 draft and complete genomes from representatives of the E.coli and S.aureus species. A number of different instances equal to the number of the retrieved genomes for each dataset (N) were built, with an increasing number of comparison genomes (from 1 to N) used during each test. This increase was performed consistently only adding new drafts to the previous set. Since the choice of the order in which the drafts are added could influence the solution, all the tests were repeated 10 times, each time varying the relative order of the comparison genomes. Moreover, since MEDUSA allows mixing closed and draft genomes in the comparison set, we tested how the presence of closed genomes affected the behaviour of the algorithm. To do this, another set of tests was performed using closed genomes instead of drafts in the comparison set. For each dataset, the following values are presented: accuracy (), recovered information () and number of scaffolds (). The results obtained showed a similar trend in all the datasets and for each of the metrics computed. After an initial improvement, the performances (in terms of accuracy, recovered information and number of scaffolds) stabilize with respect to the increase of the number of comparison genomes included in the dataset.N. of comparison genomesN. of comparison genomesThese results suggest that our method is sufficiently robust to noise created by redundant information. Also, the small number of false positives included in the final solutions is confirmed by the extreme stability of the accuracy level, shown in. These considerations are true whether closed or draft genomes are used as the comparison set. With the only exception of the MTUB dataset, the use of closed genomes gives more information and the completeness of the solution is higher. On the other hand, the accuracy in this case is slightly lower. This can be explained by at least two lines of evidence. From a biological viewpoint, complete genomes may embed structural variations (e.g. duplicated and/or inverted regions) that, due to de novo assembly issues, might not be observed in their fragmented draft counterparts. These biological features, in turn, may hinder the scaffolds reconstruction and possibly lead to wrong joins. Moreover, from an informational viewpoint, including complete genomes in the comparison dataset may lead to an increased number of predicted joins and, consequently, to a higher false-positive rate. The choice of the comparison genomes is crucial for evaluating the performance of MEDUSA since the choice of strains phylogenetically related to the target genome is less likely to produce a poor quality graph, eventually leading to better scaffolds and a low number of true positives. However, relatively recent evolutionary events, such as lineage-specific genomic rearrangements, could affect the results of MEDUSA with false-positive adjacencies even when the genomes from strains of the same species of the target are chosen as reference. In such cases, we recommend to use a weighting scheme based on sequence similarity that has been shown to perform better in specific cases (see Supplementary File S1).
BenchmarkingThe performance of MEDUSA was compared with those of five other programs, namely SOPRA V. 1.4.6 (), SCARPA V. 0.241 (), Opera V. 1.4 (), SSPACE V. 3.0 (), RAGOUT V. 1.0 (). The first four of these scaffolders are paired ends-based and the choice to use these specific ones was based on both their performances and their usability as assessed by. The choice to use the recently developed RAGOUT N. of comparison genomesrelies on the fact that it implements an overall strategy that resembles that of MEDUSA, although requiring more input information (phylogenetic tree of the analysed genomes). Options and parameters (e.g. the choice of reads mapper) for each of the paired endsbased methods were selected among those leading to the best performances on genome-scale data as reported in Hunt et al.(see Supplementary File S1). Each paired ends-based software was used both on trimmed (using DYNAMICTRIMMING from the SOLEXAQA package () and Phred 30 as the quality threshold) and untrimmed reads datasets. Indeed reads trimming is usually performed after a sequencing run to remove poor quality bases although, in some cases, it may lead to a loss of information during scaffolding. We here report the values for the option trimmed or untrimmedleading to the best results. With the exception of insert length (that was set to its appropriate value for each dataset), all the other parameters used are reported in Supplementary File S1. As for RAGOUT, the reconstruction of the reference phylogenetic tree was performed using OMA () with default parameters. Importantly, all the results obtained during this benchmarking were double-checked with those obtained using the scripts provided byin their survey. No major differences were observed concerning the performances of the mate pairs-based scaffolders on the selected genome datasets. As indicated by the results of these tests (reported in), the number of scaffolds produced by our algorithm is lower than that produced by all the other four paired end-based scaffolders in all the performed tests. Notably, RAGOUT and MEDUSA produce similar results on each dataset, with the latter leading to a lower number of scaffolds in the BCEN, ECOL and SAUR datasets and both of them leading to a single scaffold with the MTUB dataset. What is particularly interesting is also the high percentage of multi-contig scaffolds over the total number of scaffolds reconstructed by MEDUSA (75%, on average), a crucial aspect since minimization of the number of scaffolds is clearly the final goal of any scaffolding method. As expected, the analysis of the N50 metrics revealed that MEDUSA outperforms all the other paired ends-based scaffolders and produces results that are, in most cases, similar to RAGOUT (see Supplementary File S1). Additionally, in, we report accuracy and recovered information for the software tested herein and for MEDUSA. This comparison revealed that our algorithm produces results that overlap (and, in some cases, outperform) those from other currently available programs, even in terms of reliability of the proposed solution. In conclusion, both the high percentage of true joins recovered and the low percentage of errors observed make MEDUSA very competitive with the other scaffolders in general, including those exploiting a similar strategy (i.e. RAGOUT). It is to be noticed, however, that MEDUSA requires far less information in respect to the aforementioned methods and this greatly increases its usability. Also, MEDUSA performs very well in respect to all the other benchmarked software in terms of required running time. Indeed, all the paired end-based tools generally have long running time due to their reprocessing and read mapping stages and, on our datasets, most of them were unable to complete the scaffolding in <2 h. Despite the fact that RAGOUT processes input files quite quickly (23, 4, 16 and 90 min for the MTUB, RSPH, BCEN and ECOL datasets, respectively), it requires two operations that can be quite time consuming when dealing with a high number of genomes, i.e. computation of orthologous groups of sequences and phylogenetic tree reconstruction. The same datasets were scaffolded by MEDUSA in <10 min, on average.
E.Bosi et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Conclusion and perspectives Draft genome scaffolding is a key step in the finishing stages of microbial genomic pipelines. In this article, we presented MEDUSA, a novel graph theory-based algorithm for scaffolding draft genomes by ordering and orientating their contigs. Unlike traditional software, it does not rely either on paired-end information of sequencing reads or on a phylogenetic distance of the microorganisms used in the analysis. This sensibly increases the usability of our software and, at the same time, reduces the computational time required for genome scaffolding. Using real microbial and eukaryotic datasets, we show that the algorithm implemented in MEDUSA is capable of significantly reducing the fragmentation of draft genomes and, in most cases, of producing less and longer scaffolds in comparison to commonly used scaffolders, while maintaining comparable accuracy and correctness of the predicted joins. Funding B.D. is a recipient of a grant from the European Research Council under the European Community's Seventh Framework Programme (FP7/20072013) / ERC grant agreement [247073]10 SISYPHE. The work described in this publication was financially supported by two PNRA (Piano Nazionale per la Ricerca in Antartide) grants (PNRA 2013/B4.02 and PNRA 2013/AZ1.04). P.C. was supported in part by the Italian Ministry of Education, University, and Research under PRIN 2012C4E3KT national research project. Conflict of Interest: none declared.
