Motivation: Clustering gene expression data given in terms of time-series is a challenging problem that imposes its own particular constraints. Traditional clustering methods based on conventional similarity measures are not always suitable for clustering time-series data. A few methods have been proposed recently for clustering microarray time-series, which take the temporal dimension of the data into account. The inherent principle behind these methods is to either define a similarity measure appropriate for temporal expression data, or pre-process the data in such a way that the temporal relationships between and within the time-series are considered during the subsequent clustering phase. Results: We introduce pairwise gene expression profile alignment, which vertically shifts two profiles in such a way that the area between their corresponding curves is minimal. Based on the pairwise alignment operation, we define a new distance function that is appropriate for time-series profiles. We also introduce a new clustering method that involves multiple expression profile alignment, which generalizes pairwise alignment to a set of profiles. Extensive experiments on well-known datasets yield encouraging results of at least 80% classification accuracy.
INTRODUCTIONAn important process in functional genomic studies is clustering microarray time-series data, where genes with similar expression profiles are expected to be functionally related (). A Bayesian approach (), a partitional clustering based on k-means () and a Euclidean distance approach () have been proposed for clustering time-series gene expression profiles. They have applied selforganizing maps (SOMs) to visualize and to interpret the gene temporal expression profile patterns. A hidden phase model was used for clustering time-series data to define the parameters of a mixture of normal distributions in a Bayesian-like manner that are estimated by using expectation maximization (EM;). Also, the methods proposed inare based on correlation measures. A method that uses jackknife correlation with or without using seeded candidate profiles was proposed for clustering time-series microarray data as well (), where the resulting clusters depend upon the initially chosen template genes, because there is a possibility of missing important genes. A regression-based method was proposed into address the challenges in clustering short time-series expression data. Analyzing gene temporal expression profile data that are non-uniformly sampled and can contain missing values has been studied in. Clustering temporal gene expression profiles was studied by identifying homogeneous clusters of genes in. The shapes of the curves were considered instead of the absolute expression ratios. Fuzzy clustering of gene temporal profiles, where the similarities between co-expressed genes are computed based on the rate of change of the expression ratios across time, has been studied in, the idea of order-restricted inference levels across time has been applied to select and cluster genes, where the estimation makes use of known inequalities among parameters. In, pairs of profiles represented by piece-wise linear functions are aligned in such a way to minimize the integrated squared area between the profiles. An agglomerative clustering method, combined with an area-based distance measure between two aligned profiles, was used to cluster microarray time-series data. Using natural cubic spline interpolations, we re-formulated the pairwise gene expression profile alignment problem ofin terms of arbitrary functions that are continuously integrable on a finite interval, and extended the concept of pairwise alignment to multiple expression profile alignment. Finally, we combined k-means and EM clustering with multiple alignment to cluster microarray time-series data, yielding at least 80% classification accuracy on well-known data.
SYSTEM AND METHODS
Pairwise expression profile alignmentGiven two profiles, x(t) and y(t) (either piece-wise linear or continuously integrable functions), where y(t) is to be aligned to x(t), the basic idea of alignment is to vertically shift y(t) towards x(t) in such a way that the integrated squared errors between the two profiles is minimal. LetyLet Lety(t) be the result of shifting y(t). Here, the error is defined in terms of the areas between x(t) andyand andy(t) in interval. While x(t) andyand andy(t) may cross each other many times, we want that the sum of all the areas where x(t) is abovabov y(t) minus the sum of those areas wher y(t) is above x(t) is minimal (). Let a denote the amount of vertical shifting of y(t). Then, we want to find
N.Subhani et al.(The pairwise alignment that we propose here applies to profiles, that are any integrable functions on a finite interval. Suppose that we have two profiles, x(t) and y(t), defined on the time-interval. The alignment of x(t) and y(t) consists of finding the value a that minimizeswhich is a quadratic function involving a vertical shift factor, a.]dt +2aT .Setting d da f a (x,y) = 0 and solving for a gives(t)]dt.Since d 2 da 2 f a (x,y) = 2T > 0 then a min is a minimum. Thus, there is only a single vertical shift factor that minimizes the integrated squared error. The integrated error between x(t) and the shiftedyshifted shiftedy(t) = y(t)a min is then T]dt +a min T = 0.Given an original profile x(t) =[e 1 ,e 2 ,...,e n ] (with n expression values taken at n time-points t 1 ,t 2 ,...,t n ), in our approach, we use natural cubic spline interpolation, with n knots, (t 1 ,e 1 ),...,(t n ,e n ), to represent x(t) as a continuously integrable functionwhere x j (t) = x j3 (t t j ) 3 +x j2 (t t j ) 2 +x j1 (t t j ) 1 +x j0 (t t j ) 0 interpolates x(t) in interval t j ,t j+1 , with spline coefficients x jk , for 1  j  n1 and 0  k  3. For practical purposes, given the coefficients, x jk , associated with n , we only need to transform x(t) into a new space as x(t) =[x 13 , x 12 , x 11 , x 10 ,..., x j3 , x j2 , x j1 , x j0 ,..., x (n1)3 , x (n1)2 , x (n1)1 , x (n1)0 ] 4(n1). We can add or subtract polynomials given their coefficients, and the polynomials are continuously differentiable. This yields an analytical solution for a min inshows a pairwise alignment, of the two initial profiles in, after applying the vertical shift y(t)  y(t)a min. The two aligned profiles cross each other many times, and the integrated error, Equation (4), is zero. In this example, from Equation (4), the horizontal t-axis will bisect a profile x(t) into two halves with equal areas, when x(t) is aligned to the t-axis. In Section 2.2, we use this property of Equation (4) to define the multiple alignment of a set of profiles.
Multiple expression profile alignmentGiven a set X = {x 1 (t),...,x s (t)}, we want to align the profiles in such a way that the integrated squared error between any two vertically shifted profiles is minimal. Thus, for any x i (t) and x j (t), we want to find the values of a i and a j that minimizewhere both x i (t) and x j (t) are shifted vertically by an amount a i and a j , respectively, in possibly different directions, whereas in the pairwise alignment of Equation (1), profile y(t) is shifted towards a fixed profile x(t). The multiple alignment process consists then of finding the values ofWe use Lemma 1 to find the values a i and a j , 1 i < j  s, that minimize F a 1 ,...,as .In other words,  x j (t) is automatically aligned relative t x i (t), given z(t) is fixed.Proof. This follows immediately from Lemma 1, which shows the property implied by the single vertical shift minimizing the integrated squared error, i.e. TProof. From Corollary 1,, with equality holding when a k = a min k , which is attained by aligning each x k (t) independently with z(t), 1  k  s. From the definition of Equation (7), it follows thatThus, given a fixed profile z(t), applying Corollary 1 to all pairs of profiles minimizes F a 1 ,...,as x 1 (t),...,x s (t) in Equation (7).,...,x s (t)}, there always exists a multiple alignment,, such that
Multiple expression profile alignmentxand, in particular, for profile z(t) = 0, defined by the horizontal t-axis, we havProof. The proof follows from Corollary 1. Since each profile is aligned to a fixed profile, z(t), it implies that we can either align each profile and z(t) individually, or all profiles at a time, implying a 'universal' multiple alignment. We use the multiple alignment of Equation (9) in all subsequent discussions. Using spline interpolations, each profile x i (t), 1  i  s, is a continuously integrable profilewhere,in interval t j ,t j+1 , with spline coefficients x ijk for 1  i  s, 1 j  n1 and 0  k  3. Thus, the analytical solution for a min i in Equation (9) is
Distance functionThe distance between any two piecewise linear profiles is defined as follows:For any function (t) defined on, we also defineThen, from Equations (1) and(3) we haveBy performing the multiple alignment of Equation (9) to obtain new profilesxprofiles profilesx(t) andyand andy(t), we haveThus, d(x,y) 1 2 is the 2-norm, satisfying all the properties of a metric. On the other hand, it is easy to show that d(x,y) in Equation (15) does not satisfy the triangle inequality, and hence it is not a metric. We, however, use d(x,y) in Equation (15) as our distance function, since it is algebraically easier to work with than the metric d(x,y) 1 2 .is closer to the spirit of regression analysis, and thus, we can dispense with the requirement for the triangle inequality.With the spline interpolations of Equation (5), we derived the analytical solution for d(x,y) in Equation (15), using the symbolic computational package Maple 1. Full details can be found in).
Centroid of a clusterGiven a set of profiles X = {x 1 (t),...,x s (t)}, we aim to find a representative centroid profile (t), that well represents X. An obvious choice is the function that minimizeswhere plays the role of the within-cluster-scatter defined in, and the distance between two profiles, x(t) and y(t), is defined in Equation (15). The distance d(,) as defined in Equation (15) is unchanged by an additive shift x(t)  x(t)a in either of its arguments, and hence, is order. Therefore, we haveis the multiple alignment of Equation (9). This is a functional of ; i.e. a mapping from the set of real valued functions defined into the set of real numbers. To minimize with respect to , we set the functional derivative to zero 2. This functional is of the formfor some function L, for which the functional derivative is simply F(d(t). In our case, we have (t)(Setting (t) = 0 givesWith the spline coefficients, x ijk , of each x i (t) interpolated as in Equation(10), the analytical solution for (t) in Equation (20) isin each interval t j ,t j+1 . Equation (20) applies to aligned profiles whereas Equation (21) can also apply to unaligned profiles.
ALGORITHMS
k-means clustering via multiple alignmentOur approach allows us to apply a clustering algorithm such as k-means or EM, which, though not optimal, provide a fast and practical solution to the problem. In k-means (), we want to partition a set of s profiles, D = {x 1 (t),...,x s (t)}, into k disjoint clusters C 1 ,...,C k , 1 k  s; such that (i) C i =,i = 1,...,k;, where  t () = ( t) is the Dirac delta function centered at t.
N.Subhani et al.Also, each profile is assigned to the cluster whose mean is the closest. It assumes that the object features form a vector space. Let U = u ij be the membership matrix u ij = 1 if d x i , j = min l=1,...,k d x i , l ,where i = 1,...,s 0 otherwise (22) The aim is to minimize the sum of squared distances:In k-MCMA (see Algorithm 1), we first multiple-align the set of profiles D, using Equation (9), and then cluster the multiple alignedDaligned alignedD with k-means. Recall that the process of Equation (9) is to pairwise-align each profile with the t-axis. The k initial centroids are found by randomly selecting k pairs of profiles inDin inD, and then take the centroid of each pair. In Step (4.6), we do not use pairwise alignment to find the centroidcentroid centroid i (t) closest to a  x j (t); since, by Lemma 1, they are automatically aligned relative to each other. When profiles are multiple-aligned, any arbitrary distance function other than Equation (15) can be used in Step (4.6), including the Euclidean distance. Also, by Theorem 2 below, there is no need to multiple-alignCalign alignCalignC alignC i in Step (4.7), to update its centroidcentroid centroid i (t).be the centroid of a cluster of m multipleThus, Lemma 1 and Theorem 2 make k-MCMA much faster than applying k-means directly on the non-aligned dataset D. An important implication of Equation (15) is that applying k-means on the non-aligned dataset D (i.e. clustering on D), without any multiple alignment, is equivalent to k-MCMA (i.e. clustering onDon onD). That is, if a profile x i (t) is assigned to a cluster C  i by k-means on D, its shifted profil x i (t) will be assigned to clusterCcluster clusterCclusterC clusterC i by k-MCMA (k-means onDon onD). This can be easily shown by the fact that multiple alignment is order-preserving. In k-means on D, Step (6) would require O(sk) pairwise alignments to assign s profiles to k clusters; whereas no pairwise alignment is needed in k-MCMA. In other words, we show that we can multiple-align once, and obtain the same k-means clustering results, provided that we initialize the means in the same manner. This also, reinforces a known fact demonstrated in; which is a dissimilarity function that is not a metric can be made metric by using a shift operation. In this case, the objective function of k-means does not change, and convergence is assured. Thus, this saves a lot of computations.
EM clustering via multiple alignmentIn this section, we present the EM clustering algorithm combined with the alignment methods. EM is used for clustering in the context of mixture models (). The goal of EM clustering is to estimate the means and covariances for each cluster so as to maximize the likelihood of the observed data distribution. In EM, we want to partition a set of s profiles,,...,k and i = j. Let D be the complete-data space drawn independently from the mixture densityis fixed but unknown and P(C i ) the known posterior probability of class C i. The aim is to maximize the likelihoodWe consider normal distributions,are the means and the covariances of classes, respectively. Both steps iterate until the log-likelihood reaches a maximum. Thus, EM assigns profiles to multiple clusters, as in fuzzy clustering. Also, unlike in k-means, EM assigns each profile to the cluster that finds the maximum posterior probability.
Algorithm 2 EMMA: EM clustering with multiple alignmentRequire: Set of profiles, D = {x 1 (t),...,x s (t)}, and desired number of clusters, kassignxassign assignx j (t) to clusterCcluster clusterCclusterC clusterC i with maximum log-likelihood, forIn EMMA (see Algorithm 2), we first multiple-align the set of profiles D, using Equation (9), and then cluster the multiplealignedDaligned alignedD with EM. Recall that the process of Equation (9) is to pairwise-align each profile with the t-axis. The k centroids can be initialized randomly in Step (3) of EMMA, or by any initialization approach. However, to obtain better clustering results with EMMA, it is necessary to start with near-optimal centroids; thus, we applied), (c) k-MCMA clusters and (d) VCD clusters, with centroids shown.
k-MCMA to generate the k initial centroids inStep (3) (we have also tried different initialization methods but with less success). By Theorem 2, there is also no need to multiple-align a clusterCcluster clusterCclusterC clusterC i in Step (6) of EMMA, for updating its centroidcentroid centroid i (t). Likewise, any arbitrary distance function can be used in Step (6), for computing the centroids. EMMA is not a distance-based clustering method. Nevertheless, the quantities p(x|), p(x|Cx| x|Cx|Care also preserved when the distances are preserved. To conclude this section, we note that all the above theoretical results on Natural Cubic Spline representation of profiles and clustering algorithms that are proposed in the previous section also apply to piecewise linear representations of time-series profiles.
RESULTS AND DISCUSSIONOne of the datasets, the pre-clustered budding yeast genes ofprofiles to cluster microarray time-series data. The profiles are represented as natural cubic spline functions, where the expression measurements are not necessarily taken at regular time-intervals. Four cluster validity indices are used in conjunction with the above methods to determine the appropriate number of clusters and also the validity of the clusters. An objective measure for comparing the k-MCMA and EMMA clusters with the yeast phases is computed by taking the average classification accuracy. EMMA combined with natural cubic spline profiles performs better than piecewise linear profiles, and also outperformed VCD. Our experiments also show that EMMA is able to find better clusters than biologically characterized yeast phases. We finally note that our vertical alignment method is different from the temporal alignment of Bar, where the alignment is horizontal, i.e. it is performed along the time axis to match the time points of one profile to the time points of the other profile, in such a way that the integrated squared error between the horizontally aligned profiles is minimal. Temporal alignment is used for profiles that are either sampled at different time points, have different number of time points, or have different time extents. In the future, we plan to study other distance-based clustering approaches using our multiple alignment method. Other clustering algorithms with multiple alignment, cluster validity indices based on multiple alignment, phase detection by aligning over a portion of the time series expression and studying the effectiveness of our clustering methods in doseresponse microarray datasets can alsobe interesting to investigate. Though our main focus is clustering, the effect of using different imputation methods rather than natural cubic spline in representing the profiles are also worth investigating.
N.Subhani et al.
The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2281 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:47 23/8/2010 Bioinformatics-btq422.tex] Page: 2282 22812288
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:47 23/8/2010 Bioinformatics-btq422.tex] Page: 2283 22812288
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
M phase (31 genes); the phases are visualized in Figure 2a. Another dataset used in the experiments is the Pseudomonas aeruginosa, which contains expressions of the transcriptomes from planktonic clusters at eight different points, from 0 to 48 h (Waite et al., 2006). The clustering methods were also tested on the dataset containing the expressions of the cell-cycle progressions of the fission yeast, Schizosaccharomyces pombe (Peng et al., 2005). This dataset contains 747 genes, representing the expression ratios measured at 14 different time points, for two types of cells, namely, wild-type and cdc25 mutant cells. Setting k = 5, we applied k-MCMA and EMMA on the yeast dataset to see if k-MCMA and EMMA are able to find these phases as accurately as possible. Once the clusters have been found, to compare the clustering with the pre-clustered dataset of Cho et al. (1998), the next step is to label the clusters, where the labels are the 'phases' in the pre-clustered dataset. To measure the performance of k-MCMA and EMMA, we assigned each EMMA cluster to a yeast phase using the Hungarian algorithm (Kuhn, 2005). The Hungarian method is a combinatorial optimization algorithm, which solves the assignment problem in polynomial time. Our phase assignment problem and the complete discussion of the solution can be found in Subhani et al. (2009). In Figure 2, the cluster and the phase of each of the five selected pairs, found by the Hungarian algorithm, are shown at the same level; e.g. cluster C3 of Figure 2bd is assigned to the late G1 phase of Cho et al. (1998) by our phase assignment
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [10:47 23/8/2010 Bioinformatics-btq422.tex] Page: 2286 22812288
