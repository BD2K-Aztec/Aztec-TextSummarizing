Motivation: Detecting modules of coordinated activity is fundamental in the analysis of large biological studies. For two-dimensional data (e.g. genes Ã‚ patients), this is often done via clustering or biclustering. More recently, studies monitoring patients over time have added another dimension. Analysis is much more challenging in this case, especially when time measurements are not synchronized. New methods that can analyze three-way data are thus needed. Results: We present a new algorithm for finding coherent and flexible modules in three-way data. Our method can identify both core modules that appear in multiple patients and patient-specific augmentations of these core modules that contain additional genes. Our algorithm is based on a hierarchical Bayesian data model and Gibbs sampling. The algorithm outperforms extant methods on simulated and on real data. The method successfully dissected key components of septic shock response from time series measurements of gene expression. Detected patient-specific module augmentations were informative for disease outcome. In analyzing brain functional magnetic resonance imaging time series of subjects at rest, it detected the pertinent brain regions involved. Availability and implementation: R code and data are available at
IntroductionIdentifying modules of elements acting in concert is a fundamental paradigm in interpreting, visualizing and dissecting complex biomedical data. For two-dimensional data (e.g. genes versus conditions), clustering is the simplest way to group the elements of one dimension (). Biclustering seeks row and column subsets that manifest similarity (). Such analysis has become standard in computational biology (). Algorithms for finding biclusters differ in how they define (and identify) biclusters (). For example, biclusters were defined as sub-matrices with constant values (), row or column additive or multiplicative values () and submatrices with order preserving values (). Recent studies have extended the idea of biclustering to more complex input structures beyond the standard rowcolumn data (extended the classic Iterative Signature Algorithm (ISA) () to analyze a single matrix of time series data together with prior knowledge on gene function to detect temporal transcription modules that are biologically meaningful. Li and Tuck (2009) introduced an algorithm for joint analysis of ChIP-chip and gene expression data to find biclusters that are likely to be regulated by similar transcription factors.andproposed threeway clustering of gene-condition-organism data. The algorithm ofuses sequence information to integrate data across species, and a post-processing step allows detection of species-specific information.cluster tissues hierarchically and then find the representative gene set of each tissue cluster in the hierarchy. A common data source that calls for three-way analysis is a collection of gene expression profiles measured for a set of subjects over a series of time points. Hence, the data are represented by a V C The Author 2015. Published by Oxford University Press.
i17This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com). For such matrices,presented EDISA, an extension of ISA that handles a time-course vector for each genesubject pair instead of a single scalar. Extant models are limited in their ability to detect a signal that is specific to a particular subject. For example, the set of genes active under one subject in a module may only partially overlap with the gene set of other subjects. Another limitation is the assumption of synchronicity of time points across subjects. Although this assumption is valid for technical repeats or well-tailored experiments, it is less plausible in other situations, e.g. samples taken from patients over time, due to possible heterogeneity in the response of different patients. Here, we introduce a new, flexible definition of a module suitable for three-way data where subjects have entities (e.g. genes) measured over time, but time courses are unsynchronized among the subjects. A core module is defined by a subset of the subjects and a subset of the entities, along with subject-specific subset of the time points. In addition, subjects may have private modules that only partially coincide with the core set of entities. The assumption is that the resulting submatrices will show values markedly different from the whole matrix. A toy example is shown in. We developed a statistical framework and algorithm for analyzing such data. Our framework can detect core modules and for each subject in a core module, a private module with relevant time points. We developed a hierarchical Bayesian generative model for the data and a procedure that aims to fit model parameters for a given dataset. Our algorithm uses a regular biclustering solution as a starting point and then performs iterative improvement using a Gibbs sampling procedure. The algorithm is called TWIGS (threeway module inference via Gibbs sampling). In simulations, we show that TWIGS outperforms standard algorithms even when the core modules have no additional subject-specific signal. When subject-specific signals exist, the ability of extant algorithms to detect the core modules declines markedly, whereas the performance of TWIGS remains high. We demonstrate the advantage of our framework on experimental data from two different domains: gene expression and brain functional magnetic resonance imaging (fMRI) signals. We first analyzed whole blood expression profiles, taken daily for 5 days from 14 patients after septic shock (). TWIGS detected two core modules of up-regulated genes, showing enrichment for different immune system processes. The first was related to response to bacteria, whereas the second was related to regulation of T-cells. Analysis of the subject-specific private modules revealed multiple enrichments that illustrate patient-specific-activated biological processes. Hence, our analysis produced both shared and subject-specific insights, highlighting biological pathways that repeatedly emerge as up-regulated after septic shock, together with additional biological functions particular to each patient. We also analyzed fMRI readings for 20 subjects at rest (). The data for each subject are a matrix of 464 brain regions (parcels) measured over 94 time points at 3 s intervals. Each value in the matrix is the parcel's average blood-oxygen-level-dependent (BOLD) contrast. These levels are indicators of the activity at that region. TWIGS revealed several core modules of highly activated bi-lateral brain regions. Reassuringly, the detected modules were enriched with regions that are known to be active during rest. This analysis shows that our framework is able to detect large functional networks that reappear as activated across subjects and also highlight subject-specific activation patterns.
Methods
The probabilistic modelThe input for our problem is summarized as a 3D matrix Z where Z v;t;s is the activity level of the measured object v 2 1;. .. ; V, at time t 2 1;. .. ; T, for subject s 2 1;. .. ; S. We will say that v and t represent the rows and columns of the matrix and s represents layers. In gene expression data, v represents genes, whereas in fMRI, data v represents brain regions (parcels or voxels). For uniformity, from now on we use for v the term row or voxel. Here, we describe a hierarchical probability model for generating a single module from the distribution of Z. We assume that there is a set of voxels Vf1;. .. ; Vg that tend to have high values jointly in a subset of the subjects. V is specified by the indicator vector H  H 1 ;. .. ; H V , through the relation V  fv : H v  1g. We assume that H v $ Bernoullip VC . Although H marks the rows of the core module, the signal in each specific subject might change. The subject-specific voxel sets are specified by the matrix HS  fHS 1;1 ;    ; HS V;S g, where HS v;s  1 specifies that voxel v participates in the module of subject s. The relation between H and HS is as follows: if H v  1 then HS v;s $ Bernoullip s , otherwise HS v;s $ Bernoullip 0 . We next model the time-series relations. C  C t;s 2 f0; 1g indicates whether the voxel set of subject s is active at time t. We assume PrC 1;s  1  p 1;1. The activity at time t  2;. .. ; T, depends on the time window of size w ! 1 before t. In times t  2;. .. ; w, the time window is 1    t  1. Let C 0 t;s  1, if the time window of subject s right before time point t contains at least one active time point and set C 0 t;s  0 otherwise. We assume that PrC t;s  1jC 0 t;s  0  p 1j0 and PrC t;s  1jC 0 t;s  1  p 1j1. Finally, we assume that for v, t, s for which C t;s  1 and HS v;s  1; Z v;t;s $ F 1 , otherwise Z v;t;s $ F 0. An overview of the model hierarchy is shown in
The Gibbs sampling algorithmOur algorithm starts from a solution produced using a standard biclustering algorithm and then applies iterative improvement steps. In each step, all parameters are fixed except a single one that is sampled according to its conditional probability. The order of parameters matches the subsections below. This order is repeated cyclically k times. The output of the process is the set of sampled values for each parameter in all iterations. We then extract the core modules and the subject-specific modules from this output.(Therefore, the conditional posterior of H v is:On the basis of the equations above, we can calculate the conditional posterior of HS v;s , given that H v  1, through:Similarly, the conditional posterior of HS v;s given that H v  0 can be calculated by replacing every p s with p 0 in the formulas above.(Unlike the equation above, calculating the probability of C 1;s  0 requires breaking the window into two parts. Assume that the time window contains at least one active cell. Let l be the first time point of C 2;s ;. .. ; C w1;s that changes from 0 to 1. Thus:If there are no active cells in C 2;s ;    ; C w1;s , then the calculation reduces to:PrC 1;s  0; C 2;s ;    ; C w1;s ; Z ;1;s j   Finally, the conditional of C 1;s can be calculated by:PrCThe conditional probability of the event C 1;s  0 is computed in the same way.(5) For t 2 2;. .. ; T  1, the value of C t;s is affected by the value of CThus, PrC t;s  1j    can be calculated similarly to the calculations in the previous section.
Setting f 0 and f 1Here, we discuss two options for setting f 0 and f 1 and their hyperparameters: (i) a Bernulli-Beta model for binary data and (ii) a Normal-Gamma model for normal distributions. Let A be the cells within the module (including the core and private parts):In the continuous case, we assume that f 0 is Nl 0 ; r 0  and f 1 is Nl 1 ; r 1 . Under the Normal-Gamma model, the prior distribution for the mean l and the standard deviation r of a normal distribution Nl; r is:The conditional posteriors for Y  y 1 ;. .. ; y n  where for each i, y i $ Nl; r are: 1=rjY $ Gamma1=2  v 0  n;Thus, we apply the model above for A and B, thereby modeling f 0 and f 1 as normal distributions.
Finding multiple modulesTo find a single module, we use a standard biclustering algorithm to produce an initial solution and then use the Gibbs sampler to improve it. The biclustering algorithm is applied on a 2D matrix M obtained by concatenating the layers in Z, i.e. M v;i  Z v;t;s , where i  s  1S  t. In this study, we tested Bimax () and ISA () as the base algorithms. To binarize real-valued data Z to run Bimax, we use a threshold s: we set every value Z v;t;s ! s (< s) to 1 (0). By default, we set s to be the 0.9 quantile of the values in Z. After running the Gibbs sampler, we take the mode of H, HS and C as the solution. By default, all hyperparameters of the Gibbs sampler are set to non-informative priors. This means that the algorithm infers these parameters and thus no tunning is required. To find multiple modules, we tested two previously used heuristics (). In the first (), which we call masker, we run the algorithm iteratively on the residual matrix of Z. The residual matrix is calculated by going over all cells in the module and updating their values in Z. In the binary model, the update rule is to change all module cells to zero. In the normal model, we subtract the mean of f 1 from the value of each cell. The second heuristic, called filter, takes a set of biclusters U as input and produces a reduced set. It first uses the overlap reduction method of Serin and Vingron (2011): initially U 0  ;, then the largest module in U is added to U 0 and all remaining modules with a large overlap with it (we used Jaccard index ! 0:5) are removed from U. The process is repeated until U is empty. Next, we run the Gibbs sampler on the original matrix Z starting with each module in U 0. The result is a set of new modules U 00. Finally, as different modules in U 0 might converge into similar modules in U 00 , the overlap removal process is used again, taking U 00 as input. For both heuristics, we define when to add a module to the final output. When using masker, we add modules until the first time a module is rejected. A module is accepted if it is large enough and the difference jf 1  f 0 j for it is large enough. In the binary case, we set p C1 > 0:5 and in the normal case we set l > 0:3. Setting the minimal module size depends on the application and on the size of the input data. By default, we set the minimal size of a core module to 5 rows and 5 time points (combining all subjects).
Performance measuresIn the results below, we compare algorithms on simulated data. In each case, we compare the known H, HS, C to the algorithm output H 0 ; HS 0 ; C 0 using the Jaccard coefficient. For example, the Jaccard score of H and H 0 is:When the data contain more than one module we use the running max average of all pairwise Jaccard scores. Given the known solution H  H 1 ;. .. ; H k1  and the algorithm output H 0  H 0 1 ;. .. ; H 0 k2  the running max average score is:The same method is used for HS and C.
Results
SimulationsOur simulations setup was as follows. We set V  500, T  50, S  10 and create an initial matrix Z in which all values are zero. We then add modules to Z in which all values are 1 and later add noise according to the tested model (binary or normal). To define a new module, we first need to randomly select the rows and columns of each subject s. Time points are selected randomly with w  1,core module. Then, we add row r to the private module of subject s with probability p 0 s if r 2 fi 1. .. i 20 g, otherwise r is added with probability p 0 0. Adding random noise to the data depends on the tested model. In the binary case, we randomly replace Z v;t;s with 1  Z v;t;s , with probability p w if (v, t, s) belongs to the private module of s and with probability p o otherwise. In the normal model for each (v, t, s) within the private module of s we select e v;t;s $ N0; r w , otherwise we select e v;t;s $ N0; r o . We then add the noise by updating Z v;t;s  Z v;t;s  e v;t;s. We tested scenarios of a single module with and without subject-specific signals and of multiple modules.
Case 1: a single core moduleIn this test, we set p 0 s  1 and p 0 0  0. This case represents the standard biclustering task because there is no subject-specific signal. Thus, biclustering algorithms are expected to achieve high performance. The results are shown inand B. Each algorithm was tested on 10 instances and the average Jaccard score, which quantifies the agreement between the known solution and the algorithm output, is shown. We set high noise levels both in the binary data ()p 0 w  p 0 o  0:25 and in the normal data ()The Bimax algorithm had a low Jaccard score in most cases, since its output covered only a small part of the true bicluster. Although the false-positive rate was very low (<0.01 both for the bicluster rows and columns), the true-positive rate was low as well (<0.25). ISA performed much better, especially in terms of identifying H and HS. Using TWIGS to improve the solution was beneficial: it was able to keep the high performance of ISA for H and HS and to considerably improve the score of C. It greatly improved the Bimax solution in all criteria. For example, in the normal data, the score of C went up from 0.053 to 0.93. The ISA solution improved from 0.63 to 0.95 using TWIGS. Notably, this improvement was achieved with only 50 sampling iterations, which took less than 7 s on average (over simulation repeats). Thus, this boost in performance was achieved at a low cost of running time. We kept this number of iterations also in subsequent analyses. Note, however, that when the data are much larger (e.g. jTj > 1000), the running time could increase to several minutes. We also tested a binary case in which the noise levels were not symmetric: we set p 0 w  0:5 and p 0 o  0:1. The results are shown in Supplementary. In this case, the BimaxGibbs combination reached the top performance in all measurements, with very high scores: 0.92 (H), 0.86 (HS) and 0.93 (C). The performance of both ISA and Bimax was low (all scores were <0.7), indicating that standard algorithms have difficulty in such noise levels.
Case 2: a core module with subject-specific signalIn this test, we set p 0 s  0:9 and p 0 0  0:01. Thus, this scenario is different from standard biclustering and triclustering tasks in two ways: (i) not all shared rows are necessarily part of each private module and (ii) each private module is likely to contain additional rows that are not shared among all subjects. The results (averaged over 10 instances) are shown inand D. The noise levels were p 0 w  p 0 o  0:25 in the binary data) and r 0 w  r 0 o  1 in the normal data (). Similar to Case 1, Bimax had low scores because it typically covered only a small perfect fraction of the module, whereas ISA reached higher performance. However, the performance of ISA was much lower than in Case 1. For example, in the normal data the score of H, which represents the core module rows, dropped from 0.87 in Case 1 to 0.57. This result demonstrates a weakness of standard biclustering algorithms when the data contain subject-specific signal: the algorithms might fail to discover even the shared information. In contrast to ISA and Bimax, TWIGS improved the solution considerably in all measures. For example, the score of H and C was >0.89 when starting with the Bimax solution.
Case 3: multiple modulesHere, we tested the performance of TWIGS with filter and masker on data with five core modules, each with it own subject-specific signals, using as before p 0 s  0:9 and p 0 0  0:01. The results are shown in. As expected, the results were lower than in the single core module tests. Nonetheless, the results were still high in spite of the high noise levels. Unlike the previous cases, using masker with Bimax as the base algorithm was much better than all other algorithms. For example, in the binary case (), it reached scores of 0.86 and 0.8 for HThree-Way module Inference using Gibbs Sampling i21 and C respectively, where all other algorithms had scores below 0.6. In the normal data, we observed a sharp decrease in performance when setting the noise levels to r 0  1 as in the previous sections, see Supplementary. With a bit lower noise levels of 0.75, the results were similar to the binary case (). Interestingly, forcing high mean value in f 1 (i.e. by setting m 0 ! 1 and high p 0 constant in the Normal-Gamma model, see Section 2) achieved higher performance scores. For example, setting the mean value to 1.5 improved the score of H from 0.8 to 0.9 and the score of C from 0.71 to 0.77. We discovered that the non-informative variant had some detrimental instances in which some core modules were grouped together (average number of detected modules was 4.2), whereas enforcing high mean for f 1 detected the correct number of core modules. On the basis of the above results, from this point on, we used the Bimax-Gibbs-masker as the default variant of the TWIGS algorithm.
Gene expression dataWe tested the performance of TWIGS by analyzing transcriptional response of patients to sepsis.monitored patients after septic shock. For up to 5 days after sepsis, blood samples were taken daily, and whole blood gene expression was measured using Illumina microarrays. The dataset contained 14 patients for which five profiles, one for each day after sepsis, were available. Our goal was to detect up-regulated biological functions after septic shock. Therefore, for each subject we calculated the log fold change between time points 2; 3; 4; 5 and the first time point. We binarized the data by setting a threshold of 2 for the fold change (i.e. 1 for the log fold change) and ran masker with Bimax as the base algorithm. See the Supplementary Text for additional analyses using the nonbinarized data and for sensitivity analysis of the binarization threshold. We set the minimal size of the detected core module to 10 rows and 10 columns (number of time points from all patients) and f 1 to have p C1 > 0:5. Using these stop criteria in masker, a single small module of 5 genes was detected over 20 repeats in which we independently and randomly shuffled the values of each row in the input matrix. Two core modules were detected on the real expression matrix. The first covered 11 patients and 53 genes. The second covered seven patients and 62 genes. Four patients were represented in both. Distinct private modules were assigned to each subject in each module. Thus, a total of 20 modules (core or private) were detected in the analysis. GO enrichment analysis [using EXPANDER (detected significant enrichment (0.05 FDR) in 19 of the modules. The two detected core modules differed in their enriched biological functions. The first was highly enriched with genes related to killing of cells of other organisms (P  2:7E  11) and response to bacterium (P  2:2E  9.The second core module was enriched with functions that were more specific to T-cell activity (e.g. regulation of T cell activation P  4:5E  10). Thus, TWIGS identified a fuzzy partition of the subjects into two main branches of the immune system and also pointed out the relevant up-regulated genes. The private modules in the solution were often much larger than the core modules. For example, in the first core module, the private modules of subjects 19 and 24 contained more than 450 genes each. The first core module and the enrichment analysis results of its private modules are shown in. See Supplementaryfor the results of the second core module. Only biological functions that were not significant in the core modules are shown. The figure illustrates how our analysis provides a complementary view to the core modules. That is, although the core modules indicate which biological functions tend to reappear across subjects, the private modules reveal additional enrichments that are sometimes much more specific biologically. For example, the private module of subject 24 was highly enriched with genes related to viral infectious cycle (P  1:7E  9). The network also highlights patients without subject-specific unique enrichments (subjects 30, 46, 49 and 50) and two hubs: subjects 24 and 19. Strikingly, out of the 11 patients covered by this core module, these two patients had much larger private modules and they were the only patients that did not survive the septic shock.collected brain fMRI data from 20 male subjects at rest over 94 time points. In this technique blood flow (BOLD) intensity is measured at every voxel of the brain along time, providing levels of some 100 000 voxels every 23 s. The level reflects the activation intensity of the brain voxel. Standard fMRI preprocessing was applied on the raw data as reported in (). We used a whole brain functional parcellation to transform the data into 517 brain parcels (). Parcels were masked to include gray matter voxels only using the WFU Pick Atlas Tool () and 54 parcels that had 5 gray matter voxels were excluded. For each subject, average BOLD value across all gray matter voxels was calculated within each parcel at each time point. As is standard practicein fMRI analysis (), to reduce the effect of physiological artifacts and nuisance variables, the whole-brain mean signal, six motion parameters, cerebrospinal fluid and white matter signals were regressed out of the parcel signals. The result is a matrix M s for each subject s, in which rows are parcels and columns are time points. We standardized the signal of each row in M s by subtracting the mean and dividing by the standard deviation. This normalization allows us to find relative changes in the activity of brain regions to highlight temporally activated regions (). We ran TWIGS with the normal model, Bimax as the initial solution finder and masker. With non-informative priors, the algorithm converged to large modules with relatively low mean value (<0.5). As we were interested in highly activated brain regions, we reset the mean of f 1 to a high value: we tested l 1  1:5 and l 1  2. As in the simulations, using such prior improved the results considerably since the non-informative variant tended to merge core modules with high mean value. No module was detected when running the algorithm after randomly and independently shuffling each row of the data matrix (20 repeats). Unlike in the gene expression analysis, each subject participated in each core module. For l 1  2 (), four core modules were detected (labeled 1A4A), with an average of 48.5 parcels. For l 1  1:5 (), five core modules were detected (labeled 1B5B), with an average of 66.4 parcels. Out of the five core modules detected using l 1  1:5, four had a parallel core module detected using l 1  2. In addition, modules 1A and 1B maintained similar spatial structure and size and so did 3A and 3B. Modules 2A and 4A were larger than their counterparts. We evaluated the parcel sets of the identified core modules by comparing them to known functional annotations of the brain (). The results show that our analysis detected well-known functional modules that are expected to share common activation patterns both during task and at rest. In both solutions, core module 1 was enriched with regions that are involved in visual processing in the occipital lobe of both hemispheres (q E  11) (). Core module 2B was enriched with parcels located within the ventral attention network, which is involved in bottom-up orienting of attention (q 0:02) (). In both solutions,Three-Way module Inference using Gibbs Sampling i23 core module 3 was enriched with parcels located in regions that are involved in sensori-motor processing (q 1E  11) and in parcels located within regions of the dorsal attention network, which is involved in top-down orienting of attention (q 0:03) (). Modules 4A and 4B were enriched with parcels located in the default mode network (q 1E  4), which is composed mainly of midline structures and is involved in self referential functions that include remembering the past as well as planning the future, and the frontoparietal control network, which is responsible for adaptive behavior (q 1E  7) (). Finally, core module 5B contained 29 parcels and was enriched with regions that are involved in visual processing (q 5E  9) and with parcels that are located within the dorsal attention network (q 0:001). Inspecting the private modules, we observed large heterogeneity in their tendency to overlap with their core module parcels and in the number of time points.and D shows the results for core module 4B. This module is of particular interest as it was enriched with both the default mode network and the frontoparietal control networks. Patterns of co-activation between these two networks have been reported before and suggested to support goaldirected thought processes (). On average, each private module covered 44.4% of the core module parcels () and contained 15.5 time points. In addition, in 18 out of 20 subjects, the overlap between the subject-specific parcels and the core module parcels was significant (hyper-geometric P < 0.001). Other modules had much higher coverage. For example, core module 1B had mean coverage of 64.4% and a larger number of time points (mean 23), see Supplementary. When including the private modules in the enrichment analysis, 15 out of 20 private modules of core module 4B were also enriched with the default mode network. The frontoparietal control network was identified in 12 of the 20 subjects. Although to a much lower extent than in the gene expression analysis, we also detected subjectspecific signal. For example, ventral attention enrichment was identified in 4 out of 20 subjects but not in the core module. This suggests a tendency of these four subjects to engage in bottom-up processing (e.g. be more attentive to sensory stimuli) during goaldirected thought processes. These results demonstrate the advantage of our multi-subject analysis: it was able to detect large functional networks that reappear as activated across subjects and even highlight subject-specific activation patterns.
fMRI data
Comparison to related algorithmsExtant algorithms for three-way data analysis were mainly developed for gene expression data. Triclustering () assumes that a module is a subcube created by one subset in each of the three dimensions. This setting is too rigid for simultaneous analysis of responses in many patients. Figures 4 and 5 show that our modules are not triclusters since the time points and genesimultaneously cluster tissues and genes to produce biclusters, while accounting for three possible time responses for each tissue when introduced to a drug. However, this analysis answers very different questions than TWIGS as it assumes a hierarchical structure of tissue clusters without overlap, whereas we analyze a single tissue over many time points at rest and allow overlapping core modules. We compared TWIGS to seven methods: ISA (), Bimax (), SAMBA (), EDISA (), the plaid model (), sliding window analysis of fMRI data () and modularity analysis of fMRI data (). For each method, we tested a wide range of its internal parameters to fine tune it for the tested dataset. The Supplementary Text provides all details; here we give a brief overview. Our comparison shows that except for modularity analysis (which enforces using all subjects by the method's definition), extant methods have difficulties in finding modules that cover many subjects. TWIGS provides an almost 2-fold improvement in the ability to find modules that cover many patients. For example, on average, modules identified by EDISA on the sepsis data covered less than five patients compared with nine by TWIGS. The sliding window analysis, which estimates the covariance matrix of each time window and then clusters all windows from all subjects, had an average coverage of less than 10 on the fMRI data, whereas TWIGS covered all 20 subjects. TWIGS was comparable to other methods in enrichment analysis for known biological functions in terms of: (i) the total number of covered functions, (ii) the strength of the detected enrichments and (iii) the fraction of modules with enriched terms. When consolidating scores 13 using non-parametric ranking, TWIGS ranked first. When applying the plaid model to the sepsis data, it tended to find much larger gene sets. However, these modules manifested a very mild up-regulation response compared with the TWIGS modules. The fMRI modularity analysis method of Rubinov and) partitioned the brain into clusters, each containing one of our core modules. TWIGS's subject-specific module augmentations provided additional biological results.
DiscussionWe presented a novel problem formulation and algorithm for flexible three-way clustering of multi-matrix time course data. We defined a core module as (i) a set of rows that are likely to be active together across a set of subjects and (ii) a set of active time points in each covered subject. In addition, each core module has subject-specific private modules that can contain additional genes and have high overlap with the core module. The set of active time points of a module can vary in size and times among subjects. Our model is much more flexible than existing models. First, it allows different active time points for each subject, thereby accommodating heterogeneity and asynchrony in the response of different subjects. Second, different subjects can differ in their underlying features (rows) and time points (columns). The row set of a particular subject in a module does not necessarily cover all core module rows. This property was crucial in the analysis of fMRI data, where it allowed discovering core modules that better covered active brain regions. In addition, the row set of a private module can contain additional rows that represent subject-specific signal. This property was crucial in the gene expression case as it allowed discovering patient-specific up-regulated immune processes. We compared TWIGS to seven other methods and showed that extant methods have difficulties in finding modules that cover many subjects, whereas TWIGS easily finds modules that represent a biological function shared by many subjects. In addition, our method outperformed other methods in terms of enrichment analysis. We employed additional metrics for evaluation in each domain. Other comparison criteria can be used in the future, e.g. test-likelihood or perplexity. Our current analysis has some limitations that can be addressed by future studies. First, we assume that the data originated from two distributions f 0 and f 1. Other approaches could be considered, such as row-based or column-based additive models (). Second, our basic model deals with only a single module at a time. More complex models and algorithms could be proposed to directly model multiple modules. Finally, additional tests are needed to fully exploit the abilities of the model. For example, we focused only on testing a time window of size 1 to find homogenous highly activated private modules.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
D.Amar et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
