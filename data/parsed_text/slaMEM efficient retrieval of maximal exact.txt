Motivation: Maximal exact matches, or just MEMs, are a powerful tool in the context of multiple sequence alignment and approximate string matching. The most efficient algorithms to collect them are based on compressed indexes that rely on longest common prefix array-centered data structures. However, their space-efficient representations make use of encoding techniques that are expensive from a computational point of view. With the deluge of data generated by high-throughput sequencing, new approaches need to be developed to deal with larger genomic sequences. Results: In this work, we have developed a new longest common prefix array-sampled representation, optimized to work with the backward search method inherently used by the FM-Index. Unlike previous implementations that sacrifice running time to have smaller space, ours lead to both a fast and a space-efficient approach. This implementation was used by the new software slaMEM, developed to efficiently retrieve MEMs. The results show that the new algorithm is competitive against existing state-of-the-art approaches. Availability and implementation: The software is implemented in C and is operating system independent. The source code is freely available for download at
INTRODUCTIONWith the new high-throughput sequencing technologies becoming faster, cheaper and more accurate, the number of available genomes is growing fast. Metagenomics is also pushing forward the need to align new sequences to those already known to compare different strains or assemblies, build phylogenetic trees, identify new genes, identify mutations or polymorphisms, observe structural variations and perform other relevant operations. It is well known that dynamic programming approaches are prohibitive, both in terms of required memory and processing time, when aligning large genomes or a number of different genomes. To approach these problems, strategies using seeded alignments with shared segments, which are identical among the sequences and act as anchor points for the alignment, have been developed. These anchors can be fixed-length exact matches, or k-mers, as those used in the BLAST () tool. However, this type of match is inefficient because it can lead to an oversized number of hits, and these still have to be extended in both directions using pairwise comparisons, implying a significant processing time. Much more efficient is the identification of maximal unique matches (MUMs) that have been introduced first by). MUMs are identical substrings that occur exactly once in each sequence and whose occurrences cannot be extended to either side without producing a mismatch. The second version of MUMmer () introduced a new more compact suffix tree (ST) representation, and the third and last one () added the ability to output maximal exact matches (MEMs). These are similar to MUMs but can occur any number of times, which is useful when the number of MUMs is insufficient to produce enough anchors for a solid alignment, e.g. when many repeated regions exist. Also, using MEMs instead of MUMs multiplies the regions covered by anchors, reducing considerably the areas requiring further processing. However, the bottleneck of MUMmer is the memory requirements of its ST index structure, which can become problematic when it does not fit into the main memory. Other closedsource tools based on enhanced suffix arrays (ESAs) such as Vmatch () and CoCoNUT () have also been released, but they share the same problem. For this reason, and to deal with larger sequences, other approaches to find MEMs have been developed. The sparseMEM approach () makes use of a sparse SA as an index, which trades memory space for extra computational time. Later, backwardMEM () used a backward search method over a compressed ESA. More recently, essaMEM () improved sparseMEM by enhancing it with a sparse child array that reduces computational time maintaining the same memory footprint. This method currently shows the best tradeoff between time and memory consumption for MEM identification. In this work, we propose another approach as an alternative to these previous tools. We have developed a new sampled representation of the longest common prefix (LCP) array, optimized to work with the backward search method inherent from the *To whom correspondence should be addressed. FM-Index. Results show the effectiveness of the new method for a number of different genomes.
Basic notionsSTs () are fundamental data structures in the field of string processing. However, despite being linear (), their space requirements are large. Consequently, they have been progressively replaced by SAs () and more recently by more space-efficient Burrows Wheeler Transform (BWT) ()-based indexes, namely, the FM-Index (). Although these more advanced indexes work just fine for standard pattern matching, they lack certain functionalities originally present in STs, including the possibility to follow suffix links. To overcome these limitations, other data structures have been proposed, like the ESA (), which extends the original SA with additional information to simulate the behavior of STs. Other alternatives are reviewed in (Navarro and MakinenMakinen, 2007) and (). Let AE  { 1 ,. .. , jAEj } be a finite ordered alphabet, and AE* be the set of all strings over AE, including the empty string ". Let T be a string or text over AE*, which is always terminated by a special character $, which is lexicographically smaller than any character in AE and does not occur anywhere else in T. Let Tdenote the character at position i in T, for 0 i5n, where n  jTj. This way, we define T[i. .. j] as the substring of length (j  i  1) starting at the ith position and ending at the jth position of T, where 0 i j5n. We call T i the ith suffix of T, i.e. the substring T[i. .. (n  1)], with 0 i5n. In the same way, the substring T[0. .. i], 0 i5n corresponds to a prefix of T.
STs and SAsThe ST of T is a rooted tree that represents all the non-empty suffixes of T in the following compact way. Each node has a label corresponding to a substring that occurs in T. The special top node is called the root and corresponds to the empty string. Each internal node has at least two children, and no two children branching from the same node can have labels starting with the same character. Each node can also be identified by its path label, i.e. the string obtained by concatenating all the node labels on the path from the root down to that node. The tree has exactly n leaves, corresponding to the n suffixes of T, where the path label of the ith leaf spells the ith suffix. A suffix link is a pointer that connects a node to its subsequent suffix node, i.e. it associates each node with path label !, such that 2AE and !2AE*, to the node whose path label is !. The SA of T is an array of size n of numbers corresponding to the lexicographical ordering of the n suffixes of T, i.e. a permutation of the integers {0,. .. ,(n  1)} such that T SA5 T SA5.. .5T SA. The SA takes O[n*log(n)] bits of space and can be built using linear time and space (Karkkanen). Taking advantage of the SA as an index structure, a pattern P can be matched in O[m*log(n)] time using binary search. The term !-interval () is often used to denote the interval in the index obtained from matching the string !.
BWT and FM-IndexThe BWT of T is a permutation of the characters of T such that BWTcorresponds to the character preceding the ith lexicographically ordered rotation of T, i.e. BWT T[SA1] if SA6  0 and BWT $ otherwise. If we consider the conceptual matrix M consisting of all the sorted rotations of T, the BWT array corresponds to the last column of M. In the example of, the BWT of the previously illustrated string () is 'TCACCG$GAATAGC'. The BWT array takes O[n*log(jAEj)] space and can be constructed in linear time and space, e.g. using the induced sorting approach from Okanohara and Sadakane (2009), among others. Using the BWT together with some extra information, we can build another index structure called the FM-Index (). One of its key concepts is the Last-to-First column mapping (LF-mapping), which finds, for each position i, the position j such that SA[j]  (SA 1) (mod n). Like the name suggests, it simply maps the kth occurrence of each symbol in the last column L to the kth occurrence of the same symbol in the first column F. In other words, and noting that the BWT is in fact the last column L, if L BWT T[(SA 1)(mod n)]  c is the kth occurrence of the character c in the last column L, then we will have LF j where F T[SA]  c is the kth occurrence of the same character in the first column F. For the example in, LF 12 for character 'T' and LF 5 for character 'C'. The LF-mapping can be efficiently computed by setting: LF C occ(c,i)  1, where: c  BWTCis the total number of occurrences in T of all the characters strictly smaller than c occ(c,i) is the number of occurrences of c in BWT[0 .
.. i]Pattern matching on a pattern P of size m is done in O(m) time according to the BackwardSearch procedure () detailed in the Supplementary Material. The search is performed backward by iteratively applying the LF-mapping rule to obtain the P[i. . .Because the BWT stores characters and not numbers, the FMIndex space requirements of O(n*log(jAEj)) are much lower than those of ST and SA, O(n*log(n)). More specifically, these values are typically $10*n20*n bytes for ST and 5*n bytes for SA, assuming 32-bit integers (Kurtz, 1999).
LCP array and lcp-intervalsThe ESA can simulate all the functionality of the original ST while improving the SA's pattern matching time to O(m), and consists of the basic SA augmented with two additional structures, the LCP array and the lcp interval tree represented by a child table. The LCP of T is an array of numbers with size n that stores the length of the lcp between each suffix and the previous one, i.e. LCP j lcp(T SA, T SA) j for 05i n LCP (1)It can be built in both linear time and space using the SA (). An lcp-interval with lcp-value l is named an l-interval and is denoted by l , where 0 i5j (n1) and the following properties hold: LCP5 l LCP! l for all k with (i  1) k j LCP l for at least one k with (i  1) k j LCP5 l if j 6  (n1)Consequently, if we have an lcp-interval l , this means that the substring T[(SA). .. (SA l  1)] of size l is the longest common prefix between all the (j  i  1) suffixes T SA.. . T SAof that SA interval. Note that because the lcp is calculated between the current SA position and its predecessor, the first position i of an lcp-interval l always has an lcp-value lower than l. In this way, it is sometimes useful to refer to the depth of an interval or a single position, which for an lcp-interval l is always l, but for a general !-interval given by, it can be obtained from the LCP as:Depth()  max{LCP, LCPThe parent interval of an lcp-interval l  [i,j] is an lcp-interval q such that q5l, r i and s ! j, and there is no other lcpinterval of lcp-value t enclosing l  [i,j] such that q5t5l. Therefore, it corresponds to the first larger lcp-interval that encloses l PSV max{k:(0 k 5 i and LCP5 LCP) or k  0} NSV min{k:(i5 k n and LCP5 LCP) or k  n} As their names suggest, the PSV/NSV arrays contain the first position above/below in the LCP array that has an lcp-value lower than the current one, respectively. Because in an lcp-interval l the nearest lcp-values lower than l are located at LCPand LCP, its first enclosing interval will have an lcp-value equal to the higher of these two values. Therefore, the resulting parent interval is defined by:Parent(l )  (LCP)  [PSVSome illustrative lcp-intervals inmake this more clear, e.g. the parent of the 3interval, corresponding to the 'CAG'-interval, is the 2interval corresponding to the 'CA'-interval, and lcp-interval 3has 1as parent, coinciding with the 'GCA' and 'G' intervals, respectively. From the parent/child relations of the lcp-intervals, an lcpinterval tree can also be built to simulate the topography of the ST. Instead of pre-computing and storing the PSV/NSV arrays explicitly, they can also be calculated on the fly using Range Minimum Queries (RMQ) () that rely on other auxiliary data structures. Although many applications exist that use these last two methods, they have not been applied in this work.
LCP array representationsSome direct representations of the LCP include storing each value using only 1 byte with the larger values going in a separate array (), or encoding it with a wavelet. Matrix of all the rotations of the string CAGCAACTGCAGT$ evidencing its BWT, the first and last columns F and L and the counts of each alphabet character c along the BWT in occ(c,i). The last characters of the rotations are grayed out to show the difference from each corresponding suffix i gives the position i in the SA where the text position j is stored, i.e. SA j. This means that if we rearrange the LCP entries in text order rather than lexicographic order, the values decrease by at most 1. From this observation, a new array of size n defined by Hgt (j  LCP[SA 1) and composed entirely of nondecreasing integers can be constructed and stored using only 2n  O(n) bits, with a special data structure used to encode sorted numbers. Given SA j, LCPcan then be derived from Hgt. This method of storing the LCP in text order and not in SA order originated the concept of the permuted longestcommon-prefix array (Karkkanen) defined by PLCP LCP[SA 1]. The major drawback of this approach is that it is dependent on the time needed to retrieve SA[i]  j, which can be expensive when SA is not available explicitly. Another representation of the LCP array is the sampled LCP (SLCP) described in SirenSiren (2010). It introduces the notions of maximal or irreducible values, which satisfy PLCP, and minimal values, if either j  (n  1) or PLCP[j  1] is maximal, i.e. if it is the last value of the array or the last one of a run of decreasing values flanked by a larger value on the right. The LCP is then sampled at these minimal PLCP values, which are as many as the number of equal letter runs in the BWT, and stored in SA order using a bit vector to mark their positions. To retrieve the value of LCP, the (i) function is iterated k times until we fall over a sample, and finally it outputs LCP (LCP[ k (i)]  k). The (i) function is defined as (i)  SA 1 [SA 1], meaning that it is the converse of the LF(i) function but returning the position in the SA of the suffix one text position to the right instead of to the left.
METHODS
SLCP arrayThe main motivation for our sampled version of the LCP is the observation that when performing the backward search over the BWT, if we want to retrieve the parent interval of the current BWT interval through the LCP, PSV and NSV arrays, we only need the values located at the two positions corresponding to both ends of the interval (more accurately, we need the top end and the position next to the bottom end) and not on any of the values in between. Therefore, it suffices to store the data only for positions that correspond to edges of non-singular BWT search intervals instead of storing it for all the positions of the BWT. This can be seen in, where, for example, at the 'AG'-interval, given by 2, we only need the values of the mentioned arrays at positions 7 and 12  11  1. As mentioned before, to be able to retrieve LCP, previous LCP representations need to first perform a series of  steps to compute the value of SA, and in virtually all implementations of compact indexes, the SA array is already stored in some sampled form. Unlike them, our approach does not require this time penalty cost for any supplemental computation of SA or LF values. Because we need to access the LCP array quite often for the purpose of resolving parent intervals, the retrieval of the lcp values should be as fast as possible. Therefore, the efforts in this work have been made in the direction of reducing the LCP space requirements with this SLCP approach, but without making use of any other space-oriented representations that would sacrifice speed, such as representing it with a wavelet tree (). Unlike the sampled version from SirenSiren (2010), our SLCP method takes the positions in the LCP that correspond to the boundaries of the search intervals in the BWT. More precisely, these positions of interest are the ones delimiting BWT ranges with the same depth, i.e. the positions whose lcp value differs from the next one: SLCP  {LCP:i  (n  1) or LCP6  LCP[i  1]}. This is the same as discarding the positions with consecutive equal lcp values, similar to what is done in run length encoding, but without the need to store the length of each run. The rest of the positions, if needed, can be deduced from the sampled ones. We use the terms top corner and bottom corner to refer to the lower value/topmost position and to the higher value/bottommost position of the BWT search interval, respectively. Attending to this, every sampled position is either a top corner or a bottom corner. Formally, the sets of both types of corners are defined by:TopCorners  {i:(i  1) 6  n and LCP5 LCP[i  1]} BottomCorners  {i:(i  1)  n or LCP4 LCP[i  1]}
Sampled smaller valuesWhile calculating parent intervals when executing a BWT search, we only need to perform PSV requests on the higher edge of each interval, i.e. on top corners, and NSV requests on the lower edge, i.e. on bottom corners. Therefore, it is sufficient to keep one single sampled smaller value (SSV) array instead of both PSV and NSV arrays. SSVwill automatically return the value of PSVor NSVif position i corresponds to a top corner or to a bottom corner, respectively. More correctly, SSVWhere i 0 is the number of sampled positions in the interval [0,(i  1)] because SSV does not have the same size as PSV/NSV, as it only stores the sampled positions. Algorithm 1 associates each SLCP position with its corresponding PSV or NSV positions depending on whether it is a top or bottom corner, and stores it in the unified SSV array. It shares some resemblances with the procedure from () to calculate the lcp-interval. Example of a hypothetical section of an index structure showing arrays LCP, PSV and NSV. The sampled values of these three arrays are emphasized in gray. Only top and bottom corner positions are sampled for the LCP. The PSV is only sampled at top corners and the NSV only at bottom corners tree, as the PSV/NSV queries are the basis for the parent/child relationships in the tree's hierarchy. For simplicity, it uses the full LCP and SSV arrays with size n, but it is easy to adapt it to use the sampled versions instead.Algorithm 1 maintains two stacks, one for top corners (line 1) and another for bottom corners (line 2). Each stack stores pairs of values containing the position of the corner in the BWT and an lcp-value. This lcp-value is LCPfor top corners and LCPfor bottom corners, as we are interested in how low the lcp-value was before and how low will it decrease next, respectively. This means the top corners stack stores {i,LCP} and the bottom corners stack stores {i,LCP[i  1]}. At every moment, the set of pairs stored in both stacks is always ordered by increasing positions and non-decreasing lcp-values. To fill the SSV array, the LCP is scanned from top to bottom. When a top corner is found (line 5), it is linked to the previous found top corner (line 6) and added to the stack (line 7) to be later linked to by another top corner. When a bottom corner is found (line 8), all the active previous bottom corners with an lcp-value higher than the current one (line 9) are linked to it and removed from the stack (line 10), as they were already used. This new bottom corner is saved (line 12) to be later linked to the next lower such corner. All the top corners with lcp-value higher or equal than the current bottom corner are also removed from its stack (lines 13 and 14), as these will not have a chance of being linked to anymore. Algorithm 2 allows us to obtain the parent interval of a given interval by relying solely on the sampled arrays, SLCP and SSV. For clarity reasons, the check to ensure that (j 0  1) does not go beyond the size of the SLCP was omitted from the pseudo-code above to facilitate its reading. First, the edge positions of our initial interval in the full arrays, i and j, are translated into positions in the sampled arrays, i 0 and j 0 (lines 1 and 2). At this point, we cannot simply set each corner to its SSV position because we also have to take into consideration the depth of the parent interval. Similarly to the Parent operation on lcp-intervals, we need to check which side of the interval will lead to a higher lcp-value (lines 3 and 7), because the lcp-value of the parent is always max{LCP,LCP[j 0  1]}. The corner displaying this property is expanded and replaced by the corner at its SSV position and the other corner remains unchanged. If both corners share the same value (line 11), they are both updated. Finally, it outputs the parent interval in the BWT along with its destination depth (line 15). In, the illustrated arrows are connecting the top/bottom corners of the child intervals with the top/bottom corners of their parent intervals at their corresponding depths. Note that because intervals with different depths can share one of their borders, these arrows do not necessarily correspond to the destination SSV positions. For example, in the succession of parent intervals 3, 2and 1, the first two share the same bottom corner at position 5, so SSVpoints directly to position 12, the bottom corner of the last one. When we have an interval composed of a single position, we find its parent interval by doing a simple scan in the SLCP for the closest top and bottom corners around that position. Because we use the SLCP instead of the LCP, the search is faster. The boundaries of our target interval are promptly determined by starting at those initial corners and iteratively following the SSV values until the required destination depth is reached. Because in the current context only parent-interval queries are required and we have no need for child-interval queries, this new SSV array replaces the lcp-interval tree and it also eliminates the need for other representations of the ST topology such as balanced parenthesis () or RMQs (). We give the term Sampled Search Intervals from Longest Common Prefixes (SSILCP) to the structure combining the described SLCP and SV arrays. Each interval with no children intervals is of size no larger than jAEj, as there are only jAEj distinct characters (including the terminator character '$') that can be used to extend the common prefix in each suffix, otherwise if at least one of the characters was repeated, it would create a child interval. This means that in each childless interval, we will have at most (jAEj2) un-sampled positions, because we always need one sample for each edge. Therefore, theoretically, the maximum number of positions saved by using the SLCP instead of the full LCP will be of 3*(n/5) for DNA alphabet, which means, at most, a 60% size reduction, although in practice that value will be lower.
Finding MEMsThe MEM searching algorithm is based on the one proposed in Section 4 of () and used in backwardMEM, as theBasically, Algorithm 3 processes the query sequence backward (line 2), and for each intervalfound (line 3), it keeps following parent intervals(line 20) until the length l 0 of the current match is lower than a given threshold minLength (line 11). Because the right-maximality is already assured (lines 47), we check for left-maximality by verifying that each position inside [i 0 ,j 0 ] can no longer be further extended to the left, i.e. if the character to the left in the text, given in the BWT array, is not the same as the character to the left in the pattern (lines 13 and 17). Because each new parent interval [i 0 ,j 0 ] encloses the previous one, only the newly found positions above (lines 1215) and below (lines 1619) are checked. This algorithm runs in O(m  R L  M L *t SA ) time, where m is length of the query sequence, R L and M L are the number of right maximal matches and MEMs, respectively, of size at least L  minLength and t SA is the time needed to obtain a value from the SA, which is constant in our case.
ImplementationThe SSILCP is built from the full LCP, presenting a variable sampling rate of $1.2 based on the test results of, and is used as a replacement for both the LCP and the PSV/NSV arrays. Following the same idea as in (), based on the observation that the vast majority of the values in the LCP array are small, the lcp values 5255 are stored using 8 bits per number, while the remaining values go into a complementary table containing only larger numbers. We also use an additional space-saving trick based on the fact that most of the PSVand NSVvalues do not jump too far away from its position i. Therefore, the SSV array can also take advantage of a similar approach as the LCP array by storing the differential values between the source and destination positions, with negative values representing PSV jumps and positive values NSV jumps. Now the values represented using only 8 bits are within the range from 127 to 127. To comply with the most commonly used computer memory architectures, the SA array coupled to the FM-Index uses a fixed sampling rate of 32. Further details about the index and SSILCP implementations are available in the Supplementary Material. All algorithms and data structures have been developed from scratch without relying on any other existing code base.
RESULTS
DatasetsAs test suites, we have chosen two real-life scenarios that feature significantly sized genomes. The first dataset is constituted by two species of the fruit fly, Drosophila melanogaster and Drosophila yakuba, with 162 and 163 Mbp, respectively, as this setting was also featured in the publications of every other tested tool. The second dataset includes the complete genomes of Homo sapiens, build 19 (HG19) (), and Mus musculus, build 10 (MM10) (), with 3.1 and 2.7 Gbp, respectively. The chosen references for each dataset were D. melanogaster and HG19. Specific LCP-related characteristics for each one are depicted in. Using this new SSILCP data structure, we get O(1) time for LCP and parent operations. It also scales linearly with the size of the reference genome. The space requirements are typically around 2.2*n bytes for practical applications on DNA according to the tests presented in the second last row of, consuming $19% of the space we would have used by storing the full LCP, PSV and NSV arrays in the navenave way.Note: The reference genome size considers {A,C,G,T} chars only. Samples with an lcp value 4254 and SV samples with an absolute value 4127 are considered oversized. The maximum lcp value indicates the length of the largest repeat present in the genome. The full SSILCP size accounts for the SLCP and SSV arrays and all the supporting data structures, excluding the FM-Index. MB, Megabyte; Mbp, Mega base pair. reducing the time complexity by removing the log(n) term while maintaining a similar memory usage of (9/K  1)*n bytes. backwardMEM uses an enhanced compressed SA supported by a BWT encoded as a wavelet-tree and adapted existing MEM locating algorithms to work with backward search. It features a balanced parentheses representation of the lcp-interval tree capable of constant time parent interval queries. Its memory requirements are $(4/k  2)*n bytes in practice. When available, the tools were given different SA sampling values of powers of 2 ranging from 1 to 32, using the run-time parameter '-k' in sparseMEM and essaMEM and the compiletime flag 'BWTK' in backwardMEM. All tools were run with the same parameters '-maxmatch-n-l L' to report all MEMs, with minimum length L  50 for the Drosophila dataset and L  100 for the human/mouse dataset. The source code of each tool was edited to launch a process in the background that starts collecting the time and memory values right after the data structures were built and just before the actual MEM finding algorithms take place. Because each tool uses different index structures and different construction algorithms that would be difficult to compare as a whole, this allows the benchmarks to reflect the MEM retrieving efficiency only.
Tested programs
BenchmarksTime corresponds to the elapsed real time and memory to the maximum physically resident memory, fields 'etime' and 'rss', respectively, in the Unix system command 'ps', and measured using the 'memusgpid' script included in the source package. All tests were run on a Linux server machine featuring an Intel Xeon CPU clocked at 2.13 GHz with 256 GB of RAM and 64 cores, but none of the tools was run with multi-threading options. The results are presented inand Figures 6 and 7 and detailed in the Supplementary Material. Because all the tools only index the reference genome, the used memory is determined by the reference size, with the addition of the currently loaded query. As the results show, slaMEM's approach consumes $3.3*n bytes in practice. In the Drosophila dataset, it uses approximately the same memory as backwardMEM and sparseMEM, both with a sampling value of 32, while being almost 7 times faster than backwardMEM and 25 times faster than sparseMEM. Therefore, between the two backward searching-based methods, slaMEM achieves the best performance. It is only outperformed in terms of memory by essaMEM with K  16 and K  32, while still running slightly faster. Compared with the un-sampled approach used in MUMmer, slaMEM runs in half the time and uses almost four times less space. In the human/mouse dataset, MUMmer, backwardMEM and essaMEM with K  1 all failed or crashed possibly due to the use of signed integer variable types, which do not support arrays with sizes larger than 2 billion positions. Theoretically, for a comparable memory usage, slaMEM is equivalent to a sampling rate of K  6 in the sparse methods and still almost 8 times faster than the closest test results (K  4 and K 8). The best time/memory ratio belongs to essaMEM. Nevertheless, slaMEM achieves the fastest running times among all the tested tools and sampling values in both datasets.
CONCLUSIONSAn algorithmic improvement that can be further explored is based on the observation that on applications that involve pursuing parent intervals only when a mismatch occurs, e.g. matching statistics () or super-maximal matches (), we only need to retrieve parent intervals when the current BWT search interval does not include at least one of the letters of the alphabet, which might be the one we were interested in following backward. This way, the SSILCP memory requirements can be lowered even further by ignoringNote: Only MEMs with size at least 50 and 100, respectively, have been considered.
The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
slaMEM at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
F.Fernandes and A.T.Freitas at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
MUMmer builds an ST for the reference using the compact representation from (Kurtz, 1999) that requires $15.4 bytes per input character and streams the query sequences against it. sparseMEM indexes the reference with a sparse SA and uses the LCP and SA 1 arrays to simulate suffix links, which are essential to accelerate the computation of MEMs in that data structure. Its time complexity is O(m*log(n)  q) for a reference of size n, query of size m and q dependent on the sparseness factor and minimum matches length. A sampled SA approach keeps all the suffixes of the text but only stores each kth entry of the SA array, whereas the sparse SA approach only maintains each Kth suffix of the text and their corresponding SA entry. essaMEM works over an enhanced sparse SA that replaces the SA 1 array of sparseMEM with a sparse child array, greatly
F.Fernandes and A.T.Freitas at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from the samples for LCP intervals that contain all the DNA letters. slaMEM could also take advantage of multi-threading to speed up computation by processing many queries or parts of the same query in parallel. Furthermore, by extending the current implementation to support some missing ST operations, the combination of the FM-Index with the SSILCP could be used as a full compressed ST representation. We observed that because the boundaries of non-unitary BWT search intervals can only fall in certain positions, it is enough to sample the LCP, PSV and NSV arrays at those specific positions. Therefore, we engineered the SSILCP specifically to closely wrap around the string matching mechanism that characterizes the FM-Index. This added ability to the index enables faster parent interval queries, which makes it especially useful for calculating matching statistics and maximal exact matches, where its absence would otherwise render the MEM retrieval algorithm impractically slow. Unlike other representations of the LCP, ours does not depend on the calculation of any previous SA or LF values, resulting in a strategy with a good space/time tradeoff to replace both the LCP array and the lcp-interval tree. Results on real data show that, for this application, our new combined SLCP and PSV/NSV representation proves to be a competitive approach against other equivalent structures such as the lcpinterval tree, thus making slaMEM a useful backbone for any project in the field of comparative genomics that relies on MEMs.
