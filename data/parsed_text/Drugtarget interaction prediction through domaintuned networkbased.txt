Motivation: The identification of drug–target interaction (DTI) represents a costly and time-consuming step in drug discovery and design. Computational methods capable of predicting reliable DTI play an important role in the field. Recently, recommendation methods relying on network-based inference (NBI) have been proposed. However, such approaches implement naive topology-based inference and do not take into account important features within the drug–target domain. Results: In this article, we present a new NBI method, called domain tuned-hybrid (DT-Hybrid), which extends a well-established recommendation technique by domain-based knowledge including drug and target similarity. DT-Hybrid has been extensively tested using the last version of an experimentally validated DTI database obtained from DrugBank. Comparison with other recently proposed NBI methods clearly shows that DT-Hybrid is capable of predicting more reliable DTIs. Availability: DT-Hybrid has been developed in R and it is available, along with all the results on the predictions, through an R package at the following
INTRODUCTIONDetecting and verifying new connections among drugs and targets is a costly process. From a historical point of view, the pharmaceutical chemist's approach has been commonly focused on the development of compounds acting against particular families of 'druggable' proteins (). Drugs act by binding to specific proteins, hence changing their biochemical and/or biophysical activities, with many consequences on various functions. Furthermore, because proteins operate as part of highly interconnected cellular networks (i.e. the interactome networks), the 'one gene, one drug, one disease' paradigm has been challenged in many cases (). For this reason, the concept of polypharmacology has been raised for those drugs acting on multiple targets rather than a single one (). These polypharmacological features of drugs bring a wealth of knowledge and enable us to understand drug side effects or find their new uses, namely, drug repositioning (). Nevertheless, many interactions are still unknown, and given the significant amount of resources needed for in situ experimentation, it is necessary to develop algorithmic methodologies allowing the prediction of new and significant relationships among elements interacting at the process level. In the literature, several computational tools have been proposed to afford the problem of DTI prediction and drug repositioning. Traditional methods rely either on ligand-based or receptorbased approaches. Among ligand-based methods, we can cite quantitative structure-activity relationships, and a similarity search-based approach (). On the other hand, receptor-based methods, such as reverse docking, have also been applied in drugtarget (DT) binding affinity prediction, DTI prediction and drug repositioning (). However, the latter have the shortcoming that cannot be used for targets whose 3D structures are unknown. Recently, much attention has been devoted to network-based and phenotype-based approaches. Most of these methods rely on the successful idea of using bipartite graphs. In, a bipartite graph linking US Food and Drug Administration-approved drugs to proteins by DT binary associations is exploited.identified new DTIs using side effect similarity.make use of transcriptional responses, predicted and validated new drug modes of action and drug repositioning. Recently,have presented drug repositioning methods exploiting public gene expression data. Furthermore,developed a bipartite graph learning method to predict DTI by integrating chemical and genomic data.present a technique based on network-based inference (NBI) implementing a naive version of the algorithm proposed by. All these results clearly show the good performance of this approach. On the other hand, knowledge about drug and protein domain is not properly exploited. vanuse a machine learning method starting from a DTI network to predict new ones with high accuracy. The calculation of the new interactions is done through the regularized least squares algorithm. The regularized least squares algorithm is trained using a kernel (GIPGaussian interaction profile) that summarizes the information in the network. The authors developed variants of the original kernel by *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com taking into account chemical and genomic information. This improved the accuracy, in particular for small datasets.introduced their Network-based Random Walk with Restart on the Heterogeneous network (NRWRH) algorithm predicting new interactions between drugs and targets by means of a model based on a random walk with a restart in a 'heterogeneous' network. The model is constructed by extending the network of DTI interactions with drugdrug and proteinprotein similarity networks. This methodology shows excellent performance in predicting new interactions. However, its disadvantage is due to its random nature, mainly caused by the initial probabilities selection.proposed the Bipartite Local ModelInteraction-profile Inferring (BLM-NII) algorithm. Interactions between drugs and targets are deduced by training a classifier (i.e. support vector machine or regularized least square). This is achieved by exploiting interaction information, drug and target similarities. This classifier is appropriately extended to include knowledge on new drug/target candidates. This is used to predict the new target probability of a specific drug. The algorithm is highly reliable in predicting interactions between new drug/target candidates. On the other hand, its capability of training several distinct classifiers to obtain the final model is not strong enough. In this present article, we propose a novel method called domain tuned-hybrid (DT-Hybrid). It extends the NBI algorithm proposed inand applied in Cheng et al.(2012) by adding application domain knowledge. Similarity among drugs and targets is plugged into the model. Despite its simplicity, the technique provides a complete and functional framework for in silico prediction of drug and target relationships. To demonstrate the reliability of the method, we conducted a wide experimental analysis using four benchmark datasets drawn from DrugBank. We compared our method with the one proposed by. The experiments clearly show that DT-Hybrid overcomes the problems shown by the naive NBI algorithm, and it is capable of producing higher quality predictions.
METHODS
AlgorithmThe method we propose is based on the recommendation technique presented byand extended by. Let X  x 1 , x 2 ,. .. , x m f gbe a set of small molecules (i.e. biological compounds, molecules), and T  t 1 , t 2 ,. .. , t n f ga set of targets (i.e. genes, proteins); the X-T network of interactions can be described as a bipartite graph G X, T, E  where E  e ij : x i 2 X, t j 2 T   . A link between x i and t j is drawn in the graph when the structure x i is associated with the target t j. The network can be represented by an adjacency matrix A  a ji   nm, where a ji  1 if x i is connected to t j ; otherwise, a ji  0.proposed a recommendation method based on the bipartite network projection technique implementing the concept of resources transfer within the network. Given the bipartite graph defined above, a two-phase resource transfer is associated with one of its projections: at the beginning, the resource is transferred from nodes belonging to T to those in X, and subsequently the resource is transferred back to the T nodes. This process allows us to define a technique for the calculation of the weight matrix (W  w ij   nn) in the projection as follows:where  determines how the distribution of resources takes place in the second phase, and k x   is the degree of the x node in the bipartite network. By varying the  function, we obtain the following algorithms (Given the weight matrix W and the adjacency matrix A of the bipartite network, it is possible to compute the recommendation matrix R  r ij   nm by the product:For each x i in X, its recommendation list is given by the set R i  t j , r ji   j a ji  0   , where r ji is the 'score' of recommending t j to x i. This list is then sorted in a descending order with respect to the score because the higher elements are expected to have a better interaction with the corresponding structure. Notice that the method described above does not make use of any previous biological knowledge of the application domain. Here we propose the DT-Hybrid algorithm, which extends the recommendation model by introducing: (i) similarity between small molecules (i.e. molecular compounds), and (ii) sequence similarity between targets. Let S  s ij   nn be the target similarity matrix [i.e. either BLAST bits scores () or Smith-Waterman local alignment scores (. This information can be taken into account by using equation (1) with  i, j   defined as in row 4 of. Including structural similarity requires more effort. Therefore, it is necessary to manipulate such information to obtain a variant of the S matrix, and simplify the computation of the equation (1).This matrix can be linearly combined with the target similarity matrix S,where is a tuning parameter. This additional biological knowledge yields faster computation and higher numerical precision. The matrix defined by equation (4) inDrugtarget interaction prediction connection with equations (1) and (2) allows the prediction of recommendation lists.
Datasets and benchmarksWe evaluated our method using four datasets () containing experimentally verified interactions between drugs and genes. We analyzed the performances of NBI [equation (1) using (i,j) in, row 1], Hybrid [equation (1) using (i,j) in, row 3] and DTHybrid [equation (1) using (i,j) in, row 4]. The datasets were built by grouping all possible interactions between genes and drugs (DTI) based on their main gene types: enzymes, ion channels, G-protein coupled receptors (GPCRs) and nuclear receptors (). The following similarity measures have been used: (i) SIMCOMP 2D chemical similarity of drugs (), and (ii) Smith-Waterman sequence similarity of genes (). Similarities have been normalized according toS norm i, j    S i, j   ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi S i, i  S j, j   p : 5Results are evaluated by combining the methods presented byMore precisely, we applied a 10-fold cross-validation and repeated the experiments 30 times. Notice that, the random partition used in the cross-validation could cause isolation of nodes in the network on which the test is performed. Because all the tested algorithms are capable of predicting new interactions only for drugs and targets for which we already have some information, we computed the partition so that for each node, at least one link to the other nodes remains in the test set. According to, the following four metrics were considered: precision and recall enhancement, recovery, personalization and surprisal. Precision and Recall Enhancement, e P L   and e R L  . Quality is measured in terms of the top L elements in the recommendation list of each biological structure. Let D i be the number of deleted interactions recovered for drug i, and let D i L be its position in the top L places of i's recommendation list. The average precision and recall for the prediction process can be computed as follows:where m 0 is the number of structures with at least one deleted link. A better perspective can be obtained by considering these values within random models P rand L   and R rand L  .If the structure i has a total of D i deleted interactions, then. Consequently, averaging for all structures we obtain P rand L    D=n  m, where D is the number of links in the test set. On the other hand, the average number of links deleted in the first L positions is given by LD i = n  k i    %LD i =n. Again by averaging for all structures, R rand L    L=n. Given these random models, it is possible to compute the precision and recall enhancement as follows:Finally, as opposed to the recommendation on social systems, the three other metricsrecovery, personalization and surprisalare not so significant in drugtarget systems. For this reason, we report the details of such metrics (their definitions together with the experimental results), just for completeness, in the Supplementary Materials.
RESULTSIn this article, we propose a method called DT-Hybrid, which extends NBI () and the Hybrid () algorithms by integrating previous domain-dependent knowledge. Experiments show that this extension improves both algorithms in terms of prediction of new biologically significant interactions. In the supporting materials, we report a comprehensive analysis of DT-Hybrid and Hybrid, together with their behavior varying the (only for DT-Hybrid) and parameters.illustrates the result of comparing NBI, Hybrid and DT-Hybrid in terms of precision and recall enhancement. DT-Hybrid clearly outperforms both NBI and Hybrid in recovering deleted links. It is important to point out that hybrid algorithms are able to significantly improve recall (e R ) measuring the prediction ability of recovering existing interactions in a complex network.illustrates the receiver operating characteristic (ROC) curves calculated over the complete DrugBank dataset. Simulations were executed 30 times, and the results were averaged to obtain a performance evaluation. Experiments show that all three techniques have a high truepositive rate against a low false-positive rate. However, hybrid algorithms provided better performance than NBI. In particular,clearly shows an increase of the average areas under the ROC curves (AUC) in the complete dataset (a detailed analysis can be found in the supporting materials section). This indicates that hybrid algorithms improve the ability of discriminatingNote: The sparsity is obtained as the ratio between the number of known interactions and the number of all possible interactions.Note: For each algorithm the complete DrugBank dataset was used to compute the precision and recall metrics, and the average area under ROC curve (AUC). The parameters used to obtain the following results are  0:7, and  0:8. Values are obtained using the top-20 predictions. Bold values represents best results. known links from predicted ones. The increase of the AUC values for the DT-Hybrid algorithm demonstrates that adding biological information to prediction is a key choice to achieve significant results.demonstrates that exploiting biological information leads, in most cases, to a significant increase of the adjusted precision and recall.illustrates the ROC curves calculated on the enzymes, ion channels, GPCRs, and nuclear receptor datasets using the top-30 predictions. Finally, it can be asserted that adding similarity makes prediction more reliable than an algorithm, such as NBI, which applies only network topology to score computation. Indeed, using only known interactions of a new structure without any target information makes it impossible to predict new targets for this drug. This weakness is a problem for all methods based on recommendation techniques. The introduction of new biological structures is equivalent to the addition of isolated nodes in the network, whose weight, based on the equation (1), is always zero. Such a weight, ultimately, leads to the impossibility of obtaining a prediction for this new molecule. Another important feature of the DT-Hybrid algorithm that we would like to highlight is its ability of increasing performance by keeping computational complexity acceptable. The asymptotic complexity of the NBI algorithm is O n 2 m   , whereas that of DT-Hybrid is O n 2 m  m 2     . However, parallelization and optimization techniques can be easily applied to speed computation. We investigated the dependence of DT-Hybrid prediction quality with respect to the and parameters (see the supporting materials for the details). Results show that we cannot discern a law that regulates the behavior of the metrics based on the values of these parameters. They depend heavily on the specific characteristics of each dataset, and therefore require a priori analysis to select the best ones. In the reported results, we made such analysis before to run our experiments to establish the parameters yielding the best results in terms of precision and recall enhancement. Finally, notice that our analysis has shown an increase in the precision, recall and AUC, neglecting other metrics, such as recovery, personalization and surprisal. This was done because the latter measure only the capability of analyzing the structure of an interaction network without evaluating the biological significance of predictions.
CONCLUSIONDT-Hybrid is a technique proposed for the prediction of new interactions between small molecules. Thanks to the domain-dependent additional knowledge, it clearly outperforms the NBI algorithm for DTI prediction. DT-Hybrid integrates biological knowledge and the bipartite interaction network into a unified framework. This yields high quality and consistent interaction prediction, allowing a speedup of the experimental. Comparison of DT-Hybrid, Hybrid, and NBI through the precision and recall enhancement metric, and the average area under ROC curve (AUC) calculated for each of the four datasets listed inPrecision enhancementNote: The results were obtained using the optimal values for and parameters as shown in the supporting materials. We set for both Hybrid and DT-Hybrid  0:5. Concerning the parameter, we have the following setting: enzymes  0:4; ion channels  0:3; GPCRs  0:2; nuclear receptors  0:4. Bold values represents best results.
2007Drugtarget interaction prediction verification activity. Finally, thanks to the hybrid approach, the algorithm overcomes numerical instability that we experienced in the NBI algorithm in presence of particular datasets (i.e. highly sparse).
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
S.Alaimo et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
