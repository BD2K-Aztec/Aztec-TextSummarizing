Motivation: Coexisting in a DNA system, meiosis and recombination are two indispensible aspects for cell reproduction and growth. With the avalanche of genome sequences emerging in the post-genomic age, it is an urgent challenge to acquire the information of DNA recombination spots because it can timely provide very useful insights into the mechanism of meiotic recombination and the process of genome evolution. Results: To address such a challenge, we have developed a predictor, called iRSpot-EL, by fusing different modes of PseKNC (pseudo K-tuple nucleotide composition) and mode of DACC (dinucleo-tide-based auto-cross covariance) into an ensemble classifier of clustering approach. 5 fold cross tests on a widely used benchmark dataset have indicated that the new predictor remarkably outper-forms its existing counterparts. Particularly, far beyond their reach, the new predictor can be easily used to conduct the genome-wide analysis and the results obtained are quite consistent with the experimental map. Availability: For the convenience of most experimental scientists, a user-friendly web-server for iR-Spot-EL has been established at http://bioinformatics.hitsz.edu.cn/iRSpot-EL/, by which users can easily obtain their desired results without the need to go through the complicated mathematical equations involved.
IntroductionRecombination plays an important role in genetic evolution, which describes the exchange of genetic information during the period of each generation in diploid organisms. Recombination provides many new combinations of genetic variations and is an important source for biodiversity, which can accelerate the procedure of biological evolution. Knowledge of recombination spots may also provide very useful information for in-depth understanding the reproduction and growth of cells. Therefore, it is highly demanded to develop computational methods for predicting the recombination spots.Actually, many efforts have been made in this regard. For instance, based on the gapped dinucleotide composition features,) developed a predictor called RF-DYMHC to do the job.), using the kmer approach and the increment of diversity combined with quadratic discriminant analysis, developed the IDQD predictor for the same purpose. In the above two predictors, however, only the local DNA sequence information was utilized, and hence their prediction quality may be limited. To improve this situation, recently two new predictors, iRSpot-PseDNC () and iRSpot-TNCPseAAC () were developed. The former was based on the DNA local structural properties () and pseudo dinucleotide composition (); while the latter based on the DNA trinucleotide composition () as well as the corresponding pseudo amino acid components (). Each of the aforementioned methods has its own advantage, and did play a role in stimulating the development of this important area. Meanwhile, they also have some disadvantages, as reflected by the following facts. (1) Although powerful predictors have been proposed, there is no efficient approach to combine them to further improve the predictive performance. (2) None of these methods allows users to set the desired parameters for prediction, and hence it is difficult for them to optimize the predictor system according to the need of their focus. (3) Except the RF-DYMHC (), all the other predictors cannot be directly used for genome-wide analysis. Even for the RF-DYMHC predictor, its approach is not accurate because the window size therein is arbitrary. The current study was initiated in an attempt to address these shortcomings by developing a more powerful predictor for identifying DNA recombination spots. The proposed predictor is called iRSpot-EL, where " i " stands for " identify " , " RSpot " for " recombination spot " , and " EL " for " ensemble learning ". To develop a new predictor usually consists of two purposes. One is to stimulate theoretical studies in the relevant areas, and the other is to make experimental scientists easier to get their desired information. To realize these, the rest of this article is presented according to the following five guidelines (): (1) benchmark dataset, (2) sample representation, (3) operation algorithm, (4) validation, and (5) web-server.
MATERIALS AND METHOD
Benchmark DatasetA reliable and stringent benchmark is pivotal to the development of an accurate prediction method. In literature, the benchmark dataset usually consists of a training dataset and a testing dataset: the former is for the purpose of training a proposed model, while the latter for the purpose of testing it. As pointed out by a comprehensive review (), however, there is no need to separate a benchmark dataset into a training dataset and a testing dataset for validating a prediction method if it is tested by the jackknife or subsampling (K-fold) cross-validation because the outcome thus obtained is actually from a combination of many different independent dataset tests. In this study, for facilitating the comparison of the proposed predictor with the existing ones, we adopted the widely used benchmark dataset () that can be formulated as = where is the benchmark dataset, the positive subset containing 490 DNA segments (hotspot samples) with the relative hybridization ratios () higher than 1.5 (), the negative subset containing 591 DNA segments (coldspot samples) with the relative hybridization ratios () lower than 0.82 (), and the symbol  denotes the union in the set theory. In order to reduce redundancy and homology bias, the CD-HIT software () was used to remove sequences whose similarity is higher than 75%. Finally, 478 hotspots (positive samples) and 572 coldspots (negative samples) were obtained. For readers' convenience, the 478 hotspot samples and 572 coldspot samples as well as their detailed sequences are given in Supporting Information S1.
Pseudo k-tuple nucleotide composition (PseKNC)With the avalanche of biological sequences emerging in the postgenomic age, one of the most challenging problems in computational biology is how to formulate a biological sequence with a vector, yet essentially still keep its key pattern or characteristics. This is because nearly all the existing machine-learning algorithms were developed to handle vector but not sequence samples, as elaborated in a recent review (). Unfortunately, a vector defined in a discrete model may completely lose all the sequence-order information or sequence pattern characteristics. To overcome such a problem for protein/peptide sequences, the pseudo amino acid composition (PseAAC) () was introduced, and has become an important tool () widely used in nearly all the areas of computational proteomics (see a long list of references cited in (). Encouraged by the successes of PseAAC, the pseudo nucleotide composition () was introduced to formulate DNA/RNA sequences, and it has been increasingly used in computational genetics and genomics (see, e.g., a recent review () as well as a long list of references cited therein). Recently, a web-server called " Pse-inOne " was developed for generating various modes of pseudo components for DNA/RNA and protein/peptide sequences (). Here the concept of PseKNC was used to define the feature vectors for identifying recombination spots via 15 indices () of local DNA structural properties, which were selected from (). Note that PseKNC model contains three uncertain parameters: k is the number of neighboring nucleic acid residues;  is the highest ranks or tiers (); w is the weight factor. These three parameters will be discussed in the Ensemble Learning Section.
Dinucleotide-based auto-cross covariance (DACC)In this study, the DNA sequences were generated by a very special mode of PseKNC (), the so-called DACC approach, which is a combination of dinucleotide-based auto covariance (DAC) and dinucleotide-based cross covariance (DCC). The former is based on a same physicochemical property listed in; while the latter, based on two different ones. Note that there is one shift parameter lag in the DACC, as will be discussed later.
Support vector machine (SVM)Support vector machine () is an efficient supervised learning approach in the field of machine learning, and has been widely used for classification and regress analysis. The basic idea of SVM is to transform the input data into a high dimensional feature space and then determine the optimal separating hyperplane. For more details about SVM, see (). In the current study, the LIBSVM package (with RBF kernel was used to implement SVM, in which there are two parameters: one is the regularization parameter C, and the other is the kernel width parameter . Thus, there are a total of five uncertain parameters when using SVM on the PseKNC model, while three uncertain parameters on the DACC model. All these parameters were optimized on the validation sets
Ensemble LearningAs demonstrated by a series of previous studies, such as protein fold pattern recognition (), membrane protein type classification (), signal peptide prediction (), protein subcellular location prediction (), enzyme functional classification (), identifying phosphorylation sites () and multiple lysine PTM sites in proteins (), the ensemble predictor formed by fusing an array of individual predictors via a voting system can yield much better prediction quality. There are two main components in the ensemble learning framework: 1) How to select the basic classifiers? 2) How to ensemble the basic classifiers so as to make the final prediction? In order to select the representative basic classifiers, the distance between any two classifiers () and () was measured by the following equation considering both the diversity and complementarity of the classifiers:where m represents the number of training samples, represents the misclassification probability of classifier () on the k-th sample, and d d can be calculated by: = + , if () and () incorrectly predicts the th sample 0, otherwiseThe range of the distance defined in Eq. 2 is from 0 to 1, where a distance of 1 indicates the predictive results of two classifiers are completely complementary, and 0 means that their results are identical. Based on the distance, the affinity propagation clustering algorithm () was employed, which is quite suitable for the current task since the center clusters are not required in this algorithm. For the PseKNC (), different values of , k, and w will correspond to different input types. In the present study, 500 different PseKNC classifiers were constructed by using the following parameter combinations: 2   6 with step  = 1 0   1 with step  = 0.1 1    10 with step  = 1Likewise, 10 different DACC classifiers were generated with different values of lag (lag = 1, 2, , 10). By using the aforementioned methods, 510 different classifiers were obtained, which were then clustered into seven clusters by using the affinity propagation clustering (). For each cluster, the top performing one was selected. For the current study, the ensemble classifier can be formulated by (seewhere  E denotes the ensemble classifier, the symbol  denotes the fusing operator (), and the fusion was operated via the following fractional voteswhere denotes the probability from the classifier (), and its fraction used, which was optimized on the validation sets (see). If Y > 0.5, the sample is predicted as a hotspot; otherwise, coldspot. For more detailed about the process of fusing individual basic classifiers into an ensemble classifier, see a comprehensive review () where a crystal clear elucidation with a set of elegant equations are given and hence there is no need to repeat here. The flowchart of ensemble strategy on different clustering is given in
Cross-ValidationThree cross-validation methods are often used in literature; they are independent dataset test, K-fold cross-validation test, and jackknife test (). In this study, the five-fold cross-validation was used. The benchmark dataset was randomly divided into five subsets with an approximately equal number of samples. Each predictor runs five times with five different training and test sets. For each run, three sets were used to train thepredictor, one set was used as the validation set to optimize the parameters, and the remaining one was used as the test set to give the final results.
Metrics Used to Reflect the Success RatesFor a binary classification system such as the one in the current study, the following set of four metrics are often used to quantitatively measure the quality of a predictor (see, e.g., ())where Sn, Sp, Acc, and MCC represent sensitivity, specificity, overall accuracy, and Mathew's correlation coefficient, respectively (). The total numbers of recombination hotspots and coldspots are denoted by and , respectively. The number of hotspot samples incorrectly predicted to be of coldspot is denoted by , while the number of coldspot samples incorrectly predicted to be of hotspot is by .As for the meanings of the four metrics in Eq.7 along with their score regions, see () where a clear and incisive analysis has been elaborated and hence there is no need to repeat here.
F-ScoreThe F-score can be calculated by using the following equation:where n + stands for the total number of the positive samples, n  for the total number of the negative samples,the mean value of the i-th feature of entire positive samples,the mean value of i-th feature of entire negative samples, for the mean value of the i-th feature of the total samples. , () for the value of the i-th feature of the k-th sample in the positive data set, and , () for the value of the i-th feature of the kth sample in the negative data set. The larger the F-score is, the more important the feature is ().
RESULTS AND DISCUSSION
Comparison with Basic Methods and Existing MethodsListed inare also the corresponding results obtained by the RF-DYMHC predictor (), IDQD predictor (), iRSpot-PseDNC predictor (), and iRSpot-TNCPseAAC (). From the table, we can see the following. (1) Among the five predictors the newly proposed one achieved the highest success rates in both Acc and MCC, the two most important metrics used to measure the quality of a predictor as elucidated in the follow-up text toAlthough the Sn rate by the proposed predictor was about 4% lower than that by IDQD, its Sp rate was about 7% higher than that by IDQD. As mentioned in Section 2.7, the two metrics are used to measure a predictor from two opposite angles, and they are constrained with each other. Therefore, it is meaningless to use only one of the two for comparing the quality of two predictors. In other words, a meaningful comparison in this regard should count the rates of both Sn and Sp, or even better, the rate of their combination that is none but MCC. As shown in
Feature AnalysisIn order to further investigate the discriminant power of different features and basic classifiers, the F-score method () was adopted to analyze the seven basic classifiers listed in. The top 10 most important features for each basic classifier are listed in, from which we can see that the important features between PseKNC and DACC classifiers are different, indicating that these classifiers are mutually complementary. Therefore, performance improvementcan be observed by combining these classifiers via an ensemble learning approach. Some common patterns can also be observed, for examples, CG, AT, TA, GC are very important for all the six PseKNC classifiers, which is fully consistent with Jiang et al's study ().0.8138, 0.8822, 0.8631 and 0.8777 for iRSpot-EL, iRSpot-TNCPseAAC, IDQD, iRSpotPseDNC and RF-DYMHC, respectively. The larger the AUC, the better the corresponding predictor is ().
Performance on Analysis of the Whole GenomeTo further demonstrate its practical application, the genome-wide analysis by iRSpot-EL was performed on the yeast chromosome III. In order to avoid the homology redundancy bias, the CD-HIT software (version 4.6) () was used to remove those DNA sequences from the benchmark dataset that have more than 75% sequence identity to the 1kb length DNA fragments in chromosome III. Trained with such a reduced benchmark dataset, the iRSpot-EL predictor was used to identify the hotspots in chromosome III with reliability index (RI) value set as 6 as suggested by (). For investigation into the effects of different parameters on the predictive performance, the genome-wide prediction was conducted with different sliding windows and step sizes. The predicted results of the center position were smoothed by using the average value of 200-bp in a sliding window. The results predicted by iRSpot-EL on yeast chromosome III are given in, where for facilitating the comparison the corresponding recombination profile by experiments () is also given. It can be clearly seen that the recombination profile predicted by iRSpot-EL is highly consistent with that of experimental observations (), further demonstrating that iRSpot-EL is indeed a very useful high throughput tool for genome-wide analysis of recombination spots. Interestingly, we have also observed that the cases with lager sliding window sizes tend to show better results. The reason is that larger window sizes can incorporate more global sequence information, which is critical for improving the performance (). Another important observation is that the step size has little impact on the predictive performance. Based on the aforementioned experimental outcomes, we suggest the users to set the parameters of sliding window size and its step size as 2000 bp and
The Author (2016). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com Associate Editor: Dr. John Hancock Bioinformatics Advance Access published August 16, 2016 at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
