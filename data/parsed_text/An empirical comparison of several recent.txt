Motivation: Many new methods have recently been proposed for detecting epistatic interactions in GWAS data. There is, however, no in-depth independent comparison of these methods yet. Results: Five recent methods—TEAM, BOOST, SNPHarvester, SNPRuler and Screen and Clean (SC)—are evaluated here in terms of power, type-1 error rate, scalability and completeness. In terms of power, TEAM performs best on data with main effect and BOOST performs best on data without main effect. In terms of type-1 error rate, TEAM and BOOST have higher type-1 error rates than SNPRuler and SNPHarvester. SC does not control type-1 error rate well. In terms of scalability, we tested the five methods using a dataset with 100 000 SNPs on a 64 bit Ubuntu system, with Intel (R) Xeon(R) CPU 2.66 GHz, 16 GB memory. TEAM takes ∼36 days to finish and SNPRuler reports heap allocation problems. BOOST scales up to 100 000 SNPs and the cost is much lower than that of TEAM. SC and SNPHarvester are the most scalable. In terms of completeness, we study how frequently the pruning techniques employed by these methods incorrectly prune away the most significant epistatic interactions. We find that, on average, 20% of datasets without main effect and 60% of datasets with main effect are pruned incorrectly by BOOST, SNPRuler and SNPHarvester. Availability: The software for the five methods tested are available from the URLs below.
INTRODUCTIONA genome-wide association study (GWAS) examines the association between phenotypes and genotypes in a study group. The first exciting finding was on age-related macular degeneration (AMD) (), which uncovers a disease allele (tyrosinehistidine polymorphism) with an effect size of 4.6 in 100 000 single nucleotide polymorphisms (SNPs). Since then, over 600 GWASs have been conducted for 150 diseases and traits; * To whom correspondence should be addressed. and 800 associated SNPs have been reported. The methodologies of these studies are similar: a quality control criteria is first defined to filter the genotype data; then the remaining genotypes are each tested for association with the disease phenotypes. Finally, the significant SNPs are reported after multiple testing correction. Most of these GWASs could only identify disease alleles with moderate effect size. Thus, single SNP association studies could explain very limited heritability of these diseases (). Consequently, researchers have started exploring multi-SNP interactions in the hope of discovering more significant associations. Multi-SNP interactions are also called 'epistatic interactions'. This term originated from Bateson's definition of epistasis 100 ago (). It was defined as the change of segregation ratio and the interaction of genes. However, in the current literature, there is a debate on the exact definition of epistasis (). Our article focuses on evaluating epistatic interaction detection methods in their computational aspect and all the experiments are based on simulation data. Thus, we consider epistatic interactions as the statistically significant associations of k-SNP interaction (k  2) with phenotypes. There are mainly two types of epistatic interaction detection methods: model-based methods and model-free methods. In general, model-based methods () predefine a statistical model between phenotypes and genotypes; then they fit the data to the model; and finally they output the significant SNPs. They work well for only a small number of important and filtered candidate SNPs; but they often fail when the number of SNPs grows to hundreds of thousands. To make model-based methods more efficient, researchers have proposed a variety of heuristic and filtering techniques. For example,(2010a) develop an upper bound of the likelihood ratio test statistic for two-locus epistatic interaction to prune the search space and a Boolean transformation of data to make collection of contingency table information faster. As another example,devise a two-stage analysis so that the overall analysis is more efficient. As a third example,use a stochastic search to identify only 4050 (set by the user) groups of candidate epistatic interactions for follow-up model-fitting analysis. In contrast, model-free methods () have no prior assumption on the data and the model. Given the genotype data, these methods only examine the test statistic of each possible epistatic interaction with phenotypes.propose a minimum spanning tree (MST) structure to represent the data; by traversing this MST, exhaustivecompare only approaches based on neural networks while our selected methods cover both data mining and statistical methods. Second,evaluate multifactor dimensionality reduction (MDR) (), grammatical evolution neural networks (GENN) (), focused interaction testing framework (FITF) (), random forests (RF) () and logistic regression (LR) () methods. They show that MDR is superior in all settings. After 2 years of advancement, most methods selected in this article have demonstrated that their performance is better than that of MDR; we therefore omit discussing methods mentioned in Motsingercompare AMBIENCE (with MDR, restricted partitioning method (RPM) () and logistic regression. They conclude that the performance of AMBIENCE is equivalent to that of logistic regression for two-locus models and better than that of RPM and MDR. However, according to, the performance of BOOST is better than that of PLINK (), which uses a pure logistic regression model. Therefore, we omit the evaluation of AMBIENCE and RPM in our study. Lastly,have shown that their overall performance is much better than that of BEAM (). We thus omit BEAM. In this article, we give an independent empirical comparison of five methods for detecting epistatic interactionsnamely, TEAM (), BOOST (), SNPRuler (), SNPHarvester () and Screen and Clean ()to help users better understand which method is more suitable for their data, which method is good for detecting epistatic interactions with and without main effect and which method is scalable to larger datasets. We also analyze why combining several of these methods cannot enhance power. Their basic characteristics are given in. The organization of this article is as follows. We first formulation the problem in Section 2. Then we briefly introduce each of the five methods in Section 3. We describe how the evaluation data is simulated in Section 4 and the detailed setting of each experiment in Section 5. After that, we present the results under each setting in Section 6. Finally, we discuss the performance of each method and provide advice to users in Section 7.
PROBLEM FORMULATIONIn a typical GWAS, researchers collect two types of data: genotype data that encodes the genetic information of each individual, and phenotype data that measures the quantitative traits of each individual. Here, we consider only bi-allelic SNPs. The allele that occurs more frequently is called the major allele, denoted as A. The allele that occurs less frequently is called the minor allele, denoted as a. The two alleles form three genotypesAA, Aa and aaand they are encoded as 0, 1 and 2 in raw data. For phenotype data, we consider the binary form (0 for control and 1 for case). With minor modification, current methods can handle other types of phenotype data, e.g. by discretizing a continuous phenotype. The goal of each method is to identify k-SNP (k  2) epistatic interactions significantly associated with the phenotype. Thus, each method outputs a list of epistatic interactions, each involving up to k-SNPs (usually k is set to 2) and is accompanied by its P-value after correction for multiple testing. There are two challenges. First, if we constrain k to be 1, then the number of statistical tests is equal to the number of SNPs in a dataset. When k increases by 1, the number of tests grows by n-fold (n is the number of SNPs in a dataset). Thus, the total number of tests grows quickly as k increases, resulting in the inability of current methods to test all the combinations. For example, to study a moderate size of 500 000 SNPs, we can test only two-locus epistatic interactions if we use the EPISNP program () on a 2.66 GHz single processor, as it may take 1.2 years to finish all the tests. Therefore, heavy computation cost is one of the challenges for current methods (). Second, since a huge number of possible combinations are tested, a large proportion of significant associations are expected to be false positives. Thus, reducing the number of false positives while retaining power is another challenge.
METHODS
SNPRulerSNPRuler (), MDR () and a few other pattern-based methods () adopt data mining approaches for detecting epistatic interactions. These methods do not assume a model-fitting procedure, but use some filtering methods to reduce the number of SNP combinations to be tested. SNPRuler () is a rule-based approach motivated by the fact that each epistatic interaction induces a set of rules. For example, SNP 1  SNP 2  Disease contains nine rules, they are SNP 1 = i  SNP 2 = j  Disease, i,j {0,1,2}. In this article, the quality of a rule is given by its  2 test value. We define SNP 1  SNP 2  Disease as a SNP-level epistatic interaction and SNP 1 = i  SNP 2 = j  Disease, i,j {0,1,2} as allele-level epistatic interactions.To identify epistatic interactions that are significant, SNPRuler traverses a set enumeration tree where the nodes of the tree are the genotypes of the SNPs, the leaves of the tree are the phenotypes, and the path from the root to a leaf is an allele-level epistatic interaction. Exhaustive tree traversal is theoretically possible but practically impossible due to the explosive number of combinations as the tree grows. Therefore, the authors propose an upper bound on the  2 test statistic to prune the search space. After the search procedure, a post-processing step is used to get and rank SNP-level interactions. There are two hidden problems in this work. First, the upper bound they derived from the  2 formula is not a true upper bound and does not Page: 2938 29362943
Y.Wang et al.possess the anti-monotone property (). Although it helps prune a large search space, it also prunes many true-positive epistatic interactions. Second, the upper bound is based on the assumption that the number of cases should be larger than or equal to that of controls in a dataset; otherwise, the upper bound does not hold. This assumption is inconvenient since the number of controls is larger than that of cases in most GWAS datasets.
SNPHarvesterSNPHarvester () is a stochastic search algorithm to identify epistatic interactions. It consists of two steps: a filtering and a model-fitting step. The filtering step is to identify m (4050) significant SNP groups for the subsequent model-fitting step. In the filtering step, it first removes significant single SNPs according to their  2 test values, because this method is only interested in epistatic interactions that have weak marginal effect but significant joint effect. Then it randomly picks k-SNPs. These form an active set S ={SNP 1 , SNP 2 , ..., SNP k }. The rest of the SNPs form a candidate set S c. After all these preparations are done, the nested PathSeeker algorithm is called to swap SNP i  S with SNP j  S c to get the group with the highest  2 test value. A total of k(nk) combinations need to be tested to identify such a group. After this, the identified group is removed from the n SNPs. The next iteration continues to select k-SNPs to form an active set and the remaining n2k SNPs form a candidate set. The same procedure is repeated again. The complexity to identify m groups is O(knm), which is affordable even when there are >100 000 SNPs. In the second step, each of the m significant groups is fitted into the L 2 penalized logistic regression model; see Park and Hastie (2008) for details.
Screen and CleanThe Screen and Clean method () uses a two-stage analysis; datasets from Stage 1 for the screening and datasets from Stage 2 for the cleaning. In the screening stage, it only considers tag SNPs and marginal significant SNPs. These SNPs are first fitted into the main effect lasso logistic regression model,where X j is the encoded genotype value 0, 1 or 2, Y is the encoded phenotype value 0 or 1. This model first identifies a set of SNPs whose coefficients satisfy  j = 0, j  {1,2,...,n}; then it obtains the least square estimatesestimates estimates k , k  {1,2,...,n} of these SNPs. To test the significance of each regression coefficient, the t-test statistic value is calculated. Only the significant SNPs and their corresponding two-SNP combinations enter the interaction modelA similar procedure applies to interaction model fitting. After this stage, the 'surviving' SNP pairs go to the second cleaning stage for controlling type-1 error. T-test is used again to remove SNP pairs whose significance level is lower than a user-specified threshold.
BOOSTBOOST () contributes to the epistatic detection problem in two aspects. First, it provides a new Boolean representation of the data. By transforming the data representation to the Boolean type, BOOST uses established methods () of logic operations to collect contingency table information, which is very efficient. Second, it proposes an upper bound for the likelihood ratio test statistic to prune insignificant epistatic interactions. The likelihood ratio test is originally based on the deviance of difference between the full logistic regression model,where X l 1 and X l 2 are genotype variables, i, j  {0,1,2}, and the main logistic regression model logWe denote the log likelihood of the full model under maximum likelihood estimate (MLE) asLas asL F , the log likelihood of the main model under MLE asLas asL M , the log likelihood of log-linear saturated model asLas asL S and the homogeneous model asLas asL H. The likelihood ratio statistic between the main model and the full model is 2(  L M   L F ). The log-linear homogeneous association model corresponds to the main logistic regression model and the log-linear saturated model corresponds to the full logistic regression model (). This leads to an upper bound for the two loglinear models: 2(  L S   L H ). Matsuda (2000) uses Kirkwood Superposition Approximation to get a lower bound of the homogeneous association model. Therefore, the upper bound of the likelihood is established. This upper bound is tight and most non-significant interactions can be pruned. Its GPU version GBOOST () provides 40-fold speedup compared with that of BOOST.
TEAMTEAM () is an exhaustive algorithm to detect twolocus epistatic interactions in GWAS. It controls false positives by using permutation test. Permutation test is generally more accurate at finding the cut-off P-value threshold than direct adjustment methods like Bonferroni correction (), but at a much higher cost. TEAM needs to compute the contingency table for every pair of SNPs on all the permutations to calculate P-values, which is very expensive. To reduce the computation cost, the authors observe that if two SNPs have the same genotype values on many individuals, then the computation of their contingency tables can be shared by considering only those individuals with different values. TEAM uses an MST, where nodes are SNPs and the weight of edges is the number of individuals with different values on the two SNPs, to maximize the sharing of contingency table computation. As the construction of MST can be costly, TEAM constructs an approximate MST instead. The performance of TEAM is faster than the brute-force approach by an order of magnitude. As TEAM does not presume any statistical model, it is applicable to any test statistice.g.  2 test, exact likelihood ratio test and entropy-based testbased purely on contingency table information.
DATA SIMULATIONWe simulate different types of datasets to evaluate the power, type-1 error rate and scalability of each method.
PowerFor each setting in both data with and without main effect below, 100 datasets are generated. In each dataset, we embed one groundtruth epistatic interaction. Power is defined as the fraction of the 100 datasets on which the top prediction matches the ground-truth. Data with main effect: the embedded epistatic interaction demonstrates both main effect and interaction effect. There are at least 50 different models that satisfy the constraints for two-locus epistatic interactions (). We consider the three commonly used models () given in. We simulate the data based on these three models. For each model, we try two different minor allele frequencies (MAF) at 0.2 and 0.5, and three different main effect values at 0.2, 0.3 and 0.5; thus giving a total of six different settings. These values represent the low and high value for each parameter. We use 2000 samples and 1000 SNPs. Illustraion of three main models. For the two-locus problem, suppose the baseline odds of getting a disease is , and having the disease allele (a or b) increases the odds by 1+. A person with genotype Aa or Bb has an (1+) odds of getting a disease, while one with genotype aa or bb has an odds of
Comparison of epistatic interaction detection methods
Type-1 error rateWe simulate 1000 datasets without embedding any epistatic interaction, each with 2000 samples and 1000 SNPs. The MAF of each SNP is uniformly distributed in (0.05, 0.5). Type-1 error rate of the methods is defined as the proportion of the 1000 datasets on which the significance level of the top prediction satisfies the user-specified threshold.
ScalabilityTo test the scalability, we use datasets with 100, 1000, 10 000 and 100 000 SNPs. Each of the four datasets has 2000 samples.
EXPERIMENTAL SETTINGAll the experiments are conducted on a 64 bit Ubuntu system, with Intel (R) Xeon(R) CPU 2.66 GHz, 16 GB memory. SNPRuler provides a Java program. The heap size is set to-Xmx7000M, giving the maximum memory for the program to use. The maximum number of rules is set as 50 000. The rule length is set to 2 since we focus on two-locus epistatic interactions. The pruning threshold is set as 0, to test as many combinations as possible. SNPHarvester also provides a Java program; it has two running modes. One is the 'Threshold-Based' mode, where the user indicates the threshold significance level and the program outputs all results whose significance level is lower than the threshold. Another is the 'Top-K Based' mode, where the program outputs the top K most significant results regardless of their significance level. The 'Top-K Based' mode is used for our analysis. TEAM provides a C++ program that consists of two subprograms:(i) to test all combinations and record the corresponding test statistic value and (ii) to get the SNP pairs according to the user-specified false discovery rate (FDR). We use the default setting of other parameters and set the FDR value to 1. BOOST provides a C program that only runs on Windows system. To let all programs run on the same hardware configuration, we use the Wine program (http://www.wine.org) which allows us to run a Windows program on a Unix system. There is no setting for BOOST; the output is the list of results whose likelihood ratio test statistic values are >30 with 4 degrees of freedom. Screen and Clean provides an R program; it has four running strategies, among which we choose the 'Kitchen Sink'. We set the P-value threshold to 0.1 and the number of pairs to be tested to 100. BOOST filters out epistatic interactions with test statistic values <30 with 4 degrees of freedom. This corresponds to 0.1 significance level. For fair comparison, we add a post-processing step to filter output with P > 0.1 for other methods.
EXPERIMENT RESULTS
Model with main effectThe results here are obtained by using data generated in the first part of Section 4.1.shows that in each setting, TEAM outperforms all other methods. For the other four methods, different model settings lead to different rankings. For example, in Model 1 with  = 0.3, SNPRuler is second; in Model 2 with  = 0.5, Screen and Clean is second. The different performance of TEAM and BOOST is due to a key difference in defining the interaction effect. TEAM uses the  2 test to measure the significance of two-locus interactions and thus makes no assumption about the data. BOOST uses a log likelihood ratio test to get the deviance difference between the log likelihood of the log-linear homogeneous association model and log-linear saturated model. BOOST performs well when the interaction terms contribute significantly to the model. However, when single SNP association terms fit the model well and interaction terms do not contribute significantly, BOOST may not be able to detect the ground-truth. This type of epistatic interactions is often referred as 'statistical epistasis' () and is widely accepted by the statistical community. SNPRuler is not an exhaustive method, but the test used is the same as that of TEAM. We set the pruning threshold to 0; thus, it explores as many epistatic interactions as possible. Compared with TEAM, this method potentially misses true positives. The result of SNPHarvester is expected as its randomization technique makes it difficult to perform better than exhaustive search. Screen and Clean performs poorly, due to its numerous filtering steps in the two-stage design. In the screening Page: 2940 29362943step, before the main-effect lasso procedure starts, it includes only marginally significant and tag SNPs. After that, it still only considers n (set by the user) pairs of SNPs instead of all the possible pairs to continue the interaction model fitting procedure. In the cleaning step, the filtering test is applied to only a small number of SNP pairs, resulting in little power to detect the ground-truth. All five methods perform best on Model 1 compared with Models 2 and 3. This is because of the multiplicative effect between and within the two loci, making the epistatic interaction effect stronger and easier to detect. Model 2 only considers the multiplicative effect between two loci; the power to detect epistatic interactions drops obviously for all methods. The interaction effect of Model 3 is even weaker than Model 2, leading to the lowest power in all methods. It is also noted that the higher the main effect of the model, the easier it is for each method to detect epistatic interactions. However, SNPRuler and SNPHarvester do not follow this pattern because, when the main effect of the ground-truth pair is large, these two methods prune such main effect SNPs at the filtering stage. This leads to the missing detection of ground-truth.
Y.Wang et al.
Model without main effectThe results here are obtained using data generated in the latter part of Section 4.1. Screen and Clean is applicable only to data with main effect; thus we omit it here.gives an overall picture of the performance of the methods for each sample size, whilegives the details. The median power of BOOST is the highest followed by TEAM. The performance of SNPRuler is close to that of an exhaustive method (TEAM), but is at a lower computational cost. BOOST performs the best in each setting and TEAM second; but the difference is not as obvious as that in data with main effect. SNPHarvester performs relatively poorly for each sample size. All methods perform well when heritability is high; when heritability reduces to 0.001, all methods have little power.point out in their study of neurological cancers that low heritability caused by phenocopy level (PE) is the main reason for the methods to lose power. We also notice that increasing the sample size helps all these methods to improve their power in each heritability setting. When we evaluate the four methods on data without main effect, we use all datasets that are publicly available. They include 70 models and 4 different sample sizes for each model. Part of these datasets are also used in BOOST, SNPRuler and SNPHarvester. BOOST does not include the results of 70 models for 200 samples. SNPRuler and SNPHarvester merely show results of 60 models and each model with 400 samples. Our reported results are consistent with previous reported results and are complementary to them. In particular, for those models with 0.001 heritability, 0.2 MAF and 200 samples, the results of these datasets were not reported previously; and all four methods have zero power (). This shows the limitations of purely statistical methods.
ScalabilityWe apply all methods to datasets with 100, 1000, 10 000 and 100 000 SNPs. From, BOOST is the fastest under the first three settings. This is due to its fast Boolean operation to collect contingency tables and upper bound-pruning technique. When the SNP size grows to 100 000, it is much slower than the two nonexhaustive methods SNPHarvester and Screen and Clean. TEAM is the slowest in all settings for two reasons. First, the overall running time is only an order faster than that of a brute-force approach. Second, the permutation procedure makes it even more expensive, although traversing MST helps reduce the cost. SNPRuler cannot execute on the dataset with 100 000 SNPs because we get the 'out of memory' error, even though we have set the heap size to 12.8 GBfor the Java virtual machine, which is the maximum on our PC. SNPHarvester and Screen and Clean only identify a fixed number of candidate epistatic interactions, and then fit them to a statistical model for follow-up analysis. Thus, their scalability is much better than the other three methods when SNP size grows.
Comparison of epistatic interaction detection methods
Type-1 errorWe define the type-1 error rate of a method as the proportion of datasets that the method reports as the existence of significant epistatic interactions, out of the 1000 datasets in which no epistatic interactions are actually embedded. The significance level is set to 0.05 after Bonferroni correction. The type-1 error rate for TEAM is 0.018, BOOST is 0.065 and SNPRuler and SNPHarvester both are 0.003. TEAM and BOOST have higher power, and thus higher type-1 error rates are reasonable. Screen and Clean has problems controlling type-1 error, as its type-1 error rate is as high as 0.86.
CompletenessSNPRuler, SNPHarvester and BOOST use some pruning techniques to speed up the search. Hence, they have better scalability than TEAM as shown in. The side effect of using pruning techniques is the loss of powerthe most significant SNP pairs may be thrown away. To study the magnitude of this side effect, we pick the most significant SNP pair on each dataset and study how many of them are pruned. For each method, the most significant SNP pair is the SNP pair with the lowest P-value calculated using the statistical test used by the method. Thus, for BOOST, the most significant SNP pair is the SNP pair with the lowest P-value calculated using likelihood ratio test. For the other two methods, the most significant SNP pair is the SNP pair with the lowest P-value calculated using  2 test. BOOST prunes away the most significant SNP pair on 4195 out of the 26 860 datasets without main effect, and on 756 out of 1698 datasets with main effect. Among these 4195 datasets, the power of BOOST is 12.2% compared with 18.3% for the corresponding exhaustive method.also shows that the number of incorrectly pruned datasets of SNPRuler is smaller than that of SNPHarvester for both types of data. Correspondingly, the power of SNPRuler is higher than that of SNPHarvester.
Comments on CompletenessIn the completeness analysis of BOOST, we discovered a bug in our program script while this paper was in press. In particular, we missed out in our program script a step to sort the output of BOOSTthis caused the top interacting SNP pair to be not always chosen in each test. Consequently, we misreported in Section 6.5 that BOOST wrongly pruned the most significant SNP pairs in 4195 datasets without main effect and 756 datasets with main effect. After correcting the program script, BOOST was verified to be complete and did not mis-prune any most significant SNP pairs.
DISCUSSIONThe five methods all demonstrate respective utilities through the experiments results above. No single method is simultaneously the most powerful, the most scalable and has the lowest type-1 error rate in every setting. When users want powerful results and are not concerned with computation cost, we recommend using TEAM and BOOST. Compared with TEAM, BOOST uses a model-fitting procedure. If the data fits the model well, the result is usually good;Page: 2942 29362943the four methods on data with and without main effect. In (a), there are in total 1800 datasets for 18 settings of the simulated datasets, which corresponds to 1800 ground-truth. Among these ground-truth, only 800 of them can be detected by at least one of the four methods, while the best methodTEAMidentifies 787 ground-truth out of 800. This explains why using ensemble methods cannot outperform TEAM. Similar observation is illustrated in (b). otherwise, a model-free method may be the alternative choice. When users expect moderate running time and power, we recommend using SNPRuler. Its pruning technique helps reduce running time albeit at the risk of losing power. If users are conscious of computation cost and have to run very large datasets, we recommend using SNPHarvester because it only identifies a small number (4050) of groups for the model-fitting procedure. Our evaluations are based on simulation results. In a real study, users usually have no idea of the 'ground-truth' in the dataset. Hence, it may not be sufficient to rely only on one method to obtain results. We suggest that, if time and computation resources permit, users try both the recommended model-free (i.e. TEAM) and model-fitting (i.e. BOOST) methods. It is tempting to consider taking a 'majority vote' of the results of two or more methods. For example, let every algorithm report their top three predictions. An SNP pair receives k votes if it is reported by k methods. We select the one with the highest vote as the final prediction. When there is a tie, we choose the one with the lowest P-value. Unfortunately, for both types of data tested, we find that an ensemble using such a strategy cannot increase power over using solely BOOST or TEAM. In, we see that for data without main effect, BOOST's ground-truth predictions highly overlap with the other three methods, so any ensemble cannot contribute a significant number of new ground-truth predictions. Specifically, the proportion of BOOST's ground-truth predictions that are not predicted by the other three methods is 4.1%, while the proportion of the other methods' ground-truth predictions not predicted by BOOST is 0.2%. Similarly, for data with main effect, no ensemble can outperform TEAM. Our evaluations above only focus on two-locus epistatic interaction. Recently,provide a general model that can be extended to n-locus epistasis. They also provide mathematical details of dissecting the  2 test into different epistatic components. For example, two-way epistatic interaction can be partitioned into four epistatic components: additive  additive, additive  dominant, dominant  additive and dominant  dominant. This helps characterize epistatic interactions in a more specific way and provides more physiological insights.
Y.Wang et al.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
