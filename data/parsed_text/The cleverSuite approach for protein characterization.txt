Motivation: The recent shift towards high-throughput screening is posing new challenges for the interpretation of experimental results. Here we propose the cleverSuite approach for large-scale characterization of protein groups. Description: The central part of the cleverSuite is the cleverMachine (CM), an algorithm that performs statistics on protein sequences by comparing their physico-chemical propensities. The second element is called cleverClassifier and builds on top of the models generated by the CM to allow classification of new datasets. Results: We applied the cleverSuite to predict secondary structure properties, solubility, chaperone requirements and RNA-binding abilities. Using cross-validation and independent datasets, the cleverSuite reproduces experimental findings with great accuracy and provides models that can be used for future investigations. Availability: The intuitive interface for dataset exploration, analysis and prediction is available at http://s.tartaglialab.com/clever_suite.
INTRODUCTIONDue to the latest advances in technology, a large number of sequences have been deposited into databases () and computational methods are being developed for their analysis and interpretation (). Some algorithms require per-case configuration () or lack intuitive interface (), which prohibits diffusion among non-computational scientists. Experimental scales encoding physico-chemical properties are useful to retrieve basic information on protein sequences () and to predict features associated with protein folding (), aggregation () and molecular interactions (). For instance, the Zyggregator method predicts aggregation propensity using a combination of physicochemical properties including secondary structure, solvent accessibility, hydrophobicity and polarity (). Similarly, the SVMprot algorithm exploits amino acid properties to predict protein families annotated in Pfam (). Indeed, experimental scales can be employed to investigate large-scale properties of proteomes and identify common features () but no systematic approach has been attempted so far to provide a general-purpose algorithm. We aim to provide researchers with an intuitive and statistically robust method to characterize protein groups exploiting the information contained in primary structure. Our premise is that the user should be able to make multiple hypotheses on the training sets and build models that others can test. As a general-purpose universal optimization is theoretically impossible (), our strategy is to build a class of predictors that are specific for the individual problems. We pay particular attention to derive unbiased models because over-fitting of internal parameters can undermine the general applicability of algorithms (). Our approach, the cleverSuite, provides a series of easy-to-use, configuration-free tools with interactive graphical interface. The central part of the suite is the cleverMachine (CM), an algorithm to characterize protein datasets. CM does not require external fitting parameters and returns multiple physico-chemical properties ranked by their significance. Relevant properties are merged together to provide coherent and consistent classification, allowing complex feature analysis. The second element of our suite is the cleverClassifier (CC) that builds on top of results generated by the CM to allow classification of protein datasets using state of the art machine-learning approaches (). CM and CC algorithms are freely available at http://s.tartaglia lab.com/page/clever_suite. We illustrate the powerfulness of our approach by making predictions of several protein features, including structural disorder (), solubility (), chaperone interactions () and RNA-binding abilities (). CM and CC models that are available for consultation at: http:// s.tartaglialab.com/clever_community. *To whom correspondence should be addressed.  The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits noncommercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com
METHODS
The cleverMachineThe algorithm evaluates relative difference in physico-chemical properties between two provided datasets. The first dataset is considered to be positive (P) and the second negative (N). The operations of the algorithm consist of multiple stages ().
Data generationThe raw information is extracted from protein sequences using experimental physico-chemical propensities. Our curated database contains 80 physico-chemical propensities, derived from experimental data [e.g. hydrophobicity ()] and statistics on computational tools. Physico-chemical propensities are organized into groups based on higher level properties (and Supplementry). At present, we use eight classes (hydrophobicity, alpha-helix, beta-sheet, disorder, burial, aggregation, membrane and nucleic acid-binding propensities), but additional descriptors are allowed (see Section 2.3). For a given propensity, each protein sequence is scanned using a sliding window, moved one residue at a time, starting from the N-terminus (protein profile). The size of the sliding window is set to 7 amino acids to allow best discrimination between alpha helix (hydrogen bonding in the range i  3 ! i and i  5 ! i and beta sheet (strands between 310 amino acids) elements, but it can be modified.
Signal detectionFor each property, we count how many proteins from one dataset have profiles enriched with respect to the other dataset:In Equation (1), is the signal extracted from the protein profile, the counter #x  y is 1 if x4y and 0 otherwise and P tot and N tot are the total number of sequences in P and N datasets. The internal parameter is a cut-off used in the counting (see Section 2.1.6). The coverage is calculated for all proteins from both datasets and individual scale enrichments (i.e. fractions of P and N that can be discriminated) are calculated. For each physico-chemical propensity, the algorithm estimates the area under the receiver operating characteristics curve (AUC). In the five cases reported in this article, AUC and coverage P, N   show more than 0.85 correlation (and Supplementary). As AUC is cut-off independent, the high correlation indicates that coverage P, N  depends only weakly on : It is important to mention that the ROC analysis is not defined in multiple dimensions (), while different physico-chemical properties can be combined into an overall coverage. Coverage of 50% indicates that half of the dataset is differentially enriched (expectation for a random set is 25% corresponding to 0.5 of AUC;and Supplementary).
Properties selection and combinationTo calculate the significance of each physico-chemical property, P and N are merged together and shuffled sets matching P and N in size are extracted. The procedure is repeated R times. For each of the randomized dataset pairs, we estimate the coverage. Information from the random dataset discrimination is used to rank properties significance using Z-scores and their associated P-values (Supplementary). Properties not meeting the criteria Z-score4Z thrandom sets, we observe that optimal values are Z th  6 and R  15. To check consistencies among predictors of the same physico-chemical propensity, we group the properties by higher level features and also highlight the ones that pass the selection criteria (and Supplementary). For each combination of properties ranging from 1 to 5 ($10 7 alternatives), the overall coverage (union of individual coverages) is calculated and the best-performing set is selected (). We observe that some physicochemical properties are correlated. Nevertheless, since the algorithm selects only the most discriminative combination of properties, correlation does not represent a limitation. In fact, if two properties produce overlapping lists of proteins, their combination creates smaller coverage compared to scales that are more different.
Model generationIn order to identify the best model for further set classification, the algorithm evaluates combination of scales with multiple machine learning methodologies. The selected classifiers include random forests, support vector machine, nearest neighbour and adaptive boosting algorithms (). To avoid set size bias, we perform multiple equal size samplings from each of the datasets. Moreover, we perform 10-fold cross-validation with each of the models to select the best performing (highest accuracy) algorithm.
The cleverClassifierThe main goal is the set-wide assignment of query X to either P or N set from the reference submission (). The prediction is carried out using the best model evaluated on reference data. CD-HIT () algorithm is employed to detect set sequence similarity of X with respect to reference. If the similarity exceeds 10%, the value is reported to the user. Random sets generated with the same AA composition as the reference sets are employed to estimate signal strength, which is defined as the difference between performance of set X (i.e. fraction of cases that can be classified) and random sets. Signal strength ranges between 0 (no enrichment) to 0.5 (strong signal) (Supplementary Tables S1 and S2). For each of the entries from dataset X, individual physico-chemical profiles (Supplementary) are reported together with element assignment to either P or N. Moreover, for each individual prediction we estimate prediction strength using consensus from cross-validation models.
Additional features(i) Custom scales: if the 'expert mode' option is selected in the webserver, the user can submit up to 10 amino acid scales for CM calculations. As CM employs 10 scales for each physico-chemical group (e.g. hydrophobicity) we suggest a similar approach for the choice of additional scales. Custom scales do not need to be normalized.(ii) Derived scale: at every run, CM produces an ad hoc scale derived from the input sets ('expert mode'). The scale is measured by considering the frequency of each amino acid a in both sets P and N:In Equation (2), amino acid frequencies are normalized:The derived scale can be used in CC runs (see (i) above).(iii) Adaptive threshold: the optimal cut-off corresponds to the highest coverage with respect to shuffled sets:The number of shuffled sets P r and N r is R  15: If the 'expert mode' option is selected, the algorithm optimizes for the input sets. In the 'normal run' mode, the cut-off is  0:75 (Supplementary).(iv) Peak detection: the coverage can be computed using (a) the average of physico-chemical profiles or (b) regions that deviate more than one standard deviation from the average score. Average score and standard deviation are estimated from the distribution of profiles (considering both positive and negative sets). The use of a threshold, previously implemented for the calculation of aggregation properties (), introduces a sequence-position dependency in the calculation of profiles.In the webserver, this view is interactive and shows information about each scale after clicking (see also Supplementary)
1603The cleversuite approach for protein characterization
RESULTSA sketch describing CM and CC workflow is presented in. The goal of the CM algorithm is to discriminate between two protein sets. A number of properties, including hydrophobicity, alpha-helical, beta-sheet, disorder, burial, aggregation, membrane and nucleic acid-binding propensities, are employed to build physicochemical 'profiles'. The physico-chemical properties are combined together to identify similarities and differences between the two sets. Once the discriminating properties are characterized, CM generates a model, which is employed by CC to classify new datasets. As shown in the examples below, we tested CM and CC performances on protein features such as secondary structure, structural disorder, solubility, chaperone requirements and RNA-binding ability (Supplementary). Unless otherwise stated, we always remove overlap between training and test sets using CD-HIT with default cut-off set for sequence similarity ().
Alpha-helix versus beta-sheet proteinsIn this first introductory example, we trained CM to distinguish between alpha-helical and beta-sheet proteins. The PDB database () was used to retrieve protein structures, STRIDE () was applied to analyse alpha-helical and beta-sheet content and CD-HIT () was employed to filter out sequences with 450% identity. After sequence redundancy removal, the alpha-helical set consisted of 277 proteins adopting 480% of alpha-helical conformation while the beta-sheet set was comprised of 191 proteins containing 460% of beta-sheet content. Sequences coding for alpha-helical structures were used to build the positive set, while the negative set consisted of beta-sheet proteins.
PerformancesIn striking agreement with structural classification, we found that even a single physico-chemical scale of alpha-helical propensity () is able to discriminate 98% of the two sets with a 99.0% accuracy and 100% precision (). Hence, CM shows ideal performances in separating alpha-helical and beta-sheet proteins. All alphahelical scales () showed consistent enrichment in the positive set, while the beta propensity scales displayed significant enrichment in the negative set (the signal is strong with respect to permutated input sets with P-value50.01) (; Delege and Roux;).
Cross-validation Througha 10-fold cross-validation on both sets, our CM showed accuracy of 97.9% (). When compared to random sets, the signal strength was 0.5 (Supplementary). CM selected AdaBoost () classifier as the best performing algorithm for this calculation.
Independent validationsWe downloaded alpha/beta proteins from SCOP (). After redundancy removal (CD-HIT 50), the alpha-helical set consisted of 176 proteins adopting 480% of alpha-helical conformation while the beta-sheet set was comprised of 79 proteins containing 460% of beta-sheet content. Our predictions showed accuracy of 90.4% for alpha-helical (positive set) and 93.2% for beta-sheet (negative set) assignments (). The testing sets achieved separation from random of 0.4 (alpha-helix) and 0.4 (betasheet). On the same datasets, the RePROF () algorithm yielded accuracies of 92.6% (alpha-helical proteins) and 72.1% (beta-sheet proteins; Table 1 and Supplementary Material). As an additional test we used NetSurfP () that achieved accuracy of 96% (alpha-helical proteins) and 64% (beta-sheet proteins).Statistics for each scale combination and its individual members. In the webserver, click-through the combination titles reveals scales contained and detailed statistics (three-scale combination is shown; the E.coli solubility analysis is used as example). This view is used to summarize results of both CM and CCPerformance comparison with algorithms reported in literature. TPR (true positive rate) and TNR (true negative rate) are calculated on the same sets used to validate CC. Links to full results are given in Supplementary Table S1.
Structural disorderIt has been shown that natively unfolded proteins are implicated in cellular regulation, signalling and assembly of macromolecular complexes (). Absence of native structure has functional implications for complex organisms (). In fact, higher eukaryotes show larger amount of intrinsically disordered proteins with respect to prokaryotes (). We applied our algorithm to intrinsically disordered proteins
Performances CM identifies disorder asthe most discriminative physico-chemical property: TOP-IDB and DisProt cover respectively 65.5% and 61.0% (). We found that disordered proteins are more hydrophilic and soluble. Indeed, the coverage is 50% for hydrophobicity [corresponding to 0.7 of AUC ()], 45% for aggregation () and 42% for burial (). The CM achieves optimal performances by combining the scales for disorder (), hydrophobicity (), burial (), aggregation () and alpha-helix () (sensitivity of 0.9 and false positive rate of 0.07).
Cross-validation Througha 10-fold cross-validation on both sets, our CM showed accuracy of 86.7% (). When compared to random sets, the signal strength was 0.4 (Supplementary). The best performing classifier for this case was Extremely Randomized Trees (), a variant of the Random Forest ensemble classifier.
Independent validationsAs a positive set we used a database of yeast prions that are enriched in structural disorder [27 entries after sequence redundancy removal (. The negative set was comprised of a manually curated database of structured proteins whose folded native state has been studied in vitro [44 entries after sequence redundancy removal (. Our predictions showed accuracy of 84.5% for prions and 73.6% for structured proteins (). The testing sets achieved separation from random of 0.4 (prions) and 0.2 (structured proteins). On the same datasets, the FoldIndex () algorithm yielded accuracies of 62.9% (prions) and 64.7% (structured proteins; Table 1 and Supplementary Material). In addition, we employed NetSurfP () and observed accuracies of 88.8% (prions) and 63.7% (structured proteins).
SolubilityA number of proteins such as fragile X mental retardation protein FMRP, TARDNA-binding protein 43 TDP43, fused in sarcoma FUS and prions have a strong propensity to aggregate into amyloid fibrils (). Hence, prediction of protein solubility is fundamental to understand functional (e.g. RNA-binding) and dysfunctional (e.g. aggregated) states. To build a predictor of protein solubility, we took advantage of a study in which the solubility of 70% of Escherichia coli proteins was experimentally measured using an in vivo translation system (). In this analysis, we ranked proteins by their solubility and used top (1000 soluble proteins) and bottom (1000 insoluble proteins) elements as the positive and negative sets ().
PerformancesIn agreement with experimental evidence (), we found that hydrophobicity () (coverage of 41%) propensities are enriched (and Supplementary). By selecting the scales for disorder (), burial () and alpha-helix () the algorithm reported optimal performances associated with sensitivity of 0.96 and false positive rate of 0.07 ().
Cross-validation Througha 10-fold cross-validation on both sets, our CM showed accuracy of 89.7% (). When compared to random sets, the signal strength was 0.5 (Supplementary). In this case, Random Forest classifier () was selected as the best performing.
Independent validationsAs positive set we used proteins whose folding kinetics and thermodynamics have been studied in vitro [71 non-redundant entries (. The negative set contained proteins requiring molecular chaperones to fold into native structure [81 entries (. Our predictions showed accuracy of 84.7% for the positive set and 60.5% for the negative. The testing achieved separation from random of 0.5 (soluble proteins) and 0.1 (insoluble proteins). On the same datasets, PROSO II () algorithm yielded accuracies of 78.5% (positive set) and 74% (negative set;; Supplementary Material).
Chaperone requirementsHsp70, the major stress-induced heat shock protein, facilitates substrate folding into native state () and is able to associate with AU-rich transcripts (). Mass spectrometry experiments show that E.coli DnaK interacts with proteins lacking strong hydrophobic core or exposing regions that are buried in the native state. In our analysis, the positive set was composed of proteins that require DnaK/GroEL to fold properly (109 sequences) and the negative set consisted of independently folding proteins
PerformancesOur results show strong agreement with experimental findings, with proteins in the positive set having low hydrophobic propensity [43% coverage (but high burial propensity [68% coverage (, which is consistent with the observation that lack of a hydrophobic core prevents from folding into native state (). In agreement with experimental evidence (), we found that the positive set is enriched in proteins binding to nucleic acids (). By automatically combining the 1605The cleversuite approach for protein characterization scales for nucleic acid binding (), burial (), membrane () and hydrophobicity () propensities, CM achieved a sensitivity of 0.91 and false positive rate of 0.08.
Cross-validation Through a 10-fold crossvalidation we find that CM has accuracy of 81.6% and separation from random of 0.3 (and Supplementary). The best performance was achieved with the AdaBoost () classification algorithm.
Independent validations
RNA-binding abilitiesRecent technological advances have made it possible to discover that number of proteins have RNA-binding ability (). We focused on RNA-interacting proteins (715 entries) detected with UV cCL and PAR-CL protocols on proliferating HeLa cells and compared them with the cell lysate
PerformancesThe single property analysis revealed a strong and consistent RNA-binding property of the dataset: RNA-binding scales () cover between 6265%. Moreover, it has been observed that protein disorder is an important feature for RNA-binding proteins (). In agreement with this result, we found a significant enrichment in disorder propensities (). CM automatically selects the scales for RNA binding (), disorder () and aggregation propensities () achieving a sensitivity of 0.91 and false positive rate of 0.07 on the entire dataset.
Cross-validation A10-fold cross-validation on both datasets yielded accuracy of 84.3% and separation from random of 0.5 (and Supplementary). The Extremely Randomised Tree classifier () was selected as the best performing algorithm for this case.
Independent validationsThe positive set contained proteins identified as RNA-binding using quantitative proteomics (). We removed any overlap between training and test sets using CD-HIT (), leaving the positive set size to 86 entries. The negative validation contained 250 not nucleic acid binding proteins (). Our predictions showed accuracy of 72.9% for the mRNA-binding set and 79.2% for the negative validation. The separation from internal random dataset was respectively 0.5 and 0.1 for the positive and negative testing sets. Using the same data as for CC validation, the RNApred () achieved accuracy of 82.5% for the positive set and 52.8% for the negative validation (; Supplementary Material). algorithms instead of the exhaustive search, but our focus is the simple and clear interpretation of scale contributions, which is not possible through more complex approaches. We base our approach on the assumption that the algorithm works optimally if the system is able to select its predictors without external intervention (). Similarly to what has been done to rationalize the determinants of protein aggregation (), the cleverSuite identifies the most relevant properties for a specific problem with the main differences being that: (i) fitting parameters are avoided and (ii) features are selected from a large pool of physico-chemical characteristics. Notably, the method allows the user to choose the reference set, which is strategic to circumvent the problem of the lack of negative cases in literature (). Although other useful tools are available to analyse protein features (), we did not find any general-purpose method to discriminate datasets using parameter-free combinations of physico-chemical characteristics and we hope that our efforts will inspire future studies in the field. In conclusion, the cleverSuites offers an easy-to-use interface, accessible to a wide range of experimental and computational scientists. Submissions are by default private, however, if a user wishes to share an analysis result or a classifier, there is an option to publish links on the 'featured results' page (http://s.tartaglialab.com/ clever_community, maintained by the authors).
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
P.Klus et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
DISCUSSION The cleverSuite provides a novel and unique approach for both characterization and classification of protein groups. In striking agreement with experimental evidence, we reported accurate predictions of protein solubility in E.coli (Niwa et al., 2009), RNA-binding ability in H. Sapiens (Castello et al., 2012), structural disorder (Sickmeier et al., 2007) and chaperone requirements (Kerner et al., 2005). Our performances are comparable to other algorithms that were built to predict specific protein features. In agreement with previous observations, we found that physicochemical propensities linked to structural disorder and are relevant for RNA-binding, chaperone requirement and solubility (Agostini et al., 2012; Calloni et al., 2012; Cirillo et al., 2014), which very well captures the central role of natively unfolded proteins in higher eukaryotes (Babu et al., 2011). This observation is further supported by direct comparison of H.sapiens and E.coli proteomes, which shows enrichment in hydrophobicity and aggregation propensity for E.coli and structural disorder for H.sapiens (all links to results are provided in Supplementary Table S1). Our findings suggest that the cleverSuite is an ideal tool to analyse the outcome of large-scale experiments. As shown in the examples, the algorithm can be applied to very diverse types of cases to allow a fine classification of protein features (Table 1). Future plans include incorporation of more properties and alternative ways to extract the signal from protein profiles. At present, the choice of propensity scales is mainly based on their previous use but custom scales are allowed in the webserver. We would like to note that our approach is not restricted to propensity scales and that any function mapping a primary structure into a profile could be interfaced with the algorithm. In next version, we are planning to implement the projection of profiles onto orthonormal bases, which should improve our performances. In the CM each physico-chemical property is described by same number of propensity scales (eight groups containing 10 scales each; Fig. 2 and Supplementary Fig. S3), which guarantees that there is not over-representation of a particular property. We stress that the algorithm is built in a way that only non-correlated scales are selected for the analysis. In fact, if two scales discriminate the same set of proteins, their combination together would result in a smaller coverage compared to non-correlated scales. The CM can compute up to 10 millions associations of propensities (i.e. five scales out of 80 groups) to find the optimal combination, which is computationally expensive but ensures an impartial and exhaustive search. For this reason, the calculations have been parallelized to complete the analysis in short time, even when the input sets are large. We could have used other
The cleversuite approach for protein characterization at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
