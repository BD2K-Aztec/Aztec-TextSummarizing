Motivation: Identifying interactions between drug compounds and target proteins has a great practical importance in the drug discovery process for known diseases. Existing databases contain very few experimentally validated drug–target interactions and formulating successful computational methods for predicting interactions remains challenging. Results: In this study, we consider four different drug–target interaction networks from humans involving enzymes, ion channels, G-protein-coupled receptors and nuclear receptors. We then propose a novel Bayesian formulation that combines dimensionality reduction, matrix factorization and binary classification for predicting drug–target interaction networks using only chemical similarity between drug compounds and genomic similarity between target proteins. The novelty of our approach comes from the joint Bayesian formulation of projecting drug compounds and target proteins into a unified subspace using the similarities and estimating the interaction network in that subspace. We propose using a variational approximation in order to obtain an efficient inference scheme and give its detailed derivations. Finally, we demonstrate the performance of our proposed method in three different scenarios: (i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network. Availability: Software and Supplementary Material are available at
INTRODUCTIONThe functions of pharmaceutically useful target protein families such as enzymes, ion channels, G-protein-coupled receptors (GPCRs) and nuclear receptors can be modulated by interacting them with drug compounds. Our knowledge about the genomic space of target proteins and the chemical space of drug compounds is piling up as a result of high-throughput experimental projects that analyze the genome and high-throughput chemical compound screening with biological assays. Unfortunately, our knowledge about the relationship between these two spaces remains quite limited * To whom correspondence should be addressed. due to laborious and costly experimental procedures. Existing databases such as ChEMBL (), DrugBank (), KEGG DRUG () and SuperTarget () contain information about a small number of experimentally validated interactions. Hence, successful computational methods for identifying interactions between drug compounds and target proteins make genomic drug discovery significantly efficient and effective. Computational approaches can be used to guide experimentalists towards new predictions and to provide supporting evidence for their experimental results. Traditional computational methods can be grouped into three categories: (i) docking simulations (), (ii) ligand-based approaches () and (iii) literature text mining (). Docking simulations require structural information of target proteins, which is not mostly available for some protein families such as GPCRs. Ligand-based approaches compare a candidate ligand with the known ligands of a target protein and may not perform well for target proteins with a small number of known ligands. Literature text mining based on keyword search cannot be used to detect unknown interactions and suffers from the redundancy due to non-standard naming practice for drug compounds and target proteins. Recently, there are many machine learning algorithms proposed for predicting drugtarget interactions using the chemical properties of drug compounds, the genomic properties of target proteins and the known interaction network (). The main assumption of these studies is that similar drug compounds are likely to interact with similar target proteins. These similarities between drug compounds and target proteins are often encoded using kernel functions designed specifically for chemical compounds and protein sequences, respectively (). The most basic statistical approach is to formulate the interaction network inference problem as a binary classification task between drugtarget pairs using pairwise kernel functions (). However, this approach can be computationally quite heavy due to the high number of drugtarget pairs. Supervised bipartite graph inference maps drug compounds and target points into a unified space (i.e. pharmacological space) using the chemical and genomic similarities and tries to estimate the interaction network using a distance-based procedure in that subspace (). Local models are also used to predict drugtarget interaction networks after their successful applications for proteinprotein interaction networks, metabolic
Kernelized Bayesian matrix factorization with twin kernelsnetworks and regulatory networks (). Instead of using the given interaction network just as the output, integrating a kernel function that considers the given network topology and the kernels calculated using chemical compounds and protein sequences can improve the prediction performance (van). In this study, we propose a novel Bayesian formulation that combines kernel-based nonlinear dimensionality reduction (), matrix factorization () and binary classification for predicting drugtarget interaction networks using only chemical similarity between drug compounds and genomic similarity between target proteins. Different from previous studies, our proposed method is the first fully probabilistic formulation for drugtarget interaction network inference. We show its performance on four benchmark datasets using three experimental scenarios with practical importance: (i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network.
MATERIALSIn this study, we consider four different drugtarget interaction networks from humans, namely, Enzyme, Ion Channel, GPCR and Nuclear Receptor, provided by. These datasets are publicly available at http://web.kuicr.kyoto-u.ac.jp/supp/yoshi/drugtarget/. We use these datasets as they are without adding new interactions from source databases.use KEGG BRITE (), BRENDA (), SuperTarget () and DrugBank () databases to collect information about the interactions between drug compounds and target proteins.summarizes the datasets in terms of numbers of drug compounds, target proteins and interactions. The set of known drugtarget interactions is regarded as 'gold standard' and used to evaluate the performance of our proposed method in the cross-validation experiments as in the previous studies ().
Drugtarget interaction data
Chemical dataChemical structures of drug compounds are extracted from the DRUG and COMPOUND sections in the KEGG LIGAND database ().calculate the structural similarities between drug compounds using SIMCOMP (), which represents drug compounds as graphs and calculates a similarity score based on the size of the common substructures between two graphs. Given two drug compounds d i and d k , chemical similarity between them can be found as s c (d i ,d k ) =|d i d k |/|d i d k | and the similarity matrix between all drug compound pairs is denoted as S c .
Genomic dataAminoacid sequences of target proteins are extracted from the KEGG GENES database ().calculate the sequence similarities between target proteins using a normalized version of SmithWaterman score (). Given two target proteins t j and t l , genomic similarity between them can be found as, where SW(,) gives the canonical SmithWaterman score and the similarity matrix between all target protein pairs is denoted as S g .
METHODSWe mainly consider the problem of predicting new drugtarget interactions for out-of-sample drug compounds and/or target proteins that are not in the given interaction network. Our proposed method can also be used to predict unknown interactions of the given network.
Problem formulationWe are given N d drug compounds denoted as X d ={d 1 ,d 2 ,...,d Nd } and N t target proteins denoted as X t ={t 1 ,t 2 ,...,t Nt }. We are also given a set of known interactions between these two sets as the N d N t adjacency matrix denoted as Y, where y i j =+1 if drug compound d i interacts with target protein t j and y i j =1 otherwise. We can have three different prediction scenarios:(i) find interacting target proteins from X t for a new drug compound d , (ii) find interacting drug compounds from X d for a new target protein t and (iii) estimate whether a new drug compound d and a new target protein t are interacting with each other or not. In order to attack these three scenarios with a single unified approach, we formulate the problem as a binary classification task, which requires to estimate whether there is an interaction between a drug compound and a target protein using only the similarities between drug compounds and the similarities between target proteins.
Kernelized Bayesian matrix factorization with twin kernelsIn order to obtain an efficient Bayesian algorithm, we formulate a fully conjugate probabilistic model and develop a deterministic variational approximation mechanism for inference. The main idea is to project drug compounds and target proteins into a unified subspace using the kernels calculated from chemical and genomic data, respectively. These lowdimensional representations of drug compounds and target proteins can be used to estimate their interactions.illustrates the proposed probabilistic model for predicting drug target interactions from kernels on drug compounds and target proteins with a graphical model. The kernel matrix calculated from drug compounds K d is used to project them into a low-dimensional space using the projection matrix A d. Similarly, the kernel matrix calculated from target proteins K t is used to project them into the same subspace, which is called 'pharmacological space'
M.Gnenin the previous studies (), using the projection matrix A t. The low-dimensional representations of drug compounds and target proteins in the pharmacological space, namely, G d and G t , are used to calculate the interaction scores between them. Finally, the given interaction matrix Y is generated from the interaction score matrix F. The notation we use throughout the rest of the this article is as follows: N d and N t represent the numbers of training drug compounds and target proteins, respectively. R gives the dimensionality of the projected subspace. The N d N d kernel matrix for drug compounds is denoted by K d , where the columns of K d by k d,i. The N d R matrix of corresponding projection parameters a i d,s and their priors  i d,s are denoted by A d and d , respectively, where the columns of A d and d by a d,s and  d,s. The RN d matrix of projected instances for drug compounds g s d,i are represented as G d , where the columns of G d as g d,i and the rows ofwhere the interaction scores between the matrices of projected instances and interaction variables are introduced to make the inference procedures efficient (), and the margin parameter  can be used to resolve the scaling ambiguity issue and to place a low-density region between two classes (interacting versus non-interacting), similar to the margin idea in support vector machines, which is generally used for semi-supervised learning (). N (;,) represents the normal distribution with the mean vector  and the covariance matrix. G(;,) denotes the gamma distribution with the shape parameter  and the scale parameter . () represents the Kronecker delta function that returns 1 if its argument is true and 0 otherwise. We only use the gamma and normal distributions in our probabilistic model. The main reason for choosing these specific distributions is that they allow us to obtain a very efficient inference mechanism easily due to conjugacy between them. Their advantage becomes clear when we explain our inference procedure. When we consider the random variables as deterministic values, the interaction score matrix that corresponds to the decision function values in discriminative methods can be decomposed asThis strategy allows us to make predictions for out-of-sample points using kernel functions.
Efficient inference using variational approximationExact inference for our probabilistic model is intractable and using a Gibbs sampling approach is computationally expensive (). We instead formulate a deterministic variational approximation, which is more efficient in terms of computation time. The variational methods use a lower bound on the marginal likelihood using an ensemble of factored posteriors to find the joint parameter distribution (). We can write the factorable ensemble approximation of the required posterior asand define each factor just like its full conditional distribution:denote the shape parameter, the scale parameter, the mean vector and the covariance matrix for their arguments,) denotes the truncated normal distribution with the mean vector , the covariance matrix and the truncationWe can bound the marginal likelihood using Jensen's inequality:and optimize this bound by maximizing with respect to each factor separately until convergence. The approximate posterior distribution of a specific factor  can be found asFor our proposed model, thanks to the conjugacy between random variables, the resulting approximate posterior distribution of each factor follows the same distribution as the corresponding factor.
Inference detailsThe approximate posterior distributions of the precision priors for drug compounds can be found asCopyedited by: SK
Kernelized Bayesian matrix factorization with twin kernelswhere the tilde notation denotes the posterior expectations as usual, i.e.. The approximate posterior distribution of the projection parameters for drug compounds can be found as a product of multivariate normal distributions:and the approximate posterior distribution of the projected instances for drug compounds is also a product of multivariate normal distributions:The approximate posterior distributions of the precision priors for target proteins can be found asThe approximate posterior distribution of the projection parameters for target proteins can be found as a product of multivariate normal distributions:and the approximate posterior distribution of the projected instances for target proteins is also a product of multivariate normal distributions:The approximate posterior distribution of the interaction scores is a product of truncated normal distributions given aswhere we need to find their posterior expectations to update the approximate posterior distributions of the projected instances for drug compounds and target proteins. Fortunately, the truncated normal distribution has a closedform formula for its expectation. The inference procedure summarized in Algorithm 1 sequentially updates the approximate posterior distributions of the model parameters and the latent variables until convergence, which can be checked by monitoring the lower bound in (1). The first term of the lower bound corresponds to the sum of exponential form expectations of the distributions in the joint likelihood. The second term is the sum of negative entropies of the approximate posteriors in the ensemble. The only non-standard distribution in these terms is the truncated normal distribution used for the interaction scores; nevertheless, the truncated normal distribution has a closed-form formula also for its entropy. In our implementation, the chemical similarity function s c (,) is used as the kernel function between drug compounds k d (,), which means that the chemical similarity matrix S c is used as the kernel matrix for drug compounds K d. Similarly, the genomic similarity function s g (,) is used as the kernel function between target proteins k t (,), which means that the genomic similarity matrix S g is used as the kernel matrix for target proteins K t. The provided similarity matrices S c and S g may not be valid kernels (i.e. positive semidefinite), but we use them as they are because our algorithm does not require them to be positive semidefinite. The hyper-parameters (  ,  ) and  g are set to (1,1) and 0.1, respectively.
Prediction scenariosWe consider three different scenarios for drugtarget interaction prediction. For these scenarios, we can get probabilistic estimates from our Bayesian model but the variances are observed to be very small due to discriminative nature of the model (i.e. modeling the interaction between drug compounds and target proteins by introducing the binary classification part with a large margin strategy just after the matrix factorization part). Hence, we only consider point estimates for simplicity without sacrificing the generalization performance.
Prediction for a new drug compoundIn the first scenario, we assume that we are given a new drug compound d and our task is to find the set of target proteins from X t that interact with d. We first need to calculate the similarities between d and X d :and these similarities can be used to find the interaction scores for d :where positive valued entries indicate that the corresponding target proteins interact with d .
Prediction for a new target proteinIn the second scenario, we assume that we are given a new target protein t * and our task is to find the set of drug compounds from X d that interact with t * . We first need to calculate the similarities between t * and X t :and these similarities can be used to find the interaction scores for t * :where positive valued entries indicate that the corresponding drug compounds interact with t * .
Joint prediction for a new drug compound and a new target proteinThe third scenario is the hybrid of the first two scenarios and our task is to find whether a new drug compound d and a new target protein t * interact with each other. We can find the interaction score for d and t * aswhere a positive value indicates that d and t * interact with each other. Note that d and t * can be a known drug compound and a known target protein, respectively, from the given interaction network in order to predict unknown interactions.
RESULTSIn order to illustrate the effectiveness of our proposed method, called 'kernelized Bayesian matrix factorization with twin kernels' (KBMF2K), we present the results of three experimental scenarios:(i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network.
M.GnenDrugs
Exploratory data analysis using low-dimensional projectionsKBMF2K can also be used for exploratory data analysis by displaying low-dimensional projections in addition to predicting interactions. For three different prediction scenarios described earlier, we provide visualizations on Nuclear Receptor dataset due to its small network size. In this set of experiments, we set the subspace dimensionality R = 2 and the margin parameter  = 0. Given a drugtarget interaction network, we want to investigate the interactions of new drug compounds and/or target proteins within that network. We do not include 10% of drug compounds and/or target proteins and their interactions to our training network giving us three different scenarios.displays the two-dimensional projections of training networks superimposed with the predicted projections for held-out drug compounds and/or target proteins. Provided interactions between drug compounds and target proteins are also shown as dashed lines for training network and thick solid lines for held-out drug compounds and/or target proteins. We would like to point out a couple of important observations from. First of all, KBMF2K successfully captures bipartite nature of the given interaction networks (i.e. two disjoint node sets) by placing drug compounds and target proteins as clearly separated node groups. Second, we can easily see that the dashed lines (i.e. interactions from training network) connect nearby drug compounds and target proteins. Finally the projections for held-out drug compounds/target proteins are meaningful because they are connected to nearby target proteins/drug compounds. The prediction performance using just two dimensions may not be enough for a reliable system, but these two-dimensional figures can definitely be used for exploratory data analysis.
Predicting interactions for the out-of-sample drug compoundsTo show the performance of KBMF2K in predicting interactions for new drug compounds, we perform experiments on the four benchmark datasets. We exactly follow the experimental procedure ofin order to have comparable results. For each dataset, drug compounds are split into five subsets of roughly equal size. Each subset is then used in turn as the test set and training is performed on the remaining four subsets. This procedure is repeated five times to obtain robust results. The subspace dimensionality R and the margin parameter  of KBMF2K are selected from {5,10,15,20,25} and {0,1}, respectively, using the prediction performances on the training sets.gives the average AUC (area under the receiver operating curve) values for) and KBMF2K. Note thatalso report results with pharmacological similarity between drug compounds. We compare our results with the results obtained using the same similarity measures in our experiments (i.e. chemical similarity for drug compounds and genomic similarity for target proteins). We see that KBMF2K achieves higher average AUC values on all datasets. KBMF2K significantly improves the results on Ion Channel and GPCR datasets by 10.7% and 4.6% respectively.shows the average AUC values for KBMF2K with changing subspace dimensionality and  = 0. On Nuclear Receptor dataset, we do not see any effect of the subspace dimensionality possibly due to small size of the interaction network. However, there is a clear increasing trend in AUC with increasing subspace dimensionality for other datasets. On Enzyme and GPCR datasets, we get the best results with R = 25. It is still possible to improve the results on Enzyme dataset by adding more dimensions to the common subspace of drug compounds and target proteins. Instead of using a cross-validation strategy, the intrinsic subspace dimensionality can be found while learning the model parameters using, for example, automatic relevance determination (). However, we leave this extension as future work.
Kernelized Bayesian matrix factorization with twin kernels
Predicting unknown interactions of the given networkIn order to illustrate the performance of KBMF2K in predicting unknown drugtarget interactions of the given network, we perform a new set of experiments on the four benchmark datasets. Using the best parameter values for {R,} found in the previous experiments, we train KBMF2K with the complete interaction network for each dataset. We rank the non-interacting pairs with respect to their interaction scores and extract the top 100 predicted interactions. We report only the top five predicted interactions for each dataset and give the full lists of predicted interactions as Supplementary material.lists the top five predicted interactions for each dataset. We check these predicted interactions manually from the latest online versions of ChEMBL (), DrugBank () and KEGG DRUG () databases. We see that 80% of the predictions (16 out of 20) is reported in at least one of these databases. This is a strong evidence for the practical relevance of our method. For example, Enzyme dataset has 2926 interacting and 292554 non-interacting (i.e. not known to interact) drugtarget pairs. We pick only the top five predicted interactions and see that four out of these five drugtarget pairs are currently reported in at least one database. KBMF2K correctly identifies three and four out of five predicted interactions on Ion Channel and GPCR datasets, respectively. The prediction performance of KBMF2K is even better on Nuclear Receptor dataset. The top five predicted interactions are currently reported in ChEMBL database. We also check the top 10 predicted interactions and see that all of them are reported in ChEMBL database. Note that the predicted interactions that are not reported yet may also exist in reality.
DISCUSSIONIn this study, we consider four different drugtarget interaction networks from humans involving enzymes, ion channels, GPCRs and nuclear receptors. We then propose a novel Bayesian formulation that combines kernel-based nonlinear dimensionality reduction (), matrix factorization () and binary classification for predicting drugtarget interaction networks using only chemical similarity between drug compounds and genomic similarity between target proteins. The novelty of our approach comes from the joint Bayesian formulation of projecting drug compounds and target proteins into a unified subspace using the similarities and estimating the interaction
M.Gnennetwork in that subspace. Our proposed method is the first fully probabilistic formulation proposed for drugtarget interaction network inference. We propose using a variational approximation in order to obtain an efficient inference scheme and give its detailed derivations. The most time-consuming steps of the proposed variational inference mechanism are covariance calculations because we need to perform matrix inversions. The time complexity of the covariance updates for the projection matrices in (3) and (6) is O(RN 3 d ) and O(RN 3 t ), respectively. The time complexity of the covariance updates for the composite components in (4) and (7) is O(R 3 ). The other calculations in these steps can be done very efficiently using matrix matrix or matrixvector multiplications. Finding the posterior expectations of the interaction scores in (8) only requires evaluating the standardized normal cumulative distribution function and the standardized normal probability density. In summary, the total time complexity of each iteration in our variational approximation scheme is O(RN 3 d +RN 3 t +R 3 ), which makes our algorithm very efficient compared to standard pairwise kernel approaches that require calculating an N d N t N d N t kernel matrix between object pairs and training a kernel-based classifier using this kernel matrix. In order to demonstrate the performance of our proposed method, called 'kernelized Bayesian matrix factorization with twin kernels' (KBMF2K), we use four benchmark datasets containing known drugtarget interaction networks, chemical kernels between drug compounds and genomic kernels between target proteins provided by. We design three different experimental scenarios with practical importance as follows (i) exploratory data analysis using low-dimensional projections, (ii) predicting interactions for the out-of-sample drug compounds and (iii) predicting unknown interactions of the given network. In the first set of results, we show that the resulting low-dimensional projections can be used to predict drugtarget interactions and practitioners can use these projections as two-dimensional figures for exploratory data analysis. The remaining sets of results show that our novel probabilistic interpretation obtains better generalization performance than earlier optimization-based approaches. KBMF2K uses one kernel function for chemical similarity and another kernel function calculated on protein sequences for genomic similarity. The performance of our approach can be improved by integrating multiple kernels for both kinds of similarity. In kernelbased methods, this approach is known as 'multiple kernel learning' () and our method can be extended towards that direction.
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
