Motivation: Three-dimensional reconstruction of consecutive serial-section transmission electron microscopy (ssTEM) images of neural tissue currently requires many hours of manual tracing and annotation. Several computational techniques have already been applied to ssTEM images to facilitate 3D reconstruction and ease this burden. Results: Here, we present an alternative computational approach for ssTEM image analysis. We have used biologically inspired receptive fields as a basis for a ridge detection algorithm to identify cell membranes, synaptic contacts and mitochondria. Detected line segments are used to improve alignment between consecutive images and we have joined small segments of membrane into cell surfaces using a dynamic programming algorithm similar to the Needleman–Wunsch and Smith–Waterman DNA sequence alignment procedures. A shortest path-based approach has been used to close edges and achieve image segmentation. Partial reconstructions were automatically generated and used as a basis for semi-automatic reconstruction of neural tissue. The accuracy of partial reconstructions was evaluated and 96% of membrane could be identified at the cost of 13% false positive detections.
INTRODUCTIONSerial-section transmission electron microscopy (ssTEM) can produce reconstructions of neuronal morphology at very high resolution, including synaptic organelles and the contacts between neurons that constitute circuits. Alignment and reconstruction of ssTEM images is currently performed manually or semiautomatically, with the aid of computer software, to generate a 3D model of the imaged neuron and, with other such neurons, of the synaptic circuits to which that neuron contributes (). In some * To whom correspondence should be addressed. cases, approximate alignment can be achieved automatically but, even so, high-quality circuit reconstructions still require many hours of manual tracing and annotation, and are highly dependent upon the interpretative skill of the human observer and the complexity of neuronal arborizations being reconstructed (). For example, neurites are simple and have been completely reconstructed by manual means in the nematode Caenorhabditis elegans () but are complex, highly branched and reconstructed only with great difficulty or incompletely in the fruit fly Drosophila melanogaster (). Existing methods of image alignment usually rely on a control point selection method. Semi-automatic alignment can be carried out by identifying control points manually and aligning these by means of a particular algorithm (). Automatic alignment can be carried out with control point detection algorithms (), and works best when image quality is consistent throughout the dataset, but performance can be degraded when artefacts such as gaps, noise, differing levels of brightness and/or contrast are present in the images being aligned. Such artefacts are unfortunately fairly common in ssTEM because of the complicated preparative procedures and increase as the series of images becomes longer. Most currently used systems for automatically annotating electron microscopy (EM) data rely on some variant of the watershed algorithm to detect boundaries between cells (). This method usually results in oversegmentation, and several methods have been identified to reunite incorrectly over-segmented areas after the watershed algorithm is run (). A commonly used method to detect membrane present in an image is to pre-process the image by a Gaussian blur combined with image derivative or Hessian matrix analysis. Also called Gaussian smoothed Hessian (GSH), this method is effective at filtering out noise while retaining membrane edges in the image (). Random forest classifiers have also been used to successfully combine outputs from a range of generic feature detectors (). GSH, and other generic feature detectors, are efficient to implement and make reasonable assumptions when membrane profiles are Gaussian, but when line profiles are predictable the construction of a specific filter may improve performance (). For this reason, we have customized a set of receptive fields to specific features visible in EM images.Page: 2217 22162223). Four categories have been annotated: sharp membranes that pass vertically through the section thickness (a), blurred images of obliquely sectioned membrane (b), synaptic profiles (c) and mitochondria (d). Each image patch is 227227 nm.
Biologically inspired neural reconstructionHere, we explored a novel approach based on receptive fields to identify the likely locations for cell membranes, and a ridge detection approach to identify lines within the receptive field responses. We have then used a shortest path approach to close the edges detected in the image. Lines of cell membranes are aligned in 3D to improve the image alignment and generate partial 3D reconstructions. Detected membrane points are further analysed to identify likely organelle and synapse locations within the ssTEM images. Receptive fields are a well-studied feature of many sensory interneurons, especially in visual systems, and define a region within which the neuron responds to a particular stimulus, such as a line segment at a particular orientation (). Computational models of the brain also use receptive fields to further understand the visual system (). In the system presented here, receptive fields are learnt from examples of image patches taken from ssTEM training data using supervised learning techniques. The resulting Gabor-like receptive fields are applied to ssTEM data images to annotate automatically neuronal membranes, synaptic connections and organelles such as mitochondria. Objects recognized by the system are then used to improve the alignment of consecutive images and produce partial 3D reconstructions as a starting point for manual annotation. Using this biologically inspired approach to analyse and understand biological images has the potential for further improvements in semi-automatic segmentation by applying additional properties of biological vision.
METHODS
Receptive fieldsOver 500 examples of membrane, synapses and mitochondria from serial 50 nm thick sections of the mushroom body calycal neuropiles of Drosophila were manually annotated (). The images were generated by Zhiyuan Lu and Ian Meinertzhagen, Dalhousie University, seefor details.Training images were first normalized to have a range between 1 and 1. Then line detection Gabor filters at different orientations were used to detect the best orientation for each image automatically. Images were rotated so that a vertical Gabor patch produced the largest response. In the case of images of mitochondria and synapses, rotation was performed to orientate the darkest half of the image to the left. Examples of resulting image patches are shown in. In the next step, a neural network was trained on the manually annotated image patches, randomly split into training and test groups, and a selection of 400 random images from the same dataset. A standard feed forward back propagation neural network was used, with a single input per pixel and as many outputs as target classes. All weights and biases in the network were initialized to zero and mean-squared error was used as the error function. Membrane receptive fields were trained by specifying just one target class and training on membrane (or oblique membrane) from the training images with random images provided as negative examples. Synapse and mitochondria receptive fields were trained at the same time by specifying two target classes and training on positive examples from the manually annotated dataset, with membrane and random images used as negative examples. Training continued until classification performance on the test images stopped improving, typically after 1020 iterations. Resulting weight matrices for each class are shown in. Note that a self-organizing map (SOM) learning system also produced similar results and was able to identify membrane, synapse and mitochondria classes unsupervised, as shown in.
Membrane detectionSpace-filling 3D reconstructions require us to identify the surfaces of neurons. These are necessary as the first step in identifying sites of contact between reconstructions of neighbouring neurons. As the basis to detect membranes, we therefore used the membrane weight matrices from the neural network training to build a membrane detection tool. Weights were multiplied with a Gaussian probability density having a standard deviation chosen so that a constant background input produced a response of 0. The resulting Gabor-like patches were rotated to create a filter bank of membrane receptive fields. A total of 36 orientations was sufficient to produce reasonable accuracy to detect membranes (). Filters were convolved over large image patches from the same data to produce filter response images as shown in. Membrane detection based on these responses was carried out by choosing high-scoring local maxima as seed points and then searching for neighbouring areas of high response and similar orientation. The search area was modified so that response scores very near the seed point were inhibited and responses with similar orientation to the seed point, in the Page: 2218 22162223
S.Knowles-Barley et al.A B Cexpected direction, were facilitated (or received less inhibition). Modifying the scores for nearby receptive field responses in this way can also be thought of as an approximation to the lateral inhibition and excitation observed in biological visual systems (). This search was repeated in a stepwise manner to propagate the current line of membrane progressively until a lower bound at some limit was reached. Neighbouring areas of high response with different orientations were marked as potential junction points and investigated in the same manner. An example from this membrane detection process is shown in. Dataset S2 contains an open-source reference implementation of the membrane detection algorithm.
Feature detectionEach point of membrane so detected was then classified as synaptic profile, mitochondrion or normal membrane. Filter banks were created by rotating synapse and mitochondron weight matrices to the same orientations to which the membrane Gabor-like patches were rotated. Note that twice the number of orientations were required, because these weight matrices were not symmetrical. At each point of detected membrane, synapse and mitochondria filter responses were calculated by element-wise multiplication and summation. Only two filter responses were calculated for each feature; one at the same orientation of rotation as the detected membrane, and one at the same orientation plus 180 @BULLET. Filter response thresholds were chosen to achieve acceptable error rates for synapse or mitochondria classification.
Edge closureMembranes detected in this way usually failed to produce a fully segmented profile because many lines from obliquely sectioned membranes remained unclosed. We were able to complete closure by identifying end points and joining them to neighbouring lines based on the shortest path through the energy function of the receptive field responses. Dijkstra's shortest path algorithm was used to calculate the shortest path over a four-connected image graph based on the distance function shown in Equation (1), where R x, represents the filter response at angle , centred at pixel x.For correctly detected edges, reasonable closure was achieved with this method, but incorrectly detected edges introduced additional edge errors when closing lines were added.
Alignment improvementSequential images can be manually aligned by selecting several pairs of control points corresponding to the same x,y location for consecutive images z1 and z2. This approach is adopted by widely used software, Reconstruct (). Automatic selection of control points is also possible by searching for unique image features in both images, as demonstrated by software TrakEM2 (). Automatic methods are usually effective at performing a global alignment, but significant local errors can be introduced when too few control points are detected, or when image features are inconsistent between images, as when sections have been locally distorted during microtomy or imaging, resulting in the need for manual correction (). Lines of detected membrane are a useful means to improve an existing image alignment. Because membrane is abundant in EM images, many potential control points can be found by aligning ridge detection results. Drawing on experience with the linear alignment of other biological structures for this purpose, we therefore developed a dynamic programming algorithm, similar to the NeedlemanWunsch () and SmithWaterman () DNA sequence alignment procedures, with a cost metric based on the euclidean distance and angular subtense. The algorithm also has similarities with sequence matching algorithms implemented in 2D for curve morphing () and in 3D for neuron shape recognition (). We introduced a different cost metric and a modified three-pass alignment procedure that could perform many-to-many alignments and allows branching to occur within sequences. Combinations of this new alignment procedure with the existing application areas allowed morphing of multiple curves at once, and recognition of branching neuron shapes or even networks of branching neurons. Dataset S2 includes an open-source reference implementation of the alignment procedure that can be easily modified for application to other alignment problems such as these. Two consecutive images (z1, z2) from the image stack were aligned by matching sections of detected membrane in z1 with sections in z2, so that the Page: 2219 22162223
Biologically inspired neural reconstructiondistance and angular subtense between all matched points were minimized. This problem was similar to a many-to-many ends-free DNA sequence alignment with the cost metric shown in Equation (2), where d(p 1 ,p 2 ) is the euclidean distance between points p 1 and p 2 , and a is an arbitrary angle constant (a = 20 for our implementation). In principle, alignment can occur in either the forwards or backwards direction, so that low-cost diagonal lines in the cost matrix indicate the best alignment. Similarity matrix H was calculated and the traceback procedure () used to find the best alignment of points in z1 to points in z2. An example ofa cost matrix and the corresponding alignment points is shown in. Further details, including the calculation of the similarity matrix, are included in Supplementary Text S1.Once alignment was complete, the average offset between aligned points was calculated and used to improve alignment between z1 and z2. This process was repeated until the average directional offset was <1 pixel. The result from a single alignment is shown in. This alignment method assumes that the direction of membrane movement between consecutive images, when averaged over a sufficiently large area, is close to zero. For example, in a given alignment the amount of membrane moving to the left is assumed to be approximately equal to the amount of membrane moving to the right. Depending on the angle of ultrathin sectioning and the particular area of neural tissue being imaged, it is possible that there will be a bias in the direction of overall membrane movement. This bias may exist for the entire image, or for small sections of it, especially where there are large bundles of neurites all running in the same direction. Image alignment in this case does not differentiate between distortions due to preparation or imaging artefacts and areas of bias resulting from membrane movement. Ideally, we would like to correct for distortions while preserving any movement bias. However, considering 2D control points alone makes this problem ambiguous without further information. One solution to this ambiguity is to perform membrane alignment only on the highest-scoring sections of membrane; these sections of membrane have clearer, thinner profiles in the image and are expected to be perpendicular to the cutting plane. In this way, we can assume that any alignment errors are more likely to be from distortions rather than membrane movement and can use a deformation transform with greater confidence. However, this method can still introduce small errors that accumulate, resulting in large errors over many sections. A second solution is to simply use linear translation and rotation for the alignment to ensure that no unwanted distortions are introduced. This method may result in poor alignment where there are large areas of imaging artefacts. Alignment results are considered as the surfaces of cell membranes or organelles in 3D. By combining multiple alignment results, it was possible to generate partial 3D reconstructions as shown in.
A B C
S.Knowles-Barley et al.
RESULTSManual reconstructions of EM data are difficult to compare directly with segmentation derived from algorithms. Reconstructions areusually performed with the intention of tracing the neuron correctly over many sections rather than identifying the exact location of the cell membrane in every image. With these goals in mind, manual reconstructions generate the general shape of the neuron and overall neuron morphology along with the contacts made with other neurons correctly, but with the exact location of membrane not necessarily accurate in all places. In areas where a membrane runs obliquely in the section and appears blurred in its corresponding projection image, or where a large presynaptic density is present (and c), membrane signal can occupy a width of 20 pixels or more at a resolution of 3.7 nm per pixel. For the same dataset, tracing variation between experts can be up to 20 pixels, or 74 nm, depending on both the acceptable level of accuracy of tracing with a manually controlled mouse and true uncertainty in the location of oblique membranes (data not shown). This looseness in manual tracing makes direct comparison between manual and automatic tracing methods difficult to achieve. Choosing a performance metric that recognizes topological correctness rather than small differences in boundary locations () and using high-quality datasets against which to assess automatic tracing are both important considerations. To overcome the problem of the disparity between manual and automatic tracing methods, an interactive web interface was developed to view and correct membrane automatically traced from EM images that had previously been annotated manually. Errors made by the algorithm were classified as either false positives (locations where membrane was detected by the algorithm but was not actually present) or false negatives (where membrane was present but not detected) as shown in. Using the web interface, we identified false positive lines by clicking on them,and drawing in manually the missing, or false negative, lines. Using this method, all errors were identified and a fully traced membrane dataset was constructed within a small volume (Dataset S1). Selected trace results and alignment improvements were imported into manual reconstruction software, Reconstruct (), for direct visual comparison with manual tracing. 3D renderings of results are shown in. Alignment improvement and semiautomatic tracing produced a more accurate representation of the reconstructed bouton of a projection neuron, the main input neuron to the mushroom body calyx. The semi-automatic annotation is smoother and small misalignments in the z direction are corrected. The correlation coefficient between pairs of consecutive images was also calculated for the volume shown in. The average correlation coefficient was 0.29 after manual alignment, and 0.32 after alignment improvement using a linear transformation. Note that this level of accuracy can also be achieved by careful manual annotation but would take much longer time to complete. Exact membrane accuracy is usually traded for faster, less accurate tracing that preserves topological correctness. The fully traced membrane dataset was used to optimize and test algorithm performance. Convolutions necessary for the line detection algorithm were implemented on a graphics processing unit (GPU) to improve algorithm speed. Edge detection parameters were first estimated empirically, and then optimized by simplex or gradient descent optimization to maximize metric scores. The Rand index, a commonly used measure of segmentation performance (), was used to assess performance, as shown in. Performance was also measured by the number of separating pixels between segments that were correct or incorrect as a proportion of total true positive separating pixels, as shown inand displayed inRand index is expressed as a measure of similarity, with 1 being identical to the manually corrected segmentation. Separating pixel true positive (Tp) false positive (Fp) and false negative (Fn) rates are shown as a proportion of the total true positive separating pixels. Algorithm parameters were optimized by simplex or gradient descent to find 10 times more false positives than false negatives or to maximize the Rand index score. The 5-fold cross-validation was used to validate Rand index scores.Results were assessed before and after edge closure (open edges and closed edges, respectively). Performance is compared against the watershed algorithm applied to an optimized GSH, and to a manually trained random forest classifier (Ilastik). False positives are expressed as a percentage of true separating pixels, as determined by manual annotation. a receiver operator characteristic (ROC) in. Membrane detected within 10 pixels of manually annotated membrane was considered correct, because for the dataset used here this width would correspond to a flat section of membrane at an oblique angle of 36 @BULLET. Performance was benchmarked against GSH () and a freely available random forest classifier, ilastik (), manually trained on a range of generic features to identify cell membrane. Scores from both these benchmarks were segmented by the watershed algorithm. Parameters were optimized to maximize metric scores in both cases. Responses of the Gabor-like receptive fields were robust to several types of noise sometimes encountered in ssTEM images such as lowcontrast images, blurred or out-of-focus areas and sudden or gradual changes in brightness. After optimization, the ridge detection and edge closure methods were able to join gaps where noise such as oblique membrane or stitching artefacts obscured the receptive field responses. Line segments identified by edge detection and edge closure operations were further classified as enclosing the profile of either a synapse or a mitochondrion by the receptive fields shown in
A B
Biologically inspired neural reconstructionPage: 2222 22162223. False positive rates were higher than those for membrane detection; however, many false positives were identified in regions near an actual synapse or mitochondria. This level of performance could be useful for narrowing down search areas for manual classification of such biologically significant features. We also trained the ilastik classifier using the membrane receptive field responses as input features. When trained on receptive field responses alone, results were slightly better than those when trained on generic features (0.72 Rand index). Results improved further when trained on both receptive field responses and generic features (0.74 Rand index).
S.Knowles-Barley et al.
DISCUSSIONWe have presented a set of computational methods for EM image alignment and reconstruction, based on a set of receptive fields learnt from EM image data. The identification of many control points for aligning consecutive images can improve upon manual alignment methods and is robust to many types of noise encountered in EM images. Closing edges based on a shortest path algorithm can also achieve a full segmentation of images and additional receptive fields can be used to identify the profiles of synapses and other organelles present in ssTEM images. The ridge detection approach is complementary to existing regional or watershed-based methods, and achieves similar or superior results. Aligning points of membrane by the dynamic programming algorithm is also complementary to existing control point-based alignment methods and can improve upon these in some cases, especially at places where areas of noise or imaging artefacts affect control point properties. An open-source reference implementation of the ridge detection and alignment algorithms is available for download in Dataset S2. The manual alignment and segmentation of detailed ssTEM images is very time consuming, but information on synaptic connections obtained by these means is essential for research in systems neuroscience (). This reawakened need has recently received renewed recognition, identified in the recently designated field of connectomics (). Inspired by the example of tools used in biology for molecular alignment, the set of methods we report for improved alignment and detection of membrane is able to assist in the time-consuming process of manual annotation. Further information about likely membrane locations is also available from consecutive images in the stack. Areas where membrane alignment is poor between two images in the z-axis may indicate a false positive or false negative identification in either image. Utilization of this additional information and further improvements in both image processing techniques and image quality will help lead to the complete automation of neuronal reconstruction in 3D, and the complete identification and definition of circuits constituted by such reconstructed neurons. Approaches to image analysis based on receptive fields are inspired by research into the visual systems especially of mammals () and insects (O'), in which visual interneurons have been shown to respond to bars, lines or edges. That area of vision research is under constant evaluation, and advances in it can lead to improved accuracy for segmentation and feature detection. Future avenues of research include identifying additional useful receptive field types and combining outputs from different receptive fields into a layered system for more accurate detection of cell membranes and other organelles. Applying these techniques to ssTEM data offers for the future an improved understanding not only of visual systems but in turn also a further improvement of such computational techniques.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
