The 'omic' data such as genomic data, transcriptomic data, proteomic data and single nucleotide polymorphism data have been rapidly growing. The omic data are large-scale and high-through-put data. Such data challenge traditional statistical methodologies and require multiple tests. Several multiple-testing procedures such as Bonferroni procedure, Benjamini–Hochberg (BH) procedure and Westfall–Young procedure have been developed, among which some control family-wise error rate and the others control false discovery rate (FDR). These procedures are valid in some cases and cannot be applied to all types of large-scale data. To address this statistically challenging problem in the analysis of the omic data, we propose a general method for generating a set of multiple-testing procedures. This method is based on the BH theorems. By choosing a C-value, one can realize a specific multiple-testing procedure. For example, by setting C ¼ 1.22, our method produces the BH procedure. With C51.22, our method generates procedures of weakly controlling FDR, and with C41.22, the procedures strongly control FDR. Those with C ¼ G (number of genes or tests) and C ¼ 0 are, respectively , the Bonferroni procedure and the single-testing procedure. These are the two extreme procedures in this family. To let one choose an appropriate multiple-testing procedure in practice, we develop an algorithm by which FDR can be correctly and reliably estimated. Simulated results show that our method works well for an accurate estimation of FDR in various scenarios, and we illustrate the applications of our method with three real datasets.
INTRODUCTIONThe advance of 'omic' technologies has led to a great development of large-scale data such as microarray data, transcriptomic data, metabolomic data and proteomic data. These 'omic' data enable us to take a global insight into complex biological procedures, the interaction between genetic and environmental factors and pathological mechanisms of complex diseases, such as diabetes, heart disease, hypertension and various cancers, via identification of genes differentially expressed and cluster or classification of functional genes, pathway or network. Such large-scale data or high-throughput data challenge traditional statistical tests () because the traditional statistical tests are single tests. In a single hypothesis test, the threshold is meaningful for determining whether a test is significant because is a probabilistic threshold for the occurrence of an event in a population. However, threshold  0.05 does not remain valid for multiple statistical analyses of omic data because, for example, in identification of 10 000 genes, at least 500 findings are expected by chance at the significance level of 0.05 (). Therefore, threshold is required to be adjusted for multiple tests. Currently, several statistical procedures have been developed for adjusting threshold or adjusting P-values in the multiple tests. Among them, the Bonferroni procedure, the Holm procedure (), the Hochberg procedure (), the Westfall and Young procedure (), the Sidak procedure (), the BenjaminiHochberg (BH) procedure () and the BenjaminiLiu procedure () are typical multiple-testing approaches. Among these procedures, the BH procedure has been most broadly applied in practice. But we found that the true false discovery rate (FDR) does not always remain consistent with the estimated FDR of the BH procedure, and all existing multiple-testing procedures are actually special cases of the multiple-testing procedure family that ranges from the single-testing procedure to the Bonferroni procedure; in other words, these procedures give different rejection space (). In practice, our simulation also shows that true FDR is often significantly overestimated or underestimated by the BH procedure. To accurately estimate FDR in a largescale statistical analysis, here we propose a method that is based on the BH theorems to generate a set of multiple-testing procedures in a range of the single-testing procedures to the Bonferroni procedure and a simulation algorithm to choose a desirable procedure.
METHODS
Rejection area for the hypothesis testsHere we focus on discussing rejection areas of the single-testing procedure, for G hypotheses to be tested, a single*To whom correspondence should be addressed. testing procedure has the largest rejection area: As  G where is a probabilistic threshold, whereas the Bonferroni multiple-testing procedure has the smallest rejection area: AB  =G  G . These are two extreme rejection areas. In the single-testing procedure, G hypotheses would be rejected by chance, whereas the Bonferroni multiple-testing procedure would have a chance of to reject the G hypotheses, which is called the family-wise error rate. The rejection area of the BH multipletesting procedure is area under diagonal line, which is half of that of the single-testing procedure, ABH  R G 0 i=Gdi  aG=2 where i is the i-th hypothesis. But different from the single-testing procedure where is set for all hypotheses and the Bonferroni multiple-testing procedure where / G is given for all hypotheses, the BH multiple-testing procedure is a procedure where, from G to 1, the adjusted values are on a diagonal line, its rejection area is G/2. So the BH multiple-testing procedure falls in between the single-testing procedure and the Bonferroni multiple-testing procedure. Therefore, in theory, it is possible to give any multipletesting procedure with a rejection area from G to .
Benjamini-Hochberg theoremsFor m null hypotheses H 1 , H 2 ,. .. , H m , testing them has corresponding P-values p 1 , p 2 ,. .. , p m. Let p 1 , p 2 ,. .. , p m be the ordered P-values and their corresponding ordered null hypotheses be H 1 , H 2 ,. .. , H m. Then, we have a BH procedure: Let k be the largest i for which p i i m , then all H 1 , H 2 ,. .. , H k would be rejected. THEOREM: for independent statistical tests and for any configuration of false null hypotheses, the above procedure controls the FDR at the significance level (). This theorem is based on the following lemma: LEMMA: define Q  V/(V  S) as FDR where V and S are, respectively, numbers of findings in true and false null hypotheses, for any m 0 independent P-values corresponding to true null hypotheses where 0 m 0 m and for any m 1 P-values corresponding to false null hypotheses where m 1  m  m 0 , the BH procedure satisfies inequalityBy integrating inequality Equation (1), we obtain EQ m 0 m 5 2 and the FDR is controlled (). Because 0 m 0 m, any procedure with function of i p i fi m 3 also satisfies inequality Equation (2) and has control of FDR where i is an ordered number from 1 to m, and fi is any function of i and 1 fi m. From Equation (3), one can see that the aforementioned multiple-testing procedure becomes the single-testing procedure when fi  m, the Bonferroni procedure when fi  1 or the BH procedure when fi  i.
Function fiSuppose we have a set of observed P-values p 1 ,. .. , p k ,. . ., p G for G null hypotheses H 1 , H 2 ,. .. , H k ,. .. , H G. Let them be ranked as p 1 :::: p i ::: p G with corresponding ordered null hypotheses H 1 , H 2 ,. .. , H i ,. .. , H G where i is the i-th position in the ranked space corresponding to k in the unranked space. We declare all hypotheses H j i to be interesting when p i ' i in a step-up fashion where ' i is an adjusted. To realize a general adjustment of for any control of FDR across the whole observed P-values, we need a control sequence. To this end, let a set of G q-values be a linear-rank sequence q 1 5q 2 5. .. 5q g 5. .. 5q G where g  1,.., G and q g  g=G. We then define a ratio of difference between two adjacent q-values to the sum of them as q g  q g1  q g  q g1  4 and take the sum of the ratios over subset i,where S 1  1, i  2, 3,. .. , G and in the whole ranked set, we haveThus, the control sequence consists of a set of ranked rates with a power C:where C is referred to as control value. In the control sequence, we have R 1 % 0 for S 1  1 and R G  S G =S C  1 C  1 for S G  S. With the control sequence, function of i is found to be fi  G Ri 8 then is adjusted asEquation (9) gives a family of multiple procedures from the singletesting procedure to the Bonferroni procedure. The C-value is a socalled control value because it has a control effect on ' i ; in other words, different C-values have different control levels of false-positive findings. For example, when C  0, then R i  1 and ' i  G 1 =G  for all P-values, which is the single-testing procedure; when C ! 1, then lim C!1 R i  0 and lim C!1 ' i  =G or C  G41000, R i % 0 and ' i % =G for all P-values, which is just the Bonferroni procedure; and if C  1.22, we have ' i % i G , which is just the BH procedure ().. Area of rejection. Single-testing procedure is a top (solid) line with '  for all genes to be tested. The Bonferroni (Bon-) procedureis bottom (dash and dot) line with '  =G for all genes and its area for reject is area under (dash and dot) line (1=G  G  where ' is an adjusted. The BH-procedure is a up-diagonal (dash) line with ' i  i=G for gene i, and its area of rejection is area under diagonal line ( G=2) where ' i is an adjusted Thus, at C41.22, Equation (9) generates a set of multiple-testing procedures that have stronger FDR control than the BH procedure, whereas at C51.22, it generates another set of multiple-testing procedures that have weaker FDR control than the BH procedure (). Therefore, the method not only can realize the existing multiple-testing procedures but also can produce a new procedure by choosing an appropriate C-value ().
0
C-value choice for FDR controlTo control FDR, we need to choose a C-value to generate a multipletesting procedure. In theory, one can use a permutation approach () to determine a multiple-testing procedure. But as we will see in Section 3, the permutation is not a good way because it tends to significantly underestimate FDR. Therefore, we here propose an alternative approach to choose a desirable C-value for a real dataset. For the convenience of discussion, we focus our algorithm on traditional twocondition (or two-class) t-test methodology. Our algorithm runs through the following nine steps, among which Step 2 is to calculate means, variances and distances of each gene, Steps 3 and 4 are to simulate data using parametric bootstrap and Steps 5 and 6 are to estimate FDRs using a set of multiple procedures:STEP 1: apply a statistical method and a set of multiple procedures to real data and calculate a real ratio set of findings by comparing the ordered P-values to M sets of adjusted values: m  N m =G where m  1,. .. , M, and N m is number of findings by a statistical method in real data at the m-th C level. STEP 2: calculate mean " x gk and variance 2 gk of expression values of gene g (g  1,. .. ,G) in condition k (k  1, 2) from a real dataset, distance d g between two means for each gene g, d g  " x g1  " x g2 , and sort d-values from the largest to the smallest. STEP 3: adjust distance value byd g , otherwiseSTEP 4: determine a distribution of the real dataset. For microarray data, normal distribution is good, and for transcriptomic data, negative binomial distribution or Poisson distribution may be considered. Here, as an example, we focus on microarray data and use a normal pseudorandom generator to generate expression noise from gene to gene in each condition:w gkr  N 1 0, gk , r  11 where r is the r-th replicate, r  1,. .. , R k where R k is replicate number in condition k, and gk is standard deviation for gene g in condition k. We set g1  g2 to generate the same expression noise distribution in two conditions. Then the adjusted d-values are randomly assigned to m G genes:otherwise, where U g is the uniform random variable from gene to gene, and b is a weight value. The b-value should be smaller if ^ M (the smallest estimated ratio of findings) is larger than M (the smallest real ratio of findings); the b-value should be larger, otherwise. STEP 5: apply the same statistical method to the simulated data and obtain a set of G P-values from a given distribution. Apply Equation (7) and Equation (9) and a set of M C-values to create M multiple-testing procedures that have already been used in the real data and do multiple comparisons. STEP 6: because differentially expressed genes are given, count false findings and calculate FDR. STEP 7: , a and b are determined by fitting the estimated ratio set of findings to the real ratio set of findings. We begin with  a  b  1 and roughly check whether the estimated ratio set of findings identified by M multiple-testing procedures is fitting to the real ratio set. If yes, go to Step 8; otherwise, reset , a and/or b values (see Section 4) and again perform Steps 35 until the estimated ratio set is close to the real one.STEP 9: smooth the estimated FDRs by using polynomial regression. The method is to plot M estimated FDRs versus M C-values (from the smallest to the largest) to yield an observed line, use the polynomial regression line to fit the observed line, then make solution for regression coefficients 1 ,. .. , v and use the polynomial regression equation to calculate the FDR corresponding to each C-value. The order in polynomial regression depends on fitting. This is easily done in Excel.Plot the real and estimated ratio sets of findings identified by M multiple-testing procedures, and fit a linear regression model with intersection 0 and regression coefficient 1. If j 0 j 0.1 and 0:9 1 1:1, then the estimated ratio set of findings is almost identical to the real ratio set across M multiple-testing procedures, and the true FDR set would also be given with the estimated FDR set; a C-value would be chosen by choosing a calibrated FDR. Otherwise, repeat Steps 47 by resetting parameters a, b and until j 0 j 0.1 and 0:9 1 1:1.. Multiple procedures. These multiple-testing procedures for testing 7129 genes differentially expressed between two conditions are created by using C  0.50,. . .1.22,. . .3.0 on Equation 9. Compared to the BH-procedure (dash line) in, the procedure with C  1.22 (deep purple and solid line) is the BH-procedure. Therefore, procedures with C41.22 have stronger control of FDR than the BH-procedure while those with C51.22 have weaker control of FDR than the BH-procedure
Performances of statistical methods
RESULTS
Simulation evaluationWe used Tusher et al.'s (2001) microarray data to illustrate this algorithm. We downloaded the data from the website http:// www-stat.stanford.edu/*tibs/SAM/. The data consist of 7129 genes and eight human lymphoblastoid cell line samples, among which four were treated with ionizing radiation and the remainders treated with un-ionizing radiation were used as controls. From the real microarray data, means and variances of expression values of each gene in two conditions were obtained, and a normal pseudorandom generator, any one of two means, any one of two standard deviations for each gene and four replicates were used to create two noise expression datasets of 7129 genes with equal variances. Then, simulated data were generated by linearly and randomly assigning condition effects  300U on differential expressions between the two conditions to 30% of genes in the two noise datasets where U is a uniform variable in. Note that our simulation procedure generates strong dependence among these 30% of genes in assigning their expression values. We applied a classical two-condition t-test method to this simulated dataset and set M  140 C-values from 0.01 to 1.4 to create 140 procedures for multiple tests and obtained 140 ratios of findings. By applying the aforementioned algorithm and adjusting a, b and values, we found that when a  0.001, b  5 and  0.054, 140 estimated and real ratios of findings are close together. Thus, the results were averaged over 15 repeated simulations and displayed in.shows that a plot line of estimated against real ratios of findings is almost a diagonal line with intersection 0  0.009 % 0 and regression coefficient 1  1.0576 % 1, so the estimated ratio set of findings is almost identical to the real one. From, one also can see that the plot dots of estimated FDRs versus true FDRs are almost on a diagonal line, suggesting that the estimated FDR is approximately identical to its true value at each FDR point. Next, we simulated transcriptomic data with negative binomial distribution. Our simulations were conducted by setting 13 000 mRNA isoforms, two conditions (control and disease states), six replicated libraries in each condition, probability  U where U is random uniform variable, U 2 0, 1 and size  1000U for each isoform. The negative binomial pseudorandom generator and these setting parameters were used to create two noise transcriptomic datasets with equal variances, and then  100u for conditional (or treatment) effect values on differential transcription of mRNA isoforms were randomly and linearly assigned to 10% of mRNA isoforms in two noise datasets where u  (0,1] is the uniform variable. Thus, simulated data with 10% differentially transcribed isoforms, six replicates and two conditions were obtained. There are a batch of existing methods for finding mRNA isoforms of being differentially transcribed between two conditions: empirical Bayesian (), Fisher exact test (), GLM () and Beta t-test (). These methods all use the BH procedure to estimate FDR. Similarly to, we here used the simulated transcriptomic datasets to evaluate the BH procedure based on the four statistical methods. We plotted true FDRs in findings of these methods against estimated FDRs using the BH procedure from cutoff  $ 0 to$ 0.21.shows that the BH-estimated FDR curves in the empirical Bayesian, GLM and Fisher exact test and especially, in the Beta t-test are much below their theoretical lines (true FDR versus true FDR), indicating that in these methods the BH procedure heavily underestimated FDRs. To fully display statistical properties of our multiple-testing approach in various microarray experiments, we also generated simulation datasets in 27 scenarios. Our simulations were based onestimated FDR theoretical FDRshown inand B, for each scenario; instead, we listed the numbers of findings obtained by traditional t-test method and the true and estimated FDRs obtained by a procedure chosen with its estimated FDR smaller than but closest to the cutoff of 0.05. To demonstrate our algorithm, we also applied permutation () and q-value () approaches to these 27 stimulated datasets. The results are summarized in Supplementary Table S1. It can be seen in Supplementary Table S1 that C-value chosen varies in the range of 0.91.32 including C  1.22. As seen in, C  1.22 produces the BH procedure. Thus, the BH procedure is just one of our multiple procedures. The FDR estimated by our method at each C-value in each given scenario is close to its true value, except that in scenarios 3 and 17 where the true FDR values are little greater than their estimated values; all the other FDRs were slightly overestimated, meaning that our estimation of FDR is conservative. Supplementary Table S1 also gave the results obtained by performing the q-value approach (). Our method and the q-value approach have similar number of findings in most of simulated datasets. However, the q-value approach underestimated FDRs in nine scenarios (33.3%). Therefore, for conservativeness of FDR estimation, our method obviously outperforms q-value approach. By using the permutation algorithm the FDRs were severely underestimated in all 27 scenarios (Supplementary), indicating that the permutation is not a desirable approach for estimation of FDR.
ApplicationThe first example for application of the multiple-procedure approach ismicroarray data. As seen above, the data consist of 7129 genes.tried to find genes differentially expressed between four human lymphoblastoid cell line samples treated by ionizing radiation and four samples without ionizing radiation. We set 140 C-values from 0.1 to 1.39 to create 140 multiple-testing procedures. Because C-value40.92 did not produce meaningful results (no findings), we obtained a set of 83 real ratios of findings from the real data using classical two-condition t-test method. After adjusting, we found a  0.02, b  2.9 and  0.3 and repeated our algorithm process for 15 times and generated a set of 83 estimated ratios of findings and a set of 83 estimated FDRs. We plotted real and estimated ratios of findings in. Applications of our method to the real data. The real ratio set of findings was obtained by using a set of 140 procedures for multiple t-tests of gene differential expressions between two conditions from a real dataset. The estimated ratio set of findings was obtained by using our method from 15 simulated datasets each similar to real data. The estimated ratio of findings is compelled to be identical to its real value across all given procedures so that the true FDR generated by each of procedures would be reliably estimated. Column 1: plots of estimated versus real ratios of findings. Solid line is a regression line, dash line is observed line. Column 2: plots of estimated FDRs versus C-values (procedures). Row A: The ionizing irradiation microarray data provided by. 7129 genes of being expressed in 4 human lymphoblastoid cell line samples treated by ionizing radiation and in 4 samples without ionizing radiation were detected on human cDNA arrays. Row B: the data are acute leukemia microarray data that were downloaded from Broad Institute Cancer Program Data Set. This dataset consists of 12582 genes whose expression values in 24 acute lymphoblastic leukemia (ALL) cell lines and in 28 acute myelogenous leukemia (AML) cell lines were measured by oligonucleotide arrays. Row C: Arabidopsis microarray data (). This dataset contains 22810 genes that were detected for differentially expression between the C58 infected and control stalks each with 3 replicates on plant Arabidopsis gene chip. Plots of true versus BH-estimated FDR in existing statistical methods. Estimated curve was made by plotting estimated FDR against true FDR along cutoff of $0 to $0.21 and theoretical line is a diagonal line made by plotting true FDR against true FDR along the same cutoff. The true FDR was calculated by counting false positives in findings of a statistical method at an FDR cutoff point in a simulated dataset and the estimated FDR was predicted by a statistical method. The true and estimated FDRs were averaged over three simulated datasets. (A) Exact tests, (B) Generalized linear Model, (C) Empirical Bayesian, (D) Beta t-tests almost a diagonal line with intersection 0  0.0008 % 0 and regression coefficient 1  0.9451%1. Hence, the estimated ratio of findings is proximately identical to its real ratio at each of C-values. Thus, the simulated FDR given incan be used to estimate the true FDR across the 83 C-values.shows that the smallest FDR is 0.36 at C-value  0.92, which is much larger than cutoff of 0.05. Therefore, at FDR cutoff of 0.05, no gene in this dataset was found to be differentially expressed between human lymphoblastoid cell lines treated with ionizing radiation and control cell lines. This result is consistent with the report of Tusher et al., the plot dots of the estimated versus real ratios of findings almost fall on a diagonal line with intersection 0  0:0065 % 0 and regression coefficient 1  0:9824 % 1, suggesting that the estimated ratio of findings was constrained to be almost identical to the real one at each C-level. Thus, the true FDR set can be given by the estimated FDR set.shows that at C  1.31, FDR  0.049723 is close to 0.05 at which 582 genes were identified to be differentially expressed between ALL and AML cell lines. The third example is Arabidopsis microarray data. To explore whether Arabidopsis genes respond to oncogenes encoded by the transfer-DNA (T-DNA) or to bacterial effector proteins codelivered by Agrobacteria into the plant cells, Lee et al. (2009) conducted microarray experiments at 3 h and 6 d after inoculating wounded young Arabidopsis plants with strains C58 and GV3101, a cognate of strain C58, which only lacks transferDNA, but possesses proteinaceous virulence (Vir) factors such as VirD2, VirE2, VirE3 and VirF (). Wounded, but uninfected, stalks were served as control. As an example, we just downloaded 6d postinoculation data from GEO (GEO accession: GSE14106) website (http://www.ncbi.nlm.nih. gov/geo/). The data consisting of 22 810 genes were obtained from the C58 infected and control stalks each with three replicates. We performed the classical two-condition t-test approach on this dataset and applied our multiple-procedure approach to do multiple tests. We set 140 C-values from 0.01 to 1.4 to create 140 procedures and obtained 140 real ratios of findings from two-condition t-tests. After adjusting, we found a  0.08, b  15 and  0.035. Using these parameters, we obtained 140 estimated ratios of findings and FDRs by 140 procedures for 15 repeats.shows that the observed plot line of estimated versus real ratios of findings completely overlapped with the predicted line. Because intersection 0  0:007 % 0 and regression coefficient 1  0:985 % 1, the observed line of estimated and real ratios of findings is a diagonal line, so that the estimated ratio of findings is one-to-one identical to the real one at each Cvalue. Thus, the true FDR set can be given by the estimated FDR set.shows that 1427 genes were identified to be differentially expressed between the young tumor and control stalks at C  1.2 with FDR  0.0497 (). However, using the fold change method,just identified 196 differentially expressed genes at P50.01. Both have a big difference. To verify our findings, we displayed heatmap of the raw data of the 1427 DE genes selected in.shows that in the downregulation, all the 498 genes clearly had much lower expression values in young crown gall tumors than in. Heatmap. Rows are 1427 genes found to be differentially expressed between young tumor (6d postinoculation), and control stalk and columns are three control (reference) stalk replicates (right side) and three young tumor replicates (left side), among which 498 genes were downregulated in C58 strain relative to control stalk, and 929 were upregulated in C58 strain relative to control stalks. Yellow is the lowest expression values, and deep red is the highest expression values
The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Multiple procedures for accurate estimation of FDR at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Y.-D.Tan and H.Xu at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
simulated datasets show that our method works well for accurate estimation of FDR in different sample sizes, different conditional effects and different ratios of genes differentially expressed in different biological systems of study. Three real datasets also demonstrated that our method performs well even in the cases of large and unequal sample sizes or very small sample sizes but large number of genes detected on arrays. In microarray and transcriptomic experiments, the extremely large number of genes (the dimensionality of the feature space reaches tens or even hundreds of thousands) and extremely small number of biological conditions lead genes to be highly correlated in expression. This means that such genome-wide data are highly dependent data. Our simulated and real results show that the dependence among expressions of genes did not impact estimation of FDR even though the multiple procedures are based on independence of hypotheses (the BH theorems). This is because the estimation of ratio of findings is also based on highly correlative expressions of genes. In theory, not only our step-up or step-down multipleprocedure can be applicable for any statistical methods but also our algorithm for choice of C-values (procedures) can be generalized to any other statistical tests or is suitable to any data by changing distributions. For example, if a real dataset is count data such as transcriptomic data or serial analysis of gene expression (SAGE) data, then the simulation in our algorithm can be conducted by choosing appropriate parameters on the Poisson, gamma, binomial or negative binomial distribution. But in practice, our method would not be available for cases in which distribution of statistics is unclear. In addition, compared with existing large-scale statistical methods such as SAM (Tusher et al., 2001), RAM (Tan et al., 2006), ODP (Storey et al., 2007), Cyber T (Baldi and Long, 2001), Limma (Smyth, 2004; Smyth et al., 2005) and q-value (Storey and Tibshirani, 2003), our method needs more time to determine parameter values so that the estimated ratio of findings is identical or very close to its real ratio across a set of chosen C-values chosen, or say, 0 is proximate to 0 and 1 to 1. In effect, , a and b values can easily be determined by noting that, as seen in Equation 10, a larger-value would allow much larger d-values to be adjusted and a smaller a-value would make these d-values become smaller, then more ^-values near the M-end would become smaller; according to Equation 12, a larger b-value would allow differences in all differential expressions between two conditions to be larger, and as a result, more ^-values near the 1-end would be enlarged. Our experience is that first we glance at the difference between the-value set and the ^-value set with  a  b  1 and determine b-value so that at the 1-end the ^-values are close to the-values. Then we set a small a-value and adjust so that differences between the-values and ^-values at the M-ends are smaller than a tolerant value, e.g. 0.01. Also, one can first fix a smaller-value and then adjust a-value. Nevertheless, the constraint condition is that 0 is close to 0 and 1 to 1.
