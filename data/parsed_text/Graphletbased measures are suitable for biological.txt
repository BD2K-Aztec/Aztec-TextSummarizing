Motivation: Large amounts of biological network data exist for many species. Analogous to sequence comparison, network comparison aims to provide biological insight. Graphlet-based methods are proving to be useful in this respect. Recently some doubt has arisen concerning the applicability of graphlet-based measures to low edge density networks—in particular that the methods are 'unstable'—and further that no existing network model matches the structure found in real biological networks. Results: We demonstrate that it is the model networks themselves that are 'unstable' at low edge density and that graphlet-based measures correctly reflect this instability. Furthermore, while model network topology is unstable at low edge density, biological network topology is stable. In particular, one must distinguish between average density and local density. While model networks of low average edge densities also have low local edge density, that is not the case with protein– protein interaction (PPI) networks: real PPI networks have low average edge density, but high local edge densities, and hence, they (and thus graphlet-based measures) are stable on these networks. Finally, we use a recently devised non-parametric statistical test to demonstrate that PPI networks of many species are well-fit by several models not previously tested. In addition, we model several viral PPI networks for the first time and demonstrate an exceptionally good fit between the data and theoretical models. Contact:
INTRODUCTIONNetworks are used to represent relationships in molecular biology, such as those between genes in gene regulatory networks and proteins in proteinprotein interaction (PPI) networks. A PPI network models the physical bindings between types of proteins in a cell, where a node represents a type of protein and an undirected edge exists between two nodes if the corresponding two proteins can physically bind to each other. The network of all such interactions in a species has been dubbed the interactome, and understanding its structure is an integral step towards understanding cellular systems. Recent advances in the experimental determination of PPI networks, such as yeast two-hybrid (Y2H) screening () and mass spectrometry (MS) of purified complexes () have provided an abundance of network data. As these PPI networks are large and complex, it is necessary to develop efficient and biologically meaningful algorithms for their analysis. Because exactly solving many graph analysis problems is computationally intractable, heuristic and approximate methods must be devised. Systematic measures of structure (also called topology) of large networks based on graphlets (small induced subgraphs of large networks), have been introduced (). One is based on comparing graphlet frequencies between two networks and is termed relative graphlet frequency (RGF) distance (). The other is based on comparing graphlet degree distributions (GDDs) between two networks and the agreement in GDDs of two networks is measured (). Both allow quantification of similarity between the topology of two data networks (e.g. between two species), or comparison of a data network with a theoretically derived model network. Fourteen PPI networks of eukaryotic organisms were compared with four different random network models and the fit between the PPI and model networks has been assessed (). The use of graphlet-based measures for network comparison has been questioned () owing to the measures being 'unstable' in regions of low edge density. Empirical distributions of these scores were calculated and a novel non-parametric test for assessing the statistical significance of the fit between real PPI networks and theoretical models was introduced. The study found that none of the PPI networks of yeast and human that were considered were well-fit by the three theoretical models that were tested. After a discussion of methods, this article is designed to lead the reader through the following observations. First, that RGF distance and GDD agreement (GDDA) are not unstable measures for low edge density networks, but instead that they correctly detect the statistically high variance in network structure that is present in low-density model networks. Second, that this high variability [described as 'instability' by] is present in low-density model networks, but neither in real PPI networks nor in the model networks needed to correctly represent them. Third, that current PPI networks are denser than those studied byand are well outside the highly variable low-density region. Fourth, that the highly variable region shrinks with increasing network size and is of negligible *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com size for real-world networks. Finally, we use the non-parametric test proposed byto demonstrate that PPI networks of many species are well-fit by several existing network models.
METHODS
Graphs and graphletsA network or graph GV, E consists of a set V of n nodes and a set E V  V of m edges connecting them. Because the maximum number of edges is n 2  nn  1=2, we define the edge density of G as m . n 2 .The number of edges touching a node is called its degree; the node at the other end of an edge is called a neighbour. The degree distribution of G, DD G , is defined by DD G k, which is the number of nodes in G having degree k. A subgraph of G is a graph whose nodes and edges belong to G. A subgraph S of graph G is induced if S contains all edges that appear in G over the same subset of nodes. A graphlet is a small, connected and induced subgraph of a larger network ().depicts all 29 of the possible graphlets that have 2, 3, 4 and 5 nodes. Within each graphlet, some nodes are topologically identical to each other; such identical nodes are said to belong to the same automorphism orbit.shows the 73 different automorphism orbits among the 29 graphlets) resulting in the proposition of mechanistic models by which these networks have evolved (Przulj). Also, they have been used to align PPI networks of different species and transfer annotation to unannotated parts of these networks, as well as to reconstruct phylogeny from network alignment scores (). Furthermore, they have been used to measure the structure around proteins in the human PPI network that resulted in phenotypically validated predictions of new members of melanin production pathways purely from the PPI network topology ().
PPI networksWe analyse eight PPI networks of four eukaryotes and 10 PPI networks of prokaryotes and viruses (): Homo sapiens (human), Saccharomyces cerevisiae (yeast), Caenorhabditis elegans (nematode worm) and Drosophila melanogaster (fruit fly), and Arabidopsis (Arabidopsis Interactome Mapping Consortium, 2011). Here, HS is the human PPIs reported by, and HG is the human PPIs reported by; these two PPI networks were analysed both by PrzuljPrzulj (2007) and, and they are the first Y2H studies of the human interactome and hence are incomplete. HH is the human PPI network downloaded from HPRD version 9, released in April 2010 (). HR is the human PPI network collected by. Finally, HB, WB, FB and YB are the PPI networks of human, worm, fruit fly and yeast, respectively, obtained from BioGRID version 3.1.74, released in March 2011 (). Viral PPI networks are from Fossum et al. (2009) and are described in Section 3.6. Bacterial PPI networks include CJJ (Campylobacter jejuni), ECL (Escherichia coli), SPP (Synechocystis sp. PCC6803) and MZL (Mesorhizobium loti). All self-loops, duplicate interactions and interspecies interactions were removed from the PPI data, as we consider only simple undirected graphs.
Random network modelsWe briefly review the random network models discussed in this article. An ErdosRenyi (ER) random graph (ErdosErdos and Renyi) is generated by fixing the number of nodes n in the network, and adding edges uniformly at random until a given density is reached. An ER-DD model is an ER model in which we force the degree distribution to be the same as that of a data network. Scale-free (SF) networks are those in which the degree distribution follows a power law (Barabasi). SF-GD networks are scale-free networks based on a gene duplication model (). If the degree distribution is the same as the data and the data are SF, we get a special case of an ER-DD model called random SF (SF-RND). A geometric graph () is one in which each node in the network represents a point in space and nodes are joined if their corresponding points are closer than some fixed global constant r. In this article, the geometric random networks (GEO) that we generate have their points distributed uniformly at random in Euclidean space. GEO-GD graphs are geometric graphs in which the points are distributed according to a gene duplication model ().
GDD agreementThe notion of the degree has been generalized to graphlet degree (PrzuljPrzulj, 2007). In particular, the standard degree of a node u counts how many edges it touches; in turn, the graphlet degree of u is a vector of 73 integers counting how many times u is centered on each of the automorphism orbits depicted in. The degree distribution over degrees k of a graph is a distribution of how many nodes have degree k, i.e. touch k edges; in turn, a GDD is an analogous distribution for an automorphism orbit, e.g. the GDD corresponding to orbit 3 inmeasures how many nodes touch k triangles for each value of k. Hence, there are 73 GDDs for graphlets with up to five nodes; the first one of them is the degree distribution. More specifically, let G be a given graph. For each of the 73 automorphism orbits j shown in, we denote by d j G k the number of nodes in G that are touched k times by a corresponding graphlet at its orbit j. Because a dense graph tends to have a large graphlet degree for large values of k, we first downweight the graphlet degree by 1=k and then normalize, giving the normalized graphlet degree for automorphism orbit j,For a particular automorphism orbit j, we can compare the orbit j degree distributions of two networks G and H by treating the normalized degree for orbit j as a vector in degree space (that has dimension equal to the largest degree). We compute the Euclidean distance between these two vectors aswhere the 1= ffiffi ffi 2 p is a normalization constant that ensures the distance is always51 (). Finally, we subtract each distance from 1 to get an 'agreement' instead of a distance, and sum over all the 73 values of j to get the GDDA GDDAG, H  1 73If two networks G and H have a GDDA close to 1, then G and H have similar topology in the sense that their GDDs, scaled appropriately to their network size, are statistically similar.
RESULTS AND DISCUSSION3.1 GDDA is sensitive, not unstable A concern that 'GDDA has a pronounced dependency on the number of edges and vertices of the networks being considered' and that the 'GDDA score is not stable in the region of graph density relevant to current PPI networks' has been expressed ().illustrates the point: it depicts the dependency of GDDA on edge density when comparing two model networks with each other. The abrupt drop and raggedness of the GDDA curve at low densities is what was referred to as 'unstable GDDA'. It is crucial to distinguish between a measure being unstable, versus a measure that correctly detects when the structure of a network is highly variable. We maintain that GDDA (and RGF distance, although space limitations preclude a discussion) faithfully detects genuine differences between the structure of various networks, thus making them of the latter sort. For example, consider two networks that have eight nodes and four edges each. The first consists of four isolated edges, while the other consists of one square and four isolated nodes. We can rightfully say that the two networks are different from each other, and both RGF distance and GDDA would detect this fact. Thus we see that it is not the measure that is unstable but the network structure itself. The measure simply reflects this 'instability' in networks with a relatively small number of edges. Thus, although it is true that GDDA has an abrupt drop at low edge density, we believe that this drop is due to network properties having a statistically high variance at low edge densities. This high variance is evident in, where the 1 error bars are significantly larger at low densities than they are at high densities. This high variance in turn causes a low agreement when comparing two model networks that have low edge densities with each other. At higher edge densities, the statistical properties of two model networks become more similar, resulting in a higher GDDA. A simple analogy would be an experiment in which a fair coin is flipped n times in an attempt to experimentally determine the probability of heads. If n  0, then both experiments will agree in whatever 'assumed' probability is assigned a priori (analogous to GDDA  1 at zero edge density). If n is finite but small, then two experiments are likely to come up with substantially different estimates of the probability of heads, neither being close to the true value of 0.5. (This corresponds to the drop in GDDA at low but finite edge density.) However, as n ! 1, the law of large numbers ensures that both experiments will provide similar estimates, both being close to 0.5. (This corresponds to the 'recovery' of GDDA as density increases.) Model networks differ from this analogy in that even as n ! 1, the statistical difference between two models remains finite rather than approaching zero.
The unstable region is small in large networks, and natural networks have densities outside this regionWe wish to quantify the extent of the 'unstable' region to decide if a given network has a density in the 'unstable' density region.The discussion associated with. It is clear that the minimum GDDA score for GEO graphs occurs at a density that is proportional to k 1 =n for some value of k 1 , where n is the number of nodes in the graph. Furthermore, the 'recovery' referred to by(b) include one standard deviation error bars only for ER models, as all models have about the same variance as demonstrated in panel (c) for GEO networks. Green lines mark the edge densities of several viral PPI networks discussed in the text. In all cases, the viral PPI networks have densities outside the region of sensitivity(a) ER model (b) GEO model; they are grouped by color into kingdoms. As can be seen, in all cases the data networks are outside of the sensitive region for both ER and GEO models case, it is important to note that the width of the unstable region in density space asymptotically shrinks with increasing n. Even small real-world networks, such as the viral ones that will be discussed later in reference to, have densities outside the unstable region. In particular,depicts the density of viral networks (green vertical lines inand b) are in the 'stable' region, regardless of the assumed theoretical model.demonstrates a similar effect for larger networks. We plot a surface depicting the dependency of GDDA on the number of nodes n and the density for two types of model networks, ER and GEO. We also place each of the non-viral PPI networks fromin the n,  plane. As can be seen, none of these PPI networks are in the 'unstable' region of ER or GEO models. Note that the instability region and shape is different for different models; for example, the unstable region of GEO model is much smaller than the one of ER model with the same graph size and density. Furthermore, real PPI networks are not ER [e.g. Przulj; PrzuljPrzulj (2007); also]. We note that GDDA can be sensitive to noise, whereas conclusions about network fit using GDDA are robust to noise.depicts how GDDA responds when we add, delete and rewire up to 60% of the edges in the model networks. We note that as noise is added, GDDA generally (though not always) decreases. However, the ordering of which model best fits the data undergoes only small changes when noise is added because all the curves generally have a negative slope, indicating that the ordering of models on the horizontal axis remains the correct ordering of model fit, independent of noise level. Noise has also been extensively discussed previously (). As can be seen in, the largest PPI networks have thousands of nodes and tens of thousands of edges. Assuming a value of k 2 2 2, 5, we see that most of the real-world networks inWe conclude that for large networks of substantial density, the width of the sensitive region is negligible, and that for even small networks that are relatively complete, their density is outside of the unstable region. This effect was not apparent in the studies performed bybecause (i) they neglected to look at fairly small but complete networks such as viral ones, (ii) they restricted the size of their model networks to just 2000 nodes and did not study how the unstable region shrinks with increasing n and (iii) they neglected to take into account that local densities may be higher (see Section 3.4 below).
Effect of more up-to-date PPI dataFor yeast,analysed the earliest Y2H data () with only $800 nodes and edges, along with an early MS-based high confidence PPI network (von) with $1000 nodes and 2500 edges. For human, they used the initial Y2H screens ofwith only $1700 and 3000 nodes and 3000 and 6700 edges, respectively. All these data are not only out-of-date now, it was out-of-date at the timedid their study. It is of significantly lower density than more recently available networks, even networks that were available at the time of publication of. They also used the current human PPI data from BioGRID, but split it up into two subnetworks, one with only PPIs from MS-based experiments and the other with only PPIs from Y2H experiments. By doing this, they decreased coverage and density of the currently available human PPI network, hence increasing false negative rate in each of the two subnetworks they constructed.depicts a timeline of data available from the year 2000 until the present, including data that were available significantly before the publication date ofbut not used by them.
Natural networks have high local densities in which GDDA is stableWe must distinguish between average and local density.used random model networks with the same average density of the data. However, data networks have local densities much higher than a uniformly dense random ER or GEOIn particular, we see that adding, deleting or rewiring as many as 60% of the edges in the model networks has little effect on which model best fits the data. Thus, conclusions about which models better fit the data are relatively insensitive to the fact that real-world network data contain substantial amounts of noise. Legend: YB  Yeast; FB  Fly; HB  Human network would have. To see this, refer to our, where we reproduce part of Tables 2 and 3 from (). In it, we demonstrate that even the early human Y2H PPI networks, HG and HS, have many more large dense graphlets than one would expect in random network models with average densities of these PPI networks. For example, the highlighted numbers for graphlet G 28 [taken from (indicate that we do not expect even one G 28 to appear in a 2000-node ER network until the density reaches 0.02495more than 10 times the density of the HG networkand yet the HG network, with 1873 nodes and a density of just 0.00198, already contains 19 copies of this highly dense 5-node graphlet. Even if the same human PPI network were modeled as a GEO network, it is expected to have zero copies of graphlet G 28 , rather than 19. Furthermore, these human PPI networks contain millions of distinct 5-node graphlets, whereas the models predict only a few, at most. This tells us that a PPI network of low average density is not of uniformly low density, but instead contains highly dense subregions where the topology (and hence GDDA) is stable. This is also confirmed by a well-established observation that PPI networks have higher clustering coefficients than model networks (e.g. Przulj). This effect is also seen in larger clusters on the human PPI network HS (taken from). We have used theTo the left of the double vertical line, we reproduce parts offiltered the PPI network into two networks by using the keywords 'Affinity Capture-MS' and 'Two-Hybrid', and they analysed the filtered networks separately instead of the whole network at once, thus artificially decreasing its densityWe have demonstrated several network models (STICKY, SF-GD and GEO-GD) are good fits to the most complete existing viral PPI networks. We believe that this fact, in itself, is a significant milestone in the modelling of biological networks. The biological significance of the fits is not immediately clear, but the mere fact that we now have reasonably well-fitting models of viral PPI networks is a stepping stone towards greater understanding. Discerning how and why these models are not perfect, improving them and figuring out why STICKY is often but not always best, is a subject of future research.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
W.Hayes et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from Finally, the STICKY model is based on a stickiness index that is proportional to the degree of a node in a real network (PrzuljPrzulj and Higham, 2006). It is based on the assumption that the higher the degrees of two nodes, the more likely they are to be neighbours. 2.3.1 The utility of model networks 'In the further development of science, we want more than just a formula. First we have an observation, then we have numbers that we measure, then we have a law which summarizes all the numbers. But the real glory of science is that we can find a way of thinking such that the law becomes evident.'Richard P. Feynman, winner of the 1965 Nobel Prize in physics (Feynman, 1963). We have been asked several times by biologists, including reviewers of our articles, why modelling biological networks is important and what models might teach us. It is easiest to answer this question by providing an example of another science in which models have become vitally important: physics. Models provide us a way to think about a system in such a way that we can understand its behaviour; more importantly, a precise theoretical model allows us to predict a system's behaviour, so that we can learn how it reacts without having to experiment haphazardly on the system. For example, without a precise and predictive theory of gravity, we would not be able to understand the motion of planets, stars and galaxies, and NASA would not be able to launch robotic probes to the planets. A first step towards understanding biological networks is to develop mathematical models of their structure; these models may not yet have predictive value, but they have descriptive value, in the same way that detailed descriptions of observations of movement of planets centuries ago provided data for Newton to develop a predictive theory of gravity. Biological network data today are noisy and incomplete, so the network structure may be hidden by noise and adversely filtered by sampling, population averaging and other biases in data collection, handling and interpretation (Collins et al., 2007; Hakes et al., 2008; Han et al., 2005; Stumpf et al., 2005; von Mering et al., 2002). At this point in the development of structural models of biological networks, we cannot gain a detailed theoretical understanding of the networks. At best, we can try to measure statistical properties and develop models that have similar statistical properties to the real networks. Even this is an extremely difficult task. For one thing, graph theory tells us that large graphs can be almost infinitely complex in their structure; the number of undirected graphs with n nodes scales as O2 nn1=2 , which is a function that grows almost unimaginably fast. For example, the number of graphs with 22 nodes is already comparable with the number of atoms in the observable universe ($10 80 ); the number of graphs with 1000 nodes is $10 150000. Given these formidable difficulties, our goal at this juncture is not to find 'the' model that fits the datathat is hopeless. Instead our goal should be simply to aim the development of our models in the right direction.
Stability of graphlet-based measures at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
W.Hayes et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
