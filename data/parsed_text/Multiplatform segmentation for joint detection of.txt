Motivation: With the expansion of whole-genome studies, there is rapid evolution of genotyping platforms. This leads to practical issues such as upgrading of genotyping equipment which often results in research groups having data from different platforms for the same samples. While having more data can potentially yield more accurate copy-number estimates, combining such data is not straightforward as different platforms show different degrees of attenuation of the true copy-number or different noise characteristics and marker panels. Currently, there is still a relative lack of procedures for combining information from different platforms. Results: We develop a method, called MPSS, based on a correlated random-effect model for the unobserved patterns and extend the robust smooth segmentation approach to the multiple-platform scenario. We also propose an objective criterion for discrete segmentation required for downstream analyses. For each identified segment, the software reports a P-value to indicate the likelihood of the segment being a true CNV. From the analyses of real and simulated data, we show that MPSS has better operating characteristics when compared to single-platform methods, and have substantially higher sensitivity compared to an existing multiplatform method. Availability: The methods are implemented in an R package MPSS, and the source is available from http://www.meb.ki.se/âˆ¼yudpaw.
INTRODUCTIONCopy-number variants (CNVs) are defined as duplications or deletions in the number of copies of a DNA segment (larger than 1 kb in length) when compared to a reference genome. Currently, common technologies used to detect CNVs include high-density * To whom correspondence should be addressed. single nucleotide polymorphism (SNP) arrays and comparativegenomic hybridization (CGH) arrays. In recent years, whole-genome studies using commercial genotyping arrays to detect CNVs have been rapidly expanding. With decreasing cost of commercially available platforms and the fast evolution of these platforms, it is not unusual for research groups to have data from multiple platforms for each sample. For example, The Cancer Genome Atlas Research Network, a joint effort of the National Cancer Institute (NCI) and the National Human Genome Research Institute (NHGRI) to explore genomic changes involved in human cancers, used Agilent 244K, Affymetrix SNP 6.0 and Illumina 550K platforms to measure copy number alterations in its pilot study. Our own collaborators, and perhaps many other researchers, collected genotype data using both Illumina HumanHap300 and HumanHap240S arrays for each sample in order to get higher genome coverage. Marker density is an important factor for comprehensive and accurate detection of CNVs and their breakpoints, and different platforms have different probe coverage and density; seefor a summary of probe coverage of the different platforms in the different chromosomes. Combining data from different platforms can potentially yield more precise and accurate detection of CNVs and its breakpoints. However, combining such data is not straightforward because it is known that estimates from different platforms show different degrees of attenuation of the true copy-number changes () as well as different noise characteristics. Furthermore, different platforms have different marker panels and molecular assay methods (). Currently, there is still a relative lack of formal procedures for combining information from different platforms for copy-number calling. Most studies with multiple platforms interrogating the same samples process the data from the different platforms independently, then combine the segments in an ad hoc manner. This approach does not fully utilize information from the different platforms, and when the segmented results from the different platforms differ, it is difficult for researchers to come to a consensus in a statistically rigorous manner. One published method, multiple platform circular binary segmentation (MPCBS) (), is able to jointly use information from different platforms for CNV calling. The MPCBS method extends the circular binary segmentation (CBS) algorithm () by detecting coupled changes in multiple sequences. Briefly, it uses a weighted sum of t-statistics
S.M.Teo et al.from a generalized log-likelihood ratio of a multiplatform model and pools statistical evidence across platforms during segmentation. The proposed multiplatform smooth segmentation (MPSS) method extends's smoothseg algorithm, which is based on the Cauchy random-effect model that allows jumps in the underlying copy-number patterns to the multiple platforms scenario. The algorithm computes the estimated random-effect estimates that capture the underlying copy-number patterns, and is applicable to both germ-line and tumor DNA as long as the data has been appropriately normalized. As we are often interested in discrete segments of deletions, normal copies and duplications for downstream analysis such as CNV association studies, we also develop an objective method to obtain the discrete segmentation. From analyses of real and simulated data, MPSS performs well compared to single-platform methods, and shows substantially higher sensitivity compared with MPCBS.
METHODSWe first describe the correlated random-effect model for the unobserved pattern. For each individual, denote X {x 1 ,...,x n } as the union of the genomic locations of probes from the different platforms, with x 1 < x 2 < ... < x n. Denote Y j {y x 1j ,...,y x nj } as the set of log 2-intensity ratios from platform j, n j is the number of probes in platform j. Let N = n j. We consider the model:where f j is the unknown platform-specific random-effects; the platformspecific errors are independent and identically t-distributed with location parameter 0, unknown dispersion parameter  j and k degrees of freedom. We assume the errors and the random-effects to be independent. The error structure was chosen to be t-distributed to incorporate a heavy-tailed structure that can deal with outliers in the observations. We simplify (1) tosuch that f (.) is a random effect parameter common to all platforms. This simplification is justified when data from the different platforms are well normalized, because the different platforms are measuring the same underlying copy-number pattern. If not, a normalization procedure has to be applied first. Note that the error term is still platform-specific. In matrix form, we write (2) as Y  Zf + where Z is the model matrix determined by the observed x's and the choice of basis functions. We use the observed x's as knots and choose the zeroorder B-splines. Hence, Z is the N by n model design matrix that indicates the genomic locations of the probes from the different platforms, meaning that the row of Z associated with the original data y ij has value one at the i-th location and zero otherwise. The smoothness of f can be expressed by assuming that the scaled second-order differences a * i  2 f i (x i ) 2 are i.i.d. with some distribution. Since f is mostly smooth, the size ofis very small relative to the local noise. So, there will be little difference whether we specify the model on a * i or a i. For convenience, we shall use the latter. We choose the Cauchy distribution with location 0 and scale factor  2 f. The Cauchy distribution has been used to deal with jumps in the underlying patterns, with desirable results (see).
Estimation of f via maximum likelihoodWe derive an iterative weighted least squares algorithm by maximizing the likelihood of the Cauchy random-effects model (seewith k degrees of freedom: For all (i,j) where platform j has a probe at location i, logp(y ij |f ) = cwhere c is a constant. The second term comes from the Cauchy model with location 0 and scale factor  f :Differentiating (3) with respect to f , we get: logp(y|f ) f = Z WY Z WZfwhere W is a N by N diagonal matrix with diagonal elements w ij = k+1 k 2 j +(y ij f i ) 2 , associated with the corresponding original data y ij. In scalar form, the i-th element of (5) can be written as j w ij (y ij f i ). Differentiating (4), we obtain:where a = 2 f , denoted by 2 the (n2) by n matrix that represents the second-order difference operator andCombining (5) and (6), we obtain the score function, the first derivative of logL(f , 2 f , 2 j ) as:Setting S(f ) = 0, we getWe estimate f from(7) by exploiting the band-limited property of [Z WZ +] and use well-tested fortran subroutines available in Linpack (see).
Estimation of  jGivenfGiven Givenf , at each probe position i, the deviance is defined asThis can be approximated by the gamma distribution with mean  i and dispersion . To estimate  i , we use a generalized linear model with a loglink function, so h() = log() and h( i ) = x t i , where the dimension of x i and  is equal to the number of platforms. We solve using IWLS with robust weights:(1) Start with an initial  0. We estimate  once usingusing using = var(d i )(2) We writewhere Y * is called the working vector with elements(3) We use robust weightswhere w huber is the commonly used Huber weight function defined aswhere c j = 1.345 j. As an initial estimate, we use a robust measure of spread,   j = median(|e * j |)/0.6745. Then  can be solved using the usual weight least squares solution:Page: 1557 15551561
Multi-platform segmentation(4) We iterate between steps (2) and(3) until convergence. Then we obtain obtain obtain 2 j = e   j. In subsequent sections, if there is a need for a single  estimate, we use the average of the  j s.
Choosing optimal The degrees of freedom associated with f is given by (Pawitan, 2001, p. 448)where W and D are computed usingfusing usingf. This expression is hard to obtain computationally, so we use an approximation ()where  w and  d are the average diagonals of Z WZ and D, andis the j-th eigenvalue of the second derivative matrix 2. We choose  that minimizes the Akaike information criterion (AIC)AIC() =2 logp(y ij |  f )+2df
Summary of MPSS algorithmFor a given, we employ the following algorithm:(a) Start with an initial value for f 0 and  2 j 's.(b) Compute(c) Compute Z WZ and D 1 and update f using (7).(d) Update  2 j 's as described in Section 2.2 .(e) Repeat (b)(d) until convergence.
P-values for segmentsThe Fisher information for f is the negative of the second derivative of the log-likelihood.At convergence, the estimated variance matrix isIf we have a segment S, defined for instance by setting a threshold, then f S is a vector which contains the estimated values in the segment and zero everywhere else,The significance of the segment can be assessed using the statisticTo compute (12) without explicitly obtaining the inverse of a matrix with extremely large dimension, we write (12) aswhere a S,i contains the second-order differences of f S and d contains the diagonal elements of D 1. We compare this statistic to the chi-squared distribution with q degrees of freedom, where q is the number of probes in S. To adjust for multiple hypothesis testing involving a large number of segments, we compute the false discovery rate (FDR) for each segment.
Objective threshold segmentationA segment whose random-effects parameter f consistently and significantly deviates from zero is evident of a deletion/duplication. We obtain potential copy-number segments by setting thresholds forffor forf , where duplications are sets of consecutive probes for whichfwhich whichf is consistently greater than or equal to a specified threshold, and deletions are sets of consecutive probes for whichf which whichf is consistently smaller than or equal to a specified threshold. For automatic threshold selection, users can pick the threshold that maximizes the total  2 values (scaled by its associated degrees of freedom). To avoid oversegmentation, we merge the segments if the distance between adjacent segments is less than 5 kb. For each segment, we compute its associated P-value/FDR as described in the previous section. We further filter the segments by its length (those that are less than 1 kb are omitted), FDR and number of probes (minimum number of probes within segment is 10). A segment will also be omitted if the adjacent distance between 2 consecutive probes is larger than 100 times the median interprobe distance. All filtering parameters can be changed by the user. Users can also filter the segments by probe density (Number of probes/length of segment).
Removal of discrepant segmentsFor each segment identified by the MPSS algorithm, we test if the mean intensity from the different platforms differ using a t-test (corrected for autocorrelation, assuming the data has a first-order autoregressive structure) if there are two platforms and ANOVA if there is more than two platforms. We remove the segments where the FDR for the test is <0.01. We call these segments 'discrepant segments'. Discrepant segments are removed because the multiplatform algorithm assumes the signals from the different platforms are consistent with each other, hence signals from 'discrepant' segments are likely to be unreliable.
Comparisons using simulated dataWe conduct a simulation study to evaluate the performance of MPSS as well as to compare against the MPCBS method. To get a realistic noise pattern, we use the empirical CNV profile of chromosome 1 of the Hapmap sample NA10851. We use data from both Affymetrix 6.0 and Illumina 1M platforms (see Section 3.1) and apply the MPSS algorithm with segmentation threshold of 0.05 and FDR threshold of 10 5. We remove segments with <4 probes as extremely short segments are more likely to be false positives due to noise. We label the different segments of the chromosome as CNV or 'NULL'. In total, there are 12 CNV segments and 13 'NULL' segments. We perform the simulation study at three different noise levels; the input values are the smoothed intensities plus 0.5, 1, and 2 times the residuals from the respective platforms. Note that the smoothed intensities plus 1 times the residuals is exactly the original input intensities. We sample the 25 segments randomly with replacement and use their corresponding intensity values as input to the MPSS and MPCBS algorithms. We calculate the percentage of CNV probes that were correctly identified (sensitivity) and the percentage of 'NULL' probes that were correctly identified (specificity). We repeat the process 100 times by bootstrapping from the residuals. Labeling the CNV segments using segments originally identified by the MPSS method may bias the analysis in favor of MPSS. Hence, we also repeat the whole process, labeling the CNV segments using segments identified by MPCBS, with a segmentation threshold of 0.05. After removing those with less than 4 probes, we are left with 6 CNV segments and 7 'NULL' segments.
Comparisons using real dataWe compare MPSS against the single-platform smoothseg as well as MPCBS in a real data setting. We use the integer copy-numbers for a total of 5037 CNV loci from's study as well as
S.M.Teo et al.comprising of 105 000 long oligonucleotide probes was used to detect the loci and the genotypes were estimated for 450 HapMap samples using a Bayesian algorithm with stringent selection for optimal normalization and cluster locations for every locus [See Supplementary Material infor more details]. We remove segments in the reference if the number of probes from the combined probe list from the two platforms we are using is less than 10 or if the segment size is less than 1 kb. There is a median of 163 CNV segments per individual. It should be noted, however, that this reference list cannot really be considered the gold standard, as even sequencing data do not have 100% sensitivity and specificity in CNV detection (). For each method, we perform individual-specific comparisons with Conrad's CNVs and compute the number of bases that are called as CNV both by the method and byWe report the number of overlapping bases as a proportion to the total length of CNVs identified by the method and as a proportion of total length of Conrad's CNVs. While these may not be considered a 'true discovery rate' and 'sensitivity, since Conrad's CNVs are well-validated, a higher proportion of overlap is an indication of better performance.
Implementation and computing timeThe methods are implemented in an R package MPSS. The main inputs are vectors of genomic positions, chromosome numbers and log 2-intensity ratios from each platform. It is recommended that users check if data from the different platforms are well-normalized. If not, background correction should be performed first; the package rsmooth from http://www.meb.ki.se/yudpaw can be used for background correction. All computations for this article was done on a 3 GHz Intel Core 2 Duo processor. For 1 individual, with more than 2.5 million combined probes from Affymetrix 6.0 and Illumina 1M, and for a user-specified , the algorithm takes <1 min. It takes <6 min if the AIC criteria is used to find the optimal .
RESULTS
Datasets and background correctionWe use nine HapMap samples (International HapMap Consortium, 2005 and see Supplementary Materials for sample ID and population). These samples were previously genotyped by two SNP arrays (Illumina 1M and Affymetrix 6.0) in our research lab. We first perform background correction on the log 2-intensity ratios from each platform using a robust smoother in the rsmooth package from http://www.meb.ki.se/yudpaw. This normalization assumes that the majority of the genome does not contain CNVs, which is the case for germline samples. To investigate if the input intensities are well-normalized, we randomly sample a non-CNV segment of 100 consecutive probes and test if the mean intensity for the Affymetrix platform is equal to the mean intensity of the Illumina platform (using t-test corrected for autocorrelation). We repeat the process 1000 times and record the percentage of P-values that are less than 0.01. The normalization results look reasonable for all individuals with the percentage of P-values less than 0.01 ranging from 0.0043 to 0.02.
Estimated parametersFor each chromosome, we use the  that minimizes the AIC criterion. A large variation in the optimal  is observed across the genome, indicating the need for the selection of different s for different chromosomes. For example, for individual NA19139, the optimal
Choice of thresholdsFor each individual, we choose the deletion and duplication thresholds that give the largest total scaled chi-squared value. For individual NA19139, the deletion and duplication thresholds was chosen to be 0.13 (). At the chosen threshold values, after removing the discrepant segments (see Section 2.7), the algorithm identifies a median of 137, 129, 117 and 110 segments that passed the FDR threshold of 10 6 , 10 7 , 10 8 and 10 9 , respectively.
Multi-platform segmentation
Comparison: simulated dataThe average sensitivity and specificity across 100 bootstrap samples are summarized in. For most scenarios, both MPSS and MPCBS have high specificity (greater than 99%), though MPSS has slightly lower specificity when noise level is decreased. For both algorithms, sensitivity increases with decreased noise level and vice versa. In all cases, MPSS has substantially higher sensitivity than MPCBS. Mean sensitivity for MPSS can be as high as 80% when the noise level is decreased, whereas MPCBS only attains a mean sensitivity of about 41%. When noise level is high, both algorithms perform poorlyMPSS with a mean sensitivity of about 18% and MPCBS with a mean sensitivity of about 10%. However, note that with twice the magnitude of the residuals, the platform variability is increased to four times the original variability. With such high level of noise, unless the CNV signal is very strong, no algorithm is likely to identify the CNV.
Comparison: real dataWhen signals from the different platforms are consistent, we get increased power to detect the CNVs when we combine the information from the different platforms, especially in areas where a single platform has low density of probes.shows that the Illumina platform has a single probe in the deletion region, and while this probe exhibits strong evidence of a decreased intensity (log 2-intensity ratio less than 3), the single platform approach was unable to identify the deletion. On the other hand, the Affymetrix platform has several probes in the region with moderately decreased log 2-intensity ratio values, and the single platform approach detects a slight dip but the evidence is not strong.With the multiplatform approach, we see strong evidence of a deletion in that area. The gray shaded area indicates the CNV region identified by the HapMap 3 project release 3 (downloaded from(a)); this particular individual NA19139 was found to have a homozygous deletion in this region. In some cases, a single platform is unable to detect the CNV due to complete lack of probes in that region (). When signals from different platforms are inconsistent, it is difficult for the multiplatform method to detect the CNV. Even if the CNV segments are identified, they are likely to be false positives. For example, at the FDR threshold of 1e-6, the true discovery rate for the non-discrepant segments is 15.5% but it is 5.1% for the discrepant segments. On average, we remove 22 discrepant segments per individual.plots the proportion of bases that overlap with Conrad's CNVs as a function of total length of CNVs for MPSS and MPCBS. MPSS has a higher proportion of base overlap with Conrad's CNVs as compared to MPCBS., which plots the amount of overlapping bases as a proportion of Conrad's CNVs versus the amount of overlapping bases as a proportion of each method's CNVs, also shows the better performance of MPSS as compared to all the other methods.
Application: breast cancer dataTo demonstrate the applicability of the method for large studies, we apply the method to samples from the Cancer Hormone Replacement Epidemiology in Sweden (CAHRES) study, a population-based study which includes women aged 5074 years, born in Sweden and resident there between). A subset of 804 subjects were selected for genotyping on themade available to us includes lymph node status, tumor size and histologic grade. Prior to combining data from the two platforms, we use rsmooth package(http://www.meb.ki.se/yudpaw) to perform background correction with the smoothing parameter set to  = 10 5. The background-corrected intensity data is then used as inputs to MPSS algorithm. We choose the optimal smoothing parameter,  based on the AIC criterion. For convenience, the segmentation threshold is fixed at the 5th and 95th percentile of the intensities for deletions and duplications, respectively. These are similar to objectively chosen values in the previous examples. We further filter out segments with FDR more than 0.01, number of probes less than 10, length of segments less than 1 kb and segments with discrepant signals from the two platforms. An average of 14 deletions and 4.5 duplications are identified per individual. The median length of deletions is 113 kb and that for duplications is 140 kb. We use the method into form common CNV segments, defined as segments with consecutive probes where there is at least 0.5% of the subjects (4 subjects) whose individual segments overlap with the probes. We identified 942 common segments (median length of 114.5 kb). We test each segment for association with tumor size (n = 540 with size <2 cm versus n = 60 with size >3 cm), lymph node status (n = 242 lymph-node positive versus n = 561 negative) and tumor grade (n = 118 grade-1, n = 377 grade-2 and n = 308 grade-3). Fisher's exact test is used to compute the P-values. There are no significant associations with tumor size. For lymph-node status, 6 segments have P < 0.01 (see Supplementary). Of notable interest is segment 159 in Chromosome 3 which overlaps with the protein tyrosine phosphatase, receptor type, G (PTPRG) gene; overexpression of PTPRG was found to inhibit anchorageindependent growth and proliferation of breast cancer cells (). Another interesting segment is segment 845 in Chromosome 17, which overlaps with the ITGB4 gene, where studies have shown its expression to be correlated with tumor size and nuclear grade () and significantly association with basal-like breast cancer (). Ten segments are associated with tumor grade (see Supplementary). Segment 548 in Chromosome 9 overlaps with TPM2 gene, where its protein products were found to be differentially expressed between tumor and non-tumor forming breast cancer cell lines (). Segment 691 in Chromosome 11 overlaps with the PKNOX2 gene, previously shown to be deleted in breast cancer (). The 240K array was designed to supplement the 300K array, hence the probes on the two arrays are non-overlapping. The validation of the method in the earlier sections was performed on Affymetrix 6.0 and Illumina 1M arrays which have overlapping probes. Here, we are interested to know if the algorithm works for non-overlapping platforms. However, we do not have a 'gold standard' for CNVs of these individuals to make comparisons with. Instead, we take a random sample of non-overlapping 240 000 and 300 000 probes from the Illumina 1M platform for the 9 HapMap samples and make comparisons with the reference CNVs in the same way as before. The true discovery rate and sensitivity for the multiplatform approach is higher than that of the single platform approach: true discovery rate of 0.29 for the multiplatform approach, 0.24 for the 300K array and 0.22 for the 240K array. Sensitivity of 0.027 for the multiplatform approach, 0.027 for the 300K array and 0.017 for the 240K array.
DISCUSSIONWe have described a new method for identifying CNVs by using data from multiple platforms simultaneously. This method allows researchers to come to a formal consensus result when data from different platforms but for the same individuals are available. The model assumes a random-effects parameter that is common to all platforms, meaning that each platform is assumed to have the same underlying copy-number pattern. We also develop an objective method to segment the estimated random effects parameter (which describes the underlying copy-number pattern) into discrete segments. In addition, we provide a method for calculating a P-value associated with a segment of interest. The P-value would indicate how likely that the segment is a deletion/duplication, and is useful for filtering out likely false positives.Background correction is needed to make the data from the different platforms comparable; we use a robust smoother that assumes the majority of each chromosome has normal copy-number. While this assumption is likely to be true for germ-line samples, it may not hold for cancer/tumor samples. Recently,developed a normalization method to bring data from different platforms to the same scale. The method uses a technique based on principal curves to estimate the normalization functions. This method was tested on data from The Cancer Genome Atlas Research Network and seems to work well on tumor samples where there is sufficient deletions and duplications in the genome, but we found that it did not work well with the germ-line samples we use. When we performed's normalization on our samples, the correlation in the copy-number estimates between the platforms increased only very slightly after normalization (see Supplementaryand). This could be due to insufficient CNVs in the data for the principal curves to be identified. We illustrate the performance of MPSS using real and simulated data sets. In the comparisons using real datasets, we show that MPSS CNVs has greater amount of overlap with the reference as compared to the other methods. In the comparisons using simulated datasets, we show that the proposed method can achieve high sensitivity and specificity at reasonable noise levels. In general, for all methods, the proportion of overlapping bases with the highly comprehensive CNV map published byis low. However, we believe it is due to the limitation of the SNP arrays rather than the inadequacy of the algorithms. This was also noted bywhere the authors investigated and found that in the regions where the reference CNVs lie, both Affymetrix and Illumina platforms do not have a shift in the intensities and hence the algorithm would not pick out the region as a CNV. Moreover, we do not know if the reference list we have used can be considered the gold standard, since it is not likely to have 100% sensitivity and specificity. Even sequencing methods only show between 72.2% and 96.5% specificity (). The arrival of higher density arrays, for example, the Illumina HumanOmni2.5 and HumanOmni5 arrays will likely improve the sensitivity of CNV identification. Another kind of multiplatform problem arises when there is some stratification of cohorts by chips; for example, if the cases and controls were typed on different chips. Differential sensitivity or false positive rates between the platforms will lead to confounding bias in the casecontrol comparisons. The method presented here assumes that the data from the different platforms are available for each individual, hence the algorithm could not address this problem. This is an important and valid concern and warrants further investigations.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
