Motivation: Histone modifications are a key epigenetic mechanism to activate or repress the transcription of genes. Datasets of matched transcription data and histone modification data obtained by ChIP-seq exist, but methods for integrative analysis of both data types are still rare. Here, we present a novel bioinformatics approach to detect genes that show different transcript abundances between two conditions putatively caused by alterations in histone modification. Results: We introduce a correlation measure for integrative analysis of ChIP-seq and gene transcription data measured by RNA sequencing or microarrays and demonstrate that a proper normalization of ChIP-seq data is crucial. We suggest applying Bayesian mixture models of different types of distributions to further study the distribution of the correlation measure. The implicit classification of the mixture models is used to detect genes with differences between two conditions in both gene transcription and histone modification. The method is applied to different datasets, and its superiority to a naive separate analysis of both data types is demonstrated. Availability and implementation: R/Bioconductor package
INTRODUCTIONModifications of histone proteins are an epigenetic mechanism to regulate gene transcription and are fundamental to stem cell differentiation as well as to the genesis of cancer (). Histone modifications can be localized genome wide using chromatin immunoprecipitation followed by sequencing (ChIP-seq) (). Recently, several studies used this technique to explore the role of different chromatin states in transcriptional regulation (), especially when ChIP-seq data are restricted to genomic regions like genes. Mixture models have been used in many ways to cluster or classify genes. Recent applications include integrative analyses of various data types (), including gene transcription together with either DNA copy number (van Wieringen and van), DNA methylation () or transcription factor binding activity (), as well as assessing concordance between ChIP-chip and ChIP-seq platforms (). Models may consider a fixed number of components or allow for a flexible and even infinite number of components. The standard techniques for fitting such mixture models are EM algorithms in frequentist statistics (; van Wieringen and van) and Markov chain Monte Carlo (MCMC) algorithms for Bayesian mixture models implying a prior distribution on the mixture (). Input measures for mixture models are case-specific, such as different log-ratio intensity measurements or transformed P-values. In traditional clustering using mixture models, each cluster is represented by one Gaussian component. The number of clusters is determined by an external criterion or, especially in a Bayesian context, estimated within the model (). However, often clusters are poorly fitted by a single component; as a remedy, models involving a mixture of mixtures have been introduced in which each cluster is represented by a mixture itself (see, for frequentist and Bayesian approaches, respectively). In this work, we present a model involving a mixture of mixtures that circumvents overfitting and identifiability problems both by considering a fixed number of clusters suggested by the biological task and by fitting a fixed number of components corresponding to different types of distributions. The latter reduces the number of necessary mixture components and is beneficial for interpretation. Although a similar approach has been applied on ChIPseq data by, our innovation lies in using a Bayesian framework that compared with the ExpectationMaximization (EM) algorithm holds several benefits, such as the possibility of assessing the uncertainty through credible intervals and less dependence on initial values. Furthermore, we apply our model on data obtained from integrating gene transcription and ChIP-seq datasets. We demonstrate the advantages of our method over the EM approach and over a separate analysis of both datasets on simulated data as well as on actual biological data. In Section 2, we first describe our data matching and integration approach and subsequently present our Bayesian mixture model. Section 3 gives a description of results obtained on two different datasets and a simulation study. A discussion follows in Section 4 and final conclusions in Section 5.
METHODS
DatasetsThe first dataset was derived from hematopoietic stem and progenitor cells (Lineage-, Sca-1, c-Kit) from Cebpa fl/fl mice (hereafter termed wild-type mice) and Cebpa fl/fl ; Mx1Cre mice conditionally deleted for Cebpa (hereafter termed knockout mice). Specimens from three Cebpa knockout mice and three wild-type mice were hybridized separately on six Affymetrix Mouse Gene 1.0 ST arrays. Transcription data were normalized using the robust multi-array average algorithm (RMA,) (Gene Expression Omnibus GSE49975). ChIP against histone H3 lysine K4 trimethylation (H3K4me3) was applied to two pools of three wild-type mice and two pools of three knockout mice each. After ChIP, specimens were sequenced on an Illumina Genome Analyzer IIx sequencer producing 36-bp reads (GSE43007). The BurrowsWheeler aligner () was applied to map the reads against the reference genome (mm10). The second dataset was taken from a study () where epigenetic differences between a prostate cancer cell line (LNCaP) and normal primary prostate cells (PrEC) were studied. RNA-seq was carried out on an Illumina Genome Analyzer IIx to measure RNA transcription in LNCaP and PrEC cells. The STAR algorithm () was used to align reads (76 bp, single end) against the human reference genome (hg19) annotated with splice junctions obtained from the GENCODE project () to improve alignment accuracy. H3K4me3 and histone H3 lysine K27 trimethylation (H3K27me3) were localized in the LNCaP and PReC cells by ChIP-seq (Illumina HiSeq 2000 and Illumina Genome Analyzer IIx resp., 50 bp reads). ChIP-seq reads were aligned against the human reference genome (hg19) using the BurrowsWheeler aligner (). The dataset can be downloaded at Gene Expression Omnibus (GSE38685). A third dataset was taken from a study () comparing the effect of all-trans-retinoic acid (ATRA) treatment with the effect of a combined treatment of ATRA and tranylcypromine (TCP) on a leukemic cell line. Details of the dataset and analysis results are given in the Supplementary Material. A simulation dataset was generated based on the first two knockout mice replicates from the Cebpa dataset. We assumed that all genes were neither differential in gene transcription nor in histone modification between the two biological replicates. Differential genes were then simulated by multiplying the transcription value and the ChIP-seq value (calculated as described in Section 2.2) of the first replicate by 1  c with c 2 f1,  0:9. .. ,  0:1, 0:1,. .. , 1g. The 100 genes with a ChIP-seq value above the median of all ChIP-seq values were randomly chosen for each level of factor c leading to 2000 of 21 236 genes with equally directed differences in both data types.
Data matching and normalizationData matching is performed at transcript level. The basic idea is to obtain a measure for the abundance of a transcript or group of transcripts from either RNA-seq data or microarray data and then to allocate a ChIP-seq value based on the number of ChIP-seq reads aligned within the genomic region of that transcript. Here, we focus on genomic regions centered at the transcripts' transcriptional start sites (TSSs), as the histone modifications studied here primarily occur at TSSs, with H3K27me3 occurring additionally throughout gene bodies ().
RNA-seq dataAfter alignment of RNA-seq reads to the genome by software capable of producing spliced alignments, transcript abundance is estimated using the Cufflinks algorithm (). Abundances are reported in fragments per kilobase of transcript per million fragments mapped (FPKM) and are scaled via the ratio of the sample's 0.75 quartile to the average 0.75 quartile value across all samples as implemented in the Cuffdiff software (). Transcripts sharing the same TSS are grouped and their FPKM values are summarized to obtain a single FPKM value for each TSS. Finally, FPKM values are logarithmized. In the following, in case of RNA-seq data, X i and A i denote the normalized FPKM values of the two conditions/treatments of interest (e.g. cancer and normal cells) for all transcripts sharing TSS i  1,. .. , n.
Gene expression microarray data In contrast to RNA-seq orChIP-seq, gene expression microarray data consist of continuous measurement values that can be directly assigned to transcripts based on the given array design. Several normalization methods for various array platforms exist. We chose RMA () for Affymetrix GeneChips arrays and variance-stabilizing transformation () for Illumina Bead Chips. Both methods apply a logarithmic or similar transformation on the transcription values. A drawback of the array technology is that, depending on the array design, an array probe may measure several transcripts and that these transcripts may have different TSSs. In case of array data, X i and A i denote the normalized transcription values of the two conditions/treatments of interest for all transcripts measured by probe i  1,. .. , n.
ChIP-seq data ChIP-seq valuesare calculated for a given TSS i by counting the number of sequenced fragments lying within the genomic region R i of width w centered at the TSS. Let Y i and B i denote the number of reads overlapping R i in the two conditions. Reads are expanded toward the 3 0-end to the mean DNA fragment length (here 200 bp or 350 bp) before calculating Y i and B i. The size w of R i must be chosen depending on the studied histone modification. For many histone modifications, an appropriate size is known (), and we show that the choice of w is not crucial for our approach. Alternatively, a proper choice of R i can be obtained from a peak detection algorithm applied to the ChIP-seq data. In case of RNA-seq data, X i and A i can be directly matched to Y i and B i. However, array probes may be located at exons associated with more than one transcript, which may have different TSSs. In such cases, we define R i as the union of the regions derived for all single transcripts measured by probe i. So R i may consist of more than one genomic interval, and its size may differ for different probes. To account for different total number of reads and different ChIP efficiency, quantile normalization () is applied to the ChIP-seq values. The ChIP-seq values are ordered, so that Y 1. .. Y n and B 1. .. B n. The normalized values are then defined as Y i  B i : Y i  B i =2.
Data integration After data normalization and matching, acorrelation value Z inspired by the externally centered correlation coefficient () is calculated by multiplying the standardized difference of transcription values with the standardized difference of ChIP-seq values:The variances of the differences 2 XA  1=n  1 P n i1 X i  A i  2 and 2 YB  1=n  1 P n i1 Y i  B i  2 are calculated across all transcripts. If a transcript shows equally directed differences in transcription and histone modification data, the corresponding Z value is positive, whereas it is negative in case of unequally directed differences. If a transcript has differences in only one of both data types or has no differences at all, Z is expected to be close to zero. Thus, for an activating histone modification, the distribution of Z is expected to be slanted toward positive values. If biological replicates are available, the average is calculated after matching and normalization and then used in Equation (1), i.e. Y i  1=m P m j1 Y ij if m ChIP-seq replicates are available and Y ij is the quantile normalized ChIP-seq value of the j-th replicate for transcript i.
Bayesian mixture modelIn the following, the distribution of Z will be studied to detect transcripts with alterations and to explore the association between histone modification and transcript levels. As motivated in the previous section, we view the distribution of Z as consisting of three clusters: A large probability mass centered around zero corresponding to transcripts displaying differences between the two conditions/treatments of interest in none or just one of both data types, a smaller probability mass on the positive axis corresponding to transcripts displaying equally directed differences between the two conditions in transcription and histone modification data and an also smaller probability mass on the negative axis corresponding to transcripts displaying unequally directed differences between the two conditions in both data types. Measure Equation (1) aggregates the information necessary to distinguish between these three clusters of transcripts. The difficulty lies in discriminating Z values whose deviation from zero is small enough to be explained by random variability from those values that represent transcripts displaying (either equally or unequally directed) differences between the two investigated conditions in both transcription and histone modification data. A classic approach to analyze the distribution of Z that reflects this conception would be a three-component mixture model, i.e. a model in which each cluster is represented by one component. However, a cluster may be represented by more than one component in a mixture model when convenient for achieving a good fit and classification. In an investigation of an histone modification via ChIP-chip and ChIP-seq measurements (Schafer), a measure similar to Equation (1) was used in a mixture model with eight Gaussian components representing three clusters, concluding that less components, whereas preferable for interpretation, do not provide enough flexibility to fit the histogram of the Z values. Here, we want to propose a more general modeling approach that potentially reduces the number of necessary mixture components for analyzing three clusters, e.g. when considerable probability mass in the tails of the distribution constitute a challenge to standard models. We take up the idea ofto fit a mixture of not only normal distributions, as in traditional model-based clustering, but also both normal and exponential distributions. Although a number of normal components represent the center of the distribution, the probability mass in the distributions' tails is covered by two exponential distributions, one of which is mirrored at zero. By using the exponential distributions, the number of components can be considerably reduced, as each exponential component potentially replaces several normal components. In determining the number of normal components representing the center of the distribution, besides the fit, one criterion is to achieve a clean classification in the sense that the resulting classification should produce three contiguous domains of values.
ModelFormally, Z is assumed to be a random variable and Z 1 ,. .. , Z n to be an independent and identically distributed random sample of Z. The mixture model for the distribution F of Z with density f is defined as follows:with mixture proportions k , k  1,. .. , K and P K k1 k  1. The g denotes the density of the normal and h the density of the exponential distribution. Inverse gamma distributions are assigned to the variances of the normal distributions, 2 k , k  2,. .. , K  1, whereas gamma distributions are assumed for the parameters 1 and K of the two exponential distributions:These are the respective conjugate prior distributions and thus allow the application of a Gibbs sampler. The classification of transcripts is carried out by means of an allocation variable T that is given a categorical distribution. Correspondingly, T 1 ,. .. , T n are the classifications for all transcripts i  1,. .. , n. The mixture proportions are following a Dirichlet distribution,,. .. , K $ Dirichlet=K, .
.. , =K 2The use of the prior in Equation (2) generally favors a low number of non-empty components, which we prefer for the sake of interpretability (FruhwirthFruhwirth-Schnatter, 2011). Because the assignment of transcripts to the components depends essentially on the mass parameter , we estimate it as part of the model instead of choosing a fixed value. Thus, we also assign a distribution to (),The model is fitted via MCMC methods using a Gibbs sampler (, for details of our implementation see Supplementary Material), and model estimates are obtained by averaging across the posterior distributions. This mixture model is closely related to Dirichlet process models in which the potentially infinite number of components is approximated by an effective finite mixture model with an upper bound on the non-empty components (; Ishwaran and Zarepour, 2000, one application being). Depending on the application, the upper bound is usually large, e.g. on the order of several hundreds. In contrast, we prefer a small number of components for the sake of classification and easy interpretation while still achieving three contiguous classes as well as a good fit by non-standard mixing of different distributions. We found in preliminary analyses that four normal components were sufficient to achieve a good overall fit.
Prior distributions The normal components represent the Zvalues equal to or near zero and are thus given a fixed mean j  0 and a small variance a priori. The parameter of the exponential components is assigned a small value a priori, resulting in a large mean, which ensures that they represent the tails of the distribution while avoiding label switching between the components that correspond to distinct clusters. Specifically, we choose a k,0  b k,0  10 for k  2,. .. , K  1, a k,0  b k,0  0:001 for k  1, K and a 0  b 0  1 as prior values.
RESULTS
Cebpa knockout datasetNormalized transcription values were averaged across the three wild-type and three knockout samples for each probe annotated with at least one transcript. This resulted in i  1,. .. , 21 236 transcription values X i and A i for both conditions. In all, 7163 probes were assigned to multiple transcripts with different TSSs according to the ENSEMBL data base (). ChIP-seq values Y i and B i were calculated by counting the number of reads overlapping the promoter regions R i. Based on work byand on visual inspection of the read distribution at TSSs, we chose a promoter width of w  6 000. After quantile normalization, ChIP-seq values were averaged across the two knockout and wild-type replicates. To assess the effect of different choices of w, we calculated the Pearson correlation between X i  A i and Y i  B i for different choices of w ranging from 100 to 20 000 bp (). The choice of w seems not to be crucial, unless it is chosen too small. Furthermore, the correlation for probes with a unique TSS (  0:200) does not differ remarkably from probes with multiple TSSs (  0:203), indicating that the aggregation of reads from multiple TSSs is suitable.also shows that quantile normalization of the ChIPseq data leads to a higher correlation between the differences in the transcription data and the differences in the ChIP-seq data than the other studied normalization methods. A scatter plot between the ChIP-seq values of the two Cebpa knockout replicates () shows larger read counts in the promoter regions for replicate 1, although replicate 2 had more mapped reads in total (Supplementary) indicating different ChIP efficiency between both replicates.shows the ChIP-seq values after quantile normalization. After normalization, Z values were calculated and the model from Section 2.3.1 was fitted to the data.and B show the model fit andthe classifications obtained from 100 000 iterations using every 10th iteration after a burn in of 2000 iterations. Parameter estimations are given inand corresponding trace plots in Supplementary. Classifications were obtained by calculating the mode of T i across iterations. The distribution of Z had more probability mass at the right tail than at the left tail, as reflected by the estimated weights ^ j of the mixture components. The weight of the negative component ^ 1  0:002 was negligible, whereas ^ 6  0:039 was estimated for the positive component's weight.Only 27 transcripts were classified to the negative component, 20 751 to the null components and 458 to the positive component (Supplementary Spreadsheet S1). Hence, the majority of transcripts did not show differences in both data types. However, transcripts with differences in both data types clearly revealed that an increase (decrease) in H3K4me3 is associated with an increase (decrease) in gene transcription. Among the 458 transcripts in the positive cluster, we found several genes that have previously been implicated in hematopoietic stem cell biology (Mecom, Kit) and/or acute myeloid leukemia (Hoxa9, Meis1), highlighting the functions of Cebpa in normal and malignant hematopoiesis. Moreover, Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analyses (identified acute myeloid leukemia as significantly enriched (False discovery rate (FDR) 50:05). To study the reproducibility of the results, the dataset was split into two datasets each consisting of one microarray and one ChIP-seq sample from the knockout and wild-type collective, respectively. Thus, each dataset consists of a single biological replicate. The model fits and classification results obtained by applying the model to each set of replicates separately are shown in. The contingency table ((B) show the empirical distribution of Z at different scales. The histograms are overlaid with the mixture density and the densities of the single components. In (C) the observed values z i are plotted against their classification in the mixture model. One transcript classified to component 6 with z i % 107 was omitted. More transcripts were classified into the positive than into the negative component indicating a positive correlation between H3K4me3 modifications and gene transcription. No transcripts were classified to component 2: it is completely dominated by component 4 and thus plays a role with respect to the fit of the mixture distribution to the distribution of Z but not for classificationNote: The 95% credibility intervals are given in square brackets. The curly brackets summarize the weights , or, respectively, the number of classified transcripts for all four null components.
H.-U.Klein et al.replicates. Furthermore, only one transcript was classified to the negative component in both analyses, whereas 104 transcripts were classified to the positive component twice. The specificity of our approach was assessed by comparing the first Cebpa knockout replicate to the second knockout replicate. In this setup, no biological differences exist and all transcripts should be classified to the null components. We observed small weights ^ 1  0:001 and ^ 6  0:004 of the two exponential components (). Only 11 (18) of 21 236 transcripts were assigned to the negative (positive) component (). On the whole, these findings speak in favor of reproducibility of the presented results.
Prostate cancer datasetNormalized transcription values of LNCaP and PrEC cells were calculated for 113 663 (groups of) transcripts that share the same TSS based on transcript annotation from the GENCODE project (). In all, 46 657 of these showed transcript abundances in LNCaP or PrEC and were used for model fitting and classification. For both H3K4me3 and H3K27me3 histone modifications, a promoter width of w  3 000 was chosen. We chose a smaller promoter size than for the Cebpa knockout dataset on the basis of the observed correlation between differences in ChIP-seq values and transcription values for different choices of w (Supplementary) and due to the fact that RNA-seq allows to distinguish between different transcripts of the same gene that may have their TSSs in proximity. The observed correlation of  0:289 for H3K4me3 was higher than in the Cebpa knockout dataset, indicating larger differences or a larger fraction of genes showing epigenetic and transcriptional differences when comparing prostate cancer cells with normal cells. Interestingly, although it is known that H3K27me3 occurs at the TSS but also throughout the gene body (), a larger window width w covering larger parts of the gene body did not lead to a stronger negative correlation (Supplementary). Recently,also chose windows close to the TSS to predict transcription based on the occurrence of H3K27me3. We observed  0:197 for H3K27me3, and for both histone modifications, quantile normalization performed superior in terms of maximizing the absolute correlation (Supplementary), albeit the need for normalization was not as evident as in the Cebpa knockout dataset. Applying our Bayesian mixture model to the integrated transcription and H3K4me3 data lead to 3526 transcripts classified to the positive and 272 transcripts classified to the negative component (Supplementary Spreadsheet S2). Consistently, we observed a small weight of ^ 1  0:007 for the negative component compared with the weight of the positive component ^ 6  0:107 (SupplementaryC and Supplementary). Focal adhesion, axon guidance and pathways in cancer were significantly (FDR 50:05) enriched KEGG pathways (). Axon guidance genes were recently reported to be involved in pancreatic carcinogenesis () and may also play a role in other cancers (). Alternative promoter usage was observed only for 8 genes involving 20 transcripts, whereas mostly all transcripts of a gene that were classified to component 6 were consistently upregulated or downregulated. TPM1 and SMTN were among these eight genes and are involved in actin cytoskeleton development and stabilization.Note: Shown is the number of transcripts classified into the negative, null and positive components when applying the Bayesian mixture model separately to the first and second set of biological replicates.
Integration of ChIP-seq and transcription dataFor the repressive H3K27me3 mark, we obtained an estimated weight of ^ 1  0:060  ^ 6  0:015 and 2 098 (436) transcripts that were classified to the negative (positive) component (SupplementaryF, Supplementaryand Supplementary Spreadsheet S3). The same three pathways derived from the H3K4me3 model were also significant (FDR 50:05) when the pathway analysis was applied to the transcripts classified as negative by the model fitted with the H3K27me3 data. In all, 976 of the 2098 transcripts of the negative component were classified as positive by the model based on the H3K4me3 data, reflecting interactions between occurrences of active H3K4me3 and repressive H3K27me3 marks.
Simulated datasetThe simulated dataset contained 2000 of 21 236 transcripts with equally directed differences in both data types. Our approach classified 1656 of these transcripts into the positive component. A total of 15 transcripts were falsely classified to the positive component, and 344 transcripts were falsely classified to a null or negative component. In summary, a sensitivity of 0.828 and a specificity of 0.999 were observed. We compared our approach with a naive separate analysis of both data types. The differences X i  A i of the gene transcription and Y i  B i of the ChIP-seq values were calculated, and a threshold t was chosen. All k transcripts with jX i  A i j ! t were considered as differentially transcribed, and the k transcripts with the largest absolute differences jY i  B i j were considered as differentially histone modified. A Receiver-Operating Characteristic curve was plotted for varying thresholds t and compared with the results obtained from our integrative method (Supplementary). At the same level of specificity, the naive approach achieved a smaller sensitivity of 0.683, probably due to a loss of information caused by the separate analyses. Supplementaryshows that especially for moderate differences, our approach achieved a gain in sensitivity of $0.3.
DISCUSSIONThe presented results are consistent with the literature (with respect to the association between gene transcription and histone modifications. Results from the simulated dataset and from comparing two biological replicates from the Cebpa dataset give evidence for a high specificity when detecting transcripts with differences in both datasets. Furthermore, the simulation study indicates that a reasonable sensitivity may be achieved. This is substantiated by the good reproducibility of the classification results when splitting the Cebpa dataset into two datasets of sample size one. Using distributions of different types is beneficial for classifying transcripts in our Bayesian mixture model approach. In combination with a small fixed number of components, it helps to avoid label switching problems that often occur for mixture models with a large number of normal components, of which a considerable proportion often remains empty. In preliminary analyses, a mixture model using exclusively normal components had to use 15 components to achieve both a good overall fit and three contiguous classes where the proposed new model only needs six. one tail of the Z distribution to contain considerably more probability mass than the other one. When larger sample sizes are available, uncertainty could be modeled across samples for each locus, introducing an additional model layer. An adapted measure Z could be defined similarly as was done in Schaferin a frequentist context, focusing on the summands in an externally centered correlation coefficient, which could be assigned an, e.g. normal distribution.
CONCLUSIONWe propose quantile normalization for ChIP-seq data and a novel Bayesian mixture approach involving a mixture of mixtures and distributions of different type (normal and exponential) to classify transcripts based on a new measure for the correlation between histone modifications and gene transcription. This integrative analysis was able to detect transcripts for which alterations in transcript abundances and histone modification exist between two different conditions in several datasets, including different histone modification and transcription data from either microarrays or RNA-seq. We assessed the sensitivity and specificity of our approach based on simulated data and on biological replicates and showed its superiority toward naive separate analyses. Given the fact that modern studies are often not limited to one type of 'omics' data, the presented method is a useful and important tool for the integrated analysis of epigenetic and transcription data.
et al., 2011; Dong et al., 2012; Ernst and Kellis, 2010). In cancer research, it is often of interest to detect differences in histone modifications between two conditions, e.g. between cancer and normal cells or between cells carrying a mutation of an epigenetic regulator and wild-type cells. The main focus is usually on epigenetic modifications that occur together with a change in gene transcription, as these modifications are more likely to contribute to the phenotype or cancer development. Hence, in addition to histone ChIP-seq, many studies measure genome-wide RNA abundances from the same samples using expression microarrays or RNA sequencing (RNA-seq). The identification of genes showing differences in both histone modification and gene transcription data is crucial not only due to their potential causative role in cancer but also for identifying putative therapeutic targets for epigenetic drugs. Before presenting our integrative analysis approach to detect such genes using a Bayesian mixture model, we briefly review existing methods for data preprocessing and recent applications of mixture models to integrate genomic data. Before matching both data types, an appropriate preprocessing is necessary to obtain standardized ChIP-seq and transcription values. Although normalization methods for transcription data, especially expression microarray data, are well established, rigorous preprocessing methods for ChIP-seq data are still an active field of research. When comparing two or more ChIPseq samples, differences in immunoprecipitation efficiency and in sequencing depth should be accounted for. Many recent methods focus on the estimation of the proportion of background reads and require control samples either derived from input DNA or from ChIP against an unspecific antibody (Diaz et al., 2012; Enroth et al., 2012; Liang and Keles, 2012; Nair et al., 2012). Other methods, especially for comparative analysis, do not rely on control samples; for example, Xu et al. (2008) proposed dividing read counts by the total number of reads and thereby account for different sequencing depths. Taslim et al. (2009) suggested a non-linear normalization based on local regression. A related regression-based approach has recently been suggested by Shao et al. (2012). Song and Smith (2011) and Bao et al. (2013) presented models for detecting regions with differences in histone modifications that inherently account for sequencing depth or ChIP efficiency. Some methods originally designed for normalizing RNA-seq data may also be adequate *To whom correspondence should be addressed. yThe authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.
The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
H.-U.Klein et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Integration of ChIP-seq and transcription data at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
When fitting the mixture model with the EM algorithm (like in Taslim et al., 2009), the results depended on the set of initial values due to convergence in different local maxima (see Supplementary Fig. S10). It was shown that some initial values did not result in reasonable classifications, although they led to a higher likelihood. Although in our Bayesian framework in combination with MCMC algorithms for model fitting, informative prior distributions had to be chosen to ensure a sensible classification, we argue that this explicit model-based approach is preferable, at least when it is consistent across several datasets like in our analysis. Moreover, unlike the EM algorithm, the Bayesian framework allows for several possible extensions of the model, such as incorporation of interactions and spatial correlation between the transcripts. Compared with naive separate analyses of both datasets, our approach demonstrated to be superior in the simulation study. This is probably due to the fact that the classification is based on information from both datasets aggregated by our score given in Equation (1) and underlines the need for novel integrative methods for studies incorporating more than one genomic dataset. Model-based classification may consume more computing time but has the advantage that no threshold has to be chosen, in contrast to naive approaches based on P-value or fold-change rankings. We consider our approach as an appropriate framework also for other classification tasks when integrating two types of 'omics' data, helping to cope with sophisticated distributions when the number of clusters is known. As alternatives to the proposed model, a model with a variable number of components or a different number of components in the mixture may be considered. However, a fixed number of components, whereas less flexible in terms of model fit, holds more benefits in terms of interpretability and is often preferred when classification is the major goal of the analysis, and the number of clusters is obvious due to the underlying biological question. Kormaksson et al. (2012), e.g. use a two-component normal mixture model to classify probe sets with respect to low or high methylation, whereas Broet and Richardson (2006) and Wei and Pan (2008) fit threecomponent models to classify loci into being unmodified or being subject to loss or gain of genetic material. Although our model was validated by application to distinct datasets, we do not rule out the possibility that for datasets of different structure, a different number of components might be optimal. If considered appropriate for another application, the framework can be easily adapted to provide for a variable and unlimited number of clusters and/or components, e.g. based on the finite approximation to a Dirichlet process mixture model (Ishwaran and James, 2001). In such models, overfitting might be an issue and sufficient sparsity should be ensured for better interpretability (FruhwirthFruhwirthSchnatter, 2011). Of course, other distributions may also be incorporated in the model. Alternatively, one might consider to approximate the distribution of each factor in Equation (1) by a normal distribution, and hence of Z i by a normal-product distribution. We assume that this works well for datasets that lead to roughly equally formed positive and negative tails in the Z distribution, when the focus is on the fit of the distribution. Our model additionally offers the possibility of classification by representing classes by distinct components of the mixture model and is flexible enough for H.-U.Klein et al.
