Counting all the k-mers (substrings of length k) in DNA/RNA sequencing reads is the preliminary step of many bioinformatics applications. However, state of the art k-mer counting methods require that a large data structure resides in memory. Such structure typically grows with the number of distinct k-mers to count. We present a new streaming algorithm for k-mer counting, called DSK (disk streaming of k-mers), which only requires a fixed user-defined amount of memory and disk space. This approach realizes a memory, time and disk trade-off. The multi-set of all k-mers present in the reads is partitioned, and partitions are saved to disk. Then, each partition is separately loaded in memory in a temporary hash table. The k-mer counts are returned by traversing each hash table. Low-abundance k-mers are optionally filtered. DSK is the first approach that is able to count all the 27-mers of a human genome dataset using only 4.0 GB of memory and moderate disk space (160 GB), in 17.9 h. DSK can replace a popular k-mer counting software (Jellyfish) on small-memory servers. Availability: http://minia.
INTRODUCTIONDetermining the abundance of each distinct k-mer in a set of sequencing reads is a conceptually simple yet fundamental task. It is used in many bioinformatics applications related to sequencing, e.g. genome and transcriptome assembly, variants detection and read error correction. For de novo assembly, one is often interested in counting k-mers to discard those with low abundance, which likely stem from sequencing errors. State of the art methods for k-mer counting rely on hash tables (Jellyfish; MarcaisMarcais and) and/or Bloom filters (BFCounter;). These structures need to reside in memory for random access. Sequencing errors induce erroneous k-mers, in a volume typically greater or comparable with that of correct k-mers. Hence, counting k-mers for a human dataset with either a single hash table or a Bloom filter is a task that requires tens of gigabytes of memory. In Section 2, we describe a fixed-memory and fixed-disk space streaming algorithm, DSK (disk streaming of k-mers), and its worst-case complexity is analysed in function of the desired memory and disk usage. In Section 3, DSK is used to count all the 27-mers of a whole-genome human dataset. The trade-off between memory and disk space is analysed on two smaller datasets. We conclude with a discussion of the advantages of DSK over related methods.
METHODSAlgorithm 1 describes the DSK k-mer counting algorithm. The hash function h maps a k-mer to a numeric value in 0; H, where H is a large integer (typically 2 64 ). In the following analysis, we make a simplifying assumption. Let d be the total number of distinct k-mers in the input; we assume that the number of distinct k-mers having a given hash value x 2 0; H is at most d=H AE  . In other words, the set of distinct k-mer values can be uniformly partitioned by this hash function. Each k-mer is encoded using the classical 2 bits representation in the smallest available integer type, i.e. using 2 log 2 2k d e bits. The abundance of each k-mer is stored as a 32 bits integer. For convenience, let b  2 log 2 2k d e. Each k-mer m present in S is examined n iters  vb=D AE  times (once per iteration) and is written to disk only once, at the hm mod n iters -th iteration. Using the uniform repartition hypothesis, a multi-set of v=n iters D=b AE  k-mers are written to disk at each iteration. As each k-mer is encoded using b bits, the maximal disk usage of the algorithm is D bits. The maximal memory usage of the algorithm is M bits, as Steps 711 require constant memory, and Steps 1217 load a single partition in T that requires exactly M bits. With an open-addressing mechanism, each distinct k-mer occupies exactly (b  32) bits in T. To prove that the algorithm terminates, it suffices to show that T never overflows, i.e. strictlyAlgorithm 1. The DSK algorithm 1: Input: The set S of sequences, k-mer length k, target memory usage M (bits), target disk space D (bits) and hash function h5: for each iteration i  0::n iters do 6: Initialize a set of empty lists fd 0 , :::, d np g stored on disk 7: for each sequence s in S do 8: for each k-mer m in s do 9: if hm mod n iters   i then 10: j hm=n iters mod n p 11: Write m to disk in d j 12: for each index j  0::n p do 13: Initialize a hash table T with M bits of memory 14: for each k-mer m in d j do 15: Tm Tm  1, if m is present in T 1, otherwiseHash tables accesses and insertions (Step 15) are done in constant expected time with open-addressing, as long as the load factor is strictly 51 (which was proved earlier in the text). Hence, the expected time complexity of Steps 1217 (including the iteration loop) is O(v). Thus, Algorithm 1 runs in expected time Ov 2 b=D: The algorithm runs in expected linear time with respect to v when D  v, e.g. setting D equal to the sum of input bases. In practice, the simplifying assumption on the uniform repartition of the hash function h does not hold exactly. Some partitions contain a slightly larger number of distinct k-mers than v=H AE  . Hence, the actual disk usage of the algorithm is slightly above D, and the load factor of T could, in theory, be40.7 (because of high k-mer redundancy, this is not the case in practice).The dataset used is the NA18507 human genome (SRX016231), unfiltered, consisting of 1.4 billion reads of average length 100 bp (160 GB file size). Jellyfish used eight threads, DSK-SSD used four threads and DSK and BFCounter are single-threaded. The disk column indicates the temporary amount of disk space used by each method. a
0Executed on a desktop computer equipped with two hard drives, including an SSD.
The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
RESULTS In Table 1, we compared the execution time and memory usage of DSK with Jellyfish (version 1.1.5) and BFCounter (version 0.2) on a human genome Illumina dataset. The target disk usage of DSK was set to 160 GB, equal to the size of the reads file. As the algorithm relies heavily on I/O to the disk, we also tested DSK with a solid-state drive (DSK-SSD). The reads file was placed on a standard hard disk drive, and partitions of redundant k-mers were written on a 256 GB SSD. In this configuration, we noticed the algorithm is no longer limited by disk I/O and could benefit from multi-threading. The two for loops lines 7 and 12 were parallelized using openMP (four threads). DSK-SSD ran for 3.5 h using 4  1 GB of memory. Although this experiment required specific hardware, it is worth noting that the running time of DSK can be greatly reduced with an SSD and multi-core parallelism. To further assess the trade-off between time, memory and disk usage, we executed DSK (using a standard hard drive) on two smaller Escherichia coli and Drosophila ananassae datasets, with various target memory and disk usage parameters (Figure 1). For the executions with 100 MB and 1 GB memory usage, the running time of DSK on both datasets decreases as the target disk space increases. This is a consequence of the decreasing number of iterations n iters. The running times reach a plateau at roughly the reads file size (where n iters  1). The execution time generally seems to be unaffected by the target memory usage. However, at the smallest tested memory usage (10 MB), the execution time on both datasets is slightly higher, possibly because of consecutive disk writes to a large number of partitions. Note that in practice, the memory usage of DSK cannot be arbitrarily low: it is limited by the number of files that can be simultaneously opened on the system (partitions fd 0 ,. .. , d np g are all opened simultaneously). 4 DISCUSSION Contrary to other methods, DSK does not provide random access to k-mer counts. However, it benefits from three strong points: Low-memory usage: Only an arbitrarily small subset of kmers is loaded in memory at any time. In contrast, BFCounter stores all the k-mers with count ! 2 in a hash table. In principle, Jellyfish can use arbitrarily small hash tables; however, storing the intermediate results requires a prohibitive amount of disk (! 1 TB for human genome reads using a hash table of size 5 GB). Parameters are automatically inferred: The only mandatory argument is the k-mer length. Optionally, target memory and disk usages can be specified. Jellyfish and BFCounter require the user to specify a hash table size and an upper-bound on the number of distinct k-mers, respectively. Supports arbitrarily large values of k: As opposed to up to 32 for Jellyfish (unbounded for BFCounter). Funding: ANR MAPPI, ANR-10-COSI-0004. Conflict of Interest: none declared.
DSK: k-mer counting at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
