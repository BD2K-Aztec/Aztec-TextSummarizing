Motivation: Identification of somatic single nucleotide variants (SNVs) in tumour genomes is a necessary step in defining the mutational landscapes of cancers. Experimental designs for genome-wide ascertainment of somatic mutations now routinely include next-generation sequencing (NGS) of tumour DNA and matched constitutional DNA from the same individual. This allows investigators to control for germline polymorphisms and distinguish somatic mutations that are unique to the tumour, thus reducing the burden of labour-intensive and expensive downstream experiments needed to verify initial predictions. In order to make full use of such paired datasets, computational tools for simultaneous analysis of tumour–normal paired sequence data are required, but are currently underdeveloped and under-represented in the bioinformatics literature. Results: In this contribution, we introduce two novel probabilistic graphical models called JointSNVMix1 and JointSNVMix2 for jointly analysing paired tumour–normal digital allelic count data from NGS experiments. In contrast to independent analysis of the tumour and normal data, our method allows statistical strength to be borrowed across the samples and therefore amplifies the statistical power to identify and distinguish both germline and somatic events in a unified probabilistic framework. Availability: The JointSNVMix models and four other models discussed in the article are part of the JointSNVMix software package available for download at http://
INTRODUCTION
Next-generation sequencing of tumour genomesNext-generation sequencing (NGS) technologies are playing an increasingly important role in cancer research. Recent years have * To whom correspondence should be addressed. seen a number of studies exploring the mutational landscapes of various cancer subtypes. NGS investigations into prostate (), breast (), ovarian (), pancreatic (), haematological () malignancies and others (, b) have revealed new cancer genes, new insights into tumour evolution, comprehensive mutational profiles and exploration of genomic architectures. These studies have established NGS experiments as an extremely effective, unbiased approach to study cancer genomes and perform genomewide somatic mutation discovery. In the near future, large-scale international projects () generating vast sequence data repositories from hundreds of individual tumours will be complete. As such there is a major need for cancer-focused methods for robust, comprehensive interpretation of this data. The bioinformatics challenges in applying NGS to cancer research are similar to mainstream NGS applications such as the 1000 genomes project (). One crucial difference is the importance of distinguishing germline polymorphisms present in healthy tissue from somatically acquired mutations in tumour cells. This problem can be addressed by experimental design in which DNA sampled from healthy normal tissue and DNA from tumour tissue are sequenced from the same individual. Fully exploiting this experimental design and the resulting correlated nature of the pair of datasets poses computational challenges and opportunities that have not yet been thoroughly addressed by the bioinformatics community.
Methods for discovering single nucleotide variants and somatic mutationsAlmost all methods that detect single nucleotide variants (SNVs) from NGS data use a representation of digital allelic counts to infer allelic abundance in the sample. For example, a heterozygous germline SNV should be present in 50% of all aligned reads at that locus. In the cancer setting, allelic count data is used to distinguish SNVs which are unique to the tumour DNA (somatic mutations) from those SNVs which are present in the matched normal DNA (germline polymorphisms). Screening the set of predicted SNVs in a tumour against databases such as dbSNP () provides one method to address this issue. The challenge with this approach is that there are 315 million SNVs per individual; early results from the 1000 genomes indicate that 1050% of these are novel events (). This suggest that possibly millions of SNVs in a single individual will be uncatalogued in polymorphism databases. These SNVs will be falsely identified as somatic mutations if the primary strategy for distinguishing somatic and germline events is screening against public databases. In the future, as SNV databases become more comprehensive the fraction of novel SNVs found in an individual will decrease. However, even if databases were to capture 99% of all germline SNVs present in an individual and that individual carried 5 million SNVs, 50 000 SNVs would remain uncatalogued. This number is likely on the same order as the number of somatic mutations present in a tumour. Hence, there is a danger that the somatic mutations signal in a dataset could be overwhelmed by the signal from these germline events. A more robust approach to identifying somatic mutations is to sequence a paired sample of DNA from normal and tumour tissue from the same patient. The normal tissue can then act as a control against which SNVs detected in the tumour can be screened. A number of methods for discovering SNVs in NGS data have been developed (). Tools specifically tailored to somatic mutation discovery in normal/tumour pairs are under-represented in the literature [although we note very recent exceptions (. As such, ad hoc approaches for detecting somatic mutations involve using standard SNV discovery tools on the normal and tumour samples separately and then contrasting the results post hoc using so-called 'subtractive' analysis. However, due to technical sources of noise, variant alleles in both tumour and normal samples can be observed at frequencies that are less than expected and can be difficult to detect. We show that ad hoc methods would result in premature thresholding of real signals and, in particular, result in loss of specificity when detecting somatic mutations. We propose that simultaneous analysis of tumour and normal datasets from the same individual will likely result in an increased ability to detect shared signals (arising from germline polymorphisms or technical noise). Moreover, we expect that real somatic mutations that emit weak observed signals can be more readily detected if there is strong evidence of a non-variant genotype in the normal sample. Therefore, our hypothesis is that joint modelling of a tumournormal pair will result in increased specificity and sensitivity compared with independent analysis. To address this question, we developed a novel probabilistic framework called JointSNVMix to jointly analyse tumournormal pair sequence data for cancer studies and a suite of more standard comparison methods based on independent analyses and frequentist statistical approaches. We show how the JointSNVMix method allows us to better capture the shared signal between samples and remove false positive predictions caused by miscalled germline events, owing to statistical strength that can be borrowed between datasets. The article outline is as follows: in Sections 2.1 2.4 we formulate the problem, describe the JointSNVMix probabilistic model and discuss our implementation of the learning algorithm. Section 2.5 describes synthetic benchmark datasets and data obtained from 12 previously published diffuse large B-cell lymphomas (DLBCL) cases using a tumournormal pair experimental design (). Ten of these cases were sequenced to 30 aligned coverage in tumour and normal using whole genome shotgun sequencing. For the remaining two samples, 8 GB were sequenced in tumour and normal using exon capture sequencing. Section 2.6 describes the comparison methods we implemented in this study. Section 3 shows how our approach results in increased specificity without loss of sensitivity when compared with independent standard analysis. Finally, in Section 4, we discuss limitations to our method and propose future directions for the approach of simultaneous analysis of multiple-related NGS cancer samples.
METHODS
Problem formulationGiven tumournormal paired allelic counts obtained from NGS sequence data aligned to the human reference genome, we focus on the problem of identifying the joint-genotype (see below) of the samples at every location in the data with coverage. For simplicity, and following standard convention, we imagine that each position has only two possible alleles, A and B. The allele A indicates that the nucleotide at a position matches the reference genome and B indicates that the nucleotide is a mismatch. In NGS data, we can measure the presence of these alleles using binary count data that examines all reads at a given site i and counts the number of matches, a i , and mismatches, b i (). In, we see how this formalism can be extended to tumournormal paired samples. For a diploid genome, we consider all pairs of alleles that gives rise to the set, G ={AA,AB,BB}, the set of diploid genotypes. Now given two diploid samples, the set of possible joint-genotypes consists of all combinations of diploid genotypes, which is equivalent to the Cartesian product of G with itself, i.e. G G ={(g N ,g T ) : g N ,g T  G}. We assume the joint genotype of a given position can be mapped onto the more biologically interpretable set of marginal genotypes according to. This can be done by assigning the joint genotype to the most
JointSNVMixprobable state, or marginalizing together the joint genotype probabilities for a given state. As an example of marginalization, we compute P(Somatic) = P((AA,AB))+P((AA,BB)), i.e. the sum of probabilities of a wild-type genotype in the normal data and a variant genotype in the tumour data.
JointSNVMix modelsJointSNVMix1 and JointSNVMix2 are generative probabilistic models that describe the joint emission of the allelic count data observed at position i in the normal and tumour samples.shows the graphical models representing JointSNVMix1 and JointSNVMix2. A complete description of the notation and model parameters is given in.and loss of heterozygosity [LOHheterozygous normal and homozygous tumour: P(AB,AA)+P(AB,BB)]. a We treat the joint genotypes (BB,AB) and (BB,AA) as errors since this would imply that a homozygous variant mutates back to the reference base, which is a possible, but unlikely event. It is more plausible that these cases are simply errors due to alignment or base calling.We introduce a random variable G i as a Multinomial indicator vector representing the joint genotype of the samples. More explicitlyif the joint genotype of position i is (g N ,g T ), and G i (g N ,g T ) = 0 otherwise. We assume the count data from the two samples are jointly emitted from G i thus capturing correlations between the variables, and allowing statistical strength to be borrowed across the samples. This is the key insight that differentiates this model from running an independent analysis of each sample and joining the inferred genotypes post hoc. Given the joint genotype of the sample, we model the normal and tumour sample as being conditionally independent. For JointSNVMix1, the conditional distribution for each sample is modelled as a three component mixture of Binomial densities, where the densities correspond to the genotypes AA, AB, BB. These conditional densities are the same as used by SNVMix1 model (). For JointSNVMix2, the conditional densities are the same as SNVMix2 (), which allows for the incorporation of base and mapping quality information. A complete description of the model is available in the Supplementary Material.
Inference and parameter estimationWe use the expectation maximisation (EM) algorithm to perform maximum a posteriori (MAP) estimation of the values of the model parameters and latent variables. One could hand-set parameters of the model to intuitive values; however, we expect that fitting the model will allow for sample-specific adjustments to inter-experimental technical variability and inter-sample variation from tumournormal admixture (so called tumour cellularity) in the tumour samples. A full derivation of the update equations for JointSNVMix1 and JointSNVMix2 is given in the Supplementary Material.
A.Roth et al.We initialize training with user supplied parameter values. Local minima are a potential pitfall when training with EM. To check the models sensitivity to initial parameter values, we generated 100 sets of random parameters and started training from these parameters. We observed that the trained parameters consistently converge to the same values, suggesting local optima are not a major problem for this model (Supplementary Figs S2 and S3). Storing the posterior marginals generated in the E-step requires O(n) memory, thus for a large dataset training may exhaust available memory. To circumvent this problem, we subsample every n-th position with coverage exceeding a specified threshold in both the tumour and normal. For the results presented below, we subsampled every 100-th position with a coverage of at least 10 reads. Lower values of n and hence larger subsample sizes will lead to improved parameter estimates at the cost of using more memory and CPU time.
Implementation and performanceThe JointSNVMix software package is implemented using the Python programming language with computationally intensive portions written in Cython. The input is aligned sequence data in base space stored in the SAM/BAM format () from a tumournormal pair. The program implements two main commands, train and classify. A typical analysis consists of training to learn the model parameters. These can then be used with the classify command. Doing both steps of the analysis using coding space positions from a 30 genome takes 6 h on a four core Intel i7 processor running at 1.73 GHz with 8 GB memory.
Datasetswere sampled for a Poisson distribution with parameter  = 10. The synthetic data along with class labels is available in Supplementary Material. We set parameters for the AB class in the vectors  N , T to 0.6, which is slightly skewed towards the reference allele. We did this to ensure the parameters would be different than the hand-set defaults used in the untrained version of JointSNVMix1 and SNVMix1. For the SNVMix1 and JointSNVMix1 models, we used a threshold P(Somatic)  0.5 to call mutations somatic in this experiment. We did not benchmark SNVMix2 and JointSNVMix2 because our simulation technique does not generate quality scores. DLBCL: we analysed matched tumour/normal data from(dbGAP study accession phs000235.v2.p1). Exome data for patients A and B was captured using Agilent SureSelect, and subsequently sequenced on the Illumina GA II platform and aligned with Burrows-Wheeler Aligner (BWA). For patients C-M, the data were generated by whole genome shotgun sequencing (WGSS) and was run on the Illumina Hiseq2000 platform and aligned with BWA as described in. Ground truth data was predicted from the primary tumour genome and RNA-Seq data with the SNVMix software package followed by manual curation to remove artefacts. Support on both strands was required and variants near gapped alignments disregarded. Two or more high-quality bases matching SNV were required. Finally, putative variants were visually inspected in IGV. Validation of the non-synonymous curated predictions by targeted Sanger sequencing of the normal and tumour samples was performed to establish the true somatic mutations. There were 312 unique positions validated as somatic mutations across all patients in this study. Complete details are available in. In the analysis presented below, only coding space positions were analysed. For SNVMix2 and JointSNVMix2, no pre-processing was performed. For the other models, we removed bases with base or mapping qualities <10. Summary statistics for the aligned data are included in the Supplementary Material.
Alternative methodsIn order to evaluate the effect of modelling the joint distribution of the tumour and normal data, we compared the JointSNVMix1 and JointSNVMix2Indicator that base j x at position i matches reference in genome x {N,T } Latent (JointSNVMix2 only)Indicator that base j x at position i is correctly aligned x {N,T } Latent (JointSNVMix2 only) d i xDepth of coverage at position i in genome x {N,T } Observed q i x:jxProbability that base call is correct in genome x {N,T } Observed (JointSNVMix2 only)Probability that alignment is correct in genome x {N,T } Observed (JointSNVMix2 only)
Independent Fisher: this method usesa right-tailed Fisher's exact test in order to test the null hypothesis that the number of variant bases observed is due to random error. If the null hypothesis is not rejected at P-value of 0.05, the site is assigned the genotype AA. Otherwise, a site is assigned a genotype AB if the frequency of the B-allele is between 0.2 and 0.8, and a genotype of BB if this frequency is >0.8.
Joint Fisher: this method first applies the Fisher method to callthe genotypes in normal and tumour separately. Putative somatic sites are identified and a two-tailed Fisher's exact test is run to test the null hypothesis that the normal and tumour count data do not differ significantly. If the null hypothesis is not rejected at P-value of 0.05, the putative somatic site is reassigned the reference genotype (AA,AA). SNVMix1: we re-implemented the SNVMix1 model used in the published SNVMix software (). To assign joint genotype probabilities, we take the genotype probabilities from the normal and tumour samples and multiply them to obtain the joint genotype probabilities. SNVMix2: we re-implemented the SNVMix2 model used in the published SNVMix software (). Joint genotype probabilities are derived as for SNVMix1.
Performance metricsSince exhaustive validation of both somatic and non-somatic events was not available for the datasets used, we measured the concordance of the somatic predictions with databases known to be enriched for somatic or germline mutations. In theory, classifiers that predict more true somatic mutations should show higher concordance with the database of somatic mutations and lower concordance with the germline database. To generate a database of somatic mutations, we took the complete set of 312 unique somatic mutations validated across the cases and joined them with COSMIC v54 database (). We used the SNP predictions from the 2010/11/23 release of the 1000 genomes projects (), with the positions found in COSMIC v54 removed, as the database of likely germline variants. For the SNVMix and JointSNVMix methods, which assign probabilities to their predictions, we plot curves based on the rank ordering of somatic predictions. We do this by computing concordance as the probability threshold for classification is lowered. For the Fisher methods, which do not assign scores to their predictions, we plot a point in space for the complete set of predictions. To estimate the recall rate of the JointSNVMix models, we computed how many of the validated mutations for a case were found by the models using a threshold of P(Somatic)  0.5. There were 307 validated positions across the 12 cases used for this analysis. This number differs from the 312 unique positions because some mutations are found across multiples cases, and some cases from the original study were not included in our analysis. We note that copy number variation (CNV) due to segmental aneuploides and abnormal karyotypes could affect predictions. To assess the effect of CNV on prediction accuracy, we repeated the recall experiment using positions found in regions of predicted CNVs. CNVs were predicted (Supplementary) using an in-house tool, HMMCopy, available from http://compbio.bccrc.ca. This tool requires whole genome data, so patients A and B had to be excluded from this analysis. When we excluded these cases there were 187 validated somatic positions, 44 (23.5%) of which were found in regions of CNV.
RESULTS
Joint modelling shows increased ability to detect shared signals on simulated dataWe summarize the results from our synthetic experiment in. The F-measure and Matthews correlation coefficient (MCC) for the trained JointSNVMix1 model is the highest among all models, reflecting a good trade-off between sensitivity and specificity. The trained SNVMix1 model had the most true positives of all models; however, the F-measure and MCC were lower than JointSNVMix1. This is due to the high number of false positives (823) associated with the method, the bulk of which are false positive germline events (743). There is an obvious bias associated with simulating from the JointSNVMix1 model to generate the synthetic data. We only present this data to emphasize the relatively high false positive rate that can be expected from post hoc methods, which treat the data as being independently sampled. When comparing number of false positives for JointSNVMix1 and SNVMix1, we observed an 80-fold reduction with the joint modelling approach. This trend is supported by the Fisher models where we see a 2-fold reduction in false positives when using the joint approach.
Joint modelling increases enrichment of true somatics in high ranking predictionsIn, we show the aggregated concordance analysis results for the 12 DLBCL cases. (Supplementaryshows concordance results for each case separately.) The circles at the start of the lines for the JointSNVMix and SNVMix models represents the set of predictions for which P(Somatic) = 1. The JointSNVMix models show higher somatic concordance (left) in the top mutationsshows the fraction of those predictions found to be in the respective set. Lines are drawn by computing concordance as the threshold for classification is lowered. Lines start always from the left side because multiple positions may have P(Somatic) = 1. Circles at the start of lines indicate this positions, these points are also labelled with the number of somatic predictions (in 1000's) and concordance.predicted, while showing lower germline concordance (right) than their SNVMix analogues. This suggests that by distinguishing and removing false positive germline events, JointSNVMix enriches the top ranked somatic predictions for true somatic mutations. Comparing the Fisher methods, we see that the joint model significantly improves performance. The independent Fisher method produces an unrealistically large number of predictions; however, the joint Fisher approach seems much better. A major limitation of the Fisher methods is the lack of ranking information. As a result, we can only compare these methods to JointSNVMix and SNVMix models at a single point. At this single point, the Fisher methods have similar somatic concordance, but higher germline concordance. This suggests that the sensitivity of the Fisher methods is similar to the SNVMix family of models, but the specificity is lower. JointSNVMix2 has a recall rate of 0.935 (287/307) on the validated mutations, which is higher than JointSNVMix1's rate of 0.915 (281/307). JointSNVMix2 shows similar or higher somatic and germline concordance than JointSNVMix1 model. This suggests that JointSNVMix2 is erring on the side of recall versus specificity when compared with JointSNVMix1, though the performance is not dramatically different. One benefit of the JointSNVMix2 model as previously discussed in, is that it frees the user from setting arbitrary thresholds on base and mapping quality. The recall rates for both JointSNVMix1 and 2 was 0.864 (38/44) in regions of CNV, while in copy neutral regions recall rates were 0.916 (131/143) and 0.923 (132/143). This suggests that CNV slightly degrades the performance of both methods, although neither method showed statistically worse performance (Fisher's exact test, P = 0.3787, P = 0.2383, respectively.) In total, there were 2496 somatic variants called by JointSNVMix2 at the highest stringency (P = 1) of which 559 were non-synonymous variants not present in 1000 genomes polymorphism database. As discussed earlier,used stringent criteria, manual curation and validation to establish the 307 true mutations. We did not validate the non-intersecting predictions in this contribution, leaving the possibility of false positive events due to technical artefacts. We suggest a robust solution to mitigate against technical artefacts in Section 4.
DISCUSSIONIn this article, we examined the problem of simultaneous analysis of tumournormal pair NGS data for the purpose of identifying somatic point mutations. We developed a probabilistic framework called JointSNVMix to allow us to benchmark a model that can borrow statistical strength between samples against standard independent analysis. We showed that joint modelling of genotypes confers an increased specificity over simpler or independent analysis (Section 3.2). Interestingly, the frequentist statistics-based method, 'joint Fisher' method, which considers both datasets simultaneously shows an increased specificity over its 'independent'analogue, albeit considerably lower than what was achieved for JointSNVMix.
Limitations and extensionsData preprocessing: in our study, we assume that the input data is aligned correctly and focus specifically on the problem of identifying somatic mutations from allelic counts extracted from perfectly aligned data. The scope of this study is thus restricted to examining the effects of model-based classifiers for identifying somatic mutations from count-based data. The alignment and pre-processing steps leading to the generation of the count data are expected to have a dramatic effect on the quality of the classifiers we considered. The simple approach we used of filtering (JointSNVMix1) or modelling (JointSNVMix2) mapping and base qualities is likely suboptimal since they both do not consider technical artefacts such as strand bias. However, all classifiers are presented with the same data, and all will likely benefit to the same degree from improved pre-processing. As our software makes use of BAM files as inputs, it is agnostic to any upstreamprocessing in the generation of these files, and as such should be compatible with more sophisticated pre-processing strategies and efforts such as Samtools and GATK will likely continually improve this important aspect of analysis. In our experience, post-processing JointSNVMix predictions with mutationSeq () removes the majority of technical artefacts. Model extensions: the JointSNVMix models make several simplifying assumptions that may negatively affect performance. In future work, it would be interesting to extend the framework presented here to model tumournormal admixture, aneuploidy, CNV and nucleotide identity. We note in Section 3.2 that although 25% of mutations fell in regions of CNV, sensitivity was not significantly affected when copy neutral mutations and mutations in regions of CNV were compared. The effect of substantially altered karyotypes (typically exhibited by epithelial malignancies) on the ability to detect somatic mutations remains an open question. However, we expect that explicit modelling of the genomic complexities of cancer such as CNVs and subclonal populations would lead to enhanced interpretability of somatic mutation prediction and enhanced performance. In addition, the iid nature of the model easily allows for location-specific prior knowledge of germline polymorphisms to be incorporated into the joint genotype prior. As population-level databases mature, this extension to the model should increase the specificity of somatic mutation predictions.
CONCLUSIONSIn this article, we formulated the joint genotype problem for somatic mutation discovery from a tumournormal pair of NGS datasets. We have developed a novel statistical model JointSNVMix, which explicitly models the process that jointly generates a pair of samples. The joint modelling approach employed JointSNVMix allows us to reduce the number of germline events falsely predicted to be somatic. This increased specificity comes with little to no decrease in sensitivity. Additionally, we have provided a complete software package for detecting somatic mutations in paired sequence data. This package includes not only the JointSNVMix1/2 classifiers, but the other four methods presented in the article. The Python implementation of our software is available under an open-source license from http://compbio.bccrc.ca.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
