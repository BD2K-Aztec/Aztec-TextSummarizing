Motivation: In recent years, work has been carried out on clustering gene expression microarray data. Some approaches are developed from an algorithmic viewpoint whereas others are developed via the application of mixture models. In this article, a family of eight mixture models which utilizes the factor analysis covariance structure is extended to 12 models and applied to gene expression microarray data. This modelling approach builds on previous work by introducing a modified factor analysis covariance structure, leading to a family of 12 mixture models, including parsimonious models. This family of models allows for the modelling of the correlation between gene expression levels even when the number of samples is small. Parameter estimation is carried out using a variant of the expectationâ€“maximization algorithm and model selection is achieved using the Bayesian information criterion. This expanded family of Gaussian mixture models, known as the expanded parsimonious Gaussian mixture model (EPGMM) family, is then applied to two well-known gene expression data sets. Results: The performance of the EPGMM family of models is quantified using the adjusted Rand index. This family of models gives very good performance, relative to existing popular clustering techniques, when applied to real gene expression microarray data.
INTRODUCTION
Model-based clusteringCluster analysis methods are used to find subgroups in a population. Clustering is of particular interest when analysing gene expression data because it can be used to find subgroups that are well distinguished by their expression profiles. A number of clustering techniques are commonly used including agglomerative hierarchical, divisive hierarchical, k-means, k-medoids and modelbased clustering. Model-based clustering is a technique for estimating group membership based on parametric finite mixture models. The density of a parametric finite mixture model can be * To whom correspondence should be addressed., is the probability of membership of subpopulation g, and r(x |  g ) is the density of a multivariate random variable X with parameters  g. Overviews of finite mixture models are given by McLachlan and Peel (2000a) and Frhwirth-Schnatter (2006). In the model-based clustering literature, the finite Gaussian mixture model is most commonly used (examples include). The density of a finite Gaussian mixture model is given by,where (x |  g , g ) is the density of a multivariate Gaussian random variable X with mean  g and covariance matrix g ,). Note that the Gaussian mixture model has been used within the bioinformatics literature for purposes other than clustering: for example,apply a two-component mixture model to detect differential gene expression. Gaussian mixture models offer an advantage over other commonly used approaches because the covariance structure can potentially account for correlation between expression levels within an expression profile. Consequently, these models are more flexible than k-means or hierarchical clustering which commonly use Euclidean distance. However, due to the high-dimensional nature of expression data, additional structure needs to be assumed for the covariance matrices, so that the model can be fitted in high-dimensional settings. The MCLUST () approach to model-based clustering, which utilizes eigendecomposed covariance matrices, can only be applied to clustering expression profiles if a diagonal covariance structure is assumed;were able to cluster genes using MCLUST but not expression profiles. By assuming a highly parsimonious but nondiagonal covariance structure, it is possible to cluster expression profiles while allowing for correlation between gene expressions. In general, a structure like that given in Equation (1) can be used to model such data. Then the parameters, and hence group memberships, can be estimated using some variant of the expectationmaximization (EM) algorithm ().The covariance matrices g can be decomposed to allow the construction of more parsimonious models.
Parsimonious Gaussian mixture modelsThe factor analysis model () assumes that a p-dimensional random vector X i can be modelled using a q-dimensional vector of latent factors U i , where q p. The model can be written X i = +U i + i , where is a pq matrix of factor weights, the latent variables U i  N (0,I q ) and i  N (0,), where is a pp diagonal matrix. Therefore, the marginal distribution of X i is N (, +). To illustrate the implications of the covariance matrix attached to this marginal distribution, = +, suppose that X ij and X ik are expression levels from a sample X i. Then, Cov(X ij ,Hence, the matrix models the covariance between expression levels, and a combination of the and matrices models the variance of expression levels. The factor analysis model allows for the modelling of a high-dimensional non-diagonal covariance matrix with a low number of parameters.proposed a mixture of factor analysers model given by the finite Gaussian mixture model in Equation (1), with g = g g +. McLachlan andused the more general covariance structure g = g g + g .proposed the mixtures of probabilistic principal component analysers model, for which the component covariance matrix is g = g g + g I p .further generalized the factor analysis covariance structure by including the possibility of imposing the constraints:The result of imposing, or not, each of these three constraints is the family of eight parsimonious Gaussian mixture models (PGMMs) that are described in. Each member of this family of models has a number of covariance parameters that is linear in data dimensionality. This is one of the reasons that this family of models is particularly well suited to the analysis of high-dimensional data. The constraints allow for assuming common structure in the component covariance matrix g , if appropriate. By assuming common covariance structure, a more parsimonious model can be used and this can be estimated in a more stable manner. The PGMM family has another significant advantage that is particularly important in applications involving high-dimensional data. When running the alternating expectation-conditional maximization (AECM) algorithm () for these models, it is advantageous to make use of the Woodbury identity () to avoid inverting any non-diagonal pp matrices. Given an nn matrix A, an nk matrix H, a k k matrix C and a k n matrix V, the Woodbury identity states that
METHODOLOGY
Modified factor analysis covariance structureThe factor analysis covariance structure (cf.) can be further parameterized by writing g =  g g , where  g  R + and g = diag{ 1 , 2 ,..., p } such that | g |=1, for g = 1,2,...,G. The resulting covariance structure g = g g + g g shall be known as the modified factor analysis covariance structure. Now, this covariance structure can be used within the model-based clustering framework, opening up the possibility of models that are more parsimonious than their PGMM counterparts. Specifically, constraints can be imposed on the parameters g ,  g and g leading to the 12 Gaussian mixture models illustrated in. The family of models inwill be referred to as the expanded PGMM (EPGMM) family hereafter.contains a total of four new, parsimonious, models when compared with. Notably, all 12 members of the EPGMM family have a number of covariance parameters that is linear in the dimensionality of the data. Furthermore, the identities given in Equations (3 and 4) can be used for all 12 models.
Parameter estimation for the EPGMM family
Introduction Estimationof the model parameters, via the AECM algorithm, is analogous to that of the PGMM parameter estimation procedure described by McNicholas and Murphy (2008). The estimates for the eight pre-existing models are obtained from the PGMM estimates by writingHowever, the derivation of the maximum likelihood estimates of the model parameters for the new models, requires the method of Lagrange multipliers (Lagrange, 1788). Parameter estimates for the CCUU model are derived in Section 2.2.2 and derivations for the other three new models are given at the end of said section.
AECM algorithm
Model-based clustering of microarray expression dataincomplete, or are treated as incomplete. In the expectation step (E-step), the expected value of the complete-data log-likelihood (Q, say) is computed, where the complete-data is the missing data plus the observed data. Then in the maximization step (M-step), Q is maximized with respect to the model parameters. In the expectation-conditional maximization (ECM) algorithm (), the M-step is replaced by a number of conditional maximization (CM) steps. The AECM algorithm () is an extension of the ECM algorithm that permits different specification of the complete-data at each stage. Extensive details on the EM algorithm and variants thereof are given by McLachlan and Krishnan (2008). Since there are two sources of missing data for the EPGMM family, the group memberships and the latent factors, the AECM algorithm is used for parameter estimation. We shall use z ig to denote the group membership of sample i, so that z ig = 1 if sample i is in group g and z ig = 0 otherwise. At the first stage of the algorithm, the complete-data are (x i ,z ig ) and in the E-step the z ig are replaced by their expected valuesto give the expected value of the complete-data log-likelihood, Q 1 say. In the interest of brevity, the expected value of Z ig will be denotedzdenoted denotedz ig herein. The function Q 1 is then maximized in the CM-step to givAt the second stage, the complete-data is (x i ,z ig ,u ig ) and in the E-step the z ig are replaced byzby byz ig and the sufficient statistics for the factors U ig are replaced byrespectively, whereThe CM-step at this second stage will depend on the model. Consider the CCUU model, so that g = and g =. In this case, the expected complete-data log-likelihood Q 2 (, g ,) can be writtenwhere C is constant with respect to ,  g and ,To maximize Q 2 with respect to ,  g and , it is necessary to use the method of Lagrange multipliers. First, form the Lagrange. Note that we use  to denote the Lagrange multiplier to avoid confusion with the elements of the matrix. Differentiating L with respect to ,  1 g , 1 and , respectively, gives the following score functions.Note that S 4 is included for completeness only and solving, = 0 just returns the constraint ||=1. Now, solving
P.D.McNicholas and T.B.Murphy.
ButnewButButnew is a diagonal matrix with |  new |=1, thereforewhere  j is the j-th element along the diagonal of the matrixTherefore, it follows thatThe derivations for the other three new models are similar. The estimates in the UCUU case ararwhere  is as defined in Equation (5) but, in this case,  j is the j-th element along the diagonal of the matrixIn the CUCU case, the estimate for is derived in a row-by-row fashion as,...,p where r i is the i-th row of the matrixis the i-th element along the diagonal of the matrixgmatrix matrixg. The other estimates arewhere  gj is the j-th element along the diagonal of the matrixIn the UUCU case, the parameter estimates are given bynew byand  g is as in the CUCU case but with  gj given by the j-th element along the diagonal of the matrixNote that the predicted clustering for each member of the EPGMM family is given by the maximum a posteriori (MAP) classification. That is, the posterior predicted component membership of tissue i is the value of g for whichzwhich whichz ig is the greatest.
Convergence and model selection
Convergence criterionAitken's acceleration () is used in the analyses herein to estimate the asymptotic maximum of the log-likelihood at each iteration. This allows a decision to be made about whether or not a given AECM algorithm has converged. Aitken's acceleration at iteration t is given byare the log-likelihood values from iterations t +1, t and t 1, respectively. The asymptotic estimate of the log-likelihood at iteration t +1 is given by(). Herein, the stopping criterion proposed byis used, so that the algorithm can be stopped when l l (t) <<. More specifically, = 0.1 is used. Note that this criterion is very similar to that proposed by, who suggested stopping when l
Model selectionThe Bayesian information criterion (BIC) is used to select the best member of the EPGMM family, in terms of both model and number of factors. Note that the BIC can also be used to select the number of mixture components (cf.) but this is not necessary for the analyses herein since we fix G = 2. For a model with parameters  , the BIC is), the integrated completed likelihood (ICL;) and clustering stability (cf. von). However, we found that the BIC gave a quick solution and generally good clustering results.analysed two microarray gene expression data setsone on leukaemia data and another on colon tissue samplesusing the EMMIX-GENE approach. The first stage of this approach focuses on data reduction where, initially, one-and twocomponent mixtures of t-distributions are fitted to the data. Then a gene is retained only if two conditions are satisfied. One of these conditions is that the minimum cluster size exceeds some prespecified threshold a 1. The other condition concerns the result of a likelihood ratio test, or tests. First, the hypothesis H 0 : G = 1 is tested against H 1 : G = 2 and the gene is retained if 2log>a 2 ,
ANALYSES
Dimensionality reductionwhere  is the likelihood ratio statistic. However, if the condition in Equation (6) is not met then the hypothesis H 0 : G = 2 is tested against H 1 : G = 3 and the gene is retained if the same condition is satisfied, with the same a 2 , for this test statistic  and at least two of the three components contain at least a 1 tissues. When fitting the two-and three-component mixture models for this purpose, starting values for the component memberships are defined randomly or by using starting values based on k-means clustering results. This whole process represents the first stage of the EMMIX-GENE approach and can be carried out using the select-genes software that accompanies. For the analyses herein, the select-genes software is used with thresholds a 1 = a 2 = 8, as in, and 50 random and 50 k-means starts.presented data on two forms of acute leukaemia: acute lymphoblastic leukaemia (ALL) and acute myeloid leukaemia (AML). Affymetrix arrays were used to collect measurements for 7129 genes on 72 tissues. There were a total of 47 ALL tissues and 25 with AML. The data were sourced from the web site accompanyingwww.maths.uq.edu.au/gjm/emmix-gene/) and so they had been preprocessed () as follows.
Leukaemia data
The data(1) Genes with expression less than 100 or greater than 16 000 were removed.
The EPGMM approachTreating this as a clustering problem where the form of leukaemia is unknown, all 12 members of the EPGMM family () were fitted to these data for G = 2, q = 1,...,6 and 10 different random starting values for th z ig. The BIC for the best q for each of the 12 members of the EPGMM family is given in. The best of these models, in terms of BIC, was a CCUC model with q = 3 latent factors. The chosen model has a nondiagonal covariance structure where the covariance between pairs of genes is equal across different clusters but the variance of each gene is unequal across different clusters (Section 1.2). The MAP classifications arising from the parameter estimates associated with this model are given in; only five tissue samples were misclassified.
Hierarchical clustering, k-means, k-medoids and MCLUSTIn addition to the EPGMM technique, several other techniques were applied to these data using the R software (R Development Core Team, 2010). Agglomerative hierarchical clustering was used, with Euclidean distance and three different linkage methods: complete, average and single. The k-means (cf.) and k-medoids techniques were also used. In the latter case, the partitioning around medoids (PAM; cf., Chapter 2) algorithm was used. Finally, in order to compare our model-based clustering approach to the well-established MCLUST approach, we used the mclust package () for the R software. The results, which are summarized in, give the Rand and adjusted Rand indices as measures of class agreement. The Rand index () is based on pairwise agreements anddisagreements, and the adjusted Rand index () is effectively the Rand index corrected for random chance. These indices reveal that the best of the non-model-based approaches was k-means clustering, with an adjusted Rand index of 0.187. In fact, k-means clustering narrowly outperformed mclust on these data, but the EPGMM model with the greatest BIC (CCUC, q = 3) was the best model overall.
P.D.McNicholas and T.B.Murphy
The EMMIX-GENE approach McLachlan et al. (2002)analysed the same data using the EMMIX-GENE approach with four random and four k-means starts in the first stage, which reduced the number of genes to 2015. In the second stage, a mixture of 40 normal distributions with isotropic covariance structure was fitted to the 2015 genes. Two of these groups (Groups 1 and 3) provided clusterings that were most similar to the type of leukaemiaof course, in a real clustering scenario this could not be established. A two-component mixture of factor analysers, with q = 6 factors, was fitted to the data using the genes from Groups 1 and 3, respectively. Using the genes from Group 1 led to the misclassification of 13 tissues and using those from Group 3 led to the misclassification of six tissues. Note thatdid not specify how many different random starts were used but, based on other analyses, it seems likely that 50 random and 50 k-means starts were used.
Two other approachesIn addition to the EMMIX-Gene approach,used two other approaches to cluster the leukaemia tissues. In both cases, the first stage was identical to that described in Section 3.2.4. The first alternative approach was to cluster the tissues based on the 40 fitted group means and the top 50 of the 2015 genes. Fitting a two-component mixture of factor analysers with q = 8 factors to these data, using 50 random and 50 k-means starts, led to the misclassification of just one tissue. The second alternative approach was to base the analysis on the top 50 genes. Fitting a two-component mixture of factor analysers, with q = 8 factors to these data, using 50 random and 50 k-means starts, led to the misclassification of 10 tissues.
CommentsThe EPGMM approach gave very good clustering performance when applied to the leukaemia data. This approach used 10 random starts and led to the misclassification of just five tissues. This performance far exceeds that of agglomerative hierarchical clustering, k-means clustering, PAM and MCLUST. In fact, the best of all of these techniques had an adjusted Rand index of 0.187, while the best EPGMM model had an adjusted Rand index of 0.738. Although, in one instance, one of theIn this latter case, the choice of the number of clusters (40) was validated in some sense by the fact that two of the groups give classifications that were similar to the true leukaemia type. In fact, as mentioned by, an objective technique for choosing this number is not possible since genes cannot be assumed to be independently distributed within a tissue sample. Furthermore, it is quite likely that the number of factors q was selected, in each case, to give the best classification. This could be done objectively, as in Section 3.2.2, using the BIC. Finally, any comparison between the EPGMM approach and the approaches ofwould have to be taken in context with the fact that different subsets of the 3731 genes are used in each case.presented gene expression data on 62 colon tissue samples, of which 40 were tumours and the remaining 22 were normal. Affymetrix arrays were used to collect measurements for 6500 gene expressions on all 62 tissues. Following, only the 2000 genes with the highest minimal intensity are focused upon. The data were again sourced from the web site mentioned in Section 3.2.1 and, this time, the only preprocessing was the taking of natural logarithms, followed by normalization. Application of the select-genes software, with the settings specified in Section 3.1, led to the reduction of the number of genes from 2000 to just 461.
Colon data
The data
The EPGMM approachTreating this as a clustering problem where the type of tissue is unknown, all 12 members of the EPGMM family () were fitted to these data for G = 2, q = 1,...,10 and 10 different random starting values for th z ig. The BIC for the best q for each of the 12 members of the EPGMM family is given in. The best of these models, again in terms of BIC, was a CCUC model with q = 6 latent factors; the covariance structure in this model is the same as that chosen for the leukaemia data (Section 3.2.2). The MAP classifications given by the parameter estimates associated Page: 2711 27052712with this model are given in; only five tissue samples were misclassified.
Model-based clustering of microarray expression data
Hierarchical clustering, k-means, k-medoids and MCLUSTIn addition to the EPGMM technique, the methods used in Section 3.2.3 were run on these colon data using the R software. The results, which are summarized in, suggest that the best of the non-model-based approaches was PAM, with an adjusted Rand index of 0.218. This time, mclust outperformed k-means clustering but PAM outperformed mclust. The EPGMM model with the greatest BIC (CCUC, q = 6) was the best model, misclassifying just five tissues based on 10 random starts.Using various techniques,found five different clusterings of these data. However, none of these clusterings corresponded to the tissue type. While, once again, the EPGMM results are not directly comparable with those of, it is interesting to look at the second best of the EPGMM models. The second best of the EPGMM models, in terms of BIC, was a CCUU model with q = 7 latent factors. Note that this is one of the four new models that were introduced herein and, again, this model has equal covariance between pairs of genes; however, the variance structure is more complex than for the CCUC model. The MAP classification given by the parameter estimates associated with this CCUU model do not separate tumour from normal tissue. However, they are similar to whatcall C 1 , in that they seem sensible when one considers that there was a change of protocol during the experiment (). Specifically, tissues 111 and 4151 were all extracted from the first 11 patients using a poly detector, while the remaining samples were taken from the other patients using total extraction of RNA. Looking at the tissues by extraction method, rather than by tissue type, leads to the estimated classifications given in; only eight of the tissues were misclassified by this CCUU model when the data are considered by extraction method.The results from applying the other methods to the colon data (cf.), can also be viewed in terms of extraction method, rather than tissue type. These results are given, along with our best CCUU model, in. From this table, it is clear that our CCUU model gives the best clustering performance of all of the approaches. Furthermore, the hierarchical (complete and average linkage), k-means, and mclust clustering results are all better when viewed in terms of extraction method.
Correspondence with
CommentsThe EPGMM approach gave very good clustering performance when applied to the colon data. Our approach led to the misclassification of just five tissues, when these data were viewed by tissue type. This performance far exceeded that of all of the other techniques that were usedin fact, the performance of these other approaches was surprisingly poor, with only PAM giving better than random classifications (cf.). This phenomenon is partly explained when one looks at the classifications by extraction method, rather than by tissue type (cf.). In this case, only one method performed worse than random, which might suggest that techniques such as k-means clustering and MCLUST were picking up extraction method more-so than tissue type. That said, the performance of these methods was only slightly better than random which suggests that the restrictive cluster shapes imposed by kmeans clustering and MCLUST were not at all suited to the data. On the other hand, the best of the new EPGMM models gave the based clustering performance, misclassifying just eight samples.
DISCUSSIONThe EPGMM family of models has been shown to give good clustering performance when applied to gene expression microarray data. These applications, concerning leukaemia and colon tissue data, respectively, were conducted as genuine clustering examples. That is, no information on the true tissue classification was used for parameter estimation or model selection. In fact, this information was only used to assess the performance of the selected model. In this context, the clustering performance of the EPGMM family can be looked upon favourably. Moreover, the performance of the
P.D.McNicholas and T.B.MurphyEPGMM family on both data sets far exceeded that of a number of popular clustering techniques, including agglomerative hierarchical clustering and k-means clustering. However, like the techniques of, the EPGMM family relies on multiple random starts. In addition to the obvious drawback of the sensitivity of results to the starting values, there is the computation time that is required. Furthermore, there is no guarantee that increasing the number of random starts will lead to better clustering results. This is due, in the main, to the fact that models with greater BIC do not necessarily give better clustering performance. This phenomenon has been observed previously and work into finding better model selection techniques is ongoing. That said, the EPGMM family did perform well in the analyses in Section 3, based on random starting values and using the BIC.
CONCLUSIONThe EPGMM family of mixture models has been introduced and used for the model-based clustering of gene expression microarray data. This family of models is an extension of the PGMM family of models which, in turn, is an extension of the mixtures of factor analysers model. The EPGMM family of models are very well suited to the analysis of high-dimensional data. The reason for this suitability is 3-fold. First, each member of the EPGMM family has a number of covariance parameters that is linear in the data dimensionality. Second, as shown herein, the Woodbury identity can be used to avoid the inversion of any non-diagonal pp matrices, leading to efficient computation. Thirdly, as shown byin the context of the PGMM family, these models are 'trivially parallelizable', opening up the possibility of even more efficient parameter estimation using parallel computing. The EPGMM family was applied to two well-known gene expression microarray data sets. In both cases, the EPGMM family performed well and gave much better clusterings than several popular clustering techniques. Herein, we took G = 2 for all of the analysis but future work will focus on the selection of G.
The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2705 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
