Motivation: Next-generation sequencing allows us to sequence reads from a microbial environment using single-cell sequencing or metagenomic sequencing technologies. However, both technologies suffer from the problem that sequencing depth of different regions of a genome or genomes from different species are highly uneven. Most existing genome assemblers usually have an assumption that sequencing depths are even. These assemblers fail to construct correct long contigs. Results: We introduce the IDBA-UD algorithm that is based on the de Bruijn graph approach for assembling reads from single-cell sequencing or metagenomic sequencing technologies with uneven sequencing depths. Several non-trivial techniques have been employed to tackle the problems. Instead of using a simple threshold, we use multiple depthrelative thresholds to remove erroneous k-mers in both low-depth and high-depth regions. The technique of local assembly with paired-end information is used to solve the branch problem of low-depth short repeat regions. To speed up the process, an error correction step is conducted to correct reads of high-depth regions that can be aligned to highconfident contigs. Comparison of the performances of IDBA-UD and existing assemblers (Velvet, Velvet-SC, SOAPdenovo and Meta-IDBA) for different datasets, shows that IDBA-UD can reconstruct longer contigs with higher accuracy. Availability: The IDBA-UD toolkit is available at our website
INTRODUCTIONSince, over 99% of microbes cannot be cultivated, single-cell sequencing and metagenomic sequencing technologies are used to study these microbes (). Single-cell sequencing technology amplifies and sequences genome of an individual cell without cultivation (). Since the amplification bias, the sequencing depths at different regions of the genome can be extremely uneven. Metagenomic sequencing studies a microbe community as a whole () and has similar problem of uneven sequencing depths of genomes because different species in a sample have different abundances. Almost all existing de novo assembly tools were designed for single genome with uniform sequencing depth and were used by some recent studies on microbes (To whom correspondence should be addressed.
2009). However, these tools may not be able to produce long contigs when applying to data with highly uneven sequencing depths. Many existing de novo assembly tools for the next-generation sequencing reads adopt the de Bruijn graph approach () in which a vertex represents a unique length-k substring called k-mer and an edge connects vertices u and v if and only if u and v appear consecutively in a read. Each read is represented by a path of k-mers in the de Bruijn graph. After error detection and removal, a simple path in the de Bruijn graph represents a contig. There are three major problems in this approach (,(a) Incorrect k-mers: Sequencing errors introduce many incorrect k-mers (vertices) that make the de Bruijn graph complicated.(b) Gap problem: When k is large, especially in regions with lower sequencing depths, some k-mers (i.e. vertices, also edges, in the de Bruijn graph) are missing.(c) Branching problem: Due to repeat regions or erroneous reads, many branches are introduced in the de Bruijn graph especially when k is small. For Problem (a), some of these errors can be removed by the topological structure of the graph. For the remaining errors, based on the assumption of uniform sequencing depth and the observation that the multiplicity of an erroneous k-mer is usually smaller than that of a correct k-mer, existing tools use a simple threshold to either prune contigs if the contigs are formed by k-mers of low multiplicity [e.g. Velvet () and Abyss (or directly remove k-mers with low multiplicity [IDBA () and EULER-SR (. Note that this also solves some of the branching problems] due to incorrect k-mers. For Problems (b) and (c), using a small k will induce more branches whereas using a large k will result in more gaps. Most existing tools [e.g. Velvet () and SOAPdenovo (just pick an appropriate k, some intermediate value, to balance the two problems. On the other hand, the IDBA assembler () provides a better solution which, instead of using a single k, iterates from k = k min to k = k max. At each iteration, the constructed contigs are used as reads for the next iteration. These contigs carry the k-mers of the current iteration, which may be missing in the next iteration, to the next iteration, thus solving some of the gap problems. It then relies on larger k to resolve the branches for the repeat regions.
IDBA-UDHowever, when applying to single cell or metagenomic assembling, highly uneven sequencing depth aggravates these problems further that affect the performance of these tools substantially due to the following issues. Issue (A): erroneous vertices and branches in high-depth regions; Issue (B): gaps in low-depth short repeat regions.
Problems (a) and(c) due to Issue (A): Due to highly uneven sequencing depth, the assumption of an incorrect k-mer having lower multiplicity is not valid. Those incorrect ones in the high-depth regions may even have higher multiplicity than the correct ones in the low-depth regions, thus simply using a single threshold to remove incorrect vertices will not work. Setting the threshold too low induces many incorrect vertices and edges (those in high-depth regions) in the graph. Setting the threshold too high will remove many correct vertices and edges in low-depth regions. We remark that there exist some error correction algorithms for reads/k-mers (), but they do not perform very well in datasets with very uneven sequencing depths.
Problems (b) and (c) due to Issue (B):Recall that most existing assemblers do not have a good method to resolve Problems (b) and (c) probably, except IDBA. Even for IDBA, in low-depth short repeat regions [For very long repeats (longer than the whole span of a paired-end read), it is almost impossible to resolve it.], when k is small, the branching problem makes it difficult to construct a contig to be passed to the next iteration. When k is increased, due to the low-depth issue, we still have the missing k-mer problem (the gap problem). Velvet-SC () is the only tool that tries to address the assembling problem of single-cell sequencing data with very uneven sequencing depths. Following Velvet, Velvet-SC picks an appropriate k to balance the gap and the branching problem; and uses variable thresholds to address problems related to Issue (A). Short erroneous contigs are filtered iteratively using different thresholds from low to high sequencing depths based on a global average of the multiplicity of all k-mers. Its performance is already better than existing tools designed for even sequencing depth. However, problems related to Issue (B) are not yet handled. In this article, we propose an assembler called IDBA-UD for de novo assembly of reads with uneven sequencing depths that tackles both issues. To resolve Issue (A), IDBA-UD extends and enhances the idea of variable thresholds of Velvet-SC () to filter out erroneous contigs. To cater for very extreme sequencing depths, instead of using a global average of the multiplicity of all k-mers, we adopt variable 'relative' thresholds depending on the sequencing depths of their neighboring contigs based on the idea that short contigs with much lower sequencing depths than their neighboring contigs tend to be erroneous For the gap and branching problems, we follow the approach of IDBA and iterate from a small k to a large k so that the missing k-mers for large k can be obtained from contigs constructed in the iterations of small k. Then we tackle Issue (B) as follows. The problem of Issue (B) is due to the low-depth short repeat regions such that using small k, we cannot get the contig out since it is a repeat region and the branches may be complicated due to the ambiguity of using a small value of k. When k increases, however, due to the low sequencing depths some k-mers are missing. Even if we iterate from small k to large k, this problem of missing k-mers cannot be resolved. So, we employ the technique of local assembly with paired-end information to handle these cases. Paired-end reads with one end aligned to some long confident contigs are grouped together. Local assembly is performed on the unaligned ends. Since we consider only the read pairs with one end aligned to the contig, the ambiguity due to small k is removed. If the insert size is longer than the repeat involved, it is likely that we can extend the contig over this repeat region, thus constructing the missing k-mers for large k. Note that this local assembly step can also help to resolve some branching problems in high-depth regions too. To further reduce the size of the de Bruijn graph and to speed up the assembly process, at every iteration, we conduct an additional error correction step by aligning the erroneous reads from the highdepth regions to confident contigs (i.e. with many supporting reads) which turns out to be very effective. We compared the performance of IDBA-UD with other assemblers on data in actual situations when the sequencing depths are extremely uneven, e.g., with the ratios larger than 100:1. Experiments on both simulated and real datasets showed that IDBAUD produces much longer contigs than existing assemblers with higher coverage and precision.
METHODSA flowchart of the major steps of IDBA-UD is shown in. IDBA-UD iterates the value of k from k min to k max. In each iteration, an 'accumulated de Bruijn graph' H k for a fixed k is constructed from the set of input reads and the contigs (C ks and LC ks ) constructed in previous iterations, i.e. these contigs
Y.Peng et al.are treated as input reads for constructing H k. In each iteration, IDBA-UD also progressively increases the value of depth cutoff thresholds for removing some low-depth contigs so as to get longer confident contigs (C k ) in H k. Error in reads are corrected by aligning the reads to some confident contigs. Some missing k-mers in reads can be recovered from those contigs (LC k ) reconstructed by local assembling of a small set of paired-end reads with one end aligned to a confident contig. Information of these missing k-mers will be passed on to the next iteration through these contigs (LC k ) for the construction of H k+s. Finally, all outputted contigs are used to form scaffolds using paired-end reads information. Algorithm 1 shows the pseudocode of IDBA-UD for assembling a set of paired-end reads R with insert distance d and SD . In the first iteration when k = k min , H k is equivalent to a de Bruijn graph for vertices whose corresponding k-mers have multiplicity at least m (2 by default) times in all reads. During all the subsequent iterations, some sequencing errors are first removed according to the topological structure of H k , e.g. dead-end contigs and bubbles [Steps (b) and(c)]. The dead-end contigs (tangling paths in H k of lengths shorter than 2k) are likely to be false positives (). Paths (bubbles) representing very similar contigs except at one position and with the same starting vertex and ending vertex are likely to be caused by an error or a single-nucleotide polymorphism (SNP) and they should be merged together into one contig (). When constructing H k+s from H k , each length s+1 path in H k is converted into a vertex (k +s)-mer and there is an edge from between two vertices if the corresponding (k +s+1)-mer appears f (1 by default) times in reads or once in contigs in C k  LC k. In the following subsections, we will describe the other steps of IDBA-UD in detail.
Progressive relative depthThe sequencing depth, 'depth' in short, of each simple path (contig) in H k (H k which is a copy of H k is used in Algorithm 1 so as to preserve H k after the implementation of this step) is used to remove errors. The 'depth of a contig' is the average number of reads covering each k-mer in the contig. Note that long contigs are usually correct, because long simple paths can unlikely be formed by erroneous reads; similarly for high-depth contigs which have supports from many reads. For a contig, whether its length is long or short and whether its depth is high or low cannot be judged by its absolute values as the length of a contig depends on the value of k and the depth of a contig depends on the depths of its neighboring contigs (neighboring contigs can be identified by their adjacency in the de Bruijn graph). Even though wrong contigs in highdepth regions may have higher depths than correct contigs from low-depth regions, 'short' (<2k) and 'relatively low depth' (less than a fraction  of its neighboring contigs' average depth) contigs are likely to be erroneous and can be removed. There is still a risk of removing short and relatively low-depth correct contigs because some relatively low-depth correct contigs with high-depth neighbors may be broken into short contigs by some wrong contigs (as branches in H k ). Based on the observation that these short and relatively low-depth correct contigs usually have higher depths than the short wrong contigs, we can filter out these wrong contigs first by increasing the depth cutoff threshold progressively from low to high. After the wrong contigs or branches are removed by a low-depth cutoff threshold, the relative low-depth correct contigs will be linked together to form long confident contigs which will be considered as reads for the next iteration. The key idea to consider the depth progressively and relatively is shown in Algorithm 2. T (c) represents the depth of contig c and T neighbor (c) represents the mean depth of c's neighboring contigs. The filtering depth cutoff threshold t is increased by a factor  progressively ( is 10%). A geometric increase, instead of absolute increase (as used in Velvet-SC), in the depth cutoff threshold value improves implementation efficiency because the threshold difference is more sensitive at the low-depth values than the high-depth values. In each iteration, short contig c is removed if its depth T (c) is lower than the minimum of cutoff threshold t and the relative threshold *T neighbor (c) where  is in the range of 0.10.5.
Algorithm 1 IDBA-UD(R, d, ):1 Pre-Error-Correction (optional) 2 Repeat from k := k min to k max with step s (a) If k = k min , then construct H k from R else construct H k from H ks and RC ks  LC ks (b) Remove dead-ends with length <2k (c) Merge bubbles
Local assemblyIDBA makes use of the contigs (containing the information of some missing k-mers for larger k) constructed in each iteration for the construction of the de Bruijn graphs of larger k. These missing k-mers may not exist in any of the reads but they might help to fill the gaps in the de Bruijn graphs for larger k. This approach still has a limitation that not all the missing k-mers, i.e. contigs containing these k-mers, can be constructed (so not all the gaps can be filled) because of branches. The main contribution of local assembly is to construct these contigs for the missing k-mers, especially in the lowdepth regions, based on the information of paired-end reads to eliminate the branches introduced from other parts of the genome. We shall illustrate this main idea of local assembly through an example (. Let us consider the construction of a de Bruijn Graph for k = 3, based on two reads, ...AACT and ACTG..., we have a simple path connecting the 3mers, AAC, ACT and CTG. IDBA can reconstruct the missing 5mer AACTG (not appeared in any reads) by forming a simple path containing it. However, as given in, when ACT is a length-3 repeat in the genome (the repeat regions are apart by more than the insert distance) and there are reads covering the region ...TACTT... containing the other repeat. The 3mer ACT in the de Bruijn graph for k= 3 now has two in-branches and two out-branches (refer to the left diagram ofwhere vertex v represents the 3mer ACT; vertices u, w, u and w are for 3mers AAC, CTG, TAC and CTT, respectively). Under this situation, even when k is increased to 4 and 5 in IDBA (this part of graph will be disconnected in H 4 and H 5 ), the missing critical 5mersThe repeat region is a single k-mer, uvw and u vw appear in the genome. After the iteration, repeat v is resolved AACTG cannot be reconstructed because of the branches. However, when considering the de Bruijn graph when k = 3, IDBA-UD will align the pairedend reads to the contig ACGATCGTAGCTGA () whereas the reads of the other ends covering the repeat regions will only be ...AACT and ACTG... (reads covering the other repeat region ...TACTT... are not involved because they are far away). Thus, local assembly (by considering the reads locally) can produce a simple path containing the critical 5mer AACTG to resolve branches as if there were no repeats.Let C k be the set of contigs (simple paths) in H k. The set of paired-end reads R c are those with one read aligned with the ends of each long contig c (with length at least twice of read length) in C k (c rc stands for the reverse complement of contig c). The other unaligned ends of these aligned pairedend reads, which would cover the genome regions extended about an insert distance beyond each end of a long contig, are extracted separately. Assume the insert distances of paired-end reads satisfy the normal distribution N(d,). IDBA-UD groups the last d +3 bases of c/c rc and R c /R rc c together and then locally assembles them into the set of local contigs LC k using IDBA [Algorithm 1 without Steps (e), (g) and(h)] as shown in Algorithm 3. Since those reads which are far away from the contig c will not be mixed up with these unaligned ends, the contig c and these unaligned ends (reads) of R c can be used to construct a smaller and simpler de Bruijn graph whose simple paths (represented by the set of contigs LC k ) might reconstruct some of the missing k-mers and be considered as reads for the next iteration. Thus, the contigs can be extended longer and longer at each iteration. The expected number of resolved branches can be computed by Theorem 3 (Appendix).
Error correctionTo reduce the errors in reads, error correction on some erroneous bases is performed based on the alignment between reads and confident contigs. Errors in reads are corrected only if they can be aligned to contigs with certain similarity, say 95%. The reads which can be multi-aligned to different contigs will not be considered for corrections. This approach of error correction is especially effective for high-depth regions because the confident contigs are well-supported by many reads. A position of a contig is labeled as 'confirmed' if one base type appears over 80% in all reads aligned to that position. Each read, aligned to a contig region with all positions confirmed and the number of different bases no >3, will be corrected according to the confirmed bases. A pre-error-correction step for improved efficiency can be used to remove errors in high-depth regions as the first step in IDBA-UD if the sequencing depths are extremely uneven. A medium k-value and filtering threshold will be used to assemble reads to form contigs and errors in reads are corrected based on its alignment with the output contigs.
ScaffoldThe reads are finally aligned to contigs so as to build a scaffold graph in which each vertex u represents a contig and each edge (u, v) represents the connection between u and v with a support of > p (3 by default) paired-end reads. After the scaffold graph is built, scaffold algorithm () will be applied to further connect contigs.
RESULTSTo evaluate the performance of our algorithm, experiments (All experiments were done on a machine with 8-core 2.40 GHz Intel CPU and 144 GB memory. The tested assembler was run with multiple threads, if it supports.) are carried out on several datasets with different properties. Results on existing general purpose assemblers like Velvet (), SOAPdenovo (), IDBA () and special purpose assemblers like Velvet-SC (), Meta-IDBA () were compared. Different k-values were tried for each assembler and the result with best performance are shown and compared. Two most important statistics, N50 and coverage are calculated to evaluate the contiguity and completeness of assembly results. N50 is the length of the longest contig such that all the contigs longer than this contig cover at least half of the genome being assembled (). Coverage is the proportion of the genome being covered by output contigs. In this article, only correct contigs are considered in the calculation of N50 and coverage. A contig is considered as correct if it can be aligned to the genome reference by BLAT () with 95% similarity. For correct contigs, the substitution errors are computed by comparing the alignment between contigs and genome reference. For unaligned contigs, the number of contigs and the number of bases are recorded for comparison.
Error correctionThe performance of our error correction algorithm is assessed by correcting the simulated reads sampled from Lactobacillus delbrueckii genome (1.85 Mb). The simulated dataset contains 1.85 million length-100 reads (100) uniformly sampled from the reference with 1% error rate. The error correction algorithm was executed on this dataset with output contigs of IDBA with k = 60 (k min = k max in this case). The correction result is shown in. There are 1 856 822 error bases in the dataset. Our algorithm corrected 1 627 727 bases with 1 626 929 (99.95%) being true positive. Note that our target of error correction is to reduce the errors without introducing other errors. The remaining erroneous reads either contain too many errors to be aligned to contigs or are from those regions which cannot be assembled correctly. This highprecision and low-sensitivity error correction algorithm is suitable
Y.Peng et al.for IDBA-UD, because the remaining errors could be handled by other means in the later iterations. Note that error correction which simplifies the graph for next iterations improves efficiency tremendously.
Low depth assemblyLactobacillus plantarum (3.3 Mb) was used as genome reference for simulating low-depth dataset. 10 length-100 paired-end reads were simulated for testing. The assembly results of IDBA-UD, Velvet, SOAPdenovo and IDBA are shown in, which is nearly twice of N50 of scaffolds constructed by other assemblers. Although N50 of scaffolds generated by different assemblers are similar, the coverage of scaffolds generated by all assemblers is much lower than that of contigs except IDBAUD. IDBA-UD made the least misassembly during the scaffolding process, because of having longer and more accurate contigs. In general, IDBA-UD achieved its best performance by iterating k from 20 to 100, whereas Velvet, SOAPdenovo and IDBA had best performance when k is set to a small value (21, 31 and 2040, respectively). Since, the local assembly procedure can reconstruct missing k-mers, IDBA-UD can iterate k to a large value to construct very long contigs. The other assemblers are not able to reconstruct missing k-mers so that a reasonably small k is used to balance the gaps and branches problem. The running time and memory cost are more or less the same among all assemblers.
Local assemblyThe expected number of resolved branches (Theorem 3 in Appendix) by IDBA-UD, IDBA and the actual numbers by all assemblers for different repeat lengths k are shown in. We ran all assemblers with a specific k (k max ) and measured repeats with length (k10,k). Since SOAPdenovo and Velvet cannot handle even values of k due to the palindrome problem, 29, 39 etc. are considered in. The number of resolved branches by IDBA-UD is slightly smaller than the expected number because some of the (k +2)-mers
Single cell assemblyTwo single-cell short read sequencing datasets; Escherichia coli (lane 1) and Staphylococcus aureus (; http://bix .ucsd.edu/projects/singlecell/) were used to test the performance of IDBA-UD, SOAPdenovo, Velvet and Velvet-SC (Velvet-SC was run after EULER error correction as the authors suggested. The assembly result we presented is slightly different from that in Velvet-SC paper, because we calculated the N50 for aligned contigs rather than all contigs.). Genome sequences of E
.coli str. K-12 substr. MG1655 and S.aureus subsp. aureus USA300_FPR3757were downloaded from NCBI and were used as reference for validation. The statistics of the assembly results of different assemblers are summarized in Tables 4 and 5.
De novo assembly of E.coliAccording to (), the average sequencing depth of single-cell sequencing data of E.coli is 600 and the reads are sampled very unevenly. For contigs, SOAPdenovo and Velvet have similar N50 (6428 and 7679); Velvet-SC has the second best N50 (34 454), as it considers the property of uneven depth to remove errors; IDBA-UD has the longest N50 (82 007), as it considers uneven relative depth to remove errors and uses local assembly to reconstruct missing k-mers in low-depth regions. The contigs constructed by IDBA-UD also have the highest coverage. IDBA-UD and Velvet-SC have the least number of substitution errors. All assemblers constructed some contigs cannot be aligned to the reference. Some of them are really misassembled contigs, but the alignment of reads against contigs andThe read length is 100, insert distance is 215 and the average depth is 600.The read length is 100, insert distance is 265, and the average depth is 2300. reference showed that some non-aligned contigs are from regions with structure variations. After scaffolding, all assemblers produced longer scaffolds and lower coverage, but the difference between contigs and scaffolds is not much except SOAPdenovo. SOAPdenovo increased the N50 from 6428 to 25 244, but the coverage dropped from 92.42% to 86.49%. This means that the uneven depth of single cell assembly makes the scaffolding very difficult so that assemblers either cannot construct long scaffolds or make many mistakes in scaffolding procedure. Since IDBA-UD produced very long contigs, although scaffolding did not connect many contigs, the scaffolds generated by IDBA-UD have the longest N50 and highest coverage.
De novo assembly of S.aureusThe sequencing depth of single-cell sequencing data of S.aureus is 2300, much higher than that of E.coli. SOAPdenovo and Velvet performed better for dataset with higher sequencing depth. The contig N50 of SOAPdenovo and Velvet became 12 214 and 15 800, about twice of that of E.coli. IDBA-UD and Velvet-SC had similar performance as before, and handle reads with uneven depth quite well. Generally, higher sequencing depth does not affect the quality of assembly result much. The scaffolding also increases N50 and reduces coverage. The substitution error rates are very low for all assemblers for this high sequencing depth. SOAPdenovo is the fastest assemblers among four assemblers IDBA-UD took about twice the time of SOAPdenovo to perform de novo single cell assembly. The memory cost of IDBA-UD is much less than the others, as it did the filtering on k-mers. Depending on the nature of assemblers, different assemblers achieved its best performance with different k-values. SOAPdenovo got its best performance by using relatively large k-values (75 and 95) to reduce errors in high-depth regions and introducing more gaps problem at the same time It then relies on paired-end information to connect contigs to form scaffolds. Therefore, it produced more and shorter contigs and more gaps in its scaffolds than the others. Velvet preferred a relatively small k-values (45 and 55), probably because it contains a very sophisticated algorithm to remove the errors in de Bruijn graph. Velvet-SC had best performance with a moderate k-value (55) and relies on iteratively removing low-depth erroneous contigs to form long contigs. IDBA-UD is able to iterate k-values from small to large to build a de Bruijn graph with less gaps and less branches and obtain the best performance, through local assembly producing missing k-mers and iterate depth for reducing the errors.
Metagenomic assembly
De novo assembly of simulated metagenomics dataTo evaluate the performance of IDBA-UD on metagenomic data, we considered a simulated dataset with extremely uneven depth. This dataset was synthesized by combining simulated reads of three species L.plantarum (3.3 Mb), L.delbrueckii (1.85 Mb) and Lactobacillus reuteri F275 Kitasato (2 Mb) from the same genus. Length-100 reads were sampled from these three species with sequencing depth 10 (low depth), 100 (moderate depth) and 1000 (high depth), respectively, with 1% error rate. The simulated paired-end reads have an insert distance following normal distribution N(500, 50). IDBA-UD, SOAPdenovo, Velvet and MetaIDBA were executed on this simulated metagenomic sequencing dataset. Since the depth is highly uneven, the Pre-Error-Correction of IDBA-UD was activated to remove errors. The experiment results are showed inThe sequencing depth of these species are 10, 100 and 1000, respectively. The read length is 100, error rate is set to 1% and the insert distance follows normal distribution N(500, 50).). It is because they make a tradeoff between low-depth and high-depth regions and cannot handle them together. SOAPdenovo and Velvet have the best performance in N50 and coverage when k = 45. Small k is chosen because the genome size of low-depth species (3.3 Mb) is larger than high-depth species (2 Mb). In fact, their performance for k = 55 are similar except that the coverage of lowdepth species decreases, the coverage of moderatedepth species remains the same and the coverage of highdepth species increases. Meta-IDBA designed for metagenomic assembly iterates k from small to large to capture both low-depth and high-depth regions. At each iteration, missing k-mers in low-depth and moderate-depth regions introduce fragmentation in the assembly result. Thus, MetaIDBA outperforms SOAPdenovo and Velvet, but performs worse than IDBA-UD. The contigs constructed by Meta-IDBA covered >99% of the regions in high-depth species, slightly <90% of the regions in lowdepth species and moderate-depth species. As expected, IDBA-UD outperforms SOAPdenovo, Velvet and Meta-IDBA in all aspects. N50 (44 879) of contigs constructed by IDBA-UD is 10 times of the second best N50 (4588) of contigs constructed by Meta-IDBA. IDBA-UD also has the best coverage (99.15%), 10% higher than the second highest by Meta-IDBA. The contigs constructed by IDBA-UD covered almost all the region of three species, the uneven depth does not affect the assembly quality of IDBA-UD. Similar to single-cell assembly, scaffolding in all assemblers produced longer contigs but lower coverage. As for substitution error rate, IDBA-UD and Meta-IDBA have much higher accuracy and IDBA-UD constructed the least number of misassembled contigs. The running time of all assemblers are similar, but IDBA-UD and Meta-IDBA used about half of memory as SOAPdenovo and Velvet.
De novo assembly of human gut microbial short read dataReal human gut microbial sequencing data were used to assess the performance of IDBA-UD. The datasets (SRR041654 and SRR041655) were downloaded from NCBI for assembly. The reads were generated by Illumina Genome Analyzer II with read length 100 and insert distance 260. IDBA-UD, SOAPdenovo, Velvet and Meta-IDBA were compared with this dataset (The Pre-ErrorCorrection of IDBA-UD was activated.) Since there is no reference, we used the largest total contig size of all assemblers as the estimated genome size (98 407 199) for N50 calculation, and did not analyze the completeness of assembly by comparing genome coverage. MetaGeneAnnotator (; only complete genes predicted by MetaGeneAnnotator are considered as recovered) was applied to the output of each assembler to predict the number of genes recovered. The statistics of assembly results are summarized in
De novo assembly of simulated metagenomic data with different similarity levelTo show the performance of IDBA-UD on data with different similarity level, we constructed three kinds of datasets with genomes in same genus, family and class. For each similarity level, five test cases with three species are selected randomly and sampled with low-depth (10), middle-depth (50) and high-depth (250) regions. The average of assembly results are shown in. In general, all assemblers have the best performance on dataset in class level and the worst performance on dataset in genus level. Contigs and scaffolds generated by IDBA-UD have the largest N50 and highest coverage in all three kinds of datasets. Velvet generated the second highest coverage, but it produced the shortest N50. The scaffolds generated by SOAPdenovo have the second largest N50, but they covered the least portion of genomes. Meta-IDBA is somehow in the middle, because it is designed to handle similar subspecies problem rather than different expression levels. In the assembly results of IDBA-UD, all species got similar coverage. All the other assemblers generated high coverage for middle-depth (50) species but lower coverage for low-depth and high-depth species, because they balanced the gap problems in low-depth species and high-depth species and benefited the middledepth species Consistent with previous experiments, IDBA-UD outperformed all the existing assemblers in sequencing data with highly uneven depth in all these experiments.
APPENDIXBranches may be caused by erroneous reads (k-mers), variations (SNPs) or repeats. The branches caused by erroneous k-mers can be solved by the graph structure, such as dead-end or bubbles. The branches caused by a length-k repeats can be resolved if we have a (k +2)-mers covering the repeat, which can be obtained if the corresponding (k +2)-mers covering the repeat are sampled in reads or the (k +2)-mer is obtained by local assembly.shows an example of H k and H k+1 for resolving a lengthk repeat v and its associated branches. Since it is impossible to resolve these branches by H k itself, reads and contigs are considered in each iteration from H k to H k+1 to resolve them. If the (k +2)-mers covering repeat v, e.g. uvw and u vw , exist in reads, these (k +2)mers can be used to convert branches to simple paths. If some of these (k +2)-mers are missing in reads due to low depth or errors, then local assembly can be used to reconstruct them as shown in. In this section, we try to calculate the expected number of branches caused by repeats that can be resolved by (k +2)-mers which already exist in reads or reconstructed by locally assembly. Theorem 2 gives the expected number of (k +2)-mers covering a repeat being sampled f times (applied by IDBA). Theorem 3 gives the expected number of (k +2)-mers covering a repeat being sampled f times or reconstructed by local assembly (applied by IDBA-UD). Thus, the difference between these two expected numbers as given in Theorems 2 and 3 indicates the expected number of repeats resolved by local assembly.Theorem 1. Assume t length-l reads are uniformly sampled from a length-g genome with error rate e, the probability that a k-mer v appearing x (g >> x) times in the genome being sampled at least m times is at leastProof. Pr(v is sampled in a read)  Pr(a read containing v is sampled) Pr(v is sampled | a read containing v is sampled)The probability that a correct k-mer v appears < m times is at most m1 i=0 t i p i (1p) ti , so the result follows.Theorem 2. Assume t length-l reads are uniformly sampled from a length-g genome with error rate e and R k is the set of repeats with length k. If the support requirement for resolving a branch is f , then the expected number of resolved branches S k from k to k+1 is at leastwhere Y (r) is the set of the (k +2)-mers covering repeat r in the genome and x(b) is the number of times that b appear in the genome.Proof. To resolve a repeat of length k, a (k +2)-mer appearing at least f times in the reads is needed and the probability of such (k +2)-mer is P k+2,f ,x(b) (). If reads are localized to a specific region of genome, then the branches caused by distant repeats may disappear and convert to simple paths. In this way, local assembly may generate local contigs which help to resolve branches.Theorem 3. Assume t length-l reads are uniformly sampled from a length-g genome with error rate e, R k is the set of repeats with length k and LR k is the set of length-k repeats occurring at least twice in the genome within insert distance. If the support requirement for resolving a branch is f and IDBA-UD is applied on the data from k to k+1, then the expected number of resolved branches LS k is at leastwhere Y (r) is the set of the (k +2)-mers covering repeat r in the genome and x(b) is the number of times that b appears in the genome. Proof. If a repeat does not appear twice within insert distance, then it can be resolved by IDBA-UD, i.e. |R k LR k | and those repeats occurring more than once within the insert distance can only be resolved by the (k+ 2)-mers appearing at least f times in reads (Theorem 2).
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
DISCUSSION AND CONCLUSION In this article, we proposed a new assembler IDBA-UD, an extension of IDBA, to assemble short sequencing reads with highly uneven depth. Besides iterating k from small to large, IDBAUD reconstructs missing k-mers by local assembly and removes errors by iteratively removing low-depth contigs. The experiment results on both simulated and real datasets showed that IDBA-UD outperformed all existing assemblers in assembling datasets with highly uneven depth. For metagenomic data, there are more common k-mers between genomes from subspecies of the same species than genomes from different species. This information is used in MetaIDBA for assembling metagenomic data. As a future work, we should study how to integrate this information in IDBA-UD for better performance. Funding: This work was supported in part by HKGRF funding (HKU 7116/08E, HKU 719709E) and HKU Genomics SRT funding. Conflict of Interest: none declared.
