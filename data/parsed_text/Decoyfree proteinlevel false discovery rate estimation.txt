Motivation: Statistical validation of protein identifications is an important issue in shotgun proteomics. The false discovery rate (FDR) is a powerful statistical tool for evaluating the protein identification result. Several research efforts have been made for FDR estimation at the protein level. However, there are still certain drawbacks in the existing FDR estimation methods based on the target-decoy strategy. Results: In this article, we propose a decoy-free protein-level FDR estimation method. Under the null hypothesis that each candidate protein matches an identified peptide totally at random, we assign statistical significance to protein identifications in terms of the permutation P-value and use these P-values to calculate the FDR. Our method consists of three key steps: (i) generating random bipartite graphs with the same structure; (ii) calculating the protein scores on these random graphs; and (iii) calculating the permutation P value and final FDR. As it is time-consuming or prohibitive to execute the protein inference algorithms for thousands of times in step ii, we first train a linear regression model using the original bipartite graph and identification scores provided by the target inference algorithm. Then we use the learned regression model as a substitute of original protein inference method to predict protein scores on shuffled graphs. We test our method on six public available datasets. The results show that our method is comparable with those state-of-the-art algorithms in terms of estimation accuracy. Availability: The source code of our algorithm is available at: https:// sourceforge.net/projects/plfdr/
INTRODUCTIONShotgun proteomics is a strategy that is capable of identifying complex protein mixtures by combining high-performance liquid chromatography and mass spectrometry (MS). In shotgun proteomics, the protein identification procedure has two main steps: peptide identification and protein inference (). In peptide identification, we search the experimental MS/ MS spectra against a protein sequence database to obtain a set of peptide-spectrum matches. In protein inference, we report a set of proteins by assembling peptide identification results (). Basically, there are two major computational issues in protein identification that have to be solved. On one hand, we need to develop effective and fast identification/inference algorithms at both the peptide level and the protein level. On the other hand, controlling the quality of identified peptides and inferred proteins is as important as developing identification algorithms. Inferred proteins are more biologically relevant than identified peptides in a proteomics experiment. Therefore, it is vital to control the quality of identification results at the protein level. However, the accurate assessment of statistical significance of protein identifications remains an open question (). To date, several research efforts have been made to estimate the protein-level error rate in terms of false discovery rate (FDR). The mainstream approach for FDR estimation is the target-decoy strategy, which searches a target-decoy concatenated database so that the number of false positive protein identifications can be estimated from the number of decoy proteins. For instance, the MAYU method () is a typical representative in this category. By adapting the target-decoy strategy to the protein inference task, the MAYU method first assumes that protein identifications containing false positive peptide-spectrum matches are uniformly distributed over the target database. Then, the number of false positive protein identifications is hypergeometrically distributed. As a result, the expected number of false positive protein identifications can be calculated as the probability weighted average. Finally, the protein identification FDR is computed as the ratio of the expected number of false positive protein identifications and the total amount of protein identifications mapping to the target database. However, this valuable approach has certain drawbacks (). First, searching both the target and the decoy database will certainly double the running time in the protein identification process. Second, the FDR estimation result may be unstable, as we usually use only one decoy database with the same size of target database. Finally, the protein FDR value is calculated according to the distribution of decoy peptides across different proteins, making it possible to propagate errors at the peptide level to the protein level in a non-trivial manner. In this article, we propose a new method for estimating the FDR at the protein level without searching the decoy database. Our method uses random permutation to assess the statistical significance of each protein in terms of P-value and then calculates the final FDR. First, the input for the protein inference problem can be modeled as a bipartite graph: the left is a set of identified peptides and the right is the set of candidate *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com proteins with at least one matched peptide (). From this bipartite graph, a protein inference algorithm calculates the probability or score for each protein. The null hypothesis in our method is that each candidate protein matches an identified peptide totally at random. Under this null hypothesis, we first create multiple random bipartite graphs with the same set of peptides and proteins. Each random bipartite graph has the same structure as the original one, i.e. each protein (peptide) is connected to the same number of peptides (proteins). Then, we run the same protein inference algorithm on these random bipartite graphs, and check if the score of each protein is significantly different on the real graph than on the randomized graphs. That is, we calculate the permutation P-value of one protein as the percentage of random graphs that produce a larger score than its original score. Finally, we sort the proteins according to their P-values and calculate the FDR at different thresholds with permutation P-values as input using the method in Storey and Tibshirani (2003). Our method has three key steps: (i) generating random bipartite graphs with the same structure; (ii) calculating the protein scores on these random graphs; and (iii) calculating the permutation P-value and FDR. Among these steps, it is relatively easy to perform the first step and the third step. However, it is timeconsuming or prohibitive to execute some protein inference algorithms for thousands of times to fulfill step ii. To address this issue, we first train a linear regression model using the original bipartite graph and identification scores given by the target inference algorithm. Then, we use the learned regression model as a substitute of original protein inference method to predict protein scores on shuffled graphs. Experimental results on several real proteomics datasets show that our method is effective in FDR calculation. Overall, the salient features of the work described in this article can be summarized as follows:It can calculate the FDR without using a decoy database. It can be applied to evaluate the protein identification results from any algorithm that outputs protein probabilities/ scores. The rest of this article is organized as follows. In Section 2, we describe our method in detail, Section 3 presents the experimental results and Section 4 concludes the article.
METHODSIn our method, we use permutation test to calculate the P-value of each protein and then use these P-values to calculate the final FDR. Therefore, our method mainly consists of the following steps:(1) Generating multiple random bipartite graphs with the same structure;(2) Building a linear regression model with the original bipartite graph and protein identification scores reported by the target protein inference algorithm;(3) Predicting the protein scores on random graphs using the trained linear regression model;(4) Calculating the permutation P-value and FDR.In the following, we will explain each step in detail. As step 2 is tightly correlated with step 3, we will elaborate them in the same subsection.
Generating random bipartite graphsIf we wish to test the null hypothesis that each candidate protein hits an identified peptide at random, it is important to construct random graphs with the same structure as the original one. It ensures that the shuffled graphs are comparable with the original graph, whereby each protein (peptide) is connected to the same number of peptides (proteins). Given m candidate proteins and n identified peptides, the bipartite graph GL, R, E models the input for the protein inference problem. The vertex j 2 L corresponds to the jth peptide and jLj  n. Similarly, the vertex i 2 R represents the ith candidate protein and jRj  m. Then, there exists an edge j, i 2 E if the ith candidate protein contains the jth peptide. We generate a random bipartite graph by the following steps:(1) Record the degree of each protein/peptide (the number of peptides/ proteins that each protein/peptide is connected with) in the original bipartite graph.(2) Randomly select one protein i and one peptide j whose degrees are both larger than 0, and ensure that there is no edge between them in the current random graph.(3) Connect protein i and peptide j and decrease the degrees of protein i and peptide j by 1.(4) If there are no such proteins and peptides, and the number of edges in the current random graph is less than that in the original graph, select one edge j e , i e  in the random graph such that there is no edge between j e and i in the random graph. Remove edge j e , i e  and add an edge j e , i. Increase the degree of protein i e by 1 and decrease the degree of protein i by 1.(5) Do steps 24 until the generated random graph has the same number of edges as the original graph.Algorithm 1 shows a straightforward implementation of this generation method.Input: Original graph GL, R, E Output: Random graph G 0 L, R, E 0  with the same structure as G 1: E 0 null 2: Initialize the degree of each protein and each peptide 3: while jE 0 j5jEj do 4: randomly select one protein i with Degreei ! 1 5: if all j with Degreej ! 1 make j, i 2 E 0 then 6: select j e , i e  2 E 0 such that j e , i = 2 E 0 7: remove j e , i e  from E 0 and add j e , i to E 0 8: Degreei e   , Degreei   9: continue 10: end if 11: randomly select one peptide j with Degreej ! 1 12: while j, i 2 E 0 do 13: re-select one peptide j with Degreej ! 1 14: end while 15: Degreei  , Degreej   16: E 0 E 0 [ fj, ig 17: end while 18: return G 0 L, R, E 0  The most important advantage of our method for generating the random graph is that it does not require any parameter. There exist some other algorithms that can generate random graphs with the same structure as the original graph. For example, the method inis more simple and easier to understand than our method because only local swaps are performed in generating a random graph. However, this method needs to specify the number of local swaps and it is difficult to decide which parameter value is the best. To make the protein inference results comparable, the graph randomization procedure should keep all the features of the original graph unchanged except the matches between proteins and peptides. The features of a graph include the number of nodes, the number of edges, the number of connected components and so on. As our method only ensures that the individual degree of each node (protein or peptide) is preserved, one may wonder whether the number of connected components will change substantially. In the Supplementary, we plot the distribution of the number of connected components in random graphs. It shows that the difference between the random graph and the real graph with respect to the number of connected components is small. Therefore, protein inference is comparable between the original graph and random graphs, although the numbers of connected components of these graphs are not exactly the same.
Predicting the protein scores on random graphsIt is time-consuming and inconvenient to execute some protein inference algorithms for thousands of times. Therefore, we build a linear regression model to predict the protein scores reported by these algorithms. We use a response variable y i 2 R to denote the identification score of protein i and a predictor vector x i 2 R n to represent the set of associated peptide probabilities or scores. The element x ij in vector x i  x i1 , x i2 ,. .. , x in  is constructed by the following way: x ij  probability of peptide j, j, i 2 E 0: j, i = 2 E 1 That is, if there is an edge between protein i and peptide j in the bipartite graph, the probability of peptide j will be used as the corresponding predictor value. As there are m candidate proteins, we have m observation pairs (x i , y i ). Essentially, all existing protein inference algorithms use the bipartite graph or the equivalent predictor vectors as input to calculate protein scores/probabilities. If we have executed a protein inference algorithm on the original bipartite graph, then we have the protein scores generated from this algorithm. From a machine learning perspective, it is possible to 'learn' a similar model that can be used to perform protein inference in the future. As a result, we can apply our method to simulate the identification results of any protein inference algorithm without knowing its algorithmic details even when its executable program is not available to us. Based on this motivation, here we build a linear regression model to realize this goal. In this approach, we search a coefficient vector to minimize the residual sum of squares:For protein i, when we have a new peptide contribution vector ^ x i , with the estimated coefficient vector ^ , we can easily use the linear model to get the identification score ^ y i :
Calculating the permutation P-value and FDRAfter obtaining the protein scores calculated on these random graphs, we can compute the permutation P-value and FDR. If our null hypothesis that each protein matches an identified peptide by chance is true, then there is no significant difference between the score of each protein in the original graph and those calculated from the random graphs. Therefore, we can calculate the permutation P-value of one protein as the percentage of random graphs that produce a larger score than its score generated on the original graph. More precisely, the P-value of the ith protein is computed as follows:where y i is the original score of the ith protein, y t i is the score of the ith protein produced from the tth random graph, #fy t i 4y i g denotes the number of random graphs on which protein i has a larger score than y i and K is the total number of random bipartite graphs. Based on these P-values, we can calculate the FDR and the pFDR value using the method described in Storey and Tibshiraniwhere denotes the rejection threshold and 0 is the proportion of false positives. PrP  represents the probability that a P-value P is no more than. The pFDR (positive false discovery rate) is a modified version of the FDR. As becomes small, FDR is driven by the fact that the rejection threshold is small rather than the fact that the 'rate that discoveries are false' is small. In contrast, pFDR can avoid this disadvantage. Therefore, in this article, we use pFDR as the final estimated value. We estimate 0 by the following equation:where p i is the P-value of each candidate protein, is a parameter and #fp i 4g denotes the number of proteins whose P-values are larger than . And we use the method in Storey (2002) to pick. Decoy-free protein-level false discovery rate estimation A natural estimate of PrP  is:where R  #fp i g represents the number of candidate proteins with P-value. With the estimated ^ 0  and b PrP , we can easily get the pFDR value at a given threshold .
EXPERIMENT
DatasetsIn our experiments, we use six publicly available datasets: 18 mixtures (), Sigma49 (), Yeast (), DME (), HumanMD () and HumanEKC (). The first three datasets have the ground-truth protein reference sets and the other three have no such reference sets. The details of these datasets are described in the Supplementaryand S2. We use X!Tandem () as the peptide identification method. As we compare our method with MAYU (), all MS/MS data are searched against both target and decoy protein databases. The decoy database is generated using the Trans-Proteomic Pipeline (TPP) v4.6 software. In reality, it is not necessary to search a decoy database when using our method. During the database search, we use default search parameters and accept the peptides reported by PeptideProphet with probabilities 40.05 as the input. For any peptide sequence that is matched by multiple spectra with different scores, we choose the highest identification score.
Parameter settingFirst, we run the protein inference algorithm on the original bipartite graph to obtain the original score of each protein and use these scores to build a linear regression model. Second, we predict the score of each protein in random graphs with the regression model and calculate the P-value and FDR. The protein inference algorithms used in our experiment are ProteinProphet () and ProteinLP (). We run ProteinProphet included in the Trans-Proteomic Pipeline (TPP) v4.6 software with the default parameter values and use ProteinLP by setting  0. As both ProteinProphet and ProteinLP output the presence probability of each protein, we transform the score predicted by the regression model into the interval. If the score is41, we set the score to 1; if the score is 50, we set the score to 0. In addition, the number of random graphs we choose is 10 000.
ResultsFor the first three datasets with reference sets, we apply our method and MAYU to estimate the FDR and check the difference between the estimated FDR and the ground-truth FDR. We set f0:05, 0:1,. .. , 0:95, 1g as the threshold, respectively. For each threshold, the smaller the difference, the better the performance. As shown in, for the first two datasets, our method is comparable with MAYU, while our method can provide a more accurate FDR estimation on the Yeast dataset when the P-value is larger than 0.2. We can also see that both our method and MAYU have huge deviations from the real protein FDRs for the first two synthetic datasets probably because 18 mixtures and Sigma49 do not have characteristics of those complex proteomics datasets generated from real samples. Thus, the experimental result on the more complex Yeast dataset indicates that both methods can perform relatively well on real data, and the advantage of our method begins to be visible. For the other three datasets, we compare our method with MAYU and the naive target-decoy method. For MAYU, we set f0:05, 0:1, :::, 0:95, 1g as the threshold, respectively. When using the naive target-decoy method, FDR is calculated by doubling the ratio of the number of decoy proteins and the total number of protein identifications in the reported proteins. As shown in, the performance of our method is comparable with the naive target-decoy method and MAYU. One important parameter in our method is the number of random graphs. We test the influence of different numbers of random graphs by comparing absolute difference between the estimated FDR and the true FDR at each threshold. We choose f1000, 3000, 5000, 7000, 10000g as the parameter value, respectively. As shown in, we can see that the absolute differences are almost the same when using different numbers of random graphs. This means that our method is insensitive to the number of random graphs when the value is 41000. We also list the real 0 and the estimated ^ 0 on six datasets in. For the three datasets without reference sets, we calculate the real 0 by doubling the ratio of the number of decoy proteins in the datasets and the total number of protein identifications in the datasets. As shown in, the estimated ^ 0 is far from its true value on 18 mixtures and Sigma49. This explains why the absolute FDR differences on these two datasets are large. Now we test the running efficiency of our method. The running time of our method and MAYU on six datasets is provided in. All the experiments are tested on the DELL Studio XPS 8100 workstation with 2.80 GHz CPU and 8 G main memory. It shows that our method is efficient in practice and faster than MAYU.
CONCLUSIONIn this article, we propose a novel protein-level FDR estimation method. We assume that each candidate protein matches an identified peptide totally at random. Then, we use random permutation for assessing the statistical significance of each protein in terms of P-value and calculate the final FDR. The main advantage is that our method can calculate FDR without searching a decoy database. Experimental results on six proteomics datasets demonstrate the superiority of our method. In the future work, we will extend our method to validate the inference results of the algorithms that do not report protein probabilities or scores. We plan to train a logistic regression model, which can assign a corresponding probability to. Performance on 18 mixtures, Sigma49 and Yeast when ProteinLP (upper) and ProteinProphet (lower) are used as the target protein inference algorithm, respectively. The difference with the benchmark  jthe estimated FDR  true FDRj. For each threshold, the smaller the difference, the better the performance. For 18 mixtures, 18 standard proteins and 15 contaminants are marked as the ground-truth. For Sigma49, all accessions in the final list of correct proteins provided by the ABRF2007 bioinformatics committee are used as the ground-truth. The influence of different numbers of the random graphs on three datasets with reference setsNote: MAYU can only report the FDR value at one threshold in each run, whereas our method can estimate a series of FDR values at all the thresholds. The execution time listed here for MAYU is the average running time over different thresholds. The number of random graphs in our method is fixed to be 10 000.Note: ^ 0 1 and ^ 0 2 are estimated when ProteinLP and ProteinProphet are used as the target protein inference algorithm, respectively. each reported protein. Meanwhile, as 0 can affect the FDR estimation results significantly, we will find more accurate 0 estimation method in the future.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
B.Teng et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
B.Teng et al.
