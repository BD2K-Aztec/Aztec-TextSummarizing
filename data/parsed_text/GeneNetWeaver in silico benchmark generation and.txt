Motivation: Over the last decade, numerous methods have been developed for inference of regulatory networks from gene expression data. However, accurate and systematic evaluation of these methods is hampered by the difficulty of constructing adequate benchmarks and the lack of tools for a differentiated analysis of network predictions on such benchmarks. Results: Here, we describe a novel and comprehensive method for in silico benchmark generation and performance profiling of network inference methods available to the community as an open-source software called GeneNetWeaver (GNW). In addition to the generation of detailed dynamical models of gene regulatory networks to be used as benchmarks, GNW provides a network motif analysis that reveals systematic prediction errors, thereby indicating potential ways of improving inference methods. The accuracy of network inference methods is evaluated using standard metrics such as precision-recall and receiver operating characteristic curves. We show how GNW can be used to assess the performance and identify the strengths and weaknesses of six inference methods. Furthermore, we used GNW to provide the international Dialogue for Reverse Engineering Assessments and Methods (DREAM) competition with three network inference challenges (DREAM3, DREAM4 and DREAM5). Availability: GNW is available at http://gnw.sourceforge.net along with its Java source code, user manual and supporting data.
INTRODUCTIONA challenging issue in systems biology is the development of computational tools for the reverse engineering of gene regulatory networks from quantitative experimental data. Over the last decade, high-throughput assays for mRNA expression have opened the door to the inference of regulatory networks by allowing simultaneous measurements of the expression levels of thousands of genes. Technologies such as spotted microarrays () and oligonucleotide chips () have enabled * To whom correspondence should be addressed. genome-wide quantification of differential gene expression profiles and, more recently, short read sequencing technologies such as RNA-seq () have provided more precise quantification of mRNA levels. Researchers have proposed a plethora of methods for reverse engineering the complex network of interactions between the genes and their RNA and protein products (also called regulatory program) from spatial and temporal high-throughput gene expression data (). Regulatory networks are often represented as directed, signed graphs in which nodes represent genes or transcription factors (TFs). In this context, edges correspond to enhancing or inhibitory regulations that affect gene transcription rates. Network inference methods rely on various computational approaches such as correlation (), mutual information (MI) (), ordinary differential equations (ODE) models (), Bayesian networks () or hybrid algorithms (). Numerous methods have been developed for inference of gene regulatory networks; however, relatively little effort has been put into evaluating the performance of those methods on adequate benchmarks. So far, three main strategies have been proposed to generate benchmark networks. A first strategy consists in evaluating network predictions made by reverse engineering algorithms on well-studied in vivo pathways from model organisms (). However, those networks are incomplete maps of the physical interactions in the cell that are responsible for cellular functions and using them as benchmarks imply making error when evaluating network predictions. Another strategy consists of genetically engineering synthetic in vivo networks (). The main drawback of this strategy is that only a few small networks are available. Yet another strategy consists in developing in silico gene regulatory networks that can be simulated to produce artificial gene expression data. The simulation of in silico networks has the advantages of being fast, easily reproducible and less expensive than biological experiments. A few instances of small in silico networks with handcrafted topologies () have been proposed as benchmarks for reverse engineering algorithms. More recently, several generators have been developed to automate the construction of in silico regulatory networks including up to thousands of genes to be used as benchmark networks for reverse engineering algorithms ().Page: 2264 22632270
T.Schaffter et al.
Fig. 1. Benchmarking andperformance assessment of network inference methods using GNW. (A) In silico gene networks are obtained by extracting subnetwork structures from known transcriptional networks (Escherichia coli, Saccharomyces cerevisiae, etc.) before being endowed with detailed dynamical models of gene regulation accounting for both transcription and translation, independent and synergistic interactions, as well as molecular and measurement noise. (B) In silico gene networks are simulated to produce steady-state and time-series expression data for a variety of experiments such as wild-type, knockout, knockdown and multifactorial perturbation experiments. (C) Inference methods are asked to predict structures of in silico benchmark networks from gene expression data. (D) From network prediction files, GNW performs a network motif analysis which often reveals systematic prediction errors, thereby indicating potential ways of network reconstruction improvements. It also automatically generates comprehensive reports including standard metrics such as PR and ROC curves.Benchmark generators such as AGN () aim to produce in silico gene networks exhibiting topological properties observed in biological networks using Erds-Renyi, Watts-Strogatz (small-world) or Albert-Barabsi (scale-free) random graph models. However, the structures generated using random graphs capture only few of the structural properties of gene regulatory networks (Van den) and do generally not display important properties such as modularity () or occurrences of network motifs, which are statistically overrepresented regulatory patterns in biological networks (). Instead of constructing more complex random structures based on graph theory, which may be difficult to justify (), SynTReN (Van den) and ReTRN () chose to generate network structures by extracting parts of known in vivo regulatory network structures. This approach has the advantage of capturing several structural properties observed in in vivo network structures (Van den). In order to produce gene expression data, the generated structures must be endowed with dynamical models of gene regulation. Systems of non-linear ODEs are widely used (), but other approaches exist (). ODE systems allow to continuously describe levels of gene products and rates of reactions taking place in the network models where biological processes that have not been fully characterized yet are abstracted. Because current high-throughput technologies do not allow the monitoring of protein expression as microarrays do for RNA (), some benchmark generators consider mRNA as a proxy for protein expression and thus do not model translation independently of transcription (). Protein expression, however, does not correlate perfectly with mRNA expression in real biological systems due in part to different degradation rates of mRNA and protein products (). RENCO (), GeNGe () and GRENDEL () are examples of available benchmark generators considering both transcription and translation processes in their respective dynamical models. Here, we describe a method for in silico benchmark generation and performance profiling of network inference methods available to the community as an open-source software called GeneNetWeaver (GNW) (). GNW has an intuitive graphical user interface that makes the generation and simulation of gene network models as simple as a few clicks. Network topologies are generated by extracting modules from known in vivo gene regulatory network structures such as those of E.coli () and S.cerevisiae (). These structures are then endowed with detailed dynamical models of gene regulation including both transcription and translation processes using a thermodynamic approach accounting for both independent and synergistic interactions (). Expression data can be generated either deterministically or stochastically to model molecular noise in the dynamics of the networks, and experimental noise can be added using a model of noise observed in microarrays (). Different types of in vivo experimental procedures, such as wild type, knockout (null-mutant), knockdown (heterozygous) and multifactorial perturbations, can be reproduced by the software. In addition, a unique feature of GNW is the systematic and comparative evaluation of predictions by different inference methods, which none of the existing benchmark generators Page: 2265 22632270
Benchmarking with GeneNetWeaverprovide. GNW performs an exhaustive network motif analysis for a set of network predictions, which often reveals systematic prediction errors, thereby indicating potential ways of network reconstruction improvements. The accuracy of network inference is also assessed using standard metrics such as precisionrecall (PR) and receiver operating characteristic (ROC) curves. Furthermore, we show how GNW can be used to generate in silico benchmark suites to assess the performance and identify strengths and weaknesses of six network inference methods. We also show how the performance of those inference methods are affected by the structural properties and the size of the gene regulatory networks to infer, and how GNW can help to identify the most informative type of gene expression data to provide to a given inference method. Finally, we assess the performance of those six inference methods on the network inference challenge that we provided to the international DREAM4 competition (Dialogue for Reverse Engineering Assessments and Methods).
METHODS
TopologyInstead of using random graph models, which are known to only partly capture the structural properties of biological networks (Van den), we generate network structures by extracting modules from known biological interaction networks such as those of E.coli () and S.cerevisiae () (the source networks). Our approach is based on the extraction of modules, that is, groups of genes that are more highly connected than expected in a random network (). We have shown that the topological modules extracted using our method correlate with functional modules of the source networks (). Hence, obtained network structures are meaningful targets for reverse engineering algorithms because in practice, one typically tries to infer the structure of a set of functionally related genes.
Dynamical modelNetwork topologies are endowed with detailed dynamical models of gene regulation. Both transcription and translation are modeled using a standard thermodynamic approach () allowing for both independent ('additive') and synergistic ('multiplicative') regulatory interactions. For each gene i of a network, the rate of change of mRNA concentration F RNA i and the rate of change of protein concentration F Prot i are described byWhere m i is the maximum transcription rate, r i the translation rate,are the mRNA and protein degradation rates and x and y are vectors containing all mRNA and protein concentration levels, respectively. f i () is the activation function of gene i, which computes the relative activation of the gene, which is between 0 (the gene is shut off) and 1 (the gene is maximally activated), given the protein or TF concentrations y. A more detailed description of the activation function used is given by. Note that our approach conserves the nature of the gene interactions (enhancing or inhibitory) of the imported or extracted network structures. The integration of the system of equations defined by(1)and(2) results in noiseless mRNA and protein concentration levels, respectively x i (t) and y i (t) for gene i. In living cells, molecular noise originates from thermal fluctuations and noisy processes such as transcription and translation (). Hence, random fluctuations affect concentration levels of mRNA and protein, whose expression can be viewed as a stochastic process ()where  v and  d are independent Gaussian white-noise processes (). c is a multiplicative constant to control the amplitude of the molecular noise. For each gene i, we use the Stratonovich scheme and the Milstein method to integrate two equations of the form of (4), one describing the rate of change of mRNA concentration and one for the rate of change of protein concentration (). This model is derived from stochastic kinetics and the underlying assumptions are discussed by Gillespie (2000). Note that, according to this model, a gene that is not activated (V (X t ) close to zero) has a very low level of noise (leakage) and it cannot suddenly have a very high transcription rate due to noise. In contrast, a gene that is activated has a higher level of noise (which may be interpreted as transcriptional bursts, for instance). The measurement noise depends on the technology used to monitor gene expression concentrations () and is modeled here independently of the molecular noise. GNW implements Gaussian and lognormal models of experimental noise as well as a model of noise observed in microarrays ().
Synthetic expression datasetsThe next step in generating in silico benchmark networks consists in simulating the generated in silico regulatory networks to produce synthetic gene expression datasets. Available experiments in GNW are as follows:@BULLET Wild type: the steady-state levels of the wild type (the unperturbed network). @BULLET Knockout (null-mutant): steady-state levels of single-gene knockouts (deletions). An independent knockout is provided for every gene of the network. A knockout experiment is simulated by setting the transcription rate of this gene to zero. @BULLET Knockdowns (heterozygous): steady-state levels of single-gene knockdowns. A knockdown of every gene of the network is simulated. Knockdowns are obtained by reducing the transcription rate of the corresponding gene by half.@BULLET Dual knockouts: dual knockouts consist of simulating a network with two genes knocked out simultaneously.@BULLET Multifactorial: steady-state levels of variations of the network, which are obtained by applying multifactorial perturbations to the network. One may think of each experiment as a gene expression profile from a different patient, for example. We simulate multifactorial perturbations by slightly increasing or decreasing the basal activation of all genes of the network simultaneously by different random amounts.Custom perturbations can also be specified. Experiments can be simulated as steady states and/or time-series with user-defined duration and number of measurement points.
Evaluation of network inference methodsWe not only provide researchers with a method for generating in silico gene network models to be used as benchmarks for reverse engineering algorithms, but also tools to facilitate the evaluation of network predictions. From a set of predictions from one or several inference methods, GNW automatically generates a comprehensive report including the result of a network motif analysis, where the performance of inference methods is profiled on local connectivity patterns. The network motif analysis often reveals systematic Page: 2266 22632270prediction errors, thereby indicating potential ways of network reconstruction improvements (). Furthermore, PR and ROC curves are evaluated for each network prediction (). The relation between ROC and PR curves is discussed by Davis and Goadrich (2006).
T.Schaffter et al.
RESULTSWe assessed the performance of six inference methods to illustrate benchmarking and performance profiling of network inference methods using GNW (). We first describe how to generate suitable network benchmark suites for the testing of various hypotheses. Specifically, we designed benchmark suites to show how the performance of inference methods is affected by different sizes and structural properties of regulatory networks. In addition, we show how GNW can help to identify the most informative type of gene expression data that a given inference method could use to achieve the best possible reconstruction from in vivo experiments. Finally, we introduce the DREAM4 Network Inference Challenge we generated, which has been used to assess the performance of many inference methods ().
Generation of network benchmark suitesWe generated several network benchmark suites using the approach described in Section 2. Each benchmark suite is composed of several in silico regulatory networks (the so-called gold standards or target networks).shows one gold standard extracted from a regulatory network of the yeast S.cerevisiae (). The extracted structures have been endowed with stochastic dynamical models of gene regulation accounting for molecular noise in transcription and translation processes. The dynamical models of gene regulation have then been simulated to reproduce wild-type, knockout, knockdown and multifactorial perturbation experiments.illustrates the evolution of mRNA concentration levels without noise, when only molecular noise is introduced, and with both molecular and experimental noise. We generated the following benchmark suites:At least half of the genes included in each gold standard are regulators, i.e. genes which regulate the mRNA production of at least one other gene. This is to avoid structures where there are many genes that do not regulate any other genes (out-degree = 0). We used the default parameter values proposed by GNW to simulate the gene expression experiments (Supplementary Material).
Effect of network structural properties on inference method performanceThe performance of network inference methods may strongly vary depending on the structural properties of the target networks.shows systematic errors made by each inference method on four three-node motifs overrepresented in the in vivo regulatory network structures of E.coli and yeast (), and therefore in the gold standard structures we generated. Z-score, Pinna et al., and Yip et al. have different error profiles than CLR, ARACNE2 (both based on mutual information) and GENIE3, which make systematically false positive errors between Gene 2 and 3 in predicting fan-out motifs. Note that ARACNE2 seems to make less errors on that particular motif because the gene interactions present in the gold standards are in general less reliably identified than with CLR or GENIE3, independently of any network motifs considered. On the other hand, Z-score,We show that inference methods have changing performance when used to make predictions about the structure of regulatory networks having specific structural properties. Thus, we evaluated the selected inference methods () against the benchmark suite A described in Section 3.1.shows the AUROC and AUPR values obtained by those methods when applied to infer E.coli and yeast network structures from knockout expression data. The AUROC and AUPR values obtained by Z-score, Pinna et al. and Yip et al. on yeast gold standards are significantly lower than on E.coli benchmark networks (MannWhitney U-test, P < 0.01). Theperformance degradation observed on yeast is due to the fact that these methods make systematic errors in predicting cascade motifs, and because structures extracted from yeast contain more cascade motifs than in E.coli structures (data not shown). We observe a linear correlation between the number of cascade motifs to predict in a regulatory network and the AUROC and AUPR values obtained for Z-score,(Pearson's correlation, 0.703  r 0.552, P < 0.05). ARACNE2, CLR and GENIE3 are less affected by the cascade motif (). Interestingly,also shows that Z-score andexhibit very similar error profiles. Z-score is one of the simplest inference methods (), yet it has relatively high accuracy in predicting network structures from knockout steady states. Pinna et al. first performs a Z-score analysis followed by a refinement stage, which aims to suppress the errors made by Z-score on cascade motifs ().does not show any noticeable difference between Z-score andThis is confirmed by the fact that AUROC and AUPR values for Z-score and Pinna et al. are not significantly different (MannWhitney U-test,
Benchmarking with GeneNetWeaver
Effect of network size on inference method performanceWe are interested in showing how the performances of inference methods scale with the size of the regulatory networks to reconstruct. Using GNW, it is very simple to generate in silico benchmark network of size N < M, where M is the size of the source network used (e.g. E.coli or yeast). Here, we used the benchmark suite B described in Section 3.1, where each benchmark network has been simulated using the above methodology to produce knockout gene expression data.shows the performance of the inference methods listed inHowever, we identified three methods with relatively high AUPR values.
They are Z-score, and the methods developed by Pinna et al. and Yip et al. AUROC and AUPR values obtained by Z-score and Pinna et al. are significantly higher than those of Yip et al., andthis is valid for every gold standard size (MannWhitney U-test, P < 0.05). Also, Z-score, Pinna et al. and Yip et al. have high AUPR variances because they are strongly affected by cascade motifs (), which are more frequent in gold standards extracted from yeast than E.coli (each condition in benchmark suite B is composed of 20 gold standards, half being extracted from E.coli and half from yeast).shows that the AUPR values of inference methods decreases as the sizes of the gold standards increase. The reason is that the connectivity density of the regulatory networks is higher for smaller networks. The higher the connectivity density, the easier it is for each of the six inference methods to have a high AUPR value (Pearson's correlation, 0.383  r  0.839, P < 0.01).
Design of in vivo gene expression experimentsA given inference method may require a very specific type of expression data in order to enable accurate network reconstruction. We show that in silico benchmark networks have also the ability to support the design of suitable in vivo gene expression experiments, which are typically time consuming and expensive (). The benchmark suite C described in Section 3.1 is formed of 20 in silico networks consisting of 100 genes each, which we simulated using GNW to produce steady-state data for systematic knockout and knockdown, as well as 100 multifactorial perturbation experiments.shows the AUROC and AUPR values obtained by the inference methods reviewed here (). The most accurate network reconstructions are obtained using GENIE3, Z-score and the methods developed byon knockout data. Knockout experiments are very informative, because they provide network responses to individual and large perturbations (genes are 'deleted'). Knockdown expression data, where the maximum transcription rate of genes is halved, are less informative than knockout data and thus lead to less accurate network reconstructions.shows that ARACNE2 obtained AUROC and AUPR values comparable to CLR and GENIE3 when using multifactorial perturbation data. In addition, we considered providing knockout, knockdown and multifactorial perturbation data together to ARACNE2, CLR and GENIE3. We observed that AUROC and AUPR values obtained were slightly higher than when providing the three expression datasets individually (data not shown). We also added successively 100, 200, 300 and 400 additional multifactorial perturbations; however, the AUROC and AUPR values did not improve significantly for all methods (Mann Whitney U-test, P < 0.05). Furthermore, it has been shown using GNW and time-series data that the inference accuracy of inference methods reaches a saturation point after a specific data size (). This reveals that simply adding more expression data does not necessarily imply performance improvement.
DREAM Network inference challengesWe have used GNW to generate the target networks for three international competitions on gene network reverse engineering: DREAM3 (2008), DREAM4 (2009) and DREAM5 (2010). Participants of the DREAM4 In Silico challenge were asked to provide network predictions for two subchallenges made of networks of size 10 and 100, respectively. Each subchallenge was composed of five in silico gene networks (two extracted from E.coli and three from yeast), which have been simulated to produce steady-state wild-type, knockout, knockdown and multifactorial perturbation experiments. In addition, time-series data have been made available. For each subchallenge, network predictions made by participating teams have been evaluated by computing P-values, which indicate the probability that random lists of genetic interaction predictions would be of the same or better quality (). The overall score that has been used for ranking of the methods applied in the DREAM4 In Silico Challenge was a negative log-transformed P-value given by overall score (OS) =0.5log 10 (p 1 p 2 )where p 1 and p 2 are, respectively, the geometric means of AUPR P-values and AUROC P-values taken over the five networks. Thus, larger scores indicate smaller P-values, hence better predictions.compares the overall scores of the inference methods reviewed here () to those obtained by the participating methods applied in the DREAM4 In Silico Size 100 Challenge. The most accurate reconstruction of the five gene networks of size 100 genes was achieved by. They participated to the DREAM4 In Silico Size 100 Challenge, in which their method was best performer (OS = 71.589). Hence, both first bars incorrespond to the score ofWe have shown inthat AUROC and AUPR values obtained byare not significantly higher than those obtained using the original Z-score method. This can be explained by the fact that transitive causal effects are almost always weaker than the direct effects. We expect that if many amplifying cascades occur, the refinement stage introduced byoriginal algorithm is composed of several batches using both steadystate and time-series data, Yip et al. only used the first batch to build a noise model from knockout steady-state data (). The achievement of the 7th rank in DREAM4 can be partially explained by the fact that Yip et al. made a strong and correct assumption on the Gaussian measurement noise we used in DREAM3, which is no longer valid in DREAM4. Indeed, we modeled molecular noise in addition to a model of experimental noise observed in microarrays ().
Benchmarking with GeneNetWeaver
DISCUSSIONWe propose a comprehensive and powerful framework for in silico benchmark generation and performance profiling of network inference methods. We implemented this framework as an opensource tool called GeneNetWeaver (GNW). Biologically plausible network structures are generated by extracting modules from known biological interaction networks such as those of E.coli and the yeast S.cerevisiae. Network structures are then endowed with detailed dynamical models of gene regulation describing both transcription and translation processes. Transcriptional regulation is modeled using a thermodynamic approach accounting for both independent ('additive') and synergistic ('multiplicative') interactions. In addition, our models account for stochastic molecular noise as well as experimental noise observed in microarrays. The generated in silico benchmark networks can be simulated in GNW to reproduce wild-type, knockout (null-mutant), knockdown (heterozygous) and multifactorial perturbation gene expression experiments. As an example of the application, we have used GNW to generate the target networks for three international competitions on gene network reverse engineering: DREAM3 (2008), DREAM4 (2009) and DREAM5 (2010). In total, 91 teams have submitted over 900 network predictions on GNW-generated networks, making GNW one of the most widely used benchmark generators by the community. In contrast to the previously proposed benchmark generators, GNW also integrates tools for systematic evaluation of the predictions from inference methods on benchmark networks. A unique feature of GNW is the ability to perform a network motif analysis from a set of network predictions and their corresponding benchmark networks. The network motif analysis reveals systematic prediction errors made by inference method on specific network motifs, thereby indicating potential ways of network reconstruction improvements. The accuracy of network inference is assessed using standard metrics such as PR and ROC curves. We have used GNW to generate in silico benchmark suites to assess the performance and identify the strengths and weaknesses of six network inference methods. We show that Z-score, and the inference methods developed by Pinna et al. and Yip et al. make more accurate network predictions than the two widely used methods, ARACNE2 and CLR. This good performance is achieved apparently because those methods target the inference of causal relationships between genes. However, ARACNE2 and CLR do not require systematic knockout gene expression data, which are not always available in practice, to infer undirected networks. Yet ARACNE2, CLR and GENIE3 methods can be applied to infer regulatory networks even if no systematic knockout or knockdown experiments are provided. Furthermore, our results show that at some point simply giving more expression data to inference methods does not necessarily imply performance improvement. Therefore, the integration of additional information about the target regulatory networks should be considered, for instance using prior knowledge about the network structures. The novelty of GNW is that it additionally provides a unique network motif analysis, which we used to show that the structural properties of the target regulatory networks affect the performance of inference methods. We observed that the performances of Z-score, and the methods developed byare impeded by the presence of cascade motifs in the target networks. Thus, we show that those methods make significantly less accurate network predictions on the yeast S.cerevisiae, whose structure includes more cascade motifs than E.coli transcriptional network structure. Finally, we also provide evidence that in silico benchmark networks can be used to identify the most informative type of gene expression data that a given inference method could use to achieve the best possible reconstruction from in vivo experiments.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
