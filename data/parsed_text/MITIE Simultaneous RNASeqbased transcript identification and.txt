Motivation: High-throughput sequencing of mRNA (RNA-Seq) has led to tremendous improvements in the detection of expressed genes and reconstruction of RNA transcripts. However, the extensive dynamic range of gene expression, technical limitations and biases, as well as the observed complexity of the transcriptional landscape, pose profound computational challenges for transcriptome reconstruction. Results: We present the novel framework MITIE (Mixed Integer Transcript IdEntification) for simultaneous transcript reconstruction and quantification. We define a likelihood function based on the negative binomial distribution, use a regularization approach to select a few transcripts collectively explaining the observed read data and show how to find the optimal solution using Mixed Integer Programming. MITIE can (i) take advantage of known transcripts, (ii) reconstruct and quantify transcripts simultaneously in multiple samples, and (iii) resolve the location of multi-mapping reads. It is designed for genome-and assembly-based transcriptome reconstruction. We present an extensive study based on realistic simulated RNA-Seq data. When compared with state-of-the-art approaches, MITIE proves to be significantly more sensitive and overall more accurate. Moreover, MITIE yields substantial performance gains when used with multiple samples. We applied our system to 38 Drosophila melanoga-ster modENCODE RNA-Seq libraries and estimated the sensitivity of reconstructing omitted transcript annotations and the specificity with respect to annotated transcripts. Our results corroborate that a well-motivated objective paired with appropriate optimization techniques lead to significant improvements over the state-of-the-art in transcrip-tome reconstruction. Availability: MITIE is implemented in Cþþ and is available from
INTRODUCTIONMost of the complexity of higher eukaryotic transcriptomes can be attributed to the encoding of multiple transcripts at a single genic locus by means of alternative splicing, transcription start and termination (e.g.). A comprehensive catalog of all transcripts encoded by a genomic locus is essential for downstream analyses that aim at a more detailed understanding of gene expression and RNA processing regulation. RNA-Seq is a method for parallel sequencing of a large number of RNA molecules based on high-throughput sequencing technologies (ENCODE Project). Currently available sequencing platforms typically provide several 10100 millions of sequence fragments (reads) with a typical length of 50150 bases. By mapping these reads back to the genome, one can determine where gene products are encoded in the genome (e.g.) and collect evidence of RNA processing such as splicing () or RNA-editing (). In many cases, the RNA-Seq reads are first aligned to a reference genome using an alignment tool that identifies possible read origins within the genome. Contiguous regions covered with read alignments (possibly with small gaps) are candidates for exonic segments. Alignment tools for RNA-Seq reads, such as PALMapper (), TopHat (), MapSplice (), Star () or Gsnap () are typically able to identify new exonexon junctions, which are candidates for introns. This information can be compiled into a segment or splicing graph, a directed acyclic graph, where the nodes correspond to exonic segments and the edges correspond to intron candidates (cf.for an illustration). Assuming complete coverage, an expressed transcript corresponds to a path in the graph. Similar graphs are produced during de novo transcript assembly with the difference that the graph can potentially be cyclic, and the segments are not explicitly associated with a genomic location. In genome-and assembly-based transcript reconstruction, tools such as Scripture (), Cufflinks (), Trans-ABySS (), Trinity () and OASES () select a subset of paths through the graph as transcript predictions. For simplicity, we will focus on genome-based transcript reconstruction when describing the approach and discuss de novo assembly whenever necessary. The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. Owing to the nature of the RNA-Seq reads, the information obtained from the alignments is of local nature only, even when considering paired-end sequencing (e.g.). The splicing graph representation implicitly assumes independence of local events. Hence, it will typically contain more paths than expressed transcripts. This is also true in the ideal case when the graph is (i) complete in the sense that it contains all vertexes and edges and (ii) accurate in the sense that it only contains expressed exonic segments as vertexes and edges that correspond to introns of expressed transcripts. For instance, the 183 807 splice variants annotated in any of the four human genome annotations (Ensembl, HAVANNA, ENCODE, Vega, see) define splicing graphs that encode 707 386 paths, with 55% of the loci contribute460% of the paths. Thus, we encounter a few particularly complex cases that contribute most to transcriptome complexity. Defining splicing graphs based on RNA-Seq data entails the additional difficulty that inaccurate or ambiguous read alignments can substantially increase the size of these graphs. Although this problem can be addressed by filtering the read alignments, we find that strict filtering often leads to a reduced sensitivity of transcript prediction and introduces artifacts, for instance, in the presence of unknown genomic variations. Based on a detailed analysis of the problem and of previous work, we identified three important requirements that a transcript inference algorithm based on RNA-Seq data should meet. First, following the arguments in, we note that it is important to simultaneously identify and quantify transcripts to resolve long range dependencies. In Section 4.1, we illustrate how quantitative information can perfectly deconvolve contributions from multiple transcripts, whereas ignoring quantitative information leads to inaccurate predictions. Second, enumeration of all paths defined by a splicing graph is often not tractable. For instance, for % 13% and % 3% of human genes, the number of paths in splicing graphs generated from the annotation and RNA-Seq reads (see Section Supplementary Section C) is greater than 1000 and 1 000 000, respectively (see Supplementary). This large number is the result of a combinatorial explosion of possible combinations of alternative segments and edges (This is even larger in case of de novo assembly where several loci are merged into cluster of connected segments if sequence is repeated). Therefore, a generally applicable approach should avoid explicit enumeration, ideally still guaranteeing optimality. Third, we show that multiple RNASeq samples help to solve the ill-posed problem of transcript identification (see e.g.). By sharing information between samples, while still considering them separately, we can often exactly determine the correct set of expressed transcripts. We provide illustrative examples where neither merging data of multiple samples nor the independent analysis of data from each sample can solve the problem. We describe an approach called MITIE (Mixed Integer Transcript IdEntification) that meets the aforementioned requirements. The main idea of MITIE is to report a small optimal set of transcripts that can well explain the observed RNA-Seq data in multiple samples. It does not require an explicit enumeration of all paths to find the optimal set of transcripts. This is achieved by using branch-and-bound algorithms that prune parts of the combinatorial search tree that cannot yield the optimal solution. MITIE consists of two main parts: A data processing part generates a splicing graph from RNA-Seq alignments in Binary Sequence Alignment/Map-(BAM)-format, the annotation in Gene transfer format-(GTF)-format or both (Section 3.1). The second part solves the core optimization problem and starts with the graph decorated with quantitative information (Section 3.2). The design enables the flexible use of MITIE in existing RNASeq pipelines. For example, we can use the output of Trinity's inchworm tool () as input to the second part of MITIE and thereby solve the transcript reconstruction task, also solved by Trinity's butterfly tool. In the following section, we relate MITIE with previous work and illustrate the idea of combining multiple samples in a simulation study in Section 4.1. We then apply MITIE to a larger set of simulated RNA-Seq reads generated from the human genome annotation in Section 4.2. Finally, in Section 4.3 we analyze the performance of MITIE on a large set of RNA-Seq data for Drosophila melanogaster generated within the modENCODE project ().
RELATED WORKIn this section, we discuss related work grouped by the primary goals and assumptions underlying the approaches. Approaches for genome-wide transcriptome reconstruction and quantification preceding the RNA-Seq era were mainly based on expressed sequence tags (ESTs) or microarrays.first defined and identified splicing graphs based on EST alignments, but did not devise a method to obtain transcripts from the graphs.constructed EST-based splicing graphs and called transcripts using a dynamic programming approach, preferring paths with high EST support.scription start sites (TSS) and termination sites (TTS; both depicted with solid vertical lines). Potential SS positions can originate from spliced reads (e.g. between segments 4 and 5) or annotated transcripts. Analogously, TSS and TTS sites can stem from annotated transcripts or from potential transcript end positions (e.g. between 2 and 3 as well as 13 and 14). See Supplementary Section B for more details. 2. Exon identification: We keep (i) segments that have 45% of their nucleotides covered, (ii) are part of annotated transcripts or (iii) if the removal of segment s does not leave any path between two segments connected by paired-end reads (if available). 3. Intron identification: We connect segments based on spliced reads and annotated introns events using microarray probes for exon junctions and flanking regions. Candidates were processed from annotated alternative splicing events (or EST-alignments (Shair et al.), respectively. Alternative splicing events were then embedded into the reference transcript, and the resulting transcripts were finally quantified using probabilistic models for the microarray measurements. These methods constitute the algorithmic foundation of RNA-Seq based approaches, but are not directly applicable to RNA-Seq data owing to the extensive differences in abundance, error sources and biases of the underlying expression measurements. The following RNA-Seq based methods build on quantification approaches but identify additional transcripts by enumerating all potential transcripts from a splicing graph. iReckon () and NSMAP () are capable of finding new transcripts but limit the search to transcripts having the same transcription start and termination site as known transcripts. Although this significantly reduces the search space and therefore allows simpler optimization techniques, it is a biologically implausible restriction. Scripture () enumerates all potential transcripts from a splicing graph and reports them in the result file. Although this approach guarantees maximal sensitivity in the case of unfiltered data, it is in general not feasible, and alignments have to be filtered stringently. The approach does not aim to achieve specific results. IsoLasso () and rQuant () use the l 1-norm to regularize transcript abundance. This approach significantly reduces the number of reported transcripts, but the choice of the regularizer is suboptimal, given that all abundance values are positive and the sum is fixed. Thus, the regularizer does not sufficiently penalize a solution explaining the coverage with two similar transcripts compared with a solution with only one transcript (compare). CLIIQ () addresses this problem by applying an integer linear programing approach to limit the number of isoforms expressed in any sample combined with an l 1 loss on the difference of observed and expected coverage. Athough this is conceptually similar to the MITIE optimization problem with respect to the integration of multiple samples, the formulation has significant disadvantages. The number of integer variables in the CLIIQ integer linear programing depends on the number of potential isoforms, which increases exponential with the number of exons. Thus, given S exonic segments, the theoretical runtime of the algorithm is O2 2 S , and therefore stringent filters on the read data and on the enumerated transcripts have to be applied to prevent a combinatorial explosion. The following approaches avoid the explicit enumeration of transcripts using different techniques. Cufflinks reports the minimal number of transcripts such that each read alignment is explained by at least one transcript. Although this parsimony assumption reduces the computations significantly, it is violated by many known genes, and it does not deal well with inaccurate read alignments. We will discuss the benefits and drawbacks of Cufflinks in more detail in Sections 4.1 and 4.2. Montebello () uses a probabilistic model to score sets of transcripts and implements a probabilistic search strategy to generate and modify transcript sets until a certain criterion is reached. Although this strategy allows for a wide range of functions to quantify the quality of a solution, it does not provide any guarantee of optimality. MITIE instead guides the search using the branch and bound strategy and can therefore avoid regions in the search space that cannot yield the optimal solution. De novo transcript assemblers have been proven useful in cases where the reference genome is missing or of poor quality. They have the additional advantage of treating alternative transcripts and paralogous genes (resulting in multiple mappings for reads in genome alignment) naturally the same way. The optimization problem formalized by MITIE generalizes to solve transcript prediction also in the de novo setting, and we show in Sectionand described in more detail in. The main emphasis of the graph generation is completeness, whereas false information can be tolerated to some extent (see end of Section 4.3 for discussion).
The core optimization formulationPreliminaries We define segments as sets of neighboring genomic positions corresponding to minimal entities of paths in the splicing graph G  S, I with nodes (segments) S and edges (introns) I. A segment s can be allowed to be used as the initial or terminal segment in a transcript. This information is assumed to be given as s  1 s is initial 0 otherwise and s  1 s is terminal 0 otherwise . The transcript matrix U is defined as a k  S binary matrix, where S  jSj and k is a parameter determining the maximal number of transcripts returned by the algorithm. Paths through the splicing graph G can be represented as a binary vector of length S. Let P be the set of all valid paths, R the number of RNA-Seq samples and W r 2 0, 1 k the (normalized) abundance estimates for the k transcripts and sample r. Moreover,R jI j are the expected segment read counts and intron confirmation values (from spliced reads) for sample r under our model, respectively. Analogously, C obs r and I obs r correspond to observed segment and intron counts for sample r. The optimization problem Using these definitions, the core of MITIE is an optimization problem that can be formalized as:P 8t 2 f1, ::, kg, W 2 0, 1 kR U 2 f0, 1g kS : 1For technical reasons, we use the normalized transcript abundance W r 2 0, 1 k. However, without loss of generality, we can define the maximal observed count as c g, r  maxC obs r , I obs r , and then the expected counts can be computed from W r and U as C exp r  c g U T W r. Similarly, we can compute the expected number of reads I exp s1, s2, r from sample r that span from segment s 1 to segment s 2 for all s 1 , s 2  2 I as, where i t s1, s2 is a binary variable indicating whether intron s 1 , s 2  is part of transcript t. L is a loss function (see Section 3.4) and jjWjj 0 is defined as the number of non-zero rows in W; hence, we only count transcripts that are quantified above zero in any of the samples. 1 and 2 are hyper-parameters determining the trade-off between the different terms [The hyper-parameters have to be tuned by model selection to obtain the best performance. We provide useful default settings using bayesian hyper-parameter optimization strategies (; cf. Supplementary Section J)]. A version of this optimization problem is illustrated in.
Validity of paths and known annotationsWe add several constraints on U to make the resulting transcripts paths in the splicing graph. In particular, the constraints ensure that all feasible transcripts start at initial segments (s  1), terminate at a terminal segment (s  1) and uses only valid edges of the graph. The number of constraints is OS1  Q  jI j, where Q is the average of the number of segments over-spanned by the longest intron edge starting at a specific segment s but is not connected to s (see Supplementary Section L for more details). In cases where all transcripts are known a priori, we can keep the transcript matrix U fixed and only optimize over the abundance vector W. This is still a mixed integer optimization, as the sparsity term jjWjj 0 needs integer variables. If some transcripts are known and others are not, we can fix parts of the U matrix correspondingly. We then penalize the selection of new transcripts higher than the selection of known transcripts, thereby only predicting additional transcripts if the observed read coverage cannot be well explained by known transcripts.
The loss functionA commonly used loss function is the sum of squared deviations between expected and observed values (' 2-loss, see for instance,), i.e. P S s1 C exp s  C obs s  2. The choice of the loss function, however, reflects assumptions on the variance of the measurements (e.g.). The underlying assumption of penalizing the quadratic deviation is that the measurement is Gaussian distributed with mean equal to the true abundance of the mRNA and variance constant for all expression levels. It was previously observed (e.g.) that a negative binomial distribution with a standard deviation dependent on the mean of the observation is a better model for the distribution of read count data. We therefore make use of this distribution to define the log-likelihoodbased loss function. In addition, we model background noise stemming. Illustration of the core optimization problem of MITIE. The transcript matrix U (bottom left) and abundance matrix W (bottom center) will be optimized such that the implied expected read coverage of the k valid transcripts (bottom right) matches the observed coverage (top right) well. Validity of the transcripts is ensured by appropriate constraints derived from the segment graph (top left). We illustrate the case of two samples. For each sample, we have abundance estimates W for each of the k  4 transcripts. The identity of the transcripts, i.e., the rows of U, is shared among the samples. By Occam's razor principle, we implement a trade-off between loss between the observed and expected coverages and the number of used transcripts, i.e. number of rows in W with non-zero abundances from false alignments or incomplete RNA processing using a Poisson distribution with fixed mean l. We define the likelihood of observing a count V in dependence of the unknown expected count V  as followswhere p P j is the probability under the Poisson distribution with mean l, and p N jV  , 1  1 V   2  V  2  is the likelihood under the negative binomial distribution with mean V  and variance 1  1 V   2 V  2. The choice for parameters 1 , 2 ! 0 depends on the extent of biases present in the RNA-Seq library. These parameters can be estimated for a given RNA-Seq library based on single transcript genes (see Supplementary Section D for more details). We assume deviations being independent between the segments and can thus define the negative log-likelihood ^ LC exp , C obs  for all segments in sample r as follows:r, s jC exp r, s :
Exploiting paired-end readsThere are a number of ways to exploit paired-end reads. We chose a simple and efficient approach and incorporate paired end data into MITIE as follows: For each pair of segments s 1 , s 2 , N s1, s2, r stores the number of read pairs, where one read overlaps segments s 1 and the other read overlaps segment s 2 in sample r. We then add the penalty term 3  P R r1 P r to the objective function whereThis prefers solutions in which combinations of segments supported by paired-end reads are part of a predicted transcript. A straightforward extension of this strategy also allows for integration of partial transcript information. This provides an efficient way to directly integrate information from ESTs or third-generation sequencing platforms (see e.g.).
Solving the optimization problemsOptimal solutions by mixed-integer programming For certain classes of mixed integer optimization problems, fast solver implementations are available that guarantee to find the optimal solution. An important requirement is that the relaxed version of the problem (allowing real values for integer variables) can be solved efficiently. This allows the use of branch and bound techniques. The combinatorial tree defined by the different choices of integer variables is traversed, and on each node, the relaxed optimization problem has to be solved. As the relaxed solution is always a lower bound (in the minimization case) of the integer solution, the result of the relaxed optimization can be used to prune branches from the combinatorial tree, which cannot contain the optimal solution. In the current study, we used CPLEX (http://bioweb.me/cplex) to solve the mixed integer optimization problems. Piece-wise quadratic loss function For efficient optimization, we approximate the log-likelihood term  logp M C obs s jC exp s  using a piecewise quadratic proxy function lC obs s , C exp s  with the property that it is convex and has the same global minimum as  logp M C obs s jC exp s  (which is reached at C obs s  C exp s ). See Supplementary Section K for details on estimating l, . We then use this proxy function to define our loss function:We will further refer to this loss function as the approximate negative binomial loss or g NB-loss. Iterative approximations The run-time of the branch and bound algorithm depends on how widespread the near optimal solutions are in the combinatorial tree and how branched, i.e. complex, the tree is. The former can be addressed to a certain extend by eliminating equivalent solutions if possible (cf. Supplementary Section L). The complexity of the search tree can be reduced using constraints to exclude transcripts that are not paths in the splicing graph. However, it might become necessary to search distant parts of the tree to find the optimal solution, in particular when the number of samples is insufficient to exactly determine the solution (cf. Section 4.1). We found that we can obtain good approximations to (1), if we iteratively solve it in the following way: We first solve it for one new transcript (and available annotated ones). This speeds up computation significantly, as the number of free integer variables in U is S instead of k  S. Moreover, the complexity of the combinatorial search space is significantly reduced. Once we found the first transcript, we fix the U variables for this transcript, keep W free and find a new transcript with a row of free U variables. This strategy significantly speeds up the optimization, and we did not notice a significant reduction in prediction accuracy.
Confidence quantification for transcript callsGiven a set of k transcripts, we are interested in the importance of each transcript for explaining the total RNA-Seq data. We make use of a likelihood-ratio test () to quantify the confidence in each predicted transcript t. We compute the test statistic:Where ~ pDjM is the approximate likelihood of observing the read data D under our model M based on all k transcripts and ~ pDjM t  is the approximate likelihood when restricting the quantification value of transcript t to zero. To compute this, we solve the quantification task k times using all transcripts from the transcript inference step and set the quantification value of transcript t to zero. We compute the objective function setting all regularization parameters to zero. We assume the test statistic to be 2-distributed with df  k  k  1  1 degrees of freedom and compute a P-value for each transcript. This strategy allows us for example to estimate the probability that a newly predicted transcript explains features of RNA-Seq data that cannot be explained by known annotated transcripts.
A test for differential transcript expressionSimilar to the strategy in the previous section, we can also perform a test for differential transcript expression in two samples. We compute the likelihood of a model that quantifies a set of k transcripts independently, and the likelihood of a model that quantifies the transcripts identically in the two samples. We can then compute the log-likelihood ratio as test-statistic and apply the 2-test with df  k degrees of freedom. It is straightforward to apply this test only to a subset of the transcripts. One can also extend this strategy to take replicates into account. There are a few other approaches for testing for differential transcript expression (), and it goes beyond the scope of this work to provide a thorough comparison with these methods.
Multi-mapper optimizationThe quantification of RNA-transcripts is strongly affected by reads that map to multiple locations on the genome (multi-mapped reads; cf. Section 4.2.2, for results). Predicting transcripts is even harder, and one can therefore assume that appropriate handling of multi-mapped reads can lead to significant improvements.
MITIE: Transcript identification and quantification in multiple samplesOur strategy is based on the multi-mapper-resolution (MMR) approach [Kahles and RatschRatsch personal communication: For each read with multiple possible mapping location MMR decides for the location, such that the variance in read coverage is minimized.] that decides on the read coverage distribution how to optimally choose one of several ambiguous alignments. We augmented MMR now referred to as MMO (Multi Mapper Optimization) to take the predicted transcripts and their abundance estimates into account. Given the latter, we can compute the expected read coverage throughout the genome. For each read with multiple mapping locations, we can then determine which mapping location would lead to the smallest loss over all genes in the genome. This approach has the conceptual advantage that minimizing the same loss in the core optimization step and in the multi-mapper optimization step is a consistent way of integrative RNA-Seq analysis. As MMO depends on transcript predictions and abundance estimates, it needs to be run multiple times in conjunction with solving the MITIE core optimization problem in an expectation-maximization-like manner. We describe more details of this approach in Supplementary Section F.
RESULTS
An illustrative simulation studyWe start by considering a specific case of transcript inference to illustrate the limits of transcript identification from a single sample and to show how multiple samples can help identifying commonly expressed transcripts. In, we consider a splicing graph encoding three exons skips leading to eight possible transcripts. The task is to determine which transcripts are expressed. We consider multiple samples and assume that the same small set of transcripts is expressed in all samples but with different abundances (including the possibility of zero abundance). This problem can be reduced to solving systems of linear equations (). If a system of equations is solvable, then the corresponding set of transcripts can fully explain the observed read coverage (see Supplementary Section G; for simplicity, we ignore statistical fluctuations and use exact, i.e. expected, quantities). In case of multiple samples, we identify the sets of transcripts that are consistent with all samples (intersection of the sets of sets of transcripts). If only one such set of transcripts remains, then we can be sure to have found the correct solution ('identifiable'). If several sets remain, the best strategy is to randomly select one set out of the possible ones ('optimal strategy'). It turns out inference for the considered example becomes increasingly more difficult, the more transcripts are expressed (). If only one transcript is expressed, all strategies always find the correct answer. If two of the eight transcripts are expressed, it is theoretically always possible to identify them correctly. Also, Cufflinks and MITIE often identify the correct set of transcripts (see, top). Repeating the same experiment for three expressed transcripts, the observations change completely. Only in 16 and 60% of the cases, there is exactly one solution or the optimal algorithm identifies the correct one (one sample), respectively. The success rate increases significantly with the number of samples (88 and 95%). The accuracy of MITIE is close to the optimum and better than the optimal conservative algorithm. Cufflinks finds the correct three transcripts in only 2% of the runs, which comes close to randomly guessing three of eight (1.78%) (see, middle). If four of eight transcripts are expressed, Cufflinks never finds the correct solution, whereas MITIE performs comparable with the optimal strategy (cf., bottom) (Cufflinks was run on merged samples, as the Cufflinks/Cuffmerge combination as described in Section 4.2 did perform worse).
Results for simulated human reads4.2.1 Read simulation A major obstacle for the evaluation of tools for transcriptome reconstruction is the lack of a goldthe advantage that we can evaluate different aspects of predictions, which we would not be able to observe in reality. They are therefore an important part in evaluating many RNA-Seq-based algorithms. To obtain realistic RNA-Seq read alignments, we (i) randomly draw the transcript abundances in multiple samples, (ii) used the FluxSimulator () to incorporate typical biases from library preparation and sequencing, (iii) introduced errors into the generated reads and (iv) mapped the generated reads against the whole genome (see Supplementary Section A for more details). For this study, we generated simulated reads for a set of 1000 human genes with 8592 transcripts in total. The first 500 genes were used to tune hyper-parameters for all compared methods. Reported results correspond to the performance on the second set of 500 genes.illustrates the effect of different loss functions on the Pearson correlation of predicted and ground truth transcript abundances. Similar to MITIE's loss function ( g NBloss), we implemented a quadratic proxy function for the negative log-likelihood under the model of Poisson-distributed reads ( ~ P-loss). The g NB-loss generally gives more accurate results than the ~ P-loss and the ' 2-loss. Both the ~ P-loss and g NB-loss are significantly more robust to erroneous data (for instance, spurious alignments when allowing more mismatches) than the ' 2-loss (For independence of hyper-parameters, we only use the exon coverage). The correlation of Cufflinks quantification values is significantly lower and less robust to noise (cf. Supplementary) (We computed the correlation based on the lower confidence interval reported by Cufflinks, which has higher correlation to the true abundance than the estimated abundance value itself). Bohnert (2011) performed a thorough comparison of different quantification strategies including Cufflinks Trapnell et al. (2010) and MISO () with and without bias correction and found that the effect of bias correction are often minor. We also investigated the effect of multi-mapper handling on the quantification performance (). For this experiment, we used the full set of MITIE features as described earlier in the text and the g NB-loss. We observe that using all features, the quantification is much more robust with respect to noise in the reads. Moreover, by using MMO (see Section 3.9), one can significantly improve the quantification. After resolving multi-mappers with MMO, the quantification improves even beyond less stringent filtering. Finally, we evaluated how indicative the confidence value based on the likelihood-ratio test (Section 3.7) is for a transcript to be expressed. We find that among the 4718 non-zero quantified transcripts with P50.1, we have 86% correct transcripts with non-zero simulated expression, whereas of 326 transcripts with P ! 0.1, we find 44% correct predictions. This result shows that the confidence values accurately indicate cases with possible alternative explanations. We argue that it is more favorable to use the confidence values for filtering transcripts than the frequently used filtering based on relative or absolute abundance estimates because ambiguities might originate from the topology of the splicing graph and may therefore be independent of the expression level. This is supported by a relatively low Pearson correlation between predicted relative transcript abundance and P-values of only 0.18, indicating that the likelihood-ratio test adds additional information about the topology of the graph that cannot be retrieved from the predicted abundance alone.
Quantification, loss functions and multi-mapper resolution
Accuracy of transcript prediction (MITIE andCufflinks) For most genes of many organisms, we know a subset of transcripts in advance. The known transcripts are likely the ones with the highest expression level as those are easiest to identify by traditional annotation strategies. To test the accuracy for this realistic scenario, we omit the information of all transcripts, except the one that has the highest simulated abundance. We ran both MITIE and Cufflinks, given only this one annotated transcript and the RNA-Seq reads from a larger set of transcripts to predict transcripts. We compare transcript-level sensitivity and specificity of the predictions relative to all known transcripts. We counted transcripts as being correct, if the intron structure matched the one of an annotated transcript. Single exon transcripts were counted as being correct if they overlapped with an annotated single exon transcript. Each prediction was matched to at most one annotated transcript, and each annotated transcript was associated to at most one predicted transcript (cf. Section Supplementary Section J.1). The results for one to five samples are shown in. For Cufflinks, we optimized the hyper-parameters (see Supplementary Section H) and used two different strategies to perform predictions. The first strategy merged all RNA-Seq alignments, and the second strategy merged individual Cufflinks predictions for each of the samples with Cuffmerge. We observe that the latter strategy outperforms the data mergeGround Truth Alignments ~ ~(A) MITIE quantification results for the three different loss functions g NB, ~ P and ' 2-loss. We consider stringent (0 mismatches) and liberal read alignments (up to 5 mismatches), leading to fewer or more multimapping reads, respectively. (B) MITIE quantification results with g NBloss, when considering ground truth alignments, all multiple alignments, or after multi-mapper handling with MMO (see Section 3.9)
2535MITIE: Transcript identification and quantification in multiple samples strategy, but both strategies cannot benefit from additional samples. This is mostly attributed to a drastically decreasing specificity, whereas the sensitivity improves with more samples (cf. Supplementary). MITIE with MMO outperforms the best Cufflinks prediction on average by 6.7 percentage points in F-score. MITIE/MMO on five samples is 2.4% more accurate than with one sample. We observe that the significant improvements MMO contributes in quantification accuracy to not translate to similarly high transcript recognition improvements. We attribute this to the robustness of the loss function.
Comparison to Trinity Onthe same set of simulated reads, we also compared the core optimization of MITIE to the transcript calling method Butterfly, which is part of the Trinity pipeline. We ran the entire Trinity pipeline and then generated MITIE predictions based on the graphs reported by the Trinity component Chrysalis. We evaluated the performance of both methods by aligning predicted mRNA sequences to the annotated mRNA sequences. A prediction was counted to be correct if (i) it was 1% longer than the annotated transcript and (ii) the region 20 nt upstream of the first exonexon junction to 20 nt downstream of the last exonexon junction aligned with at most five edit operations to the reference sequence (For efficiency reasons, we ran the entire experiment for each gene separately on a FASTA file only containing the simulated reads, as they were simulated from this genic locus without mismatches.). In its current implementation, Trinity is not capable of integrating multiple samples. Therefore, we compared the results using only a single sample. We performed a model selection to tune hyper-parameters of Trinity and observed that the parameter determining the merging/ splitting behavior of components (min_glue) strongly influences the performance of Trinity. If min_glue  1 predictions are more sensitive but approximately 15 percentage points less specific compared to the performance with min_glue  2 (default). For both sets of predictions, we selected Pareto-optimal predictions and ran MITIE on the corresponding graphs. The MITIE core optimization problem outperforms Butterfly significantly in terms of sensitivity while having similar or higher specificity (cf.). As Trinity applies stringent filtering in the Inchworm step, the obtained segment graph does not contain all true transcripts. From our results on genome-based assembly, we expect even higher performance gains with a more sensitive graph generation algorithm. Furthermore, we expect improvements from multiple samples, which can theoretically be used in the same way as in genome-based assembly.
Application to modENCODE RNA-Seq libraries
Setup To showthat the performance improvements we have seen on simulated data translate to large-scale experimental datasets, we applied MITIE to a dataset of seven developmental stages of D.melanogaster (550 M alignments from 38 RNA-Seq libraries for seven developmental stages). We filtered the modENCODE D.melanogaster genome annotation (available from the MITIE website) for genes with at least two annotated transcripts. We then randomly removed one transcript variant (a transcript differing in splice structure to all other transcripts), which had a non-zero Cufflinks quantification value. We discarded genes where no such transcript could be found. From the remaining genes, we randomly selected 1000 genes for tuning the hyper-parameters and 1000 genes for testing. This setup retrospectively simulates the identification of new transcripts in already well-annotated genomes (as in Section 4.2.3).
Results We evaluated the sensitivity of MITIE andCufflinks based on the omitted transcripts and the specificity with respect to all annotated transcripts.shows a comparison of the F-score as a function of the number of samples. MITIE outperforms the best (in terms of F-score) Cufflinks prediction in sensitivity and specificity. Similar to the simulated data, the merge of the Cufflinks predictions using Cuffmerge significantly outperforms the Cufflinks prediction on merged data (not shown). Although having a similar performance for large sample numbers, MITIE has a much higher F-score on up to fivesamples. This is mostly due to a higher sensitivity at a similar specificity. We estimate the runtime for Cufflinks and MITIE for genomewide predictions and obtain four and 19 CPU hours for one sample, respectively (see Supplementary Section E for details). Using multiple samples significantly increases the computing time as well as the accuracy. Future releases of the software will provide more efficient strategies and implementations. As we used the alignment files provided by Celniker et al.
A
B
D. melanogaster modENCODE Data(2009), we had no control over the quality or sensitivity of the alignments and multi-mapper resolution. Our results on simulated data let us expect an even higher performance for more sensitive alignments and appropriate multi-mapper handling.
CONCLUSIONThe transcript prediction problem is typically under-determined. One important consequence of this observation is that deeper sequencing only helps to reduce the variance of abundance estimation and to close gaps in the splicing graph, but it does not solve the transcript identification problem as such. The proposed method reduces the set of solutions by leveraging quantitative information and multiple RNA-Seq samples combined with mild biologically plausible assumptions. Furthermore, prior information can be taken into account in a direct way within a single optimization problem, which we think will turn out particularly advantageous for integrating long reads from third-generation sequencing platforms with RNA-Seq data. Our results highlight the importance of a well-motivated loss function to penalize the read count deviation. The application of the g NB-loss significantly improved our quantification and transcript recognition results, while it comes at nearly zero additional computational cost. The underlying assumption of previously published transcript calling strategies like Cufflinks and Trinity is correctness and completeness of the graphs. Achieving both at the same time is challenging and typically not possible. This results in either wrong transcript predictions that have to be filtered out heuristically or in fragmented transcript predictions. MITIE assumes completeness of the graph, but not correctness. Completeness can often be achieved by not filtering the input alignments or not pruning the assembly graph. The decision of filtering can be deferred to the optimization problem that may choose to discard information in a context-dependent way. This is conceptually more attractive than global and uninformed filtering as a preprocessing step. MITIE finds a solution that is compatible to the overall observed read data. As observed on simulated and real world RNA-Seq data, MITIE pushes the boundaries of what can be observed from RNA-Seq data toward more complex mixtures of transcripts by leveraging variability between samples. These improvements come with the downside of higher computational costs; however, the vast majority of cases can be optimally computed within seconds, and our implementation provides options for approximations in cases where exact computations are too expensive. Furthermore, our experiments clearly show that we can obtain the same performance as competing methods with only a fraction of the data, which in turn can save the time, money and storage capacity of deeper sequencing. MITIE allows us to pool information from different samples in an effective way. This conceptual improvement will further future RNA-Seq studies; rather than spending efforts into deep sequencing of a few samples, future studies will have the choice to investigate a larger variety of samples at a lower depth. The combination of these samples allows us to obtain more confident transcript predictions in each sample and more insights into the biological questions at the same time.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
J.Behr et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
that the MITIE strategy is superior to the dynamic programming-based strategy of Trinity. OASES follows a different heuristic, which has been shown by the authors to be more sensitive but less specific than the Trinity approach. Trans-ABySS extends the genome assembly method ABySS (Simpson et al., 2009) to cope with the high variation in local read densities observed in RNA-Seq data. Like Cufflinks and OASES, Trans-ABySS does not aim to explain the read data quantitatively during the transcript prediction. Given this context, the strategy of MITIE is comparable with quantification methods like rQuant, NSMap, iReckon and IsoLasso. The main distinctions are an improved loss function, a parsimony regularizer and the ability of MITIE to avoid an exhaustive enumeration of transcripts. The latter solves a computational problem but raises difficulties of explicitely modeling biases in the read count data with MITIE. As the improvements in quantification accuracy achieved by explicitely modeling biases have shown to be moderate [Using rQuant with an l 2-loss function, an explicit model of the transcript length bias increased the pearson correlation coefficient by 0.41.7 percentage points (Bohnert, 2011, Table 3.1)], we decided not to incorporate this into our model. To our knowledge, MITIE and Cufflinks are the only approaches to RNA-Seq-based transcript identification that can perform predictions with and without prior annotations. We will outline the details of MITIE in the following section. 3 METHODS MITIE can build a segment graph based on given alignments of RNASeq reads to a genome or start with segment graphs obtained by other means, in particular by de novo assembly. Building such graphs from RNA-Seq data has been reported several times before (e.g. Denoeud et al., 2008), and we only describe it briefly in Section 3.1 and Supplementary Section B. In the following Sections 3.23.4, we describe (i) the main aspects of core optimization problem, (ii) how to ensure the construction of valid transcripts and (iii) give a probabilistic derivation of our loss function. We then discuss how to take advantage of paired-end reads, cope with multi-mapping reads and approximate the solution of the optimization problem in Sections 3.5 and 3.6. 3.1 Constructing the splicing graph We start by defining the boundaries of a region either based on annotated genes or read coverage. If gene/transcript annotations are available, we define regions within each annotated genic locus (see Fig. 1). Otherwise, we define islands by identifying genomic regions that are connected by fragment alignments (cf. Supplementary Section B). Each region may contain exonic and intronic segments, and the splicing graph generation is performed independently from other regions. This process is illustrated 2531 MITIE: Transcript identification and quantification in multiple samples at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
