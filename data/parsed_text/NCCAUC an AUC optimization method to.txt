Motivation: In prognosis and survival studies, an important goal is to identify multi-biomarker panels with predictive power using molecular characteristics or clinical observations. Such analysis is often challenged by censored, small-sample-size, but high-dimensional genomic profiles or clinical data. Therefore, sophisticated models and algorithms are in pressing need. Results: In this study, we propose a novel Area Under Curve (AUC) optimization method for multi-biomarker panel identification named Nearest Centroid Classifier for AUC optimization (NCC-AUC). Our method is motived by the connection between AUC score for classification accuracy evaluation and Harrell's concordance index in survival analysis. This connection allows us to convert the survival time regression problem to a binary classification problem. Then an optimization model is formulated to directly maximize AUC and meanwhile minimize the number of selected features to construct a predictor in the nearest centroid classifier framework. NCC-AUC shows its great performance by validating both in genomic data of breast cancer and clinical data of stage IB Non-Small-Cell Lung Cancer (NSCLC). For the genomic data, NCC-AUC outperforms Support Vector Machine (SVM) and Support Vector Machine-based Recursive Feature Elimination (SVM-RFE) in classification accuracy. It tends to select a multi-biomarker panel with low average redundancy and enriched biological meanings. Also NCC-AUC is more significant in separation of low and high risk cohorts than widely used Cox model (Cox proportional-hazards regression model) and L 1-Cox model (L 1 penalized in Cox model). These performance gains of NCC-AUC are quite robust across 5 subtypes of breast cancer. Further in an independent clinical data, NCC-AUC outperforms SVM and SVM-RFE in predictive accuracy and is consistently better than Cox model and L 1-Cox model in grouping patients into high and low risk categories. Conclusion: In summary, NCC-AUC provides a rigorous optimization framework to systematically reveal multi-biomarker panel from genomic and clinical data. It can serve as a useful tool to identify prognostic biomarkers for survival analysis.
IntroductionSurvival analysis studies the time to occurrence of a certain event. Identifying significant biomarkers for prediction is longstanding as an important topic to provide better understanding. Here one key challenge is that the outcome variable of interest for survival analysis is sometimes censored, which means the survive time is only partially known. In addition, the candidate features are always in high-dimension with the rapid development of high-throughput measurement technologies. As a result, discovering feature combinations is suffering from 'curse of dimensionality'. How to overcome the above difficulties and identify the most accurate prognostic multi-biomarker panel from survival data to assist clinicians is the problem we want to address. The most widely used model for survival analysis is Cox proportional-hazards regression model (Cox model). It can handle the censored survival data in a rigorous way () and provides an estimation of the hazard ratio and its confidence interval. However, Cox model directly utilizes the noisy and censored data to predict the survival ratio thus often leads to poor prognosis. Also Cox model uses all features with high dimensionality in general. It is trained on a particular dataset and usually generalized poorly to other independent datasets. To avoid overfitting, L 1 penalized Cox model (L 1-Cox model) was proposed to perform variable selection and shrinkage, which makes it very useful for de-noising and identifying the most meaningful features (). Nonetheless, both Cox model and L 1-Cox model heavily depend on the quality of input survival time. In reality, Harrell's Concordance Index (CI) is a widely used performance measure for assessing prediction models in survival analysis. The main idea is that it doesn't consider the value of survival time but the rank of patients by their survival times (). In DREAM Breast Cancer Prognosis Challenge, challenge models will be scored by calculating the CI between the predicted survival and the true survival information in the validation dataset. The final assessment of models and the determination of the best performer will be based on the CI of predictions on the test dataset (http://www.the-dream-project.org/). Recently, CI is used to assess the clinical utility of cancer genomic and proteomic data across tumor types in The Cancer Genome Atlas (TCGA) project (). In this sense, it is natural to directly optimize CI to select biomarkers and construct predictive models. However maximizing CI is a non-convex optimization problem with non-differentiable objective function and hard to solve (). We notice that CI and AUC (Area Under ROC Curve) are identical and equate the Mann-Whitney statistics in the absence of censored data (). We could use AUC to assess the classification accuracy and further to approximate CI. With this connection, our motivation is to convert survival time regression to a binary classification problem and then maximizing AUC. For example, we choose the 5-year threshold in practice without loss of generality, i.e. we predict whether the patient can live longer than 5 years. In clinical study, the 5-year survival rate is commonly used as a survival rate for estimating the prognosis of a particular disease. It serves as a general accepted standard by the American Cancer Society to assess the cancer malignancy. In addition, 5-year threshold leads to the balanced positive and negative datasets (Supplemental). In this way we focus to solve a classification problem about maximizing AUC. Classical classification methods, such as support vector machine (), logistic regression (), k-nearest neighbor (), have been widely used in survival analysis and achieved good performance. Moreover,proposed the time-dependent AUC, which was adopted as evaluation for the model performance (). Nevertheless, none of these methods optimize AUC directly to construct classifiers. AUC is an important performance measure that has been widely used (). Some algorithms have been developed to optimize AUC based on surrogate loss (). Those technologies can be borrowed in optimizing AUC to deal with the censored survival data. Meanwhile, the rapidly developed high-throughput measuring techniques usually generate high dimensional genomic or clinical data. Feature selection is necessary along with model estimation to reduce data dimension and model complexity. Also it helps to provide intuitive understanding. Here, we denote selected features having potential diagnostic usage as biomarkers. Importantly, features combine in linear or nonlinear ways to improve diagnostic accuracy. This useful feature combination is named as multi-biomarker panel. It's a challenging task to select a biomarker subset to maximize accuracy in computation. Here wrapper methods give a good example for its complexity. The idea of these state-of-art feature selection algorithms is to use each subset to train a model and then test on a hold-out dataset. Since wrapper methods need to go through all the possible subsets, they are computationally intensive. For example if there are 50 features, it should train 2 50 models to select the best subset by comparing models' error rates on the hold-out validation dataset. To reduce the computational complexity, some heuristic methods have been proposed. For example, Support Vector Machine-based Recursive Feature Elimination (SVM-RFE) has become one of the leading methods and is being widely used (). It adopts an intuitive strategy to remove a feature with the smallest coefficient in SVM model one step. We note that this stepwise feature selection strategy may miss some critical feature combinations. In this article, we convert the survival time regression to a classification problem aiming to select a small group of biomarkers and maximize AUC score. Specially, we propose a single optimization model based on nearest centroid classifier with feature selection, which maximizes AUC and minimizes the number of selected features simultaneously. To make the computation tractable, maximizing AUC is slacked to minimize a loss function. Meanwhile, we use L 1 'norm' to minimize the number of selected features instead of L 0 'norm' thus make it could be efficiently solved by a linear programming. Finally our method predicts whether a patient survives longer than 5 years in a fast and efficient way. To validate the performance, we apply the new method to gene expression data of breast cancer and clinical data of stage IB Non-Small-Cell Lung Cancer (NSCLC). The results show that our method can identify panels of biomarkers with good survival prediction performance.
Methods
Overview of NCC-AUCWe propose a novel method based on nearest centroid classifier and maximize classification accuracy by AUC. Simultaneously, we minimize the number of features to select the best multi-biomarker panel for survival prediction. To make the computation efficient, we approximate AUC by a loss function. Meanwhile the number of features (L 0 'norm') is approximated by the sum of probability for NCC-AUCselecting the features (L 1 'norm'). To balance these two objectives, a parameter k is introduced to formulate the model as a single-objective-function optimization problem. Solving the optimization problem allows us to select a panel of biomarkers to assist survival prediction (). We name our method as NCC-AUC (Nearest Centroid Classifier for AUC optimization).
Survival time classificationAs shown in, the identification of patients with longer survival time is treated here as a binary classification problem. We apply a threshold (5 years) to the survival time to each patient and classify all the patients into two groups: positive samples are patients living shorter than 5 years and negative samples are those patients living longer than 5 years. For the censored data, we only keep the patients with censored time above 5 years and classified them as negative samples. Assume that we have n positive samplesrespectively. The idea of nearest centroids is intuitive. If X is a positive sample, it should satisfy,When X is a positive sample, CX  w T X  b > 0. When X is a negative sample, CX  w T X  b < 0. It is not fair to evaluate a classifier by only a cutoff such as zero. AUC is a good settlement for such problem by considering pairwise comparison. Specially, the AUC of the classier CX should bewhere Ix  1 x > 0 0 others (However, the classifier deals with all the features without difference. Noise will be added and the dominate features won't be found. We introduce a feature selection variable h, which is a p-dimensional vector.
Constructing optimization modelSpecifically, we want to find a vector h to maximize the objective function as follows,As the paper () states, the value of AUC(h) keeps the same for the classifier c 0 Ch; X where c 0 > 0, therefore, we only consider the situation h!0. Ideally, we would want the score for positive samples to be higher than that for negative samples, which yields 1 for the AUC and completely differentiates positive and negative samples. This could be measured by the MannWhitney U test () to test whether the positive samples ranked higher than negative samples P(X > Y). We note that 1  AUCh can be interpreted as the misclassification rate. Then we formulate the feature selection and classification problem aimed for minimizing the misclassification rate (maximizing the AUC score). minHowever the objective function of this optimization problem is non-convex. For efficient computation, it is sensible to minimize a convex surrogate loss function. We choose the hinge loss function used in support vector machine as, minwhere x   xIx > 0. So the problem can be simplified as follows,)
...)
Posiive samplesNegave samples slack to " norm "
Step 1Step 2Step 3 minIn addition, we minimize the number of selected features. It is well known, L 0 'norm' is the number of non-zero entries minkhk 0  minIn certain conditions, L 1 minimizer is equivalent to L 0 minimizer (). In practice, the following L 1-approximtion to the original L 0-problem is heuristically used beyond these conditions.Since we have two objectives to be simultaneously minimized, a parameter k then is introduced as follows, minIt is equivalently to minimize the following linear programming problem,s.t. n 1 ij !0; n 2 ij !0; 1 i n; 1 j mwhere n 1 ij ; n 2 ij denotes the positive and negative part for the term r T X i  Y j . This linear programming can be solved by many efficient algorithms.
Parameter tuningParameter k is a single parameter to be tuned in our model. We chose k by two steps: primary adjustment and further adjustment. In primary adjustment, we tested 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10 000, 100 000 for k. Then the best parameter k is obtained by comparing the sum of training and validating AUCs. Next step we selected the interval containing the best parameter k for further adjustment. For example, we selected interval [0.001, 0.1] if the best parameter k  0.01 was obtained by the primary adjustment. Further, we set step length as 0.01 and selected optimal k in interval. Larger k means fewer selected features and larger misclassification rate. In this way we balanced these two terms in the objective function and selected parameter k with smaller misclassification and relative fewer features. All the calculations were calculated by MATLAB R2013a environment on a computer 3.40 GHz Inter Core i7-2600CPU and 16 GB memory.
DatasetsWe validated our method both in genomic data and clinical data.of all, we divided the patients into two groups by the fact that if a patient could survive more than 5 years or not. We selected significance genes by t-test and kept the 2101 genes with P-value < 0.001. In Basal-like subtype, we randomly selected 200 samples from 328 samples as training cohort and the others are treated as validation cohort. NCC-AUC selects 97 genes with training AUC  1 and validation AUC  0.7207 () by setting k  0.001. Gene Set Enrichment Analysis (GSEA) () reveals that these genes contain 22 up-regulated genes with q-value < 10 15 and 15 down-regulated genes with q-value < 10 7 in basal-like subtype (; Supplementary). GSEA also shows that these genes contain 16 genes which could discriminate basal-like subtype from luminal subtype with q-value < 10 13 (). These evidences support that the selected genes are closely correlated with basal-like subtype.
Gene expression profiles
NCC-AUC outperforms SVM and SVM-RFE in basal-like subtypeThe main advantage of NCC-AUC is to optimize classification accuracy and select the best biomarker panel in a single model. Here we demonstrate the performance gain of our NCC-AUC by comparing with SVM and SVM-RFE. SVM is a supervised learning model and has been widely used in machine learning () to achieve high accuracy in classifying a small set of samples. SVM-RFE is one of the most successful wrapper methods in feature selection (). SVM-RFE conducts feature selection in a sequential backward elimination manner, which starts with all the features and discards one feature at a time by checking the classification accuracy. SVM and SVM-RFE are implemented by MATLAB R2013a with default parameters. SVM gets AUC  1 in training cohort while 0.5187 in validation cohort in basal-like subtype dataset (). This shows that it's necessary to remove redundancy genes to avoid overfitting. If we add the feature selection option in SVM, SVM-RFE identifies a panel of 53 genes with performance of AUC  1 in training cohort and AUC  0.5513 in validation cohort (). NCC-AUC performs better with AUC  0.7207 in validation cohort and the same AUC in training cohort. The improvement is due to the fact that NCC-AUCNCC-AUC optimizes AUC directly while SVM and SVM-RFE optimize the classification error. Also NCC-AUC regularizes the number of selected feature in a simultaneous way while SVM-RFE in a stepwise way. In conclusion, NCC-AUC shows advantage in classification and outperforms SVM-RFE in basal-like subtype.
NCC-AUC outperforms Cox model and L 1-Cox model in basal-like subtypeTo show the advantage to treat the survival time regression problem as a binary classification problem, we compared our NCC-AUC with Cox model and L 1 penalized in Cox model. In survival analysis, Cox model and L 1-Cox model are typical methods to fully make use of the survival time while our NCC-AUC only uses whether the survival time is longer than 5 years. Cox model is one of most classical model in survival analysis, and shows efficiency for censored data (). L 1 penalized Cox model has the property that it simultaneously performs variable selection and shrinkage, which makes it very useful for finding interpretable prediction rules in high-dimensional data (). Cox model and L 1-Cox model are implemented by R package 'survival' and 'penalized' with default parameters. To investigate Kaplan-Meier analysis for the multiple-biomarker panel by NCC-AUC, we selected cutoff score based on ROC analysis. The score close to the point with best sensitivity and specificity balance was selected as the cutoff. Then we could classify samples into two classes in training and validation cohorts with the panel selected by NCC-AUC. In basal-like subtype, there are 114 predicted low risk samples and 86 predicted high risk samples in training cohort. Log-rank test demonstrates that the two groups have significant P-value < 0.00001 (). In validation cohort, there are 78 predicted low risk samples and 50 predicted high risk samples. Logrank test shows that P-value is significant (0.009) (). In comparison, Cox model also shows significant difference between predicted low risk patients and predicted high patients with P-value < 0.00001 in training cohort but not significant with Pvalue  0.235 in validation cohort (). With feature selection strategy, L 1-Cox model identifies a panel of 53 genes and gets P-value < 0.00001 in training cohort and P-value  0.735 in validation cohort (). Here we selected the median value as the cutoff for Cox model and L 1-Cox model to convenient compare with NCC-AUC. Therefore, NCC-AUC performs better than Cox model and L 1-Cox model in basal-like subtype.
NCC-AUC outperformsSVM, SVM-RFE, Cox model and L 1-Cox model across other subtypes We applied NCC-AUC to other subtypes of breast cancer and compared with SVM, SVM-RFE in classification accuracy. In Her2 subtype, NCC-AUC identifies 57 genes with AUC  0.7051 in validation cohort. This is better than SVM with AUC  0.5045 and SVM-RFE with AUC  0.6208 (). In other three subtypes, we also get consistent improvement (E). Especially in normallike subtype, our method improves AUC from 0.6006 (SVM-RFE) to 0.7810 in validation cohort (). These demonstrate that NCC-AUC outperforms classical classification model SVM and SVM-RFE across different subtypes. In addition, we compared NCC-AUC with Cox model and L 1-Cox model to show its advantage in survival analysis. In luminalA subtype, log-rank test shows that Cox model (Pvalue  0.630) is non-significant and L 1-Cox model (Pvalue  0.001) indicates significant difference between predicted high risk patients and predicted low risk patients in validation cohort (). Nevertheless, NCC-AUC shows better significance than L 1-Cox model in validation cohort (P-value < 0.00001). In luminalB subtype, both Cox model (P-value  0.063) and L 1-Cox model (P-value  0.303) are not significant but NCC-AUC (Pvalue  0.00005) shows significance in validation cohort. In normallike and Her2 subtype, NCC-AUC also shows much better. Receiver operating characteristics curves for NCC-AUC, SVM and SVM-RFE in validation cohort for five subtypes of breast cancer; (A) for basal-like subtype, (B) for Her2 subtype, (C) for lunminalA subtype, (D) for luminalB subtype, (E) for normal-like subtype. NCC-AUC consistently outperforms other methodsperformance than Cox model and L 1-Cox model (). These evidence strongly support that NCC-AUC outperforms classical survival analysis method Cox model and L 1-Cox model across subtypes of breast cancer.
The performance gain by NCC-AUC is robustThe performance gain by NCC-AUC is robust to the random splitting of training and validation cohorts. To demonstrate this, we randomly selected 200 samples from 328 samples as training cohort in basal-like subtype and the others are in validation cohort. The procedure was repeated by 100 times. SVM and SVM-RFE serve as control (). The mean AUC of NCC-AUC is 0.7264 and the variance is 0.0012. It significantly improves the results of SVM 0.5337 (P-value < 10 89 , Student's t-test) and SVM-RFE 0.5879 (Pvalue < 10 74 , Student's t-test), respectively. Those side-by-side comparisons show that NCC-AUC is a robust method and it is not influenced by randomly sampling the training cohort. To look at the consistent improvement for the different thresholds, we also took threshold as 3, 4, 6, 7 years to divide the patients into two groups in the basal-like subtype. NCC-AUC consistently outperforms SVM and SVM-RFE at different thresholds (Supplementary). Moreover, we compared NCC-AUC with Cox model and L 1-Cox model. Results show that the improvement of NCC-AUC is robust (Supplementary). To demonstrate NCC-AUC is robust at different thresholds, we randomly selected 200 samples from 328 samples as training cohort in basal-like subtype 100 times. Then the time-dependent AUC () of validation cohort at different thresholds can be obtained. The results demonstrate that NCC-AUC is robust at the threshold  5, 6, 7 years by Student's t-test (Supplementary).
NCC-AUC selectsbiological meaningful biomarkers with low redundancy NCC-AUC is efficient in selecting biomarkers with low redundancy and identifying plausible biomarkers consistent with existing annotations and previous study. Good multi-biomarker panel should be a set of non-redundant and complementary biomarkers that maintain the maximal classification ability. To show NCC-AUC can select low redundancy biomarkers, we proposed a mean redundancy score and compared NCC-AUC with L 1-Cox model and SVM-RFE in basal-like subtype. Here we evaluated biomarker redundancy by the mean redundancy score among the identified biomarkers. Given a set of biomarkers, the average redundant score is defined as the average of pairwise Pearson Correlation Coefficients (PCC). The biomarker redundancy of NCC-AUC is 0.3897 and the improvements compared to L 1-Cox model and SVM-RFE are significant: 0.5504 (P-value < 10 141 , Student's t-test) and 0.5251 (P-value < 10 107 , Student's t-test), respectively (). To demonstrate that NCC-AUC can select more plausible biomarkers than L 1-Cox model and SVM-RFE, we further applied GSEA for the genes identified L 1-Cox model, and SVM-RFE and compared with NCC-AUC. Results show that SVM-RFE selects one gene set (SMID_BREAST_CANCER_BASAL_UP) closely associated with basal-like subtype (Supplementary). While NCCAUC selects three gene sets related to basal-like subtype (SMID_BREAST_CANCER_BASAL_UP, FARMER_BREAST _CA NCER_BASAL_VS_LULMINAL, SMID_BREAST_CANC-ER_BAS AL_DN). Although SMID_BREAST_CANCER_BASA-L_UP shows up in both results, our NCC-AUC gets a 22 gene overlap with a significant q-value (1.79E-16). SVM-RFE obtains a 9 gene overlap with a q-value 1.10E-04. For L 1-Cox model, it can select 50 genes which overlap significantly with the three gene sets related to basallike subtype (Supplementary). However, the significance levels are all less than the 97 genes identified by NCC-AUC. For example, this 50 gene set overlaps with SMID_BREAST_CANCER _BASAL_UP by 12 genes with a q-value 1.11E08. Moreover, we investigated the genes which were uniquely identified by NCC-AUC in basal-like subtype. We found that more than half of these genes are not contained in L 1-Cox model and SVM-RFE (). By checking the functional annotation, half of these genes are contained in top 10 gene sets by GSEA from the 97 genes identified by NCCAUC. To look at the consistency, we compared prognosis result by NCC-AUC in validation cohort in all subtypes. We found that). Except for normal-like subtype, the validation AUC of the other four subtypes are low, which further confers the limitation of gene expression data in breast cancer prognosis prediction. In addition, we also found that more than half of the genes selected by SVM-RFE are consistent with NCC-AUC in basal-like subtype (). Taken together, NCC-AUC selects biologically meaningful genes, which are consistent with other research in basal-like subtype.
Performance in clinical data of lung cancer
Multi-biomarker panel identified by NCC-AUC in clinical dataIn addition to genomic data, we further tested NCC-AUC in clinical data for multiple-biomarker panel identification. The training cohort contains 42 positive samples and 58 negative samples, and validation cohort contains 20 positive samples and 28 negative samples. NCC-AUC selects a panel of 12 biomarkers with AUC  0.8284 in training cohort and AUC  0.7589 in validation cohort by setting k  0.013 (). The panel consists of p21ras, NM23-H1, CD34-MVD, BAX, CD44v6, EMA, CEA, cyclin-D1, p27kip1, VEGF, cancer-cell type and PCNA. p21ras is an oncogene and has been reported as an independent predictors of prognosis for NSCLC (). Besides, NM23-H1 increases CD34-MVD's expression and VEGF and may be associated with NSCLC metastasis (). BAX has important regulatory roles in apoptosis and is associated with early stage NSCLC (). In addition, CD44v6 is related to CEA and EMA and may play role in differentiation and progression of NSCLC (). These biomarkers combine together to form a panel to assist survival time prediction.
NCC-AUC outperforms SVM and SVM-RFE in clinical dataCompared with NCC-AUC, SVM gets AUC  0.9020 and AUC  0.4786 in training and validation cohort respectively (). It shows that NCC-AUC successfully avoids overfitting by selecting a panel of biomarkers to de-noise. SVM-RFE identifies a panel of 8 biomarkers with performance of AUC  0.8173 in training cohort and AUC  0.5037 in validation cohort (). NCCAUC is better with training AUC  0.8284 and validation AUC  0.7589. Those comparison shows that NCC-AUC possesses advantage in feature selection and performs better than SVM-RFE in both training and validation cohorts of clinical data.
NCC-AUC outperforms Cox model and L 1-Cox model in clinical dataTo investigate the survival analysis by NCC-AUC, we selected a cutoff score similar as before and then classified training and validation cohort into two groups. The training cohort contains 55 predicted low risk and 45 predicted high risk patients. Similarly, the validation cohort contains 25 predicted low risk and 23 predicted high risk patients. Log-rank test shows P-value < 0.00001 in training cohort and P-value  0.0158 in validation cohort (, 7B). Compared to NCC-AUC, Cox model shows significance in training cohort (Pvalue < 0.00001) while non-significance in validation cohort (P-value  0.5939) (). With feature selection strategy, L 1-Cox model identifies a panel of 17 biomarkers with Pvalue < 0.00001 in training cohort and 0.7166 in validation cohort (). NCC-AUC performs better than both Cox model and L 1-Cox model in validation cohort of clinical data. Therefore, converting survival time prediction to a classification problem with evaluating AUC accuracy significantly improves patient survival prediction and achieves better performance than classical survival models.
Discussion and conclusionSelecting multi-biomarker panel in cancer survival analysis is a challenging task because of the complexity of cancer pathogenesis and the difficulty of estimating the time until event occurs. Cox model is a classical model and widely used in survival analysis and L 1-Cox model could select a panel of features for survival risk ratio estimation. However, the quality of survival time is very crucial for Cox. Receiver operating characteristics curves for NCC-AUC, SVM and SVM-RFE in training cohort (A) and validation cohort (B) in clinical data. NCCAUC outperforms the existing methods in validationestimation, we aim to optimize CI directly. Noticing that AUC is a good approximation for CI, we treat the problem as a classification problem. This key idea allows us to propose NCC-AUC to identify meaningful biomarkers for survival analysis. NCC-AUC optimizes AUC and the number of biomarkers simultaneously thus we could select a multi-biomarker panel that has more powerful prognosis-predicting ability. We demonstrated the good performance of NCC-AUC on not only gene expression profiles of breast cancer but also clinical data of Stage IB NSCLC. We observed that the multi-biomarker panel identified by NCC-AUC is more plausible in biology. For example, in basal-like subtype NCC-AUC identifies 97 genes and GSEA annotation shows that these genes were closely related with this subtype (Supplementary). Furthermore, these genes also show lower average redundancy than L 1-Cox model and SVM-RFE. This further demonstrates NCC-AUC's ability to remove redundant features. In addition, NCC-AUC shows robust performance gain across tumor subtypes and training cohort sampling, and it also shows consistent improvement than SVM, SVM-RFE, Cox model and L 1-Cox model at different thresholds. Finally, we validated NCC-AUC in clinical data and NCC-AUC selects the biomarkers closely associated with stage IB NSCLC. Thus NCC-AUC holds the promise to identify plausible multi-biomarker panel to assist survival analysis. Our results show that the binary classification framework works well in real survival data analysis. The comparisons with traditional survival analysis, such as Cox model and L 1-Cox model, clearly demonstrate this point. Unlike Cox model, NCC-AUC converts survival time prediction to a classification problem and evaluates classification by AUC. Here AUC is a good approximation of CI which is a classical index in survival analysis. Importantly NCC-AUC performs better than Cox model and L 1-Cox model in validation cohort for both gene expression dataset and clinical dataset (Supplemental Tables S5, S6). Therefore, we have a good reason to believe that NCC-AUC is a useful tool for survival analysis. Especially when the survival data is noisy, NCC-AUC can be more useful to ignore the detailed values. Further comparison with existing feature selection method SVM-RFE reveals the advantage of NCC-AUC in feature selection. Unlike SVM-RFE's stepwise way to eliminate one feature in each step, NCC-AUC allows us to select the best feature combination by solving a single optimization model. We showed that NCC-AUC is better than SVM-RFE in both datasets (Supplemental Tables S5, S6). In addition, we maximize AUC to improve the classification accuracy instead of classification error with a specified cutoff in SVM-RFE. Furthermore, NCC-AUC is formulated as a linear programming and could be solved rapidly and effectively. We acknowledge that our current NCC-AUC is limited in several ways, which suggests future improvements. On one hand, NCCAUC is limited in identifying much biological insights. NCC-AUC directly selects the molecular signatures for the samples with different phenotypes (whether a patient survive more than 5 years) while a posteriori justification may happen from molecular level to phenotype level then the ambiguous molecular signature may be useless. () proposed a method to reduce the justification, which may help to solve the problem. In addition, two improvements may enhance the biological insights in the future work. One is that we should integrate the pathway information into NCC-AUC and then we will identify the network biomarker with good interpretability; the other is that, we should also take the values of survival time into account rather than only take a threshold. We tried to maximize the sum of PCCs of the selected features and survival time, which shows no significant improvement (P-value  0.9186, Student's t-test) (Supplementary) in the basal-like subtype. But it integrates more information and may have a significant improvement in other cases. NCC-AUC is also limited in model construction. We classify patients by assessing whether the patient's survival time is longer than 5 years. We assume that the two classes are stable and have its own centroid distribution, which allows us to design simple nearest centroid based classifier. Besides, NCC-AUC failed to consider some patients with censored survival time. This ignores the information from censored patients with survival time less than five years. In addition, NCC-AUC is based on linear classifier and we should seek other nonlinear classification methods. Finally, AUC is only a good measure of CI and we should consider to optimize CI directly in future. In conclusion, we convert the survival time regression problem to a classification problem motivated by optimizing CI. In practice, we evaluate classification accuracy by AUC and propose a novel optimization model to maximize it. Our main contribution is to simultaneously optimize two objectives: AUC and the number of selected features. We slack AUC by a loss function and the number of features by L 1 'norm' and solve the problem via a linear programming. We applied NCC-AUC to gene expression profiles of breast cancer and stage IB NSCLC. The results fully demonstrate the advantages of NCC-AUC by outperforming SVM, SVM-RFE, Cox model and L 1-Cox model. Our novel method holds the promise to predict the reliable prognosis of breast cancer and stage IB NSCLC. We also note that our new method can be widely extended in analyzing cancer genomics data and studying other complex diseases.
Funding
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
)) min 1 Balance Nearest centroid classifier Predicted high risk paents Predicted Low risk paents Linear programming Fig. 1. The flowchart of our NCC-AUC method. Step 1, we group patients into positive and negative samples by thresholding the survival time. Step 2, by utilizing nearest centroid classifier, we maximize the classification accuracy (AUC) and minimize the number of selected features simultaneously. To balance the two objectives, we introduce a parameter k to formulate it as an optimization problem with a single objective function. Step 3, by solving the optimization model, we could select a panel of features which maximizes its AUC score in classification
M.Zou et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
