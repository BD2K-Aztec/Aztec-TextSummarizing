Motivation: The identification of short insertions and deletions (indels) and single nucleotide polymorphisms (SNPs) from Ion Torrent and 454 reads is a challenging problem, essentially because these techniques are prone to sequence erroneously at homopolymers and can, therefore , raise indels in reads. Most of the existing mapping programs do not model homopolymer errors when aligning reads against the reference. The resulting alignments will then contain various kinds of mismatches and indels that confound the accurate determination of variant loci and alleles. Results: To address these challenges, we realign reads against the reference using our previously proposed hidden Markov model that models homopolymer errors and then merges these pairwise alignments into a weighted alignment graph. Based on our weighted alignment graph and hidden Markov model, we develop a method called PyroHMMvar, which can simultaneously detect short indels and SNPs, as demonstrated in human resequencing data. Specifically, by applying our methods to simulated diploid datasets, we demonstrate that PyroHMMvar produces more accurate results than state-of-the-art methods, such as Samtools and GATK, and is less sensitive to mapping parameter settings than the other methods. We also apply PyroHMMvar to analyze one human whole genome resequencing dataset, and the results confirm that PyroHMMvar predicts SNPs and indels accurately. Availability and implementation: Source code freely available at the following
INTRODUCTIONThe most prevalent variants on the human genome are single nucleotide polymorphisms (SNPs) (). The second most prevalent variants are insertions and deletions (indels) that occur every 7.2 k bp (). Among them, 484% are short indels (55 bp) (). At present, the next-generation sequencing technology facilitates the direct detection of SNPs and short indels by resequencing a personal genome (). After sequencing, reads are mapped against the reference genome by read-mapping programs (), and variants are called by hypothesis testing methods on the piled-up reads (). However, accurate variant detection depends on the ability to discriminate true variants from sequencing errors. Particularly, for Ion Torrent and 454 data, indels are the most common sequencing errors causing incorrect alignments and thus posing a major roadblock to the accurate detection of variants. Ion Torrent and 454 can uniquely sequence homopolymers by quantifying the number of released by-products in the process of DNA synthesis (). At the same time, however, these techniques are prone to homopolymer sequencing errors, either overcalling or undercalling the number of homopolymer bases (). Moreover, the carry forward and incomplete extension effects, which happen as a few template copies may grow in desynchronization with the population, also raise insertions in reads. However, existing mapping methods do not include models to tackle homopolymer errors; therefore, alignments around homopolymers can be incorrect, resulting in calling false variants (). Therefore, a comprehensive method is necessary to improve the accuracy of variant calling for Ion Torrent and 454 data. Most of the existing methods detect SNPs and indels independently. The general strategy is to establish an accurate error model for the specific sequencing platform. For example, AtlasSNP2 () developed a logistical regression model relying on sequence context to discriminate true SNPs from sequencing errors. Realignment has been proven as an efficient method to improve accuracy by adjusting raw mappings. In response, Samtools (), for example, deploys a concept termed base alignment quality (), which is calculated by realigning a read against a reference to decrease false SNPs caused by nearby indels. Meanwhile, GATK () adjusts the alignments of reads spanning over indels by performing local multiple sequence alignment. However, as noted above, most of these methods are not designed to engage the problem of homopolymer errors and incorrect alignments around homopolymers. We previously proposed a method termed PyroHMMsnp () for Ion Torrent and 454. This method implements a hidden Markov model (HMM) to formulate homopolymer errors and trains the HMM by an expectation-maximization (EM) algorithm using resequencing data. Then, the trained HMM is used to realign reads against the reference sequence around homopolymers to improve the performance of SNP calling. *To whom correspondence should be addressed. Identification of indels in the reference is a more challenging problem in short-read sequencing. One of the major obstacles is to identify potential genome positions where indels are located. Strategies for identifying indels are different. Specifically, long insertions can only be found through sequence assembly, either local assembly () or global assembly (), whereas deletions can be found through either sequence assembly or sequence alignments (). Strategies for identifying short and long indels are also quite different. In principle, short indels, sometimes even long deletions, can be found by aligning one read against the reference, as long as a reliable read-mapping program is used. However, because the read length is short, such mapping generally produces many false alignments with various kinds of indels and mismatches. To confirm the existence of an indel, we would have to examine multiple pieces of evidence, such as multiple aligned reads, read coverage and constraints of paired-end reads. To the best of our knowledge, robust indel detection remains unsettled. In this article, we propose a method termed PyroHMMvar to call SNPs and short indels for both Ion Torrent and 454 resequencing data. Two distinct features are highlighted in PyroHMMvar. First, we introduce an HMM to formulate homopolymer errors. The HMM can accurately distinguish real signals from sequencing errors and thus improve the alignment of reads against the reference. The parameters of HMM are trained directly from raw mapping results through an iterative EM algorithm. Second, we propose a graph data structure that merges multiple aligned reads at a given locus into a weighted alignment graph from which we reconstruct the consensus sequence(s). The use of the weighted alignment graph provides the following advantages. First, it enables the straightforward construction of the haplotype(s), which may contain both SNPs and indels. In comparison, Dindel () infers indels separately from SNPs. Second, we propose an efficient traversal algorithm over the weighted alignment graph to avoid the exhaustive and computationally complex enumeration of candidate haplotypes. We simulate SNPs and short indels in the diploid genome and use them to test the performance of PyroHMMvar. Compared with two state-of-the-art methods, Samtools () and GATK (), PyroHMMvar gives more accurate results. We also test the effect of the raw alignments produced by mapping programs to indel/SNP-calling accuracy by varying the scoring function of BWA-SW () to produce different mappings. The test results show that PyroHMMvar is less sensitive to the variation of the scoring function than the other programs. Finally, we apply PyroHMMvar to analyze one human whole genome resequencing dataset, and the results confirm that PyroHMMvar predicts SNPs and indels accurately.
METHODSAs shown in, the workflow of PyroHMMvar includes the following steps. (i) We build and train an HMM model directly from the raw mapping of the resequencing data or the spike-in data using an iterative EM algorithm. (ii) We use a sliding window to scan the genome. If the sliding window contains one or more candidate variants, we collect the short reads aligned within the sliding window and realign them against the reference using the HMM. (iii) We then merge all the alignments (paths in HMM) to build a weighted alignment graph and traverse the graph to reconstruct the top candidate haplotypes. (iv) Finally, weuse a Bayesian method to infer the genotype from the set of candidate haplotypes and the short reads, followed by alignment of the genotype to the reference to determine the alleles and coordinates of variants. Details of these four steps are described in the following paragraphs.
Homopolymer HMMAn appropriate error model can facilitate the correct alignments of reads against the reference. We previously proposed an HMM () to formulate homopolymer sequencing errors in both Ion Torrent and 454 data (). The HMM accepts a nucleotide sequence as input, and then converts the sequence into units of homopolymers using the run length encoding rule (). As shown in, ATTTTGGCCCC becomes a sequence of four homopolymers 5A,14 5T,44 5G,24 5C,34. For each homopolymer, there are two hidden states C and D. C means that the corresponding homopolymer is being sequenced, whereas the length of the output homopolymer could be varying because of overcalling or undercalling errors. D represents that the homopolymer is not being sequenced in case that either the homopolymer may be deleted or the flow signal is too weak to be detected. A third hidden state I sitting between two consecutive homopolymers is used to model random insertions. Two hidden states B, E f gare added into the model to represent the beginning and ending of the alignment because (i) the quality at the beginning and ending of a read may be low and (ii) sometimes the exact boundaries (the beginning and ending) of the corresponding reference substring that produces the read are not clearly defined. Thus, the HMM model represents a local, rather than global, alignment. Based on the above notation, a hidden state can take values from the set   B, C, D, I, E f g. For each read that is mapped to the reference, we use Viterbi's algorithm to compute a hidden state path p  1 2    n , which represents a unique alignment between the read and the corresponding reference substring.
Hidden State EmissionIn the above HMM, each hidden state can emit a homopolymer. Let h  , l h irepresent the homopolymer input to a state, and let g  , k where k ! 0 represent the homopolymer emitted by the state, where , 2 , A, C, G, T f g. However, in sequence comparison, we need a special homopolymer, a null homopolymer  , 0 h i, to represent homopolymer indels. For a read homopolymer g  1 2    k , each compositional nucleotide i has a quality score q i. We, therefore, define the quality score of the homopolymer as the average over the compositional nucleotides, as,Hence, the probability that state emits output g given input h is modeled as,The base call rate p j,  represents the probability that an input base is sequenced to an observed base during nucleotide incorporation. The length call rate p kj, l,  reflects the probability of observing k consecutive bases when a l bp homopolymer is given, and it is represented by a hierarchical model of the sequencing and base-calling procedures (). p q g , l, j   formulates the quality score assigned by the base-calling procedure.
Parameter Estimation To usethe HMM to perform the realignment, the parameters of the HMM will be inferred from the following iterative EM algorithm. Parameters in the above HMM include the hidden state transition matrix, the base call rates, the length call rates and the quality score distribution. The training data can be the resequencing data from one or more genomic loci, with no variants, or few variants or the spike-in data, which are sequenced through the control lane of a sequencing platform to assess sequencing quality. The estimation of these parameters would be simple if the ground-truth alignments that represent the procedure of generating read sequences from templates were known. However, because the ground-truth alignments are not available, we propose an iterative strategy inspired by the EM algorithm () to train the HMM without the groundtruth alignments. In this strategy, the learning procedure is divided into two successive processes. First, given a read and its mapped reference sequence, the best alignment is computed and simultaneously assigned a posterior probability conditional on the previously learned parameters using the forwardbackward algorithm (). Next, occurrences of the state transitions and state emissions are counted from the probabilistically weighted alignments, and parameters of the HMM are updated according to the occurrences by using the maximum likelihood estimation. This procedure iterates until the likelihood value converges.
Pairwise ReadHMM alignmentAfter parameter estimation, the HMM is used to adjust a read mapping by realigning the read to the reference through the HMM. Given a read r  r 1 r 2    r n and the corresponding reference sequence t  t 1 t 2    t m 0 that is located through readmapping, we first transform the reference t into homopolymer sequence h  h 1 h 2    h m , where h j  j , l j . Then, we apply the HMM to search for the optimal alignment between the read r and the template h using the Viterbi algorithm (). We define the Viterbi variable V i, j, k,   as the probability of the optimal alignment between the read prefix subsequence r 1:i   and the homopolymer prefix subsequence h 1:j   ending with the hidden state , and, simultaneously, the suffix of r 1:i   is a homopolymer of length k. We use the following recursion to calculate the Viterbi variable for 1 i n, 1 j m, as V i, j, k,max is the maximum length of the homopolymer ended at read position i, k 0 max is the maximum length of the homopolymer at read position i 0 and p 0 j  is the transition probability between two states. Based on the recursion, we can use dynamic programming to compute the Viterbi variables, starting with the boundary conditions V 0, 0, 0, B  1 and V 0, 0, 0,  0, where 6  B, and ending with the Viterbi score p r, h,
Weighted alignment graphGiven all the pairwise readreference alignments within a scanning window, we propose a graph data structure, termed weighted alignment graph, to merge all these alignments. Each read-reference alignment is represented by a path from B to E in the hidden space of the HMM (). Stacking up all the paths in this window, we construct a weighted alignment graph, which is a directed acyclic graph with a starting node at the hidden state B and an ending node at the hidden state E. In this graph, the same hidden states and transition edges in multiple paths are merged and represented by one node and one directed edge, respectively. Each edge is weighted by the number of paths in which it appears. An example is shown in. In this weighted alignment graph, a diploid genome should have one consensus path if the two underlying haplotypes are identical, or two different paths if the two underlying haplotypes are different. However, because each path in the graph represents a haplotype candidate, the number of paths grows exponentially by the number of branches in the graph. In regions where either the read quality or the alignment quality is low, the graph can be so complicated that an exhaustive search for all haplotype candidates is a computational burden. Fortunately, for most cases, true haplotypes correspond to paths with high weights in the graph. Therefore, we traverse the graph using a modified depth-first search (DFS) algorithm. For each node, we define an array to store the top k weighted paths from the starting node to this node. The algorithm consists of the following two steps:(1) Topological sort. We traverse the graph using the DFS algorithm to produce a topological sort. The topological sort is a sorted order of the nodes from the left to the right such that every edge in the graph points from the left to the right. The topological sort takes O V j j  E j j time, where V j j is the number of nodes and E j j is the number of edges.(2) Graph traversing. We traverse the nodes from the left to the right in the topological order. For each node, we compute the weights of all incoming paths, rank them and store the top k weighted paths. The graph traversing takes O k V j j  k E j j  time.This algorithm reduces the computational complexity.
Bayesian variant detection for diploid genomeWe use the Bayesian method to infer the underlying genotype from the observed short reads and the candidate haplotypes generated by traversing the weighted alignment graph. Let h be a haplotype sequence. A read subsequence r i 2 R  r i 1 i n j f gis aligned against h by using the Viterbi algorithm. The alignment score is used as the likelihood that h generates r i , asThe haplotype likelihood that h generates all read subsequences R is calculated by assuming that every read is sequenced from the haplotype independent of others, asFor diploid genome, the sequencing procedure can be considered as a two-stage model, shown in the followingAt the first stage, a haplotype h is randomly sampled from the genotype g  h 1 , h 2 h i. At the second stage, a read r is sequenced from the h. Based on the Bernoulli model, the genotype likelihood that g generates the data R is calculated bywhere by default p h 1 g    p h 2 g    0:5. With genotype prior p g  , the posterior that all reads are sequenced from g is computed byWe use a multinomial distribution to model the prior of a haplotype pair h 1 and h 2. Let n a be the length of the alignment between h 1 and h 2. Given the mismatch probability q m and indel probability q d , the prior probability of a genotype is defined as the probability that observing n m mismatches and n d indels in the alignment, calculated by,This prior setting is used to penalize a genotype of which two haplotypes are largely different from each other. The genotype g  with the maximum posterior probability will be selected as the most possible underlying genotype. A predicted variant is assigned a quality score, which is defined by how well the predicted variant explains the data. Specifically, a variant is of high quality if the best genotype explains the observed short reads well with the variant, but poorly without it. Therefore, the quality score for a variant v is defined as the following log-likelihood ratio: Q v  10  log max g2 " Gv p g R j   max g 0 2Gv p g 0 R j  max g2 " Gv p g R j   10 where G v is the set of genotypes having the variant v, and " G v is the complement set of G v. The previously proposed variant calling method works under the assumption of the reliable mappings, i.e. a read should be mapped back to the original genomic locus, at which there are a few false aligned positions or it is a correct alignment. However, this assumption cannot be guaranteed in practice. Therefore, we recalibrate the aforementioned variant quality score Q v by integrating the mapping quality Q m. The recalibrated variant quality score is calculated as the geometric mean of the above quality scores,where Q m is defined as the median mapping quality score of short reads within the sliding window.
Aligning genotype with referenceThe inferred genotype g  contains the variant allele(s), but without such explicit information as a locus. For the example shown in, the haplotype sequence reconstructed by the weighted alignment graph gives two insertions5C,14 5T,34followed by a homopolymer sequencing error of undercalling. Therefore, to explicitly determine the variant(s), we use the standard dynamic programming for multiple sequence alignment to align the genotype against the reference. In our case, we have three sequences, including two haplotype sequences and one reference sequence, so the running time is OL 3  where L is the length of the sequences.
Computational complexityThe computational complexity of PyroHMMvar arises from two components. The first component is the pairwise readHMM alignment. Suppose there are N reads of length w bp within a sliding window. The Viterbi algorithm, which is used to perform the pairwise alignment, achieves the time complexity ONw 2 . As a consequence of traversing the weighted alignment graph, k paths are generated as candidate haplotype sequences. N short reads are aligned pairwise against a candidate haplotype to calculate the data generation likelihood. Therefore, the computational complexity within a sliding window before we perform the Bayesian inference is OkNw 2 . The second component is the alignment between the inferred genotype against the reference. This alignment is done through a standard dynamic programming for multiple sequence alignment. In our case, we have three sequences, including two haplotype sequences and one reference sequence; therefore, the running time is Ow 3  where w is the length of the sequences. Hence, the total computational complexity within a sliding window is OkNw 2  w 3 . When PyroHMMvar is applied to a genome of size L bp, the complexity will bewhere  L=w is the number of the sliding windows in the genome. To reduce the complexity, we use the banding technique to avoid the computation of the entire dynamic programming table for both the pairwise and multiple sequence alignment.
RESULTS
DatasetsWe used two simulation datasets and one human whole genome resequencing data to compare the performance of PyroHMMvar with Samtools and GATK. We used the human chromosome 21 (chromosome size 48 129 895 bp) to generate the first simulation data. We randomly chose 35 110 SNP sites (SNP rate 0.1%) and 4409 indel sites (indel rate 0.01%; indel size 15 bp) on chromosome 21 to generate a pair of haplotypes. A variant site has a probability of two-third to be heterozygous and one-third to be homozygous. Next, we used the Ion Torrent simulator DWGSIG (https://github/com/nh13/dwgsim) to simulate the sequencing reads which are, on average, 400 bp long with an error rate of 2%. Six datasets were generated by the simulator to assess the performance of variant calling programs at the 5-, 10-, 15-, 20-, 25-and 30-fold sequencing depths. The simulated short reads were mapped against human chromosome 21 by using the BWA-SW () with the default parameter setting. The second simulation dataset was used to evaluate the effect of the mapping parameter setting on the performance of PyroHMMvar and other variant calling programs. Different parameter settings could produce different mappings and/or raw alignments of reads. We used the aforementioned simulation strategy to generate the sequencing reads (read length 400 bp) with 10 depth from a 5 Mbp segment on human chromosome 20 (Chr20:10000006000000). The simulated short reads were mapped against human chromosome 20 by using the BWASW with different mismatch penalties varying from 1 to 9. We also applied PyroHMMvar and other variant calling programs to call SNPs and short indels in the human genome by using the whole genome resequencing data produced by an Ion Torrent PGM machine (National Center for Biotechnology Information SRA Accession: ERX016676). The dataset consists of 859 757 279 reads, with an average length of 183 bp at roughly 6 coverage.
Performance criteriaThree evaluation criteria were used: sensitivity, specificity and F 1 score. Sensitivity is defined as the fraction of the annotated variants called by the program, specificity as the fraction of the called variants that are correct. Sensitivity measures the performance of a method in detecting true variants, and specificity assesses whether a method is capable of reporting few falsepositive variants. F 1 score is the harmonic mean of sensitivity and specificity. The formulas are shown in the following: sensitivity  specificity sensitivity  specificity 12
Diploid simulation with various sequencing depthsWe used the DWGSIM simulator to generate six sets of sequencing reads from human chromosome 21 with varying coverage depths: 5, 10, 15, 20, 25 and 30. PyroHMMvar, Samtools and GATK were applied to call SNPs and short indels. A called SNP is regarded as correct or true positive if the called locus is exactly the same as the simulated locus and the called genotype is concordant with the simulated genotype; otherwise, it is incorrect or false positive. An indel is regarded as a correct call if the called locus is within 5 bp of the simulated locus, and the called genotype is concordant with the simulated genotype. These concepts, as applied to true and false positives, were applied to both SNPs and indels. A comparison of the performance of these three variant calling programs is shown inThe results also show that PyroHMMvar is accurate at detecting short indels. Overall, PyroHMMvar had the best performance in all three criteria (sensitivity, specificity and F 1 ) across all sequencing depths. PyroHMMvar predicted more simulated indels, as well as PyroHMMvar had the highest specificity. It is worth noting that the number of false-positive indels called by PyroHMMvar decreases as the sequencing depth increases, whereas GATK and Samtools called more falsepositive indels along with the increase of sequencing depth. Across all sequencing data, the performance of Samtools' indel calling is well below that of PyroHMMvar and GATK. Overall, PyroHMMvar achieved the best performance in detecting both SNPs and short indels. We also demonstrated the runtime of the three programs, which were performed at a single thread of a computer with a 3.4 GHz CPU and 16 GB of memory. GATK achieved the fastest speed across all datasets. PyroHMMvar was slower than GATK, but faster than Samtools. These three programs can all be accelerated by using the parallel computing technique.
Diploid simulation with varying scoring functionBWA-SW deploys a SmithWaterman algorithm () to perform local alignment of long reads. In general, different scoring functions will produce raw alignments, and may thus affect the performance of variant calling. Therefore, it is desirable that a variant calling method be lesssensitive to the scoring function of the mapping programs to produce robust results. To assess this performance, we varied the mismatch penalty of BWA-SW from 1 to 9 and applied it to map the second simulated dataset at 10 depth. At a high mismatch penalty, the mapping program prefers indels over mismatches and produces different raw alignments. After applying PyroHMMvar, GATK and Samtools to these datasets, we computed the sensitivity, specificity and F 1 measure, and the results are shown in. Clearly, PyroHMMvar achieves consistent sensitivity and specificity across all parameter settings in detecting short indels. In contrast, the sensitivity of GATK increases when the mismatch penalty increases. We also noticed that the behavior of Samtools is different from other programs in that both the sensitivity and specificity increase as the mismatch penalty increases. This is because Samtools relies more on raw alignments to call indels. Because the mapping program prefers indels over mismatches, the sensitivity in detecting SNPs decreases as the mismatch penalty increases. PyroHMMvar selects a variant locus as an SNP candidate when there are at least two reads supporting the variant. If the original mismatches are replaced by indels in the alignments, evidence is insufficient to support a variant locus as a candidate site. For the same reason, the sensitivity of SNP detection decreases in GATK and Samtools. However, although the specificity of PyroHMMvar and Samtools is consistent between them, the specificity of GATK is quite low at low mismatch penalty. Thus, with a small mismatch penalty, some indels appear like SNPs in the raw alignments, in turn causing GATK to call false-positive SNPs. These results show that PyroHMMvar is more robust than the other tools.
Application to whole genome resequencing dataWe downloaded a human whole genome resequencing dataset (National Center for Biotechnology Information SRA Accession: ERX016676), which was generated by an Ion Torrent PGM machine (). We used the BWA-SW to map the short reads back to the human reference hg19 with the default parameter setting and then applied the three variant calling programs to call SNPs and short indels. The called variants with a prediction error rate of higher than 0.1% (quality score 530) were eliminated. As demonstrated in
The contribution of the HMM and the alignment graph in PyroHMMvarTo evaluate the contribution of the HMM in PyroHMMvar, we implemented a program, named PyroHMMvar-SW, which replaces the HMM by a homopolymer-aware SmithWaterman alignment method, resembling PanGEA (). In PyroHMMvar-SW, we assign a score 5 to a match and 3 to a mismatch. For an insertion or a deletion, we assign a score 4 to the gap opening penalty, and 1 to each gap extension penalty. For each pair of aligned homopolymers, in which a k-mer polynucleotide stretch is aligned to an l-mer polynucleotide stretch with identical nucleotide bases, we penalize the difference by 1jk-lj in the following scoring function, s k, l    5  min k, l  1  k  l j j 13We simulated a diploid genome sequencing dataset with 10-fold sequencing coverage, and applied both PyroHMMvar and Pyro HMMvar-SW to this dataset. The results are shown in.Both programs show a similar performance in SNP calling, but the HMM clearly out-performs the SmithWaterman method in the detection of indels. PyroHMMvar called less false indels and achieved a higher specificity (96.6%) than PyroHMMvar-SW(89.7%). This improvement is due to the contribution of the HMM in modeling the homopolymer errors. To evaluate the contribution of the weighted alignment graph method, we implemented a program called PyroHMMvarUnique, which identifies potential haplotypes by using short reads instead of the weighted alignment graph and the DFSbased algorithm implemented in PyroHMMvar. Similarly, we simulated a diploid genome sequencing dataset with 10-fold sequencing coverage, and applied both PyroHMMvar and PyroHMMvar-Unique to this dataset. The results are shown in. PyroHMMvar has higher F 1 scores for both the SNP calling (89.0%) and the indel calling (73.4%) than PyroHMMvarUnique (75.2% for the SNP calling and 56.0% in the indel calling). This proves that the weighted alignment graph method significantly improves the performance of variant calling.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
F.Zeng et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
PyroHMMvar at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Table 2. Performance comparison of variant calling programs based on human whole genome resequencing data at the prediction accuracy 499.9% (variant quality score 430)
DISCUSSION The Ion Torrent and 454 sequencing machines are the routine benchmark next-generation sequencing platforms with the leverage of affordable sequencing cost, low error rate and long read length. These sequencing machines are commonly used in microbiology and virology research. However, short reads generated by both Ion Torrent and 454 machines are contaminated by homopolymer errors, which invariably raise indels in data, thereby decreasing the accurate detection of SNPs and indels from resequencing data. In this article, we introduced a computational framework that includes four components: (i) an HMM to model homopolymer errors; (ii) a pairwise readHMM realignment method by which scoring parameters are estimated from resequencing data; (iii) a weighted alignment graph to reconstruct the underlying haplotype sequences; and (iv) a Bayesian method to call the genotype. Based on the simulation experiments and application to real human whole genome resequencing data, the proposed realignment approach combined with the weighted alignment graph was demonstrated to be an effective strategy to increase the accurate detection of SNPs and short indels on both Ion Torrent and 454 resequencing data. Although the method introduced in the article is designed for Ion Torrent and 454 sequencing technologies, we believe that this computational framework conveys the following insights on the future development of variant calling method. Frist, it demonstrates a method of establishing an appropriate error model for a specific sequencing platform by (i) training the error model using the resequencing data and (ii) applying the error model to realign the mappings. Second, it demonstrates the use of the alignment graph technique to reconstruct haplotype sequences. The alignment graph technique has also been shown to be effective in constructing high-quality consensus sequences from the long reads generated by the third-generation single molecular sequencing technology (Chin et al., 2013). Furthermore, the alignment graph technique dramatically reduces the computational time of the otherwise exhaustive haplotype enumeration strategy, which was used in previously published works (Albers et al., 2011; Zeng et al., 2013). Overall, by replacing the homopolymer error model with an appropriate error model, the proposed computational framework can also benefit the detection of single nucleotide variants from resequencing data generated by other sequencing technologies, such as Illumina or Pacific Biosciences.
