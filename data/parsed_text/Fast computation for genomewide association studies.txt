Motivation: Statistical analyses of genome-wide association studies (GWAS) require fitting large numbers of very similar regression models, each with low statistical power. Taking advantage of repeated observations or correlated phenotypes can increase this statistical power, but fitting the more complicated models required can make computation impractical. Results: In this article, we present simple methods that capitalize on the structure inherent in GWAS studies to dramatically speed up computation for a wide variety of problems, with a special focus on methods for correlated phenotypes. Availability: The R package 'boss' is available on the Comprehensive R Archive Network (CRAN) at http://cran.r-project.org/web/packages/boss/
INTRODUCTIONIn analysis of genome wide association studies (GWAS), it is standard to fit very large numbers of very similar regression models. A general form of commonly used models iswhere 1  i  n indexes subjects in the study, y i is the subject's outcome of interest, X i is a vector of subject-specific adjustment variables, g i is the set of genotype-dependent variables and i is an error term. The genotype-dependent variables g i vary from model to model, within one analysis, but the adjustment variables X i remain identical within each analysis. If the errors are uncorrelated, standard ordinary least squares (OLS) or generalized linear models (GLM) efficiently estimate genetic effects  g. However, when the errors are correlated notably, greater efficiency can be obtained, by incorporating this structure into the model. For instance, if repeated measures on an individual are available, either generalized estimating equations (GEE) or mixed models can increase power relative to an analysis that uses a single phenotype measure for each individual (). Similarly, when subjects are related, kinship can be incorporated into a mixed model to increase power (). A single GEE or mixed model analysis * To whom correspondence should be addressed.involves negligible computing effort, but the number of analyses carried out often extends into several millions, meaning more complicated GEE and mixed models computation with standard methods can be infeasible. Some computational speedups are available, by capitalizing on the similarity of each regression, meaning one can obtain genomewide estimates at a substantially reduced computational cost. For example,introduced an approximation to the Maximum Likelihood Estimate for mixed models which is currently implemented in ProbABEL. In their approach, both phenotypic correlation and non-genetic effects are estimated once and assumed constant across all models in an analysis. When the inclusion of genotype does not change these parameters, the inference is close to that obtained from the full fit, but can be misleadingly inaccurate when genotype is correlated with non-genetic covariates. In another example, rather than fixing both non-genetic effects and variance structure,) proposed mixed model methods where the variance structure of phenotype is fixed over all markers in which case simple modifications to Generalized Least Squares procedures can give fast computation of the results. This is more complicated to implement and slower than the ProbABEL approximation, but makes less assumptions about the nature of the genetic association. However, one drawback of a mixed model approach is that results may be invalid if either the correlation structure or the covariatephenotype relationship is not well specified. If the phenotype correlation is due to repeated observations on an individual, then GEE models provide powerful testing, which does not require us to correctly specify either the correlation structure or the phenotypecovariate relationships, that may be complicated (). However, there are no software packages that can currently implement this on a genome-wide scale in reasonable amounts of time. In this article, we explore two approaches that substantially reduce the computation required for a broad class of statistical models. Each exploits two important features of GWAS analyses: (i) few covariates are different in each regression and (ii) little variation in phenotype is explained by genotype at a particular locus. Our first approach exploits symmetry in the estimation of single marker models. For ordinary least squares, it is 20 times faster than current implementations, and for mixed models it can reduce computation by a factor of a few hundred. Our second approach is based on matrix decompositions and applies to a broader class of models, including those with multiple markers, and allows model-robust variance estimation. In the case of linear mixed models, it aligns with a proposal by
Boosted one-step statistics for GWASTier (2011). The speedup for this approach is not large for GEE and GLM models with few covariates or observations, but in our tests estimation in GEE models was 6080 times faster than currently implemented GEE packages in R. Although these computational approaches are approximations, estimation in practice is almost identical to traditional methods, as we demonstrate. The two approaches have the unifying feature that they are based on classical one-step approximations, suggesting the name boosted one-step statistics (BOSS).
APPROACHThis is sufficiently simple to perform on a genome-wide scale, and there is software available to do so (). For more complicated models, such as mixed models, GLM or GEE, we can estimate the coefficients through iteratively re-weighted least squares (IWLS) that repeatedly calculateswhere W k is a matrix of weights andYand andY k is a modified phenotype at the kth iteration of this procedure. The details of how this arises and the exact scheme by which these are updated are not important for this discussion, and the interested reader can refer e.g. Diggle (2002) and McCullagh and Nelder (1989). It suffices to note that, at each iteration, W k and Y k differ from W k1 and Y k1 in ways that only depend on the fitted values at the current iteration. Since it can be assumed that genotype has little effect on these fitted values, we can estimate W k andYand andY k in the absence of genotype and substantially lower the number of iterations required to converge. In fact, for the models we consider one iteration of the IWLS algorithm is typically sufficient. This can be considered an instance of a so-called 'one-step approximation', which are well known to be asymptotically equivalent to fully converged solutions (). Here, since the one step is based on a model with nearly identical fitted values to the model of interest, the practical performance is superior to classically implemented one-step estimators, as we demonstrate in Section 4. The accuracy decreases with the strength of the genetic effect, but our simulations suggest that this loss in accuracy occurs far beyond the threshold of genome-wide significance. That is when there are genome-wide significant results, both BOSS and traditional tests will identify them, but the exact size of the effect may differ slightly when it is very large. This procedure is already used in mixed models, although is not identified as such. There W is proportional to the inverse variance covariance matrix of phenotype induced by random effects. The details of this model are explored by (). BOSS applies the same idea to GLM and GEE. The use of one-step estimators takes advantage of the fact that genotype at a particular loci explains little of the variation in complicated phenotypes, but does not use the fact that only one variable changes in each regression. Sections 3 and 4 outline two methods used by BOSS which perform one-step estimation quickly by avoiding calculations that do not involve g. The first applies to single marker models and allows only model-based standard errors. The second is slower, but applies more generally and allows computation of robust test statistics. To make the remaining discussion simpler, we first express this weighted least-squares problem as an OLS problem. If we decompose the matrix W as a square root, i.e. W = D T D, we see that the above procedure is equivalent to regressing DX g =on D  Y. In general, W is an nn matrix, making this factorization difficult, slow and memory-intensive. However, W will often have structure. For GLM it is a diagonal matrix, so we only need to store a vector of length n. For GEE and mixed models, W is typically composed of small blocks corresponding to independent clusters of observations, so we need only to store and factorize these blocks. For some mixed model problems, W may be dense, and difficult to factorize in this way, but as shown in the Supplementary Appendix we can reduce the effective dimension to the number of random effects terms using the spectral decomposition. The factorization will need to be performed only once, but the multiplication Dg will need to be performed for each marker. So, where the weight matrix is sufficiently simple to factorize and handle, speed in one-step estimation will come from fast implementations of OLS.
METHODSIn this section, we describe fast implementations for one-step estimation. In the previous section, we demonstrated how this can be phrased in terms of fast OLS, so we will restrict our discussion to that case.
A fast algorithm for GWAS with single markersTypically, we model a quantitative trait Y as an outcome variable with genotype g and covariates X as predictors. That is we form the modelwhere  (0,var). With model-based approaches, we assume that vardoes not change with X and g. After fitting the model via OLS, the output is used to test the hypothesis H aHowever, if we swap Y and g to form the modelThe hypothesis test H b 0 :  y = 0 is equivalent to the previous test that  g = 0 and yields identical P-values when one uses model-based standard errors. (A straightforward proof of this is given in the Supplementary Appendix.) While this formulation may seem unnatural, it leads to simplified calculations. Almost all of the computational effort involved in regression is spent on the matrix of covariates, and using g as an outcome allows us to do this work only once, before we examine genotype. To use this result in a GWAS setting, we first denote the new matrix of predictors X y =andGand andG to be an nm matrix of genotypes for the entire GWAS (in practice we may break this up into more manageable chunks). The test statistics can then be computed by:where RR indicates element-wise multiplication. Here, T is a vector of  2 test statistics, identical to those computed with traditional methods.
A.Voorman et al.It is notable that this technique yields test statistics, but not regression coefficients. In typical GWAS, only a tiny fraction of these coefficients might be of interest, and they could be computed without special techniques, at minor computational cost. However, regression coefficients could be approximated, genome wide, by using the identity (By settingsetting setting 2 =   2 g /T , we can get an estimate of the variance and report a coefficient-standard error pair that are close approximations to the truth (because the genetic effect can be assumed to be small) and whose ratio gives the same test statistic as the full regression. The approximation is worse when var[Y |X +G] is much different than var, but this difference is typically negligible, as we demonstrate in Section 4. Furthermore, as noted by Zhong and Prentice (2010), interpretation of coefficients near the significance threshold is difficult due to the 'winner's curse' bias. Thus, when differences between this method and OLS exist, they are likely small compared to bias.
Efficient GWAS using Cholesky updatesThe method described in the previous section, while very fast for the models described, has some limitations. It only allows us to use model-based standard errors and thus relies on parametric assumptions; in GWAS settings, these are not likely to be checked, nor is there good power to detect important model misspecification (). When our model is not correct, either in how, we specify the variance structure or the mean structure, results can be misleading. In main-effects analysis with independent outcomes, the modelbased analysis may be appropriate, but there is little work exploring the impacts of misspecification of variance structure (). Furthermore, it does not give us fitted values that we can use in subsequent IWLS iterations, if desired. In this section, we explore a method based on well-known matrix decompositions which, while slower, overcomes these limitations. We start with the case of a single marker, which is later generalized to multiple marker models. In order to distinguish between those variables that are the same in each regression and those that differ, denote the model matrix asThe bottleneck calculation of each fit is a matrix inversion of the formThis matrix inversion is typically done by first factorizing X g T X g to a form which makes inversion very simple. This factorization comprises the bulk of the computation involved in a regression. In this case, all but one column of X g remains unchanged between markers. Rather than computing the inverse for each marker, we can simply update the factorization calculated without genotype; this can be done easily using the Cholesky decomposition of X T X. Formally, we denote L as the lower-triangular Cholesky factorization of X T X. We want to augment L with rows corresponding composed of a pvector l T g and a scalar c to form the updated Cholesky decompositionSince L is lower triangular, solving the system of equations Ll g = X T g is straightforward. We then set c T c = g T g l T g l g. For p variables and n observations, this updating can be done with O(p 2 +np) calculations, rather than O(p 3 +np 2 ) calculations, the cost of a typical OLS fit. [The same approach is used byin the LARS algorithm to successively add covariates to a model]. The benefit of this approach is small when there are few covariates or observations, but becomes substantial in larger models and studies, which is precisely when computational speed becomes an issue in GWAS. The application of this procedure to mixed model equations was recently noticed by. Our discussion extends the results to a still broader class of models.The approach for main-effects GWAS outlined above easily extends to the situation where multiple markers or interactions are included. These terms can be subsequently added using the same method, which gives the matrix inverse using the same order of computation as standard matrix inversion ().
RESULTS
Timing comparisonsWe implemented the above methods in R and compared the timings using synthetic data (R Development Core Team, 2009). We simulated data for n = 2000 subjects and averaged time over m = 1000 simulated genetic markers, which is sufficient to accurately estimate the relative speeds. For GEE and mixed models, we generated three observations per patient. For GEE, we modeled the variance structure with an exchangeable working correlation matrix, and for mixed models we used a random intercept and one random slope. To make calculations as fair as possible, we implemented OLS directly with matrix inversion, which is twice as fast as the specialized code in the 'lm()' function; we used 'glm.fit()' for logistic regression, 'geese()' from the 'geepack' package for GEE calculations and 'lmer()' from the 'lme4' package for mixed models (). All comparisons were carried out on a Macbook pro with a 2.8 GHz Intel Dual Core i7. The timing comparisons are given in. For OLS, the Cholesky updating method is twice as fast as traditional methods, while the swap method is 20 times as fast. The advantage of the Cholesky updating is less pronounced for GxE analyses, but more so for logistic regression. For logistic regression, the swap method is about 125 times faster than the naive method.For repeated measures, the Cholesky method is 60 times faster than traditional methods for GEE with continuous outcomes 70 times faster for GEE with binary outcomes, and about 137 times faster for linear mixed models. If we do not want to use robust variance estimates, the 'swap' method gives GEE and mixed model estimates 1000 and 750 times faster, respectively, than standard code.
Boosted one-step statistics for GWAS
Accuracy of the one-step estimatorIn general, we found that the P-values from BOSS approximations are extremely accurate, which agrees with what () demonstrated for mixed models.displays results for logistic regression and GEE with exchangeable working correlation. Genotype was simulated away from the null to demonstrate that there is little difference between the two methods, even for small P-values. The simulations are described in more detail in the Supplementary Appendix. For logistic regression, the traditional one-step approximation is not sufficiently accurate for genome-wide significant associations. For GEE, traditional one-step approximation is the same as estimation with an independence working correlation. Although both the independence and exchangeable working correlations are consistent for arbitrary correlation structures, we see that correctly modelling correlation structure increases power. There is no clear choice for a threshold to identify when further iterations may be beneficial. Since the accuracy of the approach depends on the change in the fitted values, iterating further either when within-cluster or overall fitted values change relative to the model fitted without genotype. However, since the approximations are so close, the simplest and most practical approach is performing subsequent iterations when the approximate P-values fall below a certain threshold, say p onestep <1/m where m is the number of tests. In this way, we would not expect to perform subsequent iterations in a study where genotype has no effect, and when an association is present in the data the P-value reported will be as accurate as possible.
Accuracy of approximations in the single marker methodFirst, as discussed in the previous section, the single marker method calculates a coefficient-standard error pair, which is different from the OLS estimate, but gives identical Wald statistics. We simulated 1000 genotypes for 2000 subjects away from the null hypothesis and computed both the OLSOLS OLS g and the described approximation.demonstrates that this approximation is very close to the truth, even when the genetic effect is large. We see that genotype with, we know that the approximation is an overestimate, but we see that it is by a very small amount.
CONCLUSIONIn this article, we provided general computational methods that capitalize on the structure of genome-wide association studies to increase speed. BOSS is composed of two distinct procedures, but each takes advantage of two important features of genomewide association studies (i) few variables change from analysis to analysis and (ii) genotype at each locus explains a small component of variation in phenotype. Recognizing this, we demonstrated that one could perform nearly exact estimation and testing in a wide variety of statistical models fit with IWLS including GLM, GEE and mixed models, for a lower computational cost than currently implemented least squares. This had also been noticed in mixed models, but our contribution allows the analyst to use a much(b)The error in the approximation, as a percent of the OLS coefficient, against the P-value. Herein, the approximate coefficient, with its associated variance, yields identical inference to the OLS estimate broader set of tools, and for single marker models we provide a method which is substantially faster (). In particular, it is now feasible to take advantage of repeated measures with GEE and doubly robust standard errors on a genome-wide scale.
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
.3 Missing data One drawback of pre-computing before genotype is observed is that it is more difficult to adapt the analysis to peculiarities for any single regression. For example, if a subject is missing genotype data, the quantities computed without genotype will still contain this subject's information. If this constitutes only one observation, rank-one downdating algorithms can compute the appropriate factorization efficiently, to which the genotype of the remaining observations can be added as described above (Dongarra, 1979). If there are many missing observations, as would be the case with repeated measures, this downdating may be applied repeatedly; however, it may be more straightforward to conduct a naive analysis. In practice, linkage disequilibrium allows one to accurately impute missing genotype data, so this is not a large concern (Browning and Browning, 2009; Howie et al., 2009; Scheet and Stephens, 2006). The methods used by BOSS can accommodate uncertain genotype, given by a continuous variable, without modification. Currently, BOSS ignores missing genotype, which is equivalent to imputing a value of 0. Observations with missing non-genetic covariates are dropped from the analysis by BOSS. 3.4 Meta-analyses It is common in GWAS analyses to pool effect estimates and associated standard errors from multiple study centers. Since meta-analyses typically do not require that all study centers use the same estimator of an effect, the one-step estimators produced by BOSS can be considered compatible with those produced by other software. Furthermore, in the range of scenarios where it would be beneficial to meta-analyse results, that is, when the effect is modest, one should expect BOSS estimates to nearly identical to traditional estimators.
