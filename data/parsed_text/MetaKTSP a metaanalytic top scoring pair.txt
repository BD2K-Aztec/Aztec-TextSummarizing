Motivation: Supervised machine learning is widely applied to transcriptomic data to predict disease diagnosis, prognosis or survival. Robust and interpretable classifiers with high accuracy are usually favored for their clinical and translational potential. The top scoring pair (TSP) algorithm is an example that applies a simple rank-based algorithm to identify rank-altered gene pairs for classi-fier construction. Although many classification methods perform well in cross-validation of single expression profile, the performance usually greatly reduces in cross-study validation (i.e. the prediction model is established in the training study and applied to an independent test study) for all machine learning methods, including TSP. The failure of cross-study validation has largely diminished the potential translational and clinical values of the models. The purpose of this article is to develop a meta-analytic top scoring pair (MetaKTSP) framework that combines multiple transcrip-tomic studies and generates a robust prediction model applicable to independent test studies. Results: We proposed two frameworks, by averaging TSP scores or by combining P-values from individual studies, to select the top gene pairs for model construction. We applied the proposed methods in simulated data sets and three large-scale real applications in breast cancer, idiopathic pulmonary fibrosis and pan-cancer methylation. The result showed superior performance of cross-study validation accuracy and biomarker selection for the new meta-analytic framework. In conclusion , combining multiple omics data sets in the public domain increases robustness and accuracy of the classification model that will ultimately improve disease understanding and clinical treatment decisions to benefit patients.
IntroductionHigh-throughput experimental techniques, including microarray and massively parallel sequencing, have been widely applied to discover underlying biological processes and to predict the multi-causes of complex diseases (e.g. cancer diagnosis,), prognosis (van de) and therapeutic outcomes,). The associated data analysis has brought new statistical and bioinformatic challenges and many new methods have been developed in the past 15 years. In particular, methods for classification and prediction analysis (a.k.a. supervised machine learning) are probably the most relevant tools towards translational and clinical applications. Take breast cancer as an example, many expression-based biomarker panels have been developed [e.g. MammaPrint (van 't), Oncotype DX (), Breast Cancer Index BCI () and PAM50 (for classification/prediction of survival, recurrence, drug response and disease subtype. Reproducibility analysis of these markers and classification models has been a major concern and has drawn significant attention to ensure clinical applicability of these panels (). Many articles have focused on normalization, reproducibility of marker detection, inter-lab or inter-platform correlation concordance. For direct clinical utilities, more attention have shifted towards cross-study validation or inter-study prediction (i.e. a prediction model is established in one study and validated independently in a test study (). Such an issue is critical for translating models from transcriptomic studies into a practical clinical tool. For example, the training cohort may have utilized an old Affymetrix U133 platform. A biomarker panel and a model are constructed and a test study from a different medical center using an RNA-seq platform is available. A successful machine learning model should retain high prediction accuracy in such inter-lab and inter-platform validation. We note that many normalization methods have been developed to adjust for systematic biases across studies, including distance weighted discrimination (), cross-platform normalization () and Knorm correlation (). But the normalization performance largely depends on whether the observed data structure fits the model assumptions. In most applications, researchers have applied meta-analysis methods and have avoided relying on effectiveness of normalization (). To compare the metaanalysis methods with mega-analysis (i.e. normalize across studies and directly merge data for inference) in this article, we only perform simple quantile normalization within each study and then standardize each sample to mean zero and unit SD before we adopt mega-analysis. In addition to the issue of cross-study validation, it's critical to select a robust and accurate machine learning method. In the literature, many supervised machine learning methods have been proposed and applied to high-throughput experimental data. For example, the CMA package allows easy implementation of 21 popular classification methods such as linear or quadratic discriminant analysis, lasso, elastic net, support vector machines (SVMs), random forest, PAM etc (). In addition to these popular methods, the top scoring pair (TSP) method () is a straightforward prediction rule utilizing building blocks of rank-altered gene pairs in case and control comparison (see Section 2.1 for more details). The method is mostly rank-based without any model parameter. It is invariant to monotone data transformation and the feature selection and the model are more transparent for biological interpretation. Although TSP and its variant are robust methods that do not require normalization in cross-study validation, we have found that some of the selected TSPs from the training study may not reproduce in the test study possibly due to platform differences.illustrates the expression levels of a good TSP gene pair, ITGAX and XBP1, identified from the first IPF (idiopathic pulmonary fibrosis) training study Emblom (see data descriptions in Supplementary). XBP1 is over-expressed than ITGAX in control samples but under-expressed in cases. If we use this TSP to validate in the test study Konishi, we find that XBP1 is over-expressed than ITGAX in both cases and controls and we obtain 0% sensitivity and 100% specificity (i.e. Youden index  sensitivity  specificity  1  0). We found similar poor performance in two other studies Tedrow B and Pardo, showing that the TSP is likely a false positive. In, GPR160 is over-expressed than COMP in controls and under-expressed in cases for all three studies Emblom, Tedrow B and Pardo. It is a more reliable TSP across three studies and conceptually is less likely a false positive. Indeed, the cross-study validation in Konishi shows good performance with 80% Youden index. The two real examples inargue the potential of a meta-analytic approach by combining multiple training transcritomic studies to identify reliable TSPs so the resulting model has enhanced cross-study validation performance. In this article, we propose three meta-analytic approaches for TSP method (MetaTSP) by combining information across multiple training studies using (i) averaged TSP scores (ii) combining P-values via Fisher's method () (iii) combining P-values via Stouffers method (). To decide the number of TSPs used for model construction, a classical cross validation (CV) method and a variance optimization (VO) () method are applied and compared. Simulations and three real omics data sets (two gene expression data on breast cancer and IPF, and. Two TSP examples from real data to show advantage of MetaTSP. Xaxis and Y-axis refer to sample indices and gene expression levels, respectively. (A) Gene pair ITGAX/XBP1 has high TSP score (XBP1 > ITGAX in controls but ITGAX > XBP1 in cases) in the training 'Emblom' study but fail to replicate in the testing 'Konishi' study as well as the other two Tedrow B and Pardo studies. (B) Gene pair GPR160/COMP has high TSP scores (GPR160 > COMP in controls and COMP > GPR160 in cases) in all three training studies 'Emblom', 'Tedrow B' and 'Pardo'. The gene pair is successfully validated in the testing 'Konishi' study one pan-cancer methylation data) are used to benchmark the crossstudy validation performance.
Methods
TSP algorithm and kTSPThe original TSP algorithm was first proposed by. Denote by data matrix X  fx gn g the gene expression intensity of gene g (1 g G) in sample n (1 n N) and y n the class label of sample n. Particularly, we consider y n 2 f0; 1g, representing controls and cases for binary classification in this article. For any gene pair i and j (1 i, j G), define the conditional ordering probability score T ij  C  PrX i < X j jY  C for C 2 f0; 1g, where X i and X j are gene expression intensities of gene i and j. Intuitively, T ij (0) is the probability in controls that gene j has larger expression intensity than that of gene i and similarly T ij (1) is for cases. Given observed expression profile data matrix X, the probability scores can be estimated as b T ij C   P N n1 Ix in < x jn Iy n  C= P N n1 Iy n  C, where I() is an indicator function that generates value one if the statement inside the parenthesis is true and zero otherwise. The discriminant score of the gene pair is defined as S ij  b T ij 1  b T ij 0. Note that 1 S ij 1 always holds. When S ij  1, expression of gene j is always greater than that in gene i in cases and expression of gene j is always smaller than that in gene i among controls. As a result, the ordering of gene i and gene j expression is predictive to the class label. On the contrary, if S ij  1, gene j always has a smaller expression than gene i in cases and the relation is reversed in controls. In summary, the absolute value of S ij reflects the predictive value of the gene pair. The TSP algorithm seeks the best gene pair i 0 ; j 0   argmax i6 j jS ij j as the classifier. When multiple gene pairs give the same highest absolute score, the best pair that gives the largest differential magnitude D ij is chosen, where D ij  jd ij (1)  d ij (0)j and dijC   P N n1 R in  R jn Iy n  C=  P N n1 Iy n  C for C 2 f0;1g, where R in is the rank of the ith gene in the nth sample. When a new test sample ~ x test  x 1 test ;...;x G test  is encountered in the future, the class prediction is determined byBy construction, the TSP classifier above is based on only one TSP (two genes) and the method can be very sensitive to slight noise perturbations (). To circumvent this issue, Tan et al.(2005) introduced kTSP to combine multiple TSPs for a more stable algorithm. The method identified the sorted TSPs similar to above. Instead of choosing only the best TSP, it selected the top K (K is a parameter to be tuned) TSPs to construct the model. The TSPs were selected from the sorted list such that the genes in the TSPs had no overlap otherwise the latter TSPs containing overlapping genes would be skipped and the next TSP in the sorted list would be considered. In other words, the selected top K TSPs always contain 2K distinct genes. Suppose fi 0 1 ; j 0 1 ;. .. ; i 0 K ; j 0 K g represents the K selected TSPs. The kTSP algorithm makes a prediction for a new test sample ~ x test by b C~ x test   argmax C P K k1 I b C i k j k ~ x test   C. In a sense, the k-TSP is an ensemble classifier that aggregates multiple weak classifiers by majority vote (). To avoid ties, we usually select odd numbers for K in binary classification. The TSP algorithms have the following advantages for omics prediction analysis: (i) The method is non-parametric since the method is constructed based on the relative ranking of gene pairs. Since different transcriptomic studies are usually conducted in different labs and in different platforms, the applicability of nonparametric nature facilitates cross-study validation that we aim in this article. (ii) The method is based on one or a few gene pairs. The biological interpretation of the model and the translational application are more straightforward. It is more likely to succeed by designing a reproducible commercial assay for wider clinical applications, such as the 21-gene RT-PCR-based Oncotype DX test for breast cancer (). (iii) Researchers have repeatedly found that the family of TSP algorithms provides good prediction performance in many transcriptomic data ().
Estimate K for kTSPTo estimate the best K in the kTSP algorithm, we will apply and compare the following two methods.
Cross-validation (CV) methodIn, leave-one-out CV was used to determine K in kTSP. In each iteration, one sample was left out as the test sample. The remaining samples were used to construct a prediction model and apply to the test sample. The procedure was repeated until each sample was left out as the test sample once. The cross-validated error rates were then calculated for different selections of K and the best K that produced the smallest CV error rate was chosen.
VO methodDefine the t-statistics of the target function:K is chosen by the value that maximizes t kTSP (i.e. K*  arg max K t kTSP ). The VO procedure greatly reduced high computational demand in CV. is encountered in the future, the class prediction by the k th TSP and study m is:
MetaKTSP algorithmsThe final meta-analyzed class prediction is determined byBelow we introduce the three meta-analytic approaches to select the top K TSPs. In meta-analysis, test statistics (e.g. it t-statistics) across studies are not comparable and combining P-values has become a popular practice. Under the null hypothesis that gene i and j are not discriminant, S m i;j can be well-approximated by Gaussian distribution SAlternatively, one-sided p-values can be calculated as Pfor right-sided P-value.
Select K TSPs by Fisher's method The Fisher's method combines P-values across studies byare the left and right one-sided P-values of discriminant score S m ij of gene i and j in study m. The modified one-sided corrected Fisher's statistic is T Fisher;OC ij) and with no overlapping genes are selected.
Select K TSPs by Stouffer's methodInstead of using log-transformation in Fisher's method, Stouffer's method applies an inverse normal transformation by T Stouffer ijUnder null hypothesis that gene i and j have no discriminant power in all studies, T ij $ N0; 1. The top K gene pairs with the smallest meta-analyzed two-sided P-values and with no overlapping genes are selected for prediction. Note that Stouffer's method has an advantage over Fisher's method that onesided concordance correction is not necessary if one-sided P-values are input in the inverse normal transformation.
Select K TSPs by mean scoreBecause the discriminant score is difference of two conditional probabilities, the scores are directly comparable across studies and can be directly combined. We define the mean score T mean ijis increasingly influenced as sample size rises. Therefore, it is worth to adjust sample size to the total discriminant score.
Estimate K for MetaKTSPSimilar to Section 2.2, cross-validation and VO methods can be extended to estimate K for MetaKTSP.
Cross-validationEach of the M studies are firstly split into V equal-sized subgroups. In each cross-validation, one subgroup of samples in each study is left out as the testing samples. The remaining (V  1) subgroups are used as training samples to construct the classifier and then apply to the test sample. We choose the optimal K such that the highest average Youden index over M studies is obtained. In this article, we adopted 5-fold cross-validation.
Variance optimizationMotivated by, we define the following target function:u t :
Results
SimulationsWe hypothesize that if gene pairs are consistently identified with strong TSP scores over multiple training studies such gene pairs outperform original TSPs from a single study. We tested this hypothetical argument using simulated data sets.Cross-study validation of omics prediction analysisR  cjm $ W 1 W; 60 for every gene cluster c and sample subgroup j of study m, where W  0:5I 2020  0:5J 2020 ; W 1 denotes inverse Wishart distribution, I is the identity matrix, and J is the matrix with all the entries being 1. Set vector r cjm as the square roots of the diagonal elements in R  cjm. Calculate R cjm such that r cjm R cjm r T cjm  R  cjm .(ii) We simulate two clusters of consensus predictive genes, each containing 20 genes. The first down-regulated gene cluster is generated from MVN 20 l a ; R 1jm , where sample u belongs to class j in study m and l a  0:8 for j  1 (controls) and l a  0:8 for j  2 (cases). This is a smaller effect size simulation. We also simulate a strong effect size simulation by l a  1 or  1 for controls and cases. Similarly, the second up-regulated gene cluster is simulated from MVN 20 l a ; R 2jm , where l a  0:8 and 0:8 for controls and cases in weak signal scenario and l a  1 and 1 in strong signal scenario. These 40 consensus predictive genes are the basis to aggregate predictive power across studies (red dotted rectangle in Supplementary).
Step 2. Simulate study-specific predictive genesWe next simulate four clusters (m 0  1,2,3,4) of study specific genes, each containing 10 genes. Each gene cluster has specific predictive power to the corresponding study m. The down-regulated genes are simulated from MVN 10 l b ; R 2m 0 ;j;m , where m 0  m; R 2m;j;m (1 m 4) are simulated similar to (1) of Step 1 and l b  4 or 4 for controls and cases. For up-regulated predictive genes, we randomly sample from MVN 10 l b ; R 6m 0 ;j;m and l b  4 or 4 for controls and cases. When m 0 6  m, the gene cluster m 0 has no predictive power in study m and is randomly sampled from N(0,1) (blue dotted rectangle in Supplementary). These study-specific genes are a main source of errors in cross-study validation.
Step 3. Simulate non-informative genesFinally, the remaining 80 non-informative genes are simulated by x m g;u $ N0; 1 for 121 g 200. We repeated simulations for 50 times, and the results are benchmarked by averaged Youden index.shows the simulation evaluation for different methods using Youden index, and we tested MetaKTSP (VO  mean) and MetaTSP (mean). In each meta-analysis evaluation, we take one study out as the test study, combine the remaining three studies to select the TSPs and construct the model, and finally use the model to predict samples in the test study. The result ofin the weaker signal setting (l a  1) shows that the MetaKTSP (VO  mean) method performed well (Youden Index  0.8570.865). The MetaTSP (mean) performed slightly worse (Youden Index  0.7340.752). In mega-analysis approaches, the three training studies are normalized and combined into one study to construct the prediction model and evaluate in the test study. In single study analysis, the accuracy was evaluated by averaging inter-study accuracy from each of the three training studies to the test study. The result of(l  0:8; weak signal scenario) clearly shows inferior performance of MegaKTSP and MegaTSP approaches, and poor performance of single study KTSP and TSP approaches. The single study SVM and mega-analysis of SVM also performed slightly worse than MetaKTSP inand B. Taken together, this confirms our hypothesis that prediction model from a single study may not be robust and accurate. Proper meta-analysis by combining multiple training studies improves the stability and accuracy of the model to predict an independent test study. Supplementaryand B contain simulation results of all meta-and mega-analytic methods in strong and weak signal cases. In the weaker signal case in Supplementary(l a  0:8), we found that MetaKTSP using Fisher's selecting approach often has inferior performance than Stouffer and mean methods. This is probably because of the nature of heavy tail logtransformation in the Fisher's method. A P-value close to 0 (e.g. 1E20) can contribute a very large score in Fisher's method and can easily dominate the analysis. The inverse transformation in Stouffer's method and the mean score approach somewhat alleviated the problem. From Supplementaryand B, it is evidently shown that MetaKTSP (mean) is superior (or equal at least) to weighted MetaKTSP (weighted.mean). Interestingly, even if the parameter for mean (l a ) decreases in value (10.8), the order of Youden Index largely remains the same. We conclude that MetaKTSP (VO  mean) generally outperformed the other methods, and so chose to apply this method in the following real applications.
Application to genomic data setsBelow we demonstrate application of MetaKTSP methods to three real omics examples of breast cancer expression profiles (1658 samples in seven studies), IPF expression profiles (IPF; 291 samples in six studies) and The Cancer Genome Atlas multi-cancer methylation profiles (TCGA, http://cancergenome.nih.gov/; 1785 samples in six studies). Supplementary Table S1 provides detailed data description of all 19 studies and their data sources. Genes and methylation probes were matched across studies. Non-expressed and/or non-informative genes were filtered according to the rank sum of mean intensities and variances across studies. Note that this filtering procedure has been used in a previous meta-analysis work () and the filtering is unbiased in the prediction accuracy estimate since class labels are not used in the procedure. This generated 3035 genes in breast cancer, 3010 genes in IPF and 3061 methylation probes in TCGA for down-stream prediction analysis. From simulation, VO feature selection method performed slightly better than CV method so it was applied to all TSP methods to determine K in real data. We tested Meta-KTSP (mean), MetaKTSP (Stouffer), and single-and mega-variations of KTSP and five popular machine learning methods, including linear discriminant analysis, CART, K-nearest-neighbor, random forest and SVMs. The complete result is shown in Supplementary Table S4.shows the inter-study prediction performance of selected methods of the three real examples (A, breast cancer ER versus ER prediction byexpression profiles; B, IPF versus controls prediction by expression profiles; C, cancer versus adjacent normal prediction by methylation profiles). Mega-SVM was the best performer among the five existing machine learning methods tested so we chose to present Mega-SVM and Single-SVM in. For single study analysis, we performed all pairs of cross-study validation and averaged the performance. For mega-analysis, each sample was standardized to mean zero and unit variance and multiple studies were merged for analysis. Finally, we aggregated Youden indexes of all studies using weighted average by sample size (last plot in each row). In, MetaKTSP (VO  mean) obviously best performed inter-study prediction of all three examples, whereas mega-analysis methods had worse performance and single study analysis without combining information across studies performed the worst. In the example of breast-and pan-cancer analysis, the performance of single study analysis was below random guess (Youden index < 0). This suggests that prediction models from single study analysis mostly reflected study-specific (cancer-specific) signature that could not be generalized to other cancers. In addition, to assess robustness of MetaKTSP (VO  mean), we performed 50 simulations of bootstrapped samples and applied Meta-KTSP and single study kTSP and calculated the degree of robustness by calculating the number of overlapping TSPs between bootstrapped data analysis and whole data analysis divided by the number TSPs detected by whole data analysis. Supplementaryand Supplementaryand B clearly showed greater robustness of MetaKTSP than individual study kTSP analysis in selecting top gene pairs. Supplementaryprovides further insight on this concept. In Supplementary, nine TSPs were selected in individual training studies (Breast invasive carcinoma, Colon adenocarcinoma, Kidney renal clear cell carcinoma, Lung adenocarcinoma and Stomach adenocarcinoma), respectively. When these TSPs were evaluated in the ovarian cancer (OV) study, the absolute discriminant scores dropped significantly, many of which dropped from close to 1 to below 0.5. On the contrary, the nine TSPs selected by metaanalysis shared universally large discriminant scores for all five training studies (Supplementary) and the discriminant scores were mostly maintained in the test OV study. SupplementaryC provides the full results of all 15 methods comparison in the 3 examples. It is interesting to note that Emblom and Larsson studies in the IPF examples had almost none predictive value (Youden index near 0), while the other four studies performed well. This argues that the two studies might have heterogeneous cohorts from the other four studies or they may have worse experimental quality [see similar quality control result in () for the same data sets].In practice, one may perform such CV to exclude potential 'outlier' studies before implementing MetaKTSP. Below we explore biological validation of detected gene pairs from MetaKTSP using existing literature. We first applied MetaKTSP (VO  mean) to all seven breast cancer studies and identified nine TSPs. For the 18 genes in the 9 detected TSPs, 12 of them were found to associate with ER expression in previous publications and all of them had consistent differential expression direction compared with the microarray data (). For the pan-cancer methylation result, we also identified 9 TSPs and 15 of the 18 genes have been previously indicated as cancer related (Supplementary). For example, the PCDH8 gene from the fourth gene pair was previously confirmed as a candidate tumor suppressor regulated by methylation in multiple cancers: (i) Kidney cancer: frequent promoter region methylation (58%) in primary renal cell carcinoma tumor samples (). (ii) Breast cancer: either mutation or epigenetic silencing in a high fraction of breast carcinomas inactivates PCDH8 that leads to oncogenesis in cancers () (iii) Stomach cancer: tumor suppressor function in gastric cancer ().
Conclusion and discussionAs high-throughput experimental data become more and more prevalent and publicly available, integrative methods to fully utilize information from the abundant multi-lab data sets have become critical. Generating predictive biomarkers and classification model from a single study often suffer from limited sample size and possibly study-specific biases. The resulting models are often found with poor performance in cross-study validation (). To improve translational and clinical utility of the biomarker discovery and classification model construction, combining information from multiple studies provide a promising opportunity. In this article, we seek to improve a TSP method that is a non-parametric, accurate and easily interpretable model that likely will succeed in cross-study validation for clinical applications. We developed three MetaKTSP approaches that combine multiple omics data sets to improve the credibility of TSP biomarker selection. Using simulations and real transcriptome and methylome data sets, we demonstrate its improved performance on cross-study validation. We compared two methods, CV and VO, to decide the number of TSPs used in the model construction. The result showed similar performance of the two model selection methods. Since VO does not involve repeated subsampling and is computationally faster, we recommend to use VO for future applications. There are a few limitations and future directions to consider. First, our method and evaluation focus on binary case-control classification. The method could be extended to multi-class classification scenario. Second, biological knowledge such as pathways or known disease relevant genes can be incorporated to enhance the TSP discovery accuracy. For example, Oncotype DX started with 250 breast cancer related genes to identify the 21 predictive genes in their panel. Although this runs the risk to miss understudied but significant biomarkers, this approach can potentially improve cross-study validation in well-studied diseases. Third, we may take into account the original differences across platforms to pursue more accurate meta-analysis. In particular, gene expression platforms may measure different genes on different scales. Therefore, it is worth to match up genes across platforms by mapping onto identical exon sites and probes. Finally, the current TSP approaches may be extended towards module-based prediction scheme where TSPs of gene modules are sought to provide extra redundancy and robustness (). The 'MetaKTSP' R package is available on the authors website and is part of MetaOmics, a software suite for omics data meta-analysis of differentially expressed gene detection, pathway, prediction, clustering, classification and network analyses.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
S.H.Kim et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
