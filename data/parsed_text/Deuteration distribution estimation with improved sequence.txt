Motivation: Time-resolved hydrogen exchange (HX) followed by mass spectrometry (MS) is a key technology for studying protein structure, dynamics and interactions. HX experiments deliver a time-dependent distribution of deuteration levels of peptide sequences of the protein of interest. The robust and complete estimation of this distribution for as many peptide fragments as possible is instrumental to understanding dynamic protein-level HX behavior. Currently, this data interpretation step still is a bottleneck in the overall HX/MS workflow. Results: We propose HeXicon, a novel algorithmic workflow for automatic deuteration distribution estimation at increased sequence coverage. Based on an L 1-regularized feature extraction routine, HeXicon extracts the full deuteration distribution, which allows insight into possible bimodal exchange behavior of proteins, rather than just an average deuteration for each time point. Further, it is capable of addressing ill-posed estimation problems, yielding sparse and physically reasonable results. HeXicon makes use of existing peptide sequence information, which is augmented by an inferred list of peptide candidates derived from a known protein sequence. In conjunction with a supervised classification procedure that balances sensitivity and specificity, HeXicon can deliver results with increased sequence coverage. Availability: The entire HeXicon workflow has been implemented in C++ and includes a graphical user interface. It is available at
INTRODUCTIONThe determination of protein structure and dynamics is a key issue for the understanding of living systems ().s: the isotope envelope shifts to higher m/z values because of deuterium incorporation. The deuteration content is encoded in a complex mixture of isotope distributions. Due to the noise and overlapping isotope clusters, the separation of individual peptides is non-trivial. The abundance of the spectrum is labeled as y.By combining the information of the protein dynamics and other classical functional data, a more complete understanding of protein function can be obtained. In many cases, protein dynamics are directly related to specific protein functions such as conformational changes during enzyme activation and protein movements during binding (). Hydrogen exchange (HX) followed by mass spectrometry (MS) (HX/MS) has become a standard approach for interpreting HX experiments: the location and rate of deuteration are indicative of solvent accessibility and in particular hydrogen bonding and hence of conformation and dynamics (). They can be estimated by tracking the mass shift of peptide fragments in mass spectra over samples with different incubation times () (). In comparison to nuclear magnetic resonance (NMR) spectroscopy, MS requires lower protein concentrations and amounts, provides higher measurement speed and better scalability in terms of protein size, and detects coexisting conformations (). Whereas manifold improvements in experimental methodology and instrumentation have been implemented for HX/MS experiments,Page: 1536 15351541
X.Lou et al.data processing still remains a major difficulty in the overall experimental workflow (). First, the precise deuteration distribution is represented by complex peak patterns that are difficult to separate and quantitate even in 2D liquid chromatography/MS (LC/MS) representation. Second, the peptide sequences of interest have to be pre-determined via MS/MS search report or selected empirically, yielding suboptimal sequence coverage of the protein of interest. Finally, manual analysis is time-consuming, error-prone as well as inaccurate in case of overlapping isotope clusters (). Several methods and tools have been developed to facilitate the manual analysis.modeled the deuterium incorporation as a binomial distribution and used  2 statistics to extract the optimal parameter. Weis and Engen () designed HX-Express as a semi-automatic data processing tool, which measures the deuteration by the width of the given isotope pattern. TOF2H () is an integrated software framework designed specifically for semi-automatic LCmatrixassisted laser desorption/ionization (MALDI) data analysis. Note that while the approaches mentioned above facilitate the analysis of HX/MS data, they do not yield the complete deuteration distribution, but only the average deuteration. The true deuteration distribution offers a more detailed characterization and more insightful description of the exchange process. In particular, it is suitable for discovering bimodal exchange behaviors of large protein oligomers, which are not detectable by average deuteration levels. The algorithms developed for extracting deuteration distribution information mainly fall into two categories. The first set of methods fit a hypothetical deuterated isotope pattern to the observed spectrum by least-squares regression (). They exhibit the advantage of speed but have difficulties in handling ill-posed problems, which, as shown in the following, are common in large-scale HX/MS data analysis. It is possible to make use of padding methods to regularize the ill-posed regression problem. Given the optimal degree of padding, this approach can address data truncation problems and avoid over-fitting to noise (). The second set of methods is based on maximum entropy deconvolution (). Those methods can handle ill-posed problems and yield non-negative outputs; however, they are computationally much more expensive (). One common limitation of these two categories is that they are designed for well-tuned and smallscale problems, i.e. the peptide sequence of interest is pre-selected in a well-separated spectrum, thus making them less applicable in practice, especially for large-scale HX/MS data processing. These methods have been implemented by several software tools such as Deuterator () and Hydra (). Both frameworks focus on incorporating existing algorithms and providing user-friendly graphical user interface and powerful visualization. We propose a novel algorithmic approach named HeXicon to the deuteration distribution estimation problem for large-scale HX/MS experiments. HeXicon exploits information in the retention time and m/z domains for optimized separation of large HX/MS data and applies Non-greedy, Iterative Template-based peak PICKer (NITPICK) () for LC/MS feature extraction, resulting in a robust and regularized estimation of the deuteration distribution. It integrates protein sequence and protein identification information in an attempt to increase the sequence coverage. Section 2 of the manuscript elaborates the methodological development of our approach. Sections 3 describes the experimental setup and reports the results, focusing on the novelty of delivering a robust estimate of the deuteration distribution and the comparison to manual analysis. Discussion and conclusion are offered in Sections 4 and 5, respectively.
METHODSAs illustrated in, our approach consists of two major modules that jointly carry out our goals of robust deuteration distribution estimation and sequence coverage improvement. Given a hypothetical set of peptide sequences inferred in peptide sequence set determination (A), the deuteration distribution estimation starts by constructing an over-complete set of basis functions (B) and then feeds them into the NITPICK algorithm to yield peak groups with features (C). Inter-experiment peak groups are then associated via correspondence estimation (D) and the deuteration distribution is derived for each association (E). The subsequent quality estimation of peptide sequence set determination retains the high-quality results, and thus balances the sensitivity and specificity (F, G). Our approach makes extensive use of the NITPICK algorithm, a regularized, non-greedy, globally optimal linear mixture modeling algorithm for feature extraction from multi-component mass spectra.
Deuteration distribution estimationDEFINITION. Let p be a peptide sequence of interest. The deuteration level k is the number of deuterium exchanges at the back-bone hydrogens of p. The deuteration distribution (p,k,) is the fraction of peptide with sequence p at deuteration level k for incubation time , where k {0,1,...,K(p)} and K(p) is the maximal possible deuteration level. The average deuteration (p,) is the average deuteration level of all peptides with sequence p at incubation time .
NITPICK algorithmWe formulate the deuteration distribution estimation as a regression problem. That is, the observed spectrum s is explained as a linear combination of constituent basis spectra, which represent a particular peptide. Each feasible basis spectrum is specified by one column of the regression matrix , and the regression coefficients  determine the abundance of those constituents in the mixture. If the matrix contains more basis functions than are actually present in any given mixture s, the regression problem is ill-posed and has to be constrained.showed that the introduction of a L1-constraint leads to a sparse solution vector , which assigns non-zero abundance only to those basis functions that are contained in the mixture with high probability. The resulting regression problem is is is = argminwhich can be solved with the same computational efficiency as an ordinary least squares problem by the least angle regression algorithm (). The regularization parameter  controls the model complexity based on the Bayesian information criterion (BIC;). The NITPICK algorithm () determines its value automatically so that the number of degrees of freedom in the model is matched to the observed noise level of s.
Basis function constructionAssuming that the peptide sequence set of interest P is known (see Section 2.2), the solution to the regression problem must lie in a space spanned by all deuteration levels of all peptide sequences in the set (). Thus, we build the basis function set by combining the theoretical isotope distribution for every deuteration level of each peptide sequence inPage: 1537 15351541where (p,k) is the transformation function that computes the basis function for peptide sequence p at deuteration level k (i.e. its theoretical isotopic spectrum) and K(p) the maximum number of exchangeable hydrogens (). To accommodate for the non-constant, m/z-dependent resolution (), we use a m/zdependent peak shape function and learn its parameterization from the data (see Supplementary Material).
HeXicon
Quantitative LC/MS feature extractionThis feature extraction procedure provides two key steps for the workflow: first, it selects a subset of basis functionsfunctions functions that optimally explain the observed spectrum and thus determines the peptide sequences of interest; and second, it extracts features of selected basis functions for the following deuteration distribution computation and correspondence estimation. We first apply segmentation techniques to achieve optimized separation of the LC/MS data, which yields better signal-to-noise ratio (SNR) and groups signals that belong to the same peptide. Manual analysis and some existing methods normally use a heuristic window-based approach for separating the LC/MS data. The integration of LC/MS peaks along the entire retention time window yields suboptimal SNR and fails in case of overlapping peak clusters (). Therefore, we integrate over retention time only within segments and are thus able to benefit from better SNR. The exact retention time position of the peptide is then determined via a sparse elution profile estimation on the LC/MS data segment (). Thereafter, to determine the ratio of different deuteration levels of the peptide sequence of interest, the abundance of their corresponding basis function (p,k) is estimated using the NITPICK algorithm (). The regression problem] is normally ill-posed because the basis function construction yields an over-complete set of explanatory variables. Also, NITPICK provides sparse solutions that represent a subset of the overcomplete basis function set that is indeed necessary to explain the observed spectrum.Eventually, for each incubation time , the feature extraction procedure outputs a list of peak groups G  , where a group g  corresponds to a certain segment and contains peaks with featureswhere m is the monoisotopic m/z position,  the abundance of the corresponding basis function, z the charge and t the estimated retention time.
Correspondence estimationThis step determines the correspondences between the peak groups over incubation time points and the peptide sequences of interest (). Given a peptide sequence p of interest, its zero exchange peak group is first determined by matching a measured peak to its theoretical m/z value,where f theoretical (p,z,k) computes the theoretical m/z of p at charge z and deuteration level k. The corresponding peak group at every other incubation time is determined by minimal weighted Euclidean distancwhere S is a diagonal matrix that normalizes and weights the contributions of different features to the distance measure. The matrix S is designed to express the characteristics of signals belonging to the same peptide sequence over incubation time. To speedup the computation, we also applied a filtering procedure to eliminate unlikely candidates by charge consistency and thresholding via retention time window and m/z accuracy cutoff (see Supplementary Material).
X.Lou et al.
Deuteration distribution estimationAfter determining the interexperiment correspondence of peak groups with respect to a peptide sequence of interest, its deuteration distribution can be derived as ()where the   g  (k) is the abundance of the basis function corresponding to deuteration level k. The average deuteration is merely the average of the deuteration distribution over all deuteration levels.
Peptide sequence set determinationTo perform complete deuteration distribution estimation for the entire protein, optimized protein sequence coverage is desirable. We achieve this goal by extending the peptide sequence set via sequence search and later using a supervised classification approach to discard incorrect or ambiguous peptide sequences.
Unsupervised peptide sequence inferenceWe use a two-step procedure to infer possible peptide sequences directly from the observed spectrum and from prior knowledge (i.e. the protein sequence and the MS/MS report). We first perform peak picking on the observed spectrum using the NITPICK algorithm. In a second step, the picked monoisotopic masses, for which no MS/MS identifications are available, are matched to theoretical peptide sequences extracted from the known protein sequence. Eventually, a list of candidate peptide sequences is generated, which consists of peptide sequences from two sources: peptides that are identified by MS/MS data and peptides that are extracted by searching the protein sequence for subsequences with a mass proximate to the picked peaks.
Supervised quality estimationThe unsupervised peptide sequence inference procedure exploits information without sufficient concern for multiple assignments of peptide sequences to the same peak or peptide sequences hallucinated from noise peaks. Despite the fact that this apparently improves the system's sensitivity, the payoff is a reduced specificity, i.e. false positives are mixed into the peptide sequence set. Therefore, HeXicon implements a quality estimation procedure to recover reasonable specificity while maintaining high sensitivity. We tackle this problem using a supervised classification approach: given training data {x,q} where x  X is the quality feature vector and q  Q is the quality label, train a classifier h : X  Q that maps x to its estimated quality q. In particular, we use the random forest classifier (), a supervised, decision-tree based ensemble learning method with high prediction accuracy and little sensitivity to the hyper-parameter settings (). A representative dataset was selected as training data and each reported peptide sequence was labeled with a quality score q {3,2,1}, in which 3 represents highly confident results, 2 indicates ambiguous results, i.e. unidentified peptide sequence resulting from multiple assignment to the same peak and 1 contains all results containing no useful information. The quality features x are designed to characterize the quality of a peptide sequence from several different aspects. See Supplementary Material for a full list of quality features. Retraining is necessary for different instruments.
RESULTSHeXicon has been evaluated on two protein datasets of different complexity (): C-terminus of Hsp70 interacting protein (CHIP) and high-temperature protein G (HtpG). In each experiment, protein samples were first incubated in heavy water to induce a certain amount of exchange before being subjected to pepsin digestion. To identify peptic peptides from the investigated proteins, we digested the undeuterated protein under the same conditions as later used for the exchange experiments. We then analyzed the peptic peptides by automated MS/MS using a 1 h acetonitrile gradienteither on a nanoLC-QSTAR MS system (CHIP, HtpG) and on a nanoLC-Orbitrap MS system (HtpG). Subsequently we determined, which of the identified peptides could be found consistently on the HPLC-QSTAR MS system using a 10 min acetonitrile gradient.Both datasets have been processed manually, yielding average deuterations for selected peptide sequences that we use as ground truth. Segment retention time extensions are between 20 and 50 s.
Deuteration distribution estimationFor the CHIP spectra in, HeXicon provides a sparse and condensed estimation of the deuteration distribution that exhibits smoothness along the deuteration levels, as shown in. For comparison, we created a well-posed regression problem by constructing basis functions for the corresponding peptide CIEAKHDKYMADM and applied the non-negative leastsquares regression based method described in. We optimized the degree of padding by manually estimating the maximal deuteration level, yielding a solution very similar to the HeXicon's, see. Without optimizing the degree of padding, i.e. padding to the theoretically maximal possible deuteration level, Chik's approach selects several spurious basis functions due to overfitting.shows a mixture of signals from two peptide sequences: AAERERELE and IAKKKRWNSIEER. HeXicon yields condensed deuteration distributions for both peptide sequences, as shown in. After padding optimization, Chik's approach gives a similar distribution for AAERERELE but the estimate for IAKKKRWNSIEER is questionable, see.
Sequence coverage enhancementCombining MS/MS identifications and inferred peptide sequences, HeXicon yields an apparent improvement on the number of extracted peptide sequences with concomitant increases in sequence coverage when compared to the manual analysis (). For the manual analysis, we only used those peptides identified that we could find consistently in the 10 min gradient runs on the QSTAR system.
Exchange rate inferenceThe deuteration distribution estimated by HeXicon can easily be transformed into an average deuteration estimate  H (p,) by computing the empirical mean. We validated HeXicon by comparing its average deuteration estimate to the manually obtained average deuteration estimate  M (p,). We applied two metrics to measure the accuracy: (i) the average m/z difference m is computed by
AB a b c r. Comparison of deuteration distribution estimation for overlapping patterns. Overlapping patterns consist of AAERERELE and IAKKKRWNSIEER (A). HeXicon yields condensed and smooth solutions for both peptide sequences (Ba). Even with padding optimization, Chik's approach overfits the spectrum and yields an unrealistic deuteration distribution for IAKKKRWNSIEER (Bb). Without padding optimization, Chik's approach selects more spurious peaks (Bc). Here, (p,k) indicates the maximum peak position of the basis function of peptide p at deuteration level k.where  is the exchange rate inferred by fitting the average deuteration to the HX kinetic model function (). Since the fitting is nonlinear and non-convex and since its first-and second-order derivatives could be derived analytically, we applied. Comparison of the exchange rate inference between manual analysis (dash) and HeXicon (dot) for selected examples. While the estimate by HeXicon coincides well with the manual analysis for the peptides displayed on (A), (B) and (C), the estimate for LRELISNASDAADKLRF (D) is incorrect due to under-segmentation of overlapping peptides in the LC/MS spectrum. a generalized Newton method to approximate the optimal solution (see Supplementary Material). For the CHIP dataset and 20 of 21 manually selected peptide sequences, the estimates by HeXicon coincide well with the manual analysis (see examples inand B), yielding an average m/z difference of 0.06880.0307 Da (mean  SD) and a relative exchange rate difference of 0.09940.0847. For the HtpG dataset, HeXicon correctly estimates the average deuteration for 32 of 39 manually selected peptide sequences and yields an average m/z difference of 0.0578  0.0339 Da and a relative exchange rate difference of 0.1205  0.0958 (e.g.). For the remaining seven manually selected peptides, the estimates are inaccurate (e.g.). The complete list of peptide sequences and their average deuteration is given in the Supplementary Material.
Quality filtering accuracyThe quality estimation step aims at identifying high-quality results and discarding the remaining results. We measure the cross validation performance of this step using common criteria from Page: 1540 15351541information theory: recall, precision and F-score. The results given inindicate that the quality estimation step is accurate and generalizes well across datasets, providing an F-score over 90%.
X.Lou et al.
Runtimes and implementationHeXicon has been implemented in C++ and the compiled software is available at http://hci.iwr.uni-heidelberg.de/software.php. As indicated in, HeXicon strongly reduces the analysis time compared to manual analysis. Since HeXicon is fully automated, it does not require any real-time user-interaction. Experiments were carried out without replicates. To perform replicate analysis, HeXicon results need to be obtained separately for each replicate and subsequently aggregated. The software package requires the spectrum data as mzXML files and other information (i.e. the protein sequence and the MS/MS search result) as plain text files. Comma-separated values files are the output.
DISCUSSIONAs shown in Section 3.1, to avoid overfitting Chik's approach requires padding optimization by user-input or pre-processing. The reason is that the least-squares regression attempts to use each predictor without any restriction, and thus overfits the data and causes several spurious basis functions to be selected, as shown in(marked by ''). The proposed approach benefits from the sparsity of the L1-regularization and discards those spurious deuteration levels automatically, and thus requires no additional processing such as thresholding or any further user interaction. This overfitting problem becomes worse when overlapping patterns occur. As shown in, Chik's approach (with padding optimization) gives a reasonable distribution for AAERERELE, but yields an unrealistic estimate for IAKKKRWNSIEER, i.e. the large gaps between neighboring deuteration levels. HeXicon, on the other hand, keeps the intrinsic smoothness and sparsity of the deuteration levels. Although the estimate for the lowintensity IAKKKRWNSIEER is subject to low SNR, it is still represented by a compact deuteration distribution at the most relevant positions and appears to be physically reasonable. While maximum entropy deconvolution based methods () might theoretically be appealing, they are not applicable to the problem since they require a pre-defined noise level (), which is usually not available to the users and may vary among different m/z regions or experiments. Further, these approaches are prone to overfitting and are computationally expensive (). The improved sequence coverage provided by HeXicon is particularly helpful to gain a more complete and detailed understanding of a dataset. Due to under-segmentation of crowded regions in the LC/MS data, HeXicon did not recover all manually selected peptide sequences from the HtpG dataset, but it still managed to yield a higher sequence coverage because other peptide sequences were selected to compensate for the missing ones. Further, as shown in, HeXicon finds more than twice the number of peptide sequences selected by human experts, which allows exchange behavior prediction in finer regions. For instance, the estimation of exchange rate at positions 279284 can be inferred from both HLQRVGHFDPVTRSPLTQEQLIPNL (position 259284) and HLQRVGHFDPVTRSPLTQE (position 259278). Since we only considered those HeXicon results with the highest quality score for the computation of the sequence coverage, this number can be regarded as a conservative estimate. Additional lower quality results provided by HeXicon can guide users towards further targeted experiments. For instance, ambiguous results, when multiple peptide sequences could be assigned to the same spectrum, might motivate additional MS/MS run on specific peptide sequences of interest, and thereby allow further improvement on the sequence coverage.
The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 1535 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
CONCLUSION In this article, we introduced HeXicon, a novel algorithmic workflow for the robust estimation of deuteration distributions with increased sequence coverage for HX/MS experiments. Comparisons to previous methods showed that the L1-regularization adopted in our method provides a sparse estimation of deuteration distributions and avoids over-fitting. The overall sequence coverage is increased by inferring peptide sequences from prior knowledge, and the tradeoff between sensitivity and specificity is balanced using a supervised classification procedure. In comparison to manual analysis, we showed that HeXicon succeeds in accurately extracting the deuteration content while improving sequence coverage and reducing analysis time.
