Motivation: The problem of ab initio protein folding is one of the most difficult in modern computational biology. The prediction of residue contacts within a protein provides a more tractable immediate step. Recently introduced maximum entropy-based correlated mutation measures (CMMs), such as direct information, have been successful in predicting residue contacts. However, most correlated mutation studies focus on proteins that have large good-quality multiple sequence alignments (MSA) because the power of correlated mutation analysis falls as the size of the MSA decreases. However, even with small autogenerated MSAs, maximum entropy-based CMMs contain information. To make use of this information, in this article, we focus not on general residue contacts but contacts between residues in-sheets. The strong constraints and prior knowledge associated with-contacts are ideally suited for prediction using a method that incorporates an often noisy CMM. Results: Using contrastive divergence, a statistical machine learning technique, we have calculated a maximum entropy-based CMM. We have integrated this measure with a new probabilistic model for-contact prediction, which is used to predict both residue-and strand-level contacts. Using our model on a standard non-redundant dataset, we significantly outperform a 2D recurrent neural network architecture, achieving a 5% improvement in true positives at the 5% false-positive rate at the residue level. At the strand level, our approach is competitive with the state-of-the-art single methods achieving precision of 61.0% and recall of 55.4%, while not requiring residue solvent accessibility as an input. Availability:
INTRODUCTIONThe problem of ab initio protein folding is one of the most difficult in modern computational biology. The prediction of residue contacts within a protein provides a more tractable immediate step, and these contacts can be used as a guide to generate the tertiary structure of the protein. Correlated mutation (CM) methods, first pioneered by Valencia and colleagues (), take a multiple sequence alignment (MSA) profile of evolutionarily related proteins and attempt to predict residues that have co-evolved. If residues have co-evolved, this may imply proximity in the native structure. For example, if a small residue increases in size by mutating, a proximal residue may have to reduce in size to retain the viability of the fold. Many CM methods have been developed using Pearson correlation coefficients (), adaptions of Mutual Information (), perturbation methods () and Dynamic Bayesian networks (). A recently developed correlated mutation measure (CMM), the direct information (), is a global measure that is derived from modelling the entire MSA, specifically defining the probability of each sequence being a member of the MSA. This distribution shares the same low-order moments as the MSA, and the maximum entropy principle () is used to fully specify the distribution.have used this measure to successfully aid the folding of a diverse range of proteins. However, like the majority of CM studies, these authors focused on a small number of proteins for which there is a large high-quality MSA because all CMMs suffer as the size of the MSA decreases (). A key distinction of this work is that we focus on a wide selection of proteins that have a variety of sizes of MSAs. We also automate the generation of MSAs and do not rely on a large high-quality MSA being available. In an attempt to improve the power of CM methods, the Dynamic Bayesian network of Burger and van Nimwegen (2010) incorporates primary-sequence distance into an informative prior for the model. The incorporation of this knowledge substantially improves the results. Inspired by this, we have chosen to predict the lateral pairs of residues in interacting-strands,-contacts, using a CMM.-contacts are associated with strong constraints, for example, sequential pairs of residues form-contacts and residues can only be in-contact with up to two other residues. These constraints mean-contacts are ideally suited for prediction using a CMMthe noise associated with the CMM is compensated for by incorporating the strong-contact constraints. The prediction of-contacts can be used to aid tertiary structure prediction (), explore energy landscapes (), in designing proteins () and understanding protein folding pathways (). *To whom correspondence should be addressed.We highlight BetaPro, the work of, which uses a three-stage method to predict-topologies and was the first method to take into account the global nature of-topologies. Firstly, a 2D recurrent neural network is used to generate a residue-level pairing map. Secondly, a dynamic programming algorithm is applied to this map to derive strand-level pseudo binding energies and finally, a graph matching algorithm is used to predict strand contacts. There are a variety of other existing methods for-contact prediction. They include the use of statistical potentials (), information theoretic approaches (), integer linear optimization (), hybrid neural network-probabilistic models () and Markov logic networks (MLNs;). In this article, we have developed a global probabilistic model for-contact prediction, inspired by the secondary structure models of Schmidler (2002), which can be used to predict both residue-and strand-level interactions. We have integrated this model with a CMM, similar in nature to direct information, and using this model on a standard dataset, significantly outperform the recurrent neural network of BetaPro and are competitive with the best single methods currently available. Unlike these methods, our approach does not require additional information such as residue solvent accessibility to be entered as an input to the model. In common with other methods, we assume the native secondary structure is known. However, our framework can be easily extended to predict both secondary structure and-contacts simultaneously, and this is the focus of our current work.
METHODS
Data setIn this work, we use the set of 916 proteins from Cheng and(CB916). The proteins share no 41520% sequence identity, and the set consists of 187 516 residues, of which 48 996 are strand residues, which are involved in 31 638-contacts. Most CM analysis procedures focus primarily on proteins for which there is a large good-quality MSA, often a large PFAM alignment (). We wanted to develop a method that will take advantage of this information where it exists, and yet is applicable even if the CM analysis is not useful, or indeed there is no MSA, which can be the case for newly sequenced proteins, such as those selected as targets in the Critical Assessment of Techniques for Protein Structure Prediction (CASP) community-wide experiment. Therefore, our method of generating MSAs is extremely general. We generate MSAs following a similar method to. For each sequence, we run PSI-Blast () for two iterations (Evalue  0.005) against the Non-Redundant database, keeping all sequences that share at least 30% identity to the profile constructed after the first PSI-Blast iteration, similar to the procedure recommended in. We then perform a globallocal alignment using GLsearch () to trim the sequences PSI-Blast found. We then use CD-Hit () to cluster the trimmed sequences at the 98% threshold and use Muscle () (maxiters  2) to generate MSAs. Finally, we removed columns of the MSA that were gaps in our target sequence and any row that contained 433% gaps. There is an enormous variation in the number of sequences in the alignments: six proteins have no homologues, one-fifth have 5100 homologues and 7% have 42000 (see).
Maximum entropy-based CM measureCMMs based on maximum entropy modelling (also called Direct Coupling Analysis) () aim to distinguish between direct and indirect correlations. Direct correlations arise owing to proximity in the native structure of the protein and are of primary interest in contact prediction; indirect correlations are caused by other reasons, such as the fact that correlations are transitive, and are the cause of the poor performance of many CMMs. The idea is to model the entire family of evolutionarily related proteins, assigning probability mass over all possible (fixed-length) sequences, including those that have not been observed. From this global model, measures can be developed to model the strength of the direct correlations between pairs of residues. This idea is formalized below. Given an MSA containing M sequences for a protein of length N, we define f i A i  as the observed frequency of residue A i occurring in position i of the MSA and f ij A i , A j  as the observed frequency of both residue A i occurring in position i and residue A j occurring in position j of the MSA. Given any sequence A  A 1 , A 2 ,. .. , A N , we model the probability of it occurring in the MSA by a distribution PA  PA 1 , A 2 ,. .. , A N  However, there are q N possible different sequences (where q is the size of the alphabet of amino acids) and only M ( q N sequences in the MSA. The sparsity of the data and the number of sequences imply that it is impractical for detailed use. However, we would like our model to match the empirical low-order moments given by the MSA. Specifically we would likewhere P i : is the marginal distribution for position i and P ij :, : is the (joint) marginal distribution (We have not added pseudo-counts or weighted sequences) marginal distribution of positions i and j (we have not added pseudo-counts or weighted sequences). Among the valid distributions P satisfying these constraints, using the maximum entropy principle (), we favour P, the distribution that has maximum entropy, S:and solving this optimization problem using Lagrange multipliers leads to the distribution PA 1 ,. .. , A N  / exp  X 1 i j N e ij A i , A j   X 1 i N h i A i  " # for some pair-interaction energies e ij A i , A j  and local fields h i A i  (). See the Supplementary Data for further details.The maximum entropy distribution can be viewed as a Potts model on an underlying complete graph, where the nodes represent the residue positions, the 'spins' correspond to the amino acid types and the edges describe the pairwise interactions, whose strengths are described by the pairwise interaction energies e ij. A related model for protein families, using Markov random fields (), can also be viewed as a Potts model. However, instead of the underlying graph being complete, an optimal subgraph is chosen that aims to fully explain the correlations and conditional independencies within the underlying protein family. To generate the maximum entropy distribution P, we use a statistical machine learning technique, contrastive divergence (). This work represents the first application of this approach to the modelling of protein MSAs. For a given set of e ij A i , A j  and h i A i , we use contrastive divergence to approximate the marginal distributions P i : and P ij :, : and use gradient descent to update e ij and h i. We iterate this procedure to convergence. For a protein of 75 residues, the procedure takes $10 minutes on a single core of an Intel Core i7 processor, and for a protein of 350 residues, the procedure takes $2.5 h. Further details are found in the Supplementary Data. Once we have calculated the distribution P, we define our CMM, D. For each pair of residues (i, j), we define Di, j as follows:This is a modified version of the Direct Information previously used to predict protein contacts (). The Direct Information measure itself was tried but produced slightly poorer results than D. See the Supplementary Data for more details. To show the power of D, for each protein in the dataset, we took the top N/2 ranked Di, j, where N is the length of the protein (we remove those for which ji  jj 4 from the analysis) and calculated the contact ratio: the proportion of these pairs of residues whose C distance is 8 A . The contact ratio versus logM is shown in(Top).(shows the average C distance of these N/2 predicted contacts. These figures show that there is a lot of information contained within D, especially as M increases. However, using randomly chosen contacts of known structures, it has been shown that one needs around a quarter to two-fifths of contacts to be able to successfully regenerate the native structure ().have shown that if a protein has a large number of sequences in its MSA, then maximum entropy-based CM analysis, together with predicted secondary structure is enough to successfully reconstruct the tertiary structure of the protein. In these articles, the authors take the highest-ranked correlated pairs of residues to be incorporated into distance constraints used to generate initial all-atom conformations of the protein. Simulated annealing, relaxing these distance constraints throughout the simulation, is then used to generate final three-dimensional structures. However, as shown by Figures 1 and 2, a large number of proteins have only a small MSA and CMMs by themselves are unlikely to be able to provide a large enough number of contacts to successfully fold the protein. For example,restrict their attention to proteins whose MSA has at least 1000 sequences, and usually significantly more. Nevertheless, even an alignment with M  e 6 % 400 sequences produces an average contact ratio of $0.15, which still contains lots of information (for an average protein, the contact ratio for randomly chosen contacts is $0.03). In contrast to these other studies, we investigate whether one can make use of this evolutionary information. We propose to use D to improve the prediction of-contacts, for which there is a large amount of structural knowledge, which can be incorporated as prior beliefs within a Bayesian statistical framework. The following sections describe the new-strand Bayesian model we have developed and how we couple Di, j to it.
b-Topology modelGiven a primary sequence R  fR 1 , R 2 ,. .. , R N g and its secondary structure S  fS 1 , S 2 ,. .. , S N g, where S i is the secondary structure of residue i, residues R i and R j are defined to be a-contact if they are a lateral pair within two interacting-strands. For example, in, residues 6 and 53 are a parallel-contact and residues 44 and 53 are an antiparallel-contact. We define I to be the set of-contacts. Specifically i, j, 1 2 I if residues R i and R j are a parallel-contact, i, j,  1 2 I if residues R i and R j are an antiparallel-contact and i, j, 0 2 I if either residue R i or R j is an isolated-bridge. We say i, j 2 I if i, j, 1, i, j, 0 or i, j,  1 2 I. The general framework we are using (from) allows inference for S and I given R. Following the Bayesian method, we require a prior PS, I  PI jSPS and a likelihood PRjS, I. Using Bayes' theorem, these yield the posterior of interest PS, IjR / PRjS, IPS, I. In this work, we assume the secondary structure is fixed. Specifically PS  1, if S is the secondary structure assignment given by DSSP ()we map residues labelled E and B to E, strand residues, and all other labels to C, non-strand residues. For clarity we suppress the dependency on S, i.e. PI jS  PI . A focus of our current work is to extend the model to allow joint inference for S and I .Definitions: Viewing I as a collection of individual residue contacts does not easily allow the incorporation of the structure of-contacts into a model; therefore, we model I as a set of interacting strand segments, following (). The set of residue contacts in I can be uniquely determined by specifying which strand segments interact and for each pair of interacting strands specifying their direction, alignment and position of any bulges. We formalize these terms below. The strand residues of a protein can be represented as a set of distinct strand segments (For some proteins, DSSP defines two separate strand segments immediately adjacent in sequence. For example 'EEEB'. For a fair comparison with BetaPro we define a strand segment as a contiguous block of strand residues. However, this is not necessary for our model). For example,shows 4 strand segments (E 1 ,E 2 ,E 3 ,E 4 ). In this protein, there is a single sheet, and in this simple case, the strand interactions can be described by a permutation of the set of strand segments. Specifically 1, 2,. .. , m  1, 2,. .. , m and implies segment E r and E r1 interact for r  1, 2,. .. , m  1. In, 1, 2, 3, 4  3, 4, 1, 2. In more complicated cases, the sheet structure cannot be described by a permutation. For example, if there is more than one sheet, if strands are involved in more than two interactions or if there is a cycle (for example in-barrels, where every strand interacts with two partners). Following the terminology in (), we say there is a jump between segments E r and E r1 if E r and E r1 are not interacting. In, there is a jump between segments E 2 and E 3 and no other jumps. We define the jump pattern J as the set of r for which E r and E r1 are not interacting; in, the jump pattern J  f2g. See(ad) for further examples of and J. We introduce d rs to describe the direction of interaction, specifically d rs  1 if interacting segments E r and E s are a parallel strand interaction and d rs  1 if the segments are antiparallel. In, d 34  d 12  1 and d 14  1. If either E r or E s is an isolated-bridge, then d rs  0. The variable a rs is used to define the shift between strands. For parallel interactions, a rs describes the shift between the final residues of both strands. For example, in, a 14  0 because 8, 55 2 I. If E 1 was shifted up by one residue, so that 8, 54 2 I, then a 14 would equal 1. Conversely, if E 1 was shifted down by two residues, so that residue 6, 55 2 I, then a 14 would equal 2. For antiparallel interactions, a rs describes the shift between the end of the strand earlier in the sequence and the beginning of its interacting partner (i.e. between residues 8 and 13 for a 12 in). Restricting the number of bulges to at most one per-strand interaction (which is the case in 98.6% of cases), we can define b rs  0 if there is no bulge or b rs  k if residue k is the-bulge. There are no bulges in the sheet shown in.shows the values of fd rs , a rs , b rs g for different interacting segments.Prior for I , PI : There is a huge amount of structure in-topologies and the challenge for a Bayesian statistician is to try and capture this while being able to efficiently calculate posterior probabilities and not overfitting the model. Rather than aim for the most probable-topology, we calculate Pi, j 2 IjR, producing a probability contact map, analogous to the output from BetaPro's Neural Network. Unlike other statistical models (), we do not take the output from BetaPro's Neural Network as an input to our model. We take advantage of the framework of Bayesian inference, which allows us to exercise our scientific judgement and experience concerning parameters that we expect to be of particular importance, and by specifying how these are plausibly related. We model the interacting-strands as a single sheet defined by a permutation , as described above. Although our approach does not model more than one sheet per protein, we can predict multiple sheets (see). More complicated models involving partitioning the segments into different sheets were tried, but these did not improve the results. We only allow a single bulge per strand interaction. Our prior is defined asPdwhere the product is over all segments E r and E s that are interacting, given permutation , and we have suppressed the dependence of everything on the secondary structure S. The set f, d rs , a rs , b rs g gives a unique set of residue contacts i, j 2 I, and if I cannot be described by a set f, d rs , a rs , b rs g, then PI   0. We define the distance rs as the number of residues between segments E r and E s. For example, in, 12  4, and we define l r as the number of residues in segment E r. P: The probability of a specific permutation depends on all the distances rs and the lengths of all the strands l r. However, incorporating all this information leads to an exponential number of parameters. In the dataset, 50% of interacting strands are adjacent in sequence (and 42% of adjacent strands are interacting), so one of the most important things we would like the distribution to capture is whether adjacent strands are in contact. For these reasons, in our 4, 1, 3, 2, J  f1, 3g; (d)  2, 4, 1, 3, J  f1, 2, 3g. (ei) Examples of different fd rs , a rs , b rs g: (e) f1, 0, 0g; (f) f1,  1, 12g; (g) f1, 1, 0g; (h) f1,  4, 0g; (i) f1, 0, 15g model, all that share the same jump pattern J are equally likely, and the probability Pr 2 Jj rr1 , l r , l r1  is independent for each r. Pr 2 Jj rr1 , l r , l r1  is taken from the training set by counting occurrences. For small l and , we take values directly from the training set, and for larger l and , owing to sparsity of data, we collapse the data into a small number of bins. We added a pseudo-count to smooth the data from the training dataset. If either l r or l s  1, then Pd rs  0  1, otherwise Pd rs  1j rs  is a piecewise linear function of rs , fitted from the training set. Pa rs jd rs : There is an inherent asymmetry in our definition of a rs ; in the case of parallel strands, we are measuring the shift from a perfect alignment of the ends of the segments, not the beginnings. In proteins, it is found that the shift measured from a perfect alignment of at least one end of the segments is small. Compare a rs for Figures 4(hi). Previous work has not taken this into account (), which leads to a drop in performance. Therefore, we model Pa rs jd rs  as a mixture (equally weighted) of the distributions P drs a rs  and P drs  ^ a rs , where ^ a rs is the shift required from aligning the beginnings of the segments to get the same residue contacts as a shift of a rs produces from aligning the ends of the strands. These distributions are taken from the training set. An analogous procedure is followed for the antiparallel case.Pb rs 6  0jd rs , a rs   Pb rs 6  0 is taken from the training set, and if there is a bulge, there is a uniform probability over all residues involved in the interaction that they are a bulge (hence the dependence on d rs and a rs to know which residues can be the bulge).where the joint likelihood LR i , R j jd ij  is approximated from the limited training set by the product of the conditionals, PR i jR j , d ij  and PR j jR i , d ij , where P:jR j , d ij  is the distribution of amino acids in contact with the residue type of R j in the direction of d ij. jI j is the number of contacts and jEj is the number of-residues. The distributions P:jR j , d ij  are taken from the training set, and u and v are constants to be determined. We have chosen this likelihood because of its simplicity. More complicated dependencies, such as letting R i depend on R jAE1 , were tried, but did not noticeably improve the results. We include a gamma distribution on the number of contacts into the likelihood because, without this term, the likelihood is a product of 2jI j numbers smaller than one, and so actively penalises against contacts. We include jEj so that the mean and variance of the gamma distribution depend on the number of-residues, which allows the model to control the total number of contacts. This is important as jI j and jEj are strongly correlated. The constants u and v were fitted using an empirical Bayes approach, and set to 18 and 12, respectively. See Supplementary Data for more details.
Integrating CM measure with the b-topology modelIn this work, we perform inference on both the posterior distribution P 1 I jR / PI PRjI  and, by adapting the concept of a 'product of experts' (), on a distribution that couples Di, j to the-topology model. A product of experts allows different probabilistic models of the same data to be combined together by multiplying the probabilities together and renormalizing. An advantage of this method is that each model ('expert') can focus on different aspects of the underlying problem, and that regions of space with high probability mass must satisfy each of the experts, owing to the multiplication of their probabilities. A product of experts has been successfully used for secondary structure prediction (), where there were separate experts for segmental dependency and strand and helical capping signals. In the present case, we have a distribution for inference of I given strand pattern P 1 , and a distribution for inference of I given D, a distribution proportional to exp!D, I, described below. Adapting the idea of a product of experts distribution, we use a product of distributions P 2 I jR / P 1 I jR exp!D, I. When P 2 I  is large, I must satisfy both the strand pattern model of P 1 and the CMM exp!D, I: (Formally, P 2 I jR  PIjR, D / PI jRPI jD and PI jD  exp !D, I   = P i exp !D, I i    where the sum is over the (finite) set of possible I i .)Correlated mutation measure, exp!D, I: As previously described, Di, j is a measure of how strongly residues in columns i and j co-vary, and a large Di, j suggests residues in columns i and j have co-evolved, and may imply a-contact between R i and R j. This information can be incorporated into the inference as a CMM exp!D, I. The better I and Di, j fit the larger the value of !. The formal description of ! follows. We define ; i  j : R j is a residue in a different strand to residue R i :As a concrete example,shows a protein with three strands, residues 35, 1214 and 2325, where, for example, ; 4  f12, 13, 14, 23, 24, 25g and ; 23  f3, 4, 5, 12, 13, 14g. In-sheets, the side chains of residues j and j AE 2 are near each other in space, and so if Di, j AE 2 are large, this may also imply a contact between R i and R j. For a particular set of contacts I and residue R i , we define the score i, I as the mean of the set fDi, j : j 2 I i g wherefj  2, j, j  2g otherwise (As a concrete example,shows a specific instance of I , and in this case I 5  ; 5 , I 4  f12, 14, 16g and I 13  f1, 3, 5, 22, 24, 26g. The larger i, I the better D and I fit for residue R i. However, for different residues R i , the mean and variance of the set of values fDi, j : j 2 ; i g differ wildly and so i, I needs to be standardized before being used. For this standardization we take the sample mean i and standard deviation i of the set fDi, j : j 2 ; i g. So the standardized score, for residue R i and interaction set I is then defined asDefining I native as the crystal structure-contacts defined by DSSP,shows the empirical distribution of Zi, I native  over all residues involved in at least one-contact from the dataset. A much larger mass has positive score than a negative score, implying native contacts have, on average, a larger value for Z. We then definewhere the sum is over all i for which R i are strands and M  number of sequences in MSA; so that proteins with larger MSA attach more importance to !.
RESULTS AND DISCUSSIONWe performed 10-fold cross validation using the same folds as Cheng and Baldi (2005). To estimate posterior probabilities, we used importance sampling. We generated 1 million independent samples from the prior PI, fI g and use these to generate a probability contact map:Ii, j 2 Iwhere I is the indicator function and PRjI  is the likelihood described above (in the case with the CMM we replace PRjI  by PRjI  exp!D, I. See Supplementary Data for further details. We repeated this 50 times and took the mean of the 50 values to generate a single result.We first quantify the effect of incorporating the CMM into our model. We can take the output of our model and discretize the results, taking as our-contacts, all (i, j) such that Pi, j 2 IjR is larger than a threshold value. Taking different threshold values,shows the receiver operating characteristic (ROC) curve for-contacts using both the posterior without the CMM P 1 (dashed) and the model using the CMM P 2 (solid). Using the CMM has significantly improved the results. For example, there is a 10% improvement in the number of true positives at the 5% false-positive rate.clearly shows that we have successfully used the evolutionary information, shown to exist in Figures 2 and 6, to improve the prediction of-contacts. We can also compare our model with existing-contact prediction methods. For example,shows a comparison with the Neural Network output of the first stage of BetaPro. The results quoted are AUC (Area Under Curve), the true-positive (TP) rate at 5% false positives (FP), TP at the break even point (BEPwhen the total number of predicted-contacts is equal to the true number of contacts) and the correlation coefficient TPxTNFPxFN= ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi TPFNTPFPTNFNTN FP p at the BEP. This table shows that without the CMM, we produce poorer results than BetaPro. This is to be expected as P 1 is a single sequence method, in contrast to BetaPro that inputs the whole MSA into its neural network. The addition of our CMM improves our method, producing better results than BetaPro. Unlike some existing models, including BetaPro, our model is completely probabilistic, which enables us to predict both residue-level contacts and strand interactions simultaneously, rather than the latter needing a post processing step. Given strands E r and E s , they are defined to be interacting if there exist any-contact between a residue in strand E r and a residue in strand E s. Using our model, we find the following:shows the results for two proteins, the N-terminal domain of the yeast HSP90 chaperone. For these proteins, our model correctly predicted all strand level interactions and it is interesting to note that for 1NN7, two separate-sheets are correctly predicted (strands {5,6}, {3,4,1,2} are distinct-sheets), despite our model not explicitly modelling multiple sheets. By thresholding the strand interaction probabilities at different values, we can generate a Precisionshows a comparison of the strand interactions results for our model, the final output of BetaPro and a MLN (). For the comparison, we have only included independent methods and not those such as MLN-2S () or those found in, which are hybrid approaches that combine results from more than one method. The results quoted for our model use the specific probability threshold of 0.45; however, taking the threshold at anyStandardized Score Density(b) A specific set of contacts I  f3, 13, 4, 14, 12, 23, 13, 24, 14, 25g. See the text for how the standardized score is calculated for this example value between 0.25 and 0.63 produces an F 1  2PR=P  R statistic equal to or above the value found by BetaPro. The results of our model are clearly better than BetaPro and competitive with MLN. This is an impressive result, as unlike these methods we do not require the additional information of the solvent accessibility of the residues as an input. We also do not require the secondary structure of the non-strand residues, which is important to the MLN method. The only information we use is the maximum entropy-based CMM D (P 1 is a single sequence method). D is as useful as providing the entire MSA as a set of 20-dimensional vectors of probabilities as input to a neural or MLN. This may be because providing the columns of the MSA as independent input vectors captures the wrong information; although certain residue pairs are more likely to form-contacts (for example, pairs of hydrophobic residues in the core of a protein), the individual pairing preferences are not especially strong, and proteins do not seem to have strong evolutionary pressure to maintain favourable pairings between strands (Mandel). Also, just considering the specific residue types, rather than how they co-vary, suffers from the problem of transitivity: if E r is paired with both E s and E t , then it is often the case E t and E s themselves contain residues with favourable pairings, as they both favourably interact with E r. For our method to be useful for proteins with unknown structure, it is important to test our method with predicted secondary structure. In the Supplementary Data, we have presented results for the CASP 2010 set of proteins using both known and predicted strand structure, and in both cases our method compares favourably with BetaPro.
CONCLUSION AND FURTHER WORKIn this article, we have used a statistical machine learning approach known as contrastive divergence to efficiently calculate a Maximum Entropy distribution that models the evolutionarily related family of a protein and have used this to calculate a CMM to predict residue contacts. We have coupled this measure to a probabilistic model of-strand interactions to produce a state-of-the-art-contact predictor that can be used even if a poor quality or no MSA is available. The current focus of our work is to allow joint inference of-contacts and secondary structure by incorporating a semi-segmental Markov model to model the secondary structure of proteins (). Unlike other recent CM studies, we have focused on proteins that do not necessarily have large enough MSAs to enable full tertiary structure determination using a CM approach. However, our strand interaction prediction can be incorporated into a tertiary structure prediction method. For example, our previously published work describes a coarse-grained protein model that uses a physically meaningful energy function, biased by a harmonic potential on-contacts to enable the protein to fold (). Using our strand prediction method to predict-contacts enables this model to be used for protein tertiary structure prediction.. Precision versus Recall graph for strand interactions. As a comparison, a naive algorithm always pairing adjacent strands yields P  0.42 and R  0.50. The results from the final output of BetaPro and a Markov Logic method () are also displayed for comparison. Contact maps for the strand level for proteins 1A4H (left) and 1NN7 (right). Above the main diagonal, the native (true) strand interactions are shown in yellow, and below the diagonal, PE r , E s interactjR using P 2 is shown. For protein 1NN7, it is interesting to note that two separate-sheets are correctly predicted, despite our model not explicitly modelling multiple sheets
The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Predicting protein b-sheet contacts at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
N.S.Burkoff et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
