Motivation: Regulatory DNA elements are associated with DNase I hypersensitive sites (DHSs). Accordingly, identification of DHSs will provide useful insights for in-depth investigation into the function of noncoding genomic regions. Results: In this study, using the strategy of ensemble learning framework, we proposed a new pre-dictor called iDHS-EL for identifying the location of DHS in human genome. It was formed by fusing three individual Random Forest (RF) classifiers into an ensemble predictor. The three RF operators were respectively based on the three special modes of the general pseudo nucleotide composition (PseKNC): (i) kmer, (ii) reverse complement kmer and (iii) pseudo dinucleotide composition. It has been demonstrated that the new predictor remarkably outperforms the relevant state-of-the-art methods in both accuracy and stability. Availability and Implementation: For the convenience of most experimental scientists, a web ser-ver for iDHS-EL is established at http://bioinformatics.hitsz.edu.cn/iDHS-EL, which is the first web-server predictor ever established for identifying DHSs, and by which users can easily get their desired results without the need to go through the mathematical details. We anticipate that iDHS-EL will become a very useful high throughput tool for genome analysis.
IntroductionIn genetics, DNase I hypersensitive sites (DHSs) are the regions of chromatin that are sensitive to cleavage by the DNase I enzyme. In these specific regions of the genome, chromatin has lost its condensed structure. As a consequence, the corresponding DNA region will become more exposing and easier to be accessible by enzymes, such as DNase I, and hence enhance its degradation. These accessible chromatin zones are functionally related to transcriptional activity because of the necessity to bind with proteins, such as transcription factors. Since its discovery about 30 years ago (), DHSs have been used as the markers for detecting the regulatory DNA regions. In general, these specific regions are usually nucleosome-free and associated with a wide variety of genomic regulatory elements, such;). Accordingly, one effective approach for discovering functional DNA elements from the noncoding sequences is to identify DHSs. The gold-standard approach for identifying DHS is the Southern blot technique, but it is a tricky, time-consuming and inaccurate to acquire the DHS information by using the Southern blot approach (). In 2010, by combining the DNase I digestion and high throughput sequencing technology, the DNase-seq technique was proposed (), leading to a remarkable enhance in resolution. Unfortunately, there is no effective methodology for analysing the DNase-seq data (). Therefore, one has to resort to the computational approaches for identifying DHSs. In fact some efforts have been made in this regard. For example,proposed a predictor based on the Support Vector Machine (SVM) in which the nucleotide composition was used to formulate the feature vector for predicting DHSs in K562 cell line. Recently, by using the pseudo nucleotide composition (PseKNC) (), which was developed based on the idea of pseudo amino acid composition for proteins (), Feng et al. (2014) proposed a more powerful predictor to identify DHSs by incorporating both the local and global sequence-order effects of DNA. Although the aforementioned computational approaches yielded quite encouraging results, and they did stimulate the development of this area, some further work is needed due to the following reasons.(i) These existing methods were based on different features extracted from a DNA sequence, and hence lacking the elegance and efficiency of uniform treatment; in other words, a new framework is needed to combine them into one framework. (ii) None of these methods has ever provided a web-server or stand-alone tool, and hence their practical usage value is quite limited, particularly for the majority of experimental biologists (). This study was initiated in an attempt to address these shortcomings by developing a more powerful and also more uniform predictor for identifying DHSs. As manifested in a series of recent publications (), to develop a really useful sequence-based statistical predictor for a biological system and also to make the developing process logically clearer and easier to follow, according to Chou's five-step guidelines () we should make the following five procedures crystal clear: (i) benchmark dataset; (ii) sample representation; (iii) operation engine; (iv) cross validation; (v) web-server. Below, let us describe how to deal with these steps one-by one.
Materials and Methods
Benchmark datasetsTo develop a statistical predictor, the first important thing is to establish a reliable and stringent benchmark dataset for training and testing the predictor. In this study, the benchmark dataset S constructed bywas adopted; it can be formulated aswhere the positive subset S  contains 280 DHS sequences collected from the human genome, the negative subset S  contains 737 nonDHS sequences, and [ denotes the 'union' in the set theory. For readers' convenience, the benchmark dataset are given in Supplementary Material.
Feature descriptionThree different features are used to construct three kinds of predictors. They are (i) kmer (), (ii) reverse complement kmer () and (iii) pseudo dinucleotide composition (PseDNC) (). These features can be used to reflect the characteristics of a DNA sequence from its different angles, as elaborated below.(i  1, 2,    ; L and 2 is a symbol in the set theory meaning 'member of'. If using kmer () or k-tuple nucleotide composition to represent the DNA sequence, we have (Chen et al., 2014c; Liu et al., 2015c)
Kmerwhere f kmer u(u  1; 2;    ; 4 k  is the occurrence frequency of the u-th k-tuple nucleotide in the DNA sequence and T is the transpose operator.2.2.2 Reverse complement kmer The reverse complement kmer () is a variant of the basic kmer, in which the kmers are not expected to be strand-specific, so reverse complements are degenerated into a single feature. For example, if k  2, there are totally 16 basic dinucleotides ('AA', 'AC', 'AG', 'AT', 'CA', 'CC', 'CG', 'CT', 'GA', 'GC', 'GG', 'GT', 'TA', 'TC', 'TG', 'TT'), but by removing the reverse complement 2mers, there are only 10 dinucleotides in the reverse compliment kmer approach ('AA', 'AC', 'AG', 'AT', 'CA', 'CC', 'CG', 'GA', 'GC', 'TA'). For more information of this approach, please refer to (). Accordingly, instead of Equation 5, we have(u  1; 2;    ; 10 is the occurrence frequency of the u-th reverse complement 2-tuple nucleotide in the DNA sequence.
Pseudo dinucleotide compositionPseDNC is an approach by incorporating the contiguous local sequence-order information (via 2mer) and the global sequence-order pattern (via the concept of pseudo components ()) into the feature vector of the DNA sequence (). According to PseDNC (), the DNA sequence D of Equation 2 can be formulated by a vector given bywherewhere f k (k  1, 2,.. .,16) is the normalized occurrence frequency of dinucleotide in the DNA sequence; the parameter k is an integer, representing the highest counted rank (or tier) of the correlation along a DNA sequence; w is the weight factor ranged from 0 to 1; h j (j  1, 2,.. .,k) is called the j-tier correlation factor that reflects the sequence-order correlation between all the most contiguous dinucleotides along a DNA sequence, which is defined by Chen et al.where the correlation function is given bywhere l  6 is the number of physicochemical properties considered in this study (see); P u R i R i1  and P u R j R j1   are the normalized numerical values of the u-th physicochemical index for the dinucleotides R i R i1 and R j R j1 , respectively. The aforementioned three types of feature vectors are actually three special modes of the general PseKNC (), as can be formulated aswhere Z is the dimension of the general PseKNC vector; e.g.Therefore, they can be easily generated by the web-server called 'Pse-in-One' () established very recently.
Random Forests algorithmWidely used in various areas of computational biology [e.g. (, the random forests (RF) algorithm is a powerful algorithm. Its detailed formulation has been clearly described in, and hence there is no need to repeat here.As shown above, by using 2mer, RC2mer, and PseDNC, the sample of Equation 2 can be defined by three different PseKNC vectors, as indicated in Equations 57, respectively. Accordingly, we have three different basic RF predictors; i.e. RF1; when the sample is based on 2mer or Eq:5 RF2; when the sample is based on RC2mer or Eq:6 RF3; when the sample is based on PseDNC or Eq:7 8 > < > : (13)
Ensemble random forestsAs demonstrated by a series of previous studies, such as signal peptide prediction (;), membrane protein type classification (;), protein subcellular location prediction (;), protein fold pattern recognition (), enzyme functional classification (), protein-proteins interaction prediction () and protein-protein binding site identification (), the ensemble predictor formed by fusing an array of individual predictors via a voting system can generate much better prediction quality. Here, the ensemble predictor is formed by fusing the aforementioned three different individual RF predictor of Equation 13; i.e.where RF E denotes the ensemble predictor, and the symbol 8 denotes the fusing operator (). In this study, the concrete fusion process can be formulated as follows. For a given DNA sequence sample D (see Eq.2), supposewhere the symbol. is an action operator () meaning using RF(i) to identify the query sequence D, and P i is the probability thus obtained for the sample query sample D belonging to the DHS sequence. Define
DNase I hypersensitive site identificationwhere F i is the fractional factor, and their optimal values were determined via the grid search as given byThus, we have D 2 DHS; if Y !0:5 non  DHS; otherwise (The predictor thus established is called iDHS-EL, where 'i' stands for 'identify', 'DHS' for 'DNase I hypersensitive site' and 'EL' for 'ensemble learning'. To provide an intuitive picture, a flowchart is provided into illustrate the prediction process of iDHS-EL.
Results and discussionAs pointed out in Section 1, among the five guidelines in developing a useful predictor, one of them is how to objectively evaluate its anticipated success rates (). To fulfil this, the following two things need to consider: one is what metrics should be used to measure the predictor's quality; the other is what kind of test method should be taken to derive the metrics rates. Below, let us to address such two problems.
Metrics used to reflect the success ratesA set of four metrics are usually used in literature to measure the quality of a predictor: (i) overall accuracy or Acc; (ii) Mathew's correlation coefficient or MCC; (iii) sensitivity or Sn and (iv) specificity or Sp (). But the four metrics have the following two problems. First, they are seriously affected by the imbalance degree of a benchmark dataset S as defined byWhen P S    1; the benchmark dataset S is completely balanced; when P S   > 1; it is negatively imbalanced; when P S   < 1; it is positively imbalanced. The larger the P S  , the more skewed the benchmark dataset will be. For the case of this study, N S     737 and N S     280 (see Eq. 1 and Supplementary Material), we have P S   % 2:63; meaning that the dataset is very skewed in favour to the negative case. To make the performance measurement more objectively reflect a prediction method for a system with high imbalance degree, two additional metrics have been incorporated. One is the product of sensitivity Sn and specificity Sp (), denoted here as Pt; the other is the property excess () denoted here as Py (). Second, the conventional formulations for the four metrics are not intuitive, and most experimental scientists feel hard to understand them, particularly for the MCC.where N  represents the total number of true-phosphorylation samples investigated, whereas N   the number of phosphorylation samples incorrectly predicted to be of false-phosphorylation sample; N  the total number of false-phosphorylation samples, whereas N   the number of false-phosphorylation samples incorrectly predicted to be of true-phosphorylation sample. According to Equation 20, the following are crystal clear. (i) When N    0 meaning none of the DHS samples is incorrectly predicted to be of non-DHS sample, we have the sensitivity Sn  1; whereas N    N  meaning that all the DHS samples are incorrectly predicted to be of non-DHS sample, we have the sensitivity Sn  0. (ii) When N    0 meaning none of the non-DHS samples is incorrectly predicted to be of DHS sample, we have the specificity Sp  1; whereas N    N  meaning that all the non-DHS samples are incorrectly predicted to be of DHS sample, we have the specificity Sp  0: (iii) When N    N    0 meaning that none of the DHS samples in the positive dataset and none of the non-DHS samples in the negative dataset is incorrectly predicted, we have the overall accuracy Acc  1 and MCCthat all the DHS samples in the positive dataset and all the DHS samples in the negative dataset are incorrectly predicted, we have the overall accuracy Acc  0 and MCC  1., we have Acc  0:5 and MCC  0 meaning no better than random guessing. As we can see from the above discussion, the set of metrics formulated in Equation 20 has made the meanings of sensitivity,specificity, overall accuracy, and MCC much more intuitive and easier-to-understand, particularly for the meaning of MCC, as concurred and adopted by many authors in a series of recent publications [e.g. (. Note that, of the six metrics in Equation 20, the most important are the Pt and Py in dealing with a system in which the number of negative samples is overwhelmingly greater than that of positive samples, as elaborated in Jin and Dunbrack (2005) and. The metrics Acc and MCC reflect the overall accuracy of a predictor and its stability. The metrics Sn and Sp are used to measure a predictor from two opposite angles. When, and only when, both Sn and Sp of the predictor A are higher than those of the predictor B, we can say A is better than B. Also, it is instructive to point out that the set of equations given in Equation 20 is valid for the single-label systems only. As for the multi-label systems existing in the system biology () and system medicine (), a completely different set of metrics is needed as elucidated in Chou (2013).
Cross-validationWith a set of intuitive evaluation metrics clearly defined, the next step is what kind of validation method should be adopted to derive the metrics values. The following three cross-validation methods are often used in literature: (i) independent dataset test, (ii) subsampling (or K-fold cross-validation) test and (iii) jackknife test (). Of these three, however, the jackknife test is deemed the least arbitrary that can always yield a unique outcome for a given benchmark dataset as elucidated in Chou (2011). Accordingly, the jackknife test has been widely recognized and increasingly used by investigators to examine the quality of various predictors [e.g. (. In this study, however, to reduce the computational time, we adopted the 5-fold cross-validation method, as done by many investigators with RF as the prediction engine. To do this, we first randomly divided the benchmark dataset S of Equation 1 into five groups that they were approximately equal to each other in the size of their subsets, as formulated belowwhere S  1 denotes the number of samples (or cardinalities) in S  1 ; and so forth. Actually, Equations 2123 can also be formulated aswhere the symbol  means that the divided five benchmark datasets in Equation 21 are about the same in size, and so are their subsets (). Thus, each of the five sub-benchmark datasets was singled out one-by-one and tested by the model trained with the remaining four sub-benchmark datasets. The cross-validation process was repeated for five times, with their average as the final outcome. In other words, during the process of 5-fold cross-validation, both the training dataset and testing dataset were actually open, and each subbenchmark datasets was in turn moved between the two. The 5-fold cross-validation test can exclude the 'memory' effect, just like conducting 5 different independent dataset tests.
Comparison with the existing methodsListed inare the 5-fold cross-validation results by iDHS-EL on the benchmark dataset of Equation 1 (see Supplementary Material). For facilitating comparison, listed in that table are also the corresponding results obtained by the SVM-RevcKmer predictor () and SVM-PseDNC predictor (), respectively. From the table, we can see the following. (i) Among the three predictors the newly proposed one achieved the highest success rates in both Pt and Py, the two most important metrics used to measure the quality of a predictor as elucidated in the follow-up text to Equation 20. (ii) Although the Sp rate by the proposed predictor was slightly (2.04%) lower than that by SVMRevcKmer, its Sp rate was 5.71% higher than that by SVMRevcKmer. As mentioned in Section 3.1, the two metrics are used to measure a predictor from two opposite angles, and they are constrained with each other (). Therefore, it is meaningless to use only one of the two for comparing the quality of two predictors. In other words, a meaningful comparison in this regard should count the rates of both Sn and Sp, or even better, the rate of their combination that is none but Pt and Py. As shown in, the Pt and Py rates achieved by iDHS-EL are remarkably higher than those by the existing predictors.
Feature analysisRF is a combination of decision trees, which have the ability to select important ones from many features and ignore others. Furthermore, because decision trees generate explicit models describing the relationship between features and the predictions, which facilities the interpretation of the models. A measure of how each feature contributes to the prediction can be calculated in the training process. A random noise value is used to replace a feature. If the performance is obviously degraded, it means that this feature contribute to the prediction. On the other hand, if the performance is stable, it means that this feature is irrelevant. Thus, we can calculate each relative importance of features according to the following procedure (). For each tree, the average prediction accuracy of the OOB (Out Of Bag) portion of the data is calculated. For each feature, replace its value with random noise, and then the average accuracy is recalculated. Finally, the difference between the two accuracies is then averaged over all trees, and normalized by the standard error. As a result, the mean decrease accuracy representsDNase I hypersensitive site identificationthe relative importance of each feature. As is shown in, it lists the top 10 most important features of the three individual RF classifiers (see Eq. 13). From the table, we can see the following. (i) Among the three RF classifiers, there are some common important features, such as CG, GC, CA, which are fully consistent with previous studies (). (ii) Some features are only important for one RF classifier but not for the others, such as CT, and k  1, 2, 3. These features describe the characteristics of DHSs in different aspects, and therefore, the predictive performance can be improved by combining these complementary features via the proposed ensemble learning framework.
Web server and user guideFor the convenience of the vast majority of experimental scientists, a web server for the iDHS-EL predictor has been established. To our best knowledge, it is the first web-server ever established for predicting the DHSs in human genome. Moreover, to maximize users' convenience, a step-by-step guide on how to use it to get the desired results is given below. Step 1.Open the web server at http://bioinformatics.hitsz.edu.cn/ iDHS-EL, and you will see its top page as shown in. Click on the Read Me button to see a brief introduction about the predictor and the caveat when using it. Step 2. You can either type or copy/paste the query DNA sequence into the input box at the center of, or directly upload your input data by the 'Browse' button. The input sequence should be in the FASTA format. For the examples of DNA sequences in FASTA format can be seen by clicking on the Example button right above the input box. Step 3. Click on the 'Submit' button to see the predicted results. For example, if you use the four query DNA sequences in the Example window as the input, you will see the following shown on the screen of your computer: (i) the first query DNA sequence (misc_ppid_8090) is of DHS; (ii) the second query sequence (misc_ppid_7576) is of DHS; (iii) the third query sequence (misc_ppid_7953) is of non-DHS; (iv) the fourth query sequence (misc_ppid_6460) is of non-DHS. All these predicted results are fully consistent with the experimental observations. Step 4. Click on the 'Benchmark Data' button to download the datasets used to train and test the model. Step 5. Click on the 'Citation' button to find the relevant papers that document the detailed development and algorithm of iDHS-EL.The abbreviation of mean decrease accuracy.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
B.Liu et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Conclusion A novel predictor called iDHS-EL was proposed for identifying the location of DHS in human genome by fusing the kmer approach, reverse complement kmer approach, dinucleotide-based auto cross covariance approach, and pseudo dinucleotide composition approach into an ensemble classifier. It was demonstrated by cross-validations on a same benchmark dataset that the new predictor outperformed the state-of-the-art methods (Feng et al., 2014; Noble et al., 2005) in this area. Furthermore, a user-friendly a web server for iDHS-EL was provided at http://bioinformatics.hitsz.edu.cn/iDHS-EL/, by which users can easily obtain their desired results without the need to go through the complicated mathematics involved, which were presented here just for its integrity. Also, it is the first web-serve predictor ever established for identifying the location of DHS in human genome.
