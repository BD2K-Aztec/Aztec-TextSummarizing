Motivation: Univariate Cox regression (COX) is often used to select genes possibly linked to survival. With non-proportional hazards (NPH), COX could lead to under-or over-estimation of effects. The effect size measure c = P(T 1 < T 0), i.e. the probability that a person randomly chosen from group G 1 dies earlier than a person from G 0 , is independent of the proportional hazards (PH) assumption. Here we consider its generalization to continuous data c and investigate the suitability of c for gene selection. Results: Under PH, c is most efficiently estimated by COX. Under NPH, c can be obtained by weighted Cox regression (WHE) or a novel method, concordance regression (CON). The least biased and most stable estimates were obtained by CON. We propose to use c as summary measure of effect size to rank genes irrespective of different types of NPH and censoring patterns.
INTRODUCTIONIn recent years, many studies aimed at finding prediction models which link high-dimensional gene expression data to a survival outcome (e.g.). A comparative analysis of methods used in this context can be found in a paper by. All these methods are extensions of the basic Cox proportional hazards regression model (COX) (). This semi-parametric model assumes that the hazard rate  i (t|x i ) of subject i at time t given a row vector x i of log 2 gene expression measurements is of the formwhere  0 (t) is an unspecified baseline hazard function. Thus the elements of  are log hazard ratios (HR) associated with a unit increase in log 2 gene expression or a doubling of gene expression. COX assumes proportional hazards (PH), which means that we consider a constant effect of gene expression on survival over the whole period of follow-up. In a typical microarray study comprising a large number of genes the assumption of PH cannot be verified for each gene, though it is unlikely that PH hold for each gene. * To whom correspondence should be addressed.Consequently, ignoring the PH assumption and applying COX based methods could lead to under-or over-estimation for a considerable number of genes, meaning that some genes may be falsely declared important for predicting survival, while at the same time relevant genes are missed. If some genes exhibit non-proportional hazards (NPH) then their HRs, estimated while ignoring time-dependency, are not comparable to those of genes with PH or of genes exhibiting different patterns of NPH. Nonetheless, very few theoretical studies have considered the possibility of NPH and its consequences on gene selection or prediction () and to our knowledge its occurrence has never been addressed in applied studies. By contrast, in classical applications a large body of literature exists which deals with COX under NPH () and the importance to cope with the possibility of NPH was often emphasized (). With gene expression as predictor, this has been a neglected area of research.and Supplementaryshow examples of genes with PHs, converging hazards (CH) and diverging hazards (DH) from the study of. For the gene with PH (left column) the correlation of scaled Schoenfeld residuals () with the rank of time is close to 0. For the other genes the correlation is considerably larger indicating violation of the PH assumption. The middle column ofshows a gene with CH, where the effect fades away with time, whereas the gene depicted in the right column exhibits DH, i.e. an effect increasing with time. In the Bhattacharjee study, genes with DH are found more often than genes with CH. NPH may arise from time-dependent effects of genes on survival, but could also result from model misspecification, e.g. from omitting a strong clinical covariate or another gene. This may particularly happen in univariate analyses.
Alternatives to COX in case of NPHTo cope with an apparent time-dependent effect of gene expression on survival, one may model the functional form of the timedependency by an interaction of gene expression with arbitrary functions of time. Suitable functions of time could be found, e.g. by fractional polynomials or penalized regression (cf.) or restricted cubic splines (), or by a simple interaction with a monotonic function, e.g. the logarithm, of survival time (). In this article, we do not follow any of these approaches, because finding the best functional form of time-dependency for a huge number of predictors may lead to numerous problems like multicollinearity or multiple testing issues,to name just two. Other options to cope with NPH, like stratification or separate modeling for different time periods (), are also not feasible with microarray data. Furthermore, all these options do not allow a comparison or ranking of genes with respect to their ability to predict short or long survival. In this article, we propose a semi-parametric generalization of the well-known concordance probability as a summary measure of effect size suitable to rank genes when some of the genes may exhibit a time-dependent effect on survival. The concordance probability c will be reviewed and its generalization c presented in Methods section, where we also introduce two methods to estimate c : concordance regression (CON) and weighted Cox regression (WHE). In Results section we present results from a simulation study comparing the performance of COX, WHE and CON in estimating c under various conditions, and in producing gene lists in microarray experiments. We will also present results of analyses of three data sets, and close with a discussion in Section 4.
METHODS
The effect size measure c for continuous dataAn intuitive non-parametric measure of separation of the survival distributions of two groups is the concordance probability c = P(T 1 < T 0 ), defined as the probability that a randomly chosen survival time T 1 from group G 1 is smaller than a randomly chosen survival time T 0 from group G 0. With uncensored data c is equivalent to the non-parametric two-sample test statistics of Wilcoxon (1945) and Mann and, and to the area under an ROC curve (). Assuming PH, one can directly use the Cox regression coefficientcoefficient coefficient C associated with a single binary covariate as an estimate of the log odds of c, i.e.   C has the interpretation of log(c/(1c)). This interesting relationship is shown in detail in the Appendix. Under NPH this connection t  C no longer applies, but c still is a measure with an intuitive interpretation. However, as recently demonstrated, c can be approximated also under NPH by using weighted estimation in Cox regression (). Since gene expressions are continuous rather than binary, the definition of c has to be generalized to continuous data. Assume that X denotes the log 2 expression of some gene of interest. Then, such a generalization of c could be defined aswhere T i and T j are the survival times of randomly chosen subjects with log 2 expressions x i and x j , respectively. Since a one-unit increase in X corresponds to a doubling of gene expression, c corresponds to the probability that survival time decreases if gene expression is doubled. Similarly,  = log c /(1c ) are the log odds that the survival time decreases if gene expression is doubled. Often, gene expression data are standardized to a common measure of spread (e.g. the standard deviation) across all genes and then our definition of c applies to a change of 1 SD. For convenience, we now assume that the log odds of concordancebetween two subjects with arbitrary log 2 gene expression values x i and x j are proportional to (x i x j ). This assumption corresponds to the linearity assumption of a PHs model, and implies that (x i ,x j )/(x i x j ) =  irrespective of the actual values of x i and x j. Even under mild departures from this assumption,  may still be a useful summary measure if redefined as the expectation of (x i ,x j )/(x i x j ) over all pairs of values (x i ,x j ):This quantity can be transformed into the generalized concordance probability by c = exp()/[1+exp()]. Our definition of c has some similarities with the concordance probability defined for time-to-event settings as CP(X,T )(Gnen, 2007, p. 89). CP(X,T ) is purely non-parametric and could also be used with gene expression data. Under PHs, Gnen and Heller (2005) have developed a modification of CP(X,T ) which is not sensitive to censoring. However, we prefer c here, because unlike CP(X,T ), c assumes a higher concordance probability with higher difference in gene expression.
Estimation of c
Concordance regressionWe now propose to model c via its log odds  by P T i < T j |x i > x j = exp(x i )/ (exp(x i )+exp(x j ) . The associated log likelihood and its derivative can be written asPage: 786 784790
D.Dunkler et al.by KaplanMeier but with the meaning of the status indicator reversed. The first term of the weight, [N(0)S(, restores the number of comparisons of a subject failing at time t i with subjects surviving that time that would have arisen had censoring not occurred. The second term of the weight, G(t i ) 1 , puts more weight on later event times compared to earlier times, and thus corrects the attenuation in observed events due to earlier censorship. It permits reconstructing the density of event times in the time range covered, i.e. till the last event. The weights w(t i ) are introduced into the score functionwhere D ij is defined as 1 if t i < t j and t i is uncensored, and 0 else. In a censored sample, the influence of the subjects on the likelihood is not equal; subjects with a long follow-up will contribute more information than those who are censored early. This unequal weighting will not bias point estimates unless, at the same time, censoring depends on gene expression and the effect of log 2 gene expression is not linear. While the first assumption can be ruled out in most applications, linearity is a standard assumption also in COX, and thus does not distinguish our method from others. Since only the combined violation of both assumptions may lead to biased point estimates, our proposed estimate can be seen as a doubly robust estimate. However, unlike in COX, one cannot use the negative inverse of the second derivative of the likelihood as variance estimate, since summation is done over risk pairs and not over risk sets. Proper variance estimates can be obtained either by the jackknife or by a robust sandwich estimate (;), but variance estimation will not be pursued here.
Weighted Cox regression Recently, Schemper et al. (2009) haveshown that by introducing weights into the score function of Cox's partial log likelihood, an approximative estimat  W of the log odds of concordance  is obtained that works well over a wide range of underlying values. The validity of the approximation is independent of the type of non-proportionality. The weights that are introduced are defined by w() and G(t i ) as defined above. Another related approach was proposed by Xu and O'. These authors also introduce weights into the score function, but their weights are defined by w(t i ) = S(t i )/N(t i ), which can be rewritten as w(Their aim was to provide an average regression effect independent of the pattern of censoring. One advantage of the approach ofis the intuitive interpretation ofof of W as log odds of concordance .
Software WHEhas been implemented in an R package coxphw and a SAS macro WCM available at CRAN.r-project.org and http://www.muw.ac.at/msi/biometrie/programs, respectively. CON for estimation of c has also been implemented in an R package concreg and is available upon request from the authors.
Gene selection based on cUnder PH, all three methods (COX, CON and WHE) will approximately supply similar estimates. Under NPH, however, we may expect differences between COX and CON or WHE, but similarity of the latter. We now assume that gene selection is done based on univariate regressions, and assume that from all candidate genes, the top-ranked are selected for further analysis. In our context, we rank genes by their absolute effect size c + = 0.5+|c 0.5|,| supplied by COX, WHE or CON, respectively. A threshold on c + can be defined to produce a list of 'significant' genes, and the false discovery rate (FDR) associated with that list evaluated. This procedure is known as FDR thresholding as proposed by
RESULTSWe evaluated COX, WHE and CON by simulating trials assessing the association of gene expression with survival. The first series of simulations aimed at comparing the methods in univariate models considering expression of only one gene the same time ('univariate evaluation'). These simulations should reveal differences of the methods in estimating the generalized concordance probability c under PH and various types of NPH. A second series simulated typical gene expression studies, where we considered a large number of genes with partly correlated expressions competing for selection in the same study ('multivariate evaluation').
Simulation study: univariate evaluationIn this series of simulations, we investigated the effect of the following factors on the distribution of c estimates in a factorial design, generating 2000 samples of 200 observations for each cell: time-dependency (PH, CH or DH), strength of effects ('small', 'medium' or 'large') and presence and amount of censoring (0, 33, 67%). We generated log 2 gene expression values from a standard normal distribution, and survival time y from a Weibull distribution with shape parameter a = 2 and scale parameter b = 0.5. Gene expression was linked to survival time by applying an algorithm of MacKenzie and Abrahamowicz (2002). For time-dependency we considered PH with (t) =  0 , CH with a time-dependent log HR of (t) =  0 [1+2.88/(1+5t)], and DH with (t) =  0 (1+1.86t).  0 was determined for pre-defined population values for c of 0.60 ('small' effect size), 0.66 ('medium' effect size) and 0.80 ('large' effect size). Under PH, these choices correspond to  0 values of log(1.5), log(2) and log(4). Further details of these computations are given in the Supplementary Data, Section 4.1 and Supplementary. To simulate censoring we drew a uniformly distributed follow-up time z from Uand defined the observed survival time as t = min(y,z) with status indicator I(z > y). We determined  to obtain proportions of censored times of 33 and 67%.shows boxplots of the estimates of c by COX, WHE and CON. The dashed reference lines indicate population values of c. In case of PH all three methods provide approximately unbiased estimates of c , irrespective of the effect size and amount of censoring, and COX shows slight efficiency advantages. In case of NPH (CH, DH) however, WHE and CON have clearly lower bias than COX, which over-or under-estimates depending on the combination of censoring and the type of NPH. With increasing censoring all three methods show variance inflation of similar magnitude. When censoring is combined with time-dependent effects a part of the bias can be attributed to the discrepancy of the population value of c given follow-up is restricted to a maximum time  compared to the unrestricted c. Across all scenarios, the largest observed discrepancy was 0.023.
Simulation study: multivariate evaluationThe aim of the second series of simulations was to see how the methods compare in selecting those genes which truly are related to survival, if a large number of genes are competing for selection. We simulated gene expressions of p = 5000 features according to a scheme outlined by, and assumed that only the first 72 genes had an additive effect on the log hazard, with an equal number of 24 genes exhibiting PH, CH and DH. From each group, we chose eight genes to have a 'large' effect size and 16 genes to have a 'small' effect size. As in the univariate simulation, we simulated survival times from a Weibull (2, 0.5) distribution with the distribution function Page: 787 784790denoted by F W (t). We linked standard normally distributed gene expressions to survival times, assuming that the hazard of subject i at time t is  i
Gene selection under non-proportional hazards. The time-dependent log HR of gene g was defined as  g (t) =  0 in case of PH,for DH. The constants  0 were set such that average regression effectsof 0.4 ('large' effect size) and 0.2 ('small' effect size) resulted. For each combination of censoring (0, 33, 67%) and sample size (200, 800) we generated 200 data sets and assessed the variability of results. Each data set was analyzed using COX, WHE and CON and for each gen c was estimated. Genes were ranked bycby byc + and the m top genes were considered 'selected'.shows some results when m is set to 72, the number of genes truly associated with survival. Results for other choices of m are given in Supplementary14 and Supplementary Tables 38. The average number of correctly selected genes which corresponds to the true positive rate, TPR, under various censoring proportions and sample sizes is graphically compared in. The TPR is significantly highest for CON in scenarios with no or 33% censoring (all paired t-tests yielded P < 10 6 , cf. Supplementary). Although CON estimates are on average least biased, their variability is higher than that of WHE or COX, which leads to the impaired performance of CON with 67% censoring. This could be due the unequal weighting of the contributions to the likelihood, which can be severe when there, weighted Cox regression (WHE) and concordance regression (CON) without and with truncation of weights from the multivariate evaluation. Lower and upper parts of each bar correspond to correctly selected genes with small and large effect sizes, respectively. %c, percent censored; N, sample size.are few 'long survivors' in the data set. To address this issue, we truncated all weights at their 95th percentile and found that the relative loss of efficiency of CON is compensated (CON compared to COX: 31.5 versus 32.0 genes, P = 0.039 for N = 200; 41.4 versus 41.7 genes, P = 0.551 for N = 800;If the number of selected genes m is varied, the TPR and similarly the false positive rates change. These changes concern all methods alike, such that we can conclude that the superior performance of CON is independent of a particular choice for m. Generally, TPRs are higher with a sample size of 800 compared to 200, but the general conclusions do not change (Supplementary). Inand Supplementary, we investigate which type of time-dependency is favored by the methods, and whether this depends on censoring and/or sample size. Ideally, genes with equal effect sizes should be selected with equal probability, irrespective of the type of time-dependency (PH, DH or CH), and the censoring pattern. We learn that this ideal situation is best accomplished by CON, which yields the best balance between genes from all types of time-dependency. By contrast, WHE selects CH genes more than others, and with COX the proportions of selected genes of different type change with increasing amount of censoring. These results are independent of the sample size, which affects the number of selected genes in all methods and with all types of genes in the same manner.
Application to real-life studiesWe applied univariate COX, WHE and CON to all genes of three microarray data sets and evaluated differences in gene selection.studied the association of survival and gene expression profiles of microarray data of 86 patients with early-stage lung adenocarcinomas. Similarly,investigated correlation of gene expression from lung adenocarcinomas with a survival endpoint in 125 patients. In a study bythe survival and gene expressions of 240 patients with diffuse large B-cell lymphoma were analyzed. For information regarding pre-processing we refer to our Supplementary Data,where q 25 and q 75 are the 25th and 75th percentiles of the permutation distribution ofcof ofc across all G genes and B permutations, andcand andc g is the original data estimate of gene g (). Estimates ofof of 0 for the three data sets are given in Supplementary. In all three data sets approximately half of the genes have a negative effect on survival, i.e.  c g < 0.5. The range ofcof ofc varies considerably between the three data sets, with the largest range in the Beer data set (0.2540.828 computed by CON) and the smallest range in the Bhattacharjee data set (0.4120.591 computed by CON). The correlation of the absolute effect size estimatescestimates estimatesc + from WHE and CON is close to 1 for all data sets, whereas it is considerably smaller when correlating WHE or CON with COX estimates. If the 250 genes with the largest absolute effect size estimatesc estimates estimatesc + are selected the best agreement in gene selection is observed between WHE and CON: 71, 79 and 69% in the three data sets. The proportion of genes selected by all three methods is 50% in all three data sets. The smallest FDR 250 values were obtained by COX in the Beer data (0.389), WHE in the Bhattacharjee data (0.841) and CON in the Rosenwald set (0.369). These data dependent advantages of the methods were also observed with higher or lower numbers of selected genes (see Supplementary). In the Bhattacharjee data the FDR 250 estimate from COX selection was larger than 1, a situation which was already anticipated by.
DISCUSSIONWe have introduced c , a semi-parametric generalization of the well-known concordance probability for continuous predictors and Page: 789 784790Assume that S j (t ), f j (t ) and  j (t ) denote the survivor function, the density and the hazard function in group j, j ={0,1} at time t. Under PH we assume that the hazard ratio is constant over time,
Gene selection under non-proportional hazards, thus under PH we can us  C from a Cox regression analysis to estimate c.
The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
, where summation is over all available pairs (i,j) such that t i < t j. These pairs (i,j) will in the sequel be denoted as 'risk pairs' (as opposed to 'risk sets' in COX), and subjects may appear in multiple risk pairs. In our model the dependent variable is the concordance of the risk pair (i,j) and hence, setting the first derivative of the log likelihood to zero yields a direct estimate of the log odds of concordance of t i < t j related to a one-unit increase in X. Therefore, we denote this method as concordance regression. Our approach is semi-parametric as it does not require approximating or knowing the survivor function S(T |X). Once an estimat  has been computed,  c can be derived byc by byc = exp(  )/{1+exp(  )}. Despite the continuous nature of gene expression, in practical problems ties in gene expression may occur. In this case, we omit risk pairs with x i = x j from the likelihood, since they do not contribute information about  or c. In case of censoring, we omit all risk pairs where t i is censored, because it is not clear whether the true underlying survival time is less than t j. Therefore, censoring leads to an overrepresentation of some subjects compared to others. In order to obtain an unbiased estimate of c despite this overrepresentation, we weight the risk pairs by their inverse sampling probabilities. Suitable weights are defined by w(t i ) =[N(0)S(t i )1]/[N(t i )1]G(t i ) 1 , with S(t) denoting the left continuous version of the KaplanMeier estimate of the survivor function at time t, N(t) the number of patients at risk at t, and G(t) denoting the probability to be still under follow-up at t, estimated
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
data it was proposed to use gene selection as a first step, e.g. supervised principal components regression (Bair and Tibshirani, 2004; Bair et al., 2006). Application of the methods investigated in this contribution in combined selection and prediction models like the LASSO (Park and Hastie, 2007; Tibshirani, 1997), ridge regression (Verweij and van Houwelingen, 1994) or partial least squares regression (Park et al., 2002) is in principle straightforward. However, our investigation leaves the question open whether the modest improvements in gene selection observed with WHE or CON can contribute to improved estimation of prediction models. Nevertheless, we consider the robustness of these methods to NPH as being of particular advantage for real-life applications. Thus, one may replace Cox regression by WHE or CON at any stage of model development, to obtain prediction models without having to assume PHs. As final result, such prediction models supply cross-validated risk scores to assess and compare different levels of risk between subjects. An evaluation of the association of the risk scores with survival using c may improve interpretation as it allows quantifying the impact of the genetic information on survival, provides a direct comparison of subjects and at the same time is robust to violations of the PHs assumption.
