Motivation: Intrinsically disordered regions are key for the function of numerous proteins. Due to the difficulties in experimental disorder characterization, many computational predictors have been developed with various disorder flavors. Their performance is generally measured on small sets mainly from experimentally solved structures, e.g. Protein Data Bank (PDB) chains. MobiDB has only recently started to collect disorder annotations from multiple experimental structures. Results: MobiDB annotates disorder for UniProt sequences, allowing us to conduct the first large-scale assessment of fast disorder predictors on 25 833 different sequences with X-ray crystallographic structures. In addition to a comprehensive ranking of predictors, this analysis produced the following interesting observations. (i) The predictors cluster according to their disorder definition, with a consensus giving more confidence. (ii) Previous assessments appear over-reliant on data annotated at the PDB chain level and performance is lower on entire UniProt sequences. (iii) Long disordered regions are harder to predict. (iv) Depending on the structural and functional types of the proteins, differences in prediction performance of up to 10% are observed. Availability: The datasets are available from Web site at URL:
INTRODUCTIONThe rigid structure of proteins has been considered the determinant of function for many years. Recently, an alternative view is emerging with respect to non-folding regions, suggesting a reassessment of the structure-to-function paradigm (). Flexible segments lacking a unique native structure, known as intrinsic disordered regions (), are widespread in nature, especially in eukaryotic organisms (). These regions have been shown to play important roles in various biological processes such as cell signaling or regulation (), DNA binding and molecular recognition (). Their malleable properties allow multiple binding partners () with the flexible region often becoming folded on binding (). Despite an emerging consensus regarding their existence, there is no single definition of disorder. As a result, various flavors of disorder have been proposed (). These disorder flavors have become diverse with some based on amino acid composition (), flexibility () and functional roles coupled with conservation (). Perhaps the simplest flavor distinction is the length of a disordered region, separated into short and long. Long regions seem to behave differently () and are difficult in structural determination, causing them to be underrepresented in the Protein Data Bank (PDB) (). The PDB contains structural information from X-ray crystallography and nuclear magnetic resonance (NMR) spectroscopy, which can be used indirectly to study disorder. A plethora of computational predictors have also appeared, with special efforts to capture different flavors. Available methods can be broadly divided into three classes: biophysical, machine learning and consensus based. Biophysical methods () derive pseudoenergy functions from residue pairings in rigid structures (i.e. non-disorder) to recognize sequence regions with high energy as disordered. Machine learning, especially neural networks, has been widely used to predict protein disorder (). Many are tuned for the disorder style used in the Critical Assessment of techniques for protein Structure Prediction (CASP), where the goal is to detect missing residues in the X-ray crystal (). Others attempting to move away from this disorder style measure some form of protein backbone flexibility. For example, ESpritz () can predict mobile NMR regions and DisEMBL () loops regions with high B-factor (high flexibility). The most recent disorder predictor category uses a consensus of various *To whom correspondence should be addressed.
yThe authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors. biophysical and machine learning methods (). Consensus approaches are frequently more accurate, but at the computational cost of running several predictors in parallel and averaging their output. Because there is no consensus on how to define disorder, predictors often vary in their parameter setting and disorder output. In nearly all cases, disorder is defined at the residue level, and the goal of the predictor is to maximize recovery of correct residues. Among applications of disorder prediction, we can distinguish at least two different scenarios. The first is the CASP experiment (), i.e. methods are used to predict a relatively small number of proteins with maximum accuracy and consensus predictors aiming for maximum accuracy should clearly excel. A more practical scenario is represented by high-throughput analysis of protein disorder on entire genomes (). Over the years, most prediction methods have addressed the first problem, with comparatively little attention to the practicalities of large-scale predictions (). MobiDB () is a large-scale disorder database containing experimental information on the entire PDB and predictions for all UniProt () sequences. Here, we use the vast quantity of disorder data for a first large-scale assessment. While most assessments are performed with hundreds or a few thousand examples, we have analyzed 425 000 UniProt sequences combining all available X-ray crystallographic structures. All disorder assessments so far are carried out on single PDB chains, whereas here the UniProt sequence is the final target. The UniProt annotation is unique and we compare it with standard PDB chain analysis for further insights.
METHODS
Datasets and classificationsAll UniProt () sequences with at least one X-ray annotation in MobiDB () were downloaded on the May 13, 2013 (25 833 entries). Where more than one MobiDB annotation was available, a majority vote was used () to produce a more stable disorder definition, filtering rare conflicts due to experimental conditions. Where MobiDB cannot find annotation for part of the UniProt sequence, residues are annotated as unknown and ignored. Each PDB () chain that covered UniProt entries was also extracted for comparison and identical chains majority voted (). Similar chains were removed at 90% pairwise sequence identity using CD-HIT (101 338 chains reduced to 24 669). See Table 1 for statistics. Each UniProt entry was assigned to CATH using SIFTS (). Gene Ontology (GO) terms () were downloaded from UniProt and expanded to the ontology root. For a deeper analysis, the UniProt dataset was further split according to the following rules (Supplementary): removing short (530 residue) PDB fragments, excluding conflicting residues, up to 10 non-consecutive disordered residues, 410 disordered residues.
PredictorsPredictors were selected with the condition that they must be available as an executable and fast, ideally returning predictions in 51 min. The following 11 programs were used (disorder definition used in parenthesis): ESpritz (X-ray, NMR and DisProt;), IUPred (short and long;), DisEMBL (hot loops and remark 465;), RONN (X-ray;) and VSL2b (combination of X-ray and Disprot;), GlobPlot (globularity;) and FoldIndex (folding;). This resulted in a total of 11 predictors with different disorder flavors. A short description of the predictors is given in the Supplementary Material. Predictor similarity was calculated on their residue scores (e.g. probability of disorder) was shown as a dendogram based on SOV performance. Low-complexity regions are parts of the sequence with strongly biased compositions (e.g. polyQ), which are thought to correlate with intrinsic disorder (). The low-complexity predictors SEG () and Pfilt () were used both as disorder predictors and to analyze disorder predictor performance in low-complexity regions.
Performance assessmentDisorder prediction is a binary classification problem. As such, the standard measures accuracy, sensitivity, specificity, Matthews Correlation Coefficient (MCC) and area under the curve (AUC) are used (see Supplementary Material). All these measures are calculated both per residue and as average on a per protein basis. MCC and AUC were replaced by SOV and FPreg in the per protein analysis. SOV is the mean of the segment overlap for disorder and structure, in analogy. Human P53 (UniProt ID: P04637) disorder annotation. The top bar shows the majority voting scheme, with blue for order and red for disorder. For simplicity, only a subset of PDB hits was shown. Missing regions are not considered. The bottom bar shows an example majority voted chain used in the PDB chain analysisNotes: UniProt contains full sequences annotated from MobiDB. PDB90 contains PDB chains at 90% sequence identity. CASP10 is shown for comparison purposes. Short disorders are proteins with at least three and long at least 20 consecutive residues. Order lists completely ordered proteins. to secondary structure (). FPreg counts the number of predicted false-positive disordered regions. Disorder content measures the ability to recover the fraction of disordered residues in a protein independent of residue position. We adopted two previously used measures (), root mean square error (RMSE) and Pearson Correlation Coefficient (PCC), with predicted and observed disorder content normalized by the number of annotated residues. As a large number of measures hinders a global view of performance, we established an overall ranking as the average over all 12 quality measures. The Welch t-test was used to compute statistical significance.
RESULTS
First large-scale disorder assessmentWe report the first large-scale assessment of disorder predictions on UniProt sequences through a comprehensive assessment of 11 fast predictors with new performance measures and a statistical evaluation. With respect to diversity, the UniProt set has 15 942 unique clusters at 40% identity cutoff. The 24 699 PDB chains are non-redundant by design (see Methods). Therefore, in both sets there is no large cluster of similar sequences, guaranteeing no bias in the analysis.shows human P53 sequence (UniProt ID: P04637) covered by different disorder and structure definitions from the PDB. Using the majority voting approach, all structural and disorder information is combined and a more reliable global picture of the full p53 complex is constructed.shows the number of proteins and residues using this annotation strategy. A total of 25 833 UniProt entries are annotated and a dataset of unique PDB chains is constructed for comparison purposes. For all sets, there is a clear imbalance between disorder and structured residues. Similar to the CASP10 experiment () where 20% of the data was completely ordered, 6271 sequences 24.3% of the UniProt dataset are completely ordered. Long disordered regions (420 residues) are also abundant with 3439 examples.shows the per-residue performance on the UniProt dataset. Supplementary Tables S3 and S4 show similar results when excluding short PDB fragments and conflicting positions.The same trends are also found when separating the UniProt dataset for disorder content (see Supplementary Tables S5 and S6 and Section 3.4 below).shows the per protein and disorder content performance. Most predictors have disorder scores significantly above random (AUCs 470). Depending on the prediction style, e.g. high coverage (overprediction) or highly confident (underprediction), one could argue for and against different predictors. For example, VSL2b has a lower residue specificity (81.16) predicting many false positives (1 268 274 residues), yet its AUC is the highest. On the contrary, IUPred-short has the best MCC (31.43) due to its high specificity.can reveal detailed future objectives such as the need to retune the VSL2b decision threshold for higher specificity. For the SOV measure, DisEmbl-465 has the best performance (50.23). FPreg measures overprediction on segments as opposed to single residues. Again VSL2b clearly over predicts compared with DisEmbl-465.Notes: All values are shown as percentages. The top performing method in each category is shown in bold and the second best underlined.
Similarity between measures and predictorsWhile the evaluation complexity arises due to predictor variability and the quantity of performance measures, it is useful to understand the deeper predictor behavior. Although many more observations could be made, for the sake of brevity a summarized ranking was chosen to give a clearer performance summary. Before ranking, it is important that the measures are evaluating different aspects of the predictions.shows that no measure correlates highly and most are diverse (pairwise correlation value 40.7 or 50.7 in only 9 of 66 cases). This diversity ensures the ranking procedure is fair. Interestingly, per-residue MCC correlates highly with both disorder content measures (0.7 with RMSD and 0.9 with PCC), suggesting they could be captured effectively by residue-level MCC. Both were kept because they are not completely redundant and the content measures do not depend on residue positions. From, the top-ranked predictors are DisEmbl-465 and IUPred-short, with no statistically significant difference between performance (P-value 0.64). A second group consists of EspritzNMR, VSL2b and Espritz-X-ray. In Supplementary, these top five predictors are analyzed using receiver operating characteristic curves at low 05% false-positive rates (FPR). VSL2b starts outperforming the rest at around 2% FPR, again suggesting high-quality residue scores but a need for recalibration of its decision threshold. Combining several good but complementary predictors is the heart of most consensus methods.shows the Pearson correlation between predictors. Examining similarity and performance is the first step in designing a consensus. Both are not necessarily related, e.g. IUPred-short, IUPred-long and RONN form a group of highly correlated predictors (PCC range 0.70.8) with different performances.shows a dendrogram of predictors grouped by SOV. This SOV difference of correlated predictors is mainly due to their selected decision threshold with residue scores remaining similar. Three methods, FoldIndex, GlobPlot and DisEmbl-HL correlate poorly with all others (PCC50.5) and also perform poorly on SOV.They nevertheless define different disorder flavors, which may be useful in certain situations. IUPred-short and DisEmbl-465 have high correlation (40.7 PCC) in conjunction with similarly high SOV, suggesting they detect the same disordered regions well. For a consensus approach, however, it is more interesting to combine, for example, Espritz-NMR/X-ray with DisEmbl-465, as they have low correlation (PCC 0.5) and quality SOV. To investigate consensus further, we measure agreement among predictors.shows the residues split into three equal groups: consensus structure, consensus disorder and uncertain. Uncertain is defined when there is disorder agreement for 47 predictors because the accuracy continually decreased below 61.2% (see Supplementary). When there is confident agreement, accuracy increases as expected, i.e. both tails of Supplementary: 03 structure and 811 disorder agreement. In these regions, a consensus can recover 88.8 and 24.5% highly confident structured and disordered residues, respectively. Applying a simple majority vote in analogy to secondary structure () produced 43.3% sensitivity, 95.6% specificity and an AUC of 78.8 per residue (seefor comparison).
Uniprot versus PDB chainsThe most surprising result is the large decrease in performance compared with previously published performances. As most of the assessments in the literature are based on PDB chains, we examine whether assessments on PDB chains behave differently from UniProt sequences.shows the per-residue AUC differences between the UniProt and PDB chain datasets. Most predictors perform better on PDB chains and start approaching their published values (e.g. ESpritz-X-ray AUC 86.58 on CASP9). This is possibly due to the fact that predictor parameters are optimized on PDB chains. Another possible reason may be the positional dependence in PDB sequences, i.e. missing atoms or disordered residues in solved structures are often located at the N and C termini. This effect was recently noted for CASP-10 (). Given that most methods encode the sequence context (e.g. using sliding windows in neural networks) they will implicitly learn the position of the termini. This information is lost when the PDB sequence is assigned to a part, often the middle, of the UniProt sequence. Moreover, the definition is different in UniProt because it is a majority combination of multiple experimental sources. Supplementaryshows the full set of performance measures on the PDB chain set.
Sequence and structure variabilityFluctuations in performance given different protein properties are often overlooked. To our knowledge, this has never been examined comprehensively. In all cases, performance is assessed using SOV and there are indeed some striking performance differences. Proteins are grouped into bins of low complexity content (1% intervals), and the top five predictors are analyzed for. Proportion of data that can be assigned confidently using a consensus. The pie chart shows each of the 11 possible scenarios (i.e. from 0 to 11 disorder predictions) and the corresponding fraction of truly disordered residues (in red). Each row corresponds to a situation (structure, uncertain, disorder) for which the percentages of occurrence are summarized. Dendogram for disorder residue score and performance using the SOV measure. On the Y axis, the cumulative SOV score difference is plotted. Increasing low complexity content increases SOV logarithmically with the largest gains in the 520% low complexity range. A similar concept was already investigated (), suggesting that disorder predictors are generally using low complexity patterns to predict unstructured regions. At first glance, this seems to contradict, which shows SEG and Pfilt producing almost random predictions. It can be explained by the fact that no low complexity regions were detected for 40.1% of the disordered proteins. From Supplementaryit is clear that low complexity has a significant relationship with disorder performance whenever present. Disorder region length is perhaps the most obvious sequence property, and the majority (75.8%) of sequences in our dataset contain at most 10 disordered residues (Supplementary). The performance separated on this threshold is shown in Supplementary Tables S5 and S6. This skewed distribution may not reflect the truth in nature, especially for long proteins where long disordered regions may be missed owing to lack of evidence, but is nevertheless interesting, as we are using a common disorder definition ().shows the performance of each method separated into two sets. Proteins containing at least one long disorder stretch (i.e.420 residues) or not. Detection of disorder with long regions had a decreased performance in 5 of 11 methods, but 4 of these were the top ranked ones. Conversely, methods trained to take into account long disorder (e.g. IUPred-long, Espritz-Disprot, RONN and VSL2b) and the folding predictors (GlobPlot and Foldindex) showed better performance on proteins with long disorder. This suggests that the top-ranked methods can be improved by taking into account long disorder regions in their training. Using CATH, 9378 proteins with disorder were extracted form the UniProt set. Supplementaryshows the performance of the top five methods on the four main CATH classes. The CATH few secondary structure class is predicted considerably below average. This could be due to the high quantity of disorder in this class (Supplementary). Mainly alpha structures are clearly easier to detect, perhaps due to alpha helices being dependent on local sequence. Conversely, mainly beta structures are harder to predict perhaps because beta sheet hydrogen bonds are dependent on distant residues. This difficulty in capturing distant sequential dependencies is a common problem in secondary structure prediction () and likely also true for disorder.
Functional variabilityThe top five predictor SOV performances for proteins with at least one disordered residue are separated into the three GO classes (). Cellular Component covers 3458 proteins, Biological Process 4696 and Molecular Function 5260.shows how SOV varies significantly for different cellular component terms. Virion-related proteins have the most interesting performance drop, probably due to an increased level of disorder in these proteins (Supplementary). Perhaps more interestingly, performance for membrane and extracellular proteins is generally lower than average, even though the amount of disorder was not enriched (Supplementary). This may be a consequence of disorder having different amino acid composition in these proteins (). For GO Molecular Function (Supplementary), binding and transporter activity are predicted well but the activity relationships structural molecule and receptor have the lowest performance. Disorder performance also varies with Biological Process (Supplementary). Signaling and regulation were easier to predict while biological adhesion has a glaringly poor performance. In each of the three GO classes, SOV performance varies by up to 10% for different GO terms.mobility, we feel that it should capture most aspects of intrinsic disorder. The assumption is that in most cases, missing backbone atoms in PDB structures correlate with intrinsic disorder defined in DisProt (). Our definition is also arguably more stable because it is based on a majority vote on all PDB structures covering a UniProt entry. Thus experimental errors in X-ray crystallography (e.g. missing residues due to low resolution) should be removed, as disorder is only considered if it occurs most frequently in the PDB. The evaluation reveals a strong variability in predictors across the 12 measures, indicating different prediction styles (e.g. overprediction or confident underprediction). Ranking each predictor with the 12 measures shows both DisEmbl-465 and IUPred-short performing consistently well on each measure. The ranking was robust because the 12 measures show little correlation (). Predictors that ranked poorly still contain a good signal across our disorder definition. In most cases, they fall behind because they offer a different interpretation, which may be useful in alternative settings. At CASP, the best disorder predictors are widely known to be meta-predictors combining orthogonal information (i.e. unique predictors performing well). A correlation analysis on the predictors produced similar clusters as well as unique predictors. Some predictors showed both uniqueness and good performance, indicating a consensus predictor may be beneficial. Using predictor combinations, 88.8% of structured and 24.5% of disordered residues are found with highly confident agreement. The remaining 10.0% structured and 34.2% disordered residues classified as uncertain may be decided with more sophisticated heuristics (e.g. high residue scores). Highly accurate predictors on UniProt sequences are vital, considering that users are invariably trying to understand disorder properties of unannotated proteins and not the PDB, which is already annotated with quality structural information. Despite this, the literature largely concentrates on PDB chain assessments. The performance on the UniProt disorder definition is substantially lower than the equivalent evaluation on PDB chains. A similar effect was recently noted in the CASP-10 assessment, where database predictions were worse than the direct submissions by the same methods (). In general, increases in PDB chains are observed across all measures (Supplementary), suggesting that the prediction of the more desirable UniProt disorder may be worth considering for training new predictors. There are large performance variations when splitting the data into groups of proteins. As expected, predictors prefer large amounts of low sequence complexity, but the performance seems to plateau after 20% low complexity. On the other hand, long disorder detection seems to be more difficult, especially for the predictors we find to be accurate. While both trends are somewhat expected, the dependence of performance on structure and function are less obvious. At the structural level, beta-only proteins seem to be more difficult to predict compared with alpha-only or mixed alpha/beta. The few secondary structure class is certainly the poorest, but this may be due to long disordered regions being poorly detected. Given that functional disorder analysis using predictors is gaining attention (), prediction error is shown relative to GO. The analysis shows that the average error rate is not universal across all functions. It is possible that enriched functions found in genome analysis may have a slight bias. For example, the association with disorder and binding, signaling and regulation is known, but here we found that they are more easily detected, possibly inferring enrichment. Compared with virion sequences, which are more abundant in experimental disorder (Supplementary) and supported by the literature (), the error rates on their predictions are higher than average. One of the main reasons for performance variation could be the distribution of protein types in predictor training sets. Binding, signalling and regulation proteins together constitute a large fraction of known disorder datasets, and it is reasonable to assume that the same distributions are used in each predictor. It is therefore possible that predictors are optimized for these common families. Optimistically, the use of this prior knowledge could enhance predictor training or motivate the development of specific tools. To our knowledge, this is not only the first large scale analysis of disorder predictions from X-ray crystallographic structures but also the first attempt to provide error rates on sequence, structure and functional protein types. We are in the process of developing this evaluation into an automatic evaluation server and plan to integrate it in the new version of MobiDB ().
DISCUSSION
The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
I.Walsh et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Large-scale disorder assessment at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
