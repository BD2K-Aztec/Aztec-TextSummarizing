Motivation: Gene-model curation creates consensus gene models by combining multiple sources of protein-coding evidence that may be incomplete or inconsistent. To date, manual curation still produces the highest quality models. However, manual curation is too slow and costly to be completed even for the most important organisms. In recent years, machine-learned ensemble gene predictors have become a viable alternative to manual curation. Current approaches make use of signal and genomic region consistency among sources and some voting scheme to resolve conflicts in the evidence. As a further step in that direction, we have developed eCRAIG (ensemble CRAIG), an automated curation tool that combines multiple sources of evidence using global discriminative training. This allows efficient integration of different types of genomic evidence with complex statistical dependencies to maximize directly annotation accuracy. Our method goes beyond previous work in integrating novel non-linear annotation agreement features, as well as combinations of intrinsic features of the target sequence and extrinsic annotation features. Results: We achieved significant improvements over the best ensemble predictors available for Homo sapiens, Caenorhabditis elegans and Arabidopsis thaliana. In particular, eCRAIG achieved a relative mean improvement of 5.1% over Jigsaw, the best published ensemble predictor in all our experiments. Availability: The source code and datasets are both available at
INTRODUCTIONEnsemble predictors are automated gene-model curation tools that build gene models by combining conflicting and incomplete information provided by multiple sources of coding evidence. To date, manual curation still produces the highest-quality annotations as it benefits from problem-domain knowledge of expert human curators that is difficult to build into gene predictors. However, manual curation is slow and costly, and has been unable to complete * To whom correspondence should be addressed. the annotation even for the most important organisms (). Several methods of semi-automatic curation try to speed up manual methods by automating the selection of good combinations of manually-tuned evidence integration rules. Such methods include ExonHunter (), Eugene (), GAZE () and more recently Augustus+hints (). Semi-automated gene annotation pipelines also belong in this category. ENSEMBL () and Pairagon+NSCAN_EST () for example, use expressed sequence tags (ESTs), complementary DNAs (cDNAs) and automated predictions to find a consensus gene model. In recent years, ensemble predictors based on machine learning have become a viable alternative to manual or semi-automated methods. These methods measure signal and genomic region consistency among sources encoded as feature vectors and use voting schemes to resolve evidence conflicts. Fully automated, learningbased ensemble predictors include the work of () and JIGSAW (). In particular, JIGSAW has performed favorably in multiple benchmark datasets in comparison with the best semi-automated annotation pipelines. Some learning-based ensemble predictors require annotated sequences for training (supervised methods); others learn combination parameters to maximize agreement without needing annotated training data beyond what was used for individual sources of evidence (unsupervised methods). Unsupervised methods such as GLEAN () and Evigan () are advantageous in cases where no manually-curated gene annotations are available. However, they tend to perform less well than supervised ensemble predictors. Among supervised ensemble predictors, the work of () uses maximum-likelihood estimation to learn the parameters of an inputoutput Hidden Markov Model (HMM) that combines multiple gene predictions. JIGSAW () is an improved version of Combiner () that uses a semi-Markov structure model and a learning procedure that implicitly models dependencies of evidence sources given the input sequence. The main idea in Combiner and JIGSAW is to classify feature vectors of the input sources as either accurate or inaccurate using decision trees. An accurate (inaccurate) vector is one that led to predictions that match the annotation in at least (most) half of the training set. The learned decision trees partition the feature space into accurate and inaccurate regions, allowing the combiner to decide
A.Bernal et al.which predictions to trust where. This technique tries to emulate the way expert human curators decide on the structure of the final consensus gene model and it has proven to be quite effective in practice as Combiner and JIGSAW have consistently produced the best automated prediction results in a variety of benchmark datasets. However, this approach is unable to globally optimize the combiner to minimize error of its output consensus prediction. In this article, we describe eCRAIG [ensemble CRAIG, since it is based on the earlier CRAIG gene predictor (, a learning-based automated curation tool that integrates multiple predictions through global discriminative training. This learning approach has been successfully used for ab initio gene prediction in CRAIG, which uses the margin infused relaxed algorithm (MIRA;) online learning algorithm to train a semi-Markov conditional random field (CRF). We use the adaptive regularization of weight vectors (AROW) learning algorithm (), which combines the robustness to label-noise of large-margin classifiers like MIRA with the fast convergence and accuracy of confidence-weighted learning algorithm (). The combined model is still a semi-Markov CRF, now using not just a rich variety of genomic features (as CRAIG does), but also features derived from the source predictions and their patterns of (dis)agreement. Training optimizes globally the feature weights to maximize annotation accuracy. The rich feature language allows the model to represent non-linear interactions involving intrinsic genomic properties of the sequence under analysis with extrinsic properties of the individual evidence sources as well as their patterns of agreement. These refinements led to significant overall improvements over the current best predictions available for Homo sapiens, Caenorhabditis elegans and Arabidopsis thaliana. In particular, eCRAIG achieved a gene-level relative mean improvement () of 5.1% over JIGSAW, the best published combiner-type predictor in all our experiments.
EXPERIMENTS AND RESULTSWe performed experiments on three different organisms: A.thaliana, C.elegans and H.sapiens. Table S-1 (see Supplementary Material) provides an overview of the training and test sets used in each case. Predictions made by eCRAIG include partial genes, multiple genes per region and genes on both strands, but exclude alternatively spliced transcripts and genes within genes. Accuracy numbers for all programs were either reported from their corresponding publications if available, or computed using the program eval (). As described in Section S-3 (see Supplementary Material), the eCRAIG learning algorithm requires the tuning of hyper-parameters r, N and loss function L. To accomplish this, for each experiment we constructed a development setor validation setusing all unreachable genes found in the available training data. Unreachable genes are genes that have at least one genomic signal with no supporting evidence in all their transcripts. As such, they are inherently difficult to predict, impossible to decode correctly and thus could potentially cause overfitting if used for training. However, if used for validation, even a few unreachable genes could be enough to effectively measure prediction performance. The number of unreachable genes in the original training sets for A.thaliana, C.elegans and H.sapiens are 21, 103 and 5, respectively. As shown in1 (see Supplementary Material), the values for N, r and L that yield the best validation results are 4, 10 and WS+MS for A.thaliana; 5, 1.0 and FP +FN for C.elegans; and 6,1.0 and FP +FN for H.sapiens. For selecting control points for a particular property, we made sure that the two outermost control points covered 99% of the range for property values found in the training set; the remaining control points were placed equidistantly. For sparse property values, such as lengths, we used a log scale for the placements. The actual control point values are given in Tables S-9 and S-10.
Predictions for A.thalianaWe compared eCRAIG with ab initio predictors GeneMarkHMM, GenScan, GlimmerA, GlimmerM, TwinScan, and ensemble predictors GLEAN, Evigan and Combiner. We tested two different evidence sets for ensemble predictors. The first set integrates ab initio predictions with protein and EST alignment evidence, whereas the second one, with suffix '-NoAlign', only includes ab initio predictions. Figures 1a and b show gene-and exon-level prediction results for all programs on dataset ATTS1783. Accuracy values for all levels and types of exons are reported in2 (see Supplementary Material). Most ensemble predictors have an exonlevel F-score of 92%, and a gene-level F-score of 80%. These results are significantly better than those obtained by the best ab initio predictor (Twinscan), showing the benefit of evidence combination. Furthermore, eCRAIG achieves the highest overall accuracy at all levels both with and without alignment evidence. In both cases, specificity improves slightly more than sensitivity across all levels, supporting the hypothesis that global discriminative training is advantageous in evidence combination. Overall, eCRAIG performs the best among of all methods, except for a somewhat lower single exon sensitivity but higher single exon specificity than eCRAIG-NoAlign. The absolute F-score improvement of eCRAIG over Combiner, the second-best program overall along with eCRAIG-NoAlign (seeand b), is 5.8% for complete gene structures. The absolute F-score improvement at the gene level for eCRAIG-NoAlign over Combiner-NoAlign is 3.8%. eCRAIG improves over eCRAIG-NoAlign on internal and terminal exons with an absolute F-score of 1.7% and 2.2%, respectively. Single and initial exon predictions also improve somewhat, which is expected as the alignments are of better quality near splice signals than translational signals. The improved gene-level accuracy follows from these gains at the exon level. Evigan(-NoAlign) performs worse than Combiner(-NoAlign) in most categories whereas ab initio gene finders perform much worse than ensemble predictors at all levels.
Predictions for nGASP dataThe nGASP project () is a C.elegans gene annotation initiative which emulates the efforts made by EGASP () for H.sapiens. Several groups involved in computational gene prediction research were invited to submit gene predictions on 10 non-overlapping 1 Mb regions of C.elegans genome assembly build WS160. Ten regions of similar size were also provided as training data. The organizers asked the participating groups to train new gene models using only the given training set. The nGASP evaluation had two rounds. In the first round, the contest was open to all Category 13 predictors: ab initio,
Automated gene-model curation(a)de novo and reference-based. In this phase, alignments to closely related organisms and EST and protein data for all regions were made readily available as auxiliary information. The second round, open to ensemble-type predictors, allowed predictors to use all round-one predictions as well as the original auxiliary information. Sensitivity and specificity were evaluated with eGASP metrics. Seventeen groups participated and submitted 44 prediction sets to nGASP; out of these, 12 sets corresponding to Category 4 predictions were filtered out. Some groups submitted multiple prediction sets using different running parameters; out of these, we removed redundant sets: Category 3 predictors MGENE v2, EUGENE v1 and MAKER+SNAP v2; Category 2 predictor MGENE v2; and Category 1 predictors AUGUSTUS v1, MGENE v1 and SNAP. Finally, we did not include Category 1 predictors Agene and ExonHunter due to their very poor prediction performance and to avoid the extra computational cost. The final set of evidence sources which were used as input for training eCRAIG are listed in3 (see Supplementary Material). The current version of eCRAIG can only accomodate evidence for a single transcript at each gene locus. This posed a problem when incorporating prediction sets containing multiple transcripts at a single locus. In these cases, we removed all transcripts but the longest one; the actual number of transcripts used as input evidence for eCRAIG is shown in3 (see Supplementary Material). Following the nGASP guidelines for performance evaluation, we added a transcript-level prediction category in our reports to better evaluate predictions on alternatively spliced genes. Accuracy results at the gene and transcript level for all these submissions as well
A.Bernal et al.
Predictions for the ENCODE regionsOur)] as our gold standard. To handle prediction sets with multiple transcripts per locus, we proceeded in similar way to the nGASP experiment above, retaining only the longest transcript for each locus. This procedure affected prediction sets corresponding to predictors ENSEMBL, Aceview, MARS, Exogean and FgenesH++. As with C.elegans, we added a transcript-level prediction category in our evaluation and closely followed the evaluation procedures proposed by () and (). Following nGASP guidelines for training ensemble predictors, we trained eCRAIG on set ENCODETR137 but using only annotations from input sources which are not combiners themselves. From the 16 available sources, we used only the top nine as input, ranked by their accuracy on the training set. These sources are ENSEMBL, Pairagon+mRNA_EST, NSCAN, Aceview, Exogean, ExonHunter, MARS, Twinscan and CRAIG. Including other sources (see Section 4) did not increase prediction accuracy and slowed down training and decoding considerably. The absolute F-score improvements at the transcript and gene levels are 3.2% and 7.3% over JIGSAW (see Figs 1e and f), yet again the runner-up program. Actual accuracy values for all levels are shown in Table S-5 (see Supplementary Material). As in previous experiments, eCRAIG achieves higher gains in specificity than in sensitivity at all levels. At the transcript and gene level, eCRAIG predicts with slightly more sensitivity and considerably more specificity than JIGSAW. At the exon level, eCRAIG predicts correctly 5% fewer exons than JIGSAW, but it also makes 5% fewer mistakes. However, eCRAIG predicts 15% more correct gene structures and 11% fewer TIS false positives than JIGSAW. Furthermore, there are 75 genes that eCRAIG predicts correctly but JIGSAW either misses or predicts wrongly averaging 9.8 exons and 56 kb in length; conversely, JIGSAW predicts correctly 43 genes averaging 6.3 exon and 23 kb in length that eCRAIG either misses of predicts incorrectly. These results imply that eCRAIG predicts longer transcriptstypically those with a higher number of exonssignificantly better than JIGSAW as the latter would sometimes miss a long transcript in favor of two shorter, often incorrect ones.
Significance testingWe tested the statistical significance of eCRAIG's improvements at the transcript level by comparing its results against the runnerup program for each experiment. Any transcript belonging to a particular test set is associated with two dependent Bernoulli random variables that indicate whether it was correctly predicted by eCRAIG and by the runner-up program. We compute twotail p-value upper bounds with McNemar's test for dependent, paired samples extracted from predictions made by eCRAIG and the runner-up in each case. The null hypothesis is that eCRAIG's advantage in transcript predictions is due to chance. The p
values,shown in6 (see Supplementary Material) are <0.05 for all the experiments, which implies that eCRAIG's improvements are unlikely to be due to chance.
METHODS
BackgroundIn what follows,,T,C,G}, is the input or target sequence, s = s 1 s Q is a segmentation of x, where each segment s j = p j ,l j ,y j starts at position pos(s j ) = p j , has length len(s j ) = l j and state label lab(s j ) = y j , where p j+1 = p j +l j  P, 1 l j  B for some upper bound B and lab(s j ) is a state in the finite state machine (FSM) that models the gene structure shown in2 (see Supplementary Material). Given E, the set of evidence sources, we define,.}, the evidence sequence associated to source e  E, as follows:where source e is encoded as a segmentation s e over x, 1 i  P, range(s) = [pos(s),pos(s)+len(s)1], p is the segment phase and frame(i,s) = (i pos(s)) mod 3. For H.sapiens and C.elegans, evidence sequences distinguish between short (i) and long introns (l).shows this notation applied to an example in A.thaliana. Linear structure models for ab initio gene prediction were first introduced in (, pp. 494495). In this article, we apply these models to the ensemble gene prediction problem with two notable extensions. First, online parameter updates are now computed using AROW instead of MIRA and second, our learning procedure can now train with alternatively spliced instances. Detailed descriptions of these extended models are given in Section S-1 (see Supplementary Material). For gene prediction, we need to define three basic components. First, an inference method that can efficiently find the best-scoring segmentation for a given sequence x. Second, a training method that can learn weights using dataset T ={(x (t) ,s (t) )} T t=1 , such that the best-scoring segmentation of x (t) is close to s (t). Finally, we need to select a feature function f that is compatible with the first two components while providing good generalization to unseen test sequences. The inference and online learning algorithms are described in Sections S-2 and S-3 (see Supplementary Material), respectively. Feature function f is described in the next section.for a fragment of A.thaliana's gene annotation_60464.08. We use E p (I p ) to represent all types of exons(introns) in phase p. These phases are computed as the CDS length (mod 3); the CDS length is measured up to the end of the previous segment. For instance, s 3 represents an intron in phase 16 (mod 3) = 1. Phases are reset to zero for intergenic regions. Notice how, at testing time, coding exon phases could be guessed by examining x e 's triplet occurrences. For example, segment s 4 is likely an exon in phase 1 since the triplet following the acceptor is of the form-E in four out of the five available sources of evidence
Automated gene-model curation
FeaturesThe main component of our model is a feature function f used to score candidate segments based on properties of the input sequence. A typical feature relates a proposed segment to some property, i.e. a real-valued function of the input sequence around that segment, and possibly to the label of the previous segment. We distinguish between state and transition features. The former represent the content properties of a given genomic region whereas the latter look at biological signals and indicate a switch in genomic region type. Features testing for those signals look for motif enrichment within a window centered at a given offset from the position where the region switch occurs. In all our experiments, feature functions do not depend on the strand of the genomic signal or region given as argument, so we only give the feature descriptions for the forward strand. Features looking at genomic regions or signals in the reverse complementary strand receive as input the reverse complemented sequence. First, we introduce a variation of binning (, p. 496), also described in Section S-4.2 (see Supplementary Material), to handle multimodal and/or sparse property value distributions.
Piecewise-linear binningWe found that a better alternative to binning is to pass property values through a continuous piecewise-linear function instead of a piecewise-constant one. To this end, we initially proceed as in binning, i.e. we split the range of property values into disjoint intervals and their associated tests. In contrast to binning, each interval test is now associated with two real-valued functions instead of a boolean function. These real-valued functions are associated to the interval's left and right boundaries and their values add to one. More formally, let c = c 1 ,...,c m be the interval boundaries, also called control points, let v be the property value and let [c l ,c r [ be the interval selected for property value v, where:The functions associated with the control points c l  v < c r are 1h(v,c) and h(v,c), respectively, whereUsing this procedure, the property value v is transformed into a linear interpolation of the heights of the interval boundaries c l and c r. These heights are learned as weights of the real-valued feature functions associated with the interval's left and right boundaries. For regular w-wide intervals, we denote this transformation by Lbins w (v).
Piecewise-N-linear binningPiecewise-linear binning can be generalized to N-dimensional vectors of correlated real-valued properties. Here, control points defined for each property are placed along each dimension with the goal of constructing a N-dimensional grid where the height of each grid point is learned as the weight of its associated feature. Given property values v 1 ,...,v N and control point sets c 1 c N , it is easy to see that the set of intervals], 1  i  N selected for each value v i form a hyper-rectangle. The set of features associated to each corner of this hyper-rectangle, denoted by S N , is given by the following recursive formula:It is easy to see that property values v 1 v N are transformed into a Nlinear interpolation of the heights at each corner of the hyper-rectangle formed by the selected intervals. For regular w-wide intervals used across all property values, we denote this transformation by N-Lbins w ({v 1 , ,v N }).shows the complexity in the number of features to be exponential in N, the number of dimensions. This is a theoretical limitation of our model.
State features
Agreement features:These features measure how much different sources of evidence agree on the analysis of the target sequence. To measure agreement, we start by summarizing each evidence sequence x e , e  E with a set of n-gram counts. The simplest agreement features count 3-grams u in phase q = 0,1,2 on evidence sequence x e and are denoted by count e,u,q. We also define agreement features dcount e,u,u ,q that summarize the distribution of count e,u,q counts for each 3-gram u in target sequence x. Counting n-grams for each source separately can suffer from data sparsity, so we also use aggregate features that simply count the number of sources that agree on a particular n-gram and phase, ovcount u,q. Count features for individual sources can also be conjoined to extract more fine-grained features from source agreements. Conjunctions between S count e,u,q features are denoted with countcnjAll the agreement features mentioned above have a predictive effect that is a linear function of their value. However, typically, evidence sources display a varying predictive effect that depends on their level of agreement with the reference annotation. This non-linear effect can be achieved by splitting the range of agreement counts into bins, as described in S-4.2 (see Supplementary Material). We refer to this function as agreement count duration, since it constructs a explicit length model for agreement count distributions. To handle sparse observations in the tail region of these distributions, we take the log 2 of the original feature values as input. We only define duration models for the log 2-scaled values of features count e,u,q , u,, |u 1 |=|u 2 |=1. These restrictions are necessary due to data sparsity and computational complexity problems that arise for large values of u. None of the agreement features mentioned above are defined for intergenic states. A formal, detailed description of these features is given in Section S-5 (see Supplementary Material).shows how most of these agreement features are extracted from four sources and a reference annotation in A.thaliana.
Coding quality score:If an evidence source e provides a quality measure of its annotation, we define q e = q e,1 q e,P as the alignment quality scores associated with source e. These scores are zero for positions not in phase with a coding region. The coding quality score is computed in the following way:This sum is computed over non-overlapping codon scores instead of base scores to capture coding phase information. Coding quality scores could also display a non-linear predictive effect. To model this behavior, we use piecewise-linear binning over the range of codQ e values, as described in Section 3.2.1. This method performed significantly better than simple binning in all experiments.
Coding quality score correlations: Let Ebe the set of evidence sources with associated quality scores. To capture correlations of coding quality scores among multiple evidence sources e, e  E , we use piecewisen-linear binning, as described in Section 3.2.2. Here the binning is over the range of feature values codQ e , e  E. As mentioned before, this multidimensional binning generates a number of features that is exponential in |E |. However, |E | is typically a small value in practiceit is 2 in our experiments. Furthermore, correlations can be computed as pairwise relations or precomputed and cached if needed, so the computational cost was not high in practice.. Agreement features are described in detail in Section S-5 (see Supplementary Material)displays the feature values computed for all the training dataset of a piecewise-2-linear binning of codQ e quality scores provided by protein alignment source NRAA and EST alignment source GAP2 in A.thaliana. Table S-9 (see Supplementary Material) shows a summary of all the state features associated with each genomic region type.
Transition features
Motif features:Motif features look for combinations of particular motifs within a window at a given offset from a state transition. These features, denoted by motif e,o,u,l,p , where o is the offset, u is the enriched motif, l is the window width and p = 0,1,2, test for motif occurrences around potential genomic signal locations in the target sequence. These locations correspond to positions annotated as genomic signal occurrences by some evidence source e  E. This approach gave better accuracy and decoding efficiency than using the signal consensus sequences typical in ab initio gene prediction. It is straightforward to define windowed weight array models (WWAMs;, where q and r are set so that the WWAM can capture both motif occurrence and phase information from each source. A position weight matrix (PWM) is a special case of WWAM and can be definedIn situations where data sparsity is a problem, features that simply count the number of sources agreeing on a motif with the reference annotation could be useful. We call these features overall motifs and denote them by ovmotif o,u,l,p. These counts are piecewise-linearly binned to incorporate a non-linear predictive effect on the number of sources agreeing on motif u. A visual representation of some of these WWAM-based features for a region in A.thaliana is given in. For a more formal, detailed description of these features refer to Section S-6 (see Supplementary Material).
Signal quality score:Quality scores can also be associated with signal occurrences. Let E be the set of evidence sources that are either. Piecewise-2-linear binning feature values for NRAA (protein alignment) and GAP2 (EST alignment) scores for A.thaliana. Feature values were computed for coding regions in the entire training dataset. The alignment quality scores range from 0 to 100. A peak in the surface indicates strong agreement between the sources. For example, the peak at coordinates (0,0) and (100,100) in the XY plane, indicate that a significant portion of coding regions were either not aligned or aligned with the highest score in both sources simultaneously. The feature values computed at each corner of any rectangle of this two-dimensional grid are: (1h(v 1 ,, where function h is described in the textthe corresponding signal quality score. These scores will be zero for positions where e does not indicate a signal. We proceed similarly as in coding quality scoring features and use piecewise-linear binning over the range of q e,i values, 1  i  P.
Signal quality score correlations:To capture correlations of signal quality scores among multiple evidence sources e, e  E , we use piecewisen-linear binning, as described in Section 3.2.2. The setting is similar to the one applied for coding quality score correlations, but here the binning is over the range of q e,i , e  E , 1  i  P values.Descriptions of eCRAIG-NoDConj and eCRAIG-NoLBin are given in the text. Note, eCRAIG-NoLBin was only trained and tested on the A.thaliana experiments, as those were the only ones including alignment quality scores as input evidence. Sp, specificity; Sn, sensitivity
Automated gene-model curation
DISCUSSION
Unreachable genesOur prediction results did not account for the presence of unreachable genes in the test datasets; as such, all our results are biased toward lower sensitivity values at all levels. The statistics for unreachable genes and signals as well as the sensitivity of oracle predictions at the transcript, gene and signal levels are given in11 (see Supplementary Material). For example, the highest possible transcript-level prediction sensitivity that could be achieved in the EGASP test dataset is 63%; at 32.0% sensitivity, eCRAIG predicts slightly more than half of the EGASP transcripts correctly. On the other hand, at a gene-level sensitivity of 70.8%, eCRAIG missed or predicted incorrectly only 34 out of the 241 reachable EGASP genes, or 14.1%.
Accuracy effect of complex featuresOur gene models integrate features such as durations of agreement count conjunctions and quality score multidimensional correlations, that are either conceptually or computationally complex. Here, we investigate whether the predictive effect of these features is worth their inclusion. For this, we trained and tested '-NoDConj', to denote a variant of eCRAIG that removes all duration features for agreement count conjunctions. For A.thaliana only, we used '-NoLBin', to denote a variant of eCRAIG that uses simple binning and binning conjunctions instead of linear (and n-linear) binning for modeling both state and signal quality scores and their correlations. The results at the gene level for these variants compared with the base model for each experiment are shown in. The results are as expected: n-linear binning features and durations of agreement count conjunctions improve accuracy across all experiments. In particular, the predictive effect of duration conjunction features on EGASP improved gene-and transcript-level accuracy by 10% in absolute F-score. An effect of this magnitude was not observed in A.thaliana or C.elegans, presumably because potential gains might have been offset by having sufficient training data. Detailed results of these comparisons and an analysis of the relevance of other features for prediction are given in Table S-12 and Section S-7 (see Supplementary Material).
Accuracy effect of the evidence source setIt would be expected for prediction accuracy to increase as more external annotations are integrated as evidence sources, provided the features extracted from these sources are conditionally independentgiven the input sequence. However, conditional independence is not guaranteed, as sources typically are created using related algorithms, or even the same algorithm ran with different parameters. To quantify the accuracy effects as more evidence sources are added, we conducted a series of experiments using an increasing number of non-redundant evidence sources ordered by their agreement level with respect to the annotation. Sources deemed redundant (see Section 2) were added last. In a second round of experiments, we added a single source two consecutive times at some point early in the series to illustrate the negative effects of feature dependencies and whether the model recovers from its inclusion. At each point, we computed splice site prediction accuracy on the original test set and plotted these results for organisms H.sapiens and C.elegans as shown in.
Global discriminative learningOur experiment results have shown that global discriminative learning can achieve superior results in ensemble-based gene prediction. A similar conclusion had been reached earlier for the simpler problem of ab initio gene prediction (). Yet, our present work uses a refined learning algorithm better able to cope with the wide range of features and feature distributions in genomic data. Discriminative models involve fewer conditional independence assumptions on observations and labels than generative models such as HMMs, thus allowing us to combine a wide range of
A.Bernal et al.weakly informative features to learn models that directly maximize annotation accuracy. We have benefitted from those advantages in designing the rich, varied features discussed in Section 4.2, and especially in using conjunctions to model feature interactions as seen in Section 4.3. However, discriminative models are also more prone to overfitting due to insufficient training data, and discriminative learning algorithms for complex problems like gene prediction need to be carefully tuned to actually get close to the theoretical optimum of the learning objective. In particular, the training algorithm used in our CRAIG ab initio predictor, MIRA/PA, does not converge well when features have very different dynamic ranges and distributions in the training data, leading us to adopt the newer AROW algorithm. Accuracy results obtained by MIRA-trained models are shown in3 and Table S-12 (see Supplementary Materials). These results are comparable to JIGSAW but significantly lower than eCRAIG. This improved performance can be explained by AROW's ability to keep track of weight confidence information during learning. Intrinsic attributes of gene structures, such as variable state lengths, bring about features that scale differently, appear in different fractions of the input data and have different scopes. For instance, counting features that look at sequence positions will occur much more often than features that look at entire segments, such as lengths. For features that are rare or sparse, methods like MIRA and perceptron do not attribute enough weight during training because such features are also updated rarely. However, when using confidence information, the weights for rare features have lower confidence and are thus updated more aggressively than the higher-confidence weights for features seen often in training. In other words, AROW, in contrast to MIRA and perceptron, can distinguish between features that are important and features that are reliable. This ability of AROW to better handle data sparsity and rare features made it also possible for eCRAIG to successfully learn from relatively small training sets. For instance, we only used 129 genes and 8 Mb of sequence data to learn our H.sapiens model, compared with 1500 genes which were reportedly used for training JIGSAW.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
as eCRAIG's are presented in Figures 1c and d. Actual prediction accuracy values for all levels can be found in Table S-4 (see Supplementary Material). Performance numbers for predictors other than eCRAIG were obtained from Coghlan et al. (2008). Evaluation of eCRAIG's predictions followed the same procedure established by the nGASP organizers to assess prediction performance, that is to say, sensitivity (Sn) at all levels was obtained using only full-length cDNAs as reference (set NGASPA313) whereas specificity (Sp) was obtained using all manually curated genes in the test regions, both experimentally confirmed and unconfirmed (set NGASPC966). As shown in Figure 1c and d, eCRAIG outperforms all other programs at the gene and transcript level. The performance gap between eCRAIG and the second-best program, JIGSAW v1, measured by absolute F-score improvement, is 4.4% at the transcript and 4.7% at the gene level. These improvements are similar to those in our A.thaliana experiment above: scores are improved overall, with specificity gains being slightly higher than sensitivity gains. Some programs do well at predicting individual exons, but less well at assembling exons into correct transcripts, especially in the presence of alternative splicing. As a result, eCRAIG's gains relative to those programs are lower at the exon level than at the transcript level. Programs capable or predicting multiple transcripts at each gene locus reported fewer number of false negative exons at the cost of a much higher number of false positives. For example, EUGENE cat4 v2 predicts 1638 transcriptsalmost 70% more than the annotationand finds 32 more true positive transcripts than eCRAIG. However, EUGENE cat4 v2 also predicted 301 more false positive transcripts than eCRAIG.
