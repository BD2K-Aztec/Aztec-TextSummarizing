Motivation: A palindrome is a string that reads the same forward and backward. Finding palin-dromic substructures is important in DNA, RNA or protein sequence analysis. We say that two strings of the same length are pal-equivalent if, for each possible centre, they have the same length of the maximal palindrome. Given a text T of length n and a pattern P of length m, we study the pal-indrome pattern matching problem that finds all indices i such that P and T ½i À m þ 1 : i are pal-equivalent. Results: We first solve the online palindrome pattern matching problem in O(m 2) preprocessing time and O(mn) query time using O(m 2) space. We then extend the problem for multiple patterns and solve the online multiple palindrome pattern matching problem in Oðm k MÞ preprocessing time and Oðm k n þ cÞ query time using Oðm k MÞ space, where M is the sum of all pattern lengths, m k is the longest pattern length and c is the number of pattern occurrences. Availability and implementation: The source code for all algorithms is freely available at http://toc.
IntroductionFinding motifs and patterns in bio strings has been one of the most popular topics in both computer science and biology (). A palindrome is a string that reads the same forward and backward. Namely, a string w is a palindrome if w  w R , where w R denotes the reversal of w. If a substring of a string is a palindrome, we say that the string has a palindromic substring or palindromic structure. It is important to find palindromes and identify similar palindromic structures in DNA, RNA or protein sequence analysis (). Since palindromic structures in bio data reflect the capability of molecules to fold and form doublestranded stems (), bio data with similar palindromic structures may have similar secondary structures. Moreover, palindromic sequences are closely associated with DNA breakage during gene conversion (), and palindromic substructures are presented in CRISPR/Cas9 (), which has been used for gene editing and gene regulation in species (). Therefore, it is useful to identify palindromic substructures and palindromic equivalence efficiently. We focus on the palindrome pattern matching problem introduced by. Given a text T of length n and a pattern P of length m, the palindrome pattern matching problem is to find all indices i such that P and Ti  m  1 : i have the same set of all centre-distinct maximal palindromes. Seefor an example.presented two algorithms that solve the palindrome pattern matching for an arbitrary size alphabet. We notice that both algorithms byrequire a preprocessing step of T. This may slow down the whole process when T is an extremely large text and I/O for T is considerably slow due to the large but slow storages. Moreover, these algorithms might not be applicable if T is a stream data. Many researchers designed online string algorithms to avoid these problems, where each character in T is given online, and we want to report intermediate results without readingwhole T (). For the palindrome pattern matching problem, we want to report all matching indices i while reading T online. Based on the KnuthMorrisPratt algorithm (), we first build an automaton A from P and process T using A. For a text T of length n and a pattern P of length m, our algorithm requires O(m 2 ) preprocessing time and runs in O(mn) query time using O(m 2 ) space. We, furthermore, tackle the online multiple palindrome pattern matching based on a modification of the AhoCorasick automaton (). For multiple patterns P 1 ;. .. ; P k of length m 1 ;. .. ; m k , our algorithm requires Om k M preprocessing time and runs in Om k n  c query time using Om k M space, where M is the sum of all pattern lengths, m k is the longest pattern length and c is the number of pattern occurrences. Note that the second algorithm considers multiple patterns and has the same query time as the first algorithm except the number of pattern occurrences.
Methods
Strings, palindromes and finite automataA finite-state automaton (FA) A is specified by A  Q; R; d; s; F, where Q is a set of states, R is an alphabet, d : Q  R ! Q is a transition function, s 2 Q is the start state and F Q is a set of final states. A string w is accepted by A if there is a labeled path from s to a state in F such that the path spells out w. For complete background knowledge in automata theory, the reader may refer to textbooks (). For a string w, let w R denote the reversed string of w. A string w is called a palindrome if w  w R. The radius of a palindrome w is jwj 2. The centre of a palindromic substring wi : j of a string w is ij 2. A palindromic substring wi : j is called the maximal palindrome at the centre ij 2 if no other palindromes at the centre ij 2 have a larger radius than wi : j; in other words, if wi  1 6  wj  1, i  1 or j  jwj. Let Pals(w) be the set of all centre-distinct maximal palindromes where each element is encoded by a pair of its centre and radius (). Namely, given a string w, Palsw  c; r wc  r  0:5 : c  r  0:5 is a maximal palindrome at centre c  1; 1:5; 2;. .. ; nFor example, if w  abbacabbba, we have Palsw  f1; 0:5; 1:5; 0; 2; 0:5; 2:5; 2; 3; 0:5; 3:5; 0; 4; 0:5; 4:5; 0; 5; 3:5; 5:5; 0; 6; 0:5; 6:5; 0; 7; 0:5; 7:5; 1; 8; 2:5; 8:5; 1; 9; 0:5; 9:5; 0; 10; 0:5g:For two strings w and z of the same length, we say that w and z are pal-equivalent if Palsw  Palsz.proved that for a string w of length m, we can compute Pals(w) in O(m) time. From now on, we assume that the elements of Pals(w) are sorted in increasing order of centrers cthe algorithm ofBased on Definition 2.3, we establish the following result: after running Algorithm 1, if there is a surjection of A to R where Ai 6  Aj holds for all i, j such that j 2 Bi, then PalsP 0   PalsP. Moreover, given a string w such that Palsw  PalsP, there exists a surjection of A to R such that P 0  w. We analyze the time and space complexity of Algorithm 1. Computing Pals(P) takes O(m) time. Since the for loop from line 6 to line 10 takes O(m) time and line 12 also takes O(m) time, the time complexity of the algorithm is O(m 2 ). For the space complexity, Am and P 0 requires O(m) space and Bm requires O(m 2 ) space. Therefore, the space complexity is O(m 2 ). Once we have P 0 , we can construct a special automaton A  Q; Ag; d; s; F; R; B; d f ; H that finds all occurrences of P 0 in T as follows: @BULLET Q is the set of states, @BULLET A is the array of variables (which is used as an alphabet in A) and ] is a wildcard variable, @BULLET d : Q  A ! Q is the transition function, @BULLET s is the start state, @BULLET F is the set of final states, @BULLET R is the alphabet of the original pattern P, @BULLET B is the array for inequality conditions of variables, @BULLET d f : Q ! Q is the failure transition function, and @BULLET H : Q ! 2 AAg is the set of injective functions for variables.Note that four parametersR; B; d f ; Hare added to the definition of a traditional FA. The automaton A simulates the Knuth MorrisPratt algorithm, using P 0 instead of P as a pattern. In the KnuthMorrisPratt algorithm, when there occurs a mismatch, the algorithm uses the longest suffix of the prefix of T read so far, which is a prefix of P 0. The automaton A simulates the process when a mismatch occurs by d f , and additionally, changes surjection of A to R according to H. Algorithm 2 constructs an automaton A from P andshows an example automaton constructed from P  AGCGTA. We establish the time and space complexity of Algorithm 2 as follows: We can compute Pals(P) in O(m) time and, based on Pals(P), line 11 takes O(m) time. Since other lines in the algorithmexcept for loops require constant time, the total time complexity is O(m 2 ). For the space complexity, there are O(m) states in A. For each state, there are one out-transition, one outgoing failure transition and O(m) injective functions. Therefore, the space complexity is O(m 2 ). Now we present an algorithm that solves Pal-Matching using A. Based on the KnuthMorrisPratt algorithm, Algorithm 3 processes T in A and reports all end-indices of matching occurrences. We analyze the time and space complexity of Algorithm 3. Checking the condition in line 5 takes O(m) time, and the for loop in line 6 takes O(m) time. Note that lines 56 runs once for one execution of line 6, where l decreases. For each i, l increases by 1 in line 7. Since l ! 0, the total runtime of the while loop from line 5 to line 6 is O(mn). Combined with Algorithm 2 in line 1, the algorithm requires Om 2  mn time and O(m 2 ) space. Thus, given a text T of length n and a pattern P of length m, we can solve the online palindrome pattern matching problem with O(m 2 ) preprocessing time and O(mn) query time using O(m 2 ) space.
The algorithm for MPal-matchingNow we extend the previous algorithm to solve MPal-Matching. The basic idea of the algorithm is to process multiple patterns at once with a single automaton, based on the idea of the Aho Corasick automaton (shows an example automaton constructed from P 1  AGA; P 2  ACTG; P 3  ATAT; P 4  TCTGC. We analyze the time and space complexity of Algorithm 4. We can compute PalsP j  in Om j  time and, based on PalsP j , lines 14For each state, there are one out-transition, one outgoing failure transition, at most one outgoing pattern suffix transition and Om k  injective functions. Therefore, the space complexity is Om k M. We design Algorithm 5 similar to Algorithm 3 on B to solve MPal-Matching with an additional process: whenever the current state q l reaches a final state q f , return all patterns that are connected by d p from q f. This additional process requires O(c) total runtime, where c is the number of pattern occurrences. Since the size of H for each state in B is bounded to m k , the algorithm requires Om k M  m k n  c time and Om k M space. Therefore, given a text T of length n and a pattern P of length m, we can solve the online multiple palindrome pattern matching problem with Om k M preprocessing time and Om k n  c query time using Om k M space.
ExperimentsWe design three experiments to estimate the average performance of the algorithms. For Algorithm 3, we first establish two parameters the length m of the pattern and the length n of the textand estimated three valuesthe preprocessing time t p , the query time t q , the number s of variablesfor random DNA patterns and texts. Second, we calculate the average number of variables for small m by considering all possible patterns of length m. Third, for Algorithm 5, we use real RNA data as a pattern set and measure the preprocessing time t p and the query time t q by two parametersthe sum M of all pattern lengths and the longest pattern length m k. The details of the experiment are as follows:1. For the first experiment, @BULLET The length m of the pattern changes from 10 to 100 by 10, and then from 100 to 1000 by 100. The length n of the text changes from 10 000 to 100 000 by 10 000. @BULLET For each pair of m and n, we randomly generate a pattern and a text from an alphabet fA; G; C; Tg 100 times, and calculate the average value of the preprocessing time t p , the query time t q and the number of variables s.
Forthe second experiment, we iterate all possible strings for 1 m 10 and calculate the average of s for each m. 3. For the third experiment, @BULLET We use 24 RNA secondary structures belonging to distinct RNA families from the Rfam database () as a superset of a pattern set. The set of RNA secondary structures used is in the supplementary material. @BULLET We use a RNA-sequence of length 100 000 from the ArrayExpress database () as a text. We checked that each pattern in the superset does not appear in the text, which erases the factor c from the runtime. @BULLET We run 100 iterations. For each iteration, we first choose a pattern p k , and then select each pattern in the superset with the length less than jp k j with the probability 1 2 to form a set of patterns for the iteration. We compute the preprocessing time t p and the query time t q. We obtain the following results from our experiments (note that we have rounded our results to the nearest hundredth.):@BULLET Preprocessing time of Algorithm 3:shows the preprocessing time t p of Algorithm 3 according to the length m of the pattern (the table for the graph is in the supplementary material). @BULLET Query time of Algorithm 3:shows the query time t q of Algorithm 3 according to the length m of the pattern and the length n of the text (tables for graphs are in the supplementary material). @BULLET Number of variables: In Algorithm 3, the query time is bounded to O(ns), where s is the number of variables.shows the number of variables s according to the length of the pattern m (The table for the graph is in the supplementary material). The data for m  110 is the average of s for all possible cases, and the data from m  10 to m  1000 is the average for 100 random cases. @BULLET Pre-processing time of Algorithm 5:shows the preprocessing time t p of Algorithm 5, according to the sum of all pattern lengths M and the longest pattern length m k. @BULLET Query time of Algorithm 5:shows the query time t q of Algorithm 5 according to the longest pattern length m k and the sum of all pattern lengths M. We observe that t q is independentthe preprocessing time. We can observe that t p follows the quadratic function of m since tp  Om 2 . to M but it is not clear whether or not t q is proportional to m k. We design another experiment to determine the factor that affects m k most. @BULLET T is a randomly generated text of length 100 000. We run 1000 iterations for different sets of patterns. @BULLET For each iteration, we choose m k between 100 and 200, and generate a set of random patterns, where M is 1000.the query time. We observe that t q is proportional to n and m since tq  Onm. Note that t q for n  10 000 and m  100 is 13.02, whereas t q for n  100 000 and m  10 is 31.56. This implies that the increase of m affects t q less than the increase of n. Query time graph for Algorithm 5, considering m k and M. m k denotes the length of the longest pattern, M denotes the sum of the lengths of all patterns and t q denotes the query time. We observe that t q is independent from M. Number of variable graph, where m denotes the length of the pattern and s denotes the number of variables used. For m  110, we observe linear increase of s as m increases. The difference of s between m and m  1 tends to decrease as m increases, but the difference rapidly converges to 0.47, and we can easily approximate s  0:47m (Note that s  468.78 when m  1000.). Preprocessing time graph for Algorithm 5. We observe that t p is proportional to M and m k since tp  Omk M. Query time graph for Algorithm 5, considering goback and checkall. goback denotes the number of changes on the array of variables, checkall denotes the number of pattern suffix transitions taken, and t q denotes the query time. This graph shows that t q is proportional to goback, which is Om k n but the average value is far less than m kn and not proportional to m kn @BULLET We record the number of changes on the array of variables (which we call goback) and the number of pattern suffix transitions taken (which we call checkall).shows the query time t q of Algorithm 5 according to goback and checkall. Theoretically, t q  Om k n  c, the upper bound of goback is m kn and the upper bound of checkall is c. This experiment shows that t q is proportional to goback, which is Om k n but the average value is far less than m kn and not proportional to m kn. This feature makes the algorithm much more efficient than running pattern matching algorithms for individual pattern k times.
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Definition 2.1 (Palindrome Pattern Matching, Pal-Matching in Short): Given a text T of length n and a pattern P of length m, compute all positions i such that PalsP  PalsTi  m  1 : i. We then define the multiple palindrome pattern matching problems as follows: Definition 2.2 (Multiple Palindrome Pattern Matching, MPal-Matching in Short): Given a text T of length n and patterns P 1 ;. .. ; P k of length m 1 ;. .. ; m k , compute all pairs of a position i and a corresponding pattern P j such that PalsP j   PalsTi  m j  1 : i. For a pattern matching problem, we can consider an environment where we want to report all matching occurrences at position i after reading each character Ti. This often requires a preprocessing step of the pattern Pwe call such a problem an online pattern matching problem. We call the time to preprocess P preprocessing time, and the time to read T and find all matching occurrences query time. 2.2 The algorithm for Pal-matching We start from designing an algorithm for Pal-Matching in Definition 2.1. The main idea of our algorithm is to design a special automaton simulating the KnuthMorrisPratt algorithm (Knuth et al., 1977). Before we design an algorithm, we have the following observation (See Figure. 2 for an illustration): For two strings w, z and an index i, if there exists c; r 2 Palsw such that c i and c  r  0:5 ! i, then zi  z2c  i. If there is no (c, r) satisfying the condition, then zi 6 2 fz2r  ijc; r 2 Palsw and c  r  0:5  i  1g. Note that zi is computed based on zj's for j < i, instead of characters in w. This leads us to define z to be a new sequence of variables, where we can assign characters to variables based on equality and inequality conditions, and the result string is palequivalent to w. Based on the observation, we define a variable pattern of P as follows: Definition 2.3: For a pattern P of length m over R of size t, a variable pattern P 0 is defined by an array Am of variables and an array Bm of inequality conditions satisfying the following conditions: 1. P 0 i  Al i  for 1 i; l i m. 2. If there exists c; r 2 PalsP where c i and c  r  0:5 ! i, then l i  l 2ci , and thus, P 0 i  P 0 2c  i. 3. Otherwise, for all j 2 f2r  ijc; r 2 PalsP and c  r  0:5  i  1g; P 0 i 6  P 0 j. For P 0 i  Al i  and P 0 j  Al j , we use Bl i   l j and Bj  i to denote P 0 i 6  P 0 j. Namely, if we assign characters to A based on inequality conditions, then PalsP 0   PalsP. Initially, we have no variables for constructing P 0. The inequality condition of Definition 2.3 implies that for every index i where every maximal palindrome with a centre c i ends before i, we need to introduce a new variable satisfying inequality conditions with respect to the previously-used variables. We construct an array Am of variables. We also construct an array Bm that represents the inequality conditions between all pairs of Fig. 1. An example of the palindrome pattern matching. Stripped boxes below a string represent the set of all centre-distinct maximal palindromes with the length at least 1. Note that the pattern on the left is matched, while the pattern on the right is not matched due to the red-stripped box
H.Kim and Y.-S.Han at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Conclusions Palindromic structures are widely studied in string processing and combinatorics and have applications in the analysis of DNA, RNA and protein sequences. For a text T of length n and a pattern P of length m, we have solved the online palindrome pattern matching in O(m 2 ) preprocessing time and O(mn) query time using O(m 2 ) space. Then we have extended the problem for multiple patterns P 1 ;. .. ; P k and solved the online multiple palindrome pattern matching in Om k M preprocessing time and Om k n query time using Om k M space, where M is the sum of all pattern lengths and m k is the longest pattern length. Note that the algorithm for the multiple palindrome pattern matching does not increase the query time. We performed experiments to analyze the runtime of the algorithms, and found out that the runtime for the multiple pattern matching is much faster than expected. We believe that the algorithm can be efficiently used to find a structural similarity between multiple bio strings. Since the online multiple palindrome pattern matching is first proposed in the paper, our future work includes reducing time and space requirement of the algorithm. Moreover, we believe that the approach to solve the multiple pattern matching based on the AhoCorasick automaton can be applied to pattern matching problems considering other structural equivalences.
