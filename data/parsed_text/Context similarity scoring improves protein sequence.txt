Motivation: High-quality protein sequence alignments are essential for a number of downstream applications such as template-based protein structure prediction. In addition to the similarity score between sequence profile columns, many current profileâ€“profile alignment tools use extra terms that compare 1D-structural properties such as secondary structure and solvent accessibility, which are predicted from short profile windows around each sequence position. Such scores add non-redundant information by evaluating the conservation of local patterns of hydrophobicity and other amino acid properties and thus exploiting correlations between profile columns. Results: Here, instead of predicting and comparing known 1D properties, we follow an agnostic approach. We learn in an unsupervised fashion a set of maximally conserved patterns represented by 13-residue sequence profiles, without the need to know the cause of the conservation of these patterns. We use a maximum likelihood approach to train a set of 32 such profiles that can best represent patterns conserved within pairs of remotely homologs, structurally aligned training profiles. We include the new context score into our HMM-HMM alignment tool hhsearch and improve especially the quality of difficult alignments significantly. Conclusion: The context similarity score improves the quality of homology models and other methods that depend on accurate pairwise alignments.
IntroductionMost methods for fold recognition and protein structure prediction are based on the pairwise alignment of query and template sequence profiles (). Top-performing structure prediction tools add to the profile column similarity score a secondary structure score, which improves the sensitivity for detecting remote homologs and the quality of the resulting alignments (). In order to maximize the information gain and therefore the improvements in alignment quality, various finer-grained alphabets of backbone structure states have been developedtogether with tools to predict these states (). In addition to secondary structure, other 1D structural properties are employed to improve sequence alignments in the so-called twilight and midnight zone, such as solvent accessibility (), residue coordination numbers (), backbone dihedral torsion angles (), 1D environmental fitness scores (), or a combination of these (). In allcases, the discretized 1D structural property is predicted from a local sequence profile window of 13 to 15 positions, and the similarity between predicted and actual 1D properties of the aligned query and template positions is scored. One can get independent of structural information by comparing 1D predictions with 1D predictions. Surprisingly, this works almost as well (). We believe the reason is that the conservation of a 1D structural property is tied to the conservation of characteristic local patterns of amino acid properties, and the conservation of these patterns is scored indirectly by comparing the predicted 1D property. Because the relationship of patterns to properties is 'many to few', for example, many quite different patterns are all characteristic of alpha helix states, more information might be extracted by learning and comparing conserved patterns directly, independent of what actual structural properties they are associated with. Two studies learned local sequence context patterns to improve alignments.train a self organizing map (SOM) to cluster local profile windows. They then trained a neural network to compute an optimum similarity score for aligned pairs of SOM states. Improvements were small, however.and(2013) reported substantial improvements in alignment quality using a non-linear extension of conditional random fields which include as features the local sequence profile neighborhood. Here, we devised a method to explicitly learn strongly conserved local patterns. For training, we cut out pairs of sequence profile windows from structurally aligned, homologous proteins and learn the set of the 32 best-conserved patterns using the expectation maximization (EM) algorithm. With these patterns, which we call 'context states', we define a score that helps to discriminate homologous from nonhomologous positions by analyzing the conservation of patterns between the aligned positions. We show that the new context similarity score improves the quality of global and local alignments of our pairwise alignment tools hhsearch and hhalign () and that this in turn results in better 3D homology models.
Materials and Methods
General approach and notationWe built a large training set of N aligned profile window pairs of D  2d  1  13 columns, by cutting out windows from the structural alignments of the full-length protein domains from the SCOP database (see Section 3.1). We seek to identify the maximally conserved patterns ('context states') irrespective of any predefined structural or functional properties. The conserved patterns are represented by sequence profiles of length D. We call the N aligned training profiles X n  X n i  d; ;.. .; X n i  d;  and Y n  Y n j  d; ;.. .; Y n j  d; ; n 2 f1;.. .; Ng. Here, X n i; a is the number of effective counts of amino acid a at position i in one training profile and position i is aligned to position j in the aligned profile. The effective counts are defined in the following way: let p Xn i; a be standard sequence profile built for sequence X n , that is, the probability of amino acid a occurring at position i in the MSA for X n. The effective counts are defined as X n i; a  p Xn i; a N eff Xn i and analogously Y n j; a : p Yn j; a N eff Yn j. Here, N eff Xn i (abbreviated 'Neff') is the number of effective sequences at position i (Supplementary Material). Each of the K conserved patterns ( context states) is parameterized by a sequence profile p k. p k is a D  20 matrix with p k j; a being the occurrence probability of amino acid a 2 f1;.. .; 20g at profile column j 2 fd;.. .; dg. Each context state has a mixture weight a k. We abbreviate the model parameters by h k  p k ; a k  and H  h 1 ;.. .; h K .
Generative modelWe want to find parameters H that maximize the likelihood functionAll training samples are supposed to be independent of each other so that the likelihood can be decomposed into a product. We use a mixture model for PX n ; Y n jH as shown in. The hidden variable z n 2 f1;.. .; Kg indicates the index of the context state that gave rise to X n ; Y n :Because our model assumes conditional independence of X n and Y n given the hidden context state z n , it follows thatThe context state prior probabilities pz n ja k  are simply the mixture weights a k. We model PX n jp k , the probability to observe counts X n j; a of amino acid a  1;.. .; 20 in column j  d;.. .; d, using a multinomial distribution for each column j,and analogously for PY n jp k . Because the effective counts X n j; a can assume values outside the natural numbers, we replaced factorials x! with Gamma functions Cx  1. We assign a weight w j to each column in Equation (4). The weights are parameterized as w j  w center b jjj , so that central columns contribute more than flanking columns when b < 1. p k and a are discrete probability distributions which need to satisfy. Generative graphical model: each of the N training profile pairs (Xn ; Yn ) is generated by a mixture distribution with K components, the 'context states'. The hidden variables z n encode the context state that gave rise to the n'th training sample (Xn; Yn). Each of the D columns in these count profiles is modeled by a multinomial distribution over the 20 amino acids with parameters p k. The context states have mixture weights a k k  1;.. .; K
EM algorithmWe use the EM algorithm () to maximize the likelihood in eq (1) of generating the pairs of aligned training profiles. Lagrange multipliers allowed us to analytically perform the optimization in the M-step under the constraints in Equation (5) (see Supplementary Material).
Scoring functions
Context states scoreWe define the context score for position i in profile X and position j in profile Y as a log-odds score, S ctx X i ; Y j   log PX i ; Y j jH PX i jH PY j jH (6) that is, the logarithm of the ratio of probability for X i and Y j to have been generated together from the same context state (see Equation 3), divided by the probability for X i and Y j to have been generated independently of each other. By applying Bayes' Theorem twice, PX i jz n ; H  Pz n jX i ; HPX i jH Pz n jH ;this expression can be transformed into the following form, S ctx X i ; Y j   log X znPz n jX i ; HPz n jY j ; H Pz n jH :Note the analogy to the log-sum-of-odds scoring function for profile-profile alignment that was derived in (Here, the amino acid a is analogous to our context state k. The numerators describe the probability to co-emit the same amino acid a or the same context state z n  k, respectively. f(a), the background frequency of amino acid a, is analogous to a k. Multiplying by 1/f(a) (or 1/a k ) corrects for the fact that frequent amino acids (context states) match up more frequently by chance than rare ones. Finally, the total score is a linear combination of profile column score, context states score, and hhsearch's standard three-state secondary structure score ():As the context states score comprises of D  13 columns, we correct the weight w ctx for the redundancy caused by the overlap of D1 positions between two consecutive windows (Supplemental Material).
str alphabet scoreApart from secondary structure, we tested a fine-grained structural alphabet str, which was developed to improve the alignment quality and which performed well in several CASP competitions (). It is an enhanced version of the DSSP alphabet (), which subdivides the E state (bstrand) into six states. We applied the improved four-layer neural networks of () and determined for all query and template residues the probabilities for each of the 13 letters in the str alphabet.We denote p str X i; s as the probability for letter s 2 f1;.. .; 13g at position i of profile X and similarly p str Y j; s for the Y. The str structural score S str is defined as a log-sum-of-odds score in analogy to Equations (8) and(where p str bg is the background probability for str state s in a large set of proteins. This str score was added to the total score with its own optimized weight (Section 2.6).
Data setsFirst, we filtered the SCOP (V1.75, Lo) to obtain a set with a maximum pairwise sequence identity of 20% and enriched each SCOP20 sequence by generating a multiple sequence alignment with our iterative HMM-HMM searching tool hhblits () (two iterations against uniprot20 with standard parameters). Then each MSA was converted into an HMM via hhmake (), ftp://toolkit.genzentrum.lmu.de/ pub/HH-suite/hhsuite-userguide.pdf) with standard parameters. Finally, the dataset was divided into two sets by assigning the members of every fifth fold into a smaller set S train (1492 domains) and the rest into a set S test (5426 domains). Query and templates for the training and optimization set were then sampled from S train, whereas test alignments are sampled from S test. This procedure is important to ensure that none of the sequences in the test sets are homologous to any of the sequences in the training and optimization sets.
Parameter optimizationBecause the time to compute the context score is proportional to K, we need to keep K low in order not to significantly slow down hhsearch. The improvements between K  128 and K  32 were moderate, so we chose K  32. As D  13 for the window width was found to perform well in various related applications (e.g.) we chose the same value without further optimization. We needed to optimize the parameters w center and b describing the weights w j in Section 2.2 and the weight w ctx of the context score in Equation (10). We could get better results by using separate parameter sets for training the context states library w tr center ; b tr  (for which no weight w ctx is needed) and for the alignment stage w al center ; b al ; w ctx . Because systematic testing of w tr center and b tr requires to generate a context library for each setting and furthermore the performance then depends on the other parameters, these were also adapted from () (w tr center  1:3 and b tr  0:85), so that the left and rightmost columns in a context profile get a weight w j6  w j6  0:49. We checked libraries with lower w tr center  0:2 and 0.5, but this led to flatter context states and a drop in performance. To optimize the alignment algorithm parameters, we performed a grid search for w al center 2 f0:2; 0:25; 0:5; 1g and w ctx 2 f0:8; 0:9; 1; 1:1; 1:2g and measured the average of alignment sensitivity and precision on 1000 pairwise alignments where query and template were sampled from S train. We obtained best results for w al center  0:2 and w ctx  1. Surprisingly, w al center turned out to be clearly smaller than 1 so that the context states become flatter during scoring. We optimized the parameters (w ctx ; w al center ; corr) specifically for the ROC5 homology detection benchmark by maximizing the area under the ROC5 curve, using the same context state library as in the alignment quality benchmarks. We used all sequences in S train. In addition to w ctx and w al center , the parameter corr from hhsearch was reoptimized. Differing from the setting for alignment quality, we arrived at w ctx  0:6; w al center  0:4 and corr  0.2. The optimization of the secondary structure score weight and the str alphabet weight were done on the same set and yielded w ss  0.25, w str  0.12.
Results
TrainingWe sampled up to 10 pairs of proteins per superfamily in S train and accepted if their structural alignment score using tmalign () was between 0.5 and 0.85. If a window of width D  13 centered at a structurally aligned residue pair had at least nine pairs within a distance of 5 A  in the structural alignment, the window was selected as a training sample and the D columns in the two corresponding count profiles were cut out. This procedure returned 141 508 training profile window pairs from 2987 pairwise alignments. Subsequently, these training pairs were filtered by calculating the mean column score S aa (Equation 9) over all D  13 columns and we rejected the trivial cases with S aa > 1.5 (46 839 samples). At the beginning of training, we initialized the context states library randomly and ran 25 EM iterations. Different initializations and more iteration led to quite similar log-likelihood values and libraries, indicating a robust training (see Supplementary Section 9 for a plot of the library).
Alignment qualityWe first assess the effect of context similarity scoring for global alignments (Tables 14) since global alignments (or quasiglobal local alignments) are used as input to homology modeling, the most important application of our method. We then proceed to analyze the quality of local alignments (). We created two sets of pairwise alignments, a 'hard set' and an 'easier set'. For the hard set, we sampled 6000 query-template pairs from S test by randomly selecting pairs from the same SCOP superfamily but from a different family, with a tmalign score between 0.5 and 0.9, up to a maximum number of 25 pairs. For the easier set, we sampled 3000 query-template pairs from S test by randomly selecting up to 25 pairs from the same SCOP family with a tmalign score between 0.6 and 0.95. These resulted in a mean tmalign score of 0.61 for the hard and 0.72 for the easier set and in a mean sequence identity of 14.3% for the hard and 16.4% for the easier set (see Supplementary Table S2 and Supplementary Data File). The difficulty for an HMM-HMM alignment algorithm also depends strongly on the amount of evolutionary information available in the two profile HMMs. Even structurally very similar pairs can be difficult to align when their profile HMMs were only trained on thin MSAs with few homologous proteins. Vice versa, even very remote homologs can often be reliably aligned when their profile HMMs were trained on thick, diverse MSAs. To test the influence of the context similarity score on the amount of evolutionary information available in the profile HMMs, we created variant test sets of HMMs trained on MSAs with low diversity. These reflect better the diversity of MSAs encountered in practice than the typically rich and diverse MSAs from sequences in the SCOP, which mostly belong to large, very well studied protein families. To this end, we reduced the number of effective sequences (Neff) of the MSAs to a maximum value of 3 by using hhfilter (with the-neff 3 option. Neff quantifies the diversity in an MSA (Supplemental Material). It lies between 1 for a single sequence and 20. In summary, we have created four different test sets: hard Neff def ; hard Neff low ; easier Neff def and easier Neff low. We measured the alignment accuracy in terms of residue-based sensitivity and precision, where sensitivity TP/(TPFN) and precision  TP/(TPFP). A true positive (TP) is a pair of residues that is aligned correctly, that is, occurs in the reference alignment by tmalign (). A false positive (FP) occurs in the test alignment but not in the reference alignment. A false negative (FN) occurs in the reference alignment but not in the test alignment. All alignments were generated in global alignment mode using hhalign with option-mact 0. We evaluated six different score combinations on each of the four benchmark sets (Tables 13): (i) the baseline version ('profile') that uses only the column score S aa (Equation 9) and no secondary structure score, (ii) the secondary structure score based on PSIPRED predictions () for the first and 3D structure-based DSSP assignments for the second sequence of each pair ('ss'), (iii) the secondary structure score based only on PSIPRED predictions for both sequences ('SS pred '), (iv) the sum of the score in (3) and the score based on the predictions of the 13-state str alphabet (Equation 11) ('ssstr') that was optimized for its positive impact on alignment quality (), (v) the context similarity score (Equation 8) ('ctx') and(vi) the sum of the score in (3) and the context similarity score ('ssctx'). Tables 1 and 2 show the results of the alignment benchmark for the hard test set with default diversity and with low diversity MSAs, respectively. The score 'SS pred ' that makes use of only predicted secondary structure performs almost as well as the score 'ss' that requires the actual secondary structure of one of the aligned proteins, for high and low diversity MSAs. When combined with the secondary structure score based on DSSP, both the 'str' alphabet-based score ('ssstr') and the context similarity score ('ssctx') lead to additional improvements, but these are clearly more pronounced for the 'ssctx' score, which achieves the highest sensitivity and precision on high and low diversity MSAs. All three secondary structure classes profited to a similar degree from the additional scoring terms. Interestingly, the improvements owing to the secondary structure scoring and to the context score are much stronger for low-diversity MSAs than for high-diversity ones (improvement of 'ssctx' over 'ss' of 3.6/2.7% (sensitivity/precision) for high-diversity MSAs and of 11.5/9.2% for low-diversity MSAs). Although the purely sequence-based score SS pred performs similarly to the context similarity score 'ctx' for high-diversity MSAs, the new context score is clearly superior for low-diversity MSAs. On the easier dataset (), secondary structure was still beneficial but the relative improvements in sensitivity/precision declined from 3.6/2.7% for more distantly related pairs to 1.3/1.1% for the easier cases. In contrast to the hard cases, the str-based score and the context scoring led to only minor gains. However, as for the hard set of protein pairs, when MSA diversity was low, str and in particular the context score again yielded significant improvements () over the secondary structure score alone (sens/prec gain: 1 and 0.9% for str and 4.8 and 3.9% for ctx, respectively). So far we have assessed global alignments. To render the comparison of the quality of local alignments meaningful, we have to measure residue-wise precision and sensitivity for different settings of sensitivity versus precision tradeoff. The alignment tools in HHsuite allow the user to control this tradeoff with the-mact option.shows the resulting receiver operator characteristic (ROC) plot. Similarly to the global alignment case (-mact 0.0), context similarity scoring improves the alignment quality and is most beneficial when the number of effective sequences is low.In summary, our new context similarity score consistently improved the alignment quality when combined with the standard secondary structure scoring in hhsearch. In the cases in which no secondary structure is available, the context score ('ctx') also consistently improved the alignment quality in comparison with the other purely sequence-based score ('SS pred '). The extent of improvements is larger the more difficult the alignment is, that is, the more diverged the two proteins are and the lower the diversity of the MSAs that their profile HMMs were trained on (see Supplementaryfor the dependence on alignment diversity). Because the calculation of the context states score increases the runtime by a factor of about 100, one profit mostly when realigning only a set of preselected templates for homology modeling (Section 3.4).
Comparison with the profile alignment tool PPASNext, we wanted to compare hhsearch/hhalign with other profileprofile alignment tools. Although many profileprofile alignment methods have been developed by the protein structure prediction community, most modern methods were not designed to run independently of their protein structure prediction pipeline. Because our goal here is to compare alignment methods and not methods to generate sequence profiles, we could not benchmark these tools. However, PPAS, a profileprofile alignment tool developed in the lab of Yang Zhang, could be modified to run on user defined database profiles. It had been reported to yield equal or better results than hhsearch on a benchmark with hard and medium targets () and performed only slightly worse than their flagship aligner MUSTER () that includes several 1D structure-based scores. We were unable to benchmark MUSTER as tools for pre-computing template profiles containing the 1D structure information are not available. Because PPAS requires profiles in PSI-BLAST format, we converted our template MSAs into PSI-BLAST format by calling blastpgp with the-C option and a dummy database containing a single sequence. Yet for the query we had to keep the dependency on the PSI-BLAST output, because PPAS needs to parse it directly. For the default Neff benchmarks (easier Neff def ; hard Neff def ), we ran PPAS with three PSI-BLAST iterations, and used the default MSAs from S test for hhalign. For the low Neff benchmarks (easier Neff low ; hard Neff low ), we reduced the number of iterations to two, the minimum valid value for PPAS to run. This resulted in an average diversity of Neff  5.9 for the easy set and 5.67 for the hard set which is clearly above our filtered low Neff MSAs (Neff 2.84).The differences between 'ssctx' and 'ss' are significant according to the paired t-test P-value (< 2:2e  16).The upper part summarizes which information is used by each versions (PSIPRED predictions, 13-state str prediction (), the new context score, and the 8-state DSSP secondary structure assignments from the known 3D structure. The lower part gives the overall sensitivity and precision, below subdivided into helix (h) extended beta strand (e) and coil (c) residues, as assigned by DSSP. The differences between 'ssctx' and 'ss' are significant according to the paired t-test P-value (<2.2e16).It is compared with hhalign with secondary structure and context score. For a comparison of hhalign with COMA (), another profileprofile alignment tool (see Supplemetary). Thus, we converted these query PSI-BLAST alignments into a format readable by hhalign, ensuring that PPAS and hhalign received the same input. We compared PPAS with two versions of hhalign: version (3)with secondary structure scoring based on PSIPRED and DSSP and version (6) that additionally includes the context score. Both versions exceeded PPAS's sensitivity and precision by 14 and 17% on the hard set and by 7 and 10% on the easier set, respectively. Surprisingly, hhsearch outperformed PPAS even without secondary structure information.
Application to homology modelingA quality bottleneck in homology modeling is the generation of accurate alignments between the query and template sequences. We therefore tested the impact of our context similarity scoring on homology modeling by comparing the quality of 3D models generated from alignments of different methods. To build the 3D models we used MODELLER (), the most widely used tool for homology modeling. The results are shown in. As expected, the better alignments led to better homology models: The context score in hhalign improved models on the hard set on high diversity MSAs by 10.2% (default Neff) and 9.9% (low Neff) over PPAS models and on the easier set by 6.4% (default Neff) and 5.9% (low Neff). Again, the more difficult the query-template alignments, the larger were the improvements due to the context similarity score.
Remote homology detectionWhen searching large databases like the PDB, out of the numerous matches detected, often only a few are of interest. For homology modeling, for instance, it suffices to identify 15 suitable homologous templates. Consequently, it is important to rank homologous proteins on top. We therefore analyze the sensitivity for remote homology detection using a ROC5 plot. For each query protein, one computes the ROC5 value, which is the area under the ROC curve up to the fifth FP. The ROC5 plot shows the fraction of queries for which the ROC5 value is above the threshold on the x-axis. A measure that summarizes the performance on the ROC5 benchmark is the area under the ROC5 curve (AUC). We performed an all-against-all search with hhsearch in local alignment mode (the standard setting for template searches in our HHpred structure prediction server) on the proteins in S test. We defined members belonging to the same superfamily as TPs and those of different folds as FPs. Pairs with both proteins within the four-to eight-bladed b-propellers (SCOP fold IDs b:66b:70) were treated as unknown, and the same for Rossmann-like folds (c:2  c:5; c:30; c:66; c:78; c:79; c:111). The ROC5 analysis inshows that adding secondary structure ('ss') increases the AUC from 0.583 to 0.609 (4.4%). str and ctx scoring give moderate improvements to 0.625 and 0.641 (2.6 and 5.2% compared with 'ss'), respectively.
Discussion
Context-specific pseudocountsEach residue in a protein is subject to very specific selection constraints that mostly are caused by the requirement of folding into a stable 3D structure. The constraints depend on the local structural context, which can be predicted to some extent directly from each residues' sequence context. In Angerm ller et al. (2012) and Biegert and S ding (2009), we exploited this concept to learn a set of 4000 patterns best describing a representative set of 10 6 training sequence profiles. Using these, we could enrich sequences and sequence profiles with context-specific pseudocounts. This approach is implemented in all hh-suite programs since version 2.0.15. Hence, the improvements observed here come on top of those already reported for context-specific pseudocounts. The difference between the previous approach and the one taken here is the degree to which we demand conservation of patterns. In Angerm ller et al. (2012) and Biegert and S ding (2009), conservation needed to be just good enough to leave a clear pattern in the training profiles built from relatively closely related sequences. Here, in contrast, we use pairs of remotely homologous proteins and structural alignments, which are more reliable than HMM-HMM alignments at low sequence similarities, to find patterns that are highly conserved across large evolutionary distances, roughly corresponding to the SCOP superfamily level.
D structural propertiesIn contrast to secondary structure similarity scores and similar scores based on the conservation of 1D structural properties, we take an unsupervised approach of learning the conserved patterns. Hence, we do not need to know what particular property led to the conservation of the patterns we learn. Therefore, while we have not succeeded in capturing all possible conserved patterns in our 32-state library (shown in Supplementary), we have manifestly learned conserved patterns whose information cannot beThe methods are tested on the same hard and easy set of query-template protein pairs as in the previous section. A high and a medium diversity set of MSAs was built from the query and template sequences using three and two iterations of PSI-BLAST, respectively. The paired t-test P-values demonstrate a statistically significant improvement of 'ssctx' over 'ss' quality scores.. Sensitivity and precision for local alignments on the hard set. The mact parameter controls the tradeoff of alignment sensitivity and precision ('greediness'). Global alignment corresponds to-mact 0.0 reduced to a 3-state or even 13-state alphabet of local backbone geometries. Because protein structure is known to be well conserved, we expect many recurring local structural features such as those described by structural alphabets to be overlapping to some degree with our context states.
0.4
Failed approach 1: discriminative learning Instead of maximizing the likelihood in Equation(1) we tried hard to maximize the sum of similarity scores of positive training samples minus the sum of scores for negative training samples. Yet, this objective function is no longer likelihood, precluding use of the EM algorithm. Moreover, it proved to be prone to degenerate solutions and required careful enforcement of the restraint that the probability in the denominator in Equation (8) be equal to the average probability of that context state over all training states.
Failed approach 2: transitions between context statesWe tried out a more general model that allows transitions between context states k and k 0. We learned the matrix of transition probabilities Pk 0 jk by maximum likelihood. The score between local profilesPz  k 0 jYPk 0 jk. The alignment quality and sensitivity did not improve, however, probably because K  32 states are not yet fine-grained enough to necessitate substitutions between these states.
ConclusionThe new context score helps most in the difficult cases: (i) when little evolutionary information is contained in the HMMs to be aligned, and (ii) when proteins are remotely related. In the first case, integrating the sparse evolutionary information vertically within an MSA leads to only little noise suppression (i.e. the distinction of correct from incorrect alignments). Therefore, we profit most from pulling together information horizontally along the MSAs. In the second case, it makes sense to focus on the features that are best conserved among remote homologs, which is what our context score was trained to do. The new score slows down hhsearch by a factor of 100. This precludes its use in hhblits, whereas it will be unproblematic for homology modeling and other applications, where a relatively small set of proteins needs to be aligned with the best possible quality.profile only ss ss+str ss+ctxplot: fraction of query HMMs whose ROC5 value is above the value on the x-axis. The ROC5 value for a query is the average sensitivity in a query-specific ROC plot up to the fifth FP match
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
A.Meier and J.S ding at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
