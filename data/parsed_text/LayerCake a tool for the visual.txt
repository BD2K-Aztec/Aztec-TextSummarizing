Motivation: The advent of next-generation sequencing (NGS) has created unprecedented opportunities to examine viral populations within individual hosts, among infected individuals and over time. Comparing sequence variability across viral genomes allows for the construction of complex population structures, the analysis of which can yield powerful biological insights. However, the simultaneous display of sequence variation, coverage depth and quality scores across thousands of bases presents a unique visualization challenge that has not been fully met by current NGS analysis tools. Results: Here, we present LayerCake, a self-contained visualization tool that allows for the rapid analysis of variation in viral NGS data. LayerCake enables the user to simultaneously visualize variations in multiple viral populations across entire genomes within a highly customizable framework, drawing attention to pertinent and interesting patterns of variation. We have successfully deployed LayerCake to assist with a variety of different genomics datasets. Availability and implementation: Program downloads and detailed instructions are available at
IntroductionComparative sequence analysis can reveal evolutionary relationships that could otherwise not be discerned. Sequence comparisons can also identify signatures of natural selection and, when analyzed in conjunction with appropriate phenotypic data, can be used to infer the 'pressures' driving selection processes. Prior to the arrival of next-generation sequencing (NGS), comparative sequence analysis was largely restricted to the comparison of consensus sequences; i.e. sequences represented by the most abundant nucleotide at a given position in a particular sample. The limitations of consensus-level sequence analyses are particularly apparent when examining RNA viruses, as samples often contain a highly heterogeneous 'swarm of mutants'the diversity of which cannot be represented by a consensus sequence. NGS yields thousands of short 'reads' that together represent the full diversity of virus sequences in a sample. The assembly of these sequencing reads using either a pre-determined reference or a reference assembled de novo from the reads themselves allows for the reconstruction of coding-complete viral genomes with the detection of nucleotide variants that exist in as little as 1% of a viral population. With this paradigm, it is now possible to overlay useful information such as nucleotide polymorphisms, polymorphism frequencies and sequencing coverage depth onto every position of a whole-genome consensus sequence. Conveying the read depth at each position in conjunction with the above information creates a large multi-dimensional matrix, which can be difficult to display visually in a manner that) is compared, especially when the virus in question has a high degree of intra-sample sequence variability. However, it is in precisely these contexts that a visualization tool can be most useful for evaluating variation across genomes. Relevant to the discussion of genomic sequence variability is the notion of a sample. Rather than a sequence of nucleotides, an individual sample contains the population of nucleotides observed at different locations along a genome, derived from NGS data. These populations can be compared to a reference sequence (or 'reference population', see Section 2.2.2) to define a certain proportion of variability at each location. By visualizing different samples simultaneously, we can observe change in variability over time (if we take multiple samples from the same infected organisms but at different time points) or observe subgroups within a particular virus (if we take samples from multiple organisms and compare them). In both cases, the analyst compares multiple samples at once. We have therefore developed the LayerCake visualization tool to address the problem of visualizing sequence variability in viral populations. In LayerCake, samples are visualized as a colored row or layer in a single view, with variability and confidence information encoded as color. LayerCake automatically aggregates regions of the genome into discrete bins, the size of which can be controlled by the user. This design allows viewers to immediately receive an overview of the entire dataset and quickly locate regions of interest within or among samples. Zooming and side displays allow the user to retrieve detailed, nucleotide-level statistics with a single click. Interaction allows the user to adjust the aggregation, update the metrics used to define variation or update metrics related to data quality or importance. In this article, we describe the LayerCake system in detail, contextualizing its design with respect to other visual analytics tools for genomics and presenting case studies of how LayerCake has been used in multiple genomic analysis settings. We expand upon the initial LayerCake prototype detailed in, supporting a more robust model of sequencing data, the capacity to deal with multiple settings of 'references' and 'pseudo-references' and adaptation to more general datasets.
Related worksThere are a number of general purpose genome browsers which employ principles from visualizationfor a survey and discussion of the difficulties in building such systems], including some which are track based (in which different samples or data types are placed in their own distinct rows and visualized simultaneously). Many of these systems are visually similar to LayerCake in design, relying on comparison across rows or tracks and the heavy use of color to encode value (e.g. see). The LayerCake system differs in two key ways from these systems: first, it supports flexible aggregation and zooming, allowing the analyst to compare across an entire genome and examine small regions of interest simultaneously. Second, LayerCake is tailored for NGS data models and can adapt to the specificities of examining this sort of sequencing data (as opposed to treating each of the variables involved in NGS sequencing and alignment as orthogonal tracks). Tools for the visualization of NGS data specifically must display the heterogeneity of reads at particular locations. Most of these NGS tools have relied on the 'scaffold view' in which sequencing reads are assembled against a reference sequence and stacked atop one another. Nucleotides that vary from the reference are highlighted within their respective read, and the frequency of these variants is represented by proportional sequence logos at the bottom of the stack (seefor a partial list of NGS visualization tools employing the scaffold view). These sequence logos are notoriously difficult to interpret (see), making it difficult for analysts to compare variation at individual locations, let alone large regions of a genome. Even if other aggregation strategies are used, the scaffold view is most useful when examining a single sequence of reads, since each scaffold is large and visually complex (requiring the display of potentially thousands of reads, hundreds of base pairs long). Even tools which do not use the scaffold metaphor are still limited to the exploration of variants within a single NGS sample (such as). A survey of tools for NGS variant analysis () confirmed that most tools for this task afford the viewing of only a few separate tracks of reads at a time (one or two per window), although some tools allow the analyst to dynamically combine samples (). One exception to the tools which present only one (or a few) samples at a time is the Sequence Surveyor tool (). Originally designed for the analysis of linkage and conservation across large numbers of genomes, Sequence Surveyor encodes each genome as a row in a large display and aggregates sections of the genome into discrete colored blocks, allowing hundreds of sequences of millions of base pairs in length to be summarized on a single screen.recommend a similar layered design for observing trends in longitudinal data. The initial design of LayerCake adapts Sequence Surveyor techniques to the variant analysis task while maintaining a scalable design based on the arrangement of colored rows of blocks. A key difference between the two methods is that Sequence Surveyor is for viewing static sequences of genes or nucleobases. LayerCake deals with the simultaneous comparison of multiple sample populations of sequentially organized reads. Instead of one bit of information per location (for instance 'what is the nucleobase at this location?'), LayerCake must contend with at least four (how many of each type of nucleobase are at this location?). This problem becomes even more challenging when we compare populations to each other. Section 2.2.2 expands on this formalistic difference.
System and methodsLayerCake, as a tool for the quick, visual comparison of large amounts of genomic variability data, has three primary design components: 1. Techniques for visually aggregating large amounts of genomic variability data from multiple samples and populations. 2. Techniques for calculating and displaying various conceptions of variation and reference 3. Techniques for calculating and displaying various conceptions of data quality and confidence.Central to LayerCake is the notion of a layereach separate sample of viral sequence data is visually represented as a row of colored glyphs.shows an example of a LayerCake layer; red regions of the layer correspond to locations along the genome for which this particular population has high variance compared with the current reference.shows the entire LayerCake system: dozens of discrete layers organized and displayed simultaneously, with annotations and tools for viewer interaction.
AggregationAlthough viral genomes are smaller in length than mammalian genomes (tens of thousands of nucleobases rather than billions), it is still LayerCakenot feasible to visually present all the information from dozens of samples simultaneously. To present a meaningful overview in limited space, LayerCake compresses the sequence and chooses a visual representation of each sample that is compact enough to afford the simultaneous presentation of many samples in a single screen. Sequence compression must be considered not just in pixels, but also in visual complexity. By definition, this compression inherently aggregates some information, but LayerCake gives the viewer the ability to recover these details on demand. The primary form of aggregation LayerCake supports is binning: contiguous locations in the genome are aggregated together into discrete blocks. The resulting color of the block represents the average variation of all sites within the block. We used color to encode data rather than, for instance, vertical position (as in a line graph or scatterplot) as prior work has shown that viewers are better at estimating and comparing average color values from sequences as opposed to average positional values (). A typical viral genome consisting of tens of thousands of nucleobases can then be reduced to a few hundred blocks, which can easily fit within the dimensions of a standard computer monitor. The viewer can interactively choose how many base pairs are contained within a single bin, which alters the aspect ratio of each block as the entire layer is stretched to fit the available space. To guarantee the visibility of each block, the number of nucleobases within a block cannot be reduced to a number so low that a block would be less than a pixel wide. Conversely, the number of nucleobases within a block cannot be a number so high that the display of a bin's contents will not fit in the available space. In practical use cases, viewers tend to make bins dozens of base pairs large, to reduce the visual complexity of the display while still permitting the investigation of small-scale features in the data.
Recovering DetailLayerCake averages together multiple locations into a single bin; this aggregation can create ambiguity (is this location somewhat red because many of the locations within it are somewhat variant or is it because there is one highly variant location surrounded by locations with little or no variation?) and erase details (since a region of interest in the overview could ambiguously refer to any location within a region dozens or hundreds of nucleobases long). We therefore include two techniques to recover detail: focus  context lenses and 'event striping'. When the viewer right-clicks on a particular bin, LayerCake expands the contents of the bin to a detail view and shrinks the rest of the layer to maintain total length. Since this zooming occurs discontinuously, this is a 'table' or 'Manhattan' lens. This detail view explicitly shows the variation at each location within a bin.shows an example.The overview merely shows the average value of each bin. A single point of high variation can be lost in this averaging process. If the viewer wishes to see small scale (but important) features, we support a technique called 'event striping' (see). When enabled, the viewer selects a threshold of interest, and then LayerCake will draw thin red stripes on bins which contain locations where variation meets or exceeds this threshold. For instance, a viewer might use event striping to highlight locations on the genome where more than 50% of reads are variant. An individual bin in the main display might, on average, have significantly less than 50% variation but still have a number of visible red stripes which suggest that the viewer might wish to investigate this bin with zooming. Event striping increases the visual complexity of the display (since the number of events is only limited by the number of locations in the dataset) but allows viewers to find locations that would otherwise be lost in the averaging. Prior work has shown the utility of event striping for identifying outliers in sequence data ().
Defining Variation and ReferenceVariation presupposes a non-variant sequence or population from which deviation can be measureda reference. Typically, this is a reference sequence; however, in LayerCake we expand on the definition of reference to include more complex situationsfor instance we may be concerned in how a viral population has changed compared to a particular time point, as opposed to some initial preinfection reference. Different datasets will have different references (sequences, pseudo-sequences or populations against which we define variation), but they also might have different definitions of what constitutes a valid reference. These definitions might even change dynamically over the course of a session.
Variation from a Static Reference Sequence
Let Reads     ! n be a four dimensional convex vector whose components sum to 1.0, denoting the population of all reads at a location n.n;A would then be the proportion of reads at location n that were identified as adenine. Let Ref n denote the reference at n. If Ref n is a static, single base pair, then the variation from the reference at n is straightforward to compute. Namely, it is the percentage of reads which do not match the reference base pair:
Variation from a Reference PopulationIn real tasks, the assumption of a static reference is frequently violated. For instance, we might want to compare against a population at a particular timepoint, or an individual might have been infected by a diverse population of viruses rather than a single homogeneous population. In this case we would represent not just the sample but also the reference as another four dimensional vector Ref    ! n. Variation should then be represented as some sort of distance from one vector to another. Many possible distance metrics exist; however, for this task, the distance metric ought to be easily comparable to Equation (1) above: it should preserve the semantic meaning of 'more' or 'less' variation and have a range in the interval. We chose a distance metric based on the central metaphor of swapping. That is to make two locations identical, one would change individual reads until the distributions matched. For instance, if the population was entirely adenine at a location, but the reference was one entirely cytosine, one would 'swap' out 100% of the adenine and replace it with 100% cytosine: 100% of the reads would be swapped, so the total variation would be 100%. Likewise, if the reference was 50% A and 50% C, only half as many swaps would need to be performed, so variation would be 50%. This behavior of examining distance at each dimension (or nucleotide) individually and then summing up is captured by the ' 1-norm or Manhattan distance. To avoid double-counting swaps (adding more adenine by necessity means subtracting quantities for another nucleotide), we divide the ' 1-norm by 2.0 to derive the final metric for variation between two populations:2.
Synonymous and non-synonymous variationThe analysis of viral NGS data within a sample or from multiple samples can be used to identify signatures of natural selectionan exercise that can yield powerful biological insights, especially when supported by phenotypic data. At the core of this analysis is the identification of 'non-synonymous' mutations: those which change the amino acid sequence of the encoded protein. Since mutations are generated randomly, a high density of non-synonymous mutations in a particular region is indicative of natural selection favoring. A LayerCake layer. Variation at multiple sequential locations on the genome is averaged together into bins, presenting an overview of the entire genome at once (above). By right clicking on a bin (below), the viewer can recover specific information about a section of the genome while keeping the overview in contextLayerCakediversification of the respective protein sequence: a phenomenon referred as 'positive selection'. The opposite is also true: a paucity of non-synonymous mutations indicates selection against protein sequence changes (i.e., 'purifying selection'). To enable the visualization of non-synonymous variation across the genome, LayerCake can display either non-synonymous mutations, synonymous mutations or both when open reading frame (ORF) annotations are included in the input reference sequence. A mutation is considered non-synonymous if it would result in a changed amino acid for even one of the relevant ORFs. The metrics presented above extend to this case by filtering out the relevant types of variation before calculating total variation.
Defining References in LayerCakeLayerCake considers three different reference scenarios: 1. Individual references: In this scenario, each discrete population considers variation separatelyfor each population, the user either provides a reference sequence (for instance from a FASTA file) or LayerCake will generate a consensus sequence for each sequence. This scenario highlights regions which have systematically high variation within a sample. 2. Population consensus: In this scenario, variation is defined with reference to a single reference sequence. This sequence is either provided from a source file (for instance a GFF file) or LayerCake will generate a single consensus sequence by voting. That is if there are 10 populations in the dataset and 6 of them have an adenine at a given position, then the population consensus will also be adenine, regardless of the read depth of any individual sequence. This scenario affords the quick apprehension of particular regions of particular samples that have high variations. 3. Per sample comparison: Individual samples, through the method described in Equation (2), can be used as a pseudo-reference for the rest of the dataset. This scenario readily shows variation between samples and also the identification of sub-groups of samples. Seefor an example.Users may dynamically choose between different reference scenarios, even in the course of a single session. For instance, if one is interested in general regions where variation occurs, they might begin with individual references. Once those locations are identified, they might choose a particular population as a reference, to see if there are groups of populations that have different sorts of variation in these hotspots.
Confidence VisualizationUncertainty about variation at a particular location on the genome can occur for a number of reasons. There can be error in assembling reads, aligning reads, identifying base pairs and sampling error that could arise from insufficient read coverage at a location. Uncertainty data, no matter the source, must be visualized along with the variation information, especially for tasks where the viewer must decide which locations of the genome require more detailed analysishighly variant but uncertain information might warrant less attention than a location with less variation but little uncertainty. In LayerCake, color is used in each layer to display information. Color has been shown into be a useful visual variable for helping analysts to quickly find outliers and estimate average value in regions. Since we have two types of information to display (frequency of variation and average uncertainty), this means that we must use a bivariate color map to represent the data. To avoid many theoretical obstacles to creating these color scales (see Trumbo 1981), we presume that highly uncertain values are unimportant, regardless of the variation at this location. Thus, rather than our color map resembling a square (two equal orthogonal axes), our color map resembles a wedge (with the uncertainty axis converging to a point). This makes the choice of colors significantly easier, while maintaining the desired visual behavior (important regions are highly visible, unimportant regions recede into the background). While we interpolate in multiple color attributes (both hue and saturation) to make discriminability easier, as confidence decreases it is intentionally more difficult to distinguish colors; in effect we have fewer distinct color values as we descend the wedge, replicating the intended effect of making value less important as confidence decreases.shows the color wedge in detail. While a bivariate encoding (such as color and size or color and orientation) would allow us to faithfully present value and confidence simultaneously, we wished to make it easier for analysts to filter out uncertain (and likely irrelevant) portions of the dataset without having to integrate multiple channels of visual information.
DiscussionThe LayerCake system has been widely deployed across a number of viral datasets. In this section, we highlight three case studies that highlight the benefits of the LayerCake system: the presentation of a genome-scale overview of data, the ability to interactively alter notions of reference and variation and the alignment and aggregation of many samples in a single, all-encompassing display. In addition to finding regions of high variation (as described in), LayerCake affords longitudinal comparison of variation (as in) and allows for the identification of subgroups with similar variation signatures (as in Section 3.1).
Simian arterivirusLayerCake also allows for the description of nucelotide variation and deep population analysis of novel viruses for which little or no prior data on sequence evolution exists. In), we used LayerCake to examine nucleotide variation in novel, highly divergent simian arteriviruses that we discovered in wild red. The LayerCake color wedge, showing the mapping from the two axes of variation (1) and uncertainty (3) to color. Highly uncertain data are all mapped to the same grey color, giving the visual impression of data receding into a " fog " of unimportance. The two yellow dots (2) can be moved by the viewer to redefine standards of interest and importance. On the right (4b) the viewer has moved the topmost yellow dot counterclockwise, making all locations with more than 1% variation dark red, which is interactively reflected in the layers colobus monkeys and yellow baboons living in Uganda and Tanzania, respectively. With a population-wide consensus selected (the Population Consensus option described in Section 2.2.4), LayerCake revealed several genomic regions with high levels of nonsynonymous diversity. Follow-up analysis showed that the region with the most intense signal was within the ORF encoding the major envelope glycoprotein. When compared with functional data from more extensively characterized arteriviruses, this region aligned with the primary neutralizing antibody epitope of these viruses (i.e., the region of the viral protein targeted by adaptive humoral immune responses)again providing mechanistic insight into the selective pressures driving the accumulation of non-synonymous mutations. Selecting individual references in LayerCake (the Per Sample Comparison option described in Section 2.2.4) quickly revealed varying degrees of viral sequence homology between animals, reflecting the pattern of transmission among individual monkeys (see). In the red colobus, this exercise identified one animal that was super-infected with two unique virus strains.. By defining variation from a particular population rather than a reference sequence, we can easily identify subgroups. The first row is selected as the reference population. Here, the first three rows are very similar to each other but not to the other sample, indicating a meaningful subgroup. An example of the utility of LayerCake for viewing systematic patterns of variation, illustrated by examining the evolution of HIV-1 in an infected individual over time. While the standard heatmap display (a) makes the overall trend visible (variability increases over the course of the infection), it is difficult to compare specific locations over time. In LayerCake (b), each row represents the viral population at a different timepoint in the infection. Change over time at a particular location can be estimated by visually scanning a particular column. Annotations (across the top of the LayerCake display) also adds context to the pattern of variation accumulated over time
LayerCake
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
M.Correll et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
LayerCake is a full-featured visualization tool for exploring patterns of variability in viral genomes. We have deployed LayerCake to experts in the field and incorporated their feedback into further refinements. The tool, and more broadly the analytics and visual metaphor of the per-sample layer, has been applied to a large number of datasets, with positive scholastic results. The LayerCake tool is freely available and extensible to datasets beyond those we present.
