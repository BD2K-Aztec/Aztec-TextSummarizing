Motivation: The advent of next-generation sequencing (NGS) techniques presents many novel opportunities for many applications in life sciences. The vast number of short reads produced by these techniques, however, pose significant computational challenges. The first step in many types of genomic analysis is the mapping of short reads to a reference genome, and several groups have developed dedicated algorithms and software packages to perform this function. As the developers of these packages optimize their algorithms with respect to various considerations, the relative merits of different software packages remain unclear. However, for scientists who generate and use NGS data for their specific research projects, an important consideration is choosing the software that is most suitable for their application. Results: With a view to comparing existing short read alignment software, we develop a simulation and evaluation suite, Seal, which simulates NGS runs for different configurations of various factors, including sequencing error, indels and coverage. We also develop criteria to compare the performances of software with disparate output structure (e.g.some packages return a single alignment while some return multiple possible alignments). Using these criteria, we comprehensively evaluate the performances of Bowtie, BWA, mr-and mrsFAST, Novoalign, SHRiMP and SOAPv2, with regard to accuracy and runtime. Conclusion: We expect that the results presented here will be useful to investigators in choosing the alignment software that is most suitable for their specific research aims. Our results also provide insights into the factors that should be considered to use alignment results effectively. Seal can also be used to evaluate the performance of algorithms that use deep sequencing data for various purposes (e.g.identification of genomic variants). Availability: Seal is available as open source at http://compbio.case .edu/seal/.
INTRODUCTIONNext-generation sequencing techniques are demonstrating promise in transforming research in life sciences (). These techniques support many applications including metagenomics (), detection of SNPs () and genomic structural variants () in a population, DNA methylation studies (), analysis of mRNA expression (), cancer genomics () and personalized medicine (). Some applications (e.g. metagenomics) require de novo sequencing of a sample (), while many others (e.g. variant detection, cancer genomics) require resequencing. For all of these applications, the vast amount of data produced by sequencing runs poses many computational challenges (). In resequencing, a reference genome is already available for the species (e.g. the human genome) and one is interested in comparing short reads obtained from the genome of one or more donors (individual members of the species) to the reference genome. Therefore, the first step in any kind of analysis is the mapping of short reads to a reference genome. This task is complicated by many factors, including genetic variation in the population, sequencing error, short read length and the huge volume of short reads to be mapped. So far, many algorithms have been developed to overcome these challenges and these algorithms have been made available to the scientific community as software packages (). Currently available software packages for short read alignment include Bowtie (), SOAP (), BWA (), mrFAST (), mrsFAST (), Novoalign () and SHRiMP (). In this article, we assess the performance of currently available alignment algorithms, with a view to (i) understanding the effect of various factors on accuracy and runtime performance and (ii) comparing existing algorithms in terms of their performance in various settings. For this purpose, we develop a simulation and evaluation suite, Seal, that simulates short read sequencing runs for a given set of configurations and evaluates the output of each software using novel performance criteria that are specifically designed for the current application. Our results show significant differences in performance and accuracy as quality of the reads and the characteristics of the genome vary. In the next section, we briefly describe the alignment algorithms that are evaluated in this article. Subsequently, in Section 3, we describe the simulation suite implemented in Seal and our performance criteria in detail.Page: 2791 27902796
Comparison of alignment algorithmsWe present detailed experimental results in Section 4. We conclude with a detailed discussion of our results in Section 5.
BACKGROUNDThe problem of short read alignment is formulated as follows. Given a reference genome (for which the entire nucleotide sequence is available) and a donor genome (for which the nucleotide sequence is not known), a sequencing run produces many short reads from the donor genome. These short reads are generated by taking relatively long (2008000 bp) fragments from the donor genome and sequencing a number of bases (35150 bp for Illumina, 400 bp on average for 454) from either only one end (single-end read) or both ends (paired-end read) of the fragment. Given this set of short reads from the donor genome, the objective of alignment is to correctly determine each read's corresponding location in the reference genome. Here, we briefly describe the alignment algorithms and the major differences between their approaches. Many of these algorithms have undergone major revisions in recent years, with their authors producing either 'version 2' of their tools [e.g. SOAP (or using a different name for the new version [e.g. Mapping and Assembly with Qualities (MAQ) () versus Burrows-Wheeler Alignment (BWA) (. We only consider the most recent version of each tool for brevity; the developers of these tools perform their own evaluation to demonstrate the superiority of their newer approaches.
BowtieBowtie () uses an index built with the Burrows-Wheeler transformation () and claims a small memory footprint about 1.3 GB for the entire human genome. Bowtie makes some compromises to provide its speed and memory usage; notably that it does not guarantee the highest quality read mapping if no exact match exists. Additionally, it may fail to align some reads with valid mappings when configured for maximum speed. If a user desires higher accuracy, Bowtie provides options to adjust this trade-off.
BWABWA () can be considered as 'MAQ () version 2'. Whereas MAQ uses a hash-based index to search the genome, BWA uses an index built with the BurrowsWheeler transformation that allows for much faster searching than its predecessor. Like its predecessor, BWA reports a meaningful quality score for the mapping that can be used to discard mappings that are not well supported due to e.g. a high number of mismatches.
mrFAST and mrsFASTThe mr-and mrsFAST tools () are notable in that they report all mappings of a read to a genome rather than a single 'best' mapping. The ability to report all possible reference genome locations is useful in the detection of copy number variants (). Indeed, these algorithms are developed primarily for applications that involve detection of structural variants (). mr-and mrsFAST use a seedand-extend method for alignment, and create hash table indices for the reference genome. Each read is split into first, middle and last k-mers (the default k = 12), and each of these k-mers are searched in the hash index to place initial alignment seeds.
NovoalignNovoalign is a proprietary product of Novocraft () that uses a hashing strategy similar to that of MAQ (). It has become quite popular in recent publications due to its accuracy claims, and it allows up to eight mismatches per read for single end mapping.
SHRiMPSHRiMP () specializes in mapping SOLiD color-space reads, but is also usable for the reads simulated in our evaluation. It takes advantage of recent advances in sequence alignment: q-gram filters (), which allow multiple matching seeds to start the alignment process; spaced seeds (), which allow predetermined sections of mismatches in seed sequences; and specialized hardware implementations/instructions to speed up the standard Smith Waterman (Smith and) alignment algorithm.
SOAPv2SOAP is an alignment algorithm specifically designed for detecting and genotyping single nucleotide polymorphisms. Like BWA and its predecessor MAQ, SOAP version 2 () improves on SOAPv1 () by using an index based on the BurrowsWheeler transformation (BWT). This improved index significantly improves alignment speed and memory usage. SOAPv2 determines matches by building a hash table to accelerate the searching of the BWT reference index.
METHODS
SimulationWe develop Seal (SEquence ALignment evaluation suite), a comprehensive sequencing simulation and alignment tool evaluation suite. This software (implemented in Java) provides several utilities that can be used to evaluate alignment algorithms, including:@BULLET Reading a pre-existing reference genome from one or more FASTA files.@BULLET Alternatively, generating an artificial reference genome based on input parameters (length, repeat count, repeat length, repeat variability rate).@BULLET Simulating reads from random locations in the genome based on input parameters of read length, coverage, sequencing error rate and indel rate.@BULLET Applying alignment tools to the genome and the reads through a standardized interface. @BULLET Parsing the output of the alignment tool and calculating the number of reads that were correctly or incorrectly mapped.@BULLET Computing runtimes and measures of accuracy.The ability to generate random reference genomes enables systematic studies of the effect of various factors on performance. In particular, besides specifying the length of the reference genome, the user can also adjust different repeat parametersrepeat count, repeat length and repeat variability rate (the probability of altering a base at each genome location during a repeat). This repeat variability rate is intended to introduce variability in the potential mappings of a read. Repeats are quite common in real genomes ().
M.Ruffalo et al.Our evaluation simulates reads from a reference genome, choosing uniformly distributed locations at random and making reads from fragments of normally distributed sizes. In the paired-end case, the underlying fragment is of normally distributed size and the read length at each end is fixed. The user can evaluate the effect of various factors by adjusting the following parameters: @BULLET Read length: this is the average number of bases in each read. In current platforms, read length ranges from 30 to hundreds of base pairs. @BULLET Sequencing error rate: this is the fraction of miscalled bases in a sequencing run. It also implicitly accounts for single nucleotide variants in the population. The error rate reported by current platforms is around 1% (Illumina, 2010). @BULLET Indel rate: in addition to base read errors, we also consider short insertions and deletions, which may be caused by sequencing errors or variations in the population. This parameter specifies the fraction of short insertions and deletions in simulated reads.@BULLET Indel length: this parameter controls the length of short insertions and deletions in the reference genome and is used to assess the robustness of an alignment tool. The length of indels is selected from a normal distribution and the indel length parameter determines the mean of this distribution.@BULLET Coverage: since the reads come from random locations on the genome, it is important to have sufficient number of reads to adequately cover the entire genome. If the length of the reference genome is n, read length is m, and the number of mapped reads is k, then coverage is defined as mk/n, i.e. the expected number of aligned read bases that cover a given reference base position. Note that coverage does not have a direct effect on the accuracy of an alignment algorithm since each read is aligned independently. However, it is important for an alignment algorithm to scale to realistic levels of coverage in terms of runtime performance.
EvaluationMost tools report a quality score for the mapping of a read to the reference genome. These scores mirror Phred scores (); they represent the log-scaled probability that the mapping is incorrect. Meaningful scores typically range from 0 to 60, where 0 corresponds to very low-quality mapping and scores of > 30 are considered to be very good. A score of 30 denotes a 10 3 chance that the mapping is incorrect; as the score increases to 40, the chance of an incorrect mapping theoretically drops to 10 4. Our evaluation incorporates a threshold on this mapping quality; we only consider reads whose quality is reported to be greater than or equal to a certain value. This threshold value is used as a parameter in calculating the accuracy of a set of read mappings. We define the performance figures from the perspective of reads, i.e. the true location of a read is considered the truth and an alignment is considered a prediction. Note that the use of one evaluation method for all tools is not appropriate, since some tools (mrFAST and mrsFAST in particular) report all matching genome positions while others report only the 'best' mapping. Standard definitions of an 'incorrect mapping' would unfairly penalize tools that report multiple mappings since a read may map equally well to multiple locations due to paralogous sequences in the reference genome. Motivated by this observation, we use two alternate definitions of an incorrect mapping, namely a strict incorrect mapping and a relaxed incorrect mapping. For a fixed threshold on mapping quality, we classify the accuracy of the mapping(s) of a read as follows.@BULLET Correctly mapped read (CM): the read is mapped to the correct location in the genome and its quality score is greater than or equal to the threshold. @BULLET Incorrectly mapped readstrict (IM-S): the read is mapped to an incorrect location in the genome and its quality score is greater than or equal to the threshold. @BULLET Incorrectly mapped readrelaxed (IM-R): the read is mapped to an incorrect location in the genome, its quality score is greater than or equal to the threshold and there is no correct alignment for that read with quality score higher than the threshold. @BULLET Unmapped read (UM): the read is not mapped at all by the alignment tool or the quality score is less than the threshold. For a given set of reads, we compute strict accuracy as |CM|
|CM|+|IM-S| and relaxed accuracy as|CM| |CM|+|IM-R| , where CM denotes the set of correctly mapped reads, IM-S denotes the set of incorrectly mapped reads in the strict sense and IM-R denotes the set of incorrectly mapped reads in the relaxed sense. For example, if a read is mapped to four locations in the reference genome and one of those mappings is correct, the other three alignments are not counted as incorrect mappings in the relaxed sense. Note that strict and relaxed accuracy provide two extreme (respectively pessimistic and optimistic) measures of accuracy; therefore, they provide an interval for the accuracy of an algorithm. These two measures are equal if the tool reports a single genome location for each read. Furthermore, to assess the ability of a tool in finding a mapping for all reads, we define the used read ratio for an alignment tool as
RESULTS
AccuracyWe simulate reads from two genomes: an artificially generated genome and the human genome. The generated genome is of length 500 Mb, with 100 repeats of length 500 bp each. Results from the simulated genome are available in the Supplementary Material. Due to computational considerations, SHRiMP's accuracy results are only available for the simulated genome.shows the details of each experiment.
Varying error rateThe accuracy of all algorithms on the human genome for varying error rate is compared in. The results for quality threshold 0 (accepting all reads) are shown in, whereasshows the mapping accuracy when considering reads of quality 10. We can see that Bowtie, BWA and Novoalign are the most sensitive to mapping quality threshold at high error rates; their accuracy significantly increases as reads ofshows the proportion of reads that have mapping quality of at least 10.-R and-S suffixes denote relaxed and strict accuracy, respectively.. Human genome: comparison of reported accuracy versus theoretical accuracy for 0.1% base call error rate (only tools that report meaningful quality scores are included). (a) Shows a comparison of the theoretical accuracy for each mapping quality score versus each tool's accuracy at that quality threshold. (b) Shows the proportion of reads with a mapping quality greater than or equal to each threshold value. mapping quality 0 are discarded. SOAP's mapping accuracy is quite high even at quality threshold 0, which is consistent with its intended usage for genotyping SNPs.shows the proportion of mapping results that are used to create, i.e. the proportion of reads that have mapping quality of at least 10.shows a direct comparison of the theoretical accuracy at each quality score against each tool's actual accuracy. The mapping quality Q is defined as the log-scaled probability P that the mapping is incorrect: Q =10log 10 P, giving a theoretical accuracy A for each quality score: A = 1P = 110 Q/10 .shows that most tools underestimate their mapping quality; most incorrect mappings can be discarded simply by considering mapping qualities of at least 1.shows the accuracy of the alignment tools with fixed indel rate (0.05/bp) as the average indel size varies. This level of indel rate can be considered 'frequent' (as seen in). These figures again emphasize that SOAP is better suited for SNP analysis than indel callingas the average indel size approaches 10, SOAP fails to align any reads and its accuracy drops to 0. Bowtie, BWA and Novoalign show very unfavorable accuracy when all reads are considered (i.e. when the mapping quality threshold is low); however, it can be seen that they report many of the incorrect mappings with low-quality scores, since their accuracy with quality threshold 10 is significantly improved. It can also be seen in these figures that mr(s)FAST and Novoalign are most robust to longer indels and Novoalign's mapping quality scores become particularly useful as indels get longer.
Varying indel sizes
Varying indel frequenciesThe accuracy provided by each tool for fixed indel length (2) and varying indel rate on the human genome is shown in. As seen in this figure, the accuracy of all algorithms depend strictly on indel rate; the accuracy provided by all algorithms is almost always >95% for indel rate <0.001. It should be also noted that mr-and mrsFAST show a tremendous difference in the relaxed and strict precision measures with varying indel frequency; they not only report the correct genome location, but also report many incorrect locations.
Runtime
M.Ruffalo et al.
Indel Size (mean)Accuracyshows the proportion of reads that have mapping quality of at least 10.-R and-S suffixes denote relaxed and strict accuracy, respectively. At indel sizes 10 and 16, SOAP discards all reads, producing missing values in (c).shows the proportion of reads that have mapping quality of at least 10.-R and-S suffixes denote relaxed and strict accuracy, respectively. indexing time for various genome sizesmost tools show a linear relationship between the length of the genome and the time required to build an index.shows the alignment runtime versus read count on a 500 Mb genome. We can see that most tools are designed with a trade-off between indexing runtime and alignment runtime; Bowtie, BWA and SOAP align quickly but require significant amounts of time to build an index of a genome. Novoalign, conversely, requires little indexing time but shows more of a dependence on the number of reads. Interestingly, SHRiMP, seems to show no dependence on read count.
Indel
DISCUSSIONAs expected, these alignment tools are designed with different approaches to trading off speed and accuracy to optimize detection of different types of variations in donor genomes. This trade-off is evident in the performance of BWA and SOAP on the human genome (): without a threshold value to eliminate unreliable reads, BWA is not as accurate even at low error rates ( 0.9 at a base pair substitution rate of 10 3 and falling sharply to  0.37 at an error rate of 10 1 ). SOAP has a consistently high accuracy ( 0.95) even with no threshold and high error rates. Based on these observations, we can conclude that BWA is specifically designed not to miss any potential mappings, at the cost of reporting many incorrect mappings. The evaluation of mrFAST, mrsFAST and SHRiMP shows some expected trends; since each fragment is potentially mapped to many locations in the genome, we expect their strict accuracy value to be much lower than that of other tools. As the error rate increases from 0.001 to 0.1, however, we see the strict accuracy measure increase for all three of these tools. Intuitively, this seemingly surprising trend makes sense since we expect the number of potential genome mappings to decrease as the reads become less reliable, thus reducing the number of incorrect mappings in relation to the single potential correct mapping. These tools' relaxed accuracy values (as defined in Section 3.2) also show some expected trends; since mrFAST and mrsFAST can report many genome locations for each fragment, we expect their relaxed accuracy to be quite high for low error rates and to decline as the error rate increases. We must emphasize the large difference between our relaxed and strict accuracy measures in our evaluation of mrFAST, mrsFAST and SHRiMP. The relative usefulness of these two measures depends on the user's specific research aims; one may be more interested in tools with good relaxed accuracy if studying structural variants,while strict accuracy may be of more use in genotyping SNPs. We must also note that our analysis may not be fair to SHRiMPthis tool is designed for mapping color-space reads and our simulation does not generate this type of data. As expected, the tools show an overall linear relationship between coverage (number of reads) and the total runtime. For most alignment tools, we can further separate the total runtime into separate measurements for indexing and alignment; if the index can be reused across multiple alignment runs, a high indexing time can be affordable. We believe that our results will be useful to a wide variety of genomic researchers, though we must recognize that we cannot precisely simulate all experimental scenarios or sequencing hardware characteristics. As the state of the art advances, data from new sequencing hardware may challenge the assumptions that today's high-performing algorithms depend on. Similarly, algorithms with unfavorable accuracy or speed on today's data sets may find renewed use in the future.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
