Motivation: Sequence discovery tools play a central role in several fields of computational biology. In the framework of Transcription Factor binding studies, most of the existing motif finding algorithms are computationally demanding, and they may not be able to support the increasingly large datasets produced by modern high-throughput sequencing technologies. Results: We present FastMotif, a new motif discovery algorithm that is built on a recent machine learning technique referred to as Method of Moments. Based on spectral decompositions, our method is robust to model misspecifications and is not prone to locally optimal solutions. We obtain an algorithm that is extremely fast and designed for the analysis of big sequencing data. On HT-Selex data, FastMotif extracts motif profiles that match those computed by various state-of-the-art algorithms, but one order of magnitude faster. We provide a theoretical and numerical analysis of the algorithm's robustness and discuss its sensitivity with respect to the free parameters. Availability and implementation: The Matlab code of FastMotif is available from http://lcsb-portal.
IntroductionIn the last decades, due to the advent of new sequencing technologies, motif discovery algorithms have become an essential tool in many computational biology fields. In cell biology, sequence motif discovery plays a primary role in the understanding of gene expression through the analysis of sequencing data and the identification of DNA-transcription factor binding sites (). Various experimental techniques are nowadays available to extract DNA-protein binding sites in vivoand in vitro [protein binding microarray (PBM) (), HT-Selex (. Thanks to the quantity and quality of the generated data, HT-Selex is considered one of the most promising high-throughput techniques for studying transcription factor binding affinity in vitro [see the recent work () for a quantitative comparison between HT-Selex and other high-throughput techniques as ChIP. In the HT-Selex protocol, tens of thousands enriched DNA fragments are obtained through a series of incubation/selection cycles. In each cycle, an initial pool containing randomized ligands of length 1440 bp is incubated with an immobilized DNA-binding protein. Bound ligands are amplified by polymerase chain reaction steps (PCR), sequenced and then used as initial pool for a next cycle, until the pool is saturated (). Due to the high but not exact specificity of transcription factor binding affinities, enriched DNA fragments in a dataset typically contain similar but not exactly conserved instances of the same binding motif. This calls for algorithms that can extract simple and intuitive binding motifs that are robust to such stochasticity (). In the simplest case, the binding preferences are modelled by means of consensus sequences, obtained by selecting a few deterministic character strings that are over-represented in the dataset. A more flexiblerepresentation is provided by Position Weight Matrices (PWM) that describe binding sites as probability distributions over the DNA alphabet. Based on the simplifying assumption that the total binding energy is a site-by-site sum of single protein-nucleobase interactions, PWM's are only approximate models of the true transcription factor preferences. A debate is still open on whether such an approximation gives a satisfactory picture of the DNA-protein interaction or it is a too simplified reduction of the real biological process (). More sophisticated models, that go beyond the PWM representation by taking into account multi-base probability distributions or long-distance interactions, have been proposed and tested in the literature (). However, in most cases, these improvements did not bring about cogent evidence against the simpler and more intuitive approach based on position independent distributions (). In statistics and machine learning, factorized (aka product) distributions like PWMs and their linear combinations (aka mixtures) are commonly used in modelling empirical distributions from various kinds of data, and an important problem is how to estimate such models from data (). In pioneering work,showed that it is possible to infer a mixture of product distributions via the spectral decomposition of 'observable' matrices, i.e. matrices that can be estimated directly from the data using suitable combinations of the empirical joint probability distributions (). Extensions and improvements of this idea have been developed more recently in a series of remarkable works, where the spectral approach is applied to a larger class of probability distributions, and robust versions of the original method have been analysed theoretically (). In this article, we further develop the original spectral technique of Chang (1996) and study its application to the problem of learning probabilistic motif profiles from noisy sequencing data. The key observation is that, under the PWM approximation, motif discovery reduces to the more general problem of learning a mixture of product distributions, and hence, it is possible to extract motif profiles from sequencing data using usual spectral decompositions. We present FastMotif, a new motif finding algorithm that is faster than other sequence discovery tools and is designed for processing noisy high-throughput datasets. Based on a new and more stable version of the spectral techniques introduced in (), our algorithm is robust to model misspecification, is not prone to local optima, and it can be adapted to searching for motifs of arbitrary length. In addition, the method is completely general and, upon minor modifications, can be used for sequence discovery over any sequence alphabet and for analyzing datasets with binding affinity scores (). Throughout this work, we assume that transcription factor specificities are well described by product distributions, i.e. PWM's, and leave for future work the spectral inference of more advanced motif representations. Finally, a comment on the claimed optimality of FastMotif. It has been shown [see for example] that in the limit of infinitely many data and under no model misspecification, a spectral method is statistically consistent, that is, it always recovers the true underlying model. FastMotif, being a spectral method, inherits this optimality property by the way of the uniqueness of matrix eigen decomposition. This is in marked contrast to algorithms like Expectation Maximization (EM) that can easily get trapped in poor local optima even under favourable sample conditions. In practice, we expect the output of FastMotif to approach optimality when the true binding model approaches a PWM and the size of the training dataset is big enough, as for example in the case of HT-SELEX data. The article is organized as follows: In Section 2, we give a brief overview of related work; in Section 3, we describe FastMotif and its application to sequencing data; and in Section 4, we show our results. More mathematical details about spectral approaches in general and FastMotif in particular can be found in the Supplementary Material. The Matlab code of FastMotif is available from http:// lcsb-portal.uni.lu/bioinformatics.
Related work
Motif findingThe literature on sequence motif discovery is vast. We refer to () for reviews and additional references. There are two main classes of motif finding algorithms, probabilistic and wordbased. Probabilistic algorithms search for the most represented ungapped alignments in the sample to obtain deterministic consensus sequences, PWM models, or more advanced models that take into account multi-base correlations (). Word-based algorithms search the dataset for deterministic short words, measure the statistical significance of small variations from a given seed, or transform motif discovery into a kernel feature classification problem (). Our method and well known motif discovery algorithms as MEME () and STEME (), belong to the probabilistic class, while the two algorithms we have used for evaluating our results, namely the method used in () and DREME () are word-based algorithms. The latter algorithms can also compute PWM models, so it is of interest to compare algorithms of different classes (Section 4).
Spectral methodsSpectral methods have been applied as an alternative to the EM algorithm () for inferring various kinds of probability distributions, such as mixtures of product distributions, Gaussian mixtures, Hidden Markov models, and others () [see () for a recent review]. These methods are not as flexible as the EM algorithm, but they are not prone to local optima and have polynomial computational time and sample complexity. Various spectral decomposition techniques have been proposed: Chang's spectral technique (), a symmetric tensor decomposition method (), and an indirect learning method for inferring the parameter of Hidden Markov Models (). The practical implementation of the spectral idea is a non-trivial task because the stability of spectral decomposition strongly depends on the spacing between the eigenvalues of the empirical matrices. In () certain eigenvalue separation guarantees for Chang's spectral technique are obtained via the contraction of the higher (order three) moments to Gaussian random vectors. In the tensor approach presented in (), the non-negativity of the eigenvectors is ensured by using a deflating power method that generalizes usual deflation techniques for matrix diagonalization to the case of symmetric tensors of order three. A third possibility involves replacing the random vector of Chang's spectral technique with an 'anchor observation' that, for each hidden state, 'tends to appear in the state much more often than in the other states' () and guarantees the presence of at least one well separated eigenvalue (). Finally, as briefly mentioned in (), the stability of Chang's technique can be significantly improved through the simultaneous diagonalization of several random matrices. Here, we present a new approach based on the simultaneous Schur triangularization of a set of nearly commuting matrices ().
Spectral methods and sequence analysisTo the best of our knowledge, spectral methods have not been applied so far to the problem of DNA sequence motif discovery that we address here. Nevertheless, spectral techniques have been applied to other types of sequence analysis problems, such as poly(A) motif prediction (), chromatin annotation (), and sequence prediction (). The techniques used in these works are all based, with minor modifications, on the spectral algorithm offor learning Hidden Markov Models, in which a dataset of time-series of observed values fx 1 ; x 2 ;. .. g is used to recover a single observation matrix (O x ) whose columns are the conditional probabilities associated with the hidden states. Our approach marks a significant departure from these methods by allowing the recovery of distinct observation matrices (O x ; O y ;. .. ) and hence the extraction of motif PWM's. Finally, we note that a general technique for learning mixture of product distributions in the presence of a background has been recently presented (); it would be interesting to study how this technique could be applied to the problem of sequence motif discovery.
Materials and methodsBinding site models represent the binding preferences of DNAbinding proteins via probability distributions over the set of all possible 'words' of some given length. If the DNA-protein interaction is assumed to be the sum of single protein-nucleobase interactions, these probability distributions can be represented by PWM's (). Given the length of the binding site ', a position weight matrix is a 4  ' matrix whose columns are interpreted as the probability distribution associated to the various position within the binding site. Then, according to the factorizability assumption, the total binding score of a particular sequence is obtained by summing (in the log domain), over all positions, the matrix entries corresponding to the sequence letters. De novo motif discovery algorithms compute one or more binding motifs from a set of enriched sequences, i.e. a set of sequences that contain, with high probability, several instances of the protein binding site. FastMotif computes the binding motifs in three steps: First the enriched sequences dataset is modelled using a special class of probability distributions (mixture of product distributions). Then the model parameters are estimated using a powerful machine learning technique (spectral method). Finally, the binding profile is identified as one of the components in the obtained model. Next we provide a high-level description of the above three steps, in a simple (ideal) case where a single binding site (no secondary motif) of length three is overrepresented in the dataset, and the protein binding preferences are exactly described by a 4  3 position weight matrix PWM. In the first step we assume that the dataset is drawn from a suitable probability distribution. Given three consecutive letters in the sample, one should consider two cases: (i) the three letters belong to one instance of the binding site or (ii) the three letters belong to the background. When the three letters belong to a binding site their probability is given by the binding model P motif I; J; K  PWMI; 1 PWMJ; 2 PWMK; 3, where I, J, K take values from the set fA; C; G; Tg. When the three letters do not belong to a binding site, their probability is given by the (constant) background distribution P background I; J; K  BI BJ BK, where B(I) is the frequency of the letter I 2 fA; C; G; Tg in the dataset. Then the probability of observing three consecutive letters (I, J, K) at a random position in the sample is given by P sample I; J; K  WP motif I; J; K  1  WP background I; J; K, where W is the overall probability of finding a binding site in the sample. In other words, each overlapping subsequence of length three in the dataset can be assumed to be drawn either from P motif or P background , with probability given by the coefficient W and 1  W, respectively. In particular, letting S 3 be the set of all overlapping sub-sequences of length 3, one can write S 3 $ P sample. The second step consists of recovering the entries of both P motif and P background from the dataset. In a general, that would require solving a hard non-convex constrained optimization problem, with a large number of parameters. Spectral methods provide a powerful technique to obtain the entries of P motif and P background directly. The parameters are obtained from the eigenvalues of suitable 'observable' matrices, computed by counting joint frequencies in S 3. The observable matrices are formed out of the empirical pairwise and triple probability distributions, defined as the probabilities of observing two or three consecutive letters in S 3. For any three letters I, J, K, where each letter belongs to fA; C; G; Tg, the corresponding triple empirical probability, denoted by ^ PI; J; K, is obtained by the number of occurrences of the sub-sequence I; J; K in S 3 , normalized by the total number of elements in S 3. Since I, J, K assume discrete values in an alphabet of four letters, the triple empirical distribution ^ PI; J; K is a 4  4  4 multi-dimensional array (tensor), obeying X I;J;K ^ PI; J; K  1. Equivalently, the triple empirical distribution can be represented as a set of four 4  4 matrices, namely ^ PI; J; A; ^ PI; J; C; ^ PI; J; G; ^ PI; J; T, whose columns sum to one. The main idea behind FastMotif is that, assuming the factorizability of the position weight matrix PWM motif and the background matrix P background , triple and pairwise empirical distributions can be written in a very simple form, as we will explain next. Moreover, by multiplying different empirical distributions together, it is possible to form 'observable' matrices, whose eigenvalues are directly related to the entries of PWM motif and P background. The last step consists of identifying PWM motif with the binding model and P background with the background distribution. This is done via an exact P-value test where the matrices are used to define a classifier to distinguish between sequences containing the binding site and randomly reshuffled sequences.
Detailed description of FastMotif
Estimating the motif lengthIn the earlier example, we assumed an a priori knowledge of the target motif length ('  3). In general, the expected length of the binding site is not known a priori, and it should be estimated via a statistical test over the sample. FastMotif obtains an estimation of the binding site length by measuring the Pearson test statistic of all sub-sequences of length k appearing in it. For k  3;. .. ; 15 the expected length is defined aswhere O k is the frequency of the most represented subsequence of length k in the random subset and E k  4 k is an expectedSpectral sequence motif discoverytheoretical frequency, based on the null hypothesis PA  PC  PG  PT  1 4. For speed reasons the statistical test is performed on a small random subset of the whole dataset ($ 5000 sequences). Given an expected motif length ' of the target binding site, we define S ' to be the collection of all overlapping sub-sequences of length ' in the dataset. Equivalently, S ' can be thought as the set of all records of a sliding window of length ' running over the sample.
Modelling secondary motifsTo relax the assumption of a single binding site, the two-component mixture in the earlier example is replaced in FastMotif by a p-component mixture with factors PWM r , with r  1; 2;. .. ; p. In this case, the set S ' is modelled by a convex combination of PWM models, that is S 'Intuitively, the p PWMs are associated to the primary motif, the background, and the remaining p  2 secondary motifs, respectively. We note that, even if the dataset is expected to contain a single binding motif, working with a p-component mixture increases the robustness of the model, as it allows taking into account possible constant patterns that often appear in the background.
The spectral methodWe now describe how we can extract the entries of each matrix PWM r from a set of 'observable' matrices using the spectral method. For illustration purposes, let us assume again that '  3, and let S 3 denote the set of all 3-mers in the dataset. Let ^ P be the empirical joint distribution whose entry ^ PI; J; K is the frequency of the subsequence I; J; K in S 3. Pairwise joint probability matrices are defined analogously and can be obtained from ^ P by marginalization, for example ^More generally, the 3D array ^ P can be transformed into a matrix by considering a linear combination of its 2D slices. For example, slicing on the 3-direction, one can select one of the four slices by setting ^where i 2 fA; C; G; Tg and e i is a 4D basis vector with 1 on the i-th entry and 0 elsewhere. Assuming a p-component mixture modelis a probability distribution over the alphabet fA; C; G; Tg. We also define a 4  p conditional probability matrix X  X 1 ;. .. ; X p , whose r-th column is the first column (X r ) of the r-th matrix PWM r , and analogously for Y and Z. Then, assuming that the data are drawn exactly from a mixture of p  4 product distributions, and under the factorizability assumption of the PWM model, it is easy to verify the following identities:^ P i  Xdiagwdiage T i ZY T ; i 2 fA; C; G; Tg;where w  w r  is the vector of mixing weights, and diagv denotes a diagonal matrix with the entries of the vector v on the diagonal. The key idea in spectral methods is that, provided that (2)and(3) hold and the matrices X and Y are invertible, we can recover the entries of the matrix Z from the eigenvalues of four 'observable' matrices defined asi 2 fA; C; G; Tg:According to (4), the observable matrices ^ M i are simultaneously diagonalizable for all i 2 fA; C; G; Tg. From the definition of, where Z r is the probability distribution at position 3 according to the r-th model. Given the set of observable matrices ^ M A ; ^ M C ; ^ M G ; ^ M T , we can recover all entries of the matrix Z from the matrix of their eigenvalues K ir  k r  ^ M i , where we denote by k r A the r-th eigenvalue of a matrix A. The entries of X and Y are obtained from analogous observable matrices, where the role of the three variables (I, J, K) is interchanged.
Model misspecificationSo far we have assumed that the model is exact, i.e. the data are drawn exactly from a mixture of p product distributions and an infinite size sample is available. When the model is misspecified, (4) holds only approximately and the observable matrices ^ M i are not exactly simultaneously diagonalizable. In this case, the entries of the conditional probability matrices can be recovered via an approximate diagonalization of the matrices ^ M i , for i  A; C; G; T. Letting ^ M i  M i  E, where M i  Xdiage T i ZX 1 and E is the misspecification term, it is then possible to obtain upper bounds for the eigenvalue estimation error in terms of jjEjj  ffiffiffiffiffiffiffiffiffi ffi E T E p . The standard procedure consists of choosing an arbitrary linear combination of the observable matrices ^compute its eigenvectors and use them to approximately diagonalize all single ^ M i , for i 2 f A; C; G; Tg (). The choice of the linear combination coefficients h i is crucial and the stability of the method depends strongly on the eigenvalues separation of the matrix ^ Mh (). Some separation guarantee can be obtained from classic concentration bounds on the Gaussian distribution, if the vector h is chosen to be a random Gaussian vector of zero mean and unit variance (). In FastMotif, we depart from the standard spectral procedure in two ways. First, in order to improve the stability of the spectral decomposition, we compute an ad hoc vector h from a previous estimate of the conditional matrix Z. This estimate is obtained from the eigenvectors of a different observable matrix, obtained by exchanging the role of the sub-sequence positions in the definition of ^ P i and ^ P 12 , and we can show that the resulting h has good separation guarantees (depending on the previous estimate's error). Second, instead of using the eigenvectors of the matrix ^ M to diagonalize the matrices ^ M i , we estimate the eigenvalues of ^ M i using the orthogonal matrices appearing in the Schur decomposition of ^ M instead of its eigenvectors. Intuitively, we exploit the fact that the Schur form of a matrix A is not unique on its upper-diagonal terms but it always contains the eigenvalues of A on the diagonal (). In the Results section, we provide a numerical comparison between the standard spectral approach and the simultaneous diagonalization approach of FastMotif based on the Schur decomposition, demonstrating the advantages of the proposed method ().
General setupFor simplicity, we have presented so far the simple special case of motifs of length three and have restricted the number of mixture components to p  d. Binding site models of general length ' > 3 can be obtained by iterating the procedure described earlier with I, J, K assigned to different positions within the motif. Regarding the number of components in the mixtures, one should distinguish between two situations. The case p < d can be handled by reducing the size of the empirical matrices by means of a set of p  d orthogonal matrices obtained from the truncated singular value decomposition of ^ Px; y; ^ Py; z and ^ Px; z (). The case p > d requires the definition of a new working space of dimensionality D > p, that can be obtained by considering grouped consecutive bases of length n > 1. For example, choosing n  2, the set S ' of all sub-sequences of length ' over the DNA alphabet fA; C; G; Tg is transformed into the equivalent set of sub-sequences of length ' 2 over the grouped alphabet fAA; AC;. .. ; TTg and one has D  4 n  16. Because higher dimensional variables are able to capture interdependences between neighbouring positions of the binding sites, FastMotif maximizes the length of grouped variables. Note that binding sites of general length ' > 3 can be represented in terms of length-3 'high-dimensional' binding sites. Given ' > 3 it is always possible to define grouped variables of different lengths, say n 1 ; n 2 ; n 3 , such that n 1  n 2  n 3  ' and recover the binding model via the method described in the previous sections. However, in the case of grouped variables, the output of the spectral algorithm is a set of p frequency matrices HPWM r   ~ X r ; ~ Y r ; ~ Z r  2 0; 1 D3 whose columns are probability distributions over the alphabet of grouped variables. The corresponding 4D models are then obtained from the set S ' as follows. According to the model assumption, the set S ' of all sequences of length ' is the direct sum of exactly p subsets each of them containing the sub-sequences of length ' generated by the r-th model. Letting, S r ' be the subset of sub-sequences generated by the model r, the corresponding 4D position weight matrix PWM r is defined by the frequencies of each letter A; C; G; T at each position i  1;. .. ; ' in S r '. To select whether a sub-sequence has to be included in a subset S r ' , we define a scoring function f r s  log HPWM r s=HBs, where HB is a background model computed over S '. The subsets S r ' are defined bywhere b is a random sequence of length ' and match is a user defined P-value matching threshold. In practice, since the computation of Pr f r b > f r s can be expensive, we approximate the exact P-value computation by introducing a threshold n r such that Prf r b > n r  < match is true over a finite set of N match $ 1 match random sequences. Finally, we admit a sequence s 2 S ' to the set S r ' if f r s > n r. The last step consists of isolating the model corresponding to the protein binding site from the other p  1 models in the mixture. For that we use the ame tool of the MEME suite (), which allows computing the exact P-value of each model over a test dataset consisting of positive sequences from the dataset and negatives obtained by random reshuffling of the positives.
ResultsThe present version of FastMotif has been optimized to process datasets from HT-Selex experiments on transcription factor binding. Due to the enormous number of sequences, HT-Selex data are hard to analyse using other available motif discovery algorithms. Designed to fill this gap, FastMotif is able to process HT-Selex datasets in few seconds and extract high quality probabilistic binding models that match those produced by other state-of-the-art algorithms. In this section, we present and discuss the performance of the algorithm on various HT-Selex datasets and compare the motifs produced by FastMotif with the ones produced by other algorithms. To test the robustness of FastMotif to model misspecification, we have also tested FastMotif on semi-synthetic data with increasing amounts of noise. Finally, we report some important theoretical features of the algorithm and discuss its sensitivity with respect to some user-defined parameters that can be tuned to optimize the search.
HT-Selex dataWhat distinguishes FastMotif from other sequence discovery algorithms is the inference technique based on spectral methods. HTSelex is a domain where high quality and biologically meaningful outputs can be obtained directly form spectral learning. To test FastMotif on real data, we have focused on the HT-Selex experiments described by. All data are available at the European Nucleotide Archive (ENA) database under accession number ERP001824. For a given transcription factor, we have downloaded the dataset corresponding to the Selex cycle used to compute the binding models published in the Supplementary Material of (). Other available motif discovery tools, as for example the popular Expectation-Maximization algorithm MEME () or STEME (), were unable to process files of the size of the original datasets and could not be included in the comparison. Moreover, since the code of 'Multinomial' is not available, we have only considered the PWM published in. Both FastMotif and DREME ran on the same machine with default settings: for FastMotif we set the number of mixture components p  15 and the matching P-value threshold to 0.001, and DREME was launched with the option 'm1' that stops the) is the motif discovery algorithm of the MEME suite designed for processing big datasets. All logos were obtained using weblogo 3.3 (). Except for some discrepancies on the motif lengths, we observe very good agreement between the output of the three algorithmsSpectral sequence motif discoverysearch when one motif has been found. Inand 2, we show respectively the models obtained by the different algorithms on the various datasets, and the corresponding number of sites used to compute the frequency matrices. All logos inwere computed using the application weblogo 3.3 (). In some case the columns of the models computed by 'Multinomial' do not sum to the same values and we have reported the sum of the entries in the most deterministic column. In general, the numbers shown in, compared with the total amount of sequences in the datasets, show that only a relatively small subset of sequences contains the expected binding site. The experimental interpretation of this fact goes beyond the scope of this paper, but we only note that, except for one case, the number of 'sites' used to compute the final model by 'Multinomial' is significantly smaller than for DREME and FastMotif. This can partially explain the difference in length between the models computed by FastMotif and 'Multinomial'. Because we do not know how the motif length is fixed by 'Multinomial', we do not discuss further the possible biological meaning of such discrepancies. Conversely, on approximately the same amount of sites, FastMotif is able to compute models that are two or more positions longer than the models computed by DREME. The number of binding sites used to compute the model by FastMotif depends on the choice of a user defined P-value matching threshold match (Section 3), which is here set to its default value 0.001. Assuming the set S ' of all sub-sequences of a given length ' to be drawn from a mixture of product distributions, the role of such matching threshold is to assign each sub-sequence in the dataset to the correct component in the mixture. We show in(centre) that, for HT-Selex data, small variations of match do not significantly affect the quality of the output, but we expect that a fine tuning may be needed for more noisy data.A quantitative comparison between the logos shown inhas been obtained by computing the exact P-value of each model on a series of ground-truth test samples. For each transcription factor we have created 20 test samples containing 1000 positive sequences from the original dataset and 1000 negatives. The negative sequences were obtained by reshuffling of the positives. Given such test samples and the models in, the corresponding P-values were computed using the tool ame (), launched as >ame-fix-partition 1000bgfile <background file><model>, where the option-fix-partition 1000 fixes the size of the positive set and the background file contains the single letter frequencies in the test dataset. In(left), we show the logarithm of the average P-value over the 20 tests and the corresponding variances dlogy  1 y dy as error bars. We observe that FastMotif obtains the best score for all the models shown in, except for the HMBOX1 model where the low performance of FastMotif is probably due to the small size of the dataset. A possible weakness of this evaluation is the uncertainty about the ground-truth test sample, built on the probably false assumption that all sequences in a dataset contain the relevant binding site. However, since all algorithms were tested on the same datasets, we expect the true number of false positives to affect only mildly the validity of our comparison test. We have already briefly commented on the limited length of the models computed by DREME, that restricts the search to sub-sequences of length '  8 for speed reasons. As it is shown in, the motifs computed by DREME coincide with the most deterministic part of the models computed by FastMotif. The presence of several flanking positions is perhaps one reason for the better classification performance of the motifs computed by FastMotif. Another reason of the slightly better performance of the models computed by FastMotif. In same cases, the columns of the PWM computed by 'Multinomial' () do not sum to the same value. In those cases, we report the number of sites of the most deterministic columnsis probably their fully stochastic profile, compared with the almost deterministic models computed by DREME. Finally, in(right), we show the execution times of FastMotif and DREME on datasets of increasing size. 'Multinomial' has been excluded from this comparison because we could not have access to any estimation of its running time. FastMotif was about 10 times faster than DREME, in each of the datasets considered.
Sensitivity with respect to noise levelTo test the robustness of FastMotif with respect to the level of noise in the data and model misspecification, we created semi-synthetic data and studied the performance of the algorithm in increasing levels of noise. The semi-synthetic data were generated by implanting instances of a stochastic motif on random genome sequences of increasing length. The motif instances were generated by sampling from a position weight matrix [the ELF3 binding site model computed by FastMotif on the corresponding dataset of ()] via the Matlab function discrete sample. In total, we created 50 datasets, each containing 1000 sequences of length L  10  5  n, with n  1;. .. ; 50. FastMotif ran on each dataset and the obtained models were compared with the reference ELF3 model by computing the distance in norm between the two PWM. With default settings, FastMotif outputs three models ranked according to their P-value and we have chosen for the comparison the model of lowest P-value. Moreover, when the matrices computed by FastMotif and the reference model had different lengths we restricted the comparison to the eight most informative positions. In(top), we report the difference in norm between the reference and the estimated model as a function of the amount of noise in the dataset, i.e. the length of background random genome sequences. Due to the presence of secondary motifs in the random genome sequences, the lowest P-value motif that we chose for the comparison did not always correspond to the expected target motif. We expect this issue to be the main cause of the big jumps in the error function (dashed line) shown in(top). When the length of the sequences becomes too large, trivial secondary sub-sequences start being over-represented in the dataset and the algorithm cannot distinguish between them and the instances of the reference motif. We also repeated the experiment by replacing the random genome sequences with random sequences generated using the Matlab function randseq, and the jumps disappeared (solid line). In summary, the above analysis seems to indicate that any use of our algorithm to noisy in vivo data, as for example ChIP-Seq data, may require some pre-processing steps that we do not address here.
Sensitivity with respect to user-defined parametersFastMotif depends on two user-defined parameters: the number of mixture components (p) and a P-value matching threshold ( match ). The number of mixture components (p) defines the number of PWM to be included in the probability distribution that is used to model S ' , the set of sub-sequences of length '. Extra components are ideally associated to secondary motifs or over-represented redundant parts of the background, and make the algorithm more stable in the case of noisy data. The matching threshold ( match ) is used to assign each sequence in S ' to the correct mixture component and extract the corresponding position weight matrix. Small matching thresholds make this selection restrictive and the final position weight matrix more deterministic, while bigger matching thresholds increase the number of sites used to compute the model, and hence the noise. A careful tradeoff between the information content of the final logo and the number of enriched sites to be used () is often required. In this article, we have always set the user-defined parameters to their default values p  15 and match  0:001. In(centre), we show the quality of the output as a function of such user-defined parameters. The plot shows that for reasonable (not extreme) values of the two free parameters, the quality of the output is rather constant (plateau). Finally, we comment on the new fully probabilistic motif discovery approach implemented in FastMotif. One of the main features is that no deterministic consensus sequence is required to initialize the search and models are computed directly from the empirical joint frequency matrices. The search strategy is analogous to the one used by MEME (), where the sequence discovery problem is translated to the problem of learning a mixture of product distributions. The key novelty of FastMotif is the spectral learning algorithm that is used to infer the parameters of the mixture. In. Synthetic data experiment (top): distance between a ground-truth model and the FastMotif prediction on semi-synthetic data (dashed line) and synthetic data (solid). A set of motif instances, generated from a given binding site model (ELF3), have been inserted at random positions on random genome sequences (semi-synthetic data) or on randomly generated sequences (synthetic data) of increasing length. Better performances on the synthetic data can be explained by the presence of secondary motifs in the genome background. Parameter sensitivity (centre): P-value of the output model as a function of varying user-defined parameters, on HT-Selex data (MAFK dataset). For reasonable values of the parameters, the quality of the output is substantially constant (plateau). Noise sensitivity (bottom): a random four-components mixture Ttrue 2 0; 1 444 is perturbed by adding an extra component associated to the mixing weight wp1  2 0; 0:2 and compared with its estimations T est obtained via a standard spectral algorithm () (solid line) and FastMotif (dashed line). For each value of the misspecification parameter, we plot the average normalized distance jjTtrue Test jj jjTtrue jjjjTest jj over 50 equivalent experiments. In all cases, the Schur-based decomposition turned out to be more stable than the standard one
Spectral sequence motif discoveryparticular, FastMotif is built on a new and more stable spectral technique based on the Schur decomposition of matrices (Section 3). The new method comes with a theoretical analysis and we provide bounds of the error of parameter estimation as a function of the amount of noise (Supplementary Material). In particular, we generated a set of triple joint probability distributions using a random five-components mixture, and used FastMotif and the standard spectral algorithm () to infer the parameters of the corresponding four-components approximations. The weight of the fifth component 2 0; 0:2 has been used as a misspecification parameter. In(bottom), we compare the distance in norm between the original fourcomponents model, obtained by subtracting the fifth component, and its estimation for increasing values of. In average, and for almost all values of the misspecification parameter, the FastMotif decomposition scheme performs better than the standard approach.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
N.Colombo and N.Vlassis at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Conclusions Under the approximation that TF-DNA binding affinities are position-independent, the problem of finding over-represented motifs in a set of sequences is equivalent to the problem of learning a mixture of product distributions. The inference of mixtures of product distributions is a well-known problem in statistics and machine learning, and powerful techniques have been developed to solve the problem based on spectral decompositions. We described FastMotif, a spectral motif discovery algorithm that is fast, robust to model misspecification, not prone to local optimal solutions, and that can search for motifs of arbitrary length. We have tested the algorithm on HT-Selex experimental data and produced PWM's that match the profiles obtained by other state-of-the-art motif finding algorithms, but one order of magnitude faster. FastMotif is based on a new approximate simultaneous matrix diagonalization scheme, for which we provide theoretical and numerical error bounds. We have analysed the robustness of the algorithm theoretically and via numerical experiments on semi-synthetic data. Moreover, we have studied the sensitivity of the algorithm on its input parameters and shown that, at least for HT-Selex data, small variations around their default values do not affect the quality of the extracted motifs. Designed for the analysis of large-scale transcription factor binding data, the current version of FastMotif restricts the search to sub-sequences of relatively small length (from 3 to 15 nucleobases), but the arbitrary-length case can be handled with minor modifications. For increasing search ranges, the complexity of the spectral decomposition part of FastMotif, which is linear in the sample size, is substantially unchanged. Because of its flexibility and speed, FastMotif can be a useful tool in many important biological applications that go beyond the identification of transcription factor binding sites. In future work, we would like to extend our method to the more challenging domain of RNA-binding proteins and consider applications in other kinds of amino acid sequence analysis.
