
INTRODUCTIONGenome-wide association studies (GWAS) have become increasingly popular for studying complex human diseases. Within the last several years, the number of single nucleotide polymorphisms (SNPs) per DNA array has grown from 10 000 to 1 million (). Despite the very large number of SNPs that are genotyped in a study, GWAS data are commonly analyzed one SNP at a time. Indeed, the Armitage trend test (ATT) is used almost exclusively. * To whom correspondence should be addressed.There are at least two strong reasons for considering all the SNPs or at least a large subset of them simultaneously. First, the marginal effects of SNPs (i.e. the effect of each SNP on disease when it is considered alone) may be quite different from their joint effects:(i) a SNP that is not related to disease but is correlated with a causal SNP will be marginally associated with disease; (ii) some SNPs may have weak marginal effects but strong joint effects. Conditional on causal SNPs that are already in the model, false positive signals tend to be weakened while marginally uncorrelated causal SNPs have a better chance of being selected. Second, the predictive power of a single SNP tends to be very low. The accuracy of prediction can be improved substantially by utilizing a large number of relevant SNPs. It is extremely challenging to decide which set of SNPs should be included in the joint analysis because the number of SNPs in a GWAS is much larger than the sample size. This is commonly referred to as the 'small n, large p' problem. A major difficulty in this problem is that the number and extent of spurious associations between predictors and response increase rapidly with increasing p. Weak effects of causal variants and strong linkage disequilibrium (LD) among SNPs present additional challenges. There is a large body of literature on variable selection methods, including bridge regression (), least absolute shrinkage and selection operator (LASSO;), smoothly clipped absolute deviation (SCAD;), elastic net () and adaptive lasso (). However, these methods were designed for a moderate number of predictors (i.e. tens or hundreds). For ultra-high p, these methods may be computationally infeasible and statistically inaccurate. Recently, Fan and Lv (2008) developed the so-called sure independence screening (SIS) strategy for high-dimensional statistical modeling. The idea is to first reduce the dimension from a very large scale to a moderate scale that is below sample size by univariate correlation learning, and then select important predictors by a moderate-scale variable selection method, such as the LASSO or SCAD. In a similar spirit,reduced the dimension of SNPs in a GWAS to several hundreds using a simple score criterion and applied the LASSO to the reduced set of SNPs. A drawback of this approach is that important features that are marginally uncorrelated with response are bound to be missed because the univariate screening step is based entirely on marginal correlations.suggested the iterative sure independence screening (ISIS) procedure, which iterates the SIS procedure conditional on the previously selected features so as to capture important features that are marginally uncorrelated with response. Fan and Lv's work is confined to linear regression of a continuous response, and the number of features they considered is merely thousands. In this article, we extend Fan and Lv's ISIS idea to logistic regression of casecontrol GWAS data. This extension is challenging for several reasons. First, the ISIS performs linear regression analysis of residuals, but residuals cannot be used as response variables in logistic regression. Second, prediction errors tend to be much higher for binary outcomes than continuous outcomes. Third, the number of SNPs can be extremely large, typically more than half a million. Fourth, the effects of causal SNPs on complex diseases tend to be small to modest, so the signal-to-noise ratio in GWAS data is low. Fifth, the LD among SNPs is extensive and can be extremely high in certain regions. A separate challenge is that the false discovery rate (FDR) associated with the ISIS, and indeed with any existing variable selection method, tends to be high. Recently, Meinshausen andproposed the stability selection strategy to reduce the FDR. The idea is to repeatedly subsample the original data and perform variable selection on each subsample. The features selected frequently among the subsamples tend to be truly associated with outcome and thus should be included in the final model. In this article, we integrate stability selection into our ISIS procedure to develop a new approach, GWASelect, for genome-wide variable selection. We describe our approach in the next section. In Section 3, we demonstrate through simulation studies that GWASelect has robust performance under a variety of LD structures and can substantially increase the power and reduce the FDR compared with existing methods. In addition, the regression models generated by GWASelect significantly improve prediction accuracy. In Section 4, we apply GWASelect to the GWAS data from the Wellcome Trust Case-Control Consortium () and show that it yields several novel discoveries and improves prediction accuracy.
METHODSOur ISIS method consists of one marginal SIS and two rounds of conditional SIS. We first describe the marginal SIS procedure. The data contain n subjects and p SNPs. The genotypes of each SNP are standardized by its sample SD. The SIS theory suggests to reduce the original set of features to a small subset whose dimension is in the order of n/logn. Since binary outcomes generally contain less information than continuous outcomes, we shrink the dimension of SNPs from p to n/(4logn). The SIS theory also suggests to use a large proportion of the subset for the marginal SIS; therefore, we choose to use t SNPs, where t is the integer part of 0.9n/(4logn). That is, we perform the ATT (under the additive model) on each SNP and select the t most significant SNPs to form a set S 1. Then we apply the LASSO to S 1 as follows. For i = 1,...,n, let Y i denote the disease status (1 = case, 0 = control), and X i denote the (t +1)-vector consisting of 1 and the genotypes of the t SNPs in S 1. The genotype of each SNP is represented by the number of minor alleles. It is natural to assume the logistic regression modelT denotes the vector of unknown regression coefficients. The penalized log-likelihood function takes the formwhere  is the tuning parameter. We adopt the cyclic coordinate decent (CCD) algorithm (), which is tantamount to maximizing l() in a component-wise manner. Cross-validation can be used to determine the tuning parameter (and consequently the model size), but for now, we set the model size to a user-specified number, say d. (We will show later how to determine the model size adaptively.) That is, we run the LASSO on a dense grid of  until it generates a model containing d predictors. If the exact number of d cannot be achieved, we choose the model whose size is right below d. This model is labeled M 1. To reduce potential collinearity, we prune M 1 using pairwise correlations. Our analysis revealed that 99.9% of the pairwise correlations among the Illumina300K SNPs have absolute values less than 0.8 (corresponding to r 2 of 0.64). Thus, we set the pruning threshold for r 2 to 0.64 so as to minimize the loss of information due to pruning. The pruned model is labeledwhere  and  are unknown regression coefficients. We are interested in testing the null hypothesis H 0 :  = 0. It is computationally intensive to fit the above model for each of the (pt 1 ) SNPs. To bypass this difficulty, we perform the conditional score test. Specifically, we calculate S = U/V 1/2 , whereand  is the maximum likelihood estimator of  under H 0. Note that  and I  do not involve any data in M * 1 and thus need to be calculated only once at the outset of the conditional SIS. Given  and I 1  , we calculate the test statistic S for each of the (pt 1 ) SNPs in M * 1. In vein with the SIS theory, we choose the most significant q SNPs, where q is the integer part of 0.05n/(4logn), and call this set of SNPs S 2. (We use 0.05 since 0.9+0.05+0.05 = 1, where 0.9 pertains to the marginal SIS, and (0.05+0.05) to the two rounds of conditional SIS.) The first step of the conditional SIS is aimed at identifying important SNPs that are marginally uncorrelated (but conditionally correlated) with disease while weakening the priority of those unimportant SNPs that are highly associated with disease through their correlations with the SNPs inthe FDR, we combine the extended ISIS procedure with the stability selection strategy () to create the GWASelect method, as illustrated in. Specifically, we randomly obtain half of the cases and half of the controls from the GWAS data to form a subsample and then run the ISIS on this subsample. The resulting model is named T 1. Repeating this subsampling concatenated with the ISIS 50 times, we obtain T 1 ,...,T 50. Let T = 50 j=1 T j , and denote T ={v 1 ,...,v L }. We then calculate the selection probabilities for the L SNPs in Tis the indicator function. We choose the d SNPs with the highest selection probabilities from T to form the GWASelect model. It is sometimes desirable to determine the model size adaptively from the data. To this end, we develop dynamic-GWASelect (d-GWASelect), which contains two modifications to the GWASelect. The first modification is that cross-validation is used to determine the tuning parameter for the LASSO embedded in the ISIS. Specifically, we divide the data randomly into five equal parts, with the k-th (k = 1,...,5) part being the testing data and the remaining four parts being the training data. For a given tuning parameter , we apply the LASSO to the training data and select the SNPs that have non-zero regression coefficients. We calculate the liability score (i.e. the linear predictor) for each testing subject. Let J 1 denote the set of subjects with the highest 100% liability scores, and J 2 the set with the lowest 100%, where  is a user-specified number between 0 and 0.5. We then calculate the -error rate, defined as (where n is the number of subjects in the testing data. We choose the value of  that minimizes the -error rate averaged over the five testing datasets forThe second modification is that, instead of fixing the model size at d, we specify a selection threshold  and select all SNPs with selection probabilities  . As shown in the next section, the influence of  on the final model is typically small.In the third scheme, multiple causal SNPs were generated to be marginally uncorrelated with Y. We let the first causal SNP be independent of the other nine causal SNPs. The latter were simulated to form three clusters,
SIMULATION STUDIES, each cluster residing on one chromosome. The three clusters are independent of each other, but within each cluster, SNPs have a compound symmetry correlation structure with correlation 0.5. We set  * = (0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5) T. Under this scheme, corr(Y ,G 4 ), corr(Y ,G 6 ) and corr(Y ,G 9 ) are equal to 0. For all three schemes, the positions of the causal variants on the chromosomes were randomly chosen. Thus, our simulation results would not be affected by any local LD patterns. It is not trivial to simulate non-causal SNPs as they are desired to mimic the actual LD structure of human population. There exist several genome simulators based on the coalescent approach (), for which the users have to arbitrarily specify a number of parameters. As an alternative, the GWAsimulator of Li and Li (2008) employs a moving-window mechanism and can simulate genotypes based on the Illumina HumanHap300 chip data. We adopted the latter approach. Because the average distance between two SNPs for the Illumina HumanHap300 chip data is roughly 10 kb, the total length we simulated is approximately 600 Mb, which accounts for 1/5 of the whole genome. The LD was well preserved and no trimming was done for the simulated data.explored variable selection from a Bayesian point of view by imposing the Laplace prior or the normal exponential gamma prior on each SNP. The former prior yields the LASSO procedure, while the latter generates a more sparse model and is called hyper-LASSO (HLASSO). We included the HLASSO in our simulation studies. Thus, we analyzed the simulated data by five methods: (i) the ATT method, for which the threshold for declaring significance was set to 0.05/60000 (i.e. Bonferroni correction); (ii) the method by; (iii) the (extended) ISIS method; (iv) the HLASSO; and (v) the GWASelect method. We set the model sizes to 15 for all methods (except the ATT) because most biology labs are likely to restrict their resources to a small number of top SNPs. There are different criteria to evaluate a variable selection method. We chose to use the true discovery rate (TDR) and false discoveryrate (FDR;) because the main goal of GWAS is to identify causal variants. For genetic studies, how to define the true discovery and false discovery is a delicate issue. This is because once a SNP is declared to be significant, all SNPs that are close to and in LD with that SNP will be followed up. We defined the true positive and false positive as follows. If a captured SNP was no more than 50 SNPs away from a true causal SNP and had r 2 > 0.05 with that same causal SNP, then we classified it as a true positive. [Our experiments revealed that replacing 50 with 20 yielded similar results;provided a rationale for choosing 0.05 for r 2 .] If more than one SNP satisfied these conditions, we counted them only as one true positive cluster. The remaining captured SNPs were classified as false positives. If two false positive SNPs were no more than 10 SNPs apart (i.e. within 100 kb in distance), we counted them as only one false positive cluster. The calculations of the TDR and FDR were based on clusters, rather than on individual SNPs. For each simulation scheme, the number of replications was set to 200. The results are shown in. Scheme 1 was designed to compare the five methods under a scenario where all causal variants are independent and their effects are moderate. Under this scheme, all five methods yield high TDRs (>95%), but the FDRs are highly variable. Despite a large model size, the ATT method has the lowest FDR. This seemingly paradoxical phenomenon is explained by the fact that most of the SNPs in the ATT model are highly clustered due to strong LD. The GWASelect model has an elevated FDR, but far lower than the ISIS and the HLASSO, and slightly lower than the Wu et al. model. This demonstrates that, by repeated subsampling and variable selection, GWASelect is able to remove many noise features from the model. The ATT method appears to be a good option when causal variantsare independent with moderate effects, but if one wishes to achieve higher power without too many false discoveries, the GWASelect method would be a reasonable choice. In scheme 2, all 10 causal variants are correlated with each other, which makes variable selection more challenging. It can be shown that under this scheme, the marginal effects of the causal SNPs are much higher than their joint effects. For variable selection, this has the undesired effect of selecting unimportant SNPs that are in proximity of the causal SNPs. Reflecting this fact, the ATT, the ISIS, and the HLASSO all have FDRs above 30%. The GWASelect is able to keep the FDR at a low level and preserve most of the power because of stability selection. The Wu et al. method has high power and a relatively low FDR, suggesting that this method is particularly capable of distinguishing causal SNPs from unimportant SNPs that are in LD with them. Scheme 3 represents a more complex correlation structure in which the three causal SNPs (i.e. the fourth, sixth and ninth SNPs) are marginally uncorrelated with Y. As expected, the methods that are strongly driven by marginal correlations, such as the ATT and themethod, almost completely missed G 4 , which drives down their power to 70%. Both the ISIS and the HLASSO methods achieved higher power, but at the price of high FDRs (around 30%). The GWASelect model offers a more balanced solution in terms of the TDR and FDR. In summary, only the HLASSO and the GWASelect were able to keep their power above 90% under all three schemes, and the latter appears to have a much lower FDR. The other three methods either lack power under some schemes or entail high FDRs in others. Next, we investigated the prediction accuracy of the five methods. For each scheme, we further simulated 2000 testing subjects under the prospective sampling. To avoid numerical instabilities, we pruned the obtained models and used the pruned models for prediction. We calculated the true liability score and the estimated liability score for each subject and used the correlation between the two scores as a measure of prediction accuracy. We also calculated the absolute difference between the model-predicted and true disease probabilities, termed as p-diff, to measure the prediction error. The results are shown in.
Q.He and D.-Y.LinPage: 5 18The Wu et al. method excels under scheme 2, consistent with its high TDR and low FDR under this scheme. However, both the Wu et al. and the ATT are less accurate than the other methods under scheme 3 because they missed those marginally uncorrelated SNPs. The HLASSO performs well under schemes 2 and 3, suggesting that high prediction power can be achieved even if some noise features are included in the model. Only the HLASSO and the GWASelect have prediction accuracy above 0.9 under all three schemes. To assess data-adaptive choice of model size, we repeated the above simulation studies but now incorporated a 5-fold crossvalidation into all the methods (except the ATT) by using the 10% error rate as the evaluation criterion (see Section 2). For d-GWASelect, we set the selection threshold  to 0.3. All effect sizes were set to be moderate. For both schemes 1 and 3,  * = (0.4, 0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6) T. For scheme 2,  * = (0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2) T. The results are shown in Tables 3 and 4. The d-GWASelect remains a robust variable selection method under all three schemes and indeed appears to have a better performance than its counterpart with a fixed model size. Thethe ISIS and the HLASSO now entail extremely high FDRs and poor prediction accuracy. The reason is that crossvalidation often favors a large model size for logistic regression, especially when the signalnoise ratio is low. The d-GWASelect method, however, has a well-controlled model size because stability selection sifts away many noise features. Overall, the d-GWASelect enjoys low FDR, high TDR and excellent prediction performance. Replacing the selection threshold with 0.4 yielded highly similar results (data not shown). We also explored the use of deviance(instead of the 10% error rate) as the evaluation criterion for crossvalidation, and the d-GWASelect remains more favorable than the other methods (Supplementary Tables S1 and S2).; the analysis for the other five diseases is presented in Supplementary Tables S3S7. We excluded a small number of subjects according to the sample exclusion lists provided by the WTCCC. In addition, we excluded a SNP if (i) it is on the SNP exclusion list provided by the WTCCC; (ii) it has a poor cluster plot as defined by the WTCCC; (iii) its MAF <0.01 in both cases and controls; or (iv) it has extreme departure from HardyWeinberg equilibrium (P< 10 4 ). Approximately 390 000 SNPs were used in the analysis, and there were 2938 controls, 1924 T2D cases and 1963 T1D cases.indicates the SNPs selected by the ATT,HLASSO and GWASelect for T2D; the details are shown inand Supplementary Table S9. Under the ATT method, 15 SNPs reach the genome-wide significance of P < 10 7. The most significant one is rs4506565 (P-value = 7.5  10 13 ), which is located in gene TCF7L2. The other 14 SNPs are clustered within either TCF7L2 or FTO. These results are consistent with the WTCCC's findings. The HLASSO model is essentially identical to the ATT model, albeit with a smaller model size. For the Wu et al. and GWASelect methods, we set the model sizes to 20. Both methods successfully detected TCF7L2 and FTO. They also identified a locus that spans TSPAN8/LGR5, which was one of the most significant loci reported in a recent meta-analysis of 10 128 subjects (). This finding demonstrates empirically that regression-based variable selection methods can be more powerful than the ATT method.It is interesting to compare themodels. Five SNPs, rs11688935, rs6846031, rs6872465, rs2389591 and rs10435018, show up only in the GWASelect model. Among these SNPs, rs6846031 was selected partly due to its conditional correlation with T2D, underscoring the importance of conditional screening in variable selection. This finding also indicates that genetic factors underlying T2D are not simply in parallel with each other, but rather form a complex structure that needs to be carefully dissected. Several SNPs in our GWASelect model have not been reported in the literature on T2D. Some of them are plausibly related to T2D. For example, GULP1 is an adaptor protein that binds and directs the trafficking of LRP1 (), a protein that has been shown to play a critical role in adipocyte energy homeostasis and insulin sensitivity (). Thus, genetic variants in GULP1 may potentially influence the amount of LRP1 in adipocyte cells and thereby modulate a person's risk to T2D. As another example, the CREB5 was recently found to be downregulated along with other members of the insulin signaling cascade when stimulated by a ligand of PPAR, which is known to be associated with T2D (). This suggests that CREB5 is closely related to PPAR and the insulin pathway. The other SNPs do not have known connections with T2D, but further investigation of those loci may reveal novel mechanisms or pathways related to T2D. For prediction of T2D, the -error rates (with  = 0.1) of all four models are over 40%, suggesting that T2D is greatly influenced by other types of genetic variations and environmental factors. Since it is not very meaningful to compare prediction errors at such a high level, we turned our attention to the T1D data because it is well-known that T1D is genetically more homogeneous than T2D. For the T1D data, we used cross-validation to choose the tuning parameter for the d-GWASelect method and set the selection threshold  to 0.20. For themethod, we set the model size to 15. The results are shown in,ADAM29, SYNGAP1, CUX2 and ALDH2 do not appear in any of the other three models. The gene SYNGAP1 was observed to have strong conditional correlation with T1D, demonstrating again that selection solely based on marginal correlation is insufficient. Searching the T1DBase (http://www.t1dbase.org) revealed that all four genes have expressions in pancreas, although none has been previously considered as strong candidates for T1D. Interestingly, the CUX2 has been shown to directly regulate the expression of Page: 7 18NeuroD (), a gene that can cause T1D if mutated. Finally, we compared the prediction accuracy of the four methods. We randomly divided the data into three parts, two as the training data and one as the testing data. Since the training dataset contains only 2/3 of the original data, we reduced  from 0.20 to 0.10 to ensure that a similar number of loci are included in the d-GWASelect model. Since the true liability scores and disease probabilities are unknown in real data, we measured the prediction errors by the -error rates for  = 0.1, 0.15 and 0.25 (see Section 2 for detail). Considering that pruning was done before each model was used for prediction, we report the actual (i.e. effective) number of SNPs used by each model for prediction. Under default settings, the effective model sizes of thethe HLASSO and the d-GWASelect are 14, 4 and 21, respectively. Since the former two models are much smaller, we also evaluated their prediction accuracy with 21 effective SNPs. (We were not able to evaluate the ATT with 21 effective SNPs due to numerical instabilities.) The results are reported in. Clearly, the d-GWASelect performs the best or nearly the best for all three -error rates. We have also calculated the area under the ROC curve for the four methods, and GWASelect achieves the highest value (Supplementary).
GWAS variable selection
ANALYSIS OF WTCCC DATA
Q.He and D.-Y.Lin
GWAS variable selection
DISCUSSIONWe have developed a new tool, GWASelect, for variable selection at the genome-wide level. This regression-based method has the ability to capture both marginally correlated and marginally uncorrelated causal SNPs and has low FDR. The advantages over the existing methods have been demonstrated through simulated and real data. Our method has two versions. The first version requires the specification of the model size d, for which we suggest to choose a number that is consistent with the current biological knowledge of the studied disease. The second version (d-GWASelect) does not require the specification of the model size, and this is the version we recommend for general use. The correlation structures for causal variants used in our simulation studies have biological relevance. Scheme 2 mimics a scenario in which the causal variants form a gene cluster that contributes synergistically to the disease outcome, while scheme 3 reflects a scenario in which several biological pathways (or networks) affect the disease development. We did not include least angle regression (LARS) in our studies because it has been shown to have highly similar performance to LASSO (). Indeed, LASSO can be implemented by LARS with a small modification.demonstrated that CCD is 'considerably faster and more robust than LARS' and is 'more successful than LARS in model selection'. The HLASSO adopts a concave penalty function, but the CCD algorithm may not converge for non-convex penalty functions (). A valid algorithm to implement concave penalty functions is local linear approximation (), which amounts to multiple rounds of CCD and would make the HLASSO computation prohibitively expensive. For the WTCCC T1D data, running the CCD version of the HLASSO with 10 iterations on an Intel Quadcore Nehalem processor (2.4 GHz, 16 GB memory) requires 67.5 to 175 h, depending on the value of the tuning parameter. In contrast, we have been running the GWASelect in a parallel computing environment, and the same analysis can be completed within several hours on 16 processors. In an independent effort,developed an ISIS method for generalized linear models in the context of microarray data analysis. In their method, the conditional screening procedure requires fitting a separate regression model for each feature, which would create heavy computational burden for GWAS data. In addition, their method tends to have high FDR. They observed that cross-validation tends to yield large models for logistic regression, resonating our findings. We can extend our methods to select interactions. Instead of considering all possible interaction terms, we may incorporate known biological network information () into our selection procedure. Another approach is to first extend the existing genetic network identification tools, such as the liquid association () and bounded mode stochastic search (), to infer SNP interactions and then incorporate such information into our GWASelect procedure. Recently,proposed a Markov blanket-based method to evaluate epistatic interactions for GWAS data. It will be interesting to compare to that method when we extend our work to interaction effects.
Q.He and D.-Y.LinHow to obtain P-values for high-dimensional variable selection is an active research area. The stochastic error introduced by the selection process makes it very difficult to assign P-values to the selected features.offered one possible solution by 'aggregating' P-values from stability selection, but our experiments indicated that this procedure is too conservative for SNP data, likely due to the ultra-high dimension and strong LD. The prediction of genetic risk using GWAS data has drawn considerable attention in recent years.pioneered this area of research. Their approach selected genetic predictors by a univariate screening method. As shown in this article, our GWASelect method tends to provide more accurate prediction than univariate screening when the SNPs are in strong LD.explored genetic risk prediction through a Support Vector Machine algorithm. It is difficult to compare our results directly with theirs because (i) their analysis involved two other datasets besides the WTCCC T1D data; (ii) our testing samples are far smaller than theirs; and (iii) interaction effects are not considered in our current work.
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [11:26 2/12/2010 Bioinformatics-btq600.tex] Page: 4 18
