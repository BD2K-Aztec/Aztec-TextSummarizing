Motivation: Large amount of research efforts have been focused on estimating gene networks based on gene expression data to understand the functional basis of a living organism. Such networks are often obtained by considering pairwise correlations between genes, thus may not reflect the true connectivity between genes. By treating gene expressions as quantitative traits while considering genetic markers, genetical genomics analysis has shown its power in enhancing the understanding of gene regulations. Previous works have shown the improved performance on estimating the undirected network graphical structure by incorporating genetic markers as covariates. Knowing that gene expressions are often due to directed regulations, it is more meaningful to estimate the directed graphical network. Results: In this article, we introduce a covariate-adjusted Gaussian graphical model to estimate the Markov equivalence class of the directed acyclic graphs (DAGs) in a genetical genomics analysis framework. We develop a two-stage estimation procedure to first estimate the regression coefficient matrix by ' 1 penalization. The estimated coefficient matrix is then used to estimate the mean values in our multi-response Gaussian model to estimate the regulatory networks of gene expressions using PC-algorithm. The estimation consistency for high dimensional sparse DAGs is established. Simulations are conducted to demonstrate our theoretical results. The method is applied to a human Alzheimer's disease dataset in which differential DAGs are identified between cases and controls. R code for implementing the method can be downloaded at http://www.stt.msu.edu/ $cui. Availability and implementation: R code for implementing the method is freely available at
IntroductionThe past decades have witnessed enormous methodology developments in gene network inference using gene expression data (e.g.). Such networks were developed mostly by assessing the pairwise correlation of gene expressions. From a statistical point of view, under the assumption that the joint distribution of the gene expressions of interest is a multivariate normal distribution, such networks can be constructed by assessing the nonzero elements of the inverse covariance matrix, the so called precision matrix or concentration matrix. Assume X  X 1 ; :::; and Lin (2007). Under certain assumptions, the positions of zero entries in the precision matrix indicate conditional independence between variables of study. When inferring a network only based on gene expressions, two genes could show correlation in expression simply because they share a common regulator, while they should be independent conditioning on the common regulator. Motivated by this, a few methodological developments have been focused on covariate-adjusted graphical models by using genetic markers as covariates to correct both false positives and false negatives (e.g.). In their estimation procedures, the effect of genetic variants is estimated in the first step. Then, the graphical structure is estimated in the second step while adjusting for the genetic effects. Their simulation results and real data analysis showed that graph estimates were substantially improved when taking the genetic effects into account. These models are all focused on the estimation of undirected graphs without considering direction information. The directed graphs, however, are more attractive in the sense that often people are interested in the causal relationships, i.e. interests are not only focused on whether two variables are conditionally independent but also if one causes the other one. In real life, gene expressions are often the results of directed regulations. Thus, the estimation of directed graphs should provide more biological information for further functional investigation. Genetical genomics data provide optimal resources to learn such directed graphical networks. In typical directed acyclic graph (DAG) inference, one probability distribution has a set of corresponding DAGs which are Markov equivalent under certain assumptions. The directions of the edges in the graphs indicate causal relations. Studies on directed graphs have flourished in the literature both in theory and in application (e.g.). The most common case is the Gaussian case. Let Y  Y 1 ; :::; Y p  be a p-dimensional Gaussian random vector, and each coordinate represents a gene expression. To infer the regulatory relationship of these p gene expressions, the PC-algorithm developed bycan be applied to construct a completed partially DAG (CPDAG). The CPDAG can uniquely represent all DAGs corresponding to the common distribution of Y and can be represented as the regulatory networks of the gene expressions. Kalisch and B hlmann (2007) later proved that the graph obtained from the PCalgorithm is consistent under some conditions, even in high dimensional cases. Directed graphs constructed with the PC-algorithm are more biologically relevant compared with undirected graphs. However, as mentioned before, if two genes share a common regulator, their expression relationship could be complicated or even distorted without considering the underlying genetic structure. When adjusting for the genotype (i.e. the common regulator) effects, the two related genes could be independent or vice versa. This motivates us to develop a covariate-adjusted directed graphical model by extending the CPDAG estimation procedure to a regression framework. We treat genetic markers as covariates and develop a two-stage estimation method, which combines the penalized estimation and PC-algorithm to estimate the marker-adjusted CPDAG structure. In the following of the article, we first provide some background knowledge about graphical models and the formulation of our model and the two-stage estimation procedure in Section 2. Theoretical results are given in Section 3. Simulations and real data analysis are given in Sections 4 and 5 to justify our method followed by discussions in Section 6. All the proofs of the theoretical results are rendered in the Supplementary File due to space limit.
Model and estimation
BackgroundLet G  V; E be a graph where V represents the set of vertices and E represents the set of edges. A directed graph is a graph in which each edge has a direction represented by a " ! " sign. A DAG is a directed graph with no directed cycles. A criterion called d-separation is used to read conditional independence relationships from a DAG structure (). Other criteria can be used to generate conditional independence relationships. The reason why d-separation is particularly useful is that it is related to causal inference () and for the purpose of constructing directed graphs. Given a random vector, its coordinates can be viewed as the vertices of a graph G  V; E. A probability distribution is called faithful to a DAG if and only if the conditional independence relationships indicated by the distribution are the same as those obtained via d-separation. Multiple DAGs may represent the same set of conditional independence relationships. The DAGs to which a probability distribution is faithful are Markov equivalent and compose a Markov equivalence class. Two DAGs are Markov equivalent if and only if they have the same skeleton and the same v-structures (). The skeleton of a DAG is the graph where all directed edges are replaced with undirected edges. A v-structure is a triple (v 1 ,v 2 ,v 3 ) having the structure v 1 ! v 2 v 3. A Markov equivalence class of DAGs can be described by a unique CPDAG (). A CPDAG is the union of the DAGs in a Markov equivalence class in the sense that a directed edge exists if that edge exists in each DAG and an undirected edge exists if that edge has different directions in two DAGs. PC-algorithm () is an effective and efficient algorithm to estimate CPDAGs. The reason why we estimate the CPDAG is that multiple DAGs correspond to the same probability distribution, while only one CPDAG corresponds to a probability distribution. After a CPDAG is obtained, we can extend it to the DAGs by adding directions on the edges, such that no directed cycles are generated. It has been proven that PC-algorithm can generate a consistent estimate under certain assumptions, even in high dimensional cases (Kalisch and B hlmann, 2007).
Covariate-adjusted Gaussian graphical modelConsider a multi-response linear regression model with p responses and q covariates. Suppose we have n independent observations y i ; x i ; i  1; :::; n, where y i  y i1 ; :::; y ip  T and x i  x i1 ; :::; x iq  T. We assume that the data are centered and standardized. Define Y  y 1 ; :::; y n  T and X  x 1 ; :::; x n  T. The relationship between the multivariate response Y and the covariates X can be described by the following regression model,where B  B 1 ; :::; B p  is a q  p coefficient matrix and E   1 ; :::; n  T is the error term. We assume that the errors i   i1 ; :::; ip  T ; i  1; :::; n, are i.i.d. random variables following a multivariate normal distribution N0; R. Let y j  y 1j ;    ; y nj  T be the jth response vector (j  1; ::; p) and x l  x 1l ;    ; x nl  T be the lth covariate vector (l  1; ::; q). In a genetical genomics framework, X represents the single-nucleotide polymorphism (SNP) markers and Y represents the gene expressions. Our interest is to estimate the CPDAG structure of Y, while adjusting for the effect of X. Conditional on X, we expect that false positives and/or false negatives of connections will be reduced.
A two-stage estimation procedureWithout X, the PC-algorithm can be applied to infer the CPDAG structures. In the model described above, the conditional mean of Y changes as X varies. Thus, the PC-algorithm cannot be directly applied since it is only for a model with a constant mean, i.e. X  X 1 ; :::; X q  follows a multivariate normal distribution with mean l and covariance matrix R. To overcome the difficulty, we propose a two-stage estimation procedure to estimate the mean function and the CPDAG structure. In the first stage, we estimate the coefficient matrix B. We implement a penalized estimation procedure with respect to each response in Y via solving the following p optimization problems,where k j;n ; j  1; :::; p; are tuning parameters, and jj  jj 1 refers to the L 1 norm. The estimate of B is denoted as ^ B   ^ B 1 ; :::; ^ B p . Let ^ E  Y  X ^ B. In the second stage, the PC-algorithm is applied to ^ E to estimate the directed graphical structure corresponding to the probability model N0; R. The two-stage estimation algorithm is termed as the covariate-adjusted PC-algorithm (caPC). The caPC contains two steps. The first step is to estimate the skeleton, and the second step is to extend the skeleton to the CPDAG. Information obtained from the first step is used to determine the directions of the edges in the second step. If we have the perfect knowledge about the conditional independence relationships, the PC-algorithm can return us with the correct skeleton in the first step (). However, we do not have perfect knowledge in practice. Therefore, we use samples to estimate the skeleton by implementing a testing procedure. For testing the conditional independence, Kalisch and B hlmann (2007) applied estimated partial correlations and Fisher transformation to construct a testing statistic. They proved that the PC-algorithm could generate consistent estimates under certain assumptions even in the high dimensional situations. To make the article self-contained, we also included the PC algorithm in the Supplementary File.
Theoretical resultIn this work, we allow the number of responses to increase along with the sample size, i.e. p is a function of n. The number of marker covariates q is fixed. This is a valid treatment as we can do an eQTL mapping study to first find the eQTLs for the expression responses, then fix them in the model. Below we show that the two-stage estimation method generates consistent estimate of a CPDAG. To show the estimation consistency, we adopt the setup of Knight and Fu (2000) and Kalisch and B hlmann (2007). The dimension of a multivariate response variable is denoted as p(n) and a DAG is denoted as G  G n. Let q n;i;j be the correlation between i and j. Let q n;i;jjk be the partial correlation between i and j given f r ; r 2 kg, where k is a subset of f1; :::; pngnfi; jg. ^ q n;i;j and ^ q n;i;jjk are the corresponding estimated ones. To establish the estimation consistency, we need the following lemmas. The required conditions for the lemmas and theorem can be found in the Supplementary File.Assume that the distribution P n is normally distributed, we have ^ q n;i;j  ^ B  ^ q n;i;j B  o p 1; 8 i; j  1; :::; p:Assume that the distribution P n is normally distributed, we have ^ q n;i;jjk  ^ B  ^ q n;i;jjk B  o p 1; 8 i; j  1; :::; p:Assume that the distribution P n is normally distributed and sup n;i;j;k jq n;i;jjk j M < 1. Then, for any c > 0, we have sup i;j;k2K mn i;j P j^ q n;i;jjk ^ B  q n;i;jjk j > cfor some positive constant C 1 .Lemma 1 shows that the difference between the estimated correlation coefficient ^ q n;i;j given the estimated coefficient matrix ^ B and the estimated correlation coefficient given the true coefficient matrix B is o p 1. Lemma 2 states that the difference between the estimated partial correlation coefficient ^ q n;i;jjk given the estimated coefficient matrix ^ B and the estimated partial correlation coefficient given the true coefficient matrix B is o p 1. Lemma 3 shows that the difference between the estimated partial correlation coefficient ^ q n;i;jjk given the estimated coefficient matrix ^ B and the true partial correlation coefficient q n;i;jjk is bounded. The proofs of the three lemmas are relegated in the Supplementary File. Define a n as the significance level for testing the significance of the partial correlation after Fisher's transformation, i.e. for testing H 0 : q i;jjk  0. With the above assumptions, we have the following theorem. Theorem: Define ^ Ga n  as the estimated CPDAG using the twostage estimation procedure and G is the true CPDAG. If k j;n  on; j  1; :::; p and Conditions (C1)-(C6) are satisfied, then there exists a n such that P ^ Ga n   G  1  Oexpcn 12d  ! 1; as n ! 1 where c is a positive constant and d > 0 is as in Condition (C6).The convergent rate of the CPDAG estimation is the same as that in Theorem 2 in Kalisch and B hlmann (2007). This means that the errors occurred in the first stage do not have a great effect on the second stage of the estimation of graphical structures. The proof of the Theorem can be found in the Supplementary File.
Simulation
Simulation designWe did extensive simulations to assess the estimation performance. We followed the simulation setup in Yin and Li (2013) and Kalisch and B hlmann (2007). To generate the error term, we began with an adjacency matrix A pp filled with zeros. Then, every entry in the lower triangle was replaced with independent realizations of a Bernoulli random variable with success probability p A 0 < p A < 1, where p A is called the sparseness of the model. Entries with 1 were then replaced by realizations of a Uniform (0,1) random variable. The corresponding DAG was constructed by drawing a directed edge from node s to node t if A st 6  0 and s < t. The created DAG has the following property: EN j   p A p  1, where N j is the number of neighbors for a given node j. We denote Eas the average number of neighbors per node. The size of EN j  determines the sparseness of the graph with small values corresponding to a sparse graph and large values corresponding to a dense graph.
B.Gao and Y.CuiThe matrix A will be used to generate the data as follows.where g j 0 s are independent. We applied the R-package pcalg to generate DAGs according to the above description. Such processes were repeated to generate the error matrix E np. To generate the q  p coefficient matrix B, we generated a q  p sparse indicator matrix whose entry is 1 with a probability proportional to j=q, where j is called the sparseness of the coefficient matrix. If an entry is 1, it is replaced by a realization from Unif([), where u is a realization from Unif(). Next we generated X whose entries were realizations of Bernoulli (1, 0.5). Finally, we generated Y by Y  XB  E. The performance was evaluated based on true-positive rate (TPR), false-positive rate (FPR) and the structural Hamming distance (SHD) following the evaluation criteria proposed by Kalisch and B hlmann (2007). TPR and FPR were used for the evaluation of the estimate of the skeleton. TPR is defined as the ratio of the number of correctly estimated edges to the number of total edges. FPR is defined as the ratio of the number of incorrectly estimated edges to the number of total nonedges (the number of locations where there are no edges). SHD was used for the evaluation of the estimated CPDAG and is defined as the number of edges where the true CPDAG and the estimated CPDAG are different.
Performance in the low dimensional caseWe chose a n  0:01 in the low dimensional situation where p was fixed and n varied. We called it low dimensional case in which the sample size n is larger than p and q. For comparison purpose, we also included the log(n)  4 case. Three parameter settings and seven sample sizes were chosen, each with 40 replications.depicts the simulation results. In all the cases, TPR increases and SHD decreases as the sample size increases (denoted by log(n) in the plot). The tendency of FPR is not clear. However, the overall scale of FPR is small in all cases, implying reasonable control of FPR. A similar pattern was also observed in Kalisch and B hlmann (2007). The authors explained that this is because a constant a n was used under all sample sizes. In addition, the performance of a sparse graph estimation (denoted as circles with EN  2) appears to be better than that of a dense graph estimation (denoted as triangles with EN  5). The 95% confidence interval based on the 40 replicates for each case is also shown. It is clear that the confidence interval becomes narrower as the sample size increases in all the cases. This is consistent with our large sample theoretical result.
Performance in the high dimensional caseIn this section, we reported the performance of the estimation in high dimensional situations where p varied as n increased, to check the consistency results as stated in Theorem 1. In all the cases, p was assumed to be larger than n. We closely followed the setup in Kalisch and B hlmann (2007) and chose a n  0:05 in the high dimensional case. Specifically, data were simulated following, and the number of covariates was assumed to be q  100 and 500. The average number of neighbors was calculated as EN  n 0:5 =6. The sparseness of the coefficient matrix was controlled by j. We ran 30 simulations in each setting.show the results for q  100 and q  500, respectively. As shown in both figures, it is clear that TPR is increasing and FPR is decreasing along with the increasing of the sample size. These observations are consistent with our theoretical results. In addition, the size of q also has an effect on the estimation performance in which larger q (500) gives smaller TPR and larger FPR compared with the results under smaller q (100). We did another simulation in which both p and q increase with n. The sample size n was assumed to be 50, 100, 150, 200, 250 and 300. The dimension of Y and X was assumed to be p  n 1:5 =6:3 and q  p=2, respectively. The average number of neighbors is given as EN  n 0:5 =6. The detailed setup can be found in. Thirty simulations were run in each setting. The results of the simulation are shown in. We observed a similar pattern as shown in, i.e. TPR is increasing and FPR is decreasing as n increases. This result provides supportive evidence that our method also works in the situation where both p and q increase with n.
Comparing graphs with or without covariatesThe proposed method improves the DAG estimation by adjusting for potential marker effects. To evaluate the gain by adjusting for the marker effects, we compared the estimation performance of before and after adjusting for the marker effects using the PCalgorithm (denoted as PC in the table) and caPC based on simulated data. We considered six scenarios as listed in. We observed consistently larger TPR, smaller FPR and SHD by using the caPC estimation method compared with the results using the PC-algorithm in all the simulation scenarios. This simulation further justifies the benefit of adjusting for the covariates' effect when estimating the DAG structure. We also did simulations considering the case where q > p following the suggestion of one reviewer. The results are summarized in. We observed similar pattern in which caPC outperformed PC.
Comparing directed and undirected graphsWe did additional simulations to compare the performance of the directed and undirected graph estimation adjusting for the covariates' effects. Here, we choose p  50, 100, 200, q  2p and n  250. As before, we chose EN  2, j  3.5. The results are summarized in. We applied graphical LASSO to estimate the undirected graphical structure (). We can see that undirected method achieves a higher TPR, but the directed method achieves a lower FPR and smaller SHD. Here, SHD is used to measure the skeleton of the graph since undirected graphs do not have direction information. The reason that undirected method is better on TPR is because, in theory, directed graphs give sparser solutions than the undirected method due to the extra constraint on direction inference. So overall, the directed graph performs better than the undirected method on both FPR and SHD but suffers a little bit on TPR.
Application to real dataWe applied our proposed two-stage estimation method to an Alzheimer disease dataset (). Following the article, 176 Alzheimer cases and 187 controls were included in our analysis. For the SNPs, those with low genotyping call rate (<90%), low minor allele frequency (<5%) and those that failed the Hardy Weinberg equilibrium test in control group (P value < 0.001) were removed. After these operations, around 332 000 SNP markers were left for further analysis. We used the residual expression data after adjusting for the effects of several covariates such as gender, APOE status and age at death (data can be found at http:SNPs in the control group (as the X variables). We applied our estimating method to the two groups separately. Our goal was to learn the DAG structure for the 100 genes while adjusting for the effects of SNP markers in the case and control groups with the hope to identify differential DAG structures that can distinguish the two groups. Any differences might potentially explain the disease etiology of Alzheimer. We learned the CPDAGs at the a n  0:001 level. For the case group, the estimated CPDAG has 101 directed edges (). For the control group, the estimated CPDAG has 88 directed edgesB.Gao and Y.Cui(). The graphs were generated with the R package igraph. In both graphs, genes were represented with numbers. The corresponding gene names can be found in the Supplementary Table. The two CPDAGs share 18 edges in common. We noticed that some subCPDAG structures shown in the case group were not present in the control group. For example, the graph 70 ! 95 38 was observed in the case group, while the three genes are separated from other groups in the control population. On the other hand, some CPDAGs shown in the control group were not present in the case group. For example, the sub-graph by 17-26-31-32-76 is observed in the control group, while the genes are less connected in the case group. Such differential graphical structures between the two groups might indicate regulation heterogeneity between the two groups. Further biological verifications are needed to validate the findings. As a comparison, we applied PC-algorithm directly to the 100 genes without adjusting for the SNPs' effects. For the case group, the estimated graph has 124 edges. For the control group, the estimated graph has 100 edges. This is consistent with our assumption that the number of edges should be reduced after adjusting for the markers' effect. This phenomenon has been explained and demonstrated in other works focusing on undirected graphs (e.g.). We did another case study by focusing on the Alzheimer's disease pathway from the KEGG database. There are total 168 genes in this pathway, but only 120 gene expressions in this dataset were mapped to the pathway. For each of the 120 gene expressions, we performed a single marker linear regression analysis using each of the SNPs. We selected those markers with P value < 0.001. Then the 5000 SNPs (with 93 in common) with the smallest P values were selected in case group and control group, respectively. The data we used for the final analysis contain 120 gene expressions (the Y variables), 5000 SNP markers in the case group and 5000 SNP markers in the control group (the X variables). Our goal is to learn the DAG structures based on the 120 gene expressions while adjusting for the effects of 5000 SNP markers in both groups. We applied our estimating method to the case and control group separately. In the case group, the estimated CPDAG has 108 directed edges (). In the control group, the estimated CPDAG has 109 directed edges (). There are 25 common edges between the two graphs. We can see different graphical structures between the two groups. Some of the estimated sub-DAGs agree with the real biological network. For example, some genes in mitochondria were identified as connected in the case graph (e.g. COX7A2, NDUFB2, SDHC; NDUFV3, COX7B, COX4I1, COX1, NDUFB4, NDUFA10).
DiscussionGenes function in networks and gene expressions often result from gene regulations. Hence, learning directed regulations can enhance. Simulation setup in the high dimensional case with varying p, q and jour knowledge about gene function and disease etiology. In this work, we introduced a covariate-adjusted model to study the graphical structures of multiple gene expressions with direction regulation information. We proposed a two-stage procedure to obtain the estimated CPDAG corresponding to the probability distribution. The marker adjusted expression network can reduce the false connections of two genes if they share a common regulator. Simulated data were used to test our method and showed supportive results both in low and high dimensional cases. We provided a consistency result for the case when p is increasing along with sample size n. We applied our method to a real case-control dataset to understand the gene regulation mechanism in Alzheimer disease. Different graphs were learned corresponding to the case and control group. For the Alzheimer pathway analysis, we were able to recover some of the structures for genes involved in Mitochondria function. In the real data analysis, we could not recover the exact causal relationships between variables that are shown in the KEGG database. This is due to the complexity of the biological structure and limited data samples. Moreover, the data may violate the normality assumption. Other robust methods such as the nonparanormal model () which implement a nonparametric transformation of the data may be applied to our framework. In addition, we expect more reliable structures can be obtained if we incorporate prior known information into our analysis by pre-setting some edges. We expect that more accurate and stable estimation can be achieved via incorporating both statistical and biological knowledge into the model development process. These will be incorporated into our future investigation. R code for implementing the method can be downloaded at http://www.stt. msu.edu/ $cui.
X p  $ N0; R and X  R 1. X i ? ?X j jfX t g t6 i;j , x i;j  0, where x i;j is the (i, j)th entry in X. That is, X i and X j are conditionally independent if and only if x i;j  0. Thus, one can infer the positions of zero entries in X to infer the graphical structure, i.e. the conditional independencies between components in X. However, when the data dimension is larger than the sample size, the inverse of the sample covariance matrix is not available. When considering such networks as undirected graphs, there has been huge statistical interests in developing Gaussian graphical models assuming sparsity of the precision matrix, to name a few, Friedman et al. (2008), Cai et al. (2013), Meinshausen and B hlmann (2006) and Yuan V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 3953 Bioinformatics, 31(24), 2015, 39533960 doi: 10.1093/bioinformatics/btv513 Advance Access Publication Date: 2 September 2015 Original Paper at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
