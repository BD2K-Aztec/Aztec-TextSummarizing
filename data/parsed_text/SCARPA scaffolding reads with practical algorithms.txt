Motivation: Scaffolding is the process of ordering and orienting con-tigs produced during genome assembly. Accurate scaffolding is essential for finishing draft assemblies, as it facilitates the costly and laborious procedures needed to fill in the gaps between contigs. Conventional formulations of the scaffolding problem are intractable, and most scaffolding programs rely on heuristic or approximate solutions , with potentially exponential running time. Results: We present SCARPA, a novel scaffolder, which combines fixed-parameter tractable and bounded algorithms with Linear Programming to produce near-optimal scaffolds. We test SCARPA on real datasets in addition to a simulated diploid genome and compare its performance with several state-of-the-art scaffolders. We show that SCARPA produces longer or similar length scaffolds that are highly accurate compared with other scaffolders. SCARPA is also capable of detecting misassembled contigs and reports them during scaffolding. Availability: SCARPA is open source and available from http://comp
INTRODUCTIONWhile assemblers developed for high-throughput sequencing (HTS) platforms can produce high-quality draft assemblies for the genomes of bacteria and viruses, de novo assemblies of more complex genomes using short reads are typically fragmented. This fragmentation can be partially alleviated through scaffolding: the process of linking contigs into longer sequences (possibly with gaps) using paired read information. Scaffolding not only improves the contiguity of the initial assembly, but is also helpful for designing experiments for finishing of the genome through additional sequencing of selected regions with lower-throughput technology, such as Sanger. Although many genome assemblers produce scaffolds using paired reads during the assembly process (), the problems of building contigs and scaffolding them are distinct. A scaffolder takes as input a set of assembled contigs and a set of paired reads. The relative orientation of two paired reads and the approximate distance between them are known. Thus, if the two reads can be unambiguously mapped to different contigs, we can identify the relative ordering and the distance between these contigs. Owing to errors in the read pair data (e.g. chimeric pairs) and in the assembly (e.g. misassembled contigs), the ordering achieved from different read pairs can be contradictory. Consequently, the scaffolding problem is often defined as finding an ordering on the contigs that maximizes the number of supporting read pairs. Computationally, this formulation is NP-hard (), leading most scaffolding approaches to use heuristic algorithms with no provable guarantees. Some scaffolders greedily link contigs by considering them in order of strongest paired read support () or largest contig length (), while rejecting links that contradict those already chosen. Alternatively, the scaffolding problem is often represented as a graph, where nodes denote contigs and edges denote paired read links. SOPRA () partitions this graph into smaller parts and solves the scaffolding problem in each subgraph using statistical optimization. MIP Scaffolder () partitions the graph in a similar way; however, it solves the problem for each subgraph exactly using Mixed Integer Programming. To keep the algorithms tractable, both of these scaffolders limit the sizes of the subgraphs. Opera () applies an alternate partitioning scheme using a graph contraction procedure and solves the scaffolding problem with a fixed-parameter tractable algorithm based on a graph-bandwidth formulation. These approaches to scaffolding attempt to maximize the number of paired reads that are satisfied, implicitly assuming that paired read links are noisy and the contigs are error-free. However, in larger and more complex genomes, the assembled contigs may well have misassemblies. In this article, we present a novel method that combines several practical algorithms for the scaffolding problem. Our approach assumes that both erroneous read pairs and contigs are possible, allowing us to detect misassembled contigs and remove these from the scaffolds. This formulation of the problem allows for an algorithm with practical time and memory requirements, while providing an exact solution of bounded error. This algorithm is implemented within SCARPA, a stand-alone scaffolder for HTS data. We have tested SCARPA on real datasets as well as on a simulated diploid genome, and show that it builds highly accurate and longer scaffolds compared with several state-ofthe-art scaffolders.
METHODSWe implement our methods in a stand-alone scaffolder named SCARPA. As input, SCARPA takes a FASTA file containing a set of contigs and a *To whom correspondence should be addressed. SAM file containing the mapping positions of one or more paired read libraries. These files can be generated by any software of choice. As a preprocessing step, SCARPA filters ambiguously mapping reads and estimates the mean and standard deviation of the insert size for each library. SCARPA then assigns an orientation to each contig discarding a minimal set of contradictory contigs and paired read links. In the next step, contigs are given a pairwise-consistent order, and finally the exact order of the contigs is determined using a Linear Programming (LP) framework. We explain these steps in detail below.
PreprocessingThe first step of SCARPA is to filter and analyze the read mappings. Like other scaffolders, SCARPA discards a read pair if either of the reads maps ambiguously (i.e. has more than one optimal hit). Next, SCARPA analyzes the read mappings to estimate the mean and standard deviation of the insert size for each library. While for most sequencing projects initial estimates of these are available, inaccurate values will cause gap sizes between the contigs to be incorrectly estimated. SCARPA re-estimates the insert size distribution using paired reads that map to the same contig. To make sure this estimation is reliable, we only use contigs that are longer than the contig N50 (see Section 3.2 for a definition of N50). If the calculated mean is more than half of the contig N50, we use the provided library statistics instead. After the library statistics are finalized, we build a scaffolding graph where nodes are contigs and edges are paired read links between the contigs. If there are multiple links between a pair of contigs, we bundle them provided that they suggest the same relative orientation. Each edge is weighted by the number of paired reads supporting the link, and edges with support lower than a threshold are discarded. By default this threshold is 2; however, it can be set during program execution. In addition, each edge has an associated estimate for the distance between the contigs it connects. This distance, denoted with ij , is computed using the formula below:where m l is the estimated distance between the contigs i and j based on the paired read link l, and n is the number of paired read links between these two contigs. Here m l is calculated by subtracting the distance between the mapped positions and the end of the contigs from the mean insert size. Note that it is possible for this value to be negative because the end of the contigs may overlap.
Contig orientation as odd cycle transversalEach assembled contig is arbitrarily oriented; it could be mapped to either strand of the genome. The orientation stage of scaffolding attempts to orient the contigs based on the read pairs so that within each scaffold all of the contigs lie on the same strand. This is illustrated in. With error-free data this problem has a feasible solution, easily identified via a greedy algorithm. In the presence of errors, such as chimeric read pairs, mismapped reads and incorrectly assembled contigs, the problem may be infeasible unless we remove some constraints. The orientation problem is usually formulated as follows: assign an orientation for each contig so that the maximum number of paired reads is satisfied. This formulation, adapted by most scaffolders (), is motivated by the assumption that the majority of incorrect links are due to chimeric pairs or mismapped reads. However, contradictory links may also be due to misassembled contigs (see). In such cases, it might be desirable to remove contigs instead of links. Furthermore, links that are due to chimeric pairs tend to have low supportsuch errors are expected to occur independentlyand can often be identified during preprocessing. Instead, we adopt an approach that allows removal of contigs as well as paired read links. We will first illustrate how to optimize the number of contigs that are removed, and then generalize the approach to paired read links. First, we build an undirected graph G, where each contig c is represented by two nodes c  and c  corresponding to the 5 0-and 3 0-ends of the contig, respectively. For each contig c, we add an edge between c  and c . For each read pair r 1 and r 2 mapping to contigs x and y, respectively, we add an edge between (in practice, we bundle the paired reads that suggest the same orientation and represent them as a single edge):Note that the contig orientation problem has a feasible solution if and only if G has no cycles containing an odd number of nodes. We thus attempt to find the smallest set of nodes that can be removed from theHere, we assume the correct orientation of a read pair is forward-reverse (i.e. paired-end orientation). If the orientation of the library is otherwise, reads are reverse complemented to match this orientation before scaffolding. Above, we reverse complement the middle contig to satisfy the orientation of the paired reads. An example of a misassembled contig. Top: A genome divided into several regions depicted with letters AG. The repeat region A has three copies in the genome, one of which is inverted. Bottom: Five assembled contigs and a set of paired reads mapped to these contigs. The third contig is misassembled because of overcollapsing of the repeat region A. Here, we have to discard two paired read links so that the contig orientation problem has a feasible solution. Moreover, removing the wrong links will cause further errors in scaffolds graph to allow for a feasible solution. In graph theory, this is known as finding a minimum odd cycle transversal, and while this problem is NP-hard in general, it can be solved efficiently if the number of nodes to be removed is small.developed a fixed-parameter tractable algorithm, which identifies a set X of nodes with jXj k, for any fixed k, such that G  X has no odd cycles or asserts that no such set exists. This algorithm runs in time O3 k kmn (). The value of k, i.e. the maximum number of nodes to remove, is first set to 0 and then iteratively increased until a feasible solution is found.
Removing paired read links in addition to contigsThe algorithm we describe above is based on removal of nodes (contigs). To allow removal of edges (paired read links) in addition to nodes, we build another graph G 0 , which is derived from G by inserting auxiliary nodes. Briefly, we insert two nodes for each edge that connects two contig nodes (but not for an edge that connects the two ends of the same contig).illustrates this process. It is easy to see that this transformation does not alter the parity of existing cycles or create new cycles. If there is a tie between discarding a contig node versus discarding an auxiliary node representing a paired read link, we would like the algorithm to remove the auxiliary node. To encourage the algorithm to remove paired read links before removing contigs, we order the nodes of G 0 such that the auxiliary nodes are considered before any contig node. Note that the algorithm will never choose to discard both auxiliary nodes representing the same paired read link, as this would contradict the optimality of the algorithm.
Assigning the orientation of the contigsOnce the graph G is free of odd cycles, we transform it into a directed graph T, while simultaneously assigning each contig an orientation. To perform this task, we start with an arbitrary contig x. Without loss of generality, we assign the orientation of this contig as 'forward'. This assignment is reflected in the graph T by setting the direction of the edge x  , x   as x  ! x . This also means that all other edges incident to x  must be outgoing edges. Similarly, all other edges incident to x  must be incoming edges. This information is propagated to the rest of the graph via a breadth-first search. For example, if there is an edge x  , y  , the direction of this edge is set to y  ! x . In turn, the direction of the edge y  , y   is set to y  ! y  and therefore the orientation of contig y is assigned as 'reverse'. This process is illustrated in.
A note on the relation of bidirected graphs and the odd cycle transversal problemThe scaffolding problem is sometimes represented as a bidirected graph (). It is easy to see that the initial undirected graph G we construct above is equivalent to a bidirected graph. For interested readers, we hereby note that this section also provides a general algorithm to convert an arbitrary bidirected graph into a directed graph by removing a minimal set of nodes and edges.
OrderingAlthough the orientation step removes all odd cycles from G, the directed graph T may still have cycles (see). To place the contigs into a linear order, we need to eliminate all directed cycles from T. The problem of finding a minimal set of edges whose removal makes a directed graph acyclic is known as the feedback arc set problem. For arbitrary graphs, this problem is NP-hard (). We use a heuristic algorithm, which runs in Om time, where m is the number of edges and guarantees an asymptotically optimal error bound for sparse graphs ().
SpacingDuring the ordering stage, T is transformed into a directed acyclic graph and is now guaranteed to have an ordering of the contigs so that the remaining links are satisfied. In other words, each connected component of T admits a topological ordering. Yet, this ordering may not be unique. In the last stage of scaffolding, we try to find a placement of contigs within each scaffold such that the distances between the contigs agree best with the size of the gaps as suggested by the paired read links. This task can be formulated as an LP problem as follows. For each contig 1 i N, where N is the number of contigs, we have a real valued free variable x i that represents the 5 0-end of the contig. Without loss of generality, we set x 1 to 0. For each paired read link, we introduce the following constraints:where d ij is the distance between the 5 0-ends of the contigs i and j suggested by the paired read link. ij is a real valued slack variable in the range 0, 1. C is a large constant set to the sum of all the contig lengths. Subject to the set of constraints as constructed above, we maximize P ij. Note that the LP formulation is designed to place the contigs so that the paired read links are satisfied best; however, it may allow two contigs to occupy the same coordinates. In practice, we do not use the coordinates returned by the LP solver; rather, we use these coordinates to order the contigs in linear paths as follows. If a contig i is followed by a contig j according to the coordinates returned by the solver and i and j are already connected by an edge in T, we keep this edge. If the two nodes are not connected by an edge, we compute the shortest path between i and j in T. If the length of this path is less than a small threshold, we create an edge between i and j. The length of the gap between these contigs is computed using the coordinates returned by the solver. If the shortest path between i and j is longer than the threshold, we infer that these contigs are not supposed to be adjacent. In this case, the contigs following j are considered in order until one of them passes these criteria. If such a contig is found, then it follows i in the path and a new path is created for j. The resulting linear paths are output as scaffolds. If the estimated length of the gap between two adjacent contigs is negative, we align the ends ofthese contigs to see whether an overlap is present. If a high identity overlap is present, we merge these contigs. Otherwise, a fixed gap length of 10 bp is assigned.
ComponentsTrivially, all the steps we describe above can be solved separately for each connected component of the relevant graph. To keep the running time of SCARPA within practical limits (for orientation) and to improve accuracy (for ordering and spacing), we further divide the graph into biconnected components. The biconnected components of an arbitrary graph can be computed in linear time using the classical algorithm by. This algorithm works by finding a set of nodes, called the articulation points, whose removal from the graph increases the number of connected components. For the orientation and ordering steps, we have to ensure that each biconnected component can be solved independently without violating the correctness of the algorithms. To accomplish this, we only use those articulation points with in and out degrees equal to 1. Such nodes can never form cycles, hence their removal does not violate the correctness of the odd cycle transversal and the feedback arc set algorithms. Note that highly connected graphs may not admit any articulation points. These graphs often contain several repeat contigs that act as hubs. To avoid this scenario, we limit the maximum number of links a contig can make. If a contig exceeds the threshold, it is disconnected from the graph. This threshold is adjusted automatically depending on the component sizes.
Multiple librariesIn the presence of two or more libraries, SCARPA starts with the library of the smallest insert size. Remaining libraries are processed in order of increasing insert size, where scaffolds from the previous stages are treated as contigs.For the E.coli dataset, we additionally report the number of multi-contig scaffolds that contain breakpoints in the mappings. Note that we can not compute these numbers reliably in the G.clavigera and Assemblathon1 datasets. In the former case, a finished reference sequence is not available: the draft assembly we use for evaluation consists of 289 scaffolds. In the latter, the presence of two haplotypes implies that there may be haplotype switches within the contigs as well as the scaffolds, making it difficult to estimate the real number of breakpoints. To estimate the accuracy of the scaffolds in the other datasets, we use a method similar to the one used by. Briefly, this method works by extracting pairs of sequences separated by a certain distance from the scaffolds. These pairs are then mapped to the reference, and the proportion of pairs that map with the correct orientation and within 10% of the correct distance is reported. In our experiments, we use a tiling of 1000 bp long sequences separated by a distance of 3000 bp.shows the accuracy versus the N50 measure for each dataset. We also report the number of inversion type errors in. An inversion error is said to occur when one of the tiling pairs map to the forward strand of the reference, while the other maps to the reverse strand. SCARPA produces highly accurate scaffolds that are at least as long or longer than the other tools. We also find that for the E.coli dataset, out of the three contigs with lengths 282, 426 and 428 bp removed by SCARPA during scaffolding, two of them (with lengths 282 and 428 bp) do not map to the reference sequence. For the other datasets, SCARPA only removed paired read links. The running times of the scaffolders on a server with 20 cores operating at 2.67 GHz and 80 GB memory are given in. On these datasets, SSPACE is the fastest, followed by SCARPA and MIP Scaffolder, while SOPRA is the slowest. Note that SSPACE actually takes less time than Bowtie, probably owing to the fact that it runs Bowtie internally avoiding the extra time needed to process the read mappings.
CONCLUSIONScaffolding improves the contiguity of an assembly and facilitates the finishing of a genome by establishing an order and orientation of contigs. In this article, we have presented SCARPA, a novel scaffolder for HTS data that combines graph algorithms with LP. Using simulated and real datasets, we show that SCARPA produces as long or longer scaffolds than the current state-of-the-art tools, while at the same time achieving high accuracy.Note: For G.clavigera, the size of the available draft sequence is given in place of the genome size. For the Assemblathon1 dataset, the genome size is given as an average of the haploid reference sequences. A novel feature of SCARPA is the ability to detect misassembled contigs. Although this procedure may produce false positives, SCARPA reports only a few such contigs per dataset, which can be manually investigated if necessary. For instance, SCARPA discards no contigs in the G.clavigera and Assemblathon1 datasets and only three contigs in the E.coli dataset, two of which are indeed found to be erroneous.We also show that SCARPA has favorable running time on these datasets, although it is slightly slower than SSPACE. In addition, SCARPA has a small memory footprint, requiring 52 GB on the Assemblathon1 dataset. Within SCARPA, the most time-consuming step is the contig orientation task. While we believe our method typically produces more accurate scaffolds compared with greedy-or heuristicbased approach and has the advantage of detecting misassemblies, it can be computationally expensive for large and complex genomes. On the other hand, the fixed-parameter tractable algorithm we use is suitable for parallel computation. Although our current implementation is single-threaded, we plan to explore this direction in a future version.Note: Mapping is performed using Bowtie with 16 threads, and mapping time is included for all scaffolders. For information, the total wall-clock time taken by Bowtie to index the reference and write read mappings in SAM format is also reported.
The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
SCARPA Genome Scaffolder at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
N.Donmez and M.Brudno at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
RESULTS 3.1 Datasets In our first set of experiments, we compare SCARPA with other state-of-the-art scaffolders on two real Illumina datasets sampled from the bacterium Escherichia coli (strain K-12 substrain MG1655) and the fungus Grosmannia clavigera. For E.coli, we evaluate the scaffolders using the high-quality finished sequence available from NCBI (accession code: NC_000913.2). A finished reference sequence for G.clavigera is not available, so we evaluate the scaffolders on the draft sequence assembled using Sanger, Roche/454 and Illumina data as described by DiGuistini et al. (2009). For both genomes, we use two Illumina paired-end libraries downloaded from the NCBI Short Read Archive. To estimate the performance of SCARPA on a larger dataset, we also test the scaffolders using a simulated paired-end library taken from the first Assemblathon experiment (Dent et al., 2011). This library consists of 100 bp long reads with 300 bp insert size sampled from an artificially evolved diploid genome. Reads are simulated with sequencing errors and correspond to 40 coverage. The characteristics of the diploid reference and the simulation process are described in detail by Dent et al. (2011). The statistics of all datasets are given in Table 1. For the E.coli and G.clavigera datasets, we assemble the reads into contigs using Velvet (Zerbino et al., 2009) and report the contigs with the kmer size that achieves the highest N50 value (29 and 27, respectively). For these datasets, we set the expected coverage and coverage cutoff to automatic, and only report contigs that are 100 bp or longer. For the Assemblathon1 dataset, we assemble the reads using Hapsembler (Donmez and Brudno, 2011), which has support for diploid datasets. Because the reads are longer, we set the minimum contig size to 200 bp. For this dataset, we also discard read pairs that map to the E.coli genome before assembly and scaffolding to remove contamination. The total number of pairs removed by this process is 864 758 corresponding to $1.5 reduction in coverage. 3.2 Evaluation We compare SCARPA with three other scaffolders: SSPACE (Boetzer et al., 2011), MIP Scaffolder (Salmela et al., 2011) and SOPRA (Dayarian et al., 2010). We also report the scaffolds produced by Velvet on the E.coli and G.clavigera datasets. The standard deviation for each library is set to 10% of the mean insert size. For MIP Scaffolder, the minimum and maximum insert size values are set to 3 SD below and above the mean, respectively. The other parameters are left at default values. We let SCARPA adjust all parameters automatically for each dataset. For all scaffolders, the reads are mapped with Bowtie using the same options (Langmead et al., 2009). For all evaluations reported in this section, the mapping of scaffolds is performed using the nucmer and delta-filter utilities of the MUMmer package (Version 3.22) (Kurtz et al., 2004). The scaffold length statistics are summarized in Tables 24. N50 is calculated as the largest scaffold length such that the sum of scaffolds at least as long is greater than half the total scaffold size. The coverage is measured by mapping the scaffolds to the reference sequence and includes gaps. Statistics regarding the number of contigs merged in scaffolds are included in the Supplementary Material. Fig. 4. Assigning orientations. (a) An undirected scaffolding graph G after odd cycles are removed. (b) The edges are given directions in a greedy manner starting from an arbitrary contig (in this example, from contig 1). (c) Once the directions of the edges are assigned, we merge the nodes corresponding to the ends of the same contig into a single node. The contigs labeled with rc(.) are reverse complemented
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
