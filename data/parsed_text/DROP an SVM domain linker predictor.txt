Motivation: Biologically important proteins are often large, multidomain proteins, which are difficult to characterize by high-throughput experimental methods. Efficient domain/boundary predictions are thus increasingly required in diverse area of proteomics research for computationally dissecting proteins into readily analyzable domains. Results: We constructed a support vector machine (SVM)-based domain linker predictor, DROP (Domain linker pRediction using OPtimal features), which was trained with 25 optimal features. The optimal combination of features was identified from a set of 3000 features using a random forest algorithm complemented with a stepwise feature selection. DROP demonstrated a prediction sensitivity and precision of 41.3 and 49.4%, respectively. These values were over 19.9% higher than those of control SVM predictors trained with non-optimized features, strongly suggesting the efficiency of our feature selection method. In addition, the mean NDO-Score of DROP for predicting novel domains in seven CASP8 FM multidomain proteins was 0.760, which was higher than any of the 12 published CASP8 DP servers. Overall, these results indicate that the SVM prediction of domain linkers can be improved by identifying optimal features that best distinguish linker from non-linker regions. Availability: DROP is available at
INTRODUCTIONBiologically significant proteins are often large and consist of many domains, which make them difficult to characterize by highthroughput experimental methods (). Efficient methods for dissecting proteins into structural domains that can be readily analyzed are gaining practical importance in proteomics research (). Experimental approaches for identifying structural domains are mostly based on limited proteolysis, but these methods require * To whom correspondence should be addressed. significant quantities of proteins, and large amount of time and effort. Computational domain prediction methods are thus being actively investigated (). Methods that can predict domain regions without using sequence similarity to an existing domain cataloged in reference databases such as Pfam () and PROSITE () are particularly useful, as they may lead to the discovery of 'novel' domains, which are preferred targets of proteomics projects. Many domain prediction methods first detect domain boundaries or linkers, and in turn assign the location of the domain regions. This strategy takes advantage of the local nature of the boundary/linker sequence characteristics (). Initially, simple domain linker predictors that use variations in amino acid composition between domains and domain linkers were proposed [e.g. UMA (), DomCut (), Armadillo () and DLiP (. More recently, domain linker prediction performances were improved by the use of machinelearning methods (). Additionally, position specific scoring matrix (PSSM) could further improve the performances of domain linker predictions [e.g. Nagarajan's method (), CHOPnet () and PPRODO (. Though the ability of machine-learning methods for predicting domain linkers appears well established, their performances might be further improved by selecting optimal features for distinguishing linkers from non-linkers. The previously derived domain linker properties () combined with PSSM elements as well as 544 recently cataloged amino acid properties () would represent a vast feature space from which the best or the nearly best subsets could be searched. However, no systematic search from such a large number of features has yet been reported, and when systematic searches were carried out, they were applied to feature sets of modest sizes (). This is probably because a huge number of feature combinations need to be tested by trial-and-error, which requires a significant amount of computational time. Random forest, which is based on random sampling, could potentially provide a method for rapidly screening the optimal features (). It was originally developed as an ensemble classifier based on a collection of decision trees, and with each decision tree, randomly chosenPage: 488 487494
T.Ebina et al.features are scored according to their importance for classifying vectors into, e.g. linkers and non-linkers. Here, we report a domain linker predictor based on a support vector machine (SVM) trained with optimal features, DROP (Domain linker pRediction using OPtimal features). We selected optimal features from a set of 3000, which included PSSMs and over 2000 physicochemical properties, using a random forest algorithm complemented by a stepwise selection protocol. The selected features were mostly related to secondary structures, PSSM elements of hydrophilic residues and prolines. DROP performances were superior to previously developed domain linker predictors trained without systematic optimization of the features. In addition, the efficiency of DROP for predicting novel domains was confirmed by predicting linkers in CASP8 FM multidomain protein targets.
METHODS
Domain linker datasetWe constructed a domain linker dataset according to our previously reported protocol (). According to our definition, a domain linker is a loop region separating two structural domains, and a structural domain is defined as a protein fragment that can fold in isolation. Domain boundary sequences containing -helices or -strands were not included in our study, because their amino acid compositions differ from domain linkers formed by coils only (). Discontinuous domains were also discarded from our dataset as our definition of a structural domain was originally motivated by the practical need of detecting autonomously folded novel protein domains, whose crystal or solution structure could be readily analyzed by biophysical methods (). Our domain linker dataset, DS-All, contained 169 protein sequences, with a maximum sequence identity of 28.6%, and 201 linkers.
Vector encodingResidues were encoded into a 3000-dimensional real-valued vector, where each element represented a different property (properties are described in Supplementary Methods). Vector elements were assigned to the following features: 544 amino acid indices describing physicochemical properties (), 20 PSSM elements (see PSSM construction details in Supplementary Methods), three probabilities of secondary structure (PSS) by PSI-PRED (), two -helix/-sheet core propensities (), one sequential hydrophobic cluster index (), sequence complexity as defined by Shannon's entropy (one element;), one expected contact order (), amino acid compositions (20 elements), three domain/coil/linker propensity indices (), two linker likelihood scores () and three newly defined scores quantifying the amino acid composition similarity between domain and linker regions (see Supplemental Methods). Vector elements were averaged with windows of 5, 10, 15 or 20 residues around the considered residue for including local and semi-local information into the vectors. For each residue, a 3000-dimensional real-valued vector [(544+20+3+2+ 1+1+1+20+3+2+3) features  (4 averaging window size + un-averaged element) = 3000] was generated. The total number of the vectors encoding linkers and domains were, respectively, 2230 and 52 335.
Random forest feature selectionWe first assessed the vector elements using the mean decrease Gini index (MDGI) calculated by random forest [R-Random Forest package (); http://cran.r-project.org/]. The MDGI represents the importance of individual vector elements for correctly classifying a residuewhere x i is the mean MDGI of the i-th feature; and  is the SD of all mean MDGI. Vector elements with MDGI Z-Score larger than 3.0 were selected as optimal feature candidate-1 (OFC-1) and those with MDGI Z-Score between 2.0 and 3.0 were selected as OFC-2.
Stepwise feature selectionWe performed a stepwise selection by constructing and assessing several SVM linker predictors trained with different sets of optimal feature candidates. The stepwise selection was performed by training an original SVM with an original data set, which was OFC-1 for the first round of the stepwise selection (). The performances of the original dataset were compared, using Score, to that of test SVMs (54-test SVMs). The test SVMs were trained using a test dataset consisting of either the original dataset from which one feature was removed (22 test SVMs in the first round)Page: 489 487494
DROP: a domain linker predictor trained with optimal featuresor the original dataset to which one feature from a feature candidate dataset, which was OFC-2 for the first round, was added (32 test SVMs in the first round). The best test SVM, as evaluated by Score, was selected as the original SVM for the next round of selection (Score is described in the next paragraph). Features removed from an original set during a selection round were included in the test dataset of the next round, so that a feature discarded in an early round of the stepwise selection could still appear in the final SVM. Consequently, the number of tested feature combinations, and thus of SVMs, remained constant at any round of the stepwise selection, as they corresponded to the number of features contained in the original dataset plus those in the test dataset (54 test SVMs, in our case). The stepwise selection process was repeated until Score became negative for all tested SVMs (i.e. the original SVM was better than any newly tested SVMs). The prediction performance was evaluated by defining a score difference(Score) defined as:where O prec and O sens are, respectively, the precision and the sensitivity of the original SVM predictor; T prec and T sens are the corresponding values of the test SVM. T AUC and O AUC are the area under curve (AUC) (see next section) of the test SVM and the original SVM predictor, respectively. We assessed the SVMs using Score because it is easy to calculate and useful for simultaneously monitoring the changes of all of the three parameters. Score becomes 0.0 when the prediction performances, as assessed by the product of the prediction's precision, sensitivity and AUC, remain unchanged; 1.0 when the test SVM is perfect and the original one fails completely; and 1.0 in the opposite case. We defined Score using the product of T prec , T sens and T AUC rather than their sum, because their increase/decrease increments differed significantly (T AUC variation is about 1/10 of that of T prec or T sens ).
SVM parameter optimizationWe used the SVM light package with a RBF kernel for the classifiers (). Residues were encoded using the above identified optimal feature values as their elements. The SVM parameters (, C and E) were optimized using SVMLab software (http://rubygems.org/gems/ svmlab) with a dataset of 400 randomly selected vectors containing the same number of linker and non-linker vectors. The smoothing window size was optimized according to the AUC. The AUC is the area under the receiver operating characteristic (ROC) curve, which is a plot of R FP against R TP , where R FP is the ratio of the number of correctly classified linker residues to the total number of residues classified as linker residue, and R TP is the ratio of the number of correctly classified linker residues to the total number of linker residues. ROC curves were calculated for each SVM predictions with smoothing window sizes of 1, 5, 9 and 13 residues with a five-fold cross-validation test.
Domain linker predictionThe raw SVM output values, which represent a residue's domain linker propensity, were smoothed using 5-residue moving averages. The region with the highest smoothed output value was predicted as a linker if its output value was larger than the threshold value (TV). The default TV was chosen so as to maximize R TP R FP .
Prediction assessmentThe prediction performances were assessed using the sensitivity and the precision of the prediction. Sensitivity is the ratio of correctly predicted linkers to all of the structure-derived linkers listed in DS-All. Precision is the ratio of correctly predicted linkers to all of the predicted linkers. The prediction was defined as correct when the predicted linker residue with the highest SVM value overlapped with a structure-defined linker residue. This criterion is significantly more stringent than those previously used for assessing domain linker prediction ().Additionally, we assessed the performances of DROP using the average overlapped score (AOS;), and the normalized domain overlap (NDO) score (). The AOS is the ratio of correctly assigned residue number to the total number of residues. The AOS of DROP was calculated by assuming a prediction as correct when it coincided with the CAFASP4 assignment. The NDO-Score is useful as it provides a single value that evaluates (penalize/prioritize) both over-and underpredictions. The NDO-Score and AOS were also used to compare the prediction performances of DROP to those of other domain boundary predictors using CAFASP4 DP targets (http://www.cs.bgu.ac.il/dfischer/ CAFASP4/) and CASP8 () protein targets including FM (Free Modeling) domains.
RESULTS
Selection of optimal feature candidates by random forestDROP is a domain linker predictor trained with 25 optimal features that best distinguish linkers from non-linkers (Supplementary Table S-1, Table S-2 and). The 25 features were selected in two steps. In the first step, we used a random forest protocol and evaluated the importance of 3000 features for distinguishing linker from non-linker regions using the mean MDGI Z-Score (). Fifty four features with Z-Scores >2.0 were selected as optimal feature candidates (Supplementary Table S-1 and Figure S-2). In order to provide insight into the feature's charateristics, we clustered the optimal feature candidates according to their vector elements using a complete linkage algorithm. The feature candidates clustered into 10 groups (Supplementary Table S-1 and Figure S-2): predicted secondary structure element (PSS) by PSI-PRED () (Groups 1, 3 and 9 corresponding to PSS-H,-E and-C, respectively); indices that attribute a low value to Pro (Group 2); amino acid indices that attribute a high value to Pro [Group 8, which included a linker likelihood score defined in our previous reports (
Stepwise selectionThe second step of our selection protocol was a stepwise selection, where features that decreased the prediction performances were removed whereas those that increased them were added. To this end, the above set of 54 feature candidates was divided into 22 features with Z-Scores larger than 3.0 (OFC-1), and 32 features with Z-Scores between 2.0 and 3.0 (OFC-2; Supplementary Table S-1, Table S-2 and). OFC-1 was used as the initial original training set (see 'Methods' section). Three features were added in four rounds of stepwise selection () and no feature was removed. The added features were PSSM elements of Glu, Arg and Ser with 21-, 41-and 21-residue windows, respectively.
Performance improvements by choosing optimal featuresThe efficiency of our feature selection was tested using five SVM domain linker predictors trained with various combinations of features. Besides DROP, trained with the 25 optimal features, SVMAf was trained with all 3000 features described in the 'Methods' section, and SVM-SD3.0 and SVM-SD2.0 were trained using features with Z-Scores larger than 3.0 and 2.0, respectively. Further, SVM-PeP was trained using only the PSSM (17 elements) and PSS (3 elements) elements among the 25 elements used in DROP. According to a five-fold cross-validation test, the sensitivity, precision, NDO-Score and AOS of DROP were, respectively, 41.3%, 49.4%, 0.766 and 0.796. These values represented 19.9% sensitivity, 23.7% precision, 0.079 NDO-Score and 0.062 AOS improvements over SVM-Af, and were over 1.0%, 0.3%, 0.03 and 0.04 higher thanThe performances were measured using the first-ranked prediction with a five-fold crossvalidation test. All the SVMs were trained using DS-All, but encoded with different features (details are shown in the 'Results' section). DROP was trained with the 25 optimal features listed in Supplementary Table S-1, and DROP-SD5.0 and DROP-SD8.0 were trained with 15 and 9 optimal features, respectively (see 'Results' section). SVMPep was trained using 20 PSSM and PSS features, which were obtained by removing non-PSSM and non-PSS features from the 25 optimal features. SVM-SD3.0 andSD2.0 were trained, respectively, with 22 OFC-1 features, and 56 features with mean MDGI Z-Scores larger than 2.0. SVM-Af was trained with all 3000 features. A random guess was performed according to the same prediction protocol as for the SVM-based predictors but using a randomly selected 11-residue region in place of the predicted region. For each protein, the random selection was performed 1000 times and the results were averaged. the respective values of SVMs developed without stepwise feature selection ().
Dependence of the prediction performances on the initial feature set of the stepwise selectionTo assess the prediction dependency on the initial state of the stepwise selection, we constructed two additional domain linker predictors, DROP-SD5.0 and DROP-SD8.0. DROP-SD5.0 was trained with 15 optimal features derived from OFC-1a and OFC2a. OFC-1a and OFC-2a contained, respectively, features with MDGI Z-Scores larger than 5.0 and between 2.0 and 5.0. Similarly, DROP-SD8.0 was trained with nine optimal features derived from OFC-1b and OFC-2b, which contained features with MDGI ZScores larger than 8.0 and between 2.0 and 8.0, respectively. The optimal features in DROP-SD5.0 included PSSM elements of Pro, Lys, Arg and Thr, PSSs, and the Shannon's entropy (Supplementary Table S-1), whereas those in DROP-SD8.0 included PSSM elements of Pro, PSSs, Shannon's entropy and one AAIndex (BLAM930101). Overall, the sensitivity and precision of DROPSD5.0 were slightly higher than those of DROP and DROP-SD8.0 ().
Comparison to publicly available predictorsWe compared the prediction performances of DROP to those of publicly available domain boundary predictors that, similarly to DROP, do not use sequence similarity to domain databases, such as SMART, Pfam PROSITE etc (). DROP's sensitivity and precision were, respectively, at least 11.4 and 12.1% higher than those of other predictors when assessed with DS-All. In addition, the AOS and NDO-Score of DROP were also higher than those of all other predictors except PPRODO. Furthermore, we assessed the characteristics of DROP with an independent set of proteins, BDS (benchmarking dataset), which contained multidomain proteins and single domain proteins in a Page: 491 487494Predictors were constructed using the same protocol as that of DROP, but by averaging the vector element using a single window size. The prediction performances were calculated with a five-fold cross-validation test using DS-AII.proportion and a size distribution similar to those computed in whole genomes (detail of the BDS construction are shown in the Supplementary Methods). BDS contained 275 multidomain and 183 single-domain protein sequences, and their ratio was set to 60.0%, which is an estimate calculated over several genomes (). The AOS and NDO-Score of DROP calculated with BDS were the highest with, respectively, 0.661 and 0.646 (Supplementary Figure S-5). Furthermore, we found very similar results when we assessed DROP's performance using CAFASP4 protein targets, which contains 27 multidomain and 51 single-domain proteins, and seven CASP8 FM (Free modeling) multidomain proteins (http://predictioncenter.org/casp8/). DROP's AOS calculated with CAFASP4 multidomain proteins was 0.666, which was higher than any of the 12 CAFASP4 DP predictors except Robetta-Ginzu (). Additionally, the mean NDO-Score of DROP was 0.760, which was also higher than any value reported for the 12 CASP8 DP servers ().We also assessed the prediction performance dependency on the initial state of the stepwise selection. DROP, DROP-SD5.0 and DROP-SD8.0 stepwise selection processes were started with different initial feature sets and eventually yielded the respective 25, 15 and 9 optimal features. The discrepancies between the final numbers of optimal features indicate that the feature space is not exhaustively searched, and that 'the optimal sets' are local minima. However, in all three cases, similar, though not identical, features were chosen (Supplementary Table S-1), and the performances were improved when compared with those of DROP-Af (). Eight features, which were related to PSSM elements of Pro, PSSs and Shannon's entropy, were present in all of the three optimal feature sets. Previous reports have shown that domain linker regions preferentially contain Pro and hydrophilic residues and/or secondary structure breaker (). In particular, linkers contain more Pro and Lys but less Gly, Asp and Asn than non-linker loops. The selected optimal features for training DROP roughly corroborated these observations: the mean MDGI Z-Scores of Pro and Lys PSSMs and PSSs were among the highest (Supplemntary Tables S-1 and S-2 and). On the other hand, PSSMs of Gly and Asn were not selected. Additionally, five non-PSSM or non-PSS features, such as Shanon's entropy and domain linker likelihood, were found among the optimal features. Though their Z-Scores were relatively low (Supplementary Table S-2), and they were typically not used for linker prediction, they nevertheless contributed to improve the prediction performances of DROP (). The inclusion into DROP of features not typically used for boundary prediction (two AAIndex and a linker likelihood score) may help predicting domain boundary regions in novel proteins. For instance, features that contributed most to the identification of the linker sequence in T0496, by DROP and DROP-SD8.0 but not DROP-SD5.0, were the PSSM elements of Pro, PSS-Coil, PSSHelix and three features that were not used in training DROP-SD5.0 (). In this and previous studies, we focus on loop regions separating continuous structural domains (See 'Methods' section). Our choice to discard discontinuous domains was motivated by our original and practical need of detecting autonomously folded domains (). Additionally, domain boundary regions containing -helices and/or -strands, which represent a minority (Supplementary Table S-4), were also excluded from the training dataset. This is because their amino acid compositions differ from those of domain linkers formed by coils (), and SVMs trained with a dataset containing sequences with differing properties are likely to perform poorly. In our study, this idea was corroborated by DROP's significantly better ability to recognize domain than other predictors (). The possibility of applying DROP to large protein sequence datasets and possibly whole proteomes was analyzed using BDS, CASP and CAFASP protein targets, though their domains are not strictly structural domains. The prediction performances of DROP assessed using BDS and CASP8 FM multidomain targets were the highest and second highest when assessed using CAFASP4 multidomain targets (Figs 4B, 5A and 5C). On the other hand, DROP had a tendency to overpredict domain linkers in single-domain targets of BDS and CAFASP4 (Figs 4B and 5B). Overprediction could be decreased simply by increasing the default threshold level or by including non-local features (as discussed below). However from an experimental viewpoint, over-prediction can be considered less detrimental than missing an existing domain, since the experimental cost for assessing a putative domain linker is nearly equivalent to that of testing a new domain terminus (). In addition, there is usually little reason to apply domain prediction to small proteins since many are single-domain proteins. Finally, domain linker predictions that consider only local sequence characteristics cannot yield a perfect predictor. This is because domain boundaries are most likely determined by the
DROP: a domain linker predictor trained with optimal features
Page: 492 487494
T.Ebina et al.Page: 493 487494
DROP: a domain linker predictor trained with optimal features
T.Ebina et al.Funding: Japan Society for Promotion of Science (JSPS-18500225 and 21300110).
Conflict of Interest: none declared.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
DISCUSSION Feature selection can significantly influence the performances of machine learning-based predictors (Kernytsky and Rost, 2009). However, because of the computational time required for performing an exhaustive search, features are usually selected by trial-anderror from a relatively small set of intuitively pre-selected features (Ye et al., 2008). Our two step approach, which combines random forest and a stepwise selection, provides a realistic approach for selecting an optimal set of features within a reasonable computational time. In our present setting, the random forest and the stepwise selection assessed, respectively, 3000 features in 7 h and 54 features in 69 h (for 4 rounds) on an 8 Xeon processors Linux server. Stepwise selection is not an exhaustive search and may overlook the very best set of features, but it assesses a sufficient number of combinations to yield one of the best (54 feature combinations were tested in each round of stepwise selection). Furthermore, the correlated effect of multiple features is partially assessed by the stepwise selection, whereas a simple forward or backward selection would merely assess the effect of adding or removing a single feature. Indeed, the re-inclusion of a feature that is discarded from the training set in a previous round of selection into the next round's test dataset enables the recovery of a feature that might not be useful with a given set of features but becomes useful when combined with a different set of features. Another advantage related to our fast two-step feature selection approach is that it enables to test several averaging windows: we encoded 600 properties averaged with five different windows into a 3000-dimensional vector. Indeed, it is not usual to include elements containing the same properties averaged over different window sizes (Hirose,S. et al., 2007). One possible reason for the scarce use of multiple averaging windows is the time-consuming search, which might counterbalance the advantages of including additional window sizes, especially when the search space is as large as in our case. However, the prediction performances of DROP significantly improved by using multiple size windows (Table 2), and this suggest that using multiple averaging window sizes might be a useful approach for improving predictions of properties determined by both local and non-local nature.
178 were thus assigned to domain-1 and domain-2, respectively, resulting in a NDO-Score of 0.955. Similarly, residues 105 and 121 were predicted as domain boundary by DROP-SD5.0 and DROP-SD8.0, respectively. The NDO-Score of DROP-SD5.0 and-SD8.0 were, respectively, 0.740 and 0.944. foldability of the domain region as much as by the local information encoded in the linker region. Previous reports suggest that nonlocal information may have a strong potential for improving domain prediction (George et al., 2005; Zhang, 2009). Our random forestbased approach can readily accommodate multiple window sizes, and it may be particularly suitable for selecting optimal non-local features, such as C density or foldability index, because the number of candidate non-local features is anticipated to be large, probably much larger than that of local features. In conclusion, our approach efficiently selected optimal sets of features from a large number of features, by combining two types of methods: the random forest and the stepwise selection. Using this approach, a vast feature space consisting of 3000 features was searched within a realistic computational time, which improved the performances of DROP. Constructed on such premises, we expect DROP to help analyzing the enormous amount of sequential data by assisting the discovery of novel domains.
