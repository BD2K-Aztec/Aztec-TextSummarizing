Motivation: Resolving tandemly repeated genomic sequences is a necessary step in improving our understanding of the human genome. Short tandem repeats (TRs), or microsatellites, are often used as molecular markers in genetics, and clinically, variation in microsatellites can lead to genetic disorders like Huntington's diseases. Accurately resolving repeats, and in particular TRs, remains a challenging task in genome alignment, assembly and variation calling. Though tools have been developed for detecting microsatellites in short-read sequencing data, these are limited in the size and types of events they can resolve. Single-molecule sequencing technologies may potentially resolve a broader spectrum of TRs given their increased length, but require new approaches given their significantly higher raw error profiles. However, due to inherent error profiles of the single-molecule technologies, these reads presents a unique challenge in terms of accurately identifying and estimating the TRs. Results: Here we present PACMONSTR, a reference-based probabilistic approach, to identify the TR region and estimate the number of these TR elements in long DNA reads. We present a multistep approach that requires as input, a reference region and the reference TR element. Initially, the TR region is identified from the long DNA reads via a 3-stage modified Smith–Waterman approach and then, expected number of TR elements is calculated using a pair-Hidden Markov Models–based method. Finally, TR-based genotype selection (or clustering: homozygous/heterozygous) is performed with Gaussian mixture models, using the Akaike information criteria, and coverage expectations. Availability and implementation: https://github.com/alibashir/
INTRODUCTIONTandem repeats (TRs) are contiguous regions of DNA in which the same (or highly similar) DNA sequences are repeated multiple times in order. TRs can range in size from single nucleotide repeats (homopolymers) to encompassing entire genes (). Short tandem repeats (TRs) of 16 bp, or microsatellites, are often used as molecular markers in genetics () or in forensic applications (Veselinovic,Veselinovic, 2006). Clinically, variation in microsatellites is observed in many genetic disorders. Triplicate CAG repeat expansions have been implicated in a number of neurological disorders, including exonic expansions in Huntington's disease () and spinocerebellar ataxia () and non-coding expansions in fragile X syndrome (). Microsatellite instability has also been used as a marker of cancer progression (). Additionally, microsatellites are implicated in regulatory roles; they have been shown to be highly conserved near transcription start sites () and are sometimes known to modulate gene expression (). Despite their importance, TRs are often ignored because accurate resolution of TRs in both variation and assembly settings remains a challenging task. With the availability of high-quality genomes, a number of tools were developed specifically for TR resolution (). Tools like Tandem Repeat Finder (TRF;) attempt to detect such repeats de novo. TRF has a detection phase that looks for statistically significant k-mer matches within sliding windows and an analysis phase, which determines period size, multiplicity and consensus repeats (). Other methods have used clustering-based approaches (T-Reks) and local autocorrelation (TandemSwan), respectively, to attempt to identify more divergent and complex TRs [sometimes termed Fuzzy Tandem Repeats (. This increased sensitivity comes at the cost of increased runtime and higher false-positive rates (). Other methods, such as RepeatMasker, can then be used to screen entire genomes using known databases of TRs (and other repeat elements) identified by such de novo tools (Tarailo). The advent of low-cost sequencing over the past decade has made cataloguing genomic variation cost-effective across individuals. Robust tools have been created for short-read alignment (), singlenucleotide polymorphism (SNP) and indel detection (), as well as completely integrated end-to-end pipelines (). These methods have proven highly accurate in calling SNPs in diverse populations (). Additionally, these technologies have been used to enumerate more complex copy number and copy neutral forms of structural variation (SV;). Similarly, a number of excellent tools have become available for detecting microsatellites in short-read sequencing data (). Some of these methods rely on databases of known TRs (such as those generated by TRF across a genome sequence or a curated list of known variable TR intervals) and look at spanning reads (short reads which span *To whom correspondence should be addressed.  The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com the repeat) to call TR alleles for a given individual (). Given the length of the reads being analyzed, these methods are limited in the multiplicity and/or period size of TRs that can be resolved even when they take into account more complex mate-pairing information. More recently, methods have arisen to detect such repeats de novo using short read data (). Doi et al.'s study uses depth of coverage information on tagged TRs to estimate TR multiplicity in repeats longer than the size of a single short read. In the past few years, 'third-generation' sequencing technologies have arisen that offer substantially improved read lengths. Single-molecule real-time (SMRT) sequencing from Pacific Biosciences (PacBio) creates continuous sequence reads ranging from several kb to tens of kb in length. These reads have been shown to allow dramatic improvements in genome assembly (), haplotype phasing () and SV applications (). Although they are obvious candidates for broadening the scope of detectable TRs, the unique error profile (and higher raw error-rate) () necessitate new approaches for accurate resolution of TR multiplicities. Here, we present PACMONSTR, a tool for the detection and resolution of TRs specifically optimized for raw single-molecule sequencing data. PACMONSTR attempts to build on the ideas of previous reference-based approaches to best capture the idiosyncratic features of single-molecule sequencing data. The method provides the following:(1) Improved boundaries of spanning TRs by performing a more sensitive TR-specific dynamic programming alignment(2) Statistical estimates of TR multiplicity using a pair-hidden Markov models (pairHMM)(3) Predictions of heterozygosity and homozygosity with consensus sequences when multiple spanning reads exist(4) Predictions of boundaries for compound structural variants within or around a TR interval Using simulated and real sequencing data compared with the hg19 build of the human genome, we compare the performance of our methods and de novo approaches in terms of detecting TRs and estimating multiplicity. Clustering performance is assessed using known homozygous and synthetic heterozygous TR sequences. Lastly, we simulate the introduction of SV into TR intervals to show the ability of the tool to flag non-TR intervals, and apply the SV detection approach on real data.
METHODSAn overview of the methods is shown in Supplementary. We begin with alignment of a set of reads Q = {Q k jk=number of reads} to the reference genome G (hg19), using BLASR (). Uniquely mapped reads spanning TR intervals on the reference are selected. In the scenario that two disparate alignments are found spanning a reference TR interval (which may occur if a TR allele is highly divergent from the reference allele at that locus), multiple unique alignments may be merged to provide the initial query seed interval for downstream processing. Next we use a modified NeedlemanWunsch alignment algorithm to better identify TR boundaries and give initial TR multiplicity estimates (Section 2.1). The identified TR interval is then passed through a pairHMM to give a more rigorous estimate of the TR multiplicity (Sections 2.2 and 2.3). Reads are then grouped by locus and clustered based on their estimated TR multiplicities to determine zygosity (Section 2.4). Lastly, the probability values calculated by the forward algorithm of the pairHMM forms a basis to discover potential SVs internal to TRs (Section 2.5).
Identification of TR boundaries within readsLet the interval ; ) denote the occurrence of a TR in G and r denote the consensus sequence for the TR element. The initial alignment information is used to extract a subinterval from the query, Q k , containing the TR as well as a predetermined amount of flanking reference sequence,. Given that the TR in Q k may deviate from the expected reference size, it is likely that the initial reference alignment inaccurately represents the boundaries of the TR. To address this, we extract subinterval a  e; b+e in Q k corresponding to the reference coordinates   ; +), where a; b are query positions in the alignment that match reference position ;. The spanning query interval Q k a  e; b+e, along with r and the set of prefix and suffix sequences in G (corresponding to the intervals   ;  and ; +, respectively), are passed into a TR-specific dynamic programming algorithm to improve boundary resolution, as shown in. For a given query subinterval Q k a  e; b+e, let p, r and s correspond to the prefix, TR element and suffix reference sequences and P, R and S correspond to their respective alignment matrices to Q k a  e; b+e. The prefix alignment matrix P is filled out according to the Needleman Wunsch algorithm (). The repeat matrix R, however, requires additional initialization and recurrence conditions:Here, 'Read' corresponds to the query subinterval Q k a  e; b+e and sequence 'TCC' corresponds to the reference TR element. The thick dashed gray lines in the Prefix (P) and TR (R) matrices represent the resolved TR boundaries within the read. The arrows represent the recurrence conditions for the three matrices where i 2 Q k a  e; b+e, j jrj, is used to denote a gap penalty, and mQ i k ; r j  is the score for aligning the corresponding base i in Q k a  e; b+e and j in r. First, any position i in Q k a  e; b+e, denoted by Q i k , which reaches the end of the prefix sequence is a valid entry point into the repeat matrix R at row i+1. We cannot assume a priori that the repeat starts at the beginning of the predicted consensus copy, and thus, at any position R i;j we must consider P i1;jpj +mQ i k ; r j . The key distinguishing feature of the repeat matrix is its ability to traverse a repeat unit multiple times. This is captured at position i5jQ k a  e; b+ej=jQ k j, by allowing the move from position i  1; jrj in R to any position i; j in the following row by R i1;j +j  1+mQ i k ; r j  (the term penalizes any insertion gaps induced by such a move). This allows unbiased expansion and contraction of the repeat and substantially reduces the time complexity, especially in the case of highly expanded repeats (the most challenging types of TRs to resolve). Under the assumption that no sequence was lost at the junction, the suffix is straightforward to compute. A single special case is required in the first column of the suffix matrix S to consider entries from the repeat matrix R. This is handled by the relation S i;1 = max 05k5jrj R i1;k +mq i ; s 1 , otherwise the standard Needleman Wunsch recurrence is used. After retracing the optimal path through the S, R and P matrices, in order, and returning the entry and exit points in R, the predicted TR sequence in Q k a  e; b+e is obtained. The multiplicity of the repeat is given directly by this traversal; it is roughly the number of times the last case of the repeat recurrence is used in the optimal traversal path, plus the fractions of the repeat from the prefix entry and suffix exit points. The time complexity of this algorithm is OjQ k jjpj+OjQ k jjsj+OjQ k jjrj. However, the prefix and suffix lengths are constrained by the fixed flanking criteria, , leading to time complexity OjQ k j+OjQ k jjrj. In practice, as ( jQ k j and r ( jQ k j, this compute is substantially faster than jQ k j 2 .
Probabilistic TR resolution through pairHMMTo improve estimations and allow for allele assignment, we extend the previous strategy in two key ways:(1) Explicit modeling of error modes specific to the sequencer, such as cognate sampling ()(2) Provide probabilities for predicted TR multiplicities in a given read.To address this we propose a pairHMM approach that computes the probability for the sum of all alignment paths between the query and a putative repetitive TR sequence. In this paradigm, the number of TR elements is treated as a random variable and the pairHMM is used to calculate the expected value of this random variable based on an estimated discrete probability mass function. Supplementarydetails the model structure of the pairHMM, which takes as input the predicted TR interval in Q k a  e; b+e (labeled as q) and the consensus TR element sequence, r, and models the error modes with three hidden states: M = match, X = deletion and Y = insertion. Transition and emission probabilities are generated from BLASR () alignments in non-TR regions. These probabilities are computed globally over all sequenced reads and locally using the flanking sequence to account for variability between reads. In practice, global parameters for transitions are seen in Supplementary. To more accurately represent the known issue of 'cognate sampling' (), whereby the emitted base has a dependence on the last incorporate nucleotide, we incorporate conditional dependence in emission probabilities when calculating forward probability values (Supplementary Methods) for the insertion state (defined as X). Parameters for these conditional emission probabilities for the insertion state X are shown in Supplementary. Our application differs from the canonical pairHMM in that we are not comparing two true sequences, but rather comparing an error-prone sequence (the long read) to the potential true sequence derived from a reference TR element (r). Therefore, we use a slightly modified version of the pairHMM presented by Durbin et al., to allow for an insertion of a base to be followed immediately by a deletion (or vice versa) to account for this type of sequencing pathology.
Calculating expected TR multiplicitiesLet PO ! j correspond to the probability of an observation sequence O ! given the pairHMM model parameters. We run the forward algorithm () with q and an upper bounded synthetic TR sequence, (constructed by repeating r), as the pair of sequences constituting the observation sequence O ! =q; . In practice, we use j j=1:5jqj=jrj. For all j=1;. .. ; j j, we calculate the sum of forward probabilities f S jqj; j from each state S=M; X; Y to obtain PO ! j; j=f M jqj; j+f X jqj; j+f Y jqj; j. Details on the forward calculation can be found in Supplementary Methods. These probability values are used to get relative normalized weights,; k of observing a given TR multiplicity j in the observation sequence O ! . The relative weights are then used to calculate the expected value of the TR multiplicity, numTR= X jw j (Supplementary). We also calculate the log odds ratio with respect to a random model, Z (). Let j  i = argmax 8j PO ! i j; j represent the TR multiplicity at which PO ! i j; j is maximal. The log odds ratio is calculated as logThe higher the value of the log odds ratio, higher the significance of the pairwise alignment between the query sequence, q, and the constructed TR sequence,. Optimization of the model parameter , given the observation sequence O ! is typically performed using BaumWelch or expectation-maximization algorithms (). In our construct, the true observation sequence O ! is unknown and hence we estimate the model parameters from the known pairwise alignments. We calculate PO ! j where is either Local or Global. Global is pre-estimated from sequence alignments of the reads to the reference genome, G, and Local is estimated at runtime from the sequence alignments upstream and downstream of q (from the prefix P and suffix S matrices, as previously defined). The model parameter is then selected based on the higher value for PO
TR allele callingTo determine zygosity for each TR event, we use a generalized Gaussian mixture models (GMMs)-based approach, which uses Akaike information criterion (AIC) for the initial model selection. Algorithm 1 details the process by which heterozygous or homozygous calls are made and consensus sequences are generated for each cluster. We assume the observed TR multiplicity calls are normally distributed around the true TR length for each allele. We use the scikit-learn GMM Algorithm 1 TrAlleles. Takes as input the set of reads spanning a TR event and returns the consensus homozygous or heterozygous allele(s) implementation (), with the covariance type for the dataset to be diagonal (given that the one-dimensional data points have no correlations). For diploid genomes, we allow either 1 or 2 components in the model, corresponding to homozygous or heterozygous alleles at each locus. Note that outliers are inevitable in such analyses and to handle such outliers we require that each component in the mixture model contain at least two data points. If a component represents a singleton value, we eliminate the value from the initial set and iterate until a component with at least two data points is observed. For initial model selection, we compare the AIC () for n = 1 and n = 2 components, and choose the one with a lower value (). To call the event as heterozygous, we intersect the model selection with two different sets of criterions. The first criterion calculates the c-separation, C SEP , between the means of the two predicted Gaussian distributions (), where c is a constant scaling factor. Let C SEP  1 ; 2 =c  max  1 ; 2  where 1 ; 2 corresponds to the standard deviation of clusters 1 and 2, respectively. We set a threshold t C =j 1  2 j, where 1 ; 2 corresponds to cluster means. For the second criterion, we confirm whether the number of data points per cluster is possible under the assumption that the observed split of data should follow a binomial distribution. We approximate this by calculating BINCDF, 1-binomial CDF of observing at least the number of reads in the larger component given total clustered reads, and enforce that this is above some cutoff, t b. If C SEP  1 ; 2 5t c and the probability of observing the number of predicted data points per clusters is more than t b , the event is labeled as heterozygous. The parameters 'min_covar' (the lower bound for the covariance values of the mixture model in scikit-learn's GMM implementation) and c are optimized using a homozygous and heterozygous training set (See Section 3). In the final step, a consensus sequence is generated for each cluster via 'partial order alignment', using the heaviest bundle algorithm (). These consensus sequences are then used to reestimate the number of TRs via pairHMM for each allele.
SV detection and multiplicity lower boundsThe sequence in the query TR interval may not simply represent TR expansions or contractions. SVs have been shown to flank many repeat-mediated structural variants including TRs (). The PO ! j derived from the forward algorithm provides a probabilistic basis to estimate and classify non-repeat intervals in q. These non-repeat intervals (defined as regionSV) could either be repeat sequences with some similarity with the reference TR element or internal SV. Using q as the input we follow a simple procedure to identify these non-repeat intervals. For each index i of q, we calculate max 8j PO ! i j; j and j  i (refer section 2.3), where O ! i =q 1;2;...;i ;  is the observation sequence. Next, we calculate log-likelihood ratio, LLRi;, for each index i of q. We then calculate the deviation of LLR for each i, defined as "LLR i;i1 =LLRi; j  i  LLRi 1; j  i1 : For a perfect TR sequence between i 0 ; i, "LLR i;i 0 will be 40;SVs in q can then be identified as follows:regionSV=fi h ; i h- : "LLR ih-;ih 50 j0 i h 5i h-jqjgThe likely repeat region in q is then a set f1; jqj  regionSV}. Thus, regionSV q may refine our estimate of the expected TR multiplicity as numTR  jregionSVj. This correction presents a more conservative bound to the expected TR multiplicity in q. A high value for jregionSVj suggests a significant insertion region in q with respect to the reference TR sequence. In the current implementation we have restricted ourselves to evaluating small SV insertions; a simple two-state HMM with Gaussian emissions was used to flag predicted insertion intervals within the query by looking at the "LLR values at each adjacent i 0 ; i, of q. The GaussianHMM implementation from scikit-learn () was run with two components to call SV events in q. The mean and covariance values for the model were initialized based on the assumption that the inserted intervals would have "LLR50.
RESULTS
Raw read TR prediction analysisTo evaluate TR detection methods we created simulated reads on chromosome 1 of hg19 using pbsim () with 'datatype' as CLR, 'depth' as 10, 'length-mean' as 7000 and using the 'model-qc' option. We focused on detection (Does the method identify a TR in a TR spanning read?) and accuracy (How consistent is the predicted TR multiplicity with the known value)? Detection is only relevant for de novo TR predictions; referencebased methods (such as PACMONSTR) depend on the reference as input. TRF was run on all raw read sequences using a minimum score setting of 25 (roughly twice as sensitive as default settings, leading to many false-positive calls).indicates the ability of TRF to detect a consensus sequence similar to the true repeat consensus. To provide a conservative comparison, we tried to be as permissive as possible in our definition of 'detection'. Each predicted consensus repeat from TRF was compared with the known TR, by performing SmithWaterman alignment of the predicted repeat against a 2 TR of the true consensus. This ensured that any cyclic variations of the true repeat would be captured. Using a match score of 5, mismatch of 5 and indel penalty of 5, a true repeat was considered 'detected' if any of the alignment scores to TRF repeat predictions in the interval exceeded 0:35L=0:8  5  L  0:1  5  L, where L is the length of the true TR consensus. In general, the higher the multiplicity and the shorter the repeat interval the more likely TRF was able to accurately detect the element. The multiplicity result is straightforward: the more instances of a TR, the more likely the method is able to capture it. Shorter repeats are likely easier to detect owing to error ratesthe longer repeats are often too highly diverged to satisfy TRF's k-tuple requirements unless extremely high copy numbers are observed. Reads that had detectable events by TRF were used to assess the accuracy of TR multiplicity predictions. For TRF, the best candidate repeat (closest to the true consensus) was used for multiplicity estimation.shows the performance of TRF versus our modified recurrence ('Na ve DP') and pairHMM algorithms over all simulated reads of hg19 chromosome 1. As expected, TRF underpredicts missing TR instances or over-fragmenting a continuous TR in multiple disjoint elements. At all frequencies and period lengths the pairHMM accurately predicts TR multiplicity, outperforming both the na ve dynamic program and the TRF. The pairHMM and na ve dynamic programming converge at large period sizes (416 bp), as it is unlikely that slight indels or substitutions would disrupt the optimal path of the query through a predicted repeat instance.
Evalutation of clustering performance3.2.1 Dataset construction To assess the performance of the clustering approach, we used a roughly publicly available sequence reads (roughly 9 coverage) from the CHM1hTERT cell line (), a haploid complete hydatiform mole (CHM) (). All TR zygosities for this genome should therefore be homozygous. Evaluating heterozygous calls is more challenging, as it is difficult to establish 'ground truth' for individual reads derived from a diploid reference. To address this ambiguity we constructed a synthetic heterozygous test set using the same haploid CHM dataset. First, we identified disparate regions in the reference genome with identical consensus TR sequences. Next, for each group of regions with a shared TR sequence we performed a pairwise merger of the constituent read sets. Each disparate pair yielded a synthetic heterozygous event. These events were then grouped by the difference in their TR multiplicities. We then evaluated the performance of the clustering approach for the TR multiplicity differences of 1, 3, 5 and 8. To select the parameters for our clustering approach, we trained our model on a training set and selected the model parameters with the highest accuracy score on the homozygous and synthetic heterozygous test sets. 'min_covar' of 0.0175 and t C of 2.0 were used for clustering of CHM data.
Clustering performancePacmonSTR's ability to call homozygous TRs is shown in. The approach correctly predicts 490% of events at medium to large period sizes. Small periods were more difficult to accurately resolve, as small variances in size can lead to large deviations in predicted multiplicity (especially for singletons or small repeats that contain homopolymeric sequences).
Small insertion detection in TRsAs expected, heterozygous calling performance improves as the difference in the TR multiplicity increases (). However, even at a multiplicity difference of 3 the method is still able to identify 475% of regions accurately. As in the case of homozygous events, single base TR elements were problematic at all difference levels. For heterozygous events we also evaluated the accuracy of assigning reads to a given cluster.shows the fraction of reads that are misassigned based on the periodResolving complex tandem repeats with long reads size and TR multiplicity differences. In general, clustering is extremely accurate except for small repeats or low differences in the TR multiplicities. To evaluate the pairHMM's ability to identify insertions (or structural variations, SV) in the TR interval, we simulated random sequences and added those to the simulated repeats from chromosome 1 of the CHM cell line. Fifty replicates were performed at each period, frequency and SV size bin. We then assessed the ability of the method to accurately call the insertion and estimate its boundaries in two different cases: (i) insertions internal to TR regions (and B) and (ii) insertions at the ends of TR regions (Supplementaryand B).and B highlights the predicted number of events under different period, multiplicities and insertion sizes. As expected, the smallest insertion (10 bp) was consistently the hardest event to detect. Notably, larger SV sizes are rarely missed and no over-calling occurs at any event size (). To assess the accuracy of the boundaries, we examined reads that predicted a single insertion;shows that the algorithm is roughly centered at 0 bp divergence between the expected and observed start sites. Insertion sizes do not seem to substantially change the precision of boundary predictions. Though smaller periods give the best results, the boundary predictions are surprisingly tight across simulated values. Using these parameters, we probed for insertions within CHM chromosome 1. Nine regions on chromosome 1 showed up as positive for insertions.highlights an example insertion that we were able to confirm via comparison with hg19. The consensus repeat 'TG' is split by an internal 'AG' repeat; this is detected without knowledge of the full reference sequence (only the 'TG' element). The observed consensus differs from hg19 in 'TG' multiplicity downstream of the event insertion site.
DISCUSSIONWe have presented an approach for reference-based TR detection that is specifically adapted for long reads with high insertion/deletion error rates. The method substantially outperforms de novo approaches both in detection and resolution of events. Additionally, the probabilistic pairHMM not only provides an even tighter prediction of TR multiplicities on raw reads it can also be used to infer structural variants within, or immediately flanking, a TR region. Despite meeting these goals, PACMONSTR and the simulations used to evaluate it have a number of limitations and areas where further improvements can be made. Validation of clustering accuracy is an issue that may need to be addressed on a genome by genome (or repeat by repeat) level (). We attempted to model this by using real haploid genome sequences and creating synthetic heterozygous TRs from disparate genomic regions of the genome. In real diploid data, however, one does not know if a region is truly heterozygous. An alternative approach for evaluating calls is to identify SNVs, indels and SVs upstream and downstream of a called TR. Once TR multiplicities are predicted for each read, and clustering assignment has occurred, one can evaluate concordance of flanking variant alleles with the TR clustering assignment of raw reads to determine whether they form a consistent haplotype. The high-error profile of SMRT sequencing on a per-read basis could make accurate SNP assignment challenging. However, as the read lengths continue to expand, it has been shown that multiple SNPs and SVs captured within a single long read could create a stronger statistical signal to validate phasing (). Ideally, this haplotype information can be incorporated into the clustering process, in addition to the estimated TR multiplicity, to more robustly separate TR alleles with small periods or with small multiplicity differences. Given the quadratic runtime for the pairHMM, if read lengths continue to improve into the hundreds of thousands of base pairs, the runtime of the algorithm may become unwieldy in real-world scenarios. However, the pairHMM is not required to accurately resolve multiplicity for most TRs. For largeperiod TRs, the modified prefix-repeat-suffix dynamic program provides nearly identical results at substantially faster speeds. Although the DP runtime grows linearly as the period size increases (and may also become prohibitively large), faster banded heuristics become viable with large periods. Many small-period TRs can be resolved in the clustering phase without requiring the pairHMM. If two alleles are highly dissimilar, even if read-toread variation is high, it is likely that they still will form distinct clusters. Once clusters are identified and consensus sequences are generated, TRs can be identified directly from the consensus. Thus, the full pairHMM can be restricted for scenarios where accurate resolution is required on short period repeats for which clear clustering cannot be performed. The proposed and related approaches are reliant on predetermined locations of TRs in the reference as input. This limits the generalizability of the method, but can be alleviated by preprocessing the data with other de novo and structural variant tools.showed that TRF was often able to detect repeats from the raw reads. In practice, the algorithm can be run on all raw data to seed potential repetitive positions in the queries. These positions can be projected back onto the reference to identify candidate intervals for novel TR events. Reads spanning these positions of interest can then be interrogated by running the full pairHMM on the set of TRs predicted in the interval. As multiple consensus repeats will likely be identified, the one yielding highest probability can be selected for clustering analysis. Additionally, some SV tools, like Delly, allow for detection of novel TRs using reference coordinates that can similarly be passed into the method (). Just as we can inform de novo TR calling by integrating other tools, we can similarly use our approach to help inform compound structural events involving TRs. Inwe demonstrated the method's ability to reliably identify inserted sequence within a TR element. SV elements observed on chromosome 1 were often TR expansions (such as in); these sometimes existed at TR boundaries, suggesting potential refinements may be needed to the initial DP algorithm to better distinguish TR intervals from prefix and suffix sequences. Additionally, SVs may not always represent a distinct sequence block, the predicted consensus periods for a TR within an individual have been shown to diverge from the expected TR consensus, especially in the case of compound TRs where smaller repetitive units are grouped within a larger repeating unit (). Although these can be more easily seen once a consensus is generated, local fluctuations in pairHMM probabilities can inform when such slight deviations in TR consensus are occurring periodically across a TR interval. As alternative sequencing platforms become available, algorithms are needed that are able to harness the unique features of each technology. For any technology, even as the cost per base decreases, one must always make a choice between higher sequencing depth and larger numbers of samples. This decision is tied to the experimental goals of the project as well as the relative precision of a technology at different sequencing depths. In the context of TRs, our method provides informative guidelines for TR resolution given the type and size of the desired repeat. By allowing single read calls (and providing a probabilistic framework for evaluating these calls), the method is immediately applicable even at low depth, making it a useful option given the platform's comparatively higher cost, while also enabling potential applications in heterogeneous cell populations, as observed in cancer. Integrating raw read TR resolution with robust consensus calling, will continue to make the approach applicable for the type of high-depth studies that will soon be feasible as these technologies mature and become used by the broader research community.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
A.Ummat and A.Bashir at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Resolving complex tandem repeats with long reads at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
