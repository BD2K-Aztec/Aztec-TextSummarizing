Motivation: Clustering protein structures is an important task in structural bioinformatics. De novo structure prediction, for example, often involves a clustering step for finding the best prediction. Other applications include assigning proteins to fold families and analyzing molecular dynamics trajectories. Results: We present Pleiades, a novel approach to clustering protein structures with a rigorous mathematical underpinning. The method approximates clustering based on the root mean square deviation by first mapping structures to Gauss integral vectors—which were introduced by Røgen and co-workers—and subsequently performing K-means clustering. Conclusions: Compared to current methods, Pleiades dramatically improves on the time needed to perform clustering, and can cluster a significantly larger number of structures, while providing state-of-the-art results. The number of low energy structures generated in a typical folding study, which is in the order of 50 000 structures, can be clustered within seconds to minutes.
INTRODUCTIONPredicting the 3D fold for a given amino acid sequence remains one of the greatest challenge in computational biology today. While many of the driving forces behind the folding process are understood in principle, their calculation in the context of a folding study is still challenging. Most de novo prediction methods rely on sampling a large number of decoy structures from an approximate force field. Due to the effects of configurational entropy and of the folding pathway, the native structure is not necessarily the structure with the lowest energy, even with a perfect physical force field.point out that decoy clustering is the correct way to select the final prediction, since the native structure is typically located near the bottom of a broad well in the energy landscape. They showed that selecting the centroid structure of the largest cluster readily results in structures that are closer to the native structure than the structure with the lowest energy. Here, the centroid is the structure with the lowest average distance to all other structures in the cluster. Modern computer hardware allows to generate tens of * To whom correspondence should be addressed. thousands of low energy decoys in a few hours. These developments underline the demand for software that is able to clusters tens of thousands of structures in seconds or minutes. There are several clustering programs available in the public domain. They usually rely on an atomic representation of the decoys and subsequently cluster based on the pairwise root mean square deviation (RMSD), a standard measure of structure similarity (). The most popular programs, Calibur (), Durandal (), Scud () and Spicker () follow the Rosetta/iTasser procedure () and perform exact clustering. The structure with the most neighbors within a given cutoff is chosen as the first centroid. The selected structure, along with all neighbors, is then removed from the set and the procedure is repeated to find the next largest cluster. Calibur applies pruning to exclude a large part of the decoy set from the costly pairwise comparison using auxiliary grouping with upper and lower bounds. Durandal similarly avoids large amounts of the pairwise calculations in the initial step of filling the distance matrix, by propagating the information gained in the exact measurement: knowing the RMSD values of structure pairs (A,B) and (A,C) allows to infer information about the RMSD value of (B,C). Both methods are substantially faster than Spicker, which evaluates all pairwise distances. Scud also applies exact clustering, but uses a reference root-mean-squared distance to calculate the pairwise distances. Here, all structures are aligned to a randomly selected reference structure. The approximate RMSD between two structures is then calculated based on their respective RMSD values with that reference structure, thereby avoiding the cost of an explicit superposition. With the exception of Spicker (), the number of structures that can be clustered is not limited by any of the programs. However, extensive memory consumption becomes a limiting factor with growing numbers of decoys, as reloading the structures from the hard disk leads to a significant drop in performance. Currently, with a common desktop computer, 10 000 to 30 000 structures can be clustered, depending on the amount of main memory available (). Here we present Pleiades, a novel approach to protein structure clustering that uses Gauss integrals () to represent a protein's 3D structure. Gauss integrals allow to represent structures by 31-dimensional vectors, whose pairwise Euclidean distances correlate well with the RMSD of the corresponding structures (). Using this efficient representation, Pleiades is able to quicklyPage: 511 510515
Pleiadescluster a large number of protein structures, improving drastically on existing methods.
IMPLEMENTATION
Representing proteins using Gauss integralsIn order to describe the overall fold of a protein structure, it is usually sufficient to consider the so-called C  trace, which consists of the segments that connect the C  carbon atoms of the protein backbone. More detailed information such as the exact side chain conformations are of less importance for describing the fold.) introduced a simplified description of the 3D fold by interpreting the protein's C  trace as an oriented open curve in space, and subsequently calculating a series of generalized Gauss integrals. In a planar projection of a curve, one can count the number of crossings and, using a handedness rule, also the signed number of crossings. The two simplest Gauss integrals, called writhe and average crossing number, are the signed and unsigned number of crossings averaged over all planar projections of the curve. The writhe and average crossing number are natural measures of how 'entangled' a curve is. The higher order Gauss integrals measure specific patterns of entanglement along the backbone; for almost planar curves they count how often a particular pattern of two or more crossings occurs (). A protein's C  trace can thus be represented as a vector of Gauss integrals.) showed that for two given proteins, the Euclidean distance between their Gauss integral vectors correlates well with the RMSD. Pleiades uses an enhanced version of the measure called the tuned Gauss integral (GIT). The inspection of 24 000 high-resolution domains from the CATH database () revealed both a correlation between different Gauss integrals as well as a dependency on the length of the amino acid chain. This analysis led to an empirical correction factor, reducing the length dependency, that is applied to each Gauss integral. Moreover, some Gauss integrals can be predicted from lower order integrals and the length of the protein. In these cases, the estimated value is removed to limit the internal correlation. Lastly, calculating a smoothed curve from the otherwise rugged C  trace further decreases the correlation between different Gauss integrals and improves the signal to noise ratio. Overall, the use of the GIT measure leads to a significantly better correlation with the RMSD, especially when the compared proteins have different lengths (). The result is a 31-dimensional GIT vector that describes a protein's fold. The distance between two structures is simply the Euclidean distance between the two vectors  x and  y:where  x and  y are the GIT vectors calculated from structures X and Y , respectively; x i and y i is the i-th component of  x and  y, respectively; and the sum runs over all 31 components of the vector. While the GIT measure accurately describes a protein's fold, it is not possible to derive a unique 3D structure from a GIT vector: different structures may map to the same GIT vector. Formally, the set of proteins and the GIT vector distance form a pseudometric space. Unlike in a metric space, in a pseudometric space the distance between two different points can be zero. However, the strong correlation between the two measuresespecially at low RMSD valuesindicates that the GIT distance adequately approximates the RMSD distance for our purposes.
K-means clusteringThe K-means algorithm was first introduced by Lloyd (1982) and has since then been used in a variety of applications (). The algorithm itself is straightforward and has proven to be especially useful in high-dimensional spaces due to its speed. The distance matrix required for exact clustering is an N N matrix where N is the number of points in the dataset. For performance reasons, it is desirable to store at least the upper triangle of the matrix in main memory, as this allows fast access. For large datasets, however, the size of the matrix easily exceeds the amount of available memory. For K-means clustering, it is not necessary to store this distance matrix, allowing the clustering of significantly larger datasets. The algorithm consists of the following steps: (i) choose k initial cluster centers at random from the entire dataset. (ii) Assign each data point to its nearest cluster. (iii) Compute new cluster centroids for all clusters, given their current members. (iv) Repeat (ii) and (iii) until convergence. The total energy of a cluster is then defined aswhere C is the cluster, c j is the j-th member of C, c c is the centroid of cluster C, | C | is the cluster size, d is given by Equation (2.1) and the sum runs over all members of cluster C.
K-means++The K-means algorithm is non-deterministic; the result depends on the initial seed of cluster centroids, which are selected randomly. Both performance and convergence time can be improved by selecting the initial seeds more carefully ().) suggest to select the initial cluster centroids by sampling seeds dependent on the distance to all seeds selected so far. The initial seeding procedure is modified as follows:(i) select one initial cluster randomly from the entire dataset; (ii) sample the next centroid, as explained below; (iii) repeat step (ii) until k cluster centroids have been selected. After this step, the algorithm is identical to the regular K-means procedure as described in the previous section. In our case, the next centroid is sampled with probability:where c i is the GIT vector representing the i-th structure; d(c i ,c c,i ) is the distance between the i-th structure and its nearest cluster centroid c c,i ; and the sum runs over all structures. In other words, the probability of selecting a certain structure as another seed is proportional to the distance to the current nearest cluster center.
DISCUSSION
Properties of the GIT measureWe start with two tests to illustrate that GIT vectors are an appropriate measure of structural similarity. In order to illustrate the correlation between RMSD and the GIT distance, we analyzed structures from three ensembles involving two different proteins (). The ensembles were obtained by starting from the native structure and re-sampling parts of the structure guided by probabilistic models of backbone and side chain conformations (). The first protein, adenylate kinase (PDB 4AKE) (), catalyzes the AMP+ATP  2ADP reaction and undergoes significant conformational changes during its catalytic cycle, making it a prime target for protein dynamics simulations. The protein is 214 residues long and has an / fold. The second protein, Candida antarctica lipase B (CalB), is an enzyme with industrial applications, (PDB: 1TCA) (). The CalB protein also has an / fold, but is significantly longer with 317 residues. For two ensembles, the compactness and the hydrogen bond network of the native state were enforced using Gaussian restraints, resulting in a 'native ensemble'. For the third ensemble, no such restraints were imposed, resulting in an 'unfolding ensemble'. All simulations were performed using the PHAISTOS package () and generated 1000 decoys each. Details on the simulation setup can be found in the Supplementary Material.illustrates the high correlation between the GIT distances and the corresponding RMSD values, especially for highly similar structures. The Pearson's correlation coefficient is 0.90 for the adenylate kinase unfolding ensemble, 0.74 for the native ensemble of the same protein and 0.90 for the native ensemble of CalB.In a second test, we investigate whether GIT can detect structural similarities in a diverse set of protein structures, in terms of both fold and protein length. First, we converted the entire Structural Classification of Proteins (SCOP) () database into GIT vectors. We then removed all families with 30 or less members. The final dataset contained GIT vectors calculated from 52 876 structures.shows a projection of the SCOP dataset of GIT vectors after principal component analysis (). As expected, the all  and all  fold classes are indeed well separated, with the mixed  and  classes located in between the two.
Rebuilding the SCOP hierarchyThe SCOP database organizes known protein structures into a hierarchy describing the folds (). The SCOP database is organized in four hierarchy levelsclass, fold, superfamily and familyand contains a total of 110 800 domains from 38 221 Protein Data Bank (PDB) () entries in version v1.75 from June 2009. In order to illustrate the capabilities of Pleiades, we start with an evaluation that involves a large number of protein structures and a clear biologically relevant goal: the automated detection of protein folds. More specifically, we compared the results of our clustering method with the fold classification in the SCOP database (). We extracted and converted all domains present in the current release of SCOP into GIT vectors. For the clustering test, we limited ourselves to domains from the main SCOP classes all , all , + and /, since multichain complexes as well as small peptides are beyond the scope of this algorithm. We further removed very small families, with less than five members, and structures with problems in the conversion, for example due to missing atoms. In total, we included 63 864 domains from 1436 families and 823 superfamilies.In order to investigate the quality of the clustering, we calculated the sensitivity, specificity, correct classification rate (CCR) and the adjusted Rand index. The sensitivity and the specificity are defined as the ratio of the detected true positives and the entire positive set, and the ratio of the detected true negatives and the entire negative set, respectively: sensitivity = TP TP+FN specificity = TN TN+FP where TP is the number of true positives or correctly clustered structures, FN is the number of false negatives or incorrectly clustered structures, TN is the number of true negatives or correctly discriminated structures and FP is the number of false positives or incorrectly discriminated structures. For a perfect clustering, both values are one. The CCR is the ratio of correctly classified structures over all structures, which has been used to evaluate the results of protein structure clustering before (). We considered a structure as correctly clustered when it was assigned to the same cluster as the majority of the members of the same family. The adjusted Rand index (ARI) () is a measure of the similarity of two clustered sets. Unlike the classic Rand measure (), the ARI takes the chance of a correct or incorrect random assignment into account, which is especially important in cases of large datasets with numerous clusters. The sensitivity (, dash-dotted line) decreases as the number of clusters increases, because more structures belonging to the same SCOP family end up in different clusters. The specificity in our tests is very close to one (, medium dashed line), since there is a large number of structures that are correctly discriminated; the number of structures that are incorrectly clustered together becomes almost insignificant. This indicates that the GIT measure is able to discriminate different structures well (high specificity), but sometimes struggles with detecting similar structures (lower sensitivity). This test is challenging because members of the same fold family can have different chain lengths, which is a known difficulty for the GIT measure (). According to the CCR (, small dashed line), the number of correctly assigned structures increases as k decreases. When setting the number of clusters equal to the number of families (1436) in the dataset, the CCR is 67.2%; when setting it to the number of superfamilies in the set (823), 74% of the structures are assigned to the correct cluster (, small dashed line). In our test, the classic Rand measure followed the specificity and was very close to one (not depicted). We then turned to the ARI (, black line), which indicates that optimal clustering occurs around k = 400. The large number of clusters and the often relatively small cluster sizes, many with 10 or less members, form a difficult task for the algorithm. From k = 600 and upwards, there is an excess of clusters available, which results in empty clusters. However, the test shows that clustering such a large number of structures into a large number of clusters is indeed feasible and yields meaningful results.
Page: 513 510515
Pleiades
Clustering improves decoy selectionIn the following test, we show the applicability of Pleiades in the context of protein structure prediction. We also investigate the applicability of K-means clustering in the context of protein structure clustering in general. The clustering task here is somewhat different since all the structures are structural variations of the same amino acid sequence, and thus all have the same length. Additionally, we are only interested in a relatively small number of well-populated clusters. Also, the suitable number of clusters k is usually unknown. Many structure prediction procedures use a Markov chain Monte Carlo approach and therefore generate decoys that are not fully independent. This often leads to clusters that are interconnected, which renders the evaluation more difficult, since there is not necessarily a clearly correct or incorrect cluster assignment possible for each decoy. The purpose of clustering decoy structures is to improve the decoy selection for the final refinement (). Thus, we evaluate the performance of Pleiades by comparing the cluster centroids obtained from Pleiades, and those from the state-of-the art clustering tool Calibur, to the native structure. Additionally, we also investigate whether the K-means clustering procedure in general is applicable in the context of protein structure clustering. Therefore, as a baseline, we implemented an RMSD-based K-means clustering procedure. All results are given in  RMSD to the native structure. Due to excessive computational demands, Pleiades RMSD was only applied to decoy sets with 12 500 or less decoys. We used a decoy set generated by) (http:// zhanglab.ccmb.med.umich.edu/decoys/), which we will call the iTasser set, that has been used to evaluate protein structure clustering as before (). The decoy set consists of 56 folding simulations with a varying number of decoy structures generated per simulation.shows the clustering results on each decoy set. We applied Pleiades clustering with the number of clusters k set to 10. All results Page: 514 510515are given in  RMSD to the native structure for the best centroid of the first five clusters reported (). On average, the Calibur and Pleiades perform equally well, with a difference in the average result of <0.1 . The differences between the clustering programs are within 0.5  of each other, with few exceptions. The dependency of the clustering result on the initial seed is often stated as a problem of K-means clustering. Therefore, we repeated the previous exercise, but chose the initial seeds using the K-means++ algorithm.shows the results for clustering with k = 10. The smarter seeding leads to equal or better results in 66% of the cases compared with the regular K-means approach. The Supplementary Tables ST1 through ST4 show the clustering result for varying values of k. The choice of the number of clusters appears to have little effect; the average difference between k = 5 and k = 20 is within 0.1 . Note that for the final selection of the decoys, only the five highest ranked cluster centroids were considered, regardless of the value of k. We implemented a K-means clustering procedure that uses the standard distance measure between protein structures, the RMSD. The exact description of the approach can be found in the Supplementary Material. Since the RMSD evaluation is computationally expensive, we ran this test only for the smaller decoys sets.lists the results of these tests which are on par with both Pleiades and Calibur, showing that the K-means approach using the RMSD as exact distance measure provides state-of-the-art clustering results. This finding also suggest that the K-means approach is capable of compensating for potential loss of information due to the approximative GIT description.
T.Harder et al.
Computational performanceUsing GIT vectors instead of the detailed atomic positions in combination with K-means clustering allows Pleiades to be fast, even for large datasets. All the tests for this study were performed on a common desktop PC (2.7 GHz, AMD Dual Core 5200+) with 4 GB of main memory. Pleiades relies on the precalculation of the GIT vectors, which takes some additional time. We argue, however, that in a typical scenario of a folding study, this does not pose a problem, as the GIT vectors can be calculated in parallel with the actual simulation. Secondly, once converted, different clustering experimentsfor example, using different values for kcan be quickly conducted. The calculation of the GIT vectors can easily be parallelized on multicore systems, for example by using tools like GNU Parallel (http://www.gnu.org/software/parallel/). Software for the convenient conversion of PDB files to GIT vectors is included in the program package (see Section 5).lists run-times for a number of randomly selected decoy sets with different sizes and protein lengths from the iTasser set. All run-times were measured in seconds for a single core process. The table shows that Pleiades is at least one order of magnitude faster than Calibur. Even when including the conversion time, Pleiades is still faster in three cases, comparable in one and only significantly slower for the smallest sets. All times are measured in seconds and all calculations were performed on a single CPU core on an otherwise idle machine.
Page: 515 510515
Pleiades
CONCLUSIONIn this article, we present Pleiades, a novel approach to protein structure clustering using the GIT representation. Pleiades is able to quickly cluster a very large number of protein structures, a task that is highly relevant in the context of protein folding simulations. Using the efficient GIT representation, we were able to successfully cluster up to 1 million decoys resulting from protein folding studies on a common desktop computer in a few hours. One of the main advantages of Pleiades is its computational speed. The program is able to cluster the output of a regular folding simulation, up to 50 000 structures, in a matter of seconds runtime, while maintaining an accuracy comparable to state-of-the-art programs. In order to use the convenient GIT representation of the protein fold, some preprocessing is necessary; all structures must first be converted to GIT vectors. Folding studies usually run for extended periods of time, occasionally saving structures to disk. The conversion of a single structure takes fractions of a second and can be performed in parallel with the actual folding simulation. The benefits of Pleiades are 2-fold: the increased efficiency and reduced memory consumption. Pleiades redefines the limits of how many protein structures can be clustered, routinely dealing with several hundred thousand structures in minutes run-time. At the same time, conventional clustering tasks involving only tens of thousands of structures can be performed in a few seconds, while maintaining an accuracy on par with state-of-the-art clustering methods. Because of these features and the availability of an implementation under an open-source license, Pleiades timely addresses a current bottleneck in structural bioinformatics.
AVAILABILITYPleiades was developed in C++ as part of the Phaistos package () and is freely available from sourceforge (http://sourceforge.net/projects/phaistos/) under the GNU General Public License.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
