Motivation: A perennial problem in the analysis of environmental sequence information is the assignment of reads or assembled sequences, e.g., contigs or scaffolds, to discrete taxonomic bins. In the absence of reference genomes for most environmental microorganisms, the use of intrinsic nucleotide patterns and phylogenetic anchors can improve assembly-dependent binning needed for more accurate taxonomic and functional annotation in communities of microorganisms, and assist in identifying mobile genetic elements or lateral gene transfer events. Results: Here we present a statistic called LCA* inspired by Information and Voting theories that uses the NCBI Taxonomic Database hierarchy to assign taxonomy to contigs assembled from environmental sequence information. The LCA* algorithm identifies a sufficiently strong majority on the hierarchy while minimizing entropy changes to the observed taxonomic distribution resulting in improved statistical properties. Moreover, we apply results from the order-statistic literature to formulate a likelihood-ratio hypothesis test and p-value for testing the supremacy of the assigned LCA* taxonomy. Using simulated and real-world datasets, we empirically demonstrate that voting-based methods, majority vote and LCA*, in the presence of known reference annotations, are consistently more accurate in identifying contig taxonomy than the lowest common ancestor algorithm popularized by MEGAN, and that LCA* taxonomy strikes a balance between specificity and confidence to provide an estimate appropriate to the available information in the data. Availability: The LCA* has been implemented as a stand-alone Python library compatible with the MetaPathways pipeline; both of which are available on GitHub with installation instructions and use-cases
INTRODUCTIONThe rise of next-generation sequencing technologies has generated a tidal wave of sequencing projects in natural and engineered ecosystems, resulting in a plethora of environmental sequence information. Several software pipelines, including MG-RAST (Meyer * to whom correspondence should be), HUMAnN (), and MetaPathways () have been developed to process environmental sequence information, provide taxonomic and functional annotations and assist in metabolic pathway reconstruction. Despite the availability of these pipelines, accurately assigning taxonomy to environmental sequence information remains a challenging enterprise given a general lack of reference genomes for most uncultivated microorganisms. From a bioinformatics perspective, current software tools lack statistical frameworks and hypotheses tests for the assignment of reads or assembled contigs to discrete taxonomic bins leaving developers and investigators with limited theoretical direction (). Due to the popularity of the MEGAN software, the lowestcommon ancestor (LCA) method is routinely applied to individual open reading frame (ORF) annotations with a correction based on homology search quality statistics (). While using LCA to assign individual ORF taxonomy seems straightforward, it is unclear how to effectively apply this rule to contigs or scaffolds containing multiple ORFs. Consider an alternative perspective of electing a representative taxonomy where each qualifying ORF annotation 'votes' for overall contig assignment. In this election individual ORFs may have differing 'taxonomic opinions', projecting their vote differently onto the Tree of Life. Two popular Voting Theory results provide justification in choosing a majority as the correct response. Condorcet's Jury Theorem considers an election of two opinions, one correct and one incorrect, and voters each independently choose one of these two opinions with the assumption that they choose the correct response with probability p > 1 2 (). The observed majority converges in probability to the correct decision as the election size grows to infinity. Alternatively, Feige and colleagues studied the depth of noisy decision trees where each query at a node produces the correct answer with some probability p > 1 2 (). They derived tight bounds on the number of queries required to compute threshold and parity functions, and analyze a noisy comparison model with tight bounds on comparison, sorting, selection, and merging. However, applying these Voting Theory methods to taxonomic count data is complicated by the hierarchical definitions. For instance, individual ORFs predicted on the same contig may be assigned to different
1
Associate Editor: Prof. Alfonso Valencia The Author(s) 2016. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com taxonomic levels within closely related lineages, e.g. species, subspecies, strain, or serovar. The approximate nature of popular homology search algorithms and idiosyncratic database annotation increases uncertainty in taxonomic estimation from functional genes, making accurate placement on the taxonomic hierarchy a challenge. Moreover, sparse observations of multiple related taxa can undermine confidence in the reported majority. Here we introduce LCA*, an entropy-based statistic and algorithm for declaring a sufficiently supported majority on the NCBI Taxonomic Database Hierarchy (NCBI Tree) (). The statistic offers a principled method of electing a majority taxon by applying results from Information and Voting Theory to contig or scaffold annotations, obtaining an acceptable majority while minimizing changes to the underlying taxonomic distribution. Moreover, order-restricted statistical results can be used to provide supremacy tests for an elected taxonomy as an alternative to traditional -squared uniformity tests. Using both simulated and real world datasets we demonstrate that in the presence of reference known reference alignments, voting-based methods of simple Majority and LCA* are consistently more accurate than the conventional LCA algorithm popularized by MEGAN, hereafter referred to as LCA 2 , and that LCA* taxonomy strikes a balance between specificity and confidence to provide an estimate appropriate to the available information in the data.
MotivationLets work LCA* through an illustrative example where taxonomic annotations are quite variable and dispersed (). A simple Majority method, choosing the taxonomy with the most annotations may be intuitive, but a majority of 3 out of 11 taxa is not very convincing. Alternatively, to combat this dispersion it might be a good idea to elect the LCA as the majority, but this very conservative estimate manifests limited resolving power (e.g., root, prokaryotes, etc.). In the case of individual ORF annotations, LCA estimates would be made less extreme by discarding annotations that do not meet certain quality thresholds, on the evolutionary assumption that hits to taxa phylogenetically further away from the origin will be less similar. However, in the case of assembled environmental sequence information, e.g., contigs or scaffolds, this is often not an option, because common practice summarizes annotations via some taxonomic estimation method (e.g., Best-BLAST, LCA). LCA* takes a bottom-up approach by expanding the specific simple majority estimate upwards in the taxonomic hierarchy, progressively collapsing annotations until a satisfying majority, an -majority, is obtained. Here we can leverage relevant Voting Theory results like Condorcet's Jury Theorem and the work of Feige on noisy decision trees to justify a proportion  > 1 2 . However, there remains the issue of how to collapse the tree automatically, as collapsing arbitrarily can introduce significant bias. Here we will use the information-theoretic interpretation of entropy to motivate an algorithm of collapsing annotations in a principled way. Since the application of information entropy is relatively rare in microbial ecology outside of diversity estimation (), we will provide a brief introduction that will help in the understanding and motivation of LCA*. Entropy (Shannon's Entropy) is the fundamental unit of information defined as the average amount of information needed to specify the state of a random variable. Intuitively it can be described as a measure of uncertainty. The uniform random variable, a situation where all outcomes are equally likely has the highest possible uncertainty, and therefore the highest entropy, while a more spiked random variable has less uncertainly, and therefore less entropy. Entropy is an extremely useful concept, and has been central to the development of coding theory (e.g., file compression), cryptography, and signal processing (). Moreover, differences in entropy (also known as Relative Entropy or the Kullback-Leibler divergence) are used as a measure for the divergence between two probability distributions (). For example, in Machine Learning, Random Forest classifiers use entropy as a measure of separation quality, and it is used to identify the most discriminating separations in a hierarchy of classifier models (). The LCA* algorithm, uses the concept of entropy to measure the amount of change that collapsing annotations up the tree to a particular node will cause, calculating an -majority while minimizing the change in entropy of the taxonomic distribution as much as possible.
LCA*: DERIVATION AND ALGORITHMIn order to reason clearly about assembled environmental sequence information, annotations, and taxonomy within the NCBI Tree, it is first necessary to construct a mathematical framework that defines them, their relationships, and describes any additional notation needed to perform the entropy calculations and implement the algorithm. First, we will describe notation for the inherent treestructure of the NCBI Tree, and add some specific notations for child nodes and child sub-trees that will be useful when calculating the entropy of annotations within the tree. Next, we will describe assembled environmental sequence information from contigs or scaffolds, predicted ORFs, and annotations, and define what it means for a particular set of annotations to have a sufficient -majority. To facilitate the collapsing of annotations up the taxonomic hierarchy, we will define an annotation as having a taxonomic lineage in terms of partially-ordered sets, which will allow us to define phylogenetically-valid transformations among observed annotations. In particular, we will define consistent reductions to be a special kind of transformation for collapsing all annotations within a sub-tree up to its root node. Having devised clear methods for moving annotations around the tree, we will then define the entropy of the tree in terms of its annotations collapsed at a particular node. From here we will make a key observation that the entropy of annotations collapsed at a given node can be decomposed to the sum of itself and its children. Using this new decomposition to formulate the difference in entropy between two annotations, we observe that minimizing the difference is equivalent to minimizing the entropy of the node we choose to move to, an observation that will be extremely useful in formulating an efficient algorithm. Reasoning that we can calculate the change in entropy of annotations collapsed at every node, there must be some node with annotations that has both a valid -majority and a minimal entropy change compared to all other nodes n the tree. This node is the target LCA*. Finally, we formulate an algorithm to calculate LCA*. We first describe a brute-force method of finding the valid node, and then observe that a node-coloring scheme restricting calculations to observed annotations significantly reduces computational complexity. metagenome, and every ORF in R is by way of some annotation associated with a taxonomic node x  X on TNCBI. Let ORFs that came through the annotation procedure without a known taxonomy be set to 'root' at node x * . In other words, every predicted ORF in a contig has a corresponding taxonomic annotation, which is set to 'root' if it did not find an acceptable hit in the annotation database. Suppose contig C has the set of N ORFs OC = {o1,. .. , oN } with a corresponding n-tuple of annotations AC = (a1,. .. , aN ) where annotation ai corresponds to ORF oi  OC for i = 1,. .. , N. We use the notatio A to denote the set of annotations in the n-tuple A, with the set of annotations from contig C being detonated asACas asAC. We need to determine or elect a taxon from annotationsAannotations annotationsA to label contig C. One straight-forward method might be to use a simple majority vote procedure on the taxonomic assignments for each ORF on contig C, AC. However, there may not be a simple majority among taxa AC , or even a majority with a minimum proportion of the votes , where  > 1 2 , a so-called -majority. DEFINITION 1 (-majority). Given an n-tuple of annotations A, for any  > 1 2 we say that A satisfies an -majority if there is a taxon a  A that constitutes at least -fraction of the elements. Conversely, if no such taxon a exists then we say annotations A does not satisfy an -majority.Clearly, given two proportions  and   such that     > 1 2 , if some annotation n-tuple A has an -majority, then by transitivity it implies that A also has an  -majority. It might be possible to obtain an -majority by replacing annotations A with modified annotations A  , where each taxon a is replaced by one of its ancestral taxa a  , and define such a relationship as a partial order on taxa as a  a, where a, a   X. For example, if a is Alphaproteobacteria, a  could be Proteobacteria or some other ancestor of a all the way to the root x * . Clearly, it is always possible to create a majority by replacing each taxon a  A with the root x * . However, this trivial result has limited resolving power, as we have lost almost all taxa-specific information about contig C other than " C came from LUCA. " In fact, any modified set of taxa A  essentially represents some loss of taxon-specific information from A. Therefore, we would like to formulate a way to quantify this loss of information in a principled way such that we can design an algorithm to construct an -majority while minimizing the amount of information loss required to attain it.
...
Fig. 2. The NCBI taxonomy tree structure used in our derivation.Nodes represent taxons and a line between two nodes shows taxonomic relationships. Tx denotes the sub-tree of T N CBI rooted at x and y 1 , y 2 ,. .. , ys are the immediate children of x.To formulate this problem, we need to extend the definition of the partial order to n-tuples as follows. We will now denote some specific transformations on an n-tuple of taxa that we call reductions:(i) For any two taxa a, a   X we denote the reduction of a to a  as a  a  , such that, a  a. If there exists an annotation a  such that a  a then either a  is equal to a or a . In other words, a  is either a itself or in its lineage. When a is reduced to a  through a  a       a  then we denote such a multistep reduction of a to a  as a *   a  .(ii) We define the partial order relation r for n-tuples A and A  as: A  r A if for every pair of elements a and a  from A and A  , at the same index positions, satisfies the relation a  a. Then we denote by A  A  to mean for every corresponding element a (in A) and a  (in A  ) we have a  a  ; and by A *   A  we denote the fact that for every corresponding pair of elements a (in A) and a  (in A  ) we have some series of transformationsWe define annotation n-tuple A  to be consistent if for every pair of annotations a and a  from A and A  we have a a  and a  a. Thus, we define a consistent reduction to be any reduction A  A  , and similarly, a set of consistent reductions as A *   A  where this condition holds. This consistency condition is imposed in order to not bias a taxon in terms of its depth on the NCBI Tree (measured from the root node). For example, if for annotations A  (a1, a2), where a1 = Alphaproteobacteria and a2 = Proteobacteria, then A does not preserve consistency since a2 a1. However, annotations, then annotations A  preserves consistency. Intuitively, we can view a consistent reduction A  A  as a reduction of all annotations descending from x to x, or in other words, the collapsing of all annotations corresponding to a sub-tree of x to x. Let's note some observations about the reduction of annotation ntuples. Every reduction step for an annotation n-tuple A to another n-tuple A  , A  A  , A  is less specific with respect to A. It is important to realize that A  can not convey any new information about A. Moreover, for any annotation n-tuple A, there exists a reduction A *   A  where A  respects -majority for some  in the interval ( 1 2; note that A  = A * , where A * is the n-tuple where every element is the root x * , can always provide a possible solution. Therefore, if annotation n-tuple A does not have a majority, there exists an A  that has -majority and A *   A  , i.e., a sequence of single step reductions A  A1      Ak  A . For a given A there may be multiple solutions to take the position of A  , and in such cases we would like to pick the candidate that loses the least amount of taxonomic information. In this case, we assume that information-theoretic entropy and biological " taxonomic information " coincide. We must now define entropy of taxonomic annotations A.
DEFINITION 2. Given annotation n-tuple A and nodex in TNCBI , we define entropy H(x; A) as H(x;is the unique set of elements in A, r A (z) is the number of annotations i A that are taxon z, and N is the length of the annotation n-tuple A. Having defined our reductions and tree entropy given annotation ntuple A, given an acceptable majority proportion threshold   (0.5, 1], we can now formulate a minimal entropy reduction on A to an -majority satisfying A  .In order to find an annotation n-tuple A  that has an -majority and minimizes the change in entropy, it is sufficient to replace some subset of A, S, by the lowest common ancestor of all taxa a in S, i.e., a s for all s  S. If there exists another a  such that a  s for each s, this implies a  = a, (i.e., the lowest common ancestor of S is unique). Therefore, one brute-force way would be to compute the change in entropy for all valid transformations H(x; A, A  )  H(x; A)  H(x; A  ) at every node x. Next we will expand on and define some simplifications of entropy H(x; A) and change in entropy H(A, A  ), that will prove useful in the actual construction of the LCA* algorithm. Notice that entropy can be written
DEFINITION
LCA*: an entropy-based measure for taxonomic assignment within assembled metagenomes
...
Fig. 3. Decomposition of entropy into sub-trees.A key observation in our derivation is that the entropy of annotation A in a tree rooted at a given annotation node x, Tx, can be decomposed into the sum of node x and the nodes of its immediate children's subtrees (y 1 , y 2 ,. .. , ys) as Xx = {x}  yYx Xy. From here we can decompose the calculation of entropy H(A) in the same partition.where r A (z) refers to the number of annotations assigned to taxon node z. Similarly, observing that the set of annotations in a sub-tree at x, Xx, can be partitioned as the union of itself and the nodes in its immediate children's sub-trees Xx = {x}  yYx Xy, we can partition the entropy of a set of annotations as follows:otherwise. Note that we decomposed the entropy into two main terms, the entropy of node x, r A (x) log r A (x), and the sum of the entropy terms of its immediate children's trees,). From here we can express the change in entropy H(A, A  ) on a consistent reduction of annotations A  A  asSince we are interested in an A  that minimizes H(A, A  ), note that all terms corresponding to A in the above relation remain constant. We can simplify the calculation by focusing on finding an A  such that A  is a consistent reduction of A and minimizesbased on which we will design our algorithm. We will now show that such a transformation to A  exists for any given starting annotations A. PROPOSITION 1. Suppose A is any n-tuple of annotations, then for any  > 1 2
there exists a taxonxtaxon taxonx and a consistent reduction ofA to some n-tuple A  , such that (i) A  respects -majority,(iii) A and A  only differ in the elements wher x is in A  .PROOF. Note that in the above proposition it is easy to show the existence of a taxonxtaxon taxonx that satisfies conditions (i) and (ii). This is becaus x = x * is a trivial solution that satisfies condition (i), and the set of candidates that satisfies A  is non-empty, hence here exists a taxon that satisfies condition (ii). In order to realize (iii), note that since A *   A  and A  has an -majority, therefore, there exists an annotatio x in A  which is at least  fraction of all elements in A . Since the reductions A *   A  are consistent, we can achieve the  majority by simply collapsing the annotations that are descendants ofxof ofx in TNCBI , or specifically, for all annotations a  A wherex where wherex a, a *    x.
AlgorithmSince we have outlined a mathematical framework defining majority, consistent reductions on the NCBI Tree, and a recursive definition of the entropy of annotations A = (a1, a2,    , aN ) on TNCBI , we can now focus on designing and implementing an algorithm, ComputeLCA*, that calculates an -majority for a given contig C while minimizing changes to its underlying information entropy. The input to ComputeLCA* consists of the NCBI taxonomy tree TNCBI , and the n-tuple of ORF annotations A for the ORFs in a contig C, and the threshold  that defines the majority (Algorithm 1). Since we are interested in the taxon that minimizes the change in entropy H(A, A  ), our algorithm is designed to exploit the recursive nature of traversal in the TNCBI as well as the recursive delta entropy term (Equation 1). We use the global hash data-structures Sand Lfor every node x  X. Sstores the sum of annotations at node x at its collapsed sub-tree x   Xx, and similarly Lstores the sum of entropy terms r(x  ) log r(x  ) for each node in the subtree of x   Xx, i.e., H(x; A, A  ) at a given x. ComputeLCA* starts at the root x * and recursively traverses TNCBI , calculating sums of L and S at all nodes. The algorithm then selects the sum that minimizes the relative entropy and also has sufficient support .
ImplementationComputeLCA* for a typical number of annotations on a contig does not take more than a few hundred milliseconds, but the described brute-force method traversing the entire NCBI Tree is computationally inefficient, and for samples with hundreds of thousands of contigs the total computation time could be large. Therefore, in the implementation of thefor each c in Children(x)ComputeLCA*, a key optimization step is incorporated that skips the examination of subtrees where no annotations exist. Consider the set of N ORFs and corresponding set of N annotations originating from contig C. Let M be the total number of taxonomic nodes in TNCBI. Then according to ComputeLCA*, it can take O(M N ) steps to compute the LCA* taxonomy for C. Note that at line 14 of ComputeLCA*, it is redundant to visit the sub-tree rooted in the child node stored in loop variable c if there are no annotations in the sub-tree. However, in order to know if annotations are present in a given sub-tree of TNCBI , before running ComputeLCA*, we color all nodes whose subtree contains a non-empty set of annotations. We mark the nodes by considering one annotation at a time, say a, and mark the nodes as follows:(i) we start at the node a in TNCBI and travel upwards towards the root one parent step at a time;(ii) in each step, if the current node p is not marked then mark p, and move to its parent (if present), otherwise we are done with annotation a; (iii) if the parent is already marked we are done with annotation a. We now describe the relative computational complexity after our optimization. Consider the partially ordered set (  A, ) of annotationsAannotations annotationsA on TNCBI , and suppose L is the size of largest subset S ofAof ofA such that any two annotations in S are not comparable via to each other. Our modified algorithm therefore takes (DL) steps to mark the nodes in the upfront step, where D is the maximum treedepth in our set of annotationsAannotations annotationsA  TNCBI. Since we only visit nodes that have been colored at line 14, our modified algorithm has time complexity O(DL). Although the worst-case time complexity could still be O(M N ), where the annotation-breath spans the entire TNCBI , i.e., D = M and L = N , most real-word contig annotations tend to coalesce around common lineage in the NCBI Tree. This makes L < N and D << M , and hence real-world running time O(DL) is typically much smaller than O(M N ).
STATISTICAL SIGNIFICANCEAlthough LCA* represents an -majority taxonomic estimate, this majority might not have statistical confidence, especially for smaller contigs with only a few ORFs. Here we apply a multinomial 'supremacy' p-value to measure the statistical confidence of the elected taxonomy (). More details on the mapping of LCA* to the hypothesis test and its implementation can be found in Supplementary file 1, Section S1.
METHODSSimulated samples, parameter settings, distances, and analytical methods used in the performance analysis of LCA* can be found in Section S2 of Supplementary File 1. A RMarkdown document containing the code of this analysis can be found in Supplementary File 2.
RESULTSThe performance of LCA* was compared against two other taxonomic estimation methods, LCA 2 and Majority. LCA 2 is the application of the LCA algorithm to the taxonomic annotations of a contig, while Majority is a simple majority method where taxonomy is ascribed to the most number of annotations (Supplementary File 1, Section S2). We evaluated the relative prediction performance of the three methods against two sets of simulated metagenomic contigs (with and without target genes in the annotation database) and one set of contigs from 201 microbial " dark-matter " (MDM) single-cell Amplified Genomes (SAGs) obtained from the Genomic Encyclopedia of Bacteria and Archaea (GEBA) MDM project (), a United States Department of Energy Joint Genome Institute (JGI) initiative for sequencing thousands of bacterial and archaeal genomes from diverse branches of the Tree of Life (Section 4). In general, the voting-based measures Majority and LCA* outperformed LCA 2 using both the Simple-walk and weighted taxonomic distance (WTD) distances (see methods). In both the Small (10  100 randomly sampled contigs from 100 taxa) and Large (10  2000 randomly sampled contigs from 2000 taxa) simulations, as well as the GEBA MDM contigs, LCA* and Majority had Simple-walk distances closer to zero when compared with LCA 2 (). With reference annotations removed from the target database, distances of all three measures were significantly increased in magnitude and variability, with voting based measures offering only a marginal improvement (). A similar pattern was observed with the WTD, but here LCA 2 is more penalized for predictions widely outside their original taxonomic lineage. Here, LCA 2 predictions near the root caused a cluster of negative WTD values in the GEBA MDM contigs (). Again, the removal of reference annotations increased WTD distances in terms of magnitude and variability, with the voting-based measures offering relatively minor improvement (). From a regression analysis perspective, it is also possible to express these distances as error measurements, and calculate the Root-mean squared error (RMSE) as a measure of accuracy (). Here the voting-based methods exhibited smaller RMSE values in all cases, but were only significantly different at the 95% confidence level in the Large simulation and GEBA MDM contigs when measured by the WTD. Without reference annotations there was a trend to smaller RMSE values in the voting-based methods, but there was no significant has numerous impossibility results that challenge all three of the common-sense principles of voting: preserving majority rule, requiring a minimum level of core support, and rewarding sincere voters (). " Taxonomic reconciliation " between NCBI Tree entries and ribosomal RNA gene or COG alignments (akin to methods recently implemented in PhyloSift ()) would allow for an apples-to-apples comparison between taxonomic and functional marker gene binning methods, e.g., ML-TreeMap, MetaPhlan (), support more powerful integrative alignmentdependent binning models, and facilitate principled placement of taxa from one tree into the other.
CONCLUSIONSThe LCA* algorithm assigns taxonomy to contigs assembled from environmental sequence information using the NCBI Tree. The algorithm identifies a sufficiently strong majority on the hierarchy while minimizing entropy changes to the observed taxonomic distribution resulting in improved statistical properties. The algorithm and its statistical tests have been implemented as a standalone Python library compatible with the MetaPathways pipeline; both of which are available on GitHub with installation instructions and use-cases (http://www.github.com/hallamlab/LCAStar/).
Bioinformatics Advance Access published August 11, 2016 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from Hanson et al.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from LCA*: an entropy-based measure for taxonomic assignment within assembled metagenomes 3 2 1 1 2 1 1 Majority LCA* LCA 2 Fig. 1. Illustrative example of taxonomic assignment methods: LCA*, Majority, and LCA 2. Node numbers indicate the number of annotations associated with each taxonomic position in the tree, and the double-circled node is the actual originating taxonomy. In many multi-omic samples, annotations can be variable, spanning a number of different positions in the tree. In this example, LCA 2 provides a conservative estimate, while the simple Majority method provides a specific taxon without very much support from the data. The LCA* tempers the Majority estimate by collapsing annotations up the tree in a principled way until a sufficient -majority is reached ( > 0.5), distributing the entropy of the underlying taxonomic distribution as little as possible. 2.1 Derivation Let the NCBI Taxonomic Database Hierarchy be a tree TNCBI , where the nodes x represent taxa and edges represent phylogenetic relationships. Let X denote the set of all nodes in TNCBI , X = {x1, x2,. .. , xM }, where M is the total number of taxa in TNCBI (including taxa at internal nodes). Next, let Tx denote a sub-tree within TNCBI rooted at node x. Let the set of nodes in sub-tree Tx be denoted Xx, allowing a complete recursive notation for all trees and sub-trees of TNCBI (Figure 2). As a special case we will denote the root node of TNCBI as x * , and it follows that X  Xx * . It will be convenient to discuss the children of a given node x  X, so let the set of immediate children of node x be Yx = {y1,. .. , ys}, where s is the number of immediate child nodes of x. Further, the set of immediate children of x have respective subtrees Yx = {Ty 1 , Ty 2 ,. .. , Ty s }, where each child sub-tree has the set of nodes Xy 1 , Xy 2 ,. .. , Xy s. A node x is a leaf node if it has no immediate children, i.e., Yx =  and Yx = , otherwise x is a non-leaf node. Next, let us describe assembled contigs, ORFs, and their taxonomic annotations. Let R be the set of ORFs in the
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from Hanson et al.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from Hanson et al.
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
