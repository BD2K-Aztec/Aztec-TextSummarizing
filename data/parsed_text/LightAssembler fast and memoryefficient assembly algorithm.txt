Motivation: The deluge of current sequenced data has exceeded Moore's Law, more than doubling every 2 years since the next-generation sequencing (NGS) technologies were invented. Accordingly, we will able to generate more and more data with high speed at fixed cost, but lack the computational resources to store, process and analyze it. With error prone high throughput NGS reads and genomic repeats, the assembly graph contains massive amount of redundant nodes and branching edges. Most assembly pipelines require this large graph to reside in memory to start their workflows, which is intractable for mammalian genomes. Resource-efficient genome assemblers combine both the power of advanced computing techniques and innovative data structures to encode the assembly graph efficiently in a computer memory. Results: LightAssembler is a lightweight assembly algorithm designed to be executed on a desktop machine. It uses a pair of cache oblivious Bloom filters, one holding a uniform sample of g-spaced sequenced k-mers and the other holding k-mers classified as likely correct, using a simple statistical test. LightAssembler contains a light implementation of the graph traversal and simplification modules that achieves comparable assembly accuracy and contiguity to other competing tools. Our method reduces the memory usage by 50% compared to the resource-efficient assemblers using benchmark datasets from GAGE and Assemblathon projects. While LightAssembler can be considered as a gap-based sequence assembler, different gap sizes result in an almost constant assembly size and genome coverage.
IntroductionThe advent of next-generation sequencing (NGS) technologies has revolutionized the genomic research, but has not been able to provide a complete picture of a sequenced organism, since the relative positions of the billions of fragmented pieces are unknown without a genome assembly, which is a highly ambiguous overlapping puzzle (). De novo sequence assembly is an initial step towards downstream data analysis such as understanding evolutionary diversity across different species, evidenced by the multitude of data collection projects, including Genome 10K (). With the increasing efforts to sequence and assemble the genomes of more organisms, the assembly problem becomes more complicated and computationally intensive, especially with short inaccurate sequenced reads and genomic repeats (). Next-generation assembly algorithms play around two basic frameworks for efficiently completing their task: namely, De Bruijn and string graphs. In a De Bruijn graph, nodes are the set of distinct k-mers (substrings of length k) extracted from reads and the edges are the k  1  -overlap among them. The string graph is a simplified version of a classical overlap graph, where nodes are the sequenced reads and the non-transitive edges encode their suffix-to-prefix overlaps (). Many efforts have been made to fit the assembly graph into computer memory by the creation of resource-efficient genome assemblers. The term resource efficiency touches on both memory space and speed (). One compressed representation for a string graph is introduced in SGA () using FM-index and BurrowsWheeler transformation of the sequenced reads (). Recently, an incremental hashing technique combined with a probabilistic data structure (Bloom filter) revisited the string graph representation (Ben). The early condensed representation of De Bruijn graph is a sparse bit vector (), later implemented in a Gossamer sequence assembler (). This representation is changed in Minia () by introducing the exact representation of De Bruijn graph using the combination of a Bloom filter and a hash table that holds an approximate set of false positive nodes. The hash table is replaced in subsequent versions of Minia by a set of cascading Bloom filters for further space optimization (). The BurrowsWheeler transformation plays another role in the succinct representation of De Bruijn graph () by combining FM-index with frequency-based minimizers to reduce its complexity (). SparseAssembler () stores a subsample of k-mers in a hash table with their overlap links, recorded to maintain De Bruijn graph representation. ABySS () distributes the assembly graph nodes among different machines to reduce the representation complexity in a computer memory. Resource-efficient sequence assemblers vary in their assembly results in terms of both accuracy and contiguity measures. Each tool has a set of advantages and disadvantages according to the compromises made to achieve efficiency. Also, different evaluation studies () generally reported that the assembly algorithms differ in their outputs according to their working scenarios such as the quality of sequenced data and the complexity of the corresponding genome. There is a common conclusion that there is no one tool is best for all scenarios, and that there is still room for improvement in current assembly pipelines. In this paper, we revisit De Bruijn graph representation and introduce an optimized cache oblivious Bloom filter to the sequence assembly. Our method is inspired by Lighter's idea () to correct the sequenced errors using a pair of Bloom filters and a simple statistical test. Lighter stores a random sample of k-mers in a Bloom filter and uses them with a simple statistical test as seeds to classify the read positions as trusted or untrusted. While Lighter's goal is to use the trust-classified k-mers to correct erroneous ones, our ultimate goal is assembling these k-mers without error correction since they are already classified as trusted nodes (k-mers made by k consecutive trust-classified positions in the sequenced reads are considered to be trusted). LightAssembler obtains a uniform sample of k-mers by skipping g bases between the k-mers, where g is the gap length and stores them in a Bloom filter. The erroneous bases in a read will produce rare k-mers and are unlikely to survive in the sample compared to the abundant k-mers generated by the correct bases. The trustiness of a read position will be determined by comparing the number of k-mers that cover the position and appear in the sample to a statistically computed threshold. LightAssembler uses the k-mers made by k consecutive trust-classified reads positions as the set of assembly graph traversal nodes, while several assemblers rely on error correction modules to identify and correct the erroneous k-mers before starting the assembly process. The majority of error correction algorithms count the k-mers to determine their confidence and exclude ones with a multiplicity less than a specified threshold, which might result in missing a subset of true k-mers with low abundance. Other assemblers such as Velvet () rely on intensive graph simplification modules to resolve the erroneous structures introduced by erroneous bases such as tips and bubbles. Complex assembly pipelines combine both approaches and perform postprocessing graph filtering using mate pairs during scaffolding stage. LightAssembler uses only two passes over the sequenced reads to identify the approximate set of trusted nodes without error correction or intensive graph simplification modules. Also, one of the efficient representations of De Bruijn graph based on a Bloom filter is implemented in Minia and uses k-mer counting module to identify the set of trusted k-mers. Minia's counting algorithm follows a divide and conquer paradigm and utilizes the disk space as secondary memory storage. Our method is able to identify the set of trusted k-mers without utilizing either a counting module or disk-space overhead. We will present our comparable results to the current state-of-the-art sequence assemblers as well as resource-efficient ones using the simulated and benchmarked datasets.
Methods
Pattern-blocked bloom filterA Bloom filter () is a memory-efficient data structure for storing a given subset of elements K U. In the assembly context, K is a subset of k-mers and U is the whole set of sequenced k-mers. It supports approximate membership queries on K using a compact representation of its elements (i.e. k-mers). A Bloom filter has a feature of one-sided error, which means if the filter reports yes for an element e then either e 2 K or with a small 'false positive' probability e 6 2 K. On the other hand, if the filter reports no then necessarily e 6 2 K. The standard implementation of a Bloom filter is a zero-initialized bit array B with length m and y independent hash functions. To insert an element e 2 K in a Bloom filter, the set of indices H 1 e  ; H 2 e  ;. .. :; H y e   are computed and their corresponding bits in B are set to one, that is 8e 2 K; B H i e  1, where 1 i y. The membership queries are achieved by evaluating the same set of hash functions on an element e and testing their corresponding bits. If all B H i e  equal 1 then a Bloom filter answers yes and no otherwise. In a Bloom filter, each hash function has equal probability to choose a position in the bit array, so the false-positive rate p f for the bit array of size m with the number n of inserted elements is:By choosing appropriate Bloom filter parameters m and y, the false positive rate p f can be adjusted. The standard Bloom filter implementation is cache-inefficient since each insertion or membership query operation generates at most y cache misses. The cache-efficient variant of a Bloom filter () is implemented by a sequence of consecutive blocks, each of size b that can fit into one-cache line. In this implementation, the first hash function is used to choose the block number and the subsequent hash functions are performing in the same chosen block. Therefore, a blocked Bloom filter minimizes the cache misses to one rather than y for each operation. To improve the implementation further in terms of the computation time, the precomputed hash patterns are used to set all y bits at once rather than doing this separately in each block, which is called Pattern-blocked Bloom filter. In a Pattern-blocked Bloom filter, the false-positive rate can be computed using the following equation ():where B j j  m  b  1, size of a Pattern-blocked Bloom filter in terms of blocks; b, number of bits in one block; b 0 i , number of bits set to one in the i-th block; y; number of hash functions. The false-positive rate is increased in a Pattern-blocked Bloom filter compared to the standard implementation of a Bloom filter and the false positive generally can be managed using large m and y. LightAssembler uses the Pattern-blocked Bloom filter to hold a set of canonicalized k-mers extracted from the sequenced reads. The canonical k-mer is the minimum lexicographic k-mer of the k-mer itself and its reverse complement.
LightAssembler frameworkThe light version of an assembly algorithm can be viewed as the combination of two basic modules, graph construction and graph traversal as depicted in.
Graph constructionThe graph construction module has two stages, uniform k-mers sampling and trust/untrust k-mers filtering. The input to this module is the set of sequenced reads and the outputs are Bloom filter B and the trusted k-mers file. 2.2.1.1 Uniform k-mers sampling. The whole set of sequenced kmers are obtained using a sliding window of length k one base at a time across the input reads. The g-mers or g-spaced k-mers are obtained by skipping g bases between the k-mers. The gap values are in the range 1 g < L  k  1, where L is the length of the sequenced read. LightAssembler uses this uniform sampling process to store a sample of k-mers (g-mers) in Bloom filter A. A gap size is chosen by a user or computed by LightAssembler parameters extrapolation module. g-mers in Bloom filter A represent a 1=g sample of the nodes diversity in De Bruijn graph of the sequenced genome. Base-called errors of the NGS technologies are typically identified as unusual events and their corresponding erroneous k-mers are occurring less frequently than the correct k-mers under the assumption of deep uniform coverage (). The most abundant sequenced k-mers will survive in the sample stored in Bloom filter A and we will use them with a simple statistical test as seeds to mark each read position as trusted or untrusted.
Trusted/untrusted k-mers filtering. A trusted k-mer is defined as a k-mer made up by k consecutive trust-classified read positions and it is untrusted otherwise. Each read position is classified as trusted or untrusted based on the following idea with illustration in. Suppose that we have a sequenced read R  r 1 r 2 r 3. .. :r L , a read position r i is overlapping by maximum x i k-mers where x i is defined as the following:If a sequenced base r i is erroneously called, the overlapped x i kmers are all incorrect and occur rarely in the dataset. Accordingly, these incorrect k-mers are unlikely to survive in the sample stored in Bloom filter A. We define a statistically computed threshold for each read position r i such that if the number of overlapped x i k-mers appeared in the sample is less than the defined threshold, the read position r i is classified as untrusted. Otherwise the read position r i is classified as trusted (). The multiplicity of an incorrect k-mer in the sequenced reads has been modeled previously using Poisson distribution (). We will assume that the erroneous k-mers will occur at some rate k e  ce in the sequenced dataset and k 0 e  ce=g in the sample stored in Bloom filter A where c and e are the expected coverage and error rate of the sequenced reads, respectively. Suppose M e is a random variable for the number of times an incorrect k-mer appears in the sample:The probability of an incorrect k-mer appears in the sample p 0 is defined as:By considering the false-positive rate p f of Bloom filter A that stores a sample of k-mers, we redefine p 0 as:We compute a threshold t 0 k for each x i  k as the minimum integer that satisfies the following equations:Then for each x i 2 1; k  1, we define other t 0 xi thresholds as:
Graph traversalSince our goal is efficiently using the computational recourses to construct and traverse De Bruijn graph, we found the most optimized traversal algorithm for visiting and marking the graph nodes is implemented in Minia. We modified Minia's traversal algorithm according to LightAssembler graph construction method. There are two steps in the graph traversal module: (i) computing branchingk-mers and (ii) simplifying De Bruijn graph and extending the branching-k-mers (). The inputs to this module are Bloom filter B and the trusted k-mers file and the output is the set of assembled contigs. 2.2.2.1 Branching-k-mers computation. The traversal algorithm starts by computing the set of branching nodes (k-mers have multiple extensions) by querying Bloom filter B for each k-mer in the trusted k-mer file. We use this file to store the set of trusted k-mers to avoid the third iteration over the dataset that might introduce false-positive nodes. The file contains only the minimum set of trusted graph nodes in a binary format. The file is removed after the branching k-mers are computed and stored in a hash table, which serves as a recording structure for the visited branching nodes.
Graph simplification and branchingk-mers extensions. Every assembled contig represents a simple path starting from a branching node and ending with a marked branching node. Rather than marking every used node on a simple path that adds an additional space overhead, we only mark the branching nodes as terminal points for every simple path. The number of branching nodes also compared to the complete set of graph nodes is very small and depends on the genome complexity. Storing and marking only the branching nodes saves an additional space in LightAssembler implementation. The assembly graph has dead end paths called tips, LightAssembler removes the tips of length 2k  1 bases or shorter.LightAssembler also resolves the bubbles that represent the multiple paths started from a branching node by traversing them until the convergence point is reached and accordingly, LightAssembler finds the best consensus sequence that is expressed by all multiple branches. LightAssembler ignores solving the complex bubbles that might solve using the paired-end information encoded in the sequenced libraries.
LightAssembler usability and scalabilityLightAssembler has two parameters that a user must specify, a genome length G and a k-mer size k. A gap size g is an optional parameter, which can be set by a user or LightAssembler invokes the parameters extrapolation module to compute a gap size based on a sequenced coverage c and an error rate e. A user can utilize our suggested gap starting values presented in, which are computed based on the simulated datasets using different sequenced coverage and error rates. Also, the genome size and the k-mer size can be estimated using stand-alone tools such as KmerGenie () and KmerStream (). Moreover, LightAssembler is a multithreaded program with an optional parameter t to specify the number of working threads, where the default value is one, for more detail of parallelized implementation see Supplementary 1 Results, section 1.
ResultsWe evaluated the performance of LighAssembler against Minia v2.0.3 (), SparseAssembler () and ABySS v1.5.2 () using simulated datasets from the Escherichia coli reference genomewith different attributes listed in Supplementary 1. We also compared our results with the same assemblers, including Velvet v1.2.10 () using real benchmark datasets from GAGE () and Assemblathon 2 () evaluation studies, the characteristics of benchmark datasets are presented in Supplementary 1. LightAssembler, like the other chosen assembly tools, is a. LightAssembler graph traversal module. The first step in the graph traversal module is computing the set of branching k-mers (k-mers have multiple extensions). (a) The successors for each trusted k-mer are computed by appending a nucleotide nt 2 A; C ; G; T f g , for example, the successors of a k-mer  CATA, where k  4 are ATAA; ATAC ; ATAG; ATAT f g : (b) Bloom filter B is queried for each successor to check its presence in the sequenced reads. If the number of existing successors for each trusted k-mer is larger than one, the trusted k-mer is considered as a branching node. Otherwise, it is a simple node. (c) Each assembled contig starts from a branching node in the assembly graph, where each node is extended one nucleotide at a time and Bloom filter B is continuously queried for checking the presence of extended k-mers. The assembly graph is simplified by removing the dead end paths and resolving the simple bubbles De Bruijn graph-based assembler. LightAssembler, Minia and SparseAssembler are also considered as resource-efficient contigbased assembly tools. They do not utilize the paired-end information encoded in the sequenced libraries to perform scaffolding, while ABySS and Velvet have their own scaffolding modules. In order to make a fair comparison, we evaluated all methods based on their resulted contigs without using paired-end information such as the insert size. Then, we performed scaffold analysis based on our resulted contigs compared to those from other methods using SSPACE v3.0. 0 () as one of stand-alone scaffolding tools. One of the major assembly steps is evaluating assembly results to assess their accuracy and contiguity. When a reference genome is available, the assembly results are evaluated by mapping the assembled contigs or scaffolds back to the reference with the possibility of setting a minimum length threshold for the mapping contigs/scaffolds. The assembly evaluation tools have different reported metrics and even different approaches when a reference genome is absent. GAGE, Assemblathon and QUAST () are the most popular tools. The metrics used to evaluate the assembly results from the competing tools are described in Supplementary 1according to their definition in GAGE and Assemblathon studies. While QUAST has GAGE option to run the assembly evaluation using GAGE standards, we found that for the same minimum contigs threshold length, QUAST NG50 equals to GAGE N50 before performing the contigs correction step (breaking contigs at every misjoin and at every indel longer than 5 bases.). QUAST has a slightly higher N50 contig length compared to those from GAGE and Assemblathon 2. The default minimum threshold for contigs analysis in QUAST is 500 bp, which can be adjusted by the end user. GAGE has a fixed threshold contig length equals to 200 bp, while it is not specified in the Assemblathon's paper their threshold-based analysis. The scaffold-based contiguity analysis is used in Assemblathon 2 to report the contigs statistics by breaking the scaffolds into their corresponding contigs, which increases the N50 contig length compared to the length reported by the contigs-based analysis from other evaluation tools. Also, NG50 reported by the Assemblaton script equals to the N50 length reported by GAGE before doing the contigs correction step. We will use GAGE script to evaluate the assembly results from all competing programs. All conducted computer experiments and the exact command lines used for each tool are described in detail in Supplementary 1.
Resource requirementsThe major goal of LightAssembler is to use the computational resources efficiently, in particular reducing the memory requirements for contigs production. We compared LightAssembler memory usage and the running time with those of ABySS, Minia and SparseAssembler using simulated datasets and with the same assemblers, including Velvet using real benchmark datasets. The experiments were run on a computer running Red Hat Linux with 16 2:4-GHz Xeon E5-2665 cores and 128 GB memory. The maximum memory for our computational resources is 128 GB, which is not sufficient to run Velvet and ABySS for the bird dataset from the Assemblathon project, so we used temporarily another limited-access machine with 1TB memory. The memory usage peaks for the simulated datasets with low error rate e % 1% and real benchmark datasets are presented in Tables 2 and 3. For the simulated datasets with 3% error rate, see Supplementary 1. LightAssembler has the lowest peak memory usage for all different simulated datasets that vary in the sequencing coverage from 25 to 280. Also, LightAssembler has the lowest peak for different real datasets that vary in sizes from 2:9 Mbp to 1:23Gbp. The memory usage is almost constant for different sequencing coverage of the same genome and increases slightly when the coverage is 280. SparseAssembler has the next lowest memory peak, but the memory peak increases greatly when the sequenced coverage is increased and the gap size is decreased. While Minia uses less memory than ABySS and Velvet, it utilizes the disk space to overcome the memory usage limitations, which increases Minia's peak for the virtual memory usage. The assembly results by Minia vary greatly when the disk space is not sufficient to run the k-mer counting module. Velvet uses less memory than ABySS, which is designed to distribute the overhead of memory usage among multiple machines. The disk size of the assembly results for real datasets is reported in Supplementary 1. We also studied the peak memory usage of LightAssembler using different gap values (see Supplementary 1 Results, section 2). We reported the running time for Velvet, ABySS and LightAssembler using only one thread (see Supplementary 1 Tables 68). The latest version of Minia adjusts the number of threads according to the number of the available cores without being able to modify the number of threads to a single-thread mode. SparseAssembler is a single-thread assembler where Velvet, ABySS, Minia and LightAssembler are able to run in the multithreaded mode.
Simulated datasetsThe assembly results for all simulated datasets are presented inand Supplementary 1with more detail in Supplementary 2. Also, apart from Minia, SparseAssembler, ABySS and LightAssembler achieve the highest N50 length with low coverage dataset c 35x and low error rate e % 1%. When the error rate is increased to 3%, Minia and LightAssembler achieve the highest N50 length. LightAssembler outperforms all methods with the high coverage dataset c ! 75x and low error rate e % 1% according to the different evaluation metrics. ABySS utilizes the high coverage to overcome the sequenced errors when the error rate is increased to 3% and achieves the best results. It seems from our simulation that all assemblers have comparable results when the error rate is 1% and the average coverage c ! 75x. LightAssembler outputs the minimum number of contigs across different coverage values when the error rate is 1% and has comparable numbers to
LightAssemblerMinia in the experiments with 3% error rate. LightAssembler, SparseAssembler and ABySS have no assembly errors across all different experiments according to the error definition in Supplementary 1, while all assemblers have indel (i.e. insertion/deletion) errors with length less than 5 bases (see Supplementary 2). For the simulated datasets, we found that the maximum corrected contig length (max corr.) and the N50 corrected length (N50 corr.) equal to their lengths before doing the correction step (see Supplementary 2). SparseAssembler produces the highest genome coverage for all simulated datasets because of the large assembly size, which increases when the sequenced coverage and error rate of datasets are increased and the gap size is decreased. SparseAssembler has also the largest chaff size, which is the total size of all contigs that are in length less than 200 bp. LightAssembler, ABySS and Minia have the constant genome coverage across different scenarios. The assembly parameters supplied to all programs are presented in Supplementary 1. Minia uses the minimum abundant parameter to filter the erroneous k-mers by implementing a k-mer counting module to remove k-mers with abundance less than a specified threshold. While the k-mers counting module has an additional overhead of the running time and disk usage, Minia's performance drops dramatically when we tried to use all k-mers in the simulated datasets (minimum abundant threshold equals one). LightAssembler and SparseAssembler use the gap size parameter to get a uniform sample of k-mers in the sequenced reads. While LightAssembler uses the sample to filter the whole set of sequenced k-mers, SparseAssembler assembles the sampled k-mers by extending their links. The assembly results changed dramatically with different gap sizes in SparseAssembler, unlike LightAssembler, which was relatively insensitive, starting from a suitable value, for datasets with low error rates (see Supplementary 3). SparseAssembler has a maximum gap size, g  25, We think that this gap size should increase for the high coverage datasets with c ! 140x. We also studied the effect of varying the gap size g and the k-mer size k on the assembly results of LightAssembler (see Supplementary 1 Results, section 3).
Real datasetsThe assembly parameters supplied to all programs are presented in Supplementary 1. The detailed assembly results for each assembler on each dataset are presented in Supplementary 2.
Accuracy of LightAssembler k-mers classificationWe measured the number of correct classified k-mers by LightAssembler compared to the number of distinct k-mers in reference genomes for real datasets (). Also, we reported the number of incorrect k-mers that are kept in Bloom filter B. While LightAssembler kept some incorrect k-mers, the number of introduced errors in the final assembled contigs is comparable to Minia and SparseAssembler and is very low compared to Velvet and ABySS. In addition, we studied the effect of varying a gap value on the accuracy of LightAssembler k-mers classification with more detail in Supplementary 1 Results, section 4.
GAGE human chromosome 14Human chromosome 14 is a paired-end dataset from the GAGE evaluation study. We evaluated assembly results using the GAGE evaluation metrics that are computed based on aligning the assembled sequences to the reference of Human chromosome 14 dataset. The assembly results for all assemblers are presented in. No assembler performs the best on all combined metrics. Velvet produces the highest N50 length at the expense of introducing more errors compared to the other assemblers. Minia produces the lowestnumber of errors with LightAssembler very close behind. The assembled sequence of ABySS and SparseAssembler is longer than the reference sequence, which increases their genomic coverage compared to other assemblers. Velvet and LightAssembler outputs the minimum number of contigs, while ABySS has the maximum contig length. Overall, LightAssembler performance on human chromosome 14 is comparable to other assemblers for all evaluation metrics.
Assemblathon 2 bird datasetLightAssembler is designated to overcome the intensive memory requirements for assembling large genomes, so we compared LightAssembler results with other assembly tools () using one of the vertebrate species (Melopsittacus undulatus or simply bird dataset) from Assemblathon 2. Since there is no reference genome available for the bird dataset, we evaluated different results based on the assembly contiguity metrics. We used GAGE script to compute the N50 length with the minimum threshold set at 200bp for the contigs-based contiguity analysis. SparseAssembler has the highest N50 length, while LightAssembler has the second best value. As we reported previously, ABySS and SparseAssembler have the largest assembly size and the highest number of resulted contigs. Overall, LightAssembler results for the bird dataset are comparable using all contiguity evaluation metrics.
Importance of error correction and data cleaningWe used two bacterial genomes (S.aureus and R.sphaeroides) from GAGE project to compare the performance of all assemblers using uncorrected and corrected sequenced reads. We used the error-free datasets corrected by ALLPATHS-LG () since it has one of the best error correction modules for these datasets as mentioned in GAGE. The assembly results for all methods are increased dramatically after the error correction step (), which highlights the importance of data quality on the assembly process. Some assemblers like Velvet have extensive graph simplification modules, which resulted in high N50 length before data cleaning process at the expense of introducing more errors in the finished assembled contigs. The number of errors might be increased for some assemblers after data cleaning due to false-positive or false-negative error correction. Some error correction tools have also trimming processes, which truncate the tails of the sequenced reads at the bases with low quality scores and discard the reads that cannot be corrected. ABySS and SparseAssembler have the largest assembly size, which is reduced effectively after error correction. The large assembly size can mislead the assembly evaluation because it might result from errors in the dataset (tips or dead-ends) or repeated regions when assemblers infer different paths due to heterozygosity. More discussion can be found in Supplementary 1 Results, section 5 and Supplementary 2.
Scaffold results for GAGE human chromosome 14Sequence assembly is the combination of two stages: contig assembly followed by the use of paired-end reads or mate pairs to link the contigs further into scaffolds. Typically, contig assembly is the most memory-intensive stage for an assembler compared to the scaffolding stage. Some assemblers have their own built-in scaffolding modules, while others rely on the stand-alone tools to accomplish scaffolding. LightAssembler, Minia and SparseAssembler are contigbased assemblers, which are not designated to consider the pairedend information and perform scaffolding, while Velvet and ABySS have their own scaffolding modules. We assessed the contiguity and accuracy of the resulted contigs into scaffolds for all assemblers using the SSPACE scaffolding tool. The stand-alone scaffolding tools vary in their assembly results according to the number of correct/incorrect misjoins they made between the contigs as reported recently in one of the evaluation studies (). They reported SSPACE as one of the best scaffolding tool for their defined assembly evaluation metrics. Also, Human chromosome 14 is one of the benchmark datasets used in their study. We used the contigs resulted by all assembler and GAGE short jump library for Human chromosome 14 and ran SSPACE with the same reported best parameters for this dataset. In order to make a fair comparison, we used the contigs file from Velvet and ABySS without utilizing their own scaffolding modules. The assemblers' contig files are produced using only one sequenced library and without correcting the sequenced errors as mentioned previously. The scaffolding results are presented inwith more detail in Supplementary 1 Results, section 6 and Supplementary 2. The maximum scaffold length and the minimum number of scaffolds are resulted from the contigs produced by Velvet, while the lowest number of misjoins is resulted from SparseAssembler and LightAssembler. Velvet also has the highest N50 scaffold length, which is reduced dramatically after breaking scaffolds at every indel and at every misjoin. We also evaluated the scaffolding results of LightAssembler contigsLightAssemblerusing error corrected version of GAGE short jump library supplied to SSPACE, the N50 scaffold length is increased to 36426 bp. Moreover, the N50 scaffold length is increased to 46582 bp and the N50 contig length is increased to 4171 bp when we supplied the error corrected version of GAGE human chromosome 14 dataset to LightAssembler, more detail in Supplementary 3. The scaffolding results of LightAssembler contigs are comparable to other assemblers for the human chromosome 14 dataset.
DiscussionsLightAssembler is a light-version of an assembly algorithm that is executed on a desktop machine. It retains the assembly accuracy and contiguity using a pair of Bloom filters, one holding a uniform sample of the sequenced k-mers and the other holding k-mers that are likely correct using a simple statistical test. While LightAssembler is a gapbased assembler, different gap sizes result in an almost constant assembly size and genome coverage with varying in the sequenced coverage. The starting value for the gap size interval is chosen according to the sequenced coverage and error rate of a dataset with the gap value increases when the sequenced coverage and error rate are increased. We compared LightAssembler results with those from Velvet, ABySS, Minia and SparseAssembler using benchmark datasets from evaluation studies such as GAGE and Assemblathon 2. The assembly results reported in those studies are based on using multiple sequenced libraries (paired-ends and mate pairs) with different insert sizes and the sequenced errors corrected before starting the assembly process. In our paper, we used only one sequenced library for each dataset without error correction to verify the validity of our method without increasing the cost of sequencing process (using more libraries) or using error correction tools. To highlight the importance of these concepts on the assembly process, we studied the effect of the error corrected dataset on increasing the performance of different assemblers. We also discussed the scaffolding results of contigs produced by LightAssembler and other assembly tools using one short jump library from GAGE evaluation study. The data quality and complexity of the assembled genome rather than the assembler itself play a key role on the assembly results. The accuracy and contiguity of the assembly results are not correlated and the large assembly size can mislead the assembly evaluation. The major goal for resource-efficient contigs-based assemblers such as LightAssembler is reducing the memory usage for contigs production, which is the most memory-intensive stage among different assembly stages. LightAssembler achieved an improvement of a 50% reduction in the memory usage compared to the lowest memory usage reported by the current state-of-the-art assembly tools.Future improvements to LightAssembler will focus on the exploitation of paired-end information via implementing a built-in scaffolding module. Also, extending LightAssembler approach to metagenomic and single-cell assembly where the coverage is highly non-uniform and the number of sequenced errors and chimeric reads are increased. One possible solution is using different sampling rates, gap values, in the first pass so Bloom filter A can be populated with k-mers of different abundance from different genomic regions. The statistically computed thresholds in the second pass will be adjusted accordingly. Moreover, LightAssembler is an initial step towards full implementation of a streaming algorithm in the sequence assembly. It is considered as a multi-pass semi-streaming algorithm with low-memory usage for sequence assembly. LightAssembler is an open-source software released under the GNU GPL license.
S.El-Metwally et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
