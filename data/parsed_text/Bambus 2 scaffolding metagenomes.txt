Motivation: Sequencing projects increasingly target samples from non-clonal sources. In particular, metagenomics has enabled scientists to begin to characterize the structure of microbial communities. The software tools developed for assembling and analyzing sequencing data for clonal organisms are, however, unable to adequately process data derived from non-clonal sources. Results: We present a new scaffolder, Bambus 2, to address some of the challenges encountered when analyzing metagenomes. Our approach relies on a combination of a novel method for detecting genomic repeats and algorithms that analyze assembly graphs to identify biologically meaningful genomic variants. We compare our software to current assemblers using simulated and real data. We demonstrate that the repeat detection algorithms have higher sensitivity than current approaches without sacrificing specificity. In metagenomic datasets, the scaffolder avoids false joins between distantly related organisms while obtaining long-range contiguity. Bambus 2 represents a first step toward automated metagenomic assembly. Availability: Bambus 2 is open source and available from http://amos.sf.net.
INTRODUCTIONMetagenomics, the direct sequencing of DNA from all organisms in an environment without culturing, has recently emerged as a new scientific field that enables the discovery of novel organisms and genes ()as well as the study of population structure and dynamics (). Metagenomic studies have greatly expanded the understanding of microbial diversity. For example, viral quasi-species have been shown to affect pathogenicity in the poliovirus due to cooperation between differently adapted individuals in a population, as well as between coinfecting viruses (). Other recent studies have relied on metagenomics to identify novel genes and uncultured microbes (). The assembly of metagenomic data is complicated by several factors such as: (i) widely different levels of representation for different organisms in a community; (ii) genomic variation between * To whom correspondence should be addressed. closely related organisms; (iii) conserved genomic regions shared by distantly related organisms; and (iv) repetitive sequences within individual genomes. Similar challenges occur in the assembly of polymorphic eukaryotes, a challenging domain for existing assembly algorithms. For example, the assembly of the sea squirt genome Ciona savignyi required extensive manual intervention and customized scripts despite the fact that this genome is fairly 'simple'there were only two haplotypes of roughly equal coverage (). Metagenomic data are considerably more complex. Due to the lack of assembly tools specifically targeted at metagenomic projects, studies rely on existing assemblers and attempt to mitigate some of the challenges posed by the data through iterative adjustment of assembly parameters and post-processing. Tuning is critical as existing assemblers make frequent errors even in simulated datasets with significantly lower complexity than true environments (). At the same time, current assemblers produce fragmented assemblies, hampering downstream analysis. For example, in the analysis of the Global Ocean Survey data, the Celera Assembler () was heavily modified to allow high error rates in order to account for strain variation, and to overcome the effects of varied coverage levels on the statistical repeat detection procedure (). Only two assemblers were developed specifically for metagenomic datasets (). However, neither utilizes mate-pairs, our focus in this work. We present novel scaffolding algorithms optimized for non-clonal assembly. Though our algorithms are also applicable to polymorphic genomes, the primary focus of this article is on metagenomic analysis. These algorithms are implemented in a software tool called Bambus 2. Bambus 2 supersedes our previous scaffolder, Bambus (), which was targeted at clonal Sanger data. We will show that, when applied to metagenomic datasets, Bambus 2 generates large scaffolds while avoiding false joins between distantly related organisms. Furthermore, our software can automatically identify genomic regions of variation that correspond to previously characterized polymorphic loci.
Metagenomic scaffoldingIn our opinion, the main challenge in metagenomic assembly is to develop an assembler that can automatically generate contiguous assemblies yet accurately capture genomic variation information throughout the assembly process. It is important to first define the basic concepts underlying genome scaffolding. Most modern genome assemblers start by reconstructing segments of the genome that are unambiguously defined by the set of reads. These segments, called unitigs, are sections of the genome
Bambus 2entirely contained in either unique regions or repeats, i.e. they do not span the boundary between individual repeats or between repeats and unique regions. The nucleic acid sequence of unitigs can, therefore, be unambiguously reconstructed. Irrespective of the assembly algorithm employed, the unitigs themselves are generally small and assembly software must use additional information to increase the size of the contigs produced. Commonly, assemblers leverage the information contained in matepairsinformation constraining (in orientation, the DNA strand from which the sequence originated, and approximate distance) the pairwise position of reads along the genome. The process through which mate-pair information is used to increase contig sizes, as well as to determine a global arrangement of contigs along the genome, is called scaffolding. Note that longer contigs can also be constructed by careful analysis of the assembly graph without the use of mate-pair information ()we broadly consider scaffolding to also include such analyses. Most existing genome assemblers contain dedicated scaffolding modules [e.g.;;;. The unitig graph is output by a variety of modern assemblers such as Newbler (), Celera Assembler () and SOAPdenovo (), allowing scaffolding tools to operate as a stand-alone module post-assembly (). Throughout the article, we will assume that the unitig graph is given and will demonstrate how this information can be used to effectively analyze metagenomic datasets. Genomic repeats are the major challenge when assembling isolate genomes, and their effect is compounded in metagenomic datasets. Repeats link together disparate sections of the genome. As the number of reconstructions grows exponentially with the number of repeats (), it is intractable to find the one correct reconstruction. Therefore, most assemblers start by masking out unitigs that appear to represent repetitive segments of a genome. Celera Assembler, for example, uses depth of coverage statistics to determine whether a particular unitig represents a repeat, then ignores these unitigs until the later stages of scaffolding (). Coverage statistics are also used in other assemblers (). An alternative approach relies on topological information: unitigs that have multiple conflicting neighbors () can be inferred to represent repeats. While the approaches described above work well in isolate genomes, they can lead to false positives in metagenomic datasets. Coverage-based methods can classify abundant organisms as repeats, preventing the assembly of exactly those segments of the community that should be easily assembled (). Distinguishing between repeats within the same genome and conserved genomic segments shared by closely related organisms can be difficult. As seen in, the local unitig graphs and coverage look identical in both cases. Below, we will describe new approaches for repeat detection that work well in metagenomic datasets. Currently available scaffolders attempt to construct linear scaffolds, i.e. where unitigs can be placed in a linear, nonoverlapping order. When multiple unitigs occupy the same genomic region, they are either collapsed into one or the scaffolds are broken apart. Collapsing unitigs assumes the differences are due to error (). Breaking scaffolds assumes theambiguity is due to repeats (). In metagenomic assembly, such bubbles (multiple contigs occupying the same position in the assembly) are common due to polymorphisms between closely related strains, and fracturing the scaffolds at such positions leads to fragmented assemblies. Collapsing unitigs can lead to a 'mosaic' consensus sequence. If the variation occurs within genes, the consensus may contain frameshifts and even make it difficult to determine whether a gene exists. Previous attempts at untangling the genomic variation information from assembly data have relied on visualization techniques (). While valuable insights have been obtained through such studies, these approaches are manually intensive and not scalable to large metagenomic datasets. In this article, we propose an approach that can preserve polymorphic bubbles within the assembly yet allows long-range scaffolds to be constructed.
OUR APPROACHWe propose that repeats and genomic variation can be distinguished from each other by examining the unitig graph. Repeats appear to 'tangle' the unitig graph, thereby masking the global structure of the genome. Genomic variants, on the other hand, lead to localized motifs in the graph. For example, assume that several strains of a same organisms are virtually identical with the exception of a region of variation (e.g. a locus of antigenic variation). The graph pattern corresponding to this situation inappears as a bubble in the unitig graph. We suggest that the global structure of the genome can be best recovered if the ambiguity due to genomic variation is maintained throughout the scaffolding process. Specifically, motifs due to genomic variation do not affect the long-range structure of the common backbone shared by related genomes. Instead of resolving the bubbles, we detect regions of variation and replace each of them with a single graph node, simplifying the graph without obscuring the structure. Through the iterative application of this process, interleaved with standard graph simplification procedures we can obtain scaffolds that capture a large fraction of the common genome structure of closely related organisms. For each variant, we output a main sequence along with alternatives corresponding to the haplotypes in the data. Fasulo and others () havePage: 2966 29642971
S.Koren et al.(a)) alignment of a subset of the fasta output from Bambus 2, with an edit region corresponding to (a).previously presented an approach for detecting and representing variant bubbles during the assembly process, primarily targeting short-range variation that can be found within a single sequencing read. Our approach is more general and can tolerate larger scale variants (our approach detected variants with an average size of 5606.28868.26 when scaffolding 75 bp reads). Used in concert with the algorithm described byour method will detect large-scale polymorphisms in addition to the short-range within-read variants. Underlying the procedure above is the assumption that the ambiguity in the assembly graph is primarily caused by genomic variants, i.e. repeats have been detected and removed from the graph. We will describe two approaches for finding repeats in metagenomic samples. The first approach is based on the observation that repeat nodes appear to 'tangle' the graph structurethese nodes look like focal points in the graph, as in. We detect such repeats using a measure of node centrality similar to the vertex-betweenness centrality measure used in social network analysis (). We also propose a variant of coverage-based repeat detection that tracks the change in coverage within-graph components instead of using a global coverage statistic. We will show that this localized coverage measure is less sensitive to coverage differences between organisms in the sample.
METHODSOur algorithms operate on a contig graph. A contig may represent a single unitig or an ungapped concatenation of multiple contigs. For each matepair connecting pairs of contigs, we generate a link l with length d(l) and orientation computed from the orientation and positions of the reads in the contigs. The SD (l) is provided as input to Bambus 2. Using the set of links between pairs of contigs, the orientation is set as the orientation of the majority of the links. Once an orientation is selected, we check whether the distance constraints implied by the links are consistent with each other. If not, we discard the smallest number of links that results in a consistent set S (the largest consistent set can be found in nlogn time using an algorithm for maximal clique finding in an interval graph). Each(2001). Additional information, such as overlaps between adjacent contigs (contigs sharing common sequence), is also included when constructing the edges. The resulting graph is bidirected (). Scaffolding consists of three operations: orientation, positioning and simplification. Throughout the process, we prune the graph by removing contradictory edges and recording their reason for removal. To avoid the ambiguity introduced by repeats, we start with a repeat detection step, then exclude all repeat contigs and incident edges from scaffolding. The (possibly multiple) placement of these nodes can be determined after the initial scaffolding is complete. Centrality-based repeat detection: we calculate the all-pairs-shortest paths with each edge having weight w = 1. For each node, v, we calculate the number of times it appears on a shortest path: P v. Note that larger contigs are expected to have a higher degree because they contain more reads and, therefore, have a higher chance of being the end-point of a mate-pair link. To correct for this, we linearly scale P v by the contig length. Such a length-dependent correction has been previously proposed in the context of estimation of gene abundance in metagenomic samples (). A node is declared repetitive if the scaled P v > x +c where c is a constant (usually set to 3),  x is the mean of all scaled P v v  V and  is the SD of all scaled P v v  V. Local coverage statistic: for each connected component S and for each node v  S, we compute the A-stat value (). An abundant organism is less likely to appear repetitive in our approach as the connected component is more homogeneous. This operation is carried out after the repeat nodes identified by all-pairs-shortest paths have been removed. Orientation: we must first convert the bidirected graph into a directed graph by choosing an orientation for each node in the graph. We call reverse edges any pairwise constraints that require the adjacent contigs to be in opposite orientations. It is impossible to assign a consistent order to nodes involved in a cycle with an odd number of reverse edges without discarding edges. We attempt to remove a minimum number of edges to allow a consistent orientation to be assigned. Finding such a minimum set is equivalent to the Maximal Bipartite Subgraph problem which is NP-hard (). We rely on a greedy heuristic proposed bythat achieves a two-factor approximation. The algorithm runs in O(V +E) time. Positioning: in addition to assigning an edge direction, we want to assign a position for each contig. There may be multiple edges assigning contradictory positions to a node. These imperfect data are the result of experimental errors and repeats (ambiguities in the placement of reads along a genome). We want to maximize the number of satisfied edges by placing nodes as close to the specified position as possible. This problem is similar to the Optimal Linear Arrangement problem which is also NP-hard (). We rely on the following greedy extension heuristic to linearly order the Page: 2967 29642971contigs: scaffolding starts by placing an arbitrary node at position 0. For each node without a position, compute an initial position based on all alreadyplaced neighbors as a weighted average. Subsequent edges can reposition the node within a limit of 3(e) where (e) is the SD of the edge. The extension stops when the ratio of an edge weight w(e(u,v)) to the maximum weight edge incident on node u or v is below a threshold. Edges eliminated from the graph due to invalid orientation are not used in this step. The algorithm runs in O(V +E) time. This heuristic is sufficient once the graph is simplified as above and repeat contigs removed. Simplification: a transitive reduction is applied to the contig graph and redundant edges are removed. Transitive edges [an edge e(u,v) such that there is a path p with a set of edges p e  E incident on nodes p v  V between u and v not including e(u,v)] are removed from acyclical components of the graph by performing a depth-first search from each node in topological order. Given the sequence lengths of contig in the graph l(v) v  V and a path p, we define the length of the path as l(p) =  contigs vpv l(v)+  edges epe l(e). Define the SD of the path as (p) =  edges epe (e). A transitive edge is removed when |l(e)l(p)|(e)+(p). These edges can be removed without loss of information. Simple paths (all nodes have in-and outdegree equal to 1) are then collapsed: the nodes on the path are replaced with a single node representing the concatenation of the original nodes, and the intervening edges are removed from the graph. Finally, each simplified connected component in the graph gets reported as a scaffold. Variant detection: once we have oriented and positioned the contigs and simplified the graph, we iteratively search for variation motifs. We search for subgraphs where multiple paths begin at a source node and collapse to one sink node within a certain number of hops. To allow for artifacts due to incomplete coverage, we allow subgraphs where paths terminate before reaching the sink. Given graph G = (V ,E) and motif set S  V incoming edges = S in (u,v)  E s.t. u  V S and v  S outgoing edges = S out (x,w)  E s.t. x  S and  V S
Bambus 2That is, the incoming edges may only be incident on the source node and the outgoing edges may only be incident on the sink node. Finally, to avoid false positives due to layouts that satisfy edge constraints but where nodes can be placed in a linear, non-overlapping order, we calculate the overlap ratio. Given S  V , node v  S, start coordinate of v, B(v) and end coordinate of v, E(v)length(S) = abs(E(sink)B(source))The overlap ratio is then overlap(S) length(S). Intuitively, it is the total number of bases covered by two or more nodes, divided by the total number of bases in the motif. Motifs whose overlap ratio exceeds a threshold are marked as a polymorphism. To make the problem tractable, only subgraphs with a diameter of 2 are detected in the current implementation of our algorithm. Each iteration of motif detection has a runtime of O(|V |((G) 3 +3(G))) where (G) is the maximum degree of G. This algorithm has a worst-case runtime of O(|V |(|E| 3 +3|E|)). However, in a contig graph it is likely that (G) << |E|. Every level of depth multiplies the runtime by a factor ofOutput: Bambus 2 supports several output formats. Since we do not linearize scaffolds and maintain ambiguity due to variation in the graph, the native output is a graph [in Graphviz format. Bambus 2 also finds the longest sequence reconstruction through each scaffold. That is, it will ignore variant motifs and generate a single selfconsistent sequence for each scaffold. Additionally, Bambus 2 outputs each variation motif as a set of sequences. For each motif, S, we start from the source node, as defined above. For each child node c of source, we recursively compute the sequences starting at c. The longest sequence starting at source is the master sequence of the motif. The alternate sequences found in the graph are also output, including edit positions specifying where within the master sequence they belong.shows an example alignment of the fasta output for a variant region within E.coli. Test data: we tested the algorithm using nine datasets. Brucella suis 1330 comprised 36 080 reads and available as NCBI Trace Archive Project ID 320. The reference includes: AE014291:AE014292 (2 107 792 bp, 1 207 381 bp). Three simulated datasets were generated using MetaSim () (). The acid mine drainage dataset, generated by;, consists of 179 770 reads and is available as NCBI Trace Archive Project ID 13696. The reference AMD dataset includes: Ferroplasma acidarmanus Type I, Ferroplasma sp. Type II, Leptospirillum sp. Group II 5-way CG, Leptospirillum sp. Group III and Thermoplasmatales archaeon Gpl and is available as CH003520:CH004435. The Twin Gut data were generated byand is available as SRA002775 (8.30M GS FLX fragments). The MetaHit datasets were generated by the MetaHit consortium () and are available as ERS006526, ERS006594 and ERS006494.
RESULTSIn the following section, we demonstrate the performance of Bambus 2 by comparing it with two assemblers used in recent Page: 2968 29642971
S.Koren et al.metagenomic projects [Celera Assembler () and SOAPdenovo (. We have not included a comparison with our previous scaffolder, Bambus (), as it lacks the functionality necessary in a metagenomic setting. Also, we have omitted comparisons to Genovo () and Meta-IDBA () as neither of these use mate-pair information during the assembly process.
Repeat detectionWe benchmarked our algorithms for repeat detection using artificial and real datasets by comparing repeats identified by Bambus 2 with those identified by the Celera Assembler () with metagenomic settings () (referred to as CA-met). The CA-met settings increase the tolerance for mismatches when building unitigs, providing longer range contiguity, but possibly leading to mis-assembly. The repeat detection from Celera Assembler relies on coverage, a common approach and procedures for tuning this assembler for both isolate and metagenomic assemblies have been documented (http://wgsassembler.sf.net).shows the results. Ideally, the repeat detection should have both high sensitivity and specificity. Sensitivity reflects how many true repeats are detected. Detecting too few repeats can lead to assembly errors in scaffolding. Specificity reflects the false positives. Detecting too many repeats leads to a suboptimal assembly as these contigs do not fully participate in scaffolding. In the case of B.suis 1330, both methods have high sensitivity and specificity. Celera Assembler repeat detection was designed for clonal organisms. Since the B.suis dataset is clonal, CA can accurately detect repeats. In all other cases, Bambus 2 has a higher sensitivity and specificity than Celera Assembler. The default genome size estimates in CA are too sensitive, identifying too many repeats. While varying the genome size improves repeat detection, it is at the expense of sensitivity or specificity. On all datasets, this tuning, which is difficult when the true taxonomic distribution is unknown, still does not match Bambus 2's automated sensitivity and specificity result.
Scaffolding of simulated metagenomic datasetsWe compared Bambus 2 to CA with default settings and CA-met. While other assemblers have been used in metagenomic studies [e.g. Phrap http://www.phrap.org/ and Newbler (, as far as we are aware, they have not been extended to target metagenomic data. SOAPdenovo has also been used for metagenomic studies; however, no scaffolding results were reported (). We ran Bambus 2 to scaffold unitigs from CA-met and Minimus (). As seen in, for all genomes, Bambus 2 outperforms CA. For all but one genome, Bambus 2 also outperforms CA-met. The only case where CA-met performs better than Bambus 2 is E.coli O157:H7 EDL933. The closely related E.coli strains are present at sufficient combined coverage for CA-met to obtain large scaffolds. However, the low-abundance genomes in the same sample are not assembled. In scaffolds over 2 kb, CA-met only includes 10.90 and 13.31% of the low-abundance genomes, versus 17.24 and 18.37% for Bambus 2. Additionally, CA-met constructs a 'mosaic' sequence of the two E.coli strains, masking variation and potentially introducing error (Supplementary Material). As we will show below, on the acid mine dataset, thisA total of 30 variation motifs were detected in the Sim3 dataset. The motifs detected include genes for ferrochelatase () as well as outer membrane proteins and integrase for prophage, which are known to vary across strains of E.coli () and more broadly, across other enterobacteria.
Scaffolding of the acid mine drainage metagenomeWe tested Bambus 2 on an acid mine drainage () metagenomic set. These data represent an ideal benchmark as they comprise a low number of organisms, and the genomic variation between related members of the community has been extensively studied. We generated unitigs using CA and scaffolded them with Bambus 2. The Bambus 2 assembly has fewer scaffolds in three of the five organisms present in this sample when compared with CA-met (). In two genomes, Leptospirillum sp Group III and Ferroplasma acidarmanus Type I, Bambus 2 halves the number of scaffolds while reconstructing a larger percentage of the references, as compared to CA-met. In one case, Ferroplasma sp Type II, CAmet produces fewer scaffolds than Bambus 2. However, we found that over 61% of the contigs in the Ferroplasma sp Type II CAmet assembly cannot be uniquely assigned to a single reference genome. We hypothesize that CA-met combined the assemblies of Ferroplasma acidarmanus Type I and Ferroplasma sp Type II, creating chimeric contigs and scaffolds. We validated our hypothesis by counting the fraction of contigs in chimeric scaffolds. Chimeric scaffolds either include a chimeric contig or contain contigs from different organisms (Supplementary Material). Bambus 2 had the lowest rate of chimeras, 5.66%, while CA-met had the highest at 23.07%. This is expected as CA-met was tuned to maximize scaffold size, possibly merging unrelated organisms. Bambus 2 built large scaffolds while making fewer mistakes. The acid mine community used in our analysis is dominated by two genera: Leptospirillum bacteria and Ferroplasma archaea. A large extent of genomic variation, primarily due to recombination, was characterized in both these groups of organisms (). Initial studies of this environment indicated that most genomic variation can be found in Ferroplasma sp Type II, with no predominant functional groups being associated with the variable regions (). Subsequent publications with additional sequencing (included in our dataset), also showed significant variation in Leptospirillum sp Group II '5-way CG' (). Here we evaluated whether Bambus 2 is able to rediscover these results. We detected a total of 99 motifs, of which 66 represented alternate sequences (two contigs occupying the same positions) and 33 represent insertion/deletion of sequence. The majority of motifs could be assigned to regions from the Ferroplasma sp Type II, as expected. However, as a percentage of bases contained within variation motifs (the extent, rather than number of motifs), the most varied organisms appear to be Leptospirillum sp Group II '5-way CG' and Leptospirillum sp Group III, followed by Ferroplasma sp Type II. The difference in the patterns of variation (frequent but small in Ferroplasma and less frequent but large in Leptospirillum) was also observed byand could be explained by different biological mechanisms that drive the genomic variability. It was hypothesized () that recombination frequently occurs within Ferroplasma possibly due to the fact that that these organisms (as well as many other archaea) lack the mutS and mutL DNA repair systems. Conjugation or transduction, which produce large events (as they are dependent on the F-plasmid and phage size), was hypothesized to contribute to the genomic variation in Leptospirillum (). We compare the genes within variation motifs to those identified in previous publications. We annotated the assembly by taking non-overlapping best BLASTX () hits for each unitig and assigned a COG () functional category to each hit. We tabulated the counts of each COG category within the assembly and within the motifs. We then characterized the functional categories that are statistically enriched in motif regions (Supplementary Material). The functional category corresponding to 'DNA replication, recombination and repair' (category L) is significantly enriched (P = 0.006, hypergeometric test). Also enriched (P = 0.25, hypergeometric test) is one of the poorly characterized COG categories, 'general function prediction' (category R). Our results are consistent with previous analysis of the data (). One specific motif identified within Leptospirillum sp Group II '5-way CG', corresponds to glycosyltransferase, a gene previously characterized as occurring within a mobile region of Leptospirillum sp Group II and Leptospirillum sp Group III (). Thus, it is expected that this mobile element would mutate and recombine independently within the members of the Leptospirillum sp population, giving rise to the motif.
Scaffolding output of NGS assemblersFinally, we tested Bambus 2 on four dataset composed of nextgeneration sequencing reads. The first dataset, comprising the gut microbiome of twins (), was assembled using Newbler () followed by Bambus 2. Our assembly combined all 18 individual samples from the original study. The assembly generated 3230 variation motifs. Since we lacked a reference, we could not map our assembly and tabulate statistics as with previous datasets. Instead, we evaluated the assembly contiguity. We sorted the scaffolds in decreasing order by size and counted the number and size of the smallest scaffold Page: 2971 29642971
Bambus 2The current version of our code does not make use of sequence information when performing graph simplification. We plan to incorporate such information in the future, allowing Bambus 2 to merge contigs, when appropriate. In addition, using sequence information can allow Bambus 2 to avoid false positives in detecting variation motifs. We also plan to distribute a visualization tool to allow users to interact with the variants and the assembly graph. The repeat detection procedures used in Bambus 2 are sensitive without sacrificing specificity, and could also be applied to the assembly of single genomes, in particular in single-cell projects where depth-of-coverage artifacts are common. The scaffolds generated by Bambus 2 cover a large percentage of the genomes in the samples, while largely avoiding misjoins. The fasta output of variants motifs facilitates analysis of the full diversity in an environment. Furthermore, the ability to highlight regions of variation has proven useful in detecting biologically meaningful patterns that match previously published results. Accurately assembling metagenomic datasets automatically is challenging with current assemblers, and often requires manual tuning of parameters and post-processing. Bambus 2 represents a first step toward automated metagenomic assembly, and is able to obtain long-range contiguity in metagenomic datasets while also characterizing regions of variation.
The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [17:51 7/10/2011 Bioinformatics-btr520.tex] Page: 2970 29642971
