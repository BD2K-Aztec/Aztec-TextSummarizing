Motivation: As the quantity of data per sequencing experiment increases, the challenges of fragment assembly are becoming increasingly computational. The de Bruijn graph is a widely used data structure in fragment assembly algorithms, used to represent the information from a set of reads. Compaction is an important data reduction step in most de Bruijn graph based algorithms where long simple paths are compacted into single vertices. Compaction has recently become the bottleneck in assembly pipelines, and improving its running time and memory usage is an important problem. Results: We present an algorithm and a tool BCALM 2 for the compaction of de Bruijn graphs. BCALM 2 is a parallel algorithm that distributes the input based on a minimizer hashing technique, allowing for good balance of memory usage throughout its execution. For human sequencing data, BCALM 2 reduces the computational burden of compacting the de Bruijn graph to roughly an hour and 3 GB of memory. We also applied BCALM 2 to the 22 Gbp loblolly pine and 20 Gbp white spruce sequenc-ing datasets. Compacted graphs were constructed from raw reads in less than 2 days and 40 GB of memory on a single machine. Hence, BCALM 2 is at least an order of magnitude more efficient than other available methods. Availability and Implementation: Source code of BCALM 2 is freely available at: https://github.com/ GATB/bcalm Contact: rayan.chikhi@univ-lille1.fr
IntroductionModern sequencing technology can generate billions of reads from a sample, whether it is RNA, genomic DNA, or a metagenome. In some applications, a reference genome can allow for the mapping of these reads; however, in many others, the goal is to reconstruct long contigs. This problem is known as fragment assembly and continues to be one of the most important challenges in bioinformatics. Fragment assembly is the central algorithmic component behind the assembly of novel genomes, detection of gene transcripts (RNA-seq) (), species discovery from metagenomes, structural variant calling (). Continued improvement to sequencing technologies and increases to the quantity of data produced per experiment present a serious challenge to fragment assembly algorithms. For instance, while there exist many genome assemblers that can assemble bacterial sized genomes, the number of assemblers that can assemble a high-quality mammalian genome is limited, with most of them developed by large teams and requiring extensive resources (). For even larger genomes, such as the 20 Gbp Picea glauca (white spruce), graph construction and compaction took 4.3 TB of memory, 38 h and 1380 CPU cores (). In another instance, the whole genome assembly of 22 Gbp Pinus taeda (loblolly pine) required 800 GB of memory and three months of running time on a single machine (). Most short-read fragment assembly algorithms use the de Bruijn graph to represent the information from a set of reads. Given a set of reads R, every distinct k-mer in R forms a vertex of the graph, while an edge connects two k-mers if they overlap by k  1 characters. The use of the de Bruijn graph in fragment assembly consists of a multi-step pipeline, however, the most data intensive steps are usually the first three: nodes enumeration, compaction and graph cleaning. In the first step (sometimes called k-mer counting), the set of distinct k-mers is extracted from the reads. In the second step, all unitigs (paths with all but the first vertex having in-degree 1 and all but the last vertex having out-degree 1) are compacted into a single vertex. In the third step, artifacts due to sequencing errors and polymorphism are removed from the graph. The second and third step are sometimes alternated to further compact the graph. After these initial steps, the size of the data is reduced gradually, e.g. for a human dataset with 45 coverage, To overcome the scalability challenges of fragment assembly of large sequencing datasets, there has been a focus on improving the resource utilization of de Bruijn graph construction. In particular, k-mer counting has seen orders of magnitude improvements in memory usage and speed. As a result, graph compaction is becoming the new bottleneck; but, it has received little attention (). Recently, we developed a compaction tool that uses low memory, but without an improvement in time (). Other parallel approaches for compaction have been proposed, as part of genome assemblers. However, most are only implemented within the context of a specific assembler, and cannot be used as modules for the construction of other fragment assemblers or for other applications of de Bruijn graphs (e.g. metagenomics). In this paper, we present a fast and low memory algorithm for graph compaction. Our algorithm consists of three stages: careful distribution of input k-mers into buckets, parallel compaction of the buckets, and a parallel reunification step to glue together the compacted strings into unitigs. The algorithm builds upon the use of minimizers to partition the graph (); however, the partitioning strategy is completely novel since the strategy ofdoes not lend itself to parallelization. Due to the algorithm's complexity, we formally prove its correctness. We then evaluate it on whole-genome human, pine and spruce sequencing data. The de Bruijn graph for a whole human genome dataset is compacted in roughly an hour and 3 GB of memory using 16 cores. For the >20 Gbp pine and spruce genomes, k-mer counting and graph compaction take only 2 days and 40 GB of memory, improving on previously published results by at least an order of magnitude.
Related workThe parallelization of de Bruijn graph compaction has been previously explored. In (), the problem is reduced to the classic list ranking problem and solved using parallel techniques such as pointer jumping. Another recurrent MPI-based approach is to implement a distributed hash table, where the k-mers and the information about their neighborhoods are distributed amongst processes. Each processor then extends seed k-mers locally as far as possible to build sub-unitigs and then passes them off to other processors for further extension. Variants of this approach are used in (). Other papers have proposed using a parallelized depth-first search () or a small world asynchronous parallel model (). Before a de Bruijn graph can be compacted, it has to be constructed. Parallel approaches currently represent the state-of-the-art in this area. Many original efforts were focused on edge-centric de Bruijn graphs, where edges are represented by k  1-mers. They required the identification of both all distinct k-mers and k  1mers (). More recent efforts have focused on the node-centric graph, which only requires the counting of k-mers (). In genome assembly, the construction and compaction of a de Bruijn graph form only the initial stages. There are also alternate approaches that do not use the de Bruijn graph at all (e.g. greedy or string graph). Numerous parallel assemblers are available for use, including ABySS (), SOAPdenovo (), Ray (), PASQUAL (), PASHA (), SAND (), SWAPAssembler (). Other methods for parallel assembly have been published but without publicly available software (). There has also been work done in reducing the overall memory footprint de Bruijn graph assembly. This challenge is most pronounced for k-mer counters. However, when scaling to mammaliansized genomes, memory usage continues to be an issue in downstream steps such as compaction.
DefinitionsWe assume, for the purposes of this paper, that all strings are over the alphabet R  fA; C; G; Tg. A string of length k is called a k-mer. For a string s, we define its k-spectrum, sp k s, as the multi-set of all k-mer substrings of s. For a set of strings S, we define its multi-set k-spectrum as sp k S  [ s2S sp k s. For two strings u and v, we write u 2 v to mean that u is a substring of v. We write ui::j to denote the substring of u from the ith to the jth character, inclusive. We define suf k u  ujuj  k  1; juj and pre k u  u1::k. For two strings u and v such that suf k u  pre k u, we define a glue operation as u k v  u  vk  1::jvj. The binary relation u ! v between two strings denotes that suf k1 u  pre k1 v. For a set of k-mers K, the de Bruijn graph of K is a directed graph such that the nodes are exactly the k-mers in K and the edges are given by the ! relation. Note that our definition of the de Bruijn graph is node-centric, where the edges are implicit given the vertices; therefore, we use the terms de Bruijn graph and a set of k-mers interchangeably. Suppose we are given a de Bruijn graph, represented by a set of k-mers K. Consider a path p  x 1 ;. .. ; x m  over m ! 1 vertices. We allow the path to be a cycle, i.e. it is possible that x 1  x m. The endpoints of a path are x 1 and x m if it is not a cycle. A single-vertex path has one endpoint. A cycle does not have endpoints. The internal vertices of a path are vertices that are not endpoints. p is said to be a unitig if either jpj  1 or for all 1 < i < m, the out-and indegree of x i is 1, and the in-degree of x m and the out-degree of x 1 are 1. A unitig is said to be maximal if it cannot be extended by a vertex on either side. The problem of compacting a de Bruijn graph is to report the set of all maximal unitigs. We say that two strings u and v are compactable in a set S if u ! v and, 8w 2 S, if w ! v then w  u and if u ! w then w  v. That is, u is the only in-neighbor of v, and v is the only out-neighbor of u. The compaction operation is defined on a pair of compactable strings and replaces u and v by a single string u k1 v. Consider some ordering of '-mers. We define the '-minimizer of a string x as the smallest '-mer substring of x. Given k > ' and a string x with at least k characters, we define lmmx as the '-minimizer of the prefix k  1-mer, and rmmx as the '-minimizer of the suffix k  1-mer. We refer to these as the left and right minimizers of x, respectively. Two strings (u, v) are m-compactable in S if they are compactable in S and if m  rmmu  lmmv. The m-compaction of a set S is obtained from S by applying the compaction operation as much as possible in any order to all pairs of strings that are m-compactable in S.
Algorithm overviewIn this section, we give a high-level description of our BCALM 2 algorithm (Algorithm 1), leaving important optimizations and implementation details to Section 6. Recall that the input is a set of k-mers K and the output are the strings corresponding to all the maximal unitigs of the de Bruijn graph of K. If time and memory are not an issue, then there is a trivial algorithm: repeatedly find compactable strings and compact them until no further compactions are possible. However, such an approach requires loading all the data into memory, which is not feasible for larger genomes. Instead, BCALM 2 proceeds in three stages. In the first stage, the k-mers are distributed into buckets, with some k-mers being thrown into two buckets. In the second stage, each bucket is compacted, separately. In the third stage, the k-mers that were thrown into two buckets are glued back together so that duplicates are removed.shows the execution of BCALM 2 on a small example.In the first stage (lines 16 of Algorithm 1), BCALM 2 distributes the k-mers of K to files F1;. .. ; F4 ' . These are called bucket files. Each k-mer x 2 K goes into file Flmmx, and if lmmx 6  rmmx, also in Frmmx. The parameter ' controls the minimizer size (in our implementation, we set '  8). In the second stage of the algorithm, we process each bucket file using the CompactBucket procedure (Algorithm 2). After the k-mer distribution of the first stage, the bucket file F(i) contains all the k-mers whose left or right minimizer is i. We can therefore load F(i) into memory and perform i-compaction on it. Since the size of the bucket is small, this compaction can be performed using a simple inmemory algorithm. The resulting strings are then written to disk, and will be processed during the third stage. At the end of the second stage, when all CompactBucket procedures are finished, we have performed all the necessary compactions on the data. At this stage of the algorithm, notice that the k-mers x 2 K with lmmx 6  rmmx exist in two copies. We call such k-mers doubled. We will prove in Section 5 that these k-mers are always at the ends (prefix or suffix) of the compacted strings, never internal, and they can be recognized by the fact that the minimizer at that end does not correspond to the bucket where it resides. We record these ends that have doubled k-mers by marking them 'lonely' (lines 4 and 5 of Algorithm 2), since they will need to be 'reunited' at the third stage of the algorithm. Strings that have no lonely ends are maximal unitigs, therefore they are output (line 8). At the third stage of the algorithm, we process the strings output by CompactBucket with the Reunite procedure (Algorithm 3). At a high level, the purpose of Reunite is to process each string u that has a lonely end, and find a corresponding string v that has a matching lonely end with the same k-mer. When one is found, then u and v are glued together (Algorithm 4), thereby 'reuniting' the doubled k-mer that was split in the k-mer distribution stage. The new string inherits its end lonely marks from the glued strings, and the process is then repeated for the next string u that has a lonely end. After Reunite() completes, all duplicate k-mers will have been removed, and the strings in the output will correspond to the maximal unitigs.1: Load F(i) into memory. 2: U i-compaction of F(i). 3: for all strings u 2 U do 4: Mark u's prefix as " lonely " if i 6  lmmu. 5: Mark u's suffix as " lonely " if i 6  rmmu. 6: if u's prefix and suffix are not lonely then 7: Output u. 8: else 9: Place u in the Reunite fileInput: the set of strings R from the Reunite file. 1: UF Union find data structure whose elements are the distinct k-mer extremities in R. 2: for all parallel u 2 R do 3: if both ends of u are lonely then 4: UF:unionsuf k u; pre k u 5: for all parallel classes C of UF do 6: P all u 2 R that have a lonely extremity in C 7: while 9u 2 P that does not have a lonely prefix do 8: Remove u from P 9: Let s  u 10: while 9 v 2 P such that suf k s  pre k v do 11: s Glues; v 12: Remove v from P 13: Output sAlgorithm 4. Glue(u, v) Input: strings u and v, such that suf k u  pre k v. 1: Let w  u k v. 2: Set lonely prefix bit of w to be the lonely prefix bit of u. 3: Set lonely suffix bit of w to be the lonely suffix bit of v. 4: return wCompacting de Bruijn graphs from sequencing data quickly and in low memory i203To perform these operations efficiently in time and memory, Reunite first partitions the strings of R so that any two strings that need to be reunited are guaranteed to be in the partition. Then, each partition can be processed independently. To achieve the partition, we use a union-find (UF) data structure of all k-mers extremities. Recall that a UF data structure is created by first assigning a set to each distinct element (here, an element is the k-mer extremity of a string). Then, the union operation replaces the sets of two elements by a single set corresponding to their union. Here, union is applied to both k-mer extremities of a string. After the UF is constructed, the set of strings to be reunited is partitioned such that k-mer extremities of sequences in a partition all belong to the same UF set.
Proof of correctnessRecall that K is the input to the algorithm and let U be the strings corresponding to the set of all maximal unitigs of K. We will assume for our proof that U does not contain any circular unitigs. We note that since BCALM 2 outputs strings, it cannot represent circular unitigs in its output. Circular unitigs present a corner case for both the analysis and the algorithm itself, and, for the sake of presentation brevity, we do not consider them here. We prove the correctness of BCALM 2 by showing that it outputs U. We first give a Lemma that will allow us to show that the output is U by arguing about its k and k  1 spectrums. LEMMA 1. Let S and T be two sets of strings of length at least k such that sp k1 S  sp k1 T and sp k S  sp k T and all these spectrums are without duplicates. Then, S  T. PROOF. We will prove that S T. The same argument will be symmetrically applicable to prove T S, which will imply S  T. First, we show that for all s 2 S, there exists a t 2 T such that s 2 t. Let s 2 S and let p  maxfi : 9t 2 T; s1::i 2 tg, and let t be a string achieving the max. Note that p ! k  1 since every k  1mer of S is also in T. Suppose for the sake of contradiction that p < jsj. Then the k  1-mer sp  k  1; p  1 must occur in either another location of t or another string t 0 2 T. Either way, this means that the k-mer sp  k  1; p must also occur elsewhere besides at tp  k  1; p. Since there are no duplicate k-mers in T, this is a contradiction. Now, we show that S T. Let s 2 S and let t 2 T such that s 2 t. By applying an argument symmetrical to the one above, there exists a s 0 2 S such that t 2 s 0. This means that s 2 s 0 , and, in particular, s1::k 2 s 0. Since k-mers can only appear once in S, we must have that s  s 0 and hence s  t 2 T. h Next, we characterize the k and k  1 spectrums of U. Given a multi-set M, we denote by Set(M) as the set version of M, with all multiplicity information implicitly removed. When referring to a set, such as K, as a multi-set, we will mean that all the elements have multiplicity one. LEMMA 2. sp k U  K PROOF. Since every vertex is a single vertex unitig path, every vertex must be covered by some maximal unitig and hence Setsp k U  K. It remains to show that the set of maximal unitigs never share a vertex. First, observe that a single unitig cannot visit a vertex more than once, otherwise that vertex will be an internal vertex at one of its occurrences but will have either multiple ins or outs. We therefore need to show that no two maximal unitig paths share a vertex. Let p  v 1 ;. .. ; v jpj  and p 0  v 0 1 ;. .. ; v 0 jp 0 j  be two maximal unitigs that share a vertex. Because p is maximal, it cannot be a subpath of p 0 , and cannot be a single vertex. If p is a cycle, then all its vertices have in-and out-degree one so that the only other paths it can share vertices with are sub-paths of p, contradicting the fact that p is maximal. Hence, we can assume that p and, by symmetry, p 0 , is not a cycle. First, suppose that all shared vertices are internal to both paths. Consider such a vertex v i , for a maximal i. Because v i must have different out-neighbors on both paths, it has out-degree at least two, contradicting that it is an internal vertex. Therefore there must exist at least one shared vertex that is an endpoint of one of the paths. Suppose that v 1 is a shared vertex, and that it is not the first vertex of p 0 , If the previous vertex of p 0 is not on p, then p can be extended with it, contradicting its maximality. Otherwise, consider the first vertex at which p and p 0 diverge. That is, the smallest i < jpjsuch that v i 2 p 0 but v i1 6 2 p 0. The last vertex of p 0 must be v i , otherwise it has out-degree at least two, contradicting that p is a unitig. Therefore, there can only exist one such vertex v i , and it must be the last vertex of p 0. h We define a k  1-mer w as actionable if there exists x 2 K and y 2 K such that (x, y) are compactable in K and w  x k1 y. We define A as the multi-set of all actionable k  1-mers, but note that it does not contain duplicates because there are no duplicate k-mers in K.First we note that neither A nor sp k1 U have any multiple elements (by Lemma 2), and we do not need to consider multiplicities of the elements. Suppose that there exist two k-mers x and x 0 such that x k1 x 0 2 A but is not in sp k1 U. Because every vertex is part of some unitig, by Lemma 2 there must exist a unique unitig path p 2 U that contains x and a unique unitig path p 0 2 U that contains x 0. Note that because x; x 0  are compactable, x 0 is the unique our-neighbor of x and x is the unique in-neighbor of x 0. Also, x must be the last vertex of p and x 0 must be the first vertex of p 0. We can therefore join p and p 0 by adding the edge from x to x 0 , obtain a unitig and contradicting the maximality of p and p 0. Now suppose that there exists k-mers x and x 0 such that x k1 x 0 2 sp k1 U but not in A. Let p be the unitig containing x k1 x 0. Since x is not the last endpoint, it must have an out-degree of 1. Similarly, x 0 has an in-degree of 1. Hence, x; x 0  is compactable, a contradiction. h Next, we characterize the effect that CompactBucket() has on the k and k  1 spectrums. Let B be the collection of all strings u that are either output at line 7 of Compactbucket or placed in the Reunite file at line 9. We can think of these as the sum output of the CompactBucket calls. LEMMA 4. sp k1 B  A and sp k B is the same as K except every doubled k-mer has multiplicity of 2 in sp k B.
PROOF.During distribution of the k-mers into the bucket files, every k-mer is distributed to exactly one file except for doubled k-mers, which go into two files. The compaction operations that follow do not affect the k-spectrum. Thus, the statement about sp k B holds. Initially, sp k1 K  1. The compaction operation changes the k  1 spectrum by creating one new k  1-mer. Hence, we will show that x k1 y 2 A if and only if (x, y) gets compacted at some point. Consider an actionable k  1-mer x k1 y 2 A. Observe that the right minimizer of x is the same as the left minimizer of y. Denote it by i. Because (x, y) are compactable, they are also i-compactable. The bucket file F(i) will contain x and y. Because x does not have an out-neighbor that is not y in K, it will not have an outneighbor that is not y in F(i). Similarly, y will only have x as an inneighbor in F(i). Hence, (x, y) will be i-compacted in F(i). On the other hand, consider an i-compaction of x 2 K and y 2 K in F(i). Any out-neighbor of x in K must have i as a left minimizer and hence must be in F(i). Similarly, any in-neighbor of y in K must have i as a right minimizer and hence must also be in F(i). Because (x, y) are i-compactabile in F(i), x does not have an out-neighbor y 0 6  y in K and y does not have an in-neighbor x 0 6  x in K. Therefore, (x, y) are compactable in K and hence x k1 y 2 A. h Next, we analyze the third stage of the algorithm. The following two Lemmas connect the notion of loneliness to doubled k-mers.Let x 2 K be a doubled k-mer. Then, x appears as a prefix of some string in R and as a suffix of some other string in R, and the ends where it appears are marked lonely. PROOF. Let i  rmmx. Since x is a doubled k-mer, lmmx 6  i. Consider the fate of x in CompactBucket(i). Because CompactBucket only performs i-compactions, x will never be compacted from the left. Thus it will be a prefix of some string in U at line 2 of CompactBucket, and line 4 will mark the prefix end as lonely. The argument for the suffix is symmetrical. h LEMMA 6. Let x be a k-mer at a lonely end of a string in R. Then, x is a doubled k-mer.
PROOF.The only way for x to be marked lonely in B would be in CompactBucket(i), for some i. Assume without loss of generality that this happens in line 4. The left minimizer of x is therefore not i, however, to have been placed into F(i), its right minimizer must be i. Hence, its left and right minimizers are different and it is a doubled k-mer. hThe next Lemma is helpful to establish that each string in R that has a lonely prefix will be examined by Reunite. LEMMA 7. Let u be a string in R with a lonely prefix. Then, there exists distinct strings v 1 ;. .. ; v a in R such that, letting v 0  u; suf k v i   pre k v i1  for 0 < i a and v a has a non-lonely prefix. PROOF. By Lemma 6, the k-mer prefix x of u is doubled, therefore by Lemma 5 there exists a string v 1 in R such that x is the suffix of v 1. If the prefix of v 1 is not lonely, then set a  1 and the Lemma statement is satisfied. Hence, consider the case where the prefix of v 1 is lonely. We prove by an induction over the size of R that v 1 ;. .. ; v a exist and satisfy the conditions stated in the Lemma. For the base case, let R be of size 2. We will prove that the prefix of v 1 is not lonely. Assume for the sake of contradiction that it is. Applying Lemmas 6 and 5 again yields that the prefix of v 1 is the suffix of another string w. Given that R is of size 2, w must be u. Hence, u and v 1 have identical k-mers extremities, they therefore spelled an isolated cycle in the input de Bruijn graph. This contradicts our assumption that U is free of circular unitigs, and concludes the base case. Assume that the inductive hypothesis holds for sets of size strictly smaller than of R. Applying the hypothesis to v 1 in Rnfug, thereNext we analyze the effect that Reunite has on the k and k  1 spectrums. Let G be the final output of the algorithm.Let x 2 K be a doubled k-mer. Then x appears only once in G, either internal to a string or as a non-lonely end. PROOF. By Lemma 5, x appears as a lonely suffix of some string u 1 2 B and as a lonely prefix of another string u 2 2 B. As a consequence of the UF data structure, u 1 and u 2 belong to the same partition P at line 6 of Algorithm 3. We will show that u 1 and u 2 are consecutively selected at line 10 of the Reunite algorithm. Observe that in Reunite, strings selected at line 10 have a lonely prefix (as a consequence of Lemma 5), and strings selected at line 7 do not. If u 1 not does have a lonely prefix, u 1 must be selected at line 7 of Reunite. Then, u 2 is selected at the next execution of line 10. Now, assume that u 1 has a lonely prefix. Then by Lemma 7, thereCompacting de Bruijn graphs from sequencing data quickly and in low memory i205 exists strings v 1 ;. .. ; v a such that suf k v i   pre k v i1  for 0 < i a and v a has a non-lonely prefix. Then, since v a does not have a lonely prefix, v a is selected at line 7 of Reunite, and it follows that v a1 ;. .. ; v 1 ; u 1 ; u 2 are consecutively selected at the following executions of line 10. We conclude that Glueu 1 ; u 2  is performed in all cases. The action of Glue reduces the multiplicity of x from 2 to 1, and furthermore x becomes either an internal k-mer or a non-lonely end of a string in G. h Let R final be the set of strings that might remain in R at the end of the algorithm. LEMMA 9. sp k G has only single elements, and is equal to Set(B).
PROOF.The only difference between B and G [ R final is caused by executing the Glue function, which only affects the k-spectrum by changing the multiplicity of k-mer from 2 to 1. By Lemma 8, all kmers will have multiplicity one in G [ R final , and hence sp k G [R final  has only single elements and is equal to Set(B). It remains to show that R final is empty. All strings in R final have at least one lonely end, otherwise they would have been output at line 7 of CompactBucket(). By Lemma 6, such a lonely end must be a doubled k-mer. However, by Lemma 8, all doubled k-mers are either internal or non-lonely ends in G. Therefore, R final must be empty. h Finally, we are ready to prove the correctness of BCALM 2.We will show that the conditions of Lemma 1 are satisfied for G and U. The glue operation does not change the k  1-spectrum, and R final  1, so sp k1 B  sp k1 G [ R final   sp k1 G. Combining this with Lemma 3 and Lemma 4, we get that sp k1 G  sp k1 B  A  sp k1 U and that, because A is duplicate free by definition, these spectrums do not contain duplicates. Combining Lemma 4 and Lemma 9, we also get that sp k G  K and by Lemma 2, sp k U  K. h
Optimizations and implementationIn this section, we describe some of the optimizations and important implementation details that we used to implement the pseudocode of Section 4. For the sake of brevity, we have only described the algorithm for the directed de Bruijn graph. In our implementation, we extend the algorithm to the bidirected graph model (
Experimental resultsWe evaluated the scalability of BCALM 2, and how it compares to other tools for compacting the de Bruijn graph. Experiments were run on a single machine equipped with an Intel Xeon CPU with 32 cores clocked at 2.76 GHz and 512 GB of memory. We used two human sequencing datasets from the GAGE benchmark () and from and two larger datasets from the spruce and pine sequencing projects ().
Human datasetsThe first dataset is Illumina reads from a human chromosome 14 (36 million, 155 bp each, 2.9 GB compressed FASTQ). The second dataset is Illumina reads from the whole human genome NA18507 (1.4 billion, 100 bp each, 54 GB compressed FASTQ, SRA SRX016231).We first evaluate how BCALM 2 is affected by changes in the parameters k (k-mer size) and ' (minimizer length).(a) shows that BCALM 2 has nearly identical running times for 6 ' 10, and across all tested k values. Shorter minimizers sizes such as '  4 create fewer buckets, hence limit parallel speedups. Second, we evaluate how well BCALM 2 scales with multiple processors.(b)shows that compaction and Reunite steps scale almost linearly with the number of threads. There remains overheads related to disk I/O. We compare the performance of BCALM 2 to other available implementation of compaction algorithms: (i) our own previous serial compaction algorithm BCALM (), (ii) the parallel ABYSS-P step of the ABySS assembler (version 1.9.0), excluding bubble removal (), (iii) the parallel compaction step of the Meraculous 2 assembler (version 2.0.5), executed from the mergraph to the contigs step () and (iv) the single-threaded unitig construction step of the Minia assembler (version 2.0.3) (). There are other promising stand-alone tools that implement parallel de Bruijn graph compaction, but we found them to either not be publicly available () or unable to run on real mammalian data because of an upper bound of 31 on the k-mer size (). For BCALM, the datasets were first processed using the DSK kmer counting software () to generate the set of kmers. In addition to the results shown in, Minia took 27 h and 7 GB of memory on the whole human dataset (using identical k and abundance cutoff as in the table). For ABySS-P, the shown numbers include the k-mer counting step, which could not be extricated from the software. For the purposes of comparison, the k-mer counting step to generate the input for BCALM 2 completed in 46 mins and 2 GB of memory for the whole human dataset.shows that BCALM 2 outperforms existing techniques in terms of running time. Since multiple graph compactions are done in parallel, BCALM 2 requires more memory than BCALM, however it is more memory-efficient than Meraculous 2.
Pine and spruce datasetsWe further evaluated BCALM 2 on two very large sequencing datasets: Illumina reads from the 20 Gbp Picea glauca genome (8.5 billion reads, 152300 bp each, 1.1 TB compressed FASTQ, SRA056234) (), and Illumina paired-end reads from the 22 Gbp Pinus taeda genome (9.4 billion reads, 128154 bp each, 1.2 TB compressed FASTQ, SRX016231). The k-mer counting step took around a day and <40 GB of memory for each dataset.shows the performance of BCALM 2 on these two datasets, as well as unitigs statistics. Graph construction of the spruce dataset previously required 4.3 TB of memory and 2 days on a 1380-core cluster (), while the assembly of the pine dataset previously required 800 GB of memory and 3 months on a single machine (). Another execution of BCALM2 on the same datasets using a value of k61 shows similar performance, see Supplemental. Although we used the same sequencing datasets, several parameters differ between these previous reports and our results (e.g. k value, abundance cutoff, and whether reads were error-corrected). Hence run time, memory usage, and unitigs statistics cannot be directly compared. However, it seems reasonable to infer that BCALM 2 would remain 12 orders of magnitude more efficient in time and memory. In addition, we tested the robustness of BCALM 2 to an even larger number of erroneous k-mers by reducing the k-mer abundance cutoff to 2. The k-mer counting and compactions steps completed also within 2 days and 40 GB of memory. The resulting unitig file was much larger (resp. 67 GB and 107 GB). This is expected, due to a large number of sequencing errors resulting in erroneous k-mers being incorporated into the graph (roughly 2 billion k-mers in both cases, i.e. %2k  10 9  62 Gbp of new unitigs). A non-negligible amount of sequencing errors is also likely present in the data presented in.
DiscussionIn this paper, we present BCALM 2, an open-source parallel and lowmemory tool for the compaction of de Bruijn graphs. BCALM 2 constructed the compacted de Bruijn graph of a human genome sequencing dataset in 76 mins and 3 GB of memory. Furthermore, k-mer counting and graph compaction using BCALM 2 of the 20 Gbp white spruce and the 22 Gbp loblolly pine sequencing datasets required only 2 days and 40 GB of memory each. BCALM 2 is different from previous approaches in several regards. First, it is a separate module for compaction, with the goal that it can be used as part of any other tools that build the de Bruijn graph. While parallel genome assemblers offer impressive performance, there are many situations where differences in data require the development of a new assembler, and hence it is desirable to buildFor BCALM 2 and BCALM we used k  55, and '  8 and '  10, respectively; abundance cutoffs were set to 5 for Chr 14 and 3 for whole human. We used 16 cores for the parallel algorithms ABySS, Meraculous 2 and BCALM 2. Meraculous 2 aborted with a validation failure due to insufficient peak k-mer depth when we ran it with abundance cutoffs of 5. We were able to execute it on chromosome 14 with a cutoff of 8, but not for the whole genome. (  )For the whole genome, we show the running times given in. The exact memory usage was unreported there but is less than <1 TB. Meraculous 2 was executed with 32 prefix blocks.The k-mer size was 31 and the abundance cutoff for k-mer counting was 7.
Compacting de Bruijn graphs from sequencing data quickly and in low memory i207modular components. Second, we do not aim at a method that can be distributed on a cluster over thousands of nodes. While clearly powerful, such machines are not usually accessible to a biology lab, and we believe that a tool that uses a shared memory multi-core machine is more applicable. Methods that are designed for multi-node clusters will often consume a prohibitive amount of memory when run on multiple threads of a shared memory machine.
R.Chikhi et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from
Medvedev et al., 2007), in the natural way, to handle the doublestranded nature of DNA. To compute minimizers, we do not use a lexicographical ordering of '-mers, as this has been previously shown to lead to unbalanced bucket files and increased memory usage (Chikhi et al., 2014; Deorowicz et al., 2014). Deorowicz et al. (2014) proposed to use the lexicographic order but to forbid certain well known frequent '-mers from being minimizers (e.g. the poly-A). We use frequency based minimizers, which we proposed in an earlier work (Chikhi et al., 2014). In this approach, an initial '-mer counting step is performed on the data and '-mers are ordered by increasing frequency. Because ' is small, the time and memory for this step is negligible. Buckets are organized into groups, in order to introduce natural checkpoints in BCALM 2 in between parallel sections. BCALM 2 iterates sequentially through the groups, but parallelizes the processing within a group. The For loop at line 1 of Algorithm 1 is executed in parallel within a group, with each thread given a subset of K. k-mers are distributed only to those buckets that are in the group, with other buckets being ignored. Bucket files are implemented as threadsafe queues, as opposed to physical files on disk. The statements at lines 2 and 4 of Algorithm 1 enqueue x into the appropriate queue, and Algorithm 2 dequeues them at line 1, instead of reading them from disk. After the k-mers are distributed, buckets from a group are compacted in parallel. The CompactBucket routines are independent of each other, and hence we run CompactBucket(i) in parallel using all available processors. After a BCALM 2 finishes processing a group, it moves on to the next group. To reduce memory of the UF data structure, we created a minimal perfect hash function (MPHF) (Cormen, 2009) of all distinct k-mer extremities in the Reunite file (denote their number as d). The UF structure is therefore implemented as a vector v of MPHF indices, of total size dlogd. The UF class of a given k-mer is therefore vx, where x is the MPHF index of the k-mer. The BCALM 2 algorithm takes as input a set of distinct k-mers. However, in our implementation, BCALM 2 is developed using the GATB library (Drezen et al., 2014), allowing it to seamlessly integrate GATB's k-mer counter. Therefore, the BCALM 2 software takes reads as input, and executes this k-mer counter prior to compaction. This is a disk-based algorithm inspired by KMC2 (Deorowicz et al., 2014) and DSK (Rizk et al., 2013). In this k-mer counter, k-mers are divided into partitions according to their minimizer, then each partition is counted independently. We modified the GATB k-mer counting algorithm so that partition files correspond exactly to bucket groups. We obtained further optimizations by representing strings using two bits per character.
