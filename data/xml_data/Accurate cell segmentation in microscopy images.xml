
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics Accurate cell segmentation in microscopy images using membrane patterns</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">18 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Sotiris</forename>
								<surname>Dimopoulos</surname>
							</persName>
							<email>Contact: sotiris.dimopoulos@gmail.com or joerg.stelling@bsse. ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Swiss Institute of Bioinformatics</orgName>
								<orgName type="institution" key="instit2">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Christian</forename>
								<forename type="middle">E</forename>
								<surname>Mayer</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Swiss Institute of Bioinformatics</orgName>
								<orgName type="institution" key="instit2">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Fabian</forename>
								<surname>Rudolf</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Joerg</forename>
								<surname>Stelling</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Swiss Institute of Bioinformatics</orgName>
								<orgName type="institution" key="instit2">ETH Zurich</orgName>
								<address>
									<postCode>4058</postCode>
									<settlement>Basel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimage informatics Accurate cell segmentation in microscopy images using membrane patterns</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="2644" to="2651"/>
							<date type="published" when="2014">18 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu302</idno>
					<note type="submission">Received on November 25, 2013; revised on April 17, 2014; accepted on April 24, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Identifying cells in an image (cell segmentation) is essential for quantitative single-cell biology via optical microscopy. Although a plethora of segmentation methods exists, accurate segmentation is challenging and usually requires problem-specific tailoring of algorithms. In addition, most current segmentation algorithms rely on a few basic approaches that use the gradient field of the image to detect cell boundaries. However, many microscopy protocols can generate images with characteristic intensity profiles at the cell membrane. This has not yet been algorithmically exploited to establish more general segmentation methods. Results: We present an automatic cell segmentation method that decodes the information across the cell membrane and guarantees optimal detection of the cell boundaries on a per-cell basis. Graph cuts account for the information of the cell boundaries through directional cross-correlations, and they automatically incorporate spatial constraints. The method accurately segments images of various cell types grown in dense cultures that are acquired with different micros-copy techniques. In quantitative benchmarks and comparisons with established methods on synthetic and real images, we demonstrate significantly improved segmentation performance despite cell-shape irregularity, cell-to-cell variability and image noise. As a proof of concept, we monitor the internalization of green fluorescent protein-tagged plasma membrane transporters in single yeast cells. Availability and implementation: Matlab code and examples are available at http://www.infobiotics.org/infobiotics
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Nowadays, optical microscopy is widely used to quantify singlecell features, such as cell size or intracellular densities of fluorescent markers. Accurate quantification of such features critically depends on the spatial detection of the cells in the image, that is, on cell segmentation (<ref type="bibr" target="#b18">Li et al., 2013</ref>). Although there is a rapid development of imaging hardware and image analysis software platforms (<ref type="bibr" target="#b12">Eliceiri et al., 2012</ref>), the development of cell segmentation algorithms is lagging behind. For good segmentation results, current approaches are typically applicable to narrowly defined image acquisition protocols (<ref type="bibr" target="#b14">Gordon et al., 2007</ref>) or cell types (<ref type="bibr">W€ ahlby et al., 2012</ref>). As summarized succintly by E. von Meijering: 'Rather than converging to a robust, unified solution, it thus seems that the field is diverging, and by now almost as many cell segmentation methods have been developed as there exist cell analysis problems. . .' (<ref type="bibr" target="#b22">Meijering, 2012</ref>). Cell segmentation is challenging (<ref type="bibr" target="#b26">Peng, 2008</ref>) for many reasons. First, segmenting cellular images requires the identification of multiple objects in the image. The objects have heterogeneous shapes that are typically subject to dynamic changes; mathematical shape models are therefore nearly impossible to define. Second, cell compartmentalization as well as intra-and intercell variability induces non-homogeneous marker distributions within and across cells, leading to undesirable image features such as intensity gradients. Third, growing cell populations usually result in dense cell regions; this makes it hard to assign image features to the correct cell, especially among sets of spatially close cells. Finally, different experimental configurations such as cell types or imaging protocols generate images with greatly varying morphological or intensity characteristics. Most current methods use a few basic algorithms for cell segmentation: intensity thresholding, filtering, morphological operations, region accumulation or deformable models (<ref type="bibr" target="#b22">Meijering, 2012</ref>). In particular, region accumulation approaches such as Voronoi-based methods (<ref type="bibr" target="#b16">Jones et al., 2005</ref>) or the watershed transform (<ref type="bibr" target="#b23">Meyer, 1994</ref>) can result in inaccurate cell boundaries by misspecifications of the cell region to be divided or by oversegmentation (<ref type="figure" target="#fig_1">Fig. 1A</ref>and B). Similarly, popular deformable model approaches such as geodesic active contours (<ref type="bibr" target="#b7">Caselles et al., 1997</ref>), which detect cell boundaries by minimizing a predefined energy functional, can result in poor boundary detection because they use local optimization algorithms that only guarantee to find a local minimum or use the gradient vector field of the image to decode the boundary information (<ref type="figure" target="#fig_1">Fig. 1C</ref>). However, optical microscopy can generate distinctive intensity information across the cell membrane, which, so far, has been algorithmically used to only a small extent. For example, cell segmentation via ring filters (<ref type="bibr" target="#b13">Eom et al., 2010</ref>) accounts crudely for the intensity profile across the cell membrane and imposes strict cell-shape requirements. Furthermore, certain combinatorial optimization algorithms can guarantee to find the global optimum of a defined energy functional, such as the combinatorial graph-cut algorithms. To segment microscopy images, previous *To whom correspondence should be addressed. y The authors wish it to be known that, in their opinion, the last two authors should be regarded as Joint Last Authors. applications of graph cuts in conjunction with the gradient vector field of the image (<ref type="bibr" target="#b30">Xu et al., 2007;</ref><ref type="bibr" target="#b17">Lesk o et al., 2010</ref>) were limited to identify the image background (<ref type="bibr" target="#b0">Al-Kofahi et al., 2010</ref>) or to separate cell nuclei (<ref type="bibr" target="#b11">Dan ek et al., 2009</ref>). Graph cuts with automatic spatial constraints applied to the cellular segmentation of RNA interference (RNAi) screening images need an additional image (<ref type="bibr" target="#b9">Chen et al., 2008</ref>). Other graph-cut-based object detection approaches that do not use the gradient vector field of the image typically only work well when the intensity distributions of the cellular regions and the background are rather dissimilar (<ref type="bibr" target="#b32">Zeng et al., 2006</ref>). Here, we present a method for cell segmentation that uses a single image, allows for image acquisition with different experimental techniques and copes with various cell shapes and densely populated areas. The method is based on the detection of membrane patterns, and we therefore term it membrane pattern-based cell segmentation (MPCS). The membrane pattern information is cast into a spatially constrained graph-cut framework, which allows us to address the typical challenges in the segmentation of microscopy images discussed above. We demonstrate the applicability and performance of MPCS for diverse synthetic and real biological examples, with significantly improved performance compared with established segmentation methods. Because accurate boundary detection is especially important in quantitative signaling studies, we quantify the internalization of plasma membrane transporters in yeast as a proof of concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detection of cell boundaries</head><p>Overview. MPCS works with microscopy images of cells with a membrane pattern, that is, a characteristic intensity profile across their membrane. Based on the input image, we first specify few biologically intuitive parameters. Then, we detect potential points inside the cells (called seeds). Each seed is processed individually, and an optimal connected boundary for each cell is detected by combining directional cross-correlation operations with graph cuts. Cross-correlation is a signal processing technique that measures similarities between two signals and is used here to decode the membrane pattern information. This pattern information is cast to a graph, and together with automatically defined spatial constraints, we use graph cuts to optimally separate each cell from the background. All individual segmentation results are processed to obtain the final segmentation of the image. Input. The biologically intuitive parameters of MPCS can be set interactively through the graphical user interface of CellX (<ref type="bibr" target="#b21">Mayer et al., 2013</ref>), set manually, or automatically derived via supervised machine learning approaches from a small training set of segmented cells. For the example image of budding yeast cells with aberrant morphology (<ref type="figure" target="#fig_3">Fig. 2A</ref>), we first estimate the maximal radii of circles in the smallest and largest cells in the image (r min , r max values; blue). Then, we determine the length of the major axis of the largest cell (l m value; green line). We estimate the cells' membrane pattern (vector of intensity values M, shown in the red plot) by averaging the intensities of a set of example membrane profile rays (drawn from the inside of the cell to the outside, as shown by the red arrows). We also define the position of the cell's boundary on the membrane pattern (index m o : Mðm o Þ 2 M; shown with the white filled circle). Seeding. In this step, we identify potential points inside the cells (seeds). In most cases, a combination of traditional image processing operations can easily provide us with seeds (see Supplementary Note; Supplementary<ref type="figure" target="#fig_1">Fig. S1</ref>). Here, we exemplify the process by use of a gradient-based Hough algorithm (<ref type="bibr" target="#b1">Ballard, 1981</ref>) on the input image composed of a set of pixels L=W Â H, W=f1;. .. ; wg, H=f1;. .. ; hg, where w and h are the image's width and height (measured in number of pixels), respectively. We compute the gradient vector field of the image (blue arrows in<ref type="figure" target="#fig_3">Fig. 2B</ref>) and perform a counting operation for image pixels along each gradient vector. Every time a pixel lies in the direction of a gradient vector (at a distance between r min and r max ), we collect a value proportional to the gradient's magnitude. The counts for all image pixels are stored in the so-called accumulation array (color-coded region in<ref type="figure" target="#fig_3">Fig. 2B</ref>). Typically, lines in the direction of the gradients originating from convex features of the input image intersect the same pixels, thereby generating local maxima in the accumulation array. We detect the image regions with local maxima and use their centers as seeds (green crosses in<ref type="figure" target="#fig_3">Fig. 2B</ref>; see Supplementary Note and Supplementary<ref type="figure" target="#fig_3">Fig. S2</ref>). For every seed located at pixel s=ðx s ; y s Þ, where x s 2 W and y s 2 H, we also compute the radial distance r c 2 ½r min ; r max  that maximizes the gradient information along the perimeter of the circle with center s and radius r c .<ref type="bibr">, 1975</ref>) followed by a Voronoi-based algorithm (<ref type="bibr" target="#b16">Jones et al., 2005</ref>). Regions inside the blue rectangles were used as seeds. (B) Phase-contrast of S.pombe cells. Boundaries were automatically detected by the watershed algorithm (<ref type="bibr" target="#b23">Meyer, 1994</ref>), applied to a smoothed gradient vector field of the initial image. Regions inside the blue rectangles were used as minima during the flooding operation. (C) Bright-field image of alf1" S.cerevisiae cells. Boundaries were automatically detected by active contour-based segmentation [active contour evolution with level sets (<ref type="bibr" target="#b29">Whitaker, 1998</ref>); geodesic active contour as the energy model (<ref type="bibr" target="#b7">Caselles et al., 1997)]</ref>. Blue rectangles represent the initial state of the active contour Bresenham's algorithm (<ref type="bibr" target="#b5">Bresenham, 1965</ref>) to find which image pixels lie in every line segment that starts at the seed and ends in each of the border pixels of I. We then compute the intensity profiles along these directed line segments (rays) and use cross-correlation (<ref type="bibr">Orfanidis, 1996</ref>) to quantify their similarity with the reference membrane pattern, M. Cross-correlation values are high in regions consistent with the membrane pattern and low in regions that do not follow the pattern. The cross-correlation values along all rays allow us to construct a cross-correlation image (<ref type="figure" target="#fig_3">Fig. 2C</ref>; see Supplementary Note) that is used for the formulation of the cell boundary-tracing problem on a graph. We further refer to CC(p) as the cross-correlation result assigned to pixel p=ðx p ; y p Þ in the pixel set P=X Â X, X=f1;. .. ; 2l m +1g of I. Graph cuts and energy minimization. For every image crop I, we use graph cuts to separate the image region comprising the cell from the region outside the cell (background and neighboring cells). This amounts to assigning a binary (cell or background) label A p to each pixel p 2 P. We combine these assignments in a vector A of dimension 1 Â jPj (where jPj % 10 4 for microscopy images of cells with l m =50 pixels). We first define a directed weighted graph G=ðV; E; wÞ with vertex set V = P. We define the neighborhood of radius r of a pixel p 2 P by the function Nðp; rÞ =fq 2 Pj jjp À qjj 2 rg to specify the edge set as E=[ p2P<ref type="bibr">[</ref>where wðp; qÞ measures the cost of assigning two neighboring pixels to different partitions (boundary information), and the function idðÁÞ is 1 if the condition inside the parenthesis is true, and 0 otherwise. We find the optimal vector A that minimizes EN(A) by finding the min-cut on the previously defined image graph. The min-cut/max-flow algorithm (<ref type="bibr" target="#b4">Boykov and Kolmogorov, 2004</ref>) yields the optimal solution in polynomial time. According to (<ref type="bibr" target="#b3">Boykov and Kolmogorov, 2003</ref>), if we define the weights of the edges as</p><formula>wððp; qÞÞ= 2 Á j pq j 2 Á " Á detðDðpÞÞ 2 Á ½ T pq Á DðpÞ Á pq  3=2 ;</formula><p>then the min-cut corresponds to the globally optimal geodesic for the processed cell. denotes the side length of the square pixels (equals to 1 in our case); pq , the vector connecting the graph vertices p and q; ", the angular orientation difference of the grid's characteristic vectors (equals to =4 for our 8-neighborhood system); detðÁÞ, the determinant operation; and D(p) is the metric tensor in pixel p defined as</p><p>DðpÞ=gðpÞ Á I+ð1 À gðpÞÞ Á uðpÞ Á uðpÞ T ;</p><p>where I is the identity matrix, u(p) is a unit vector in the direction of image gradient at pixel p and g(p) is the scalar function that maps the magnitude of the boundary information on the weights of the graph. As in (<ref type="bibr" target="#b3">Boykov and Kolmogorov, 2003</ref>), we use the exponential function and include the cross-correlation values as gðpÞ=expðÀ10 CCðpÞ Þ. Spatial constraints. To avoid trivial solutions and constrain the number of meaningful cell boundaries, we pose automatic spatial constraints to our graph cut definition by transforming the problem to a multisource/ multisink max-flow problem (<ref type="figure" target="#fig_3">Fig. 2D</ref>). Specifically, we define a circular region around the seed s of radius r c =2, C=Nðs; r c =2Þ &amp; P, that has to be part of the cell (orange region) as well as the pixel set in the cropped image border B=fp 2 P jjNðp; ffiffi ffi 2 p Þj58g &amp; P (green region) as background. By using infinite edge weights to connect the pixels in C and B to dedicated source and sink vertices, respectively, we constrain graph cuts to the region between C and B (e.g. white contour). The assignment of A with minimal energy EN(A) given by the min-cut results in an optimal binary segmentation of the cropped image (blue and red regions). Final segmentation. The single-seed segmentation results are further processed to obtain the final segmentation of the image. First, we eliminate single-seed segmentations that represent statistical outliers with respect to their morphology and cross-correlation values across the predicted membrane pixels. Then, we merge those seeds that claim almost identical regions in the image. Finally, we resolve small overlaps of cell segmentations by assigning the pixels to the closest competing cell. These steps (for more details, see Supplementary Note) ensure that finally every image pixel is uniquely assigned to either the background or to one of the cells. The segmentation result for the input image can be seen inFigure 2E (and for the other examples of<ref type="figure" target="#fig_1">Fig. 1</ref>in<ref type="figure" target="#fig_3">Fig. 2F</ref>). Additional full image segmentations are shown in Supplementary Figures S3–S10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ALGORITHMIC FEATURES</head><p>Diverse types of microscopy images. To evaluate the applicability of our method to different image acquisition techniques, we considered different transmission light and fluorescence microscopy methods. Saccharomyces cerevisiae and Saccharomyces pombe cells were imaged using out-of-focus bright-field and phasecontrast imaging, respectively, whereas fluorescence microscopy of endogenously tagged Mup1-GFP (green fluorescent protein) S.cerevisiae cells was used to generate a nearly uniform intensity pattern around the cell (<ref type="figure" target="#fig_5">Fig. 3A left</ref>). An important feature of MPCS is that, despite differences in the characteristic membrane patterns of the imaging methods, similar correlation images are generated (<ref type="figure" target="#fig_5">Fig. 3A</ref>middle). As a result, the cell boundaries can be accurately inferred (Flexible boundary definition. Many segmentation algorithms associate the high intensity gradient information of the image with the cells' boundaries. This is reasonable, for instance, when the background intensity distribution is different from the cells' intensity distribution. However, depending on the image acquisition protocol, high intensity gradients could be present inside a cell (e.g. out-of-focus bright-field image in<ref type="figure" target="#fig_1">Fig. 1C</ref>). Furthermore, the intensity distribution of the background may be different in regions around the cells (locally) than in the rest of the image (e.g. local fluorescence effects in<ref type="figure" target="#fig_1">Fig. 1A</ref>). In such cases, it is difficult to accurately detect the cells' boundaries based on the gradient information or on the identification of the image background. MPCS circumvents these problems by assigning the highest cross-correlation values to the pixels of the cell membrane corresponding to the position m o (white dot in<ref type="figure" target="#fig_5">Fig. 3B</ref>) of the membrane pattern M (red line). Thereby, we can conveniently define the cell boundaries independent of the local gradient information across the membrane profile (<ref type="figure" target="#fig_5">Fig. 3B</ref>). Dense cultures. Our method leads to a successful segmentation in crowded image regions, as illustrated for dense S.pombe culture images acquired in bright field (<ref type="figure" target="#fig_5">Fig. 3C</ref>left) because of the directionality in the cross-correlation step. As every intensity ray traverses from a seed to the border, we analyze an intensity segment that includes the cell's membrane pattern followed by the adjacent cell's mirrored version of the pattern. Along this segment, the cross-correlation is high at the cell's membrane region (red area in<ref type="figure" target="#fig_5">Fig. 3C</ref>; middle) and low immediately afterwards (blue area in<ref type="figure" target="#fig_5">Fig. 3C</ref>); the same effect appears for all basic forms of membrane patterns (Supplementary<ref type="figure" target="#fig_1">Fig. S11</ref>). This suppression of the neighboring cell's information restricts the graph cut to optimally isolate the currently processed cell from the rest of the image; graph cuts in low-valued cross-correlation regions have an increased cost. As a result, MPCS successfully segments crowded cell regions (<ref type="figure" target="#fig_5">Fig. 3C</ref>right; see Supplementary<ref type="figure">Fig. S6</ref>for the full image segmentation). Non-convex shapes and cell types. Cells may have non-convex and diverse shapes, which makes segmentation difficult. MPCS deals with non-convex shapes in two different ways. First, if the seed is placed inside the non-convex object such that all rays cross the membrane region in the correct direction (seed 'S1' in<ref type="figure" target="#fig_5">Fig. 3D</ref>), the cross-correlation image captures the membrane information accurately, leading to accurate segmentation (<ref type="figure" target="#fig_5">Fig. 3E</ref>). However,if the seed is not placed in such a region (seed 'S2' in<ref type="figure" target="#fig_5">Fig. 3D</ref>), the rays may cross a part of the membrane region in the wrong direction, leading to partially inaccurate boundary detection (<ref type="figure" target="#fig_5">Fig. 3F</ref>). Therefore, we place extra seeds at low-valued pixels of each initial membrane result (<ref type="figure" target="#fig_5">Fig. 3G</ref>), and we update the cross-correlation image (<ref type="figure" target="#fig_5">Fig. 3H</ref>) to also segment non-convex shapes (<ref type="figure" target="#fig_5">Fig. 3I</ref>). As a result, our segmentation method provides a tool for the analysis of images of different cell types (<ref type="figure" target="#fig_5">Fig. 3J</ref>and K; see Supplementary Figs S8–S10 for full image segmentations). Note, however, that MPCS may fail to capture highly irregular parts of the cell boundary (<ref type="figure" target="#fig_5">Fig. 3K</ref>), as the use of the geodesic model leads typically to smooth segmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SEGMENTATION PERFORMANCE ON SYNTHETIC IMAGES</head><p>We next aimed at a quantitative characterization of the segmentation algorithm's performance. For this purpose, we generated realistic synthetic microscopy images that represent different cell phenotypes as well as fluorescence, bright-field and phasecontrast imaging (<ref type="figure" target="#fig_6">Fig. 4</ref>; see Supplementary Note for details). We defined two measures for the cell detection quality (sensitivity, that is, the proportion of true-positive findings, and positive predictive value, the proportion of detected cells that are true), one measure for the spatial accuracy of the segmentation (pixel accuracy of the cell area) and one measure to quantify the error in the detected cell contour (see Supplementary Note for details). Cell-shape irregularity. To evaluate the influence of cell shapes on the segmentation performance, we generated synthetic microscopy images with increasing cell-shape irregularities (<ref type="figure" target="#fig_6">Fig. 4A</ref>). The shape irregularity coefficient is a multiplier of a random term that displaces the pixels of an initial ellipse. For regular shapes, the mean segmentation sensitivity is close to 1 and the contour error below half a pixel; sensitivity only drops below 0.9 at an irregularity value of 0.5 (<ref type="figure" target="#fig_6">Fig. 4A</ref>). Hence, the algorithm captures accurately a large fraction of the cells even for non-convex cell shapes. Importantly, the positive predictive value and the pixel accuracy are barely affected by the shape: their respective mean values are always 40.9 (<ref type="figure" target="#fig_6">Fig. 4A</ref>). Cell-to-cell variability. Because of uneven illumination of bright-field images or through stochastic noise in fluorescent protein expression, intensities within the cell population can vary, which poses additional challenges for segmentation (see Supplementary<ref type="figure" target="#fig_6">Fig. S4</ref>for S.cerevisiae with fluorescence staining). To examine the segmentation performance under such conditions, we generated images with variable cell intensity values (see Supplementary Note for details).<ref type="figure" target="#fig_6">Figure 4B</ref>shows that MPCS performance is largely unaffected by this variability, indicating high-quality segmentation for all levels of intercell variability investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS COMPARISON</head><p>To compare our algorithm with popular methods for cell segmentation, we quantified segmentation performance with respect to the error in the cell contour (for definition, see Supplementary Note) and morphological cell features such as cell area and eccentricity. Accurate membrane identification is particularly crucial for cell-signaling studies, for example, when densities of fluorescent markers on the cell membrane need to be quantified (<ref type="bibr" target="#b15">Irani et al., 2012</ref>). Accurate morphological cell features aid substantially in the analysis of cellular phenotypes, for example, to automatically classify subpopulations of cells (<ref type="bibr" target="#b33">Zhong et al., 2012</ref>). For controlled performance comparison, we used different types of synthetic images with various levels of imaging noiseImages were generated with varying levels of cell-shape irregularity (A) and of cell-to-cell intensity variability (B). Numbers in the images specify the corresponding coefficient values: shape irregularity coefficient (A) and variation for independently drawn random assignments of intensities for each cell (B). Statistics were obtained for 12 randomly generated synthetic images [(A): fluorescence, bright field and phase contrast; (B): fluorescence only] of 150 cells. Graphs show median and quartiles for the segmentation sensitivity (blue), the positive predictive value (green), the pixel accuracy of the cell area (red) and the contour error (black, in pixels). (C) Example of a synthetic image with three cell subpopulations (identified by colored dots in the cells' centroids) with low (green), medium (red) and high (blue) eccentricity and area. (D) Crops of synthetic fluorescence (top), brightfield (middle) and phase-contrast (bottom) noisy images used for comparison. Noise levels (numbers) are measured in decibel (see Supplementary Note). (E) Cell classification by quadratic discriminant analysis based on 'true' cell areas and eccentricities. (F–H) Comparison of algorithms: 'MPCS' (our algorithm), 'watershed' (the watershed algorithm), 'Chan–Vese' and 'geodesic active contour' (active contour evolution with level sets; Chan–Vese and geodesic active contours as the energy model, respectively). Mean error values for cell contour (F), cell area and cell eccentricity (G) and cell type classification (H) for the fluorescence (blue), bright-field (green) and phase-contrast (red) image sets (<ref type="figure" target="#fig_6">Fig. 4C</ref>and D; see Supplementary Note). Cells were generated such that three distinct subpopulations exist with respect to their area and eccentricity, as verified by quadratic discriminant analysis on these cellular features (<ref type="figure" target="#fig_6">Fig. 4C</ref>–E). We compared our method with the watershed algorithm (<ref type="bibr" target="#b23">Meyer, 1994</ref>) and with two algorithms that evolve active contours (implemented with levels sets) by use of the Chan–Vese (<ref type="bibr" target="#b8">Chan and Vese, 2001</ref>) and of the geodesic active contour (<ref type="bibr" target="#b7">Caselles et al., 1997</ref>) energy model, respectively (for implementation details, see Supplementary Note). This selection represents the algorithmic basis of numerous cell segmentation approaches. With respect to accurate detection of the cell contour, the mean error of MPCS never exceeds one pixel, but the other algorithms yield large errors because of the high intensity gradients inside the cell and the undesired gradients from imaging noise (<ref type="figure" target="#fig_6">Fig. 4F</ref>). Similarly, for the extracted morphological cell features, MPCS's mean errors are always 50.1, whereas competing algorithms show substantially larger error ranges (<ref type="figure" target="#fig_6">Fig. 4G</ref>). Finally, we quantified the effect of the morphological errors in a classification problem. We built a classifier based on the morphological features of the ground truth cell images and assessed the effect of segmentation errors on the classification accuracy. Segmentation errors of our algorithm lead to low misclassification rates in contrast to wrong assignments of 15–75% of the cells for the other algorithms (<ref type="figure" target="#fig_6">Fig. 4H</ref>; see also the distributions in Supplementary<ref type="figure" target="#fig_1">Fig. S12</ref>).Time courses of total fluorescence (normalized by the cell area and the mean fluorescence of the cells at t = 0 min) in the cell (black), the cytoplasm (blue), the membrane (red) and spots (green, scaling factor 50). Dots denote the population average, and error bars show the standard error parameters need to be carefully set to avoid erroneous segmentations (<ref type="bibr" target="#b22">Meijering, 2012</ref>). A key feature of our algorithm is to combine cross-correlation for detecting membrane patterns with graph cuts for tracing the cell boundary. The cross-correlation operation decodes the cell membrane information, and the result is robust to intensity perturbations or image noise (Supplementary<ref type="figure" target="#fig_1">Fig. S13</ref>). Furthermore, the directional application of the cross-correlation aids in accurately detecting the cell membrane in dense regions by suppressing the intensity information of touching cells. Graph cuts are a convenient and efficient method to solve the optimization problem posed by image segmentation (<ref type="bibr">Boykov and FunkaLea, 2006</ref>), and here they are used to find an accurate boundary for each cell without needing prior knowledge on the cell shape. So far, the use of graph cuts for cell segmentation has not included a formulation with cell membrane pattern information. Automatic placement of topological constraints has been primarily used for cell tracking purposes (<ref type="bibr" target="#b20">Ma ska et al., 2013</ref>), and it can improve the segmentation quality only if each cell is initialized with one seed. An advantage of our segmentation strategy is that it is largely unaffected by the seeding scheme. Other deformable model-based segmentation methods that define the optimization problem on the space of continuous functions, such as level-set methods (<ref type="bibr" target="#b27">Sethian, 1999</ref>), typically use optimization algorithms that guarantee to find a local minimum of the defined energy functional (<ref type="bibr" target="#b2">Boykov and Funka-Lea, 2006</ref>). As a result, when the gradient vector field of the image is used to detect the cell boundary, good segmentation performance depends substantially on a reliable initial boundary estimate, which is hard to obtain automatically. MPCS, in contrast, requires easily accessible spatial constraints, such as the image border and the region around a seed. To illustrate typical applications enabled by our method, we showed for yeast endocytosis how accurate boundary detection can be successfully performed when GFP intensities are subject to spatiotemporal dynamics. We used only the bright-field images to detect cell boundaries and used a single fluorescence channel to acquire a variety of high-quality single-cell fluorescence measurements. Such a quantification strategy allows for the monitoring of spatially dynamic quantities in all available fluorescence channels, and compared with other approaches (<ref type="bibr" target="#b6">Carpenter et al., 2006;</ref><ref type="bibr" target="#b9">Chen et al., 2008</ref>), it does not need additional 4 0 ,6-diamidino-2-phenylindole markers or constitutively expressed markers for the segmentation process. We envisage that the accurate identification of cells and cell membranes will enable the extraction of quantitative datasets that will increase our understanding in many biological applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QUANTITATIVE ANALYSIS OF BUDDING YEAST ENDOCYTOSIS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Construction of cross-correlation images. Next, we process each seed individually and center it in a square window of the image [image crop I with width 2l m +1; new seed location at s=ðl m ; l m Þ]. We first use</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Limitations of existing segmentation approaches. Initial cell images (top), identified boundaries (middle; red) and final segmentations (bottom). (A) Fluorescence image of S.cerevisiae cells. Boundaries were automatically detected by automatic Otsu's thresholding (Otsu, 1975) followed by a Voronoi-based algorithm (Jones et al., 2005). Regions inside the blue rectangles were used as seeds. (B) Phase-contrast of S.pombe cells. Boundaries were automatically detected by the watershed algorithm (Meyer, 1994), applied to a smoothed gradient vector field of the initial image. Regions inside the blue rectangles were used as minima during the flooding operation. (C) Bright-field image of alf1" S.cerevisiae cells. Boundaries were automatically detected by active contour-based segmentation [active contour evolution with level sets (Whitaker, 1998); geodesic active contour as the energy model (Caselles et al., 1997)]. Blue rectangles represent the initial state of the active contour</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>This connects each pixel to its vertical, horizontal and diagonal neighbors in I. The edges carry a weight according to the edge weight function w : E ! R, which leads to the definition of an energy function ENðAÞ= X ðp;qÞ2E wððp; qÞÞ Á idðA p 6 ¼ A q Þ ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Fundamental steps of MPCS and segmentation results. (A) Initial bright-field image (left) and parameters (right). (B) Gradient-based Hough algorithm. Based on the gradient vector field of the image (blue arrows; see inset), we acquire an accumulation array (color coded), and its maxima (red) serve as seed locations (green crosses). (C) Cross-correlation images for the six seeds shown in the initial image (panel A; white numbers). The magnitude of the cross-correlation values is color coded. (D) Spatial graph-cut constraints. The orange and green regions are assigned a priori to the cell and to the background, respectively. The white contour represents a feasible cut. The final optimally segmented regions are shown in red (cell) and blue (background) of MPCS. Segmentation results. (E) For the initial image. (F) For the rest of the images shown in Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Fig. 3A right) for such image acquisition techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.3.</head><figDesc>Fig. 3. Exploitation of membrane patterns, dense cultures, non-convex shapes and cell types. (A) Left: membrane patterns generated with bright field (top), bright field (middle) and fluorescence microscopy (bottom). The inset shows the cell's membrane pattern across the red line segment; automatically detected seeds are denoted with 'S1' and 'S2'. Middle: cross-correlation images for the detected seeds. Right: segmentation results. (B) Detected cell boundary depending on the relative position of the outer membrane (white dot) on the membrane pattern (red line). (C) Crowded region of S.pombe culture recorded in bright field. Seeds of two neighboring cells (left: red and orange frames; seeds denoted by 'S') generate different cross-correlation landscapes (middle). The final boundary detection is shown on the right image. (D) Synthetic image of a nonconvex shape with seeds. (E–F) Cross-correlation image (left) and graphcut result (right) for (E), seed 'S1', and (F), seed 'S2'. (G) Identification of low cross-correlation region (black line) after analysis of 'S2'. Extra seed placement ('eS2'; black dot). (H) Updated cross-correlation image for seed 'S2' and graph-cut result. (I) Final segmentation result. (J–K) Initial bright-field image (left) and final segmentation result (right) for (J), Escherichia coli cells, and (K), mouse embryonic stem cells (mESCs). Blue boxes indicate incorrectly identified parts of a cell's boundary</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.4.</head><figDesc>Fig. 4. Segmentation performance of MPCS on synthetic images and algorithmic comparison. Images were generated with varying levels of cell-shape irregularity (A) and of cell-to-cell intensity variability (B). Numbers in the images specify the corresponding coefficient values: shape irregularity coefficient (A) and variation for independently drawn random assignments of intensities for each cell (B). Statistics were obtained for 12 randomly generated synthetic images [(A): fluorescence, bright field and phase contrast; (B): fluorescence only] of 150 cells. Graphs show median and quartiles for the segmentation sensitivity (blue), the positive predictive value (green), the pixel accuracy of the cell area (red) and the contour error (black, in pixels). (C) Example of a synthetic image with three cell subpopulations (identified by colored dots in the cells' centroids) with low (green), medium (red) and high (blue) eccentricity and area. (D) Crops of synthetic fluorescence (top), brightfield (middle) and phase-contrast (bottom) noisy images used for comparison. Noise levels (numbers) are measured in decibel (see Supplementary Note). (E) Cell classification by quadratic discriminant analysis based on 'true' cell areas and eccentricities. (F–H) Comparison of algorithms: 'MPCS' (our algorithm), 'watershed' (the watershed algorithm), 'Chan–Vese' and 'geodesic active contour' (active contour evolution with level sets; Chan–Vese and geodesic active contours as the energy model, respectively). Mean error values for cell contour (F), cell area and cell eccentricity (G) and cell type classification (H) for the fluorescence (blue), bright-field (green) and phase-contrast (red) image sets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.5.</head><figDesc>Fig. 5. Quantitative dynamic analysis of yeast endocytosis. (A) Yeast cells expressing Mup1-GFP imaged before and after addition of methionine. The bright-field out-of-focus and fluorescence images are overlaid, and the time after addition is indicated. (B) Image crop of a bright-field image with its segmentation result (left). The blue frame includes an example cell for which the fluorescence image is shown (right). (C) Detected intensity spots (left) and membrane area (right). (D) Time courses of total fluorescence (normalized by the cell area and the mean fluorescence of the cells at t = 0 min) in the cell (black), the cytoplasm (blue), the membrane (red) and spots (green, scaling factor 50). Dots denote the population average, and error bars show the standard error</figDesc></figure>

			<note place="foot">ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Cell segmentation at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">S.Dimopoulos et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">To test the accuracy and usefulness of MPCS in a real-world proof-of-principle application, we focused on the internalization of plasma membrane transporters. Specifically, we used the budding yeast methionine transporter Mup1 tagged with GFP to monitor the clearance of the protein from the plasma membrane (Fig. 5A, Supplementary Movie). Mup1 is internalized upon the addition of methionine to the media, and it serves as a model in studying ubiquitin-dependent endocytosis (Lin et al., 2008). A time-resolved single-cell quantification of this process clearly requires faithful detection of the cell boundaries and accurate quantification of fluorescence quantities. As expected, shortly after the onset of the internalization process, fluorescence transferred from the cell membrane to the cytoplasm. For such dynamic phenomena, accurate boundary detection of the cells based on the fluorescence image is nearly impossible because at the end of the experiment, fluorescence levels in the membrane are close to zero and because lowexpressing cells are hard to detect in all frames. We performed the segmentation on the bright-field images and used the fluorescence images to properly define the relative position of the cell boundary on the membrane pattern (Fig. 5B). This allowed us to precisely detect the cell boundaries throughout the experiment and hence to accurately capture the GFP information in the membrane and in other cellular compartments (Fig. 5C; see Supplementary Note). Despite using only one of the available fluorescence channels, the quantification process resulted in a wealth of information on the single-cell dynamics of the Mup1 transporter (see Fig. 5D for all cells that were tracked over the entire time course; quantities were normalized by each cell&apos;s area and mean initial intensity). Such single-cell quantitative data will allow for future detailed studies of endocytosis beyond existing studies that used bulk measurements of specific regulators involved in vesicle maturation (Zeigerer et al., 2012) or extracted only endosomal intensity properties via confocal microscopy (Collinet et al., 2010). 4 DISCUSSION Accurate detection of cell boundaries is a crucial and challenging step for high-quality single-cell quantification, and, to this date, no general cell segmentation solution exists. Our method allows us to analyze microscopy images taken by diverse acquisition techniques and for a variety of cells types. For the real and synthetic images analyzed here, the segmentation quality is largely independent of cell shape, density, intercell variability and image noise. Compared with popular algorithms used for the detection of the cell boundaries, MPCS shows small errors in the spatial identification of the cells&apos; membranes and their morphological features. Clearly, limitations of our method exist, mainly when cells do not have a single uniform membrane pattern, or when the cell shape is highly irregular. The intensity pattern across the cell membrane or the cell length is intuitive and easily accessible features of the cell population. Our segmentation method can be easily parametrized by annotating example cells through the graphical user interface of CellX [for a detailed user guide, see (Mayer et al., 2013)]. In contrast, boundary detection of cells based on deformable models, such as active contours, involves non-intuitive adjustments of the parameters that control the energy terms, which are typically correlated and problem dependent. These</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved automatic detection and segmentation of cell nuclei in histopathology images</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Al-Kofahi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="841" to="852" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Generalizing the Hough transform to detect arbitrary shapes</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ballard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph cuts and efficient ND image segmentation</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Boykov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Funka-Lea</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="109" to="131" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Computing geodesics and minimal surfaces via graph cuts</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Boykov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kolmogorov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth IEEE International Conference on Computer Vision</title>
		<meeting>the Ninth IEEE International Conference on Computer Vision<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">An experimental comparison of min-cut/ max-flow algorithms for energy minimization in vision</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Boykov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kolmogorov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1124" to="1137" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Algorithm for computer control of a digital plotter</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">E</forename>
				<surname>Bresenham</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Syst. J</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="25" to="30" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Cellprofiler: image analysis software for identifying and quantifying cell phenotypes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Carpenter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Geodesic active contours</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Caselles</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Active contours without edges</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">F</forename>
				<surname>Chan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">A</forename>
				<surname>Vese</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Constraint factor graph cut–based active contour method for automated cellular image segmentation in RNAi screening</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Microsc</title>
		<imprint>
			<biblScope unit="volume">230</biblScope>
			<biblScope unit="page" from="177" to="191" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Systems survey of endocytosis by multiparametric image analysis</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Collinet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">464</biblScope>
			<biblScope unit="page" from="243" to="249" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Segmentation of touching cell nuclei using a two-stage graph cut model</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Dan Ek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 16th Scandinavian Conference, SCIA</title>
		<meeting>16th Scandinavian Conference, SCIA<address><addrLine>Oslo, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="410" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Biological imaging software tools</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Eliceiri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="697" to="710" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Detection of hematopoietic stem cells in microscopy images using a bank of ring filters</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Eom</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Int. Symp. Biomed. Imaging</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="137" to="140" />
			<date type="published" when="2010" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Single-cell quantification of molecules and rates using opensource microscope-based cytometry</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gordon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="175" to="181" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Fluorescent castasterone reveals bri1 signaling from the plasma membrane</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">G</forename>
				<surname>Irani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Chem. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="583" to="589" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Voronoi-based segmentation of cells on image manifolds</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Jones</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of First International Workshop, CVBIA</title>
		<meeting>First International Workshop, CVBIA<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="535" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Live cell segmentation in fluorescence microscopy via graph cut</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lesk O</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1485" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Bioimage informatics for systems pharmacology</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Arrestin-related ubiquitin-ligase adaptors regulate endocytosis and protein turnover at the cell surface</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="714" to="725" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Segmentation and shape tracking of whole fluorescent cells based on the chan-vese model</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ma Ska</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="995" to="1006" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Using CellX to quantify intracellular events</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Mayer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Protoc. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Cell segmentation: 50 years down the road [life sciences]</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Meijering</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="140" to="145" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">Topographic distance and watershed lines. Signal Process</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Meyer</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="113" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title level="m" type="main">Optimum Signal Processing: An Introduction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Orfanidis</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>McGrawHill Publishing Company</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">A threshold selection method from gray-level histograms</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Otsu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="23" to="27" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Bioimage informatics: a new area of engineering biology</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1827" to="1836" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<monogr>
		<title level="m" type="main">Level Set Methods and Fast Marching Methods</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sethian</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">3</biblScope>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">An image analysis toolbox for high-throughput C. elegans assays</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>W€ Ahlby</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="714" to="716" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">A level-set approach to 3D reconstruction from range data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">T</forename>
				<surname>Whitaker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="203" to="231" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Object segmentation using graph cuts based active contours</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Xu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="210" to="224" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Rab5 is necessary for the biogenesis of the endolysosomal system in vivo</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Zeigerer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">485</biblScope>
			<biblScope unit="page" from="465" to="470" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title level="m" type="main">Efficiently solving the piecewise constant mumford-shah model using graph cuts</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Zeng</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised modeling of cell morphology dynamics for time-lapse microscopy</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Zhong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="711" to="713" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>