
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics Determining the subcellular location of new proteins from microscope images using local features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">18 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Luis</forename>
								<forename type="middle">Pedro</forename>
								<surname>Coelho</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Center for Computational Biology</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Joint Carnegie Mellon University-University of Pittsburgh Ph.D. Program in Computational Biology</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Joshua</forename>
								<forename type="middle">D</forename>
								<surname>Kangas</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Center for Computational Biology</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Joint Carnegie Mellon University-University of Pittsburgh Ph.D. Program in Computational Biology</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Armaghan</forename>
								<forename type="middle">W</forename>
								<surname>Naik</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Center for Computational Biology</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Joint Carnegie Mellon University-University of Pittsburgh Ph.D. Program in Computational Biology</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Elvira</forename>
								<surname>Osuna-Highley</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Biomedical Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Estelle</forename>
								<surname>Glory-Afshar</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Biomedical Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Margaret</forename>
								<surname>Fuhrman</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Biological Sciences</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ramanuja</forename>
								<surname>Simha</surname>
							</persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer and Information Sciences</orgName>
								<orgName type="institution">University of Delaware</orgName>
								<address>
									<postCode>19716</postCode>
									<settlement>Newark</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Peter</forename>
								<forename type="middle">B</forename>
								<surname>Berget</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Biological Sciences</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jonathan</forename>
								<forename type="middle">W</forename>
								<surname>Jarvik</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Biological Sciences</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Robert</forename>
								<forename type="middle">F</forename>
								<surname>Murphy</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Center for Computational Biology</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Joint Carnegie Mellon University-University of Pittsburgh Ph.D. Program in Computational Biology</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Biomedical Engineering</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Biological Sciences</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Machine Learning</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Janet</forename>
								<surname>Kelso</surname>
							</persName>
						</author>
						<title level="a" type="main">Bioimage informatics Determining the subcellular location of new proteins from microscope images using local features</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="page" from="2343" to="2349"/>
							<date type="published" when="2013">18 2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt392</idno>
					<note type="submission">Received on September 14, 2012; revised on June 12, 2013; accepted on July 3, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Contact: murphy@cmu.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Evaluation of previous systems for automated determination of subcellular location from microscope images has been done using datasets in which each location class consisted of multiple images of the same representative protein. Here, we frame a more challenging and useful problem where previously unseen proteins are to be classified. Results: Using CD-tagging, we generated two new image datasets for evaluation of this problem, which contain several different proteins for each location class. Evaluation of previous methods on these new datasets showed that it is much harder to train a classifier that generalizes across different proteins than one that simply recognizes a protein it was trained on. We therefore developed and evaluated additional approaches, incorporating novel modifications of local features techniques. These extended the notion of local features to exploit both the protein image and any reference markers that were imaged in parallel. With these, we obtained a large accuracy improvement in our new datasets over existing methods. Additionally, these features help achieve classification improvements for other previously studied datasets. Availability: The datasets are available for download at http://murphy lab.web.cmu.edu/data/. The software was written in Python and Cþþ and is available under an open-source license at http://murphylab. web.cmu.edu/software/. The code is split into a library, which can be easily reused for other data and a small driver script for reproducing all results presented here. A step-by-step tutorial on applying the methods to new datasets is also available at that address.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Generation of images of cells and tissues is increasingly easy. With the advent of automated microscopes, the capability for data generation has out-stripped the capability for visual data analysis. This has led to extensive work on automated methods for interpreting microscope images. The problem of classification of subcellular patterns has received particular attention, and a number of datasets and classifiers have been described. These datasets typically feature one different protein for each class of interest, with multiple images for the same tagged protein. On these datasets, better than human performance has been reported (<ref type="bibr" target="#b25">Murphy et al., 2003;</ref><ref type="bibr" target="#b28">Nattkemper et al., 2003</ref>). This previous work implicitly assumed that results obtained in those datasets can be generalized to the problem of classifying previously unseen proteins. In this work, we test this assumption using two new datasets where there are multiple proteins in each location class (and multiple images per protein). These datasets were created using NIH 3T3 cell lines expressing green fluorescent protein (GFP)-tagged proteins created by CD-tagging (<ref type="bibr" target="#b11">Garcıá Osuna et al., 2007;</ref><ref type="bibr" target="#b17">Jarvik et al., 2002</ref>). We tested classifiers using a cross-validation protocol whereby images from the same protein are never present in both the training and testing sets. This is a stricter proxy for cross-protein generalization than randomizing by image, and guards against the possibility that learning is based on properties of the tagging method (e.g. intensity) or too specific to the protein in question (e.g. a particular subpattern of an organelle). With this protocol and existing methods, generalization accuracy was only 60% for our new datasets. We therefore investigated whether improved generalization could be obtained using alternative feature representations of the images. Many previous systems use image-level features such as texture features (<ref type="bibr" target="#b7">Chebira et al., 2007;</ref><ref type="bibr" target="#b15">Huang et al., 2003;</ref><ref type="bibr" target="#b26">Nanni and Lumini, 2008;</ref><ref type="bibr" target="#b27">Nanni et al., 2010;</ref><ref type="bibr" target="#b33">Shamir et al., 2008b</ref>), but some specialized features for cell images have also been proposed (<ref type="bibr" target="#b4">Boland and Murphy, 2001</ref>), including features for single-cell regions [in fact, historically, classification on cell-segmented images was reported first (<ref type="bibr" target="#b5">Boland et al., 1998</ref>In the computer vision literature, local features, such as the scale-invariant feature transform, introduced by Lowe (1999), have shown good results in many settings. They have not been widely used in bioimage analysis [there are a few uses of patchbased methods, a basic form of these features (<ref type="bibr" target="#b16">Huh et al., 2009;</ref><ref type="bibr" target="#b24">Mareé et al., 2007)]</ref>. Object-level features, which can be seen as a form of local features, were used for subcellular location unmixing, both in supervised and unsupervised modes (<ref type="bibr" target="#b8">Coelho et al., 2010a;</ref><ref type="bibr" target="#b30">Peng et al., 2010;</ref><ref type="bibr" target="#b35">Zhao et al., 2005</ref>). Local features, as presented in the literature, are generally defined on a gray-scale image and do not take advantage of the multiple image channels frequently acquired by fluorescent microscopy. There is some work on natural scene color images (van de<ref type="bibr" target="#b33">Sande et al., 2010</ref>), but it does not directly apply to fluorescence microscopy images for analyzing subcellular patterns where one channel is privileged (depicting the protein distribution of interest) and others serve as references. Naturally, the simplest protocol is to ignore all but the primary channel. However, the use of a reference channel can provide additional important information, particularly at the local level. For example, we could distinguish between two vesicle classes that appear similar in the primary (protein) channel but differ in distance from the nucleus because the region containing vesicles will appear differently in the reference nuclear channel. We present a simple protocol to take these reference channels into account. Using these features, we obtain a large accuracy gain on our datasets. We also use other datasets to further validate the value of the features and find that they lead to good results in all tested datasets. widefield confocalon the left, and nucleoli on the right), second row of confocal images (cytoplasmic pattern on the left, mitochondrial pattern on the right). Images are false color: the red channel shows the nuclear marker Hoechst, the green channel is the GFP-tagged protein. Images shown are the first image in their classes and have not been manually chosen. The widefield images were automatically acquired and the quality is lower than if they had been manually acquired. Images have been contrast stretched for publication</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DATASETS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">RandTag datasets</head><p>Two datasets are introduced in this article, both from the RandTag (RT) project (<ref type="bibr" target="#b11">Garcıá Osuna et al., 2007</ref>). The first dataset consists of widefield images, the second of confocal images. The widefield images were collected with an automated microscope. Therefore, the quality of the images is variable. As a preprocessing step, images that are completely out-of-focus or empty of cells were removed. The confocal images were acquired manually and are of higher quality. Examples are shown in<ref type="figure" target="#fig_0">Figure 1</ref>. These examples were not chosen as particularly pleasant looking, but are representative of the images in the dataset. The images were labeled by three experts (The experts were L.P.C., E.O.H. and E.G.A. for the widefield dataset, and L.P.C., E.G.A. and A.N. for the confocal dataset.) using a protocol where the experts first labeled the images independently and were then given an opportunity to change their minds given the other labelings. Only images where all experts agreed after this second step were retained.<ref type="figure" target="#tab_1">Table 1</ref>shows summary statistics for these two datasets. The two datasets contain multiple images of the same protein, and multiple proteins per location class. Most other subcellular location datasets contain multiple images per protein but only one protein for each location class (the exception is the Locate database).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Other datasets</head><p>We present the main properties of the datasets in<ref type="figure" target="#tab_2">Table 2</ref>. All are publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Murphy Lab 2D HeLa Dataset</head><p>The Murphy Lab 2D HeLa dataset is by now a benchmark in the field, used by many researchers (<ref type="bibr" target="#b4">Boland and Murphy, 2001;</ref><ref type="bibr" target="#b7">Chebira et al., 2007;</ref><ref type="bibr" target="#b14">Huang and Murphy, 2004;</ref><ref type="bibr" target="#b22">Lin et al., 2007;</ref><ref type="bibr" target="#b24">Mareé et al., 2007;</ref><ref type="bibr" target="#b27">Nanni et al., 2010;</ref><ref type="bibr" target="#b31">Rajapakse, 2008;</ref><ref type="bibr" target="#b33">Shamir et al., 2008b</ref>). The dataset contains approximately 100 images collected by widefield fluorescence microscopy (with nearest neighbor deconvolution) for each of 10 subcellular patterns.<ref type="bibr" target="#b27">Nanni et al. (2010)</ref>obtained the best reported results on this dataset, 96% accuracy, using a combination of texture and other features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Locate endogenous and Locate transfected</head><p>These images were collected by widefield microscopy to detect 10 endogenous proteins or 11 transfected proteins (<ref type="bibr" target="#b12">Hamilton et al., 2007</ref>). Each dataset contains approximately 50 images for each subcellular patterns.The images were manually annotated and most proteins are labeled with more than one location. We are not aware of previous work in automatic classification of these images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Locate Confocal</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Image Informatics and Computational Biology Unit (IICBU) 2008 Benchmark The IICBU 2008 collection</head><p>of datasets includes several collections of bioimages with different properties, which was intended for testing computer vision algorithms (<ref type="bibr" target="#b32">Shamir et al., 2008a</ref>) (The datasets are available at http://ome. grc.nia.nih.gov/iicbu2008.). We used the fluorescent microscopy datasets (the collection includes other modalities). This collection includes the HeLa 2D dataset, but it includes a version without dna channel. Our experiments were on the original, two channel, dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.5">Human Protein Atlas</head><p>The Human Protein Atlas (HPA) contains a collection of confocal images of immuno-stained proteins in human cells, with visual annotation (<ref type="bibr" target="#b2">Barbe et al., 2008</ref>). We used those images where the visual annotation is to a single location class (<ref type="bibr">Li et al., 2012a, b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MATERIALS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">SURF-Ref</head><p>Speeded-Up Robust Features (SURF) are calculated by a two pass algorithm. The first pass detects interest points by using an approximate Gaussian blob detector. These interest points are localized in both space (i.e. at a specific pixel location) and scale (i.e. they have an automatically determined size). The second pass computes 64 descriptors at each interest point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Determining the subcellular location of new proteins</head><p>SURF works on a single channel (a gray-scale image), while bioimages are frequently multichannel: in addition to the primary channel, one or more reference channels are often acquired in parallel. Typically the primary channel is a protein image and a nuclear marker is used as a reference. SURF as presented in the literature can only be applied to the primary channel, discarding valuable information. The protocol to incorporate the reference information is as follows: run the point detection on the primary channel and compute feature descriptors on both channels independently. The feature descriptor for each point is then the concatenation of both descriptors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Baseline feature sets As a baseline</head><p>feature set, we used a global feature set, which includes Haralick texture features (<ref type="bibr" target="#b13">Haralick et al., 1973</ref>), parameter-free Threshold Adjacency Statistics (<ref type="bibr" target="#b9">Coelho et al., 2010b;</ref><ref type="bibr" target="#b12">Hamilton et al., 2007</ref>), object and skeleton features (<ref type="bibr" target="#b4">Boland and Murphy, 2001</ref>), and overlap features (<ref type="bibr" target="#b29">Newberg and Murphy, 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classification</head><p>Computing local features leads to several hundred descriptor vectors per image. To use these in classification, we clustered the descriptor vectors. This process assigns each descriptor to a cluster index. We represent an image as a normalized histogram of membership in the various clusters (<ref type="bibr" target="#b34">Willamowski et al., 2004</ref>). This is known as the ''bag of visual words'' model. The first step is to obtain a set of k centroids, using k-means. This algorithm takes two parameters: k, the number of clusters; and an initial set of centroids. This is implemented by setting the random number generator seed to different values and randomly selecting elements. For efficiency, centroids were obtained from a fraction (1/16th) of the data. All feature vectors are then assigned to the closest centroid. The resulting histogram can then be used with a standard support vector machine (SVM) classifier.<ref type="figure" target="#fig_2">Figure 2</ref>provides an overview of the method. As<ref type="figure" target="#fig_3">Figure 3</ref>shows, there is a large variation in accuracy for different choices of the random seed even for the same value of k: the difference between the highest scoring and the lowest can be as high as six percentage points. Furthermore, as<ref type="figure" target="#fig_4">Figure 4</ref>shows, the typical solution of minimizing the value of the Akaike information criterion (AIC) introduced by Akaike (1974), will not necessarily lead to a high accuracy. In fact, high AIC leads to high accuracy. Given the results in<ref type="figure" target="#fig_3">Figures 3</ref>and 4, we used k ¼ n=4 clusters, where n is the number of images in the training set. For the RTwidefield dataset shown in the<ref type="figure">Figure,</ref>this corresponds to circa 310 clusters. Supplemental<ref type="figure" target="#fig_0">Figure S1</ref>repeats the calculation for the other datasets and confirms the value of this rule. We used a different random initialization for each point. The models learned are SVM based after feature normalization and selection using stepwise discriminant analysis (Jennrich, 1977a, b). A radial basis function kernel is used for the SVM, and an inner loop of cross-validation is used to select the hyperparameters. For the Locate database, which is a multilabel dataset, we used a separate classifier per label; for all other datasets, we used the ''one versus one'' strategy to convert binary classification into multiclass learning (These are the default settingsfor the milk Python machine learning library used in this work, no settings were changed or tuned).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Significance computation</head><p>For the measurement of statistical significance, we used a Bayesian approach. Given a dataset of size n, on which two algorithms correctly classify c 0 and c 1 elements, respectively, we assume that each algorithm has an underlying accuracy of r i and compute the Pðr 0 4r 1 jc 0 , c 1 , nÞ, the probability that the first algorithm is better than the second one. We also assume that the performance of the algorithms is independent,</p><formula>pðc 0 , c 1 , njr 0 , r 1 Þ ¼ pðc 0 , njr 0 Þpðc 1 , njr 1 Þ, ð1Þ</formula><p>and compute</p><formula>R 1 0 R 1 0 r 0 4r 1 ½  ½  pðc 0 , njr 0 Þpðc 1 , njr 1 Þdr 0 dr 1 R 1 0 R 1 0 pðc 0 , njr 0 Þpðc 1 , njr 1 Þdr 0 dr 1 : ð2Þ</formula><p>To be able to numerically obtain a value for (2), we model the accuracy of each classifier with a binomial distribution:</p><formula>pðc, njrÞ ¼ r c ð1 À rÞ nÀc : ð3Þ</formula><p>In this framework, higher values are better, which is the opposite of the traditional statistical practice. Therefore, we report 1 À Pðr 0 4r 1 jc 0 , c 1 , nÞ as a significance value. If the assumptions (1) and (3) are accepted, this significance value is the probability of making a Type I error (i.e. erroneously rejecting the null hypothesis that r 0 r 1 ). The Locate database needs to be handled differently as its proteins are annotated with multiple labels. The system we built learns a binary classifier for each label and, at evaluation time, outputs all the labels whose corresponding binary classifier returned a positive label. Each binary classifier was learned independently. For evaluation, the above framework is not directly applicable and we measured and report the F 1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Cross-validation</head><p>All results were obtained using cross-validation. Ten-folds were used, except in the cases where the smallest class had less than 10 objects. In that case, the number of folds was set to the minimum class size. When handling the RandTag datasets with multiple images of the same protein, we can perform cross-validation in two ways:</p><p>(1) Per image, in which we group the images into 10-folds without taking the depicted protein into account.</p><p>(2) Per protein, in which we group the proteins into 10-folds. In this setting, there were never any images in training and testing from the same protein. Accuracy is still reported on a per-image level (the fraction of images that were correctly classified).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Software All software presented was developed in Python and</head><p>Cþþ and incorporates code from dlib (Dlib's webpage is at http://www.dlib.net) by David King and LIBSVM by Chang and Lin (2001) for feature computation and classification, respectively. The software is designed to be easily reused in new datasets (<ref type="bibr" target="#b10">Coelho, 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generalization to new proteins</head><p>As described above, the RandTag datasets have images from several proteins in each dataset. Cross-validation over proteins is a stricter test of generalization capabilities and it was expected that it would lead to lower accuracies than the cross-validation over images (where training and test sets have different images of the same labeled protein).<ref type="figure" target="#tab_3">Table 3</ref>shows that the resulting difference in accuracy is large: a drop of 22 percentage points (84–62%). Even with multiple proteins per class, having examples from the same protein in training and testing results in high measured accuracies. These values (91–88%) are close to what is typically reported in subcellular location problems. However, when results are evaluated using the stricter cross-validation protocol, accuracy values are much lower, circa 60% for the baseline results. The differences in results with the two forms of cross-validation are statistically significant (at the 10 À51 and 10 À10 levels, for the widefield and confocal datasets, respectively). The HPA dataset also contains multiple proteins per class and a small number of images of each protein, often only two.Note: Shown are accuracies, in percentage, obtained either with per-protein or per-image cross-validation on two feature sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Determining the subcellular location of new proteins</head><p>Therefore, we used 2-fold cross-validation. The results in this dataset confirm that performing cross-validation per protein results in lower accuracy than cross-validating per image. The difference of 12 percentage points is significant at the 10 À7 level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SURF-ref</head><p>Table 4 summarizes the results obtained. On five of the datasets, using SURF variations shows a statistically significant improvement over the baselines used. On the other datasets, the results are not statistically distinguishable from the baseline. The worst results are obtained in the RNAi dataset, where local features alone perform much worse (significant at the 2:5 Â 10 À8 level). However, once the baseline is added, the results are indistinguishable from the baseline. Therefore, we recommend the use of all features combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Computational Costs</head><p>SURF-ref is efficient in terms of computational time. On average, our implementation requires 7 s per image for both interest point detection and feature descriptor computation. Images in this case are 768 Â 1024 pixels large. As part of interest point detection, each point is ranked according to a metric of how strongly it matches the approximate filter used—see the original SURF article for details (<ref type="bibr" target="#b3">Bay et al., 2008</ref>). For large datasets, the computed feature data can be overwhelming. Therefore, we limited the number of interest points per image to 1024 (which are the 1024 highest matches according to the metric alluded to above). The traditional SURF consists of 64 descriptor values. In addition, we save the location, scale, angle and match strength for 70 floating point values per interest point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>This work frames the subcellular location problem as recognizing different proteins in the same class. While this may have been implicit in previous work, it was not directly tested by datasets with a single representative protein per location class. We introduce two new datasets, which contain multiple proteins per class (and multiple images per protein). We observed that when cross-validation was performed over proteins, the resulting accuracy was much lower than when it was performed over images (where it is comparable with other datasets). This is intuitive as it is an easier problem to recognize proteins that are in the training set than proteins that are only in the same class (in particular, in the first case, it is possible that the system distinguishes the proteins by artifacts of the tagging or variation in subpatterns). Our data show that it is incorrect to assume that the high accuracy values obtained in datasets composed of multiple images of the same protein imply that the system would generalize well to other proteins in the same location class. Our datasets are publicly available. There is still a lot of room for improvement in accuracy and we hope that other researchers will test their methods on this harder problem. We also introduce a new methodology for classification of subcellular location patterns, which is based on interest point detection and local feature analysis. We developed a protocol to integrate the information in reference channels (which are typically acquired in parallel to the protein of interest). We implemented this method based on SURF, but the protocol is a generic method and could be applied to other local feature sets, such as scale-invariant feature transform (<ref type="bibr" target="#b23">Lowe, 1999</ref>) or any combination of detector and descriptor. On our new datasets, these methods performed better than the traditional whole-field features by 10 percentage points (a difference that is highly statistically significant). We tested these features on traditional datasets as well. On these, the baseline methods already perform well and there was less room for improvement. In four cases, the results are statistically indistinguishable from the baseline. It should be noted, though, that in no dataset did we observe that adding the local features lead to a statistically distinguishable worse outcome. These features have the further advantage that they are computed on the raw images without any pre-processing such as background correction or contrast enhancement. No tuning is necessary for adapting to new datasets and it is flexible for application to large datasets. Therefore, we recommend that local features with reference information be added to the standard toolkit for bioimage classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank the HPA project team, especially Emma Lundberg, for providing the high-resolution confocal microscopy images used for the HPA dataset, and Jieyue Li for preparing this dataset for computational analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Examples of RandTag datasets. Top row consists of widefield images (nuclear pattern on the left, and nucleoli on the right), second row of confocal images (cytoplasmic pattern on the left, mitochondrial pattern on the right). Images are false color: the red channel shows the nuclear marker Hoechst, the green channel is the GFP-tagged protein. Images shown are the first image in their classes and have not been manually chosen. The widefield images were automatically acquired and the quality is lower than if they had been manually acquired. Images have been contrast stretched for publication</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Aturaliya et al. (2006) presented a collection of mouse membrane-bound proteins imaged with confocal microscopy. The images are available online in the locate database (Available at http://locate.imb.uq.edu.au/). It consists of 6985 images of 2047 different mouse proteins expressed in HeLa cells.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Overview of local feature-based classification. The training set is subsampled and centroids are obtained from this smaller dataset. All the training points are then projected to their nearest centroid and a SVM is trained to classify the per-image histograms. At testing time, the same centroids and SVM are used</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Results of classification as a function of the number of clusters k. Each dot is the result of one clustering of the data (differing by a different number of clusters and a different initial set of clusters). The solid line is the baseline accuracy (using global instead of local features)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Results of classification as a function of the Aikake information criterion. Each dot is the result of one clustering of the data (differing by a different number of clusters and a different initial set of clusters). Note that AIC is typically minimized</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Funding: National Institute of General Medical Sciences (R01 GM075205 to R.F.M.); National Institutes of Biological Imaging and Bioengineering (T32 EB009403-01 to A.W.N. by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>)]. *To whom correspondence should be addressed. y Present address: European Molecular Biology Laboratory (EMBL), Heidelberg, Germany. z Present address: Department of Biological Sciences, University of the Sciences, Philadelphia, USA.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. Dataset statistics</figDesc><table>Name 
Number 
of 
images 

Number 
of 
classes 

Reference 

RT-widefield 
1382 
10 
RT-confocal 
304 
10 
HeLa2D 
862 
10 
Boland and Murphy, 2001 
LOCATE-transfected 
553 
11 
Hamilton et al., 2007 
LOCATE-endogenous 502 
10 
Hamilton et al., 2007 
Binucleate 
41 
2 
Shamir et al., 2008a 
CHO 
327 
5 
Shamir et al., 2008a 
Terminalbulb 
970 
7 
Shamir et al., 2008a 
RNAi 
200 
10 
Shamir et al., 2008a 
HPA 
1842 
13 
Barbe et al., 2008 

Note: The first two datasets, from the RandTag project, are introduced in this 
article; the others were previously described elsewhere. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 1. Properties of RandTag datasets</figDesc><table>UL NO N M G Cyto PM Lyso Cytosk ER 

Widefield 
Number of proteins 12 
5 14 
8 3 10 
3 
4 
9 
3 
Number of images 254 113 255 175 63 155 51 69 
197 
50 
Confocal 
Number of proteins 
5 
3 
8 12 4 
8 
3 
3 
18 
3 
Number of images 
20 17 40 60 16 34 12 12 
80 
13 

Note: UL, unlabeled; NO, nucleoli; N, nuclear; M, mitochondria; G, Golgi; Cyto, 
cytoplasmic; PM, plasma membrane; Lyso, lysosome; Cytosk, cytoskeleton; ER, 
endoplasmic reticulum. 
Shown are number of proteins (first line) and images (second line) per class. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 3. Comparison of per-protein and per-image cross-validation</figDesc><table>Dataset 
Method 
Baseline 
SURF-ref þ 
baseline 

RT-widefield 
Per image 
84.2 
91.1 
RT-widefield 
Per protein 
61.6 
70.3 
RT-confocal 
Per image 
83.9 
88.8 
RT-confocal 
Per protein 
59.9 
65.5 
HPA 
Per image 
76.1 
82.8 
HPA 
Per protein 
68.2 
78.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 4. Summary of results for all datasets</figDesc><table>Dataset 
Baseline SURF SURF-ref Local a þ 
baseline 

Significance 

HeLa2D 
86.0 
88.7 
90.4 
94.4 
2:4 Â 10 À9 
RT-widefield (per image) 84.2 
79.6 
85.7 
91.1 
4:0 Â 10 À8 
RT-widefield 
61.6 
67.5 
71.9 
70.3 
1:1 Â 10 À6 
RT-confocal (per image) 83.9 
80.9 
84.2 
88.8 
0.04 
RT-confocal 
59.9 
72.0 
62.8 
65.5 
0.08 
LOCATE-transfected 
75.4 
84.8 
84.8 
88.1 
3:1 Â 10 À8 
LOCATE-endogenous 
74.5 
91.2 
91.2 
95.6 
1:8 Â 10 À22 
Binucleate 
85.4 
95.1 
95.1 
0.08 
CHO 
96.6 
96.9 
98.5 
0.08 
Terminal bulb 
45.8 
32.4 
44.6 
0.31 
RNAi 
72.0 
43.0 
67.5 
0.17 
HPA 
69.9 
67.8 
78.0 
78.9 
5:0 Â 10 À10 
LOCATE b 
66 
62 
69 

c 

Shown are accuracy (as a percentage) and significance as defined in Section 3.3. The 
baseline is cell-level features for the HeLa 2D dataset and field-level features for all 
other sets. Significance is on the difference between the baseline and the bolded 
column. 

a 

For datasets with a dna channel, SURF-ref was used, for those without a dna 
channel, SURF features were used. 

b 

As discussed in the text, F 1 score is shown. 

c 

The significance calculation is not directly applicable to F 1 scores. </table></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">L.P.Coelho et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Akaike</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Subcellular localization of mammalian type II membrane proteins</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">N</forename>
				<surname>Aturaliya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Traffic</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="613" to="638" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Toward a confocal subcellular atlas of the human proteome</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Barbe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Cell. Proteomics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="499" to="508" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Speeded-Up Robust Features (SURF)</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Bay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="346" to="359" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A neural network classifier capable of recognizing the patterns of all major subcellular structures in fluorescence microscope images of HeLa cells</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">V</forename>
				<surname>Boland</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1213" to="1223" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">V</forename>
				<surname>Boland</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="366" to="375" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">LIBSVM: a library for support vector machines</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">C</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">J</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Sys. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A multiresolution approach to automated classification of protein subcellular location images</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Chebira</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">210</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Quantifying the distribution of probes between subcellular locations using unsupervised pattern unmixing</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">P</forename>
				<surname>Coelho</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="7" to="12" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Structured literature image finder: extracting information from text and images in biomedical literature</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">P</forename>
				<surname>Coelho</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lect. Notes Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">6004</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Mahotas: open source software for scriptable computer vision</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">P</forename>
				<surname>Coelho</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Open Res. Softw</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Large-scale automated analysis of location patterns in randomly tagged 3T3 cells</title>
		<author>
			<persName>
				<forename type="first">Garcıá</forename>
				<surname>Osuna</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1081" to="1087" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast automated cell phenotype image classification</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">A</forename>
				<surname>Hamilton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">110</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Textural features for image classification</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Haralick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Boosting accuracy of automated classification of fluorescence microscope images for location proteomics</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Huang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">78</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature reduction for improved recognition of subcellular location patterns in fluorescence microscope images</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE 4962, Manipulation and Analysis of Biomolecules, Cells, and Tissues. SPIE, United States</title>
		<meeting>SPIE 4962, Manipulation and Analysis of Biomolecules, Cells, and Tissues. SPIE, United States</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="307" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient framework for automated classification of subcellular patterns in budding yeast</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Huh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="934" to="974" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">In vivo functional proteomics: mammalian genome annotation using CD-tagging</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Jarvik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biotechniques</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">856</biblScope>
			<biblScope unit="page" from="852" to="854" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Stepwise discriminant analysis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">I</forename>
				<surname>Jennrich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Methods for Digital Computers</title>
		<editor>Enslein,K. et al.</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Stepwise Regression</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">I</forename>
				<surname>Jennrich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical Methods for Digital Computerss</title>
		<editor>Enslein,K. et al.</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Automated analysis and reannotation of subcellular locations in confocal images from the human protein atlas</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">50514</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Protein subcellular location pattern classification in cellular images using latent discriminative models</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="32" to="39" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Boosting multiclass learning with repeating codes and weak detectors for protein subcellular localization</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">C</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="3374" to="3381" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">G</forename>
				<surname>Lowe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh IEEE International Conference on Computer Vision</title>
		<meeting>the Seventh IEEE International Conference on Computer Vision<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Random subwindows and extremely randomized trees for image classification in cell biology</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mareé</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cell Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust numerical features for description and classification of subcellular location patterns in fluorescence microscope images</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. VLSI Signal Process. Syst. Signal Image Video Technol</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="311" to="321" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">A reliable method for cell phenotype image classification</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nanni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lumini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="87" to="97" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Novel features for automated cell phenotype image classification</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nanni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Exp. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">680</biblScope>
			<biblScope unit="page" from="207" to="220" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Human vs machine: evaluation of fluorescence micrographs</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">W</forename>
				<surname>Nattkemper</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="43" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">A framework for the automated analysis of subcellular patterns in human protein atlas images</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Newberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2300" to="2308" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Determining the distribution of probes between different subcellular locations through automated unmixing of subcellular patterns</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>. Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2944" to="2949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Protein localization on cellular images with Markov random fields</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Rajapakse</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Joint Conf. Neural Netw</title>
		<imprint>
			<biblScope unit="page" from="2127" to="2132" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">IICBU 2008: a proposed benchmark suite for biological image analysis</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Shamir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Biol. Eng. Comput</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="943" to="947" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Wndchrm—an open source utility for biological image analysis Evaluating color descriptors for object and scene recognition</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Shamir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Source Code Biol. Med. IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Categorizing nine visual classes using local appearance descriptors</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Willamowski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR 2004 Workshop Learning for Adaptable Visual Systems</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Object type recognition for automated analysis of protein subcellular location Determining the subcellular location of new proteins</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1351" to="1360" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>