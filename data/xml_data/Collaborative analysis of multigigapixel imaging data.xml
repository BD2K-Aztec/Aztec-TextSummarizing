
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaborative analysis of multi-gigapixel imaging data using Cytomine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Raphaë</forename>
								<forename type="middle">L</forename>
								<surname>Maré</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Bioimage Analysis Unit</orgName>
								<orgName type="institution">Institut Pasteur</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Loı¨cloı¨c</forename>
								<surname>Rollus</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Benjamin</forename>
								<surname>Sté Vens</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Renaud</forename>
								<surname>Hoyoux</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Gilles</forename>
								<surname>Louppe</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ré</forename>
								<surname>My Vandaele</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jean-Michel</forename>
								<surname>Begon</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Philipp</forename>
								<surname>Kainz</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Biophysics</orgName>
								<orgName type="institution">Medical University of Graz</orgName>
								<address>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Pierre</forename>
								<surname>Geurts</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Louis</forename>
								<surname>Wehenkel</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Systems and Modeling</orgName>
								<orgName type="department" key="dep2">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="department" key="dep3">GIGA-Research</orgName>
								<orgName type="institution">University of Liè ge</orgName>
								<address>
									<addrLine>Liè ge</addrLine>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Collaborative analysis of multi-gigapixel imaging data using Cytomine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw013</idno>
					<note type="submission">Received on 2 November 2015; revised on 4 January 2016; accepted on 5 January 2016</note>
					<note>Bioimage informatics *To whom correspondence should be addressed. Associate Editor: Robert Murphy Contact: info@cytomine.be Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Collaborative analysis of massive imaging datasets is essential to enable scientific discoveries. Results: We developed Cytomine to foster active and distributed collaboration of multidisciplinary teams for large-scale image-based studies. It uses web development methodologies and machine learning in order to readily organize, explore, share and analyze (semantically and quantitatively) multi-gigapixel imaging data over the internet. We illustrate how it has been used in several bio-medical applications. Availability and implementation: Cytomine</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In various scientific domains (incl. biology, biomedicine, astronomy, botany, geology, paleobiology, marine research, aerobiology, climatology), projects leading to terabytes of multi-gigapixel images become increasingly common (The data deluge, 2012) e.g. biomedical research studies often rely on whole-slide virtual microscopy or automated volume electron microscopy. In these fields, significant advances could be made by multidisciplinary collaboration involving distributed groups of life scientists and computer scientists exploiting large-scale image networks (<ref type="bibr" target="#b24">Moody et al., 2013;</ref><ref type="bibr" target="#b28">Poldrack, 2014</ref>), or eventually by enlisting the help of members of the general public in large imaging surveys (<ref type="bibr" target="#b8">Clery, 2011</ref>) through interactive games (e.g. EyeWire (http://eyewire.org/) and Brainflight (http:// brainflight.org/) projects). For example, researchers in experimental histology are willing to precisely annotate images and need to consult distant experts in pathology or molecular biology. Developers of image processing algorithms are willing to collaborate with machine learning specialists to build complementary image analysis workflows. Furthermore, all these individuals need to actively collaborate to gain new insights, e.g. computer scientists require realistic ground truth and proofreadings (Ground-truth data cannot do it alone, 2011) provided by life scientists to design and refine their analysis methods. Vice versa, life scientists increasingly rely on algorithms or crowdsourced outputs in combination with proofreading tools to enable efficient analysis of very large image sets. Bioimage informatics aims at developing software to ease the analysis of large-scale biomaging data (<ref type="bibr" target="#b26">Myers, 2012</ref>). In recent years, several software have been developed including CellProfiler (<ref type="bibr" target="#b7">Carpenter et al., 2006</ref>), CATMAID (<ref type="bibr" target="#b30">Saalfeld et al., 2009</ref>), BisQue (<ref type="bibr" target="#b15">Kvilekval et al., 2010</ref>), ilastik (<ref type="bibr" target="#b33">Sommer et al., 2011</ref>), Icy (<ref type="bibr" target="#b9">de Chaumont et al., 2012</ref>), Fiji (<ref type="bibr" target="#b31">Schindelin et al., 2012</ref>), OMERO (<ref type="bibr" target="#b1">Allan et al., 2012</ref>) and BigDataViewer (<ref type="bibr" target="#b27">Pietzsch et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1395</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.<ref type="bibr" target="#b23">Mikut et al., 2013</ref>) research, or in plant sciences (<ref type="bibr" target="#b17">Lobet et al., 2013</ref>)) to address rather specific biological questions (e.g. to map neuronal circuitry in Schneider<ref type="bibr" target="#b32">Mizell et al., 2015)</ref>. In this work, we present Cytomine, a novel open-source, rich web environment to enable highly collaborative analysis of multigigapixel imaging data. This tool has been designed with the following objectives in mind: @BULLET provide remote and collaborative principles, @BULLET rely on data models that allow to easily organize and semantically annotate imaging datasets in a standardized way, @BULLET efficiently support high-resolution multi-gigapixel images, @BULLET provide mechanisms to readily proofread (Ground-truth data cannot do it alone, 2011) and share image quantifications produced by machine learning-based image recognition algorithms (<ref type="bibr" target="#b11">de Souza, 2013;</ref><ref type="bibr" target="#b25">Murphy, 2011</ref>). While some of these features are available in existing tools, none of these tools provide all these features simultaneously. By emphasizing collaborative principles, our aim with Cytomine is to accelerate scientific progress and to significantly promote image data accessibility and reusability (The data deluge, 2012;<ref type="bibr" target="#b24">Moody et al., 2013;</ref><ref type="bibr" target="#b28">Poldrack, 2014</ref>). We want to break common practices in this domain where imaging datasets, quantification results and associated knowledge are still often stored and analyzed within the restricted circle of a specific laboratory. To achieve this goal, the Cytomine platform permits active collaboration between distributed groups of life scientists, computer scientists and citizen scientists. It allows seamless online sharing and reviewing of semantic and quantitative information associated with large images, either produced manually or automatically using machine learning algorithms, as schematically illustrated in<ref type="figure" target="#fig_1">Figure 1</ref>. The paper is structured as follows. In Section 2 we describe the main design principles and functionalities of Cytomine. In Section 3, we briefly present use cases initiated by our collaborators to help readers to determine how they can use our software to address their own research questions. We then discuss the concepts of extensibility of the platform in Section 4, and finally, we conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bioinformatics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System and methods</head><p>To allow image-based collaborative studies and meet software efficiency and usability criteria (Software with impact, 2014;<ref type="bibr" target="#b6">Carpenter et al., 2012;</ref><ref type="bibr" target="#b29">Prins et al., 2015</ref>), the software is decomposed into four main components (Supplementary Note 1) communicating through web mechanisms (through a RESTful API): Cytomine core (Cytomine-Core), Cytomine Image Management System (CytomineIMS), Cytomine web user interface (Cytomine-WebUI) and Cytomine analysis modules (Cytomine-DataMining), designed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cytomine-core</head><p>Cytomine-Core relies on recent web and database software development technologies. Its underlying data models (Supplementary Note 2) allow to create and store projects. Each project can be accessed by multiple users through authentication. A project can contain multi-gigapixel image sequences and a user-defined ontology, i.e. a structured list of domain-specific semantic terms. Each image instance can be annotated by users or software using annotation objects of various shapes for regions of interest (e.g. a cell or a tissue subregion) and labeled with one or multiple semantic terms from the(i) Reviewed annotations can eventually be reused to refine and re-apply the recognition model. (j) Once image annotations are validated by an expert, final quantification results of the 'reviewed layer' are exported in standard formats ontology (e.g. a specific cell type or tissue structure). In addition, metadata (key-value properties, associated files and rich descriptions) can be associated to any project, image and annotation. Such data can be created remotely either by human experts (through Cytomine-WebUI) or automatically (by our analysis modules or any third-party software implementing basic web communication mechanisms). Because these data are identified by URLs they are de facto shared with any authenticated user. Also, as they are represented in standard formats (namely JSON, a lightweight data-interchange format), they can be automatically parsed and generated by registered external applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cytomine-IMS</head><p>Cytomine-IMS backend server provides web services that encapsulate a collection of distributed, specialized image server instances. It is used to upload 5D image sequences (x,y,z,c,t planes) and to dynamically deliver original image areas and annotation masks over the internet – at any pyramid resolution. It supports various standards and specific microscopy image formats (including most of whole-slide scanner formats) either by directly accessing their native formats, or by seamlessl conversion to a pyramidal format during the upload phase (see Supplementary Note 1 for a list of supported formats).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cytomine-WebUI</head><p>Cytomine-WebUI is a customizable and responsive rich internet application (<ref type="figure" target="#fig_2">Fig. 2</ref>), accessible through regular web browsers and mobile devices. It allows to create, organize, visualize and edit all data. It includes a zoomable, tile-based viewer for multi-gigapixel images with the visualization of overlaid (human or computer-generated) annotation layers and their properties. Furthermore, an ontology editor, several modules to derive annotation statistics and visualize annotation galleries, a textual search engine and proofreading tools for expert reviewing of annotation objects are part of this user interface. In addition, we have implemented functionalities to allow various forms of collaborative works. One of them is the tracking of all user activities to e.g. allow multiple users to follow remotely another user's observation paths and actions. Conversely, a blinded mode can be activated to hide image and user information to allow independent studies and reduce bias when analyzing imaging data. An additional module (Cytomine-IRIS, the interobserver reliability study module) also allows independent ground-truth construction and inter-observer annotation statistics e.g. to identify cell type classification disagreements among experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Cytomine-DataMining</head><p>Cytomine-DataMining analysis modules currently include variants of machine learning based image recognition algorithms (<ref type="bibr" target="#b19">Marée et al., 2013a</ref>) that can be run on remote servers (Supplementary Note 3). This property facilitates large-scale analysis on distributed cluster systems where expensive computations can be outsourced. We provide an unsupervised, incremental, content-based image retrieval method that searches on-the-fly for visually similar annotations in the database and displays them in Cytomine-WebUI every time a user draws an annotation (see examples in Supplementary Note 4.2). Variants of supervised image recognition algorithms are also provided for object classification, semantic segmentation and landmark detection (see examples in Supplementary Note 4.2). Through web communication mechanisms, these analysis modules can be launched from Cytomine-WebUI. These modules typically retrieve filtered sets of labeled annotation objects through the API and build computational image recognition models. These models can be applied at any pyramid level of a gigapixel image in order to analyze its content at different resolutions and automatically create novel annotation objects (e.g. cell or tumor geometries and their semantic terms for cell sorting and tumor quantification, or coordinates of points corresponding to landmarks for morphological measurements). Despite progress in machine learning, it often remains necessary for experts to proofread automatically generated annotations. For this purpose, we also provide Web UIs to revise computer-generated annotations (e.g. edit their shape or spatial localization, modify their ontology term,. .. ). Notably, these editing tools are independent of our image recognition algorithms and can be used to remotely review annotation objects created by other software (see Supplementary Note 5.3 for details on extensibility) or scientists. Reviewed annotations are stored as novel entities in the database so they can be disseminated or used later to refine recognition models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Applications</head><p>While our first developments were primarily motivated by the analysis of brightfield cytology and histology images (digital slides) in lung cancer research (<ref type="bibr" target="#b20">Marée et al., 2013b</ref>), we have significantly increased our software's versatility and improved its extensibility. Cytomine has now been used on various bio(medical) imaging datasets that involved various types of images and experts in different collaborative operating modes to perform various quantification tasks. In particular, we briefly present here several use cases to help readers to determine how they can use our software to address their own research questions (see illustrative examples in<ref type="figure" target="#fig_3">Fig. 3</ref>and Supplementary Note 5 for a user guide). These applications were regrouped into 4 categories corresponding to different image recognition tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tissue area quantification</head><p>In these use cases, scientists aims at quantifying the size (area) of tissue regions (e.g. the ratio of tumor islets with respect to whole tissue sections). This type of task implies to delineate the whole tissue section as well as the specific regions of interest within the tissue, either manually or semi-automatically (see Supplementary note 5.2.4.1 for a step-by-step guide using automatic recognition algorithms on toy data). Following these principles, Cytomine enabled semi-automatic tumor area assessment in hundreds of whole lung Hematoxylin– Eosin (H&amp;E) stained digital slides in mice inflammation and cancer research (<ref type="bibr" target="#b21">Marée et al., 2014</ref>) (<ref type="figure" target="#fig_3">Fig. 3a</ref>). Experts (pneumologists and biomedical researchers) first used Cytomine-WebUI drawing tools to provide manual tumoral islets and non-tumour annotations. Cropped images of these annotations were retrieved using web services and fed into our supervised learning algorithms for semantic segmentation. The task was formulated as pixel classification problem using multiple outputs. User interfaces and communication mechanisms to launch algorithms from Cytomine-WebUI were implemented to allow experts to execute training and prediction algorithms in an autonomous way. As our algorithms were not perfectly recognizing tumors, tools were implemented in Cytomine-WebUI to allow scientists to proofread annotations that were generated automatically. Experts are therefore able to accept or reject annotations and edit their shapes using drawing tools which allow to edit vertices, scale, substract or merge polygons, or fill internal holes. These manual operations are automatically translated internally into spatial queries on polygons, and validated annotations are stored in Cytomine-Core. After expert validation, statistics can be exported in standard formats for further analysis. A similar workflow was used in (<ref type="bibr" target="#b16">Leroi et al., 2015</ref>) for semiautomatic tumor delineation in tens of whole Hematoxylin– Diaminobenzidine (HDAB) stained immunohistochemical digital slides in mice lung cancer research (<ref type="figure" target="#fig_3">Fig. 3b</ref>). Manual annotations (tumor, stroma and necrosis) were provided by experts to build a binary semantic segmentation model whose predictions were thenproofread. In this study, this step was followed by quantitative assessment of antibody staining in relevant tissue area. Finally in (<ref type="bibr" target="#b34">Suarez-Carmona et al., 2015</ref>), Cytomine was used to enable independent assessment by two observers (using the blinded configuration mode) of recruitment of CD11b þ GR1 þ myeloidderived suppressor cells using mouse ear sponge models from whole immunofluorescent stained frozen sections. Experts used manual freehand annotation tools and multidimensional image visualization interface to analyze and merge fluorescent images (<ref type="figure" target="#fig_3">Fig. 3c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scoring and object counting</head><p>In these use cases, scientists aim at scoring or counting 'objects'. This type of task implies to define (manually or automatically) regions of interest and count different types of 'objects' (e.g. cells marked with a marker-specific antibody) within these regions. Cytomine was used to enable independent assessment by two observers (using our blinded configuration mode) of tens of thousands of BRCA1 mRNA expression signals and nucleus counts by in situ hybridization assays in tens of formalin-fixed, paraffin-embedded tissues in human breast cancer research (<ref type="bibr" target="#b5">Boukerroucha et al., 2015</ref>) (<ref type="figure" target="#fig_3">Fig. 3e</ref>). This study involved pathologists (for manual tumor delineation) and biomedical researchers (for manual annotation of spots and nucleus using point annotations). It required the development of web services performing polygon intersection operations to count spots within specific regions of interest. In addition, scripts using these web services were implemented to export quantification statistics in standard formats for further statistical analysis. Similarly, experts in sexual maturation research performed manual classification and counting (using point annotations) of thousands of oocytes in whole H&amp;E slides of Chondrostoma nasus (<ref type="figure" target="#fig_3">Fig. 3d</ref>). In<ref type="bibr" target="#b35">Weekers et al. (2015)</ref>, semi-automatic counting of immunoreactive cells in regions of interest (cortex, medulla, corticomedullary junction) of tens of kidney sections was performed (<ref type="figure" target="#fig_3">Fig. 3i</ref>). Experts (nephrologists, pathologists and biomedical researchers) first provided manual freehand annotations (regions of interest, positive and negative cells) to train semantic segmentation models. These were applied for positive cell detection whose statistics were exported for each region of interest. Other applications include manual double-blind scoring within tissue subregions from immuno-histostained digital slides in melanoma cellular microenvironment research (<ref type="figure" target="#fig_3">Fig. 3j</ref>), and manual point annotations of hundreds of thousands of nuclei for microproteomics from small regions of interest in H&amp;E formalin-fixed paraffinembedded tissue samples in human breast cancer research (<ref type="bibr" target="#b18">Longuespée et al., 2015</ref>) (<ref type="figure" target="#fig_3">Fig. 3k</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Labeled ground truth creation and object classification</head><p>In this family of tasks, scientists aim at sorting 'objects' (e.g. to detect rare abnormal cells or phenotypes). This type of task implies to detect objects and then classify them according to predefined categories (see Supplementary Note 5.2.4.2 for a detailed guide on using automatic detection and recognition algorithms on cytology toy data, and Supplementary Note 5.2.7.2 that describes how to create independent ground truth data). Following these principles, Cytomine enabled manual semantic annotation of eleven categories of Danio rerio larva defects (e.g. edema, dead, curved tail,. .. ) in hundreds of brightfield microscopy images by consensus voting of three biologists (<ref type="figure" target="#fig_3">Fig. 3h</ref>). These annotations were then used as ground-truth to build a worfklow for automatic phenotype classification using tree-based supervised learning (<ref type="bibr" target="#b13">Jeanray et al., 2015</ref>). In<ref type="bibr" target="#b22">Marée et al. (2016)</ref>, we analyzed tissue components in human renal biopsies (Masson-Trichrome stain). We proposed an automatic glomeruli detection workflow combining image processing operations using Icy (<ref type="bibr" target="#b9">de Chaumont et al., 2012</ref>) and variants of our supervised classification algorithms. Icy was registered in CytomineCore using our software parameter templating mechanisms and it was therefore able to import and export image and annotation data using our web services (see examples in Supplementary Note 5.3). To build a large ground truth dataset (almost thirty thousand tissue components), glomeruli candidates automatically detected by Icywere analyzed using our proofreading tools for object classification. These interfaces show galleries of classified objects and allow a user to readily validate or correct (by drag and drop) predictions of ontology terms. Other large ground truth datasets were collected using manual annotation tools. Several thousands of cells were annotated to build a large ground truth dataset in human thyroid cytology for the (ongoing) development of rare cell detection algorithms (<ref type="figure" target="#fig_3">Fig. 3f</ref>), inspired by previous work on cervical cancer screening (<ref type="bibr" target="#b10">Delga et al., 2014</ref>). We also implemented novel user interfaces (Cytomine-IRIS, see Supplementary Note 5.2.7.2) to enable different users to independently assign ontology terms to objects of interest. In particular, it was used by several pathologists to annotate bone marrow cells in order to study inter-observer agreements and build a large concordant ground truth dataset for the design of cell classification algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Landmark detection and morphometric measurements</head><p>In this fourth family of quantification tasks, the goal is to detect specific landmarks (or interest points) in images to perform morphometric measurements (e.g. distances between skeletal points in developmental studies). This implies to scan images to identify localizations of specific points (see Suppl Note. 5.2.4.3 for a step-by-step guide using automatic recognition algorithms on toy data). Cytomine was used to perform manual annotation of tens of thousands of landmarks (positioning and naming) in hundreds of microscopy images of Danio rerio embryo for morphometric measurements in hormonal and hypergravity bone development studies (<ref type="bibr" target="#b0">Aceto et al., 2015</ref>) (<ref type="figure" target="#fig_3">Fig. 3g</ref>). These annotations are currently used to design and evaluate a generic landmark detection algorithm, following previous work in cephalometry (<ref type="bibr" target="#b12">Huang et al., 2015</ref>). For this type of tasks, we implemented proofreading web interfaces to rapidly and precisely visualize the localization of detected interest points, and to manually move them if they are not well positioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>The proposed software and its algorithms have already been applied to a wide variety of image types to accelerate discovery and to enable collaborative analysis. These results encourage its exploitation in many domains. However, in practical applications, obtaining satisfactory recognition performance using automatic algorithms depends on many factors including image variations (e.g. due to image acquisition and sample preparation protocols), and the quality and quantity of annotations provided for training (see e.g. empirical evaluations in Supplementary Note 4.2). Although the combination of our algorithms and proof-editing tools enabled to derive relevant quantification results in various applications, it is important to note that further adaptation of algorithms or developing novel recognition algorithms might be needed for specific types of images or varying acquisition conditions. A key advantage of our platform is therefore its extensibility. Indeed, our architecture enables computer scientists to add their novel software, register them to the CytomineCore and launch them from Cytomine-WebUI or from the command line. Also, annotation objects created by each instance of a software are stored in the database and are available through web services. These can then be subsequently proofread, or retrieved through the API by other software for further analysis and creation of novel – more precise – annotation objects. This allows to create complex image analysis pipelines based on distributed software. It has to be noted that although the software allows visualization of 5D image planes (x,y,z,c,t), current applications cited in Section 3 have involved independent analysis of 2D image planes only (e.g. fluorescent image planes in (<ref type="bibr" target="#b34">Suarez-Carmona et al., 2015</ref>) and tissue slices in (<ref type="bibr" target="#b21">Marée et al., 2014)</ref>). Using our API based on web services, one is able to extend the software by designing analysis algorithms that integrate 5D information if needed, or to interoperate with existing software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Cytomine is a versatile software for collaborative analysis of multigigapixel images as already demonstrated by its various applications. With our design choices, we also believe our platform will facilitate accessibility, curation and dissemination of imagingrelated data. In the future, it might be extended and tailored to support: (i) the setup of large-scale, multi-centric image repositories or the emergence of an imaging 'data bazaar' (<ref type="bibr" target="#b28">Poldrack, 2014</ref>) to enable new research questions or validate results on larger cohorts, (ii) the organization of image analysis challenges on unprecedented benchmarks to foster image machine learning research, (iii) the crowdsourcing of image annotation tasks to tackle intractable datasets, (iv) the dissemination of multi-gigapixel imaging data and associated quantification results to support scientific claims of research papers and (v) increase the reproducibility of scientific results by providing a platform where published results are available along the algorithms and the image data. We have also started to derive the software for teaching purposes (see Supplementary Note 4.1.2).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>V</head><figDesc>C The Author 2016. Published by Oxford University Press.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Overview of multidisciplinary collaborative principles illustrated for tumor segmentation in H&amp;E lung cancer whole tissue slides: (a) Images are uploaded using Cytomine-WebUI or remote clients. (b) Images and related data are stored by Cytomine-Core and Cytomine-Image Management System. (c) Once uploaded, multi-gigapixel images are de facto available to other distributed users according to access rights and referenced by URLs. (d) Remote, multidisciplinary individuals are collaboratively and semantically annotating regions of interest in images and each annotation is referenced by its URL. (e) Expert annotations can be filtered and sets of annotations can be displayed or retrieved through the API. (f) Distributed algorithms can exploit these annotations, here a segmentation recognition model is built by supervised learning based on expert training examples. (g) An algorithm or recognition model can be applied remotely on new multi-gigapixel images for automatic annotation. (h) Experts review other user and automatic annotations by using Cytomine-WebUI proofreading tools. (i) Reviewed annotations can eventually be reused to refine and re-apply the recognition model. (j) Once image annotations are validated by an expert, final quantification results of the 'reviewed layer' are exported in standard formats</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Overview of Cytomine-WebUI: (a) Zoomable multi-gigapixel image viewer (a la Google Maps) with overlaid annotations colored according to ontology terms (Original image size: 19968 Â 25088 pixels). (b) Annotation drawing tools including various shapes and operations on polygons. (c) Gallery of bronchus annotations in current image. (d) Main menu including project listing, ontology editor, storage to upload images, user activity statistics, textual search engine. (e) Selected annotation panel with thumbnail, suggested terms (based on content-based image retrieval algorithm), textual description. (f) Project-specific, userdefined ontology for semantic annotation. (g) Activation of annotation layers of possibly distributed users and softwares. (h) Annotation properties (key-value pairs). (i) Proofreading tools to accept or edit annotations. (j) Job template panel to launch pre-configured processing routines on regions of interest. (k) Gigapixel image overview with current position. (l) Multidimensional image panel with selectors for channel, slice in a z-stack, and time point. (m) Image layer panel to apply on-the-fly tile image processing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Examples of annotations created using Cytomine in images from various research fields (see Section 3 for additional details): (a) Delineation of tissue components in H&amp;E images in mice lung cancer research (D.Cataldo's lab), (b) Tumoral areas in HDAB images in mice lung cancer research (P. Martinive's lab), (c) Area quantification in immunofluorescent mouse ear sponge assays in tumor angiogenesis (C. Gilles' lab), (d) Counting of oocytes in H&amp;E images in Chondrostoma nasus sexual maturation research (V. Gennotte's lab), (e) mRNA expression quantification through in situ hybridization assays in human breast cancer research (C.Josse's lab), (f) Cell types in fine-needle aspiration cytology in human thyroid (I. Salmon's lab), (g) Landmarks in Danio rerio embryo development (M. Muller's lab), (h) Phenotypes in Danio rerio toxicology research (M.Muller's lab), (i) Region delineation and cell counting in immunohistochemistry images in renal ischemia/reperfusion research (F.Jouret's lab), (j) Cell scoring in immunohistochemistry images in melanoma microenvironment research (P.Quatresooz's lab), (k) Nucleus counting in H&amp;E images in human breast cancer research (E. De Pauw's lab)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>, 32(9), 2016, 1395–1401 doi: 10.1093/bioinformatics/btw013 Advance Access Publication Date: 10 January 2016 Original Paper</figDesc><table>Applications and extensions of these software packages have been 
proposed in various research fields (e.g. in the context of Drosophila 
(Jug et al., 2014) and Zebrafish (</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">R.Maré e et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Pierre Ansen, Julien Confetti and Olivier Caubo for various code contributions, and Alain Empain for system administration. Natacha Rocks, Fabienne Perin, Didier Cataldo, Caroline Degand and Isabelle Salmon were early testers of the software who provided useful feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was funded by the research grants 1017072, 1217606 and 1318185 of the Wallonia (DGO6). R.M. was also partially supported by the GIGA with the help of the European Regional Development Fund. G.L. was supported by F.N.R.S., and R.V. by F.N.R.S Télévie grant. Conflict of Interest: none declared.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Zebrafish bone and general physiology are differently affected by hormones or changes in gravity</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Aceto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">126928</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">OMERO: flexible, model-driven data management for experimental biology</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Allan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">245</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Ground-truth data cannot do it alone</title>
	</analytic>
	<monogr>
		<title level="j">Anonymous Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">885</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">The data deluge</title>
	</analytic>
	<monogr>
		<title level="j">Anonymous Nat. Cell Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">775</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Software with impact</title>
	</analytic>
	<monogr>
		<title level="j">Anonymous Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">213</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluation of BRCA1-related molecular features and microRNAs as prognostic factors for triple negative breast cancers</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Boukerroucha</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cancer</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">755</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A call for bioimaging software usability</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Carpenter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="666" to="670" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">CellProfiler: image analysis software for identifying and quantifying cell phenotypes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Carpenter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Galaxy zoo volunteers share pain and glory of research</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Clery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="page" from="173" to="175" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Icy: an open bioimage informatics platform for extended reproducible research</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>De Chaumont</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="690" to="696" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluation of CellSolutions BestPrep(R) automated thin-layer liquid-based cytology papanicolaou slide preparation and BestCyte(R) cell sorter imaging system</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Delga</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Cytol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="469" to="477" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Machines learn phenotypes</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>De Souza</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluation and comparison of anatomical landmark detection methods for cephalometric X-ray images: a grand challenge</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">T</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1890" to="1900" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Phenotype classification of zebrafish embryos by supervised learning</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Jeanray</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">116989</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Bioimage informatics in the context of Drosophila research</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Jug</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="60" to="73" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Bisque: a platform for bioimage analysis and management</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kvilekval</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="544" to="552" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The timing of surgery after neoadjuvant radiotherapy influences tumor dissemination in a preclinical model</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Leroi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oncotarget</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="36825" to="36837" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">An online database for plant image analysis software tools</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lobet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plant Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A laser microdissection-based workflow for FFPE tissue microproteomics: important considerations for small sample processing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Longuespée</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Extremely randomized trees and random subwindows for image classification, annotation, and retrieval. Invited chapter in Decision Forests in Computer Vision and Medical Image Analysis Advances in Computer Vision and Pattern Recognition</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Marée</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="125" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A rich internet application for remote visualization and collaborative annotation of digital slides in histology and cytology</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Marée</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Diagnos. Pathol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">S1</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">A hybrid human-computer approach for large-scale image-based measurements using web services and machine learning</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Marée</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th IEEE International Symposium on Biomedical Imaging (ISBI)</title>
		<meeting>. 11th IEEE International Symposium on Biomedical Imaging (ISBI)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="902" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">An approach for detection of glomeruli in multisite digital pathology</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Marée</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th IEEE International Symposium on Biomedical Imaging (ISBI)</title>
		<meeting>. 13th IEEE International Symposium on Biomedical Imaging (ISBI)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Automated processing of zebrafish imaging data: a survey</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mikut</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zebrafish</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="401" to="421" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">The big picture</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Moody</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">502</biblScope>
			<biblScope unit="page">95</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">An active role for machine learning in drug development</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Chem Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="327" to="330" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Why bioimage informatics matters</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="659" to="660" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">BigDataViewer: visualization and processing for large image data sets</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pietzsch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="481" to="483" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Making big data open: data sharing in neuroimaging</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Poldrack</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Neurosci</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1510" to="1517" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards effective software solutions for big biology</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Prins</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="686" to="687" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">CATMAID: collaborative annotation toolkit for massive amounts of image data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Saalfeld</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1984" to="1986" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Fiji: an open-source platform for biological-image analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schindelin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="676" to="682" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title level="m" type="main">Quantitative neuroanatomy for connectomics in Drosophila</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Schneider-Mizell</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Ilastik: Interactive Learning and Segmentation Toolkit</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sommer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th IEEE International Symposium on Biomedical Imaging (ISBI)</title>
		<meeting>. 8th IEEE International Symposium on Biomedical Imaging (ISBI)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="230" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Soluble factors regulated by epithelial-mesenchymal transition mediate tumour angiogenesis and myeloid cell recruitment</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Suarez-Carmona</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Pathol</title>
		<imprint>
			<biblScope unit="volume">236</biblScope>
			<biblScope unit="page" from="491" to="504" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Activation of the calcium-sensing receptor before renal ischemia/reperfusion exacerbates kidney injury</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Weekers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Transl. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="128" to="138" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>