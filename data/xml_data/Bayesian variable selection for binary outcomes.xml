
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian variable selection for binary outcomes in high-dimensional genomic studies using non-local priors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Amir</forename>
								<surname>Nikooienejad</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Wenyi</forename>
								<surname>Wang</surname>
							</persName>
							<email>wwang7@mdanderson.org or vjohnson@stat.tamu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Bioinformatics and Computational Biology</orgName>
								<address>
									<addrLine>M. D. Anderson Cancer Center</addrLine>
									<postCode>77030</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Valen</forename>
								<forename type="middle">E</forename>
								<surname>Johnson</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bayesian variable selection for binary outcomes in high-dimensional genomic studies using non-local priors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv764</idno>
					<note type="submission">Received on 12 August 2015; revised on 27 December 2015; accepted on 28 December 2015</note>
					<note>Structural bioinformatics *To whom correspondence should be addressed. Associate Editor: John Hancock http:// www.stat.tamu.edu/$amir/code.html. Contact: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The advent of new genomic technologies has resulted in the production of massive data sets. Analyses of these data require new statistical and computational methods. In this article, we propose one such method that is useful in selecting explanatory variables for prediction of a binary response. Although this problem has recently been addressed using penalized likelihood methods, we adopt a Bayesian approach that utilizes a mixture of non-local prior densities and point masses on the binary regression coefficient vectors. Results: The resulting method, which we call iMOMLogit, provides improved performance in identifying true models and reducing estimation and prediction error in a number of simulation studies. More importantly, its application to several genomic datasets produces predictions that have high accuracy using far fewer explanatory variables than competing methods. We also describe a novel approach for setting prior hyperparameters by examining the total variation distance between the prior distributions on the regression parameters and the distribution of the maximum likelihood es-timator under the null distribution. Finally, we describe a computational algorithm that can be used to implement iMOMLogit in ultrahigh-dimensional settings (p &gt;&gt; n) and provide diagnostics to assess the probability that this algorithm has identified the highest posterior probability model. Availability and implementation: Software to implement this method can be downloaded at:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent developments in bioinformatics and cancer genomics have made it possible to measure thousands of genomic variables that might be associated with the manifestation of cancer. The availability of such data has resulted in a pressing need for the development of statistical methods to use these data to identify variables that are associated with binary outcomes (e.g. cancer or control, survival or death). The topic of this article is a statistical model for identifying, from a large number p of potential feature vectors, a sparse subset that are useful in predicting a binary outcome vector. Throughout this article, we assume that the binary vector of interest is denoted by y, and that the matrix of potential explanatory variables is denoted by X. Letting X k denote the submatrix of X containing the 'true' predictors, we assume that</p><formula>p ¼ FðX k b k Þ; (1)</formula><p>where F denotes a known binary link function (assumed to be the logistic distribution in what follows), and p is the n vector of success probabilities for y. The regression coefficient b k represents the nonzero regression effect for each column of X k in predicting p. The primary statistical challenge addressed in this article is the selection of the submatrix X k to be used for the prediction of p. A number of related methods have been proposed to address this problem. These include the LASSO (<ref type="bibr" target="#b24">Tibshirani, 1996</ref>), which is a penalized likelihood method that maximizes a product of the binary likelihood function implied by (1) and a constraint on the sum of the absolute value of components of the regression coefficient b k. A closely related method called Smoothly Clipped Absolute Deviation (SCAD) (<ref type="bibr" target="#b6">Fan and Li, 2001</ref>) uses a non-convex penalty function and has been demonstrated to have certain oracle properties in idealized asymptotic settings. Other penalized likelihood functions include the adaptive LASSO (<ref type="bibr" target="#b29">Zou, 2006</ref>) and the Dantzig selector (<ref type="bibr" target="#b4">Candes and Tao, 2007</ref>); these methods share asymptotic properties similar to SCAD. In ultrahigh-dimensions (p &gt;&gt; n), an effective computational technique for implementing the techniques described above is the Iterative Sure Independence Screening (ISIS) procedure (<ref type="bibr" target="#b7">Fan and Lv, 2008</ref>), which iteratively performs a correlation screening step to reduce the number of explanatory variables so that penalized likelihood methods can be applied. ISIS has been used in conjunction with several penalized likelihood methods—including adaptive LASSO (<ref type="bibr" target="#b29">Zou, 2006</ref>), the Dantzig Selector (<ref type="bibr" target="#b4">Candes and Tao, 2007</ref>), and SCAD (<ref type="bibr" target="#b6">Fan and Li, 2001</ref>)—to perform model selection. A number of Bayesian methods have also been proposed for variable selection. Notable among these are the approaches proposed by<ref type="bibr" target="#b9">George and McCulloch (1997)</ref>, which used a mixture-of-normals approximation to spike-and-slab priors on the regression coefficients.<ref type="bibr" target="#b16">Lee et al. (2003)</ref>proposed a hierarchical probit model along with MCMC based stochastic search to perform gene selection in high-dimensional settings using a latent response variable and Gaussian priors on model coefficients.<ref type="bibr" target="#b25">West et al. (2000)</ref>provided a Bayesian approach to this problem employing singular value regression and classes of informative prior distributions to estimate coefficients in high-dimensional settings.<ref type="bibr" target="#b17">Liang et al. (2008)</ref>studied mixtures of g priors for Bayesian variable selection as an alternative to default g priors to overcome several consistency issues associated with the default g prior densities. Along more similar lines,<ref type="bibr" target="#b20">Rossell et al. (2013)</ref>studied the utilization of non-local priors in Bayesian classifiers where they also address the problem of identifying variables with high predictive power. Except for<ref type="bibr" target="#b20">Rossell et al. (2013)</ref>, each of the Bayesian methods described above impose local prior densities on regression coefficients in the true model. That is, the prior density on the regression coefficients has a positive prior density function at 0 (and in most cases has its mode at 0), which from a Bayesian perspective makes it more difficult to distinguish between models that include regression coefficients that are close to 0 and those that do not. Johnson and Rossell (2012) proposed two new classes of non-local prior densities to ameliorate this problem. In the model selection context, non-local prior densities are 0 when a regression coefficient in the model is 0. This makes it easier to distinguish between coefficients that do not have an impact on the prediction of y from those that do.<ref type="bibr" target="#b15">Johnson and Rossell (2012)</ref>used a Markov Chain Monte Carlo (MCMC) algorithm to sample from the posterior distribution on the model space; the convergence properties of this algorithm were studied in Johnson (2013). The primary goal of this article is to extend the methodology proposed in<ref type="bibr" target="#b15">Johnson and Rossell (2012)</ref>for application to binary outcomes and to compare the performance of this algorithm to leading penalized likelihood methods. In addition, we describe a default procedure for setting the hyperparameters (i.e. tuning parameters) in the non-local priors, and we examine a numerical strategy for identifying the highest posterior probability model (HPPM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>Let y n ¼ ðy 1 ;. .. ; y n Þ T denote a vector of independent binary observations, X n an n Â p matrix of real numbers, b a p Â 1 regression vector, and x i the i th row of X n. We denote a model by k ¼ fk 1 ;. .. ; k j g where ð1 k 1 &lt; Á Á Á &lt; k j pÞ and it is assumed that b k1 6 ¼ 0;. .. ; b kj 6 ¼ 0 and all other elements of b are 0. The design matrix corresponding to model k is denoted by X k and is defined to have cardinality k. We assume that the columns of X have been standardized. The i th row of X k is denoted by x ik. Assuming the logistic link function for F in (1), the goal of the model selection procedure proposed in this article is to identify sparse regression models that have high predictive probability. We propose to do this by identifying the highest posterior probability model k for data y, distributed according to</p><formula>y i jb k $ Bernoulli expðx 0 ik b k Þ 1 þ expðx 0 ik b k Þ " # ; (2)</formula><p>under prior constraints on the model space and the assumption of non-local prior density constraints on the regression parameter b k. Our primary focus is on the case p &gt;&gt; n. Bayesian model selection is based on the calculation of posterior model probabilities. From Bayes theorem, the posterior probability of model j 2 J is specified as</p><formula>pðjjy n Þ ¼ pðjÞm j ðy n Þ X k2J pðkÞm k ðy n Þ ; (3)</formula><p>where m k ðy n Þ ¼ ð pðy n jb k Þp k ðb k Þdb k :</p><formula>(4)</formula><p>The art in implementing a Bayesian model selection procedure thus focuses on specifying the prior densities p k ðb k Þ for b k under each model, as well as the prior model probabilities pðkÞ for the models themselves. Except for the intercept, we assume non-local priors on the components of the regression vector in each model. These non-local priors are described in the next section. Discussion of the prior on the model space is described after that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Non-local priors</head><p>The form of the non-local prior densities imposed on the (non-zero) regression coefficients b k in this article take the form of a product of independent iMOM priors, or piMOM densities, expressible as pðb k js; rÞ ¼ s rk=2</p><formula>Cðr=2Þ k P k i¼1 jb i j Àðrþ1Þ expðÀ s b 2 i Þ: (5)</formula><p>Here b k is a vector of coefficients of length k, and r; s &gt; 0. The hyperparameter s represents a scale parameter that determines the dispersion of the prior around 0, while r is similar to the shape parameter in the Inverse Gamma distribution and determines the tail behavior of the density. An example of an iMOM density is illustrated in<ref type="figure" target="#fig_0">Figure 1</ref>for the particular case of r ¼ 1 and s ¼ 3. An important feature of this non-local prior, as highlighted in<ref type="bibr" target="#b15">Johnson and Rossell (2012)</ref>, is that these priors do not necessarily impose significant penalties on non-sparse models, provided that the estimated coefficients in the non-sparse models are not too small. That is, large values of regression coefficients are not penalized since the value of the exponential kernel in (5) tends to 1 as b i becomes large. This fact lies in stark contrast to most penalized likelihood methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prior on model space</head><p>To define the prior on the model space, we adopt a subjective version of the prior proposed by<ref type="bibr" target="#b22">Scott et al. (2010)</ref>. In the fully Bayesian version of the beta-binomial prior, this formulation specifies that the prior probability for model k is pðkÞ ¼ Bða þ k; b þ p À kÞ Bða; bÞ ;</p><formula>(6)</formula><p>where B(a, b) denotes the beta function and a and b are prior parameters that describe an underlying beta distribution on the marginal probability that a selected feature is associated with a non-zero regression coefficient in (2). This type of prior on the model size is also recommended in<ref type="bibr" target="#b5">Castillo et al. (2015)</ref>, where it is suggested that an exponential decrease in prior probabilities with model size provides optimal results when the prior density on regression parameters has the form of a double exponential. To incorporate our belief that the optimal predictive models are sparse, we arbitrarily set a ¼ minðk Ã ; blogðpÞcÞ, and b ¼ p À a. For large n, this implies that we expect, on average, a feature vectors to be included in the model. Here, k Ã ¼ argmax k p k &lt; 2 n. This choice of k Ã for the prior hyperparameter reflects the belief that the number of models that can be constructed from available covariates should be smaller than the number of possible binary responses. Similarly, by restricting a to be less than logðpÞ, comparatively small prior probabilities are assigned to models that contain more than logðpÞ covariates. Finally, we impose a deterministic constraint on model size and define PðkÞ ¼ 0 if k &gt; n=2. A sensitivity analysis for a and b in (6) is provided in Section 4.1.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Choosing hyperparameters</head><p>A critical aspect of implementing our model is the choice of the hyperparameters r and s. The value of r determines the tail behavior of the piMOM prior, while s plays a role similar to the tuning parameter in penalized likelihood methods, with its value largely determining the minimum value of a component of b k that will be selected into a high posterior probability model. To pick an appropriate, application-specific value for s, we adopt a strategy in which we compare the null distribution of the maximum likelihood estimator for b k (i.e., when all components ofTo find an appropriate value of r for the piMOM prior (5), we impose a constraint that the prior mass assigned to the interval (À10,10) equals 0.95. This constraint is imposed because coefficients larger than 10 in magnitude are not expected when the columns of the design matrix have been standardized. Together, these constraints identify a unique combination of r and s for the piMOM prior. A numerical strategy for finding this hyperparameter vector is outlined in Algorithm 1.</p><p>Notice that this procedure for choosing the hyperparameters depends on the prior on the model space. This implies that s will tend to be larger in larger models, because it is more likely that the sampled columns X will exhibit high collinearity in large models. Ideally, we would adjust s for each individual model, but as mentioned earlier it was not computationally feasible to do so for the applications and simulations reported in this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Numerical aspects of implementation</head><p>The model described in Section 2 leads to a joint density for the data, model k and its parameters. As a result, the posterior distribution of model k and its coefficients can be expressed as</p><formula>pðb k ; kjy n Þ / s rk=2 Cðr=2Þ k Y k i¼1 jb i j Àðrþ1Þ exp À s b 2 i ! Â Bða þ k; b þ p À kÞ Bða; bÞ Y n j¼1 ( e x T jk b k 1 þ e x T jk b k ) yj ( 1 1 þ e x T jk b k ) 1Àyj : (7)</formula><p>Because of the high dimension of the parameter space and the complexity of the posterior density function in (7), it is not feasible to maximize this function analytically to obtain the HPPM. To search for the HPPM, we therefore utilized a Markov chain Monte Carlo algorithm. To reduce the dimension of the parameter space, we used a Laplace approximation to marginalize over the regression coefficient b k associated with each model. The resulting approximation to the marginal posterior density of the data y under model k can be expressed as</p><formula>m k ðy n Þ ¼ ð pðy n jb k Þp k ðb k Þ db k % ð2pÞ k 2jRj À 1 2pðy n j ~ b k Þp k ð ~ b k Þ:</formula><formula>(8)</formula><p>Here ~ b k is the MAP estimate of b k and jRj is the determinant of the Hessian of the function f ðy n ; b k Þ ¼ Àlogðpðy n jb k ÞÞÀ logðp k ðb k ÞÞ, computed at ~ b k. The elements of the Hessian matrix can be expressed as</p><formula>H i;j ðb k Þ ¼ i ¼ j; À r þ 1 b 2 ik þ 6sb À4 ik þ X s x 2 si e x 0 sk b k ð1 þ e x 0 sk b k Þ 2 i 6 ¼ j; X s x si x sj e x 0 sk b k ð1 þ e x 0 sk b k Þ 2 : 8 &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; : (9)</formula><p>A simple birth-death scheme was used to sample from the posterior distribution. At each iteration of MCMC algorithm, each of the p covariates was visited in random order. The update at position i was performed by proposing a candidate model by flipping the inclusion state of that variable in the model. The candidate model was accepted using a Metropolis algorithm where the probability of accepting the candidate model, k cand , was</p><formula>r ¼ m k cand ðy n Þpðk cand Þ m k curr ðy n Þpðk curr Þ :</formula><formula>(10)</formula><p>The MAP estimate for b k was obtained using the nlminb() function in R. We assumed that an intercept was present in all models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convergence diagnostics</head><p>Convergence diagnostics of MCMC can be used to assess whether an adequate number of iterations have been performed. Because of the high dimension of the parameter space for even moderately large p, we implemented a modified coupling diagnostic (<ref type="bibr" target="#b12">Johnson, 1996</ref><ref type="bibr" target="#b13">Johnson, , 1998</ref>) to assess the probability that our MCMC algorithm had identified the true model. In the standard implementation of this method, one randomly initializes two MCMC chains by independently including each variable in the model according to a fixed probability. The components of the model in each chain are then updated synchronously, using the same uniform random deviate to perform acceptance/ rejection of the candidate models. The chains are said to couple when the models from each chain are identical. Note that once the chains become coupled, they never uncouple. In theory, the distribution of the number of updates of the chains required to obtain coupling can be used to establish a bound on the total variation distance (TVD) between iterates in the chain and the target distribution. In our implementation of the coupling diagnostic, we started 100 pairs of model chains. Each pair was updated until either they had coupled or all p components in each of the chains had been updated N times where N ¼ 250. The (local) HPPM identified by each chain was recorded, and then the HPPM's for the 100 chains were compared. We then identified the global HPPM among the 100 models in the paired chains, and also examined the proportion of chains that had both coupled and identified the 'global' HPPM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>To investigate the performance of the proposed model selection procedure, we applied our procedure to both simulated data sets and real data. We compared the performance of our algorithm to ISISSCAD (<ref type="bibr" target="#b7">Fan and Lv, 2008</ref>) in both real and simulated data because ISIS-SCAD has proven to be among the most successful model selection procedures used in practice. For the real data analyses, we also compared our method to another Bayesian procedure based on the product moment prior (<ref type="bibr" target="#b20">Rossell et al., 2013</ref>).Bayesian variable selection for binary outcomes</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Simulation studies</head><p>In all simulation studies, we assumed that the response vector represents a sequence of Bernoulli samples whose component probabilities of success are given byfor a true model k. Elements of the design matrix X were sampled from a multivariate normal distribution with mean 0 and covariance matrix R, where the diagonal elements of R were 1 and off diagonal elements were 0.5. That is, R ¼ 1 0:5 Á Á Á 0:5 0:5 1 Á Á Á 0:5 .. . .. . .. . .. . 0:5 0:5 Á Á Á 1</p><formula>(12)</formula><p>Different combinations of n and p were investigated. Moreover, different ranges of regression coefficients were tested. In our simulations, the true model contained three variables. The following combinations of n, p and b were used to perform the simulation studies.The hyperparameters s and r for the piMOM prior were selected by the procedure explained in Section 2.2.1 for each of the 10 combinations of n and p. Values of s and r selected by this procedure are summarized in Tables 1 and 2, respectively. To run ISIS-SCAD, we used the R package 'SIS' (<ref type="bibr" target="#b8">Fan et al., 2015</ref>) available from CRAN. The variable selection procedure in both algorithms was run 50 times for each of the 30 combinations of n, p and b. In each trial, true and false positive values for iMOMLogit and ISIS-SCAD were counted by comparing the selected model with the true one. TP and FP rates were defined as the average true and false positive values over 50 trials. A true positive, TP, was defined to be the number of variables that were correctly selected, while false positives, FP, were the number of variables that were mistakenly selected. Figures 2 and 3 show average TP and FP counts of both methods for all combinations of n and p and b ¼ b 1. The figures for b 2 and b 3 are provided in the supplementary materials and demonstrate similar trends. In all cases, the average FP count for iMOMLogit was less than ISIS-SCAD, while its average TP count was higher. The only case where both iMOMLogit and ISIS-SCAD had the same average TP count was when they both found the true model in all 50 simulation trials. We next compared the performance of both methods in estimating the regression coefficients. For each simulation setting, we compared the mean squared error in estimating the probability of success for each binary observation by performing 10-fold cross validation. The point estimate ^ b was estimated as the posterior mode under the HPPM. The predicted value of ^ p was then computed according to (1). Note that the prediction of the response vector involves both coefficient estimation and variable selection. The mean squared error of prediction (MSE) was defined as follows:</p><formula>MSEð^ pÞ ¼ 1 n jj^ p À pjj 2 ¼ 1 n X n i¼1 ð^ p i À p i Þ 2 : (13)</formula><p>The comparison between cross validated MSEs of both methods is shown in<ref type="figure" target="#fig_5">Figures 4</ref>and 5. As in the comparisons of TP and FPrates, these figures suggest that iMOMLogit is preferred to ISISSCAD in estimating the success probabilities of binary observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Sensitivity analysis for prior parameters on model space</head><p>To assess the sensitivity of our results to the prior hyperparameters on the model space (6), we conducted a brief sensitivity analysis under the simulation settings for which n ¼ 200, p ¼ 1000 and b ¼ ½4; 5; 6 T. We also fixed b ¼ p À a as before. This insured that the prior mean of the number of variables selected would be a. Based on the default procedure for defining a described in Section 2.2, the default value for a in this setting was 6. We examined sensitivity to this choice of a by varying a around this default value within the interval (3, 9). To quantitatively assess the sensitivity of the selection procedure to values of a in this range, we examined the consequent changes to MSEð^ pÞ described in (13). This measure incorporates errors in both variable selection and coefficient estimation. The figure provided in the supplementary material depicts MSEð^ pÞ for different values of a in the described simulation setting. As shown in that figure, model output does not change dramatically with changes in a, varying by at most 4:8 Â 10 À5 from the default choice of a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Real data analysis</head><p>We applied iMOMLogit to two data sets, one with a small sample size and one with a large sample size. These two data sets are publicly available and have good clinical annotations. The first data set was the Golub leukemia data (<ref type="bibr" target="#b10">Golub et al., 1999</ref>). The goal of our analysis for these data was to discriminate between two types of acute leukemia, myeloid (AML) and lymphoblastic (ALL). The design matrix consisted of gene expression levels produced by cDNA microarrays from bone marrow samples, and was pre-processed by RMA (<ref type="bibr" target="#b11">Irizarry et al., 2003</ref>). There are 72 samples and 7,129 genes in the data set. The second data set was the clear cellTo run pmomPM method, we used the R package 'mombf' (<ref type="bibr" target="#b21">Rossell et al., 2015</ref>) available from CRAN. In contrast to iMOMLogit and ISIS-SCAD, the mombf package focuses on prediction using Bayesian model averaging, rather than on the identification of biologically important genes using the HPPM. Because of the behavior of the pMOM prior near the origin, the pMOM model selects many more genes in the models over which it averages. Though model averaging can improve prediction accuracy (<ref type="bibr" target="#b19">Raftery et al., 1997</ref>), the current version of the mombf package does not provide estimates of the HPPM, which complicates comparisons with the other methods considered here. These attributes of the pmomPM method are illustrated in the examples that follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Leukemia data</head><p>Following<ref type="bibr" target="#b10">Golub et al. (1999)</ref>, we split the data into training and test sets. The training set contained 38 samples, with 27 ALL and 11 AML. The testing set contained 34 samples, with 20 ALL and 14 AML.<ref type="figure" target="#tab_3">Table 3</ref>summarizes the results of applying iMOMLogit, ISISSCAD and pmomPM to these data. The error rate for predicting the test data observations was 5.88% for iMOMLogit, which misclassified 2 out of 34 observations, samples 17 and 31. Both ISIS-SCAD and the method described in<ref type="bibr" target="#b10">Golub et al. (1999)</ref>resulted in an errorBayesian variable selection for binary outcomesrate of 14.7%. ISIS-SCAD achieved this error rate by finding two significant genes, 'Zyxin' and 'FAH', whereas<ref type="bibr" target="#b10">Golub et al. (1999)</ref>selected 50 genes. The pmomPM method achieved an error rate of 23.53% with an average model size of 11.08. None of the genes were assigned marginal posterior probability of 0.5 by the pmomPM method; the highest marginal posterior probability of any gene was 0.052, acheived by CD33. iMOMLogit selected a model containing only one gene named 'Zyxin', which perfectly predicted the classifications in the training data. This gene was also listed in the top 50 genes reported by<ref type="bibr" target="#b10">Golub et al. (1999)</ref>, and was found to be advantageous for classifying the two types of leukemia in four published data sets (<ref type="bibr" target="#b2">Baker and Kramer, 2006</ref>). The gene 'FAH' found only by ISIS-SCAD is involved in certain metabolic pathways that are not known to be associated with leukemia (Kegg.org). Following the methodology discussed in Section 3.1, 74% of pairs of chains that were updated using the coupling algorithm found the same highest posterior probability model (HPPM). Among all pairs, 95% coupled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Renal cell carcinoma data</head><p>The second data set was generated by the Cancer Genome Atlas Research Network (2013) and contained Illumina HiSeq data on mRNA expression for 467 patient samples. The survival outcomes of these patients were available. A hierarchical clustering of the gene expression data [preprocessed using DeMix (<ref type="bibr" target="#b0">Ahn et al., 2013</ref>) to remove stromal contamination] were performed on the data. That led to the identification of four clusters of patients based on survival times. To apply iMOMLogit, we considered two of those clusters, presenting the best and worst survival outcomes and labeled them as 0 (worst) and 1 (best). The resulting number of samples included in our analysis was 193, with 14150 features in the design matrix. The results using iMOMLogit, ISIS-SCAD and pmomPM are summarized in<ref type="figure" target="#tab_4">Table 4</ref>. To compare methods, we performed a 10fold cross-validation. The error rate of iMOMLogit was 9.79%, ISIS-SCAD's error rate was 12.97%, and pmomPM was 9.84%. In the model selected by iMOMLogit, there were 3 significant genes named 'C7orf43', 'NUMBL' and 'SAV1', with the latter two being uniquely identified by our model. 'NUMBL' participates in the Notch signaling pathway and is believed to contribute to nervous system tumors (glioma) (<ref type="bibr" target="#b23">Tao et al., 2012</ref>) as well as lung cancer (<ref type="bibr" target="#b28">Yingjie et al., 2013</ref>). The Notch signaling pathway is highly conserved, manages communication between adjacent cells and maintenance of adult stem cells, and is linked to the development of various cancers (<ref type="bibr" target="#b1">Alketbi and Attoub, 2015</ref>). Not surprisingly, we identified NUMBL as differentiating two groups of kidney patients. 'SAV1' has been reported to play a role in kidney cancer (<ref type="bibr" target="#b18">Matsuura et al., 2011</ref>), and is located in a Hippo signaling pathway (Kegg.org). The Hippo signaling pathway is highly conserved and controls epithelial tissue growth. Recently, its relation to other signaling pathways has been studied to identify new therapeutic interventions for cancer (<ref type="bibr" target="#b27">Yimlamai et al., 2015</ref>). Among all pairs of chains with different random starts, 32% of them reported the same global HPPM and 6% of paired chains were coupled. This suggests that convergence in this data set was more problematic, and that our multiple coupled chain approach (or other modifications of the standard, single chain MCMC algorithm) is required to identify the HPPM model. The genes uniquely selected by ISIS-SCAD were 'C19orf66', 'ATXN7L2' and 'MIICAL1'. 'ATXN7L2' was previously reported to be associated with non-small cell lung cancer (<ref type="bibr" target="#b26">Wu et al., 2013</ref>), whereas 'MICAL1' was previously reported to control survival in melanoma cell lines. As for the leukemia data, the pmomPM selected substantially more genes in each of its sampled models, and the genes selected in each model were highly variable. The average model size of the pmomPM method for this data set was 13.84. As before, none of the genes were assigned marginal probability of 0.5; the highest marginal posterior probability assigned to any gene was 0.33, for API5. The genes identified by iMOMLogit seem to be more biologically meaningful and better annotated in the literature for ccRCC than those selected by ISIS-SCAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this article, we introduced a Bayesian method, iMOMLogit, for variable selection in binary response regression problems in high and ultrahigh-dimensional settings. There are many applications associated with these type of data. Such data are of great interest to bioinformaticians and biologists, who routinely collect gene expression data to find prognostic features to classify cancer types. For two real datasets, iMOMLogit identified sparse models with low prediction error rates. In both cases, biological considerations suggest that the genes reported by iMOMLogit appear to be valid predictors of biological outcomes. The primary disadvantage of the iMOMLogit procedure is that it is computationally much more intensive than ISIS-SCAD and related penalized likelihood methods. We are currently investigating methods for reducing the computational burden of our algorithm by implementing various screening procedures that are similar to those used in ISIS-SCAD.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. iMOM prior for r ¼ 1 and s ¼ 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Average true positive count for b 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Average false positive count for b 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Renal Cell Carcinoma (ccRCC) RNAseq data, available from the Cancer Genome Atlas projects (Cancer Genome Atlas Research Network, 2013) (TCGA). There were 467 tumor samples and more than 20 000 genes in this data set. As mentioned earlier, we also compared our selection procedure results to a related Bayesian method proposed in Rossell et al. (2013), called pmomPM. This method uses a probit link function with a moment prior, (pMOM), another type of non-local prior. The pMOM prior has Gaussian tails and decreases quadratically near the origin. We implemented this method with the default hyperparameter suggested in Rossell et al. (2013) for sparse models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. 10-fold cross validation MSEð^ pÞ of iMOMLogit vs. ISIS-SCAD, P ¼ 1000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.5.</head><figDesc>Fig. 5. 10-fold cross validation MSEð^ pÞ of iMOMLogit vs. ISIS-SCAD, P¼ 10 000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1. Selected s parameter of piMOM prior for different simulation settings</figDesc><table>n ¼ 50 
n ¼ 100 
n ¼ 200 
n ¼ 400 
n ¼ 600 

P ¼ 1000 
5.50 
1.66 
0.68 
0.30 
0.20 
P ¼ 10 000 
4.28 
1.85 
0.76 
0.34 
0.21 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 2. Selected r parameter of piMOM prior for different simulation settings</figDesc><table>n ¼ 50 
n ¼ 100 
n ¼ 200 
n ¼ 400 
n ¼ 600 

P ¼ 1000 
2.04 
1.50 
1.24 
1.07 
1.00 
P ¼ 10 000 
1.90 
1.54 
1.27 
1.09 
1.01 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 3. Comparison between iMOMLogit and other methods for leukemia data set</figDesc><table>Method 
Error rate 
Reported genes 

iMOMLogit 
5.88% 
Zyxin 
ISIS-SCAD 
14.70% 
Zyxin -FAH 
pmomPM 
23.53% 
No genes had marginal posterior 
probability greater than 0.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 4. Comparison between iMOMLogit and other methods for renal cell carcinoma data set</figDesc><table>Method 
Error rate 
Reported genes 

iMOMLogit 
9.79% 
C7orf43 -NUMBL -SAV1 
ISIS-SCAD 
12.97% 
C7orf43 -C19orf66 -
ATXN7L2 -MICAL1 
pmomPM 
9.84% 
No genes had marginal posterior 
probability greater than 0.5 </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">b k are 0), obtained from a randomly selected design matrix X k , to the prior density on b k under the alternative assumption that the components are non-zero. By choosing s to be just large enough so that the intersection of these two densities falls below a specified threshold, we are able to approximately bound the probability of false positives in the model, while at the same time maintaining sensitivity to regression coefficients that fall outside of the distribution of MLEs that estimate 0. In principle, we could employ this strategy to obtain a distinct value of s for each model k, but were unable to do so in this article because of the computational expense this procedure would impose. Instead, we mixed over models to obtain a single value of s. Numerically, our strategy is implemented as follows. We begin by sampling a model from the prior on the model space. That is, we randomly sample k columns of X where k is determined by a draw from the prior on the model space. A Bernoulli vector of length n with success probability ^ p is generated, where ^ p is the proportion of successes in the observed data. Then the MLE for the model is estimated using standard logistic regression software with an intercept included in the model. This process is repeated N times to obtain a normal density approximation to the marginal density of maximum likelihood estimates under the condition that all true regression coefficients (except for the intercept) are 0. Typically, N ¼ Oð10 4 Þ. Next, piMOM priors corresponding to different values of s are compared to the null distribution of the MLE. Based on these comparisons, we numerically determine the value of s so that the overlap of these densities falls below a threshold of p À1=2. This overlap value is chosen heuristically in a way that suggests the number of false positives will decrease to 0 as p and n become large. Other thresholds of the form p Àa might also be considered, but we have found that a ¼ 1=2 provides good performance in a wide range of simulation studies and in real data examples. Further justification for this threshold is provided in the supplementary data. Notice that for a fixed p, the dispersion of the null distribution of the MLE around 0 decreases as the sample size n increases, although the rate of decrease is also affected by the structure of the design matrix X. This effect is illustrated in Table 1. We also note that a similar procedure for setting the scale parameter for local priors on the regression coefficients could potentially be implemented. Unfortunately, the application of this procedure to local priors can require extremely large values of tuning parameters in order to &apos;squash&apos; the prior near 0 and achieve small overlap with the null distribution. As a consequence of this fact, the tuning parameters selected by this procedure will not reflect any reasonable prior belief on the values of the regression parameters in a logistic model with a standardized design matrix.</note>

			<note place="foot">A.Nikooienejad et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank John Hancock and three anonymous referees for their valuable comments that improved the presentation of the materials in this article. The authors would also like to thank Jaeil Ahn for providing the deconvolved RNAseq data for ccRCC samples as well as the two clusters of patients with most distinct survival outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Demix: deconvolution for mixed cancer transcriptomes using raw measured data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ahn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1865" to="1871" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Notch signaling in cancer: Rationale and strategies for targeting</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Alketbi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Attoub</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Cancer Drug Targets</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="364" to="374" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying genes that contribute most to good classification in microarrays</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Baker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">S</forename>
				<surname>Kramer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">407</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Comprehensive molecular characterization of clear cell renal cell carcinoma</title>
	</analytic>
	<monogr>
		<title level="j">Cancer Genome Atlas Research Network Nature</title>
		<imprint>
			<biblScope unit="volume">499</biblScope>
			<biblScope unit="page" from="43" to="49" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">The dantzig selector: Statistical estimation when p is much larger than n</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Candes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Tao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="page" from="2313" to="2351" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Bayesian linear regression with sparse priors</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Castillo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1986" to="2018" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Variable selection via nonconcave penalized likelihood and its oracle properties</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1348" to="1360" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Sure independence screening for ultrahigh dimensional feature space</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lv</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="849" to="911" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title level="m" type="main">SIS: Sure Independence Screening. R package version 0</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="7" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Approaches for bayesian variable selection</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">I</forename>
				<surname>George</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">E</forename>
				<surname>Mcculloch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Molecular classification of cancer: class discovery and class prediction by gene expression monitoring</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">R</forename>
				<surname>Golub</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="531" to="537" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Summaries of affymetrix genechip probe level data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">A</forename>
				<surname>Irizarry</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="15" to="15" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Studying convergence of markov chain monte carlo algorithms using coupled sample paths</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">E</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="154" to="166" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A coupling-regeneration scheme for diagnosing convergence in markov chain monte carlo algorithms</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">E</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="238" to="248" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">On numerical aspects of bayesian model selection in high and ultrahigh-dimensional settings</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">E</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Anal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="741" to="758" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Bayesian model selection in highdimensional settings</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">E</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rossell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="649" to="660" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Gene selection: a bayesian variable selection approach</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">E</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="90" to="97" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Mixtures of g priors for bayesian variable selection</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Liang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Downregulation of SAV1 plays a role in pathogenesis of high-grade clear cell renal cell carcinoma</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Matsuura</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cancer</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">523</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian model averaging for linear regression models</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Raftery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="179" to="191" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">High-dimensional bayesian classifiers using non-local priors. In: Statistical Models for Data Analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rossell</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="305" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">mombf: Moment and Inverse Moment Bayes Factors</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rossell</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>R. package version 1.6.1</note>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Bayes and empirical-bayes multiplicity adjustment in the variable-selection problem</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">G</forename>
				<surname>Scott</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">O</forename>
				<surname>Berger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2587" to="2619" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Numbl inhibits glioma cell migration and invasion by suppressing TRAF5-mediated NF-B activation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Tao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Cell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2635" to="2644" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Stat. Soc. B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title level="m" type="main">Dna microarray data analysis and regression modeling for genetic expression profiling</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>West</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>ISDS Discussion</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Genome-wide association study of genetic predictors of overall survival for non-small cell lung cancer in never smokers</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Wu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="4028" to="4038" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Emerging evidence on the role of the hippo/yap pathway in liver physiology and cancer</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Yimlamai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Hepatol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1491" to="1501" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Numblike regulates proliferation, apoptosis, and invasion of lung cancer cell</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Yingjie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tumour Biol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2773" to="2780" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">The adaptive lasso and its oracle properties</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1418" to="1429" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>