
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics Improved image alignment method in application to X-ray images and biological images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Ching-Wei</forename>
								<surname>Wang</surname>
							</persName>
							<email>cweiwang@mail.ntust.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="institution">Graduate Institute of Biomedical Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Hsiang-Chou</forename>
								<surname>Chen</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Graduate Institute of Applied Science and Technology</orgName>
								<orgName type="institution" key="instit1">Honors College National Taiwan University of Science and Technology</orgName>
								<orgName type="institution" key="instit2">Taipei City</orgName>
								<address>
									<postCode>10607</postCode>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimage informatics Improved image alignment method in application to X-ray images and biological images</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">15</biblScope>
							<biblScope unit="page" from="1879" to="1887"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt309</idno>
					<note type="submission">Received on March 8, 2013; revised on May 22, 2013; accepted on May 24, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren Availability: The software implementation of the presented method and the data used in this study are made publicly available for scien-tific communities to use (http://www-o.ntust.edu.tw/$cweiwang/Imp rovedImageRegistration/). Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Alignment of medical images is a vital component of a large number of applications throughout the clinical track of events; not only within clinical diagnostic settings, but prominently so in the area of planning, consummation and evaluation of surgical and radio-therapeutical procedures. However, image registration of medical images is challenging because of variations on data appearance, imaging artifacts and complex data deformation problems. Hence, the aim of this study is to develop a robust image alignment method for medical images. Results: An improved image registration method is proposed, and the method is evaluated with two types of medical data, including biological microscopic tissue images and dental X-ray images and compared with five state-of-the-art image registration techniques. The experimental results show that the presented method consistently performs well on both types of medical images, achieving 88.44 and 88.93% averaged registration accuracies for biological tissue images and X-ray images, respectively, and outperforms the benchmark methods. Based on the Tukey&apos;s honestly significant difference test and Fisher&apos;s least square difference test tests, the presented method performs significantly better than all existing methods (P 0.001) for tissue image alignment, and for the X-ray image registration , the proposed method performs significantly better than the two benchmark b-spline approaches (P50.001).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Image registration is the process of systematically placing separate images in a common coordinate system so that the information they contain can be optimally integrated or compared. This is becoming the central tool for image analysis, understanding and visualization in both medical and scientific applications (<ref type="bibr" target="#b19">Matsopoulos et al., 2001</ref>). Time series of images are acquired for various reasons, such as monitoring of bone growth in children, monitoring of tumor growth, post-operative monitoring of healing or observing the passing of an injected bolus trough a vessel tree, and image registration plays an important role for these medical applications. However, alignment of medical images is challenging because of variations on data appearance, imaging artifacts and complex data deformation problems, making existing registration approaches unstable and performs poor (<ref type="bibr" target="#b15">Hill et al., 2001</ref>); Section 2 shows the experimental results of four existing registration methods. Although there has also been substantial progress in non-rigid registration algorithms that can compensate for tissue deformation or align images from different subjects, many registration problems remain unsolved (<ref type="bibr" target="#b15">Hill et al., 2001</ref>). From literature review (<ref type="bibr" target="#b0">Alic et al., 2011;</ref><ref type="bibr" target="#b2">Arganda-Carreras et al, 2006;</ref><ref type="bibr" target="#b10">Chakravarty et al., 2006;</ref><ref type="bibr" target="#b12">Dauguet et al., 2007;</ref><ref type="bibr" target="#b22">Pitiot and Guimond, 2008;</ref><ref type="bibr" target="#b24">Saalfeld et al., 2010</ref><ref type="bibr" target="#b25">Saalfeld et al., , 2012</ref><ref type="bibr" target="#b28">Sorzano et al., 2005;</ref><ref type="bibr" target="#b30">Tan et al., 2007</ref>), the raw data tends to be carefully prepared, showing little morphological distortions or stain variation, to simplify the registration task. In addition, they tend to work with low-resolution images without dealing with high-precision tissue or cell-level registration. The aim of this work is to investigate a robust and fully automatic image registration method for medical images. Two types of medical data are included in this study. One is serial microscopic tissue images with conventional histopathological hematoxylin and eosin (H&amp;E) staining, and the other is dental X-ray images acquired using different radiation time from 0.04 to 2.5 s with slightly different capturing views.<ref type="figure" target="#fig_0">Figure 1</ref>illustrates challenges with respect to data variations in our experimental data for image alignment. There are various types of image registration techniques (<ref type="bibr" target="#b20">Oliveira and Tavares, 2012;</ref><ref type="bibr" target="#b36">Zitova and Flusser, 2003</ref>), which can be categorized into area-based methods and feature-based methods. Zitova and Flusser (<ref type="bibr" target="#b36">Zitova and Flusser, 2003</ref>) suggested that feature-based methods are recommended if the images contain enough distinctive and easily detectable objects, which is usually the case of applications in remote sensing and computer vision, and area-based methods are usually used for medical images, which are not so rich in such details. In this study, we first evaluated five existing image registration techniques on the collected medical images. They are one featurebased method, i.e. SURF (<ref type="bibr" target="#b4">Bay et al, 2008</ref>), which is popularly adopted for remote sensing and general computer vision applications, and four area-based methods demonstrated to be useful for biological images, including a unidirectional elastic b-spline model (UnwarpJ) (<ref type="bibr" target="#b28">Sorzano, et al., 2005</ref>), an improved bi-directional elastic b-spline model (BunwarpJ) (<ref type="bibr" target="#b2">Arganda-Carreras et al., 2006</ref>), a state-of-the-art 3D reconstruction system *To whom correspondence should be addressed.</p><p>(TrakEM2) (<ref type="bibr" target="#b7">Cardona et al., 2010</ref><ref type="bibr" target="#b8">Cardona et al., , 2012</ref><ref type="bibr" target="#b24">Saalfeld, et al., 2010</ref><ref type="bibr" target="#b25">Saalfeld, et al., , 2012</ref>) and mutual information-based image registration approach (<ref type="bibr" target="#b17">Maes, 1997;</ref><ref type="bibr" target="#b21">Pluim, 2003</ref>) using the MATLAB implementation (MathWorks). The five benchmark methods (SURF, UnwarpJ, BunwarpJ, TrakEM2 and mutual information) are briefly described later in the text. SURF (speeded-up robust features) (<ref type="bibr" target="#b4">Bay et al., 2008</ref>) is a scale and rotation-nvariant detector and descriptor based on sums of 2D Haar wavelet responses, and the method is a popularly adopted technique and widely applied to general computer vision applications such as remote sensing image alignment (<ref type="bibr" target="#b6">Brook and Ben-Dor, 2011;</ref><ref type="bibr" target="#b31">Teke and Temizel, 2010</ref>) and object recognition task (<ref type="bibr" target="#b13">Dreuw et al., 2009</ref>). However, as for medical images, local image features can appear confusing to one another; SURF does not perform well on corresponding feature identification. Thus, this method tends to fail in our experiment (see Section 2).<ref type="figure" target="#fig_1">Figure 2</ref>shows the results of corresponding landmark detection by SURF in application to general computer vision images and in biological images. For general computer vision applications, SURF is able to identify corresponding features (<ref type="figure" target="#fig_1">Fig. 2a</ref>), but for biological tissue images, SURF performs poor on corresponding landmark detection (<ref type="figure" target="#fig_1">Fig. 2b</ref>). UnwarpJ (unidirectional elastic b-spline model) is introduced by<ref type="bibr" target="#b28">Sorzano et al. (2005)</ref>by combining and extending some of the best techniques in the context of medical imaging. They use B-splines to model the deformation field and solve the registration problem by minimizing a pixelwise mean-square distance measure between the target image and the transformed source images with vector-spline regularization constraints. This method is demonstrated to be effective on the elastic registration of images of electrophoretic gels and fly embryos. Later, based on UnwarpJ, Arganda<ref type="bibr" target="#b2">Carreras et al. (2006)</ref>developed an improved bi-directional elastic b-spline model (BunwarpJ) to perform better registration of histopathological tissue images. However, quantitative evaluations of the method were not provided in (<ref type="bibr" target="#b2">Arganda-Carreras et al., 2006</ref>) to show the performance of BunwarpJ on alignment of tissue images. TrakEM2 (<ref type="bibr" target="#b7">Cardona et al., 2010</ref><ref type="bibr" target="#b8">Cardona et al., , 2012</ref><ref type="bibr" target="#b24">Saalfeld et al., 2010</ref><ref type="bibr" target="#b25">Saalfeld et al., , 2012</ref>) is a recent development for 2D medical image registration and/or 3D image reconstruction, but<ref type="bibr" target="#b7">Cardona et al. (2010)</ref>pointed out that 'TrakEM2 acknowledges that any automatic procedure (such as image registration and image segmentation) will eventually fail partially or fully and will require manual correction by a human operator'. Mutual information techniques (<ref type="bibr" target="#b17">Maes, 1997;</ref><ref type="bibr" target="#b21">Pluim, 2003</ref>) measure the statistical dependence or information redundancy between image intensities of corresponding voxels in both images and use mutual information or relative entropy as the matching criterion. The method has been validated for rigid body registration of computed tomography, magnetic resonance and photon emission tomography images. Here, recent MATLAB R2013a implementation (MathWorks) of the mutual information-based method is adopted for evaluation. In our experiments (see Section 2), the five existing techniques do not deal with either tissue deformations or stain variation problems and perform poor, obtaining 565% registration accuracies on average for biological tissue images, and for X-ray images, the two b-spline models produce poor results with accuracy 560%. Hence, a robust and fully automatic registration method is highly desirable. In this work, an improved image alignment approach that is a combination of feature-based and area-based elastic registration method and a tissue pattern extraction technique is introduced here, and the presented method is fully automatic and performs consistently well in our experiments for both biological tissue images and X-ray images. Detailed quantitative evaluations with statistical analysis were conducted, showing that the presented method achieves 88.44 and 88.9% averaged registration accuracies for biological tissue images and X-ray images, respectively, and outperforms the benchmark methods. Based on the Tukey's honestly significant difference test (HSD) and Fisher's least square difference test (LSD) tests, the presented method performs significantly better than all existing methods (P 0.001) for tissue image alignment, and for the X-ray image registration, the proposed method performs significantly better than the two benchmark b-spline approaches (P50.001). The outline of this article is as follows. The materials and results are presented in Section 2, and the proposed methods are described in Section 3. Information regarding the(a) For general computer vision applications, SURF is able to identify corresponding features, but (b) for biological tissue images where local features can be confusing, SURF performs poor on corresponding landmark detection implementation of the presented method is provided in Section 4 and a discussion is given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DATA AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Materials</head><p>Serial tissue images. Ninety pairs of serial histopathological slides were produced as the target and source images to be tested on the image registration techniques. The serial histological slides were collected using C57 mice with IgAN [immunoglobulin A (IgA) nephropathy], which is the most common glomerular disorder across the world (D'<ref type="bibr">Amico, 1987</ref>). IgAN was induced by daily injection of purified IgA anti-phosphorylcholine and pneumococcal C-polysaccharide (PnC) as described previously (<ref type="bibr" target="#b9">Chao et al., 2006</ref>). The renal cortical tissue was collected and stored appropriately until analysis. All animal experiments were performed with the approval (permit number IACUC-11-063) of the Institutional Animal Care and Use Committee of The National Defense Medical Center, Taiwan, and were consistent with the NIH Guide for the Care and Use of Laboratory Animals. For histopathology, the tissues were fixed in 10% buffered formalin and embedded in paraffin. Serial sections (4 m) were cut using Leica RM2155 and stained with H&amp;E. Slide images were captured by light microscopy (Olympus, Japan) at the magnification of Â400. Dental X-ray Images. Forty-five pairs of source and target dental X-ray images were collected for registration, and each pair was sampled without replacement from 10 dental X-ray images (45 ¼ C 10 2 ¼ 10! 2!8! ), acquired with different radiation time (0.04, 0.06, 0.1, 0.16, 0.25, 0.4, 0.63, 1, 1.6 and 2.5 s) and slightly different capturing views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experimental results on biological tissue images</head><p>Evaluation Method. In conventional computer vision applications, the performances of image registration algorithms can be evaluated using sum of squared differences (SSD) between the target image and the transformed source image to represent the registration accuracy level. However, for the biological data, this evaluation result can be misleading, as it is common that the intensity of the pixel in the target image and the one of the wrongly registered pixel in the transformed source image can be similar, and that the intensity of the pixel in the target image and the one of the accurately registered pixel in the transformed source image can be different because of stain variation. Hence, to provide a quantitative evaluation, five corresponding landmarks between target images and the associated transformed source images by each registration method were first manually marked, and an automatic matching system is built to compare the coordinates of the corresponding landmarks. The registration accuracy for each image pair is computed by the matching successful rate over the corresponding landmarks, and the performance of each registration method is evaluated by the averaged accuracies over all image pairs.<ref type="figure" target="#tab_1">Table 1</ref>presents the quantitative evaluation outcomes of biological tissue image registration with ANOVA analysis. Furthermore, using SPSS software (SPSS<ref type="bibr" target="#b29">Inc, 2008</ref>), the quantitative registration accuracy scores were analyzed with the Tukey's HSD and the LSD (<ref type="figure" target="#tab_2">Table 2</ref>). The experimental results show that the five benchmark techniques do not deal with either tissue deformations or stain variation problems and perform poor, obtaining 565% registration accuracies on average. In comparison, the presented method achieves 88.44% averaged registration accuracy for biological tissue images and significantly outperforms the benchmark methods based on Tukey's HSD and LSD tests (P 0.001).used for medical images, which are not so rich in such details. However,<ref type="bibr" target="#b27">Shum and Szeliski (2000)</ref>indicated that as area-based direct-matching methods use all available image data, they result in accurate registration if the initialized disparities at the start of the registration procedure are already close to the true disparities. This is consistent to our experimental results; when the target images appear similar to the source images, the three benchmark area-based methods (UnwarpJ, BunwarpJ and TrakEM2) perform well, but when the target image and source images do not appear similar to each other, the three area-based approaches tend to perform poor. Sparse methods have achieved great success in various biomedical applications, such as biomarker selection, biological network construction and magnetic resonance imaging (<ref type="bibr" target="#b35">Ye and Liu, 2012</ref>). The underlying representations of many biomedical data are compressible in the sense that they have concise representation when expressed in a proper basis. Feature-based matching methods as sparse models use invariant features to ensure reliable matching, and widely used framework rely on SURF descriptors (<ref type="bibr" target="#b4">Bay et al., 2008;</ref><ref type="bibr" target="#b6">Brook and Ben-Dor, 2011;</ref><ref type="bibr" target="#b13">Dreuw et al., 2009</ref>) or SIFT features (<ref type="bibr" target="#b16">Lowe, 2004;</ref><ref type="bibr" target="#b32">Vedaldi, 2006</ref>), which offer invariance to affine transformation (i.e. translation, rotation and scaling) in the image representation. However,<ref type="bibr" target="#b3">Barzigar et al. (2013)</ref>pointed out that feature-based methods are not well suited for estimating large transformations, as the matching accuracy and key point localization degrade for large transformations.<ref type="figure" target="#fig_6">Figure 7</ref>shows the feature-matching results by SURF, SIFT and the proposed method where SURF produces poor matching, SIFT generates some incorrect matches and the proposed method finds accurate matched key points for fast and higher-level coarse registration. The associated image registration result is displayed in<ref type="figure" target="#fig_8">Figure 8</ref>. Hence, to investigate a robust alignment method for both medical and biological images, our goal is to develop a method that integrates the strengths of both area-based approaches and feature-based methods. In this article, we develop a fully automatic, robust and fast registration method for biological and medical data, containing three major parts: (i) data normalization and feature extraction, (ii) sparse approximation of images for coarse and fast global registration, and (iii) optimize and refine local registration by area-based direct-matching approach.<ref type="bibr" target="#b7">Cardona et al., 2010;</ref><ref type="bibr" target="#b24">Saalfeld et al., 2010;</ref><ref type="bibr" target="#b8">Cardona et al., 2012;</ref><ref type="bibr" target="#b25">Saalfeld et al., 2012</ref>Note: The proposed method outperforms the benchmark methods on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data normalization and feature extraction</head><p>A data normalization process is proposed to reduce variations on image features and enhance tissue patterns, which greatly benefit the following feature-matching process and area-based directing matching results. For biological color images, in conventional histopathological staining (H&amp;E), hematoxylin induces the blue staining of nuclei and eosin induces the red/pink staining of cytoplasm. Based on our previous study (<ref type="bibr">Wang and Yu)</ref>showing that applying histogram equalization in RGB color space performed better in separating the nuclei from the cytoplasm than in HSL color space, both to enlarge the difference between the nuclear and cytoplasmic expression in color space and to further produce more distinctive tissue image features; the normalization is independently applied to the red I r and blue I b channels of each image, producing new image intensities I 0 r , I 0 b ; see Equations (2 and 3). For dental X-ray images, the normalization is applied to the single gray-scale channel. The normalization process is formulated as follows.</p><formula>I 0 r ðiÞ ¼ cfd r ðiÞ M Â N Â ð2 c À 1Þ ð 2Þ</formula><p>where r stands for the red channel, h r ðiÞ is the frequency of intensity value i in the channel r, cfd r ðiÞ ¼ P i 0 h r ðiÞ, 0 i 2 c À 1, c represents the<ref type="figure">Fig. 4</ref>. The box plot of quantitative evaluation results of tissue image registration where outliers 41:5Â interquartile range are marked with a dot and outliers43Â interquartile range are marked with an asterisk. The presented methods work constantly well overall and significantly outperform the benchmark methods based on Tukey's HSD and LSD tests (P 0.001) (<ref type="figure" target="#tab_2">Table 2</ref>)where b stands for the blue channel, h b ðiÞ is the frequency of intensity value i in the channel b, cfd b ðiÞ ¼ P i 0 h b ðiÞ, 0 i 2 c À 1, c represents the number of bits used to represent each pixel in each channel and M Â N is the size of the image. For biological images, although the dyes used are visualized as having different colors, the resulting stains actually have complex overlapping absorption spectra. In the previous studies, color deconvolution was used to achieve color separation in forensic image processing (<ref type="bibr" target="#b5">Berger et al., 2006</ref>) and to achieve stain separation (<ref type="bibr" target="#b23">Ruifrok and Johnston, 2001;</ref><ref type="bibr" target="#b34">Wang, 2012</ref>) in biological image processing. Our goal is to extract the eosinophilic structures, which are generally composed of intracellular or extracellular protein, as image features for image registration, and the color decomposition technique is used to extract independent hematoxylin and eosin stain contributions from individual histopathological images using orthonormal transformation of RGB. In the RGB color-space, every color is defined as ~ c ðc 1 , c 2 , c 3 Þ ðr, g, bÞ where r, g, b represent the red, green and blue components, and we can see additive color mixing as the vector addition of RGB components. To model the colors in an image as the vector addition of a desired (D) and undesired (U) components to a background color (P), new unit vectors can be defined as follows.</p><formula>~ u PU ! ð4Þ ~ d PD ! ð5Þ ~ n ~ u Â ~ d ð6Þ</formula><p>where ~ n is perpendicular to ~ u and ~ d; ~ n, ~ u, ~ d span the 3D space; PU ! and PD ! are alternative unit vectors based on the undesired and desired colors. Then, color ~ c can be transformed to the new unit vectors.</p><formula>~ c ¼ r Á ~ r þ g Á ~ g þ b Á ~ b ¼ u Á ~ u þ d Á ~ d þ n Á ~ n þ ~ p ð7Þ</formula><p>where ~ p OP ! ; O is the origin in the RGB 3D space; OP ! is a vector.</p><p>By setting u ¼ 0, we remove the undesired component and obtain the</p><formula>new color c 0 ! ¼ d Á ~ d þ n Á ~ n þ ~ p.</formula><p>In the case of three channels, the color<ref type="figure" target="#tab_4">Table 4</ref>) system can be described as a matrix of the form with every row representing a specific stain and every column representing the optical density (OD) as detected by the red, green and blue channel for each stain.</p><formula>M ¼ c 11 c 12 c 13 c 21 c 22 c 23 c 31 c 32 c 33 0 @ 1 A ð8Þ</formula><p>For normalization, each OD vector is divided by its total length, such that c c 11 ¼ c 11 0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi</p><formula>c 2 11 þ c 2 12 þ c 2 13 q , c c 21 ¼ c 21 0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi c 2 21 þ c 2 22 þ c 2 23 q and c c 31 ¼ c 31 0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi c 2 31 þ c 2 32 þ c 2 33 q</formula><p>. In this study, the normalized OD matrix, b M, to describe the color system for orthonormal transformation is defined as follows:</p><formula>b M ¼ R G B 0 1 1 Red 1 0 1 Green 1 1 0 Blue 0 B B @ 1 C C A ð9Þ</formula><p>When C is the 3 Â 1 vector for amounts of the stains at a particular pixel, the vector of OD levels detected at that pixel is equal to L ¼ C b M. Therefore, multiplication of the OD image with the inverse of OD matrix results in orthogonal representation of the stains forming the image (C ¼ b M À1 L). Then, the image features of the red channel are extracted as eosinophilic structures for both high-level feature-based coarse registration and local area-based direct-matching registration.<ref type="figure" target="#fig_7">Figure 9</ref>displays the flowchart of the presented approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sparse approximation for fast and coarse global registration</head><p>Given I 1 and I 2 as two images for alignment, T as a set of all possible transformations between I 1 and I 2 , and U t ðIÞ as the function that maps an image I to its transformed image using the transformation t, the goal is to find the optimal transformation t 0 :</p><formula>t 0 ¼ arg min t2T jjU t ðI 1 Þ À I 2 jj 2 ð10Þ</formula><p>The transformation invariant distance dðI 1 , I 2 Þ ¼ jjU t 0 ðI 1 Þ À I 2 jj 2 corresponds to the regular Euclidean distance when the images are aligned optimally in L 2 where images are considered as continuous functions in</p><formula>L 2 ¼ ff : R 2 ! R : R 1 À1 jfðxÞj 2</formula><p>dx51g, but finding the optimal transformation t 0 and the smallest distance dðI 1 , I 2 Þ is not easy as the objective function is non-convex and local minima trap solution might occur. Feature-based approaches represent a more efficient class of methods. Considered images can be well approximated by the sparse expansion in a series of geometric functions, we define D ¼ f : 2 T d g &amp; L 2 as a set of geometric features constructed by transforming a generating function 2 L 2 where T d &amp; T represents a finite discretization of the transformations T, and ¼ U ð Þ denotes the transformation of the</p><formula>p ¼ X K i¼1 a i i ð11Þ q ¼ X K i¼1 b i i ð12Þ</formula><p>where a i , b i are non-negative coefficients. Then, the coarse global image registration problem can be formulated as finding the optimal relative transformation t 00 between the K-sparse approximations with the smallest approximate transformation invariant distance dðp, qÞ:There are two notable advantages with respect to sparse approximation and coarse global registration. First, it helps escape from many local minimum traps, and second, it greatly reduces computational time for image alignment. Here, the K-sparse approximations p and q are obtained by the following procedures. Obtaining normalized image features F 1 , F 2 by the method described in Section 3.1, interested points S 1 , S 2 are detected using the difference of Gaussian detector (<ref type="bibr" target="#b16">Lowe, 2004</ref>), and then the corresponding feature points p, q are selected as geometric consensus between S 1 and S 2 using random sample consensus (RANSAC) (<ref type="bibr" target="#b14">Fischler and Bolles, 1981</ref>). The selected paired feature points p, q are then used for coarse global registration. The registration methodology adapted from</p><p>(<ref type="bibr" target="#b2">Arganda-Carreras et al., 2006</ref>) is based on the minimization of an energy function that incorporates three energy terms,</p><formula>( b E ¼ arg min E). E ¼ w i E img þ w m E mark þ w c E cons ð15Þ</formula><p>where E img is the energy of the similarity error between U t ðI 1 Þ and I 2 , E mark is the error of the mapping of paired feature points p, q, E cons expresses the geometrical consistency between the elastic deformation in both direction (I 1 ! I 2 ,I 2 ! I 1 ) and w k are the weights for sub-energy terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Refine local registration by area-based direct matching</head><p>Obtaining alignment outputs from the coarse registration process described in the previous section, we then refine registration by an area-based direct-matching method, adapted from the improved bi-directional elastic b-spline model (<ref type="bibr" target="#b2">Arganda-Carreras et al., 2006</ref>). The registration methodology is based on the minimization of an energy function that incorporates four energy terms; the calculation of the elastic deformation field, dðxÞ, is through the minimization of an energy function</p><formula>( b E ¼ arg min E). E ¼ w i E img þ w d E div þ w r E rot þ w c E cons ð16Þ</formula><p>where E img is the energy of the similarity error between I</p><formula>E div ¼ Z R 2 jjrdivdjj 2 dxdy ð18Þ</formula><p>where divd ¼ @ x d 1 þ @ y d 2 represents the divergence of the 2D vector field d, and the divergence of a vector represents the net flow of the vector of a unit volume.</p><formula>E rot ¼ Z R 2 jjrrotdjj 2 dxdy ð19Þ</formula><p>where rotd ¼ À@ y d 1 þ @ x d 2 represents the length of the unique component of the curl of 2D vector field d, and where rf ¼ ð@ x f, @ y fÞ is the gradient of the scalar function f; the curl is usually described as a measure of the circulation of a vector field.</p><formula>E cons ¼ E þ cons þ E À cons ð20Þ E þ cons ¼ 1 # þ X x2 þ jjx À d À ðd þ ðxÞÞjj 2 ð21Þ E À cons ¼ 1 # À X x2 À jjx À d þ ðd À ðxÞÞjj 2 ð22Þ</formula><p>where þ , À define sets of relevant pixels common to the target and source images</p><formula>À þ ¼ È x 2 2 \ Z 2 : d þ ðxÞ 2 1 \ Z 2 É , À ¼ È x 2 1 \ Z 2 : d À ðxÞ 2 2 \ Z 2 ÉÁ , where # þ , # À are</formula><p>the number of pixels in the masks, and where d þ is the elastic deformation in the direction (I 1 ! I 2 ) and d À is the elastic deformation in the direction (I 2 ! I 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION</head><p>The software implementation of the presented method is developed in JAVA (with jdk 1.7.0.07 installed) and based on ImageJ framework (1.45s version) (<ref type="bibr" target="#b26">Schneider et al., 2012</ref>). The software and the data are both made publicly available for scientific communities to use (http://www-o.ntust.edu.tw/ $cweiwang/ImprovedImageRegistration/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Image registration is the process of overlaying two or more images of the same scene taken at different times from different viewpoints or using different capturing modules, and a good image alignment method has to take a number of issues into consideration (<ref type="bibr" target="#b3">Barzigar et al., 2013</ref>), including imperfect inputs such as aberrations and artifacts, occlusion issues where many pixels in one image may not match with any pixel in another image and uniqueness issues where each pixel in an image has to uniquely map to a pixel of another image. Alignment of biological images is challenging as local image features may appear confusing to one another, and imperfect inputs are inevitable. In this article, a robust and fully automatic registration method has been presented and demonstrated to be promising for aligning biological tissue images and dental X-ray images. Moreover, for the tissue image alignment, the presented method outperforms five popularly adopted existing approaches (P 0.001) based on Tukey's HSD and LSD tests and performs consistently well for both types of data in our experiments (88.44 and 88.93% averaged registration accuracies for biological tissue images and X-ray images, respectively). The presented image registration algorithm is not limited to tissue images or dental X-ray scans but can also be applied to other anatomically or histologically defined medical data. Moreover, as complex deformation problems are unavoidable in real life data, the presented technique will prove to be a substantial advantage for any application that requires image registration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: FULL STATISTICAL RESULTS</head><p>A one-way analysis of variance (ANOVA) is a way to test the equality of three or more means at one time by using variances. The total variation is comprised the sum of the squares of the differences of each mean with the grand mean. There is the between group variation and the within group variation. The whole idea behind the analysis of variance is to compare the ratio of between group variance with within group variance. If the variance caused by the interaction between the samples is much larger when compared with the variance that appears within each group, then it is because the means are not the same. The significant ANOVA result suggests rejecting the global null hypothesis that the means are the same across the groups being compared. Multiple comparison procedures are then used to determine which means differ. Here, Tukey's HSD and LSD are used as multiple comparison tests.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Challenges with respect to data variations for image registration of medical images. (a) Rotation and translation effects in a pair of serial tissue slides, (b) significant stain variation because of potential discrepancy in thickness of individual tissue sections and stain artifacts in combination with rotation and translation effects in a pair of serial tissue slides, (c) brightness variations because of changes on radiation time with different capturing views in dental X-ray images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Corresponding feature detection by SURF. (a) For general computer vision applications, SURF is able to identify corresponding features, but (b) for biological tissue images where local features can be confusing, SURF performs poor on corresponding landmark detection</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Figure 3 illustrates the evaluation results of two pairs of tissue images. Quantitative Results with Statistical Analysis. In the Appendix,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Quantitative evaluation of two pairs of tissue images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.6.</head><figDesc>Fig. 6. Alignment results of X-ray images. r represents the level of registration accuracy based on the percentage of pixels with similar intensity levels between the target image and the registered source image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. The box plot of quantitative evaluation results of X-ray image registration. The presented methods works constantly well overall and significantly outperforms UnwarpJ and BunwarpJ based on Tukey's HSD and LSD tests (P50.001) (Table 4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.7.</head><figDesc>Fig. 7. Corresponding feature matching by SURF, SIFT and the presented method. SURF produces poor matching; SIFT generates some incorrect matches; the proposed method finds accurate matched key points for fast and higher-level coarse registration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.9.</head><figDesc>Fig. 9. The flowchart of the presented approach</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.8.</head><figDesc>Fig. 8. Image registration by the proposed method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1.</figDesc><table>Registration accuracies (%) of biological tissue image with 
ANOVA analysis 

Method 
N 
Score 
Mean 

SD 
Standard 
error 

UnwarpJ (Sorzano et al., 2005) 
90 
53.78 
45.24 
4.77 
BUnwarpJ (Arganda-Carreras 
et al., 2006) 

90 
49.56 
45.98 
4.85 

SURF (Bay et al., 2008) 
90 
13.78 
22.76 
2.4 
TrakEM2 (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. Multiple comparison for tissue image evaluation: Tukey's HSD and LSD</figDesc><table>Tukey HSD 
(I)Method 
(J)Method 
Mean 
difference 
(I–J) 

Standard 
error 

Sig. 

Proposed Method 
UnwarpJ 
34.67 a 
5.87 
50.001 
BUnwarpJ 
38.89 a 
5.87 
50.001 
SURF 
74.67 a 
5.87 
50.001 
TrakEM2 
23.78 a 
5.87 
0.001 
Mutual 
information 

42.88 a 
5.87 
50.001 

LSD 
(I)Method 
(J)Method 
Mean 
difference 
(I–J) 

Standard 
error 

Sig. 

Proposed Method UnwarpJ 
34.67 a 
5.87 
50:001 
BUnwarpJ 
38.89 a 
5.87 
50:001 
SURF 
74.67 a 
5.87 
50:001 
TrakEM2 
23.78 a 
5.87 
50:001 
Mutual 
information 

42.89 a 
5.87 
50:001 

a 

The proposed method is significantly better than the benchmark techniques using 
both Tukey's HSD and LSD tests (P 0.001). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 4.</figDesc><table>Multiple comparison for dental X-ray image evaluation: 
Tukey's HSD and LSD 

Tukey HSD 
(I)Method 
(J)Method 
Mean 
difference 
(I–J) 

Standard 
error 

Sig. 

Proposed Method 
UnwarpJ 
33.87 a 
5.37 
50.001 
BUnwarpJ 
33.89 a 
5.34 
50.001 
TrakEM2 
1.16 a 
5.34 
0.996 

LSD 
(I)Method 
(J)Method 
Mean 
difference 
(I–J) 

Standard 
error 

Sig. 

Proposed Method 
UnwarpJ 
33.87 a 
5.37 
50.001 
BUnwarpJ 
33.89 a 
5.34 
50.001 
TrakEM2 
1.16 a 
5.34 
0.828 

a 

The proposed method is significantly better than UnwarpJ and BunwarpJ using 
both Tukey's HSD and LSD tests (P50.001) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 3.</figDesc><table>Registration accuracy (%) of dental X-ray image registration 
with ANOVA analysis 

Method 
N 
Score 
Mean 

SD 
Standard 
error 

UnwarpJ (Sorzano et al., 2005) 
45 
55.06 
35.78 
5.39 
BUnwarpJ (Arganda-Carreras 
et al., 2006) 

45 
55.04 
35.21 
5.25 

TrakEM2 (Cardona et al., 2010; 
Saalfeld et al., 2010; Cardona 
et al., 2012; Saalfeld et al., 2012) 

45 
87.77 
5.54 
0.83 

Proposed method 
45 
88.93 
5.41 
0.81 

ANOVA 
df Mean square F 
Sig. 

Between groups 
3 16547.832 
25.807 50:001 
Within groups 
175 
641.222 
Total 
178 

Note: The proposed method outperforms the benchmark methods on average. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>and Amodei and Benbourhim (1991) proposed the two regularizing terms (E div , E rot ) that fully exploit the vectorial nature of the data.</figDesc><table>1 and I 2 ðdðxÞÞ, 
E div , E rot are the regularization energy based on the divergence and curl of 
the deformation, E cons expresses the geometrical consistency between the 
elastic deformation in both direction (I 1 ! I 2 ,I 2 ! I 1 ) and w k are the 
weights for sub-energy terms). 

E img ¼ 
1 
# 

X 

x2 

ðI 1 ðxÞ À I 2 ðdðxÞÞÞ 2 
ð17Þ 

where ¼ fx 2 1 \ Z 2 : dðxÞ 2 2 \ Z 2 g defines a mask common to 
the source and target images, and # is the size of the mask in pixels. 
As suggested by Sorzano et al. (2005), to use E img function, I 1 and I 2 need 
to be brought to a common intensity value framework using some 

normalization process, and in our experiments, the data normalization 
technique presented in the previous section indeed assists the registration 
method to produce better alignment outputs. 
The smoothness of the deformation field is a useful regularization 
term, </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">C.-W.Wang and H.-C.Chen at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Moreover, the box plot of the quantitative evaluation results is provided in Figure 4, showing that the proposed method works constantly well overall, and the four area-based methods (UnwarpJ, BunwarpJ, TrakEM2 and mutual information) perform better than the feature-based method (SURF) for tissue image registration. Furthermore, the modern system TrakEM2 and the B-spline model seem to perform better than the other two benchmark approaches, and thus for the following dental X-ray image registration experiments, the TrakEM2 and the B-spline models are selected for comparison. 2.3 Experimental results on dental X-ray images Evaluation Method. Unlike tissue images, local image features of dental X-ray scans appear better correlated to each other; therefore, a general registration performance measurement method, i.e. the percentage of pixels with similar intensity levels, is adopted to measure the registration accuracy, and an automatic evaluation tool is built to conduct quantitative evaluation automatically. The registration accuracy, r, is formulated as follows. r ¼ #fx : jjI 2 ðxÞ À UðI 1 ðxÞÞ5tg # ð1Þ where I 1 , I 2 , UðI 1 Þ represent the source, target and transformed source images; ¼ fx 2 1 \ Z 2 : dðxÞ 2 2 \ Z 2 g defines a mask common to the source and target images, and # is the size of the mask in pixels; t ¼ 50 in our experiments. Quantitative Results with Statistical Analysis. In the Appendix, Table 3 presents the quantitative evaluation outcomes of dental X-ray image registration with ANOVA analysis. Furthermore, using SPSS software (SPSS Inc, 2008), the quantitative registration accuracy scores were analyzed with Tukey&apos;s HSD and LSD (Table 4). Moreover, the box plot of the quantitative evaluation results is provided in Figure 5. The experimental results show that the proposed method performs well on registration of dental X-ray images, obtaining 88.93% averaged registration accuracy rate, and significantly better than UnwarpJ and BunwarpJ, which obtain 560% registration accuracy rates on average, based on Tukey&apos;s HSD and LSD tests (P50.001). Figure 6 shows registration results of some dental X-ray images. 3 METHODS In (Zitova and Flusser, 2003), the authors pointed out that feature-based methods are recommended if the images contain enough distinctive and easily detectable objects, which is usually the case of applications in remote sensing and computer vision, and area-based methods are usually</note>

			<note place="foot">Improved image alignment method at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This study has been supported by the National Science Council of Taiwan, and the authors thank Prof. Ann Chen and Dr ShukMan Ka from Department of Pathology, Tri-Service General Hospital, Taipei City, Taiwan, for providing the serial histopathological tissue slides.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Facilitating tumor functional assessment by spatially relating 3D tumor histology and in vivo MRI: image registration approach</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Alic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">22835</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A vector spline approximation</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Amodei</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Benbourhim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Approx. Theory</title>
		<imprint>
			<biblScope unit="page" from="67" to="51" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Consistent and Elastic Registration of Histological Sections using Vector-Spline Regularization</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Arganda-Carreras</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Lecture Notes in Computer Science Computer Vision Approaches to Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">4241</biblScope>
			<biblScope unit="page" from="85" to="95" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">SCoBeP: dense image registration using sparse coding and belief propagation</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Barzigar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vis. Commun. Image Represent</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="137" to="147" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Speeded up robust features (SURF)</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Bay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="346" to="359" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Color separation in forensic image processing</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Berger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Forensic Sci</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="100" to="102" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic registration of airborne and spaceborne images by topology map matching with SURF processor algorithm</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Brook</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Ben-Dor</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sens</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="65" to="82" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">An integrated micro-and macroarchitectural analysis of the drosophila brain by computer-assisted serial section electron microscopy</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cardona</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1000502</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">TrakEM2 software for neural circuit reconstruction</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cardona</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">38011</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">The endogenous immune response modulates the course of IgA-immune complex-mediated nephropathy</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">K</forename>
				<surname>Chao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kidney Int</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="283" to="297" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">The creation of a brain atlas for image guided neurosurgery using serial histological data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chakravarty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="359" to="376" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">The commonest glomerulonephritis in the world: IgA nephropathy</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>&apos;amico</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Q. J. Med</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="709" to="727" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Three-dimensional reconstruction of stained histological slices and 3D non-linear registration with in-vivo MRI for whole baboon brain</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dauguet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kidney Int</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page" from="191" to="204" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">SURF-Face: face recognition under viewpoint consistency constraints</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Dreuw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference</title>
		<meeting>the British Machine Vision Conference<address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="7" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Fischler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Bolles</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Medical image registration</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Hill</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">46</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lowe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Multimodality image registration by maximization of mutual information</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Maes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="187" to="198" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Mathworks</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Imregister</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013-03-15" />
		</imprint>
	</monogr>
	<note>date. last accessed</note>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Medical image registration and fusion techniques: a review Advanced Signal Processing Handbook</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">K</forename>
				<surname>Matsopoulos</surname>
			</persName>
		</author>
		<editor>Stergiopoulos,S.</editor>
		<imprint>
			<date type="published" when="2001" />
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Medical image registration: a review</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">P</forename>
				<surname>Oliveira</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Tavares</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods Biomech. Biomed. Engin., [Epub ahead of print</title>
		<imprint>
			<date type="published" when="2012-03-22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Mutual-information-based registration of medical images: a survey</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">P</forename>
				<surname>Pluim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="16" to="25" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Geometrical regularization of displacement fields for histological image registration</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Pitiot</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Guimond</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="16" to="25" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Quantification of histochemical staining by color deconvolution</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Ruifrok</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Johnston</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Quant. Cytol. Histol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="291" to="299" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">As-rigid-as-possible mosaicking and serial section registration of large ssTEM datasets</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Saalfeld</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="57" to="63" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Elastic volume reconstruction from series of ultra-thin microscopy sections</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Saalfeld</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="717" to="720" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">NIH image to ImageJ: 25 years of image analysis</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">A</forename>
				<surname>Schneider</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="671" to="675" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Construction of panoramic mosaics with global and local alignment</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shum</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Szeliski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="101" to="130" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Elastic registration of biological images using vector-spline regularization</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sorzano</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="652" to="663" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Spss</forename>
				<surname>Inc</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
	<note>SPSS. for Windows, Rel.17.0.1SPSS Inc</note>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">3D reconstruction from 2D images with hierarchical continuous simplices</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Tan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="905" to="914" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-spectral satellite image registration using scale-restricted SURF</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Teke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Temizel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 20th International Conference on Pattern Recognition</title>
		<meeting>the 2010 20th International Conference on Pattern Recognition<address><addrLine>Istanbul ; Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2310" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title level="m" type="main">An open implementation of the SIFT detector and descriptor</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Vedaldi</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>UCLA CSD</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<monogr>
		<title level="m" type="main">(in press) Automated morphological classification of lung cancer subtypes using H&amp;E tissue images</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Yu</surname>
			</persName>
		</author>
		<imprint>
			<publisher>Mach. Vis. Appl</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Fast automatic quantitative cell replication with fluorescent live cell imaging</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">21</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Sparse methods for biomedical data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ye</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="4" to="15" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Image registration methods: a survey</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zitova</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Flusser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="977" to="1000" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>