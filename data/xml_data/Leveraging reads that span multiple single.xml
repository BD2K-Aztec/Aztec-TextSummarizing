
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging reads that span multiple single nucleotide polymorphisms for haplotype inference from sequencing data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">18 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Wen-Yun</forename>
								<surname>Yang</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Inter-Departmental Program in Bioinformatics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Farhad</forename>
								<surname>Hormozdiari</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Zhanyong</forename>
								<surname>Wang</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Dan</forename>
								<surname>He</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="institution">IBM T.J. Watson Research</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Bogdan</forename>
								<surname>Pasaniuc</surname>
							</persName>
							<email>bpasaniuc@mednet.ucla.edu or eeskin@cs.ucla.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Inter-Departmental Program in Bioinformatics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Pathology and Laboratory Medicine</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Jonsson Comprehensive Cancer Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Eleazar</forename>
								<surname>Eskin</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Inter-Departmental Program in Bioinformatics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Human Genetics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Leveraging reads that span multiple single nucleotide polymorphisms for haplotype inference from sequencing data</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="page" from="2245" to="2252"/>
							<date type="published" when="2013">18 2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt386</idno>
					<note type="submission">Sequence analysis Advance Access publication July 3, 2013 Received on April 17, 2012; revised on June 19, 2013; accepted on June 28, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Martin Bishop Availability: Publicly available software is available at http://genetics. cs.ucla.edu/harsh Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Haplotypes, defined as the sequence of alleles on one chromosome, are crucial for many genetic analyses. As experimental determination of haplotypes is extremely expensive, haplotypes are traditionally inferred using computational approaches from genotype data, i.e. the mixture of the genetic information from both haplotypes. Best performing approaches for haplotype inference rely on Hidden Markov Models, with the underlying assumption that the haplotypes of a given individual can be represented as a mosaic of segments from other haplotypes in the same population. Such algorithms use this model to predict the most likely haplotypes that explain the observed genotype data conditional on reference panel of haplotypes. With rapid advances in short read sequencing technologies, sequencing is quickly establishing as a powerful approach for collecting genetic variation information. As opposed to traditional genotyping-array technologies that independently call genotypes at polymorphic sites, short read sequencing often collects haplotypic information; a read spanning more than one polymorphic locus (multi-single nucleotide poly-morphic read) contains information on the haplotype from which the read originates. However, this information is generally ignored in existing approaches for haplotype phasing and genotype-calling from short read data. Results: In this article, we propose a novel framework for haplotype inference from short read sequencing that leverages multi-single nucleotide polymorphic reads together with a reference panel of haplo-types. The basis of our approach is a new probabilistic model that finds the most likely haplotype segments from the reference panel to explain the short read sequencing data for a given individual. We devised an efficient sampling method within a probabilistic model to achieve superior performance than existing methods. Using simulated sequencing reads from real individual genotypes in the HapMap data and the 1000 Genomes projects, we show that our method is highly accurate and computationally efficient. Our haplotype predictions improve accuracy over the basic haplotype copying model by $20% with comparable computational time, and over another recently proposed approach Hap-SeqX by $10% with significantly reduced computational time and memory usage.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Humans are diploid organisms with two copies of each chromosome, one inherited from the father and the other from the mother. The two copies are similar to each other and only differ at a small fraction ($ 0:1%) of sites. Most of the variation is contained at single nucleotide polymorphic (SNP) sites. The sequence of alleles on each chromosome is referred to as the haplotype. Haplotype information is centrally important for a wide variety of applications, including association studies and ancestry inference (<ref type="bibr" target="#b7">Fearnhead and Donnelly, 2001;</ref><ref type="bibr" target="#b14">Hugot et al., 2001;</ref><ref type="bibr" target="#b18">Lazzeroni, 2001;</ref><ref type="bibr" target="#b23">Myers and Griffiths, 2003;</ref><ref type="bibr" target="#b25">Rioux et al., 2001;</ref><ref type="bibr" target="#b26">Sabeti et al., 2002</ref>). Unfortunately, standard methods for probing genetic variation are able to collect only genotype information but not haplotypes. A large number of computational methods, referred to as haplotype phasing approaches, have been proposed to infer haplotypes from genotypes. The most successful methods use a set of reference haplotypes to build a probabilistic model of the haplotypes in the population (<ref type="bibr" target="#b13">Howie et al., 2009;</ref><ref type="bibr" target="#b12">Howie et al., 2011;</ref><ref type="bibr" target="#b16">Kang et al., 2010;</ref><ref type="bibr" target="#b20">Li et al., 2010;</ref><ref type="bibr" target="#b22">Long et al., 2009</ref>). Using a population genetics model for the haplotype distribution, these models predict the most likely haplotype data that can explain the observed genotypes. Rapid advances in high-throughput sequencing (HTS) technologies provide new opportunities for haplotype phasing methods. HTS yields short segments of the DNA (reads) where each read originates from one of the pair of chromosomes. Therefore, all the alleles in this read are from the same haplotype. Although reads that cover multiple SNPs (multi-SNP reads) could be used to improve haplotype inference, existing methods generally ignore this information, partially owing to computational difficulty associated with modeling such reads. Several methods have been proposed to predict haplotypes directly from the reads. These methods, referred to as haplotype assembly methods, use overlapping reads to construct the haplotype (<ref type="bibr" target="#b0">Aguiar and Istrail, 2012;</ref><ref type="bibr" target="#b1">Bansal and Bafna, 2008;</ref><ref type="bibr" target="#b1">Bansal et al., 2008;</ref><ref type="bibr" target="#b4">Duitama et al., 2010</ref><ref type="bibr" target="#b5">Duitama et al., , 2012</ref><ref type="bibr" target="#b10">He et al., 2010;</ref><ref type="bibr" target="#b27">Xie et al., 2012</ref>). The most commonly used objective function for haplotype *To whom correspondence should be addressed. assembly is the minimum error correction (MEC). The MEC objective function aims at finding the minimum number of edits such that the reads can be partitioned into two disjoint sets, and each set of reads originates from one of the haplotypes. However, as these methods do not use the information in the reference haplotype panel, they significantly underperform standard phasing methods that ignore read information but use reference panel (<ref type="bibr" target="#b10">He et al., 2010</ref>). Recently, one of these methods has been extended to use the reference (<ref type="bibr" target="#b9">He and Eskin, 2013;</ref><ref type="bibr" target="#b11">He et al., 2012</ref>). Unfortunately, this method has prohibitive memory and time requirements, thus making it unfeasible for moderate to large datasets. Here, we propose a novel approach called Haplotyping with Reference and Sequencing technology (HARSH) for haplotype phasing. We use a probabilistic model to incorporate the multiSNP read information together with a reference panel of haplotypes. We use an efficient Gibbs sampling method to find sample from the posterior distribution. This algorithm has the advantages of being computationally efficient, scalable in memory usage and accurate in genotyping and phasing prediction. We evaluate our method on simulations from real haplotypes from the HapMap project. At 1Â coverage, HARSH gives $10% improvement in terms of total error rate compared with standard phasing approaches that do not use the multi-SNP read information, thus showing the benefits of modeling multi-SNP reads. We also evaluate HARSH and the basic model for varying coverage and read length, showing the benefits of our approach in higher coverage and longer read length. Additionally, we test our method on simulations starting from real sequencing data of 1000 Genomes project, where the density of SNPs is much higher than that in HapMap data. Through extensive simulations we show that the gain in performance of our approach over existing models extends to realistic read lengths (e.g. 100–400 bp), making our approach readily applicable to existing sequencing datasets. With recent works showing that short read sequencing can dramatically increase association power in genome-wide association study over genotyping arrays (<ref type="bibr" target="#b24">Pasaniuc et al., 2012</ref>), we expect our approaches to further increase power in genome-wide association study by increasing accuracy in genotype calling and phasing from short read data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>The best performing approaches for haplotype inference rely on Hidden Markov Models (HMMs) for describing the distribution of haplotypes in the population. These approaches generally ignore multi-SNP information in the reads, thus implementing the model as a linear chain graph. The model structure becomes complicated when we are considering multiSNP information, as it is not trivial to perform standard operations (e.g. Viterbi decoding) to a non-linear chain graph. Previous methods [e.g. Hap-SeqX (<ref type="bibr" target="#b9">He and Eskin, 2013</ref>)] have attempted to extend the Viterbi algorithm to the complex graph induced by multi-SNP reads and reference haplotypes, but the approach is expensive in both time and memory usage. As opposed to previous approaches, in this work, we use a Gibbs sampler–based method for fast inference. The main advantage of this approach is that the computations are efficient and it can achieve the optimal or close to optimal solution in a feasible amount of time. However, all other current methods are either not optimal or not practical in terms of computational time or memory usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gibbs sampler preliminaries</head><p>A Gibbs sampler serves as the basis for our method. We first introduce the general idea of Gibbs sampling before we use it to solve the haplotype problem. Consider the following distribution typically used to perform optimization in graphical models:</p><formula>PðXÞ ¼ 1 Z exp X i¼1 X j¼1 ij ðx i , x j Þ !</formula><p>where X ¼ ðx 1 , x 2 , Á sx d Þ is a d-dimensional vector and Z is a normalization factor. The function specifies the edge potential for two variables with an edge between them. We would like to collect samples of X based on this distribution P(X). Gibbs sampler is a special case of Monte Carlo Markov Chain method (<ref type="bibr" target="#b8">Geman and Geman, 1984</ref>), which is guaranteed to converge to the equilibrium distribution after sufficient burn-in rounds. In each round, it randomly samples one variable x i based on the conditional probability Pðx i jx ½Ài Þ when all other variables x ½Ài ¼ ðx 1 ,. .. , x iÀ1 , x iþ1 ,. .. , x d Þ are fixed. Formally, this conditional probability can be written as follows:</p><formula>Pðx i ¼ tjx ½Ài Þ ¼ Pðx i ¼ t, x ½Ài Þ P t 0 Pðx i ¼ t 0 , x ½Ài Þ : ð1Þ</formula><p>A more complete treatment of Monte Carlo Markov Chain is available in (<ref type="bibr" target="#b21">Liu, 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Haplotype assembly with sequencing data</head><p>Sequencing technologies provide us with a set of reads, each of which is a short fragment from one of the chromosomes. Haplotype assembly aims to assemble the entire haplotype based on only read information. An illustrative example is given in<ref type="figure">Figure 1</ref>. We can formalize this problem as follows. Suppose that we only consider L biallelic SNPs and M reads. Each read is represented by X j ¼ fÀ1, 1, 0g L , where 0 stands for unobserved SNP in jth read, À1 and 1 stand for observed minor and major alleles, respectively.<ref type="figure">Fig. 1</ref>. An illustration of haplotype inference problems. The two chromosomes for an individual are unknown to us at first. Sequencing technology produces a set of reads, each of which originates from one of the two chromosomes. We also have a set of reference haplotypes, which are from the same population as the donor. Haplotype assembly aims to assemble the two donor haplotypes by only using the read information. Haplotype phasing problem aims to phase the two haplotypes by mosaic copies from the reference haplotypes. However, our approach HARSH takes into account both read information and reference panel for more accurate haplotype inference Because the homozygous site does not affect the haplotype phasing, we only consider heterozygous sites. Therefore, the objective is to find a sequence of haplotype and its complementary fh, hg where h ¼ À h 2 fÀ1, 1g L , to minimize the total number of flipped loci within reads, such that every read can be perfectly assigned to one of the haplotypes. Another necessary variable for the model is the read origin indicator r j 2 fÀ1, 1g. If r j ¼ 1, the jth read is assumed to have been generated from haplotype h, and if r j ¼ À1, the jth read is from the complementary haplotype h. We assume the read generation process is as follows. First, we randomly pick one of the haplotypes (h, h) with equal probability, and then sample the read starting position from one of the L possible positions in the genome. If we consider the read generation processing is error free, then we have x ij ¼ h i r j. However, if the read generation process is error-prone and " indicates the rate of sequencing error then with probability 1 À ", we have x ij ¼ Àh i r j , and with probability ", we have x ij ¼ Àh i r j. An illustrative example is given in<ref type="figure" target="#fig_0">Figure 2</ref>. We can formalize the connection between the haplotypes and read origin variables into the following probabilistic distribution. For each possible values of the haplotypes and read origin variables, we can calculate its probability as follows:</p><p>PðR, H; XÞ</p><formula>¼ 1 Z exp X ij:xij¼1 ij ðh i , r j Þ þ X ij:xij¼À1 ij ðh i , r j Þ 0 @ 1 A 0 @ 1 A ð2Þ where ij ðh i , r j Þ ¼ lnð1 À "Þ h i ¼ r j ln " h i 6 ¼ r j ij ðh i , r j Þ ¼ ln " h i ¼ r j lnð1 À "Þ h i 6 ¼ r j :</formula><p>and the variables R ¼ ðr j Þ M j¼1 , H ¼ ðh i Þ L i¼1 and X ¼ ðx ij Þ ij are vectors and matrix composed of scalar variables r, h and x. The variable Z is a normalization constant to ensure P R, H PðR, H; XÞ ¼ 1. The functions and specify edge potentials that favor h and r to be of equal values and opposite values, respectively. The model parameter controls the 'heat' of the probabilistic model. Generally speaking, the probability distribution is smoother when is small and sharper when is large. LEMMA 1. The maximum a posteriori (MAP) assignment of (2) corresponds to the MEC haplotype for any 50:5. PROOF. We can prove by constructing the MEC haplotype from MAP assignment. Let H Ã and R Ã denote the MAP assignment of our probabilistic model, and the corresponding probability calculated from</p><p>(2) will be</p><formula>PðH Ã , R Ã ; XÞ ¼ 1 Z expððn lnð1 À "Þ þ m ln "ÞÞ</formula><p>where n is the number of edges getting potential lnð1 À Þ and m is the number of edges getting potential ln based on the configuration H Ã and R Ã. As lnð1 À "Þ4 ln " for 50:5 and the number of edges is fixed, this MAP assignment H Ã and R Ã is actually minimizing the number of edges getting potential ln. We can use this haplotype H Ã and flip every read bit corresponding to the edge getting potential ln ". The resulting MEC score for H Ã will be m, which is minimized. Suppose that there exists another haplotype H 0 with MEC score m 0 5m. It suggests that we can flip only m 0 read bit then all the reads will be perfectly assigned to one of the haplotypes. We keep those assignments into the variable R 0. Thus, we should have</p><formula>PðH 0 , R 0 ; XÞ ¼ 1 Z expðððn þ m À m 0 Þ lnð1 À "Þ þ m 0 ln "ÞÞ:</formula><p>By definition, m 0 5m; thus, PðH 0 , R 0 ; XÞ4PðH Ã , R Ã ; XÞ, which contradicts the fact that H Ã and R Ã is the MAP assignment maximizing the configuration probability. By this contradiction, we can conclude that there does not exist H 0 and R 0 with MEC score m 0 5m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Haplotype phasing with sequencing data and reference</head><p>PðH, R, S; XÞ</p><formula>¼ 1 Z exp Á X ij:xij¼1 ðh 1 i , À r j Þ þ X ij:xij¼À1 ðh 1 i , À r j Þ 0 @ 2 4 þ X L i¼1 ðh 1 i , s 1 i Þ þ X LÀ1 i¼1 ðs 1 i , s 1 iþ1 , iÞ þ X ij:xij¼1 ðh 2 i , r j Þ þ X ij:xij¼À1 ðh 2 i , r j Þ þ X L i¼1 ðh 2 i , s 2 i Þ þ X LÀ1 i¼1 ðs 2 i , s 2 iþ1 , iÞ !# ð3Þ</formula><p>where we have four edge potential functions. The functions and are defined similarly as in (2) except that there would be no penalty if the read is assigned by r to the other haplotype.</p><formula>ðh i , r j Þ ¼ lnð1 À "Þ r j ¼ 1, h i ¼ 1 ln " r j ¼ 1, h i ¼ À1 0 r j ¼ À1 , 8 &gt; &lt; &gt; : ðh i , r j Þ ¼ ln " r j ¼ 1, h i ¼ 1 lnð1 À "Þ r j ¼ 1, h i ¼ À1 0 r j ¼ À1 : 8 &gt; &lt; &gt; :</formula><p>The edge potential function specifies the 'haplotype copying', which is motivated that the predicted haplotype is a mosaic of referencef1, À 1g stands for the haplotype. The variable r 2 f1, À 1g stands for whether the read is from haplotype h or the complementary h haplotypes with a small number of differences. In this case, the predicted haplotypes are similar to reference haplotype s 1 and s 2 at position i.</p><formula>ðh 1 i , s 1 i Þ ¼ lnð1 À !Þ h 1 i ¼ G s 1 i , i ln ! h 1 i 6 ¼ G s 1 i , i (</formula><p>where G ij stands for the jth allele in ith reference haplotype. Thus, G s 1 i , i stands for the ith allele in s 1 i th reference haplotype. Moreover, we use the following function to model the transition probability in haplotype copying model (<ref type="bibr" target="#b19">Li and Stephens, 2003</ref>).</p><formula>ðs i , s iþ1 , iÞ ¼ expðÀ i N Þ þ ð1 À expðÀ i N ÞÞ=N s i ¼ s iþ1 ð1 À expðÀ i N ÞÞ=N s i 6 ¼ s iþ1</formula><p>where i ¼ 4N e r i and r i is the per generation genetic distance between site i and site i þ 1, and N e is a constant. This probabilistic model provides us a disciplined way to infer the most probable haplotype given a set of reads and a set of reference haplotypes. It extends the haplotype copying model (<ref type="bibr" target="#b19">Li and Stephens, 2003</ref>) from genotype input to sequencing data input. It also extends the haplotype assembly problem in previous section to a more general case where the reference panel can be used to improve the phasing. We are then able to design efficient sampling approach to find the most possible configurations of H, R and S that maximize the probability given in Equation (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Efficient sampling</head><p>Haplotype assembly without reference. The bipartite structure in<ref type="figure" target="#fig_0">Figure 2</ref>suggests an efficient procedure for sampling. For fixed one layer of the bipartite graph, the variables in the other layer will be independent on each other. Thus, the conditional probability in Equation (1) of Gibbs sampler can be significantly reduced. Formally, following the standard procedure of Gibbs sampling, we can sample haplotype from the conditional probability for fixed read origins. The sampling ratio i ¼ Pðh i ¼ À1jRÞ can be calculated as follows:</p><formula>i ¼ exp P j:Xij¼1 ðÀ1, r j Þ þ P j:Xij¼À1 ðÀ1, r j Þ ! exp P j:Xij¼1 ðÀ1, r j Þ þ P j:Xij¼À1 ðÀ1, r j Þ ! þ exp P j:Xij¼1 ð1, r j Þ þ P j:Xij¼À1 ð1, r j Þ ! 0 B B B B @ 1 C C C C A : ð4Þ</formula><p>Similarly, we can also do a similar Gibbs sampling step for read origin for fixed haplotype. The sampling ratio j ¼ Pðr j ¼ À1jHÞ can be calculated as follows:</p><formula>j ¼ exp P i:Xij¼1 ðh i , À 1Þ þ P i:Xij¼À1 ðh i , À 1Þ ! exp P i:Xij¼1 ðh i , À 1Þ þ P i:Xij¼À1 ðh i , À 1Þ ! þ exp P i:Xij¼1 ðh i , 1Þ þ P i:Xij¼À1 ðh i , 1Þ ! 0 B B B B @ 1 C C C C A : ð5Þ</formula><p>The complete sampling algorithm for haplotype assembly is shown in Algorithm 1. As default, we use 10 000 rounds for sampling. Haplotype phasing with reference. The sampling for haplotype phasing with both sequencing data and reference from the graph in<ref type="figure">Figure 3</ref>is more challenging. However, we can still take advantages of the special structure of the graph and perform efficient sampling procedure. Following the idea of Gibbs sampler, we will alternatively (i) sample read origin R for fixed haplotype H and reference assignment S; (ii) sample S for fixed R and H; (iii) sample H for fixed R and S. The step (i) is similar with that in haplotype assembly. Formally, the sampling ratio Pðr j ¼ À1jH, SÞ for read origin can be calculated by</p><formula>j ¼ exp P i:Xij¼1 ðh 1 i , 1Þ þ P i:Xij¼À1 ðh 1 i , 1Þ ! exp P i:Xij¼1 ðh 1 i , 1Þ þ P i:Xij¼À1 ðh 1 i , 1Þ ! þ exp P i:Xij¼1 ðh 2 i , 1Þ þ P i:Xij¼À1 ðh 2 i , 1Þ ! 0 B B B B @ 1 C C C C A : ð6Þ</formula><p>Algorithm 1 Sampling Algorithm for Haplotype Assembly 1: Randomly initialize haplotype H. 2: For fixed haplotype H, sample read origin R. For probability j , we get r j ¼ À1, and for probability 1 À j , we get r j ¼ 1, where the ratio can be calculated as in (5).</p><p>3: For fixed read origin R, sample haplotype H. For probability i , we get h i ¼ À1, and for probability 1 À i , we get h i ¼ 1, where the ratio can be calculated as in (4). 4: Repeat steps 2 and 3 for sufficient rounds until equilibrium. 5: Collect samples by repeating steps 2 and 3, and output the one with highest probability. The step (iii), sampling of haplotype H for fixed read origin R and reference assignment S is a straightforward extension from Equation (4). The modification is based on the extra edge between reference penal variables S and haplotype H. Formally, the sampling ratio Pðh 1 i ¼ À1jR, SÞ for the first haplotype can be calculated by</p><formula>1 i ¼ ðÀ1Þ ðÀ1Þ þ ð1Þ ð7Þ where ðhÞ ¼ exp X j:Xij¼1 ðh, À r j Þ þ X j:Xij¼À1 ðh, À r j Þ þ ðh, s 1 i Þ 0 @ 1 A :</formula><p>The sampling ratio Pðh 2 i ¼ À1jR, SÞ is similar with Pðh 1 i ¼ À1jR, SÞ. Similarly, we can obtain the sampling ratio for the second haplotype as follows: 2 i ¼ ðÀ1Þ ðÀ1Þ þ ð1Þ ð8Þ<ref type="figure">Fig. 3</ref>. A graphical model for haplotype phasing with reference. The variables h 1 and h 2 stand for the first and second haplotypes. The variables r i ¼ fÀ1, 1g specify whether the read comes from the first haplotype or second haplotype. The variable s 1 and s 2 specify which haplotype in the reference is generating the haplotype h 1 and h 2 , respectively where</p><formula>ðhÞ ¼ exp X j:Xij¼1 ðh, r j Þ þ X j:Xij¼À1 ðh, r j Þ þ ðh, s 2 i Þ 0 @ 1 A :</formula><p>The step (ii), sampling for the haplotype reference panel variables S for fixed read origin R and haplotype H is challenging. The difficulty comes from the dependency between the variables s i and s iþ1 , and the large number of possible values for each s i. Note that unlike the binary variables h and r, the variable s i 2 f1, 2,. .. , Ng, where N is the number of reference haplotypes. Thus, straightforward Gibbs sampler would be inefficient in this case. To tackle this computational challenge, we resort to the following Markov chain sampling procedure (<ref type="bibr" target="#b21">Liu, 2008</ref>). The joint distribution over all variables in S can be written as follows:</p><formula>PðSjHÞ ¼ 1 Z exp 0 ðs 1 Þ þ X LÀ1 i¼1 i ðs i , s iþ1 Þ ! ð9Þ where 0 ðs 1 Þ ¼ ðh 1 , s 1 Þ i ðs i , s iþ1 Þ ¼ ðs i , s iþ1 , iÞ þ ðh iþ1 , s iþ1 Þ:</formula><p>Sampling directly from PðSjHÞ is still tedious. However, we can convert the PðSjHÞ to multiplication series of probability functions as follows:Thus, we can compute the normalization factor Z ¼ P sL2S V LÀ1 ðs L Þ efficiently using dynamic programming, and then we can compute the marginal probability Pðs L , HÞ ¼ ðV LÀ1 ðs L ÞÞ=Z. Moreover, we can backward compute Pðs i js iþ1 , HÞ similarly. Note that a naive implementation of this step would result in a complexity of quadratic in the number of reference haplotypes. We take advantage of the symmetry in the haplotype coping model to reuse computation to achieve runtime linear in the number of reference haplotypes. An outline of the sampling algorithm for haplotype phasing with sequencing data and a reference panel is given in Algorithm 2. As default, we use 10 000 rounds of sampling.</p><p>Algorithm 2 Sampling Algorithm for Haplotype Phasing 1: Randomly initialize haplotype H 2: For fixed haplotype H, sample read origin R using sampling ratio j in (6). 3: For fixed haplotype H sample haplotype reference S following Markov chain sampling procedure described after (9). 4: For fixed read origin R, and haplotype reference S, sample haplotype H using sampling ratio i in (7). 5: Repeat steps 2, 3 and 4 for sufficient rounds until equilibrium. 6: Collect samples by repeating steps 2, 3 and 4. Output samples with highest probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and experimental settings</head><p>WeWe evaluate our method using a leave-one-out procedure. In each round, we infer the haplotype for one individual using simulated sequencing data and the haplotypes of the other 59 individuals as reference panel. This procedure is repeated 60 times and all the evaluation metrics are averaged. The reads are simulated uniformly across chromosome 22 for a given coverage. The read length in each end of a pair-end read is fixed but the gap between the two ends follow a normal distribution with fixed mean and standard deviation. Errors are inserted in the read at a rate ". We evaluate our method HARSH using the standard metric for genotyping and phasing accuracy: genotyping error rate and switching error rate. The genotyping error rate is the proportion of wrongly predicted genotypes, and the switching error is the proportion of switches in the inferred haplotypes to recover the correct phase in an individual. The total error rate is the sum of genotyping error rate and switching error rate. We also use percentage improvement when comparing two methods. The percentage improvement is computed as the error rate difference between two methods normalized by the error rate of baseline method. For example, suppose that HARSH has error rate x and baseline method has error rate y, the improvement of HARSH over the baseline method would be ðy À xÞ=y. We fixed the parameters ¼ 1, ! ¼ 0:002 and ¼ 0:01 for all our experiments. From our experience, the performance of the proposed method is not sensitive to parameter tuning. Using from 1 to 10 and ! from 0.001 to 0.005 does not affect the performance significantly. The sequencing error ¼ 0:01 is standard sequencing error rate. All experiments are performed in a cluster machine where each node has 8–16 cores 3.0 GHz CPU and 1–16 GB memory. Jobs are submitted in a parallel manner but each job uses only one node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">HapMap simulations</head><p>We use HapMap dataset to evaluate our method HARSH. We compare our method with three other state-of-the-art methods: the HMM at the core of the IMPUTE method (<ref type="bibr" target="#b13">Howie et al., 2009</ref>), BEAGLE (<ref type="bibr" target="#b3">Browning and Browning, 2009</ref>) and HapSeqX (<ref type="bibr" target="#b9">He and Eskin, 2013</ref>). Because IMPUTE does not support haplotype phasing for uncovered SNPs, for a fair comparison, we re-implemented the basic HMM model of the IMPUTE v1.0, which uses the pre-defined genetic map information for transition probability. We will refer to our implementation of the HMM model in IMPUTE method as IMPUTE*. In our modified version, we use the read count for each SNP as input to IMPUTE* method. The likelihood of read count from genotype is used as the emission probability for the HMM model. Then the Viterbi algorithm is used to decode two paths from the reference panel, which are most likely to generate the read counts in each SNP. The two paths in reference panel also give the two predicted haplotypes. Because the latest implementation of IMPUTE (<ref type="bibr" target="#b13">Howie et al., 2009</ref>) is not able to phase, we also compared our approach with BEAGLE 3.3.2 (<ref type="bibr" target="#b3">Browning and Browning, 2009</ref>), a widely used approach for haplotype phasing and imputation. We first use the HapMap dataset to show that haplotype assembly without a reference panel will underperform haplotype phasing with a reference panel. The main reason is that there are not enough long reads covering all continuous heterozygous SNPs. Thus, haplotype assembly cannot do more than random guess between two continuous heterozygous SNPs if there is no read spanning them. We can compute a lower bound of the number of switches for haplotype assembly as K=2 where K is the number of those gaps, assuming the MEC score to be zero. For pair-end reads with fixed length 1000 bp mean and 100 bp standard deviation, we evaluate our method using six levels of sequencing coverages: 1Â, 2Â, 4Â, 6Â, 8Â and 10Â. As shown in<ref type="figure">Figure 4a</ref>, higher coverage does not help haplotype assembly to achieve similar performance than haplotype phasing methods. At fixed coverage 4Â, we simulated pair-end reads with 1000, 2000, 3000 and 4000 bp in each end. As shown in<ref type="figure">Figure 4b</ref>, we can observe that the lower bound of haplotype assembly achieves similar performance as haplotype phasing only under the unrealistic read length 4000 bp. Also, at 4Â coverage, we can observe that our method can improve $44% over BEAGLE and $37% over IMPUTE in terms of numbers of switches. For simulated pair-end reads with 1000 bp for each end at 1Â coverage, only 32% reads contain one SNP and $26% of the reads contain more than three SNPs. On average, every read contains around 2.8 SNPs. Following the procedure similar to that of He and Eskin (2013), we divide the chromosome into overlapping chunks containing 1200 SNPs each and run our method on each chunk independently. The final haplotypes are then constructed by stitching together the haplotypes from each chunk. Chromosome 22 is divided into 36 chunks. The total error rate for both IMPUTE* and HARSH are shown in<ref type="figure">Figure 5</ref>. We can observe from the figure that HARSH consistently performs better than IMPUTE* across all 36 chunks. The average improvement over IMPUTE* is 7.6%. We then concatenated those haplotype chunks by minimizing the mismatches in the overlap region between two adjacent chunks. After concatenation, the overall error rate for HARSH is 4.01% for chromosome 22, compared with 4.42% for IMPUTE*. The overall improvement is 9.3% over IMPUTE*. We compare HARSH with a previous method for combining multi-SNP reads with a reference panel, Hap-SeqX (<ref type="bibr" target="#b9">He and Eskin, 2013</ref>). Hap-SeqX is an approximation to the dynamic programming approach of the Hap-Seq method (<ref type="bibr" target="#b11">He et al., 2012</ref>), which optimizes a similar objective function to HARSH. Hap-SeqX only searches a fraction of the search space compared with Hap-Seq by only storing the top values at each state. However, Hap-SeqX is still an expensive method in both time and memory usage. In this experiment, we use the default parameters of Hap-SeqX, where t ¼ 0:01 specifies that the algorithm saves the top 1% of values for each state. On addition, Hap-Seq and Hap-SeqX, unlike HARSH, can only handle up to three SNPs in a read and split reads containing more SNPs into multiple reads. The performance comparisons are shown in<ref type="figure" target="#tab_1">Table 1</ref>. HARSH and IMPUTE* have similar running time. HARSH takes $10 min compared with IMPUTE* 5 min on chromosome 22. Both these methods compare favorably with Hap-SeqX, which takes 5 h for the same dataset. Cross validation of 60 individuals would be prohibitive for Hap-SeqX. Thus, we compare all these three methods using only the first individual in HapMap dataset. The results averaged more than 36 chunks. We can see that Hap-SeqX improves by $12.53% from the baseline method IMPUTE*, and HARSH significantly improves by 21.34% from IMPUTE*. We conducted significance test (paired-sample t-test) on the improvement of HARSH over Hap-SeqX and IMPUTE*. The test results show that HARSH significantly outperforms both Hap-SeqX and IMPUTE* with P51 Â 10 À3 and P51 Â 10 À7 , respectively. Overall, the comparison shows that HARSH is the most accurate and practical method among existing methods. To fully evaluate the performance of our method, we apply our method to cases with different coverages and read lengths. For pair-end reads with fixed length 1000 bp mean and 100 bp standard deviation, we evaluate our method using six levels of sequencing coverages: 1Â, 2Â, 4Â, 6Â, 8Â and 10Â. The result is shown in<ref type="figure" target="#fig_4">Figure 6a</ref>. As expected, the performance improvement of HARSH over BEAGLE and IMPUTE* becomes more significant when the coverage increases. The reason we expect this is that the higher the coverage, the larger number of reads that<ref type="figure" target="#tab_2">Table 2</ref>, we show the genotyping and switching error rate of HARSH and IMPUTE* method for different coverages. It can be observed that both genotyping error and switching error are significantly reduced by HARSH over BEAGLE and IMPUTE*. It is also worth mentioning that 4Â seems to be the best choice in terms of the compromise between the cost of coverage and achieved accuracy. The coverage 4Â gives 0.28% genotyping error and 0.62% switching error. However, the improvement of higher coverage than 4Â is limited. We also evaluate HARSH with different read lengths. At fixed coverage 4Â, we simulated pair-end reads with 1000, 2000, 3000 and 4000 bp in each end. The results are shown in<ref type="figure" target="#fig_4">Figure 6b</ref>. It is not immediately intuitive why the genotyping error rates for BEAGLE, IMPUTE* and HARSH increase when the read length increases. A possible reason is that longer reads for a fixed coverage result in fewer total reads and larger gaps without any coverage. In other words, longer reads result in less random read bits across the chromosome. An extreme example is that the gap will be half of the genome on average if the read length is equal to the genome size and coverage is 1Â. Sequentially, larger gap where no reads cover will potentially harm the imputation and haplotype phasing accuracy. However, we can still see that the performance gap between BEAGLE or IMPUTE* and HARSH is enlarged while the read length increases. This is attributed to the ability of HARSH to leverage the multi-SNP information in longer reads. In<ref type="figure" target="#tab_3">Table 3</ref>, we show the improvement of HARSH over BEAGLE and IMPUTE*. The improvement is basically from the reduced switching error, which is reduced from 0.62 to 0.48% by HARSH but not by IMPUTE*. The genotyping error for both methods increases at the same pace because of the larger gaps caused by longer reads. The error rates for BEAGLE, IMPUTE* and HARSH increase from 0.59 to 0.79%, from 0.56 to 0.85% and from 0.28 to 0.48%, respectively, when the read length increases from 1000 to 4000 bp. But HARSH consistently performs better than BEAGLE and IMPUTE even while the genotyping error rate is increasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">1000 Genomes simulations</head><p>The 1000 Genomes project is an ongoing project that uses HTS technology to collect the genetic variant data across many individuals with the goal of characterizing rare variants, which are not present in HapMap. This provides us the opportunity to evaluate our method using simulations that will realistically capture the distributions of rare variants and more accurately reflect a tubal performance. We simulate realistic paired end reads, which have 100 bp for each end, and a gap size following a normal distribution with 100 bp mean and standard deviation of 10 bp. Only 22% reads contain only one SNP and $55% reads contain more than three SNPs. On average, every read covers around 3.1 SNPs. Following the same settings as what we did for HapMap data, we test HARSH for different coverages and read lengths. The results for coverage 1Â, 2Â, 4Â, 8Â, 16Â and 32Â are shown in<ref type="figure" target="#fig_7">Figure 7a</ref>. We observe that the error rate does not further drop after coverage 8Â. At coverage 8Â, the improvement of HARSH over IMPUTE* is 29% from 0.021 to 0.015 in terms of error rate. Thus, for fixed coverage 8Â, we simulate pair-end reads with 100, 200, 300 and 400 bp in each end. The results are shown in<ref type="figure" target="#fig_7">Figure  7b</ref>. We observe that, HARSH, unlike IMPUTE*, benefits from using longer reads, as it contains more multi-SNP reads than shorter reads. Thus, as expected, the performance gap between IMPUTE* and HARSH increases as the read length increases. However, in<ref type="figure" target="#fig_7">Figure 7b</ref>, we do not see that the error rate increases when the read length increases as in<ref type="figure" target="#fig_4">Figure 6b</ref>. A possible reason is that the SNPs are much denser in 1000 Genomes data than HapMap data, and we simulated much shorter reads for 1000 Genomes data. Thus, the gap caused by 400 bp read length would be much shorter than previous 4000 bp read length for HapMap dataset. The reference haplotype panel could well take advantage of Linkage Disequilibrium effect to recover those gaps. Therefore, the error rate for IMPUTE* keeps almost the same for different read lengths but our method HARSH reduces the error rate by incorporating more multi-SNP read information when the read length increases.Note: Read length is fixed to be 1000 bp.Haplotype phasing plays an important role in a wide variety of genetic applications. Although it is possible to determine haplotypes using laboratory-based experimental techniques, these approaches are expensive and time-consuming. Recently,<ref type="bibr" target="#b17">Kitzman et al. (2011)</ref>were able to generate the complete phased sequence of a Gujarati individual using a Fosmid library. Unfortunately, this method is not easily scalable to phasing more than one individual. Thus, the need for a practical computational method for haplotype phasing remains. We have presented HARSH, an efficient method that combines multi-SNP read information with reference panels of haplotypes for improved genotype and haplotype inference in sequencing data. Unlike previous phasing methods that use read counts at each SNP as input, our method takes into account the information from reads spanning multiple SNPs. HARSH is able to efficiently find the likely haplotypes in terms of the marginal probability over the genotype data. Using simulations from HapMap and 1000 Genomes data, we show that our method achieves superior accuracy than existing approaches with decreased computational requirements. In addition, we evaluate our method as function of coverage and read length, showing that our method continues to improve as read length and coverage increases.Note: Coverage is fixed to be 4Â.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.2.</head><figDesc>Fig. 2. A graphical model for haplotype assembly. In this example, two reads and four heterozygous SNPs are considered. Read 1 covers the SNPs 1, 2 and 3. Read 2 covers SNPs 2, 3 and 4. The variables h 2 f1, À 1g stands for the haplotype. The variable r 2 f1, À 1g stands for whether the read is from haplotype h or the complementary h</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig</head><figDesc>Fig. 4. The number of switches within heterozygous SNPs for haplotype assembly, BEAGLE, IMPUTE* and HARSH. The number of switches of haplotype assembly is estimated by the lowest bound. (a) Varying coverage for fixed read length 1000 bp. (b) Varying read length for fixed coverage 4X</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.6.</head><figDesc>Fig. 6. Performance of BEAGLE, IMPUTE* and HARSH for varying coverage and read length on HapMap. (a) Varying coverage for fixed read length 1000 bp. (b) Varying read length for fixed coverage 4X</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.7.</head><figDesc>Fig. 7. Performance of IMPUTE* and HARSH for varying coverage and read length on 1000 genomes. (a) Varying coverage for fixed read length 1000 bp. (b) Varying read length for fixed coverage 4X</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Pðs 1 js 2 , HÞPðs 2 js 3 , HÞ Á sPðs LÀ1 js L , HÞPðs L , HÞ. Then sampling from Pðs L Þ and sampling backward using those conditional probabilities becomes trivial. We can use dynamic programming to convert the PðSjHÞ distribution to the alternative form. We define</figDesc><table>V 1 ðs 2 Þ ¼ 
X 

s2S 

exp 

0 ðsÞ 1 ðs, s 2 Þ 


and 

V i ðs iþ1 Þ ¼ 
X 

y2S 

V iÀ1 ðyÞ exp ð i ðy, s iþ1 ÞÞ for i ¼ 2, Á Á Á , L: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>performed simulation experiments using HapMap Phase II data (International HapMap Consortium, 2005) and 1000 Genomes data (Durbin, R. et al., 2010). For our simulations, we used the 60 parental individuals of CEU populations from HapMap Phase II as well as 60 individuals randomly chosen from the European populations for 1000 Genomes data. Although our method is scalable to the entire genome, for the purpose of demonstration, we use only chromosome 22 as representative of the rest of the genome, as it is the shortest chromosome. Because we are performing many simulations, we restrict our results to the 35 421 SNPs in chromosome 22 of the HapMap data, and the first 30 000 SNPs in chromosome 22 of 1000 Genomes data, which span $3 Mb. The datasets are publicly available at http://mathgen.stats.ox.ac.uk/impute/ and http:// hapmap.ncbi.nlm.nih.gov/.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 2. Genotyping and switching errors (%) for varying coverages on HapMap dataset</figDesc><table>Coverage 
1Â 
2Â 
4Â 
6Â 
8Â 
10Â 

Genotyping Error 
BEAGLE 
4.21 
1.94 
0.59 
0.22 
0.10 
0.04 
IMPUTE* 
3.59 
1.53 
0.56 
0.30 
0.17 
0.12 
HARSH 
3.42 
1.28 
0.28 
0.08 
0.04 
0.02 
Switching Error 
BEAGLE 
0.97 
1.04 
1.05 
1.11 
1.23 
1.23 
IMPUTE* 
0.82 
0.87 
0.90 
0.94 
0.97 
0.98 
HARSH 
0.72 
0.67 
0.62 
0.63 
0.65 
0.65 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 1.</figDesc><table>Comparison between IMPUTE*, Hap-SeqX and HARSH on a 
HapMap dataset with 1 donor individual, 59 reference individuals and 
35 421 SNPs 

Methods 
Error rate (switch, genotyping) 
Time 

IMPUTE* 
0.04836 (0.00804, 0.04033) 
$5 min 
Hap-SeqX 
0.04230 (0.00726, 0.03504) 
$5 h 
HARSH 
0.03804 (0.00664, 0.03140) 
$10 min 

Note: Read length of 1000bp and 1Â coverage are simulated. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 3. Genotyping and switching errors (%) for varying read lengths on HapMap dataset</figDesc><table>Read length 
1000 bp 
2000 bp 
3000 bp 
4000 bp 

Genotyping error 
BEAGLE 
0.59 
0.67 
0.74 
0.79 
IMPUTE* 
0.56 
0.70 
0.77 
0.85 
HARSH 
0.28 
0.37 
0.40 
0.48 
Switching error 
BEAGLE 
1.05 
1.10 
1.07 
1.07 
IMPUTE* 
0.90 
0.93 
0.94 
0.94 
HARSH 
0.62 
0.57 
0.49 
0.48 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">W.-Y.Yang et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Current haplotype assembly methods mainly focus on de novo assembly, which uses short reads as the only information source. This is partially owing to the complexity of extending the method to the scenario of assembly using reference. On the other hand, current haplotype phasing methods only use the reference panel and genotype likelihood in each SNP but ignore the multi-SNP information in the reads. We aim to use both the reference panel and sequencing data to perform haplotype phasing as shown in Figure 1. Formally, suppose that we are only considering L biallelic SNPs, M reads and N reference haplotypes. Each read is represented by X j ¼ fÀ1, 1, 0g L , where 0 stands for unobserved SNP in jth read. The objective is to find two haplotypes, H ¼ fh 1 , h 2 g, where h 1 , h 2 2 fÀ1, 1g L. We want to find the two haplotypes with small number of inconsistent loci with reads, as well as more consistent with reference haplotypes. We use another set of variables, S ¼ fs 1 , s 2 g, where s 1 , s 2 2 f1, 2,. .. , Ng L , to stand for the assignment of each loci to reference haplotypes. We also need a set of variables R ¼ fr 1 , r 2 ,. .. , r M g, where r i 2 fÀ1, 1g stands for the haplotype that each read originates from. An illustrative example of the graph structure is given in Figure 3. Similar to the previous section, we can formalize the connection between the three variables H, R and S into the following probabilistic distribution. For each possible values of H, R and S, we can calculate its probability as follows:</note>

			<note place="foot">Leveraging multi-SNP reads from sequencing data at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">HapCompass: a fast cycle basis algorithm for accurate haplotype assembly of sequence data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Aguiar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Istrail</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="577" to="590" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">HapCUT: an efficient and accurate algorithm for the haplotype assembly problem</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bafna</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="153" to="159" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">An MCMC algorithm for haplotype assembly from wholegenome sequence data</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1336" to="1346" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A unified approach to genotype imputation and haplotype-phase inference for large data sets of trios and unrelated individuals</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Browning</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Browning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="210" to="223" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Refhap: a reliable and fast algorithm for single individual haplotyping</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Duitama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First ACM International Conference on Bioinformatics and Computational Biology</title>
		<meeting>the First ACM International Conference on Bioinformatics and Computational Biology<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Fosmid-based whole genome haplotyping of a hapmap trio child: evaluation of single individual haplotyping techniques</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Duitama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2041" to="2053" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A map of human genome variation from population-scale sequencing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimating recombination rates from population genetic data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Fearnhead</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Donnelly</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="1299" to="1318" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, gibbs distributions, and the bayesian restoration of images</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Geman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Geman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Hap-seqX: expedite algorithm for haplotype phasing with imputation using sequence data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>He</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Eskin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gene</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="page" from="2" to="6" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimal algorithms for haplotype assembly from whole-genome sequence data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Hap-seq: an optimal algorithm for haplotype phasing with imputation using sequencing data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual International Conference on Research in Computational Molecular Biology (RECOMB)</title>
		<meeting>the 16th Annual International Conference on Research in Computational Molecular Biology (RECOMB)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Genotype imputation with thousands of genomes</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">G3 (Bethesda)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="457" to="470" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A flexible and accurate genotype imputation method for the next generation of genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">N</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000529</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Association of nod2 leucine-rich repeat variants with susceptibility to crohn&apos;s disease</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">P</forename>
				<surname>Hugot</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">411</biblScope>
			<biblScope unit="page" from="599" to="603" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A haplotype map of the human genome</title>
	</analytic>
	<monogr>
		<title level="j">International HapMap Consortium. Nature</title>
		<imprint>
			<biblScope unit="volume">437</biblScope>
			<biblScope unit="page" from="1299" to="1320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">EMINIM: an adaptive and memory-efficient algorithm for genotype imputation</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">M</forename>
				<surname>Kang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="547" to="560" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Haplotype-resolved genome sequencing of a gujarati indian individual</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">O</forename>
				<surname>Kitzman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="59" to="63" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A chronology of fine-scale gene mapping by linkage disequilibrium</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">C</forename>
				<surname>Lazzeroni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Methods Med. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="57" to="76" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Modeling linkage disequilibrium and identifying recombination hotspots using single-nucleotide polymorphism data</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="2213" to="2233" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">MaCH: using sequence and genotype data to estimate haplotypes and unobserved genotypes</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="816" to="834" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">Monte Carlo Strategies in Scientific Computing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">HI: haplotype improver using paired-end short reads</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Long</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2436" to="2437" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Bounds on the minimum number of recombination events in a sample history</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Myers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">C</forename>
				<surname>Griffiths</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="375" to="394" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Extremely low-coverage sequencing and imputation increases power for genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Pasaniuc</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="631" to="635" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Genetic variation in the 5q31 cytokine gene cluster confers susceptibility to Crohn disease</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Rioux</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="223" to="228" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Detecting recent positive selection in the human genome from haplotype structure</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">C</forename>
				<surname>Sabeti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">419</biblScope>
			<biblScope unit="page" from="832" to="837" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">A fast and accurate algorithm for single individual haplotyping</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Xie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>