
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining MissForest—non-parametric missing value imputation for mixed-type data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Daniel</forename>
								<forename type="middle">J</forename>
								<surname>Stekhoven</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Seminar for Statistics</orgName>
								<orgName type="department" key="dep2">Department of Mathematics</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Life Science Zurich PhD Program on Systems Biology of Complex Diseases</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Competence Center for Systems Physiology and Metabolic Diseases</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Peter</forename>
								<surname>Bühlmann</surname>
							</persName>
							<email>buhlmann@stat.math.ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Seminar for Statistics</orgName>
								<orgName type="department" key="dep2">Department of Mathematics</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Competence Center for Systems Physiology and Metabolic Diseases</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining MissForest—non-parametric missing value imputation for mixed-type data</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="issue">1</biblScope>
							<biblScope unit="page" from="112" to="118"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr597</idno>
					<note type="submission">Received on May 3, 2011; revised on September 27, 2011; accepted on October 24, 2011</note>
					<note>[18:15 5/12/2011 Bioinformatics-btr597.tex] Page: 112 112–118 Associate Editor: Jonathan Wren</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Modern data acquisition based on high-throughput technology is often facing the problem of missing data. Algorithms commonly used in the analysis of such large-scale data often depend on a complete set. Missing value imputation offers a solution to this problem. However, the majority of available imputation methods are restricted to one type of variable only: continuous or categorical. For mixed-type data, the different types are usually handled separately. Therefore, these methods ignore possible relations between variable types. We propose a non-parametric method which can cope with different types of variables simultaneously. Results: We compare several state of the art methods for the imputation of missing values. We propose and evaluate an iterative imputation method (missForest) based on a random forest. By averaging over many unpruned classification or regression trees, random forest intrinsically constitutes a multiple imputation scheme. Using the built-in out-of-bag error estimates of random forest, we are able to estimate the imputation error without the need of a test set. Evaluation is performed on multiple datasets coming from a diverse selection of biological fields with artificially introduced missing values ranging from 10% to 30%. We show that missForest can successfully handle missing values, particularly in datasets including different types of variables. In our comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected. The out-of-bag imputation error estimates of missForest prove to be adequate in all settings. Additionally, missForest exhibits attractive computational efficiency and can cope with high-dimensional data. Availability: The R package missForest is freely available from</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Imputation of missing values is often a crucial step in data analysis. Many established methods of analysis require fully observed datasets without any missing values. However, this is seldom the case in medical and biological research today. The ongoing * To whom correspondence should be addressed. development of new and enhanced measurement techniques in these fields provides data analysts with challenges prompted not only by high-dimensional multivariate data where the number of variables may greatly exceed the number of observations, but also by mixed data types where continuous and categorical variables are present. In our context, categorical variables can arise as any kind ranging from technical settings in a mass spectrometer to a diagnostic expert opinion on a disease state. Additionally, such datasets often contain complex interactions and non-linear relation structures which are notoriously hard to capture with parametric procedures. Most prevalent imputation methods, like k nearest neighbours<ref type="bibr">[KNNimpute, Troyanskaya et al. (2001)</ref>] for continuous data, saturated multinomial model (<ref type="bibr" target="#b13">Schafer, 1997</ref>) for categorical data and multivariate imputation by chained equations [MICE, Van Buuren and<ref type="bibr" target="#b20">Oudshoorn (1999)</ref>] for mixed data types depend on tuning parameters or specification of a parametric model. The choice of such tuning parameters or models without prior knowledge is difficult and might have a dramatic effect on a method's performance. Excluding MICE, the above methods and the majority of other imputation methods are restricted to one type of variable. Furthermore, all these methods make assumptions about the distribution of the data or subsets of the variables, leading to questionable situations, e.g. assuming normal distributions. The literature on mixed-type data imputation is rather scarce. Its first appearance was in the developing field of multiple imputation brought up by<ref type="bibr" target="#b11">Rubin (1978)</ref>. Little and<ref type="bibr" target="#b7">Schluchter (1985)</ref>presented an approach based on maximum likelihood estimation combining the multivariate normal model for continuous and the Poisson/multinomial model for categorical data. This idea was later on extended in the book of Little and Rubin (1987). See also<ref type="bibr" target="#b5">Li (1988)</ref>, Rubin and Schafer (1990) and Schafer (1997). A more refined method to combine different regression models for mixed-type data was proposed by Van Buuren and Oudshoorn (1999) using chained equations. The conditional model in MICE can be specified for the missing data in each incomplete variable. Therefore, no multivariate model covering the entire dataset has to be specified. However, it is assumed that such a full multivariate distribution exists and missing values are sampled from conditional distributions based on this full distribution (for more details see Section 3). Another similar method using variable-wise conditional distributions was proposed by<ref type="bibr" target="#b10">Raghunathan et al. (2001)</ref>called sequential regression multivariate imputation. Unlike in MICE, the predictors must not be incomplete. The method is focussed on survey data and therefore includes strategies to incorporate restrictions on<ref type="bibr">[</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MissForest</head><p>subsamples of individuals and logical bounds based on domain knowledge about the variables, e.g. only women can have a number of pregnancies recorded. Our motivation is to introduce a method of imputation which can handle any type of input data and makes as few as possible assumptions about structural aspects of the data. Random forest<ref type="bibr">[RF, Breiman (2001)</ref>] is able to deal with mixed-type data and as a non-parametric method it allows for interactive and non-linear (regression) effects. We address the missing data problem using an iterative imputation scheme by training an RF on observed values in a first step, followed by predicting the missing values and then proceeding iteratively.<ref type="bibr" target="#b8">Mazumder et al. (2010)</ref>use a similar approach for the matrix completion problem using a softthresholded SVD iteratively replacing the missing values. We choose RF because it can handle mixed-type data and is known to perform very well under barren conditions like high dimensions, complex interactions and non-linear data structures. Due to its accuracy and robustness, RF is well suited for the use in applied research often harbouring such conditions. Furthermore, the RF algorithm allows for estimating out-of-bag (OOB) error rates without the need for a test set. For further details, see Breiman (2001). Here we compare our method with k-nearest neighbour imputation<ref type="bibr">[KNNimpute, Troyanskaya et al. (2001)</ref>] and the Missingness Pattern Alternating Lasso (MissPALasso) algorithm by Städler and Bühlmann (2010) on datasets having continuous variables only. For the cases of categorical and mixed type of variables, we compare our method with the MICE algorithm by Van Buuren and Oudshoorn (1999) and a dummy variable encoded KNNimpute. Comparisons are performed on several datasets coming from different fields of life sciences and using different proportions of missing values. We show that our approach is competitive to or outperforms the compared methods on the used datasets irrespectively of the variable type composition, the data dimensionality, the source of the data or the amount of missing values. In some cases, the decrease of imputation error is up to 50%. This performance is typically reached within only a few iterations which makes our method also computationally attractive. The OOB imputation error estimates give a very good approximation of the true imputation error having on average a proportional deviation of no more than 10–15%. Furthermore, our approach needs no tuning parameter, and hence is easy to use and needs no prior knowledge about the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">APPROACH</head><p>We assume X = (X 1 ,X 2 ,...,X p ) to be a n×p-dimensional data matrix. We propose using an RF to impute the missing values due to its earlier mentioned advantages as a regression method. The RF algorithm has a built-in routine to handle missing values by weighting the frequency of the observed values in a variable with the RF proximities after being trained on the initially mean imputed dataset (<ref type="bibr" target="#b0">Breiman, 2001</ref>). However, this approach requires a complete response variable for training the forest. Instead, we directly predict the missing values using an RF trained on the observed parts of the dataset. For an arbitrary variable X s including missing values at entries i (s) mis ⊆{1,...,n} we can separate the dataset into four parts:</p><p>(obs is typically not completely observed since the index imis is typically not completely missing. To begin, make an initial guess for the missing values in X using mean imputation or another imputation method. Then, sort the variables X s ,s = 1,...,p according to the amount of missing values starting with the lowest amount. For each variable X s , the missing values are imputed by first fitting an RF with response yThe stopping criterion γ is met as soon as the difference between the newly imputed data matrix and the previous one increases for the first time with respect to both variable types, if present. Here, the difference for the set of continuous variables N is defined as</p><formula>N = j∈N (X imp new −X imp old ) 2 j∈N (X imp new ) 2 ,</formula><p>and for the set of categorical variables F as</p><formula>F = j∈F n i=1 I X imp new =X imp old #NA ,</formula><p>where #NA is the number of missing values in the categorical variables. After imputing the missing values, the performance is assessed using the normalized root mean squared error<ref type="bibr">[NRMSE, Oba et al. (2003)]</ref>for the continuous variables which is defined by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.J.Stekhoven and P. Bühlmann</head><p>where X true is the complete data matrix and X imp the imputed data matrix. We use mean and var as short notation for empirical mean and variance computed over the continuous missing values only. For categorical variables, we use the proportion of falsely classified entries (PFC) over the categorical missing values, F. In both cases, good performance leads to a value close to 0 and bad performance to a value around 1. When an RF is fit to the observed part of a variable, we also get an OOB error estimate for that variable. After the stopping criterion γ was met, we average over the set of variables of the same type to approximate the true imputation errors. We assess the performance of this estimation by comparing the absolute difference between true imputation error and OOB imputation error estimate in all simulation runs.</p><formula>k best ← argmin k 1 l l t=1 ε k,t ;</formula><p>10. X imp ← KNN imputation of X using k best nearest neighbours. In the original paper of<ref type="bibr" target="#b18">Troyanskaya et al. (2001)</ref>, the data were not standardized before applying the KNNimpute algorithm. This constitutes no issue in the case of gene expression data, because such data generally consist of variables on similar scales. However, we are applying the KNNimpute algorithm to datasets with varying scales in the variables. To avoid variancebased weighting of the variables, we scale them to a unit SD. We also centre the variables at zero. After imputation, the data are retransformed such that the error is computed on the original scales. This last step is performed because missForest does not need any transformation of the data and we want to compare the performance of the methods on the original scales of the data. Another approach for continuous data, especially in the case of highdimensional normal data matrices, is presented by Städler and Bühlmann (2010) using an EM-type algorithm. In their Missingness Pattern Alternating Imputation and l 1-penalty (MissPALasso) algorithm, the missing variables are regressed on the observed ones using the lasso penalty by<ref type="bibr" target="#b16">Tibshirani (1996)</ref>. In the following E step, the obtained regression coefficients are used to partially update the latent distribution. The MissPALasso has also a tuning parameter λ for the penalty. As with KNNimpute, we use crossvalidation to tune λ (cf. Algorithm 2). When applying MissPALasso, the data are standardized as regularization with a single λ requires the different regressions to be on the same scale. In the comparative experiments with categorical or mixed-type variables, we use the MICE algorithm by Van Buuren and Oudshoorn (1999) based on the multivariate multiple imputation scheme of Schafer (1997). In contrast to the latter, the conditional distribution for the missing data in each incomplete variable is specified in MICE, a feature called fully conditional specification by Van Buuren (2007). However, the existence of a multivariate distribution from which the conditional distribution can be easily derived is assumed. Furthermore, iterative Gibbs sampling from the conditional distributions can generate draws from the multivariate distribution. We want to point out that MICE in its default setup is not mainly intended for simple missing value imputation. Using the multiple imputation scheme, MICE allows for assessing the uncertainty of the imputed values. It includes features to pool multiple imputations, choose individual sampling procedures and allows for passive imputation controlling the sync of transformed variables. In our experiments, we used MICE with either linear regression with normal errors or mean imputation for continuous variables, logistic regression for binary variables and polytomous logistic regression for categorical variables with more than two categories. For comparison across different types of variables, we apply the KNNimpute algorithm with dummy coding for the categorical variables. This is done by coding a categorical variable X j into m dichotomous variables˜X variables˜ variables˜X j,m ∈{−1,1}. Application of the KNNimpute algorithm for categorical data can be summarized as:</p><p>(1) Code all categorical variables into {−1,1}-dummy variables;</p><p>(2) standardize all variables to mean 0 and SD 1;</p><p>(3) apply the cross-validated KNNimpute method from Algorithm 2;</p><p>(4) retransform the imputed data matrix to the original scales;</p><p>(5) code the dummy variables back to categorical variables; and</p><p>(6) computed the imputation error.</p><p>For each experiment, we perform 50 independent simulations where 10, 20 or 30% of the values are removed completely at random. Each method is then applied and the NRMSE, the PFC or both are computed (Section 2). We perform a paired Wilcoxon test of the error rates of the compared methods versus the error rates of missForest. In addition, the OOB error estimates of missForest is recorded in each simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Continuous variables only</head><p>First, we focus on continuous data. We investigate the following four publicly available datasets:smaller than that of missForest, the significance level is encoded by a hash (#) instead of an asterisk. In the lowermost dataset, results for MissPALasso are missing due to the implementations limited capability with regard to high dimensions. also contains a response variable giving the health status. Dealing only with continuous variables, the response was removed from the data. We will return to this later on. @BULLET Shapes of musk molecules: this dataset describes 92 molecules of which 47 are musks and 45 are non-musks. For each molecule P = 166 features describe its conformation, but since a molecule can have many conformations due to rotating bonds, there are n = 476 different low-energy conformations in the set. The classification into musk and non-musk molecules is removed.</p><p>@BULLET Insulin gene expression: this high-dimensional dataset originates from an analysis by<ref type="bibr" target="#b22">Wu et al. (2007)</ref>of vastus lateralis muscle biopsies from three different types of patients following insulin treatment. The three types are insulinsensitive, insulin-resistant and diabetic patients. The analysis involves P = 12 626 genes whose expression levels were measured from n = 110 muscle biopsies. Due to computation time we only perform 10 simulations instead of 50.</p><p>Results are given in<ref type="figure">Figure 1</ref>. We can see that missForest performs well, sometimes reducing the average NRMSE by up to 25% with respect to KNNimpute. In case of the musk molecules data, the reduction is even &gt;50%. The MissPALasso performs slightly better than missForest on the gene expression data. However, there are no results for the MissPALasso in case of the Insulin dataset, because the high dimension makes computation not feasible. For continuous data, the missForest algorithm typically reaches the stopping criterion quite fast needing about five iterations. The imputation takes ∼10 times as long as performing the crossvalidated KNNimpute where {1,...,15} is the set of possible numbers of neighbours. For the Insulin dataset, an imputation takes on average 2 h on a customary available desktop computer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Categorical variables only</head><p>We also consider datasets with only categorical variables. Here, we use the MICE algorithm described in Section 3 instead of the MissPALasso. We use a dummy implementation of the KNNimpute algorithm to deal with categorical variables (Section 3). We apply the methods to the following datasets:<ref type="bibr" target="#b17">Towell et al. (1990)</ref>for nonpromoters totalling n = 106. For each candidate, a sequence of 57 bp was recorded. Each variable can take one of four DNA nucleotides, i.e. adenine, thymine, guanine or cytosine. Another variable distinguishes between promoter and non-promoter instances.</p><p>@BULLET Lymphography domain data: the observations were obtained from patients suffering from cancer in the lymphatic of the immune system. For each of the n = 148 lymphoma, P = 19 different properties were recorded mainly in a nominal fashion. There are nine binary variables. The rest of the variables have three or more levels. In<ref type="figure" target="#fig_3">Figure 2</ref>, we can see that missForest is always imputing the missing values better than the compared methods. In some cases, namely for the SPECT data, the decrease of PFC compared with MICE is up to 60%. However, for the other datasets the decrease is less pronounced ranging around 10–20%, but there still is a decrease. The amount of missing values on the other hand seems to have only a minor influence on the performance of all methods. Except for MICE on the SPECT data, error rates remain almost constant increasing only by 1–2%. We pointed out earlier that MICE is not primarily tailored for imputation performance, but offers additional possibilities of assessing uncertainty of the imputed values due to the multiple imputation scheme. Anyhow, the results using the cross-validated KNNimpute (Algorithm 2) on the dummy-coded categorical variables is surprising. The imputation for missForest needs on average five times as long as a cross-validated imputation using KNNimpute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Mixed-type variables</head><p>In the following, we investigate four datasets where the first one has already been introduced, i.e. musk molecules data including the categorical response yielding the classification. The other datasets are as follows:</p><p>@BULLET Proteomics biomarkers for Gaucher's disease: Gaucher's disease is a rare inherited enzyme deficiency. In this dataset,<ref type="bibr" target="#b14">Smit et al. (2007)</ref>present protein arrays for biomarkers</p><p>Page: 116 112–118(P = 590) from blood serum samples (n = 40). The binary response distinguishes between disease status. @BULLET Gene finding over prediction (GFOP) peptide search: this dataset comprises mass-spectrometric measurements of n = 595 peptides from two shotgun proteomics experiments on the nematode Caenorhabditis elegans. The collection of P = 18 biological, technical and analytical variables had the aim of novel peptide detection in a search on an extended database using established gene prediction methods. @BULLET Children's Hospital data: this dataset is the product of a systematic long-term review of children with congenital heart defects after open heart surgery. Next to defect-and surgeryrelated variables, also long-term psychological adjustment and health-related quality of life was assessed. After removing observations with missing values, the dataset consists of n = 55 patients and P = 124 variables of which 48 are continuous and 76 are categorical. For further details see Latal et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.J.Stekhoven and P. Bühlmann</head><formula>(2009).</formula><p>The results of this comparison are given in<ref type="figure" target="#fig_4">Figure 3</ref>. We can see that missForest performs better than the other two methods, again reducing imputation error in many cases by &gt;50%. For the GFOP data, KNNimpute has a slightly smaller NRMSE than missForest but makes twice as much error on the categorical variables. Generally, with respect to the amount of missing values the NRMSE tends to have a greater variability than the PFC which remains largely the same. The imputation results for MICE on the Children's Hospital data have to be treated cautiously. Since this dataset contains illdistributed and nearly dependent variables, e.g. binary variables with very few observations in one category, the missingness pattern has a direct influence on the operability of the MICE implementation in the statistical software R. The imputation error illustrated in<ref type="figure" target="#fig_4">Figure 3</ref>was computed from 50 successful simulations by randomly generating missingness patterns, which did not include only complete cases or no complete cases at all within the categoriesof the compared method is smaller than that of missForest, the significance level is encoded by a hash (#) instead of an asterisk. Note that, due to illdistribution and near dependence in the Child hospital data, the results for MICE have to be treated with caution (Section 4.3). of the variables. Therefore, the actual numbers of simulations were &gt;50 for all three missing value amounts. Furthermore, nearly dependent variables were removed after each introduction of missing values. This leads to an average of seven removed variables in each simulation. Due to this ad hoc manipulation for making the MICE implementation work, we do not report significance statements for the imputation error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Estimating imputation error</head><p>In each experiment, we get for each simulation run an OOB estimate for the imputation error. In<ref type="figure" target="#fig_5">Figure 4</ref>the differences of true imputation error, err true , and OOB error estimates, err OOB , are illustrated for the continuous and the categorical datasets. Also, the mean of the true imputation error and the OOB error estimate over all simulations is depicted. We can see that for the Isoprenoid and Musk datasets, the OOB estimates are very accurate only differing from the true imputation error by a few percents. In the case of Parkinson's dataset, the OOB estimates exhibit a lot more variability than in all other datasets. However, on average the estimation is comparably good. For the categorical datasets, the estimation accuracy behaves similarly over all scenarios. The OOB estimates tend to underestimate the imputation error with increasing amount of missing values. Apparently, the absolute size of the imputation error seems to play a minor role in the accuracy of the OOB estimates, which can be seen nicely when comparing the SPECT and the Promoter data.Runtimes are averaged over the amount of missing values since this has a negligible effect on computing time. NA, not available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 117 112–118</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MissForest</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Computational efficiency</head><p>We assess the computational cost of missForest by comparing the runtimes of imputation on the previous datasets.<ref type="figure" target="#tab_1">Table 1</ref>shows the runtimes in seconds of all methods on the analysed datasets. We can see that KNNimpute is by far the fastest method. However, missForest runs considerably faster than MICE and the MissPALasso. In addition, applying missForest did not require antecedent standardization of the data, laborious dummy coding of categorical variables nor implementation of CV choices for tuning parameters. There are two possible ways to speed up computation. The first one is to reduce the number of trees grown in each forest. In all comparative studies, the number of trees was set to 100 which offers high precision but increased runtime. In Table 2, we can see that changing the number of trees in the forest has a stagnating influence on imputation error, but a strong influence on computation time which is approximately linear in the number of trees. The second one is to reduce the number of variables randomly selected at each node (m try ) to set up the split.<ref type="figure" target="#tab_2">Table 2</ref>shows that increasing m try has limited effect on imputation error, butHere, we consider the GFOP dataset with artificially introduced 10% of missing values. For each comparison, 50 simulation runs were performed using always the same missing value matrix for all number of trees/randomly selected variables for a single simulation. computation time is strongly increased. Note that for m try = 1 we no longer have an RF, since there is no more choice between variables to split on. This leads to a much higher imputation error, especially for the cases with low numbers of bootstrapped trees. We use for all experiments √ p as default value, e.g. in the GFOP data this equals 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Our new algorithm, missForest, allows for missing value imputation on basically any kind of data. In particular, it can handle multivariate data consisting of continuous and categorical variables simultaneously. MissForest has no need for tuning parameters nor does it require assumptions about distributional aspects of the data. We show on several real datasets coming from different biological and medical fields that missForest outperforms established imputation methods like k-nearest neighbours imputation or multivariate imputation using chained equations. Using our OOB imputation error estimates, missForest offers a way to assess the quality of an imputation without the need of setting aside test data nor performing laborious cross-validations. For subsequent analysis, these error estimates represent a mean of informal reliability check for each variable. The full potential of missForest is deployed when the data include complex interactions or non-linear relations between variables of unequal scales and different type. Furthermore, missForest can be applied to high-dimensional datasets where the number of variables may greatly exceed the number of observations to a large extent and still provides excellent imputation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 118 112–118</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.J.Stekhoven and P. Bühlmann</head><p>providing the data. The Lymphography dataset was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Slovenia. Thanks to M. Zwitter and M. Soklic for providing the data. The Children's Hospital dataset was obtained from the Child Development Center at the University Children's Hospital, Zürich, Switzerland. Thanks to B. Latal and I. Beck for providing the data. Finally, we thank two anonymous referees for their constructive comments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>The imputation procedure is repeated until a stopping criterion is met. The pseudo Algorithm 1 gives a representation of the missForest method. Algorithm 1 Impute missing values with RF. Require: X an n×p matrix, stopping criterion γ 1. Make initial guess for missing values; 2. k ← vector of sorted indices of columns in X w.r.t. increasing amount of missing values;end while 12. return the imputed matrix X imp</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Algorithm 2 Cross-validation KNN imputation. Require: X an n×p matrix, number of validation sets l, range of suitable number of nearest neighbours K 1. X CV ← initial imputation using mean imputation; 2. for t in 1,...,l do 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Categorical data. Average PFC for cross-validated KNNimpute (grey), MICE (white) and missForest (black) on three different datasets and three different amounts of missing values, i.e. 10, 20 and 30%. Standard errors are in the order of magnitude of 10 −4. Significance levels for the paired Wilcoxon tests in favour of missForest are encoded as '*' &lt;0.05, '**' &lt;0.01 and '***' &lt;0.001.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Mixed-type data. Average NRMSE (left bar) and PFC (right bar, shaded) for KNNimpute (grey), MICE (white) and missForest (black) on four different datasets and three different amounts of missing values, i.e. 10, 20 and 30%. Standard errors are in the order of magnitude of 10 −3. Significance levels for the paired Wilcoxon tests in favour of missForest are encoded as '*' &lt;0.05, '**' &lt;0.01 and '***' &lt;0.001. If the average error of the compared method is smaller than that of missForest, the significance level is encoded by a hash (#) instead of an asterisk. Note that, due to illdistribution and near dependence in the Child hospital data, the results for MICE have to be treated with caution (Section 4.3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. Difference of true imputation error err true and OOB imputation error estimate err OOB for the continuous datasets (A) and the categorical datasets (B) and three different amounts of missing values, i.e. 0.1, 0.2 and 0.3. In each case, the average err true (circle) and the average err OOB (plus) over all simulations is given.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>Funding: The work was partly financed with a grant of the Swiss SystemsX.ch Initiative to the project LiverX of the Competence Center for Systems Physiology and Metabolic Diseases. The LiverX project was evaluated by the Swiss National Science Foundation. Conflict of interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>1) The observed values of variable X s , denoted by y</figDesc><table>(s) 

obs ; 

(2) the missing values of variable X s , denoted by y 

(s) 

mis ; 
(3) the variables other than X s with observations 
i 

(s) 

obs ={1,...,n}\i 

(s) 

mis denoted by x 

(s) 

obs ; and 
(4) the variables other than X s with observations i 

(s) 

mis denoted by 
x 

(s) 

mis . 

Note that x 

(s) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>← error of KNN imputation for k and t; 7.</figDesc><table>X CV 
mis,t ← artificially introduce missing values to X CV ; 

4. 

for k in K do 

5. 

X CV 
KNN,t ← KNN imputation of X CV 
mis,t using k nearest 
neighbours; 

6. 

ε k,t end for 
8. end for 
9. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>@BULLET Isoprenoid gene network in Arabidopsis thaliana: this gene network includes P = 39 genes each with n =</figDesc><table>118 gene 
expression profiles corresponding to different experimental 
conditions. For more details on this dataset, see Wille et al. 
(2004). 

@BULLET Voice measures in Parkinson's patients: the data described 
by Little et al. (2008) contains a range of biomedical voice 
measurements from 31 individuals, 23 with Parkinson's disease 
(PD). There are P = 22 particular voice measurements and 
n = 195 voice recordings from these individuals. The dataset Page: 115 112–118 

MissForest 

Fig. 1. Continuous data. Average NRMSE for KNNimpute (grey), 
MissPALasso (white) and missForest (black) on four different datasets and 
three different amounts of missing values, i.e. 10, 20 and 30%. Standard 
errors are in the order of magnitude of 10 −4 . Significance levels for the 
paired Wilcoxon tests in favour of missForest are encoded as '*' &lt;0.05, '**' 
&lt;0.01 and '***' &lt;0.001. If the average error of the compared method is 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>@BULLET Cardiac single photon emission computed tomography (SPECT) images: Kurgan et al. (2001) discuss this processed dataset summarizing over 3000 2D SPECT images from n = 267 patients in P = 22 binary feature patterns. @BULLET Promoter gene sequences in Escherichia coli: the dataset contains sequences found by Harley and Reynolds (1987) for promoters and sequences found by</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 1. Average runtimes (in seconds) for imputing the analysed datasets</figDesc><table>Dataset 
n 
P 
KNN MissPALasso MICE missForest 

Isoprenoid 
118 
39 
0.8 170 
− 
5.8 
Parkinson's 
195 
22 
0.7 120 
− 
6.1 
Musk (cont.) 
476 
166 
13 
1400 
− 
250 
Insulin 
110 12626 1800 
NA 
− 6200 

SPECT 
267 
22 
1.3 
− 
37 
5.5 
Promoter 
106 
57 
14 
− 
4400 
38 
Lymphography 148 
19 
1.1 
− 
93 
7.0 

Musk (mixed) 476 
167 
27 
− 
2800 
500 
Gaucher's 
40 
590 
1.3 
− 
130 
29 
GFOP 
595 
18 
2.7 
− 
1400 
40 
Children 
55 
124 
2.7 
− 
4000 
110 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 2. Average imputation error (NRMSE/PFC in percent) and runtime (in seconds) with different numbers of trees (n tree ) grown in each forest and variables tried (m try ) at each node of the trees m try n tree</figDesc><table>10 
50 
100 
250 
500 

1 
36.8/35.5 
27.4/32.3 
20.4/31.3 
17.2/30.0 
16.0/30.8 
2.5 s 
3.2 s 
3.9 s 
5.8 s 
9.2 s 

2 
34.9/31.8 
24.8/29.2 
18.3/28.8 
16.0/28.6 
15.5/29.1 
6.9 s 
11.8 s 
15.0 s 
25.2 s 
39.3 s 

4 
34.9/31.3 
24.4/28.9 
17.9/28.2 
15.4/28.2 
15.8/28.7 
16.5 s 
25.1 s 
35.0 s 
49.0 s 
83.3 s 

8 
34.7/31.4 
24.3/28.9 
18.1/27.8 
15.2/27.8 
15.7/28.6 
39.2 s 
57.4 s 
84.4 s 
130.2 s 
190.8 s 

16 
34.6/30.9 
24.3/28.7 
18.1/28.0 
15.4/27.8 
15.6/28.5 
68.7 s 
99.7 s 
172.2 s 
237.6 s 
400.7 s 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3"> METHODS We compare missForest with four methods on 10 different datasets where we distinguish among situations with continuous variables only, categorical variables only and mixed variable types. The most well-known method for imputation of continuous datasets especially in the field of gene expression analysis is the KNNimpute algorithm by Troyanskaya et al. (2001). A missing value variable X j is imputed by finding its k nearest observed variables and taking a weighted mean of these k variables for imputation. Thereby, the weights depend on the distance of the variable X j. The distance itself is usually chosen to be the Euclidean distance. When using KNNimpute the choice of the tuning parameter k can have a large effect on the performance of the imputation. However, this parameter is not known beforehand. Since our method includes no such parameter, we implement a cross-validation (Algorithm 2) to obtain a suitable k.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>Except for the Isoprenoid, the Lymphography, the Children's Hospital and the GFOP data all other datasets were obtained from the UCI machine learning repository (<ref type="bibr" target="#b1">Frank and Asuncion, 2010</ref>). The GFOP dataset was obtained from the Institute of Molecular Systems Biology, Zurich, Switzerland. Thanks to L. Reiter for</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Frank</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Asuncion</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Analysis of e. coli promoter sequences</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">B</forename>
				<surname>Harley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">P</forename>
				<surname>Reynolds</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2343" to="2361" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowledge discovery approach to automated cardiac SPECT diagnosis</title>
		<author>
			<persName>
				<surname>Kurgan &quot; L</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="149" to="169" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Psychological adjustment and quality of life in children and adolescents following open-heart surgery for congenital heart disease: a systematic review</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Latal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Pediatr</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Imputation using Markov chains</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Comput. Simul</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="57" to="79" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Suitability of dysphonia measurements for telemonitoring of Parkinson&apos;s disease. Nature Precedings</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Little</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical Analysis with Missing Data Maximum likelihood estimation for mixed continuous and categorical data with missing values</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Little</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rubin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Schluchter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<publisher>Wiley</publisher>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="497" to="512" />
			<date type="published" when="1985" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Spectral regularization algorithms for learning large incomplete matrices</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mazumder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2287" to="2322" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A Bayesian missing value estimation method for gene expression profile data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Oba</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2088" to="2096" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A multivariate technique for multiply imputing missing values using a sequence of regression models</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Raghunathan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Surv. Methodol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="85" to="96" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiple imputations in sample surveys-a phenomenological Bayesian approach to nonresponse</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rubin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Survey Research Methods Section</title>
		<meeting>the Survey Research Methods Section</meeting>
		<imprint>
			<publisher>American Statistical Association American Statistical Association</publisher>
			<date type="published" when="1978" />
			<biblScope unit="page" from="20" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficiently creating multiple imputations for incomplete multivariate normal data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rubin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schafer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Statistical Computing Section of the American Statistical Association</title>
		<meeting>the Statistical Computing Section of the American Statistical Association</meeting>
		<imprint>
			<publisher>American Statistical Association</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="83" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">Analysis of Incomplete Multivariate Data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schafer</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Chapman &amp; Hall, UK</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Assessing the statistical validity of proteomics based biomarkers</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Smit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chim. Acta</title>
		<imprint>
			<biblScope unit="volume">592</biblScope>
			<biblScope unit="page" from="210" to="217" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Pattern alternating maximization algorithm for highdimensional missing data</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Städler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bühlmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arxiv preprint</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Refinement of approximate domain theories by knowledge-based neural networks</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Towell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth National Conference on Artificial Intelligence</title>
		<meeting>the Eighth National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI press</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="861" to="866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Missing value estimation methods for DNA microarrays</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Troyanskaya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="520" to="525" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiple imputation of discrete and continuous data by fully conditional specification</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Van Buuren</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Methods Med. Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="219" to="242" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Flexible Multivariate Imputation by MICE</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Van Buuren</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Oudshoorn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TNO Prevention Center</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Sparse graphical Gaussian modeling of the isoprenoid gene network in Arabidopsis thaliana</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Wille</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">92</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">The effect of insulin on expression of genes and biochemical pathways in human skeletal muscle</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Wu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Endocrine</title>
		<imprint>
			<biblScope unit="page" from="31" to="36" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>