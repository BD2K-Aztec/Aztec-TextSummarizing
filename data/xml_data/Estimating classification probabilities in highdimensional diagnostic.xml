
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gene expression Estimating classification probabilities in high-dimensional diagnostic studies</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="25632563">2563 2563–2570 . 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Inka</forename>
								<forename type="middle">J</forename>
								<surname>Appel</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Functional Genomics</orgName>
								<orgName type="institution">University of Regensburg</orgName>
								<address>
									<postCode>93053</postCode>
									<settlement>Regensburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Wolfram</forename>
								<surname>Gronwald</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Functional Genomics</orgName>
								<orgName type="institution">University of Regensburg</orgName>
								<address>
									<postCode>93053</postCode>
									<settlement>Regensburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Rainer</forename>
								<surname>Spang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Functional Genomics</orgName>
								<orgName type="institution">University of Regensburg</orgName>
								<address>
									<postCode>93053</postCode>
									<settlement>Regensburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Janet</forename>
								<surname>Kelso</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Functional Genomics</orgName>
								<orgName type="institution">University of Regensburg</orgName>
								<address>
									<postCode>93053</postCode>
									<settlement>Regensburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gene expression Estimating classification probabilities in high-dimensional diagnostic studies</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">18</biblScope>
							<biblScope unit="page" from="2563" to="2570"/>
							<date type="published" when="25632563">2563 2563–2570 . 2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr434</idno>
					<note type="submission">Received on May 27, 2011; revised on July 13, 2011; accepted on July 19, 2011</note>
					<note>[10:03 19/8/2011 Bioinformatics-btr434.tex] Page: Associate Editor:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Classification algorithms for high-dimensional biological data like gene expression profiles or metabolomic fingerprints are typically evaluated by the number of misclassifications across a test dataset. However, to judge the classification of a single case in the context of clinical diagnosis, we need to assess the uncertainties associated with that individual case rather than the average accuracy across many cases. Reliability of individual classifications can be expressed in terms of class probabilities. While classification algorithms are a well-developed area of research, the estimation of class probabilities is considerably less progressed in biology, with only a few classification algorithms that provide estimated class probabilities. Results: We compared several probability estimators in the context of classification of metabolomics profiles. Evaluation criteria included sparseness biases, calibration of the estimator, the variance of the estimator and its performance in identifying highly reliable classifications. We observed that several of them display artifacts that compromise their use in practice. Classification probabilities based on a combination of local cross-validation error rates and monotone regression prove superior in metabolomic profiling. Availability: The source code written in R is freely available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Diagnosis, prognosis and prediction of treatment response based on transcriptomic, proteomic or metabolomic profiles is a well developed field (<ref type="bibr" target="#b11">Michiels et al., 2007;</ref><ref type="bibr" target="#b15">Sotiriou and Piccart, 2007</ref>). A plethora of classification algorithms have been proposed and critically compared (<ref type="bibr" target="#b4">Fan et al., 2010;</ref><ref type="bibr" target="#b10">MAQC Consortium, 2010;</ref><ref type="bibr" target="#b21">Zervakis et al., 2009</ref>). It very much depends on the classification problem at hand, whether an almost error-free classifier can be developed or whether classification errors are unavoidable regardless of what algorithm is chosen. In the latter case, it is natural that a clinician asks for the reliability of an individual diagnosis before moving on to treatment decisions. Classification algorithms are typically evaluated by the frequency of misclassifications in cross-validation or on an independent test set. These performances are averages over many predicted cases. They say little about the reliability of an individuals diagnosis. The case * To whom correspondence should be addressed. might be easier or more difficult to diagnose than the average in the test set. For each case, every class is assigned a value p j ∈<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, which is an estimated probability that the case belongs to that class, given the profiling data. In microarray-based classification, the performance of classification algorithms has been analyzed and compared in great detail (<ref type="bibr" target="#b3">Dudoit et al., 2002;</ref><ref type="bibr" target="#b17">Wessels et al., 2005</ref>). However, little attention has been given to the usefulness of probability estimates and this is even more true for metabolomic analyses. In fact, only relatively few classification algorithms estimate class probabilities and in the majority of clinical papers on the performance of classifiers, case-specific probabilities are not shown. A class probability estimator is most useful, if it flags incorrect classifications as low confidence classifications. In other words: if a classifier produces confident class probabilities close to one, these should be correct classifications. In this article, we compare class probability estimators in the context of high-dimensional data-based diagnosis. We briefly review a selection of class probability estimators including those that are most frequently used in the context of gene expression analysis like Naive Bayes estimators or binary regression. In addition, we discuss alternative approaches from different fields of application like text categorization and digit recognition and adapt them to metabolomics analysis. We complement the pool of methods by a novel approach based on smooth local error rates. The approaches are compared on a recently published metabolomics dataset of patients with various types of kidney disease. We found that artifacts can compromise the utility of some frequently used methods. A widely observed problem is the dependence of classification probabilities on the number of features used in a diagnostic signature. The more features are used by a classifier, the more confident the classification probabilities, even in cases where the classification is incorrect. Moreover, class probabilities need to be estimated from test data or cross-validated classification scores since training scores display a better but unrealistic separation of classes. This overfitting phenomenon can greatly affect class probabilities. In our comparative metabolomics study, class probabilities derived from local error rates proved to be the method of choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CLASS PROBABILITY ESTIMATORS</head><p>We first review a selection of class probability estimators. In order to separate the class probability estimation problem from the classifier learning problem, we compare methods based on the same type of classifier. We chose a sparse linear classifier, which has been shown to be among the best-performing<ref type="bibr">[10:03 19/8/2011 Bioinformatics-btr434.tex]</ref>Page: 2564 2563–2570</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I.J.Appel et al.</head><p>algorithms in microarray two-class classification problems (<ref type="bibr" target="#b17">Wessels et al., 2005</ref>). Notations: let x ij be a data matrix with i = 1,2,...,m denoting features (metabolites) and j = 1,2,...,n denoting cases. Further let C k be a vector storing the true class membership (disease types) of cases. The end product of all linear classification algorithms is a classification that assigns a case to Class 1 if s(x) &lt; 0 and otherwise to Class 2, where x = (x 1 ,x 2 ,...,x p ) is the vector of intensity values of p signature features, w = (w 1 ,w 2 ,...,w p ) a vector of corresponding feature weights and s(x) = w,x−b with distance to the origin b. Note that the vector w spans a line orthogonal to the separating hyperplane, w,x is the orthogonal projection of profile x onto this line and s(x) the distance of x to the hyperplane. Intuitively, cases that fall closer to the separating hyperplane are less reliably classified than those that are further away.<ref type="bibr" target="#b16">Tibshirani et al. (2002)</ref>proposed a method for class prediction in DNA microarray studies based on nearest shrunken centroids. Each class k is represented by a shrunken centroid ¯ x k and a case x is assigned to the class with the nearest centroid. Formally, the discriminant score</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naive Bayes Estimates (NB):</head><formula>δ k (x) = p i=1 (x i −¯ x ik ) 2 σ 2 i −2·logπ k</formula><p>is calculated independently for each class, where the sum runs over all genes with non-zero weights after shrinkage , σ i is the pooled within-class SD of gene i and π k the estimated proportion of cases from class k in the entire population. A case is assigned to the group k with minimal δ k (x). Classification probabilities are derived from the δ k (x) by</p><formula>p k (x) = e − 1 2 δ k (x) e − 1 2 ·δ 1 (x) +e − 1 2 ·δ 2 (x) .</formula><formula>(1)</formula><p>Note that the nearest shrunken centroid classification rule defines a separating hyperplane with normal vector w.</p><p>In this approach, every gene in the classifier is assumed to contribute independent evidence as to whether the case x belongs to class k or not. This assumption is mostly not justified biologically and produces artifacts that will be discussed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compound</head><formula>p k (x) = φ 1 (s(x); ˆ µ 1 , ˆ σ 2 1 ) φ 1 (s(x); ˆ µ 1 , ˆ σ 2 1 )+φ 2 (s(x); ˆ µ 2 , ˆ σ 2 2 )</formula><p>where φ(x;µ,σ 2 ) represents the normal density function with mean µ and variance σ 2. The four parametersˆµparametersˆ parametersˆµ 1 , ˆ µ 2 , ˆ σ 1 , ˆ σ 2 are estimated from the projected data s(x j ). Binary Regression (BReg): another well-established approach is binary regression, which has many ramifications some of which have been applied to genomic data (<ref type="bibr" target="#b6">de Hoon et al., 2004;</ref><ref type="bibr" target="#b18">West et al., 2001</ref>). In our evaluation here, we represent the class of binary regression models by the approach described in<ref type="bibr" target="#b14">Platt (2000)</ref>, which fits the logistic model p k (s(x)) = 1 1+e A·s(x)+B by minimizing a cross-entropy error function to adjust the parameters A and B. Although<ref type="bibr" target="#b14">Platt (2000)</ref>use this estimator in combination with linear and non-linear support vector machines, it can also be used together with our linear classifiers without changes, since the regression simply operates on a set of precalculated classification scores s(x j ) without exploiting any properties implied by the method that generated these scores. Local Error Frequencys<ref type="bibr">[LEF(Bin)</ref>]: if the shape of the regression function that relates classification scores to class probabilities is unknown, it can be estimated from local misclassification frequencies. Zadrozny and Elkan (2002) sort cases by the scores s(x j ) and split them into equally sized disjoint bins. The local class k frequency F k (x) of case x is then calculated as the relative frequency of class k cases that fall into the same bin as x. The estimates F k (x j ) do not need to be strictly monotonous in s(x j ). Hence, a few cases that are closer to the separating hyperplane might be judged more reliably classified than some of those that are further away from it, in contrast to intuition. To assure monotonicity, Zadrozny and Elkan (2002) use monotone regression as implemented in the pair-adjacent violators algorithm (PAVA) (<ref type="bibr" target="#b1">Ayer et al., 1955</ref>). PAVA replaces F k (x j ) and F k (x j+1 ) with their average when the monotonicity constraint is violated. This averaging process is continued until an ordered set of probabilities is obtained. Note that local misclassification frequencies do not need to be combined with the PAVA algorithm but can be combined with any regression method. As with previous methods, it needs to be noted that the original work by Zadrozny and<ref type="bibr" target="#b20">Elkan (2002)</ref>used the estimator in combination with a different classification algorithm (decision trees). However, since this method is also based only on post-processing classification scores, it can be used in the linear classifier context as well.</p><p>Smooth Local Error Frequencies<ref type="bibr">[LEF(Smooth)</ref>]: a drawback of the binning approach is its coarseness. All cases in a bin receive the same local error frequency estimate F k (x) regardless of where they fall in the bin, and scores in the same bin can vary substantially. While the monotone regression step is partly compensating for this artefact, we argue that it cannot fully adjust for the binning effect and more smooth estimates of F k (x j ) are needed. Next we will describe two modifications of the LEF concept that combine monotone regression with smooth estimates of local error frequencies. We propose to use Gaussian smoothing kernels</p><formula>K(s(x j )) = 1 √ 2πλ 2 exp − (s(x j )−s(x)</formula><p>) 2 2λ 2 to estimate the local error frequencies F k (x) by</p><formula>F k (x) = j∈C k K(s(x j )) j K(s(x j )) .</formula><p>The bandwidth λ is the same for all cases x j (one fits all approach). It is a tuning parameter whose calibration will be discussed in the next section. Note that the kernels are centered at s(x) and that the classification accuracy of the algorithm for cases with scores similar to s(x) still determines the local error frequencies. Different to the binning approach, the actual distances of neighboring cases are now taken into account. Once the local error rates are estimated, we proceed like in the binning method of Zadrozny and Elkan (2002). We use monotone regression on the F k (x j ) employing the PAVA algorithm to achieve class probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive Local</head><p>Error Frequencies<ref type="bibr">[LEF(Adapt)</ref>]: this constant λ assumption is problematic, if the density of scores s(x j ) is far from uniform. For these situations, we propose an adaptive estimator of F k (x j ). We propose to use the neighborhood adaptive Gaussian smoothing kernels</p><formula>K x j ,l (s(x j )) = 1 2πλ(x,l) 2 exp − (s(x j )−s(x)) 2 2λ(x,l) 2 .</formula><p>Note that the kernels are centered at s(x) and that their bandwidths depend on a tuning parameter l and vary across cases. The bandwidth λ is adapted to the local density of scores around s(x). It is narrower in regions where we have many cases with similar scores s(x j ). We achieve this by setting λ(x,l)</p><p>Page: 2565 2563–2570In the innermost loop, the class probability function CPF is optimized, in the next loop classifier sparsity is tuned and in the outermost loop validation is performed. The different loops are marked by the size of the corresponding bars. Note that in the Figure, each loop is further separated into different rows to indicate that data present in that loop are split several times in training and test data to ensure that all data of a specific loop are used once for testing. The outermost loop contains all data, of this the training data of the outermost loop are passed to the middle loop where the passed data are split again in training and test data and the training data of the middle loop are transferred to the innermost loop where again a splitting in training and test data is performed. (B) Shows estimated classification probabilities for cross-validated scores for method LEF(Adapt) exemplarily. The stripes on the x-axis show the cross-validated classification scores s(x j ) from ADPKD patients (top) and healthy donors (bottom). equal to the empirical variance of the l nearest neighbors of s(x). We will discuss tuning of the parameter l in the next section. The adaptation of the kernel bandwidths ensures that the local error frequencies are supported by roughly the same number of neighboring cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimating classification probabilities</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and validating class probability functions:</head><p>the end product of all methods is always an estimated class probability function (CPF) p k (s(x)) that maps the score s(x) to a number between 0 and 1 that we interpret as the probability that case x is in class k. The CPF needs to be trained on sets of classification scores. Training includes the estimation of distribution parameters like the class means and variances in the Compound Bayes Estimator, the regression parameters A and B of the binary regression approach or the local error frequencies F k (x j ) and the non-parametric regression curves resulting from monotone regression. In addition, training might depend on tuning parameters like the number of bins, the bandwidth of a Gaussian kernel, or the number of nearest neighbors in the adaptive LEF approach. Once a CPF is estimated, it can be used to predict classification probabilities of test cases x j by first calculating the scores s(x j ) using a linear classifier and then plugging them into a CPF to gain the class probability</p><formula>p k (s(x j )</formula><p>). This requires a CPF and a classifier and both need to be previously learned from data. It is important that the test cases x j were not included in any of these learning processes. With respect to CPF estimation, it is important to distinguish between training scores s(x j ) and test scores s(x j ), since it is known that their distributions can be greatly different (<ref type="bibr">Ambroise and McLachlan, 2002</ref>). Compared to test scores, training scores display a better but unrealistic separation of classes. This overfitting phenomenon can greatly affect the estimated CPFs as we will show in the next section. Here, we use a 3-fold nested cross-validation that covers the processes of classifier estimation, CPF estimation, parameter tuning and evaluation. Parameters that need to be calibrated include the tuning parameters of the local error frequency approaches, which we call and the shrinkage parameter of the nearest shrunken centroid classification algorithm that controls the sparsity of the classifier.</p><p>(1) CPF estimation In the most inner loop is fixed. N 1 cases are left out and the remaining cases are used to learn a classifier, which is applied to the leftout cases yielding scores s (x j ). By leaving out all cases in turn, we achieve cross-validated scores for all cases that entered the most inner cross-validation loop. A CPF is estimated from these scores for a variety of values of the parameter. For each value, the</p><formula>p , k</formula><p>(x j ) are computed using one of the methods described above. They are evaluated with respect to their classification performance by calculating the negative log-likelihood of true classes</p><formula>−log(L()) =− k j∈C k logp , k (x j ) (2)</formula><p>The with minimal −log(L) is chosen and the corresponding CPF p k (·) is returned to the middle cross-validation loop.</p><p>(2) Tuning classifier sparsity In the middle loop, N 2 cases are left out. The remaining cases are forwarded to the inner loop varying. For every , the inner loop returns a CPF p k (·) which is applied to the leftout cases of the middle loop. These are evaluated by their misclassification rate and the optimal value of and with it the optimal number of features is determined. The optimized CPF p k (·) is returned to the outer loop.</p><p>(3) Validation In the outer loop N 3 cases are left out. The remaining cases are forwarded to the middle loop, which returns a CPF p k (·) to be applied to the leftout cases. Finally, this leaves a set of cross-validated probabilities p k (x j ) which we will next evaluate with respect to different criteria.</p><p>Our design allows different CPF estimation procedures to use different numbers of features for classification. This is enabled by the middle crossvalidation loop. This is important since some CPF estimators for instance the PAM estimator are sensitive to the number of features. Our entire crossvalidation design is summarized in<ref type="figure" target="#fig_0">Figure 1</ref>. For data used here, we set</p><formula>N 1 = 1, and N 2 = N 3 = 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We compared the class probability estimators in the context of a recently published metabolomic profiling study on kidney diseases (<ref type="bibr" target="#b5">Gronwald et al., 2011</ref>). The dataset comprised 168 urine samples measured using 1D nuclear magnetic resonance (NMR) spectroscopy. 54 samples were obtained from patients with autosomal polycystic kidney disease. The challenge is to separate them from samples taken from healthy volunteersfrom patients 3 months after renal transplantation). More details on the composition of cases in the study can be found in<ref type="figure" target="#tab_1">Table 1</ref>. NMR 1D spectra were split into 701 equally sized buckets and globally normalized to the signal of the CH 2 group of creatinine to ensure sample to sample comparability. Furthermore, compatibility across metabolites was ensured by applying the glog transformation (<ref type="bibr" target="#b13">Parsons et al., 2007</ref>). For full details of sample preparation and data preprocessing see<ref type="bibr" target="#b5">Gronwald et al. (2011)</ref>. We learned a shrunken centroid classifier aiming at the separation of ADPKD patients and healthy controls. Across all patients, we observe a classification performance of 76% correct classification in cross-validation.<ref type="figure" target="#fig_0">Figure 1B</ref>resolves this classification performance further. The ticks on the x-axis show the cross-validated classification scores s(x j ) from ADPKD patients (top) and healthy donors (bottom). In line with the global performance of only 76%, one can observe that there is no perfect separation of the two groups. Scores between −0.96 and +0.86 can be observed in both classes. The separating hyperplane lies in the middle of these points. It assigns 41 of them to the ADPKD class and 40 to the healthy donor class. Confined to this range of scores, the classifier has a performance of 71% correct classifications. These diagnoses should be flagged 'unreliable'. However, scores &gt; 0.86 are only found among ADPKD patients and hence reliably indicate that a patient suffers from ADPKD. Identifying this group of patients boils down to estimating ADPKD probabilities for all patients. The y-axis exemplarily shows such estimates obtained using a local error frequency approach<ref type="bibr">[LEF(Adapt)]</ref>. All patients with a score &gt; 0.93 receive probabilities close to one indicating their reliable classification as ADPKD positives. Patients with scores between −0.97 and +0.22 obtain probabilities between 0.2 and 0.8 flagging them as problematic classifications. We next compare the six CPF estimators, Naive Bayes (NB), Compound Bayes (CB), binary regression (BReg) and the local error frequency methods (LEF(Bin), LEF(Smooth), LEF(Adapt)), with respect to several criteria including modification of classification performance, sparseness bias, calibration and the performance in identifying reliable classifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modification of classification performance</head><p>Qualitative classifications can be obtained directly from the linear classifier. No CPF estimation is necessary. Nevertheless, once a CPF is estimated it is natural to assign cases with a class probability p k (x j )For each patient group, comparison (rows) performances are listed for each estimation method. The assignment of patient groups to the indices can be found in<ref type="figure" target="#tab_1">Table 1</ref>. &gt;0.5 to class k and those with probabilities &lt;0.5 to the other class. This might lead to a reassignment of some cases, as in the example shown in<ref type="figure" target="#fig_0">Figure 1</ref>where 14 cases were reassigned.<ref type="figure" target="#tab_2">Table 2</ref>shows the global classification performance in several pairwise classifications using the plain shrunken centroid classifier [equal to the Naive Bayes (NB) estimator] and its modifications resulting from the different CPF estimators. For group sizes, see<ref type="figure" target="#tab_1">Table 1</ref>. The local error frequency method LEF(Adapt) reaches the highest average performance of 81.7%, followed by binary regression (BReg) and LEF(Bin) with 81.5 and 81.1%, respectively. Overall, the classification accuracies of all CPF estimators differ 3.6–5.7% depending on the pair of groups.<ref type="figure" target="#tab_2">Table 2</ref>also shows that the performance of a given method depends on the investigated pair of groups. Therein, CB, BReg and LEF(Adapt) won most frequently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sparseness bias</head><p>Estimated class probabilities should not depend on the number of features used by the classifier except for reflecting shifts in the overlaps of scores.<ref type="figure" target="#fig_1">Figure 2</ref>shows discriminant scores and a PAMbased CPF (NB) of a 5 feature and a 200 feature classifier. In order to ensure comparability, discriminant scores are standardized to mean zero and SD one. Both refer to a comparison of ADPKD patients with healthy donors. One can observe that the overlap of scores only marginally changes for the two classifiers. However, the estimated CPFs change dramatically. For the 5 feature curve, all patients receive probabilities between 0.35 and 0.70 flagging them all as unreliable. This result does not reflect the score distributions well. In contrast, for the 200 features curve all probabilities are either close to 0 or close to 1. Hence, the curve considers all classifications reliable, which is misleading given the mix of classes in cases with scores between −1.1 and +1. The PAM estimator (NB) has an obvious sparseness bias. The more features are included in a classifier, the more confident the estimator becomes regardless of how the classes overlap. We next investigate to which extent the individual methods suffer from such a sparseness bias.<ref type="figure" target="#fig_2">Figure 3</ref>shows scatter plots of estimated probabilities for classifiers including different numbers of metabolites. For each number of features, the class probabilities of all cases are subtracted Page: 2567 2563–2570</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimating classification probabilities</head><p>by those obtained for the same patient by the 2 feature classifier. The differences (y-axis) are plotted against the number of features (x-axis, logarithmic). The density of points in the scatter plots is coded on a gray scale with dark regions indicating high density. The first plot clearly shows the sparseness bias of the PAM approach (NB). The two gene classifier gives probabilities ∼0.5. This is kept up for classifiers up to 10 features. Classifiers with many features produce probabilities near 0 or 1 leading to differences of ±0.5. This effect becomes manifest for classifiers with 75 features or more. None of the other methods showed this behavior.Although differences of class probabilities can reach high values, there is no systematic sparseness bias observable. For the Compound Bayes estimator and the binary regression estimator, the majority of differences stay close to zero. For the local error rate-based methods, the differences are greater but also here we do not observe a systematic trend towards more self-confident probabilities when more features are included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Calibration</head><p>A straightforward criterion to evaluate probability estimators is calibration. An estimator is well calibrated, if in the long run the relative frequency of true classifications of cases with estimated class probabilities falling in a small interval [p 0 −,p 0 +] is close to the estimated probability p 0 (<ref type="bibr" target="#b2">Dawid, 1982</ref>). The ADPKD dataset is not large enough to test long run performance. That is why we simulated data with structures similar to the ADPKD data for the comparison of the ADPKD patients and healthy controls. Therein, pairs of samples (x 1 ,x 2 ) were drawn randomly from the original dataset and sample x 1 was shifted on the line spanned by samples</p><formula>x 1 and x 2 such that x 1 = x 1 +β ·(x 2 −x 1 ) where β ∈[−1,1]</formula><p>. This procedure was repeated, for each class separately, until the simulated dataset was of the same size as the original one. In this way, 30 datasets were simulated and compared in terms of calibration.<ref type="figure" target="#fig_3">Figure 4A</ref>compares estimated class probabilities to long run classification accuracies. Both estimated error probabilities and observed error frequencies were collected in bins of width 0.1. If the classifier is well calibrated, all points fall close to the x = y line. Root mean square errors (RMSE) from this line quantify the calibration of the estimator. We found that the RMSE was large for the Compound Bayes estimator and for binary regression whileit was decreased by a factor of up to 6 for the local estimation methods, indicating that the local estimators are better calibrated. To test whether calibration depends on the number of samples used for estimator training, we rerun our evaluation for sample sizes between 100 and 3200.<ref type="figure" target="#fig_3">Figure 4B</ref>shows that in our study the RMSE values remain relatively constant, and that local estimators outperform the competing methods independent of the sample size, contrary to Niculescu-Mizil and Caruana (2005) who report a superior performance of the binary regression estimator for datasets with less then 1000 samples in the domain of text classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Variance of estimators</head><p>Another criterion for estimator evaluation is the variance of the estimator with respect to sampling. Typically, flexibility of an estimator comes at the price of increased variance. The binary regression approach is the most rigid in our collection with only two adjustable parameters. Compound Bayes has four parameters, while the non-parametric local estimators seem to be the most flexible ones. Here, we assess the variance of probability estimators across multiple simulation runs. For this purpose, the original data of ADPKD patients and healthy controls were enclosed as test set in the outer loop of the cross-validation scheme within all simulation runs (from Section 3.3). Hence, each case was predicted number of outer folds multiplied by the number of simulated datasets times for each CPF method. For each fold, a variance was calculated for each case across simulations. Finally, the median variance of each case across folds and methods was evaluated. Thus, we assess the variance for each sample individually.<ref type="figure" target="#fig_3">Figure 4C</ref>shows box plots of the variance of estimated class probabilities across all samples. We observed that the variance was smallest for the binary regression estimator followed by the Compound Bayes method and larger for the local error estimators, which is not surprising given the increased flexibility of these estimators. Moreover, we observed that the local estimators displayed a wider range of variances across samples showing high variance for samples in the gray zones between classes. To test for the dependency of estimator variances on the size of the study, we drew random samples of cross-validated scores of ADPKD and healthy patients and re-estimated class probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 2569 2563–2570</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimating classification probabilities</head><p>The subsampled group sizes varied from 3 to 45 samples (about group size of healthy patients) and we drew 1000 random subsets per study size. The number of features was fixed to 50 in analogy to<ref type="bibr" target="#b5">Gronwald et al. (2011)</ref>. For each study size, every sample receives multiple probability estimates which are summarized into a variance for each sample. Figures 4D and E show the maximum and the median of these variances, respectively. We observed that the maximal and median variance was smallest for the binary regression method uniformly across study sizes. The Compound Bayes performed very poorly for small group sizes of three and five samples, but improved rapidly with studies getting bigger. The variances of the local error frequency-based methods were acceptable also for small studies but decreased only very slowly with studies getting larger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Identifying reliable classifications</head><p>The ultimate goal of class probability estimation is the identification of those samples that can be reliably classified. Misclassifications should be rare among samples with high class probabilities. This property of an estimator is related to calibration in that we relate long run misclassification rates with estimated probabilities. However, the focus here is on extreme probabilities only. If an estimator is poorly calibrated for probabilities around 0.5, this is less of a problem since clinicians would not base treatment decisions on classifications that are labeled unreliable. If however, an estimated probability is close to 1, it must be reliable since a clinician might want to adjust treatment decisions based on this diagnostic result. Moreover, there is a trade-off between the reliability of a diagnosis and the number of samples that receive class probabilities close to 1. An estimator might assign extreme probabilities only to a small number of cases thus obtaining very low misclassification rates among these cases. However, this estimator might also miss many cases that could actually be reliably classified.<ref type="figure" target="#fig_3">Figure 4F</ref>shows the trade-off between the percentage of correct classifications and unclassified cases. Confidence threshold α is varied from 0.5 to 1. Samples below the threshold are left unclassified (x-axis), whereas the percentage of correct classifications is computed among samples above α (y-axis). We observed that the percentage of correct classifications of the local methods does not fluctuate as much as that of the Compound Bayes and binary regression. More importantly, the local methods reached 100% correct classifications faster than the others. For α = 0.90 (indicated by the vertical dashed lines in<ref type="figure" target="#fig_3">Fig. 4D</ref>), Compound Bayes left 76% of samples unclassified with 87.5% correct classifications, 2.5% below the confidence level and binary regression left 85% unclassified being 100% sensitive. The local methods left 78–81% cases unclassified and classified the remaining samples correctly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. (A) Schematically shows the 3-fold nested cross-validation. In the innermost loop, the class probability function CPF is optimized, in the next loop classifier sparsity is tuned and in the outermost loop validation is performed. The different loops are marked by the size of the corresponding bars. Note that in the Figure, each loop is further separated into different rows to indicate that data present in that loop are split several times in training and test data to ensure that all data of a specific loop are used once for testing. The outermost loop contains all data, of this the training data of the outermost loop are passed to the middle loop where the passed data are split again in training and test data and the training data of the middle loop are transferred to the innermost loop where again a splitting in training and test data is performed. (B) Shows estimated classification probabilities for cross-validated scores for method LEF(Adapt) exemplarily. The stripes on the x-axis show the cross-validated classification scores s(x j ) from ADPKD patients (top) and healthy donors (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Scores of a 5 feature classifier (gray) and a 200 feature estimator (black) together with a CPF estimated by the PAM approach are shown. Scores on the x-axis were standardized to mean zero and SD 1 for comparing CPFs directly. Cross-validated scores are indicated as gray and black stripes for the comparison of ADPKD patients (top) and healthy controls (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Smoothed scatter plots of estimated probabilities for classifiers including different numbers of metabolites. For each patient, the class probability of the 2 feature classifier was subtracted from probabilities for all numbers of features for the given patient. The differences (y-axis) are plotted against the number of features (x-axis, logarithmic). The density of points in the scatter plots is coded on a gray scale with dark regions indicating high density.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. (A) Estimated class probabilities to long run classification accuracies are shown in a reliability diagram. Both estimated error probabilities (x-axis) and observed error frequencies (y-axis) were collected in bins of width 0.1. If the classifier is well calibrated, all points fall close to the x = y line. Root mean square errors (RMSE) from this line quantify the calibration of the estimator. (B) Calibration of CPFs with increasing sample size. To test whether calibration depends on the number of samples used for estimator training, the evaluation of calibration was repeated for sample sizes between 100 and 3200 and RMSEs were plotted for all CPFs with increasing sample size. (C) Variance of probability estimators across multiple simulation runs. Variances were calculated across cross-validation folds and simulation runs while the box plots displays the distribution of these variances across cases. (D) and (E) Dependency of the variance of estimated probabilities on the size of the study. Shown are the maximal (D) and median (E) variance across cases. (F) Reliability of classifications with increasing confidence level α. α is varied from 0.5 to 1 estimated probability. Samples below the threshold are left unclassified (x-axis), whereas the percentage of correct classifications is computed among samples above α (y-axis). The vertical dashed lines indicate the 90% confidence level for the different CPF estimators.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>i = 2·(¯ x i1 −¯ x i2 ) σ 2 i , and Equation (1) can be</figDesc><table>translated to 

p k (x) = 
1 

1+e − 1 

2 ·s(x) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>) instead of the multidimensional distributions of the original data x j. Given a separating hyperplane with normal vector w and associated classification scores s(x j ) = w,x j −b, one assumes that the s(x j ) are distributed normally in both classes with possibly different means µ k and SDs σ k. Bayes rule yields</figDesc><table>Bayes Estimates (CB): Wright et al. (2003) introduced 
Compound Bayes Estimates to microarray analysis. In line with the 
PAM approach, the CB estimator models both classes individually using 
normal distributions. However, unlike the PAM approach the CB estimator 
models the 1D distributions of the projected data s(x j </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>(46 samples), and samples from patients with compromised kidney function but no ADPKD (52 samples from diabetes mellitus patients and 16 samples</figDesc><table>Page: 2566 2563–2570 

I.J.Appel et al. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 1. Patient groups defined within the ADPKD dataset Groups 1A and 1B correspond to ADPKD patients with and without medication for arterial hypertension, Group 2 consists of healthy volunteers. Patients 3 months after renal transplantation without rejection are assigned to Group 3 and diabetes mellitus type 2 patients with and without microalbuminuria are in Groups 4 and 5, respectively.</figDesc><table>Description 
Index 
Size 

ADPKD 
1 
54 
ADPKD with medication 
1A 
35 
ADPKD without medication 
1B 
19 
Healthy 
2 
46 
Other CKD 
Renal transplant without rejection 
3 
16 
Diabetes with microalbuminuria 
4 
30 
Diabetes without microalbuminuria 
5 
22 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 2. Classification performances of the outer cross-validation loop for the six probability estimation methods, Naive Bayes (NB), Compound Bayes (CB), binary regression (BReg) and the local error frequency methods using binning (Bin) and smoothing (Smooth/Adapt)</figDesc><table>Group comparison 
Classification performance 

NB 
CB 
BReg Bin 
Smooth Adapt 

1 
2 
76.0 75.0 76.0 
71.0 74.0 
76.0 
1 
3 
97.1 95.7 92.9 
97.1 97.1 
98.6 
1 
4 
82.1 82.1 85.7 
88.1 85.7 
85.7 
1 
5 
82.9 88.2 86.8 
85.5 84.2 
85.5 
1 
2,3,4,5 
75.0 78.6 76.8 
76.2 76.8 
76.2 
1A 2 
86.4 86.4 86.4 
85.2 80.2 
84.0 
1B 2 
63.1 60.0 66.2 
64.7 64.6 
66.2 
Average 
80.4 80.9 81.5 
81.1 80.4 
81.7 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="4"> DISCUSSION Before a clinician decides on the treatment of a patient, the reliability of the diagnosis must be assessed. In machine learning, reliability can be expressed in terms of classification probabilities. Since little attention has been given to the usefulness of probability estimates so far, we have compared a selection of class probability estimators including Naive Bayes methods, binary regression and local error-based methods in the context of metabolomics-based diagnosis of disease. We found that local error-based estimators show superior performance for instance to more widely used methods, the PAM program, binary regression and Compound Bayes classifiers. Strikingly, the PAM approach displayed a strong sparseness bias. We do not recommend its use in clinical diagnosis. Binary regression-based estimators display the least variance, but are inferior with respect to all other criteria evaluated here. A collection of three local error-based estimators performed best overall with only marginal differences between the individual implementations. We conclude that this type of approach is the method of choice. The computation time of the entire study is rather large due to three nested cross-validation loops combined with multiple simulation runs. For a practical use of the method, the determining factor is the estimation of class probabilities, which is much faster and corresponds to the innermost loop of the nested cross-validation scheme. The CPU times of an Intel Xeon E5320 1.86 GHz processor at a group size of 45 samples were 0.03, 1.54, 2.32, 2.92 and 9.24 seconds for Compound Bayes, LEF(Smooth), LEF(Adapt), binary regression and LEF(Bin), respectively. Although the present study is confined to metabolomics data, we believe that similar results can be obtained for different forms of clinical diagnosis based on high-dimensional genome size readouts, e.g. proteomic or transcriptomic profiling data. Note, that from the perspective of CPF estimation the effective dimensionality is that of the signature and not that of the original dataset. The dimensionality of gene expression-based signatures described in the literature is well comparable to that of our metabolomics study. We believe that translational science will profit from further research on class probability estimation in the various contexts of omics data.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors would like to thank Ann-Kathrin Immervoll and Matthias S. Klein for sample preparation and measurement. For provision of urinary samples, we thank Bernhard Banas, Carsten A. Böger, Kai-Uwe Eckardt, Stephan Reinhold, Bernd-Detlef Schulze and Raoul Zeltner. We thank the group members Claudio Lottaz, Tully Ernst and Peter Butzhammer of the Statistical Bioinformatics Department, University of Regensburg, for fruitful discussions on the manuscript.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Selection bias in gene extraction on the basis of microarray gene-expression data</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ambroise</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="6562" to="6566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">An empirical distribution function for sampling with incomplete information</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ayer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Stat</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="641" to="647" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">The well-calibrated Bayesian</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">P</forename>
				<surname>Dawid</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="605" to="610" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparison of discrimination methods for the classification of tumors using gene expression data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dudoit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">DNA microarrays are predictive of cancer prognosis: a reevaluation</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Fan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="629" to="636" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Detection of autosomal dominant polycystic kidney disease by NMR spectroscopic fingerprinting of urine</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Gronwald</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kidney Int</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1244" to="1253" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Predicting gene regulation by sigma factors in Bacillus subtilis from genome-wide data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J L</forename>
				<surname>De Hoon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="101" to="108" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2570" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Appel</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">The MicroArray Quality Control (MAQC)-II study of common practices for the development and validation of microarray-based predictive models</title>
		<author>
			<persName>
				<forename type="first">Maqc</forename>
				<surname>Consortium</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="827" to="838" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Interpretation of microarray data in cancer</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Michiels</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br. J. Cancer</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1155" to="1158" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Predicting good probabilities with supervised learning</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Niculescu-Mizil</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Caruana</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;05: Proceedings of the 22nd International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved classification accuracy in 1-and 2-dimensional NMR metabolomics data using the variance stabilising generalised logarithm transformation</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">M</forename>
				<surname>Parsons</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">234</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">Advances in large margin classifiers Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Platt</surname>
			</persName>
		</author>
		<editor>Smola,A. et al.</editor>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="61" to="74" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Taking gene-expression profiling to the clinic: when will molecular signatures become relevant to patient care?</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sotiriou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Piccart</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Cancer</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="545" to="553" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Diagnosis of multiple cancer types by shrunken centroids of gene expression</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="6567" to="6572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">A protocol for building and evaluating predictors of disease state based on microarray data</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wessels</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3755" to="3762" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting the clinical status of human breast cancer by using gene expression profiles</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>West</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 98</title>
		<meeting>. Natl Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="11462" to="11467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A gene expression-based method to diagnose clinically distinct subgroups of diffuse large B cell lymphoma</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Wright</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="9991" to="9996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Transforming classifier scores into accurate multiclass probability estimates</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zadrozny</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Elkan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD&apos;02</title>
		<meeting><address><addrLine>Edmonton, Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="694" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Outcome prediction based on microarray analysis: a critical perspective on methods</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zervakis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>