
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis Toward a statistically explicit understanding of de novo sequence assembly</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Mark</forename>
								<surname>Howison</surname>
							</persName>
							<email>mhowison@brown.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Computation and Visualization</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Felipe</forename>
								<surname>Zapata</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Ecology and Evolutionary Biology</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02912</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Casey</forename>
								<forename type="middle">W</forename>
								<surname>Dunn</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Ecology and Evolutionary Biology</orgName>
								<orgName type="institution">Brown University</orgName>
								<address>
									<postCode>02912</postCode>
									<settlement>Providence</settlement>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis Toward a statistically explicit understanding of de novo sequence assembly</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">23</biblScope>
							<biblScope unit="page" from="2959" to="2963"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt525</idno>
					<note type="submission">Received on June 20, 2013; revised on July 25, 2013; accepted on September 2, 2013</note>
					<note>Associate Editor: Jonathan Wren Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Draft de novo genome assemblies are now available for many organisms. These assemblies are point estimates of the true genome sequences. Each is a specific hypothesis, drawn from among many alternative hypotheses, of the sequence of a genome. Assembly uncertainty, the inability to distinguish between multiple alternative assembly hypotheses, can be due to real variation between copies of the genome in the sample, errors and ambiguities in the sequenced data and assumptions and heuristics of the assemblers. Most assemblers select a single assembly according to ad hoc criteria, and do not yet report and quantify the uncertainty of their outputs. Those assemblers that do report uncertainty take different approaches to describing multiple assembly hypotheses and the support for each. Results: Here we review and examine the problem of representing and measuring uncertainty in assemblies. A promising recent development is the implementation of assemblers that are built according to explicit statistical models. Some new assembly methods, for example, estimate and maximize assembly likelihood. These advances, combined with technical advances in the representation of alternative assembly hypotheses, will lead to a more complete and biologically relevant understanding of assembly uncertainty. This will in turn facilitate the interpretation of downstream analyses and tests of specific biological hypotheses.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The low cost and increasing availability of next-generation sequencing data have driven a growing interest in methods and software tools for de novo genome assembly of short read sequences. Recent surveys of assembly tools (<ref type="bibr" target="#b8">Finotello et al., 2012;</ref><ref type="bibr" target="#b22">Miller et al., 2010</ref>), practical guides (<ref type="bibr" target="#b23">Nagarajan and Pop, 2013;</ref><ref type="bibr" target="#b25">Paszkiewicz and Studholme, 2010</ref>), competitions like the Assemblathon (<ref type="bibr" target="#b2">Bradnam et al., 2013;</ref><ref type="bibr" target="#b7">Earl et al., 2011</ref>) and benchmarking tools like GAGE (<ref type="bibr" target="#b30">Salzberg et al., 2012</ref>) highlight the diverse ecosystem of available assemblers. New data structures, algorithms and software tools for assembly continue to be published every month. Many investigators have claimed that it is now possible to assemble high quality genomes from next-generation sequencing data when using appropriate protocols and assembly methods (<ref type="bibr" target="#b11">Gnerre et al., 2011;</ref><ref type="bibr" target="#b18">Li et al., 2010;</ref><ref type="bibr" target="#b31">Schatz et al., 2010</ref>). Yet, others have expressed concern over the integrity of publicly available draft genomes assembled from such data. Some have described errors and shortcomings in specific draft assemblies (<ref type="bibr" target="#b0">Alkan et al., 2011;</ref><ref type="bibr" target="#b28">Ricker et al., 2012;</ref><ref type="bibr" target="#b29">Salzberg and Yorke, 2005</ref>), whereas others have questioned the quality of publicly available draft assemblies in general, and advocated better quality standards for the community (<ref type="bibr" target="#b4">Chain et al., 2009;</ref><ref type="bibr" target="#b20">Mardis et al., 2002</ref>). In particular, the Assemblathon 2 competition (<ref type="bibr" target="#b2">Bradnam et al., 2013</ref>) found large-scale inconsistencies among current assembly methods, suggesting they are not robust to changes in parameters and input data, and that there is a need for unambiguous measures of assembly uncertainty. A genome assembly is a hypothesis consisting of a collection of contigs (contiguous sequences) and scaffolds (groups of contigs with gaps of known length between them) that typically cover 90% or more of the genome (<ref type="bibr" target="#b4">Chain et al., 2009</ref>), but are often fragmented and unordered. Current de novo assemblers use various heuristics and algorithms to select an assembly that optimizes some criteria, such as path length or graph complexity (<ref type="bibr" target="#b22">Miller et al., 2010</ref>); however, these optimization criteria are typically ad hoc. This is largely because of the computational difficulty of performing assembly on short reads, and a primary goal for existing assembly methods has been computational tractability and efficiency. As a result, assemblers choose a single point estimate as their final output with sparse information about the quality, certainty or validity of the chosen assembly, or of alternative assembly hypotheses (many of which may have almost as much support). In most cases, it is difficult, if not impossible, to answer even basic questions like, 'How well is this contig supported by the read sequences?' or 'Are there alternative assemblies that have similar support from the data?' Downstream analysis tools use assemblies to make their own point estimates of other aspects of biology, such as multiple sequence alignments, differential gene expression analyses or phylogenetic trees. In the end, there is no accounting for how the uncertainty is compounded at each stage. Existing tools cannot be integrated into pipelines that propagate uncertainty through a large multistep analysis, for example integrating assembly uncertainty with tree uncertainty when constructing phylogenies. The ability to propagate uncertainty about point estimates or, preferably, to propagate entire sets of multiple alternative hypotheses will become increasingly important as analyses grow in complexity. *To whom correspondence should be addressed.Thanks to the progress on computational efficiency of genome assembly, it is now possible to tackle the difficult goal of placing de novo sequence assembly within an explicit statistical framework. In such a framework, single assembly hypotheses selected according to ad hoc optimality criteria are replaced by sets of hypotheses accompanied by statistics that summarize confidence in each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ÃŸ</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">VARIANTS IN ASSEMBLIES</head><p>Alternate assembly hypotheses are called variants. There are many types of variants, but they fall into two broad categories that we refer to as hard and soft: Hard variants correspond to real differences present in the sample. Hard variation can include heterozygosity, somatic polymorphism (as in the case of cancer), polymorphism across multiple individuals when they are pooled for sequencing or variation across individuals when they are sequenced and assembled separately but data are then combined across assemblies. Hard variants reflect aspects of organism biology that may or may not be of direct interest to the investigator. Soft variants are uncertainties that are introduced during the sequencing and assembly process, and include library preparation artifacts and sequencing errors. They persist when there is not enough information to resolve conflicts and identify the true assembly. Soft variants are nuisances that investigators seek to reduce or work around. Discerning between hard and soft variants presents difficult statistical and computational challenges, and is a fundamental difficulty for metagenome assembly in particular (<ref type="bibr" target="#b5">Charuvaka and Rangwala, 2011</ref>). Although hard and soft variants have different origins, they can both be described within a common statistical framework, as they both result in multiple assembly hypotheses. After this common framework is in place, the next challenge will be to differentiate between hard and soft variants, either by eliminating soft variation, or by learning to identify each. However this is ultimately addressed, the very existence of hard variation is a direct challenge to the expectation that there is a single true assembly that accurately represents an organism's genome. One of the best-studied types of hard variation is heterozygosity in diploid individuals. Provided enough depth of coverage, existing statistical methods can accurately identify alleles (<ref type="bibr" target="#b24">Nielsen et al., 2011</ref>). In the absence of enough coverage, though, it becomes difficult to differentiate true alleles from sequencing errors. The identification of alleles from different loci that are colocated on the same chromosome is called haplotype phasing. Phasing can be achieved computationally or experimentally (<ref type="bibr" target="#b3">Browning and Browning, 2011</ref>). Computational phasing requires population level sampling, which is uncommon in most studies of de novo genome assembly. Experimental phasing relies on laboratory techniques that are applied during data generation, such as developing fosmid libraries or separation of chromosomes. This approach incurs higher costs, and it usually involves additional computational phasing when phased haplotype fragments must be pieced together into larger haplotypes (<ref type="bibr" target="#b3">Browning and Browning, 2011</ref>). At present, phase information from sequencing reads is not sufficient to fully determine haplotype phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RECORDING VARIANTS</head><p>Some assemblers report variants in their output, though without any accompanying statistical interpretation or distinction between hard and soft variants. Although much of the focus has been on tools for single nucleotide polymorphism (SNP) detection, there is interest in larger-scale structural variants as well. Preserving and reporting ambiguities in the assembly is an important step toward assessing assembly uncertainty, especially if future computational methods can incorporate alternative assemblies. Assemblers that report variants include: ALLPATHS-LG (<ref type="bibr" target="#b11">Gnerre et al., 2011</ref>) has a custom intermediate output format for SNPs or homopolymers. For example, the output sequence TC{A,T}GG represents an SNP, and TT{,T,TT}AC represents a homopolymer. The authors note that making use of this information in downstream analyses is an important challenge for the field. The String Graph Assembler (SGA) (<ref type="bibr" target="#b32">Simpson and Durbin, 2012</ref>) retains variants that are not selected by the assembly algorithm, but instead of storing them in a custom format, writes them to a separate FASTA file that can be inspected after assembly. ABySS (<ref type="bibr" target="#b33">Simpson et al., 2009</ref>) similarly writes multiple variants and organizes them into two FASTA files, one for SNPs and the other for insertionsâ€“deletions. Cortex (<ref type="bibr" target="#b16">Iqbal et al., 2012</ref>) and fermi (<ref type="bibr" target="#b19">Li, 2012</ref>) are both designed to discover variants during assembly. Both show that structural variant detection can be improved by discovering variants during assembly rather than through simply mapping the assembly to a reference genome. In addition to advances in the assemblers themselves, there have also been improvements in data formats. The FASTG (<ref type="bibr" target="#b17">Jaffe et al., 2012</ref>) specification addresses the problem of storing complex polymorphisms and variants by using a graph representation for assembly output. Most assemblers' final output uses a linear FASTA representation, with a record for each contig or scaffold sequence. Although this format is compact, humanreadable and a suitable representation of a correct unambiguous assembly, in practice most assemblies include ambiguities that cannot be represented linearly. At the opposite extreme of the linear FASTA representation is the intermediate output provided by most assemblers that dumps out the complete unresolved graph structure produced during assembly. For most downstream applications, this output is too verbose and too raw: it might not even include the graph traversals chosen by the assembler's heuristics or algorithms as the final assembly. FASTG attempts a balance between these two extremes. It is an extension of the approach taken by ALLPATHS-LG, and specifies 'constructs' enclosed in brackets that can be inserted into a typical FASTA sequence to represent local non-linear features like gaps, alleles, tandem repeats or haplotypes. For example, the sequence GANNNNN[5:gap:sizeÂ¼(5,4..6)] CAGGC<ref type="bibr">[1:alt:alleleâ€”C,G]</ref>includes constructs for both a gap of 4â€“6 bases and an SNP with a similar proportion of C and G bases, which can therefore be interpreted as an allele. Another example of a richer description for assembly output is the 'gene graph', introduced by the GeneStitch (<ref type="bibr" target="#b36">Wu et al., 2012</ref>) method for reconciling and improving metagenomic assemblies. Using alignments against a reference genome, GeneStitch identifies clusters of gene fragments that are highly similar across the individual genomes within the metagenome. Instead of trying to separate the individual genes, GeneStitch merges them into a structure called a gene graph, which is a subgraph of the assembly graph that connects all the similar gene fragments. The gene graph is a condensed representation of the similar genes, and individual genes can be reconstructed by traversing paths through the gene graph. Another middle ground between linear representation and full assembly graph output is to simply enumerate the full set of possible assemblies, the approach that the SGA assembler takes when it writes alternative contigs to an auxiliary file. This is analogous to the approach taken by phylogenetic inference tools that generate sets of phylogenetic trees. An investigator will typically construct and report a consensus tree, which is a lossy summary of the full set of trees according to some statistical justification (<ref type="bibr" target="#b12">Holder et al., 2008</ref>). Similarly, an assembler could output the full set, but construct a consensus assembly for each contig. The full set of assemblies is inherently redundant, and could be compressed with generic text compression tools, like gzip. Although these representations are better suited to storing the variation in assembly output than FASTA, they do not address the statistical or computational problem of how to quantify the uncertainty of a given assembly hypothesis. We discuss existing approaches to these problems below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MIS-ASSEMBLY APPROACHES</head><p>Earlier efforts to automate assembly validation successfully applied statistical tests to identify 'mis-assemblies,' or regions of an assembly hypothesis that violate specific statistical assumptions. For instance, the amosvalidate tool (<ref type="bibr" target="#b26">Phillippy et al., 2008</ref>) uses the compression-expansion statistic (<ref type="bibr" target="#b37">Zimin et al., 2008</ref>) to identify regions of an assembly where paired-end reads align with insert sizes that deviate from an expected normal distribution. It also calculates statistics based on the overall read coverage, the distribution of k-mers and the presence of fragmented read alignments. More recently, the Recognition of Errors in Assemblies using Paired Reads (REAPR) tool (<ref type="bibr" target="#b15">Hunt et al., 2013</ref>) applied similar metrics of fragment coverage and insert-size distribution to identify mis-assembled regions, and introduced the ability to call errors at specific bases in an assembly hypothesis. Computationally, it decides which individual bases are 'error-free,' meaning that the base is supported by a specified number (by default 5) of perfectly and uniquely aligned reads, and that the difference between the theoretical and observed fragment coverage falls below a dynamically inferred threshold. Regions with erroneous bases are reported as mis-assemblies. The algorithm also distinguishes between contig and scaffolding errors, and can produce a new assembly where erroneous scaffolds are broken into separate contigs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LIKELIHOOD APPROACHES</head><p>In statistics, likelihood is the probability of the data if the data were generated according to a specified hypothesis. In the context of assembly, it is the probability of sequencing the observed reads under a specified assembly hypothesis and model of read generation. Maximum likelihood estimation attempts to identify the hypothesis that has the highest probability of producing the observed data. A maximum likelihood assembly is the assembly that has the highest likelihood. Maximum likelihood estimation does not itself provide a confidence interval on any particular hypothesis; it simply provides a way to find the hypothesis that maximizes the probability of the data. The assembly with the maximum likelihood may do a much better job than any other assembly at explaining the data, or there may be millions of other assemblies that are almost as likely. Even though a likelihood approach does not directly quantify assembly uncertainty, it provides an explicit framework with a clear statistical interpretation for optimizing and evaluating alternative assembly hypotheses. The Computing Genome Assembly Likelihoods (CGAL) tool (<ref type="bibr" target="#b27">Rahman and Pachter, 2013</ref>) approximates the likelihood of an assembly given the sequence reads and a generative model. To reduce computational burden, read generation is considered only in the region of the assembly where each read maps. The generative model incorporates separate terms for the length of a read pair and its aligned site on the genome, and an error model for SNPs, insertions and deletions. The generative model has to be learned from the data. Because the distribution of insert sizes for read pairs depends on both the sequencer and library preparation, CGAL uses the empirical distribution for the read pair lengths. For the distribution of sites, it assumes uniform sampling of read pairs across the genome. For the error model, it assumes sequencing errors are independent events and learns the substitution rates for each position and for each substitution combination (because there are known biases for some sequencing technologies), and the insertion and deletion rates for each position in a read sequence. The aggregate CGAL score for an assembly is the log of the product of the probabilities that each individual read could have been generated from the assembly. Although CGAL is not an assembler, it could be applied to optimizing assembly by using the annotated likelihood score to iteratively guide the selection of assemblies and parameter values. In fact, a maximum likelihood genome assembler was already proposed based on similar principles (<ref type="bibr" target="#b21">Medvedev et al., 2009</ref>). Like CGAL, it calculates likelihood based on the depth of read coverage, but it does not incorporate paired-end information at this stage. Instead, it takes the approach typical of many genome assemblers of first assembling the contigs, then resolving conflicts by looking for contigs that agree with the orientation and insert size of the paired reads. Also, it requires as a parameter the accurate size of the target genome, which is not available in all de novo assembly projects. A related design for maximum likelihood assembly (<ref type="bibr" target="#b35">Varma et al., 2011</ref>) uses a different formulation that starts from an approximate size and estimates the actual size during the optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">BAYESIAN APPROACHES</head><p>Instead of the probability that a given assembly hypothesis could have generated the sequenced data (i.e. the likelihood), an investigator may be more interested in the conditional probability of the assembly hypothesis after taking into account the sequenced data. This is the posterior probability, PÃ°HjDÃž, of the assembly hypothesis, and it is related to the likelihood, PÃ°DjHÃž, by the Bayes' theorem:</p><p>PÃ°HjDÃž Â¼ PÃ°DjHÃžÃ°PÃ°HÃžÃž PÃ°DÃž Ã°1Ãž where P(D) and P(H) are the prior probabilities on the data and the assembly hypothesis, respectively. The priors are the probability distributions that express the uncertainty before the data are taken into account. There is already at least one tool that considers posterior probabilities on assemblies, the Assembly Likelihood Evaluation (ALE) framework (<ref type="bibr" target="#b6">Clark et al., 2013</ref>). ALE implements an expression for the probability that an assembly is correct, and also reveals the contribution of local regions of the assembly to this score. This is an important advance toward assessing the uncertainty of assemblies, especially because it is made in the context of an explicit statistical framework rather than ad hoc optimality criteria. ALE estimates the posterior probability of an assembly (their PÃ°SjRÃž) by estimating the prior probabilities (their P(S)) directly from the data (i.e. an empirical Bayes approach) in conjunction with an approximation of the assembly likelihood (their PÃ°RjSÃž) in a similar fashion to CGAL. One of the most difficult aspects of calculating a posterior probability is deriving the prior probability of the read data, P(R) (that they denote as Z). They address this challenge with a rough but efficient approximation of Z. They then refer to the approximated posterior probability as the ALE score. The ALE score is a comparative measure of assembly correctness and should be compared among assemblies of the same genome from the same sequenced data. The ALE score cannot be calculated for different datasets because of the possible inaccuracy in approximating the prior probability of the data, which cancels out when computing a comparative score between difference assembly hypotheses of the same data. In contrast, CGAL could conceivably be used to compare the likelihood of an assembly hypothesis against different datasets (for instance, from different sequencing technologies) because it does not calculate the prior probabilities of the data. Markov chain Monte Carlo (MCMC) is an alternative approach to approximating posterior probabilities. Rather than approximate the posterior probability of a particular assembly as ALE does, an MCMC approach would generate a set of alternative assembly hypotheses. This provides a natural way to deal with assembly uncertainty. The frequency of a particular attribute of the assembly in this set is an approximation of the posterior probability of that attribute. In addition to deriving this probability, the investigator can also examine the other alternative hypotheses. An investigator could ask, for example, 'What are the most probable hypotheses for gene order that together account for 90% of the posterior probability?' To overcome the challenges of estimating the prior probability on the data, MCMC uses the ratios of posterior probabilities so that the prior probability on the data cancels out and does need to be calculated (for an introduction to MCMC, see<ref type="bibr">Gilks et al., 1996</ref>). MCMC methods have been applied to related problems, such as assembling the haplotype of resequenced human genomes (<ref type="bibr" target="#b1">Bansal et al., 2008</ref>). However, we do not know of a de novo assembly method that has used MCMC to generate a set of assembly hypotheses. Like maximum likelihood assembly, MCMC assembly will have significant technical challenges with computational cost and scalability because of the many samples needed to construct a stable posterior distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>The pieces are now falling in place for assembly to move away from point estimates that are selected according to ad hoc criteria, toward a statistically explicit framework that provides not only biologically relevant measures of certainty but also sets of alternative hypotheses. This will greatly facilitate the evaluation of assemblies, their application to specific biological questions, improvements in assembly algorithms and integration with downstream analyses that can then take assembly uncertainty into account. Bioinformatics workflow frameworks, such as the web-based framework Galaxy (<ref type="bibr" target="#b9">Giardine et al., 2005</ref>) and the lightweight command-line framework BioLite (<ref type="bibr" target="#b13">Howison et al., 2012</ref>), already provide biologists with functionality for establishing provenance and reproducibility for computational analyses. These workflow frameworks are the logical foundation for implementing pipelines that propagate uncertainty through complex multistage analyses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>One of the limitations of the maximum likelihood approach is that it relies on complex optimizations that are polynomial time in the number of read sequences, compared with the linear time algorithms used by most de Bruijn graph assemblers. Also, unlike most assembly methods described in the literature, neither the maximum likelihood methods by Medvedev et al. nor Varma et al. provide an open-source reference implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com</figDesc><table></table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">M.Howison et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Statistically explicit sequence assembly at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Limitations of next-generation genome sequence assembly</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Alkan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="61" to="65" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">An MCMC algorithm for haplotype assembly from wholegenome sequence data</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1336" to="1346" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">Assemblathon 2: evaluating de novo methods of genome assembly in three vertebrate species</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">R</forename>
				<surname>Bradnam</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Haplotype phasing: existing methods and new developments</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Browning</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Browning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="703" to="714" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Genome project standards in a new era of sequencing</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">S</forename>
				<surname>Chain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics Science</title>
		<imprint>
			<biblScope unit="volume">326</biblScope>
			<biblScope unit="page" from="236" to="237" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluation of short read metagenomic assembly</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Charuvaka</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Rangwala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">ALE: a generic assembly likelihood evaluation framework for assessing the accuracy of genome and metagenome assemblies</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">C</forename>
				<surname>Clark</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="435" to="443" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Assemblathon 1: a competitive assessment of de novo short read assembly methods</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Earl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2224" to="2241" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparative analysis of algorithms for whole-genome assembly of pyrosequencing data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Finotello</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="269" to="280" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Galaxy: a platform for interactive large-scale genome analysis</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Giardine</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1451" to="1455" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title level="m" type="main">Markov Chain Monte Carlo in Practice</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R</forename>
				<surname>Gilks</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Chapman and Hall/CRC</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">High-quality draft assemblies of mammalian genomes from massively parallel sequence data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gnerre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1513" to="1518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A justification for reporting the majority-rule consensus tree in Bayesian phylogenetics</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">T</forename>
				<surname>Holder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="814" to="821" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">BioLite, a lightweight bioinformatics framework with automated tracking of diagnostics and provenance</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Howison</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th USENIX Workshop on the Theory and Practice of Provenance</title>
		<meeting>the 4th USENIX Workshop on the Theory and Practice of Provenance</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Ma</forename>
				<surname>Boston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Usa</forename>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">REAPR: a universal tool for genome assembly evaluation</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hunt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">De novo assembly and genotyping of variants using colored de Bruijn graphs</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Iqbal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="226" to="232" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<monogr>
		<title level="m" type="main">The FASTG Format Specification (v1.00) http://fastg.sour ceforge.net/FASTG_Spec_v1</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">B</forename>
				<surname>Jaffe</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012-02-27" />
		</imprint>
	</monogr>
	<note>00. .pdf.. date. last accessed</note>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">State of the art de novo assembly of human genomes from massively parallel sequencing data</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Genomics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="271" to="277" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring single-sample SNP and INDEL calling with whole-genome de novo assembly</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1838" to="1844" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">What is finished, and why does it matter</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Mardis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="669" to="671" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Maximum likelihood genome assembly</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Medvedev</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Brudno</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1101" to="1116" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Assembly algorithms for next-generation sequencing data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Miller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="315" to="327" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequence assembly demystified</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Nagarajan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Pop</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="157" to="167" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Genotype and SNP calling from next-generation sequencing data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Nielsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="443" to="451" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">De novo assembly of short sequence reads</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Paszkiewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Studholme</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="457" to="472" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Genome assembly forensics: finding the elusive mis-assembly</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Phillippy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">CGAL: computing genome assembly likelihoods</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rahman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Pachter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">The limitations of draft assemblies for understanding prokaryotic adaptation and evolution</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Ricker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Beware of mis-assembled genomes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Salzberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Yorke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="4320" to="4321" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">GAGE: a critical evaluation of genome assemblies and assembly algorithms</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Salzberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="557" to="567" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Assembly of large genomes using second-generation sequencing</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">C</forename>
				<surname>Schatz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient de novo assembly of large genomes using compressed data structures</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="549" to="556" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<monogr>
		<title level="m" type="main">ABySS: a parallel assembler for short read sequence data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1117" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">An improved maximum likelihood formulation for accurate genome assembly</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st IEEE International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)</title>
		<meeting>the 1st IEEE International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)<address><addrLine>Orlando, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="165" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Stitching gene fragments with a network matching algorithm improves gene assembly for metagenomics</title>
		<author>
			<persName>
				<forename type="first">Y.-W</forename>
				<surname>Wu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="363" to="369" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Assembly reconciliation</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">V</forename>
				<surname>Zimin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="42" to="45" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>