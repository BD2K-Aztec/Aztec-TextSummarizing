
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gene expression Decoy-free protein-level false discovery rate estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Ben</forename>
								<surname>Teng</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116621</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ting</forename>
								<surname>Huang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116621</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Zengyou</forename>
								<surname>He</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Software</orgName>
								<orgName type="institution">Dalian University of Technology</orgName>
								<address>
									<postCode>116621</postCode>
									<settlement>Dalian</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gene expression Decoy-free protein-level false discovery rate estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">5</biblScope>
							<biblScope unit="page" from="675" to="681"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt431</idno>
					<note type="submission">Received on May 24, 2013; revised on July 14, 2013; accepted on July 20, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Martin Bishop Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Statistical validation of protein identifications is an important issue in shotgun proteomics. The false discovery rate (FDR) is a powerful statistical tool for evaluating the protein identification result. Several research efforts have been made for FDR estimation at the protein level. However, there are still certain drawbacks in the existing FDR estimation methods based on the target-decoy strategy. Results: In this article, we propose a decoy-free protein-level FDR estimation method. Under the null hypothesis that each candidate protein matches an identified peptide totally at random, we assign statistical significance to protein identifications in terms of the permutation P-value and use these P-values to calculate the FDR. Our method consists of three key steps: (i) generating random bipartite graphs with the same structure; (ii) calculating the protein scores on these random graphs; and (iii) calculating the permutation P value and final FDR. As it is time-consuming or prohibitive to execute the protein inference algorithms for thousands of times in step ii, we first train a linear regression model using the original bipartite graph and identification scores provided by the target inference algorithm. Then we use the learned regression model as a substitute of original protein inference method to predict protein scores on shuffled graphs. We test our method on six public available datasets. The results show that our method is comparable with those state-of-the-art algorithms in terms of estimation accuracy. Availability: The source code of our algorithm is available at: https:// sourceforge.net/projects/plfdr/</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Shotgun proteomics is a strategy that is capable of identifying complex protein mixtures by combining high-performance liquid chromatography and mass spectrometry (MS). In shotgun proteomics, the protein identification procedure has two main steps: peptide identification and protein inference (<ref type="bibr" target="#b8">Nesvizhskii et al., 2007</ref>). In peptide identification, we search the experimental MS/ MS spectra against a protein sequence database to obtain a set of peptide-spectrum matches. In protein inference, we report a set of proteins by assembling peptide identification results (<ref type="bibr" target="#b3">Huang et al., 2012</ref>). Basically, there are two major computational issues in protein identification that have to be solved. On one hand, we need to develop effective and fast identification/inference algorithms at both the peptide level and the protein level. On the other hand, controlling the quality of identified peptides and inferred proteins is as important as developing identification algorithms. Inferred proteins are more biologically relevant than identified peptides in a proteomics experiment. Therefore, it is vital to control the quality of identification results at the protein level. However, the accurate assessment of statistical significance of protein identifications remains an open question (<ref type="bibr" target="#b12">Spirin et al., 2011</ref>). To date, several research efforts have been made to estimate the protein-level error rate in terms of false discovery rate (FDR). The mainstream approach for FDR estimation is the target-decoy strategy, which searches a target-decoy concatenated database so that the number of false positive protein identifications can be estimated from the number of decoy proteins. For instance, the MAYU method (<ref type="bibr" target="#b11">Reiter et al., 2009</ref>) is a typical representative in this category. By adapting the target-decoy strategy to the protein inference task, the MAYU method first assumes that protein identifications containing false positive peptide-spectrum matches are uniformly distributed over the target database. Then, the number of false positive protein identifications is hypergeometrically distributed. As a result, the expected number of false positive protein identifications can be calculated as the probability weighted average. Finally, the protein identification FDR is computed as the ratio of the expected number of false positive protein identifications and the total amount of protein identifications mapping to the target database. However, this valuable approach has certain drawbacks (<ref type="bibr" target="#b5">Kim et al., 2008</ref>). First, searching both the target and the decoy database will certainly double the running time in the protein identification process. Second, the FDR estimation result may be unstable, as we usually use only one decoy database with the same size of target database. Finally, the protein FDR value is calculated according to the distribution of decoy peptides across different proteins, making it possible to propagate errors at the peptide level to the protein level in a non-trivial manner. In this article, we propose a new method for estimating the FDR at the protein level without searching the decoy database. Our method uses random permutation to assess the statistical significance of each protein in terms of P-value and then calculates the final FDR. First, the input for the protein inference problem can be modeled as a bipartite graph: the left is a set of identified peptides and the right is the set of candidate *To whom correspondence should be addressed. ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com proteins with at least one matched peptide (<ref type="bibr" target="#b3">Huang and He, 2012</ref>). From this bipartite graph, a protein inference algorithm calculates the probability or score for each protein. The null hypothesis in our method is that each candidate protein matches an identified peptide totally at random. Under this null hypothesis, we first create multiple random bipartite graphs with the same set of peptides and proteins. Each random bipartite graph has the same structure as the original one, i.e. each protein (peptide) is connected to the same number of peptides (proteins). Then, we run the same protein inference algorithm on these random bipartite graphs, and check if the score of each protein is significantly different on the real graph than on the randomized graphs. That is, we calculate the permutation P-value of one protein as the percentage of random graphs that produce a larger score than its original score. Finally, we sort the proteins according to their P-values and calculate the FDR at different thresholds with permutation P-values as input using the method in Storey and Tibshirani (2003). Our method has three key steps: (i) generating random bipartite graphs with the same structure; (ii) calculating the protein scores on these random graphs; and (iii) calculating the permutation P-value and FDR. Among these steps, it is relatively easy to perform the first step and the third step. However, it is timeconsuming or prohibitive to execute some protein inference algorithms for thousands of times to fulfill step ii. To address this issue, we first train a linear regression model using the original bipartite graph and identification scores given by the target inference algorithm. Then, we use the learned regression model as a substitute of original protein inference method to predict protein scores on shuffled graphs. Experimental results on several real proteomics datasets show that our method is effective in FDR calculation. Overall, the salient features of the work described in this article can be summarized as follows:</p><p>It can calculate the FDR without using a decoy database. It can be applied to evaluate the protein identification results from any algorithm that outputs protein probabilities/ scores. The rest of this article is organized as follows. In Section 2, we describe our method in detail, Section 3 presents the experimental results and Section 4 concludes the article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>In our method, we use permutation test to calculate the P-value of each protein and then use these P-values to calculate the final FDR. Therefore, our method mainly consists of the following steps:</p><p>(1) Generating multiple random bipartite graphs with the same structure;</p><p>(2) Building a linear regression model with the original bipartite graph and protein identification scores reported by the target protein inference algorithm;</p><p>(3) Predicting the protein scores on random graphs using the trained linear regression model;</p><p>(4) Calculating the permutation P-value and FDR.In the following, we will explain each step in detail. As step 2 is tightly correlated with step 3, we will elaborate them in the same subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generating random bipartite graphs</head><p>If we wish to test the null hypothesis that each candidate protein hits an identified peptide at random, it is important to construct random graphs with the same structure as the original one. It ensures that the shuffled graphs are comparable with the original graph, whereby each protein (peptide) is connected to the same number of peptides (proteins). Given m candidate proteins and n identified peptides, the bipartite graph GðL, R, EÞ models the input for the protein inference problem. The vertex j 2 L corresponds to the jth peptide and jLj ¼ n. Similarly, the vertex i 2 R represents the ith candidate protein and jRj ¼ m. Then, there exists an edge ðj, iÞ 2 E if the ith candidate protein contains the jth peptide. We generate a random bipartite graph by the following steps:</p><p>(1) Record the degree of each protein/peptide (the number of peptides/ proteins that each protein/peptide is connected with) in the original bipartite graph.</p><p>(2) Randomly select one protein i and one peptide j whose degrees are both larger than 0, and ensure that there is no edge between them in the current random graph.</p><p>(3) Connect protein i and peptide j and decrease the degrees of protein i and peptide j by 1.</p><p>(4) If there are no such proteins and peptides, and the number of edges in the current random graph is less than that in the original graph, select one edge ðj e , i e Þ in the random graph such that there is no edge between j e and i in the random graph. Remove edge ðj e , i e Þ and add an edge ðj e , iÞ. Increase the degree of protein i e by 1 and decrease the degree of protein i by 1.</p><p>(5) Do steps 2–4 until the generated random graph has the same number of edges as the original graph.</p><p>Algorithm 1 shows a straightforward implementation of this generation method.Input: Original graph GðL, R, EÞ Output: Random graph G 0 ðL, R, E 0 Þ with the same structure as G 1: E 0 null 2: Initialize the degree of each protein and each peptide 3: while jE 0 j5jEj do 4: randomly select one protein i with DegreeðiÞ ! 1 5: if all j with DegreeðjÞ ! 1 make ðj, iÞ 2 E 0 then 6: select ðj e , i e Þ 2 E 0 such that ðj e , iÞ = 2 E 0 7: remove ðj e , i e Þ from E 0 and add ðj e , iÞ to E 0 8: Degreeði e Þ þ þ, DegreeðiÞ À À 9: continue 10: end if 11: randomly select one peptide j with DegreeðjÞ ! 1 12: while ðj, iÞ 2 E 0 do 13: re-select one peptide j with DegreeðjÞ ! 1 14: end while 15: DegreeðiÞ À À, DegreeðjÞ À À 16: E 0 E 0 [ fðj, iÞg 17: end while 18: return G 0 ðL, R, E 0 Þ The most important advantage of our method for generating the random graph is that it does not require any parameter. There exist some other algorithms that can generate random graphs with the same structure as the original graph. For example, the method in<ref type="bibr" target="#b2">Gionis et al. (2007)</ref>is more simple and easier to understand than our method because only local swaps are performed in generating a random graph. However, this method needs to specify the number of local swaps and it is difficult to decide which parameter value is the best. To make the protein inference results comparable, the graph randomization procedure should keep all the features of the original graph unchanged except the matches between proteins and peptides. The features of a graph include the number of nodes, the number of edges, the number of connected components and so on. As our method only ensures that the individual degree of each node (protein or peptide) is preserved, one may wonder whether the number of connected components will change substantially. In the Supplementary<ref type="figure" target="#fig_0">Figure S1</ref>, we plot the distribution of the number of connected components in random graphs. It shows that the difference between the random graph and the real graph with respect to the number of connected components is small. Therefore, protein inference is comparable between the original graph and random graphs, although the numbers of connected components of these graphs are not exactly the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Predicting the protein scores on random graphs</head><p>It is time-consuming and inconvenient to execute some protein inference algorithms for thousands of times. Therefore, we build a linear regression model to predict the protein scores reported by these algorithms. We use a response variable y i 2 R to denote the identification score of protein i and a predictor vector x i 2 R n to represent the set of associated peptide probabilities or scores. The element x ij in vector x i ¼ ðx i1 , x i2 ,. .. , x in Þ is constructed by the following way: x ij ¼ probability of peptide j, ðj, iÞ 2 E 0: ðj, iÞ = 2 E ð1Þ That is, if there is an edge between protein i and peptide j in the bipartite graph, the probability of peptide j will be used as the corresponding predictor value. As there are m candidate proteins, we have m observation pairs (x i , y i ). Essentially, all existing protein inference algorithms use the bipartite graph or the equivalent predictor vectors as input to calculate protein scores/probabilities. If we have executed a protein inference algorithm on the original bipartite graph, then we have the protein scores generated from this algorithm. From a machine learning perspective, it is possible to 'learn' a similar model that can be used to perform protein inference in the future. As a result, we can apply our method to simulate the identification results of any protein inference algorithm without knowing its algorithmic details even when its executable program is not available to us. Based on this motivation, here we build a linear regression model to realize this goal. In this approach, we search a coefficient vector to minimize the residual sum of squares:</p><formula>min fðÞ ¼ min ½ X m i¼1 ðy i À x T i Þ 2 : ð2Þ</formula><p>For protein i, when we have a new peptide contribution vector ^ x i , with the estimated coefficient vector ^ , we can easily use the linear model to get the identification score ^ y i :</p><formula>^ y i ¼ ^ x T i ^ : ð3Þ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Calculating the permutation P-value and FDR</head><p>After obtaining the protein scores calculated on these random graphs, we can compute the permutation P-value and FDR. If our null hypothesis that each protein matches an identified peptide by chance is true, then there is no significant difference between the score of each protein in the original graph and those calculated from the random graphs. Therefore, we can calculate the permutation P-value of one protein as the percentage of random graphs that produce a larger score than its score generated on the original graph. More precisely, the P-value of the ith protein is computed as follows:</p><formula>p i ¼ #fy t i 4y i g K , ð4Þ</formula><p>where y i is the original score of the ith protein, y t i is the score of the ith protein produced from the tth random graph, #fy t i 4y i g denotes the number of random graphs on which protein i has a larger score than y i and K is the total number of random bipartite graphs. Based on these P-values, we can calculate the FDR and the pFDR value using the method described in Storey and Tibshirani</p><formula>(2003): d FDRð&#x0D;Þ ¼ 0 PrðP Þ , ð5Þ d pFDRð&#x0D;Þ ¼ 0 PrðP Þf1 À ð1 À Þ m g , ð6Þ</formula><p>where denotes the rejection threshold and 0 is the proportion of false positives. PrðP Þ represents the probability that a P-value P is no more than. The pFDR (positive false discovery rate) is a modified version of the FDR. As becomes small, FDR is driven by the fact that the rejection threshold is small rather than the fact that the 'rate that discoveries are false' is small. In contrast, pFDR can avoid this disadvantage. Therefore, in this article, we use pFDR as the final estimated value. We estimate 0 by the following equation:</p><formula>^ 0 ðÞ ¼ #fp i 4g ð1 À Þm , ð7Þ</formula><p>where p i is the P-value of each candidate protein, is a parameter and #fp i 4g denotes the number of proteins whose P-values are larger than . And we use the method in Storey (2002) to pick. Decoy-free protein-level false discovery rate estimation A natural estimate of PrðP Þ is:</p><formula>b PrðP Þ ¼ #fp i g m ¼ Rð&#x0D;Þ m , ð8Þ</formula><p>where Rð&#x0D;Þ ¼ #fp i g represents the number of candidate proteins with P-value. With the estimated ^ 0 ðÞ and b PrðP Þ, we can easily get the pFDR value at a given threshold .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>In our experiments, we use six publicly available datasets: 18 mixtures (<ref type="bibr" target="#b6">Klimek et al., 2008</ref>), Sigma49 (<ref type="bibr" target="#b15">Tabb et al., 2007</ref>), Yeast (<ref type="bibr" target="#b9">Ramakrishnan et al., 2009a</ref>), DME (<ref type="bibr" target="#b0">Brunner et al., 2007</ref>), HumanMD (<ref type="bibr" target="#b10">Ramakrishnan et al., 2009b</ref>) and HumanEKC (<ref type="bibr" target="#b9">Ramakrishnan et al., 2009a</ref>). The first three datasets have the ground-truth protein reference sets and the other three have no such reference sets. The details of these datasets are described in the Supplementary<ref type="figure" target="#tab_1">Table S1</ref>and S2. We use X!Tandem (<ref type="bibr" target="#b1">David and Cottrell, 2004</ref>) as the peptide identification method. As we compare our method with MAYU (<ref type="bibr" target="#b11">Reiter et al., 2009</ref>), all MS/MS data are searched against both target and decoy protein databases. The decoy database is generated using the Trans-Proteomic Pipeline (TPP) v4.6 software. In reality, it is not necessary to search a decoy database when using our method. During the database search, we use default search parameters and accept the peptides reported by PeptideProphet with probabilities 40.05 as the input. For any peptide sequence that is matched by multiple spectra with different scores, we choose the highest identification score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parameter setting</head><p>First, we run the protein inference algorithm on the original bipartite graph to obtain the original score of each protein and use these scores to build a linear regression model. Second, we predict the score of each protein in random graphs with the regression model and calculate the P-value and FDR. The protein inference algorithms used in our experiment are ProteinProphet (<ref type="bibr" target="#b7">Nesvizhskii et al., 2003</ref>) and ProteinLP (<ref type="bibr" target="#b3">Huang and He, 2012</ref>). We run ProteinProphet included in the Trans-Proteomic Pipeline (TPP) v4.6 software with the default parameter values and use ProteinLP by setting ¼ 0. As both ProteinProphet and ProteinLP output the presence probability of each protein, we transform the score predicted by the regression model into the interval<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. If the score is41, we set the score to 1; if the score is 50, we set the score to 0. In addition, the number of random graphs we choose is 10 000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>For the first three datasets with reference sets, we apply our method and MAYU to estimate the FDR and check the difference between the estimated FDR and the ground-truth FDR. We set f0:05, 0:1,. .. , 0:95, 1g as the threshold, respectively. For each threshold, the smaller the difference, the better the performance. As shown in<ref type="figure">Figure 2</ref>, for the first two datasets, our method is comparable with MAYU, while our method can provide a more accurate FDR estimation on the Yeast dataset when the P-value is larger than 0.2. We can also see that both our method and MAYU have huge deviations from the real protein FDRs for the first two synthetic datasets probably because 18 mixtures and Sigma49 do not have characteristics of those complex proteomics datasets generated from real samples. Thus, the experimental result on the more complex Yeast dataset indicates that both methods can perform relatively well on real data, and the advantage of our method begins to be visible. For the other three datasets, we compare our method with MAYU and the naive target-decoy method. For MAYU, we set f0:05, 0:1, :::, 0:95, 1g as the threshold, respectively. When using the naive target-decoy method, FDR is calculated by doubling the ratio of the number of decoy proteins and the total number of protein identifications in the reported proteins. As shown in<ref type="figure" target="#fig_2">Figure 3</ref>, the performance of our method is comparable with the naive target-decoy method and MAYU. One important parameter in our method is the number of random graphs. We test the influence of different numbers of random graphs by comparing absolute difference between the estimated FDR and the true FDR at each threshold. We choose f1000, 3000, 5000, 7000, 10000g as the parameter value, respectively. As shown in<ref type="figure">Figure 4</ref>, we can see that the absolute differences are almost the same when using different numbers of random graphs. This means that our method is insensitive to the number of random graphs when the value is 41000. We also list the real 0 and the estimated ^ 0 on six datasets in<ref type="figure" target="#tab_1">Table 1</ref>. For the three datasets without reference sets, we calculate the real 0 by doubling the ratio of the number of decoy proteins in the datasets and the total number of protein identifications in the datasets. As shown in<ref type="figure" target="#tab_1">Table 1</ref>, the estimated ^ 0 is far from its true value on 18 mixtures and Sigma49. This explains why the absolute FDR differences on these two datasets are large. Now we test the running efficiency of our method. The running time of our method and MAYU on six datasets is provided in<ref type="figure">Table 2</ref>. All the experiments are tested on the DELL Studio XPS 8100 workstation with 2.80 GHz CPU and 8 G main memory. It shows that our method is efficient in practice and faster than MAYU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>In this article, we propose a novel protein-level FDR estimation method. We assume that each candidate protein matches an identified peptide totally at random. Then, we use random permutation for assessing the statistical significance of each protein in terms of P-value and calculate the final FDR. The main advantage is that our method can calculate FDR without searching a decoy database. Experimental results on six proteomics datasets demonstrate the superiority of our method. In the future work, we will extend our method to validate the inference results of the algorithms that do not report protein probabilities or scores. We plan to train a logistic regression model, which can assign a corresponding probability to<ref type="figure">Fig. 2</ref>. Performance on 18 mixtures, Sigma49 and Yeast when ProteinLP (upper) and ProteinProphet (lower) are used as the target protein inference algorithm, respectively. The difference with the benchmark ¼ jthe estimated FDR À true FDRj. For each threshold, the smaller the difference, the better the performance. For 18 mixtures, 18 standard proteins and 15 contaminants are marked as the ground-truth. For Sigma49, all accessions in the final list of correct proteins provided by the ABRF2007 bioinformatics committee are used as the ground-truth<ref type="figure">Fig. 4</ref>. The influence of different numbers of the random graphs on three datasets with reference setsNote: MAYU can only report the FDR value at one threshold in each run, whereas our method can estimate a series of FDR values at all the thresholds. The execution time listed here for MAYU is the average running time over different thresholds. The number of random graphs in our method is fixed to be 10 000.Note: ^ 0 1 and ^ 0 2 are estimated when ProteinLP and ProteinProphet are used as the target protein inference algorithm, respectively. each reported protein. Meanwhile, as 0 can affect the FDR estimation results significantly, we will find more accurate 0 estimation method in the future.</p><formula>P P P P P P</formula><formula>P P P P P P</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure1gives</head><figDesc>Figure 1 gives an overview of this method. In the following, we will explain each step in detail. As step 2 is tightly correlated with step 3, we will elaborate them in the same subsection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. An overview of our FDR estimation algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Performance on DME, HumanMD and HumanEKC when ProteinLP (upper) and ProteinProphet (lower) are used as the target protein inference algorithm, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Funding:</head><figDesc>This work was supported by the Natural Science Foundation of China under Grant No. 61003176. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 2. The running time of our method and MAYU on six datasets</figDesc><table>Datasets 
MAYU 
Our method (ProteinLP) 
Our method (ProteinProphet) 

18 Mixtures 
3 s 
2 s 
2 s 
Sigma 49 
30 s 
2 s 
2 s 
Yeast 
12 s 
106 s 
90 s 
HumanEKC 
41 s 
35 s 
35 s 
DME 
35 s 
30 s 
30 s 
HumanMD 
41 s 
13 s 
13 s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1.</figDesc><table>Real 0 and the estimated ^ 
0 on six datasets 

Datasets 
Real 0 
Estimated ^ 
0 1 
E s t i m a t e d^ 0 2 

18 Mixtures 
0.698 
0.024 
0.090 
Sigma49 
0.333 
0.068 
0.048 
Yeast 
0.331 
0.248 
0.196 
DME 
0.308 
0.195 
0.222 
HumanMD 
0.232 
0.202 
0.180 
HumanEKC 
0.063 
0.177 
0.121 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">B.Teng et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">B.Teng et al.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">A high-quality catalog of the Drosophila melanogaster proteome</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Brunner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="576" to="583" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Unimod: protein modifications for mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>David</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Cottrell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteomics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1534" to="1536" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Assessing data mining results via swap randomization</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gionis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A linear programming model for protein inference problem in shotgun proteomics</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Huang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2956" to="2962" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Protein inference: a review</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="586" to="614" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Spectral probabilities and generating functions of tandem mass spectra: a strike against decoy databases</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3354" to="3363" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">The Standard Protein Mix Database: a diverse data set to assist in the production of improved peptide and protein identification software tools</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Klimek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="96" to="103" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A statistical model for identifying proteins by tandem mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">I</forename>
				<surname>Nesvizhskii</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="4646" to="4658" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Analysis and validation of proteomic data generated by tandem mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">I</forename>
				<surname>Nesvizhskii</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="2405" to="2417" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining gene functional networks to improve mass-spectrometry based protein identification</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Ramakrishnan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2955" to="2961" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Integrating shotgun proteomics and mRNA expression data to improve protein identification</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Ramakrishnan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1397" to="1403" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Protein identification false discovery rates for very large proteomics data sets generated by tandem mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Reiter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Cell. Proteomics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="787" to="797" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Assigning spectrum-specific p-values to protein identifications by mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Spirin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1128" to="1134" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A direct approach to false discovery rates</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Storey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B Stat. Methodol</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="479" to="498" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Statistical significance for genomewide studies</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Storey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad Sci. USA</title>
		<meeting>. Natl Acad Sci. USA</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="9440" to="9445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Myrimatch: highly accurate tandem mass spectral peptide identification by multivariate hypergeometric analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">L</forename>
				<surname>Tabb</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="654" to="661" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">Decoy-free protein-level false discovery rate estimation</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>