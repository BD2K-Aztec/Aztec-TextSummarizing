
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-order neural networks and kernel methods for peptide-MHC binding prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Pavel</forename>
								<forename type="middle">P</forename>
								<surname>Kuksa</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Biomedical Informatics</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Pathology and Laboratory Medicine</orgName>
								<orgName type="institution">University of Pennsylvania School of Medicine</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Machine Learning</orgName>
								<orgName type="institution">NEC Laboratories America</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Martin</forename>
								<forename type="middle">Renqiang</forename>
								<surname>Min</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Machine Learning</orgName>
								<orgName type="institution">NEC Laboratories America</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Rishabh</forename>
								<surname>Dugar</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Machine Learning</orgName>
								<orgName type="institution">NEC Laboratories America</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Mark</forename>
								<surname>Gerstein</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Program of Computational Biology and Bioinformatics</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Molecular Biophysics and Biochemistry</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<postCode>06511</postCode>
									<settlement>New Haven</settlement>
									<region>CT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">High-order neural networks and kernel methods for peptide-MHC binding prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv371</idno>
					<note type="submission">Received on December 20, 2014; revised on June 8, 2015; accepted on June 11, 2015</note>
					<note>Structural bioinformatics *To whom correspondence should be addressed. † The authors wish it to be known that, in their opinion, the first three authors should be regarded as Joint First Authors. Associate Editor: Anna Tramontano Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Effective computational methods for peptide-protein binding prediction can greatly help clinical peptide vaccine search and design. However, previous computational methods fail to capture key nonlinear high-order dependencies between different amino acid positions. As a result, they often produce low-quality rankings of strong binding peptides. To solve this problem, we propose nonlinear high-order machine learning methods including high-order neural networks (HONNs) with possible deep extensions and high-order kernel support vector machines to predict major histocompatibility complex-peptide binding. Results: The proposed high-order methods improve quality of binding predictions over other prediction methods. With the proposed methods, a significant gain of up to 25–40% is observed on the benchmark and reference peptide datasets and tasks. In addition, for the first time, our experiments show that pre-training with high-order semi-restricted Boltzmann machines significantly improves the performance of feed-forward HONNs. Moreover, our experiments show that the proposed shallow HONN outperform the popular pre-trained deep neural network on most tasks, which demonstrates the effectiveness of modelling high-order feature interactions for predicting major histo-compatibility complex-peptide binding. Availability and implementation: There is no associated distributable software.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Complex biological functions in living cells are often performed through different types of protein–protein interactions. An important class of protein–protein interactions are peptide (i.e. short chains of amino acids)-mediated interactions, and they regulate important biological processes such as protein localization, endocytosis, post-translational modifications, signalling pathways and immune responses, etc. Moreover, peptide-mediated interactions play important roles in the development of several human diseases including cancer and viral infections. Because of the high medical value of peptide-protein interactions, a lot of research has been done to identify ideal peptides for therapeutic and cosmetic purposes, which renders in silico peptide-protein binding prediction by computational methods an important problem in immunomics and bioinformatics(<ref type="bibr" target="#b1">Brusic et al., 2002;</ref><ref type="bibr" target="#b9">Hoof et al., 2009;</ref><ref type="bibr" target="#b12">Lundegaard et al., 2011;</ref><ref type="bibr" target="#b14">Nielsen et al., 2003</ref>). In this article, we propose novel machine learning methods to study a specific type of peptide-protein interaction, i.e. the interaction between peptides and major histocompatibility complex class I (MHC I) proteins, although our methods can be readily applicable to other types of peptide-protein interactions. Peptide-MHC I protein interactions are essential in cell-mediated immunity, regulation of immune responses, transplant rejection and vaccine design. Therefore, effective computational methods for peptide-MHC I binding prediction will significantly reduce cost and time in clinical peptide vaccine search and design. Previous computational approaches to predicting peptide-MHC interactions are mainly based on linear or bi-linear models, and they fail to capture key non-linear high-order dependencies between different amino acid positions. Although previous kernel support vector machine (SVM) and Neural Network (NetMHC) (<ref type="bibr" target="#b4">Giguere et al., 2013;</ref><ref type="bibr" target="#b9">Hoof et al., 2009;</ref><ref type="bibr" target="#b12">Lundegaard et al., 2011</ref>) approaches can capture nonlinear interactions between input features, they fail to model the direct strong high-order interactions between features. As a result, the quality of the peptide rankings produced by previous methods is not good. Producing high-quality rankings of peptide vaccine candidates is essential to the successful deployment of computational methods for vaccine design. For this purpose, we need to effectively model direct non-linear high-order feature interactions to directly capture interactions between primary (anchor) and secondary amino acid residues involved in the formation of peptide-MHC complexes. Deep learning models such as deep neural networks (DNNs) pretrained with restricted Boltzmann machine (RBM) have been successfully applied to handwritten digit classification, embedding, image recognition and many other applications (<ref type="bibr" target="#b8">Hinton, 2010;</ref><ref type="bibr" target="#b13">Min et al., 2010;</ref><ref type="bibr" target="#b17">Ranzato et al., 2013</ref>). But they have never been successfully applied to peptide-protein interaction problems. In this article, we propose using high-order semi-RBMs to pretrain a feed-forward high-order neural network (HONN) and propose high-order kernel SVM for peptide-MHC binding prediction, including identification of MHC-binding, naturally processed and presented (NPP) and immunogenic peptides (T-cell epitopes). Our proposed models achieved a significant gain of up to 25–40% over the state-ofthe-art approach on benchmark and reference peptide datasets and tasks. Furthermore, our shallow HONNs even outperformed popular powerful pre-trained DNNs that was applied to model peptide-MHC binding prediction for the first time by this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Position-specific scoring matrix (PSSM) and matrix-based methods: In<ref type="bibr" target="#b15">Nielsen et al. (2004)</ref>Reche and Reinherz (2007) and<ref type="bibr" target="#b19">Reche et al. (2002)</ref>, PSSMs were derived from a set of known binding peptides and PSSM matching score was used as an indicator of the binding potential of a query peptide. In<ref type="bibr" target="#b16">Peters and Sette (2005)</ref>, the peptide binding task was solved as a matrix-vector regression problem. Neural network-based methods: In<ref type="bibr" target="#b23">Zhang et al. (2005) and</ref><ref type="bibr" target="#b1">Brusic et al. (2002)</ref>, neural networks were built to predict peptide binding potentials by encoding peptides and contact residues on the MHC molecules as a fixed-dimensional vector of amino acid and contact residues. Similarly, in<ref type="bibr" target="#b14">Nielsen et al. (2003</ref><ref type="bibr" target="#b2">), Buus et al., (2003</ref><ref type="bibr" target="#b12">) and Lundegaard et al. (2011</ref>, neural networks and committees of networks with peptide representations combining sparse, BLOSUM and profile HMM encodings of the peptides were used. In<ref type="bibr" target="#b9">Hoof et al. (2009)</ref>, both the peptide sequence and MHC protein sequence were used as input to neural networks to enhance predictive ability for MHC alleles with limited peptide binding data. Kernel-based methods: The work in<ref type="bibr" target="#b20">Salomon and Flower (2006)</ref>used the local alignment kernel method for predicting MHC-II-peptide binding. In<ref type="bibr" target="#b21">Tung et al. (2011)</ref>, weighted-degree kernels were adopted to identify immunogenic peptides. The work in<ref type="bibr" target="#b11">Liu et al. (2007)</ref>employed support vector regression (with RBF, polynomial, etc. kernels) using sparse encoding of a peptide sequence and 11-dim physicochemical amino-acid descriptors. Recent work (<ref type="bibr" target="#b4">Giguere et al., 2013</ref>) used kernel logistic regression for MHC-II-peptide binding prediction using both peptide and MHC sequences. In<ref type="bibr" target="#b5">Gigure et al. (2013)</ref>, an SVM with kernel from (<ref type="bibr" target="#b4">Giguere et al., 2013</ref>) was used for NPP ('eluted') peptide prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>For the peptides to bind to a particular MHC allele (i.e. its peptidebinding groove), the sequences of the binding peptides should be approximately superimposable: contain amino acids or strings of amino acids (k-mers) with similar physicochemical properties at approximately the same positions along the peptide chain. It is then natural to model peptide sequences X ¼ x 1 ; x 2 ;. .. ; x n ; x i 2 R (i.e. sequences of amino acid residues) as a sequences of descriptor vectors d 1 ;. .. ; d n , encoding relevant properties of amino acids observed along the peptide chain and/or MHC-peptide interaction terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Descriptor sequence peptide representations</head><p>Although the descriptor vectors d i in general may be of unequal length, in the matrix form (equal-sized vectors d i 2 R R ) of this representation ('feature-spatial-position matrix'), the rows are indexed by features (e.g. individual amino acids, strings of amino acids, k-mers, physicochemical properties and peptide-MHC interaction features), while the columns correspond to their spatial positions (coordinates).<ref type="figure" target="#fig_0">Figure 1</ref>illustrates descriptor sequence representation of a nonamer. In this descriptor sequence representation, each position in the peptide is described by a feature vector, with features derived from the amino acid occupying this position or from a set of amino acids (e.g. a k-mer starting at this position or a window of amino acids centred at this position) and/or amino acids present in the MHC protein molecule and interacting with the amino acids in the peptide.The purpose of a descriptor is to capture relevant information (e.g. physicochemical properties) that can be used by our HONNs and kernel functions to differentiate peptides into binding, nonbinding, immunogenic, etc. A real-valued descriptor of an amino acid is a quantitative descriptor encoding (i) relevant properties of amino acids such as their physicochemical properties and substitution probabilities by other amino acids and/or (ii) interaction features (such as binding energy) between the amino acids in the peptide and those in the MHC molecule. An example of the real-valued descriptor sequence representation of a peptide using 5-dim physicochemical amino acid descriptors is given in<ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DNN and HONN</head><p>Given the matrix-form descriptor representation of each peptide based on BLOSUM substitution matrix as illustrated above, we concatenate all the columns of the matrix into a long vector as input feature vector to our neural networks. In this representation, a 9-mer peptide is represented by a 180-dimensional continuous vector, with each amino acid represented by its corresponding 20-dimensional substitution probabilities. Instead of using an ensemble of traditional neural networks to predict MHC class-peptide bindings as in the state-of-the-art approach NetMHC (<ref type="bibr" target="#b2">Buus et al., 2003;</ref><ref type="bibr" target="#b12">Lundegaard et al., 2011;</ref><ref type="bibr" target="#b14">Nielsen et al., 2003</ref>), we propose to use HONNs pre-trained with a special type of high-order semi-RBMs called mean-covariance RBMs (mcRBMs) (<ref type="bibr" target="#b17">Ranzato et al., 2013</ref>), capable of capturing strong highorder interactions of feature descriptors of input peptides, to produce high-quality rankings of binding peptides (T-cell epitopes). The pretraining strategy has been widely adopted for training a popular powerful model called DNN (<ref type="bibr" target="#b0">Bengio, 2009;</ref><ref type="bibr" target="#b7">Hinton, 2006</ref>). DNN has attracted world-wide attention in the machine learning community recently. In<ref type="bibr" target="#b7">Hinton (2006)</ref>, it has been shown that DNN is more powerful than shallow neural networks and performs much better than shallow ones on a benchmark dataset widely used in machine learning. In this article, for the first time, we apply DNN to predict peptide-MHC binding, and we compare its performance to our proposed HONN. DNN is shown on the left panel of<ref type="figure" target="#fig_1">Figure 2</ref>. We use Gaussian RBM to pre-train the network weights of its first layer, and we use binary RBM to pre-train the connection weights of upper layers in a greedy layer-wise fashion (see Hinton, 2006 for detailed descriptions about pre-training). Our proposed HONN is shown on the right panel of<ref type="figure" target="#fig_1">Figure 2</ref>. We use mcRBM to pre-train the network weights of it first layer, and we optionally add upper layers, and we use binary RBM to pre-train the connection weights in possibly available upper layers. In both DNN and HONN, we use a logistic unit as our final output layer, and then we use backpropagation to fine-tune the final network weights by minimizing the cross entropy between predicted binding probabilities P n and target binding probabilities t n as follows,</p><formula>À X N n¼1 ½t n log P n þ ð1 À t n Þlogð1 À P n Þ; (1)</formula><p>where N is the total number of training peptides. The pre-training module mcRBM of HONN extends traditional Gaussian RBM to model both mean and explicit pairwise interactions of input feature values, and it has two sets of hidden units, mean hidden units h m modelling the mean of input features and covariance hidden units h g gating pairwise interactions between input features. If the gating hidden units are binary, they act as binary switches controlling the pairwise interactions between input features. The energy function of mcRBM with factorized weights for reducing computational complexity is defined as follows,</p><formula>Eðv; h g ; h m Þ ¼ 1 2 X f X i v i C if 2 X k h k P kf À X i a i v i À X k b k h k g À X ij v i h j m w ij À X k c k h k m (2)</formula><p>where i indexes visible units such as peptide sequence features, j indexes hidden units and f indexes the factors. Using this energy function, we can derive the conditional probabilities of hidden units given visible units, as well the respective gradients for training the network. The structure of this factorized mcRBM is shown on the bottom of the right panel of<ref type="figure" target="#fig_1">Figure 2</ref>, the hidden units on the left model the mean of input features and those on the right model the input covariance. During pre-training, we used Contrastive Divergence (<ref type="bibr" target="#b6">Hinton, 2002</ref>) to learn the factorized weights in mcRBM as in Gaussian RBM, and we used Hybrid Monte Carlo sampling to generate the negative samples as in<ref type="bibr" target="#b17">Ranzato et al. (2013)</ref>with 20 leap-frog steps. The structures and parameters of both DNN and HONN are decided based on performance on validation sets. In fact, for our HONN, only the learning rates, batch size and the number of hidden units need to be carefully tuned, and the final performance is not sensitive to other hyper-parameters. During the training phase, our algorithm randomly selects 10% of the original training data as validation set for early stopping. When the algorithm monitors that the validation error increases up to 10 times even if the training error is still decreasing, we end the training process for early stopping. Although HONN can be easily extended to have many upper layers to form a deep architecture, HONN without deep extensions works best in all our experiments, which is probably due to the limited training data we have.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">High-order kernel models</head><p>The sequence of the descriptors corresponding to the peptide X ¼ x 1 ; x 2 ;. .. ; x jXj ; x i 2 R (as in, e.g.<ref type="figure" target="#fig_0">Fig. 1</ref>) can be modelled as an attributed set of descriptors corresponding to different positions (or groups of positions) in the peptide and amino acids or strings of amino acids occupying these positions:</p><formula>X A ¼ fðp i ; d i Þg n i¼1</formula><p>where p i is the coordinate (position) or a set (vector) of coordinates and d i is the descriptor vector associated with the p i , with n indicatingthe cardinality of the attributed set description X A of peptide X. The cardinality of the description X A corresponds to the length of the peptide (i.e. the number of positions) or to in general to the number of unique descriptors in the descriptor sequence representation. A unified descriptor sequence representation of the peptides as a sequence of descriptor vectors is used to derive attributed set descriptions X A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">High-order kernel functions on peptide descriptor sequence representations</head><p>In the following, we define kernel functions for peptides based on peptide descriptor sequence representations (such as in<ref type="figure" target="#fig_0">Fig. 1</ref>). The proposed kernel functions for peptide sequences X and Y have the following general form:</p><formula>KðX; YÞ ¼ KðMðXÞ; MðYÞÞ ¼ KðX A ; Y A Þ ¼ X iX X jY k p ðp X iY ; p Y jY Þk d ðd X iX ; d Y jY Þ (3)</formula><p>where MðÁÞ is a descriptor sequence (e.g. spatial feature matrix) representation of a peptide, X A ðY A Þ is an attributed set corresponding to M(X) (M(Y)), k d ðÁ; ÁÞ; k p ðÁ; ÁÞ, are kernel functions on descriptors and context/positions, respectively, and i X , i Y index elements of the attributed sets X A , Y A. While k d measures similarity between descriptors, the context/position kernel k p measures similarity of the of the descriptor context (e.g. position and spatial distribution of amino acids). A number of kernel functions for descriptor sequence (e.g. matrix) forms MðÁÞ is described below. Using real-valued descriptors (e.g. vectors of physicochemical attributes), with RBF or polynomial kernel function on descriptors, the k d ðd a ; d b Þ is defined as exp ðÀc d jjd a À d b jjÞ where c d is an appropriately chosen weight parameter, or ðhd a ; d b i þ cÞ p where p is the degree (interaction order) parameter and c is a parameter controlling contribution of lower order terms. Kernel functions k p ðÁ; ÁÞ on position sets p i and p j are defined as a set kernel</p><formula>k p ðp i ; p j Þ ¼ X i2p i X j2p j</formula><p>kði; jja; bÞ where kði; jja; bÞ ¼ 1 ji À jj a þ b ¼ expðÀalogðji À jjÞÞ þ b is a kernel function on pairs of position coordinates (i, j). The position set kernel function above assigns weights to interactions between positions (i, j) according to kði; jja; bÞ. The descriptor kernel function (e.g. RBF or polynomial) between two descriptors d i ¼ ðd i 1 ; d i 2 ;. .. ; d i R Þ and d j ¼ ðd j 1 ; d j 2 ;. .. ; d j R Þ induces high-order (i.e. products-of-features) interaction features (such as d i1 d i2. .. d ip for polynomial of degree p) between positions/attributes. The proposed kernel function (Eq. 3) captures high-order interactions between amino acids/positions by considering essentially all possible products of features encoded in descriptors d of two or more positions. The feature map corresponding to this kernel is composed of individual feature maps capturing interactions between particular combinations of the positions. The interaction maps between different positions p a and p b are weighted by the position/context kernel function k p ðp a ; p b Þ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>To assess the performance of our high-order methods, we tested our methods on three prediction tasks: 1. MHC-I binding prediction. The datasets used for MHC-I binding prediction task are listed in<ref type="figure" target="#tab_1">Table 1</ref>For all the tasks, we focused on the 9-mer peptides. For MHC-I binding prediction, we threshold at a standard value IC50 ¼ 500 to separate binding peptides (IC50 &lt; 500) and non-binding (IC50 &gt; 500) peptides and focus on three alleles, HLA-A*0201, HLA-A*0206 and HLA-A*2402. The choice of these alleles is motivated by the target population group (Japanese) in our research lab. The application of our method to other alleles or peptide lengths would be straightforward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training and testing protocol</head><p>For MHC-I binding prediction, we train our models for each allele on the publicly available data from the Immune Epitope Database and Analysis Resource (IEDB) (<ref type="bibr" target="#b22">Vita et al., 2010</ref>). The datasets (http://www.iedb.org) are labelled with IEDB suffix in<ref type="figure" target="#tab_1">Table 1</ref>. For testing, we use the experimental data from our lab for each allele. These datasets are denoted with 'Japanese' suffix in<ref type="figure" target="#tab_1">Table 1</ref>. For 'Japanese' data, the experimentally determined binding strength is measured as log ðK d Þ, where K d is a dissociation coefficient, i.e. higher negative values of log ðK d Þ suggest stronger binders. The training 'IEDB' datasets and the test 'Japanese' datasets are completely disjoint. The average sequence identity between any peptide in the 'Japanese' datasets and the most similar peptide from IEDB data is about 46–55% (Supplementary<ref type="figure" target="#tab_0">Table S10</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation metrics</head><p>To assess performance, we use two sets of metrics, classical binary metrics and non-binary relevance metrics. Binary performance metrics. We used (i) area under ROC curve (AUC) and (ii) area under ROC curve up to first n false positives (ROC-n). Non-binary relevance/quality metrics. While classical binary performance metrics use binary relevance (i.e. '1' ¼ relevant, '0' ¼ nonrelevant), to take into account more 'precise' relevance measure, i.e. theHigh-order neural networks and kernel methodsbinding strength of the peptides, we use normalized discounted cumulative gain (nDCG), a classical non-binary (graded) relevance metric. Given a list of peptides P 1 ;. .. ; P N ordered by the output scores of the predictor f ðP 1 Þ;. .. ; f ðP N Þ, the discounted cumulative gain (DCG N ) is defined as a sum of individual peptide relevance scores (experimentally determined binding strength) q 1 ; q 2 ;. .. ; q n discounted by the log of their position i in the list:</p><formula>DCG N ¼ X N i¼1 2 qi À 1 log ði þ 1Þ</formula><p>The normalized DCG N is defined as a ratio between DCG of the method and an ideal DCG iDCG N (i.e. DCG of an ideal ordering of peptides from the highest degree of binding affinity to the lowest binding affinity):</p><formula>nDCG N ¼ DCG N iDCG N</formula><p>The normalized DCG N value is then ranges between 0 and 1, with nDCG N ¼ 1 corresponding to the ideal value (i.e. normalized DCG ¼ 1 when the predictor orders peptides according to their actual binding strength). We find this measure (nDCG) to be more indicative of the prediction performance of the MHC-I binding prediction method as it directly assesses whether the predictor ranks stronger binders higher than weaker binders [as opposed to binary measures (e.g. area under ROC curve) that measure whether 'binders' are ranked higher than 'nonbinders' irrespectively of the actual peptide binding strength<ref type="bibr">]</ref>. This measure is popular for assessing performance of the document retrieval systems (e.g. Web search engines) as it is maximized if the most relevant documents appear at the top of search results, but it has not been used to differentiate performance of the MHC binding predictors. In the case of the peptide-MHC prediction, the nDCG is maximized if peptides are placed (according to the predictor output) in the ideal order: from the strongest binders to the weakest/non-binders. We emphasize that the two methods with the same AUC scores may differ significantly with respect to their nDCG scores: even with the equally good separation between 'binders' and 'non-binders' for the two methods, the method that correctly ranks stronger binders higher than weaker binder will have a higher nDCG score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We first present results for MHC-I binding prediction on benchmark datasets and experimental data from our lab (section 5.1). We show next results on predicting peptides NP by the MHC pathway (section 5.2). Finally, we show results for predicting promising T-cell epitopes for clinical development (section 5.3). The following AUC and nDCG scores are shown in percentage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">MHC-I binding prediction</head><p>We train a DNN, a high-order semi-RBM (HONN) and a highorder kernel SVM (hkSVM) on IEDB data. In our experiments, we use BLOSUM substitution matrix as continuous descriptors of input peptide sequences. We compare with the popular NetMHC method that has been shown to yield state-of-the-art accuracy for MHC-I binding prediction with respect to other best published methods (see e.g.<ref type="bibr" target="#b5">Gigure et al., 2013;</ref><ref type="bibr" target="#b12">Lundegaard et al., 2011;</ref><ref type="bibr" target="#b24">Zhang et al., 2009</ref>). We first use 'Japanese' datasets to test our methods. Results are shown in Tables 3–5 for target alleles on Japanese test datasets. Corresponding ROC curves are shown in<ref type="figure" target="#fig_4">Figure 3</ref>(top row). We also plot nDCG@n curves in<ref type="figure" target="#fig_4">Fig. 3</ref>(bottom row), where nDCG @n is nDCG up to nth peptide in the sorted output (i.e. nDCG of the top-n predicted peptides). As evident from the AUC and ROC-n results in the tables and ROC plots, our method achieves significant improvements in separating 'binders' versus 'non-binders'. For example, for A2402 allele, ROC-n ¼ 10 score increases from 66.88 for NetMHC to 77.76 for HONN and hkSVM. Similar improvements are observed on A0201 allele data where ROC-n ¼ 10 score improves from 26.61 for NetMHC to 35.59 with HONN and hkSVM. Observed improvements in the AUC and ROC-n scores across all alleles are significant (paired signed rank test, P value 1.22e-4). To further validate our methods, we used recent benchmark MHC-I binding data proposed in<ref type="bibr" target="#b10">Kim et al. (2014)</ref>consisting of the training data (BD2009) and independent (BLIND) test data (Supplementary<ref type="figure" target="#tab_8">Table S8</ref>). We report performance on the independent test data (BLIND) in Supplementary Table S9. As can be seen from the results in the table, while the area under ROC curve (AUC) scores are very similar for both our method and the NetMHCmethod, for the very highest ranked peptides [low false-positive (FP) rates], both hkSVM and HONN þ hkSVM perform better on average compared with NetMHC as measured by ROC-n scores [e.g. ROC-1 scores of hkSVM or HONN are higher in about 67% (31/46) of the<ref type="bibr">tested alleles]</ref>. Observed improvements in ROC-n scores (low FP rates) are significant (paired signed rank test P values ¼ 7e-3 and 1.38e-2 for hkSVM and HONN þ hkSVM, respectively). At the same time, the results in terms of nDCG quality scores suggest significant increase in ranking quality (Tables 6–8). Our method ranks peptides by their actual binding strength significantly better than other methods. We observe that strong binders are placed much higher in the classification results compared with the state-of-the-art NetMHC method. For instance, for the A0201 allele, nDCG@n scores improve from 60.98, 63.50 achieved by NetMHC to 65.94, 70.61 using our HONN method for n ¼ 20 and n ¼ 30 respectively. We note that for both HONN and DNN, the pre-training is critical to achieve good performance. The performance comparisons of DNN and HONN with and without pre-training are in the supplementary material (Supplementary Tables S2–S7). All the results of DNN and HONN reported in the main article are based on pretraining and fine-tuning. Using a combination of network and kernel models further improves peptide-MHC recognition as evident by the increase in both area under ROC curve scores (improved 'binder' versus 'non-binder' separation) and nDCG metric quality scores (improved ranking of peptides by binding strength). We note that unlike the previous approaches that utilized quantitative binding information during training, no quantitative information regarding actual binding strength was used to train our models. However, even with only binary training data [i.e. only with binding (B) versus non-binding (NB) information], our models correctly order peptides according to their binding strength. This can be attributed to explicit high-order interaction modelling by our method(f) Normalized DCG curves on test A2402 allele.High-order neural networks and kernel methodsthat allows to capture intrinsic binding strength information. Nevertheless, our models can easily use quantitative training data (e.g. IC50) to further improve our results. To visualize the learned weights of HONN, we used 8 mean hidden units, 1 covariance hidden unit and 1 factor unit to train HONN on the training data of A2402. We obtained AUC score 86.02 and nDCG score 85.01 that are slightly worse than the ones in Tables 5 and 8. In<ref type="figure" target="#fig_6">Figure 4</ref>, the factorized rank-1 interaction weight vector with absolute values greater than 0.1 is shown in the top, and the weight matrix connecting input features and mean hidden units with absolute values greater than 0.02 is shown at the bottom. This<ref type="figure">figure  clearly</ref>shows that positions 2, 8, 9 and the interaction between middle position and position 9 are very important for predicting 9-mer peptide binding, which has experimental support from the crystal structure of the interaction complex (<ref type="bibr" target="#b3">Cole et al., 2006</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NP peptide prediction</head><p>We test ability of our methods on a difficult task that aims at predicting whether a peptide is NP by the MHC pathway ('eluted'). This is a very important task as only a fraction of binding peptides (see 'MHC-I binding task' in Section 5.1) constitute a set of peptides that are processed to the surface of a cell and may serve as epitopes. Eluted peptide prediction thus aims at verifying whether a peptide not only binds to a given MHC molecule, but that it is also NP by MHC pathway in vivo. To train our models, we used the data provided by 2012 Machine Learning in Immunology competition (MLI-II) http://bio. dfci.harvard.edu/DFRMLI/ HTML/natural.php.</p><p>We directly train our models to recognize NPP peptides, using 'eluted' peptides as a positive set, and all other peptides (non-binders þ non-eluted binders) as a negative set. We then test our models on the data composed of non-eluted binding peptides, non-binding peptides and NP ('eluted') peptides. We used the same training and test split as specified in the competition. We compare our approach with the popular NetMHC method, which was used as a benchmark in the competition, as well as the recently introduced MHC-NP (<ref type="bibr" target="#b5">Gigure et al., 2013</ref>) method that yielded state-ofthe-art accuracy for NP peptide prediction.<ref type="figure" target="#tab_9">Table 9</ref>lists results of NP peptide prediction (9-mers) on the test set in terms of AUC, ROC-n and F1 scores. Our approach significantly outperforms both NetMHC method and the MHC-NP (<ref type="bibr" target="#b5">Gigure et al., 2013</ref>) method. Supplementary table S11 shows the performance of hkSVM for the other test alleles with similar improvements on test peptides with all varying lengths (8-mers to 11-mers).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Epitope prediction</head><p>We demonstrate ability of the method to predict promising peptides for clinical development using as an example WT1-derived strong binding peptides WT-TEST-PEPTIDE1 and WT-TEST-PEPTIDE2 discovered by NEC-Kochi Univ. We compare the performance of our method and NetMHC by 'predicting' in a retrospective way these T-cell epitopes from WT1 antigen. Peptides (441 9-mers) that are part of WT1 antigen are ranked by the output scores of NetMHC and our method (HONN and hkSVM). The order of the WT-TEST-PEPTIDE1 and WT-TEST-PEPTIDE2 peptides in the output (out of the 441 peptides) of the two prediction methods is given in<ref type="figure" target="#tab_0">Table 10</ref>. As evident from the table, our method ranks these peptides higher than NetMHC method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and future work</head><p>In this article, we propose using nonlinear high-order machine learning methods including HONN and hkSVM for peptide-MHC I protein binding prediction. Experimental results on both public and private evaluation datasets according to both binary and non-binary performance metrics (AUC and nDCG) clearly demonstrate the advantages of our methods over the state-of-the-art approach NetMHC, which suggests the importance of directly modelling nonlinear high-order feature interactions across different amino acid positions of peptides. Our results are even more encouraging considering that our models were only trained on a subset of the binary binding datasets used by NetMHC and NetMHC was also trained on private quantitative binding datasets. In the future, we will use available quantitative binding datasets to refine our HONN model with possible deep extensions, and we will incorporate the descriptors of structural contacting amino acids on MHC proteins into current feature descriptors. The addition of peptide binding strength and structural information will potentially further improve the performance of our current models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Peptide descriptor sequence representation of a nonamer 'MVLSAFDER' using 5-dim amino acid descriptors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. The structure of DNN (left) and HONN (right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>.2.</head><figDesc>Naturally processed (NP) ('eluted') peptide prediction. We use recently compiled benchmark data from the 2nd Machine Learning in Immunology competition (MLI-II). Table 2 provides details of this dataset. 3. T-cell epitope prediction. We use data of known T-cell epitopes to test ability of the methods in predicting promising candidates for clinical development.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. ROC curves (top row) and normalized discounted cumulative gain (nDCG) curves (bottom row)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.4.</head><figDesc>Fig. 4. The learned weights of HONN with largest absolute values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 3600 Bioinformatics, 31(22), 2015, 3600–3607 doi: 10.1093/bioinformatics/btv371 Advance Access Publication Date: 23 July 2015 Original Paper</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Peptide-MHC binary datasets (binding/non-binding)</figDesc><table>Dataset 
No. peptides 
No. binders 
No. non-binders 

A0201-IEDB 
8471 
3939 
4532 
A0201-Japanese 
281 
106 
175 
A0206-IEDB 
1820 
951 
869 
A0206-Japanese 
278 
97 
181 
A2402-IEDB 
2011 
890 
1121 
A2402-Japanese 
405 
176 
229 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2. NP peptide datasets</figDesc><table>Dataset 
No. peptides 
No. eluted 
No. non-eluted 

A0201-MLI-II 
8225 
971 
7254 
A0201-MLI-II-EvalSet 
492 
63 
429 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 4.</figDesc><table>Comparison of AUC test scores on A0206-Japanese data 

Method 
AUC 
ROC-10 
ROC-20 
ROC-30 

hkSVM 
86.23 
54.84 
72.58 
78.68 
DNN 
80.24 
52.42 
64.02 
71.31 
HONN 
84.41 
49.7 
69.7 
77.78 
hkSVM þ HONN 
86.24 
54.24 
73.33 
80.2 
NetMHC 
83.93 
50.91 
67.42 
76.77 

The bold values highlight the best comparable performance achieved by 
different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 3. Comparison of AUC test scores on A0201-Japanese data</figDesc><table>Method 
AUC 
ROC-10 ROC-20 ROC-30 ROC-50 

hkSVM 
79.60 
32.71 
50.59 
63.67 
77.56 
DNN 
77.23 
30.34 
47.03 
60.11 
74.95 
HONN 
77.26 
33.39 
48.14 
60.11 
74.98 
hkSVMþHONN 79.11 
35.59 
50.51 
62.99 
77.02 
NetMHC 
76.90 
26.61 
46.02 
58.87 
74.47 

The bold values highlight the best comparable performance achieved by 
different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 5. Comparison of AUC test scores on A2402-Japanese data</figDesc><table>Method 
AUC 
ROC-5 
ROC-10 
ROC-30 

hkSVM 
90.59 
68.8 
75.92 
86.93 
DNN 
89.1 
63.52 
70.96 
84.75 
HONN 
86.29 
54.88 
65.04 
81.17 
hkSVM þ HONN 
91.07 
72.16 
77.76 
87.55 
NetMHC 
88.88 
53.76 
66.88 
84.48 

The bold values highlight the best comparable performance achieved by 
different methods. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 6. A0201-Japanese data</figDesc><table>Method 
nDCG@ 10 nDCG@ 20 nDCG@ 30 nDCG@ 50 nDCG 

hkSVM 
60.69 
61.75 
66.78 
74.11 
85.01 
DNN 
63.89 
65.59 
70.12 
74.57 
86.33 
HONN 
63.93 
65.94 
70.61 
75.55 
86.46 
hkSVM þ HONN 65.69 
65.12 
71.49 
76.46 
86.98 
NetMHC 
59.48 
60.98 
63.50 
72.68 
83.94 

Relevance/ranking quality (nDCG). 
The bold values highlight the best comparable performance achieved by 
different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 7. A0206-Japanese data</figDesc><table>Method 
nDCG@ 10 nDCG@ 20 nDCG@ 30 nDCG 

hkSVM 
76.52 
74.64 
82.49 
91.43 
DNN 
77.50 
82.21 
81.72 
91.74 
HONN 
75.39 
78.06 
79.92 
90.80 
hkSVM þ HONN 
80.2 
76.98 
83.75 
91.75 
NetMHC 
70.97 
73.60 
82.57 
89.88 

Relevance/ranking assessment (nDCG). 
The bold values highlight the best comparable performance achieved by 
different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><figDesc>Table 8. A2402-Japanese data</figDesc><table>Method 
nDCG@ 10 
nDCG@ 30 
nDCG 

hKSVM 
53.77 
64.33 
86.68 
DNN 
51.07 
56.88 
84.36 
HONN 
57.36 
60.82 
85.20 
hkSVM þ HONN 
60.41 
69.59 
87.35 
NetMHC 
55.98 
68.76 
87.57 

Relevance/ranking assessment (nDCG) 
The bold values highlight the best comparable performance achieved by 
different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><figDesc>Table 9. NP peptide prediction (MLI-II competition)</figDesc><table>Method 
AUC 
ROC-10 ROC-20 ROC-30 ROC-50 

hkSVM 
94.75 
53.65 
65.71 
71.48 
77.46 
HONN 
93.17 
49.21 
58.20 
64.13 
72.73 
DNN 
91.80 
30.48 
41.11 
51.32 
62.92 
hkSVM þ HONN 94.96 
53.65 
68.25 
74.39 
79.59 
NetMHC 
92.26 
10.63 
28.33 
40.21 
54.32 
MHC-NP a 
88.06 
— 
— 
— 
— 

Comparison of test AUC scores. 

a 

Quoted from Gigure et al. (2013). 
The bold values highlight the best comparable performance achieved by 
different methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="true"><figDesc>Table 10. Prediction of WT1-derived epitopes</figDesc><table>NetMHC-rank 
hkSVM þ HONN-rank 

A0201 allele 
WT-TEST-PEPTIDE1 
2 
1 
WT-TEST-PEPTIDE2 
20 
2 
A0206 allele 
WT-TEST-PEPTIDE1 
2 
1 
WT-TEST-PEPTIDE2 
8 
3 
A2402 allele 
WT-TEST-PEPTIDE1 
41 
2 
WT-TEST-PEPTIDE2 
7 
4 </table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">P.P.Kuksa et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Dr Keiko Udaka for providing valuable experimental datasets and validations and Dr Hans Peter Graf for helpful discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was mainly supported by the funding from NEC Laboratories America. Conflict of Interest: none declared.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning deep architectures for ai. Found</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Bengio</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Prediction of promiscuous peptides that bind HLA class I molecules</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Brusic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Immunol. Cell Biol</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="280" to="285" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Sensitive quantitative predictions of peptide-MHC binding by a &apos;Query by Committee&apos; artificial neural network approach</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Buus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tissue Antigens</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="378" to="384" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Crystal structure of HLA-A*2402 complexed with a telomerase peptide</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">K</forename>
				<surname>Cole</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Immunol</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="170" to="179" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning a peptide-protein binding affinity predictor with kernel ridge regression</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Giguere</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">MHC-NP: Predicting peptides naturally processed by the MHC</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gigure</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Immunol. Methods</title>
		<imprint>
			<biblScope unit="volume">400401</biblScope>
			<biblScope unit="page" from="30" to="36" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1771" to="800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to represent visual input</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. R. Soc. B Biol. Sci</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page" from="177" to="184" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">NetMHCpan, a method for MHC class I binding prediction beyond humans</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Hoof</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Immunogenetics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Dataset size and composition impact the reliability of performance benchmarks for peptide-MHC binding predictions</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">241</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">In silico prediction of peptide-MHC binding affinity using SVRMHC</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods in Molecular Biology</title>
		<editor>Flower,D.R.</editor>
		<imprint>
			<publisher>Humana Press</publisher>
			<biblScope unit="volume">409</biblScope>
			<biblScope unit="page" from="283" to="291" />
			<date type="published" when="2007" />
			<publisher>Humana Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Prediction of epitopes using neural network based methods</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lundegaard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Immunol. Methods</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="page" from="26" to="34" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep supervised t-distributed embedding</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Min</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)<address><addrLine>Haifa, Israel ; Omnipress, Norristown, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06-21" />
			<biblScope unit="page" from="791" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Reliable prediction of T-cell epitopes using neural networks with novel sequence representations</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Nielsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1007" to="1017" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Improved prediction of MHC class I and class II epitopes using a novel Gibbs sampling approach</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Nielsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1388" to="1397" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Generating quantitative models describing the sequence specificity of biological processes with the stabilized matrix method</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Peters</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sette</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling natural images using gated MRFs</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ranzato</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2206" to="2222" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Prediction of peptide-MHC binding using profiles</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Reche</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">L</forename>
				<surname>Reinherz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Immunoinformatics</title>
		<editor>Flower,D.R.</editor>
		<meeting><address><addrLine>Totowa, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Humana Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="185" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Prediction of MHC class I binding peptides using profile motifs</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Reche</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Immunol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="701" to="709" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Predicting class II MHC-peptide binding: a kernel based approach using similarity scores</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Salomon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Flower</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">501</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">POPISK: T-cell reactivity prediction using support vector machines and string kernels</title>
		<author>
			<persName>
				<forename type="first">C.-W</forename>
				<surname>Tung</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">446</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">The immune epitope database 2.0</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Vita</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="854" to="862" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">MULTIPRED: a computational system for prediction of promiscuous HLA binding peptides</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="172" to="179" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Web. Server Issue</note>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Pan-specific MHC class I predictors: a benchmark of HLA class I pan-specific prediction methods</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="83" to="89" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title level="m" type="main">High-order neural networks and kernel methods</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>