
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Predicting biodegradation products and pathways: a hybrid knowledge-and machine learning-based approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Jörg</forename>
								<surname>Wicker</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik/I12</orgName>
								<orgName type="institution">Technische Universität München</orgName>
								<address>
									<addrLine>Boltzmannstr. 3, 2 Eawag</addrLine>
									<postCode>D-85748</postCode>
									<settlement>Garching b. München, Germany</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Swiss Federal Institute for Aquatic Science and Technology</orgName>
								<address>
									<postCode>CH-8600</postCode>
									<settlement>Dübendorf</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Kathrin</forename>
								<surname>Fenner</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Biogeochemistry and Pollutant Dynamics (IBP)</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>CH-8092</postCode>
									<settlement>Zürich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Lynda</forename>
								<surname>Ellis</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Laboratory Medicine and Pathology</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Larry</forename>
								<surname>Wackett</surname>
							</persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Biochemistry, Molecular Biology and Biophysics</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<postCode>55108</postCode>
									<settlement>St. Paul</settlement>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Stefan</forename>
								<surname>Kramer</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Institut für Informatik/I12</orgName>
								<orgName type="institution">Technische Universität München</orgName>
								<address>
									<addrLine>Boltzmannstr. 3, 2 Eawag</addrLine>
									<postCode>D-85748</postCode>
									<settlement>Garching b. München, Germany</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Swiss Federal Institute for Aquatic Science and Technology</orgName>
								<address>
									<postCode>CH-8600</postCode>
									<settlement>Dübendorf</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Predicting biodegradation products and pathways: a hybrid knowledge-and machine learning-based approach</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="issue">6</biblScope>
							<biblScope unit="page" from="814" to="821"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq024</idno>
					<note type="submission">Advance Access publication January 26, 2010 Received on August 11, 2009; revised on December 30, 2009; accepted on January 17, 2010</note>
					<note>[15:15 19/2/2010 Bioinformatics-btq024.tex] Page: 814 814–821 Associate Editor: Jonathan Wren Availability: The program is freely available on the web at http://wwwkramer.in.tum.de/research/applications/ biodegradation/data. Contact: kramer@in.tum.de</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Current methods for the prediction of biodegradation products and pathways of organic environmental pollutants either do not take into account domain knowledge or do not provide probability estimates. In this article, we propose a hybrid knowledge-and machine learning-based approach to overcome these limitations in the context of the University of Minnesota Pathway Prediction System (UM-PPS). The proposed solution performs relative reasoning in a machine learning framework, and obtains one probability estimate for each biotransformation rule of the system. As the application of a rule then depends on a threshold for the probability estimate, the trade-off between recall (sensitivity) and precision (selectivity) can be addressed and leveraged in practice. Results: Results from leave-one-out cross-validation show that a recall and precision of ∼0.8 can be achieved for a subset of 13 transformation rules. Therefore, it is possible to optimize precision without compromising recall. We are currently integrating the results into an experimental version of the UM-PPS server.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In silico methods to predict products and pathways of microbial biotransformations of chemical substances are increasingly sought due to rapidly growing data requirements for regulatory chemical risk assessment at the European (cf. REACH) and global level. Existing methods for the prediction of biotransformation products and pathways can be categorized as either knowledge-or machine learning-based approaches. Each of the two approaches has its strengths and weaknesses. Knowledge-based approaches, such as METEOR for the prediction of mammalian metabolism (<ref type="bibr" target="#b8">Greene et al., 1999</ref>) or the University of Minnesota Pathway Prediction<ref type="bibr">[15:15 19/2/2010 Bioinformatics-btq024.tex]</ref>Page: 815 814–821</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicting biodegradation products and pathways</head><p>e.g. pesticides, biocides or pharmaceuticals. Potential users of such a system such as environmental microbiologists, risk assessors and analytical chemists are overwhelmed by the number of possible products, and find it hard to identify the most plausible products. In an effort to restrict combinatorial explosion, some of the knowledge-based approaches to metabolic prediction employ what is called relative reasoning (<ref type="bibr" target="#b1">Button et al., 2003</ref>). In relative reasoning, the possibility to apply a rule depends on the presence of other applicable rules. Practically, this requires additional rules for the prioritization of rules and the resolution of conflicts. These meta-rules, or relative reasoning rules, express that some reactions take priority over others, and vice versa, and that some reactions only occur if others are not possible. Relative reasoning rules have recently been derived automatically for the set of UM-PPS biotransformation rules and have been successfully implemented into the working UM-PPS (<ref type="bibr" target="#b6">Fenner et al., 2008</ref>). However, although reductions in the number of predicted products in one prediction step of ∼20% were achieved, the selectivity (precision) of UM-PPS still remained rather low, at ∼16–18%. Thus, the question remains how, when a set of rules applied to the structure of a given substrate, we can further refine the process of selecting and accepting those rules that most likely lead to observed products. In this article, we propose a solution that transfers the idea of relative reasoning to a machine learning setting, to further improve the system's selectivity (precision). Rule probabilities are to be estimated such that they depend not only on all other rules that are applicable, but also on the structure of the substrate. The priorities are learned statistically from data on known biodegradation pathways. In our solution, one classifier is learned for each rule, generalizing over the molecular substructures of the substrate and the 'activation patterns' of the rules as given by the set of all other rules that are triggered by the same substrate. Given the availability of such probabilistic classifiers, the decision to accept a product or not can be made dependent on a probability threshold: the application of individual rules can be tuned such that only transformations with a probability above a certain threshold are accepted. In this way, one can also control the generality of whole rule sets and the overall number of products. Thus, it is easy to address the fundamental trade-off between the completeness and the accuracy of predictions. In technical terms, we can analyze the performance of both individual rules and the whole system in recall–precision space, and visualize their performance in 2D plots. Moreover, it is possible to explicitly choose a suitable point in recall– precision space by setting the probability threshold for accepting a rule to a certain level. This article is organized as follows: In Section 2, we explain the method for learning classifiers to restrict the scope of transformation rules. Section 3 presents the data that were used as the basis of our study and some implementation details. In Section 4, the performance measures used to evaluate the results of our experiments are presented and finally, in Section 5, the results themselves are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head><p>To illustrate the problem and the proposed solution, we start with an example shown in<ref type="figure" target="#fig_0">Figure 1a</ref>: given a new compound c new , several rules of the UM-PPS are applicable and suggest possible transformation products. In the example, a subset of rules r 1 ,r 2 ,r 5 , etc., triggers for the given input structure. In the illustration, triggering rules are indicated by solid arrows, rules not triggering by dashed arrows. As mentioned above, the problem is that the rules of the system are overly general, i.e. they suggest a wide range of possible products, many of them false positives. To restrict the number of possible products, it would be desirable to score the proposed transformations by estimated probabilities. In this way, it would also be possible to tune the number of products depending on a user-defined threshold: If the estimated probability of a transformation exceeds a threshold, it is accepted, otherwise it is discarded. The probability for each rule r i is estimated by a corresponding function f i. Function f i tells us how likely a transformation suggested by rule r i is, depending on the structure of the input compound and all other triggering rules. This is illustrated in<ref type="figure" target="#fig_0">Figure 1b</ref>: function f 1 estimates that the probability of obtaining a correct product from applying r 1 to substrate c new is 0.6, given the molecular structure of c new and the other rules applicable (r 2 ,r 5 , ..., r 179 ). The dependency of the decision on all other transformation options reflects the fact that, under certain conditions, one reaction should be given priority over another. If the cut-off was set to 0.5 in the example, we would only accept the transformations proposed by r 1 and r 5. The problem is of course to derive suitable probability scores. In this article, the solution is based on a training set of examples and machine learning. In<ref type="figure" target="#fig_0">Figure 1c</ref>, a sample of three compounds from a hypothetical training database is shown. For the three training compounds, we assume that we not only know which rules are applicable, but also which rule applications lead to observed products. In the figure, the observed transformation products are indicated by a check mark, whereas the spurious products are indicated by a cross. Given this information, it is possible to learn under which conditions the suggested product of a transformation rule can actually be observed. As a classifier is only needed when a rule triggers, the training set for a rule also includes only those compounds for which the rule suggests a product.<ref type="figure" target="#fig_0">Figure 1d</ref>shows two training sets constructed from the three training compounds c 1 –c 3 , one for rule r 1 (upper table) and one for rule r 2 (lower table). The first group of features (s 1 ,...,s m ) is a fingerprint-based representation of the structure of the input compound. The second group of features (all r 1 ,...,r 179 except the rule for which the classifier is built) indicates which other rules are applicable to the compound: a feature is set to +1, if the corresponding rule fires, and 0, otherwise. As explained above, the training set for f 1 does not contain an entry for c 2 , because rule r 1 is not applicable to that compound. Similarly, c 1 is not listed in the training set for f 2 , because rule r 2 cannot be applied. Also note that c 3 is a positive example for f 1 , whereas it is a negative example for f 2. Given such training sets, any machine learning algorithm for classification can be applied to induce a mapping from the structural and rule descriptors to the target variable, i.e. whether a rule generates an observed product. To be more precise (amongst others, to enable reproducibility), we have to introduce some notation: in the following, C denotes the set of compounds c i , and R the set of rules r j. Then triggers(r j ,c i ) is a predicate indicating whether r j triggers on compound c i. Moreover, observed(r j ,c i ) is a predicate indicating that rule r j fires and provides an observed degradation product. For instance, we have the following list of facts for c 1 and c 2 , and r 1 to r 3 from<ref type="figure" target="#fig_0">Figure 1c</ref>:</p><formula>triggers(r 1 ,c 1 ). triggers(r 3 ,c 1 ). observed(r 3 ,c 1 ). triggers(r 5 ,c 1 ). observed(r 5 ,c 1 ). triggers(r 2 ,c 2 ). observed(r 2 ,c 2 ). triggers(r 4 ,c 2 ).</formula><p>Finally, S denotes the set of molecular substructures s l , and predicate occurs(s l ,c i ) checks the occurrence of a substructure s l in a compound c i. To prepare for training, we need two transformation operators, one for the construction of individual examples, and one for the construction of whole</p><p>Page: 816 814–821</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Wicker et al.</head><formula>(a) (b) (c) (d)</formula><formula>τ instance (c i ,k) = x i suchthat x i,j = occurs(s j ,c i ) for 1 ≤ j ≤ |S|∧ x i,j = triggers(r j −|S|,c i ) for |S| &lt; j ≤|S|+k −1∧ x i,j = triggers(r j −|S|+1,c i ) for |S|+k −1 &lt; j ≤|R|+|S|−1</formula><p>This means that operator τ instance (c i ,k) constructs the description of an individual example without its class information. It takes a compound c i and constructs a feature vector (see the example above), taking into account substructures and applicable rules. Parameter k is used to exclude the information for the k-th rule, which is convenient for our purposes, because it constitutes the target for training. Making use of τ instance (c i ,k), we are ready to define a transformation operator generating a training or test set for rule k from a given set of compounds C: τ set takes a compound c i from C and checks whether rule k triggers. Only if this is the case, a training example</p><formula>(x i ,y i ) is constructed: τ set (C,k) ={(x i ,y i )|c i ∈ C∧ triggers(r k ,c i )∧ x i = τ instance (c i ,k)∧ y i = 1if observed(r k ,c i ), y i = 0 otherwise}</formula><p>In the above example, τ set ({c 1 ,c 2 ,c 3 ,...,c 718 },1) gives us the training set for classifier f 1 shown in the upper table of<ref type="figure" target="#fig_0">Figure 1d</ref>, τ set ({c 1 ,c 2 ,c 3 ,...,c 718 },2) gives us the training set for f 2 in the lowertrain returns the classifiers needed for the restriction of the rules based on such training sets. As already indicated above, classifiers are represented as functions f j returning class probability estimates for given examples. Given those preliminaries, we can explain how training and testing is performed and how it is embedded into the working system (see Algorithm 1 for the pseudocode). In the training phase, a classifier is trained for each rule in turn. In the testing phase, we first obtain a list of rules applicable to each test compound using the UM-PPS. If a rule triggers, we apply the rule's classifier to the instance, where information from the molecular structure and all competing rules is taken into account to obtain a probability estimate. If this estimate exceeds a threshold θ, the product suggested by rule r k is accepted, otherwise, the proposed transformation is rejected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicting biodegradation products and pathways</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DATA AND IMPLEMENTATION</head><p>It is possible to validate the above procedure by running a crossvalidation over the compounds of the UM-BBD database. This can be optimized considerably, if the predicates triggered, observed and occurs are precomputed once for all compounds and stored for later use. In our implementation, we precomputed a |C|×|R| table indicating the rules' behavior on the UM-BBD compounds: the value +1 of an entry encodes that a rule is triggered and produces an observed product, 0 encodes that a rule is triggered but the product is not observed, and −1 encodes that the rule is not triggered for a given compound. Simple database and arithmetic operations can then be applied to extract training and test sets, e.g. for (leave-oneout) cross-validation. Additionally, we learned the classifiers on the complete dataset and tested our approach on an external validation set of 25 xenobiotics (pesticides), which was also used in previous work (<ref type="bibr" target="#b6">Fenner et al., 2008</ref>). 1 Pesticide biodegradation data is the largest cohesive dataset available, because these compounds are made to be put into the environment and are among the most heavily regulated class of chemicals. The matrix encoding described above was applied to the UMBBD/UM-PPS from July 24, 2007, containing 1084 compounds and 204 biotransformation rules (btrules). Of these, 366 compounds not triggered by any rule (terminal compounds of reported pathways, compounds containing metals or other compounds whose biodegradation should not be predicted) were removed. Likewise, 25 strictly anaerobic (unlikely or very unlikely) btrules and btrules not triggered by any compounds in the UM-BBD were removed. Finally, 48 transformation rules triggered by only one structure were removed from the set. The remaining 718 UM-BBD compounds were submitted to 131 UM-PPS btrules. The predicate triggered was then defined to be true if a rule applied to a compound, and observed was defined to be true if the product could be found in the database. The class distribution in the dataset is very diverse (<ref type="figure" target="#fig_3">Fig. 2</ref>). There are only few transformation rules with both a balanced class distribution and a sufficient number of structures triggering them. Thus, we decided to implement classifiers for a subset of the transformation rules. We chose rules that provide at least a certain amount of information for the construction of the classifiers. The transformation rules are needed to be triggered by at least 35 structures. On the other hand, for the ratio of 'correct triggers', we set a minimum of at least 0.15. These parameters seem sufficient to cover a sufficient number of cases and exclude overly skewed class distributions. Varying the parameters in further experiments did not lead to an improvement of the results. Of the 131 transformation rules in the training set, this leaves 13 rules for the validation process (<ref type="figure" target="#tab_1">Table 1</ref>). Considering the class distribution and number of examples of the remaining rules, it is not reasonable to learn classifiers for these transformation rules. To compare the results with previous work and to evaluate all transformation rules, we generated a default classifier (DC) for these rules which predicts the ratio of positive examples as the probability to produce a correct product. Thus, if the chosen threshold is below 1 Those 25 pesticides were also tested in our previous experiments investigating the sensitivity and selectivity of the method [see<ref type="figure">Table 6</ref>in (<ref type="bibr" target="#b6">Fenner et al., 2008)]</ref>. Twenty-two other xenobiotics (pharmaceuticals) were only used for determining the reduction of predictions [see<ref type="figure">Table 4</ref>in (<ref type="bibr" target="#b6">Fenner et al., 2008</ref>the ratio of positive examples, all structures are predicted as positive, i.e. they are predicted to trigger this transformation rule correctly. For the computation of frequently occurring molecular fragments, we applied the FreeTreeMiner system (<ref type="bibr" target="#b17">Rückert and Kramer, 2004</ref>), as it builds on a computer chemistry library to handle structures and substructures conveniently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PERFORMANCE MEASURES</head><p>Clearly, we are facing a fundamental trade-off also found in many other applications of machine learning and classification: if the Page: 818 814–821</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Wicker et al.</head><p>rules are too general, we will not miss many positive examples, but we might also include too many false positives. Vice versa, if the rules are too specific, we probably have few false positives, but we will potentially miss too many positives. It is convenient to think of this trade-off in terms of recall (sensitivity) and precision (selectivity). If the overall system predicts an observed product for a given substrate, we can count this as a true positive. If the system predicts a product that is not observed, we have a false positive. If a product is missing for a substrate, we have a false negative. 2 The number of true positives is denoted by TP, the number of false positives by FP and the number of false negatives by FN. Then the standard definitions of recall (sensitivity) and precision (selectivity) can be applied:</p><formula>R = Sensitivity = TP TP+FN P = Selectivity = TP TP+FP</formula><p>The overall number of products predicted by the system critically depends on the cut-off parameter θ. To evaluate the performance of the system, this parameter does not need to be fixed in advance. Instead, the parameter can be varied over the whole range from 0 to 1, and the resulting values for R and P can be plotted in two dimensions: recall is plotted on the x-axis and precision on the y-axis. Recall–precision plots offer an easy and intuitive visualization of the trade-offs involved in choosing a certain value of θ. Also the results of approaches without cut-off parameters (e.g. relative reasoning as discussed above) appear as single data points in recall–precision space. Recall–precision analysis can be performed on the system level as well as on the level of individual rules. In principle, one could set the threshold individually for each rule, but this would introduce a large number of parameters. For simplicity, we chose to visualize the system's performance below by applying the same threshold for all rules. Also, as individual classifier schemes should be sensitive and adaptive to different class distributions, one parameter for all should work reasonably well in the first approximation. In addition to recall–precision analysis, we measure the area under the receiver operating characteristic (ROC) curve, which indicates the capability of a classifier to rank the examples correctly (<ref type="bibr" target="#b2">Cortes and Mohri, 2004</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL RESULTS</head><p>In the following, we present the experimental results obtained with our approach. After introducing various learning schemes and settings, we present the results on the xenobiotics test set and, more importantly, our main results from a leave-one-out cross-validation over the UM-BBD structures. For the 13 transformation rules in the subset, we applied the Random Forest algorithm (<ref type="bibr" target="#b0">Breiman, 2001</ref>) in the implementation 2 We count the false negatives in a slightly different way than in a previous paper (<ref type="bibr" target="#b6">Fenner et al., 2008</ref>), as we only consider products that are suggested by any of the biotransformation rules. In other words, we do not take into account products of reactions that are not subsumed by any of the rules. This is done because only for the products suggested by the UM-PPS, the method proposed here becomes effective—the classifiers can only restrict the rules, not extend them. of the Weka workbench (<ref type="bibr" target="#b20">Witten and Frank, 1999</ref>), because it gave good probability estimates in preliminary experiments. As a second classifier, we used Support Vector Machines (SVMs) trained using sequential minimal optimization (<ref type="bibr" target="#b15">Platt, 1999a</ref>) in the implementation of the Weka workbench. We automatically adjusted the complexity constant of the support vector machine for each transformation rule separately. We used a 10-fold cross-validation to generate the data for the logistic models (<ref type="bibr" target="#b16">Platt, 1999b</ref>) to obtain wellcalibrated class probability estimates. 3 For the DC on the remainingPage: 819 814–821The columns LC and DC indicate the number of transformation rules used for the LC, SVMs or Random Forests, and the DC, ZeroR. The value of θ is determined manually considering the trade-off between recall and precision. We chose the threshold manually at an approximate optimum for recall and precision to provide a comparison to previous work (<ref type="bibr" target="#b6">Fenner et al., 2008</ref>). AUC is threshold independent and only given for the new approach. The column with the variant refers to the assignment of rules to the different classifiers and is explained in the text. structural similarity between test and training structures is higher than in the validation with the 25 xenobiotics as test structures. Our main results from leave-one-out over the UM-BBD compounds are visualized in the recall–precision plots of<ref type="figure" target="#fig_7">Figure 3</ref>and shown quantitatively in<ref type="figure">Table 2</ref><ref type="figure" target="#fig_7">Figure 3b</ref>and d uses the DC for the remaining rules. The plots tend to flatten while including predictions of the DC. The overall performance does not differ too much between Random Forest and SVMs. Using both classification methods, we can achieve recall and precision of slightly less than 0.8 (see<ref type="figure" target="#fig_7">Fig. 3a</ref>and c and also the values for 13+0 in the lower part of<ref type="figure">Table 2</ref>) for the LC only in a leave-one-out cross-validation. The quantitative results in<ref type="figure">Table 2</ref>also show that the performance of Random Forests and SVMs are on a similar level. Also in this case, the performance of LCs complemented by DCs is nearly as good as the performance of the LCs for all rules, supporting the idea of having such a mixed (LC and DC) approach. 5 However, in this case, the machine learning component consisting of 13 LCs only, as expected, performs better on average than the overall system with 118 DCs added. In summary, the AUC scores are satisfactory, and the recall–precision scores of ∼0.8 of the machine learning component show that improvements in precision are possible without compromising recall too much. Therefore, the machine learning approach provides some added value compared with the relative reasoning approach developed previously (<ref type="bibr" target="#b6">Fenner et al., 2008</ref>).On the lefthand side (a and c), only the results of classifiers on a subset of the rules is shown. On the right-hand side (b and d), classifiers were generated for the same subset and a DC is used for the remaining rules. The subset was chosen by using transformation rules with at least 35 triggered examples and a minimum ratio of known products of 0.15. Using these parameters, 13 transformation rules were selected. The threshold θ is given in 10 steps per plot. Note that the points in recall–precision space are connected by lines just to highlight their position: in contrast to ROC space, it is not possible to interpolate linearly. To evaluate the enhancement of using both the structural information and the expert knowledge in the transformation rules, we applied the new method individually to the dataset leaving out the structure and, in a second run, the transformation rules. As it tends to give smoother probability estimates, we focus on Random Forest classifiers here and in the remainder of the section. Using only the structural information gives an AUC of 0.895, whereas the transformation rules only give an AUC of 0.885. Taken together, we can observe an AUC of 0.902, which, despite the apparent redundancy for the given dataset, marks an improvement over the results of the individual feature sets. An example prediction of the biotransformation of a structure is given in<ref type="figure" target="#fig_8">Figure 4</ref>. We applied our approach to amitraz, a pesticide from the xenobiotics dataset. The incorrectly triggered transformation rules all get a rather low probability, while bt0063, a correctly triggered rule, is the only transformation rule being predicted with a probability higher than 0.53. As the xenobiotics dataset is very small, we generated Random Forest classifiers for every transformation rule triggered by this structure for the purpose of the example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicting biodegradation products and pathways</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND CONCLUSION</head><p>We presented a combined knowledge-and machine learning-based approach to the prediction of biodegradation products and pathways. The proposed solution performs relative reasoning in a machine learning framework. One of the advantages of the approach is that probability estimates are obtained for each biotransformation rule.Thus, the results are tunable and can be analyzed in recall– precision space. Making the trade-off between recall (sensitivity) and precision (selectivity) explicit, one can choose whether one or the other is more important. In contrast to CATABOL, the approach works on the level of rules and not on the level of pathways. In CATABOL, the structure of pathways has to be laid out in advance in order to solve the equations based on the training data. To make the computations more stable, reactions have to be grouped using expert knowledge. In contrast, we apply the rules to the training structures to extract a matrix, which is the basis for the creation of the training sets for each rule. CATABOL learns parameters for a fixed pathway structure, whereas the approach proposed here learns classifiers for (individual) transformation rules. During testing, only the pathways laid out for training can be used for making predictions in CATABOL. In contrast, the approach presented here predicts one transformation after the other according to the rules' applicability and priority determined by the classifiers. Overall, the training of CATABOL requires more human intervention than our approach, e.g. for grouping and defining hierarchies of rules (<ref type="bibr" target="#b3">Dimitrov et al., 2004</ref>). One might speculate (i) which other methods could be used to address this problem, and (ii) where the proposed solution could be applied elsewhere. Regarding (i), it appears unlikely that human domain experts would be able and willing to write complex relative reasoning rules as the ones derived in this work. Alternatively, other machine learning schemes could be used to solve the problem, for instance, methods for the prediction of structured output (<ref type="bibr" target="#b10">Joachims et al., 2009</ref>) or multi-label classification (<ref type="bibr" target="#b19">Tsoumakas et al., 2009</ref>). Methods for the prediction of structured output should be expected to require a large number of observations to make meaningful predictions. Also, with the availability of transformation rules, the output space is already structured and apparently much easier to handle than the typically much less-constrained problem of structured output. Since multi-label classification seems particularly promising to address the problem described here, we are planning to investigate its use in future work. Regarding (ii), the approach could be used wherever expert-provided over-general transformation rules need to be restricted and knowledge about transformation products is available. It would be tempting to use the same kind of approach for other pathway databases like KEGG, if they were extended toward pathway prediction systems such as the UM-BBD. Our extended pathway prediction system could also be used as a tool in combination with toxicity prediction, as the toxicity of transformation products often exceeds the toxicity of their parent compounds (<ref type="bibr" target="#b18">Sinclair and Boxall, 2003</ref>). The procedure would be first to predict the degradation products and then use some (Q)SAR model to predict their toxicity. Currently, we are integrating the resulting approach into an experimental version of the UM-PPS server. In the future, it may become necessary to adapt the method to more complex rule sets, e.g. (super-)rules composed of other (sub-)rules. Such complex rule sets should be useful for the representation of cascades of reactions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. (a) Indication of the rules applicable to an input compound c new by solid arrows. (b) Illustration of the use of one classifier for each rule to determine the probability of obtaining a proper product, depending on the structure and other applicable rules. (c and d) Examples for the construction of two training sets, one for f 1 (upper table) and other for f 2 (lower table).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>[15:15 19/2/2010 Bioinformatics-btq024.tex] Page: 817 814–821</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Characteristics of datasets for rules: size (number of triggered compounds) and class distribution (fraction of correctly triggered compounds). The 13 transformation rules used in the subset are marked. The dotted lines are the cutoffs (number = 35, fraction = 0.15) used to select the subset (see text).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Table1.</head><figDesc>List of the 13 transformation rules in the subset used for prediction Rule Description bt0001 Primary Alcohol → Aldehyde bt0002 Secondary Alcohol → Ketone Secondary Alcohol → Ester bt0003 Aldehyde → Carboxylate bt0008 vic-Dihydroxybenzenoid → extradiol ring cleavage bt0029 organoHalide → RH bt0036 Aromatic Methyl → primary Alcohol bt0040 1-Aldo/keto-2,4-diene-5-ol → Carboxylate + 1-ene-4-one bt0055 1-carboxy-2-unsubstituted Aromatic → Catechol derivative bt0060 vic-Hydroxycarboxyaromatic → Catechol derivative vic-Aminocarboxyaromatic → Catechol derivative bt0063 Primary Amine → Aldehyde or Ketone Secondary Amine → Amine + Aldehyde or Ketone Tertiary Amine → secondary Amine + Aldehyde or Ketone Methylammonium derivative → Trimethylamine + Aldehyde or Ketone bt0065 1-Amino-2-unsubstituted aromatic → vic-Dihydroxyaromatic + Amine bt0254 vic-Dihydroxyaromatic → intradiol ring cleavage vic-Dihydroxypyridine → intradiol ring cleavage bt0255 vic-Dihydrodihydroxyaromatic → vic-Dihydroxyaromatic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>. Figure 3a and b shows the plots of the Random Forest classifiers and Figure 3c and d displays the results of the SVMs. Figure 3a and c shows the results of the classifiers on the 13 transformation rules in the subset and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.3.</head><figDesc>Fig. 3. Recall–precision plots from a leave-one-out cross-validation using the Random Forest classifier (a and b) and SVMs (c and d). On the lefthand side (a and c), only the results of classifiers on a subset of the rules is shown. On the right-hand side (b and d), classifiers were generated for the same subset and a DC is used for the remaining rules. The subset was chosen by using transformation rules with at least 35 triggered examples and a minimum ratio of known products of 0.15. Using these parameters, 13 transformation rules were selected. The threshold θ is given in 10 steps per plot. Note that the points in recall–precision space are connected by lines just to highlight their position: in contrast to ROC space, it is not possible to interpolate linearly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.4.</head><figDesc>Fig. 4. Application of the new method to amitraz, a compound from the xenobiotics dataset. For each transformation rule triggered by this structure, an example product is given. Some of the transformation rules can produce more than one product from this structure. We applied Random Forest classifiers to the structure. The numbers indicate the predicted probability that the corresponding transformation rule produces a known product. From the transformations predicted by the UM-PPS, only bt0063 produces a known product. As shown in the figure, this is the only transformation rule with a relatively high predicted probability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><figDesc>Funding: Fellowship for advanced researchers from the Swiss National Science Foundation (PA002-113140 to K.F.), Lhasa Limited, the US National Science Foundation (NSF0543416); the University of Minnesota Supercomputing Institute. EU FP7 project OpenTox Health-F5-2008-200787. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>table. A training procedure Algorithm 1 Pseudocode for training and testing classifiers for biotransformation rules % training one classifier per rule for all rule r k do D k Trg := τ set (C Trg ,k) f k := train(D k Trg ) end for % testing for a new test compound c new % the cut-off for acceptance is given by parameter θ for all rule r k do if triggers(r k ,c new ) then if f k (τ instance (c new ,k)) &gt;θ then classify as " product of k " else classify as " no product of k " end if end if end for</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. Recall and precision for one threshold (on the predicted probability of being in the positive class) of the machine learning approach and for relative reasoning Method Variant LC DC θ Recall Precision AUC</figDesc><table>Xeno-RF 
(a) 
13 0 
0.417 0.400 0.333 
0.505 
biotics RF 
(b) 
13 118 0.296 0.525 0.447 
0.676 
RF 
(c) 
131 0 
0.35 0.475 0.404 
0.664 
SVM 
(a) 
13 0 
0.023 0.800 0.235 
0.389 
SVM 
(b) 
13 118 0.296 0.475 0.463 
0.674 
SVM 
(c) 
131 0 
0.157 0.410 0.390 
0.599 
RR 
– 
– 
– 
– 
0.950 0.242 
– 

UM-
RF 
(a) 
13 0 
0.600 0.777 0.788 
0.902 
BBD RF 
(b) 
13 118 0.308 0.595 0.594 
0.842 
RF 
(c) 
131 0 
0.485 0.653 0.632 
0.857 
SVM 
(a) 
13 0 
0.329 0.813 0.771 
0.903 
SVM 
(b) 
13 118 0.294 0.582 0.588 
0.841 
SVM 
(c) 
131 0 
0.250 0.632 0.623 
0.833 
RR 
– 
– 
– 
– 
0.942 0.267 
– 

</table></figure>

			<note place="foot">* To whom correspondence should be addressed. System (UM-PPS) for microbial biodegradation (Hou et al., 2004) take into account expert knowledge on the basis of sets of transformation rules. However, they run the risk of including potentially overly general, incomplete or inconsistent rules. In contrast, machine learning approaches produce accurate probability estimates on the basis of empirical data, but often lack the ability to incorporate prior domain knowledge. Also, recent machine learning approaches for biotransformation prediction only predict quite general classes [e.g. whether a compound plays a role in central metabolism (Gomez et al., 2007) or whether it is the substrate of some broad reaction class, e.g. oxidoreductase-catalyzed reactions (Mu et al., 2006)]. The goal of this article is to combine the two approaches: we assume a given set of biotransformation rules and learn the probability of transformation products proposed by the rules from known, experimentally elucidated biodegradation pathways. Only two comparable systems exist so far: META (Klopman et al., 1997) that is similar in spirit, but uses a less-advanced problem formulation and machine learning approach than the one presented here, and CATABOL (Dimitrov et al., 2007), the only rule-based method explicitly aiming for probability estimates. However, the CATABOL system works with a fixed pathway structure for training, which is different from the approach presented here working on the basis of individual rules (for a detailed discussion, see Section 6). Rule-based systems, such as UM-PPS, work on the basis of rules that are generalizations and abstractions of known reactions, in the case of UM-PPS, its underlying Biocatalysis/Biodegradation Database (UM-BBD; Ellis et al., 2006). UM-BBD is a manually curated compilation of over 200, experimentally elucidated microbial biotransformation pathways, encompassing enzymatic reactions for roughly 1000 parent compounds and intermediates. If certain functional groups of a query substrate match with any of the biotransformation rules in UM-PPS, then its structure is transformed into one or several products according to the rule(s). These rules are typically fairly general, either to cover all known reactions, or because there is not enough information known to restrict them. As a consequence, UM-PPS produces a large number of possible reaction products, especially when used to predict several subsequent generations of transformation products. This combinatorial explosion is a phenomenon also known from other rule-based systems and approaches. It is particularly aggravated for the structurally more complex contaminants of current concern,</note>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="118"> transformation rules, we used the ZeroR algorithm of the Weka workbench. In total, we evaluated three variants: (a) 13 learned classifiers (LC) (i.e. Random Forests or SVMs) only, (b) 13 LCs and 118 DC and (c) 131 LCs (without DCs). The idea of (a) is to evaluate the performance of the machine learning component of the system only. In (b), the overall performance of the system is evaluated, where 13 classifiers are complemented by 118 DCs. The purpose of (c) is to show whether the DCs are really sufficient, or whether LCs should be used even when samples are very small and classes are unequally distributed. All the results are shown in terms of manually chosen points in recall–precision space (e.g. before inflection points) as well as the area under the ROC curve (AUC). The possibility to choose thresholds manually is one of the advantages of working in recall–precision and ROC space: instead of fixing the precise thresholds in advance, it is possible to inspect the behavior over a whole range of cost settings, and set the threshold accordingly. Finally, we compare the results to the performance of relative reasoning. 4 For compatibility with a previous paper (Fenner et al., 2008), we start with the results of training on all UM-BBD compounds and testing on the set of 25 xenobiotics. The results are given in the upper part of Table 2. It should be noted that in this case the DCs were &apos;trained&apos; on the class distributions of the UM-BBD training data, and subsequently applied to the external xenobiotics test set. First, we observe that ROC scores are on a fairly good level. The results in recall–precision space indicate that variant (b) is as good as variant (c). However, with an AUC of ∼0.5, having 13 LCs only [variant (a)], performs on the level of random guessing. An indepth comparison of the two sets of structures (UM-BBD and xenobiotics) shows that this can be attributed to (i) the low structural similarity between the two sets, and (ii) the fact that a very limited set of rules trigger at all for the xenobiotics [a consequence of (i)]. The average number of free tree substructures per compound is 48.76 in the xenobiotics dataset, whereas it is 65.24 in the UM-BBD dataset. Due to this structural dissimilarity, the transfer from one dataset to the other is a hard task. Therefore, we decided to perform a leaveone-out cross-validation over all UM-BBD compounds, where the 3 It should be noted that any other machine learning algorithm for classification and, similarly, any other method for the computation of substructural or other molecular descriptors could be applied to the problem. 4 We cannot compare our results with those of CATABOL, because the system is proprietary and cannot be trained to predict the probability of individual rules—the pathway structure has to be fixed for training (for details we refer to Section 6). This means that CATABOL addresses a different problem than the approach presented here.</note>

			<note place="foot" n="5"> In other words, it shows that informed classifiers do not pay off for the rest of the rules.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Using absolute and relative reasoning in the prediction of the potential metabolism of xenobiotics</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">G</forename>
				<surname>Button</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inf. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1371" to="1377" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">AUC optimization vs. error rate minimization</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Cortes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Mohri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 16</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Predicting the biodegradation products of perfluorinated chemicals using catabol</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dimitrov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SAR QSAR Environ. Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="82" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A kinetic model for predicting biodegradation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dimitrov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SAR QSAR Environ. Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="443" to="457" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">The university of minnesota biocatalysis/biodegradation database: the first decade</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">B</forename>
				<surname>Ellis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="517" to="521" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Data-driven extraction of relative reasoning rules to limit combinatorial explosion in biodegradation pathway prediction</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Fenner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2079" to="2085" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">The environmental fate of organic pollutants through the global microbial metabolism</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Gomez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">114</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge-based expert systems for toxicity and metabolism prediction: DEREK, StAR and METEOR</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Greene</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SAR QSAR Environ. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Encoding microbial metabolic logic: predicting biodegradation</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">K</forename>
				<surname>Hou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Ind. Microbiol. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="261" to="272" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Predicting structured objects with support vector machines</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Joachims</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="97" to="104" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Meta 3 a genetic algorithm for metabolic transform priorities optimization</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Klopman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inf. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="329" to="334" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Prediction of oxidoreductase-catalyzed reactions based on atomic properties of metabolites</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Mu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="3082" to="3088" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Bioinformatics-btq024.tex] Page</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="15" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">Predicting biodegradation products and pathways</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast training of support vector machines using sequential minimal optimization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Platt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel Methods: Support Vector Learning</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="185" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Platt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Frequent free tree discovery in graph data</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Rückert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kramer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SAC&apos;04: Proceedings of the 2004 ACM symposium on applied computing</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="564" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Assessing the ecotoxicity of pesticide transformation products</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sinclair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Boxall</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Environ. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="4617" to="4625" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Mining multi-label data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Tsoumakas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining and Knowledge Discovery Handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">H</forename>
				<surname>Witten</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Frank</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>