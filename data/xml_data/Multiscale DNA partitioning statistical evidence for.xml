
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiscale DNA partitioning: statistical evidence for segments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Andreas</forename>
								<surname>Futschik</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Statistics</orgName>
								<orgName type="institution">JK University Linz</orgName>
								<address>
									<postCode>A-4040</postCode>
									<settlement>Linz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Thomas</forename>
								<surname>Hotz</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Mathematics</orgName>
								<orgName type="institution">Technische Universitä t Ilmenau</orgName>
								<address>
									<postCode>D-98693</postCode>
									<settlement>Ilmenau, Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Axel</forename>
								<surname>Munk</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Institute for Mathematical Stochastics</orgName>
								<orgName type="institution">Felix Bernstein Institute for Mathematical Statistics in Biosciences</orgName>
								<address>
									<country key="GE">Georgia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Augusta University of Goettingen</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Max Planck Institute for Biophysical Chemistry</orgName>
								<address>
									<postCode>D-37077</postCode>
									<settlement>Goettingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Hannes</forename>
								<surname>Sieling</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Institute for Mathematical Stochastics</orgName>
								<orgName type="institution">Felix Bernstein Institute for Mathematical Statistics in Biosciences</orgName>
								<address>
									<country key="GE">Georgia</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Augusta University of Goettingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">John</forename>
								<surname>Hancock</surname>
							</persName>
						</author>
						<title level="a" type="main">Multiscale DNA partitioning: statistical evidence for segments</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">16</biblScope>
							<biblScope unit="page" from="2255" to="2262"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu180</idno>
					<note type="submission">Sequence analysis Advance Access publication April 21, 2014 Received on August 6, 2013; revised on March 28, 2014; accepted on April 1, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Supplementary information: Supplementary Data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: DNA segmentation, i.e. the partitioning of DNA in com-positionally homogeneous segments, is a basic task in bioinformatics. Different algorithms have been proposed for various partitioning criteria such as Guanine/Cytosine (GC) content, local ancestry in population genetics or copy number variation. A critical component of any such method is the choice of an appropriate number of segments. Some methods use model selection criteria and do not provide a suitable error control. Other methods that are based on simulating a statistic under a null model provide suitable error control only if the correct null model is chosen. Results: Here, we focus on partitioning with respect to GC content and propose a new approach that provides statistical error control: as in statistical hypothesis testing, it guarantees with a user-specified probability 1 À that the number of identified segments does not exceed the number of actually present segments. The method is based on a statistical multiscale criterion, rendering this as a segmen-tation method that searches segments of any length (on all scales) simultaneously. It is also accurate in localizing segments: under benchmark scenarios, our approach leads to a segmentation that is more accurate than the approaches discussed in the comparative review of Elhaik et al. In our real data examples, we find segments that often correspond well to features taken from standard University of California at Santa Cruz (UCSC) genome annotation tracks. Availability and implementation: Our method is implemented in function smuceR of the R-package stepR available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>It has been observed a long time ago (<ref type="bibr" target="#b26">Sueoka, 1962</ref>) that DNA sequences are not composed homogeneously and that bases fluctuate in their frequency. These inhomogeneities often have an evolutionary or a functional interpretation, and can be relevant for the subsequent analysis of sequence data. Because it correlates with many features of interest, the GC content, i.e. the relative frequency of the bases G and C, is one of the most commonly studied sequence properties. Large-scale regions, typically 300 kb (<ref type="bibr" target="#b2">Bernardi, 2001</ref>), of approximately homogeneous GC content have been called isochores. In view of the somewhat vague notion of 'approximate homogeneity' and conceptual criticism in studies such as<ref type="bibr" target="#b10">Cohen et al. (2005)</ref>or<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>, there is less interest in isochores nowadays. However, there is no doubt about variation in GC content along genomes, and search is done instead for domains of any length exhibiting distinct local GC content; see, for instance, Elhaik et al. (2010b). Several factors can influence the GC content of a region. At larger scales, it correlates with the density of genes, with gene-rich regions typically exhibiting an elevated GC content compared with regions of low gene density. At smaller scales, there is fluctuation in the GC content, for instance, because of repetitive elements and GpC islands. The GC content is also known to vary between exons and introns. Especially for long introns, their lower GC content seems to play a role in splice site recognition (<ref type="bibr" target="#b0">Amit et al., 2012</ref>). There is also a correlation between the GC content and the local recombination rate (<ref type="bibr" target="#b20">Fullerton et al., 2001;</ref><ref type="bibr" target="#b21">Galtier 2001</ref>). For a further discussion of features correlated to the GC content, see<ref type="bibr" target="#b19">Freudenberg et al. (2009)</ref>. In gene expression studies, regions of homogeneous GC content are of interest because the GC content of a region affects the number of reads mapped to this region. For DNA and RNA-seq experiments with the Illumina Genome Analyzer platform, this has been, for instance, investigated in Benjamini and Speed (2012) and<ref type="bibr" target="#b25">Risso et al. (2011)</ref>. Segmentation algorithms aim to partition a given DNA sequence into stretches that are homogeneous in their composition but differ from neighboring segments. The classical approach of using moving windows is simple and available, for instance, as an option with the UCSC and Ensembl genome browsers. However, it has some disadvantages. For instance, the choice of the window size is difficult because it defines implicitly a fixed scale at which segments primarily will be detected. Further, the involved smoothing blurs abrupt changes. Without additional statistical criteria, the method also does not tell us whether differences between neighboring windows are statistically significant. Therefore, several more sophisticated approaches have been proposed. These methods include hidden Markov models (<ref type="bibr" target="#b7">Churchill, 1989</ref><ref type="bibr" target="#b8">Churchill, , 1992</ref>) and walking Markov models (<ref type="bibr" target="#b16">Fickett et al., 1992</ref>). There are also change-point methods available; see, for instance,<ref type="bibr" target="#b5">Braun et al. (2000)</ref>. A Bayesian approach *To whom correspondence should be addressed. that relies on the Gibbs sampler has been proposed by<ref type="bibr" target="#b22">Keith (2006)</ref>. An older approach based on information criteria can be found in<ref type="bibr" target="#b24">Oliver et al. (1999)</ref>. Furthermore, recently developed methods based on entropy criteria have been shown to perform particularly well; see Elhaik et al. (2010a) and Elhaik et al. (2010b). A review of segmentation methods can be found in the article by Braun and Muïler (1998), and for a more recent comparative evaluation of the more popular approaches, see<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>. In this paper, we focus on binary segmentation, where the four-letter alphabet of a DNA sequence is converted into a two-letter code. For GC content, we set the response to be '1' for G or C at a position and 0 for A/T; we use Y i to denote the response at position i and summarize the responses for a sequence of length n by Y ¼ ðY 1 , Y 2 ,. .. , Y n Þ: ð1Þ</p><p>We model the responses Y i to be independent and Bernoulli Binð1, i Þ distributed, and also assume that there is a partition 0 ¼ 0 5 1 5 Á Á Á 5 K ¼ n into an unknown number K of segments on which the i are piecewise constant, i.e. i ¼ p j for i 2 I j. Here, I j :¼ ð jÀ1 , j  denotes the j'th segment with response probability p j for 1 j K. A segmentation algorithm provides estimates ^ K for the number of segments, for the internal segment boundaries,</p><formula>0 ¼ ^ 0 5 ^ 1 5 ^ 2 5 Á Á Á 5 ^ ^ KÀ1 5 ^ ^ K ¼ n, ð2Þ</formula><p>and for the response probabilities, ^ p j , on the estimated segments</p><formula>^ I j :¼ ð ^ jÀ1 , ^ j .</formula><p>In the following, we will identify a segmentation with ðp, IÞ, where p ¼ ðp 1 ,. .. , p K Þ and I ¼ ðI 1 ,. .. , I K Þ. Our proposed algorithm provides a parsimonious estimate ^ K for K: ^ K will not exceed the actual number of segments K, except for a small user-specified error probability ; as a default value, we suggest ¼ 5%, the error probability also chosen in our simulations and data analyses. Relaxing this significance level to a larger value, say ¼ 20%, will typically lead to more identified segments but at the cost of statistical accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head><p>Our proposed multiscale segmentation provides estimates for the number of segments and their boundaries at the same time. We use a certain multiscale statistic that will ensure that the estimator fits the data well on all segments simultaneously, i.e. the number of segments is not underestimated with high probability. This estimator is based on<ref type="bibr" target="#b17">Frick et al. (2014)</ref>who proposed a general statistical multiscale change-point estimator (SMUCE) for exponential family models. Exponential families include many classes of well-known distributions, such as the Gaussian (normal) class, the Poisson class or the Bernoulli class, which is of particular interest for this article. In the Gaussian setting, a related estimator has also been suggested in<ref type="bibr" target="#b11">Davies et al. (2012)</ref>. Forerunners of SMUCE are based on a penalized likelihood with a penality that depends on the number of jumps; see, e.g.<ref type="bibr" target="#b29">Yao (1988</ref><ref type="bibr" target="#b5">), Braun et al. (2000</ref><ref type="bibr" target="#b28">), Winkler et al. (2002</ref><ref type="bibr" target="#b3">), Boysen et al. (2009</ref>and the introduction in<ref type="bibr" target="#b17">Frick et al. (2014)</ref>for a brief survey. The underlying multiscale statistic is based on the work of<ref type="bibr">Duëmbgen et al. (2001)</ref>; see also<ref type="bibr">Duëmbgen et al. (2008) and</ref><ref type="bibr" target="#b27">Walther (2010)</ref>. For a general description of the approach underlying the present work, its statistical interpretation, statistical optimality and theoretical results, we again refer to<ref type="bibr" target="#b17">Frick et al. (2014)</ref>. To ease the understanding, in the following, we elaborate in greater details on the case of binary Bernoulli observations with success probabilities given as piecewise constant segments, as this model underlies the methodology for the segmentation problem at hand. In contrast to other approaches such as hidden Markov models, we require neither explicit nor implicit distributional assumptions on the segments and their lengths. Let 'ðY i , i Þ denote the likelihood of Y i under the parameter i , i.e. 'ðY i , i Þ ¼ i if Y i ¼ 1 and 'ðY i , i Þ ¼ 1 À i else. We then define for a fixed interval ði, j with 0 i5j n the local likelihood ratio statistic T ði, j ðp 0 Þ ¼ log max ~ p02½0, 1</p><formula>Y j l¼iþ1 'ðY l , ~ p 0 Þ 'ðY l , p 0 Þ ! : ð3Þ</formula><p>Roughly, this statistic indicates how well the data on the subinterval ði, j are described by the constant response probability p 0 2 ½0, 1 of some segment under consideration as opposed to choosing some ~ p 0 2 ½0, 1 freely for that subinterval. As a goodness-of-fit measure for the segmentation ðp, IÞ, we consider the scale-calibrated multiresolution statistic</p><formula>T n ðp, IÞ ¼ max 1 l K max ði, jIl ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 2T ði, j ðp l Þ p À ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 2 log e Á n j À i s ! : ð4Þ</formula><p>(Here 'e' denotes Euler's number.) This statistic may be interpreted as follows: for all segments I l in I, the response probability is assumed to be constant, and for every interval ði, j within such a segment, T n ðp, IÞ measures whether the data are well described by the constant response probability p l on that interval. It thus checks the quality of fit on all scales simultaneously, hence the name. Note that the log-penalty term depends on the length j – i of the interval that is currently checked for deviations from the model. It takes the number of disjoint intervals of the considered length into account, thereby adjusting for multiple testing. For our final estimate, we determine</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Details of the algorithm</head><p>We follow Frick et al. (2014) and use a pruned version of dynamic programming to compute our estimated segmentation ^ I and levels ^ p. This is possible because our multiresolution statistic T n considers only subintervals of the candidate segments of constant response probability. For related ideas, where dynamic programming has been used for other segmentation estimators, see<ref type="bibr" target="#b18">Friedrich et al. (2008)</ref>,<ref type="bibr" target="#b3">Boysen et al. (2009)</ref>,<ref type="bibr" target="#b11">Davies et al. (2012)</ref>and, in particular for pruning,<ref type="bibr" target="#b23">Killick et al. (2012)</ref>. To describe the algorithm for computing B-SMUCE, we need the following notation, identifying a segmentation with ðp, IÞ again: for an interval ði, j, we define the local costs of a response probability p 0 2 ½0, 1 as</p><formula>c ði, j ðp 0 Þ ¼ À Q j l¼iþ1 'ðY l , p 0 Þ ifT ði, j ðp 0 Þ q, 1 otherwise: ð8Þ</formula><p>Let c Ã ði, j ¼ min p02½0, 1 c ði, j ðp 0 Þ denote the minimal costs on ði, j for a constant response probability under the multiresolution constraint, whereas p ði, j ¼ argmin p02½0, 1 c ði, j ðp 0 Þ denotes the corresponding optimal estimate. Let us, for the moment only, consider the observations Y 1 ,. .. , Y i for fixed 1 i n, and denote by c Ã i, K , the optimal overall costs on ð0, i using K segments, i.e.</p><formula>c Ã i, K ¼ argmax ðp, IÞ2CK, i , Tiðp, IÞ q Y 1 l K Y j2Il 'ðY j , p l Þ, ð9Þ</formula><p>cf. (5), where C K, i denotes the set of segmentations of ð0, i with K segments; if no segmentation ðp, IÞ 2 C K, i fulfills the multiresolution constraint T i ðp, IÞ q, we let c Ã i, K ¼ 1. The algorithm for B-SMUCE is then based on the observation that for K40</p><formula>c Ã i, K ¼ min 1 l i c Ã l, KÀ1 þ c Ã ðl, i : ð10Þ</formula><p>In dynamic programming, this is called the Bellman equation; it is the main ingredient for an efficient implementation; see line 11 in Algorithm 1.</p><p>Algorithm 1: dynamic programming algorithm for B-SMUCE 1: ^ K 0, ^ I 0 ;, ^ p 0 ;, i 1 2: while i n do 3: if ^ K ¼ 0 then 4:</p><formula>l Ã 0 5: c Ã i, 0 c Ã ð0, i</formula><p>6: else 7: for l ¼ i À 1,. .. , 1 do 8: if c ðl, i ¼ 1 then 9: goto 14 10: else 11:</p><formula>c l i c Ã l, ^ KÀ1 þ c Ã</formula><p>ðl, i 12: end if 13: end for 14:</p><formula>l Ã argmin l j5i c j i 15: c Ã i, ^ K c l Ã i 16: end if 17: if c Ã i, ^ K ¼ 1 then 18: ^ K ^ K þ 1 19: goto 3 20: end if 21: ^ I i ð ^ I l Ã , ðl Ã , iÞ 22: ^ p i ð ^ p l Ã , p ðl Ã , i Þ 23: end while 24: return ^ K, ^ I n , ^ p n</formula><p>Note that we introduced two rules that permit for early stopping of loops: if c Ã ðl, i ¼ 1, i.e. if the hypothesis of constancy on ðl, i is rejected, then consequently, this also happens on any larger interval, i.e. for any smaller l; this justifies lines 8–9. Similarly, if K segments are insufficient to fulfill the multiresolution constraint on ð0, i, then a fortiori so for any larger i, whence lines 17–20. To the best of our knowledge, these shortcuts that are possible because of the specific structure of the multiscale constraint have not been used so far. Additional improvements were used in our implementation; these, however, are rather technical and thus omitted from the present article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We evaluated our segmentation approach both on simulated data and on data taken from the human genome and the longknown-phage. In our simulations, we used the benchmark scenarios proposed in<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>. Because an extensive comparison of popular DNA segmentation algorithms under these benchmark scenarios is already available in Elhaik et al.</p><p>(2010a), we provide a comparison of our approach with the method that performed best in<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>, namely, the one based on the Jensen–Shannon divergence. This recursive approach (called D JS ) splits one of the current segments in each step. This is done by adding a new break point such that the improvement in Jensen—Shannon divergence is maximized. The algorithm stops when the improvement does not reach a threshold value obtained via simulations. Here, we used the Matlab implementation Djsegmentation.m of the algorithm, which is publicly available as part of ISOPLOTTER 2.4 (http://code. google.com/p/isoplotter/). There, 5:8 Â 10 À5 is taken as a threshold, a value obtained from simulating long (1 Mb) homogeneous sequences. Although this value seems to work well for the considered benchmark scenarios and might also be useful to prevent false-positive findings when searching for long homogeneous sequences, it might be less suitable for balancing false-positives and false-negatives under other scenarios. Therefore, a modified version (called ISOPLOTTER) of D JS has been proposed briefly after (<ref type="bibr" target="#b15">Elhaik et al., 2010b</ref>) that uses critical values dependent both on the segment length and the standard deviation of the GC content. Therefore, we also report on the performance of ISOPLOTTER 2.4 (again under the default parameter settings) and provide detailed results in the Supplementary Material. To facilitate the comparison and to accelerate the computations for longer sequences, we binned the data and applied our algorithm to the resulting binomial frequencies. We choose the bin size equal to 32, which is the default value with the D JS and IsoPlotter software and has also been used in<ref type="bibr">Elhaik</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance measures</head><p>We measured performance both by a qualitative criterion proposed by<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>and by a new quantitative criterion. For the qualitative criterion, we classify an identified segment as true-positive if both segment boundaries are identified correctly within an error margin of 5000 bases or 5% of the segment length, whichever is smaller. Thus, an identified segment is considered to be a false-positive, unless both detected boundaries were within 5000 bases (or 5%) from the boundaries of a true segment. Similarly, actual segments were taken as false-negative findings if they were not detected correctly within the permitted tolerance. Let now tp, fp and fn denote the number of true-positives, false-positives and falsenegatives, respectively. Following<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>, we define a sensitivity rate as r s :¼ tp tp þ fn , ð11Þ and a precision rate as r p :¼ tp tp þ fp : ð12Þ We investigate the performance of our proposed approach based on these criteria. Furthermore, we defined two quantitative criteria that better reflect the accuracy of detecting segment boundaries. We denote them by false-negative sensitive localization error (FNSLE) and false-positive sensitive localization error (FPSLE). To introduce the FNSLE, consider a true segment I j :¼ ð jÀ1 , j , and let m j ¼</p><formula>e ðFNSLÞ :¼ 1 K X K j¼1 e ðFNSLÞ j : ð14Þ</formula><p>Analogously, the FPSLE can be defined by measuring how closely an estimated segment matches to one of the true segments. By starting with an estimated segment ^ I l and its midpoint ^ m l , we look for the true segment satisfying ^ m l 2 I j. With analogously defined errors e ðFPSLÞ l , we call</p><formula>e ðFPSLÞ :¼ 1 ^ K X ^ K l¼1 e ðFPSLÞ l : ð15Þ</formula><p>the overall FPSLE. These measures for the error may be interpreted as follows: assume that the estimated segmentation agrees with the true segmentation in the number of segments, and that all boundaries have been determined with an error smaller than half the length of each neighboring segment. Then, FPSLE and FNSLE agree: they essentially give the average distance between true and estimated boundaries. These error measures behave differently, however, if the numbers of true and detected segments do not coincide: assume that the estimated segmentation is the true segmentation except that it has incorrectly split one true segment into two estimated segments. Then, the FNSLE increases by the length of that true segment minus the length of the longer estimated segment divided by 2K, i.e. a spurious split is treated like an error in localizing that boundary. The FPSLE, however, will get rather large, as the length of that true segment divided by 2 ^ K gets added. Similarly, if a true boundary is not detected, the FNSLE will be larger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Simulations</head><p>3.2.1 Segments of equal length We first implemented Scenario I of<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>. Thus, we simulated sequences that consist of 10 segments of equal length. We considered the following eight different segment lengths: 10kb, 50kb, 100kb, 200kb, 300kb, 500 kb, 1Mb and 5Mb. Thus, the longest sequences had total length 50Mb. For each sequence, we selected a global probability p ðtÞ for the response '1' at a position according to a uniform distribution on<ref type="bibr">[0.1,0.9]</ref>. Then, we randomly modified this probability for each sequence segment j by taking</p><formula>p j ¼ p ðtÞ þ Z j : ð16Þ</formula><p>Here Z j denotes a standard normal random number, and was chosen from f0, 0:025, 0:05, 0:075, 0:1g. The p j were conditioned to lie within<ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, i.e. if p j did not turn out to be a proper probability, a new random number was generated. The individual observations Y i within a given segment I j were then chosen as independent Bernoulli random variables with expected value p j .</p><p>We simulated 100 sequences for each combination of segment length and heterogeneity of the segment-specific response probabilities. In<ref type="bibr" target="#b14">Elhaik et al. (2010a)</ref>, a detection threshold was introduced, and neighboring true segments for which the value of p j differed by less than this threshold have been merged and considered as a single segment in the subsequent performance analysis. We did not use such a threshold, however, as we did not want to penalize high sensitivity. A correct detection of two neighboring segments with unequal but too similar levels of p j would be counted as an error if such a detection threshold was used. The average sensitivity and precision rates of B-SMUCE and the method based on the Jensen–Shannon entropy (D JS ) are displayed in<ref type="figure" target="#fig_2">Figures 1</ref>and 2, respectively. Especially for shorter segments, B-SMUCE performs better than D JS , with higher sensitivity and precision. IsoPlotter performed worse than D JS under the considered scenarios and gave up to 40 segments on average for the long sequences. B-SMUCE is able to detect also short segments, while controlling the number of spuriously detected segments. However, notice that in the case of a homogeneous sequence without partitioning into segments ( ¼ 0), D JS always obtained the correct answer, whereas B-SMUCE sometimes introduced spurious segment boundaries. This is to be expected, as the error of introducing spurious boundaries has been set to ¼ 5% under such a model. Furthermore, under all scenarios, too many boundaries were estimated by B-SMUCE in 55% of the simulations, as predicted. We consider the ability to control this error to be a particular strength of our approach. Figures 3 and 4 show the average FNSLE (14) and FPSLEs (15) that measure the accuracy of the segment detection. For these quantitative criteria, we only consider sequences that are non-homogeneous (40). Again, B-SMUCE shows better performance, leading to smaller errors on average. With increasing heterogeneity , there will be typically larger differences between neighboring segments and thus smaller errors. The graphs also seem to indicate that both FPSLE and FNSLE tend to get larger with increasing sequence lengths. A closer inspection reveals that this is mostly caused by outliers, as the median accuracy of detection stays nearly the same for all segment lengths. These outliers occur when a segment is either missed or detected incorrectly, and such events lead to larger errors when the segments are longer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Segments according to power law</head><p>In our second simulation setup, we generated 100 sequences consisting of segments. Notice that the minimal segment length x 0 ¼ 10 000 was introduced to avoid short segments that are difficult to detect. The total sequence length was taken to be n ¼ 10 6. For even numbered segments, we selected the response probability p j according to a uniform distribution on<ref type="bibr">[0.6,1]</ref>, whereas for odd segments, we took p j uniformly from p j 2 ½0, 0:4. Qualitatively, it turns out that B-SMUCE performs better than the Jensen–Shannon entropy criterion D JS both in terms of sensitivity and precision rate; see<ref type="figure" target="#tab_1">Table 1</ref>. B-SMUCE detected 90% of all true segments within the desired margin of error. Furthermore, 94% of all detected segments were correct, again, within the desired level of accuracy. Because we used B-SMUCE with a type I error probability of 5% for including too many segments, this implies that almost all of the detected jumps were detected within the required level of accuracy. Furthermore, when incorrect, our method usually detected not more than one spurious segment boundary. We also tried IsoPlotter on the simulated sequences and got 85.23 detected segments on average. Given an mean number of 27.51 true segments (see<ref type="figure" target="#tab_1">Table 1</ref>), more than three times the true number of segments has been detected on average. More detailed results on ISOPLOTTER can be found in the Supplementary Material. B-SMUCE also leads to good results in terms of the FPSLE and FNSLE; see<ref type="figure" target="#tab_2">Table 2</ref>. Thus, on average, detected segments and true segments match more closely with B-SMUCE than with the D JS criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Real data</head><p>We applied our segmentation algorithm to three data sets. The first two examples, phage and human major histocompatibility (MHC) complex, have previously been studied in the context of segmentation algorithms. As a further example, a 10 Mb sequence chunk (hg19, chr1:50000002-60000000) has been arbitrarily chosen from human chromosome 1. The genome of bacteriophage consists of 48 502 bases and was one of the first completely sequenced genomes. Our segmentation led to six segments with boundaries 1, 22501, 27829, 33186, 39172, 46367 and 48502. Notice that the same number of segments, although with a bit different boundaries, has been reported as the outcome of a segmentation using hidden Markov models in Chapter 4 of Cristianini and Hahn (2007). We next investigate human genome data from chromosome 6p21.3 and 6p22.1 (hg19, chr6:29 677 952–33 289 874). This segment harbors the much studied human MHC complex. We found a number of segments even larger than that in<ref type="bibr" target="#b15">Elhaik et al. (2010b)</ref>, contradicting once again the concept of homogeneous isochores (from the UCSC browser for this example.) We recoded G,C as '1' and A,T as 0 and applied B-SMUCE and both D JS and IsoPlotter to these data. With D JS , we found 182 segments. With B-SMUCE and a type I error probability of ¼ 0:05, we identified 640 segments. (With ¼ 0:01, 528 segments were obtained, and choosing ¼ 0:1 led to 716 segments.) A natural question is whether the number of 640 or 182 segments is more appropriate. To address this issue, notice that theNote. Long and short segments were generated under a power-law distribution, and the total sequence length was n ¼ 10 6. The results are averages (and standard errors) over 100 simulation runs. The error rates were standardized according to the average segment length. statistical error control associated with the multiresolution criterion suggests that there are (except for a small error probability) at least 640 segments. To check whether this finding is also compatible with the D JS segmentation, we simulated the segmentation with 640 segments obtained with B-SMUCE as our null model. We simulated 100 datasets from this null model, and for 80% of all datasets, D JS led to a segmentation with the number of segments at most 182. With the number of segments taken as test statistic, this amounts to an estimated p-value of 0.80. Thus, the segmentation based on the Jensen–Shannon (D JS ) criterion does not contradict the assumption of 640 segments, whereas the hypothesis of 182 segments is rejected by the multiscale criterion underlying B-SMUCE as not being compatible with the data. We also applied IsoPlotter 2.4 to the data. With its adaptive detection threshold, 227 segments were identified. The homogeneity test (one-sided F-test) provided with the IsoPlotter software confirmed for 180 of these 227 segments that they are significantly more homogeneous than the entire considered DNA sequence. Although this observation does not give us the number of segments actually present, it seems interesting that the number of sufficiently homogeneous segments found by IsoPlottor is almost the same as the number of segments identified with the D JS criterion. Finally, we considered the region between 50 and 60 Mb on the human chromosome 1. Here, we tried bins both of size 10 and 32. It turned out that with the finer partition slightly more segments were detected than with the larger bins of size 32, although the difference (1096 versus 1041) was not large. It seems plausible that fine-scale variation can be detected more easily with shorter bins. To illustrate the run-time behavior of the B-SMUCE algorithm with our default significance threshold ¼ 0:05, we considered several shorter sequences taken from the aforementioned 10 Mb DNA sequence.<ref type="figure" target="#tab_3">Table 3</ref>gives the run times of our algorithm (in s) in dependence of the sequence length. To give an idea about the run times of D JS and IsoPlotter, we applied them on the same sequence pieces. With the standard options (bin size: 32, shortest detectable domain size: 3008), the run times for the longest sequence (10 7 bases) were 6.2 s (D JS ) and 9.6 s (IsoPlotter). However, notice that B-SMUCE is designed to detect segments of any length, and the shortest segment detected by B-SMUCE in the context of our run time analysis was 80 bases long. Therefore, we also recorded the run times for D JS and IsoPlotter with the minimum segment length changed from 3008 to 80. For a bin width of 32 and a sequence length ofNote. The computations were carried out on a single cluster core with 2.6 GHz and 8 GB RAM. The results are reported for ¼ 0:05 and for bins of lengths 32 and 10. For ¼ 0:01, similar run times have been obtained.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>et al. (2010a). Although binning the data clearly improves the speed, it should be noted that it is not essential for the algorithm to work. The first scenario considered there involves sequences consisting of fixed-size homogeneous domains. Although not realistic in practice, this setup has been proposed by Elhaik et al. (2010a) as a minimum standard: a criterion that does not perform well on such data cannot be expected to perform well under more complex settings. The second scenario consists of sequences with domains of random length generated according to a power-law distribution. These sequences are reported to mimic mammalian genomes well; see Clay et al. (2001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.3.</head><figDesc>Fig. 3. Logarithm (base 10) of average FNSLE, as defined in (14) for D JS ( * ) and B-SMUCE (Â). Results are based on simulations under Scenario I (segments of equal length) for several values of. The errors encountered with the multiresolution criterion tend to be smaller. At the simulated segment lengths, 95% confidence intervals are given as error bars</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.1.</head><figDesc>Fig. 1. Average sensitivity rate as defined in (11) for D JS ( * ) and B-SMUCE (Â). Results are based on simulations under Scenario I (segments of equal length) for several values of. The sensitivity obtained with the multiresolution criterion tends to be higher. At the simulated segment lengths, 95% confidence intervals are given as error bars</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Average precision rate, as defined in (12) for D JS ( * ) and B-SMUCE (Â). Results are based on simulations under Scenario I (segments of equal length) for several values of. The precision rate obtained with the multiresolution criterion tends to be higher. At the simulated segment lengths, 95% confidence intervals are given as error bars</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Logarithm (base 10) of average FPSLE, as defined in (15) for D JS ( * ) and B-SMUCE (Â). Results are based on simulations under Scenario I (segments of equal length) for several values of. The errors encountered with the multiresolution criterion tend to be smaller. At the simulated segment lengths, 95% confidence intervals are given as error bars</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Sensitivity rate and precision rate under Scenario II for the Jensen–Shannon divergence method (D JS ) and B-SMUCE</figDesc><table>Performance criterion 
D JS 
B-SMUCE 

Average true number 
27.51 (1.90) 
27.51 (1.90) 
Average number of true-positives 
23.26 (1.69) 
24.68 (1.80) 
Average number of false-positives 
2.51 (0.20) 
1.60 (0.14) 
Average number of false-negatives 
4.25 (0.37) 
2.83 (0.24) 
Average sensitivity 
0.83 (0.016) 
0.87 (0.015) 
Average precision 
0.88 (0.013) 
0.92 (0.013) 

Note. Long and short segments were generated from a power-law distribution, and 
the total sequence length was n ¼ 10 6 . We provide averages (and in parentheses 
standard errors) over 100 simulation runs. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2.</figDesc><table>FNSLEs and FPSLEs under Scenario II for the Jensen– 
Shannon divergence method (D JS ) and B-SMUCE 

FNSLE 
FPSLE 

D JS 
0.27 (0.436) 
0.06 (0.103) 
B-SMUCE 
0.11 (0.164) 
0.01 (0.014) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 3. Run times (in s) of the B-SMUCE algorithm when applied to sequences of different length taken from the human chromosome 1</figDesc><table>Sequence length 
10 5 2 Â 10 5 5 Â 10 5 10 6 5 Â 10 6 10 7 

Run-time bin size 32 0.37 1.0 
3.3 
9.4 
51.9 
102.9 
Run-time bin size 10 1.7 
4.0 
12.3 
30.7 169.7 
384.0 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">(1) the minimal number of segments ^ K, such that there exists a segmentation ð ^ p, ^ IÞ with ^ K segments satisfying the multiresolution constraint T n ð ^ p, ^ IÞ q for some predetermined significance threshold q, and (2) the segmentation ð ^ p, ^ IÞ with maximal likelihood among all segmentations having ^ K segments and satisfying the multiresolution constraint. To be more precise, let C K denote the set of segmentations with K segments. Then, our estimate in the second step is ð ^ p, ^ IÞ ¼ argmax ðp, IÞ2C ^ K , Tnðp, IÞ q &apos;ðY; p, IÞ, ð5Þ where argmax denotes a position ð ^ p, ^ IÞ at which the maximum is obtained, and &apos;ðY; p, IÞ denotes the likelihood of all data if the segmentation ðp, IÞ with ^ K segments were true, i.e. &apos;ðY; p, IÞ ¼ Y 1 l ^ K Y i2Il &apos;ðY i , p l Þ: ð6Þ Following Frick et al. (2014), the general class of such estimators in exponential families has been denoted as SMUCE. We adopt this terminology and will denote the estimator in (5) for the Bernoulli and binomial case as B-SMUCE. The threshold parameter q determines the parsimony of the estimator; the larger q, the fewer segments will be included into B-SMUCE. Hence, the choice of q is crucial. A statistically attractive feature of B-SMUCE is that q can be chosen as the ð1 À Þ quantile of the distribution of T n ðp, IÞ under the hypothesis that ðp, IÞ is the true model. In Frick et al. (2014), it has been proven that this choice ensures that the number of segments is not overestimated with probability at least 1 À .</note>

			<note place="foot">A.Futschik et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from To be more precise, in Frick et al. (2014), Theorem 2.1 was shown under some mild technical assumptions that for any ðp, IÞ the asymptotic distribution of the multiresolution statistic T n ðp, IÞ can be bounded by the asymptotic distribution of the statistic for a signal with only one segment. Moreover, the latter distribution converges to the limit distribution of (4) for the case of i.i.d. (independent and identically distributed) zero-mean Gaussian observations. Therefore, we may (and we do in the following) simply use Monte Carlo simulations with i.i.d. zero-mean Gaussian data to determine bounds on the quantiles of the distribution of T n ðp, IÞ. In simulations, we found the approximate quantiles thus obtained to be rather conservative (i.e. the preassigned error probability was not exceeded) even for small sample sizes. This adds support to the basic inequality Pð ^ K4KÞ PðT n ðp, IÞ4qÞ ð7Þ in Section 1.2. of Frick et al., 2014, which renders SMUCE to be a method that statistically controls the error to overestimate the number of segments in the binary case, i.e. it provides the statistical validity of BSMUCE in the above sense (7). The other way around, Theorem 2.2 in Frick et al. (2014) provides an exponential deviation bound for the error to underestimate the true number of segments, which explicitly depends on the smallest segment length and signal strength. Under prior information on these quantities, these two inequalities together even allow to give a guarantee for the probability Pð ^ K ¼ KÞ of specifying the number of segments correctly. Moreover, in the Gaussian case, it can be shown that SMUCE attains optimal detection rates (and even constants) over a large range of segment lengths; see Frick et al. (2014), Theorems 2.6 and 2.7. Our simulations suggest a similar performance in the binary/binomial case, although we do not have a rigorous proof of this statement.</note>

			<note place="foot">Multiscale DNA partitioning at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">A.Futschik et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="10"> 7 , the run time for D JS remained unchanged, whereas the run time for IsoPlotter increased to 329.1 s. For the human genome data considered here, a cross-check with the genome annotation revealed that several segments have an interpretation in terms of genes/exons, repetitive elements or CpG islands. Because the GC content may depend on several functional and evolutionary factors, we do not expect simple explanations for many of the identified segments. Nevertheless, we explore the overlap of the identified segments with available annotation in the Supplementary Material. 4 CONCLUSION We introduced a new method (B-SMUCE) for the segmentation of biological sequences. The segmentation is with respect to a binary response; here, we have considered GC content, but it might be interesting to apply the method to other applications involving binary responses (such as ancestral/derived state of alleles in population genetic applications). Our approach provides precise statistical error control and will produce a parsimonious segmentation that does not contain more segments than there actually are with a user-specified preassigned probability of 1 À. A comparison under the benchmark scenarios taken from Elhaik et al. (2010a) suggests that the proposed method B-SMUCE is more accurate than previously proposed approaches. Interestingly, the difference to the popular Jensen–Shannon criterion in terms of the number of detected segments has been particularly large for the human data.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Differential GC content between exons and introns establishes distinct strategies of splice-site recognition</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Amit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell Rep</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="543" to="556" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Summarizing and correcting the GC content bias in high-throughput sequencing</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Benjamini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">P</forename>
				<surname>Speed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">72</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Misunderstandings about isochores. Part I</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Bernardi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gene</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Consistencies and rates of convergence of jump-penalized least squares estimators</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Boysen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="157" to="183" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Statistical methods for DNA segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">V</forename>
				<surname>Braun</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">G</forename>
				<surname>Muïler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="142" to="162" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiple change-point fitting via quasi-likelihood, with application to DNA sequence segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">V</forename>
				<surname>Braun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="301" to="314" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Computational Genomics</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Cristianini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">W</forename>
				<surname>Hahn</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Stochastic models for heterogeneous DNA sequences</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">A</forename>
				<surname>Churchill</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Math. Biol</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="79" to="94" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Hidden Markov chains and the analysis of genome structure</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">A</forename>
				<surname>Churchill</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Chem</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="107" to="115" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Compositional heterogeneity within and among isochores in mammalian genomes. I. CsCl and sequence analyses</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Clay</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gene</title>
		<imprint>
			<biblScope unit="page" from="276" to="1524" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">GC composition of the human genome: in search for isochores</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Evol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1260" to="1272" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Recursive computation of piecewise constant volatilities</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Davies</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3623" to="3631" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Multiscale testing of qualitative hypotheses</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Du¨mbgendu¨mbgen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">G</forename>
				<surname>Spokoiny</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="124" to="152" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Multiscale inference about a density</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Du¨mbgendu¨mbgen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Walther</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1758" to="1785" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparative testing of DNA segmentation algorithms using benchmark simulations</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Elhaik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Evol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1015" to="1024" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Identifying compositionally homogeneous and nonhomogeneous domains within the human genome using a novel segmentation algorithm</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Elhaik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Base compositional structure of genomes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Fickett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1056" to="1064" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiscale change-point inference</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Frick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="495" to="580" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Complexity penalized M-estimation: fast computation</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Friedrich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="201" to="224" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Partial correlation analysis indicates causal relationships between GC-content, exon density and recombination rate in the human genome</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Freudenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">66</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Local rates of recombination are positively correlated with GC content in the human genome</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">M</forename>
				<surname>Fullerton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biol. Evol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1139" to="1142" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">GC-content evolution in mammalian genomes: the biased gene conversion hypothesis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Galtier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="907" to="911" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Segmenting eukaryotic genomes with the generalized gibbs sampler</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Keith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1369" to="1383" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimal detection of changepoints with a linear computational cost</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Killick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="1590" to="1598" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">SEGMENT: identifying compositional domains in DNA sequences</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Oliver</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="974" to="979" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">GC-Content Normalization for RNA-Seq Data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Risso</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">480</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">On the genetic basis of variation and heterogeneity of DNA base composition</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Sueoka</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<publisher>PNAS</publisher>
			<biblScope unit="page" from="582" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Optimal and fast detection of spatial clusters with scan statistics</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Walther</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1010" to="1033" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Smoothers for discontinuous signals</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Winkler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Liebscher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Nonparametr. Stat</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="203" to="222" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Estimating the number of change-points via Schwarz&apos; criterion</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">C</forename>
				<surname>Yao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Probab. Lett</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="181" to="189" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>