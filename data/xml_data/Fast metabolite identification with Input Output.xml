
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast metabolite identification with Input Output Kernel Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Cé</forename>
								<surname>Line Brouard</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aalto University</orgName>
								<address>
									<settlement>Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Helsinki Institute for Information Technology</orgName>
								<address>
									<settlement>Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Huibin</forename>
								<surname>Shen</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aalto University</orgName>
								<address>
									<settlement>Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Helsinki Institute for Information Technology</orgName>
								<address>
									<settlement>Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Kai</forename>
								<surname>Dü</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Chair for Bioinformatics</orgName>
								<orgName type="institution">Friedrich-Schiller University</orgName>
								<address>
									<settlement>Jena</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Florence</forename>
								<surname>D &apos;alché-Buc</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Sebastian</forename>
								<surname>Bö Cker</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Chair for Bioinformatics</orgName>
								<orgName type="institution">Friedrich-Schiller University</orgName>
								<address>
									<settlement>Jena</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">LTCI</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<addrLine>Télé com ParisTech</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Juho</forename>
								<surname>Rousu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aalto University</orgName>
								<address>
									<settlement>Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Helsinki Institute for Information Technology</orgName>
								<address>
									<settlement>Espoo</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast metabolite identification with Input Output Kernel Regression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw246</idno>
					<note>*To whom correspondence should be addressed. Availability and implementation: Contact: celine.brouard@aalto.fi Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: An important problematic of metabolomics is to identify metabolites using tandem mass spectrometry data. Machine learning methods have been proposed recently to solve this problem by predicting molecular fingerprint vectors and matching these fingerprints against existing molecular structure databases. In this work we propose to address the metabolite identification problem using a structured output prediction approach. This type of approach is not limited to vector output space and can handle structured output space such as the molecule space. Results: We use the Input Output Kernel Regression method to learn the mapping between tandem mass spectra and molecular structures. The principle of this method is to encode the similarities in the input (spectra) space and the similarities in the output (molecule) space using two kernel functions. This method approximates the spectra-molecule mapping in two phases. The first phase corresponds to a regression problem from the input space to the feature space associated to the output kernel. The second phase is a preimage problem, consisting in mapping back the predicted output feature vectors to the molecule space. We show that our approach achieves state-of-the-art accuracy in metabolite identification. Moreover, our method has the advantage of decreasing the running times for the training step and the test step by several orders of magnitude over the preceding methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Metabolomics is a science which concerns the study of small molecules, called metabolites, and their interactions in the cell. An important problem of metabolomics is the identification of the metabolites present in a sample. Information on metabolites can be obtained using tandem mass spectrometry. This technology allows to obtain a tandem mass spectrum, also called MS/MS spectrum, by fragmenting a compound. A MS/MS spectrum is a plot containing a set of peaks, where each peak corresponds to a fragment. These peaks represent the relative abundance of the different fragments, also called intensity, in function of their mass-to-charge ratio. The identification of the metabolite from its mass spectrum is then needed for a more detailed biological interpretation. In general this step consists in a research of the obtained spectrum in databases of reference spectra, followed by an analysis by experts of the domain. Computational approaches for interpreting and predicting MS/ MS data of small molecules date back to the 1960s (<ref type="bibr" target="#b21">Lindsay et al., 1980</ref>). However, the early approaches were hampered by the unavailability of large scale data on molecular structures as well as reference spectra. The introduction of molecular structure databases such as PubChem (<ref type="bibr" target="#b3">Bolton et al., 2008</ref>) as well as open mass spectral reference databases (da<ref type="bibr" target="#b8">Silva et al., 2015;</ref><ref type="bibr" target="#b16">Horai et al., 2010</ref>) has in recent years fuelled the development of novel methods. Several novel strategies have been proposed, including simulation of mass spectra from molecular structure (<ref type="bibr" target="#b0">Allen et al., 2014</ref><ref type="bibr" target="#b1">Allen et al., , 2015</ref>), combinatorial fragmentation (<ref type="bibr" target="#b13">Heinonen et al., 2008;</ref><ref type="bibr" target="#b15">Hill and Mortishire-Smith, 2005;</ref><ref type="bibr" target="#b24">Ridder et al., 2013;</ref><ref type="bibr" target="#b31">Wang et al., 2014;</ref><ref type="bibr" target="#b33">Wolf et al., 2010</ref>) and prediction of molecular fingerprints (<ref type="bibr" target="#b14">Heinonen et al., 2012;</ref><ref type="bibr" target="#b28">Shen et al., 2014</ref>). Methods based on machine learning (<ref type="bibr" target="#b0">Allen et al., 2014</ref><ref type="bibr" target="#b1">Allen et al., , 2015</ref><ref type="bibr" target="#b9">Dü hrkop et al., 2015;</ref><ref type="bibr" target="#b14">Heinonen et al., 2012;</ref><ref type="bibr" target="#b27">Shen et al., 2013</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i28</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com<ref type="bibr">Bioinformatics, 32, 2016</ref>2014) have been proposed very recently for learning a mapping between tandem mass spectra and metabolites. These methods fall into two general approaches. The first group of methods (<ref type="bibr" target="#b9">Dü hrkop et al., 2015;</ref><ref type="bibr" target="#b14">Heinonen et al., 2012;</ref><ref type="bibr" target="#b27">Shen et al., 2013</ref><ref type="bibr" target="#b28">Shen et al., , 2014</ref>) introduces an intermediary step consisting in predicting molecular fingerprints for the metabolites from their mass spectra using Support Vector Machines (SVMs). Molecular fingerprints are a standard representation for molecules, used in cheminformatics and drug discovery. They are typically represented as binary vectors, whose values indicate the presence or absence of some molecular properties, e.g. the existence of particular substructures in the metabolite or some physiochemical properties. If two molecules share a large number of molecular properties they are likely to be similar in structure, which is the rationale in using them for metabolite identification. To identify a metabolite, the fingerprint predicted from its tandem mass spectrum is matched against a large molecular database such as PubChem. In Shen et al.</p><p>(2014) and Dü hrkop et al. (2015) fragmentation trees are computed to model the fragmentation process of the molecules and then used for predicting the molecular fingerprints. The other machine learning approach for metabolite identification, used by CFM-ID (<ref type="bibr" target="#b0">Allen et al., 2014</ref><ref type="bibr" target="#b1">Allen et al., , 2015</ref>), also relies on a two-step scheme, where the first step consists in predicting the mass spectra of the candidate molecules by modeling their fragmentation processes. In the second step, the simulated spectra of the candidate molecules are compared with the spectrum of the test metabolite. The goal of this work is to solve the metabolite identification problem in a single step, using a structured prediction method. These methods make use of structural dependencies existing among complex outputs (e.g. the fingerprints of a molecule) to improve the accuracy and make prediction efficiently. These methods have achieved an improved prediction performance over methods that predict parts of a structure independently in numerous applications. In the literature, two main structured prediction approaches can be distinguished. The first one models the dependencies between structured inputs and outputs using a joint feature map /ðx; yÞ (<ref type="bibr" target="#b22">Marchand et al., 2014;</ref><ref type="bibr" target="#b25">Rousu et al., 2007;</ref><ref type="bibr" target="#b29">Su and Rousu, 2015;</ref><ref type="bibr" target="#b30">Taskar et al., 2004;</ref><ref type="bibr">Tsochantaridis et al., 2004</ref>), and learns to discriminate the correct structure y for an input x from all incorrect output structures. The second one, called Output Kernel Regression, consists in learning a mapping between the input set and the feature space associated to some output kernel. A preimage problem, which consists in mapping back the predicted output feature vectors to the output space, is then solved. Existing Output Kernel Regression methods are Kernel Dependency Estimation (<ref type="bibr" target="#b6">Cortes et al., 2005;</ref><ref type="bibr" target="#b18">Kadri et al., 2013;</ref><ref type="bibr" target="#b32">Weston et al., 2003</ref>), Output Kernel Trees (<ref type="bibr" target="#b11">Geurts et al., 2006</ref>) and Input Output Kernel Regression (IOKR) (<ref type="bibr" target="#b4">Brouard et al., 2011</ref><ref type="bibr" target="#b5">Brouard et al., , 2015</ref>. In this work, we show how to apply the IOKR framework for solving the metabolite identification problem. Our method reaches improved identification rates compared with the previous state-ofthe-art of<ref type="bibr">Dü hrkop et al. (2015)</ref>. More importantly, though, the IOKR framework results in vast improvements in running times: the method is one to two orders of magnitude faster in the prediction phase, and four orders of magnitude faster during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The main notations used in this article are summarized in<ref type="figure" target="#tab_1">Table 1</ref>. In the following, we note X the set of input tandem mass spectra, also known as MS/MS spectra, and Y the set containing the 2D molecular structures corresponding to the spectra. We want to learn a function f that maps a MS/MS spectrum x 2 X to its corresponding molecular structure y 2 Y. In this problem both input and output data are structured. Structured data refer to data having an internal structure, for example a graph or a tree, or to data being interdependent to each other. To solve this problem we use the IOKR framework that can learn a mapping between structured inputs and structured outputs. This framework has been introduced by<ref type="bibr" target="#b4">Brouard et al. (2011)</ref>to solve link prediction in the semi-supervised setting. In<ref type="bibr" target="#b5">Brouard et al. (2015)</ref>, this approach has been extended to address general structured output prediction problems. In this section we describe this method and explain how it can be applied to solve metabolite identification. In the IOKR approach the internal structure of the output data is encoded using a kernel function j y : Y Â Y ! R. A kernel function is a positive semi-definite function that measures the similarity between two elements. Its values can be evaluated by computing scalar products in a high-dimensional space, called the feature space. In the case of the output kernel j y , this writes as follows:</p><formula>8ðy; y 0 Þ 2 Y Â Y; j y ðy; y 0 Þ ¼ h/ y ðyÞ; / y ðy 0 Þi F y ;</formula><p>where the Hilbert space F y is the feature space associated to j y and / y : Y ! F y is a feature map that maps the outputs to the output feature space. Depending of the kernel used, for example when using a Gaussian kernel, the feature map / y might not be explicitly known. We will see later that we only need to evaluate inner products between feature vectors for computing the solution, which is possible using the kernel trick in the output space. This means that the scalar products in the feature space are replaced by the kernel values. The spectra-metabolite mapping problem can then be decomposed in two tasks (see<ref type="figure" target="#fig_0">Figure 1</ref>). The first task consists in learning a function h between the input set X and the Hilbert space F y that approximates the feature map / y. This task is called Output Kernel Regression. The second task is a pre-image problem that requires to learn or define a function g from F y to the output set Y. We detail these two steps in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Output Kernel Regression</head><p>The values of the function h that we want to learn in the Output Kernel Regression step are vectors belonging to the Hilbert space F y and not scalars. IOKR uses the Reproducing Kernel Hilbert Space (RKHS) theory devoted to vector-valued functions (Micchelli and<ref type="bibr">, 1973</ref>) in order to find an appropriate functional space H for searching the function h. This theory extends nicely the kernel methods to the problem of learning vectorvalued functions. It has been used in the literature to solve different learning problems such as multi-task learning (<ref type="bibr" target="#b10">Evgeniou et al., 2005</ref>), functional regression (<ref type="bibr" target="#b17">Kadri et al., 2010</ref>), link prediction (<ref type="bibr" target="#b4">Brouard et al., 2011</ref>) and vector autoregression (<ref type="bibr" target="#b20">Lim et al., 2014</ref>). In this theory, a kernel K x : X Â X ! LðF y ; F y Þ is a function whose values are linear operators from F y to F y , where F y is a general Hilbert space. This theory does not require any assumption on the existence of an output kernel j y. K x is called an operator-valued kernel if it verifies the two following properties: 1. 8x; x 0 2 X; K x ðx; x 0 Þ ¼ K x ðx 0 ; xÞ Ã , where Ã denotes the adjoint. K x ðx 0 ; xÞ Ã is defined as the linear operator satisfying hK x ðx 0 ; xÞ~ y i ; ~ y j i F y ¼ h~ y i ; K x ðx 0 ; xÞ Ã ~ y j i F y ; 8~ y i ; ~ y j 2 F y 2. 8m 2 N;</p><formula>8fðx i ; ~ y i Þg m i¼1 X Â F y ; P m i;j¼1 h~ y i ; K x ðx i ; x j Þ~ y j i F y ! 0</formula><p>In the case where the dimension d of F y is finite, the kernel K x is a function whose values are matrices of size d Â d and the kernel matrix is a block matrix.</p><p>In the IOKR approach, the function h : X ! F y is searched in the RKHS with reproducing kernel K x. We denote this space H. This means that we are searching models of the following form:</p><formula>8x 2 X; hðxÞ ¼ X i K x ðx; x i Þc i ; c i 2 F y :</formula><p>Let fðx i ; / y ðy i ÞÞg ' i¼1 X Â F y be the set of training examples. The function h is searched by minimizing a regularized optimization problem. In this article, we chose to use the regularized least-squares loss function in the supervised setting:</p><formula>argmin h2H X ' i¼1 jjhðx i Þ À / y ðy i Þjj 2 F y þ kkhk 2 H ; (1)</formula><p>where k &gt; 0 is a regularization parameter. A sufficiently high enough value of k prevents overfitting. According to the Representer Theorem (<ref type="bibr" target="#b23">Micchelli and Pontil, 2005</ref>), the solution of this optimization problem can be written as a linear combination of the operatorvalued kernel evaluated on the training examples:</p><formula>b hðx i Þ ¼ X ' j¼1 K x ðx i ; x j Þc j ;</formula><p>where c j ; j ¼ 1;. .. ; ', are vectors in F y. By replacing this expression in the optimization problem (1) and computing the derivative of the optimization problem, it has been shown by<ref type="bibr" target="#b23">Micchelli and Pontil (2005)</ref>that the vectors c j ; j ¼ 1;. .. ; ' verify the following equation:</p><formula>X ' i¼1 K x ðx j ; x i Þ þ kd ij À Á c i ¼ / y ðy j Þ;</formula><p>where d ii ¼ 1 and d ij ¼ 0 for all j 6 ¼ i. If the dimension d of the output feature space F y is finite, this solution can be rewritten in closed form as follows:</p><formula>vecðC ' Þ ¼ ðkI 'd þ K X' Þ À1 vecðU Y' Þ; (2)</formula><p>where C ' ¼ ðc 1 ;. .. ; c ' Þ and U Y' ¼ ð/ y ðy 1 Þ;. .. ; / y ðy ' ÞÞ are two matrices of size d Â '; I 'd denotes the identity matrix of size 'd Â 'd; and K X' is the Gram matrix of the operator-valued kernel K x on the training set. This is a ' Â ' block matrix, each block being of size d Â d. vecðC ' Þ is a column vector of length 'd obtained by stacking the columns of the matrix C ' on top of each other. Equation</p><p>(2) generalizes the solution obtained with kernel ridge regression to the case of vector-valued functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preimage step</head><p>To predict the output metabolite f(x) associated to the spectra x 2 X, we must determine the pre-image of h(x) by / y. For this, we search the metabolite y in a set of candidates Y Ã that minimizes the following criteria:</p><formula>b f ðxÞ ¼ argmin y2Y Ã jj b hðxÞ À / y ðyÞjj 2 F y : (3)</formula><p>As we consider that the output kernel is normalized, Equation</p><p>(3) becomes:</p><formula>b f ðxÞ ¼ argmax y2Y Ã h b hðxÞ; / y ðyÞi F y :</formula><p>In this work, we consider operator-valued kernels of the following form: 8ðx; x 0 Þ 2 X Â X; K x ðx; x 0 Þ ¼ j x ðx; x 0 Þ Ã I d ;</p><formula>(4)</formula><p>where j x : X Â X ! R is a scalar input kernel. We note F x the Hilbert space associated to this kernel and / x : X ! F x a feature map of j x. By using this operator-valued kernel and replacing b h by the solution given in the previous subsection, we obtain the following solution for metabolite identification with IOKR:</p><formula>b f ðxÞ ¼ argmax y2Y Ã / y ðyÞ T U Y' ðkI ' þ K X' Þ À1 U T X' / x ðxÞ;</formula><p>where U X' ¼ ð/ x ðx 1 Þ;. .. ; / x ðx ' ÞÞ and K X' is the Gram matrix of the scalar kernel j x on the training set. Using the kernel trick in the output space allows us to evaluate b f ðxÞ even in the case where the output feature map / y is not known explicitly. The solution can be rewritten as follows:</p><formula>b f ðxÞ ¼ argmax y2Y Ã ðk y Y' Þ T ðkI ' þ K X' Þ À1 k x X' ; where k y Y' ¼ j y ðy 1 ; yÞ .. . j y ðy ' ; yÞ 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Kernels</head><p>In the following, we describe the pairs of kernels ðj y ; j x Þ that we used for solving the metabolite identification problem with IOKR., fragmentation trees model the fragmentation process of a molecule in a tree shape: nodes of this tree are molecular formulas that correspond to the unfragmented molecule and its fragments. An edge between two nodes indicates the existence of a fragmentation reaction between two fragments or between the unfragmented molecule and one of its fragments. These edges are directed and correspond to losses. An example of fragmentation tree is given in<ref type="figure">Figure 2</ref>. Based on fragmentation trees, different categories of kernels have been proposed, such as: loss-based kernels, node-based kernels, path-based kernels or fragmentation tree alignment kernels. We also used the recalibrated probability product kernel (PPKr), which is computed on preprocessed spectra. The PPK kernel, introduced by<ref type="bibr" target="#b14">Heinonen et al. (2012)</ref>, is computed from MS/MS spectra by modeling each peak in a spectrum by a normal distribution with two dimensions: the mass-to-charge ratio and the intensity. A spectrum is then modeled as a mixture of normal distributions. The PPK kernel between two spectra is evaluated by integrating the product between the two corresponding mixture distributions. We learned a linear combination of these 24 input kernels using multiple kernel learning (MKL). We used uniform MKL<ref type="figure">Fig. 2</ref>. An example of MS/MS spectrum and its fragmentation tree. Each node of the fragmentation tree corresponds to a peak and is labeled by the molecular formula of the corresponding fragment. The root of the tree is labeled with the molecular formula of the unfragmented molecule. Edges represent the losses. Two nodes and one edge are colored to show the correspondence between the MS/MS spectrum and the fragmentation treeCommon paths with K peaks (CPK1) the PPK K peaks are used to score the terminal peaks<ref type="bibr" target="#b28">Shen et al. (2014)</ref>Common paths with K peaks (CPK2) same as CPK1 with a different parameter<ref type="bibr" target="#b28">Shen et al. (2014)</ref>Common path joined binary (CPJB) counts the number of paths for which the union of losses is equal</p><formula>K c k ¼ I ' À 11 T ' " # K k I ' À 11 T ' " # ;</formula><p>where 1 is a column vector of ones of length '. In Cortes et al.</p><p>(2012), the target kernel was defined as K y ¼ y T y in the case of single label classification. Here we used the Gram matrix of the output kernel j y on the training set. The combination of kernels learned with ALIGNF was then used for the scalar input kernel j x in IOKR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Output kernels</head><p>For the output kernel, we have to define a similarity that takes into account the inherent structure of the metabolites. We compared the results obtained using different graph kernels (path, shortest-path and graphlet kernels) as well as kernels defined on molecular fingerprints. A molecular fingerprint is a vector encoding the structure of a molecule. Generally the values of this vector are binary values that indicate the presence or absence of certain molecular properties. A bit can indicate for example the presence of a chemical atom, a type of ring, an atom pair or a common functional group in the structure of the molecule. We consider here the kernels that obtained the best performances, which are the kernels based on fingerprints. We used the set of 2,765 binary molecular properties described in Dü hrkop et al.</p><formula>(2015)</formula><p>. More details about these molecular properties are given in the Supplementary Materials. In the experiments, we considered different type of output kernels: @BULLET linear kernel: j y ðy; y 0 Þ ¼ cðyÞ T cðy 0 Þ, @BULLET polynomial kernel: j y ðy; y 0 Þ ¼ cðyÞ T cðy 0 Þ þ a b , @BULLET Gaussian kernel: j y ðy; y 0 Þ ¼ expðÀcjjcðyÞ À cðy 0 Þjj 2 Þ, where c(y) and cðy 0 Þ denote the molecular fingerprints of y and y 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We evaluated and compared our approach on a subset of 4138 MS/ MS spectra extracted from the GNPS (Global Natural Products Social) public spectral library (https://gnps.ucsd.edu/ProteoSAFe/ libraries.jsp) in Dü hrkop et al. (2015).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Protocol</head><p>The evaluation was performed using a 10-fold cross-validation (10CV) procedure such that all compounds having the same structure are contained in the same fold. The input and output kernels were centered and normalized. The regularization parameter k and the parameter(s) of the output kernel were selected using leave-one-out CV on each training fold. We used the averaged mean squared error (MSE) as error measure for tuning these parameters. The leave-oneout estimate of the averaged MSE was computed using the closedform solution proved in<ref type="bibr" target="#b5">Brouard et al. (2015)</ref>. In the prediction step, the method was evaluated on 3,868 compounds. For solving the pre-image step, following<ref type="bibr">Dü hrkop et al. (2015)</ref>we assumed that all spectra have already their molecular formula predicted as a preprocessing step, and we searched among the PubChem (<ref type="bibr" target="#b3">Bolton et al., 2008</ref>) structures having the same molecular formula as the current target. We computed the distance between the predicted output feature vector b hðxÞ (see Equation 3) and the output feature vectors of all the candidates. After the pre-image step, we ranked the candidates according to their distances to b hðxÞ (from the smallest distance value to the highest one). For the evaluation, we evaluated the rank obtained by the true molecular structure among the candidate set for each test example and then we computed the percentage of structures that have been ranked lower than k, and this for varying k values. A test compound is said to be correctly identified if its correct structure is ranked first in the list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with competing methods</head><p>We compared the performances of our method with two competing methods: FingerID (<ref type="bibr" target="#b14">Heinonen et al., 2012</ref>) and CSI:FingerID.<ref type="bibr">Dü hrkop et al. (2015)</ref>showed that CSI:FingerID improved significantly the metabolite identification rate compared with competing methods including CFM-ID (<ref type="bibr" target="#b1">Allen et al., 2015</ref>), MetFrag (<ref type="bibr" target="#b33">Wolf et al., 2010</ref>), MAGMa (<ref type="bibr" target="#b24">Ridder et al., 2013</ref>), MIDAS (<ref type="bibr" target="#b31">Wang et al., 2014</ref>) as well as FingerID—the second most accurate method in their comparison. Both FingerID and CSI:FingerID train a SVM classifier for each molecular property. A scoring function is then used to compare the predicted fingerprint with the candidate fingerprints and the candidate fingerprints are sorted correspondingly. FingerID uses as input the PPK kernel, whereas CSI:FingerID learns a combination of this kernel with different kernels defined on fragmentation trees using ALIGNF. In our experiment, we evaluated the performances of CSI:FingerID with unit scoring and with the modified Platt score, which was shown to perform the best among the different scores compared by Dü hrkop et al. (2015).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Identification performance</head><p>CSI:FingerID and FingerID were retrained on the 4138 GNPS spectra. For all methods, the parameter(s) were tuned on the training set using an internal 10-CV procedure. For the SVM-based approaches, the soft margin parameter C was tuned independently for each SVM.<ref type="figure" target="#tab_3">Table 3</ref>shows the results obtained with IOKR, FingerID and CSI:FingerID and the differences with the identification percentage of CSI:FingerID modified Platt are visualized in<ref type="figure" target="#fig_1">Figure 3</ref>. We observe that IOKR with UNIMKL combined kernel and Gaussian output kernel reaches the first position with 30.66% of correct identifications that are ranked first. It is followed by IOKR linear UNIMKL, IOKR Gaussian ALIGNF and then by CSI:FingerID modified Platt with 28.84% of correctly identified metabolites. When considering the identification percentage between top 1 and</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Running times</head><p>We computed the running times of CSI:FingerID and IOKR using the 4138 spectra from GNPS as training set and 625 spectra from the Massbank dataset (<ref type="bibr" target="#b16">Horai et al., 2010</ref>) as test set (see<ref type="figure" target="#tab_4">Table 4</ref>). The running times correspond to the times that would have been obtained if we were using a single core. The training times were computed using fixed values for the parameters (regularization and kernel parameters). The computation of the fragmentation trees, input kernels and fingerprints was not taken into account here. The running times for the training and the test steps are shown in<ref type="figure" target="#tab_4">Table 4</ref>. In this table, we observe a substantial difference between the training times obtained with these two approaches: the IOKR method is approximately 7000 times faster to train. This can be explained by the fact that CSI:FingerID needs to train a SVM classifier for each molecular property, this means 2765 SVMs to train in this experiment. For the same reason, IOKR also presents smaller test time compared with CSI:FingerID. In the case of the linear kernel, the test running time of IOKR is smaller than when using a Gaussian or polynomial kernel. This comes from the fact that we can avoid kernel computations in the pre-image step for the linear kernel by computing explicitly the output feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Detailed evaluation of identification with IOKR</head><p>We will now analyze more in details the results obtained with our method on the GNPS dataset. We begin by presenting the results obtained for the different input and output kernels introduced in Section 2.<ref type="figure">Figure 4</ref>contains the percentage of correctly identified structures (i.e. correct structures ranked top over all candidates) obtained with IOKR for the different pairs of input and output kernels. The two last columns correspond to the linear kernel combinations with UNIMKL and ALIGNF. We observe that the two MKL approaches clearly improve the results compared with the single kernels. The best performance is obtained with the UNIMKL approach, which is performing slightly better than ALIGNF. 30.74% of the metabolites are correctly identified with UNIMKL combined kernel. Among the individual input kernels, tree alignment-based kernels, node-based kernels [except Node subformula (NSF)] and the PPKr kernel obtain the best results. At the opposite end, the loss-based kernels and chemical element counting (CEC) are associated with low percentage of correct identified metabolites. Regarding output kernels, we notice that the performance obtained with linear and polynomial kernels are the same. This is because the optimal parameters selected for the polynomial kernel are 0 for the offset parameter and 1 for the degree, thus equalling linear kernel. Using Gaussian kernel seems to slightly improve the percentage of correctly identified structures for some input kernels, except for the root loss binary (RLB) kernel. The averaged kernel weights learned with the ALIGNF algorithm on the training folds are visualized in<ref type="figure" target="#fig_2">Figure 5</ref>for the three output kernels. The PPKr kernel is selected with the highest weight by ALIGNF for the three output kernels. Consistently with<ref type="figure">Figure 4</ref>, linear and the polynomial kernels are effectively the same. We observe that the weights are quite sparse: 14 kernels on a total of 24 are associated to a weight that is lower than 10 À6. In order to analyze why these 10 particular kernels are selected by ALIGNF, we plotted the pairwise kernel alignment scores between the input kernels, as well as the alignment scores between the input and output kernels (see in the Supplementary Materials). The first plot shows which input kernels are similar to each other. Nine groups of kernels can be distinguished and we notice that at least one kernel in each group is selected by ALIGNF. The only exception is the group containing the subtree kernel CSC but this might be because this input kernel is the one having the lowest alignment score with the output kernel. The sparsity of the kernel weights can therefore be explained by the fact that some kernels are very similar to each other and thus contain redundant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Prediction analysis</head><p>In the following, we detail the performance of the testing metabolites with IOKR in function of the size of their candidate sets. For this, we consider the best pair of kernels: UNIMKL combined kernel in input and Gaussian kernel in output.<ref type="figure">Figure 6a</ref>shows the distribution of the sizes of candidate sets, and the figure 6b represents the percentage of correctly identified metabolites in top 1, top 10 and above. We observe that the majority of the candidate sets contain &lt;1000 candidates in our dataset. For these candidate sets, 32.8% of metabolites are identified correctly in the first position (magentaMetabolite identification with IOKR i33 bars) and 71.7% are within the top 10 (cyan bars). The sizes of the candidate sets do not seem to have a strong influence on the identification accuracy. Even for large candidate sets our method is able to identify significant proportions of molecules within top 1 and top 10. We found 1203 compounds in the GNPS dataset that can be linked to the ontological classification database ChEBI (<ref type="bibr" target="#b12">Hastings et al., 2013</ref>). We are interested in evaluating whether there are some classes of compounds we can identify very well and some for which we cannot. Due to the hierarchical nature of the ontological classification, the classes far away from the root are very specific classes and contain very few compounds while the classes close to the root are very generic classes which contain too many compounds. As a result, we restrict the attention to the classes with shortest paths of length 7 from the root node chemical entity (ChEBI id 24431). For those classes, we count how many compounds in the GNPS dataset belong to them and represent the counts as the size of the points in<ref type="figure">Figure 7</ref>. For each compound, the number of candidates and rank of the correct compound are known, so we plot the median number of candidates associated with the compounds in each class on the x-axis and the proportion of cases for which we have correct compounds with rank 10 on the y-axis. Notice that we only show the classes containing at least 10 compounds. From the<ref type="figure">Figure 7</ref>, it is clear that the number of candidates associated with the compounds is not a major factor of the identification results. Many classes with larger number of compounds, as shown with larger points, have around 60% of the cases where the identification lies within top 10. There are some classes we can identify very well like 3-aryl-1-benzopyrans (ChEBI id: 50753), also called isoflavonoids, and heterocyclic antibiotics (ChEBI id: 24531), while some classes, shown at the bottom of the figure, contain compounds that are more difficult to identify with our method. Among the difficult cases, there are the compounds belonging to the cyclic amide (ChEBI id: 23443) class and to the cyanides (ChEBI id: 23424) class. The compounds in the cyanide class contain a cyanid-anion sidegroup, which corresponds to a carbon atom connected to a nitrogen atom via a triple bond. We also studied the differences in prediction performance between CSI:FingerID and IOKR for the different compound classes. A detailed plot showing the differences between the numbers of compounds better ranked by the two methods is given in the Supplementary Materials. This plot shows that IOKR obtains better performances than CSI:FingerID in 74% of the classes. Interestingly IOKR presents the highest improvement for the cyanides class and one of its child. On the opposite CSI-FingerID considerably improves the performance for the compounds belonging to the heterocyclic antibiotics class and two of its children.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In this article, we have proposed for the first time to solve the metabolite identification problem using a structured output prediction method, namely IOKR. We have shown that our method improves the metabolite identification rate comparing to competing methods with considerable shorter running time, in practise allowing training the models on a single computer instead of a large computing cluster. In addition, the structured output approach provides a more streamlined—and thus more easy to maintain—one-step prediction pipeline, as opposed to two-step pipelines of CSI:FingerID and FingerID which call for predicting and scoring fingerprints as an intermediate step.<ref type="figure">Fig. 4</ref>. Heatmap of the percentage of correctly identified metabolites (Top 1) with IOKR. The rows correspond to the different output kernels built on fingerprints (linear, polynomial and Gaussian) and the columns to the 24 input kernels derived from spectra and fragmentation trees, as well as the two multiple kernel combination schemes ALIGNF and UNIMKLFor future work, the most important direction is to address the prediction of the 'dark matter' in metabolomics (da<ref type="bibr" target="#b8">Silva et al., 2015</ref>): the metabolites that fall outside the compounds in molecular structure databases. There, we need to design better kernels and preimage algorithms for molecular structures. Finally, it is important to note that the recent breakthroughs in machine learning methodologies for metabolite identification rely heavily on the existence off community efforts building open reference databases such as GNPS and Massbank. At the same time, the reference databases still cover a small fraction of relevant metabolite space. Although machine learning can generalize and extrapolate beyond the training data, as also shown in this article, the scarceness of training data still imposes limits on how accurate models can be built. To really push metabolomics forward, we should widen and make more systematic the community efforts in building and utilizing reference databases.<ref type="figure">Fig. 6</ref>. Identified metabolites with IOKR in function of the size of candidate sets. We considered the candidate sets of size smaller than 8000, which corresponds to 98.8% of the sets, and divided them in 30 bins according to their sizes. (a) indicates the number of test metabolites that have a candidate set size in the corresponding size bin. The percentage of metabolites that are ranked in top 1 position, top 10 or above is shown on the (b) for the test metabolites falling in each size bin<ref type="figure">Fig. 7</ref>. Scatter plot of classes in ChEBI ontology with shortest paths of length 7 from the class chemical entity. X-axis corresponds to the median number of candidates associated with the compounds in each class and y-axis to the proportion of correct compounds with rank less or equal to 10 for each class. The size of the point is proportional to the number of compounds in GNPS dataset that belong to that class and we only show classes with at least 10 compounds. The classes we can identify well are shown in red and the classes we cannot are shown in blue with ChEBI id and name next to them</p><p>Metabolite identification with IOKR i35</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Overview of the IOKR framework for solving the metabolite identification problem. The mapping f between MS/MS spectra and 2D molecular structures is learnt by approximating the output feature map / y with a function h and solving a preimage problem</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.3.</head><figDesc>Fig. 3. Difference in percentage points to the percentage of metabolites ranked lower than k with CSI:FingerID using the modified Platt scoring function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.5.</head><figDesc>Fig. 5. Heatmap of kernel weights learned by ALIGNF for all pairs of input and output kernels on GNPS dataset. The weights have been averaged over the 10 CV folds</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>, V C The Author 2016. Published by Oxford University Press.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 1. Notations used in the article</figDesc><table>Symbol 
Explanation 

X ; Y 
input, output sets 
x, y 
elements of X ; Y 
j y : Y Â Y ! R 
output scalar kernel 
F y 
output feature space 
/ y : Y ! F y 
output feature map 
K x : X Â X ! LðF y ; F y Þ 
input operator-valued kernel 
H 
reproducing kernel Hilbert space of K x 
K X' 
Gram matrix on training set 
j x : X Â X ! R 
input scalar kernel 
F x 
input feature space 
/ x : X ! F x 
input feature map 
K X' 
Gram matrix on training set 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 2.</figDesc><table>Description of the input kernels used in this article 

Category 
Name 
Description 
Reference 

Loss-based kernels Loss binary (LB) 
counts the number of common losses 
Shen et al. (2014) 
Loss intensity (LI) 
weighted variant of LB that uses the intensity of terminal nodes 
Shen et al. (2014) 
Loss count (LC) 
counts the number of occurrences of the losses 
Shen et al. (2014) 
Weighted loss count (LW) 
weighted variant of LC using the inverse frequency of training losses 
Root loss binary (RLB) 
counts the number of common losses from the root to some node 
Shen et al. (2014) 
Root loss intensity (RLI) 
weighted variant of RLB that uses the intensity of terminal nodes 
Shen et al. (2014) 
Loss intensity PP (LIPP) 
probability product (PP) of shared losses 
Dü hrkop et al. (2015) 
Node-based kernels Node binary (NB) 
counts the number of nodes with the same molecular formula 
Shen et al. (2014) 
Node intensity (NI) 
weighted variant of NB that uses the intensity of nodes 
Shen et al. (2014) 
Node subformula (NSF) 
counts the number of common substructures 
Dü hrkop et al. (2015) 
Fragment intensity PP (FIPP) 
PP of shared fragments (nodes) 
Dü hrkop et al. (2015) 
Path-based kernels Common paths counting (CPC) 
counts the number of common paths (identical sequences of losses) Shen et al. (2014) 
Common paths of length 2 (CP2) 
counts the number of common paths of length 2 
Shen et al. (2014) 
Common paths of length 
at least 2 (CP2þ) 

counts the number of common paths of length at least 2 
Dü hrkop et al. (2015) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><figDesc>Table 3. Comparison of the percentage of correctly identified structures for top 1, 10 and 20 using FingerID, CSI:FingerId and IOKR</figDesc><table>Method 
MKL 
Top 1 
Top 10 
Top 20 

FingerID 
none 
17.74 
49.59 
58.17 
CSI:FingerID unit 
ALIGNF 
24.82 
60.47 
68.2 
CSI:FingerID mod Platt 
ALIGNF 
28.84 
66.07 
73.07 
IOKR linear 
ALIGNF 
28.54 
65.77 
73.19 
UNIMKL 
30.02 
66.05 
73.66 
IOKR Gaussian 
ALIGNF 
29.78 
67.84 
74.79 
UNIMKL 
30.66 
67.94 
75.00 

The highest values are shown in boldface. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><figDesc>Table 4. Running time evaluation</figDesc><table>Training time 
Test time 

CSI:FingerID 
82 h 28 min 23 s 
1 h 11 min 31 s 
IOKR linear 
42 s 
1 min 15 s 
IOKR polynomial 
38 s 
21 min 58 s 
IOKR Gaussian 
41 s 
33 min 15 s 

These running times were obtained by training the methods on the 4138 
GNPS spectra and using 625 spectra from Massbank as test set. 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">C.Brouard et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We acknowledge the computational resources provided by the Aalto ScienceIT project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work has been supported by the Academy of Finland<ref type="bibr">[</ref></p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">CFM-ID: a web server for annotation, spectrum prediction and metabolite identification from tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Allen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="94" to="99" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Competitive fragmentation modeling of ESI-MS/MS spectra for putative metabolite identification</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Allen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metabolomics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="98" to="110" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards de novo identification of metabolites by analyzing tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bö Cker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Rasche</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinfomatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="49" to="55" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">PubChem: Integrated platform of small molecules and biological activities</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Bolton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chapter Annual Reports in Computational Chemistry</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="217" to="241" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Semi-supervised penalized output kernel regression for link prediction</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brouard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning<address><addrLine>Bellevue, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Input output kernel regression: supervised and semisupervised structured output prediction with operator-valued kernels</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brouard</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A general regression technique for learning transductions</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Cortes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine Learning</title>
		<meeting>the 22nd International Conference on Machine Learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Algorithms for learning kernels based on centered alignment</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Cortes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="795" to="828" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Illuminating the dark matter in metabolomics</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">R</forename>
				<surname>Da Silva</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>. Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="12549" to="12550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Searching molecular structure databases with tandem mass spectra using CSI:FingerID</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Dü Hrkop</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>. Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="12580" to="12585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning multiple tasks with kernel methods</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Evgeniou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="615" to="637" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Kernelizing the output of tree-based methods</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Geurts</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23th International Conference on Machine learning</title>
		<meeting>the 23th International Conference on Machine learning<address><addrLine>Pittsburgh, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="345" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">The ChEBI reference database and ontology for biologically relevant chemistry: enhancements for 2013</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hastings</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="456" to="463" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">FiD: A software for ab initio structural identification of product ions from tandem mass spectrometric data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Heinonen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rapid Commun. Mass Spectrom</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="3043" to="3052" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Metabolite identification and molecular fingerprint prediction through machine learning</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Heinonen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2333" to="2341" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Automated assignment of highresolution collisionally activated dissociation mass spectra using a systematic bond disconnection approach</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">W</forename>
				<surname>Hill</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
				<surname>Mortishire-Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rapid Commun. Mass Spectrom</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="3111" to="3118" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">MassBank: A public repository for sharing mass spectral data for life sciences</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Horai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mass Spectrom</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="703" to="714" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Nonlinear functional regression: a functional RKHS approach</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kadri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Artificial Intelligence and Statistics</title>
		<meeting>International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="111" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A generalized kernel approach to structured output learning</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kadri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="471" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Usa</forename>
				<surname>Atlanta</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Operator-valued kernel-based vector autoregressive models for network inference</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Lim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="489" to="513" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lindsay</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Multilabel structured output learning with random spanning trees of max-margin markov networks</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Marchand</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="873" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">On learning vector-valued functions</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">A</forename>
				<surname>Micchelli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Pontil</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="177" to="204" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic chemical structure annotation of an LC–MSn based metabolic profile from green tea</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ridder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="6033" to="6040" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient algorithms for max-margin structured classification</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Rousu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Predicting Structured Data</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="105" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Hilbert spaces of operator-valued functions</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Senkene</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Tempel &apos;man</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lithuanian Math. J</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="665" to="670" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Metabolite identification through machine learning– tackling CASMI challenge using FingerID</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metabolites</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="484" to="505" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Metabolite identification through multiple kernel learning on fragmentation trees</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="157" to="164" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Multilabel classification through random graph ensembles</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Su</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Rousu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="231" to="256" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Max-margin Markov networks Support vector machine learning for interdependent and structured output spaces</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Taskar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS) International Conference on Machine Learning (ICML)</title>
		<meeting><address><addrLine>Vancouver, Canada. Tsochantaridis,I ; Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">MIDAS: a database-searching algorithm for metabolite identification in metabolomics</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="9496" to="9503" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Kernel dependency estimation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Weston</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 15</title>
		<editor>Becker, S. Thrun, S., and Obermayer, K.</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">In silico fragmentation for computer assisted identification of metabolite mass spectra</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wolf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>