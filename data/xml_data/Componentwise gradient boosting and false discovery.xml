
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Component-wise gradient boosting and false discovery control in survival analysis with high-dimensional covariates Downloaded from</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-09-17">Advance Access Publication Date: 17 September 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Kevin</forename>
								<surname>He</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biostatistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yanming</forename>
								<surname>Li</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biostatistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ji</forename>
								<surname>Zhu</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>Michigan</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Hongliang</forename>
								<surname>Liu</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Medicine</orgName>
								<orgName type="department" key="dep2">Duke University School of Medicine and Duke Cancer Institute</orgName>
								<orgName type="institution">Duke University Medical Center</orgName>
								<address>
									<postCode>27710</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jeffrey</forename>
								<forename type="middle">E</forename>
								<surname>Lee</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Surgical Oncology</orgName>
								<orgName type="institution">The University of Texas</orgName>
								<address>
									<addrLine>M.D. Anderson Cancer Center</addrLine>
									<postCode>77030</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Christopher</forename>
								<forename type="middle">I</forename>
								<surname>Amos</surname>
							</persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Department of Community and Family Medicine</orgName>
								<orgName type="department" key="dep2">Geisel School of Medicine</orgName>
								<orgName type="institution">Dartmouth College</orgName>
								<address>
									<postCode>03750</postCode>
									<settlement>Hanover</settlement>
									<region>NH</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Terry</forename>
								<surname>Hyslop</surname>
							</persName>
							<affiliation key="aff5">
								<orgName type="department">Department of Biostatistics and Bioinformatics</orgName>
								<orgName type="institution">Duke University and Duke Clinical Research Institute</orgName>
								<address>
									<postCode>27710</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jiashun</forename>
								<surname>Jin</surname>
							</persName>
							<affiliation key="aff6">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Huazhen</forename>
								<surname>Lin</surname>
							</persName>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Center of Statistical Research</orgName>
								<orgName type="department" key="dep2">School of Statistics</orgName>
								<orgName type="institution">Southwestern University of Finance and Economics</orgName>
								<address>
									<postCode>611130</postCode>
									<settlement>Chengdu</settlement>
									<region>Sichuan</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Qinyi</forename>
								<surname>Wei</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Medicine</orgName>
								<orgName type="department" key="dep2">Duke University School of Medicine and Duke Cancer Institute</orgName>
								<orgName type="institution">Duke University Medical Center</orgName>
								<address>
									<postCode>27710</postCode>
									<settlement>Durham</settlement>
									<region>NC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yi</forename>
								<surname>Li</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biostatistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alfonso</forename>
								<surname>Valencia</surname>
							</persName>
						</author>
						<title level="a" type="main">Component-wise gradient boosting and false discovery control in survival analysis with high-dimensional covariates Downloaded from</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Bioinformatics</title>
						<imprint>
							<biblScope unit="volume">32</biblScope>
							<biblScope unit="issue">2016</biblScope>
							<biblScope unit="page" from="50" to="57"/>
							<date type="published" when="2015-09-17">Advance Access Publication Date: 17 September 2015</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv517</idno>
					<note type="submission">Received on April 1, 2015; revised on August 7, 2015; accepted on August 25, 2015</note>
					<note>Genetics and population analysis *To whom correspondence should be addressed. Associate Editor: Contact: yili@umich.edu 50 Original Paper at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Technological advances that allow routine identification of high-dimensional risk factors have led to high demand for statistical techniques that enable full utilization of these rich sources of information for genetics studies. Variable selection for censored outcome data as well as control of false discoveries (i.e. inclusion of irrelevant variables) in the presence of high-dimensional predictors present serious challenges. This article develops a computationally feasible method based on boosting and stability selection. Specifically, we modified the component-wise gradient boosting to improve the computational feasibility and introduced random permutation in stability selection for controlling false discoveries. Results: We have proposed a high-dimensional variable selection method by incorporating stability selection to control false discovery. Comparisons between the proposed method and the commonly used univariate and Lasso approaches for variable selection reveal that the proposed method yields fewer false discoveries. The proposed method is applied to study the associations of 2339 common single-nucleotide polymorphisms (SNPs) with overall survival among cutaneous melanoma (CM) patients. The results have confirmed that BRCA2 pathway SNPs are likely to be associated with overall survival, as reported by previous literature. Moreover, we have identified several new Fanconi anemia (FA) pathway SNPs that are likely to modulate survival of CM patients. Availability and implementation: The related source code and documents are freely available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Rapid advances in technology that have generated vast amounts of data from genetic or genome studies have led to a high demand for developing powerful statistical learning methods for extracting information effectively. For instance, understanding clinical and pathophysiologic heterogeneities among subjects at risk and designing effective treatment for appropriate subgroups is one of the most active areas in genetic studies. Wide heterogeneities present in patients' response to treatments or therapies. Understanding such heterogeneities is crucial in personalized medicine, and discovery of genetic variants offers a feasible approach. However, serious statistical challenges arise when identifying real predictors among hundreds of thousands of candidates, and an urgent need has emerged for the development of effective algorithms for model building and variable selection. The last three decades have given rise to many new statistical learning methods, including CART (<ref type="bibr" target="#b5">Breiman et al., 1984</ref>), random forest (<ref type="bibr" target="#b6">Breiman, 2001</ref>), neural networks (<ref type="bibr" target="#b3">Bishop, 1995</ref>), SVMs (<ref type="bibr" target="#b4">Boser et al., 1992</ref>) and high dimensional regression (<ref type="bibr">Li, 2001, 2002;</ref><ref type="bibr" target="#b21">Gui and Li, 2005;</ref><ref type="bibr" target="#b40">Tibshirani, 1996</ref><ref type="bibr" target="#b41">Tibshirani, , 1997</ref>). Boosting has emerged as a powerful framework for statistical learning. It was originally introduced in the field of machine learning for classifying binary outcomes (<ref type="bibr" target="#b17">Freund and Schapire, 1996</ref>), and later its connection with statistical estimation was established by<ref type="bibr" target="#b18">Friedman et al. (2000</ref><ref type="bibr" target="#b19">). Friedman (2001</ref>proposed a gradient boosting framework for regression settings. Bü hlmann and<ref type="bibr" target="#b8">Yu (2003)</ref>proposed a component-wise boosting procedure based on cubic smoothing splines for L2 loss functions. Bü hlmann (2006) demonstrated that the boosting procedure works well in high-dimensional settings. For censored outcome data, Ridgeway (1999) applied boosting to fit proportional hazards models, and Li and Luan (2005) developed a boosting procedure for modeling potentially non-linear functional forms in proportional hazards models. Despite the popularity of aforementioned methods, issues such as false discovery (e.g. seletion of irrelevant SNPs) and difficulty in identifying weak signals present further barriers. Simultaneous inference procedure, including the Bonferroni correction, has been widely used in large-scale testing literature. However, in many highdimensional settings, such as in genetic studies, variable selection is serving as a screening tool to identify a set of genetic variants for further investigation. Hence, a small number of false discoveries would be tolerable and simultaneous inference would be too conservative. In contrast, the false discovery rate (FDR), defined as the expected proportion of false positives among significant tests (<ref type="bibr" target="#b2">Benjamini and Hochberg, 1995</ref>), is a more relevant metric for false discovery control under the framework of variable selection. However, few existing variable selection algorithms control false discoveries. This has brought an urgent need of developing computationally feasible methods that tackle both variable selection and false discovery control. We propose a novel high-dimensional variable selection method for survival analysis by improving the existing variable selection methods in several aspects. First, we have developed a computationally feasible variable selection approach for high-dimensional survival analysis. Second, we have designed a random sampling scheme to improve the control of the false discovery rate. Finally, the proposed framework is flexible to accommodate complex data structures. The rest of the article is organized as follows. In Section 2 we introduce notation and briefly review the L 1 penalized estimation and gradient boosting method that are of direct relevance to our proposal. In Section 3 we develop the proposed approach, and in Section 4 we evaluate the practical utility of the proposal via intensive simulation studies. In Section 5 we apply the proposal to analyze a genome-wide association study of cutaneous melanoma. We conclude the article with a brief discussion in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>Let D i denote the time from onset of cutaneous melanoma to death and C i be the potential censoring time for patient i, i ¼ 1;. .. ; n. The observed survival time is T i ¼ minfD i ; C i g, and the death indicator is given by d i ¼ IðD i C i Þ. Let X i ¼ ðX i1 ; Á Á Á ; X ip Þ T be a p-dimensional covariate vector (contains all the SNP information) for the ith patient. We assume that, conditional on X i , D i is independently censored by C i. To model the death hazard, consider</p><formula>k i ðtjX i Þ ¼ lim dt!0 1 dt Prðt D i &lt; t þ dtjD i ! t; X i Þ ¼ k 0 ðtÞexpðX T i bÞ;</formula><p>where k 0 ðtÞ is the baseline hazard function and b ¼ ðb 1 ; Á Á Á ; b p Þ is a vector of parameters. The corresponding log-partial likelihood is given by</p><formula>l n ðbÞ ¼ X n i¼1 d i X T i b À log X '2Ri expðX T ' bÞ ( ) " # ;</formula><p>where R i ¼ f' : T ' ! T i g is the at-risk set. The goal of variable selection is to identify S 0 ¼ fj : b j 6 ¼ 0g, which contains all the variables that are associated with the risk of death.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">L 1 penalized estimation</head><p>Tibshirani (1997) proposed a Lasso procedure in the Cox model, e.g. estimate b via the penalized partial likelihood optimization ^ b ¼ argmax b fl n ðbÞ À kjjbjj 1 g;</p><formula>(1)</formula><p>where kÁk 1 is the L 1 norm. To solve (1), Tibshirani (1997) considered a penalized reweighted least squares approach. Let X ¼ ðX 1 ;. .. ; X n Þ be the p Â n covariate matrix and define g ¼ X T b. Let l 0 n ðgÞ and l 00 n ðgÞ be the gradient and Hessian of the log-partial likelihood with respect to g respectively. Given the current estimator ^ g ¼ X T ^ b, a two-term Taylor expansion of the log-partial likelihood leads to l n ðbÞ % 1 2 ðzð^ gÞ À X T bÞ T l 00 n ð^ gÞðzð^ gÞ À X T bÞ;</p><p>where zð^ gÞ ¼ ^ g À l 00 n ð^ gÞ À1 l 0 n ð^ gÞ. Similar to the problem of conditional likelihood (<ref type="bibr" target="#b22">Hastie and Tibshirani, 1990</ref>), the matrix l 00 n ð^ gÞ is non-diagonal, and solving (1) may require Oðn 3 Þ computations. To avoid this difficulty, Tibshirani (1997) used some heuristic arguments to approximate the Hessian matrix with a diagonal one, e.g. treated off-diagonal elements as zero. An iteratively procedure is then conducted based on the penalized reweighed least squares 1 n X n i¼1 wð^ gÞ i ðzð^ gÞ i À X T i bÞ 2 þ kjjbjj 1 ;</p><formula>(2)</formula><p>where the weight wð^ gÞ i for subject i is the ith diagonal entry of l 00 n ð^ gÞ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Component-wise gradient boosting and false discovery control</head><p>To obtain a more accurate estimation,<ref type="bibr">Gui</ref>where z Ã ð^ gÞ ¼ Azð^ gÞ and X Ã ¼ AX. Alternatively, Geoman (2010) combined gradient descent with Newton's method and implemented his algorithm in an R package penalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Gradient boosting</head><p>Gradient boosting has emerged as a powerful tool for building predictive models; its application in the Cox proportional hazards models can be found in Ridgeway (1999) and Li and Luan (2005). The idea is to pursue iterative steepest ascent of the log likelihood function. At each step, given the current estimate of b, say ^ b, let ^ g ¼ X T ^ b. The algorithm computes the gradient of the log-partial likelihood with respect to g i , the ith component of g,</p><formula>U i ¼ @ @g i l n ðgÞj g¼^ g ¼ d i À X n '¼1 d ' IðT i ! T ' Þexpð^ g i Þ X n k¼1 IðT k ! T ' Þexpð^ g k Þ ;</formula><p>for i ¼ 1; Á Á Á ; n, and then fits this gradient (also called working response or pseudo response) to X by a so-called base procedure (e.g. least squares estimation). Specifically, to facilitate variable selection, a component-wise algorithm can be implemented by restricting the search direction to be component-wise (Bü hlmann and Yu, 2003;<ref type="bibr" target="#b29">Li and Luan, 2005</ref>). For instance, fit component-wise model</p><formula>~ b j ¼ argmin b j 1 n X n i¼1 ðU i À X ij b j Þ 2 ;</formula><p>for j ¼ 1;. .. ; p. Compute</p><formula>j ? ¼ argmin 1 j p 1 n X n i¼1 ðU i À X ij ~ b j Þ 2 :</formula><p>and update ^ b j ? ¼ ^ b j ? þ v ~ b j ? , where v is a positive small constant (say 0.01) controlling the learning rate (<ref type="bibr" target="#b19">Friedman, 2001</ref>). For least squares estimation, the gradient boosting is is exactly the usual forward stagewise procedure (termed as linear-regression version of the forward-stagewise boosting in Algorithm 16.1 of<ref type="bibr" target="#b23">Hastie et al., 2009</ref>). Bü hlmann and Hothorn (2007) refer to the same procedure as " L2boost ". This approach is to detect a component-wise direction along which the partial likelihood would ascend most rapidly. At each boosting iteration only one component of b is selected and updated. The variable selection can be achieved if boosting stops at an optimal number of iterations. This optimal number works as the regularization parameter and it can be determined by cross-validation (<ref type="bibr" target="#b37">Simon et al., 2011</ref>). However, as we will show in simulation, the cross-validated choice still includes certain amount of false positive selections. A computationally feasible method is needed to control false discoveries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Control of the false discovery rate (FDR)</head><p>Benjamini and Hochberg's FDR-controlling procedure (<ref type="bibr" target="#b2">Benjamini and Hochberg, 1995</ref>), or BH's procedure for short, is a recent innovation for controlling the FDR. Consider a setting where we test a large number of tests simultaneously. Let R be the number of total discoveries (selection of SNPs) and let V be the number of false discoveries (selection of irrelevant SNPs). If we denote the False Discovery Proportion by FDP ¼ V=R; then FDR is simply the expectation of false discovery proportion (FDP). In the simplest setting (i.e. P-values associated all component tests are independent), BH's procedure is able to control the FDR at any preselect level 0 &lt; q &lt; 1 (called the FDR-control parameter). In the past 20 years, BH's procedure has inspired a great deal of research: many variants of the procedure have been proposed, and many insights and connections have been discovered. For instance,<ref type="bibr" target="#b12">Efron (2008</ref><ref type="bibr" target="#b13">Efron ( , 2012</ref>) and Storey (2003) have pointed out an interesting connection between the BH's procedure and the popular Empirical Bayes method. In particular, they proposed a Bayesian version of the FDR which they call the Local FDR (Lfdr) and showed that two versions of FDR are intimately connected to each other. Another useful variant of BH's procedure is the Significance Analysis of Microarrays (SAM;<ref type="bibr" target="#b42">Tusher et al., 2001</ref>), a method that was originally designed to identify genes in microarray experiments. While the success of the BH's procedure hinges on an accurate approximation of the P-values associated with individual tests, SAM is comparably more flexible for it is able to handle more general experimental layouts and summary statistics, where the P-values may be hard to obtain or to approximate. See Efron (2012) for a nice review on FDR-controlling methods, Lfdr and SAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Component-wise gradient boosting procedure</head><p>To introduce the proposed method, we first consider a variant of component-wise gradient boosting method that is computationally efficient in high-dimensional settings.</p><p>Algorithm 1 (Componentwise Gradient Boosting) Initialize ^ b ð0Þ ¼ 0. For m ¼ 1; Á Á Á ; M stop , iterate the following steps:</p><p>(a) For j ¼ 1;. .. ; p, compute the componentwise gradient</p><formula>G j ¼ @ @b j l n ðbÞj b ¼ ^ b ðmÀ1Þ : (3)</formula><p>(b) Compute j ? ¼ argmax 1 j p jG j j:</p><formula>(c) Update ^ b ðmÞ j ? ¼ ^ b ðmÀ1Þ j ? þ v ~ b j ? ,</formula><p>where ~ b j ? can be estimated by one-step Newton's update</p><formula>~ b j ? ¼ @ 2 @b 2 j ? l n ðbÞj b¼ ^ b ðmÀ1Þ g À1 @ @b j ? l n ðbÞj b¼ ^ b ðmÀ1Þ :</formula><p>(</p><p>(d) Iterate until m ¼ M stop for some stopping iteration M stop .</p><p>Algorithm 1 is closely connected to the traditional boosting procedure we described in Section 2.3, which first computes the working response, U i , and then fits the working response to each covariate by least squares. For instance, under the chain rule of differentiation,</p><formula>argmin 1 j p 1 n X n i¼1 ðU i À X ij ~ b j Þ 2 ¼ argmax 1 j p j X n i¼1 U i X ij j ¼ argmax 1 j p jG j j;</formula><p>where G j was defined in (3). In contrast, Algorithm 1 is based on gradient with respect to b and it avoids the calculation of working response. Such a component-wise update is connected with a minimization-maximization (MM) algorithm (<ref type="bibr" target="#b25">Hunter and Lange, 2004;</ref><ref type="bibr" target="#b28">Lange, 2013</ref>). For instance, in a minorization step, given the mth step estimate ^ b ðmÀ1Þ , an application of Jensen's inequality leads to the following minority surrogate function</p><formula>l n ðbÞ ! X p j¼1 X n i¼1 a j d i " X ij a j ðb j À ^ b ðmÀ1Þ j Þ þ X T i ^ b ðmÀ1Þ Àlog X '2Ri exp X 'j a j ðb j À ^ b ðmÀ1Þ j Þ þ X T ' ^ b ðmÀ1Þ ( ) # ¼ gðbj ^ b ðmÀ1Þ Þ ¼ X p j¼1 gðb j j ^ b ðmÀ1Þ Þ;</formula><p>where gðb j j ^ b ðmÀ1Þ Þ is defined implicitly, all a j ! 0; P j a j ¼ 1 and a j &gt; 0 whenever X ij 6 ¼ 0. In the maximization step, we maximize (or monotonically increase) the selected component of the surrogate function to produce the next iteration estimators, e.g. consider gðb j ? j ^ b ðmÀ1Þ Þ and update b j ?. Then the boosting algorithm monotonically increase the original log-partial likelihood by increasing the surrogate functions. Note that as long as the ascent property is achieved, the choice of a j is not crucial, e.g. it can be considered as part of a control for step size. Moreover, as one only needs to increase the surrogate function instead of maximizing it, one-step Newton iterations (with step-size control) shall provide sufficient and rapid updates at each boosting step. The parameter v can be regarded as controlling the step size of the one-step Newton procedure. This may explain the reason that in practice the best strategy for learning rate of a boosting procedure is to set v to be very small (v &lt; 0.1). Instead of using ~ b j ? , an alternative approach is to use the normalized updates with norm normalized to be 1, e.g.</p><formula>^ b ðmÞ j ? ¼ ^ b ðmÀ1Þ j ?</formula><p>þ v Â signðG j Þ. Its main disadvantage is that its performance is sensitive to the choice of learning rate. Although signðG j Þ provides an ascent direction, a sufficiently small step length may be needed. Empirically we found that the procedure with fitted ~ b j ? provides better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Boosting with stability selection for false discovery control</head><p>Stability Selection was recently introduced by Meinshausen and Bü hlmann (2010) as a general technique designed to improve the performance of a variable selection algorithm. The idea is to identify variables that are included in the model with high probabilities when a variable selection procedure is performed on randomly sampled of the observations. For completeness of exposure, we summarize the procedure of stability selection as follows. Let I be a random subsample of f1; Á Á Á ; ng of size bn=2c, draw without replacement. Here bn=2c is defined as the largest integer not greater than n=2. For variable j 2 f1; Á Á Á ; pg, the random sampling probability that the jth variable is selected by the stability selection is</p><formula>^ P j ¼ Pr Ã ½j 2 ^ SðIÞ;</formula><p>where ^ SðIÞ ¼ fj : ^ b ðIÞ j 6 ¼ 0g denotes the variable selected by the variable selection procedure based on the subsample I, and the empirical probability Pr Ã is with respect to the random sampling.</p><p>For a threshold P thres 2 ð0; 1Þ, the set of variables selected by stability selection is then defined as</p><formula>^ S stable ¼ fj : ^ P j ! P thres g:</formula><p>A particularly attractive feature of stability selection is that its relatively insensitive to the tuning parameter (e.g. M stop for boosting) and hence cross-validation can be avoided. However, a new regularization parameter needs to be determined is the threshold P thres. To address this question, an error control was provided by an upper bound on the expected number of falsely selected variables (Meinshausen and Bü hlmann, 2010; Theorem 1). More formally, let Ej ^ SðIÞj be the expected number of selected variables and define V to be the number of falsely selected variables. Assume an exchangeable condition, then the expected number V of falsely selected variables is bounded for P thres 2 ð0:5; 1Þ by</p><formula>E½V 1 2P thres À 1 ðEj ^ SðIÞjÞ 2 p :</formula><p>Based on such a bound, the tuning parameter P thres can be chosen such that E½V is controlled at the desired level, e.g. for E½V &lt; 1, if</p><formula>Ej ^ SðIÞj &lt; p 1 2 , P thres ¼ 1 þ ðEj ^ SðIÞjÞ 2 p ! =2: (4)</formula><p>The property of the above procedure relies on restricted assumptions such as exchangeability condition (e.g. the joint distribution of outcomes and covariates is invariant under permutations of non-informative variables), which, as noted by Meinshausen and van de Geer (2011), are not likely to hold for real data. In genetic studies with extensive correlation structure among SNP markers, the exchangeability condition fails and using threshold in (4) has been shown to suffer a loss of power (<ref type="bibr">Alexander and Lange, 2011</ref>). Moreover, in computing the threshold in (4), we face a tradeoff. Commonly used variable selection procedures will select certain amount of false positives. On one hand, we want Ej ^ SðIÞj to be large to select the true informative predictors, but on the other hand, a large Ej ^ SðIÞj also can render P thres large (which leads to too conservative threshold). If Ej ^ SðIÞj &gt; p 1 2 , we cannot control the error E½V with the formula in (4). To improve the performance of stability selection and determine a data-driven threshold for the selection frequency, we adopt the idea of SAM (<ref type="bibr" target="#b42">Tusher et al., 2001</ref>) and propose a random permutation based stability selection boosting procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 (Boosting with Stability Selection and Permutation)</head><p>(a) For s ¼ 1; Á Á Á ; 100, we draw random subsample of the data of size bn=2c. On the sth subsample, implement the proposed boosting approach (e.g. Algorithm 1). Record the set of selected predictors at the sth subsampling, ^ S ðsÞ ¼ fj : ^ b ðsÞ j 6 ¼ 0g, and compute ^</p><formula>P j ¼ 1 S P S s¼1 Iðj 2 ^ S ðsÞ Þ,</formula><p>where I(A) is an indicator function taking the value 1 when condition A holds and 0 otherwise.</p><p>(b) For b ¼ 1; Á Á Á ; B, randomly permute the outcomes so that the relation between covariates and outcomes is decoupled. Repeat the stability-based boosting described in step (a) on the permuted sample and record the set of selected predictors ~ S ðbÞ , and compute ~ PThen this ^ P thres ðqÞ can be used to determine the selected variables. If q ¼ 0.2 and 5 variables are selected with selection frequency greater than ^ P thres ð0:2Þ, then 1 of these 5 variables would be expected to be false positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Simulations</head><p>Finite-sample properties of the proposed method were evaluated through a series of simulation studies. Death times were generated from the exponential model, kðtjX i Þ ¼ 0:5expðX T i bÞ for i ¼ 1;. .. ; n, where n ¼ 1000 and X i ¼ ðX i1 ; Á Á Á ; X i2000 Þ T came from multivariate normal distributions. These 2000 predictors were in 10 blocks with equal numbers of predictors within each block. We considered three simulation schemes with within-block correlation coefficients varying between 0.2, 0.5 and 0.8. For all three schemes, the between-block correlation coefficients were 0 (i.e. independent between blocks). We chose 10 true signals; one from each block, with true b in 60:5; 61; 61:5; 62; 62:5. All other covariate effects are zero. Censoring times were generated from uniform distributions, with the percentage of censored subjects then being approximately 20–30%. Each data configuration was replicated 100 times. We first assess the speed of our algorithm.<ref type="figure" target="#tab_1">Table 1</ref>compares the computation time for the proposed approach with Lasso for proportional hazard models (implemented with R package penalized). These timings were taken on an Dell laptop (model XPS 15) with quad-core 2.1-GHz Intel Core i7-3612QM processor and 8 GB RAM. Numerically, we find the proposed approach is faster than R package penalized. As a gradient based method, at each iteration the computational speed of the proposed approach is faster than those approaches that require inverting the Hessian matrix. It is known that finding the proper regularization parameter is difficult for the Lasso procedure, especially for survival settings for which piece-wise linear solution path (LARS;<ref type="bibr" target="#b11">Efron et al., 2004</ref>) is not available and a grid search (<ref type="bibr" target="#b37">Simon et al., 2011</ref>) or bisection method (<ref type="bibr" target="#b20">Geoman, 2010</ref>) is required (e.g. multiple Lasso procedures are needed for a series of tuning parameters). In contrast, in boosting procedure, the number of iteration works as tuning parameter and the selection of optimal tuning parameter can be implemented in a single boosting procedure. Moreover, the optimal choice is less critical as boosting is more robust to overfitting (<ref type="bibr" target="#b23">Hastie et al., 2009</ref>). We compared the proposed methods, Lasso for proportional hazard models, univariate approaches with either Bonferroni correction (termed Univariate Bonferroni in<ref type="figure" target="#tab_2">Table 2</ref>) or Benjamini and Hochberg's (1995) procedure for FDR control (below a threshold 0.2; termed Univariate FDR in<ref type="figure" target="#tab_2">Table 2</ref>). For Lasso and the boosting approach without stability control (Algorithm 1), 10-fold crossvalidation was implemented to determine the optimal tuning parameters (e.g.<ref type="bibr" target="#b37">Simon et al., 2011</ref>). For the boosting approach with stability selection, we repeatedly drew 100 random subsamples of the data of size bn=2c. Both the thresholds defined in formula (4) and Algorithm 2 with q ¼ 0.2 (termed S-Boosting-1 and S-Boosting2 respectively) were used for variable selection.<ref type="figure" target="#tab_2">Table 2</ref>shows that the boosting without stability selection (termed Boosting in<ref type="figure" target="#tab_2">Table 2</ref>) outperform the univariate approaches in the average number of false positives (FP), average FDP, average number of false negative (FN) and the empirical probabilities to identify the true signal (Power). Though the Lasso has comparable performances in terms of FN and Power, the FPs of the boosting methods are substantially fewer than the Lasso. Finally, the proposed boosting method with stability selection and permutation (S-Boosting-2) further reduces the FPs and it outperforms S-Boosting-1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Application of cutaneous melanoma data</head><p>Cutaneous melanoma (CM) is one of the most aggressive skin cancers, causing the greatest number of skin cancer related deaths worldwide. Among the CM patients, wide heterogeneities are present. The commonly used clinicopathological variables, such as tumor stage and Breslow thickness (<ref type="bibr" target="#b1">Balch et al., 2009</ref>), may have insufficient discriminative ability (<ref type="bibr" target="#b36">Schramm and Mann, 2011</ref>). Discovery of genetic variants would offer a feasible approach to understanding mechanisms that may affect clinical outcomes andThe boosting procedure is described in Sections 3.1; The Lasso is implemented using R package penalized; 10-fold cross-validation was implemented to determine the optimal tuning parameters.the sensitivity of individual cancer to therapy (<ref type="bibr" target="#b30">Liu et al., 2012</ref><ref type="bibr">Liu et al., , 2013</ref><ref type="bibr" target="#b34">Rendleman et al., 2013</ref>). We applied our proposed procedures to a genome-wide association study reported by<ref type="bibr" target="#b43">Yin et al. (2015)</ref>to analyze the association of 2339 common single-nucleotide polymorphisms (SNPs) with overall survival in CM patients. Our goal was to identify SNPS that are relevant to overall survival among the patients. The dataset contains a total of 858 CM patients, with 133 deaths observed during the follow-up, where the median follow-up time was 81.1 months. The overall survival time was calculated from the date of diagnosis to the date of death or the date of the last followup. Genotyped or imputed common SNPs (minor allele frequency ! 0:05, genotyping rate ! 95%, Hardy-Weinberg equilibrium P-value ! 0:00001 and imputation r 2 ! 0:8) within 14 autosomal FA genes or their 620-kb flanking regions were selected for association analysis (<ref type="bibr" target="#b43">Yin et al., 2015</ref>). As a result, 321 genotyped SNPs and 2018 imputed SNPs in the FA pathway were selected for further analysis. Other covariates to adjust for included age at diagnosis, Clark level, tumor stage, Breslow thickness, sentinel lymph node biopsy and the mitotic rate. The proposed boosting procedure with stability selection was implemented to select informative SNPs (coded as 0, 1; without or with minor alleles). The importance of predictors is evaluated by the proportion of times that the predictor is selected in the model among the 100 subsamples. We also compared the proposed methods with the Lasso, the boosting procedure without stability selection and univariate approaches. The results are summarized in<ref type="figure" target="#tab_3">Table 3</ref>. The Lasso procedure selected 25 SNPs. Among them, 12 SNPs with absolute coefficients larger than 0.01 are listed in<ref type="figure" target="#tab_3">Table 3</ref>. None of these predictors pass the univariate approaches with Bonferroni correction or<ref type="bibr" target="#b2">Benjamini and Hochberg's (1995)</ref>procedure for FDR control (with a threshold 0.2). As we found in Section 4, these results argue that the univariate approaches may have more false negatives than other methods. In contrast, the boosting procedure selected 7 predictors, which were a subset of top 12 SNPs selected by the Lasso. To further control the false selections, the estimated false discovery rate, Fdr, were also calculated to determine a datadriven threshold for the selection frequency such that Fdr 0:2. Three of the SNPs selected by both Lasso and boosting pass the threshold ^ P thres ð0:2Þ ¼ 72%. The remaining variables find insignificant support from stability selection.<ref type="figure" target="#tab_4">Table 4</ref>summarizes the numbers of selected variables from the Lasso and the boosting without or with stability selection. These results are consistent with those from simulation section. The Lasso tends to select too many variables. The boosting selects substantially fewer variables than the Lasso. The boosting procedure with stability selection provides a control for false positives.<ref type="figure" target="#fig_1">Figure 1</ref>shows the stability path (selection frequencies across boosting iterations). The variables with selection frequencies larger than the threshold (estimated empirical Bayes false discovery rate Fdr 0:2; based 500 permuted samples) are plotted as solid lines, while the path of the remaining variables are shown as broken lines. The top 3 variables stand out clearly and the number of boosting iteration is less critical. A Manhattan plot was given in<ref type="figure">Figure 2</ref>with the dashed horizontal line corresponding to the estimated threshold ^ P thres ð0:2Þ ¼ 72%. Three variables have selection frequencies larger than this dashed horizontal line. The vertical blue lines highlight the selection frequencies of the four previously-detected SNPs that are associated with overall survival of CM patients by<ref type="bibr" target="#b43">Yin et al. (2015)</ref>. The red vertical lines highlight the SNPs whose selection frequencies pass the estimated threshold. The lower panel of<ref type="figure">Figure 2</ref>illustrates pairwise correlations across the 2339 SNPs with the strength of the correlation, from positive to negative, indicated by the color spectrum from red to dark blue. One of the top SNPs in our finding, rs74189161 (with selection frequency ¼ 72% and Fdr ¼ 0:16) is strongly correlated with rs3752447 identified by<ref type="bibr" target="#b43">Yin et al. (2015)</ref>, with correlation coefficients r 2 ¼ 1 (calculated with plink v1.07;<ref type="bibr" target="#b33">Purcell et al., 2007</ref>). Besides confirming the previously reported SNP, we also found some novel signals. For example, we identified a cluster of signals around SNP rs356665 in gene FANCC and a SNP rs3087374 in gene FANC1. Both two genes have previously been reported having regulation effects with the FA pathway (<ref type="bibr" target="#b39">Thompson et al., 2012;</ref><ref type="bibr" target="#b26">Jenkins et al., 2012;</ref><ref type="bibr" target="#b27">Kao et al., 2011</ref>). Mutations in the FA pathway are identified in diverse cancer types (<ref type="bibr">Hucl and Gallmeier, 2011</ref>) and therefore are likely to modulate the survival of CM patients.Reducing the number of false discoveries is often very desirable in biological applications since follow-up experiments can be costly and laborious. We have proposed a boosting method with stability selection to analyze high-dimensional data. We demonstrated and compared performances of the proposed method and the commonly used univariate approaches or Lasso for variable selection. The proposed method outperformed other methods in terms of substantially reduced false positives and low false negatives. Finally, it is worth mentioning that the traditional gradient boosting approach described in Section 2.3 cannot accommodate some important models, including survival models with timevarying effects wherein the generic function eta not only depends on X, but also on time. In contrast, the proposed modification of gradient boosting works in flexible parameter spaces, even including infinite-dimensional functional spaces. In the latter case, as the search space is typically a functional space, one needs to calculate the Gâ teaux derivative of the functional in order to determine the optimal descent direction. We will report the work elsewhere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>Drs Li and Lin's research is partly supported by the Chinese Natural Science Foundation (11528102). Dr Wei's research is partly supported by NIH grants R01CA100264 and R01CA133996. Dr Hyslop's research is partly supported by a NIH grant P30CA014236. Dr Lee's research is partly supported by NCI SPORE P50 CA093459, and philanthropic contributions to The University of Texas M.D. Anderson Cancer Center Moon Shots Program, the Miriam and Jim Mulva Research Fund, the Patrick M. McCarthy Foundation and the Marit Peterson Fund for Melanoma Research. Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>^</head><figDesc>b Lasso : coefficients from Lasso; ^ b Boosting : coefficients from boosting; P-value: calculated from univariate approach; Frequency ð%Þ: selection frequencies across 100 subsampling; Fdr: estimated empirical Bayes false discovery rate (based 500 permuted samples); the false discovery control of the predictors under stability selection are coded by (*) to indicate that the selection frequencies pass the Fdr threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Selection Path: selection frequencies across 500 boosting iterations; Threshold: estimated empirical Bayes false discovery rate Fdr 0:2 (based 500 permuted samples)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 1.</figDesc><table>Comparisons of computation time: 1 simulation loops; 
n ¼ 1000 and p ¼ 2000 

Lasso 
Boosting 

7.49 min 
4.16 min 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 2. Summary of simulation results</figDesc><table>Correlation Methods 
FP 
FDP FN 
Power 

0 
Univariate Bonferroni 
0.01 0 
2.28 
0.77 
Univariate FDR 
1.94 0.18 1.49 
0.85 
Lasso 
185.22 0.95 0 
1 
Boosting 
15.76 0.61 0 
1 
S-Boosting-1 
0.01 0 
0 
1 
S-Boosting-2 
0 
0 
0 
1 

0.5 
Univariate Bonferroni 
85.29 0.92 2.32 
0.77 
Univariate FDR 
172.32 0.95 0.81 
0.92 
Lasso 
186.17 0.95 0 
1 
Boosting 
22.31 0.69 0 
1 
S-Boosting-1 
0.08 0.01 0 
1 
S-Boosting-2 
0.01 0 
0 
1 

0.8 
Univariate Bonferroni 131.42 0.94 2.17 
0.78 
Univariate FDR 
207.52 0.96 0.68 
0.93 
Lasso 
185.14 0.95 0 
1 
Boosting 
29.25 0.75 0 
1 
S-Boosting-1 
0.36 0.03 0.1 
0.99 
S-Boosting-2 
0.03 0.01 0 
1 

FP: the average number of false positives; FDP: false discovery proportion; 
FN: average number of false negative; Power: the empirical probabilities to 
identify the true signal </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 3. Summary of selected SNPs by Lasso (sorted by the magnitude of coefficients; only predictors with absolute coefficients larger than 0.01 are included), their estimated coefficients by boosting without stability selection, P-values based on univariate approach, selection frequencies based on stability selection</figDesc><table>SNPs 
Chromosome Gene 
^ 
b Lasso 
^ 
b Boosting P-value Frequency 
(%) 

rs74189161 
13 
BRCA2 À0.11 À0.10 0.002 
72* 
rs356665 
9 
FANCC À0.09 À0.04 0.03 
88* 
rs11649642 
16 
FANCA À0.08 À0.05 0.01 
27 
rs9567670 
13 
BRCA2 À0.07 À0.03 0.01 
51 
rs8081200 
17 
BRIP1 À0.06 À0.02 0.05 
38 
rs3087374 
15 
FANC1 À0.06 À0.01 0.02 
73* 
rs35322368 
9 
FANCC 
0.06 
0 
0.03 
65 
rs57119673 
16 
FANCA À0.04 À0.01 0.03 
54 
rs8061528 
16 
BTBD12 À0.03 
0 
0.12 
36 
rs2247233 
15 
FANC1 
0.02 
0 
0.15 
39 
rs848286 
2 
FANCL 
0.02 
0 
0.02 
23 
rs62032982 
16 
PALB2 
0.01 
0 
0.04 
34 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 4. Numbers of selected variables</figDesc><table>Lasso 
Boosting 
Stability selection 

25 
7 
3 

0 
100 
200 
300 
400 
500 
0.0 0.2 0.4 0.6 0.8 1.0 

Iteration 
Selection Frequency (%) 

Above Threshold 
Under Threshold 

</table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">K.He et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Stability selection for genome-wide association</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H</forename>
				<surname>Alexande</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Lange</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetic Epidemiology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="722" to="728" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Final version of 2009 AJCC melanoma staging and classification</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Balch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Oncol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="6199" to="6206" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: a practical and powerful approach to multiple testing</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Benjamini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Hochberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Neural Networks for Pattern Recognition</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Clarendon Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">E</forename>
				<surname>Boser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory</title>
		<meeting>the Fifth Annual ACM Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Classification and Regression Trees</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<pubPlace>Wadsworth, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Statistics for High-Dimensional Data: Methods, Theory and Applications</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bü Hlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Van De Geer</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Boosting with the L2 loss: regression and classification</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bü Hlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="324" to="339" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Boosting for high-dimensional linear models</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bü Hlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="559" to="583" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Boosting algorithms: regularization, prediction and model fitting</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bü Hlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hothorn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="477" to="505" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Least angle regression</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="407" to="499" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Microarrays, empirical Bayes and the two groups model</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Large-Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Institute of Mathematical Statistics Monographs</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2012" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Variable selection via nonconcave penalized likelihood and its oracle properties</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="1348" to="1360" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Variable selection for Cox&apos;s proportional hazards model and frailty model</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="74" to="99" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">Manhattarn Plot for Selection Frequency (%); dashed horizontal line: estimated threshold ^ Pthresð0:2Þ ¼ 72%; vertical blue lines: selection frequencies of the four previously-detected SNPs that are associated with overall survival of CM patients by Yin et al. (2015); red vertical lines: the SNPs whose selection frequencies pass the estimated threshold; the lower panel: pairwise correlations across the 2339 SNPs with the strength of the correlation, from positive to negative</title>
		<imprint/>
	</monogr>
	<note>indicated. by the color spectrum from red to dark blue</note>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Experiments with a new boosting algorithm</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Freund</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Schapire</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: Proceedings of the Thirteenth International Conference</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffman</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Additive logistic regression: a statistical view of boosting (with discussion)</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="337" to="407" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">L1 penalized estimation in the Cox proportional hazards model</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Geoman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrical Journal</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="70" to="84" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Penalized cox regression analysis in the highdimensional and low-sample size settings with application to microarray gene expression data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gui</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3001" to="3008" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<monogr>
		<title level="m" type="main">Generalized Additive Models</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">J</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">DNA repair: exploiting the Fanconi Anemia Pathway as a potential therapeutic target</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hucl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Callmeier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiol. Res</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="453" to="465" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">A tutorial on MM algorithms</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Hunter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Lange</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Stat</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Targeting the Fanconi Anemia Pathway to identify tailored anticancer therapeutics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Jenkins</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anemia</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Upregulation of Fanconi anemia DNA repair genes in melanoma compared with non-melanoma skin cancer</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">H</forename>
				<surname>Kao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Investig. Dermatol</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="2139" to="2142" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Lange</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics</title>
		<editor>Casella,G. et al</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>2nd. edn. Springer Texts in</note>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Boosting proportional hazards models using smoothing splines, with applications to high-dimensional microarray data</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Luan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2403" to="2409" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Influence of single nucleotide polymorphisms in the MMP1 promoter region on cutaneous melanoma progression</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Melanoma Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="169" to="75" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<monogr>
		<title level="m" type="main">Stability selection (with discussion)</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Meinshausen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bü Hlmann</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="417" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">PLINK: a toolset for whole-genome association and population-based linkage analysis</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Purcell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="559" to="575" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Melanoma risk loci as determinants of melanoma recurrence and survival</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Rendleman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Transl. Med</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">The state of boosting</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Ridgeway</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Stat</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="172" to="181" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Melanoma prognosis: a REMARKbased systematic review and bioinformatic analysis of immunohistochemical and gene microarray studies</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">J</forename>
				<surname>Schramm</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Cancer Therap</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1520" to="1528" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Regularization paths for Cox&apos;s proportional hazards model via coordinate descent</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Simon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">The positive false discovery rate: a Bayesian interpretation and the q-value</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Storey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2013" to="2035" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Exome sequencing identifies rare deleterious mutations in DNA repair genes FANCC and BLM as potential breast cancer susceptibility alleles</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Thompson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Genet</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1002894</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">The lasso method for variable selection in the Cox model</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Med</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="385" to="395" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Significance analysis of microarrays applied to the ionizing radiation response</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">G</forename>
				<surname>Tusher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA, 98</title>
		<meeting>. Natl. Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="5116" to="5121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Genetic variants in Fanconi Anemia pathway genes BRCA2 and FANCA predict Melanoma survival</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Investig. Dermatol</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="542" to="550" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<monogr>
		<title level="m" type="main">Principled sure independence screening for Cox models with ultra-high-dimensional covariates. manuscript</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">S</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<monogr>
		<title level="m" type="main">Component-wise gradient boosting and false discovery control</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>