
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graphical model for joint segmentation and tracking of multiple dividing cells</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Martin</forename>
								<surname>Schiegg</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Heidelberg</orgName>
								<orgName type="institution" key="instit2">IWR/HCI</orgName>
								<address>
									<postCode>69115</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Philipp</forename>
								<surname>Hanslovsky</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Heidelberg</orgName>
								<orgName type="institution" key="instit2">IWR/HCI</orgName>
								<address>
									<postCode>69115</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Carsten</forename>
								<surname>Haubold</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Heidelberg</orgName>
								<orgName type="institution" key="instit2">IWR/HCI</orgName>
								<address>
									<postCode>69115</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ullrich</forename>
								<surname>Koethe</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Heidelberg</orgName>
								<orgName type="institution" key="instit2">IWR/HCI</orgName>
								<address>
									<postCode>69115</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Lars</forename>
								<surname>Hufnagel</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">European Molecular Biology Laboratory (EMBL)</orgName>
								<orgName type="laboratory" key="lab2">Cell Biology and Biophysics Unit</orgName>
								<address>
									<postCode>69117</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Fred</forename>
								<forename type="middle">A</forename>
								<surname>Hamprecht</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Heidelberg</orgName>
								<orgName type="institution" key="instit2">IWR/HCI</orgName>
								<address>
									<postCode>69115</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graphical model for joint segmentation and tracking of multiple dividing cells</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu764</idno>
					<note type="submission">Received on August 11, 2014; revised on October 14, 2014; accepted on November 12, 2014</note>
					<note>Bioimage informatics *To whom correspondence should be addressed. † The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors. Associate Editor: Jonathan Wren Supplementary information: Supplementary material is available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: To gain fundamental insight into the development of embryos, biologists seek to understand the fate of each and every embryonic cell. For the generation of cell tracks in embryo-genesis, so-called tracking-by-assignment methods are flexible approaches. However, as every two-stage approach, they suffer from irrevocable errors propagated from the first stage to the second stage, here from segmentation to tracking. It is therefore desirable to model segmentation and tracking in a joint holistic assignment framework allowing the two stages to maximally benefit from each other. Results: We propose a probabilistic graphical model, which both automatically selects the best segments from a time series of oversegmented images/volumes and links them across time. This is realized by introducing intra-frame and inter-frame constraints between conflicting segmentation and tracking hypotheses while at the same time allowing for cell division. We show the efficiency of our algorithm on a challenging 3Dþt cell tracking dataset from Drosophila embryogenesis and on a 2Dþt dataset of proliferating cells in a dense population with frequent overlaps. On the latter, we achieve results significantly better than state-of-the-art tracking methods. Availability and implementation: Source code and the 3Dþt Drosophila dataset along with our manual annotations will be freely available on http://hci.iwr.uni-heidelberg.de/MIP/Research/ tracking/</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Fueled by new microscopic techniques (e.g.<ref type="bibr" target="#b17">Krzic et al., 2012;</ref><ref type="bibr">Tomer et al., 2012</ref>), which allow to record in vivo multidimensional images in high spatial and temporal resolution, and by robotic high-throughput setups, biology is developing a great hunger for robust and accurate automated cell tracking (<ref type="bibr">Gonzá lez et al., 2013;</ref><ref type="bibr" target="#b14">Kanade et al., 2011;</ref><ref type="bibr">Maška et al., 2014;</ref><ref type="bibr">Meijering et al., 2009</ref><ref type="bibr">Meijering et al., , 2012</ref>). As an example, one major goal in developmental biology is the digitization of embryogenesis and its computational analysis, where cell tracking plays an important role. Great advances in this field have been reported most recently (), and one key feature in their study is that they do not strictly separate the cell detection and segmentation stage from the cell tracking stage (For brevity, we mostly refer to the combination of detection and segmentation as detection only).instead propagate the cell centroids and their approximated Gaussian shape fromthe past timesteps to the next while detecting cell divisions at the same time. Despite handling detection and tracking separately, tracking-by-assignment algorithms (<ref type="bibr" target="#b4">Bise et al., 2011;</ref><ref type="bibr" target="#b15">Kausler et al., 2012;</ref><ref type="bibr">Padfield et al., 2011;</ref>), on the other hand, have proven to be most flexible in terms of modeling power when injecting prior knowledge: biological laws can be modeled as constraints (see Section 3.2) and prior beliefs about individual detections and assignments may be incorporated by utilizing local classifiers trained on a small subset of the data (see Section 3.3) rather than using heuristic rules. Furthermore, tracking-by-assignment models allow for global optimization, which will further improve accuracy, as the assignment problems are solved in a larger temporal context. Nevertheless, this modeling power in tracking-by-assignment approaches comes at the cost of propagating errors from the first stage (segmentation) to the second (tracking) and insight from the second stage cannot be used to lift ambiguities arising in the first stage. In other words, the tracking result is highly dependent on the detection/segmentation quality, and the overall achievable quality is limited by the lack of interaction between detection and assignment decisions. Our work aims at solving this particular problem by introducing a method for joint segmentation and tracking in one graphical model. Instead of a single fixed segmentation as used in previous tracking-by-assignment models, the detection phase generates superpixels/-voxels from which regions (possible cell segmentations) are extracted as sets of the original superpixels. In particular, these regions can be understood as a selection of possible segmentation hypotheses. Global temporal and spatial information guides the selection of those hypotheses that best fit the overall tracking. During inference, each superpixel is assigned either a cell track identifier or the identifier of the background (cf.<ref type="figure" target="#fig_0">Fig. 1</ref>). Put another way, our algorithm simultaneously produces both a valid cell segmentation and an assignment of each cell to its cell lineage. Our main contribution is the formulation of a probabilistic graphical model for joint segmentation and tracking for divisible and almost indistinguishable cells. This undirected graphical model incorporates prior beliefs from multiple local classifiers and guarantees consistency in time and space. We also present a method to generate an oversegmentation, which respects the borders between cells and generates an overcomplete set of superpixels even for cells in dense populations. Furthermore, the 3Dþt Drosophila dataset we use for evaluation and our dense manual annotations are provided on our website. This is the first dataset of this size and kind for which manual annotations are freely available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Joint detection and tracking</head><p>Joint object detection and tracking is handled naturally in tracking algorithms based on active contours (<ref type="bibr">Xiong et al., 2006</ref>), space-time segmentation (<ref type="bibr" target="#b19">Lezama et al., 2011</ref>) or video segmentation of multiple objects (<ref type="bibr" target="#b8">Budvytis et al., 2011;</ref><ref type="bibr">Vazquez-Reina et al., 2010</ref>). However, these methods either cannot deal naturally with divisible objects and heuristics must be used or they cannot cope with dense object populations where objects may overlap. In a very recent study,present a fast pipeline to simultaneously segment and track cells by propagating Gaussian mixture models through time, but again heuristic rules remain to detect cell divisions. Furthermore, optical flow has been extended to jointly deal with segmentation and tracking (<ref type="bibr" target="#b0">Amat et al., 2013</ref>). These authors propose to augment an optical flow algorithm by a regularization term based on similarities of neighboring superpixels modeled in a Markov random field. In tracking-by-assignment models, however, joint optimization of segmentation and tracking is only rarely tackled. Instead, to reduce errors in the final results, errors are minimized in each step of the two-stage tracking-by-assignment separately, the segmentation step and the tracking step: for the former, specialized segmentation approaches for the detection of overlapping objects have been developed (<ref type="bibr" target="#b3">Arteta et al., 2013;</ref><ref type="bibr" target="#b20">Lou et al., 2012;</ref><ref type="bibr">Park et al., 2013</ref>). These approaches aim to find most accurate segmentations; however, they do not incorporate any time information. To reduce errors in the tracking step, probabilistic tracking-by-assignment methods for dividing objects have been proposed (<ref type="bibr" target="#b4">Bise et al., 2011;</ref><ref type="bibr" target="#b15">Kausler et al., 2012</ref>), which associate a random variable with each detected object to make allowance for false-positive detections. This idea has recently been extended byto further correct for undersegmentation errors by introducing conservation constraints between timesteps to guarantee a consistent number of objects contained in each detected region. In a postprocessing step, they correct the original segmentations. Our idea goes one step further and aims to avoid segmentation errors already in the first place by jointly optimizing segmentation (i.e. selection of foreground superpixels) and tracking. Most similar to our proposed method are the models in<ref type="bibr" target="#b9">Funke et al. (2012</ref><ref type="bibr" target="#b11">), Hofmann et al. (2013</ref><ref type="bibr" target="#b13">) and Jug et al. (2014</ref><ref type="bibr" target="#b9">). Funke et al. (2012</ref>propose an algorithm, which segments an anisotropic 3D volume of branching neurons by generating segmentation hypotheses in 2D slices separately and posing constraints between overlapping segmentation hypotheses. In contrast to our model, the authors do not need to model background for their specific use-case, whereas in our domain, it is important to infer both whether a segment should be activated as foreground and to which segments in the consecutive timesteps it should be linked. Moreover, they do not model detection variables directly but introduce additional transition variables, which model appearance, disappearance and divisions. This is in contrast to our model, where the detection variables allow to model a prior on the count of cells in sets of) is oversegmented into superpixels (middle row). Our graphical model then tracks the cells over time and assigns each segment to a track (indicated by the same random color) or background (black). Offspring cells are assigned the color of their parent cell after mitosis (here: orange). Note that one cell may be represented by multiple superpixels. Scale bars are 10 lm regions. The authors in<ref type="bibr" target="#b11">Hofmann et al. (2013)</ref>propose a similar idea for joint tracking and object reconstruction from multiple cameras. Both methods have in common that they solve an integer linear program with a large set of hard constraints between superpixels within one (time/z-slice) instance and across instances. In independent work,<ref type="bibr" target="#b13">Jug et al. (2014)</ref>jointly segment and track bacteria in 1Dþt. The original idea to refine a segmentation by modeling the conflicts between multiple overlapping segmentation hypotheses was introduced by Brendel and Todorovic (2010) and Ion et al. (2011). Although Brendel et al. propose algorithms to efficiently find the best independent sets in a conflict graph, Ion et al. present a complementary approach to search for maximum cliques in the graph of possible hypotheses (where contradicting tiles are not connected). Their ideas were extended to the temporal domain in<ref type="bibr" target="#b7">Brendel et al. (2011)</ref>, but they cannot deal with dividing objects. Extending this idea to dividing cells is a much harder problem and the main contribution of our article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>The purpose of this work is to segment and track multiple dividing cells in a tracking-by-assignment framework. To avoid errorpropagation from the segmentation to the tracking stage, we propose to jointly segment and track the targets based on an oversegmentation. This process is illustrated in<ref type="figure">Figure 2</ref>: we first run an oversegmentation algorithm on the volumes with overlapping cells to generate multiple segmentation hypotheses. This is followed by the construction of a graphical model for the joint segmentation and tracking. It models competing (intra-frame) relations between the potential cell segmentations, which overlap in space, as well as possible inter-frame hypotheses between regions of adjacent timesteps. In this section, we specify each step of this pipeline consecutively, starting with the oversegmentation step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Competing segmentation hypotheses</head><p>To make joint segmentation and tracking computationally feasible in tracking-by-assignment approaches, the time series of 2D/3D images/volumes must be coarse grained into superpixels/-voxels to reduce the problem space (stages II and III in<ref type="figure">Fig. 2</ref>). Note that the resulting superpixels also afford the extraction of more expressive features at the object rather than the pixel level. To this end, first superpixels are obtained, which are as large as possible but at the same time small enough to respect all cell boundaries. Next, neighboring superpixels are grouped to generate different segmentation hypotheses. Here, we choose to merge the superpixels in a hierarchical fashion. However, the proposed model does not rely on or exploit the resulting tree structure, so any other means of generating complementary but conflicting segmentations could be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Oversegmentation</head><p>In stage II, the purpose is to obtain an oversegmentation on every image, which is sufficiently fine but as coarse as possible. That is, we prefer single segments (superpixels) for (isolated) objects without ambiguities, whereas multiple (smaller) segments are desired in cases where objects overlap in space. To this end, we propose the following oversegmentation algorithm: 1. Obtain a coarse segmentation, which only distinguishes potential foreground from definite background (high sensitivity and low specificity). 2. Automatically select seeds fulfilling the requirements outlined above. 3. Compute the seeded watershed on the foreground mask. 4. Merge resulting segments hierarchically to potential regions.</p><p>Here, the first step may be performed by any segmentation algorithm which can be adjusted in a way that only those pixels are predicted as background where we are sufficiently certain. This step's output is either a hard segmentation or a probability map of the foreground (soft segmentation). Note that typically, it is not desirable to track the resulting connected components directly, because large clusters of cells may be contained in each connected component. Hence, we continue by splitting these connected components into multiple segments. To this end, the watershed algorithm is applied on the probability map of the potential foreground (the foreground mask is obtained by truncating probabilities below a chosen threshold; we choose 0.5). The seeds for the watershed algorithm<ref type="figure">Fig. 2</ref>. First, the raw data are oversegmented in all timesteps separately (stage II). Then, in stage III, segmentation hypotheses are generated by merging adjacent segments into bigger segments (e.g. 2, 3 may be merged into 23). From this structure, a graphical model is constructed (stage IV): overlapping segmentation hypotheses are connected by intra-frame conflicts (black: conflicting segmentation hypotheses; blue: local evidence for the number of cells in one connected component) and inter-timestep transition hypotheses are modeled by binary random variables (yellow nodes) indicating whether the corresponding cell in t has moved to, divided to or is not associated with the corresponding cell in t þ 1. Note that, for simplicity, only one connected component in only two timesteps is visualized. The proposed factor graph in stage IV, in fact, models all detections and all timesteps in one holistic model at once. Also for simplicity, only a small subset of transition variables is shown. After running inference on this factor graph, the most probable selection of active regions (actual cells) and their transitions between timesteps are found as visualized by the two cells marked in yellow and blue in stage IV are the local maxima of the distance transform on the foreground mask. This gives rise to regularly shaped compact segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Region merging</head><p>Finally, superpixels are grouped into regions, which form possibly competing cell segmentations (stage III in<ref type="figure">Fig. 2</ref>). These segmentation candidates can be generated in very different ways. For simplicity, we choose a hierarchical region merging in a region adjacency graph using L tree levels. Its edge weights between neighboring segments/regions may be arbitrarily complex, and the regions may be merged in an order determined by these edge weights. Because the segmentation hypotheses are composed from the same superpixels, natural conflicts between these regions exist and are resolved by our graphical model (stage IV in<ref type="figure">Fig. 2</ref>) as discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graphical model for joint segmentation and tracking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Overview</head><p>Based on the oversegmentation described in Section 3.1, a graphical model [here: a factor graph (<ref type="bibr" target="#b18">Kschischang et al., 2001</ref>)] is constructed whose factors collect evidence from local classifiers and, at the same time, guarantee consistency due to linear constraints. That is, impossible configurations are disallowed, e.g. a cell dividing into more than two children. Building the graphical model corresponds to stage IV in<ref type="figure">Figure 2</ref>. The construction of the factor graph and the meaning of contained factors and random variables are described in detail in this section. We will refer to the toy example depicted in<ref type="figure">Figure 2</ref>as a running example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Random variables</head><p>To build the factor graph for joint segmentation and trackings, we first introduce two types of binary random variables, detection variables and transition variables. In particular, each possible cell segmentation (region) gets assigned a detection variable X t ia 2 f0; 1g, where i is the connected component containing the region, a is the identifier of the region and t is the timestep. Secondly, variables Y t ia;jb 2 f0; 1g for each possible inter-frame transition between two regions in adjacent timesteps are added. In our illustrative example in<ref type="figure">Figure 2</ref>, one detection variable is X tþ1 f45gf4g , referring to region 4 in the connected component formed by regions 4 and 5 at time t þ 1. Y t f123gf23g;f45gf4g is an exemplary inter-frame transition variable, where the indices mean that region 23 in connected component 123 at time t may be associated with region 4 in connected component 45 at time t þ 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Factors</head><p>We continue the construction of our graphical model by adding factors. Factors may disallow specific configurations (see paragraph constraints) and score possible configurations of their associated variables based on estimated posterior probabilities ^ P that are here determined by probabilistic classifiers using local evidence f t ia. In the following, intra-frame factors (detection and count factors) and inter-frame factors (outgoing and incoming factors) are described. Obviously, all regions in each path from a leaf node to the root node in the region merging graph (see stage III of<ref type="figure">Fig. 2</ref>) form competing segmentation hypotheses and are represented by a conflict set C t k each of which contains indices of such conflicting regions. For each such conflict set C t k , a higher order detection factor w det is added in the graphical model with the energy.</p><formula>E det ðX t k ; F t k Þ ¼ Àw det log ^ P f t ia X t ia ¼ 1 À Á ; X t ia ¼ 1 Àw det max X t ia 2X t k log ^ P f t ia X t ia ¼ 0 À Á þ c bias ; X t ia ¼ 0 8X t ia 2 X t k ; 8 &gt; &gt; &gt; &lt; &gt; &gt; &gt; :</formula><formula>(1) where X t k ¼ fX t ij g j2C t k and F t k ¼ ff t ij g j2C t k</formula><p>are the detection variables (and their corresponding features) of regions contained in conflict set C t k and w det weighs the detection factor against other factors. A factor wðXÞ can be obtained from the given energy E(X) by the following transformation: wðXÞ ¼ exp ÀEðXÞ ð Þ. For the sake of brevity, we will only describe the energies in the remainder of the article. Equation</p><p>(1) translates to the following: a prior probability P f t ia X t ia ¼ 1 À Á obtained from a pre-trained local classifier (see Section 3.3 for details) with features f t ia is transformed into an energy for the configuration where exactly one X t ia is found to be a true cell. In the second case, none of the regions in the conflict set is a true cell, a penalty has to be paid based on the classifier's belief of each of the regions being false-positive detections. The model parameter c bias can put a bias on regions to be activated rather than deactivated in case of doubt. Note that impossible configurations, such as the selection of more than one competing region, are forbidden by constraint C 1 , see Section 3.2.4. In<ref type="figure">Figure 2</ref>, the potential w det ideally obtains a high energy (i.e. low probability) for the single region 2, whereas region {23} has a low energy as it better represents an entire cell. Moreover, to further leverage local evidence, a higher-order</p><formula>count factor E count ðfX t i gÞ ¼ Àw count log ^ P count X X2fX t i g X ¼ k 0 @ 1 A 0 @ 1 A ; (2)</formula><p>where fX t i g denotes the detection variables for all regions belonging to connected component i at time t. It injects prior beliefs for each connected component i to contain k actual cells. To this end, a probabilistic count classifier (see Section 3.3) is trained using features such as total intensity or size and applied on connected components. For instance, two active regions are favored for connected component {123}. The factors above are both associated with variables from single timesteps only. To achieve temporal associations of cells across timesteps, the model has to be extended by inter-frame factors, which connect detection with transition variables. Firstly, outgoing factors with energy</p><formula>E out ðX t ia ; Y t ia! Þ ¼ E dis ðX t ia ; Y t ia! Þ þ E move ðX t ia ; Y t ia! Þ þ E div ðX t ia ; Y t ia! Þ (3)</formula><p>associate each variable X t ia with all possible transitions Y t ia! to variables in the successive timestep. This factor is decomposed into three energy terms: disappearance (penalizing the termination of a track), cell division (allowing for cell division, based on estimated division probabilities by a local division classifier) and cell migration (simple association between two cells of consecutive timesteps, based on a local transition classifier). The second inter-frame factor, the incoming factor, assigns a cost in case a cell appears, i.e. X tþ1 jb is one, but all of the transition variables in Y tþ1 !jb are zero. Details for the inter-frame factors are provided in the Supplementary Material. Omitted in these factors so far are impossible configurations, such as more than one ancestor or more than two descendants for one cell. These configurations are prohibited by adding the following constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Joint cell segmentation and tracking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Constraints</head><p>We add linear constraints to guarantee that only feasible configurations are part of a solution. Constraints within individual timesteps will be referred to as intra-frame constraints, whereas inter-frame constraints regularize the interaction of detection with transition variables. The constraints are summarized in<ref type="figure" target="#tab_1">Table 1</ref>and explained in the following. Because overlapping—and hence conflicting—regions are contained in the segmentation hypotheses, constraints need to restrict the space of feasible solutions to non-contradicting solutions. For this purpose, conflicting hypotheses are subsumed into conflict sets C t k. (Red factors and their associated detection variables in<ref type="figure" target="#fig_1">Fig. 3.</ref>) Constraint C 1 in<ref type="figure" target="#tab_1">Table 1</ref>ensures that at most one detection variable is active in each conflict set. Taking conflict set C ¼ ff123g; f23g; f3gg in<ref type="figure" target="#fig_1">Figure 3</ref>as an example, the constraint states:</p><formula>X t f123gf3g þ X t f123gf23g þ X t f123gf123g 1.</formula><p>Those intra-frame constraints added outgoing and incoming constraints model inter-frame interactions and couple detection variables with transition variables. These constraints (C 2 and C 4 in<ref type="figure" target="#tab_1">Table 1</ref>) ensure compatibility of detection and assignment variables: no transition variable may be active if the corresponding detection variable has state zero. In terms of the factor graph in<ref type="figure" target="#fig_1">Figure 3</ref>, this means that, e.g. Y t f123gf23g;f5gf45g X t f123gf23g. In a similar fashion, constraints C 3 and C 5 in<ref type="figure" target="#tab_1">Table 1</ref>enforce compliance with the tracking requirement that a cell can have at most two descendants and one ancestor, respectively. A feasible tracking solution must fulfill all constraints C 1 –C 5. It should be noted that only C 3 needs to be adjusted appropriately if non-divisible objects are to be tracked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Inference</head><p>In our global graphical model, the total energy</p><formula>EðX ; YÞ ¼ X t X i X k E det X t k À Á þ E count fX t i g À Á þ X a E out ðX t ia ; Y t ia! Þ þ E in ðX t ia ; Y tÀ1 !ia Þ À Á (4)</formula><p>subject to all constraints in<ref type="figure" target="#tab_1">Table 1</ref>; is the sum of all factors over all possible variable configurations of detection variables X and transition variables Y. It should be noted that X and Y contain all random variables of all timesteps taking all information available into account in one holistic graphical model. The probability for a configuration X; Y is then given by the Gibbs distribution PðX ; YÞ / e ÀEðX ;YÞ and the optimal tracking corresponds to its MAP solution. We solve the energy minimization problem to global optimality by solving the corresponding integer linear program. After inference, the optimal configuration of the factor graph can be interpreted as a segmentation and tracking result as illustrated in stage IV in<ref type="figure">Figure 2</ref>. The graphical model assigns a track identifier to each foreground superpixel and sets segment values to zero, which are inferred to be background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Local classifiers</head><p>The factors of the graphical model introduced in Section 3.2 are based on the predictions of local classifiers for 1. the number of cells in a connected component: the count classifier is trained based on the appearance (e.g. the size, intensity and radius) of a connected component and predicts the number of cells that are contained within. The predictions are then injected into the count factors in Equation (2) as prior belief for the number of cells contained in a connected component. 2. true detections: the detection classifier estimates how strongly a region resembles a cell [cf. Equation</p><p>(1)]. 3. cell divisions: the division classifier rates the probability of triples of regions, ancestor and two children from consecutive frames, to represent a division. 4. cell migration (moves): the move classifier rates every pair of regions associated with a transition variable.</p><p>In our implementation, we train random forest classifiers, but any classifier which provides (pseudo-)probabilistic predictions can be used. These classifiers are trained on user annotated training examples. We refer the reader to the Supplementary Material for detailed specifications and features used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Implementation details</head><p>In this cell tracking application, we use the following methods and parameters for the oversegmentation algorithm sketched in Section 3.1. To obtain a coarse foreground mask, we use the segmentation toolkit ilastik (<ref type="bibr">Sommer et al., 2011</ref>), which can segment both the phase-contrast images from the Rat stem cells dataset and the stained cell nuclei from the Drosophila dataset: here, prediction maps for each timestep are computed independently using a pixelwise random forest trained on few training examples from the respective dataset. We use 100 trees in every experiment and select the following features at different scales: Gaussian smoothing, Gaussian Gradient Magnitude, Difference of Gaussians, Structure Tensor Eigenvalues and Hessian of Gaussian Eigenvalues. Then, the seeds are determined by the local maxima of the distance transform on the slightly smoothed foreground mask (Gaussian smoothing with r ¼ 0:3 and r ¼ 1:0 in the case of Drosophila and Rat stem cells, respectively) and nearby seeds are pruned by dilating with a disc/ball of radius 2 pixels. Resulting segments are merged hierarchically with edge weights determined by the ratio of the length of their common border and the perimeter of the smaller region. Although much more expressive weights could be used here, we find that these simple features already perform well. Then, at every level l 2 f0; :::; Lg of the hierarchical segmentation hypotheses (we choose<ref type="figure">Figure 2</ref>. In the factor graph, detection variables for possible cell segmentations are shown in black, whereas their allowed inter-timestep transitions are modeled by random variables depicted in yellow (most of them are omitted for clarity). Blue factors give a prior probability for each connected component how many cells it may contain. By introducing intra-timestep conflict hard constraints (black factors), it is guaranteed that at most only one variable in each conflict set, e.g. C ¼ ff123g; f23g; f3gg, may be active at a time. Outgoing and incoming factors (black squares) connect inter-frame transition with detection variables and ensure a unique lineage of cells the tree depth L ¼ 4 in the 2Dþt and L ¼ 5 in the 3Dþt dataset), edge weights are ordered and the neighbors with the p% highest weights are merged iteratively. In this way, segments completely contained within other segments are merged first, whereas regions which only touch in few pixels are merged last. Here, we set p ¼ 20 for l 2 f0; :::; L À 1g and p ¼ 100 for l ¼ L to get the connected components of the foreground mask as the root node of the segmentation hypotheses trees. Our model and implementation is not limited to hierarchical segmentation hypotheses. In fact, any algorithm that generates competing segmentation hypotheses could be used. The graphical model described in Section 3.2 is implemented in Cþþ using the open-source library OpenGM (<ref type="bibr" target="#b2">Andres et al., 2012</ref>). For tractability, the number of inter-frame hypotheses is pruned to a reasonable number of candidates in the spatial proximity of each region: in particular, inter-frame hypotheses between frames t and t þ 1 are generated by finding the two nearest neighbors in t þ 1 for each region in frame t and the two nearest neighbors in t for each region in frame t þ 1. This procedure yields many inter-frame hypotheses (</p><p>) 2) in dense cell populations and only few hypotheses in the parts of the image where cells are sparse. To create training examples for the classifiers, a small subset of the raw data is selected and sparsely annotated to train a random forest (<ref type="bibr" target="#b5">Breiman, 2001</ref>) for each classifier suggested in Section 3.3. We choose 100 trees for each and train the random forests to purity. The parameters of the factor graph are then tuned to best fit a small, fully annotated subset of the data. These parameters are used for the final predictions on the entire dataset to report the performance measures. To do inference on our graphical model, we use the (integer) linear programming solver CPLEX. The globally optimal solution for the entire time sequence is found within % 10 À 70 min. We refer the reader to the Supplementary Material, Section 5, for a more detailed runtime discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head><p>We perform comparative experiments on two datasets—a cell culture (2Dþt) and a developing Drosophila embryo (3Dþt). The former is challenging due to severe mutual overlap, whereas the latter is difficult owing to its ambiguity in the segmentation hypotheses due to high cell density under low contrast. The first dataset is publicly available from Rapoport et al.</p><formula>(2011)</formula><p>(their dataset A) and consists of a time series of 209 images (1 376 Â 1 038 pixels) of about 240 000 pancreatic stem cells of a rattus norwegicus ('Rat stem cells'). This dataset is particularly challenging due to the cells changing their appearance (shape, size and intensity) over time from long elongated to round cells. Moreover, the proliferating stem cells quickly grow to a dense population causing frequent overlaps between cells. Because of the dataset's high temporal resolution, it is difficult to pinpoint a cell division to a specific point in time. Instead, mitosis occurs over multiple timesteps. For this reason, we subsample the sequence in time, processing every second image only (leaving us with 104 timesteps) and relax the evaluation criterion for divisions (see Section 4.1). We further resample the ground truth provided by (<ref type="bibr" target="#b22">Rapoport et al., 2011</ref>) to guarantee that no cell division is lost in the subsampling. The second dataset is a developing Drosophila embryo () (their dataset B). On average, about 800 cells are tracked over 100 timesteps (730 Â 320 Â 30 voxels, voxel resolution 0:5 lm).evaluate their tracking method on this dataset conditioned on a given segmentation. To evaluate the performance of our joint approach of segmentation and tracking, we extend their manual annotations such that it also covers previously missing cells and that voxels of falsely merged cells are assigned to individual cell identities (Both the dataset and our manual annotations will be made freely available.). In this way, we can further report segmentation/detection measures in addition to tracking measures unconditioned on the segmentation result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation measures</head><p>In contrast to the typical evaluation of tracking-by-assignment methods, for which an evaluation conditioned on the segmentation is sufficient to determine the efficiency of the tracking algorithm, here, both segmentation and tracking must be compared against a ground truth. To evaluate the segmentation quality, we use the Jaccard index as a similarity measure between a region r res of the result and ground truth region r gt , i.e. qðr res ; r gt Þ ¼ jrres\rgtj jrres[rgtj. The bestmatching region r Ã res ðr gt Þ ¼ arg max rres qðr gt ; r res Þ for some ground truth region r gt counts as a true-positive segmentation for that region if its Jaccard index is greater than some threshold s (we set s ¼ 0:5) [For (), we choose s ¼ 0:0 and use a dilated centroid as segment. See Supplementary Material for details.]. Unmatched ground truth/tracking result regions are considered false-negative/false-positive detections. We then compare the frame-to-frame tracking events (moves and divisions) from the ground truth to those of the tracking result. We report an unconditioned tracking result and conditioned performance measures. The former evaluates the tracking on the raw data directly, the latter is conditioned on the true segmentation hypotheses. Note that it is often not clear from the raw data, in which exact timestep a cell division is occurring. We hence allow cell divisions to be off from the ground truth by one timestep, i.e. a division is still counted as a true positive if it occurs one timestep earlier or later within the same track. Finally, based on the number of true/false positives and false negatives, precision, recall and f-measure are computed for detections, moves and divisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results for joint segmentation and tracking</head><p>To evaluate the performance of our model for joint cell segmentation and tracking, we perform experiments on the two datasetsJoint cell segmentation and trackingdescribed above. We compare with two recently proposed cell tracking algorithms: 1. A graphical model for cell tracking () (based on a given segmentation), which can correct for falsely merged cells in a post-processing step. To show that our method operates on a reasonably fine oversegmentation and that it is not enough to merely track the superpixels in this oversegmentation, we also perform experiments using the method of () but use our oversegmentation as input. To this end, we set their parameter of maximally allowed cells in a single detection to 1. In all three methods, we use the same count and division classifier, to which in our method move and detection classifiers are added. 2. A cell tracking pipeline designed to track entire embryos (). We evaluate their algorithm on both the raw data directly and our prediction maps as input. Note that this code was made for 3Dþt datasets; we refer to our Supplementary Material for further details.</p><p>In the 2Dþt dataset, we furthermore compare with the results of<ref type="bibr" target="#b22">Rapoport et al. (2011)</ref>for the quantitative results reported there.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Segmentation quality</head><p>We first investigate the quality of cell segmentations, see<ref type="figure">Table 2</ref>for results. Note that in both ours and, cell candidates may be set inactive by the graphical model. In both datasets, our method outperforms the segmentation quality ofwith an f measure of 0.97 and 0.93 compared with 0.88 and 0.87. Because our model groups superpixels into cells or deactivates them, it is not crucial in our approach whether cell candidates (or superpixels) are touching in the segmented image. In the method of, in contrast, the complexity of the model is determined by the worst case cluster size, i.e. the number of potentially merged cells. Hence, in their approach, the need for correctly segmented individual cells leads to parameter settings that in turn make for many false negatives in the segmentation. We consider it a strong advantage of our method to deal with competing segmentation hypotheses rather than repairing a fixed segmentation.<ref type="bibr">Moreover, Rapoport et al. (2011)</ref>achieve on the Rat stem cells data a recall of 0.95 (they do not report precision), whereas our method obtains a recall of 0.96 under very high precision (0.99). Note that<ref type="bibr" target="#b22">Rapoport et al. (2011)</ref>use s ¼ 0:3 (cf. Section 4.1), whereas we set s ¼ 0:5 as a stronger criterion. Amat et al. (2014) achieve similar or slightly better detection accuracies on the 3Dþt dataset, because their parametric model for cell appearance is seemingly a good fit for the 3Dþt dataset. Our nonparametric model, in contrast, fares better on the more irregular cell shapes in the 2Dþt data, where the detection accuracy of () only increases in the course of the movie, seemingly due to the following reasons: the cells adopt a Gaussian shape only after a number of frames and their model is tailored toward Gaussian shaped objects. Moreover, because of non-homogeneous illumination, initialization with the correct number of cells seems to be imperfect. Of course, these detection errors in this dataset are also mirrored when inspecting their tracking quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Tracking quality</head><p>The detection/segmentation errors usually propagate to the next stage, the tracking stage. Our model aims at avoiding such error propagation, the performance measures for the tracking quality are reported in<ref type="figure">Table 3</ref>) (f measures of 0.32 and 0.56, respectively), although using the same classifier. On the other hand, the competitive method () yields a slightly better detection rate of division events on the 3Dþt dataset. We believe that this fluctuation is due to a lack of training data for the graphical model (only 16 divisions occur in our training set), which is more critical in our approach because it has more degrees of freedom. In particular, when dealing with oversegmented objects, a strong division classifier is crucial because the introduced ambiguity may lead to increased confusion in division events. If higher division accuracies are desired, the training set needs to be expanded at the cost of more user annotations. Furthermore, the division detection accuracy our proposed model achieves is significantly better than that of (). We believe this is due to the reason that divisions are handled naturally in tracking-by-assignment approaches (compared with heuristic rules), and further evidence can be injected through local classifiers trained on this specific event. Qualitative results for the 2Dþt dataset are presented in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This work is motivated by the desire to overcome the propagation of errors from a separate segmentation phase to an independent tracking phase in a tracking-by-assignment framework. In response, we propose an undirected graphical model that couples decisions over all of space and all of time. This model simultaneously selects a<ref type="figure">Table 2</ref>. Segmentation quality after tracking (higher is better). Note that in our method, segmentation and tracking are optimized concurrently. The rat stem cells dataset contains a ground truth of 121 632 cells across all frames, whereas the Drosophila embryo data consists of 65 821 true cellsBold values represents best performance results. subset of competing segmentation hypotheses and combines these into a tracking. All of these decisions are made to interact, so as to reach the overall most likely interpretation of the data. The benefits of this approach are borne out by experimental results that are a significant improvement over the state-of-the-art. We present results on 2Dþt and 3Dþt datasets from biology that are very challenging due to, first, the division of targets due to cell mitosis; second, mutual overlap and poor signal-to-noise and third, the near-indistinguishability of cells. The model is one of significant complexity but remains solvable to global optimality in practicable runtimes of less than an hour on the large datasets used. There are several immediately relevant avenues for future work, including structured learning of the classifiers or speed-ups in runtime. The latter may be achieved by domain decomposition, which needs to guarantee consistency in overlaps. Relaxations such as dual decomposition (<ref type="bibr" target="#b16">Komodakis et al., 2007</ref>) will break the graphical model into smaller portions for each of which inference is fast while at the same time the individual components are forced to agree on the overlap. Also approximate solvers may be used to speed up inference. Furthermore, coupling the method ofwith our approach might yield significant speed-ups and high accuracy in terms of cell division detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. An excerpt of three consecutive timesteps of the Drosophila dataset (2D slices out of 3D volumes). The raw data (top row) is oversegmented into superpixels (middle row). Our graphical model then tracks the cells over time and assigns each segment to a track (indicated by the same random color) or background (black). Offspring cells are assigned the color of their parent cell after mitosis (here: orange). Note that one cell may be represented by multiple superpixels. Scale bars are 10 lm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.3.</head><figDesc>Fig. 3. Close-up on stage IV from Figure 2. In the factor graph, detection variables for possible cell segmentations are shown in black, whereas their allowed inter-timestep transitions are modeled by random variables depicted in yellow (most of them are omitted for clarity). Blue factors give a prior probability for each connected component how many cells it may contain. By introducing intra-timestep conflict hard constraints (black factors), it is guaranteed that at most only one variable in each conflict set, e.g. C ¼ ff123g; f23g; f3gg, may be active at a time. Outgoing and incoming factors (black squares) connect inter-frame transition with detection variables and ensure a unique lineage of cells</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>. On both datasets, the proposed method is on par with Schiegg et al. (2013) and Amat et al. (2014) in terms of (frame-to-frame) move events. For the division events, we show through the f measures of 0.70 (unconditioned) and 0.84 (conditioned) that our method can deal with mitosis in the challenging 2Dþt dataset slightly better than Rapoport et al. (2011) (f measure of 0.67) and improves significantly upon (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Dataset Segmentation Method Precision Recall f measure Rat stem cells (2Dþt) (Rapoport et al., 2011) Rapoport et al. (2011) 0.95 Schiegg et al. (2013) with their segmentation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Maška,M.</head><figDesc>et al. (2014) A benchmark for comparison of cell tracking algorithms. Bioinformatics, 30, 1609–1617. Meijering,E. et al. (2009) Tracking in cell and developmental biology. In: Seminars in Cell &amp; Developmental Biology. Vol. 20. Elsevier, pp. 894–902. Meijering,E. et al. (2012) Methods for cell and particle tracking. Methods Enzymol., 504, 183–200. Padfield,D. et al. (2011) Coupled minimum-cost flow cell tracking for highthroughput quantitative analysis. Med. Image Anal., 15, 650–668. Park,C. et al. (2013) Segmentation, inference and classification of partially overlapping nanoparticles. IEEE Trans. Pattern Anal. Mach. Intell., 35. Rapoport,D.H. et al. (2011) A novel validation algorithm allows for automated cell tracking and the extraction of biologically meaningful parameters. PLoS One, 6, e27315. Schiegg,M. et al. (2013) Conservation tracking. In: ICCV, pp. 2928–2935. Sommer,C. et al. (2011) Ilastik: interactive learning and segmentation toolkit. In: ISBI, pp. 230–233. Tomer,R. et al. (2012) Quantitative high-speed imaging of entire developing embryos with simultaneous multiview light-sheet microscopy. Nat. Methods, 9, 755–763. Vazquez-Reina,A. et al. (2010) Multiple hypothesis video segmentation from superpixel flows. In: ECCV. Vol. 6315, Springer, Berlin-Heidelberg, pp. 268–281. Xiong,G. et al. (2006) Dynamical Gaussian mixture model for tracking elliptical living objects. Pattern Recognit. Lett., 27, 838–842.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 948 Bioinformatics, 31(6), 2015, 948–956 doi: 10.1093/bioinformatics/btu764 Advance Access Publication Date: 17 November 2014 Original Paper</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Linear constraints for random variables</figDesc><table>Constraint name 
Description 
Linear formulation 
ID 

Intra-frame segmentation 
conflicts 

Conflicting (i.e. overlapping) regions may not be active 
at the same time. 

P t 
j2C X t 
ij 1 
C 1 
8C 2 fC t 
k g k;t 
Inter-frame 
Couple detection outgoing 
Inter-frame hypotheses may not be active when the cor-
responding detection variable is inactive. 

Y t 
ia;jb X t 
ia 8j; b 
C 2 

Descendants outgoing 
A region may not have more than two descendants. 
P 
j;b Y t 
ia;jb 2 8i; a 
C 3 
Couple detection incoming 
Inter-frame hypotheses may not be active when the cor-
responding intra-frame hypotheses are inactive. 

Y t 
ia;jb X tþ1 
jb 8i; a 
C 4 

Ancestors incoming 
A region may not have more than one ancestor. 
P 
i;a Y t 
ia;jb 1 8j; b 
C 5 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">M.Schiegg et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Christoph Klein (University of Heidelberg) for his assistance in manual tracking annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was partially supported by the Heidelberg University Cluster of Excellence Cell Networks<ref type="bibr">[grant number EXC81]</ref>and the HGS Mathcomp<ref type="bibr">[</ref></p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast and robust optical flow for time-lapse microscopy using super-voxels</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Amat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="373" to="380" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast, accurate reconstruction of cell lineages from largescale fluorescence microscopy data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Amat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="951" to="958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">OpenGM: a Cþþ library for discrete graphical models</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Andres</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012-12-11" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to detect partially overlapping instances</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Arteta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: CVPR</title>
		<imprint>
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="3230" to="3237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Reliable cell tracking by global data association</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Bise</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ISBI. pp</title>
		<imprint>
			<biblScope unit="page" from="1004" to="1010" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Random forests. Machine Learn</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Segmentation as maximum-weight independent set</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Brendel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Todorovic</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="307" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Multiobject tracking as maximum-weight independent set</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Brendel</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title level="m" type="main">Semi-supervised video segmentation using tree structured graphical models</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Budvytis</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2257" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">Efficient automatic 3d-reconstruction of branching neurons from EM data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Funke</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1004" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title level="m" type="main">Automated quantification of morphodynamics for high-throughput live cell time-lapse datasets</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>González</surname>
			</persName>
		</author>
		<editor>ISBI. pp</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="664" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">Hypergraphs for joint multi-view reconstruction and multi-object tracking</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hofmann</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3650" to="3657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Image segmentation by figure-ground composition into maximal cliques</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ion</surname>
			</persName>
		</author>
		<editor>D.N.,Metaxas et al</editor>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2110" to="2117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimal joint segmentation and tracking of Escherichia coli in the mother machine</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Jug</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BAMBI-MICCAI</title>
		<imprint>
			<publisher>Springer, Switzerland</publisher>
			<biblScope unit="volume">8677</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2014" />
			<publisher>Springer, Switzerland</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Cell image analysis: algorithms, system and applications</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kanade</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Applications of Computer Vision (WACV). IEEE</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="374" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<monogr>
		<title level="m" type="main">A discrete chain graph model for 3dþ t cell tracking with high misdetection robustness</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">X</forename>
				<surname>Kausler</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="144" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">MRF optimization via dual decomposition: message-passing revisited</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Komodakis</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiview light-sheet microscope for rapid in toto imaging</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Krzic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="730" to="733" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">R</forename>
				<surname>Kschischang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="498" to="519" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Track to the future: spatio-temporal video segmentation with long-range motion cues</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lezama</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="3369" to="3376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning to segment dense cell nuclei with shape prior</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Lou</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1012" to="1018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Reported are precision, recall and f measure for (frame-to-frame) events move (i.e. transition assignments) and cell divisions (i.e. mitosis) Rat stem cells comprises 119 266 and 1998 such events, respectively, whereas Drosophila embryo includes 63 548 moves and 226 divisions. Results are shown for the tracking being conditioned on its segmentation result and directly compared with ground truth (unconditioned) Dataset Unconditioned Conditioned on segmentation Method Moves Divisions Moves Divisions</title>
	</analytic>
	<monogr>
		<title level="m">Table 3. Quantitative results for cell tracking</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName>
				<surname>Rapoport</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prec. Rec. f measure Prec. Rec. f measure Prec. Rec. f measure Prec. Rec. f measure Rat stem cells (2Dþt) (Rapoport et al</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">2013) with their segmentation 0</title>
		<author>
			<persName>
				<surname>Schiegg</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Schiegg</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Amat</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">on our prediction maps 0</title>
		<author>
			<persName>
				<surname>Amat</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<monogr>
		<title level="m" type="main">2013) with their segmentation 0</title>
		<author>
			<persName>
				<surname>Drosophila Embryoschiegg</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>3Dþt</note>
</biblStruct>

<biblStruct   xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Schiegg</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Amat</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<monogr>
		<title level="m" type="main">on our prediction maps 0</title>
		<author>
			<persName>
				<surname>Amat</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<monogr>
		<title level="m" type="main">Bold values represents best performance results</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title level="m" type="main">Joint cell segmentation and tracking</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>