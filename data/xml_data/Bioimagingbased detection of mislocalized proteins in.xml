
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimaging-based detection of mislocalized proteins in human cancers by semi-supervised learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Ying-Ying</forename>
								<surname>Xu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Image Processing and Pattern Recognition</orgName>
								<orgName type="department" key="dep2">Ministry of Education of China</orgName>
								<orgName type="laboratory">and Key Laboratory of System Control and Information Processing</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Fan</forename>
								<surname>Yang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Image Processing and Pattern Recognition</orgName>
								<orgName type="department" key="dep2">Ministry of Education of China</orgName>
								<orgName type="laboratory">and Key Laboratory of System Control and Information Processing</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yang</forename>
								<surname>Zhang</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computational Medicine and Bioinformatics</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Hong-Bin</forename>
								<surname>Shen</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Image Processing and Pattern Recognition</orgName>
								<orgName type="department" key="dep2">Ministry of Education of China</orgName>
								<orgName type="laboratory">and Key Laboratory of System Control and Information Processing</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<postCode>200240</postCode>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computational Medicine and Bioinformatics</orgName>
								<orgName type="institution">University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimaging-based detection of mislocalized proteins in human cancers by semi-supervised learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu772</idno>
					<note type="submission">Received on June 30, 2014; revised on November 10, 2014; accepted on November 15, 2014</note>
					<note>Bioimage informatics *To whom correspondence should be addressed. Associate Editor: Robert F. Murphy Availability and implementation: The data and code are available at: www.csbio.sjtu.edu.cn/bioinf/ SemiBiomarker/. Contact: hbshen@sjtu.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: There is a long-term interest in the challenging task of finding translocated and mislo-cated cancer biomarker proteins. Bioimages of subcellular protein distribution are new data sources which have attracted much attention in recent years because of their intuitive and detailed descriptions of protein distribution. However, automated methods in large-scale biomarker screening suffer significantly from the lack of subcellular location annotations for bioimages from cancer tissues. The transfer prediction idea of applying models trained on normal tissue proteins to predict the subcellular locations of cancerous ones is arbitrary because the protein distribution patterns may differ in normal and cancerous states. Results: We developed a new semi-supervised protocol that can use unlabeled cancer protein data in model construction by an iterative and incremental training strategy. Our approach enables us to selectively use the low-quality images in normal states to expand the training sample space and provides a general way for dealing with the small size of annotated images used together with large unannotated ones. Experiments demonstrate that the new semi-supervised protocol can result in improved accuracy and sensitivity of subcellular location difference detection.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowing the subcellular locations of proteins in human cancer tissues can improve the understanding of protein functions and cancer pathogenesis (<ref type="bibr" target="#b16">Chou and Shen, 2008;</ref><ref type="bibr" target="#b39">Pierleoni et al., 2006</ref>). It has been demonstrated that the translocation of protein might be a signal of cancer (<ref type="bibr" target="#b24">Hanash et al., 2008;</ref><ref type="bibr" target="#b25">Hung and Link, 2011</ref>). The cyclin D1 protein is an example: it shuttles between the nucleus and cytoplasm in a healthy cell and the reduction of exportation from the nucleus can lead to overexpression in the nucleus and the inactivation of the tumor-suppressing protein retinoblastoma (<ref type="bibr">Benzeno et al., 2006;</ref><ref type="bibr" target="#b20">Gladden and Diehl, 2005</ref>). Accurately detecting protein translocations in human cancer tissues can thus be of important help for clinical diagnosis and treatment. Because traditional wet lab experiments are expensive in time and costs (<ref type="bibr" target="#b19">Eliceiri et al., 2012;</ref><ref type="bibr" target="#b46">Winski et al., 2002</ref>), automated methods are highly desired for handling the increasing amounts of biomedical data. Despite its importance, only a few studies have reported automated methods to detect translocation details in cancerous tissues until now. One reason is that sequence-based analysis by itself is not V C The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com sensitive enough for detection of protein translocation as translocation can be strongly effected by mutations outside the target sequence. For example, mutations in nucleoporin complexes can have dramatic effects on the nuclear localization of multiple other proteins (<ref type="bibr" target="#b25">Hung and Link, 2011</ref>). Due to recent advances in microscopic imaging, image-based pattern analysis methods have gained popularity due to the intuitive and detailed information the images contain. For example, the Murphy group discussed the potential applications of their models based on automated analysis of fluorescence microscopy images to the analysis and classification of skin cancers (<ref type="bibr" target="#b21">Glory and Murphy, 2007;</ref><ref type="bibr" target="#b32">Murphy, 2004</ref>).<ref type="bibr" target="#b40">Rizzardi et al. (2012)</ref>compared the abilities of automated image analysis and pathologist visual examination in quantifying protein expression in ovarian cancer. Recently, our group developed a multilabel subcellular location predictor, iLocator, and identified several translocated proteins as potential cancer biomarkers (<ref type="bibr" target="#b47">Xu et al., 2013</ref>). To compare the localization difference of a protein in normal and cancerous tissues, we have to know its subcellular locations in both normal and cancerous states first. This can be achieved either through wet-lab experiments or computational predictions. Since image data with experimentally annotated subcellular locations in cancerous states are rare, prediction models have been used instead, especially in the large-scale screening. Due to the lack of location labels for proteins in cancerous states, however, most of the existing methods employed an approach named transfer learning, where models are first trained on proteins in normal tissues and then used to predict the localization of proteins in cancerous tissues (<ref type="bibr" target="#b19">Eliceiri et al., 2012;</ref><ref type="bibr" target="#b47">Xu et al., 2013</ref>). The performance of these approaches is poor, where one reason is the subtle differences in subcellular location patterns between cancer and normal states, which are influenced by cell mutations and morphological changes. In fact, there are a large number of images of proteins with cancerous tissues. The Human Protein Atlas (HPA, version 11, http:// www.proteinatlas.org/) (<ref type="bibr" target="#b45">Uhlen et al., 2010</ref>) database, for example, currently contains more than 1 million immunohistochemistry (IHC) microscopy images of proteins in cancerous tissues. But due to the lack of explicit subcellular annotations, no attempt has been made in using these images from cancerous tissues for constructing supervised models for cancer localization prediction. To address the issues, we present a heuristic semi-supervised learning framework for subcellular location prediction by taking advantage of the unannotated cancer samples in developing predictors. The key advantage of the proposed semi-supervised method, in comparison to the traditional supervised learning algorithms, is that it can train prediction models with only a few labeled image samples and a large pool of unlabeled samples (<ref type="bibr" target="#b23">Hady and Schwenker, 2013</ref>). An iterative and incremental strategy was designed to select unlabeled samples into the training set. To choose the most discriminative samples, we developed three different training modes: a single-training model consisting of only one classifier (<ref type="bibr" target="#b31">McLachlan, 1975</ref>), a co-training model consisting of two classifiers (<ref type="bibr" target="#b17">Cohen, 2002</ref>) and a tri-training model consisting of three classifiers (<ref type="bibr" target="#b48">Zhou and Li, 2005</ref>). Also, as the incorporation of prior knowledge can improve the performance of semi-supervised methods (<ref type="bibr" target="#b29">Liston and Stone, 2008</ref>), we took the location information from the corresponding normal tissues as prior knowledge to guide the selection process. Another advantage of the proposed semi-supervised framework is that the training samples become typically much more enriched compared with the traditional supervised learning. First, it selected useful lower-quality images from normal tissues for training. In general, researchers prefer using well-stained images in the training set (<ref type="bibr" target="#b37">Newberg and Murphy, 2008;</ref><ref type="bibr" target="#b47">Xu et al., 2013</ref>). But selecting only high-quality images may introduce bias into modeling because the number of high expression level images in the HPA is relatively small (<ref type="figure" target="#fig_0">Fig. 1A</ref>). Therefore, instead of being discarded, some images of normal tissues with weak expression levels were selected for use in training by the semi-supervised strategy used in this study. Then, also the large cancer dataset was used for model construction by using the semi-supervised strategy of this study, which results in a much larger dataset useable for model construction. The final predictor by the semi-supervised training can be used for images from both normal and cancer tissues. We have tested the method on an independent cancer biomarker dataset composed of translocated or mislocated proteins, which have been confirmed by biological experiments. Comparing the prediction results from models trained with and without data from cancerous tissues shows that using the cancer data improves the sensitivity of detecting protein translocations or mislocations in human cancer tissues.shows the percentages of normal protein images with different levels of expression reliability in HPA version 11. Protein images with high and medium reliability corresponding to six subcellular locations in 11 tissues were collected (Supplementary<ref type="figure" target="#tab_1">Table S1</ref>). The overlapping part of two circles represents overlap on the protein level because some proteins have different reliability levels in different tissues. For example, ornithine carbamoyltransferase is one such protein because its reliability of expression in liver is high while in the colon it is medium. The IDN is randomly selected from the nonoverlapping proteins and avoids protein overlap with the training set. The ADN and BDN are composed of the remaining images with high and medium reliability levels, respectively. Note that IDN has intersection with neither ADN nor BDN at the protein level. (B) Some examples of protein images with different reliability levels and subcellular locations. (C) Summary of all the datasets used in this study. The CDC is built by images of 348 proteins in cancerous tissues, where the 348 proteins are proteins whose images in corresponding normal tissues are of high reliability of protein expression. The IBD contains 10 proteins that were reported being translocated in human cancers by the literatures (Supplementary<ref type="figure">Table S2</ref>). In the column of expression reliability, H means high and M means medium</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets</head><p>Our image data were extracted from the HPA database, where the reliability of the annotated protein expression data is scored as high, medium, low and very low quality, depending on the consistency of the expression profile with the available literature (<ref type="bibr" target="#b45">Uhlen et al., 2010</ref>). To compromise between image quality and model generality, we used the top two categories of IHC images, i.e. high and medium reliability levels (<ref type="figure" target="#fig_0">Fig. 1</ref>). Three normal datasets with high and medium reliability levels were used, where the datasets ADN and BDN are for training and the independent dataset (IDN) is for testing. In the experiments, we evaluated different supervised and semisupervised algorithms on the IDN, which is not contained in the training set for all the training stages. It should be noted that not all of the medium quality images in the BDN dataset were used. Only those that are capable of improving model performance were selected according to our semi-supervised strategy. The cancer dataset (CDC) contains 21 920 images, which were selectively added into the training set to improve prediction performance for proteins in cancerous tissues. One hundred and forty-seven images corresponding to 10 biomarker proteins in normal and cancerous tissues were retrieved from the HPA database and composed the independent biomarker dataset (IBD) dataset. This dataset was used to validate whether the sensitivity of detecting the subcellular location difference between normal and cancer statuses is improved by incorporating the cancer data into training. All these datasets are from 11 human tissues, i.e. breast, colon, liver, lung, lymph node, ovary, pancreas, prostate, kidney, thyroid gland and urinary bladder. They involve six major cellular organelles: cytoplasm, endoplasmic reticulum, Golgi apparatus, mitochondria, nucleus and vesicles. Among all the proteins in our datasets, 26% are multilabel proteins that belong to two or three organelles simultaneously. It should be noted that the label of each protein was obtained from the annotation of its immunofluorescence (IF) images with the same antibodies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image preprocessing and feature extraction</head><p>Because each original HPA image is the fusion of DNA and protein, the linear spectral separation method was used to separate DNA and protein channels (<ref type="bibr" target="#b47">Xu et al., 2013</ref>). Then we extracted the Haralick texture features, DNA distribution features and local binary patterns (LBP) features from these two channels (<ref type="bibr" target="#b35">Nanni et al., 2010;</ref><ref type="bibr" target="#b43">Tahir et al., 2012;</ref><ref type="bibr" target="#b47">Xu et al., 2013</ref>). Each of 10 Daubechies filters can generate 836 Haralick features. They are used to create separate feature sets referred to as db1 through db10. The dimensions of DNA distribution and LBP features are 4 and 256, respectively. A feature vector of 1096 components is used to represent the image in each Daubechies filter space. Many previous studies have demonstrated that feature selection from the high-dimensional vector is useful, so we used stepwise discriminant analysis as it has been demonstrated to work well in this field (<ref type="bibr" target="#b37">Newberg and Murphy, 2008;</ref><ref type="bibr" target="#b47">Xu et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Incremental semi-supervised learning</head><p>We prepared three datasets, i.e. ADN, BDN and CDC, to construct classifiers. Among them, ADN and BDN are normal datasets with different levels of reliability of protein expression, and CDC is a cancer dataset. All of the ADN dataset were used in our experiments because this dataset has the best quality. Then the samples in BDN and CDC datasets were selectively added to the training set by semi-supervised learning. A flow chart of the proposed method is shown in<ref type="figure" target="#fig_1">Figure 2A</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Incorporating new samples</head><p>The requirement for a sample to be added to the training set is that its predicted label set is the same as the annotation in HPA and the other classifier(s). This is because such images have more obvious discriminative features for a certain class and they can therefore help to enhance the classification boundary of the current model. Since there is no subcellular location annotation of proteins in cancerous tissues in the HPA, we compare the prediction output to the annotation of corresponding proteins in normal tissues to judge whether a sample in the CDC dataset should be selected or not. This is reliable when considering more than 95% proteins are actually not cancer biomarkers (<ref type="bibr" target="#b22">Glory et al., 2008</ref>). Note that when adding the samples from the CDC set, the initial classifier(s) are the resulting classifier(s) after adding the BDN set. This ensures the generality of final predictor for both normal and cancer proteins. To test different strategies, we have implemented three training modes, i.e. singleclassifier mode, two-classifier mode and three-classifier mode. Details of their screening criteria to judge which samples need to be added are presented as follows. The single-classifier mode just constructs one classifier, which will be iteratively updated until the stop condition is reached. Before the iteration process, an initial classier is trained using the entire ADN dataset. In each iteration round, the classifier is used to predict(1) is used for determining the stop condition of iterations. The model is considered stable when eff j smaller than a threshold value (&lt;0.01 in this study) the subcellular locations of the images in the candidate sample set and those images whose predicted subcellular locations are the same as the annotations in HPA are selected and put into the training set. The classifier is then updated based on the new training set, which is ready for the next iteration. According to the two-classifier mode, a predictor is composed of two classifiers, i.e. C 1 and C 2 , where their initial models are trained on A 1 and A 2 , which are generated from the ADN dataset via the bootstrap sampling method (<ref type="bibr" target="#b18">Efron and Tibshirani, 1994</ref>). This sampling method randomly draws n independent samples with replacement from the original pooled set, where n is the number of samples in the pooled set. In this study, we sampled 4224 times with replacement from the ADN space and obtained approximately 63.2% of ADN images after discarding repeated images. This step can ensure A 1 &amp; ADN; A 2 &amp; ADN and A 1 6 ¼ A 2 , which guarantee the diversity of the initial models of C 1 and C 2. The candidate sample set was duplicated to two sets, B 1 and B 2 , which were used for updating C 1 and C 2 , respectively. In each iterative round of training, C 1 is firstly employed to predict the subcellular locations of the images in B 2 , then those images whose predicted subcellular locations are exactly the same as the annotations in HPA were removed from B 2 and added to A 2 for updating the C 2 model. Analogously, A 1 , the training set of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Stopping condition</head><p>All the three modes are based on the iteration processes shown in<ref type="figure" target="#fig_1">Figure 2A</ref>. A critical question is when the iteration should terminate. The stopping condition of the iterations is determined by the effect of newly added samples to the classifier model. In this article, this effect is measured by the number of newly added samples and the change of the predicted scores for overlapping images in the current and previous rounds. To measure the change quantitatively, the t-test was used to compare the scores of two adjacent rounds and the average of the P-values was calculated. We thus define the effect as</p><formula>eff j ¼ n j N Â 1 p j ; (1)</formula><p>where n j is the number of samples newly added in the jth round, N is the total number of initial candidate samples, p j is the average P-values between round j and (j À 1). The iteration stops when eff j &lt; 0.01, which is determined according to our experimental results. Details by varying eff j are shown in Supplementary<ref type="figure" target="#fig_0">Figure S1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Dynamic threshold criterion</head><p>Here, we used the support vector machine (SVM) as the classification model, and the LIBSVM-3.17 package is employed (http:// www.csie.ntu.edu.tw/$cjlin/libsvm/). The radial basis function was used as the kernel and its optimal width parameter was calculated by the data-driven calculator GFO (<ref type="bibr" target="#b27">Lei et al., 2012</ref>). To deal with multilabel proteins that can coexist in multiple subcellular locations, the binary relevance (BR) multilabel algorithm was used to deal with our datasets (<ref type="bibr" target="#b14">Boutell et al., 2004</ref>). According to BR, one binary SVM model was trained for predicting the relevance of test images to one class, so each BR classifier contains six SVM models (<ref type="bibr" target="#b47">Xu et al., 2013</ref>). A six-dimensional (6D) score vector [s 1 , s 2 ,.. ., s 6 ] will be obtained per test image, where each score component represents the confidence of the input belonging to the corresponding class (six subcellular locations). Based on the outputted real-value confidence score vector, it is important to decide which class or classes should be assigned to a sample. In a previous work, we investigated the top criterion (T-criterion) and the threshold criterion (S-criterion) to decide the label sets in multilabel classifications (<ref type="bibr" target="#b47">Xu et al., 2013</ref>). The T-criterion considers that the label set consists of the labels with positive scores, and if all the scores are negative, the label with the maximum score is considered as the unique label. The assumption of the S-criterion is that the score values corresponding to the real labels are the largest, and, in the case of a multiplex sample, its multiple labels will have similar scores. So in the S-criterion, a threshold is determined to measure whether a score is close enough to the largest one. However, it is a static threshold that is applied to all the images to be classified. A static unified threshold may not fit for all images because the scales of score vectors for different images can be variable, especially for the images in different classes. To solve this problem, we proposed a dynamic threshold criterion (D-criterion) in this study, which can determine a specific threshold for each sample according to the scale and distribution of its score vector. For one image whose score vector is [s 1 , s 2 ,.. ., s 6 ], the D-criterion can be presented as: if all the six scores are negative, then the label with the maximum score is considered as the unique label; if the maximum score is positive, then y i ¼ 1; if s max À s i s max t or s i &gt; h À1; otherwise</p><formula>; 8 &gt; &lt; &gt; :</formula><p>where s max ¼ maxfs 1 ; s 2 ;.. .; s 6 g; s max &gt; 0;</p><formula>(2)</formula><p>where y i is the prediction of the sample's relevance to the ith class, and t and h are two constant parameters that need to be determined. To derive these two parameters, the maximum a posteriori (MAP) principle is employed. First, the degree of closeness between s i and s max is defined as</p><formula>tdif ¼ s max À s i s max (3)</formula><p>Here, we define H 1 to denote 'yes' and H 2 to denote 'no' when deciding whether the ith class should be assigned to the predicted label set according to the tdif value. Supposing H b is the final decision, the objective function with respect to tdif is</p><formula>b ¼ arg max e¼1;2 PðH e jtdifÞ ¼ arg max e¼1;2 PðtdifjH e Þ Á PðH e Þ PðtdifÞ ; ¼ arg max e¼1;2 PðtdifjH e Þ Á PðH e Þ (4)</formula><p>where PðtdifjH 1 Þ Á PðH 1 Þ is the probability distribution of tdif for the positive samples in the ith class, and PðtdifjH 2 Þ Á PðH 2 Þ is for negative samples not belonging to the ith class. So to distinguish H 1 and H 2 with a minimum error, the tdif value in the intersection of</p><formula>PðtdifjH 1 Þ Á PðH 1 Þ and PðtdifjH 2 Þ Á PðH 2 Þ</formula><p>is taken as the parameter t according to the MAP principle (<ref type="figure" target="#fig_3">Fig. 3</ref>). As for the other parameter h, it is set to ensure all the high scores are not missed, and the confidence of the decision according to h is</p><formula>a ¼ PðH 1 js i &gt; hÞ ¼ PðH 1 Þ Á Pðs i &gt; hjH 1 Þ Pðs i &gt; hÞ ¼ ð þ1 h PðH 1 Þ Á Pðs i jH 1 Þds i ð þ1 h Pðs i Þds i (5)</formula><p>Therefore, given a confidence score a, h can then be calculated according to Equation (5). In this article, we set a ¼ 0.95, and its effects to h and classification performance are shown in Supplementary<ref type="figure" target="#fig_1">Figure S2</ref>. The statistics of</p><formula>PðtdifjH 1 Þ,PðtdifjH 2 Þ, Pðs i jH 1 Þ, PðH 1 Þ, PðH 2 Þ and Pðs i Þ</formula><p>are based on the score vectors obtained by using 5-fold cross validation on the training set. The calculation process is given in<ref type="figure" target="#fig_3">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Evaluation metrics</head><p>Due to the fact that we are facing multilabel proteins, five multilabel classification metrics, i.e. subset accuracy, accuracy, recall, precision and average label accuracy were employed to evaluate the performance of the predictors (see Supplementary text for details). Among them, we mainly use the subset accuracy, which is the most stringent one since it requires the predicted label set to be exactly the same as the true label set. In addition, we also measured the sensitivity and AUC of each binary classifier in the models (see Supplementary text for detail).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline supervised model results</head><p>As a baseline, the most straightforward supervised method was used to train classifiers for comparison. We took the entire ADN, entire BDN and a combination of them (ADN þ BDN), respectively, as training sets to construct classifiers. Then these classifiers were tested on the independent IDN dataset, and generated the results of simple supervised learning for comparison using the T-criterion (<ref type="figure" target="#fig_5">Fig. 4A</ref>) and the D-criterion (<ref type="figure" target="#fig_5">Fig. 4B</ref>), respectively. It can be seen from<ref type="figure" target="#fig_5">Figure 4A</ref>and B that: (1) D-criterion outperforms T-criterion, demonstrating the effectiveness of the D-criterion;</p><p>(2) Overall, the subset accuracies of classifiers trained on ADN are better than those on BDN, indicating that the image quality can affect the model performance; (3) Interestingly, in some cases, the results of ADN þ BDN are not better than those only using ADN, indicating that not all of the medium quality images in BDN have a positive effect on performance. The first observation suggests that a dynamic threshold is better due to the specificity for testing samples, thus we will use the D-criterion in the following experiments. The second and third observations suggest that if we add all the BDN samples into ADN to train a supervised model, the performance does not improve sometimes. The reason could be that not all of the samples in theTwo constant parameters, t and h, are needed in this criterion (Equation 2). Suppose the ith score of a sample outputted from classifier is s i. When deciding whether the label i should be assigned to the predicted label set, we defined H 1 to denote yes and H 2 to denote no. t is set to distinguish H 1 and H 2 , while h is set to ensure that the labels with high scores are not missed. Both parameters are determined by maximizing posteriori principle, as well as score vectors of training set by 5-fold cross validation. (A) The histogram of tdif1. (B) The histogram of tdif2. tdif1 and tdif2 are tdif values corresponding to H 1 and H 2 , respectively (BDN are complementary to the ADN; furthermore, some lowquality samples in the BDN will degenerate the model. This motivated us to explore a better way to take advantage of the candidate image samples rather than simply employing all of them.</p><formula>CDC. AsemiB E 1 , AsemiB E 2 , AsemiB E 3 , AsemiBC E 1 , AsemiBC E 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Improvements by selectively adding medium-reliability data</head><p>The entire ADN was used as the initial training set, and then according to the semi-supervised iteration framework, not all of the BDN images, but only those which improve model performance were iteratively selected into the training set. The final results are three semi-supervised predictors, which are denoted as AsemiB 1 (one-classifier mode), AsemiB 2 (two-classifier mode) and AsemiB 3 (three-classifier mode), corresponding to the three training modes, respectively. The classifier of each round is tested on IDN, and the changes of subset accuracies are shown in<ref type="figure" target="#fig_1">Figure 2B</ref>. The changes of number of added images, and effects on each iterative round are illustrated in<ref type="figure" target="#fig_1">Figure 2C</ref>and D. It can be seen that as the round increases, the subset accuracy tends to increase in all modes. All the final subset accuracies when these iterations terminate, i.e. 51, 49 and 51%, are higher than the result of directly adding the entire BDN, which is 46% as shown in<ref type="figure" target="#fig_5">Figure 4B</ref>. Besides, both the number of added images and effect value in the iteration decrease sharply. This indicates that the influence of the added images on classification decreases as the round increases. At the end of iterations of the db7 model, 56.75, 61.37 and 52.86% images in BDN were chosen and added to the training sets of AsemiB 1 , AsemiB 2 and AsemiB 3 , respectively. Compare<ref type="figure" target="#fig_5">Figure 4C</ref>and B, we can see that all the subset accuracies of three semi-supervised modes are higher than those of supervised learning. Adding medium-reliability data into training set not only expands the training sample space, but also validates the effectiveness of the proposed semi-supervised idea. Considering that different semi-supervised learning methods have been widely used these years (<ref type="bibr" target="#b26">Lee and Madabhushi, 2010;</ref><ref type="bibr" target="#b30">Luo et al., 2013</ref>), we also compared our methods with two stateof-the-art semi-supervised algorithms, i.e. low-density separation (LDS) and cost-sensitive semi-supervised SVM (CS4VM). LDS is a graph-based method, which represents each labeled and unlabeled sample as a node and tries to place decision boundaries in regions where there are few data nodes (<ref type="bibr" target="#b15">Chapelle and Zien, 2005</ref>). CS4VM incorporates the unlabeled data into the SVM by estimating their label means of misclassification costs (<ref type="bibr" target="#b28">Li et al., 2010</ref>).<ref type="figure" target="#fig_5">Figure 4C</ref>shows the results of LDS and CS4VM when taking ADN as labeled data, BDN as unlabeled data and IDN as testing set. The performances of our proposed methods are better than LDS and CS4VM on the multilabel dataset of this article. One reason can be the multilabel sample classification is much more comprehensive than the single-label case used by the two algorithms. For instance, the LDS might be unable to accurately find the boundaries in a graph built by multilabel data, because some multilabel samples are near the low-density areas and confuse the decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Performance of ensemble classifiers</head><p>Since an ensemble of multiple classifiers generally achieves better performance, we constructed ensemble classifiers by combining the 10 classifiers with db1–db10 features. The fusion method averages all the score vectors from the 10 single classifiers to get a final sixdimensional (6D) vector for each query image. These ensemble classifiers are tested on IDN to show their effectiveness on the normal dataset (<ref type="figure" target="#fig_5">Fig. 4D</ref>and F). By comparing the results between the ensemble classifier and the single classifiers, we find that the ensemble classifier outperforms the single classifier on IDN dataset. For example, a 2% improvement of the subset accuracy was observed for the AsemiBC E 2 compared with the single classifier AsemiBC 2 on db7. The other merit of the ensemble strategy is that it can<ref type="figure">Fig. 5</ref>. Comparison of intranormal CC, intracancer CC and inter normal and cancer CC values. In the statistics, the high expression level dataset and CDC dataset are used as normal and cancer dataset, respectively. The db7 features are used and the feature dimension is 80 significantly reduce the negative bias by adding the cancer data to the training set. For instance, the subset accuracy of single AsemiBC 1 classifier on IDN with db7 feature is 47.5% (<ref type="figure" target="#fig_5">Fig. 4D</ref>), which is 4.25% lower than the AsemiBC E 1. One final ensemble predictor without-adding CDC and one final ensemble predictor adding CDC were created. All the classifiers without-adding CDC were fused to create AsemiB E , and all the classifiers of adding CDC were fused to create AsemiBC E. Both of them could achieve good performance on IDN testing set (<ref type="figure" target="#fig_5">Fig. 4G</ref>). It is worth pointing out that besides the most stringent metric in multilabel classification, subset accuracy (<ref type="figure" target="#fig_5">Fig. 4</ref>), we also used other indices to evaluate the AsemiB E and AsemiBC E and their results can be seen in Supplementary Tables S3 and S4. For example, the average label accuracy, which indicates the reliability of prediction for single locations, can achieve 87.04% for the final system (Supplementary<ref type="figure">Table S3</ref>), which implies the reliable detection of translocation from or to a specific location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Detecting protein translocations of cancer biomarkers</head><p>The IBD set containing 10 reported biomarker proteins was used for validating whether the sensitivity of translocation detection can be enhanced by utilizing cancer data in the training phase. We compared the prediction results on the IBD set before and after adding the CDC dataset to see the effects of adding CDC data. The results from AsemiB E and AsemiBC E were compared, where the former did not incorporate the cancer data into training, whereas the latter did. To quantify the sensitivity of detecting the subcellular location changes, in addition to the predicted and reported location labels in the normal and cancer conditions, we also conducted independent sample t tests on the predicted score vectors to evaluate the significance of the location changes (Supplementary<ref type="figure" target="#fig_3">Fig. S3</ref>). The comparison results and P-values of the changes are shown in<ref type="figure" target="#tab_1">Table 1</ref>, from where we can see that: 1. The protein Bax and cyclin D1 prove that adding CDC dataset makes the classifiers more sensitive to detect the location changes occurring during cancer. In detail, protein Bax will partly translocate from the cytoplasm to the mitochondrion when lymphoma occurs (<ref type="bibr" target="#b36">Nechushtan et al., 1999</ref>). This translocation cannot be found by the predictors trained only on normal data, but can be picked out by AsemiBC E , which was trained on both normal and cancer data. The protein cyclin D1 normally shuttles between cytoplasm and nucleus locations. However, in ovarian cancer cyclin D1 is found only in the nucleus (<ref type="bibr" target="#b20">Gladden and Diehl, 2005</ref>). AsemiB E predicts cyclin D1 its locations in cancer as both the nucleus and mitochondria, while AsemiBC E correctly predicts its cancer location as the nucleus only. 2. The loss of nuclear localization of PTEN in pancreatic cancer is correctly predicted by both AsemiB E and AsemiBC E (<ref type="bibr" target="#b38">Perren et al., 2000</ref>), demonstrating that the machine-learning systems are effective for the detection of protein mislocalization. 3. AsemiBC E is able to perform prediction better than AsemiB E for the IBD proteins in their normal states. For example, the protein BAG-1 is reported to reside in the nucleus in normal conditions and translocate to the mitochondria during colorectal cancer (<ref type="bibr" target="#b44">Takayama et al., 1998</ref>). AsemiB E predicted BAG-1 would localize in both the cytoplasm and nucleus in the normal state, whereas AsemiBC E predicted only a nucleus location, which is experimentally correct. Other examples include NQO1 and GOLGA5. 4. The P-values also reveal the improved sensitivity for detecting protein translocations by the predictor of AsemiBC E. The lowerReported by literaturethe P-value, the more significant the change. There are a total of 16 experimentally known changed locations for the 10 proteins. Twelve of them have lower P-values in AsemiBC E with a P-value 0.0003–0.6167 compared with 0.001–0.8560 in AsemiB E. These results suggest that the sensitivity of detecting protein subcellular location changes is enhanced by incorporating the cancer data into the model construction. 5. Although some improvements can be observed (with lower P-values) by incorporating the cancer images into the classification system construction, there are still considerable room for improvement. For instance, there are still some cases where none of the two predictors can get completely correct prediction. This suggests that tremendous future efforts are needed for further improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Data collection. (A) Process of collecting normal datasets. The pie chart (left) shows the percentages of normal protein images with different levels of expression reliability in HPA version 11. Protein images with high and medium reliability corresponding to six subcellular locations in 11 tissues were collected (Supplementary Table S1). The overlapping part of two circles represents overlap on the protein level because some proteins have different reliability levels in different tissues. For example, ornithine carbamoyltransferase is one such protein because its reliability of expression in liver is high while in the colon it is medium. The IDN is randomly selected from the nonoverlapping proteins and avoids protein overlap with the training set. The ADN and BDN are composed of the remaining images with high and medium reliability levels, respectively. Note that IDN has intersection with neither ADN nor BDN at the protein level. (B) Some examples of protein images with different reliability levels and subcellular locations. (C) Summary of all the datasets used in this study. The CDC is built by images of 348 proteins in cancerous tissues, where the 348 proteins are proteins whose images in corresponding normal tissues are of high reliability of protein expression. The IBD contains 10 proteins that were reported being translocated in human cancers by the literatures (Supplementary Table S2). In the column of expression reliability, H means high and M means medium</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Incremental process of iteratively adding candidate samples into the training set. (A) Flow chart of the iterative process. The initial training set is either the entire ADN dataset or the entire ADN dataset plus a selected subset of the BDN dataset, while the candidate samples to be included are images in either the BDN or CDC datasets, respectively. As the iterations proceed, the training set grows and the number of candidate samples decreases. (B–D) Results of iteratively adding BDN into the training set (initially ADN) using the proposed protocol with db7 features. (E–G) Results of iteratively adding CDC into the training set (initially ADN and a selected subset of BDN) using the proposed protocol with db7 features. (D, G) Shows effects caused by updating the training set in each round. The effect (eff j ) defined by Equation (1) is used for determining the stop condition of iterations. The model is considered stable when eff j smaller than a threshold value (&lt;0.01 in this study)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>C 1 , was extended by predicting B 1 with C 2. As the iterations proceed, the size of B 1 and B 2 decreases while that of A 1 and A 2 increases. The three-classifier mode trains three classifiers, i.e. C 1 , C 2 and C 3 , by three different training sets, i.e. A 1 , A 2 and A 3 , which are also initially constructed by using bootstrap sampling. Then the candidate sample set was duplicated to three sets, B 1 , B 2 and B 3 , for updating the three classifiers, respectively. In each round, C 1 and C 2 are used to predict the subcellular locations of the images in B 3. Those images whose label sets outputted from C 1 and C 2 are both the same as the HPA annotation were removed from B 3 and added to A 3 for updating C 3. A 1 and A 2 were updated in an analogous way based on the output from the other two classifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Illustration of the process of determining parameters for D-criterion. Two constant parameters, t and h, are needed in this criterion (Equation 2). Suppose the ith score of a sample outputted from classifier is s i. When deciding whether the label i should be assigned to the predicted label set, we defined H 1 to denote yes and H 2 to denote no. t is set to distinguish H 1 and H 2 , while h is set to ensure that the labels with high scores are not missed. Both parameters are determined by maximizing posteriori principle, as well as score vectors of training set by 5-fold cross validation. (A) The histogram of tdif1. (B) The histogram of tdif2. tdif1 and tdif2 are tdif values corresponding to H 1 and H 2 , respectively (Equation 3). (C) The fitting curves. The parameter t is obtained as the intersection point. (D) The histogram of s i when H 1 happens. (E) The histogram of s i. (F) The fitting curves. h is set to ensure the ratio between the two regions of integration is 0.95. This figure is based on the model trained by ADN with db7 features</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Fig. 3. Illustration of the process of determining parameters for D-criterion. Two constant parameters, t and h, are needed in this criterion (Equation 2). Suppose the ith score of a sample outputted from classifier is s i. When deciding whether the label i should be assigned to the predicted label set, we defined H 1 to denote yes and H 2 to denote no. t is set to distinguish H 1 and H 2 , while h is set to ensure that the labels with high scores are not missed. Both parameters are determined by maximizing posteriori principle, as well as score vectors of training set by 5-fold cross validation. (A) The histogram of tdif1. (B) The histogram of tdif2. tdif1 and tdif2 are tdif values corresponding to H 1 and H 2 , respectively (Equation 3). (C) The fitting curves. The parameter t is obtained as the intersection point. (D) The histogram of s i when H 1 happens. (E) The histogram of s i. (F) The fitting curves. h is set to ensure the ratio between the two regions of integration is 0.95. This figure is based on the model trained by ADN with db7 features</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. Results of supervised learning and semi-supervised learning tested on the independent IDN dataset. (A) Results of baseline supervised classifiers trained on ADN, BDN and ADN þ BDN datasets, respectively, using the T-criterion. (B) Results of supervised classifiers using the D-criterion. (C) Comparison results of our classifiers trained by adding BDN to ADN using semi-supervised strategy on three modes, with two other semi-supervised classifiers in literature. (D) Ensemble by fusing the classifiers after adding BDN. (E) Results of classifiers trained by subsequently adding CDC to the training set using the semi-supervised strategy on three modes. AsemiB 1 and AsemiBC 1 mean using one-classifier mode, AsemiB 2 and AsemiBC 2 mean using two-classifier co-training mode, and AsemiB 3 and AsemiBC 3 mean using three-classifier tri-training mode. (F) Ensemble by fusing the classifiers after adding CDC. AsemiB E 1 , AsemiB E 2 , AsemiB E 3 , AsemiBC E 1 , AsemiBC E</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1.</figDesc><table>Comparison between literature descriptions and the results of predicting IBD by ensemble classifiers 

Protein 
Tissue 
Protein translocations from normal to cancer condition 

</table></figure>

			<note place="foot">Y.-Y.Xu et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3">.3 Incorporating images from cancer tissues to the model To enhance the performance of predicting subcellular locations of proteins in cancerous tissues, we consider adding some images from cancerous tissues into the training set to eliminate the transfer prediction error caused by the difference between the normal and cancer data. Actually, we conducted an experiment to quantify the differences of patterns between the two states. Based on the proteins in CDC set, we used the correlation coefficient (CC) to measure difference between normal and cancer images, where we assumed that proteins in the CDC set did not change their locations in cancer states. This is reasonable when considering that more than 95% protein images in current HPA database are actually not cancer biomarkers (Glory et al., 2008). Each image was represented by its feature vector, and three CC matrixes were calculated: the first is the intra-CC in the normal images group, the second is the intra-CC in the cancer images group and the third is the inter-CC between normal and cancer sets. Figure 5 shows the averaged CC values based on six subcellular locations. It can be seen that the inter-CC values between normal and cancer images are lower than the intraCC values in all cases. In addition, we also calculated the P-values with the student t test between normal and cancer dataset, and P-values of all the subcellular locations are &lt;0.05. These results demonstrate that even for the same organelle, there is a difference between the normal and cancer data. This suggests that the transfer method of using normal data as the training set to predict the cancer data may miss some specific features of proteins in the cancer state. After adding BDN in above section, we obtained three classifiers, i.e. AsemiB 1 , AsemiB 2 and AsemiB 3 , by semi-supervised learning. Following the incremental selective learning protocol, images from CDC were subsequently added to these classifiers, and we got AsemiBC 1 , AsemiBC 2 and AsemiBC 3 (Figs. 2E–G and 4E). It can be seen that the subset accuracies of classifiers on the independent IDN set fluctuate and decline slightly, which is because the added cancer data affected the prediction performance of normal data. This also highlights the difference between normal and cancer data. Nevertheless, the decline in performance is not significant, and the subset accuracies still outperform the baseline results from supervised models.</note>

			<note place="foot" n="4"> Discussion and conclusions In this article, we present a new automated bioimage analysis system for sensitively detecting translocated or mislocated proteins in human cancers. The new system is featured with a semi-supervised learning engine, which can help to enlarge the training space by incorporating lower-quality or unlabeled data key to the performance of a statistic model. The other merit of the new system is the capability of predicting proteins that shuttle among multiple subcellular locations, and a new dynamic D-criterion is proposed to deal with the multilabel set determination problem by considering the specificity of each protein. The new developed system has opened a new avenue for bioimage-based automated biomarker detection work, which suits large-scale data analysis and complement research from biological experiments. We have shown that the strategy of selectively incorporating medium staining normal images with the developed semi-supervised framework is helpful for improving the classification accuracy on the normal images as demonstrated in the independent test dataset. On the other hand, some improvements were also observed when applying the semi-supervised algorithm for adding selected cancer images into training, but they have still considerable space for further improvement. For instance, some translocated or mislocated cancer biomarkers cannot be completely predicted, especially for those multi-label proteins. To further improve the performance of our system, some efforts will be made in future studies. First, we will aim to improve the multilabel classification algorithm by taking the label correlations into account. Multiplex proteins that may shuttle among more than one subcellular location indicate a complex subcellular protein organization in the cell. The benchmark dataset of this study contains 26% multilabel proteins. This ratio is even much higher to reach approximately 60% according to a recent study of applying IF and fluorescent-protein tagging techniques on mammalian cells (Stadler, 2013). In this article, we transformed the multilabel problem into six binary classification problems, ignoring the correlation among different subcellular locations. It is expected that incorporating correlations, such as proteins coexisting at different locations due to spatial proximity or functional reasons, will be useful for further improving the performance. Second, our imaging-based studies can be integrated with analysis of non-imaging data, such as proteomics and genomics analyses (Murphy, 2014). Amino acid sequence has been used for predicting protein subcellular locations for many years, and we have developed an efficient sequence-based subcellular location predictor called Cell-PLoc in previous studies (Chou and Shen, 2008; Shen and Chou, 2009). The Cell-PLoc can also deal with multilabel proteins and have wide coverage of subcellular components. Merging prediction results from different resources is a potential effective way for further enhancing the sensitivity for translocated proteins detection. The multiclassifier mode of this study also provides a feasible combination solution, which enables us to cotrain our image-based and sequence-based software to generate a better protein subcellular location prediction system.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to Dr. Jeffrey Brender and Dr. Richard Jang for reading the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was supported in part by the National Natural Science Foundation of China<ref type="bibr">[Nos. 61222306, 91130033, 61175024]</ref>, Shanghai Science and Technology Commission<ref type="bibr">[No. 11JC1404800]</ref>, a Foundation for the Author of National Excellent Doctoral Dissertation of People's Republic of China<ref type="bibr">[No. 201048]</ref>and the National Institute of General Medical Sciences<ref type="bibr">[GM083107]</ref>. Conflict of interest: none declared.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Prediction by AsemiB E (normal ! cancer P-values of changed locations) a,b Prediction by AsemiBC E (normal ! cancer P-values of changed locations) a,b Bax Lymph node Cyto</title>
		<imprint>
			<biblScope unit="page">6336</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Mito</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page">430</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Nucl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">Colon</forename>
				<surname>Nucl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Mito</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucl.&amp; Cyto. ! Nucl.&amp; Cyto. Nucl</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Nucl.0.5944, Mito.0.3463 GOLGA5 Thyroid gland Gol. ! Mito</title>
		<author>
			<persName>
				<surname>Nucl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Nucl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gol.&amp; Mito.&amp; Nucl. ! Gol. Gol</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Gol</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page">5170</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Cyto.0.0741, Nucl.0.1143 p53</title>
		<author>
			<persName>
				<surname>Nucl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Breast Nucl. ! Nucl.&amp; Cyto. Nucl. ! Nucl. Cyto</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page">1315</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Nucl</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Nucl</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page">7419</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Cyto</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">The results have two lines: the first line is the predicted subcellular location labels in normal and cancer conditions, respectively, by the classifier; the second line is the P-values measuring the subcellular location changes when cancer occurs (column 3), which are calculated by the independent sample t test on the predicted scores for normal and cancer images</title>
		<imprint/>
	</monogr>
	<note>b. Those translocations that have lower P-values are bold</note>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Bioimaging-based detection of mislocalized proteins in human cancers References Benzeno, Identification of mutations that disrupt phosphorylation-dependent nuclear export of cyclin D1</title>
		<author>
			<persName>
				<forename type="first">S</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oncogene</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="6291" to="6303" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning multi-label scene classification</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Boutell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1757" to="1771" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised classification by low density separation</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Chapelle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Zien</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AISTATS</title>
		<meeting>. AISTATS</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Cell-PLoc: a package of web servers for predicting subcellular localization of proteins in various organisms</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">B</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protoc</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="153" to="162" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving a page classifier with anchor extraction and link analysis</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">W</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1481" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title level="m" type="main">An Introduction to the Bootstrap</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Biological imaging software tools</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">W</forename>
				<surname>Eliceiri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="697" to="710" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Location, location, location: the role of cyclin D1 nuclear localization in cancer</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">B</forename>
				<surname>Gladden</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Diehl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cell Biochem</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="906" to="913" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Automated subcellular location determination and high-throughput microscopy</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Glory</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Cell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="7" to="16" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Automated comparison of protein subcellular location patterns between images of normal and cancerous tissues</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Glory</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Biomedical Imaging</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="304" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Semi-supervised learning</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">F A</forename>
				<surname>Hady</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Schwenker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook on Neural Information Processing</title>
		<editor>Bianchini,M. et al.</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="215" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Mining the plasma proteome for cancer biomarkers</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">M</forename>
				<surname>Hanash</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">452</biblScope>
			<biblScope unit="page" from="571" to="579" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Protein localization in disease and therapy</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">C</forename>
				<surname>Hung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Link</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cell Sci</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="3381" to="3392" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised graph embedding scheme with active learning (SSGEAL): classifying high dimensional biomedical data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Madabhushi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition in Bioinformatics</title>
		<editor>Dijkstra,T.M.H. et al.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="207" to="218" />
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">GFO: a data driven approach for optimizing Gaussian function based similarity metric in computational biology</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">B</forename>
				<surname>Lei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="307" to="315" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<monogr>
		<title level="m" type="main">Cost-sensitive semi-supervised support vector machine</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">F</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="500" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Effects of prior information and reward on oculomotor and perceptual choices</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">B</forename>
				<surname>Liston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">S</forename>
				<surname>Stone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="13866" to="13875" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Manifold regularized multitask learning for semisupervised multilabel image classification</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Luo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="523" to="536" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Iterative reclassification procedure for constructing an asymptotically optimal rule of allocation in discriminant analysis</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">J</forename>
				<surname>Mclachlan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="365" to="369" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title level="m" type="main">Automated interpretation of protein subcellular location patterns: implications for early cancer detection and assessment</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Ann. N. Y</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">1020</biblScope>
			<biblScope unit="page" from="124" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">A new era in bioimage informatics</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">1353</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Novel features for automated cell phenotype image classification</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nanni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ed) Advances in Computational Biology</title>
		<editor>Arabnia,H.R. (</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="207" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Conformation of the Bax C-terminus regulates subcellular location and cell death</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Nechushtan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO J</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2330" to="2341" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">A framework for the automated analysis of subcellular patterns in human protein atlas images</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Newberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">F</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2300" to="2308" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Mutation and expression analyses reveal differential subcellular compartmentalization of PTEN in endocrine pancreatic tumors compared to normal islet cells</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Perren</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Pathol</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page" from="1097" to="1103" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">BaCelLo: a balanced subcellular localization predictor</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Pierleoni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="408" to="416" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Quantitative comparison of immunohistochemical staining measured by digital image analysis versus pathologist visual scoring</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Rizzardi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Diagn. Pathol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">A top-down approach to enhance the power of predicting human protein subcellular localization: Hum-mPLoc 2.0</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">B</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Biochem</title>
		<imprint>
			<biblScope unit="volume">394</biblScope>
			<biblScope unit="page" from="269" to="274" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Immunofluorescence and fluorescent-protein tagging show high correlation for protein localization in mammalian cells</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Stadler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="315" to="323" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Protein subcellular localization of fluorescence imagery using spatial and transform domain features</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Tahir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="91" to="97" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">Expression and location of Hsp70/Hsc-binding anti-apoptotic protein BAG-1 and its variants in normal tissues and tumor cell lines</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Takayama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="3116" to="3131" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">Towards a knowledge-based human protein atlas</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Uhlen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1248" to="1250" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">Subcellular localization of NAD (P) H: quinone oxidoreductase 1 in human cancer cells</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Winski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="1420" to="1424" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b47">
	<analytic>
		<title level="a" type="main">An image-based multi-label human protein subcellular localization predictor (iLocator) reveals protein mislocalizations in cancer tissues</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">Y</forename>
				<surname>Xu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2032" to="2040" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b48">
	<analytic>
		<title level="a" type="main">Tri-training: Exploiting unlabeled data using three classifiers</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<forename type="middle">H</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1529" to="1541" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>