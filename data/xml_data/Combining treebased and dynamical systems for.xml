
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Combining tree-based and dynamical systems for the inference of gene regulatory networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Vâ</forename>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Anh</forename>
								<surname>Huynh-Thu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Guido</forename>
								<surname>Sanguinetti</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">SynthSys -Systems and Synthetic Biology</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<postCode>EH9 3JD</postCode>
									<settlement>Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Combining tree-based and dynamical systems for the inference of gene regulatory networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu863</idno>
					<note type="submission">Received on October 18, 2014; revised on December 5, 2014; accepted on December 23, 2014</note>
					<note>Systems biology *To whom correspondence should be addressed. Associate Editor: Igor Jurisica Contact: vhuynht@inf.ed.ac.uk or G.Sanguinetti@ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Reconstructing the topology of gene regulatory networks (GRNs) from time series of gene expression data remains an important open problem in computational systems biology. Existing GRN inference algorithms face one of two limitations: model-free methods are scalable but suffer from a lack of interpretability and cannot in general be used for out of sample predictions. On the other hand, model-based methods focus on identifying a dynamical model of the system. These are clearly interpretable and can be used for predictions; however, they rely on strong assumptions and are typically very demanding computationally. Results: Here, we propose a new hybrid approach for GRN inference, called Jump3, exploiting time series of expression data. Jump3 is based on a formal on/off model of gene expression but uses a non-parametric procedure based on decision trees (called &apos;jump trees&apos;) to reconstruct the GRN topology, allowing the inference of networks of hundreds of genes. We show the good performance of Jump3 on in silico and synthetic networks and applied the approach to identify regulatory interactions activated in the presence of interferon gamma. Availability and implementation: Our MATLAB implementation of Jump3 is available at http://homepages.inf.ed.ac.uk/vhuynht/software.html.
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computational reconstruction of gene regulation from expression data is a central problem of systems biology (<ref type="bibr" target="#b1">Alon, 2006</ref>). Gene regulation is a complex process involving multiple control steps at the chromatin, transcriptional and post-transcriptional level (<ref type="bibr" target="#b0">Alberts et al., 2008</ref>); given the difficulty in measuring and modelling all of these individual processes, the identification of a suitable abstraction and associated statistical inference methodology is vital. The gene regulatory network (GRN) abstraction aims at explaining the joint variability in the expression levels of a group of genes through a sparse pattern of interactions; elucidating the topology of GRNs can provide important insights in the fundamental biology of the system and suggest possible intervention points in biomedical applications.</p><p>Inferring the topology of a GRN from gene expression timeseries data has been a subject of intense research in computational biology over the last 15 years (<ref type="bibr" target="#b3">Bansal et al., 2007;</ref><ref type="bibr" target="#b7">De Smet and Marchal, 2010;</ref><ref type="bibr" target="#b26">Penfold and Wild, 2011</ref>). Current approaches can be broadly divided into model-based and model-free approaches. Model-based methods start by formulating a computational model of the system, usually in the form of differential or difference equations and recast the network inference problem as learning the parameters of such a model. To achieve a sparse pattern of interactions, such methods usually employ sparsity-inducing priors in a Bayesian setting or regularization penalties in an optimization-based scenario. Model-based methods have many appealing qualities: the assumptions made are transparently stated and, most importantly, the generative perspective enables principled predictions of expression levels under perturbations. However, model-based methods are not free from limitations: they tend to be computationally intensive, particularly in a Bayesian setting, and their parametric nature usually implies very stringent assumptions about the dynamics (e.g. linear), which may be difficult to justify biologically. Model-free methods avoid the pitfalls of model-based methods by greedily optimizing information-theoretic measures of co-variation between pairs of genes (<ref type="bibr" target="#b10">Faith et al., 2007;</ref><ref type="bibr" target="#b20">Huynh-Thu et al., 2010;</ref><ref type="bibr" target="#b23">Margolin et al., 2006</ref>). Such methods typically have good scalability, enabling reconstructions of networks of hundreds of genes and have consistently achieved state-of-the-art reconstruction performance in comparative evaluations (<ref type="bibr" target="#b22">Marbach et al., 2012</ref>). The lack of an underpinning model also enables great flexibility, as the interactions between genes are not constrained to follow a parametric functional representation. Such flexibility comes at a cost though: model-free methods, by their very nature, do not have clearly defined semantics in terms of dynamical systems and cannot be used for prediction in a straightforward way. Furthermore, incorporation of side information, which is natural in model-based methods, is generally challenging in model-free methods. In this article, we aim to bridge the gap between model-based and model-free methods by proposing a hybrid approach to the network inference problem, called Jump3. Our approach starts from a welldefined, biologically plausible model of gene expression, the on/off model of gene expression (<ref type="bibr" target="#b24">Ocone et al., 2013;</ref><ref type="bibr" target="#b28">Ptashne and Gann, 2002</ref>), which we use to model the dynamics of individual nodes. Reconstruction of the edges is instead based on a non-parametric, tree-based method modelled on the state-of-the-art GENIE3 method (<ref type="bibr" target="#b20">Huynh-Thu et al., 2010</ref>). Adapting the tree-based method to the probabilistic setting is a novel challenge in machine learning and involves devising a novel decision function for learning the tree. Here, we introduce the 'jump tree', which uses the marginal likelihood of the node's dynamical model as a decision function. This choice has several benefits: it embeds the tree-based learning procedure in the probabilistic model, effectively grounding it as a greedy solution to structure learning in a large latent-variable model. Furthermore, the use of the marginal likelihood means our method inherits the ease with which side information can be incorporated in probabilistic models. Our experiments with both synthetic and real data show that Jump3 has good scalability and achieve competitive or better results than state-of-the-art alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model and methods</head><p>Here, we describe Jump3, a hybrid approach for GRN inference that is based on a formal dynamical model of the expression of each gene of the GRN and that employs a greedy, non-parametric, method for reconstructing the topology of the GRN. Exploiting time series of expression data, Jump3 assigns a confidence score to each putative regulatory link of the GRN. Note that in this article, we leave open the problem of choosing a threshold on the weights to obtain a practical network and focus on providing a ranking of the regulatory links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gene expression model</head><p>At the heart of our framework, we use the on/off model of gene expression (<ref type="bibr" target="#b28">Ptashne and Gann, 2002</ref>), a simple, yet plausible, model where the rate of transcription of a gene can vary between two levels depending on the activity state l of the promoter of the gene.</p><p>The expression x of a gene is modelled through the following stochastic differential equation (SDE):</p><formula>dx i ¼ ðA i l i ðtÞ þ b i À k i x i Þdt þ rdwðtÞ; (1)</formula><p>where subscript i refers to the ith target gene. Here, the promoter state l i ðtÞ is a binary variable (the promoter is either active or inactive), which depends on the expression levels of the transcription factors (TFs) that bind to the promoter (see<ref type="figure" target="#fig_0">Fig. 1</ref>). H i ¼ fA i ; b i ; k i g is the set of kinetic parameters. A i represents the efficiency of the promoter in recruiting polymerase when being in the active state, b i denotes the basal transcription rate and k i is the exponential decay constant of x i. The term rdwðtÞ represents a white noise-driving process with variance r 2. For a given trajectory of the promoter state, i.e. when we are given the states l i ðtÞ; 8t, the SDE (1) is linear and its solution x i ðtÞ is equivalent to a Gaussian Markov process, i.e. an Ornstein–Uhlenbeck (OU) process (<ref type="bibr" target="#b11">Gardiner, 1996</ref>). The mean m i ðtÞ and covariance c i ðt; t 0 Þ functions of this OU process are given by:</p><formula>m i ðtÞ ¼ x i ð0Þe Àkit þ A i ð t 0 e ÀkiðtÀsÞ l i ðsÞds þ b i k i ð1 À e Àkit Þ c i ðt; t 0 Þ ¼ r 2 2k i ðe ÀkijtÀt 0 j À e Àkiðtþt 0 Þ Þ</formula><p>Note that the covariance function contains two terms, one that is stationary (e ÀkijtÀt 0 j ) and one that is non-stationary (e Àkiðtþt 0 Þ ). The second term is typically much smaller than the first one and thus could be neglected in practice. We, however, assume that a perturbation is applied to the network at t ¼ 0, and we use the covariance function with its non-stationary term to take into account the initial transient behaviour of the network. Let us assume that the gene expression x i is observed with i.i.d. Gaussian noise at a finite number N of time points:</p><formula>^ x i;k ¼ x i ðt k Þ þ i;k ;</formula><p>i;k $ N ð0; s 2 i;k Þ; k ¼ 1;. .. ; N;</p><p>where s 2 i;k is the variance of the observation noise at time point t k. As a consequence, the observed expression levels follow a multivariate normal distribution:</p><formula>^ x i $ N ðm i ; C i þ D i Þ;</formula><p>where m i ¼ ½m i ðt 1 Þ; m i ðt 2 Þ;. .. ; m i ðt N Þ &gt; ; C i 2 R NÂN denotes the covariance matrix, with C i ½k; l ¼ c i ðt k ; t l Þ and D i 2 R NÂN is a diagonal matrix with the values s 2 i;k along the diagonal. One canL ¼ logpð^ x i Þ ¼ À N 2 logð2pÞ À 1 2 logjC i þ D i j À 1 2 ð^ x i À m i Þ &gt; ðC i þ D i Þ À1 ð^ x i À m i Þ:</p><formula>(2)</formula><p>Notice that this probabilistic formulation allows for a natural incorporation of replicate information by simply multiplying the likelihoods of replicate profiles. Within this context, our goal is, for each target gene i: 1. To identify the promoter state trajectory l i over the time interval ½0; t N  that maximizes the log likelihood L; 2. To identify the regulators of the target gene, i.e. the genes whose expression levels influence l i .</p><p>Both problems are jointly addressed by using a non-parametric approach described in the next section and illustrated in<ref type="figure" target="#fig_1">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Network reconstruction with jump trees</head><p>In our model, we make the assumption that the state of the promoter of a target gene i is a function of the expression levels of the genes that are direct regulators of gene i, i.e. the genes that are directly connected to gene i in the targeted network (<ref type="figure" target="#fig_0">Fig. 1</ref>). Denoting by x reg;i ðtÞ the vector containing the expression levels at time t of the regulators of gene i, we can write:</p><formula>l i ðtÞ ¼ f i ðx reg;i ðtÞÞ þ n t ; 8t;</formula><p>where n t is a random noise with zero mean. Recovering the regulatory links pointing to gene i thus amounts to finding the genes whose expression is predictive of the promoter state l i. To achieve this goal, we propose a procedure based on decision trees, which computes confidence scores w j;i ; 8j 6 ¼ i, measuring the importance of each gene j in the prediction of the state l i .</p><p>2.2.1 Decision trees with a latent output variable Tree-based methods have been applied successfully in the inference of GRNs (Huynh<ref type="bibr" target="#b20">Thu et al., 2010</ref>) and have appealing properties (<ref type="bibr" target="#b13">Geurts et al., 2009</ref>). First, they are non-parametric and hence do not make any assumption about the nature of the function f i , which can be non-linear. Another advantage of tree-based methods is their ability to detect multivariate interacting effects between features. This is a non-negligible advantage when inferring GRNs, since the regulation of gene expression is expected to be combinatorial, i.e. to involve several regulators. Tree-based methods are also essentially parameter-free, and since their computational complexity is at most linear in the number of features, they can deal with highdimensionality. The basic idea of our GRN inference procedure is to learn for each target gene i a model f i in the form of a decision tree (or an ensemble of decision trees), which predicts the promoter state l i at any time t from the expression levels of the candidate regulators at the same time t. However, standard tree-based methods cannot be applied here since the output l i ðtÞ is a latent variable. We therefore propose a new decision tree algorithm called 'jump tree'. (In stochastic process theory, the discrete variable l i ðtÞ is called a jump process. The term 'jump tree' thus refers to a tree that predicts such a jump process.) Briefly, a jump tree is constructed top-down using a greedy algorithm and partitions the set of observation time points into different subsets based on tests on the expression levels of the candidate regulators. Each terminal node (or leaf) of the jump tree then corresponds to a subset of time points at which l i is either 0 or 1. While in a standard decision tree the observations are split based on the minimization of the entropy of the output variable, in a jump tree the split is performed based on the maximization of the likelihood of the observations ^ x i .) is predicted from the jump tree model and an importance score is computed for each candidate regulator. The score of a candidate regulator j is used as weight for the regulatory link directed from gene j to gene i</p><p>More formally, the different steps for learning a jump tree predicting the latent variable l i are the following: 1. Initialization. Start with the simplest tree, which is only composed of one leaf. This leaf contains the whole set of N observation time points, and l i ðtÞ ¼ 0; 8t, with a corresponding log likelihood L. 2. Creation of a split node. Each iteration of the greedy algorithm consists in creating a split node from a leaf N and updating the promoter state trajectory and the likelihood. Given the current jump tree, the current promoter state trajectory l i and the current log likelihood L (obtained after the previous iteration), the set T N of observation time points of the leaf N is partitioned using the following procedure: a. Definition of a split. Given the observed expression ^ x j of a candidate regulator j 6 ¼ i and a threshold value c, a candidate promoter state trajectory l j;c i is obtained by setting:</p><formula>l j;c i ðt k Þ ¼ 0; if ^ x j ðt k Þ &lt; c; 1; if ^ x j ðt k Þ!c; (</formula><p>for each time point t k 2 T N. For the time points that do not belong to T N , the promoter states are kept the same:</p><formula>l j;c i ðt k Þ ¼ l i ðt k Þ; 8t k 6 2 T N :</formula><p>Between two observation time points t k and t kþ1 , the states l j;c i ðtÞ; t k &lt; t &lt; t kþ1 ; are merely set to the state obtained at time point t k. Note that the condition j 6 ¼ i can be relaxed to incorporate autoregulation; however, in our experiments we have kept it to improve identifiability. b. Evaluation of the split. The best candidate regulator j Ã and threshold c Ã are selected, i.e. those ones that yield the max3. Selection of the leaf. The order in which the leaves are turned into split nodes change the final value of the likelihood L. In our procedure, the jump tree is grown using a best-first strategy, i.e. at each iteration, steps 2a and 2b are repeated for each leaf of the current tree and the leaf that yields the highest maximum likelihood L Ã is selected. Step 2c is then applied to this leaf. This procedure is illustrated in<ref type="figure">Figure</ref>The jump tree pseudo-code can be found in Section 1 of the Supplementary Information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Ensemble of decision trees</head><p>A fully grown decision tree typically overfits the observed data, and significant improvements can be obtained with ensemble methods that average the predictions of several randomized trees, e.g. Random Forests (<ref type="bibr" target="#b5">Breiman, 2001</ref>) or Extra-Trees (<ref type="bibr" target="#b12">Geurts et al., 2006</ref>). In Jump3, we use the Extra-Trees procedure, which randomizes the test at each split node of a tree (in step 2 of the jump tree algorithm). Rather than testing all the possible combinations of candidate regulator j and threshold c, the best split is determined among K random splits, each obtained by randomly selecting one candidate regulator (without replacement) and a threshold value. The prediction of l i ðtÞ is then averaged over the different trees of the ensemble, yielding a probability for the promoter state to be active at time t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Importance measure</head><p>The learned tree-based model is used to derive an importance score for each candidate regulator, quantifying the relevance of that candidate regulator for the prediction of l i ðtÞ. The importance w j;i of a candidate regulator j is then used as weight for the putative regulatory link of the network that is directed from gene j to gene i. We propose a measure that, at each split node N , computes the increase of the likelihood due to the split:</p><formula>IðN Þ ¼ Lðl jÃ;cÃ i Þ À Lðl i Þ;</formula><p>where Lðl i Þ and Lðl jÃ;cÃ i Þ are the log likelihoods, respectively, obtained before and after the split on N. For a single tree, the overall importance w j;i of one candidate regulator j is then computed by summing the I values of all tree nodes where this regulator is used to split:</p><formula>w j;i ¼ X n k¼1 IðN k ÞgðN k ; jÞ;</formula><p>where n is the number of split nodes in the tree and N k denotes the kth split node. gðN k ; jÞ is function that is equal to one if the candidate regulator j is the one selected at node N k and zero otherwise. The candidate regulators that are not selected at all thus obtain an importance score of zero and those ones that are selected close to the root node of the tree typically obtain high scores. Importance measures can be easily extended to ensembles of trees, by simply averaging the importances scores over all the trees of the ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Regulatory link ranking</head><p>Each tree-based model f i yields a separate ranking of the genes as potential regulators of a target gene i in the form of importance scores w j;i. For a single tree, the sum of the importance scores of all candidate regulators is equal to the total increase of likelihood yielded by the tree:</p><formula>X j6 ¼i w j;i ¼ Lðl i Þ À Lð0Þ;</formula><p>where Lð0Þ is the initial log likelihood obtained with l i ðtÞ ¼ 0; 8t and Lðl i Þ is the final log likelihood obtained after the tree has been grown. As a consequence, if we trivially order the regulatory links according to the scores w j;i , this is likely to introduce a positive bias for the regulatory links that are directed towards the genes for which the overall likelihood increase is high. To avoid this bias, we normalize the importance scores obtained from each tree, so that they sum up to one:</p><formula>w j;i w j;i Lðl i Þ À Lð0Þ :</formula><p>Combining tree-based and dynamical systems</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Computational complexity</head><p>Since the value of the parameter k i is not optimized (see the details in the Supplementary Information), the computation of the covariance matrix C i and the inversion of the matrix C i þ D i , which are required for the computation of the log likelihood L, are done only once for each target gene. Therefore, the runtime complexity of Jump3 comes mainly from the optimization of the parameters A i and b i and the matrix multiplication in the last term of Equation (2), which are iteratively repeated during tree growing. Both parameter optimization and matrix multiplication have a complexity that is on the order of OðN 2 Þ, where N is the number of observations. Let us assume for simplicity that each tree that is learned contains S splits. It can be shown that the complexity for growing an ensemble of jump trees using the Extra-Trees procedure is OðTKS 2 N 2 Þ, where T is the number of trees and K is the number of randomly chosen candidate regulators when searching for the optimal split at a node. The complexity of Jump3 is thus OðpTKS 2 N 2 Þ since it requires to build an ensemble of trees for each of the p genes of the network. At worst, the complexity of the algorithm is thus quadratic with respect to the number of genes (when K ¼ p À 1) and OðN 4 Þ with respect to the number of observations (when S ¼ N À 1, i.e. each tree is fully developed with each leaf corresponding to one time point). However, this worst case scenario never happens in practice; S is usually much lower than N.<ref type="figure" target="#tab_1">Table 1</ref>gives an idea of the computing times, using our MATLAB implementation with K set to the number of candidate regulators and 100 trees per ensemble. These computing times were measured on an 8-GB RAM, 1.7 GHz Intel core i7 computer. Note that the large amount of time required to infer a DREAM4 size-100 network is due to the high number of observations. Such a high number is usually not encountered in real datasets, where the number of observations is typically much lower than the number of genes. The Jump3 algorithm can be easily parallelized over the p genes, as well as over the different trees of an ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Performance metrics</head><p>Jump3 provides a ranking of the regulatory links from the most confident to the least confident. To evaluate such a ranking independently of the choice of a specific threshold, we use the precision-recall (PR) curve and the area under this curve (AUPR). The PR curve plots, for different thresholds on the weights of the links, the proportion of true positives among all predictions (precision) versus the percentage of true positives that are retrieved (recall). A perfect ranking, i.e. a ranking where all the positives are located at the top A B Cof the list, yields an AUPR equal to one, while a random ranking results in an AUPR close to the proportion of positives (i.e. close to zero since the proportion of true links among all possible links in a network is usually very low).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We evaluated the proposed Jump3 procedure on several in silico networks as well as one synthetic network (IRMA). As a case study, we applied the procedure to expression data from macrophages treated with interferon gamma (IFNc), to identify IFNc-activated regulatory interactions. In all our experiments, ensembles of 100 trees were grown and the main parameter K of the Extra-Trees was set to the number of input candidate regulators. For the in silico and IRMA networks, K ¼ p À 1, where p is the number of genes in the network and K ¼ 40 in the case of the IFNc network (see later for the description of that experiment).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">In silico networks</head><p>We evaluated Jump3 on the networks of the DREAM4 In Silico Network challenge (<ref type="bibr" target="#b22">Marbach et al., 2012;</ref><ref type="bibr" target="#b27">Prill et al., 2010</ref>), which are 5 networks of 10 genes and 5 networks of 100 genes. For each network topology, two types of simulated expression data were used:</p><p>@BULLET Toy data: we simulated the expression data using the on/off model based on Equation (1). A network perturbation was simulated through a switch in the promoter state of some genes and given a set of parameters H i ¼ fA i ; b i ; k i g for each gene i, the model was simulated to produce continuous time series for both promoter states and gene expressions. Noisy observations at discrete time points were obtained from the expression time series by adding i.i.d. Gaussian noise. The toy data are available in the Supplementary Material. @BULLET DREAM4 data: we applied Jump3 to the time series data that was provided in the context of the DREAM4 challenge. Each time series experiment consisted in strongly increasing or decreasing the initial expression of about one-third of the genes, thereby simulating a physical or chemical perturbation. The perturbation was applied to the network at time t ¼ 0 and was removed after 10 time points, making the system return to its original state.</p><p>For each network of 10 (respectively 100) genes and each simulation type, noisy observations were sampled at 21 time points under 5 (respectively 10) different network perturbations, for a total of 105 (respectively 210) observations per gene. First, we checked the quality of the data modelling that is obtained with Jump3. Results on the toy and DREAM4 data are, respectively, shown in<ref type="figure" target="#fig_5">Figure 4</ref>and Supplementary<ref type="figure" target="#fig_0">Figure S1</ref>(in the Supplementary Material), for one gene of a size-100 network. We notice from a qualitative point of view that Jump3 returns a good prediction of the promoter state and that the on/off model has sufficient flexibility to provide a good fit of the gene expression, as shown before (<ref type="bibr" target="#b24">Ocone et al., 2013;</ref><ref type="bibr" target="#b25">Opper et al., 2010</ref>). Next, we evaluated the performance of the method in terms of network reconstruction and we compared it to other existing network inference procedures: two model-free methods, which are time-lagged variants of GENIE3 (<ref type="bibr" target="#b19">Huynh-Thu, 2012</ref>) and CLR (<ref type="bibr" target="#b10">Faith et al., 2007</ref>), respectively; two model-based methods, namely Inferelator (<ref type="bibr" target="#b18">Greenfield et al., 2010</ref>) and TSNI (<ref type="bibr" target="#b2">Bansal et al., 2006</ref>), and G1DBN (<ref type="bibr">Lèbre, 2009</ref>), a method based on dynamic Bayesian networks. For TSNI, a separate network was inferred for each perturbation, and a consensus network was computed as the average of the different inferred networks. For all the remaining methods, networks were inferred using the complete dataset (all perturbations simultaneously). GENIE3 was applied with the Extra-Trees, the parameter K set to the number of candidate regulators, and ensembles of 100 trees. TSNI was used with two principal components. The other methods were run using the default values of the parameters. AUPR values obtained for the size-100 networks are shown in Tables 2 and 3, for the toy and DREAM4 data, respectively. Results on the size-10 networks are shown in Supplementary Table S2. In the case of the toy data, Jump3 yields the highest AUPR for each network. As expected, its performance decreases when the networks are inferred from the DREAM4 data, due to the mismatch between the on/off model and the one used to simulate the data. For the small networks of 10 genes, CLR, Inferelator and G1DBN have the best performances, without a clear winner. Jump3 seems robust when inferring large networks, since it outperforms the other methods on the size-100 networks. Note that the official best methods of the DREAM4 challenge obtained higher AUPR levels because they used additional interventional (knockout and knockdown) data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The synthetic IRMA network</head><p>The different GRN inference methods were applied to reconstruct the IRMA (In vivo Reverse-engineering and Modeling Assessment) network, a synthetic GRN embedded in the budding yeast Saccharomyces cerevisiae (<ref type="bibr" target="#b6">Cantone et al., 2009</ref>). This network is composed of 5 genes and 6 regulatory interactions and can be activated and deactivated in the presence of galactose and glucose, respectively. The expression levels of the five genes were measured using quantitative RT-PCR during the transition from glucose to galactose ('switch-on' time series of 16 time points), as well as during the transition from galactose to glucose ('switch-off' time series of 21 time points). As shown in<ref type="figure">Table 4</ref>, Jump3 is competitive with the two modelbased methods (Inferelator and TSNI) when inferring the network from the switch-on data. In the case of the switch-off data, Jump3 yields the best performance. Notice that while the model-free methods (GENIE3 and CLR) typically perform better than the modelbased methods on the in silico networks, the opposite is observed here on the IRMA network. This shows that model-based methods can be very powerful on very small networks, but their performances rapidly degrade as the number of genes in the network increases. Promoter state predictions and gene expression fits obtained with Jump3 are shown in Supplementary Figures S2 and S3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The IFNc network</head><p>Finally, we applied Jump3 to gene expression data from murine bone marrow-derived macrophages (<ref type="bibr" target="#b4">Blanc et al., 2011</ref>). The macrophages were treated with interferon gamma (IFNc) and gene expression levels were measured at 25 half-hourly time points over 12 h, using Agilent microarray platform. We focused our analysis on the 1000 genes whose expression vary the most across the time series. Forty of these genes were classified as TFs by<ref type="bibr" target="#b14">Gray et al. (2004)</ref>, and we applied Jump3, GENIE3 and CLR to identify regulatory interactions between these 40 TFs and all the 1000 genes. The 500 top-ranked regulatory links predicted by each method are shown in<ref type="figure">Figure 5A</ref>and supplementary<ref type="figure" target="#fig_5">Figure S4</ref>. (Cytoscape files for these three predicted IFNc networks are also available in the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Combining tree-based and dynamical systems</head><p>Supplementary Material.) As can be seen in these figures, the predicted networks are highly modular with a few TFs acting as hubs and regulating a large number of target genes (although the modules of the CLR networks are less distinct).<ref type="figure">Figure 5B</ref>shows the (empirical) node degree distribution of the Jump3 network. Although the networks of GENIE3 and CLR share a relatively large number of edges, Jump3 yields very different predictions (<ref type="figure">Fig. 5C</ref>), indicating that the addition of a dynamical model significantly alters the networks found. Several of the hub TFs (defined as TFs predicted as having &gt;10 targets and listed in<ref type="figure">Table 5</ref>) have biologically relevant annotations: apart from the interferon responsive TFs Irf1 and Irf7, we find Hoxc6 (associated with cytomegalovirus infection) and cancer-associated TFs such as Egr1, Bmyc and Pbx2, reinforcing the deep connections of the immune response with cancer (<ref type="bibr" target="#b8">de Visser et al., 2006</ref>). Quantitative evaluations of these results in terms of enrichment for known regulatory links are hampered by the absence of large-scale gold standards for human regulatory networks. The widely used TRANSFAC database (http://www.gene-regulation. com/pub/databases.html) only reports information for a handful of TFs included in this analysis, and the number of known targets among the selected 1000 genes is usually very low (one or two at maximum), precluding a systematic enrichment analysis. The human homologues of three hub TFs (Egr1, Bmyc and Irf1) were assayed using ChIP-Seq by the ENCODE consortium (The ENCODE Project Consortium, 2012), providing a potentially much larger number of putative targets. An analysis of this data is reported in the Section 2 of the Supplementary Material and shows considerably higher recall for Jump3 (compared with GENIE3 and CLR) and a higher precision for two of the three TFs. Nevertheless, these numbers (only three TFs) are still very small for an enrichment analysis, which is in any case weakened by the data coming from a different organism in different experimental conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Elucidating the topology of GRNs is a fundamental step towards our understanding of how a cell or an organism can respond to its environment. Despite years of concerted efforts by the computational biology community, this task is still far from complete and a unified framework for GRN inference remains elusive. Here, we presented Jump3, a novel approach to GRN inference, which attempts to combine the interpretability of model-based methods with the scalability of greedy, model-free methods, thus bridging the gap between the two main classes of GRN inference approaches. Experiments on simulated and synthetic data show that Jump3 is always competitive and often outperforms state-of-the-art GRN inference procedures, while an experiment on a real dataset shows its potential for biologically meaningful hypothesis generation. It has good scalability with respect to the number of genes and keeps its good performance when inferring large networks. From a modelling point of view, results show that Jump3 yields good predictions of promoter states and that, despite its simplicity, the on/off model is flexible enough to allow good fits of the data. While we believe that Jump3 is a step in the right direction, we also acknowledge that the complexity of gene regulation will pose a strict limit to the potential of GRN inference from expression dataThe highest AUPR is shown in bold for each network.The highest AUPR is shown in bold for each network.The highest AUPR is shown in bold in each case.</p><p>alone. A first limitation comes from the assumption that the messenger RNA level can be used as a proxy for the protein activity, which is often not correct (<ref type="bibr" target="#b30">Vogel and Marcotte, 2012</ref>). A simple improvement of Jump3 would thus be the exploitation of protein data, which are becoming less rare gradually, to predict the target promoter states. Another important direction is the integration in GRN inference algorithms of complementary data, such as microRNA expression, chromatin, protein-protein interactions or microbiomes and some promising initial steps in this direction are being taken (e.g.<ref type="bibr" target="#b9">Ellwanger et al., 2014;</ref><ref type="bibr" target="#b17">Greenfield et al., 2013</ref>). The probabilistic generative model underlying Jump3 would allow the incorporation of additional information in a natural way via a modification of the likelihood function, while the non-parametric tree-based approach would ensure the scalability of the whole procedure. Using the method on large networks with relatively few observations may incur co-linearity problems, i.e. genes that have very similar profiles leading to confounding factors in the inference. A simple fix to this would be to pre-process the data with some clustering algorithm; this would further increase scalability, at the cost of some interpretability. Ultimately, a major limitation for many studies in computational biology is the lack of systematic, large-scale gold standards on which to evaluate the models; this generalized fact reinforces the need for a tight coupling between experimental and theoretical research, and we hope that inference methods such as Jump3 could be useful in prioritizing experimental designs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Example of GRN. Circles represent the observed gene expressions, and squares represent the latent promoter states. Thick arrows model the promoter activations and show the network topology</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. The Jump3 framework. For each target gene i ¼ 1;. .. ; p, a function f i in the form of an ensemble of jump trees is learned from the time series of expression data. The trajectory of the state of the promoter of gene i (l i ) is predicted from the jump tree model and an importance score is computed for each candidate regulator. The score of a candidate regulator j is used as weight for the regulatory link directed from gene j to gene i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Decision and update. If the likelihood is increased, i.e. L Ã &gt; L, then: @BULLET Replace the leaf N with a split node containing the optimal test 'x jÃ &lt; c Ã '; @BULLET Split T N into two subsets T 0 and T 1 according to this test; @BULLET The child nodes of the new split node are two leaves, containing, respectively, T 0 and T 1 ; @BULLET Update the promoter state trajectory: l i l jÃ;cÃ i ; @BULLET Update the log likelihood: L L Ã :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3.4.</head><figDesc>Stop. The algorithm stops when L cannot be increased anymore, i.e. when L Ã L for each leaf of the current tree. The algorithm then outputs the current jump tree and the current trajectory of the promoter state l i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Growing a jump tree predicting the state of the promoter of gene 1 (l 1 ). (A) Each iteration of the jump tree algorithm results in a new tree and a new trajectory l 1 (dashed line) yielding a likelihood L. In this example, the current tree splits the set of observation time points in two subsets T A and T B , each one corresponding to a leaf of the tree. The plot also shows the posterior mean m 1 of the expression of gene 1 (solid line), with confidence intervals (shaded area), and the observed expression levels of gene 1 (dots). (B) For each leaf of the current tree, the optimal split of the corresponding set of time points is identified. (C) The leaf for which the optimal split yields the highest likelihood is replaced with a split node</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. Modelling results on the toy data, for one target gene. (A) Predicted promoter state l i ðtÞ (solid line) versus true state (dashed line). (B) Posterior mean of gene expression x i ðtÞ, with confidence intervals. Points show observed expression ^ x i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Running times for varying network sizes and numbers of observations</figDesc><table>Network 
No. Genes 
No. Observations 
Time 

DREAM4 
10 
105 
3 min 
DREAM4 
100 
210 
48 h 
IFNc 
1000 
25 
4 h </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2.</figDesc><table>AUPRs for the size-100 networks (toy data) 

Net1 
Net2 
Net3 
Net4 
Net5 

Jump3 
0.342 
0.179 
0.299 
0.275 
0.264 
GENIE3-lag 
0.121 
0.117 
0.125 
0.103 
0.105 
CLR-lag 
0.092 
0.084 
0.099 
0.088 
0.078 
Inferelator 
0.063 
0.071 
0.075 
0.073 
0.062 
TSNI 
0.017 
0.022 
0.017 
0.023 
0.021 
G1DBN 
0.106 
0.064 
0.108 
0.126 
0.114 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 3.</figDesc><table>AUPRs for the size-100 networks (DREAM4 data) 

Net1 
Net2 
Net3 
Net4 
Net5 

Jump3 
0.270 
0.110 
0.200 
0.180 
0.174 
GENIE3-lag 
0.228 
0.096 
0.230 
0.157 
0.168 
CLR-lag 
0.179 
0.109 
0.238 
0.154 
0.163 
Inferelator 
0.126 
0.101 
0.198 
0.147 
0.148 
TSNI 
0.050 
0.055 
0.041 
0.036 
0.030 
G1DBN 
0.089 
0.055 
0.155 
0.153 
0.117 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 4.</figDesc><table>AUPRs for the IRMA network 

Switch-on 
Switch-off 

Jump3 
0.685 
0.682 
GENIE3-lag 
0.620 
0.347 
CLR-lag 
0.423 
0.372 
Inferelator 
0.718 
0.649 
TSNI 
0.706 
0.511 
G1DBN 
0.600 
0.313 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">V.A.Huynh-Thu and G.Sanguinetti at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Peter Ghazal and Thorsten Forster for useful discussions on interferon gamma biology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was supported by the European Research Council<ref type="bibr">[</ref></p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Alberts</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular Biology of the Cell. Garland Science</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title level="m" type="main">An Introduction to Systems Biology: Design Principles of Biological Circuits</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Alon</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Inference of gene regulatory networks and compound mode of action from time course gene expression profiles</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="815" to="822" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">How to infer gene networks from expression profiles</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">78</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Host defense against viral infection involves interferon mediated down-regulation of sterol biosynthesis</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Blanc</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1000598</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A yeast synthetic network for in vivo assessment of reverse-engineering and modeling approaches</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Cantone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="172" to="181" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Advantages and limitations of current network inference methods</title>
		<author>
			<persName>
				<forename type="first">De</forename>
				<surname>Smet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Marchal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Microbiol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="717" to="746" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Paradoxical roles of the immune system during cancer development</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">E</forename>
				<surname>De Visser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Cancer</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="24" to="37" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale modeling of condition-specific gene regulatory networks by information integration and inference</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">C</forename>
				<surname>Ellwanger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Large-scale mapping and validation of Escherichia coli transcriptional regulation from a compendium of expression profiles</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Faith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">8</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">Handbook of Stochastic Methods</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">W</forename>
				<surname>Gardiner</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Extremely randomized trees</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Geurts</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="3" to="42" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Supervised learning with decision tree-based methods in computational and systems biology</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Geurts</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. BioSyst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1593" to="1605" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Mouse brain organization revealed through direct genome-scale TF expression analysis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Gray</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="page" from="2255" to="2257" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">(A) IFNc network predicted by Jump3. The network was drawn using Cytoscape</title>
		<author>
			<persName>
				<surname>Figwang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012). (B) Node degree distribution of the network in (A)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Hubs of the predicted IFNc networks Jump3 Bmyc (31 Sox13 (58) GENIE3-lag Dlx4</title>
	</analytic>
	<monogr>
		<title level="m">Irf1 (30) Irf7 (12), Mrg2 (22), Myod1 (21), Pbx2 (13) Tcfec (15) CLR-lag Dlx4 Tcfec</title>
		<editor>Jump3, GENIE3 and CLR Table 5</editor>
		<imprint>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note>For. each TF, the number of predicted targets is indicated between parenthesis</note>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Robust data-driven incorporation of prior knowledge into the inference of dynamic regulatory networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Greenfield</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1060" to="1067" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">DREAM4: combining genetic and dynamic information to identify biological networks and dynamical models</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Greenfield</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">13397</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Machine learning-based feature ranking: statistical interpretation and gene network inference</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">A</forename>
				<surname>Huynh-Thu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Inferring regulatory networks from expression data using tree-based methods</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">A</forename>
				<surname>Huynh-Thu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12776</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Inferring dynamic bayesian networks with low order independencies</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lèbre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Article. 9</note>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Wisdom of crowds for robust gene network inference</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Marbach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="796" to="804" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">ARACNE: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Margolin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Hybrid regulatory models: a statistically tractable approach to model regulatory network dynamics</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ocone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="910" to="916" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Approximate inference in continuous time Gaussianjump processes</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Opper</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Lafferty,J.D. et al.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1831" to="1839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">How to infer gene networks from expression profiles, revisited. Interface Focus</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">A</forename>
				<surname>Penfold</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">L</forename>
				<surname>Wild</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="857" to="870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards a rigorous assessment of systems biology models: the DREAM3 challenges</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
				<surname>Prill</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9202</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<monogr>
		<title level="m" type="main">Genes and Signals. Cold Harbor Spring Laboratory Press</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ptashne</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gann</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">An integrated encyclopedia of DNA elements in the human genome</title>
	</analytic>
	<monogr>
		<title level="m">The ENCODE Project Consortium</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="57" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Insights into the regulation of protein abundance from proteomic and transcriptomic analyses</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Vogel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">M</forename>
				<surname>Marcotte</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="227" to="232" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">A travel guide to cytoscape plugins</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">L</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1069" to="1076" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>