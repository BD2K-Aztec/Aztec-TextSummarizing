
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Corpus Domain Effects on Distributional Semantic Modeling of Medical Terms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Serguei</forename>
								<forename type="middle">V S</forename>
								<surname>Pakhomov</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">College of Pharmacy</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>308 Harvard St. SE</addrLine>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Greg</forename>
								<surname>Finley</surname>
							</persName>
							<email>gpfinley@umn.edu, rmcewan@umn.edu,</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for Health Informatics</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>505 Essex Street SE</addrLine>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Reed</forename>
								<surname>Mcewan</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Health Informatics</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>505 Essex Street SE</addrLine>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yan</forename>
								<surname>Wang</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Institute for Health Informatics</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>505 Essex Street SE</addrLine>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Genevieve</forename>
								<forename type="middle">B</forename>
								<surname>Melton</surname>
							</persName>
							<email>gmelton@umn.edu.</email>
							<affiliation key="aff1">
								<orgName type="department">Institute for Health Informatics</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<addrLine>505 Essex Street SE</addrLine>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Corpus Domain Effects on Distributional Semantic Modeling of Medical Terms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Subject Section *To whom correspondence should be addressed. Contact: pakh0002@umn.edu,</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Automatically quantifying semantic similarity and relatedness between clinical terms is an important aspect of text mining from electronic health records, which are increasingly recognized as valuable sources of phenotypic information for clinical genomics and bioinformatics research. A key obstacle to development of semantic relatedness measures is the limited availability of large quantities of clinical text to researchers and developers outside of major medical centers. Text from general English and biomedical literature are freely available; however, their validity as a substitute for clinical domain to represent semantics of clinical terms remains to be demonstrated. Results: We constructed neural network representations of clinical terms found in a publicly available benchmark dataset manually labeled for semantic similarity and relatedness. Similarity and related-ness measures computed from text corpora in three domains (Clinical Notes, PubMed Central articles , and Wikipedia) were compared using the benchmark as reference. We found that measures computed from full text of biomedical articles in PubMed Central repository (rho = 0.62 for similarity and 0.58 for relatedness) are on par with measures computed from clinical reports (rho = 0.60 for similarity and 0.57 for relatedness). We also evaluated the use of neural network based relatedness measures for query expansion in a clinical document retrieval task and a biomedical term word sense disambiguation task. We found that, with some limitations, biomedical articles may be used in lieu of clinical reports to represent the semantics of clinical terms and that distributional semantic methods are useful for clinical and biomedical natural language processing applications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated approaches for representing the semantic content of terms and similarity and relatedness between them have been widely used in a number of Natural Language Processing (NLP) applications in both general English (<ref type="bibr" target="#b2">Budanitsky &amp; Hirst, 2006;</ref><ref type="bibr" target="#b11">Landauer, 2006;</ref><ref type="bibr" target="#b30">Resnik,</ref>knowledge discovery, among many other (see<ref type="bibr" target="#b4">Cohen and Widdows (2009)</ref>for a comprehensive review). In the general English domain, distributional semantic approaches to measuring semantic similarity and relatedness have been quite successful, achieving correlations in the 70's and 80's with human judgments (<ref type="bibr" target="#b6">Faruqui &amp; Dyer, 2014</ref>). In the biomedical domain, the problem of representing lexical semantics of medical terms in such a way as to match human judgments of semantic similarity and relatedness between them has proven to be more challenging. State of the art approaches developed so far for computing semantic similarity and relatedness achieve only modest agreement with human judgments. This applies to both distributional methods (i.e., knowledge-free) and those based on relations in manually constructed ontologies such as WordNet and the Unified Medical Language System (i.e., knowledge-based). For example, Garla and Brant (2012) reported on a large systematic investigation of a wide range of knowledge-based and knowledge-free approaches to computing semantic relatedness and similarity and found that knowledge-based approaches augmented with information content obtained from corpora of text (e.g.,<ref type="bibr" target="#b12">Leacock and Chodorow (1998)</ref>) outperformed distributional approaches based on first and second order semantic vectors (e.g., Lin (1998) and Patwardhan and<ref type="bibr" target="#b28">Pedersen (2006)</ref>). The authors used a number of publicly available benchmarks including the University of Minnesota Semantic Relatedness Standard (<ref type="bibr" target="#b26">Pakhomov et al., 2010</ref>) containing the largest number and diversity of medical term pairs to date. In terms of agreement with human ratings and the UMNSRS benchmark, the best correlations range between 0.30 and 0.46 (Spearman rank correlation).<ref type="bibr" target="#b16">Liu et al. (Liu et al., 2012</ref>) reported similar correlations between the output of the second-order context vectors (<ref type="bibr" target="#b28">Patwardhan &amp; Pedersen, 2006</ref>) and a subset of the UMNSRS benchmark.</p><p>Another study by<ref type="bibr" target="#b31">Sajadi et al. (2014)</ref>that also included the UMNSRS benchmark, among others, confirmed Garla and Brant's (2012) findings demonstrating that their knowledge-based method based on the Wikipedia network (HITS-sim) achieved significantly higher correlations with human ratings than distributional methods. The Spearman rank correlations for the UMNSRS benchmark were 0.51 and 0.58 for semantic relatedness and semantic similarity judgments, respectively. The distributional semantic methods evaluated in<ref type="bibr" target="#b31">Sajadi et al. (2014)</ref>included word2vec, a neural network based mechanism for semantic representation based on word embeddings that was originally proposed by<ref type="bibr" target="#b23">Mikolov et al. (2013</ref><ref type="bibr" target="#b31">). Sajadi et al. (2014</ref>trained a skip-gram vector representation of medical terms using word2vec on the OHSUMED corpus (a collection of 348,566 biomedical research articles). This approach achieved a correlation of 0.39 on both relatedness and similarity human judgments with the UMNSRS benchmark. A similar study by<ref type="bibr" target="#b24">Muneeb et al. (2015)</ref>also examined word2vec semantic representations derived from the PubMed Central Open Access (PMC) corpus. Similarly to the study by<ref type="bibr" target="#b31">Sajadi et al. (2014</ref><ref type="bibr" target="#b24">), Muneeb et al. (2015</ref>tested their approach on the UMNSRS benchmark and reported Spearman rank correlations of 0.45 and 0.52 for semantic relatedness and semantic similarity judgments, respectively. These previous studies targeted overall performance of distributional semantic and other approaches and did not examine the performance on subsets of the UMNSRS dataset consisting of pairs of different semantic types. We hypothesize that one of the reasons the UMNSRS benchmark has been difficult to approximate with automated approaches (particularly with knowledge-free distributional approaches) is because it consists of a large number of clinical concepts from a variety of semantic types (disorders, symptoms, and drugs). Thus, in order to model human judgments of semantic relatedness and similarity of this benchmark using distributional methods one may need to use very large amounts of textual data from a corpus that closely matches the domain of clinical language represented by this benchmark. Previous studies tended to rely on relatively small corpora that are from a closely related but not perfectly matched domains (e.g., biomedical articles). One exception to this was a study by<ref type="bibr" target="#b29">Pedersen et al. (2007)</ref>that used Mayo Clinic clinical notes as a source of training data; however, while that study had a good domain match, the size of the corpus was relatively modest by current standards (~232M tokens). The objective of the current study is to examine the effect of corpus size and sublanguage domain match on the agreement between relatedness and similarity measures produced by the popular and highly efficient distributional semantic method (word2vec) and human judgments in the UMNSRS benchmark dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Reference standard</head><p>In this study, we used a previously developed public reference standard – University of Minnesota Semantic Relatedness Standard (UMNSRS). This reference standard consists of over 550 pairs of medical terms mapped to concept unique identifiers in the Unified Medical Language System (UMLS). By design, only single word terms had been selected for this reference standard to represent SYMPTOMS and DISORDERS; however, the selection of DRUGS was not restricted to single word terms and thus the reference contains several multi-word terms (e.g, " Vitamin K " , " folic acid " , " fish oil " , etc.). Each pair of terms was assessed by 4 medical residents and scored with respect to the degree to which the terms were similar or related to each other using a continuous scale. Thus UMNSRS consists of two subsetsone contains averaged semantic similarity ratings by 4 medical residents (UMNSRS-Similarity) and the other contains semantic relatedness ratings by a different set of 4 medical residents (UMNSRS-Relatedness). UMNSRS-Similarity contains a total of 566 pairs of terms and UMNSRS-Relatedness contains 587 pairs. Each of these datasets was designed to test for similarity and relatedness between medical concepts of several semantic types. Thus, UMNSRS contains 6 semantic categories: DISORDER-DISORDER, SYMPTOM-SYMPTOM, DRUGDRUG, DISORDER-DRUG, DISORDER-SYMPTOM, and SYMPTOM-DRUG pairs. Further details on this reference standard are reported elsewhere (<ref type="bibr" target="#b26">Pakhomov et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Text corpora</head><p>We focused on three sublanguage domains – clinical, biomedical, and general English. The clinical domain was represented by a corpus of clinical notes (CLINICAL) from the Fairview Health System documenting of 5 years worth of clinical encounters between 2010 and 2014, inclusively. Since Fairview Health System uses Epic Electronic Health Records (EHR) system, we used its secondary data use tool called Clarity to extract the text of clinical reports from the Epic database. We constructed several sets of smaller corpora from this dataset in order to test the effect of corpus size on computation of semantic relatedness and similarity. To this end, we split the clinical notes repository by year and created four additional corpora that spanned the following years: 2014, 2013-4, 2012-4, and 2011-4. The biomedical domain was represented by the PMC dataset consisting of full-length biomedical articles (available as of September 2015). The general English domain was represented by all WIKIPEDIA articles (available as of September 2015). All text data were pre-processed minimally by removing non-alphanumeric characters and lowercasing the rest. No further alterations including morphological normalization or stop word removal were done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Modifications to the reference standard</head><p>For the present study, we modified the UMNSRS dataset in order to account for the differences in vocabulary in the corpora that were used to obtain the contexts for medical terms. Generally, the number of terms from UMNSRS that we could not find in the three corpora was low. For example, the list of terms from UMNSRS that were not found in the CLINICAL-ALL corpus is provided in the Appendix A. We had to discard 40 pairs of words from the UMN-Similarity and 43 pairs from the UMNSRS-Relatedness subsets based on the CLINICAL corpus. These numbers were similar for PMC – 39 pairs discarded based on UMNSRS-Similarity and 40 based on UMNSRS-Relatedness. Substantially more pairs had to be discarded with Wikipedia – 108 based on UMNSRS-Similarity and 119 based on UMNSRS-Relatedness. We also had to modify UMNSRS in order to account for some of the term pairs having been presented to human raters more than once. These repeated pairs were included in the reference standard for estimating internal rater consistency; however, we wanted to exclude them from calculating correlations with automated measures as they are not independent and can potentially artificially affect correlations. As illustrated in<ref type="figure" target="#fig_0">Figure 1</ref>, combining exclusions of word pairs from the UMNSRS-Similarity and UMNSRS-Relatedness datasets based on all three corpora resulted in the overall reduction from 566 to 449 pairs in the UMNSRS-Similarity and from 588 to 458 pairs in the UMNSRS-Relatedness datasets 1. 1 Available at http://rxinformatics.umn.edu/SemanticRelatednessResources.html</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Computation of semantic relatedness and testing</head><p>We used word2vec toolkit developed by<ref type="bibr" target="#b23">Mikolov et al. (2013)</ref>to generate word embeddings for each word in the three corpora. Default parameters were used. We trained a bag-of-words (CBOW) model for word embeddings with a window size set to 8 words. The dimensionality of vectors representing word embeddings was set to 200. Prior work comparing CBOW to the skip-gram representations is inconclusive and suggests that superiority of the representations may be task-dependent. While<ref type="bibr" target="#b23">Mikolov et al. (2013) and</ref><ref type="bibr" target="#b14">Levy et al. (2015)</ref>show that skip-gram representations are superior to CBOW,<ref type="bibr" target="#b0">Baroni et al. (2014)</ref>show the opposite, and<ref type="bibr" target="#b24">Muneeb et al. (2015)</ref>show that the skip-gram representation outperforms CBOW on semantic similarity tasks but the two are equivalent on semantic relatedness tasks. Due to lack of clear evidence that one representation is superior to the other and since the objective of the current study is not to optimize word2vec performance, we arbitrarily decided to use the CBOW representation as the basis for all experiments. During testing, we extracted word vectors for each term pair in the reference standard and computed the cosine between them in a standard fashion using their dot product and magnitude. The cosines computed this way for each term pair in the reference standard were then compared to manual similarity and relatedness judgments using Spearman rank correlation in each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Evaluation on a document retrieval task</head><p>In order to evaluate the word2vec based semantic relatedness measures on a task of direct relevance to clinical NLP and clinical research, we defined a document retrieval task in which we searched a collection of EHR clinical notes for all clinical encounters between January 1, 2015 and October 1, 2015 in the Fairview Health Services for patients diagnosed with heart failure. This particular task was motivated by prior research showing advantages of using unstructured text of EHR to identify candidate patients for participation in a cohort research study of heart failure in the community (<ref type="bibr" target="#b3">Bursi et al., 2006</ref>). The advantages included better concurrency and completeness of case ascertainment for potential inclusion into the study as compared to using diagnostic codes.</p><p>As part of evaluation for the current study, we defined a similar document retrieval task in which we indexed all EHR records from the Fairview Health Services using Elasticsearch technology with the default Snowball analyzer. The index was then queried using the Patient Information Extraction for Research (PIER) system (<ref type="bibr" target="#b20">McEwan et al., 2016)</ref>with a disjunction of the following terms: " heart failure " OR " HF " OR " CHF. " The results of this query were parsed to extract the set of unique patient IDs that formed the baseline for subsequent comparisons.</p><p>The search query was then augmented with additional search terms obtained from a word2vec model that was constructed from two data sources: CLINICAL-ALL and PMC corpora. The WIKIPEDIA corpus was excluded from further evaluations based on the results of crossdomain comparisons on the UMNSRS reference standard. Since this subsequent validation task was not constrained by the UMNSRS reference standard having only single word terms, we constructed these models by using multi-word expressions (up to 4 word sequences). This was achieved by taking two pre-processing passes over the corpora with the word2phrase tool to construct a bigrams-of-bigrams corpus (the bigram threshold was set to 200 on the first pass and 100 on the second pass),followed by training a model with word2vec using the same default parameters as described in the previous section. We took the top 5, 10, 20 and 40 most semantically closely related words to the term " heart failure " as defined by the cosine distance between their semantic vectors computed with word2vec. An expanded query was then defined that included the search terms used in the baseline query and the top 5, 10, 20 or 40 semantically related terms, thus forming four points of comparison with the baseline.</p><p>In order to control for both the baseline and semantically expanded queries returning results not relevant to heart failure diagnosis due to language use phenomena such as negation, uncertainty and family history contexts, we also ran a query on the structured part of the EHR for ICD9 billing code 428.x (heart failure). The choice of the time period betweenThe use of ICD-9 code 428.x as a primary or secondary diagnosis has been shown in multiple studies to have high precision (reported positive predictive value ~ 87%) but relatively low recall (reported sensitivity ~ 60%) for identification of patients with heart failure (see (<ref type="bibr" target="#b19">McCormick, Lacaille, Bhole, &amp; Avina-Zubieta, 2014</ref>) for review). Thus, we focused on measuring the value added by the semantically expanded queries in terms of improvements in recall-additional patients that this query found as compared to baseline. However, while querying the text of EHR to identify patients with heart failure has been shown to have high sensitivity (82% recall), it also had low precision (49% positive predictive value) (<ref type="bibr" target="#b27">Pakhomov et al., 2007</ref>). Therefore, for the current validation study, we focused on comparing the recall of both the baseline and semantically expanded queries of patients that also had an ICD-9 code of 428.x in their EHR. The disadvantage of restricting the evaluation of recall to patients with code 428 is that we will not be able to estimate how many more valid patients both the baseline and semantically expanded queries can identify. However, the advantage of this approach is the certainty afforded by the high precision of the reference standard, which is more important for comparisons of recall between the expanded and baseline queries relative to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Evaluation on a word sense disambiguation task</head><p>We also investigated the use of word embeddings as semantic representations for word sense disambiguation (WSD) in a biomedical NLP context. WSD methods that rely on distributional semantics involve automatically choosing the most context-appropriate sense of a word by maximizing the similarity of the sense and the context. With these approaches, a basic representation of the semantic content of the senses and contexts takes the form of semantic vectors containing co-occurrence counts. For example,<ref type="bibr" target="#b21">McInnes et al. (2011)</ref>introduce a modification of the Lesk algorithm for performing WSD using machine-readable dictionaries. They assign each sense an expanded definition by concatenating the definitions of the sense and of related concepts in the UMLS. They represent senses as second-order co-occurrence vectors by calculating the centroid of word co-occurrence vectors for each word in the extended definition. For each test example, a context vector is calculated similarly, by averaging co-occurrence vectors of the words within a fixed window size (six words) around the ambiguous term, and the sense vector with highest cosine similarity to the context vector is chosen.</p><p>In the current study we compared this second-order co-occurrence vector based approach to an alternative approach in which co-occurrence vectors are replaced with word embeddings. Co-occurrence vectors were derived separately from the CLINICAL-ALL and PMC corpora. Word embeddings were also generated for each corpus as described in section 2.4.</p><p>We implemented these two approaches to word sense representation in a knowledge-based WSD system similar to that employed by McInnes et al. (2011). The main differences from the latter consisted of smoothing in the form of taking a square root of all co-occurrence counts in order to emphasize rare words, and reducing the weight of the words occurring in the extended definitions by 50% to give more weight to the words in the primary definitions of concepts. The two approaches to word sense representation implemented in our WSD system were evaluated on 203 biomedical terms and acronyms contained in the publicly available National Library of Medicine MSH-WSD dataset (see Jimeno-Yepes, McInnes, &amp; Aronson, 2011 for a detailed description of this dataset). For the current study, we split this dataset 50/50 into a development and validation subsets using stratified random sampling. The parameters of both approaches to word sense representation were tuned on the development set and evaluated on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training corpora and reference standards</head><p>The general characteristics of corpora used to train neural representations of individual single-word terms are shown in<ref type="figure" target="#tab_1">Table 1</ref>.Since we are comparing three heterogeneous sources of training data with varying vocabulary coverage on a common reference standard, we had to select pairs of terms from the reference standard where both terms were in the vocabulary of each of the three corpora. This resulted in reducing the size of the reference standard. Introducing systematic bias is one potential consequence of reducing the size of the reference standard in this manner. To test for bias, we compared the agreement of the human raters (measured as the standard deviation in response included in the UMNSRS dataset) on the pairs that happened to be excluded from the overlap between the three sources of data, and thus from the comparisons, to the agreement on pairs that were included in the overlap. For the UMNSRS-Similarity dataset, the average standard deviations in human raters response were 274.2 and 275.4 for the excluded (N=109) and included (N=449) pairs, respectively. This difference was not statistically significant (p=0.795). Likewise, for the UMNSRS-Relatedness dataset, the average standard deviations in human raters response were 284.4 and 287.7 for the excluded (N=170) and included (N=458) pairs, respectively. This difference was not statistically significant (p=0.795).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparisons across domains</head><p>The results of comparing the correlations between human and machinegenerated similarity and relatedness judgments based on the three different domain corpora are shown in<ref type="figure" target="#tab_2">Tables 2</ref>When examining semantic similarity between terms (<ref type="figure" target="#tab_2">Table 2</ref>), it is evident that vector representations of term semantics trained on the PMC domain reflects human judgments of similarity on disorder-disorder pairs (rho = 0.74) and disorder-symptom pairs (rho = 0.49) much closer than representations trained on the CLINICAL domain (rho = 0.61 and 0.42, respectively). However, for disorder-drug and symptom-drug pairs the opposite is true – representations trained on the CLINICAL domain are closer to human judgments than those trained on the PMC domain (rho 0.69 vs. 0.62 for disorder-drug and 0.51 vs. 0.40 for symptom-drug pairs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Effects of corpus size</head><p>As shown in<ref type="figure" target="#tab_1">Table 1</ref>, the WIKIPEDIA corpus is substantially smaller in terms of the number of word tokens than either the CLINCAL-ALL or the PMC corpora. This potentially raises a question whether some of the lower correlations between the manual ratings and those produced automatically on the basis of neural representations of word semantics obtained with WIKIPEDIA are due to the size of the corpus rather than the mismatch between domains. Since we could not increase the size of the WIKIPEDIA corpus (all available text was already used), we decreased the size of one of the other two corpora. The CLINICAL-ALL corpus lends itself particularly well to this task as the data in this corpus are organized by year and month in which a clinical note was created. This temporal structure of the corpus also provides the opportunity to test for any recency effects that may bias models trained on more recent data to perform better than older data or vice versa. The results of comparisons across models trained on different size corpora are provided in<ref type="figure" target="#tab_4">Table 4</ref>and show that any appreciable decreases in correlations with human ratings of similarity and relatedness begin to appear only when the corpus size drops significantly below 100M tokens. At a size of ~ 2B tokens (roughly equivalent to WIKIPEDIA's ~1.7B), the correlations with human judgments of similarity and relatedness are still much higher for the term representations trained on the CLINICAL domain than on WIKIPEDIA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Document retrieval task</head><p>The sets of top 100 most semantically related terms to the term " heart failure " derived from CLINCIAL_ALL and PMC corpora are shown in Appendix B in the Supplement.</p><p>As evident from Appendix B, the sets of closely related terms derived from both corpora include not only synonymous or nearly synonymous more specific terms (e.g., " biventricular heart failure " , " diastolic heart failure " , " systolic heart failure " ), but also non-synonymous and functionally related terms for conditions closely associated with heart failure (e.g., " dilated cardiomyopathy " , " pulmonary hypertension " , " volume overload " , " chronic cor pulmonale " , " reduced EF " , " elevated BNP " ). The sets of top 100 most closely semantically related terms to " heart failure " derived from CLINCIAL-ALL and PMC corpora contain 19 phrases that occur in both sets-highlighted in bold in Appendix B.</p><p>The results of the comparisons between the baseline query and semantically expanded queries with 5, 10, 20 and 40 most closely related terms for heart failure are summarized in<ref type="figure" target="#tab_5">Table 5</ref>. Only phrases from the semantically related sets that did not contain any of the terms used in the baseline query (i.e., " heart failure " , " HF, " CHF " ) were used to expand the baseline query. The actual phrases that were added (via OR boolean operator) to the baseline query are marked in Appendix B in the columns labeled " Top, 5, 10, 20, 40. "</p><p>The results in<ref type="figure" target="#tab_5">Table 5</ref>show that queries expanded with semantically related phrases identify more patients with code 428.x than the baseline query. Both queries expanded with top 5 phrases from CLINICAL-ALL corpus and PMC corpus perform very similarly. Queries expanded with top 10, 20 and 40 PMC phrases perform slightly better with respect to recall; however, the CLINICAL-ALL queries yield higher precision and F1 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>022) 0.041</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">WSD task</head><p>The results of cross-domain comparisons of the approaches to semantic representation based on co-occurrence vectors and word embeddings are summarized in<ref type="figure" target="#tab_6">Table 6</ref>. The approach based on word embeddings outperforms co-occurrence vectors regardless of whether the training data came from the clinical (McNemar's χ 2 = 36.6, p &lt; 0.001) or biomedical (χ 2 = 128.2, p &lt; 0.001) domains. Both co-occurrence and word embeddings approaches perform better on this task when trained on the PMC corpus that matches the domain of the NLM WSD dataset (cooccurrence: χ 2 = 130.8; embeddings: χ 2 = 281.2). Embedding-based sense representations also exhibited an interesting property: a strong negative correlation between the cosine similarity of the sense vectors for a single term and disambiguation accuracy that term (Pearson's r =-0.43, p &lt; 0.001 for CLINICAL-ALL; r =-0.56, p &lt; 0.001 for PMC). It would follow intuitively that more similar senses should be more difficult to disambiguate. However, this correlation was not as reliably observed for the second-order co-occurrence vectors (r =-0.06, p = 0.40 for CLINICAL-ALL; r =-0.15, p = 0.03 for PMC). Regardless of their suitability for WSD, co-occurrence representations appear not to directly model the closeness of easily confusable senses as well as trained embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In the current study, we performed a large-scale evaluation of a popular neural network learning approach (word2vec) to representing the meaning of words in the medical domain and measuring the strength of association between them. Our results are overall slightly better than the best results reported so far on the UMNSRS benchmark by<ref type="bibr" target="#b31">Sajadi et al. (2014)</ref>that used a graph-based approach (HITS-sim) to represent word semantics that leveraged Wikipedia as a network (rho 0.58 vs. 0.51 for relatedness and 0.62 vs. 0.58 for similarity). However, these differences are probably not significant from a practical standpoint due to reasons having to do with inter-rater agreement explained later in the discussion.For comparison,<ref type="bibr" target="#b31">Sajadi et al. (2014)</ref>also used the word2vec approach (with skip-gram representation of word contexts) trained on OHSUMED corpus of 348,566 MEDLINE citations and the text of the Unified Medical Language System terms but obtained much lower correlations with human ratings (rho = 0.39). The citations included in the OHSUMED corpus are truncated at 250 words 2 ; therefore, the total size of the OHSUMED collection is at most 87M tokens. The main differences of our study's use of word2vec from the one reported by<ref type="bibr" target="#b31">Sajadi et al. (2014)</ref>are that we used the bag-of-words representation of contexts instead of the skip-gram representation, and a much larger corpus of text (over 4B tokens) for training consisting of entire articles rather than just the MEDLINE citations containing only the abstract and title of the articles. We believe that that the improved performance of word2vec approach observed in our study was mostly due to the latter two differences – larger corpus and inclusion of entire articles; however, we did not directly test these assumptions in the current study. At the outset of the current study, we intuitively expected to find domain and corpus size effects. We expected that, since the UMNSRS reference standard was created based on ratings by clinicians, semantic representations derived from the CLINICAL domain would agree better with clinicians' ratings than representations derived from PMC or WIKIPEDIA. The findings of this negative and positive directions. The detailed comparisons are shown in<ref type="figure" target="#tab_7">Table 7</ref>.Another interesting finding of the current study is that increasing the size of the corpus beyond a certain size does not seem to provide an additional advantage. In the current study, the performance on both similarity and relatedness benchmarks plateaued between 10M and 100M tokens, which is consistent with the findings of another previous study by<ref type="bibr" target="#b29">Pedersen et al. (2007)</ref>in which we found that the performance of another distributional semantics corpus-based approach to computing semantic relatedness plateaued after the training corpus reached 300,000 clinical notes (~ 66M tokens). These findings may be interpreted as providing additional evidence to show that the size of the corpus used for distributional semantic representations of medical terms does not matter beyond a certain point (e.g. 100M tokens); however, an alternative explanation is that the corpus size does matter but the plateauing of the correlations with human ratings is a function of the test data rather than the training data and has more to do with the inter-rater agreement. One possible way to test this hypothesis in future work is to apply corpus-based semantic relatedness measures in a secondary evaluation paradigm in which measures derived from corpora of different size would be used for another task such as word sense ambiguity resolution, spelling correction, or query expansion for information retrieval.</p><p>In addition to cross-domain comparisons of the word2vec based semantic relatedness measures on the UMNSRS reference standard, we also compared the use of semantically related phrases derived from clinical and biomedical domains on two tasks directly relevant to medical NLP. Automatically derived phrases for expanding text queries to identify patients with heart failure presented in the current study are consistent with the terms defined by experts in cardiovascular research that were used in prior studies examining the utility of NLP for identification of patients with heart failure from the unstructured text of EHR (<ref type="bibr" target="#b25">Pakhomov, Buntrock, &amp; Chute, 2005</ref>). These manually defined terms consisted of " cardiomyopathy, " " heart failure, " " congestive heart failure, " " pulmonary edema, " " decompensated heart failure, " " volume/fluid overload. " The sets of top 100 automatically derived terms related to " heart failure " from both the clinical (CLINCIAL-ALL) and biomedical (PMC) corpora in the current study contain all but one ( " pulmonary edema " ) of these terms manually determined to be good search terms for heart failure cases.</p><p>Our results also show that expanding text search queries with semantically related terms based on word embeddings can significantly improve recall of the queries. This is an important finding in the context of using NLP to identify potential candidates for clinical research studies such as clinical trials and cohort studies. Improved recall is particularly important for cohort studies in which the completeness of ascertaining cases with a condition of interest is critical to minimizing potential bias. Using structured billing codes (a.k.a. claims data) for case ascertainment has been shown to have limitations in terms of accuracy and completeness, particularly in community-based samples (<ref type="bibr" target="#b1">Bazarian, Veazie, Mookerjee, &amp; Lerner, 2006;</ref><ref type="bibr" target="#b5">Fan et al., 2013;</ref><ref type="bibr" target="#b27">Pakhomov et al., 2007</ref>). Furthermore, a number of conditions (e.g., symptoms and physical examination findings) may not have a diagnostic code entered as part of the medical record. Using NLP to search unstructured text of EHR can complement the use of billing codes for improved recall of potential candidates for prospective and retrospective studies. Improved recall is also relevant for clinical trials from a more practical standpoint. Being able to identify any number of additional potential candidates for a clinical trial can improve recruitment rates and consequently shorten the duration of the trial resulting in faster delivery of new therapeutic interventions to the bedside.</p><p>In the current study, we used the ICD-9 code 428.x to define the reference standard (with the understanding of the limitations inherent in this approach) for comparing query expansions to each other and to the baseline query. In order to minimize uncontrolled variability in these comparisons, we did not use advanced NLP tools (e.g., negation and family history detection) to make the text queries more precise. Therefore, the precision of the queries reported in this study does not reflect the actual precision that can be expected from text queries enhanced with NLP. In prior work, we showed that using negation detection can improve precision of text queries to approximately 50% (<ref type="bibr" target="#b27">Pakhomov et al., 2007</ref>), and this number is likely to be higher for more sophisticated and customized NLP systems. In the current study, we focused on changes in precision between semantically expanded queries and the baseline. Our findings indicate that queries expanded with top 5 semantically related phrases from the CLINICAL-ALL and PMC corpora perform better than the baseline query and are comparable to each other. The performance of these queries diverges on larger sets of expansions (10, 20, and 40) with a large decrease in precision on queries derived from the PMC corpus. This drop in precision can be attributed to the terms " cardiac " and " hypertension " that are relatively high on the list of PMC derived phrases. Queries with these two terms would capture the majority of patients with heart disease (with or without heart failure) and thus negatively affect precision. However, despite the lower precision, these results indicate that the public PMC corpus can potentially be used as an alternative source of semantic relatedness information for expanding queries when searching clinical texts. This is particularly important in settings where the query expansion is not fully automated but is curated by the end user that can manually select more specific terms from the set of semantically related suggestions. While these findings are encouraging, clearly, further investigation is necessary to test their generalizability. Similarly to the evaluation on the clinical document retrieval task, the evaluation of using word embeddings on a biomedical term WSD task showed that this type of representation improves WSD accuracy over basic co-occurrence based approaches. The accuracy of ~78% that we achieved on this dataset with word embeddings derived from the PMC corpus is comparable to other previously reported machine readable dictionary based results on the same dataset (<ref type="bibr" target="#b9">Garla &amp; Brandt, 2013;</ref><ref type="bibr" target="#b10">Jimeno-Yepes et al., 2011</ref>; B. T.<ref type="bibr" target="#b22">McInnes &amp; Pedersen, 2013</ref>). The improvement in WSD accuracy with word embeddings is likely due to the fact that even extended sense definitions are bound to be sparse, compared to occurrences in a text corpus of any reasonable size. Word embeddings may offer the advantage of smoothing over the gaps in representations based on sparse sense definitions. The fact that better WSD accuracy is achieved with methods trained on PMC data is not surprising because the NLM WSD dataset is derived from the same domain. What is interesting is that the accuracy achieved with word embeddings derived from the clinical domain is not that much lower than the accuracy achieved with in-domain training data, which constitutes additional evidence that the clinical and biomedical sources of text are similar with respect to semantic representations that can be derived from them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Based on the results of the current study we can draw several conclusions with varying degrees of confidence. We are confident that easy-touse and fast-to-compute word2vec neural representations of word embeddings are highly effective in capturing semantic relatedness and similarity relations between medical terms. We are moderately confident that equivalent, if not superior, results can be obtained with semantic representations derived from the freely available PMC biomedical corpus as from highly restricted clinical data. We are less confident at this time in concluding that there exists a threshold (e.g. 100M tokens) beyond which one can expect to stop seeing improvements in semantic representations of medical terms. Evaluating the use of semantic relatedness measures based on word embeddings in clinical and biomedical NLP applications showed that deriving word vectors from in-domain data offers a slight advantage over using text from a related but not the same domain. This study has important implications for the development of NLP and information retrieval tools for clinical and translational research. Availability of usable semantic representations of clinical terms is important for improving concept-based information and document retrieval from unstructured text of electronic health records that, in turn, is critical for defining cohorts of patients for participation in experimental and observational clinical studies. Being able to construct distributional semantic representations of clinical terms from open-access biomedical literature that are equivalent to those obtained from difficult to access clinical corpora will enable wider adoption and more rapid further development and evaluation of these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Limitations</head><p>The results of this study should be interpreted in light of several limitations. First, the UMNSRS benchmark, by design, contains mostly single word terms and has moderate inter-rater agreement. Thus, the results presented in this manuscript may not readily generalize to multi-word terms in other benchmarks and would require further investigation. Since the benchmark contains single word terms, we used the single word version of word2vec, as well; however, word2vec enables computation of embeddings at the phrase level that can also be investigated further in future work on clinical reference standards for semantic relatedenss. The moderate inter-rater agreement may introduce a ceiling for comparing various methods for computing semantic relatedness and similarity of around 0.5-0.6 correlation. The correlations reported in this study for the CLINICAL and PMC based measures are in that moderate range and thus it is possible that using a reference standard with better inter-rater agreement may show differences between using PMC and CLINICAL corpora. In the current study, we compared measures computed from these corpora on subsets of the UMNSRS benchmark with high agreement and did not find that measures computed from these corpora performed differently relative to each other than on the full UMNSRS benchmark. This finding provides additional evidence that similarity and relatedness measures derived from full text of biomedical articles are likely to be equivalent to those derived from clinical reports.</p><p>The second main limitation is that we did not experiment with various settings on word2vec such as context size and number of dimensions. Due to the number of experiments we ran in this study (combinations of corpora and benchmarks) and the size of the corpora, experimenting with parameter optimization would have been prohibitively time consuming. Thus, we relied on the default parameters. It is possible that larger context window sizes and/or larger number of dimensions to represent medical terms may yield further improvements; however, these improvements are likely to be incremental and would require a reference standard with greater inter-rater agreement to be reliably measured and compared across domains.</p><p>Another limitation that stems from the nature of the UMNSRS reference standard is that we only examined single word terms. Most medical terms consist of more that one word. The results obtained on single word terms may not generalize to multi-word terms and thus the latter need to be examined in future studies. However, in the current study, we were able to use neural representations of multi-word phrase semantics but only for evaluating a text query expansion application. Future studies will need to focus on constructing large representative collections of multi-word medical terms manually rated for semantic relatedness and similarity to enable direct evaluations of semantic representation methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure1.</head><figDesc>Figure 1. Pairs of terms remaining in UMNSRS-Similarity and UMNSRS-Relatedness datasets after reduction to match the vocabulary in the three domain corpora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2..</head><figDesc>Comparison of correlations with human raters of automated cosine distance-based approaches trained on corpora from several domains and tested on UMNSRS-Similarity (Di – disorder, S – symptom, Dr – drug)Comparison of correlations with human raters of automated cosine distance-based approaches trained on corpora from several domains and tested on UMNSRS-Relatedness (Di – disorder, S – symptom, Dr – drug)) CLINICAL-ALL 0.57 0.59 0.57 0.68 0.41 0.63 0.59 PMC 0.58 0.59 0.64 0.73 0.42 0.52 0.54 WIKIPEDIA 0.45 0.59 0.36 0.62 0.35 0.47 0.25* * p-value less than 0.05; all other p-values are less than 0.01</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>5.</head><figDesc>Comparison of results on the document retrieval task between two sources of phrases for query expansion. N patients identified (% of total study sample) N patients with 428.x (increase over baseline) Recall (95% CI) Precision (95% CI) F1 Study sample (Jan-Oct, 2015) 610282 (100%)ICD-9 (428.x) query 7497 (1.2%) 7497Baseline ( " HF " or " CHF " or " heart failure " ) query 45728 (7.5%) 6716 0.896 (.889-.903) 0.147 (.144-.150) 0.253 Baseline + related phrases derived from CLINICAL-ALL corpus query Top</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1.</figDesc><table>Descriptive statistics for text corpora 
Corpus 
Vocab. size 
(N 
word 
types) 

Corpus size 
(N 
word 
tokens) 

Dates 

CLINICAL-ALL 
401,087 
4,169,696,714 
2010-4 
CLINICAL-4B 
385,540 
3,882,516,140 
2011-4 
CLINICAL-3B 
342,074 
3,137,442,621 
2012-4 
CLINICAL-2B 
262,250 
1,853,601,667 
2013-4 
CLINICAL-500M 
132,739 
452,314,196 
2014 
(Jan-Aug) 
CLINICAL-100M 
73,147 
123,969,678 
Jan 2014 
CLINICAL-10M 
26,618 
9,931,684 
Jan 2014 
first 10 M wrds 
CLINICAL-1M 
9,616 
973,143 
Jan 2014 
first 1 M wrds 
PMC 
1,596,146 
4,533,613,517 
Up to Sept 
2015 
WIKIPEDIA 
1,350,678 
1,700,369,832 
Up to Sept 
2015 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 4.</figDesc><table>Correlations with human judgments as a function of corpus size in the CLINICAL domain. 
Corpus Size 
(word tokens) 
(x 10 9 ) 

N pairs in UMNSRS-Sim 
in common with CLINCAL, 
PMC, and WIKIPEDIA 

N pairs in UMNSRS-Rel in 
common with CLINCAL, 
PMC, and WIKIPEDIA 

Correlation with 
UMNSRS-Sim 
ratings 

Correlation with 
UMNSRS-Rel 
ratings 
CLINICAL-1M 
~ 0.001 
188 
187 
0.46 
0.43 
CLINICAL-10M 
~ 0.01 
326 
319 
0.56 
0.54 
CLINICAL-100M 
~ 0.12 
403 
405 
0.60 
0.57 
CLINICAL-500M 
~ 0.45 
419 
425 
0.60 
0.58 
CLINICAL-2B 
~ 1.85 
441 
452 
0.63 
0.59 
CLINICAL-3B 
~ 3.14 
445 
455 
0.61 
0.58 
CLINICAL-4B 
~ 3.88 
449 
458 
0.60 
0.56 
CLINICAL-ALL 
~ 4.16 
449 
458 
0.61 
0.57 

The examination of semantic relatedness (Table 3) demonstrates that 
representations trained on the PMC domain are closer to human judg-
ments in measuring the degree of relatedness between symptoms and 

drugs (rho 0.64 vs. 0.57 for symptom-symptom pairs and 0.73 vs. 0.68 
for drug-drug pairs). As with similarity judgments, term representations 
trained on the CLINICAL domain are better at capturing relatedness 
between disorders and drugs and symptoms and drugs (rho 0.63 vs. 0.52 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>Table</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 6.</figDesc><table>WSD accuracy achieved on the NLM WSD corpus with 
different representations of word senses. 

CLINICAL-ALL 
PMC 
Co-occurrence vectors 
0.700 
0.740* 
Word embeddings 
0.722 
0.777* 
Majority sense 
0.524 
Random chance 
0.492 
* indicates significant difference from CLINICAL-ALL value at p &lt; 
0.001 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 7. Changes in correlations with human ratings of similarity and relatedness after selecting pairs with high inter-rater agreement (ICC).</figDesc><table>UMNSRS-
Similarity 

UMNSRS-
Relatedness 
All 
pairs 

High 
agreement 
pairs 

All pairs 
High 
agreement 
pairs 
n=449 
n=224 
n=458 
n=228 
ICC 
0.47 
0.86 
0.50 
0.86 

CLINICAL-ALL 
0.60 
0.69 
0.57 
0.57 
PMC 
0.62 
0.68 
0.58 
0.55 
WIKIPEDIA 
0.48 
0.62 
0.45 
0.49 

</table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="2"> http://trec.nist.gov/data/filtering/README.t9.filtering study confirm that, as expected, semantic representations derived from the general English domain (WIKIPEDIA) overall agree to a lesser extent with clinician&apos;s ratings than the other two domains. However, we did not expect to find that representations derived from biomedical literature would perform similarly or better to representations derived from clinical notes. This is an important finding because it suggests that distributed semantic representations derived from full texts of biomedical articles are equivalent (at least for the purpose to finding semantically similar or related terms) to semantic representations derived from clinical corpora. This is important because access to clinical corpora is highly restricted and difficult due to patient confidentiality and security of protected health information concerns. The open-access biomedical articles from PMC have no such restrictions and are freely and easily accessible by anyone. The only exceptions are disorder-drug and symptom-drug pairs for which representations derived from the CLINICAL domain were closer to clinician&apos;s ratings of similarity and relatedness than those derived from PMC. These exceptions as well as the overall findings, however, need to be examined in light of the inter-rater agreement on the pairs of terms include in UMNSRS benchmark. As reported in our previous work (Pakhomov et al, 2010), the inter-rater agreement on all pairs of terms in the UMNSRS benchmark is in the moderate range (ICC 0.5 for relatedness and 0.47 for similarity) due to individual variability in conceptualizing the referents of medical terms and their similarity and relatedness to each other. The highest inter-rater agreement on the UMNSRS dataset was achieved on disorder-disorder pairs (ICC 0.56 for both similarity and relatedness) and similarity between symptoms and drugs (ICC 0.58 and 0.63, respectively). The lowest inter-rater agreement was observed on similarity for disorder-drug and symptom-drug pairs (ICC 0.33 and 0.24, respectively) – poor agreement. Thus, while it makes sense intuitively that in the current study we observe lower agreement on disorder-drug and symptom-drug between relatedness and similarity measures derived from the PMC domain than from the CLINCIAL domain, the observed Spearman rank correlations are substantially higher than the inter-rater agreement intraclass correlations for these categories of term pairs. Thus, we must exercise more caution in the interpretation of the results of the current study pertaining to disorder-drug and symptom-drug pairs. In the same vein, it should also be noted that the correlations in the 0.50 – 0.60 range reported in the current study and previous studies involving UMNSRS benchmark are in the same range as the intra-class correlation coefficients used to measure agreement and, therefore, may constitute ceiling performance that can be measured with the full UMNSRS benchmark. In order to test whether our findings will hold at higher levels of interrater agreement, we used the median of the standard deviations in human rater responses to select pairs with higher agreement. By doing so, we selected subsets of 224 pairs from the UMNSRS-Similarity and 228 pairs from the UMNSRS-Relatedness benchmarks. For both of these selected subsets, the intra-class correlation coefficient among the 4 human raters per benchmark was 0.86 (excellent range). We then ran correlations between these selected manual ratings and automated measures of similarity and relatedness computed from the three domain corpora. As a result, we observed a substantial improvement in correlations (more than 5 points) with the UMNSRS-Similarity subset, but not UMNSRSRelatedness. All correlations with the UMNSRS-Similarity subset improved approximately by the same amount across all three domains. On the UMNSRS-Relatedness subset, however, the correlations either stayed the same or changed very slightly (less than 5 points) in both at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>This work was supported by the National Library of Medicine (R01 LM009623-01).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Dont count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Baroni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Dinu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kruszewski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Accuracy of Mild Traumatic Brain Injury Case Ascertainment Using ICD-9 Codes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Bazarian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Veazie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mookerjee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B</forename>
				<surname>Lerner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academic Emergency Medicine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Evaluating WordNet-based Measures of Semantic Distance</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Budanitsky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Hirst</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="13" to="47" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Systolic and diastolic heart failure in the community</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Bursi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">A</forename>
				<surname>Weston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">M</forename>
				<surname>Redfield</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">J</forename>
				<surname>Jacobsen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">T</forename>
				<surname>Nkomo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">L</forename>
				<surname>Roger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="296" to="2209" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Empirical distributional semantics: Methods and biomedical applications</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Widdows</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="390" to="405" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Billing code algorithms to identify cases of peripheral artery disease from administrative data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Arruda-Olson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Leibson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">R</forename>
				<surname>Bailey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">J</forename>
				<surname>Kullo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="issue">e2</biblScope>
			<biblScope unit="page" from="20" to="349" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Community Evaluation and Exchange of Word Vectors at wordvectors.org</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Faruqui</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Dyer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (System Demonstration)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (System Demonstration)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">156</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploiting disjointness axioms to improve semantic similarity measures</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Ferreira</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hastings</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">M</forename>
				<surname>Couto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="29" to="2781" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Semantic similarity in the biomedical domain: an evaluation across knowledge sources</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">N</forename>
				<surname>Garla</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brandt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">261</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge-based biomedical word sense disambiguation: an evaluation and application to clinical document classification</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">N</forename>
				<surname>Garla</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brandt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association: JAMIA</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="882" to="886" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploiting MeSH indexing in MEDLINE to generate a data set for word sense disambiguation</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Jimeno-Yepes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">T</forename>
				<surname>Mcinnes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">R</forename>
				<surname>Aronson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">223</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">Handbook of latent semantic analysis</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">K</forename>
				<surname>Landauer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Mahwah</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining Local Context and WordNet Similarity for Word Sense Identification</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Leacock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chodorow</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WordNet: An Electronic Lexical Database</title>
		<editor>C. Fellbaum</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Comparison of ontologybased semantic-similarity measures</title>
		<author>
			<persName>
				<forename type="first">W.-N</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Shah</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sundlass</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Musen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA ... Annual Symposium Proceedings / AMIA Symposium. AMIA Symposium</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="384" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving Distributional Similarity with Lessons Learned from Word Embeddings</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Levy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Goldberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Dagan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="225" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">An Information-Theoretic Definition of Similarity</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;98 Proceedings of the Fifteenth International Conference on Machine Learning</title>
		<meeting><address><addrLine>Madison, WI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">Semantic relatedness study using second order co-occurrence vectors computed from biomedical corpora</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">T</forename>
				<surname>Mcinnes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pedersen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Melton-Meaux</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>UMLS and WordNet</publisher>
			<biblScope unit="page">363</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Investigating semantic similarity measures across the Gene Ontology: the relationship between sequence and annotation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">W</forename>
				<surname>Lord</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">D</forename>
				<surname>Stevens</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Brass</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">A</forename>
				<surname>Goble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="19" to="1275" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">ADaGO-Fun: an adaptable Gene Ontology semantic similarity-based functional analysis tool</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">K</forename>
				<surname>Mazandu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Chimusa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Mbiyavanga</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Mulder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="32" to="477" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Validity of Heart Failure Diagnoses in Administrative Databases: A Systematic Review and Meta-Analysis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Mccormick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lacaille</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bhole</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Avina-Zubieta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="9" to="104519" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">NLP-PIER: A Scalable Natural Language Processing, Indexing, and Searching Architecture for Clinical Notes</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mcewan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Melton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Knoll</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Hultman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dale</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Joint Summits of the American medical Informatics Association</title>
		<meeting>the 2016 Joint Summits of the American medical Informatics Association<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>in. press</note>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Using second-order vectors in a knowledge-based method for acronym disambiguation</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Mcinnes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pedersen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">V</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Melton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="145" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating measures of semantic similarity and relatedness to disambiguate terms in biomedical text</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">T</forename>
				<surname>Mcinnes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pedersen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1116" to="1124" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Mikolov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Sutskever</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">S</forename>
				<surname>Corrado</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dean</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, &amp; K. Q. Weinberger</editor>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating distributed word representations for capturing semantics of biomedical concepts</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Muneeb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sunil</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Anand</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Workshop on Biomedical Natural Language Processing</title>
		<meeting>the 2015 Workshop on Biomedical Natural Language Processing<address><addrLine>Bajing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="158" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Prospective recruitment of patients with congestive heart failure using an ad-hoc binary classifier</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Buntrock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">G</forename>
				<surname>Chute</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="153" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Semantic Similarity and Relatedness between Clinical Terms: An Experimental Study</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Mcinnes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Adam</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pedersen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">B</forename>
				<surname>Melton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMIA ... Annual Symposium Proceedings / AMIA Symposium. AMIA Symposium</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="572" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Electronic medical records for clinical research: application to the identification of heart failure</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">A</forename>
				<surname>Weston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">J</forename>
				<surname>Jacobsen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">G</forename>
				<surname>Chute</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Meverden</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">L</forename>
				<surname>Roger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Journal of Managed Care</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="13" to="281" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Part. 1</note>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Using WordNet-based Context Vectors to Estimate the Semantic Relatedness of Concepts</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Patwardhan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pedersen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2006 Workshop on Making Sense of Sense: Bringing Computational Linguistics and Psycholinguistics Together</title>
		<meeting>the EACL 2006 Workshop on Making Sense of Sense: Bringing Computational Linguistics and Psycholinguistics Together</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Measures of semantic similarity and relatedness in the biomedical domain</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pedersen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">V</forename>
				<surname>Pakhomov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Patwardhan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">G</forename>
				<surname>Chute</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Biomed Inform</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="288" to="99" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Semantic similarity in a taxonomy: an information-based measure and its application to problems of ambiguity in natural language</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Resnik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J of Artif Intell Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="95" to="130" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Graph-Based Domain-Specific Semantic Relatedness from Wikipedia</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sajadi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Artificial Intelligence</title>
		<editor>M. Sokolova &amp; P. van Beek</editor>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="381" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">A new method to measure the semantic similarity of GO terms</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Du</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Payattakool</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">S</forename>
				<surname>Yu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C.-F</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="23" to="1274" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Co-occurrence Retrieval: A Flexible Framework for Lexical Distributional Similarity</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Weeds</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="475" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving GO semantic similarity measures by exploring the ontology beneath the terms and modelling uncertainty</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Nepusz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Paccanaro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="28" to="1383" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>