
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Differential protein expression and peak selection in mass spectrometry data by binary discriminant analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Sebastian</forename>
								<surname>Gibb</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Anesthesiology and Intensive Care Medicine</orgName>
								<orgName type="institution">University Hospital Greifswald</orgName>
								<address>
									<addrLine>Ferdinand-Sauerbruch-Straße</addrLine>
									<postCode>D-17475</postCode>
									<settlement>Greifswald</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Korbinian</forename>
								<surname>Strimmer</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Epidemiology and Biostatistics</orgName>
								<orgName type="institution" key="instit1">School of Public Health</orgName>
								<orgName type="institution" key="instit2">Imperial College London</orgName>
								<orgName type="institution" key="instit3">Norfolk Place</orgName>
								<address>
									<postCode>W2 1PG</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Differential protein expression and peak selection in mass spectrometry data by binary discriminant analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv334</idno>
					<note type="submission">Received on February 27, 2015; revised on April 30, 2015; accepted on May 26, 2015</note>
					<note>Gene expression *To whom correspondence should be addressed. Associate Editor: Jonathan Wren Contact: k.strimmer@imperial.ac.uk</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Proteomic mass spectrometry analysis is becoming routine in clinical diagnostics, for example to monitor cancer biomarkers using blood samples. However, differential proteomics and identification of peaks relevant for class separation remains challenging. Results: Here, we introduce a simple yet effective approach for identifying differentially expressed proteins using binary discriminant analysis. This approach works by data-adaptive thresholding of protein expression values and subsequent ranking of the dichotomized features using a relative en-tropy measure. Our framework may be viewed as a generalization of the &apos;peak probability contrast&apos; approach of Tibshirani et al. (2004) and can be applied both in the two-group and the multi-group setting. Our approach is computationally inexpensive and shows in the analysis of a large-scale drug discovery test dataset equivalent prediction accuracy as a random forest. Furthermore, we were able to identify in the analysis of mass spectrometry data from a pancreas cancer study biological relevant and statistically predictive marker peaks unrecognized in the original study. Availability and implementation: The methodology for binary discriminant analysis is implemented in the R package binda, which is freely available under the GNU General Public License (version 3 or later) from CRAN at URL http://cran.r-project.org/web/packages/binda/. R scripts reproducing all described analyzes are available from the web page http://strimmerlab.org/software/binda/.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Mass spectrometry, a high-throughput technology commonly used in proteomics, enables the measurement of the abundance of proteins, metabolites, peptides and amino acids in biological samples. The study of changes in protein expression across subgroups of samples and through time provides valuable insights into cellular mechanisms and offers a means to identify relevant biomarkers, e.g. to distinguish among tissue types, or for predicting health status. In practice, however, there still remain many analytic and computational challenges to be addressed, especially in clinical diagnostics (<ref type="bibr" target="#b16">Leichtle et al., 2013</ref>). A recent overview of statistical issues in the analysis of proteomics mass spectrometry data is Morris (2012) who discusses a wide range of methods ranging from data preprocessing, i.e. removal of systematic bias, peak identification, peak alignment and quantification and calibration of relative peak intensities, to methods for high-level statistical analysis, such as peak ranking and classification. Of particular importance is the problem of differential protein expression and the identification of peaks informative for group separation and class prediction. A special characteristic of mass spectrometry data is their dualvalued nature, i.e. they contain both continuous as well as discreteinformation. Specifically, a protein may be differentially expressed if its intensity of expression varies among groups and is relatively up-or down-regulated, or if a corresponding peak is either absent or present in a specific group. Consequently, mass spectrometry intensity matrices typically contain very large amounts of missing values, which renders application of standard statistical methodology from other omics platforms, such as regularized t-scores, difficult and potentially suboptimal. Accordingly, this has initiated the development of new statistical methodology (<ref type="bibr" target="#b24">Tibshirani et al., 2004;</ref><ref type="bibr" target="#b25">Wang et al., 2012</ref>). Two main strategies to address this issue in the high-level analysis of mass spectrometry data have emerged: 1. All data are treated as continuous, with missing intensity values set to zero or imputed. Subsequently, standard omics methods are employed, such as t-scores for feature selection (e.g.<ref type="bibr" target="#b7">Datta and DePadilla, 2006</ref>). 2. The absence–presence data are used for data analysis in conjunction with the intensity values.<ref type="bibr" target="#b24">Tibshirani et al. (2004)</ref>propose peak probability contrasts (PPCs), the absolute difference in frequency of occurrence of a peak, for ranking and feature selection, and also use PPC to improve absence–presence data by dichotomization of intensity values.<ref type="bibr" target="#b25">Wang et al. (2012)</ref>propose a test based on the PPC statistic and propose to apply joint false discovery rate control of the union of intensity-based and PPCbased rankings.</p><p>Here, we follow the second route and propose a novel coherent model for differential protein expression and prediction based on binary discriminant analysis (BinDA). Our approach may be viewed as a generalization of<ref type="bibr" target="#b24">Tibshirani et al. (2004)</ref>and comprises the following: @BULLET The binary absence–presence data are explicitly modeled by a multivariate Bernoulli (MVB) distribution. @BULLET Multi-group binary discriminant analysis (BinDA) is employed for feature ranking, variable selection and prediction. @BULLET For ranking of peaks the natural relative entropy variable importance measure coherent with BinDA is used, rather than PPC. @BULLET Likewise, for dichotomization of the intensity data matrix containing missing values we employ the same entropy-based criterion.</p><p>As a result, we obtain simple principled framework for analyzing dual-valued mass spectrometry data without the need for imputation, with a natural measure for variable ranking and for differential protein expression, and with coherent prediction rules. In contrast to many other methods this approach also allows multiple groups as response variable, and thus extends beyond simple pairwise comparisons. The remainder of the paper is structured as follows. Next, we describe in detail the statistical methodology underlying BinDA. Then, for validation we investigate the performance of the proposed approach in comparison with a random forest on a large-scale chemometric dataset. Subsequently, we present a detailed case study analyzing mass spectrometry data from a pancreas cancer study. For reproducibility, we provide the R package binda implementing our approach and R scripts for all analyzes described. Finally, we discuss applicability of the BinDA approach to other molecular data as well as further extensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Setup and notation</head><p>Our analysis starts after the raw mass spectrometry data have been adequately preprocessed, i.e. transformed, smoothed, backgroundremoved, calibrated, aligned and peak-extracted (e.g.<ref type="bibr" target="#b18">Morris, 2012;</ref><ref type="bibr" target="#b12">Gibb and Strimmer, 2012</ref>). We denote the resulting peak intensities by z ij ! 0, with spectrum index i 2 f1;. .. ; ng and peak index j 2 f1;. .. ; dg. The data matrix z ij typically contains missing values as not all of the registered d peaks will be present in all of the n spectra. In a classification setting each spectrum i also carries a class label y i 2 f1;. .. ; Kg that assigns it to one of K different groups, for instance health status, tissue type or treatment outcome. The label is known for training data and unknown for test data. The sample size in group with label y is n y with n ¼ P K y¼1 n y. From the continuous data z ij we obtain binary peak intensities x ij by thresholding at peak-specific levels w ¼ ðw 1 ;. .. ; w d Þ. Specifically, we set x ij ¼ 1 if the peak is present in sample i and z ij ! w j. Conversely, if the peak is absent or z ij &lt; w j then x ij ¼ 0. The methodology we present here uses the binary matrix x ij for prediction and variable ranking, rather than the original data z ij , and it also estimates the thresholds w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modeling binary data</head><p>Stochastic models for multivariate binary data are well established (e.g.<ref type="bibr" target="#b5">Cox, 1972;</ref><ref type="bibr" target="#b6">Dai et al., 2013</ref>). A univariate binary random variable X $ BeðlÞ with two states x ¼ 0 and x ¼ 1 is completely described by a Bernoulli distribution BeðlÞ with expectation EðXÞ ¼ l and variance VarðXÞ ¼ lð1 À lÞ. In the multivariate case this generalizes to X ¼ ðX 1 ;. .. ; X d Þ $ Be d ðl; fÞ where d denotes the dimension of the MVB distribution, l ¼ ðl 1 ;. .. ; l d Þ is the vector of expectations EðXÞ ¼ l, and f contains the 2 d À d À 1 interaction parameters. As in the univariate case the variances VarðX j Þ ¼ l j ð1 À l j Þ are fully determined by the means. In many cases it is useful to ignore the dependencies among the individual variables X j in order to reduce the number of parameters in the model. Despite, or perhaps because, of its simplicity the independence 'naive Bayes' assumption can be very effective, especially for prediction in high dimensions and small sample size, see Hand and Yu (2001) and Park (2009). For MVB with independent predictor variables the joint probability mass function is given by</p><formula>PrðxÞ ¼ Y d j¼1 1 À l j if x j ¼ 0; l j if x j ¼ 1:</formula><p>with diagonal covariance matrix VarðXÞ ¼ diagfl j ð1 À l j Þg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Discriminant analysis with binary predictors</head><p>For prediction of the class associated with an unlabeled spectrum we need to construct a prediction rule. Here, we employ a Bayesian prediction rule similar as in diagonal discriminant analysis (DDA) that is routinely and successfully used, e.g. in transcriptomics (<ref type="bibr" target="#b23">Tibshirani et al., 2003</ref>). We first define group-specific models for each group with label y,</p><formula>PrðxjyÞ ¼ Y d j¼1 ( 1 À l yj if x j ¼ 0; l yj if x j ¼ 1: (1)</formula><p>For each group y we also specify a prior probability PrðY ¼ yÞ ¼ p y with</p><formula>P K y¼1 p y ¼ 1. By l 0j ¼ P K y¼1 p y l</formula><p>yj we denote the pooled mean for each variable j, i.e. the mean we would assign if there was only a single category. The posterior probability of each group is then given by Bayes' theorem PrðyjxÞ ¼ PrðxjyÞp y =PrðxÞ which after taking the logarithm yields the discriminant function d y ðxÞ ¼ log PrðyjxÞ ¼ log p y þ log PrðxjyÞ þ C :</p><formula>(2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Protein expression and peak selection by BinDA</head><p>As the purpose of d y ðxÞ is only to compare among different groups we can drop all terms that do not depend on y, such as PrðxÞ, represented above by the constant C. Prediction of a label for test data x is carried out by choosing the group y that maximizes the discriminant function,</p><formula>^ y ¼ arg max y d y ðxÞ</formula><p>This MVB independence prediction rule has shown to be highly effective (e.g.<ref type="bibr" target="#b20">Park, 2009</ref>), even if there is correlation among predictors. Typically, the parameters of discriminant function are unknown themselves and have to be learned themselves from training data, i.e. from spectra with known group labels. The training is done by estimating the means l yj and the group probabilities p y in Equations (1)</p><p>and (2). We suggest a flexible estimation strategy by employing maximum-likelihood estimation for large sample size, and otherwise using regularized estimation. For instance, to estimate the group probabilities we use observed frequencies ^ p y ¼ n y =n if n is large, and for small n the Stein-type shrinkage estimator of proportions described in Hausser and Strimmer (2009).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Variable ranking and selection</head><p>Closely tied in with prediction is the question which variables are most important for successful assignment of a class label, and conversely, which variables are irrelevant. Especially in large-dimensional problems it is very important to remove the null features as the build-up of random noise from these variables can substantially degrade the overall prediction accuracy (cf. Ahdesmä ki and<ref type="bibr" target="#b0">Strimmer, 2010</ref>). For ranking features in discriminant analysis with binary variables there have been many, in part contradictory, propositions. For the case of K ¼ 2 groups the following criteria, among others, have been used: @BULLET The v 2 statistic of independence between response and predictors (<ref type="bibr" target="#b1">An et al., 2013</ref>), @BULLET PPCs jl y1 À l y2 j (<ref type="bibr" target="#b24">Tibshirani et al., 2004</ref>), @BULLET Quinlan's information gain measure (<ref type="bibr" target="#b2">Bender et al., 2004</ref>), and @BULLET ratio of between-group and within-group covariance (<ref type="bibr" target="#b26">Wilbur et al., 2002</ref>). See<ref type="bibr" target="#b21">Tan et al. (2004)</ref>for many other proposals for measuring associations between categorical outcomes and binary variables. Only some of the criteria above can also be applied to the multiple group case (K &gt; 2). We use a principled approach to variable ranking relying on predictive information, see<ref type="bibr" target="#b11">Gelman et al. (2014)</ref>for an overview. Conceptually, we use the expected log-predictive density as measure of model fit, and compare the fully specified joint model containing all predictors and the response with a 'no-effects' model where the response is independent of the predictors. The difference of expected log-likelihood between full and 'no-effects' model is given by the relative entropy or Kullback–Leibler divergence D ¼ KLðF full jjF noÀeff Þ. The relative contributions of each individual predictor to D then provides a measure of variable importance. This procedure applied to linear regression with independent predictors results in squared marginal correlations, and applied to DDA it yields squared t-scores, both of which are optimal measures for variable ranking in their respective settings (<ref type="bibr" target="#b27">Zuber and Strimmer, 2011</ref>).</p><formula>l 0j p y if x j ¼ 1:</formula><p>This results in</p><formula>D ¼ X d j¼1 X K y¼1 l yj p y log l yj l 0j ! þ ð1 À l yj Þp y log 1 À l yj 1 À l 0j ! ! ¼ X d j¼1 X K y¼1 p y KL Beðl yj ÞjjBeðl 0j Þ % X d j¼1 1 2 X K y¼1 p y l yj À l 0j r j 2 ¼ X d j¼1 S j (3)</formula><p>where r 2 j ¼ l 0j ð1 À l 0j Þ is the variance of Beðl 0j Þ. For the special case of K ¼ 2 groups S j simplifies to</p><formula>S jðK¼2Þ ¼ p 1 p 2 2 l 1j À l 2j r j 2 :</formula><p>By construction, the score S j is a measure of variable importance of feature j where S j is a weighted sum of the squared z-scores that compare each group mean with the overall pooled mean. This is precisely analogous to the pooled-mean formulation of discriminant analysis described in Ahdesmä ki and Strimmer (2010). If the variances r 2 j are similar across features, then S jðK¼2Þ is apart from a scale factor the squared PPC. As above for learning the discriminant function, we use for estimation of the entropic ranking scores S j either maximum-likelihood or shrinkage estimates of proportions, depending on sample size. Noting that n^ p y =ð1 À ^ p y Þ ¼ ð1=n y À 1=nÞ À1 we may also introduce squared t-scores</p><formula>t 2 y0 ¼ n ^ p y 1 À ^ p y ^ l yj À ^ l 0j ^ r j 2</formula><p>that are properly scaled to allow to contrast the individual contributions of each class relative to each other, similar as in the methods described in Ahdesmä ki and Strimmer (2010) and<ref type="bibr" target="#b23">Tibshirani et al. (2003)</ref>. The estimated ranking score may also be expressed in terms of a weighted sum of the t-scores via</p><formula>^ S j ¼ X K y¼1 ð1 À ^ p y Þt 2 y0 =ð2nÞ :</formula><p>After ranking variables according to the estimated scores ^ S j , with highest scores indicating the most relevant predictors, we use cross-validation to evaluate prediction accuracy for different numbers of included predictors to determine a suitable cutoff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Dichotomization</head><p>With the above setup for BinDA it is straightforward to perform dichotomization. Specifically, we choose thresholds w ¼ ðw 1 ;. .. ; w d Þ to discretize the continuous data z ij to maximize the entropy score D (Equation 3). As in our model assume the predictors are assumed to be independent we can optimize each threshold w j independently by maximizing the individual S j. Note that the same entropy measure is used both for determining the thresholds and for ranking the predictors, thus ranking and discretization is done in an integrative fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Implementation and reproducible research</head><p>We have implemented our approach for multi-class discriminant analysis using binary predictors including functions for variable ranking and dichotomization in the R package binda that is freely available under the GNU General Public License (version 3 or later) from URL http://cran.r-project.org/web/packages/binda/. For reproducibility of the analyzes presented in this paper we provide corresponding R scripts at http://strimmerlab.org/software/ binda/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Validation of binda</head><p>BinDA has been studied extensively and is well established in the literature (e.g.<ref type="bibr" target="#b5">Cox, 1972</ref>). More recently, it was demonstrated that BinDA with naive Bayes assumption can yield high rates of predictive accuracy even if the underlying assumption of independence of predictors is not met (<ref type="bibr" target="#b26">Wilbur et al., 2002;</ref><ref type="bibr" target="#b2">Bender et al., 2004;</ref><ref type="bibr" target="#b20">Park, 2009;</ref><ref type="bibr" target="#b1">An et al., 2013</ref>). For validation of our implementation of BinDA in the R package binda we analyzed a large-scale chemometric test dataset. Specifically, we investigated the 'Dorothea' drug discovery dataset from the NIPS 2003 feature selection challenge (<ref type="bibr" target="#b13">Guyon et al., 2005</ref>). The dataset contains d ¼ 100 000 binary features describing the 3-D properties of chemical compounds that either bind (response label þ 1) or not (label À 1) to thrombin, an enzyme involved in blood clotting. We used the 'Dorothea' training data with n train ¼ 800 samples and corresponding class labels to learn a classifier with binda. Subsequently, we applied the resulting classification rule to the validation dataset with n val ¼ 350 samples and predicted the sample labels of the validation data. As for the validation data the true labels are known we were then able to compute the actual prediction accuracy, i.e. the proportion of correctly identified labels. Due to its algorithmic simplicity training the classifier and ranking variables with binda was computationally inexpensive. Applying class-balanced 5-fold cross-validation with 20 repetitions using the R package crossval on the training data alone we determined that the response can be predicted well with only very few top ranking predictors included in the classification rule. For instance, a binda classifier with three predictors yielded prediction accuracy on the validation set of 0.9371 and of 0.9429 if 10 predictors were used. The predictive accuracy without any variable selection including all 100 000 predictors was 0.9057. For comparison we also trained a random forest (<ref type="bibr" target="#b4">Breiman, 2001</ref>), a tree-based machine learning approach that emerged as one of the overall best performing methods for classification in a recent systematic study (Ferná ndez<ref type="bibr" target="#b8">Delgado et al., 2014</ref>). Due to the high-dimensionality the running time for learning the random forest from the training data was two magnitudes slower than binda, taking 652 seconds on our workstation in comparison to 5 seconds for binda. The random forest yielded an accuracy of 0.94 for prediction of the labels of the independent validation dataset. This analysis confirms that BinDA, though very simple, is able, at least for this data, to perform prediction as accurately as random forest. Correspondingly, if variables in the random forest were ranked according to the Gini variable importance measure the topranking features were mostly identical to those ranked best by BinDA, which indicates that BinDA is indeed able to select the most relevant variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis of pancreas cancer proteomics data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Pancreas cancer study</head><p>For illustration of our proposed approach to classification and peak ranking in mass spectrometry data we also reanalyzed experimental proteomics data from a pancreas cancer study conducted in Leipzig and Heidelberg (<ref type="bibr" target="#b9">Fiedler et al., 2009</ref>). For the training dataset of this study 40 patients with diagnosed pancreas cancer as well as 40 healthy controls were recruited. Each participant of the study donated serum samples which provided the basis for MALDI/TOF measurements. For each sample four technical replicates were<ref type="figure">Fig. 2</ref>. Ranking of 166 peaks in the preprocessed spectra from the pancreas cancer study according to BinDA framework(2009) using (A) the original absence–presence data and (B) the optimized binary matrix. Filled circles indicate pancreas cancer samples, empty circles healthy controls. For clustering, we employed Ward's agglomerative hierarchical clustering based on a Jaccard distance matrix computed using R standard functions hclust() with method¼'ward.D2' and dist() with method¼'binary'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="30">Most Differentially Expressed Peaks</head><formula>● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●</formula><formula>0.0 0.2 0.4 0.6 0.8 Absence/Presence Matrix ● HC067 ● HC118 ● HC008 ● HC011 ● HC033 ● HC050 ● HC057 ● HC119 ● HC120 ● HP321 ● HP413 ● HP161 ● HP438 ● HP402 ● HP410 ● HC122 ● HP151 ● HC001 ● HC002 ● HC055 ● HC054 ● HC062 ● HC056 ● HC064 ● HC059 ● HC066 ● HP417 ● HP429 ● HC049 ● HP419 ● HP212 ● HP416 ● HP424 ● HP121 ● HP262 ● HP425 ● HP393 ● HP150 ● HP120 ● HP208 0.0 0.5 1.0 1.5 2.0 2.5 Dichotomized Data ● HP410 ● HP321 ● HP438 ● HP161 ● HP120 ● HP402 ● HP150 ● HP121 ● HP425 ● HP416 ● HP424 ● HP419 ● HP208 ● HP393 ● HP262 ● HC122 ● HP151 ● HP417 ● HP429 ● HP212 ● HP413 ● HC001 ● HC002 ● HC055 ● HC008 ● HC011 ● HC033 ● HC054 ● HC062 ● HC057 ● HC119 ● HC067 ● HC118 ● HC049 ● HC050 ● HC066 ● HC120 ● HC059 ● HC056 ● HC064 A B</formula><p>obtained. Due to the presence of strong batch effects in our analysis below we restrict ourselves to patients and controls from Heidelberg, leading to a raw dataset containing 160 spectra for 40 probands, The aim of the study was to determine biomarkers to discriminate patients with pancreas cancer from healthy persons.<ref type="bibr" target="#b9">Fiedler et al. (2009)</ref>found marker peaks at m/z 3884 (double charged) and 7767 (single charged) and correspondingly supposed platelet factor 4 (PF4) as potential marker, arguing that PF4 is down-regulated in blood serum of patients with pancreatic cancer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Preprocessing and dichotomization</head><p>For preprocessing of the raw mass spectrometry data we employed the standard analysis pipeline implemented in the R package MALDIquant (<ref type="bibr" target="#b12">Gibb and Strimmer, 2012</ref>). Specifically, the raw data were variance-stabilized, smoothed, baseline-corrected, TICstandardized and aligned. Technical replicates were then averaged, peaks were identified and corresponding intensities extracted from each averaged spectrum. Precise details on the preprocessing can be found in the R script. As a result a protein expression matrix of size 40 patients times 166 peaks was obtained. In total 26% of intensities in the matrix were missing, corresponding to about 44 missing peaks per spectrum. Subsequently, we performed dichotomization of the intensity matrix using the relative entropy criterion of Equation (3). To illustrate the improvement of the resulting binary data matrix over the original absence–presence matrix we conducted hierarchical clustering on the samples. As can be seen in<ref type="figure" target="#fig_1">Figure 1</ref>the clustering based on the optimized binary matrix almost perfectly separates pancreas cancer samples from healthy samples, indicating that there is a strong signal in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Peak ranking and differential expression thresholds</head><p>In order to identify features responsible for the separation of cancer versus healthy samples in<ref type="figure" target="#fig_1">Figure 1B</ref>we applied peak ranking for binary data according to BinDA. The resulting ranking of the 30 best discriminating peaks is shown in<ref type="figure">Figure 2</ref>. As a consequence of the discrete data, the first three top-ranking peaks with m/z values 4495, 8868 and 8989) achieved the same maximum score, followed by the next three peaks 1855, 4468 and 8937, that also achieved an identical score. We note that none of these peaks was identified in the original study. The two PF4 peaks with m/z 3884 and 7768 (the slight difference is due to the MALDIquant alignment procedure) rank on places 148–151 and 157–163, respectively.Using cross-validation, we estimated prediction errors for group separation from the binary data matrix. As for the 'Dorothea' dataset we employed class-balanced 5-fold cross-validation with 20 repetitions. Interestingly, using only five predictors was sufficient to achieve an accuracy of 0.96, sensitivity of 0.96, specificity of 0.97, positive predictive value of 0.97 and negative predictive value of 0.95. This indicates that the observed clear separation between cancer and control samples in<ref type="figure" target="#fig_1">Figure 1B</ref>is attributable to only very few features of the data. Visual inspection of the group of top-ranking differentially expressed peaks revealed a further pattern (<ref type="figure" target="#fig_3">Fig. 3</ref>). First, five of the peaks are all part of the same peak group. Second, the peak group appears both in a single charged (m/z 8868, 8937, 8989) version as well as in a mirrored double charge version (m/z 4468 and 4495). This affirms that there must an underlying biological marker driving the observed changes between cancer and control samples. To study this further, we inspected the intensities for the peaks belonging to the differentially expressed peak group.<ref type="figure">Figure 4</ref>shows the overall density, as well as the sub-density for the cancer samples, along with the dichotomization threshold estimated by binda. For all five peaks the expression respectively the underlying protein abundance is up-regulated in the cancer samples compared with the controls. In addition, the estimated thresholds provide an effective means to separate the two groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8937</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Biological relevance</head><p>Finally, we also tried to identify the biological molecules behind the differentially expressed peak group shown in<ref type="figure" target="#fig_3">Figure 3</ref>. Specifically, we used the TagIdent tool (<ref type="bibr" target="#b10">Gasteiger et al., 2005</ref>) with settings Mw 8936.97, Mw range 0.05% and organism homo sapiens to query the UniProtKB/Swiss-Prot database (<ref type="bibr">The UniProt Consortium, 2015</ref>). This indicated a potential link of the central peak m/z 8937 to PDPFL_HUMAN, the pancreatic progenitor cell differentiation and proliferation factor-like protein, as well as to a fragment of C3adesArg, an acylation stimulating protein. The increased abundance of PDPFL_HUMAN in pancreas cancer tissue appears highly plausible, and the increased concentration of C3adesArg in serum of cancer patients has also been reported previously (e.g. Opstal-van<ref type="bibr" target="#b19">Winden et al., 2011</ref>). Another biologically relevant result of our analysis based on BinDA is that the originally proposed PF4 marker is not differentially expressed and hence cannot be used to distinguish between cancer and healthy samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>We have presented a simple yet effective approach to differential expression and classification for mass spectrometry data using BinDA. Our approach may be viewed as generalization of<ref type="bibr" target="#b24">Tibshirani et al. (2004)</ref>and can be applied also for multi-group discriminant analysis. A particular feature is the use of the same relative entropy criterion for peak ranking and selection and for dichotomization of the continuous protein intensity data. In addition, we obtain decision thresholds from the protein intensities that are biologically and diagnostically easy to interpret. In illustrative analysis of high-dimensional drug discovery data we showed that our approach implemented in the R package binda is computationally effective and yet competitive with a random forest. Furthermore, in reanalysis of proteomics data from a pancreas cancer study we found statistically predictive marker peaks to tumor cell growth unrecognized in the original analysis. This confirms the importance of reproducible research in proteomics, where it is unfortunately still not common to provide analysis scripts and software openly. In addition to mass spectrometry analysis, there are many bioinformatics applications in which binary data are collected, and hence, in which the present methodology and software will potentially be useful. Examples include meta-genomics, where the absence and presence of proteins and genes is compared with a pan-genome (<ref type="bibr" target="#b17">Medini et al., 2008</ref>), community analysis by DNA fingerprinting (<ref type="bibr" target="#b26">Wilbur et al., 2002</ref>), and chemometrics (<ref type="bibr" target="#b2">Bender et al., 2004</ref>). Exploring additional applications may also lead to further methodological extensions of the procedures currently implemented in binda, such as modeling overdispersion, e.g. by employing the BetaBernoulli rather than Bernoulli distribution, and to take account of interactions among predictors, e.g. by modeling pair-wise correlation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For independent binary predictors the joint full</head><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Clustering of samples from the pancreas cancer study of Fiedler et al. (2009) using (A) the original absence–presence data and (B) the optimized binary matrix. Filled circles indicate pancreas cancer samples, empty circles healthy controls. For clustering, we employed Ward's agglomerative hierarchical clustering based on a Jaccard distance matrix computed using R standard functions hclust() with method¼'ward.D2' and dist() with method¼'binary'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Top ranking peak group containing five differentially expressed peaks: (A) double-and (B) single-charged peaks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 3156 Bioinformatics, 31(19), 2015, 3156–3162 doi: 10.1093/bioinformatics/btv334 Advance Access Publication Date: 28 May 2015 Original Paper</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>t−Scores (Class Mean vs. Pooled Mean)</figDesc><table>Peaks (m/z) 

1264 
6051 
2756 
3264 
1897 
8184 
5005 
4251 
4092 
1466 
1021 
9181 
2953 
4236 
1207 
8131 
5960 
5906 
2093 
1780 
5946 
5864 
1866 
2023 
8937 
4468 
1855 
8989 
8868 
4495 

−6 −4 −2 0 
2 
4 
6 

−6 −4 −2 0 
2 
4 
6 

cancer 
control 

</table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">S.Gibb and K.Strimmer at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Feature selection in omics prediction problems using cat scores and false non-discovery rate control</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ahdesmäki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="503" to="519" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Testing the statistical significance of an ultra-highdimensional naı¨venaı¨ve bayes classifier</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>An</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Interface</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="223" to="229" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">Molecular similarity searching using atom environments, information-based feature selection, and a naı¨venaı¨ve Bayesian classifier</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bender</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inf. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="170" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Breiman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">The analysis of multivariate binary data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Cox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. C</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="113" to="120" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Multivariate Bernoulli distribution</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Dai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bernoulli</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1464" to="1483" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Feature selection and machine learning with mass spectrometry data for distinguishing cancer and non-cancer samples</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Datta</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">M</forename>
				<surname>Depadilla</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Method</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="79" to="92" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Do we need hundreds of classifiers to solve real world classification problems?</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ferná Ndez-Delgado</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3133" to="3181" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Serum peptidome profiling revealed platelet factor 4 as a potential discriminating peptide associated with pancreatic cancer</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">M</forename>
				<surname>Fiedler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3812" to="3819" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title level="m" type="main">Protein identification and analysis tools on the ExPASy server</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Gasteiger</surname>
			</persName>
		</author>
		<editor>Walker, J.M.</editor>
		<imprint>
			<date type="published" when="2005" />
			<publisher>The Proteomics Protocols Handbook. Humana Press Totowa</publisher>
			<biblScope unit="page" from="571" to="607" />
			<pubPlace>New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Understanding predictive information criteria for Bayesian models</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gelman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="997" to="1016" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">MALDIquant: a versatile R package for the analysis of mass spectrometry data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gibb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2270" to="2271" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Result analysis of the NIPS 2003 feature selection challenge</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Guyon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Saul, L.K. et al.</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="545" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Idiot&apos;s Bayes—not so stupid after all? Int</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Hand</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Rev</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="385" to="398" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Entropy inference and the James-Stein estimator, with application to nonlinear gene association networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hausser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1469" to="1484" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Potentials and pitfalls of clinical peptidomics and metabolomics</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">B</forename>
				<surname>Leichtle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swiss Med. Wkly</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Microbiology in the post-genomic era</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Medini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Microbiol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="419" to="430" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Statistical methods for proteomic biomarker discovery based on feature extraction or functional modeling approaches</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Morris</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Interface</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="117" to="135" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Searching for early breast cancer biomarkers by serum protein profiling of pre-diagnostic serum; a nested casecontrol study</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">W J</forename>
				<surname>Opstal-Van Winden</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cancer</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">381</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Independent rule in classification of multivariate binary data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Park</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Multi. Anal</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="2270" to="2286" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Selecting the right objective measure for association analysis</title>
		<author>
			<persName>
				<forename type="first">P.-N</forename>
				<surname>Tan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="293" to="313" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">UniProt: a hub of protein information</title>
	</analytic>
	<monogr>
		<title level="j">The UniProt Consortium. Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="204" to="212" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Class prediction by nearest shrunken centroids, with applications to DNA microarrays</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="104" to="117" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Sample classification from protein mass spectrometry, by &apos;peak probability contrasts</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tibshirani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3034" to="3044" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">A hybrid approach to protein differential expression in mass spectrometry-based proteomics</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1586" to="1591" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Variable selection in high-dimensional multivariate binary data with application to the analysis of microbial community DNA fingerprints</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Wilbur</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="378" to="386" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">High-dimensional regression and variable selection using CAR scores</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Zuber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>