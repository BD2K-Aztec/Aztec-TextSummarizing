
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">G-BLASTN: accelerating nucleotide alignment by graphics processors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">10 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Kaiyong</forename>
								<surname>Zhao</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Xiaowen</forename>
								<surname>Chu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computational and Theoretical Studies</orgName>
								<orgName type="institution">Hong Kong Baptist University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">G-BLASTN: accelerating nucleotide alignment by graphics processors</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="1384" to="1391"/>
							<date type="published" when="2014">10 2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu047</idno>
					<note type="submission">Sequence analysis Advance Access publication January 24, 2014 Received on August 27, 2013; revised on January 10, 2014; accepted on January 21, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Dr. John Hancock Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Since 1990, the basic local alignment search tool (BLAST) has become one of the most popular and fundamental bioinformatics tools for sequence similarity searching, receiving extensive attention from the research community. The two pioneering papers on BLAST have received over 96 000 citations. Given the huge population of BLAST users and the increasing size of sequence databases, an urgent topic of study is how to improve the speed. Recently, graphics processing units (GPUs) have been widely used as low-cost, high-performance computing platforms. The existing GPU-BLAST is a promising software tool that uses a GPU to accelerate protein sequence alignment. Unfortunately, there is still no GPU-accelerated software tool for BLAST-based nucleotide sequence alignment. Results: We developed G-BLASTN, a GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST. G-BLASTN can produce exactly the same results as NCBI-BLAST, and it has very similar user commands. Compared with the sequential NCBI-BLAST, G-BLASTN can achieve an overall speedup of 14.80X under &apos;megablast&apos; mode. More impressively, it achieves an overall speedup of 7.15X over the multithreaded NCBI-BLAST running on 4 CPU cores. When running under &apos;blastn&apos; mode, the overall speedups are 4.32X (against 1-core) and 1.56X (against 4-core). G-BLASTN also supports a pipeline mode that further improves the overall performance by up to 44% when handling a batch of queries as a whole. Currently G-BLASTN is best optimized for databases with long sequences. We plan to optimize its performance on short database sequences in our future work. Availability:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The basic local alignment search tool (BLAST) is one of the most fundamental software tools in bioinformatics for matching biological sequences (<ref type="bibr" target="#b9">Altschul et al., 1990</ref><ref type="bibr" target="#b10">Altschul et al., , 1997</ref>). Due to the explosive growth of sequence data, improving the speed of BLAST has become increasingly critical. In the last decade, many attempts have been made to design and develop new BLAST software tools for specific hardware (<ref type="bibr" target="#b13">Fei et al., 2008;</ref><ref type="bibr" target="#b14">Jacob et al., 2007;</ref><ref type="bibr" target="#b28">Sotiriades and Dollas, 2007;</ref><ref type="bibr" target="#b30">Zhang et al., 2000</ref>) or even parallel supercomputers (<ref type="bibr" target="#b15">Lin et al., 2008</ref>). Unfortunately, most researchers do not have access to these hardware platforms. Following the popularity of multicore processors, several BLAST software tools using multiple CPU cores for increased speed have been developed. One good example is the widely used National Center for Biotechnology Information (NCBI) BLAST, which supports multithreading in the preliminary stage of the BLAST algorithm (<ref type="bibr" target="#b11">Camacho et al., 2009</ref>). Our experiments on a server with two quad-core Intel Xeon CPUs show that the multithreaded NCBI-BLAST can achieve an average speedup of 3$4X over the sequential version. NCBI-BLAST also supports an indexed Mega-BLAST module, which uses the database index to achieve an approximate speedup of 2$4X (<ref type="bibr" target="#b24">Morgulis, 2008</ref>). PLAST is a parallel implementation of BLAST (<ref type="bibr" target="#b25">Nguyen and Lavenier, 2009</ref>) that applies a new indexing technique together with SSE instructions and multithreading to achieve better alignment speed. KLAST is an optimized and extended version of PLAST, and includes a module KLASTn to compare two sets of DNA sequences. As compared with NCBI BLASTN, KLASTn can achieve good speedup with comparable sensitivity. In recent years, Graphics Processing Units (GPUs) have been widely accepted as low-cost, high-performance computing platforms (<ref type="bibr" target="#b27">Owens et al., 2008</ref>). Compared with traditional multi-core CPUs, GPUs have much higher computational horsepower and memory bandwidth. Many bioinformatics tools have been accelerated by GPUs in recent years (<ref type="bibr" target="#b12">Dematte and Prandi, 2010;</ref><ref type="bibr">Liu et al., 2012a, b;</ref><ref type="bibr" target="#b20">Lu et al., 2012</ref><ref type="bibr" target="#b19">Lu et al., , 2013</ref><ref type="bibr" target="#b21">Manavski and Valle, 2008</ref>). The significant difference between GPU and CPU architectures has created many challenges in developing highly efficient GPU software (<ref type="bibr" target="#b26">Nickolls, 2007</ref>). Without the development of carefully designed parallel algorithms and sophisticated optimizations, the huge potential of GPUs may not be fully realized. Some GPU-based software tools have been developed for protein sequence alignment. Ling's GPU-based BLAST software can achieve a speedup of 1.7$2.7X, compared with NCBIBLAST (<ref type="bibr" target="#b16">Ling and Benkrid, 2010</ref>). Recently, Vouzis and Sahinidis (2011) developed GPU-BLAST, which can typically achieve acceleration speedup of 3$4X relative to the sequential NCBI-BLAST. The major advantage of GPU-BLAST is that it can produce the same results as NCBI-BLAST. To the best of our knowledge, we are the first to provide an open-source GPU solution, namely G-BLASTN, for nucleotide sequence alignment that can produce the same results as NCBI-BLAST. G-BLASTN is developed on top of the NCBI-BLAST source code. It currently supports the 'megablast' and 'blastn' modes of NCBI-BLAST. For brevity, we use BLASTN to refer to the nucleotide blast module of NCBI-BLAST. The major idea behind G-BLASTN is to store a small hash table in the fast GPU cache memory and then scan the DNA database in parallel using all of the available GPU cores. We have overcome several challenges to fully use the GPU horsepower. To achieve significant speedup, some other parts of BLASTN have also been optimized. We evaluate G-BLASTN's performance by running a set of experiments on human and mouse genome databases, as well as a partial of the NCBI nucleotide (nt) collection database. Using a contemporary NVIDIA GTX780 GPU with a cost of $650, G-BLASTN under 'megablast' mode can achieve significant speedups over the multithreaded BLASTN running on 4-core or 8-core CPUs. When running under the more sensitive 'blastn' mode, G-BLASTN also achieves reasonable speedups. When processing a batch of queries, G-BLASTN supports a pipeline mode that can further improve the performance by up to 44%. The remainder of the article is organized as follows. In Section 2, we briefly review the main algorithms of BLASTN and present our design for G-BLASTN. In Section 3, we present the detailed implementation of G-BLASTN. In Section 4, we present the experimental results. We conclude the article in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">BLASTN algorithms</head><p>BLASTN is designed to efficiently search nucleotide databases using a nucleotide query sequence (<ref type="bibr" target="#b11">Camacho et al., 2009</ref>). BLASTN's high level pseudocode is given in<ref type="figure" target="#fig_0">Figure 1</ref>, which consists of four stages. The 'setup' stage prepares search options, reads and prepares the query sequence and database sequence and builds the lookup table. The 'scanning' stage performs a preliminary search comprising three steps: seeding, ungapped extensions and gapped extensions. The seeding step scans the database for hits (i.e. a match with some word in the lookup table). The hits are then extended by ungapped alignment. The alignments that exceed a threshold score will go through the gapped extensions. Only the gapped alignments that exceed another threshold score will be saved as 'preliminary' matches. The 'trace-back' stage takes the preliminary matches as input, considering ambiguous nucleotides and finds the locations of insertions and deletions. The 'output' stage displays the alignment results to the user. BLASTN's efficiency relies on the assumption that any alignment of interest between the query and the database will contain at least one W-gram (i.e. a subsequence of length W), where W is a parameter known as 'BLASTN word size'. In practice, for any given query sequence BLASTN will construct a lookup table that stores the offsets into the query where each possible w-gram occurs, where w is a parameter known as the 'lookup table word size' which is less than or equal to W. Because each letter can be one of {A, C, G, T}, the lookup table has 4 w entries. The seeding procedure walks through the database sequence to find hits. In each round, it fetches a w-gram, calculates its hash value, looks into the lookup table and records all matched offset pairs (i.e. the pair of offsets of the matched w-gram in the query and database, respectively) if there are any. When W is larger than w, it is not necessary to scan the database letter by letter; instead, BLASTN scans the database in strides. The maximum stride size without missing any match is W-wþ1. For extremely long nucleotide databases, the seeding procedure is usually the most time-consuming step. After all w-gram hits have been found, we must determine whether each hit belongs to a W-gram match. This is done through the miniextension procedure (a.k.a. exact match extension), which extends each w-gram in both the left and right directions to check the existence of exact W-gram matches. The mini-extension step can be time consuming if millions of w-gram hits must be extended. Once we find all of the W-gram hits, the ungapped extension step begins, allowing for mismatches. Ungapped alignments that exceed a threshold score are stored for gapped extension. In the scanning stage, gapped extension returns only the score and extent of the alignment while the number and position of insertions, deletions and matching letters are not stored. During the whole-scanning stage, BLASTN processes the sequence in NCBI-NA2 format, in which each nucleic acid is represented by two bits. Hence, ambiguities cannot be handled. In the trace-back stage, ambiguous nucleotides are restored by converting NCBI-NA2 format into NCBI-NA8, and more sensitive heuristic parameters are used for the final gapped alignment. Finally, the output step formats the results according to the user options and prints the results for the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Design of G-BLASTN</head><p>GPUs have become mature, many-core processors with much higher computational power and memory bandwidth than today's CPUs. A GPU consists of a scalable number of streaming multiprocessors (SMs), each containing some streaming processors (SPs), special function units (SFUs), a multithreaded instruction fetch and issue unit, registers and a read/write shared memory. CUDA is currently the most popular programming model for general purpose GPU computing. The best way to use the hundreds to thousands of GPU cores is to generate a large number of CUDA threads that can access data from multiple memory spaces during their execution, as illustrated in<ref type="figure">Figure 2</ref>. Each thread has its private registers and local memory. Each GPU kernel function generates a grid of threads that are organized into thread blocks. Each thread block has shared memory visible to all threads within the block and with<ref type="figure">Fig. 2</ref>. GPU memory hierarchy the same lifetime as the block. All threads have access to the same global memory. Two additional read-only memory spaces are accessible by all threads: the constant and texture memory spaces, both of which have limited caches. Due to the complexity of BLASTN software, exploiting GPUs to accelerate BLASTN is a non-trivial task. The main challenge is that not all of the steps involved in BLASTN are suitable to be parallelized by GPUs. To identify which steps should be parallelized, we conducted a profiling study by running 300 different queries with a broad range of lengths against the human build 36 genome database to analyze the time distribution of different BLASTN steps under 'megablast' mode (<ref type="figure" target="#fig_2">Fig. 3</ref>). We mainly observed the following details. The scanning stage is the most time-consuming and accounts for 69–93% of the total execution time. Surprisingly, BLASTN spends 5–25% of the total execution time in the setup stage, mainly initializing the mask database. The trace-back stage takes negligible time for most queries, but can occasionally take a very long time. To achieve a good overall speedup, we designed G-BLASTN as follows. Its major component is a set of CUDA kernel functions that run on GPUs to significantly accelerate the seeding and mini-extension steps in the scanning stage. It is designed to initialize the mask database once and then serve a large number of queries. Therefore, the time spent in database initialization can be largely removed. We optimized the two most time consuming functions in the trace-back stage and further designed a pipeline mode under which the trace-back, output and scanning stages can run simultaneously. The general framework of G-BLASTN is shown in<ref type="figure" target="#fig_1">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IMPLEMENTATION</head><p>We use CUDA C language to implement G-BLASTN based on NCBI BLAST 2.2.28 software package. In the following, we present the detailed implementation of the major modules of G-BLASTN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Accelerating the seeding step by GPU</head><p>The main task of the seeding step is to scan the database sequences and identify all w-gram matches. Due to the large database sizes, the seeding step is the most time consuming in BLASTN. Fortunately, the seeding step can be parallelized due to the independence of the tasks at different offsets of the database. G-BLASTN first loads the database sequences to GPU global memory. Then for each query sequence, it stores a copy of the lookup table in GPU texture memory to achieve ultrafast table lookup. To scan each single database sequence, many GPU threads are generated to fully exploit the large number of GPU cores. The number of threads is equal to the number of thread blocks multiplied by the number of threads per thread block. As a rule of thumb, the number of thread blocks should be a multiple of the number of physical SMs available in the GPU. We empirically fine-tune the thread dimensions to optimize the performance. The implementation of the seeding step on the GPU is a major challenge, however. In CUDA, each thread block is organized as a number of warps, and each warp of threads is executed by a Single Instruction, Multiple Data (SIMD) unit. When threads within a warp take different execution paths, the SIMD unit will take multiple runs to go through these divergent paths, which will significantly decrease the utilization of GPU cores. In the case of BLASTN, the w-grams at different offsets of the database sequence may have no match or many matches to the query sequence, which can lead to severe thread branch divergence that decreases the performance significantly. To conquer this challenge, we divide the seeding step into two sub-steps: 'scan' and 'lookup'. In the scan sub-step, we go through the whole-database sequence in parallel and record all offsets of the database that have at least one match to the query. Notice that we do not need to know how many matches have been found and where they are for each offset. Thus, each GPU thread can perform almost the same execution path and the effect of thread branch divergence can be minimized. In the lookup sub-step, we use another GPU-kernel function to recheck all matched offsets and construct the complete set of matched offset pairs. This strategy works very well because the scan substep dominates the time of the seeding step. There is yet another challenge in implementing the scan substep on the GPU. Once a thread finds a w-gram match, it increases a global counter and writes the matched offset into a global array, resulting in two negative consequences: (i) increasing the global counter is an atomic operation, which means only one among all threads can operate while others have to wait; and (ii) writing a single offset pair into the global array can waste a lot of GPU memory bandwidth. To overcome this challenge, we<ref type="figure" target="#fig_0">Figure S1</ref>use a local counter and a local array for each thread block as temporary storage for the global counter and global array. The local counter and array are held in GPU shared memory. Now all thread blocks can operate on the local counters and arrays simultaneously, boosting the overall performance. Once a local array becomes full, the set of offset pairs is written into global array as a whole and the global counter is updated by an atomic operation. We exploit coalesced memory write operations to improve memory throughput. Meanwhile, the number of atomic operations on the global counter can be significantly reduced. The framework of the scan sub-step on GPU is shown in<ref type="figure" target="#fig_5">Figure 5</ref>. For performance consideration, BLASTN supports two types of lookup tables for different types of queries: small and megablast (in current NCBI-BLAST, both types of lookup tables are supported by 'blastn' mode and 'megablast' mode). Each type of lookup table has its own set of algorithms. Therefore, we have to implement different GPU-kernel functions for different types of lookup tables. A small lookup table contains a simple backbone array and an overflow array, both of which are simply an array of 16-bit integers. If the value of a backbone cell is nonnegative, it means that position in the lookup table contains exactly one query offset, which equals the cell value. If the value is À1, the corresponding w-gram does not exist in the query sequence. If the value is –x (x41), the corresponding w-gram appears multiple times in the query sequence and their offsets begin at offset x of the overflow array and continue until a negative value is encountered. The pseudocode of our GPU scan and lookup kernel functions using a small lookup table are shown in<ref type="figure" target="#fig_3">Figures 6</ref>and 7, respectively. The backbone array is held in GPU texture memory. Notice that a GPU-kernel function specifies the behavior of a single GPU thread. There are hundreds of thousands of GPU threads simultaneously active, each of which executes the same instructions while working on different data items. The megablast lookup table comprises three arrays: presence vector (PV array), hash table (hashtable<ref type="bibr">[]</ref>) and next position (next_pos<ref type="bibr">[]</ref>). The PV array is a bit field with one bit for each hash table entry. If a hash table entry contains a query offset, the corresponding bit in the PV array is set. The scanning process first checks the PV array to see whether there are any query offsets in a particular lookup table entry. The hashtable<ref type="bibr">[]</ref>array is a thick backbone with one word for each of the lookup table entries. If a lookup table entry has no query offsets, the corresponding entry in hashtable<ref type="bibr">[]</ref>is zero; otherwise, it is an offset into<ref type="bibr">[]</ref>. The position in next_pos<ref type="bibr">[]</ref>is in fact the query offset, and the actual value at that position is a pointer to the succeeding query offset in the chain. A value of zero means the end of the chain. The pseudocode of our GPU scan and lookup kernel functions using the megablast lookup table are shown in Figures 8 and 9, respectively. The scan-kernel function checks the PV array to quickly determine whether there is a match. To achieve the best table lookup performance, the PV array is held in texture memory. The lookup kernel function takes the output of scan function as input and checks the hashtable<ref type="bibr">[]</ref>and next_pos<ref type="bibr">[]</ref>to find the complete set of matched offset pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Accelerating the mini-extension step by GPU</head><p>It is not uncommon for the scan sub-step to return millions of seed matches. The mini-extension step is designed to verify whether each w-gram match can be extended to a W-gram match when w5W. We can create a huge number of GPU threads to extend those w-gram matches simultaneously. Each GPU thread reads one offset pair from the matched offset pair array, extends on the left side and then extends on the right side. If it finds a W-gram match, this offset pair will be recorded for further gapped extension. Given that the mini-extension algorithm exhibits no big difference from the original BLASTN, we do not provide the pseudocode here. We note that there are two versions of mini-extension, one for the small lookup table and another for the megablast lookup table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Optimizing the trace-back step</head><p>As mentioned in Section 2.2, occasionally the trace-back step takes quite a long time, which may counteract the speedup achieved by the previous steps. Unfortunately, the trace-back step is not naturally suitable for GPUs. We therefore resort to the following optimization techniques. First, function s_SeqDBMap NA2ToNA8() uses a translation table to convert sequence data from NCBI-NA2 to NCBI-NA8 format. BLASTN translates the data character by character, which does not fully use the CPU memory bandwidth. In G-BLASTN, we replace four 8-bit memory writes with a single 32-bit memory write, which boosts the speed by two to three times. Second, function s_SeqDBMapNcbiNA8To BlastNA8() uses a 16-byte translation table to convert sequence data from NCBI-NA8 to BLAST-NA8 format, character by character. G-BLASTN uses a 128-bit union (denoted by ntob_table) to hold the 16-byte translation table, and then SSE instructions to write 16 bytes as a whole, which achieves a speedup of 3$4X. The SSE instructions are shown in<ref type="figure" target="#fig_0">Figure 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Pipeline mode for multiple queries</head><p>Once we have accelerated the scanning stage by GPU, other stages such as trace-back and output may start to occupy a relatively large portion of the total execution time, especially when there are many final hits. G-BLASTN supports a pipeline mode when handling a batch of queries, as shown in<ref type="figure" target="#fig_0">Figure 11</ref>. The main advantage is that GPU and CPU can work on different tasks simultaneously. When the GPU is busy seeding, the CPU can execute the trace-back or output steps for a previous query. To achieve this purpose, G-BLASTN uses multithreading to maintain four queues: query, job, prelim and result. A master thread reads the queries and puts them into the query queue, andthen creates the job queue. The prelim thread(s) fetches jobs from the job queue and uses GPU to execute the preliminary search, storing the results in the prelim queue. The trace-back thread(s) reads from the prelim queue, executes the trace-back step and stores the results in the results queue. Finally, the print thread prints the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">General setup and datasets</head><p>The GPU experiments were performed on a desktop computer with an Intel quad-core CPU and Nvidia GTX780 GPU. The CPU experiments were performed on two different platforms: a 4-core platform which is the same computer that runs the GPU experiments; and an 8-core platform which is a server with two Intel Xeon CPUs. The detailed system configuration is shown in<ref type="figure" target="#tab_1">Table 1</ref>. We used the following two command lines to run NCBI BLASTN and G-BLASTN, respectively. $blastn-db 5database4-query 5query4-task megablastj blastn-outfmt 7-out 5file4-dust yes-window_masker_db 5masker_db4-num_threads 51j4j84 $gblastn-db 5database4-query_list 5query list4-task mega blastjblastn-outfmt 7-out 5file4-dust yes-window_masker_db 5masker_db4-use_gpu true-mode 51j24-num_threads 51j4j84 We used gettimeofday() functions to measure the program execution time. Each experiment was run 10 times and the average results are reported in this article. Databases: We chose human build 36 and mouse build 36 genome databases for the experiments of 'megablast' mode. In addition, we constructed a database to test the 'blastn' mode by selecting all sequences with length no 52 million from NCBI nt database. This partial NCBI nt database has a raw size of 8.4GB and can well fit into a single GPU card with 3GB memory after compression. All databases were masked with WindowMasker (<ref type="bibr" target="#b22">Morgulis et al., 2006a</ref>), including low-complexity filtering by DUST (<ref type="bibr" target="#b23">Morgulis et al., 2006b</ref>). Queries: To test the 'megablast' mode, we chose queries from the NCBI ftp server: ftp://ftp.ncbi.nlm.nih.gov/pub/agarwala/ indexed_megablast/queries (<ref type="bibr" target="#b24">Morgulis, 2008</ref>). Six query sets, each containing 100 queries, were used, which are referred to as Qsmall ($500 bases, range: 501–506), Qmedium ($10 KB, range: 10 000–10 446) and Qlarge ($100 KB, range: 100 001– 102 087). To test the 'blastn' mode, we chose the first 500 bacterial sequences from the NCBI server: http://www.ncbi. nlm.nih.gov/sra/SRX338063, namely Qbac. The length information of all database and query sequences can be found in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Performance under normal mode</head><p>Under normal mode, G-BLASTN handles the queries one at a time. We first present the experimental results of 'megablast'. The speedups over 8-core platform on human genome database are shown in<ref type="figure" target="#fig_0">Figure 12</ref>. The speedups of other experiments are shown in Supplementary Figures S3–S6. We also show the average speedup of each query set in<ref type="figure" target="#tab_2">Table 2</ref>. The overall speedups are calculated as the average of all 1600 query experiments for each hardware setting. As<ref type="figure" target="#fig_0">Fig. 11</ref>. The pipeline mode of G-BLASTN compared with 4-core Intel i7-3820, G-BLASTN achieves an overall speedup of 7.15X. As compared with the 8-core platform, G-BLASTN achieves an overall speedup of 13.76X. There are several reasons why BLASTN runs much faster on i7-3820 than on Xeon E5620. First, i7-3820 has a much higher working frequency than E5620. Secondly, the memory bandwidth of i7-3820 is twice of E5620. Thirdly, the memory module of our i7-3820 platform is faster than that of E5620 platform. Based on the results of E5620, we can notice that the speedups achieved using 8 cores are only slightly better than using 4 cores. We also notice that the speedups on the human database are less than those on the mouse database. This is mainly because the human build 36 database consists of 367 sequences, 4200 of which are short sequences (51 million bp). In contrast, the mouse build 36 database consists of 21 very long sequences. We will discuss more on this issue in Section 5. We evaluate the performance of 'blastn' mode using Qbac query set against human, mouse and the partial NCBI nt databases. We show the average speedups of each database and the overall speedups in<ref type="figure">Table 3</ref><ref type="figure" target="#fig_4">Figure S7</ref>. Since the ungapped extension is sequentially executed on CPU, the speedups achieves under 'blastn' mode are much less than 'megablast'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Performance under pipeline mode</head><p>To evaluate the performance of pipelined G-BLASTN, we use all queries in each dataset as a single input to G-BLASTN. The speedups against the NCBI BLAST on Intel i7-3820 are shown in<ref type="figure">Table 4</ref>. If we compare<ref type="figure">Table 4</ref>with Tables 2 and 3, we can observe a significant improvement on the speedups for many datasets. For small and medium queries under 'megablast', the trace-back and output steps account for a very small portion of the total time and hence the pipeline design does not offer much of an advantage. For large queries using 'megablast' in which the trace-back and output steps take a much longer time, the pipeline design hides a significant portion of time. Under 'blastn' mode, the pipeline design can further improve the speedups of the Qbac query set by 19–44%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSIONS AND CONCLUSIONS</head><p>In this article, we describe our design and implementation of G-BLASTN, an open source software tool for nucleotide alignment based on the widely used NCBI-BLAST. G-BLASTN exploits the power of GPUs to accelerate nucleotide alignments. Compared with a contemporary quad-core Intel CPU running at 3.6 GHz, G-BLASTN on a single $650 GPU card can achieve overall speedups of 14.8X and 4.32X under 'megablast' mode and 'blastn' mode, respectively. When compared with multithreaded NCBI-BLAST that uses four CPU cores, G-BLASTN can still achieve overall speedups of 7.15X ('megablast') and 1.56X ('blastn'). G-BLASTN also supports a pipeline mode that further improves the overall performance by up to 44% when handling multiple queries. G-BLASTN can be improved in the following directions. At present, G-BLASTN invokes a kernel function for each database sequence, which is not efficient when the length of the database sequence is shorter than one million bps. There are several possible solutions to this problem. One possibility is to aggregate short database sequences into longer ones. Another solution is to process multiple database sequences in each kernel function call. G-BLASTN is also limited by the GPU memory size. We firstThe meaning of the ''overall'' values are the average speedups of all query experiments for each hardware setting. plan to extend G-BLASTN to support multiple GPU cards. Doing so can not only support larger databases, but also achieve better speedups. A long-term solution is to divide the huge database into smaller volumes, and then scan each volume in GPU one by one. To minimize the overhead of copying database into GPU memory, multiple queries should be processed at a time. A more challenging task is to accelerate other steps such as ungapped extension, gapped extension and trace-back, which will improve the performance of 'blastn' mode significantly. Finally, we also plan to support 'discontiguous megablast mode' in our future work. Funding: Hong Kong Baptist University (grant FRG2/11-12/158). Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. High level Pseudocode of BLASTN Fig. 2. GPU memory hierarchy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.4.</head><figDesc>Fig. 4. The framework of G-BLASTN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Profiling of BLASTN for 300 query sequences (500$100 000 bases) against human build 36 genome under 'megablast' mode. The lengths of the query sequences can be found in Supplementary Figure S1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.6.</head><figDesc>Fig. 6. The GPU scan-kernel function using small lookup table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.7.</head><figDesc>Fig. 7. The GPU lookup kernel function using small lookup table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Framework of scan sub-step on GPU</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.8.</head><figDesc>Fig. 8. The GPU scan-kernel function using megablast lookup table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.9.</head><figDesc>Fig. 9. The GPU lookup kernel function using megablast lookup table</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.10.</head><figDesc>Fig. 10. SSE instructions used by s_SeqDBMapNcbiNA8ToBlastNA8()</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.12.</head><figDesc>Fig. 12. Speedup of G-BLASTN on human genome database (GTX780 versus Two Xeon E5620)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><figDesc>. G-BLASTN achieves an overall speedup of 1.56 and 2.95 as compared with 4-core i7-3820 and 8-core E5620, respectively. As compared with 'megablast' mode, 'blastn' mode has a much smaller value of stride size, which results in more scanning workload and more seed hits. Therefore the ungapped extension step under 'blastn' mode takes much longer time than under 'megablast' mode, as shown in Supplementary</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. System configuration</figDesc><table>CPU 
Memory 
GPU 
Storage OS 

Intel Core i7-
3820 (4-core, 
3.6 GHz) 

32GB 
(DDR3 1600) 

Nvidia 
GTX780 

SATA 
2TB 

CentOS 
6.4 (Linux 
kernel 2.6.32) 
2 x Intel Xeon 
E5620 (8-core, 
2.4 GHz) 

24GB (DDR3 
1333) 

N/A 
SATA 
1TB 

Redhat 5.5 
(Linux kernel 2.6.18) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2. Average speedup of G-BLASTN under 'megablast' mode</figDesc><table>Database 
Query 
Intel i7-3820 
Intel Xeon E5620 

1-core 
4-core 
1-core 
4-core 
8-core </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 3.</figDesc><table>Speedup of G-BLASTN under 'blastn' mode using Qbac query 
set 

Database 
Intel i7-3820 
Intel Xeon E5620 

1-core 
4-core 
1-core 
4-core 
8-core 

Human 
4.58 
1.57 
8.01 
2.99 
2.15 
Mouse 
5.02 
1.83 
8.84 
3.51 
2.70 
NCBI nt 
3.37 
1.29 
5.71 
2.36 
1.74 
Overall 
4.32 
1.56 
7.52 
2.95 
2.20 

</table></figure>

			<note place="foot">ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">K.Zhao and X.Chu at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">G-BLASTN at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Human Qsmall</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Mouse Qsmall 18.50 9.37 44.12 21</title>
		<imprint>
			<biblScope unit="page">1828</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">The meaning of the &apos;&apos;overall&apos;&apos; values are the average speedups of all query experiments for each hardware setting</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Mode Database Query 1-core 4-core megablast Human Qsmall 10</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<monogr>
		<title level="m" type="main">Qlarge 12.19 4</title>
		<imprint>
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Mouse Qsmall 20.49 10</title>
		<imprint>
			<biblScope unit="page">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Qmedium</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">51</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Mouse Qbac 6.49 2.36 NCBI nt Qbac 4.73 1</title>
		<imprint>
			<biblScope unit="page">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">REFERENCES</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Basic local alignment search tool</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="page" from="403" to="410" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Gapped BLAST and PSI-BLAST:Anew generation of protein database search programs</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3389" to="3402" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">BLASTþ: architecture and applications</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Camacho</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">421</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">GPU computing for systems biology</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Dematte</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Prandi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="323" to="333" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">FPGA-based accelerators for BLAST families with multi-seeds detection and parallel extension</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Fei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference</title>
		<meeting>the 2nd International Conference<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="58" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">FPGA-accelerated seed generation in Mercury BLASTP</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Jacob</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 15th Annual IEEE Symposium on Field-Programmable Custom Computing Machines</title>
		<meeting>15th Annual IEEE Symposium on Field-Programmable Custom Computing Machines<address><addrLine>California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="95" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Massively parallel genomic sequence search on the Blue Gene/P architecture</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM/IEEE Conference on Supercomputing</title>
		<meeting>the 2008 ACM/IEEE Conference on Supercomputing<address><addrLine>Austin, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM/IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Design and implementation of a CUDA-compatible GPU-based core for gapped BLAST algorithm</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ling</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Benkrid</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Comput. Sci. USA</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="495" to="504" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">SOAP3: ultra-fast GPU-based parallel alignment tool for short reads</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="878" to="879" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">CUSHAW: a CUDA compatible short read aligner to large genomes based on the Burrows–Wheeler transform</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1830" to="1837" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">GPU-accelerated bidirected De Bruijn graph construction for genome assembly</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Tech. Appl. Lect. Notes Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">7808</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">High-performance short sequence alignment with GPU acceleration</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distrib. Parallel Dat</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="385" to="399" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">CUDA compatible GPU cards as efficient hardware accelerators for Smith-Waterman sequence alignment</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Manavski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Valle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">WindowMasker: window-based masker for sequenced genomes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Morgulis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="134" to="141" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A fast and symmetric DUST implementation to mask lowcomplexity DNA sequences</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Morgulis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1028" to="1040" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Database indexing for production MegaBLAST searches</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Morgulis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1757" to="1764" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">PLAST: parallel local alignment search tool for database comparison</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">H</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lavenier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinform</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">329</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Nvidia GPU parallel computing architecture</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Nickolls</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Hot Chips 19</title>
		<meeting>the IEEE Hot Chips 19<address><addrLine>Stanford, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">GPU Computing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Owens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Proc</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="879" to="899" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A general reconfigurable architecture for the BLAST algorithm</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Sotiriades</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Dollas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. VLSI Signal Process</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="189" to="200" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">GPU-BLAST: using graphics processors to accelerate protein sequence alignment</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">D</forename>
				<surname>Vouzis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">V</forename>
				<surname>Sahinidis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="182" to="188" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">A greedy algorithm for aligning DNA sequences</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="203" to="214" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>