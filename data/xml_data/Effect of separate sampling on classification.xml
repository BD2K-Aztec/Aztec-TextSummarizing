
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Effect of separate sampling on classification accuracy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Mohammad</forename>
								<surname>Shahrokh Esfahani</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Bioinformatics and Genomic Systems Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Edward</forename>
								<forename type="middle">R</forename>
								<surname>Dougherty</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Bioinformatics and Genomic Systems Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Effect of separate sampling on classification accuracy</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="242" to="250"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt662</idno>
					<note type="submission">Received on August 5, 2013; revised on November 9, 2013; accepted on November 11, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Prof. Martin Bishop All the codes are available at: http://gsp.tamu.edu/ Publications/supplementary/shahrokh13b. Contact: edward@ece.tamu.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Measurements are commonly taken from two phenotypes to build a classifier, where the number of data points from each class is predetermined, not random. In this &apos;separate sampling&apos; scenario, the data cannot be used to estimate the class prior probabilities. Moreover, predetermined class sizes can severely degrade classifier performance, even for large samples. Results: We employ simulations using both synthetic and real data to show the detrimental effect of separate sampling on a variety of classification rules. We establish propositions related to the effect on the expected classifier error owing to a sampling ratio different from the population class ratio. From these we derive a sample-based mini-max sampling ratio and provide an algorithm for approximating it from the data. We also extend to arbitrary distributions the classical population based Anderson linear discriminant analysis minimax sampling ratio derived from the discriminant form of the Bayes classifier. Availability: All the codes for synthetic data and real data examples are written in MATLAB. A function called mmratio, whose output is an approximation of the minimax sampling ratio of a given dataset, is also written in MATLAB.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The medical community is being confronted with serious problems of reproducibility in the development of biomarkers. The issue has been highlighted by a recent report regarding comments by Janet Woodcock, FDA drug division head. The report states, 'Based on conversations Woodcock has had with genomics researchers, she estimated that as much as 75 percent of published biomarker associations are not replicable. ''This poses a huge challenge for industry in biomarker identification and diagnostics development,'' she said (<ref type="bibr" target="#b8">Ray, 2011</ref>).' Many issues affect reproducibility, including the measurement platform, specimen handling, data normalization and sample compatibility between the original and subsequent studies. These matters concern experimental procedures and are not our concern here; rather, we are interested in the methodology for designing classifiers. One issue in this regard is the impact of inaccurate error estimation owing to small samples. This has been previously quantified (<ref type="bibr" target="#b13">Yousefi and Dougherty, 2012</ref>). Here we are interested in a different problem, one that will confront us even if we have large samples and perfect error estimation: the effect of having predetermined sample sizes so that sampling is not random. In classification studies it is typically a tacit assumption that sampling is random; indeed, it is commonplace for this assumption to be made throughout a text on classification. For instance, Devroye et al. declare on page 2 of their text that all sampling is random (<ref type="bibr" target="#b3">Devroye, 1996</ref>). The assumption is so pervasive that it can be applied without mention. With regard to the problem at hand,<ref type="bibr" target="#b5">Duda et al. (2001)</ref>state, 'In typical supervised pattern classification problems, the estimation of the prior probabilities presents no serious difficulties.' But, in fact, there are often serious difficulties. Under the assumption of random sampling, the data set,</p><formula>S n ¼ {(X 1 , Y 1 ),. .. , (X n , Y n )</formula><p>}, is drawn independently from a fixed distribution of feature-label pairs, (X, Y); in particular, this means that if a sample of size n is drawn for a binary classification problem, then the numbers of sample points, n 0 and n 1 , in classes 0 and 1, respectively, are random variables such that n 0 þ n 1 ¼ n. An immediate consequence of the random-sampling assumption is that the prior probability c ¼ Pr(Y ¼ 0) can be consistently estimated by the sampling ratio, namely, by ^ c ¼ n0 n. Consistency is nothing but Bernoulli's weak law of large numbers, namely, n0 n ! c in probability. Thus, if the sample is large, we can expect the sampling ratio to be close to the prior probability. Suppose the sampling is not random, in the sense that the ratios n0 n and n1 n are chosen prior to sampling. In this 'separate (stratified) sampling' case, S n ¼ S n0 [ S n1 , where the sample points in S n0 and S n1 are selected randomly from Å 0 and Å 1 but, given n, the individual class counts n 0 and n 1 are not random. Then, in effect, we have no sensible estimate of c. One could let ^ c ¼ n0 n , but there would be no reason to do so. Since our aim is to use the data to train a classifier, does the inability to consistently estimate c matter? Clearly in the case of linear discriminant analysis (LDA) it does, since the LDA classifier is defined by n ðxÞ ¼ 1 if D samp ðxÞ 0 and n ðxÞ ¼ 0 if D samp ðxÞ40, where</p><formula>D samp ðxÞ ¼ x À ^ l 0 þ ^ l 1 2 T ^ D À1 ^ l 0 À ^ l 1 À Á À ln 1 À ^ c ^ c , ð1Þ</formula><p>and ^ l 0 and ^ l 1 are the sample means of the class-conditional populations Å 0 and Å 1 , respectively, and ^ D is the pooled sample covariance matrix. The rationale for the LDA discriminant is that the estimators converge to the population parameters *To whom correspondence should be addressed. as n ! 1, in which case the resulting discriminant, D Bayes ðxÞ, defines the Bayes (optimal) classifier in the two-class Gaussian model with common covariance matrix. It is obvious from Equation (1) that an estimate of c is required for LDA and a bad choice of ^ c will negatively impact the classifier. This fact, which is a consequence of separate sampling, has long been recognized (<ref type="bibr" target="#b0">Anderson, 1951</ref>). The situation is less transparent with model-free classification rules such as support vector machines. In this article we use simulation to study the effect of separate sampling on several different classification rules, where the role of c does not appear explicitly in classifier learning. We generate separate samples with different ratios r ¼ n0 n and consider the expected error, E½" n jr, of the designed classifier, given r, where the error of classifier n is defined by " n ¼ Prð n ðXÞ 6 ¼ YÞ, the probability of misclassification. We will see that the penalty for separate sampling without knowledge of c can be severe. With random (or, 'mixed') sampling, rather than being fixed prior to sampling, r is a sample-dependent random variable. In this case, E½" n jr denotes the expectation of the error conditioned on r and the expected classification error is given by E½" n  ¼ E r ½E½" n jr, where the outer expectation is relative to the distribution of r. The classifier error is likely to be smaller when the sampling ratio r is close to c. Hence, if one happens to fix r sufficiently close to c, then E½" n jr5 E½" n . Because r ! c in probability as n ! 1 for mixed sampling, as n gets larger the distribution of r gets more tightly concentrated around c, so that the distribution of E½" n jr (as function of r) gets more tightly packed around E½" n , which in turn means that to have E½" n jr5 E½" n  one must choose r very close to c. To illustrate this phenomenon, consider 2D Gaussian class-conditional densities with means at (0.3, 0.3) and (0.8, 0.8), possessing common covariance matrix 2 I, where I is the identity matrix and 2 ¼ 0:4, and with c ¼ 0:6: For this model, the Bayes error is " Bayes ¼ 0:27.<ref type="figure" target="#fig_1">Figure 1</ref>shows the difference E½" n  À E½" n jr for different values of r and different sample sizes when using LDA. If r ¼ 0:6, then E½" n jr5 E½" n  for all n. If r ¼ 0:7, which is fairly close to c ¼ 0:6, then E½" n jr5 E½" n  for n 25. Notice the lack of symmetry, both 0.5 and 0.7 being equally close to c. This should not be surprising because we should not expect the distribution of E½" n jr to be symmetric. Let us examine<ref type="figure" target="#fig_1">Figure 1</ref>from the practitioner's perspective. Suppose that cost limits the sample to a given size n. If the sample is random, then the expected error of the designed classifier will be E½" n , which is unknown since the feature-label distribution is unknown. Consider three cases: (i) if c is accurately known from existing population statistics regarding the two classes, say BRCA1 and BRCA2 breast cancer, then no matter what the sample size, it is best to do separate sampling with n 0 % cn; (ii) if c is approximately known, meaning that the practitioner believes that c is close to c 0 , then, for small n, it may be best, or at least acceptable, to do separate sampling with n 0 % c 0 n, and the results will likely still be acceptable for large n, though not as good as with random sampling; (iii) if the practitioner has no idea what c is, then sampling must be random because the penalty for separate sampling can be very large. While, at this point, these comments refer specially to<ref type="figure" target="#fig_1">Figure 1</ref>, which is for LDA, a salient point to be made in this article is that they are quite general and, moreover, can be extended to the commonplace separate sampling situation where one cannot choose n 0 and n 1. Why is all of this a major issue for bioinformatics? Simply put separate sampling is ubiquitous in bioinformatics, in particular, with genomic classification, where a standard approach is to take tissue samples from two classes, say, different types of cancer or different stages of cancer, for which the number of specimens in each class is not chosen randomly, and then to design a classifier. The Supplementary Material lists 20 published studies using separate sampling. In each case we give the classification problem, sample sizes, classification rule and error estimator. Even if an error estimate is exact for the problem at hand—that is, for the sampling ratio represented by the data—what does it mean relative to the classification error for future observations (say, patients)? That depends on the true prior probabilities, which we do not know.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SYSTEMS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Effect of sampling ratio—synthetic data</head><p>We employ simulation to study the effect of the sampling ratio for different classification rules using a general model based on multivariate Gaussian distributions with a blocked covariance structure. This model conforms to the setting where blocks represent correlated gene groups, say common pathways, and between-block correlation is negligible (<ref type="bibr" target="#b4">Doughtery et al., 2007;</ref><ref type="bibr" target="#b6">Hua et al., 2005;</ref><ref type="bibr" target="#b9">Shmulevich and Dougherty, 2007</ref>). The model has several parameters that can generate a battery of covariance matrices. For example, a 4-block covariance matrix with block size 3 has the structurein which 2 y is the variance of each variable and the i , i 2 f1, 2, 3, 4g, are the correlation coefficients inside blocks. We consider both identical and unequal covariance matrices. We assume common correlation coefficient, i ¼ , i 2 f1, 2, 3, 4g. A typical microarray or next-gen RNA sequencing (<ref type="bibr" target="#b7">Mortazavi et al., 2008;</ref><ref type="bibr" target="#b11">Wang et al., 2009</ref>) experiment yields expressions for thousands of genes, but a small number of sample points, typically 5200. Therefore, data-based feature selection is typically employed; however, since our sole aim is to study the effect of the ratio r on the expected true error, we do not consider feature selection and assume a model containing a reasonable number, D, of features (which is equivalent to assuming that a set of D genes has been chosen by the researcher based on prior biological knowledge). We let D ¼ 15. Two covariance matrix settings are considered: identical covariance matrices, 2 0 ¼ 2 1 ¼ 0:4, and unequal covariance matrices, 2 0 ¼ 0:4, 2 1 ¼ 1:6, with block size l ¼ 5 and correlation coefficient ¼ 0:8 corresponding to tight correlation within a block. The parameter settings are summarized in<ref type="figure" target="#tab_1">Table 1</ref>. Seven classification rules are considered: 3-nearest neighbor (3NN), 5nearest neighbor (5NN), linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), linear support vector machine (L-SVM), radial basis function SVM (RBF-SVM) and decision tree (DT). The SVM classifiers are trained from the package LibSVM written in MATLAB (<ref type="bibr" target="#b1">Chang and Lin, 2011</ref>). A decision tree classifier is trained using the MATLAB classregtree function.</p><formula>D y ¼</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Effect of sampling ratio—real data</head><p>Four microarray real datasets are used: pediatric acute lymphoblastic leukemia (ALL) (<ref type="bibr" target="#b12">Yeoh et al., 2002</ref>), acute myeloid leukemia (AML) (<ref type="bibr" target="#b10">Valk et al., 2004</ref>), multiple myeloma (<ref type="bibr" target="#b14">Zhan et al., 2006</ref>) and breast cancer (<ref type="bibr" target="#b2">Desmedt et al., 2007</ref>). We follow the data preparation instructions reported in the cited articles. The properties of these datasets are summarized in<ref type="figure" target="#tab_2">Table 2</ref>. The right-most column in<ref type="figure" target="#tab_2">Table 2</ref>contains the initial feature size, number of sample points in classes 0 and 1, respectively, from left to right. The Supplementary Material provides detailed descriptions of these datasets. The same classification rules as those used for the synthetic data are applied to the real data. T-test feature selection is used to reduce the original set of genes down to D ¼ 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Holdout error estimation</head><p>Because we are going to use real data, we wish to use holdout error estimation; however, the standard holdout procedure, which is unbiased with random sampling, become biased, perhaps severely so, with separate sampling. Therefore, we redefine holdout for separate sampling.</p><p>The true error of a designed classifier n is given by " n ¼ Prð n ðXÞ 6 ¼ YÞ ¼ c Prð n ðXÞ 6 ¼ 0jY ¼ 0Þ þ ð1 À cÞ Prð n ðXÞ 6 ¼ 1jY ¼ 1Þ ¼ c" 0 n þ ð1 À cÞ" 1 n : ð4Þ</p><p>Relative to a random sample, S n , the expected true error is</p><formula>E Sn ½" n  ¼ cE Sn ½" 0 n  þ ð1 À cÞE Sn ½" 1 n : ð5Þ</formula><p>For standard holdout error estimation, the sample is split into t points (the training set) to train the classifier and m points (the test set) to estimate the error, where in this scenario the notation indicates that the total sample size is n ¼ t þ m. Let S t , S m , S m0 , and S m1 denote the set of training data, the full set of test data, the class-0 test points, and the class1 test points, respectively. The holdout estimator is</p><formula>^ "ð n Þ ¼ 1 m X ðXi, YiÞ2Sm 1 n ðXiÞ6 ¼Yi ¼ m 0 m 1 m 0 X ðXi, YiÞ2Sm 0 1 n ðXiÞ6 ¼Yi þ m 1 m 1 m 1 X ðXi, YiÞ2Sm 1 1 n ðXiÞ6 ¼Yi ¼ m 0 m ^ " 0 ð n Þ þ m 1 m ^ " 1 ð n Þ, ð6Þ</formula><p>where ^ " 0 and ^ " 1 denote the holdout estimators of " 0 n and " 1 n. Taking expectations in (6) yields</p><formula>E Sn ½ ^ " ¼ cE Sn ½ ^ " 0  þ ð1 À cÞE Sn ½ ^ " 1 : ð7Þ</formula><p>Because the test data are independent from the training data, the holdout estimator is unbiased given the training data, which means that E Sn ½ ^ "jS t  ¼ " n : Taking the expectation relative to the training data yields E Sn ½ ^ " ¼ E St ½E Sn ½ ^ "jS t  ¼ E Sn ½" n : Similar expressions apply to ^</p><formula>" 0 and ^ " 1 , namely, E Sn ½ ^ " 0  ¼ E Sn ½" 0 n  and E Sn ½ ^ " 1  ¼ E Sn ½" 1 n : Thus, ^ ", ^ " 0</formula><p>, and ^ " 1 are unbiased estimators of " n , " 0 n , and " 1 n , respectively, and Expression (7) corresponds term by term to (5). With separate sampling, taking expectations in (6) yields</p><formula>E Sn ½ ^ " ¼ m 0 m E Sn ½ ^ " 0  þ m 1 m E Sn ½ ^ " 1  ¼ m 0 m E Sn ½" 0 n  þ m 1 m E Sn ½" 1 n , ð8Þ</formula><p>because the ratio m0 m is fixed. Hence, ^ " is not unbiased. The bias depends on the difference between c and m0 m : If c is known, then the holdout estimator can be redefined as</p><formula>^ " c ¼ c ^ " 0 þ ð1 À cÞ ^ " 1 , ð9Þ</formula><p>for both random and separate sampling. In both cases it is unbiased: taking expectations on the right-hand side of (9) yields the right-hand) Absent an independent estimate of c, use of (6) for separate sampling is unacceptable because it is biased and the extent of the bias is unknown. We use (9) for our real-data examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Implementation</head><p>For a given synthetic model parameter setting, sample size n, ratio r and classification rule É, we approximate the expected true error rate E Sn ½" n ðcÞjr via Monte-Carlo (MC) simulation. Each repetition of the MC simulation is depicted in<ref type="figure" target="#fig_3">Figure 2</ref>(a). The first set of experiments is done using the flowchart in<ref type="figure" target="#fig_3">Figure 2</ref>(a). In these experiments, the sample size, n, is fixed but the class sample sizes vary according to the sampling ratio r. Samples S n are generated using the model determined by ðl 0 , D 0 Þ and ðl 1 , D 1 Þ described in<ref type="figure" target="#tab_1">Table 1</ref>in accordance with r and n. Assuming a classification rule É, a classifier is trained. The last stage in<ref type="figure" target="#fig_3">Figure 2</ref>(a) is the true error computation for the designed classifiers, which is also done via MC with 10 000 repetitions. The whole procedure is repeated 5000 times. The real datasets in<ref type="figure" target="#tab_2">Table 2</ref>are sufficiently large to be divided for training and testing and we use holdout error estimation, as previously described for separate sampling. The procedure is graphically illustrated in<ref type="figure" target="#fig_3">Figure 2</ref>(b). Fixing the total sample size n, assuming different values for the parameter r, we choose n 0 ¼ rðn À mÞ AE Ç points from class 0 and n 1 ¼ ðn À mÞ À n 0 from class 1, where a d e is the smallest integer greater than or equal to a. The remaining data points are used for holdout estimation. The expected holdout estimate, E½ ^ " n ðcÞjr, is computed via MC approximation. The process is repeated 3000 times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head><p>The full set of results appears in the Supplementary Material. Herein, we provide some results covering a variety of cases. We show results of four classification rules: 3NN, 5NN, L-SVM and RBF-SVM. Results for the synthetic examples with dimension 15 are shown. Also, we only provide the results for n ¼ 100 and n ¼ 80, for the synthetic and real datasets, respectively. For the real datasets, a two-sample t-test is used to reduce the dimensions in<ref type="figure" target="#tab_2">Table 2</ref>to D ¼ 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Expected true error</head><p>The expected true errors for synthetic data with common covariance matrix are given in<ref type="figure" target="#fig_5">Figure 3</ref>(a)-(d), where each plot gives the expected true error versus the parameter r for different class prior probabilities, i.e. c 2 f0:3, 0:4, 0:5, 0:6, 0:7g: Similar behavior is observed, regardless of classification rule. There is, however, different sensitivsities of different rules to the sampling ratio r. Results for the second model with different covariance matrices are shown in<ref type="figure" target="#fig_5">Figure 3</ref>(e)–(h). In this case, there is more varied behavior among the classification rules. Note the point in each figure where the curves cross. This point corresponds to the minimax solution and will be discussed in detail when we analyze the properties of the curves in a later subsection. For equal covariance matrices, the point is close to 0.5 for all the classification rules; however, it can be far from 0.5 for unequal covarinace matrices, depending on the classification rule.<ref type="figure" target="#fig_5">Figure 3</ref>(d)–(p) show results for two real datasets, where the performance is assessed via holdout error estimation. Each plot includes the expected holdout error estimate versus r for five values of c. In contrast to<ref type="figure" target="#fig_5">Figure 3</ref>(a)–(h), the curves in<ref type="figure" target="#fig_5">Figure  3</ref>(d)–(p) are not smooth, which is a result of discrete error estimation. Nonetheless, there still is a crossing point. The solid vertical lines in<ref type="figure" target="#fig_5">Figure 3</ref>(i)–(p) are fixed on the initial sampling ratios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Properties of the error curves</head><p>The most obvious characteristic of the error curves is that in each figure they appear to cross at a single value of r. We will now examine this phenomenon. We must be careful because the figures show continuous curves but r is a discrete variable. Hence, we will have to carefully define what it means to 'cross'. According to the standard definition, a classification rule is said to be 'smart' if the expected value of the error is monotonically decreasing as a function of sample size for all feature-label distributions (<ref type="bibr" target="#b3">Devroye, 1996</ref>). This is in accord with the intuition (not always correct) that more data cannot hurt classifier design. We adapt the notion of smartness to the present circumstances by defining a classification rule to be 'class-wise smart' relative to a family of feature-label distributions f c ðx, yÞ ¼ cfðxj0Þþ ð1 À cÞfðxj1Þ, c 2 ½0, 1, if, for all c 2 ½0, 1 and r 2 4r 1 , E½" 0 n jr 2  E½" 0 n jr 1  and E½" 1 n jr 2  ! E½" 1 n jr 1 : Intuitively, r 2 4r 1 means that there are more data available from class 0 when designing the classifier when conditioning on r 2 than when conditioning on r 1 , so that one would intuitively expect that the class-0 error when conditioning on r 2 is not greater than when conditioning on r 1 , which is what is stated by the first inequality. The situation reverses relative to the class-1 error and that is what is stated by the second inequality. A classification rule is 'strictly class-wise smart' if r 2 4r 1 implies E½" 0 n jr 2 5E½" 0 n jr 1  and E½" 1 n jr 2 4E½" 1 n jr 1 : In<ref type="figure" target="#fig_5">Figure 3</ref>we observe that, if c 2 4c 1 , then for sufficiently small r, E½" n ðc 2 Þjr4E½" n ðc 1 Þjr, where the notation E½" n ðcÞjrFor small r, the preponderance of data for classifier design is in class 1 with very little data in class 0. Hence, the class-0 error tends to be greater than the class-1 error, so that E½" n ðc 2 Þjr À E½" n ðc 1 Þjr ¼ ðc 2 À c 1 ÞðE½" 0 n jr À E½" 1 n jrÞ40: ð11Þ<ref type="figure" target="#fig_5">Fig. 3</ref>. The first and the second rows show the expected true error rates of four classification rules when covariance matrices are identical and unequal, respectively. In these plots n 0 þ n 1 ¼ 100 is fixed, where n 0 and n 1 are chosen according to the ratio r. The third and the fourth rows show the expected holdout error estimate of the datasets (<ref type="bibr" target="#b12">Yeoh et al., 2002</ref>) and (<ref type="bibr" target="#b10">Valk et al., 2004</ref>), respectively, where n 0 ¼ 80r d e and n 1 ¼ 80 À n 0 points are randomly selected from classes 0 and 1, respectively, as the training set. The rest of points are held out for error estimation computed via (9)</p><formula>(e) ( f) ( g) ( h) (i) ( j) ( k) ( l) (m) ( n) ( o) ( p)</formula><p>Analogously, for sufficient large r, E½" n ðc 2 Þjr À E½" n ðc 1 Þjr50: ð12Þ</p><p>We shall assume that whatever classification rule and featurelabel distribution we are considering, (11) and (12) hold for sufficiently small and sufficiently large r, respectively. The next lemma, whose proof is in the Supplementary Material, states a fundamental property of the error curves. LEMMA 3.2.1 If a classification rule is strictly class-wise smart relative to the family ff c ðx, yÞg, then, for c 2 4c 1 , E½" n ðc 2 ÞjrÀ E½" n ðc 1 Þjr is a strictly decreasing function of r.</p><p>If we only assume class-wise smart, then E½" n ðc 2 ÞjrÀ E½" n ðc 1 Þjr would only be sure to be a decreasing function of r. The next lemma, whose proof is in the Supplementary Material, shows that constraining c results in a corresponding constraining of the expected error.To ease notation, we will say that E½" n ðc 2 Þjr is between E½" n ðc 1 Þjr and E½" n ðc 3 Þjr if either E½" n ðc 3 Þjr ! E½" n ðc 2 Þjr ! E½" n ðc 1 Þjr or E½" n ðc 3 Þjr E½" n ðc 2 Þjr E½" n ðc 1 Þjr: The salient proposition concerning the error curves involves a strictly decreasing function g(r) of r that is positive for sufficiently small values of r and negative for sufficiently large values of r. Since r is a discrete variable in ð0, 1Þ, we have a sequence of values 05r 1 5. .. 5r nÀ1 51: If g were continuous, then there would exist a unique value r Ã such that gðr Ã Þ ¼ 0, gðrÞ40 for r5r Ã , and gðrÞ50 for r4r Ã. But since g is discrete, this basic proposition is slightly altered. Rather, there are two possibilities: (i) there exists a unique value r Ã ¼ r j for some value j such that gðr Ã Þ ¼ 0, gðrÞ40 for r5r Ã , and gðrÞ50 for r4r Ã or (ii) there is a unique value r j such that gðrÞ40 for r r j and gðrÞ50 for r ! r jþ1 : In the second case, we select a point r Ã 2 ðr j , r jþ1 Þ, say, the mid-point, and then we have gðrÞ40 for r5r Ã and gðrÞ50 for r4r Ã , as in the first case. In the next theorem, whose proof is in the Supplementary Material, we will be interested in a 'unique' point r Ã 2 ð0, 1Þ: For the second case, we interpret this to mean that there is a unique interval ðr j , r jþ1 Þ and r Ã is the selected point in that interval. Given the preceding discrete interpretation, we shall say that a function pðrÞ 'crosses' function q(r) at r Ã if pðrÞ ! qðrÞ for r5r Ã and if pðrÞ qðrÞ for r4r Ã :This is precisely the theorem we want because it means that all error curves cross at r Ã : In the error curves of<ref type="figure" target="#fig_5">Figure 3</ref>, we observe that r Ã provides a minimax value; that is, r mm ¼ r Ã yields the minimum value of E½" n ðcÞjr when taking the maximum error over all values of E½" n ðcÞjr for r 2 ð0, 1Þ :</p><formula>r mm ¼ arg min r max c E½" n ðcÞjr, ð13Þ</formula><p>where we must keep in mind that r 2 R ¼ fr 1 ,. .. , r nÀ1 g is a discrete variable. The next theorem, proven in the Supplementary Material, formalizes this observation. THEOREM 3.2.4 Consider a classification rule that is strictly class-wise smart relative to ff c ðx, yÞg and let r mm be the minimax value defined by (13). If Theorem 3.2.3 yields a unique point r Ã ¼ r j , then r mm ¼ r j ; otherwise, if Theorem 3.2.3 yields an interval ðr j , r jþ1 Þ, then either r j or r jþ1 is the minimax ratio, determined by</p><formula>r mm ¼ r j if E½" 0 n jr j  E½" 1 n jr jþ1  r jþ1 if E½" 0 n jr j 4E½" 1 n jr jþ1  : &amp; ð14Þ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Practical implications of the error curves</head><p>Recall the practical implications we drew regarding<ref type="figure" target="#fig_1">Figure 1</ref>in the Section 1: (i) if c is known, then do separate sampling with n 0 ¼ cn; where the equal sign means 'as close to cn as possible'; (ii) if c % c 0 , then for small n do separate sampling with n 0 ¼ c 0 n; (iii) if one has no idea regarding the value of c, then sampling must be random. Looking at the curves in<ref type="figure" target="#fig_5">Figure 3</ref>(and similar figures in the Supplementary Material), we see that the curve for c has its minimum value at r ¼ c or r ¼ c 0 % c and, in the latter case, E½" n ðcÞjr % E½" n ðc 0 Þjr: Hence, the first two recommendations hold for the other classification rules examined. Going beyond the case where c is known or approximately known, consider the third implication, where one has no good idea concerning the value of c. Then the minimax r mm is an option. Its suitability depends upon the classification rule and feature-label distribution. As we can see from<ref type="figure" target="#fig_5">Figure 3</ref>, except for extreme values of c, E½" n ðcÞjr mm  tends not to be too much greater than E½" n ðcÞjc: Of course, there is a practical problem: while we may well know the classification rule, we will not know the feature-label distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Algorithm to approximate r mm</head><p>Algorithm 1 provides an iterative algorithm for approximating r mm when the feature-label distribution is unknown. The procedure is an empirical illustration of Theorem 3.2.4, which requires E½" n ðcÞjr, which now needs to be approximated to approximate r mm : Algorithm 1 uses holdout error estimation. The expectation of this error estimate is taken by iterative random sampling from the dataset. Here we give a brief overview of the algorithm. The inputs to the algorithm are: dataset denoted by S N , classification rule, number of points to be held out for error estimation from classes 0 and 1, denoted, respectively, by n 0 test , and n 1 test and number of iterations, MaxIters, for computing the expected holdout error estimate. The maximum number of points after holding out test sample points is N new ¼ N À ðn 0 test þ n 1 test Þ, denoted class-wise as N 0 new and N 1 new : The algorithm searches over possible values for r, from 0 to 1, until a stopping criterion is met. Suppose we fix the total sample size n. Then, considering the first extreme case, r ¼ 0, we need to have at least n points in class 1 to draw sample points from, randomly, i.e. N 1 new ! n: On the other hand, when r ¼ 1, we similarly should have N 0 new ! n: Hence, we should have n minfN 0 new , N 1 new g, whereby we set n ¼ minfN 0 new , N 1 new g:</p><p>The algorithm's search criterion is based on Theorem 3.2.4: in a 'while loop' over an increasing sequence of the ratios r, the algorithm computes the estimated slope of the expected error (as a function of c), this being slope new ¼ E½ ^ " 0 n jr À E½ ^ " 1 n jr (line 22 of the algorithm), obtained by plugging the error estimates (lines 7–21 of the algorithm) into the unknown slope formula E½" 0 n jr À E½" 1 n jr: Because the classification rule is strictly classwise smart, for sufficiently small r, the slope is positive, and it becomes negative for sufficiently large r (refer to Supplementary Material file for further explanation). Once a point is reached at which the sign of the slope becomes non-positive, the 'while loop' stops increasing r. Thereafter, the three different possibilities given by Theorem 3.2.4 are checked, in lines 26–32, and finally a single r mm is returned. Although the returned minimax ratio is only computed for sample size n defined above, the class-sizes can still be conservatively adjusted per r mm in the dataset S N because, for a ratio given by the algorithm, if one increases the sample size, then in the worst case the error is as large as the minimax value returned by the algorithm.</p><formula>1: Input: Dataset S N , Classification rule É, n 0 test , n 1 test , MaxIters 2: Output: r mm 3: Define: N 0 new ¼ N 0 À n 0 test , N 1 new ¼ N 1 À n 1 test n ¼ minfN 0 new , N 1 new g 4: Initialize: j ¼ 0, r ¼ 0, slope new ¼ 1, sign ¼ 1 5: while sign40 do 6: Set: a ^ E½ ^ " 0 n jr, slope old slope new , r j n 7: Reset: ^ E½ ^ " 0 n jr ¼ 0, ^ E½ ^ " 1 n jr ¼ 0 8: for i ¼ 1 to MaxIters do 9: S test, 0 ntest n 0 test randomly drawn points from S 0 N 10: S test, 1 ntest n 1 test randomly drawn points from S 1 N 11: S test ntest S test, 0 ntest [ S test, 1 ntest 12: S 0 Nnew S 0 N nS test, 0 ntest , S 1 Nnew S 1 N nS test, 1 ntest 13: S Nnew S 0 Nnew [ S 1 Nnew 14: S 0 n rn randomly drawn points from S 0 Nnew 15: S 1 n ð1 À rÞn randomly drawn points from S 1 Nnew 16: S n S 0 n [ S 1 n 17: n ÉðS n Þ 18: Compute ^ " 0 n , ^ " 1 n of n using S test ntest 19: Add ^ " 0 n , and ^ " 1 n to ^ E½ ^ " 0 n jr and ^ E½ ^ " 1 n jr, respectively 20: end for 21: ^ E½ ^ " 0 n jr ^ E½ ^ " 0 n jr MaxIters , ^ E½ ^ " 1 n jr ^ E½ ^ " 1 n jr MaxIters 22: slope new ^ E½ ^ " 0 n jr À ^ E½ ^ " 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Adjusting sample sizes</head><p>Consider the common situation in which n 0 and n 1 have been determined beforehand, but suppose one knows c. The curves of<ref type="figure" target="#fig_5">Figure 3</ref>still apply but we are not free to choose n 0 and n 1 , so that we cannot choose n 0 ¼ cn. Nevertheless, we desire the training data to be apportioned according to c and we want to use as much data as is possible. These conditions mean that for training we want class sample sizes m 0 and m 1 such that m ¼ m 0 þ m 1 is maximized given the constraints m 0 ¼ cm, m 1 ¼ ð1 À cÞm, m 0 n 0 , and m 1 n 1 : The solution is to let m ¼ minf n0 c , n1 1Àc g AE Ç : To see the effect of adjusting sample sizes, we consider the difference, Áðr, cÞ ¼ E½" n ðcÞjr À E½" m ðcÞjc, between the expected true errors of two cases, n being the original sample size and m the adjusted sample size. When the sampling ratio is r and the true prior probability is c, Áðr, cÞ can be interpreted as the penalty incurred.<ref type="figure">Figure 4</ref>shows Áðr, cÞ for L-SVM and RBFSVM for the equal covariance model described in<ref type="figure" target="#tab_1">Table 1</ref>. The result for the case with unequal covariance matrices can be found in the Supplementary Material. The two parameters r and c take values from 0.06 to 0.94 with the step size of 0.04. As expected, as jr À cj increases, Áðr, cÞ significantly increases. When r % c, Áðr, cÞ % 0, which is always the minimum. The figure shows that except when r is very close to c, Áðr, cÞ40, meaning that, even though m5n, a correct sampling ratio more than compensates for the loss of data due to subsampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Population-based minimax theory</head><p>The minimax value in the error curves of<ref type="figure" target="#fig_5">Figure 3</ref>depends on the sampling distribution and results from the fact that E½" n ðcÞjr is minimized over c for a single value r Ã : In Anderson (1951), a population-based minimax approach was taken to arrive at a 'best' choice for ^ c in (1) in the Gaussian model with common covariance matrix under separate sampling. Here we extend the population-based mimimax approach to arrive at much more general solution than that given by Anderson. It is based upon the fact that the Bayes classifier can be determined via a discriminant involving the class-conditional densities. Anderson also utilized the Bayes classifier in his analysis but he restricted it to the Gaussian model with common covariance matrix, in which case the Bayes classifier is given by LDA using the actual parameters rather than their estimates as in (1). Given the class-conditional distributions and prior probabilities, the Bayes classifier, Bayes , is determined by the discriminant</p><formula>D Bayes ðxÞ ¼ log fðxj0Þ fðxj1Þ À log 1 À c c , ð15Þ</formula><p>where Bayes ðxÞ ¼ 1 if D Bayes ðxÞ 0 and Bayes ðxÞ ¼ 0 if D Bayes ðxÞ40: The regions assigned to the two classes are R 1 ¼ fx : D Bayes ðxÞ 0g and R 0 ¼ fx : D Bayes ðxÞ40g: If c is unknown and replaced by ^ c, then the discriminant becomes</p><formula>D prior ðxÞ ¼ log fðxj0Þ fðxj1Þ À log 1 À ^ c ^ c , ð16Þ</formula><p>which defines the classifier ^ c , with corresponding class regions R 1 ð ^ cÞ ¼ fx : D prior ðxÞ 0g and R 0 ð ^ cÞ ¼ fx : D prior ðxÞ40g. The error associated with ^ c is</p><formula>"ð ^ c, cÞ ¼ c" 0 ð ^ cÞ þ ð1 À cÞ" 1 ð ^ cÞ, ð17Þ where " y ð ^ cÞ ¼ Z R1Àyð ^ cÞ fðxjyÞdx, ð18Þ</formula><p>for y 2 f0, 1g: R 1 ð ^ cÞ and R 0 ð ^ cÞ are strictly increasing and decreasing, respectively, for increasing values of log 1À ^ c ^ c : Hence, if the conditional densities are strictly positive, then " 1 ð ^ cÞ and " 0 ð ^ cÞ are strictly decreasing and increasing, respectively, for increasing values of log 1À ^ c ^ c : The minimax choice selects the value of ^ c that yields the minimum value of the error "ð ^ c, cÞ when taking the maximum error over all values of c 2 ð0, 1 :</p><formula>^ c mm ¼ arg min ^ c max c "ð ^ c, cÞ: ð19Þ</formula><p>We state a lemma and a theorem, whose proofs are given in the Supplementary Material that can be used to find minimax solutions. LEMMA 3.6.1 If the class-conditional distributions are strictly positive and " y ð ^ cÞ, y ¼ 0, 1, is a continuous function of ^ c, then there exists a unique point ^ c mm such that " 0 ð ^ c mm Þ ¼ " 1 ð ^ c mm Þ and this point corresponds to the minimax solution defined in (19). THEOREM 3.6.2 If the class-conditional distributions are strictly positive and " y ð ^ cÞ, y ¼ 0, 1, is a continuous function of ^ c, then the minimax solution for the discriminant in (16) is the value of c that gives rise to the maximum Bayes error for the discrimination problem of (15). To apply the lemma to the Gaussian model with common covariance matrix, note that the discriminant takes the form</p><formula>D prior ðxÞ ¼ x À l 0 þ l 1 2 T D À1 l 0 À l 1 À Á À ln 1 À ^ c ^ c ð20Þ</formula><p>and the error of the classifier induced by D prior is given by</p><formula>"ð ^ c, cÞ ¼ c À ðl 0 Àl 1 Þ T 2 D À1 ðl 0 À l 1 Þ À log 1À ^ c ^ c ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ðl 0 À l 1 Þ T D À1 ðl 0 À l 1 Þ q 0 B @ 1 C A |fflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl{zfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl} " 0 ð ^ cÞ þ ð1 À cÞ ðl 1 Àl 0 Þ T 2 D À1 ðl 0 À l 1 Þ À log 1À ^ c ^ c ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ðl 0 À l 1 Þ T D À1 ðl 0 À l 1 Þ q 0 B @ 1 C A |fflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl ffl{zfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflfflffl ffl} " 1 ð ^ cÞ , ð21Þ</formula><p>where is the standard normal cumulative distribution function. It is immediate that for ^ c ¼ 0:5, " 0 ð ^ cÞ ¼ " 1 ð ^ cÞ: Hence, ^ c mm ¼ 0:5, which is precisely Anderson's result for this special case. To illustrate the effect of the underlying feature-label distribution on ^ c mm , we consider a situation similar to that used for<ref type="figure" target="#fig_1">Figure 1</ref>, except that we allow unequal covariance matrices.<ref type="figure">Figure 5</ref>contains Bayes-error curves as functions of c for different covariance models. It shows that, except for a common covariance matrix, ^ c mm 6 ¼ 0:5, ^ c mm being the value of c at which the curve attains its maximum. The curve for equal covariance matrices is constructed analytically; for other values, MC simulation is employed. Obviously, if ^ c mm ¼ c, then the minimax value will perform well. But what happens when ^ c mm 6 ¼ c? In fact, the minimax value can work well so long at it is close to the true value, how close depending on the particulars of the problem. For a Gaussian model with common covariance matrix, as used for<ref type="figure" target="#fig_1">Figure 1</ref>, we consider LDA with random sampling under three scenarios: (i) known c, (ii) minimax ^ c mm and (iii) the maximumlikelihood estimate ^ c ml ¼ n0 n :<ref type="figure">Figure 6</ref>shows the expected errors (MC estimates) as a function of c for n ¼ 20 and 80. In all cases, known c is the best. When the sample is small, ^ c mm outperforms</p><formula>(a)</formula><p>(b)<ref type="figure">Fig. 4</ref>. The parameter Áðr, cÞ for classification rules, L-SVM and RBFSVM trained on the sample data with size n ¼ 100 from the common covariance matrix model described in<ref type="figure" target="#tab_2">Table 2</ref><ref type="figure">Fig. 5</ref>. Bayes error as a function of class prior probability c for different settings with multivariate Gaussian distributions with 0 ¼ ð0:3, 0:3Þ and 1 ¼ ð0:8, 0:8Þ ^ c ml for a fairly wide range of c, but this advantage disappears rapidly as n grows. The reason for this behavior is the difficulty of estimating c by ^ c ml for small samples. All curves show that when c is large or small the minimax solution gives poor results. Let us close this section by noting that the Bayes classifier is intrinsic to the feature-label distribution and, since the minimax choice depends only on the form of the Bayes classifier, it is independent of any particular classification rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Concluding remarks</head><p>We have shown, via simulations on both synthetic and real examples, that separate sampling with an inappropriate sampling ratio can significantly degrade classification accuracy for classification rules that do not use an explicit estimate of the prior probability. We have demonstrated some fundamental properties of the expected-error curves, developed the minimax samplebased theory for those curves, proposed an algorithm to approximate the minimax value in practice and extended the classical Anderson minimax theory for prior probabilities. We have provided heuristics on how to proceed when the prior probability is known (or known within a small range) and we have proposed a subsampling methodology to implement these heuristics when the class sample sizes are predetermined. Given the ubiquity of separate sampling in biomedicine, it would behoove the medical community to record incidence rates of patient sub-types (population statistics), so that very accurate estimates of class prior probabilities would be available. While this would certainly incur some cost, that cost would be minuscule compared to the costs incurred by the irreproducibility of classification studies. Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. The difference E½" n ðcÞ À E½" n ðcÞjr for different values of r as a function of sample size, n, with c ¼ 0.6. The class conditional densities parameters are as follows: l 0 ¼ ð0:3, 0:3Þ, l 1 ¼ ð0:8, 0:8Þ, and D 0 ¼ D 1 ¼ 0:4I, leading to the Bayes error " Bayes ¼ 0:27</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Flowcharts of the processes implemented for the synthetic and real dataset examples. The dashed boxes show one iteration of the MC simulation, repeated to find an approximation for the expected true error, i.e. E Sn ½" n ðcÞjr, and the expected holdout error estimation, i.e. E½ ^ " n ðcÞjr, respectively, for the synthetic and real dataset examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>LEMMA3.</head><figDesc>2.2 Suppose c 1 5c 2 5c 3 : If E½" n ðc 3 Þjr ! E½" n ðc 1 Þjr, then E½" n ðc 3 Þjr ! E½" n ðc 2 Þjr ! E½" n ðc 1 Þjr: If E½" n ðc 3 Þjr E½" n ðc 1 Þjr, then E½" n ðc 3 Þjr E½" n ðc 2 Þjr E½" n ðc 1 Þjr:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>THEOREM3.</head><figDesc>2.3 If a classification rule is strictly class-wise smart relative to ff c ðx, yÞg, then there exists a unique point r Ã such that for any c 2 4c 1 , E½" n ðc 2 Þjr crosses E½" n ðc 1 Þjr at r Ã :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Algorithm1</head><figDesc>Iterative algorithm to approximate r mm (an implementation of Theorem 3.2.4 using an estimate of the expected error estimate)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Distribution model parameters</figDesc><table>Parameters 
Value/description 

Mean 
0 ¼ 0:31 D , 1 ¼ 0:81 D 
Covariance matrix 
2 
0 ¼ 0:4, 2 
1 ¼ 0:4 (identical covariance) 
2 
0 ¼ 0:4, 2 
1 ¼ 1:6 (unequal covariance) 
Block size 
l ¼ 5 
Feature size 
D ¼ 15 
Feature block correlation 
¼ 0:8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. Real datasets used in this article</figDesc><table>Dataset 
Dataset type 
FeaturejSample size 

Yeoh et al., 2002 
Pediatric ALL 
5077j149/99 
Valk et al., 2004 
AML 
22215j116/157 
Zhan et al., 2006 
Multiple myeloma 
54613j156/78 
Desmedt et al., 2007 
Breast cancer 
22215j98/77 </table></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">M.S.Esfahani and E.R.Dougherty at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Effect of separate sampling on classification accuracy at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Classification by multivariate analysis</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">W</forename>
				<surname>Anderson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="31" to="50" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName>
				<forename type="first">C.-C</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C.-J</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transact. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Strong time dependence of the 76-gene prognostic signature for node-negative breast cancer patients in the transbig multicenter independent validation series</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Desmedt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="3207" to="3214" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">A Probabilistic Theory of Pattern Recognition</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Devroye</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Validation of computational methods in genomics</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Doughtery</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Genom</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Pattern Classification</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">O</forename>
				<surname>Duda</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>John Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal number of features as a function of sample size for various classification rules</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hua</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1509" to="1515" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Mapping and quantifying mammalian transcriptomes by rna-seq</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mortazavi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="621" to="628" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title level="m" type="main">FDA&apos;s Woodcock says personalized drug development entering &apos;long slog&apos; phase. Pharmacogen. Rep., http://www.genomeweb.com/mdx/ fdaswoodcock-says-personalized-drug-development-entering-long-slog-phase</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ray</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011-10-26" />
		</imprint>
	</monogr>
	<note>date. last accessed</note>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Shmulevich</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genomic Signal Processing (Princeton Series in Applied Mathematics</title>
		<meeting><address><addrLine>Princeton, New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Prognostically useful gene-expression profiles in acute myeloid leukemia</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Valk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England J. Med</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="page" from="1617" to="1628" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Rna-seq: a revolutionary tool for transcriptomics</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="57" to="63" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Classification, subtype discovery, and prediction of outcome in pediatric acute lymphoblastic leukemia by gene expression profiling</title>
		<author>
			<persName>
				<forename type="first">E.-J</forename>
				<surname>Yeoh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer cell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="144" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Performance reproducibility index for classification</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Yousefi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2824" to="2833" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">The molecular classification of multiple myeloma</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Zhan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Blood</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="2020" to="2028" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<monogr>
		<title level="m" type="main">Expected true error for different scenarios with random sampling (fixed n 0 þ n 1 with random n 0 and n 1 ) for the same model as used in Fig</title>
		<author>
			<persName>
				<surname>Fig</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>