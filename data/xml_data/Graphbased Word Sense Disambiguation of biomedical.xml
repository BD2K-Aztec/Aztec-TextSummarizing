
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Graph-based Word Sense Disambiguation of biomedical documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">. 22 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Eneko</forename>
								<surname>Agirre</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IXA NLP Group</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<settlement>Donostia, Basque Country</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Aitor</forename>
								<surname>Soroa</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IXA NLP Group</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<settlement>Donostia, Basque Country</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Mark</forename>
								<surname>Stevenson</surname>
							</persName>
							<email>: m.stevenson@dcs.shef.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Sheffield University</orgName>
								<address>
									<addrLine>211 Portobello</addrLine>
									<postCode>S1 4DP</postCode>
									<settlement>Sheffield</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Graph-based Word Sense Disambiguation of biomedical documents</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="2889" to="2896"/>
							<date type="published" when="2010">. 22 2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq555</idno>
					<note type="submission">Received on July 5, 2010; revised on September 16, 2010; accepted on September 26, 2010</note>
					<note>[15:58 20/10/2010 Bioinformatics-btq555.tex] Page: 2889 2889–2896 Associate Editor: Jonathan Wren</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Word Sense Disambiguation (WSD), automatically identifying the meaning of ambiguous words in context, is an important stage of text processing. This article presents a graph-based approach to WSD in the biomedical domain. The method is unsupervised and does not require any labeled training data. It makes use of knowledge from the Unified Medical Language System (UMLS) Metathesaurus which is represented as a graph. A state-of-the-art algorithm, Personalized PageRank, is used to perform WSD. Results: When evaluated on the NLM-WSD dataset, the algorithm outperforms other methods that rely on the UMLS Metathesaurus alone. Availability: The WSD system is open source licensed and available from http://ixa2.si.ehu.es/ukb/. The UMLS, MetaMap program and NLM-WSD corpus are available from the National Library of Medicine http://www.nlm.nih.gov/research/umls/, http://mmtx.nlm.nih.gov and http://wsd.nlm.nih.gov. Software to convert the NLM-WSD corpus into a format that can be used by our WSD system is available from http://www.dcs.shef.ac.uk/∼marks/biomedical_wsd/ under open source license. Contact</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The biomedical scientific literature is now so large that automated tools are necessary to access it effectively (<ref type="bibr" target="#b12">Chapman and Cohen, 2009</ref>). However, this process is made difficult by the fact that terms in natural language can be ambiguous, i.e. may refer to more than one possible concept. For example, in the biomedical domain the word 'cold' is ambiguous and can mean (at least) 'common cold', 'cold temperature' or 'cold sensation'. Word Sense Disambiguation (WSD) systems aim to solve this problem by identifying the meanings of ambiguous words in context (<ref type="bibr" target="#b0">Agirre and Edmonds, 2006;</ref><ref type="bibr" target="#b23">Navigli, 2009</ref>). For example, WSD would aim to identify that the meaning of cold in the sentence The role of zinc in treating cold symptoms is 'common cold'. This information could be used to improve literature searches, by ensuring that the documents returned only contain ambiguous terms when they are used in a meaning that is relevant to the search, and is also beneficial for other applications that are useful for biomedical researchers, such as automated indexing, information extraction and knowledge * To whom correspondence should be addressed. discovery (<ref type="bibr" target="#b4">Aronson et al., 2000;</ref><ref type="bibr" target="#b15">Friedman, 2000;</ref><ref type="bibr" target="#b21">MacMullen and Denn, 2005</ref>). This article describes an approach to WSD in the biomedical domain that is based on graph-based algorithms. Since the approach is unsupervised, it does not require any labeled training data and relies on information from the Unified Medical Language System (UMLS) Metathesaurus (<ref type="bibr" target="#b17">Humphreys et al., 1998</ref>) instead. The UMLS Metathesaurus is converted into a graph to which the Personalized Page Rank algorithm (<ref type="bibr" target="#b1">Agirre and Soroa, 2009</ref>) is applied to carry out WSD. Section 2 describes previous work on WSD in the biomedical domain and the use of graph-based algorithm for WSD. Section 3 describes our approach to WSD in the biomedical domain using the UMLS Metathesaurus and Personalized Page Rank algorithm. The approach is evaluated against a standard dataset and the results were analysed in Section 4. These results are discussed in Section 5. The conclusions are found in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The problem of WSD has been explored since the 1950s and is regarded as an important stage in text processing (<ref type="bibr" target="#b0">Agirre and Edmonds, 2006;</ref><ref type="bibr" target="#b23">Navigli, 2009</ref>). The majority of approaches have explored the problem in a domain-independent setting, although several researchers have developed systems specifically intended to resolve the ambiguities that are found in the biomedical domain (<ref type="bibr" target="#b28">Schuemie et al., 2005</ref>). The most popular approaches for WSD in biomedicine are based on supervised learning, for example<ref type="bibr" target="#b19">Joshi et al. (2005);</ref><ref type="bibr" target="#b20">Liu et al. (2004);</ref><ref type="bibr" target="#b27">Savova et al. (2008)</ref>. Although studies on domain-independent WSD have shown that supervised approaches outperform alternative ones, they require labeled training examples which may not be available and are expensive to create. This limitation means that most supervised approaches (including those mentioned above) can only disambiguate a small sample of words for which training data can be found, and this limits their usefulness in practise. In the context of biomedicine,<ref type="bibr" target="#b18">Humphrey et al. (2006)</ref>avoided this problem by using Medline as training data and exploiting information it contains about the source of each abstract. This approach assigns Semantic Types from the UMLS Metathesaurus but is unable to distinguish between meanings with the same Semantic Type. Unsupervised approaches do not require labeled training examples and often make use of knowledge bases, such as the UMLS Metathesaurus.<ref type="bibr" target="#b22">McInnes (2008)</ref>describes such an approach that uses the UMLS to generate textual definitions for the possible</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.Agirre et al.</head><p>meanings of ambiguous terms. WSD is carried out by comparing the context of the ambiguous term with the definitions of each possible sense and choosing the one with the most words in common. The approach is evaluated against 13 terms from the NLM-WSD corpus (see Section 4) and performance of 48.11% reported. Graph-based methods have recently become widely used for domain-independent knowledge-based WSD (<ref type="bibr" target="#b1">Agirre and Soroa, 2009;</ref><ref type="bibr" target="#b24">Navigli and Lapata, 2007;</ref><ref type="bibr" target="#b29">Sinha and Mihalcea, 2007;</ref><ref type="bibr" target="#b34">Tsatsaronis et al., 2007</ref>). These methods represent the knowledge base as a graph which is then analysed to identify the meanings of ambiguous words. An advantage of this approach is that the entire knowledge base can be used during the disambiguation process by propagating information through the graph. This article presents an unsupervised knowledge-based WSD algorithm which is capable of disambiguating all words that are ambiguous in the UMLS Metathesaurus. Relations in the UMLS Metathesaurus are used to create a graph which is analysed using the Personalized PageRank algorithm to rank possible meanings of ambiguous words based on their structural importance in the graph and their relation to the words in context. This algorithm has previously been applied in a domain-independent setting, using WordNet as the knowledge base (<ref type="bibr" target="#b1">Agirre and Soroa, 2009</ref>), and shown to outperform other, more ellaborate, graph-based algorithms (<ref type="bibr" target="#b24">Navigli and Lapata, 2007;</ref><ref type="bibr" target="#b29">Sinha and Mihalcea, 2007;</ref><ref type="bibr" target="#b34">Tsatsaronis et al., 2007</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GRAPH-BASED WSD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PageRank and Personalized PageRank</head><p>The PageRank algorithm (<ref type="bibr" target="#b5">Brin and Page, 1998</ref>) is a method for ranking the vertices on a graph according to their relative structural importance. It was originally developed to rank World Wide Web pages based on the number of pages that link to them. Here, we describe it as an algorithm for generic graphs. The next sections describe how to use it for WSD using the UMLS. PageRank uses a random walk model, where a random surfer starts a walk from an arbitrary node in the graph and, at each step, chooses an outgoing edge of the node at random to follows. The surfer may also decides to stop following edges and teleport to any node in the graph. The PageRank score of a vertex yields the probability that the random surfer is found in that vertex, assuming that the random walk continues indefinitely. Specifically, let G be a graph with N vertices (v 1 ,...,v N ). For a given vertex v i , let In(v i ) be the set of vertices pointing to it, and let d j the out-degree of vertex v j. The PageRank of vertex v i is defined as:</p><formula>P(v i ) = c v j ∈In(v i ) 1 d j P(v j )+(1−c) 1 N (1)</formula><p>where c is the so-called damping factor, a scalar value between 0 and 1. The PageRank for a vertex v i is the addition of two terms. The first term models the probability of the random surfer arriving to v i following the edges going from any vertex v j to v i , given by the sum of the probabilities of each vertex v j having an edge to v i times the weight of the edge, as given by the inverse of the degree of v j. The second term represents the probability of the surfer randomly jumping to any node with equal probability. The damping factor c models the relative importance of each of the two terms.The second term can also be seen as a smoothing factor that makes any graph fulfil the property of being aperiodic and irreducible, and thus guarantees that PageRank calculation converges to a unique stationary distribution. PageRank is calculated by applying an iterative algorithm that computes Equation (1) repeatedly until convergence below a given threshold is achieved or until a pre-specified number iterations have been executed. The damping factor is usually set in the range<ref type="bibr">[0.85..0.95]</ref>. Previous experiments (<ref type="bibr" target="#b1">Agirre and Soroa, 2009</ref>) lead us to choose a damping factor of 0.85.<ref type="figure" target="#fig_1">Figure 1</ref>shows a sample graph (a) and the PageRank values for this graph (b). Initially, P for all four nodes are initialized with a uniform distribution, i.e. 0.25. 1 Given a damping factor of 0.85, in the first iteration the PageRank values are updated as follows:where the superscripts correspond to the current iteration, i.e. P(A 0 ) corresponds to the initial value and P(A 1 ) to the first iteration. The second iteration would calculate P(A 2 ) based on P(D 1 ), and so on. After a few iterations, convergence is attained and the PageRank values shown in graph (<ref type="figure" target="#fig_1">Fig. 1b</ref>) are obtained. In certain situations, including graph-based WSD, we would like to include information about the relative importance of vertices in the graph. That is, given a set of vertices of interest, we would like to know which other vertices are closely related to them in the graph. For instance, we may be interested to know which nodes in graph (<ref type="figure" target="#fig_1">Fig. 1a</ref>) are closely related to node D (as shown in<ref type="figure" target="#fig_1">Fig. 1c</ref>). Personalized PageRank (<ref type="bibr" target="#b16">Haveliwala, 2002</ref>) computes the structural importance of the vertices in a graph when some vertices are more relevant than others for the task at hand. In order to introduce Personalized PageRank, we first rewrite Equation (1) in compact form by using matrices as follows. Let M be a N ×N transition probability matrix, where M ji = 1 d i if a link from v i to v j exists, and zero otherwise. Let v be a stochastic normalized N ×1 vector whose elements are all 1 N. Then, the calculation of the PageRank Vector P over the graph G is equivalent to resolving the following Equation:</p><formula>P = cMP +(1−c)v (2)</formula><p>Page: 2891 2889–2896</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph-based WSD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Using Personalized PageRank for WSD</head><p>To use Personalized PageRank for WSD, the UMLS is represented as a graph in which the concepts are vertices and relations between them edges. Given the context of an ambiguous word (e.g. 'cold' in the context mentioned in<ref type="figure" target="#fig_2">Fig. 2</ref>), WSD is carried out by initializing v with equal values for all concepts that appear in the context (and zero for the rest), applying Personalized PageRank and then selecting the concept corresponding to 'cold' that has the highest PageRank. Two sources of information are required for the Personalized PageRank algorithm to be used for WSD: a Knowledge Base and a dictionary. The Knowledge Base (KB) consists of a set of concepts and relations between them. It can be naturally represented as an undirected graph G = (V ,E) where nodes represent KB concepts (v i ) and the relation between concepts v i and v j is represented by an undirected edge e i,j. The dictionary maps words and phrases found in documents to their possible concepts in the KB.<ref type="bibr">, 1999</ref>) to identify co-occurrences. The MRCOC table includes details about the strength of the co-occurrence relation between concepts based on the number of co-occurrences identified. It is straightforward to convert the information contained in the MRREL and MRCOC tables into a graph. The concepts form the vertices with the relations listed in the tables being used to define the edges between them. No weights are used for the relations that are extracted from the MRREL table. In the case of the MRCOC table, we did use the strength of co-occurrence to produce some subsets of the graph (see Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Knowledge Base</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Dictionary</head><p>The dictionary contains mappings from words and phrases in text to UMLS CUIs. It is created using the MetaMap program (<ref type="bibr" target="#b3">Aronson, 2001</ref>) that splits the input text into phrases and maps each onto the set of possible CUIs that they could refer to, known as candidates. The set of candidates for each word or phrase in the context of the ambiguous terms are extracted from Page: 2892 2889–2896</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.Agirre et al.</head><p>the MetaMap output and used to create the dictionary to define the possible CUIs for each word in its context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Static PageRank baseline</head><p>Applying the traditional PageRank algorithm over the graph created from the UMLS leads to all CUIs being ranked according to their PageRank value, i.e. a context-independent ranking of CUIs. This can be used to create a WSD system by examining the relative rankings of the CUIs for a target word and returning the highest ranking one. We call this application of PageRank to WSD Static PageRank, since it does not change with the context, and use it as a baseline. The static baseline favours concepts with high degree, and thus disambiguates each word to the concept having most connections in the graph, regardless of context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Personalized PageRank Static PageRank</head><p>is independent of context, but this is not what we want in a WSD system. Given an input piece of text we want to disambiguate all content words (i.e. nouns, verbs, adjectives and adverbs) in the input based on the words in the context. This can be achieved using Personalized PageRank as follows. Given an input text, we extract the list W ={W 1 ,...,W m } of content words which have an entry in the dictionary and can therefore be related to UMLS concepts. Note that monosemous words will be attached to just one concept, whereas polysemous words may be attached to several. The context words are first inserted into G as nodes, and linked with directed edges to their respective concepts. The Personalized PageRank of the graph G is then computed by concentrating the initial probability mass uniformly over the newly introduced word nodes. As the words are linked to the concepts by directed edges, they act as source nodes injecting mass into the concepts they are associated with, which thus become relevant nodes and spread their mass over the UMLS graph. The resulting Personalized PageRank vector can be seen as a measure of the relevance of UMLS concepts given the context. As a result of the disambiguation process, every UMLS concept receives a score. Each target word can then be disambiguated by examining each of its possible concepts in the graph, G, and selecting the one with the highest score.<ref type="figure" target="#fig_2">Figure 2</ref>shows an example. A problem occurs if the possible CUIs of the target word being disambiguated are themselves related. In this situation, those CUIs reinforce each other and reduce the influence of the other senses in the context. With this observation in mind, we introduce a change in the algorithm: for each target word W i , we concentrate the initial probability mass in the senses of the words surrounding W i , but not in the senses of the target word itself, so that context words increase its relative importance in the graph. The main idea of this approach is to avoid biasing the initial score of concepts associated to target word W i , and let the surrounding words decide which concept associated with W i has more relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Interoperability and performance of the system</head><p>UKB is open source, programmed in C++ and easily integrated in thirdparty software as a library. For instance, the open source multilingual text-processing package Freeling 2 incorporates UKB. The steps needed to run our system are as follows. Before performing WSD, the MRREL and MRCOC tables from the UMLS need to be converted to a binary graph format. Given a target document, we first run MetaMap to construct the dictionary for the WSD system. The Personalized PageRank algorithm can then be run. This uses MetaMap's output for the target document, the graph and the dictionary. It outputs the disambiguated concepts in the form of CUI numbers with weights. The performance of our system on a PC with 2 QuadCore Xeon processors at 3160 MHz and 32 G of memory was the following: building the binary graph from the UMLS tables takes 21.8 s, loading the binary graph takes 5.6 s and 1.6 G of memory. WSD is performed at a rate of 37 instances per minute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EVALUATION</head><p>The WSD system was evaluated using the NLM-WSD corpus<ref type="bibr" target="#b35">Weeber et al. (2001)</ref>. This contains 50 ambiguous terms with 100 instances of each. The instances are abstracts containing the ambiguous term randomly extracted from those added to Medline in 1998. The 5000 instances were manually disambiguated by 11 annotators, who tagged each occurrence of the target term with the corresponding meaning. Some instances were tagged 'None' to indicate that the annotators did not consider any of the possible meanings in UMLS applied. Following standard practice (<ref type="bibr" target="#b18">Humphrey et al., 2006;</ref><ref type="bibr" target="#b22">McInnes, 2008</ref>), these instances were not used in the evaluation, yielding a total of 3983 examples and 49 terms. (One term, 'association', was excluded since all 100 instances were labeled as 'None'.) In addition to the full NLM-WSD dataset, a subset of 13 of these terms was also used for evaluation. This subset was used by McInnes (2008) and consists of terms that have a majority sense that accounts for less than 65% of the instances and whose possible senses do not share the same semantic type. A window of 20 terms around the target word (i.e. the 10 preceding and 10 following terms) are used as the context. This is created by using MetaMap to identify the terms around the target word (see Section 3.2.2). Any phrases that are not mapped onto a CUI are discarded and the terms that form each of the remaining phrases are used to create the context. The damping factor (Section 3.1) was set to 0.85. The values of these parameters were selected based on previous work (<ref type="bibr" target="#b1">Agirre and Soroa, 2009</ref>). Section 4.4 reports a post hoc analysis exploring the effects of varying them. The 2007AB version of the UMLS was used for the experiments. This version was chosen since we had access to a mapping between the NLM-WSD sense labels and UMLS CUIs. Such a mapping is only required to evaluate our approach and it would be possible to use the approach described in this article to carry out WSD relative to any version of the UMLS. The mapping from the 2007AB version of the UMLS was created with the assistance of publicly available software and manually verified.<ref type="figure" target="#tab_1">Table 1</ref>shows results of the system evaluation. Performance is measured by accuracy, the percentage of instances correctly disambiguated. Note that our algorithm returns a sense for all instances. The confidence interval, computed using bootstrap resampling with 95% confidence (<ref type="bibr" target="#b25">Noreen, 1989</ref>), is also shown. The top part of the table shows the results on the full NLMWSD dataset. The first two rows show the result using Personalized Page: 2893 2889–2896The best performance is obtained using the graph created from the MRREL table. Results decrease when the extra relations from the MRCOC table are added. This drop in performance was unexpected since co-occurrence information is generally considered to be very useful for WSD (<ref type="bibr" target="#b0">Agirre and Edmonds, 2006</ref>). However, the MRCOC table only contains relations for some CUIs, unlike the MRREL table which contains relations for all CUIs. This negatively affects Personalized PageRank since it is more likely to select CUIs that are more highly connected and the fact that some CUIs do not appear in the MRCOC table creates a bias towards those which do. Analysis indicated that there are only four terms ('ganglion', 'man', 'secretion' and 'surgery') for which all of the possible CUIs appear in the MRCOC table. For 25 terms some of the CUIs appear in the MRCOC table while others do not. In addition, relations in the MRCOC table are generated automatically and may also be noisy. The lower part of<ref type="figure" target="#tab_1">Table 1</ref>reports results on the 13 terms used by<ref type="bibr" target="#b22">McInnes (2008)</ref>. The best approach, Personalized Pagerank using MRREL, achieves better results than those reported by<ref type="bibr" target="#b22">McInnes (2008)</ref>, the state-of-the-art in knowledge-based WSD. Possible reasons for this improved performance are that the MRREL table contains information that is more useful for WSD than the CUI definitions used by<ref type="bibr" target="#b22">McInnes (2008)</ref>and that the graph-based algorithm used in our approach benefits from being able to make use of information from the entire UMLS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph-based WSD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">UMLS subsets</head><p>In this section, we explore the effect of using subsets of the UMLS: relations from various vocabularies in MRREL and ranked relations from MRCOC. A greedy algorithm (<ref type="bibr" target="#b14">Chvatal, 1979</ref>) was used to identify a set of vocabularies that included the CUIs used as possible senses of the terms in the NLM-WSD dataset. One vocabulary, MTH(UMLS Metathesaurus), was excluded from the set of vocabularies considered since it consists of concepts that were created specifically to create the Metathesaurus, rather than being an independent vocabulary in its own right. The greedy algorithm generated a set of four vocabularies: AOD (Alcohol and Other Drug Thesaurus), MSH (Medical Subject Headings), CSP (Crisp Thesaurus) and SNOMEDCT (SNOMED Clinical Terms). One of the possible senses for 'resistance' is only found in the MTH vocabulary and this term cannot be represented using these vocabularies. Note that the union of all four subsets covers all senses of the target words, but does not contain all relations in MRREL.<ref type="figure" target="#tab_2">Table 2</ref>shows the results when the Personalized PageRank algorithm is applied to graphs created using single vocabularies and the combination of all four. No single vocabulary includes all possible concepts for every sense and the column marked 'Terms' indicates the number of terms for which all possible concepts are included in a vocabulary or set of vocabularies. Results in the 'Acc.' column list the WSD performance over those terms using the graphs created using the single vocabularies (or their combination) while the 'MRREL' column lists the results using the graph created from the MRREL table over the same terms. Performance using individual vocabularies, or the combination of four vocabularies, is always lower than when the full MRREL graph is used. This indicates that our algorithm is able to exploit information from the multiple vocabularies that are combined to form the MRREL table in the UMLS and that including additional vocabularies, even ones that are not necessary to represent all of the possible meanings for ambiguous terms, improves WSD performance.<ref type="figure" target="#tab_3">Table 3</ref>reports results when adding several subsets of MRCOC to the MRREL relations. Instead of using all relations in MRCOC, we aim to identify the most useful ones using the Mutual Information (MI) statistic (<ref type="bibr" target="#b13">Church and Hanks, 1990</ref>) that ranks pairs of concepts based on the probability that they occur more frequently than would Page: 2894 2889–2896</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.Agirre et al.</head><p>be expected by chance. Several subsets of MRCOC relations were generated by ranking them by MI and successively adding those with the highest score to the graph created from the MRREL table. MRREL + MRCOC 1 adds approximately 750 000 new co-occurrences and MRREL + MRCOC 2 adds around 2 million. The table shows that performance drops systematically as cooccurrence relations from the MRCOC table are added to the graph. This situation is somewhat different from the positive effect of adding information from the MRREL table. These results enforce our hypothesis that co-occurrence relations negatively change the topology of the graph, degrading the performance of our algorithm. The smallest drop in performance is obtained when MRCOC 1 is added, suggesting that MI is a useful technique for selecting the most informative co-occurrence relations.<ref type="figure" target="#tab_4">Table 4</ref>shows the results when a graph is created using the combination of the four vocabularies that were considered. (There is no value for 'resistance' since one of its senses is not included in the subset of four vocabularies, see Section 4.2.) Finally, the column 'Full' shows results when the graph created using the entire MRREL table from the UMLS is used.<ref type="figure" target="#tab_4">Table 4</ref>shows a significant variation in performance for individual terms with results ranging between 99% ('secretion') and 11.1% ('fit'). The PPR algorithm has a bias towards senses that are highly connected within the graph. For some terms there are significant differences between the connectivity for the possible senses. For example, one possible meaning of 'fit', C0036572 'Seizures', is linked to 1561 other CUIs in the MRREL table while the alternative meaning, C0424576 'Fit and well', is only linked to 18. The majority of errors for this term were caused by PPR assigning C0036572 to examples for which the correct CUI was C0424576. The table also shows that the graph producing the best performance varies for each word. Overall, the graph created from the full MRREL table produces the best score for slightly more of the ambiguous terms (25) than either the individual vocabularies (20) or their combination (24). However, note that the overall average performance using the graph created from the full MRREL table is significantly better than when the subset is used (see<ref type="figure" target="#tab_2">Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Word by word analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Exploring context length and damping factor</head><p>Our algorithm has two free parameters: context length and damping factor of the PageRank formula. Default values for these parameters<ref type="figure">Figure 3</ref>shows the results obtained using different values for these two parameters.<ref type="figure">Figure 3</ref>shows that the best results are obtained using a context of 30 words. However, the difference in performance compared to using our default context (20 words) is relatively small. Performance deteriorates when the context is limited (shorter than 10 terms). The lowest performance is obtained when no context is used (i.e. context size of 0), which corresponds to the static algorithm. Our algorithm is robust to the actual context length used, given a minimum amount of context. The best results when the damping factor was varied were obtained using a damping factor of 0.70, although performance was very close to the default value used in our experiment (0.85). This shows that the method is robust to changes in damping factor, provided it does not vary too far from the values suggested in the literature (<ref type="bibr" target="#b16">Haveliwala, 2002</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>There is some debate on how accurate WSD performance has to be to assisted in applications.<ref type="bibr" target="#b26">Sanderson (1994)</ref>carried out experiments suggesting that a WSD system would need to correctly disambiguate 90% of words in order to be useful for Information Retrieval. However, more recent experiments (<ref type="bibr" target="#b1">Agirre et al., 2009;</ref><ref type="bibr" target="#b6">Caputo et al., 2009</ref>) have shown that WSD with lower performance can improve Information Retrieval results, showing that the way in which the output of the WSD system is used is as important as the WSD performance. It has also been shown that WSD can improve several applications including Cross-lingual Information Retrieval (<ref type="bibr" target="#b31">Stevenson and Clough, 2004</ref>), Machine Translation (<ref type="bibr" target="#b11">Chan et al., 2007</ref>) and Information Extraction (<ref type="bibr" target="#b7">Chai and Biermann, 1999;</ref><ref type="bibr" target="#b33">Surdeanu et al., 2008</ref>). Performance of the WSD components of these systems is generally not reported but it is likely that it will be lower than the result obtained by the best system in a community evaluation exercise of all-words WSD systems, 65% (<ref type="bibr" target="#b30">Snyder and Palmer, 2004</ref>). This suggests that the WSD accuracy obtained by our system could be used to improve performance of applications.</p><p>The results reported here are based on the only available dataset, NLM-WSD, which contains terms that are frequent and ambiguous (<ref type="bibr" target="#b35">Weeber et al., 2001</ref>). The inter-annotator agreement for this data set is relatively low [kappa score 0.47 (<ref type="bibr" target="#b27">Savova et al., 2008)]</ref>which indicates that disambiguating these examples is not easy for humans. The performance of our approach for all ambiguous terms in a document cannot be reliably extrapolated but may be higher than the results reported here given the challenging nature of the NLM-WSD dataset. It is possible that the performance of our algorithm could be further improved by adding other parts of the UMLS, such as the Semantic Types, to the graph, or by making use of domain information from the MeSH codes, which has been shown to be useful for supervised WSD in the biomedical domain (<ref type="bibr" target="#b32">Stevenson et al., 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>This article presents a WSD system for biomedical documents. The system is unsupervised and is able to disambiguate all words that are ambiguous in the UMLS Metathesaurus. Disambiguation is carried out by converting tables from the UMLS Metathesaurus into a graph and using the Personalized PageRank algorithm to select the best sense for each ambiguous word. Experiments show that the best results were obtained using the combination of all vocabularies in the MRREL table of the Metathesaurus. Performance of the approach reported here surpasses results reported for other systems that used the UMLS Metathesaurus as a knowledge source.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Examples of a graph (a) alongside PageRank (b) and Personalized PageRank (c) computations for the graph. The number inside the circles are the PageRank value of the nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Small part of the graph created from the UMLS MRREL table showing two possible concepts for the ambiguous word 'cold' (represented as ovals) and concepts connected to them (represented as rectangles). Concepts that would be assigned high weight after running personalized PageRank for the context 'To evaluate antibiotic-prescribing practices for children younger than 18 years who had received a diagnosis of cold, upper respiratory tract infection (URI), or bronchitis in the United States' are represented using solid lines, and the correct meaning of 'cold' (C0009443 'Common cold') would be selected for this example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>The UMLS Metathesaurus is used as the KB. It is created by unifying a diverse range of controlled vocabularies and classification systems. The Metathesaurus is organized around concepts and each is assigned a Concept Unique Identifier (CUI). For example, the following CUIs are all associated with the term 'cold': C0009443 'Common Cold', C0009264 'Cold Temperature' and C0234192 'Cold Sensation'. The Metathesaurus also contains a wide range of information about the relations between CUIs in the form of database tables. The MRREL table lists relations between CUIs found in the various sources that comprise the Metathesaurus. This table lists a range of different types of connections between CUIs. For example, C0009443 'Common Cold' is related to C0035243 'Respiratory Tract Infections' by the PAR (parent) relation. Other types of relations in the MRREL table include QB (can be qualified by), RQ (related and possibly synonymous) and RO (related, other). For example, C0009443 'Common Cold' is related to C0460004 'Head and Neck' by the RO relation. Figure 2 shows a small part of the graph. The MRREL table also lists the source vocabulary from which the relation was obtained. For example, it states that the connection between C0009443 and C0460004 is found in the National Cancer Institute Thesaurus. The same relation may also be found in multiple source vocabularies, e.g. the CUIs C0009443 and C0035243 are related in four separate vocabularies. Co-occurrence relations between CUIs are found in the MRCOC table. These relations exist between similar concepts (e.g. C00004238 'Atrial Fibrillation' and C0003811 'Cardiac Arrhythmia') or different concepts that share an important connection (e.g. C00004238 'Atrial Fibrillation' and C0012265 'Digoxin'). Although the MRCOC table lists a large number of cooccurrence relations, most concepts do not have any co-occurrence relations associated with them. The information in this table was created by automatically processing three information sources (Medline, 2002–2007; AI/RHEUM, 1993 and the Canonical Clinical Problem Statement System</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>lists the results for each of the individual terms using the MRREL graph. The columns labeled '#CUI' and '#inst' list the number of possible CUIs and instances for each term. The 'Single' column indicates the performance when a single UMLS vocabulary is used to create the graph, using one of the four subsets listed in Section 4.2. Missing figures indicate that the possible CUIs for a particular term are not included in any single vocabulary. 3 For some terms, all possible CUIs are included in multiple vocabularies and in these cases the best result is listed. 4 The column 'Subset'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1. Main results over the NLM-WSD dataset and the subset used in McInnes (2008) is shown together with the static and random baselines, as well as the results by McIness. PageRank (labeled ppr) using the graph created from the MRREL table alone and the combination of the MRREL and MRCOC tables. (We were not able to use the MRCOC table alone since it does not include all of the CUIs in the NLM-WSD corpus.) Performance using two baselines are also included. The first, static, applies the Personalized PageRank algorithm to the graph without making use of context (see Section 3.2.3) and the second, random, simply chooses a meaning at random. All differences in the table are statistically significant. Personalized PageRank clearly outperforms both the random and static baselines.</figDesc><table>Method 
KB 
Acc. 

Full NLM-WSD Dataset 
ppr 
MRREL 
68.1 [66.80, 69.23] 
ppr 
MRREL+MRCOC 
65.5 [64.30, 66.73] 
Static 
MRREL 
58.4 [57.07, 59.60] 
Random 
– 
45.6 

McInnes (2008) subset of NLM-WSD 

ppr 
MRREL 
55.0 [52.60, 57.76] 
McInnes (2008) 
-
48.1 

Our ppr method (ppr) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. Results using different vocabularies of the MRREL table</figDesc><table>KB 
#CUIs 
#relations 
Acc. 
Terms 
MRREL 

AOD 
15 901 
58 998 
51.5 
4 
61.5 
MSH 
278 297 
1 098 547 
44.7 
9 
66.6 
CSP 
16 703 
73 200 
60.2 
3 
69.4 
SNOMEDCT 
304 443 
1 237 571 
62.5 
29 
68.8 
All above 
572 105 
2 433 324 
64.4 
48 
68.0 

The table shows the number of CUIs and relations in the graph (#CUIs and #relations), 
WSD accuracy using the graph with the Personalized PageRank algorithm (Acc.), 
number of terms to which the graph can be applied (Terms) and the results on those 
terms using the entire MRREL table (MRREL). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 3.</figDesc><table>WSD results using different subsets of the MRCOC table 

KB 
#relations 
Acc. 

MRREL 
5 352 190 
68.1 
MRREL+MRCOC 1 
6 096 974 
68.0 
MRREL+MRCOC 2 
7 546 138 
66.9 
MRREL+MRCOC full 
11 362 335 
66.0 

The table shows the number of relations in the graph (#relations) and WSD accuracy 
over all terms (Acc). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 4. Word by word analysis of WSD results</figDesc><table>Word 
#CUI 
#inst 
Single 
Subset 
Full 

Adjustment 
3 
93 
33.3 
35.5 
Blood pressure 
3 
100 
53.0 d 
50.0 
48.0 
Cold 
5 
95 
32.6 d 
26.3 
28.4 
Condition 
2 
92 
95.7 d 
39.1 
48.9 
Culture 
2 
100 
33.0 
77.0 
Degree 
2 
6 5 
95.4 
93.8 
Depression 
2 
85 
16.9 d 
64.3 
94.1 
Determination 
2 
79 
49.4 
94.9 
Discharge 
2 
75 
24.0 d 
61.3 
69.3 
Energy 
2 
100 
73.0 
27.6 
Evaluation 
2 
100 
59.0 d 
54.0 
50.0 
Extraction 
2 
87 
23.0 
27.6 
Failure 
2 
29 
27.6 
72.4 
Fat 
2 
73 
56.2 d 
63.0 
95.9 
Fit 
2 
18 
16.7 d 
11.1 
11.1 
Fluid 
2 
100 
83.0 d 
92.0 
92.0 
Frequency 
2 
94 
98.9 d 
98.9 
98.9 
Ganglion 
2 
100 
66.0 c 
77.0 
64.0 
Glucose 
2 
100 
91.0 d 
91.0 
90.0 
Growth 
2 
100 
37.0 c 
37.0 
37.0 
Immunosuppression 
2 
100 
64.0 d 
59.0 
62.0 
Implantation 
2 
98 
75.0 b 
84.7 
84.7 
Inhibition 
2 
99 
24.2 
22.2 
Japanese 
2 
79 
70.9 d 
70.9 
64.6 
Lead 
2 
29 
93.1 d 
93.1 
93.1 
Man 
2 
92 
61.5 a 
34.8 
44.6 
Mole 
3 
84 
10.7 d 
63.1 
27.4 
Mosaic 
3 
97 
60.8 
66.0 
Nutrition 
3 
8 9 
33.7 
32.6 
Pathology 
2 
99 
34.3 
28.3 
Pressure 
3 
96 
52.1 d 
69.8 
97.9 
Radiation 
2 
9 8 
58.2 d 
53.1 
53.1 
Reduction 
2 
11 
36.4 d 
54.5 
54.5 
Repair 
2 
68 
63.2 d 
72.1 
76.5 
Resistance 
2 
3 
66.7 
Scale 
3 
65 
67.7 d 
52.3 
84.6 
Secretion 
2 
100 
99.0 c 
99.0 
99.0 
Sensitivity 
3 
5 1 
41.2 
27.5 
Sex 
3 
100 
84.0 d 
85.0 
85.0 
Single 
2 
100 
80.0 
82.0 
Strains 
2 
93 
92.5 d 
97.8 
96.8 
Support 
2 
10 
80.0 d 
80.0 
80.0 
Surgery 
2 
100 
95.9 c 
97.0 
97.0 
Transient 
2 
100 
97.0 
99.0 
Transport 
2 
94 
98.9 d 
98.9 
69.1 
Ultrasound 
2 
100 
84.0 c 
84.0 
83.0 
Variation 
2 
100 
85.0 d 
80.0 
75.0 
Weight 
2 
53 
56.6 d 
56.6 
56.6 
White 
2 
9 0 
68.9 a 
67.8 
63.3 

Best result 
20 
24 
25 

The 13 terms used by McInnes (2008) are printed underlined. In the column labeled 
'Single', the following symbols are used to indicate the vocabulary that is used to create 
the graph that was used to produce the result: a AOD, b CSP, c MSH and d SNOMEDCT. 
Where more than one single vocabulary contains all possible meanings for a particular 
term, results are shown for the vocabulary that produced the best performance. The 
best result for each term is printed in bold font. The bottom row, Best result, shows 
the number of terms for which the best result is found in that column. Missing figures 
indicate that the possible senses of the ambiguous term are not included in the graph. </table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2889 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> Note that the initial distribution values do no affect the final PageRank, provided that the algorithm converges.</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">In PageRank, the vector v is uniformly distributed, thereby assigning equal probabilities to all vertices in the graph when random jumps are made. However, in Personalized PageRank the vector v can be non-uniform and assign stronger probabilities to certain vertices, effectively biasing the resulting PageRank vector to prefer these vertices. For example, if we concentrate all the probability mass on a unique vertex v x , all random jumps on the walk will return to v x and consequently its rank will be high; moreover, the high rank of v x will cause all the vertices in its vicinity to also receive high rank. The importance of vertex v x in the initial distribution of v then spreads through the graph during successive iterations of the algorithm. In this case, the personalized P vector represents the importance of every vertex in the graph relative to vertex v x. Personalized PageRank can be solved using the same kind of algorithms as standard PageRank. Figure 1 shows the result of standard PageRank in (b), where v is uniform, and the result of Personalized PageRank in (c) for the case where v is set to 0 for all vertices except D, which is set to 1. For standard PageRank, vertex C receives a PageRank value of 0.29 [as in graph (Fig. 1b)], meaning that a random surfer on this graph would spend 29% of the time on that node. C has the highest rank among the graph nodes, and therefore node C is the most important node in the graph. On the contrary, if we use Personalized PageRank and the random surfer makes all random jumps to D [as in graph (Fig. 1c)], then the rank of D is now the highest, followed by node A—which is linked directly to D— and nodes C and B.</note>

			<note place="foot" n="2"> http://nlp.lsi.upc.edu/freeling/</note>

			<note place="foot" n="3"> For example, the term &apos;adjustment&apos; contains CUIs that are included in MSH and SNOMEDCT. However, neither vocabulary includes all three possible CUIs for this term. 4 For example, the two CUIs for &apos;immunosuppression&apos; are included in three vocabularies (CSP, MSH and SNOMEDCT) with SNOMEDCT producing the highest performance.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Word Sense Disambiguation: Algorithms and applications</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Agirre</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Edmonds</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Personalizing PageRank for Word Sense Disambiguation</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Agirre</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Soroa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2009)</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2009)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">CLEF 2009 ad hoc track overview: robust-WSD task</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Agirre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working Notes of the Cross-Lingual Evaluation Forum</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Aronson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the American Medical Informatics Association (AMIA)</title>
		<meeting>the American Medical Informatics Association (AMIA)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">The NLM indexing initiative</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Aronson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Brin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Page</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Networks ISDN Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">From fusion to re-ranking: a semantic approach</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Caputo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 33rd International ACM SIGIR Conference</title>
		<meeting>eeding of the 33rd International ACM SIGIR Conference<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="815" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">The use of word sense disambiguation in an information extraction system</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Biermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh Annual Conference on Innovative Applications of Artificial Intelligence</title>
		<meeting>the Eleventh Annual Conference on Innovative Applications of Artificial Intelligence<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="850" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">155810</biblScope>
			<biblScope unit="issue">20</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq555. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2896" to="2889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Agirre</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation improves statistical machine translation</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">S</forename>
				<surname>Chan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Current issues in biomedical text mining and natural language processing</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Chapman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Informat</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="757" to="759" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Church</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hanks</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computat. Linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">A greedy heuristic for the set-covering problem</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Chvatal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math.Operat. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="233" to="235" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A broad coverage natural language processing system</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="270" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Topic-sensitive PageRank</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">H</forename>
				<surname>Haveliwala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW &apos;02: Proceedings of the 11th International Conference on World Wide Web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">The Unified Medical Language System: an Informatics Research Collaboration</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Humphreys</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Informat. Assoc</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation by selecting the best semantic type based on Journal Descriptor Indexing: preliminary experiment</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Humphrey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Informat. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="96" to="113" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A comparative study of support vector machines applied to the Word Sense Disambiguation problem for the Medical Domain</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Joshi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Indian Conference on Artificial Intelligence (IICAI-05</title>
		<meeting>the Second Indian Conference on Artificial Intelligence (IICAI-05<address><addrLine>Pune, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="3449" to="3468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A multi-aspect comparison study of supervised Word Sense Disambiguation</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Informat. Assoc</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="320" to="331" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Information problems in Molecular Biology</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Macmullen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Denn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Informat. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="447" to="456" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">An unsupervised vector approach to biomedical term disambiguation: integrating UMLS and Medline</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Mcinnes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-08: HLT Student Research Workshop</title>
		<meeting>the ACL-08: HLT Student Research Workshop<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="49" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation: a survey</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Navigli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1" to="69" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Graph connectivity measures for unsupervised word sense disambiguation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Navigli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lapata</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>eeding of the 20th International Joint Conference on Artificial Intelligence<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1683" to="1688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title level="m" type="main">Computer-Intensive Methods for Testing Hypotheses</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Noreen</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Word sense disambiguation and information retrieval</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sanderson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGIR Conference</title>
		<meeting>the 17th ACM SIGIR Conference<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Word sense disambiguation across two domains: biomedical literature and clinical notes</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">K</forename>
				<surname>Savova</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Informat</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1088" to="1100" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation in the Biomedical Domain: an overview</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Schuemie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="554" to="565" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised graph-based word sense disambiguation using measures of word semantic similarity</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Sinha</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mihalcea</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Semantic Computing</title>
		<meeting>the IEEE International Conference on Semantic Computing<address><addrLine>Irvine, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">The english all-words task</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Snyder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Palmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="41" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">EuroWordNet as a resource for cross-language Information Retrieval</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stevenson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Clough</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="777" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Disambiguation of biomedical text using a variety of knolwedge sources</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stevenson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 11</note>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to rank answers on large online QA collections</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Surdeanu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08</title>
		<meeting>ACL-08<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>HLT. Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="719" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Word sense disambiguation with spreading activation networks generated from thesauri</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Tsatsaronis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1725" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Developing a test collection for Biomedical Word Sense Disambiguation</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Weeber</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMIA 2001 Symposium</title>
		<meeting>the AMIA 2001 Symposium</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="46" to="750" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>