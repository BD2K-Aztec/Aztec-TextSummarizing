
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint stage recognition and anatomical annotation of drosophila gene expression patterns</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Xiao</forename>
								<surname>Cai</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Hua</forename>
								<surname>Wang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Heng</forename>
								<surname>Huang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Chris</forename>
								<surname>Ding</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Texas at Arlington</orgName>
								<address>
									<postCode>76019</postCode>
									<settlement>Arlington</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint stage recognition and anatomical annotation of drosophila gene expression patterns</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="16" to="24"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts220</idno>
					<note>Copyedited by: TRJ MANUSCRIPT CATEGORY: [11:19 31/5/2012 Bioinformatics-bts220.tex] Page: i16 i16–i24 BIOINFORMATICS Availability: http://ranger.uta.edu/%7eheng/Drosophila/ Contact: heng@uta.edu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Staining the mRNA of a gene via in situ hybridization (ISH) during the development of a Drosophila melanogaster embryo delivers the detailed spatio-temporal patterns of the gene expression. Many related biological problems such as the detection of co-expressed genes, co-regulated genes and transcription factor binding motifs rely heavily on the analysis of these image patterns. To provide the text-based pattern searching for facilitating related biological studies, the images in the Berkeley Drosophila Genome Project (BDGP) study are annotated with developmental stage term and anatomical ontology terms manually by domain experts. Due to the rapid increase in the number of such images and the inevitable bias annotations by human curators, it is necessary to develop an automatic method to recognize the developmental stage and annotate anatomical terms. Results: In this article, we propose a novel computational model for jointly stage classification and anatomical terms annotation of Drosophila gene expression patterns. We propose a novel Tri-Relational Graph (TG) model that comprises the data graph, anatomical term graph, developmental stage term graph, and connect them by two additional graphs induced from stage or annotation label assignments. Upon the TG model, we introduce a Preferential Random Walk (PRW) method to jointly recognize developmental stage and annotate anatomical terms by utilizing the interrelations between two tasks. The experimental results on two refined BDGP datasets demonstrate that our joint learning method can achieve superior prediction results on both tasks than the state-of-the-art methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The mRNA in situ hybridization (ISH) provides an effective way to visualize gene expression patterns. The ISH technique can precisely document the localization of gene expression at the cellular level via visualizing the probe by colorimetric or fluorescent microscopy to allow the production of high quality images recording the spatial location and intensity of the gene expression (<ref type="bibr" target="#b2">Fowlkes et al., 2008;</ref><ref type="bibr" target="#b4">Hendriks et al., 2006;</ref><ref type="bibr" target="#b11">L'ecuyer et al., 2007;</ref><ref type="bibr" target="#b15">Megason and Fraser, 2007</ref>). Such spatial and temporal characterizations of expressions paved the way for inferring regulatory networks based on spatio-temporal dynamics. The raw data produced from such experiments includes digital images of the Drosophila embryo (examples are visualized in<ref type="figure">Fig. 1</ref>) showing a particular gene expression pattern revealed by a gene-specific probe (<ref type="bibr">Grumbling *</ref>To whom correspondence should be addressed<ref type="bibr" target="#b14">Lyne et al., 2007;</ref><ref type="bibr" target="#b20">Tomancak et al., 2002</ref><ref type="bibr" target="#b21">Tomancak et al., , 2007</ref>). The fruit fly Drosophila melanogaster is one of the most used model organisms in developmental biology. Traditionally, such ISH images are analyzed directly by the inspection of microscope images and available from well-known databases, such as the Berkeley Drosophila Genome Project (BDGP) gene expression pattern database (<ref type="bibr" target="#b20">Tomancak et al., 2002</ref><ref type="bibr" target="#b21">Tomancak et al., , 2007</ref>) and Fly-FISH (L'<ref type="bibr">ecuyer et al., 2007</ref>). To facilitate spatio-temporal Drosophila gene expression pattern studies, researchers needed to solve two challenging tasks first: Drosophila gene expression pattern stage recognition (temporal descriptions) and anatomical annotation (spatial descriptions). As shown in<ref type="figure">Figure 1</ref>, Drosophila embryogenesis has been subdivided into 17 embryonic stages. These stages are defined by prominent features that are distinguishable in living Drosophila embryos (<ref type="bibr" target="#b25">Weigmann et al., 2003</ref>). To recognize the stages of the Drosophila, embryos provide their time course patterns. On the other hand, the Drosophila gene expression patterns are often recorded by controlled vocabularies from the biologist's perspective (<ref type="bibr" target="#b20">Tomancak et al., 2002</ref>). Such anatomical ontology terms describe the spatial biological patterns and often cross stages. What is more, because the ISH images are attached to each other collectively becoming bags of images, the corresponding stage label as well as anatomical controlled terms are the descriptions of the whole group of images instead of each individual image inside the bag. A Drosophila embryo ISH image bag belongs to only one stage, but has multiple related anatomical terms. Previously, those two tasks are tackled by domain experts. However, due to the rapid increase in the number of such images and the inevitable bias annotation by human curators, it is necessary to develop an automatic method to classify the developmental stage and annotate anatomical structure using controlled vocabulary. Recently, a lot of research works have been proposed to solve the above two problems. They considered the stage recognition as a single-label multi-class classification problem while the anatomical annotation was treated as a multi-label multi-class classification problem. (<ref type="bibr" target="#b10">Kumar et al., 2002</ref>) first developed an embryo enclosing algorithm to find the embryo outline and extract the binary expression patterns via adaptive thresholding. (<ref type="bibr" target="#b16">Peng and Myers, 2004</ref>) and (<ref type="bibr" target="#b17">Peng et al., 2007</ref>) developed new ways to represent ISH images based on Gaussian mixture models, principal component analysis and wavelet functions. Besides that, they utilized min-redundancy max-relevance to do the feature selection and automatically classify gene expression pattern developmental stages. Recently, (<ref type="bibr" target="#b18">Puniyani et al., 2010</ref>) constructed a system (called SPEX 2 ) and concluded that the local regression (LR) method taking advantage of the controlled term–term interactions can get the best enhanced anatomical controlled term annotation results. The LR method was proposed by Ji et al. and developed based on their previous works</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drosophila gene expression patterns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Examples of Drosophila embryo ISH images and associated anatomical annotation terms</head><p>in the stages 4–6, 7–8, 9–10, 11–12 and 13–16 in the BDGP database. The darker stained region highlights the place where the gene is expressed. The darker color the region has, the higher the gene expression level is (<ref type="bibr" target="#b6">Ji et al., 2008</ref><ref type="bibr" target="#b8">Ji et al., , 2010</ref><ref type="bibr" target="#b12">Li et al., 2009;</ref><ref type="bibr" target="#b19">Shuiwang et al., 2009</ref>). All of the above methods have provided new inspirations and insights for classifying or annotating Drosophila gene expression patterns captured by ISH. However, none of them considered doing those two tasks simultaneously. As we know, intuitively, anatomical controlled vocabulary terms provide evidence for the stage label and vice versa. For example, the early stage range is more likely annotated with the controlled terms such as 'statu nascendi' and 'celluar' than the terms 'embryonic' and 'epidermis'. Therefore, besides the image–stage and image–annotation relationships which have been well studied and applied in the previous research, it is necessary to take advantage of the correlations between stage classes and annotation terms. In this article, we propose a novel Tri-Relational Graph (TG) model that comprises the data graph, anatomical controlled terms graph, developmental stage label graph to jointly classify the stage of images and annotate anatomical terms simultaneously. Upon the TG model, we introduce a Preferential Random Walk (PRW) method to simultaneously produce image-to-stage, image-to-annotation, image-to-image, stage-to-image, stage-toannotation, stage-to-stage, annotation-to-image, annotation-to-stage and annotation-to-annotation relevances to jointly learn the salient patterns among images that are predictive of their stage label and anatomical annotation terms. Our method achieves superior developmental stage classification performance and anatomical terms annotation results compared with the state-of-the-art methods. We consider each image bag as a data point and extract the bagof-word features that are widely used in computer vision research as the corresponding descriptors. Since the real object is 3D and each image can only provide 2D observation from a certain perspective, we integrate the bag-of-word features for different views. We summarize our contributions as follows:</p><p>(1) This article is the first one to propose a novel solution to the questions 'What is the developmental stage?' and 'What are the anatomical annotations' simultaneously, given an unlabeled image bag.</p><p>(2) Via the new TG model that we constructed, the relationships between stage label and anatomical controlled terms as well as the correlations among anatomical terms can be naturally and explicitly exploited by the graph-based semi-supervised learning methods.</p><p>(3) We propose a new PRW method to seek the hidden annotation–annotation and annotation–stage relevances. Other than only using image-to-image relevance conducted by existing methods, we can directly predict the stage label and annotate anatomical controlled terms for unknown image bags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DATA DESCRIPTORS</head><p>As we known, the Drosophila embryos are 3D objects. However, the corresponding image data can only demonstrate 2D information from a certain view. Since recent study has shown that incorporating images from different views can improve the classification performance consistently (<ref type="bibr" target="#b6">Ji et al., 2008</ref>), we will use the images taken from multiple views instead of one perspective as the data descriptor. We only consider the lateral, dorsal and ventral images in our experiment due to the fact that the number of images taken from other views is much less than that of the above three views. All the images from BDGP database have been pre-processed, including alignment and resizing to 128×320 gray images. For the sake of simplicity, we extract the popular SIFT (<ref type="bibr" target="#b13">Lowe, 2004</ref>) features from the regular patches with the radius as well as the spacing as 16 pixels (<ref type="bibr" target="#b19">Shuiwang et al., 2009</ref>), which is shown in<ref type="figure" target="#fig_0">Figure 2</ref>. Specifically, we extract one SIFT descriptor with 128 dimensions on each patch and each image is represented by 133 (7×19) SIFT descriptors. Nevertheless, the above SIFT features cannot be directly used to measure similarity between data points (image bags), because the number of images in each image bag is different. In order to get a desired equal length descriptor to release the burden of later learning task, we need to build codebook for all extracted SIFT features first and then redo the data representations for each image bag based on the constructed codebook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Codebook construction</head><p>Usually the codebook is established by conducting the clustering algorithms on a subset of the local features, and the cluster centers are then chosen as the visual words of the codebook. In our study, we use K-means to do the clustering on the training image bags. Since the result of K-means depends on the initial centers, we repeat it with 10 random initializations from which the one resulting in the smallest objective function value is selected. The number of clusters is set to 1000, 500 and 250 for lateral, dorsal and ventral images, respectively, according to the total number of images for each view as shown in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data (image bag) representations</head><p>After we get three codebooks, the images in each bag are quantized separately for each view. Features computed from patches on images with a certain view are compared with the visual words in the corresponding codebook and the visual word closest to the feature in terms of Euclidean distance is utilized to represent it. Therefore, if an image bag encompasses the images from three views, then it could be represented by three bags of words, one for each view. We concatenate the three vectors so that the images with different views (lateral, dorsal and ventral) in one bag can be represented by one vector. To be specific, Let x l ∈ R 1000 ,x d ∈ R 500 and x v ∈ R 250 denote the bag-of-words vector for images in a bag with lateral, dorsal and ventral view, respectively. The descriptor for this image bag can be represented as</p><formula>x =[x l ;x d ;x v ]</formula><p>∈R 1750. Since not all the image bags enclose the images from all three views, the corresponding bag-of-words representation is a vector of zeroes if a specific view is absent. Moreover, in order to capture the variability of the number of images in each view and each bag, we normalized the bag-of-words vector to unit length. At last, each image bag is represented by a normalized vector x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>In this section, we first construct a TG to model Drosophila gene expression patterns followed by proposing a novel PRW method. Using PRW on TG, we jointly make stage classification and annotate anatomical terms of</p><formula>y i =[y cT i ,y aT i ] T</formula><p>∈{0,1} Kc+Ka. Without loss of generality, we assume the first l &lt; n image bags are already labeled, which are denoted as T ={x i ,y i } l i=1. Our task is to learn a function f : X →{0,1} Kc+Ka from T that is able to classify an unlabeled data point x i (l +1 ≤ i ≤ n) into one stage class in C and to annotate it with a number of anatomical terms in A at the same time. For simplicity, we write</p><formula>Y c =[y c 1 ,··· ,y c n ], Y a =[y a 1 ,··· ,y a n ], and Y =[y 1, ··· ,y n ]</formula><p>. As introduced in Section 1, the stage class and anatomical terms have some relations. We utilize the following affinity matrix to model their interrelations, R ∈ R Kc×Ka , where R(i,j) indicates how closely class c i and term a j are related. In this work, we compute it as</p><formula>R(i,j) = cos( y c i , y a j ) =&lt; y c i , y a j &gt;/( y c i y a j ) (1)</formula><p>where y c i is the i-th row of Y c and y a j is the j-th row of Y a. Throughout this article, we denote a vector as a bold lowercase character and a matrix as an uppercase character. We denote the i-th entry of a vector v as v(i), and the entry at the i-th row and j-th column of a matrix M as M (i,j).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The construction of TG</head><p>Given the dataset X , pairwise similarity W X ∈ R n×n between data points can be computed using the Gaussian kernel function,</p><formula>W X (i,j) = exp(− x i −x j 2 /2σ 2 , i = j 0, otherwise (2)</formula><p>where the vector x is calculated using bag-of-word features for one image bag. Regarding the parameter σ , we resort to self-tuning method (Zelnik<ref type="bibr" target="#b26">Manor and Perona, 2004</ref>). W X (i,j) indicates how closely x i and x j are related.</p><formula>From W X , a graph G X = (V X ,E X ) can be induced, where V X = X and E X ⊆ V X ×V X .</formula><p>And we use kNN graph. To be specific, we connect x i ,x j if one of them is among the other's k nearest neighbor and define the value of the edge connecting them by Equation (2). Because G X characterizes the relationships between data points, it is usually called as data graph, such as the middle subgraph in<ref type="figure" target="#fig_2">Figure 3</ref>. Existing graph-based semi-supervised learning methods (<ref type="bibr" target="#b9">Kang et al., 2006;</ref><ref type="bibr" target="#b27">Zha et al., 2008</ref>) only make use of the data graph, on which the class label information is propagated. Different from conventional single-label classification learning problem in which classes are mutual exclusive, the anatomical terms are interrelated with one another. Again, we resort to cosine similarity to calculate the controlled term affinity matrix W A , where W A (i,j) indicates the correlation between</p><formula>a i and a j. Thus, a graph G A = (V A ,E A ) is induced, where V A = A and E A ⊆ V A ×V A .</formula><p>We call G A as annotation label subgraph, which is shown as the right subgraph in<ref type="figure" target="#fig_2">Figure 3</ref>. Similarly, stage classification label graph shown as the left subgraph in<ref type="figure" target="#fig_2">Figure 3</ref>,</p><formula>G C = (V C ,E C )</formula><p>can be constructed from stage classification labels, where</p><formula>V C = C and E C ⊆ V C ×V C ,</formula><p>where we define the value of the edge connecting two stage labels as</p><formula>W C (i,j) = S bi −S bj F ,</formula><p>where F means Frobenius norm and S bi denotes the between class scatter matrix for stage i. Connecting G X and G A by the annotation associations via the green dashed lines, connecting G X and G C by the class associations via the blue dashed lines and connecting G C and G A by the stage-term association via the purple dashed lines, we construct a TG as following:</p><formula>G = (V X ∪V C ∪V A ,E X ∪E A ∪E XC ∪E XA ∪E CA ), (3)</formula><p>which is illustrated in<ref type="figure" target="#fig_2">Figure 3</ref>. Obviously, the subgraph</p><formula>G AX = (V X ,V A ,E XA ) connects G X and G A ,</formula><p>whose adjacency matrix is Y T a. Similarly, the adjacency matrix of</p><formula>G CX = (V X ,V C ,E XC ) is Y T c. The subgraph V C ,V A ,E CA</formula><p>characterizes the associations between stage classes and anatomical terms whose adjacency matrix is R defined in Equation (1). In contrast to existing graph-based semi-supervised learning methods that only use information conveyed by G X , we aim to simultaneously classify and annotate an unlabeled data point using all the information encoded in G. Since all data points (gene expression image bags), stage terms and annotation terms are equally regarded as vertices on G, our task is to measure the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i18</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drosophila gene expression patterns</head><p>Cellular blastoderm</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Foregut anlage</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Foregut primordium Clypeolabrum anlage</head><p>Annotation label subgraph</p><formula>A A A E V G ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 7-8 Stage 13-16</head><p>Classification label subgraph</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage 4-6</head><p>Data subgraphrelevance between a class/anntotation term vertex and a data point vertex. As each class/annotation term has a set of associated training data points, which convey the same biological record information as the class/annotation term, we consider both a class/annotation term vertex and its labeled training image bag vertices as a group set,</p><formula>X X X E V G , ? ?</formula><formula>G k = c k ∪{x i |y i (k) = 1}, (4)</formula><p>which is illustrated as the vertices with orange boundary in 3. As a result, instead of measuring vertex-to-vertex relevance between a class/annotatation term vertex and an unlabeled data point vertex, we may measure the set-tovertex relevance between the group set and the data point. Motivated by<ref type="bibr" target="#b0">Brin and Page (1998)</ref>;<ref type="bibr" target="#b22">Tong et al. (2006)</ref>, we consider to further develop standard random walk and use its equilibrium probability to measure the relevance between a group set and an unlabeled data point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preferential random walk</head><p>Standard random walk on a graph W can be described as a Markov process with transition probability</p><formula>M = D −1 W , where d i = j W (i,j) is the degree of vertex i and D = diag(d 1 ,··· ,d n ). Clearly, M T = M and j M (i,j) = 1.</formula><p>When W is symmetric, it corresponds to an undirected graph. When W is asymmetric, it corresponds to a directed graph and d i is the out degree of vertex i. Let p (t) be the distribution of the random walker at time t, the distribution at t +1 is given by</p><formula>p (t+1) (j) = i p (t) (i)M (i,j</formula><p>). Thus, the equilibrium (stationary) distribution of the random walk</p><formula>p * = p (t=∞) is determined by M T p * = p * .</formula><p>It is well known that the solution is simply given by</p><formula>p * = W e/( i d i ) = d/( i d i ), where d =[d 1 ,··· ,d n ] T .</formula><p>It can be seen that the equilibrium distribution of a standard random walk is solely determined by the graph itself, but independent of the location where the random walk is initiated. In order to incorporate label information, we propose the following PRW:</p><formula>p (t+1) (j) = (1−α) i p (t) (i)M (i,j)+αh j ,</formula><formula>(5)</formula><p>where 0 α 1 is a fixed parameter, and h, called preferential distribution, is a probability distribution such that h(i) 0 and i h(i) = 1. Equation (5) describes a random walk process in which the random walker hops on the graph W according to the transition matrix M with probability 1−α, and meanwhile it takes a preference to go to other vertices specified by h with probability α. The equilibrium distribution of PRW in Equation (5) is determined by p * = (1−α)M T p * +αh, which leads to:</p><formula>p * = α[I −(1−α)M T ] −1 h.</formula><formula>(6)</formula><p>Due to Perron-Frobenius theorem, the maximum eigenvalue of M is less than max i j M (i,j) = 1. Thus, I −(1−α)M T is positive definite and invertible. Equation (5) takes a similar form to two existing works: random walk with restart (RWR) method (<ref type="bibr" target="#b22">Tong et al., 2006</ref>) and PageRank algorithm (<ref type="bibr" target="#b0">Brin and Page, 1998</ref>). In the former, h is a vector with all entries to be 0 except one entry to be 1 indicating the vertex where the random walk could be restarted; while in the latter, h is a constant vector called as damping factor (<ref type="bibr" target="#b0">Brin and Page, 1998</ref>). In contrast, the preferential distribution vector h in Equation (5) is a generic probability distribution, which is flexible thereby more powerful. Most importantly, through h we can assess group-to-vertex relevance, while RWR and PageRank methods measure vertex-to-vertex relevance. Similar to RWR (<ref type="bibr" target="#b22">Tong et al., 2006</ref>), when we set the h to be a probability distribution in which all the entries are 0 except for those corresponding to G k , p * (i) measures how relevant the k-th group is to the i-th vertex on G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Preferential random walk on TG</head><p>In order to classify and annotate unlabeled data points using the equilibrium probabilities in Equation (6) of the PRW on TG, we need to construct the transition matrix M and the preferential distribution h from G. Construction of the transition matrix M : Let</p><formula>M = ⎡ ⎣ M X M XC M XA M CX M C M CA M AX M AC M A ⎤ ⎦ ,</formula><formula>(7)</formula><p>whereone of the other two subgraphs. When both β 1 = 0 and β 2 = 0, the random walk are performed independently on G X , which is equivalent to existing graph-based semi-supervised learning methods only using the data graph G X. Similarly, we define λ as the jumping probability from G C to G A or vice versa. During a random walk process, if the random walker is on a vertex of the data subgraph which has at least one connection to the label subgraph, such as vertex x 1 in<ref type="figure" target="#fig_2">Figure 3</ref>, she can hops to the class label or annotation subgraph with probability β 1 or annotation subgraph with probability β 2 , or stay on the data subgraph with probability 1−β 1 −β 2 and hop to other vertices of the data subgraph. If the random walker is on a vertex of the data subgraph without a connection to the class label or annotation subgraph, she stays on the data subgraph and hops to other vertices on it as in standard random walk process. To be more precise, let d</p><formula>Y T c i = j Y T c (i,j</formula><p>), the transition probability from x i to c j is defined as following:</p><formula>p(c j |x i ) = M XC (i,j) = β 1 Y T c (i,j)/d Y T c i , d Y T c i &gt; 0, 0, otherwise. (8)</formula><p>Similarly, let d Yc</p><formula>i = j Y c (i,j</formula><p>), the transition probability from c i to x j is:</p><formula>p(x j |c i ) = M CX (i,j) = β 1 Y c (i,j)/d Yc i , d Yc i &gt; 0, 0, otherwise. (9)</formula><p>Following the same definition, the rest four inter-subgraph transition probability matrices are defined as:</p><formula>p(a j |x i ) = M XA (i,j) = β 2 Y T a (i,j)/d Y T a i , if d Y T a i &gt; 0, 0, otherwise. (10) p(x j |a i ) = M AX (i,j) = β 2 Y a (i,j)/d Y a i , if d Ya i &gt; 0, 0, otherwise. (11) where d Y T a i = j Y T a (i,j) and d Y a i = j Y a (i,j), and p(c j |a i ) = M AC (i,j) = λR T (i,j)/d R T i , if d R T i &gt; 0, 0, otherwise. (12) p(a j |c i ) = M CA (i,j) = λR(i,j)/d R i , if d R i &gt; 0, 0, otherwise (13) where d R T i = j R T (i,j) and d R i = j R(i,j). Let d X i = j W X (i,j), d Y i = j Y (i,j), d Qa i = j Q a (i,j), d Qc i = j Q c (i,j) where Q a = R+Y a and Q c = R T +Y c .</formula><p>The data subgraph intra transition probability from x i to x j is computed as:</p><formula>p(x j |x i ) = M X (i,j) = (1−β 1 −β 2 )W X (i,j)/d X i , if d Y T i &gt; 0 W X (i,j)/d X i , otherwise (14) Similarly, let d A i = j W A (i,j</formula><p>), the annotation label subgraph intra transition probability from a i to a j is:</p><formula>p(a j |a i ) = M A (i,j) = (1−β 2 −λ)W A (i,j)/d A i , if d Q T a i &gt; 0 W A (i,j)/d A i , otherwise (15) let d C i = j W C (i,j</formula><p>), the classification label subgraph intra transition probability from c i to c j is:</p><formula>p(c j |c i ) = M C (i,j) = (1−β 1 −λ)W C (i,j)/d C i , if d Q T c i &gt; 0 W C (i,j)/d C i , otherwise (16)</formula><p>It can be easily verified that, j M (i,j) = 1, i.e. M is a stochastic matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Construction of the preferential distribution H :</head><p>the preferential distribution vector specifies a group of vertices to which the random walker prefers to moving in every iteration step. The relevance between this group and an vertex is measured by the equilibrium distribution of the random walk process. Therefore, we construct K = K c +K a preferential distribution vectors, one for each semantic group G k :</p><formula>h (k) = γ h (k) X (1−γ )h (k) L ∈ R n+K + (17) where h (k) X (i) = 1/ i y i (k) if y i (k) = 1 and h (k) X (i) = 0, otherwise; h (k) L (i) = 1, if i = k, γ ∈[0,1] controls</formula><p>how much the random walker prefers to go to the data subgraph G X and other two subgraphs G C , G A. It can be verified that</p><formula>i h (k) (i) = 1, i.e, h (k)</formula><p>is a probability distribution. Let I K be the identity matrix of size K ×K, we write</p><formula>H =[h (1) ,··· ,h (K) ]= γ H X (1−γ )I K (18)</formula><p>PRW on TG: given the TG of a dataset, using the transition matrix M defined in Equation (7) and the preferential probability matrix H defined in Equation (18), we can perform PRW on the TG. According to Equation (6), its equilibrium distribution matrix P * is computed as:</p><formula>P * = α[I −(1−α)M T ] −1 H ,</formula><formula>(19) P * =[p * 1 ,··· ,p * K ]∈R (n+K)</formula><p>×K , and p * k is the equilibrium distribution of the PRW taking the k-th semantic group as preference. Therefore,</p><formula>p * k (i) (l + 1 i n) measures</formula><p>the relevance between the k-th class and an unlabeled image bag x i. We can predict the stage class from the sub-matrix P * nc by Equation (20) and annotate the controlled terms for x i using the adaptive decision boundary method (<ref type="bibr" target="#b24">Wang et al., 2009</ref>) on the submatrix P * na by Equation (21).</p><formula>P * nc = ⎡ ⎢ ⎢ ⎣ P * (l +1,1) ··· P * (l +1,K c ) . . . .. . . . . P * (n,1) ··· P * (n,K c ) ⎤ ⎥ ⎥ ⎦ (20) P * na = ⎡ ⎢ ⎢ ⎣ P * (l +1,K c +1) ··· P * (l +1,K c +K a ) .. . .. . .. . P * (n,K c +1) ··· P * (n,K c +K a ) ⎤ ⎥ ⎥ ⎦ (21)</formula><p>Since the stage prediction is a single-label classification problem, we select the stage label y(i) c * with the maximum probability as the stage label for image bag x i .</p><formula>y(i) c * = argmax k ( p c i ),∀i = l +1,l +2,...,n.</formula><formula>(22)</formula><p>where p c i is the i-th row vector of matrix P * nc. Therefore, we can do the stage classification and anatomical controlled term annotation simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DATA REFINEMENT</head><p>In this section, we will introduce the details of the data used in our experiment. Drosophila embryogenesis has 17 stages, which are divided into 6 major ranges, i.e. stages 1–3, 4–6, 7–8, 9–10, 11–12 and 13–16 (the stage 17 is usually studied individually), in the BDGP database (<ref type="bibr" target="#b20">Tomancak et al., 2002</ref>). Each image bag is labeled with one stage term and many controlled vocabulary terms. The total number of anatomical controlled vocabulary terms is 303. We used the following way to refine the dataset. First, we only keep the image bag data with lateral, dorsal and ventral view information. And then, we eliminate six common annotation terms, that is, 'no staining, ubiquitous, strong ubiquitous, faint ubiquitous,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i20</head><p>Copyedited by: TRJ MANUSCRIPT CATEGORY:<ref type="bibr">[11:19</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drosophila gene expression patterns</head><p>maternal, rapidly degraded', which can be regarded as outliers because they can neither provide stage-specific information nor record anatomical structures. After that, we remove the anatomical terms whose data sample is &lt;50. We ignore the stage 1–3 data since the number of anatomical terms after the above procedure becomes 2, too small to be compared with other stages. And finally we get 79 anatomical annotation terms in total that we will consider to annotate the unlabeled image bag. We refine the data mainly based on the following two reasons. On one hand, the annotation terms which appear in too few image bags are statistically too weak to be learned effectively. On the other hand, since we will use 5-fold cross-validations in our experiments, we have to guarantee there is at least one data point associated with each anatomical term in each fold. Moreover, in order to balance the number of image bags for different stages, we randomly sample 500 image bags as the data points for each stage. At last, the summary of the refined dataset is shown in<ref type="figure" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT</head><p>In this section, we will conduct experiments to evaluate PRW empirically on the refined dataset and compare it with other state-of-art classification methods. Since our method can do joint classification, in order to evaluate the benefit of joint learning, we compare its performance with that of the state-of-art multiclass single label or multiclass multilabel algorithms which can only handle either stage classification or anatomical term annotation problem. Our procedure is to train our model with stage labeled and anatomical term annotated image bags. All testing image bags are unlabeled with developmental stage and unannotated with anatomical controlled terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>When constructing PRW on TG, we used kNN graph setting k = 9. We used 'inverse' 5-fold cross-validation to determine the values of the following five parameters, that is, using 1-fold for training and using the remaining 4-folds for testing to mimic the scenario in the real application where the number of training data is much less than the testing data. In our experiment, we found that the following five parameters are not sensitive in certain ranges with good performances. β 1 , β 2 and λ controls the jumping between different subgraphs and cannot affect the result much if they are assigned in the range of (0.1,0.45). α controls initial preference of the random walker and will get stable result if it is assigned in the range of (0,0.1). γ controls how much the random walker prefers to go to the data subgraph or to go to two other subgraphs and it is usually in the range of (0.1,0.3). Besides those parameters, we also need to initialize the stage as well as anatomical controlled terms for the testing image bag x i , where i = l +1,...,n, l is the number of training image bag. In our experiment, we used k-nearest neighbor (KNN) method to do the initializations for both stage classification and anatomical term annotations tasks because of its simplicity and clear intuition. To be specific, we use k = 1 and we abbreviate it as 1NN. Our joint classification framework will self-consistently amend the incorrect labels for stage and controlled terms. We perform 10 random splits of the data and report the average performance over the 10 trials. Please note that, in each trial, we still do 'inverse' 5-fold cross validation and record the average performance result as the result of that trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Image bag stage classification</head><p>Drosophila gene expression pattern stage categorization is a singlelabel multi-class problem. We compare the result of our method with that of support vector machine (SVM) with radial basis function (RBF) kernel (<ref type="bibr">Chang and Lin, 2001</ref>). We use the optimal parameter values for C and γ got from cross-validation as well. We also compare the classification result of 1NN that we use to do the initialization. We assess the classification in terms of the average classification accuracy and the average confusion matrices. Since the data that we used is class balanced, the mean value of the entries on the diagonal of the confusion matrix is also the average classification accuracy. From the resulting average confusion matrices shown in<ref type="figure" target="#fig_5">Figure 5</ref>, we can see that the average prediction accuracy of our method is better than that of the other two state-of-art methods, especially in the last stage 13–16, where the number of anatomical terms is greatly larger than that of the other stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Image bag controlled vocabulary terms annotation</head><p>Copyedited by: TRJ MANUSCRIPT CATEGORY:<ref type="bibr">[11:19</ref>–16, because of the strong correlation between the predicted stage and its predicted anatomical terms and vice versa, NOT the similarity of its first and second nearest neighboring data induced from the data graph onlyinterrelations to make the decision for stage classification and anatomical controlled term annotation simultaneously. When there are strong correlation between those two tasks, we expect that the performance of both tasks will be enhanced by joint learning work than treating them individually and independently.<ref type="figure" target="#fig_3">Figure 4</ref>shows the pairwise label correlations of the 79 terms and stage–term correlations between 5 stages and 79 terms. As highlighted by purple arrows, we can observe that there are high pairwise correlations between the terms 'embryonic brain','ventral nerve cord' as well as 'embryonic/larval muscle system'. Moreover, all the above three terms have high correlations with the stage 13–16, which can provide strong evidence that the given testing image bag could belong to the last developmental stage besides the induction from the data graph only. If our joint classification framework annotates it with all those three terms, although from the data similarity we cannot get</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Drosophila gene expression patterns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">The more meaningful asymmetric correlation matrix</head><p>When we build the TG, at first, we assume the term–term correlation and stage–term correlation are both symmetric, since we used cosine similarity to represent their correlations. However, the above assumption does not always hold in the real data. In Drosophila embryo gene expression images, we found that the conditional probability of the occurrence of term 'ventral nerve cord' given term 'embryonic brain' is higher than that of the 'embryonic brain' given 'ventral nerve cord', which satisfies the biology meaning that ventral nerve cord occurs earlier than embryonic brain. After learning, our method can automatically discover the above hidden asymmetric correlation information, that is,</p><formula>P * aa = ⎡ ⎢ ⎣ P * (n+K c +1,K c +1) ··· P * (n+K c +1,K) .. . .. . .. . P * (n+K,K c +1) ... P * (n+K,K) ⎤ ⎥ ⎦ (23)</formula><p>In order to see the learned asymmetric term–term correlation more clearly, in<ref type="figure" target="#fig_7">Figure 7</ref>, we show the difference matrix got by</p><formula>P * aa −P * aa T .</formula><p>Taking those more accurate asymmetric correlation into consideration, our method can potentially improve both stage classification and anatomical annotation results even more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this article, we proposed a novel TG model to learn the task interrelations between stage recognition and anatomical terms annotation of Drosophila gene expression patterns. The standard bag-of-word features and three major views (lateral, dorsal and ventral) were used to describe the 3D Drosophila images. A new PRW method was introduced to simultaneously propagate the stage labels and anatomical controlled terms via TG model. Both stage classification and anatomical controlled term annotation tasks are jointly completed. We evaluated the proposed method using one refined BDGP dataset. The experimental results demonstrated in the real application, when the number of training data is scarce, our joint learning method can achieve superior prediction results on both tasks than the state-of-the-art methods. What is more, we can discovery more accurate asymmetric term–term correlation, which can potentially improve the results of both tasks even more.) In order to see the asymmetric entries more clearly, we plot</p><formula>P * aa −P * aa T .</formula><p>After PRW, the entries marked as brighter square have higher conditional probability (positive correlation) than its counterpart which is marked as darker color. This asymmetric reflects more accurate term–term correlation than the original symmetric assumption</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.2.</head><figDesc>Fig. 2. Demonstration of the regular patches. We extract one SIFT feature on one patch, where the radius and spacing of the regular patches are set to 16 pixels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>||v|| denotes the Euclidian norm of vector v. And the inner product of two vector v 1 and v 2 is defined as &lt; v 1 ,v 2 &gt;= v T 1 v 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. The TG constructed from the gene expression data. Solid lines indicate affinity between vertices within in a same subgraph, dashed lines indicates associations between vertices in two different subgraphs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. The middle part demonstrates the terms–stages correlation and the right part shows the terms–terms correlation of 79 terms. The stage unknown test data shown in the left part is classified correctly as Stage 13–16, because of the strong correlation between the predicted stage and its predicted anatomical terms and vice versa, NOT the similarity of its first and second nearest neighboring data induced from the data graph only</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Stage classification results in terms of confusion matrices on 79-term dataset: (a) the confusion matrix calculated by SVM (b) the confusion matrix calculated by 1NN. (c) the confusion matrix calculated by our method. (a) SVM: acc. 84.50%; (b) 1NN: acc. 77.40%; (c) our: acc. 85.20%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.6.</head><figDesc>Fig. 6. The Avg. Micro F1 score of five methods on each term in 79-term dataset. (It is better to be viewed in colorful and zoomed in mode.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.7.</head><figDesc>Fig. 7. The learned difference matrix. (It is better to be viewed in colorful and zoomed in mode.) In order to see the asymmetric entries more clearly, we plot P * aa −P *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1.</figDesc><table>(Other codebook sizes gave similar 
performance.) 

i17 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1.</figDesc><table>The statistics summary of the refined BDGP images with 79 terms 

Stage range 
4–6 
7–8 
9–10 
11–12 
13–16 
Total 

Size of control term 
11 
12 
12 
20 
31 
79 
No. of image bags 
500 
500 
500 
500 
500 
2500 
No. of lateral images 
1514 
812 
727 
1356 
1004 
5414 
No. of dorsal images 
226 
324 
431 
447 
724 
2152 
No. of ventral images 
164 
137 
81 
214 
216 
812 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Drosophila gene expression patterns. For the Drosophila gene expression pattern data, we have n gene expression images bags X ={x 1 ,··· ,x n }, where each image bag is abstracted as a data point x i ∈ R p. Each data point x i belongs to one of K c stage classes C ={c 1 ,··· ,c Kc } represented by y c i ∈{0,1} Kc , such that y c i (k) = 1 if x i is classified into class c k , and 0 otherwise. Meanwhile, each image bag x i is also annotated with a number of anatomical ontology terms A ={a 1 ,··· ,a Ka } represented by y a i ∈{0,1} Ka , such that y a i (k) = 1 if x i is annotated with term a k , and 0 otherwise. Also, for convenience, we write</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>M X , M C and M A are the intrasubgraph transition matrices of G X , G C and G A respectively, and the rest six sub-matrices are the intersubgraph transition matrices among G X , G C and G A. Let β 1 ∈[0,1] be the jumping probability, i.e. the probability that a random walker hops from G X to G C and vice versa. And let β 2 ∈[0,1] be the jumping probability from G X to or vice versa. Therefore, β 1 and β 2 regulates the reinforcement between G X and</figDesc><table>i19 

at :: on August 30, 2016 

http://bioinformatics.oxfordjournals.org/ 

Downloaded from 

Copyedited by: TRJ 

MANUSCRIPT CATEGORY: 

[11:19 31/5/2012 Bioinformatics-bts220.tex] 
Page: i20 i16–i24 

X.Cai et al. 

G A </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Table 2.</figDesc><table>Annotation prediction performance comparison 
on the 79-term dataset 

Method 
Ma Pre Ma F1 
Mi Pre Mi F1 

1NN 
0.3455 
0.3595 0.2318 
0.2230 
LS 
0.5640 
0.3778 0.3516 
0.1903 
LR 
0.6049 
0.4425 0.3953 
0.2243 
RW 
0.4019 
0.3385 0.2808 
0.1835 
HF 
0.3727 
0.3296 0.2756 
0.1733 
Our method 0.6125 
0.4434 0.4057 
0.2336 

Ma Pre, Avg. Macro Precision; Ma F1, Avg. Macro F1; Mi Pre, 
Avg. Micro Precision; Mi F1, Avg. Micro F1. 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Besides the stage classification task, we also validate our method by predicting the anatomical controlled terms for the Drosophila gene expression patterns, which can be considered as a multi-class multi-label classification problem. The conventional classification performance metrics in statistical learning, precision and F1 score, are utilized to evaluate the proposed methods. For every anatomical term, the precision and F1 score are computed following the standard definition for the binary classification problem. To address the multilabel scenario, following Tsoumakas and Vlahavas (2007), macro and micro average of precision and F1 score are used to assess the overall performance across multiple labels. We compared four state of art multi-label classification methods: local shared subspace (LS) (Ji et al., 2008), local regression (LR) (Ji et al., 2009), harmonic function (HF) (Zhu et al., 2003) and random walk (RW) (Zhou and Schölkopf, 2004). All of them are proposed recently to solve the multilabel annotation problem. In addition, we compare the results of 1NN as well. For the first three methods we use the published codes posted on the corresponding author&apos;s websites. And we implement the RW method following the original work (Zhou and Schölkopf, 2004). For HF and RW methods, we follow the original work to solve the multilabel annotation only. Therefore, we only evaluate those two methods on data subgraph and annotation label subgraph without using any information derived from the classification label subgraph such as the stage–term correlation. Table 2 shows the average anatomical annotation performance of 79-term dataset. Compared to the above five stat-of-the-art methods, our method has the best results by all metrics. Figure 6 illustrates the average Micro F1 score of our method, 1NN, LS, LR, RW and HF approaches for all the anatomical terms on 79-term dataset. And again, our method consistently achieves best performance for most of the anatomical controlled terms. 5.4 The advantage of joint learning Unlike the traditional work, our proposed method can take advantage of all the information to do the stage classification and anatomical term annotation simultaneously. Therefore, when the number of training data is scare, we can resort to both intrarelations and i21 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">strong evidence for the stage prediction, we can take advantage of the term–term as well as term–stage high correlations to adjust its stage to stage 13–16. In other words, relevant anatomical terms could help us to predict the stage label since they provide the spatial and temporal information of local structure corresponding to a specific embryo development stage. Nevertheless, not all anatomical terms will definitely benefit stage classification, which is consistent with our stage classification result. From Figure 5, we can see that our method may have competitive result compared with SVM with respect to some certain stage. However, given more anatomical term information, the performance of our method will gradually outperform the other methods, especially for the prediction result of stage 13–16. i22 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">i24 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The author would like to thank Dr Sudhir Kumar for his help in data collection.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Brin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Page</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web (WWW)</title>
		<imprint>
			<publisher>Elsevier Science Publishers</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">LIBSVM : a library for support vector machines</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A quantitative spatiotemporal atlas of gene expression in the Drosophila blastoderm</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Fowlkes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="364" to="374" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">FlyBase: anatomical data, images and queries</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Grumbling</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="484" to="488" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Three dimensional morphology and gene expression in the Drosophila blastoderm at cellular resolution I: data acquisition pipeline</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Hendriks</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="123" to="146" />
			<date type="published" when="2006-08-30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Downloaded from Copyedited by: TRJ MANUSCRIPT CATEGORY</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="31" to="55" />
		</imprint>
	</monogr>
	<note>bts220. .tex] Page</note>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Extracting shared subspace for multi-label classification</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="381" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Drosophila gene expression pattern annotation using sparse features and term-term interactions</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="407" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">A shared-subspace learning framework for multi-label classification</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Correlated label propagation with application to multi-label learning</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Kang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1719" to="1726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">BEST: A novel computational approach for comparing gene expression patterns from early stages of Drosophila melanogaster development</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kumar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="2037" to="2047" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Global analysis of mRNA localization reveals a prominent role in organizing cellular architecture and function</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>&apos;ecuyer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="page" from="174" to="187" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Drosophila gene expression pattern annotation through multi-instance multi-label learning</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artificial Intelligence</title>
		<meeting>the 21st International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1445" to="1450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lowe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">FlyMine: an integrated database for Drosophila and anopheles genomics</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lyne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">129</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Imaging in systems biology</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Megason</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Fraser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="784" to="795" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparing in situ mRNA expression patterns of drosophila embryos</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research in Computational Molecular Biology (RECOMB), ACM</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic image analysis for gene expression patterns of fly embryos</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cell Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">SPEX 2 : Automated Concise Extraction of Spatial Gene Expression Patterns from Fly Embryo ISH Images</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Puniyani</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intell. Sys. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A bag-of-words approach for Drosophila gene expression pattern annotation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shuiwang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Systematic determination of patterns of gene expression during Drosophila embryogenesis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tomancak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">88</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Global analysis of patterns of gene expression during Drosophila embryogenesis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tomancak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast random walk with restart and its applications</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Tong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="613" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Random k-labelsets: An ensemble method for multilabel classification</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Tsoumakas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">P</forename>
				<surname>Vlahavas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on Machine Learning, SpringerVerlag</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="406" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Image annotation using multi-label correlated Green&apos;s function</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2029" to="2034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">FlyMove – a new way to look at development of Drosophila</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Weigmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Genet</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="310" to="311" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Self-tuning spectral clustering Advances in neural information processing systems</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Zelnik-Manor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Perona</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph-based semi-supervised learning with multi-label</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Zha</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1321" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning from labeled and unlabeled data using random walks</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Schölkopf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Symposium of the German Association for Pattern Recognition (DAGM)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="237" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Semi-supervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Zhu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>ACM press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="912" to="919" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>