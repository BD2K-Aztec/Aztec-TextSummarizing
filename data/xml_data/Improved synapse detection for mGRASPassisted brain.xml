
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improved synapse detection for mGRASP-assisted brain connectivity mapping</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Linqing</forename>
								<surname>Feng</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Functional Connectomics</orgName>
								<orgName type="institution">Korea Institute of Science and Technology</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ting</forename>
								<surname>Zhao</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Qiushi Academy for Advanced Studies</orgName>
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Jinhyun</forename>
								<surname>Kim</surname>
							</persName>
							<email>kimj@kist.re.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Functional Connectomics</orgName>
								<orgName type="institution">Korea Institute of Science and Technology</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improved synapse detection for mGRASP-assisted brain connectivity mapping</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="25" to="31"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts221</idno>
					<note>Copyedited by: ES MANUSCRIPT CATEGORY: [16:14 29/5/2012 Bioinformatics-bts221.tex] Page: i25 i25–i31 BIOINFORMATICS</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: A new technique, mammalian green fluorescence protein (GFP) reconstitution across synaptic partners (mGRASP), enables mapping mammalian synaptic connectivity with light microscopy. To characterize the locations and distribution of synapses in complex neuronal networks visualized by mGRASP, it is essential to detect mGRASP fluorescence signals with high accuracy. Results: We developed a fully automatic method for detecting mGRASP-labeled synapse puncta. By modeling each punctum as a Gaussian distribution, our method enables accurate detection even when puncta of varying size and shape partially overlap. The method consists of three stages: blob detection by global thresholding; blob separation by watershed; and punctum modeling by a variational Bayesian Gaussian mixture models. Extensive testing shows that the three-stage method improved detection accuracy markedly, and especially reduces under-segmentation. The method provides a goodness-of-fit score for each detected punctum, allowing efficient error detection. We applied this advantage to also develop an efficient interactive method for correcting errors. Availability: The software is available on http://compbio.cs.wayne.edu/software/rna
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>An important challenge in neuroscience is to map the synaptic connectivity of neuronal networks in mammalian brains. Among advanced technologies for mapping connectivity, the fluorescencebased mGRASP (<ref type="bibr">Kim et al., 2012</ref>) stands as a markedly powerful tool for comprehensive studies of synaptic circuits in mammalian brains. The mGRASP technique is based on fluorescence that is reconstituted when two non-fluorescent split GFP fragments targeted to the synaptic membranes in two separate neuronal populations are closely opposed across the synaptic cleft; thus, fluorescence uniquely indicates a synapse. Computational methods including image stitch, neuron reconstruction and synapse detection have been applied successfully to investigate the locations and distributions of synapses in dendritic compartments and in neurons labeled with mGRASP. In our previous study, computational analysis for synapse detection achieved 93% accuracy. Here we introduce optimizations to improve synapse detection and other tasks. Detecting mGRASP-labeled synapses is complicated by the low signal-to-noise ratios of the original images, the variety of the sizes and shapes of fluorescent puncta, and signal overlap from neighboring puncta (<ref type="figure" target="#fig_0">Fig. 1</ref>). To overcome these difficulties, we previously applied a method based on Gaussian template matching followed by blob merging (<ref type="bibr">Kim et al., 2012</ref>). But, lacking a * To whom correspondence should be addressed.splitting procedure, this method frequently suffered from undersegmentation, which is the error of counting multiple puncta as one. Although no other method had been developed specifically for punctum detection in mGRASP images, the problem is closely related to fluorescent particle detection (e.g. GFP-labeled peroxisomes and GLUT4), for which several methods have been published (<ref type="bibr" target="#b3">Bonneau et al., 2005;</ref><ref type="bibr" target="#b8">Mashanov and Molloy, 2007;</ref><ref type="bibr" target="#b12">Sage et al., 2005;</ref><ref type="bibr" target="#b14">Smal et al., 2010</ref>). However, most of these methods are not suitable for mGRASP-labeled punctum detection because they cannot accommodate particles featuring a wide range of sizes, irregular shapes and degrees of overlap or they are not readily extended into three dimensions. For example, (<ref type="bibr" target="#b14">Smal et al., 2010</ref>) evaluated several 2D particle detection methods and found that multiscale variance-stabilizing transform (MSVST) (<ref type="bibr" target="#b20">Zhang et al., 2007</ref>) and h-dome transform (<ref type="bibr" target="#b13">Smal et al., 2008</ref>) based methods offered the best performance among unsupervised methods. However, both these methods assume that the particles are well separated. MSVST takes any connected foreground feature as a particle without providing any splitting correction, and h-dome based method treats foreground clusters as noise. Neither method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Feng et al.</head><p>provides a solution to the problem of puncta overlap. The review also introduced two supervised methods, one of which was originally reported in (<ref type="bibr" target="#b5">Jiang et al., 2007</ref>). But it is not straightforward to generalize the 2D edge features used in the methods to 3D. In particular, we found it impractical to design a set of template features for our data and to build a sufficiently large training set, both of which are necessary for any supervised method. A more promising category of method includes those using mixture models, which estimate the shapes, sizes and locations of particles from a blob in one framework. For example, (<ref type="bibr" target="#b16">Thomann et al., 2002</ref>) and (<ref type="bibr" target="#b4">Jaqaman et al., 2008</ref>) used the mixture of point spread functions to fit clustered particles. (<ref type="bibr" target="#b21">Zhao and Murphy, 2007</ref>) employed a Gaussian mixture models (GMMs) to detect protein particles in 2D images. Later this method was extended to 3D by (<ref type="bibr" target="#b11">Peng and Murphy, 2011</ref>). However, these methods have a major disadvantage. Since the number of particles is unknown, it is necessary to fit every possible mixture model to the data and then determine the best fit with minimal model complexity. Since this fitting problem is highly non-linear, finding good initial parameters is crucial to the final result. However, for synapse puncta these parameters can be hard to choose because their size is uncertain. Also, these methods lack post-processing for the mixture model, a step necessary for puncta detection since puncta can have irregular shapes and GMMs are sensitive to outlier data. Other related methods are those used for DAPI-labeled nuclei segmentation, in which a splitting procedure is often necessary (<ref type="bibr" target="#b7">Lin et al., 2003</ref>). One of the most impressive nuclei segmentation methods was developed by (<ref type="bibr" target="#b0">Al-Kofahi et al., 2010</ref>), who used watershed techniques to separate clustered nuclei and then applied graph cuts to refine the results. Here we introduce a new method based on a splitting strategy using a marker-controlled watershed approach and a variational Bayesian Gaussian mixture models (VBGMMs) to accurately detect mGRASP-labeled synapses of variable sizes and shapes. Watershed is used for separating connected blobs by distinguishing their centers, and VBGMMs are then used for learning mixture models directly from the image data rather than requiring many initial parameters and an estimate of component number. Following VBGMMs, we implement an effective mean-shift and merge postprocessing to further refine the mixture models. We compare our method to others, including the method in (<ref type="bibr" target="#b0">Al-Kofahi et al., 2010</ref>), by testing them on a large set of mGRASP data. The results show that our method outperforms other tested methods and markedly improves detection accuracy compared with our previous method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">APPROACH</head><p>Our main challenge was to correctly separate clustered puncta of mGRASP-labeled synapses of variable sizes and shapes. The two main features of puncta used by our detection algorithm are a clear bright center and a convex shape; these features are also important for a human inspecting these images. Our detection algorithm follows a three stage process. The first stage is to use thresholding to separate the image's foreground voxels from background voxels. Foreground voxels form many clusters. In the second stage, centers of these clusters are marked and then a marker-controlled watershed is utilized to separate them. In the third stage, to detect the correct number and locations of puncta automatically, we use a variational bayesian mixture of gaussians followed by mean-shift to refinedetection. For numeric stability, we set a global size threshold N threshold. In any stage, if the voxel number of a separated part is smaller than N threshold , this part is treated as a punctum and will not be separated further. N threshold is set to 20 in the example shown here.<ref type="figure" target="#fig_1">Figure 2</ref>shows a flowchart illustrating the main steps of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Automatic image binarization</head><p>The first step is to identify foreground voxels that correspond to fluorescence signals of mGRASP-labeled synapses. We employed a global thresholding method that has been successfully used to extract neurons from light microscope images (<ref type="bibr" target="#b18">Xie et al., 2011;</ref><ref type="bibr" target="#b22">Zhao et al., 2011</ref>). In brief, the method takes advantage of the fact that most local maximal regions in a microscope image are background noise. We found that a good threshold turned out to be the transition point of the normalized histogram of local maxima. As shown in<ref type="figure">Figure 3</ref>, from the histogram h where h(i) is the number of local maximum voxels that have the intensity i, we first obtain i max = argmax i h(i), the intensity value that has the highest frequency, and i min = argmin i h(i), the intensity with the lowest frequency minh(i). We then normalize the histogram as h r (i) = (h(i)−minh(i))(i min −i max )/(maxh(i)−minh(i)).</p><formula>(1)</formula><p>It can be shown that T = argmin i (i−i max +h r (i)) is the transition point (<ref type="bibr" target="#b18">Xie et al., 2011</ref>), which is also taken as the global threshold to separate the foreground and background of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i26</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Marker-controlled watershed segmentation</head><p>Binarization of an image results in many isolated blobs of connected foreground voxels. There can be one or more puncta in each blob, and the goal of this stage is to identify individual puncta blob by blob. This task is similar to separating touching objects, which is a classical application of the watershed algorithm. In practice, however, the original watershed method tends to generate uncorrectable over-segmentation in a noisy image. One common solution to this problem is to use a marker-controlled version of watershed, which sets a size threshold for adding a 'catchment basin' (<ref type="bibr" target="#b17">Vincent, 1993;</ref><ref type="bibr" target="#b19">Yang et al., 2006</ref>). Similar to any other watershed method, the marker-controlled watershed starts checking voxels progressively from the highest or lowest gray level, depending upon whether region borders are darker or brighter than region centers. In our case the process starts from the highest gray level because puncta usually have bright centers. At each gray level, a blob is dissected into connected components of voxels with intensities higher than the gray level. When a component contains only one previously defined marker, all voxels will be assigned to that marker; when a component contains more than one marker, any unmarked voxel is assigned to its closest marker. A new marker is added when a component contains no pre-defined marker and the size of a component exceeds the threshold T m. High T m value can suppress local maxima caused by noise, thus preventing over-segmentation. For our data, we choose T m = 6. After the watershed process, every voxel of a blob is assigned to one of the markers.<ref type="figure" target="#fig_4">Figure 4C</ref>shows the result of watershed separating for the example image. It misses one punctum in Part 3 because its signal is weak and the center of the punctum is unclear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mean-shift regulated VBGMMs</head><p>Since a punctum is assumed to have a bright center and a convex shape, it can be modeled as a 3D Gaussian distribution. As a result, any blob that has one or more puncta can be modeled as mixture of Gaussians. The data for fitting GMMs at this stage are taken from the previous watershed segmentation. We denote the observed dataset by X ={x 1 ,...,x N }, where</p><formula>x n = x n ,y n ,z n for n = 1</formula><p>,...,N are the coordinates of the n-th voxel of the component. The intensity I ={i 1 ,...,i N } where i n is the intensity of x n serves as weight value for fitting; that is, we can assume that there are a total of M = N n=1 i n samples, among which the position x n is observed i n times. So the observations can be expanded to (x j 1 ,...,x j M ), which contains all the duplicates of the voxels. For each observation x jm we determine a corresponding latent variable z m comprising a 1-of-K binary vector with elements z mk for k = 1,...,K, where K is the number of Gaussian components. The expectation-maximization (EM) algorithm is often used to estimate model parameters of GMM by maximizing likelihood. The number of Gaussian components, however, has to be given as a known parameter when using an EM procedure. As K is unknown in our case, instead, we would need to analyze the dataset for all possible K values and then use Akaike information criterion (AIC) or Bayesian information criterion (BIC) to compensate for the over-fitting of complex models. This is computationally inefficient. We found an alternative, better, way is to use a fully Bayesian approach based on variational inference that can optimize the trade-off between model complexity and goodness of fit at the same time (<ref type="bibr" target="#b1">Attias, 2000;</ref><ref type="bibr" target="#b2">Bishop, 2006</ref>). We adopted this method by adding data weights {i n |n = 1,...,N} to make it better suited for our problem.</p><formula>1 ,...,z M } is p Z|π = M m=1 K k=1 π z mk k .</formula><formula>(2)</formula><p>The distribution of the observed data vectors conditioned on the latent variables and the component parameters is</p><formula>p X|Z,μ,, = M m=1 K k=1 N x jm |μ k ,, −1 k z mk (3)</formula><p>where μ and are the mean vector and precision matrix. The prior distribution for mixing coefficients π is assumed to be a symmetric Dirichlet distribution</p><formula>p(π ) = Dir π |α 0 .</formula><formula>(4)</formula><p>The mean and precision matrix of each Gaussian component are governed by the Gaussian-Wishart prior</p><formula>p μ,, = K k=1 N μ k |m 0 , β 0 k −1 W k |W 0 ,v 0 .</formula><formula>(5)</formula><p>By assuming that the variational posterior distribution can factorize between latent variables and parameters: q Z,π ,μ,</p><formula>= q Z q π ,μ, ,</formula><formula>(6)</formula><p>it can be optimized by repeating two steps, the expectation (E) step and the maximization (M) steps. In the E step, the model parameters are fixed. Current distributions are used to get the responsibility value E<ref type="bibr">[z mk ]</ref>, which is the k-th component's contribution to the data point x jm. Let</p><formula>lnρ k (x) = E[lnπ k ]+ 1 2 E[ln| k |]− D 2β k − v k 2 (x−m k ) T W k (x−m k )</formula><formula>(7) andˆρ andˆ andˆρ k (x) = ρ k (x) K j=1 ρ j (x) ,</formula><formula>(8)</formula><p>whereThen we have E</p><formula>[z mk ]= ˆ ρ k (x jm</formula><p>). Since the responsibility value is only related to data position, we can only caculate responsibility r nk = ˆ ρ k (x n ) for each voxel rather than all duplicated data points. The overall contribution of the k-th component to the data point x n is i n r nk. In the M step, variational distribution parameters are updated based on the fixed responsibility. Define</p><formula>x k = 1 N n=1 i n r nk N n=1 i n r nk x n (9)</formula><formula>q * (π ) = Dir(π |α)</formula><formula>(10) q * (μ k , k ) = N μ k |m k ,(β k k ) −1 W( k |W k ,v k ) ( 1 1 )</formula><p>where</p><formula>α k = α 0 + N n=1 i n r nk (12) β k = β 0 + N n=1 i n r nk (13) m k = 1 β k (β 0 m 0 + N n=1 i n r nk x n ) (14) W −1 k = W −1 0 + N n=1 i n r nk (x n −x k )(x n −x k ) T + β 0 N n=1 i n r nk β 0 + N n=1 i n r nk (x k −m 0 )(x k −m 0 ) T (15) v k = v 0 + N n=1 i n r nk .</formula><formula>(16)</formula><p>After convergence, only components that take responsibility for explaining the data points 'survive', and those with low responsibility values ( N n=1 i n r nk ) are removed. Although VBGMMs nicely solve the model selection problem, it requires specifying a proper initial value K 0 , which should be the upper bound of the actual number of puncta. For a non-saturated watershed component, we set K 0 as the number of local maximal regions. When the intensity of the component is highly saturated, we use a 2D Euclidean distance map to estimate K 0 instead. To build the distance map, we first binarize the maximumintensity projection (on the x–y plane) of the target component by setting all saturated voxels to 1 and other voxels to 0. The distance map is built upon the foreground of the binary image. We set K as the number of local maxima in the distance map plus the number of non-saturated local maxima in the component. Since bayesian clustering using mixture of Gaussian components is sensitive to outliers and noise (<ref type="bibr" target="#b15">Svensén and Bishop, 2005</ref>), both of which can lead to over-estimating the number of components, it is necessary to provide a merging procedure to check whether some components actually belong to the same punctum and, if they do, to merge them. In this procedure, the center m k of the k-th Gaussian component is readjusted by the mean-shift algorithm, an efficient procedure for locating the nearest stationary point of the underlying density function. By using mean-shift, we can move Gaussian components disturbed by outliers and noise to the desired locations. We can then merge the adjusted components according to their degree of overlap. The mean-shift radius R k is defined as the semi-minor axis length of the x–y projection of the Gaussian component within its 90% confidence interval. It can be calculated as follows</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i28</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mGRASP-assisted synapse detection</head><formula>R k = Inv-χ 2 (p conf ,D) μ 1/2 (λ i ) D ,</formula><formula>(17)</formula><p>where μ 1/2 (λ i ) is the median eigenvalue of the covariance matrix of the corresponding Gaussian component and p conf = 0.9 defines the confidence region for its projection.<ref type="figure" target="#fig_4">Figure 4E</ref>and<ref type="figure" target="#fig_5">Figure 5</ref>shows the process of VBGMM fitting, mean-shift and merging. The initial K in<ref type="figure" target="#fig_5">Figure 5</ref>is 12, which gives 12 Gaussians in a GMM (<ref type="figure" target="#fig_5">Figure 5B</ref>), and after the EM steps, only three components remain. The second column of<ref type="figure" target="#fig_4">Figure 4E</ref>shows the noise sensitivity of GMMs. Since some Gaussian components are fit only to a small number of data points and the number of components is overestimated, they are then fed into the merging procedure.<ref type="figure" target="#fig_5">Figure 5D</ref>and the third column of<ref type="figure" target="#fig_4">Figure 4E</ref>show the result of the mean-shift process, where all components were moved to the center of puncta. After that, we merge any pair of Gaussian components if either of their x–y projections have 80% overlap with the other.<ref type="figure" target="#fig_5">Figure 5E</ref>and last column of<ref type="figure" target="#fig_4">Figure 4E</ref>show the final results of merging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Proof-Editing</head><p>Although automated detection can provide reasonably accurate results, proof-editing is needed for correcting detection errors in order to avoid drawing misleading conclusions, as can occur in some other bioimage analysis tasks (<ref type="bibr" target="#b11">Peng et al., 2011</ref>). Nevertheless, it is very time consuming to scan the whole image visually to search for detection errors because large images may contain thousands of puncta. Therefore, it would be very helpful for an algorithm to provide a detection score for each punctum to estimate the likelihood a given detection is wrong. With such a score, we can significantly improve the efficiency of proof-editing by presenting puncta in the order of their scores or with visual hints of the scores. Another advantage of our method is that it allows calculating the fitting score, e.g. the Pearson's correlation coefficient, between the signal of a punctum and its Gaussian model. The lower this confidence score, the more likely the detection is in error. Low scores can be spotted</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">m × 13.m ×</head><p>49.5 m). The lower the score (yellow), the more likely the detection error is. (A) Images with green puncta. (B) Confidence score for every punctum. Lowest score is marked by arrow. The marked puncta is clearly under-segmented. After user input the actual puncta number which is 3 and run the EM GMM split, the result becomes correct as shown in the small cropped image easily with a colormap as shown in<ref type="figure" target="#fig_7">Figure 6B</ref>. The punctum with the lowest score in the image is marked by an arrow, and it is indeed an under-segmentation error (<ref type="figure" target="#fig_7">Figure 6B</ref>). The score and colormap can guide users to find the most problematic regions quickly. After errors are located, they can be corrected using computer-assisted manual editing. Two types of errors can occur. The first is over-segmentation that can be corrected by merging neighboring puncta with one mouse click. The second type is under-segmentation that can be corrected with a splitting procedure carried out by computer after the user specifies that blob to split and how many puncta should result. Here we use GMMs again to split any under-segmented blob. An example of correcting under-segmentation is shown in<ref type="figure" target="#fig_7">Figure 6B</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Feng et al.</head><p>(TP), false positives (FP) and false negatives (FN) were counted. FP include over-segmentation errors (i.e. excessive splitting). FN include under-segmentation errors (i.e. failed splitting) and missed puncta. We compared our method with two other blob detection methods used in (<ref type="bibr" target="#b0">Al-Kofahi et al., 2010</ref>) and (<ref type="bibr">Kim et al., 2012</ref>). The method in (<ref type="bibr" target="#b0">Al-Kofahi et al., 2010</ref>) starts with an automatic binarization by Graph Cuts; we therefore refer to this method here as 'Graph Cuts'. The parameters of 'Graph Cut' are chosen based the characteristics of our data. Minimum and Maximum scale of LoG are set to 1 and 3 because our puncta range in radius from 1 to 6. The method in (<ref type="bibr">Kim et al., 2012</ref>) uses template matching to find the best Gaussian fit for covering the initial position; we therefore refer to this method as 'Template Matching'. To illustrate benefits of our three stage processing algorithm, we also created two more methods by omitting the marker-controlled watershed stage or meanshift modified VBGMM stage. We refer to these two methods as 'VBGMM' and 'Watershed' respectively. Pmtk3 (http://code.google .com/p/pmtk3/) was used for our VBGMM implementation. Results from all methods were inspected manually and ambiguous puncta, which cannot even be identified by biologists, were not counted in FP and FN.<ref type="figure" target="#tab_1">Table 1</ref>summarizes the average performance measurements of all methods. Overall, our fully automated algorithm achieved an accuracy above 97%. The average F-measure (2 × precision × recall)/(precision + recall) for these data is 98.5%. Over-and undersegmentation errors can be described in terms of precision and recall. Our method has the highest recall value, which indicates that it performs better than other methods for separating clustered puncta. The precision is slightly lower than 'Watershed' because our marker selection procedure is designed to prevent over-segmentation.<ref type="figure" target="#fig_9">Figure  7</ref>shows the detection results of each method for two example regions. Incorrect detections are marked by red arrows. We can see that when dealing with a cluster composed of puncta with various sizes, other methods tend to under-segment. The multiscale LoG used in the 'Graph Cuts' method favors larger puncta, even after we disabled the segmentation refinement step of 'Graph Cuts' to avoid even greater under-segmentation (this step requires clear edges between objects to be separated, but punctum clusters in our data usually do not have this property). In the 'Template Matching' method, under-segmentation can be produced by its masking procedure, which may occlude small neighboring puncta. The results in<ref type="figure" target="#fig_9">Figure 7E</ref>and F show that we need both watershed and VBGMM stages to better utilize the characteristic features of puncta. In the watershed stage, puncta with clear centers are identified. Then the mean-shift modified VBGMM stage use shape information to separate weak puncta from a cluster. The post merge mechanism we designed for VBGMMs works better for a small number of puncta. As the number of puncta grows, Gaussian components become more complicated, and two or more distant Gaussian components could be merged just because they overlap with an ill conditioned Gaussian. The combination of 'Watershed' and 'VBGMM' in our method can overcome this problem and avoid missing weak puncta in 'Watershed' at the same time. During our experiments, we found that a few watershed-separated components only have signals on single slices. For these data, a twodimensional version VBGMMs might give better results. Indeed, testing 2D VBGMMs on these data showed a modest improvement of the results (30% of the cases were improved). Nevertheless, more test cases are required to make a strong conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We developed a fully automated puncta-like object detection algorithm based on distinctive morphological features of puncta, i.e. a punctum has a convex shape and its center is brighter than surrounding voxels. Marker-controlled watershed is used to detect puncta with clear centers and mean-shift modified VBGMMs is used to separate puncta by exploiting their convex shapes. Simple GMMs often emphasize the distribution of data. The mean-shift and merge procedure in post-processing can make sure that fitted Gaussians not only have appropriate shapes but also have stable centers. Our method achieved very high accuracy from the detection of puncta in real images. Parameters needed for our algorithm are intuitive and easy to choose. Only T m used for watershed marker selection needs to change for different application or data. It represents the expected center voxel number which is proportional to average puncta size. However, post-processing of the detected result is necessary since our method may pick up some image noise. This procedure is relatively easy because we can compute many kinds of features for each detected punctum. In our experience, maximum intensity and radius are good choices for filter conditions. We process our detection result by removing punctum with radii smaller than 1 and maximum intensity less than T +σ. T is global image threshold we calculated in the binarization stage. sigma is an empirical choice based on the visibility of corresponding puncta. Typically it is chosen from 10 to 20 for an 8-bit image. Although only rarely, we found some cases in which our algorithm did not work as expected. Based on our analysis of testing data, we found under-segmentation usually occurs when several small elongated puncta are clustered together, like the position marked in<ref type="figure" target="#fig_9">Figure 7B</ref>. Since such a feature is elongated and consists of few voxels, it tends to be fitted by a Gaussian with an axis larger than its actual radius. Then mean-shift uses this overestimated radius value to adjust the Gaussian position, which can end up in the middle of several small puncta. Over-segmentation occurs when large saturated puncta have unusual shapes. Our method might separate it into several convex shapes. In such cases, the actual number of puncta can be hard to determine, even by an expert biologist. Fortunately, these saturated big puncta are easy to spot and can be treated differently. Our method for calculating the confidence scores of puncta can readily help us locate these problematic regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mGRASP-assisted synapse detection</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Synapses visualized by mGRASP in a mouse hippocampal CA1 neuron. (A) Merged images show neuronal dendrites in red and mGRASPlabeled synapse puncta in green. (B and C) Zoomed images of two selected areas. Image size of each area is 128×128×99 voxels (corresponding to 13.3 m × 13.3 m × 49.5 m)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Flow chart outlining the main steps of the proposed puncta detection algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Given the mixing coefficient π for each Gaussian component, the conditional distribution of the latent class variable Z ={z</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>D = 3 is the dimensionality of the data variable x. β k and v k are two parameters of prior distributions and updated in the M step. E[lnπ k ] and E[ln| k |] can be calculated by using the Dirichlet and Wishart distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Key steps of the proposed puncta detection method. (A) One blob after automatic binarization shown as a maximum intensity projection. (B) 3D view of the blob. (C) The color-coded result of marker-controlled watershed separation, which produced three parts. (D) Each part is passed to the mean-shift regulated VBGMMs. Final detection result contains four puncta. (E) Detailed steps of mean-shift regulated VBGMMs for three watershed separated parts. Blue circles represent data points projected to x–y plane. Ellipsoids are 95% confidence interval Gaussian components in each step</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Illustrating typical mean-shift regulated vbgmm steps. (A) 3D image of one punctum. (B) twelve local maxima voxels are detected, therefore K = 12. (C) After VBGMM convergence, three components left. (D) Adjust each component using mean-shift. (E) Final merged result</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.6.</head><figDesc>Fig. 6. Detection confidence score of puncta for two sample image areas, where the scores are shown as colormap. Image size of each area is 128× 128×99 voxels (corresponding to 13.3 m × 13.3 m × 49.5 m). The lower the score (yellow), the more likely the detection error is. (A) Images with green puncta. (B) Confidence score for every punctum. Lowest score is marked by arrow. The marked puncta is clearly under-segmented. After user input the actual puncta number which is 3 and run the EM GMM split, the result becomes correct as shown in the small cropped image</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><figDesc>Copyedited by: ES MANUSCRIPT CATEGORY: [16:14 29/5/2012 Bioinformatics-bts221.tex] Page: i30 i25–i31</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig.7.</head><figDesc>Fig. 7. Detection results for two areas from different methods. Image size of each area is 128 × 128 × 99 voxels (corresponding to 13.3 m × 13.3 m × 49.5 m). Detected puncta are shown as yellow spheres. Red arrows show incorrect detection. (A) 3D mGRASP channel. (B) Detection results of our method. (C) Detection results of 'Graph Cuts'. (D) Detection results of 'Template Matching', which detects big and small puncta separately and does not have size information. (E) Results of 'Watershed'. (F) Results of 'VBGMM'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 1. Comparison of detection performance</figDesc><table>Method 
Accuracy 
Precision 
Recall 
F-measure 

Ours 
0.970 
0.988 
0.982 
0.985 
Graph cuts 
0.861 
0.983 
0.875 
0.926 
Template matching 
0.937 
0.961 
0.974 
0.967 
Watershed 
0.929 
0.994 
0.933 
0.963 
VBGMM 
0.928 
0.987 
0.934 
0.960 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="4"> EXPERIMENTAL RESULTS The mGRASP-labeled synapse data used for testing our method were acquired under a Zeiss 710 confocal microscope as described in our previous study (Kim et al., 2012). In all, 33 randomly selected regions, which correspond to three neurons, were annotated semiautomatically to build a ground truth set. These regions contain more than 1000 puncta of various sizes and shapes. Some regions contain highly clustered puncta, while others contain relatively few or no puncta. Automatically detected mGRASP puncta (Kim et al., 2012) in these regions were manually inspected in the 3D visualization program vaa3d (Peng et al., 2010). True positives i29 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">i31 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved automatic detection and segmentation of cell nuclei in histopathology images</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Al-Kofahi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed. Eng. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="841" to="852" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A variational bayesian framework for graphical models</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Attias</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Informat. Process. Sys</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="209" to="215" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">Pattern Recognition and Machine Learning (Information Science and Statistics)</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Single quantum dot tracking based on perceptual grouping using minimal paths in a spatiotemporal volume</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bonneau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Proc. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1384" to="1395" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust single-particle tracking in live-cell time-lapse sequences</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Jaqaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="695" to="702" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Detection of molecular particles in live cells via machine learning</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry Part A</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="563" to="575" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">2012) mgrasp enables mapping mammalian synaptic connectivity with light microscopy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="96" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A hybrid 3d watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry Part A</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="23" to="36" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic detection of single fluorophores in live cells</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Mashanov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Molloy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biophys. J</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="2199" to="2211" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Proof-editing is the bottleneck of 3d neuron reconstruction: the problem and solutions</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">V3d enables real-time 3d visualization and quantitative analysis of large-scale biological image data sets</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Peng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="348" to="353" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Image-derived, three-dimensional generative models of cellular organization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Peng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry A</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="383" to="91" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic tracking of individual fluorescence particles: application to the study of chromosome dynamics</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Sage</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Proc. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1372" to="1383" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">A new detection scheme for multiple object tracking in fluorescence microscopy by joint probabilistic data association filtering</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Smal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biomedical Imaging: From Nano to Macro</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="264" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Quantitative comparison of spot detection methods in fluorescence microscopy</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Smal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Imag. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="282" to="301" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust bayesian mixture modelling</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Svensén</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="235" to="252" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic fluorescent tag detection in 3d with superresolution: application to the analysis of chromosome movement</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Thomann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Microscopy</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="page" from="49" to="64" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Morphological grayscale reconstruction in image analysis: Applications and efficient algorithms</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Vincent</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Process. IEEE Trans</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="176" to="201" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Anisotropic path searching for automatic neuron reconstruction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Xie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="680" to="689" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Nuclei segmentation using marker-controlled watershed, tracking using mean-shift, and kalman filter in time-lapse microscopy</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. I: Reg. Papers</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="2405" to="2414" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiscale variance-stabilizing transform for mixed-poissongaussian processes and its applications in bioimaging</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing IEEE International Conference on</title>
		<meeting><address><addrLine>San Antonio, TA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="233" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Automated learning of generative models for subcellular location: building blocks for systems biology</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytometry Part A</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="978" to="990" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Automated reconstruction of neuronal morphology based on local geometrical and global structural models</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>