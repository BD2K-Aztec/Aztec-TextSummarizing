
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Intervention in gene regulatory networks with maximal phenotype alteration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Mohammadmahdi</forename>
								<forename type="middle">R</forename>
								<surname>Yousefi</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Edward</forename>
								<forename type="middle">R</forename>
								<surname>Dougherty</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<postCode>77843</postCode>
									<settlement>College Station</settlement>
									<region>TX</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Computational Biology Division</orgName>
								<orgName type="department" key="dep2">Associate Editor: Igor Jurisica</orgName>
								<orgName type="institution">Translational Genomics Research Institute</orgName>
								<address>
									<postCode>85004</postCode>
									<settlement>Phoenix</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Systems biology Intervention in gene regulatory networks with maximal phenotype alteration</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">14</biblScope>
							<biblScope unit="page" from="1758" to="1767"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt242</idno>
					<note type="submission">Received on February 20, 2013; revised on April 11, 2013; accepted on April 24, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER are available at http://gsp.tamu.edu/Publications/supplementary/ yousefi13b. Contact: edward@ece.tamu.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: A basic issue for translational genomics is to model gene interaction via gene regulatory networks (GRNs) and thereby provide an informatics environment to study the effects of intervention (say, via drugs) and to derive effective intervention strategies. Taking the view that the phenotype is characterized by the long-run behavior (steady-state distribution) of the network, we desire interventions to optimally move the probability mass from undesirable to desirable states Heretofore, two external control approaches have been taken to shift the steady-state mass of a GRN: (i) use a user-defined cost function for which desirable shift of the steady-state mass is a by-product and (ii) use heuristics to design a greedy algorithm. Neither approach provides an optimal control policy relative to long-run behavior. Results: We use a linear programming approach to optimally shift the steady-state mass from undesirable to desirable states, i.e. optimization is directly based on the amount of shift and therefore must out-perform previously proposed methods. Moreover, the same basic linear programming structure is used for both unconstrained and constrained optimization, where in the latter case, constraints on the optimization limit the amount of mass that may be shifted to &apos;ambiguous&apos; states, these being states that are not directly undesirable relative to the pathology of interest but which bear some perceived risk. We apply the method to probabilistic Boolean networks, but the theory applies to any Markovian GRN. Availability: Supplementary materials, including the simulation results, MATLAB source code and description of suboptimal methods</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Genetic regulatory networks (GRNs) refer to a class of models describing the multivariate functional relationships among a cohort of genes or their products. From a graphical perspective, genes are nodes in this network, and edges describe regulatory relationships between genes. These networks aim to model cellular control and how abnormal cell functions result from one or several breakdowns in the regulatory mechanisms. Thus, GRNs are an essential part of translational medicine, whose ultimate goal is to develop therapies based on the disruption or mitigation of aberrant gene function contributing to the pathology of a disease (<ref type="bibr" target="#b10">Dougherty et al., 2010</ref>). Therapies usually involve some procedure and several drug candidates acting on various gene products with the aim of mitigating undesirable gene functions. Developing therapeutic methods in the context of GRNs involves designing intervention strategies to alter the dynamics of the gene activity profiles (GAPs) of the network in some desired manner, thereby identifying potential drug targets (<ref type="bibr" target="#b6">Datta and Dougherty, 2006;</ref><ref type="bibr" target="#b9">Dougherty and Datta, 2005;</ref><ref type="bibr" target="#b10">Dougherty et al., 2010</ref>). Modeling GRNs via Markovian dynamical networks has received much attention because they capture uncertainty intrinsic to the interactions among genes or gene products at different levels. Furthermore, one can use the rich theory of Markov decision processes (MDPs) to formulate optimal intervention problems. In the present article, we choose probabilistic Boolean networks (PBNs) (<ref type="bibr" target="#b33">Shmulevich et al., 2002a</ref>) as our reference model for GRNs. The transition probabilities of PBNs are characterized by their associated Markov chains, and PBNs have played the major role in intervention studies. Assuming that the collection of all possible GAPs constitutes the state space, we can partition it into desirable and undesirable cellular states according to the expression values of a given set of genes. An undesirable state can be associated with a phenotype representative of a cancerous state; e.g. cell growth in the absence of growth factors is undesirable. Although there might exist some states in the desirable set that do not represent healthy conditions, they can be classified as 'desirable' because they are not associated with the particular pathology defining the undesirable set (<ref type="bibr" target="#b28">Qian and Dougherty, 2012</ref>). Once a model for the underlying GRN is assumed and desirable and undesirable sets are recognized, the objective is to find an optimal therapeutic strategy (control policy) with respect to a predefined objective function to drive the dynamics of the network from undesirable states to the desirable ones. This problem has been extensively studied within two basic intervention approaches in the context of PBNs, external control and structural intervention. External control is generally based on flipping (or not flipping) the value of a specific gene (or possibly more than one), called the control gene. As the dynamic behavior of a PBN can be represented by a finite-state Markov chain, the first proposed intervention approach was to determine an optimal single-gene perturbation to the network based on mean first-passage times in Markov chains (<ref type="bibr" target="#b34">Shmulevich et al., 2002b</ref>). Attention, later, *To whom correspondence should be addressed. turned to dynamic programming-based finite-horizon (<ref type="bibr" target="#b5">Datta et al., 2003</ref>) and infinite-horizon external control in which the steady-state distribution (SSD) is altered (<ref type="bibr" target="#b24">Pal et al., 2006</ref>). These works were followed by several articles developing approaches to external intervention that take into account practical issues that arise from therapeutic constraints (<ref type="bibr" target="#b3">Ching et al., 2009;</ref><ref type="bibr" target="#b39">Yousefi et al., 2012</ref>), biological complexity (<ref type="bibr" target="#b25">Pal et al., 2008</ref>) and computational limitations (<ref type="bibr" target="#b11">Faryabi et al., 2007;</ref><ref type="bibr" target="#b18">Ivanov et al., 2010</ref>). Structural intervention, on the other hand, involves a one-time change in the network regulatory structure (wiring) so that the long-run behavior of the network is altered in a desired manner. Given a collection of potential structural changes, the problem is to find an optimal structural intervention resulting in a maximum alteration of the SSD toward the direction of desirable states and away from undesirable states (<ref type="bibr" target="#b27">Qian and Dougherty, 2008;</ref><ref type="bibr" target="#b35">Shmulevich et al., 2002c;</ref><ref type="bibr" target="#b38">Xiao and Dougherty, 2007</ref>). In the main, optimal infinite-horizon intervention for GRNs has involved the specification of a cost function based on the current state of the system and the desirability of potential transitions. Thus, the long-run effect of the optimal policy on the network dynamics becomes a by-product of this cost functionbased optimization problem. As phenotype is associated with steady-state behavior, as in the case of attractor cycles in BNs and PBNs (<ref type="bibr" target="#b20">Kauffman, 1993</ref>), from a practical perspective, it would be better to determine optimality directly in terms of long-run behavior. Direct optimization has been addressed to some extent in<ref type="bibr" target="#b29">Qian et al. (2009)</ref>, where the authors propose three classes of greedy stationary intervention policies that bypass the need for a user-defined cost function and directly use long-run behavior as the optimization criterion to reduce the mass of the SSD corresponding to undesirable states and increase the mass corresponding to desirable states (<ref type="bibr" target="#b29">Qian et al., 2009</ref>). In this article, we rigorously formulate this intervention problem and provide an optimal intervention policy with a computational complexity equivalent to solving a linear program (LP) optimization problem in Section 2.4 for a general cost function and in Section 2.5 for maximal phenotype alteration. We also consider a variant of this optimization problem where one might constrain the steady-state probability mass of some 'ambiguous' states in the network while finding the optimal intervention policy. This is especially important in therapeutic methods because it is prudent to avoid introducing new probability mass to states associated with unknown phenotypes (<ref type="bibr" target="#b28">Qian and Dougherty, 2012</ref>). We demonstrate the performance of optimal policies using synthetically generated networks and two real networks derived from the metastatic melanoma and mammalian cell cycle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SYSTEMS AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">PBNs</head><p>PBNs address uncertainty in the structure of BNs or the dynamics of state transitions (<ref type="bibr" target="#b33">Shmulevich et al., 2002a</ref>). We restrict ourselves to binary PBNs, it being assumed that the value of each gene is quantized to two levels 0 or 1, where 0 corresponds to an unexpressed (OFF) gene and 1 corresponds to an expressed (ON) gene. The mathematical theory extends directly to PBNs with discrete-valued nodes. DEFINITION 1. A Boolean network BNðV, FÞ is fully characterized by a set of n nodes, V ¼ fv 1 , v 2 ,. .. , v n g, (representing genes fg 1 , g 2 ,. .. , g n g or their products) and a list of Boolean functions F ¼ ff 1 , f 2 ,. .. , f n g describing the functional relationships between the nodes. The Boolean function f i : f0, 1g ji °f0, 1g determines the value of node i at time k þ 1, given the value of its predictors at time k by v i kþ1 ¼ f i ðv i1 k , v i2 k ,. .. , v iji k Þ, where fv i1 , v i2 ,. .. , v iji g corresponds to values of fg i1 , g i2 ,. .. , g iji g as j i predictors of gene g i. In a BN, all genes are assumed to update synchronously in accordance with the Boolean functions assigned to them. A BNðV, FÞ evolves according to a genome-wide GAP, v k ¼ ðv 1 k , v 2 k ,. .. , v n k Þ at time k, forming the state space of size 2 n. There is a bijection between v and its decimal representation x 2 " S ¼ f0, 1,. .. , 2 n À 1g by x ¼ P n i¼1 2 nÀi v i. In this context, genes that are reflective of an undesirable state are called target genes. S is partitioned into subsets of desirable and undesirable states, denoted by D and U, respectively. Given an initial state, a BN will eventually enter a set of states, called an attractor cycle. The set of states leading to that attractor cycle is known as the basin of attraction (BOA) (<ref type="bibr" target="#b10">Dougherty et al., 2010</ref>). DEFINITION 2. A PBNðV, F, P, q, pÞ is characterized by a set of n nodes, V ¼ fv 1 , v 2 ,. .. , v n g, and a set of m constituent BNs, F ¼ fF 1 , F 2 ,. .. , F m g, called contexts, a selection probability vector P ¼ fp 1 , p 2 ,. .. , p m g over F, a network switching probability q and a random gene perturbation probability p. Random switching and gene perturbation are also assumed to be mutually exclusive. At any time point, with probability q, the network dynamics may switch from the current governing constituent BN to another according to the selection probability vector P. It is assumed that the probability of switching to a new constituent network is independent of the current network. We also allow that the current network may switch to itself when a switch is called for (<ref type="bibr" target="#b10">Dougherty et al., 2010</ref>). In addition, with probability p, the current state of each gene in the network can be randomly flipped. The PBN is said to be context-sensitive if q51, the interpretation being that there are latent variables outside the network whose changes cause the model network to behave stochastically (<ref type="bibr" target="#b2">Brun et al., 2005</ref>). If q ¼ 1, the PBN is called instantaneously random, the interpretation being that the uncertainty in the PBN arises from uncertainty in model inference (<ref type="bibr" target="#b33">Shmulevich et al., 2002a</ref>). Averaging over the various contexts reduces the transition probability matrix (TPM) of a contextsensitive PBN to the instantaneously random PBN with identical parameters (<ref type="bibr" target="#b12">Faryabi et al., 2009</ref>). By definition, a PBN inherits the attractor structures from its context BNs without perturbation. With sufficiently small perturbation probability p, the long-run behavior of a PBN will reflect the attractor structures within the context BNs (<ref type="bibr" target="#b2">Brun et al., 2005</ref>). A Boolean network with perturbation, BNp, is a PBN in which m ¼ 1. Transition rules of any PBN can be modeled by a homogeneous Markov chain, whose states of the TPM are the GAPs of the underlying regulatory network (<ref type="bibr" target="#b33">Shmulevich et al., 2002a</ref>). Let S ¼ fðx, yÞ : x 2 " S, y 2 f1, 2,. .. , mgg denote the state space of the PBN. The sets D and U corresponding to the set of desirable, and undesirable states can be defined as D ¼ fðx, yÞ : x 2 D, y 2 f1, 2,. .. , mgg and U ¼ fðx, yÞ : x 2 " U, y 2 f1, 2,. .. , mgg. We denote by fZ k 2 S, k ¼ 0, 1,. . .g the stochastic process of the state of the PBN that has both the information about the current constituent BN and GAP of the underlying network. Originating from state i 2 S, the successor state j 2 S is selected randomly according to the transition probability P, with its ijth element defined by p ij ¼ Á PðZ kþ1 ¼ jjZ k ¼ iÞ for all k ¼ 0, 1,. . .. The transition probabilities of this Markov chain can be calculated as explained in<ref type="bibr" target="#b10">Dougherty et al. (2010)</ref>. Owing to the random gene perturbation, the equivalent Markov chain is ergodic and has a unique invariant measure, , equal to its limiting distribution. We assume that the PBN admits an external control input A from a set of actions, A, specifying the type of intervention on a set of control genes. For instance, A ¼ 0 may indicate no-intervention, and A ¼ 1 may indicate that the expression level of a single gene, g c , c 2 f1, 2,. .. , ng, is flipped. In this intervention scenario, the control action A ¼ 1 at state ðx, yÞ replaces the row corresponding to the state ðx, yÞ in the original TPM of the underlying Markov chain by the row corresponding to the state ð ~ x, yÞ, where the binary representation of ~ x is the same as x except in bit v c , where it is flipped. Let fA k 2 A, k ¼ 0, 1,. . .g denote the stochastic process of actions taken. The law of motion for the controlled network is represented by a matrix PðaÞ with its ijth element defined as p ij ðaÞ ¼ PðZ kþ1 ¼ jjZ k ¼ i, A k ¼ aÞ, ð1Þ this being the probability of going to j at time k þ 1 starting from state i and taking action a at time k. As the original Markov chain is ergodic, the controlled chain will also be ergodic having a unique invariant measure. The action process is stochastic in two ways: (i) the state process is stochastic, and the action process is a mapping from the entire history of states and actions to the action space so that the action process is also stochastic and (ii) we allow the actions to be random depending on the history and current state of the system. Indeed, the pair ðZ k , A k Þ is a stochastic process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Constrained MDPs</head><p>Discrete time MDPs constitute a class of sequential decision making problems where the system of interest evolves stochastically at discrete time units. One can observe system states at times k ¼ 0, 1,. .. , N, where N, called the 'horizon' may be finite or infinite. At each k, a decision maker can alter the costs or dynamics of the system by choosing some parameters, called 'actions'. The dynamical movement of the system from one state to another is completely characterized, given the current state and action taken at this state via a probability vector over all possible next states. The goal is to optimize an objective function (e.g. the infinitehorizon expected average cost) and find an optimal control policy inducing the optimal cost. More than one objective cost may exist, and the decision maker minimizes one of the objectives subject to constraints on the others. This class of MDPs are referred to as constrained MDPs (<ref type="bibr" target="#b0">Altman, 1999</ref>) and mathematically defined as follows.</p><p>DEFINITION 3. A tuple fS, A, PðaÞ, g, rg defines a constrained MDP, where S denotes the state space of a finite-state Markov chain, A is a finite set of actions, AðiÞ A denoting the set of actions available at state i (we also denote by K ¼ fði, aÞ : i 2 S, a 2 AðiÞg the set of state-action pairs), PðaÞ defined in Equation (1) is the TPM of the controlled Markov chain, g : K ! R is an immediate cost, and r : K ! R D is a D-dimensional vector of immediate costs defining the D constraints.</p><p>Denote by fz k , k ¼ 0, 1,. . .g and fa k , k ¼ 0, 1,. . .g the sequences of observed states and actions. A policy is a prescription for taking actions at each k. Actions may be taken in accordance with a random mechanism, possibly a function of the entire history of the system up to time k. To make this precise, let H k be the random vector of previous states and actions occurring up to time k and h k be the observed history, i.e.</p><formula>h k ¼ ðz 0 , a 0 , z 1 , a 1 ,. .. , z k , a k Þ. A policy ¼ ð 0 , 1</formula><p>,. .. , N Þ is a sequence prescribed by the decision maker that steers the dynamics of the underlying system. If the history h kÀ1 is observed up to time k, then the decision maker chooses an action a 2 Aðz k Þ with probability</p><formula>k ðajh kÀ1 , z k Þ, where 0 k ðajh kÀ1 , z k Þ 1, X a2AðzkÞ k ðajh kÀ1 , z k Þ ¼ 1:</formula><p>The class of all control policies is denoted by M. The initial state i of the Markov chain and any given policy determine a unique probability measure P i over the space of all trajectories of states and actions, which correspondingly defines the stochastic processes Z k and A k of the states and actions for the controlled system. E i denotes the corresponding expectation relative to which cost criteria are defined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DEFINITION 4. The infinite-horizon expected average costs are</head><p>Gði, Þ ¼ lim sup</p><formula>N!1 1 N þ 1 X N k¼0 E i gðZ k , A k Þ, R d ði, Þ ¼ lim sup N!1 1 N þ 1 X N k¼0 E i r d ðZ k , A k Þ, for d ¼ 1, 2,. .. , D:</formula><p>Given real numbers V 1 , V 2 ,:::, V D , we can formulate the optimization problem in its most general form: for an initial state i, OP 1 : min 2M Gði, Þ, subject to R d ði, Þ V d for all d¼ 1, 2, .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.. , D:</head><p>The set of all policies that satisfy the constraints is called the feasible region. Let G Ã ðiÞ denote the optimal value achieved by the optimization procedure. A feasible policy Ã is optimal if G Ã ðiÞ ¼ Gði, Ã Þ, for i 2 S. The search space M is infinite (possibly uncountable); however, one may identify classes within M that possess beneficial properties. We consider three classes: Markov policies, stationary policies and stationary determinist policies, denoted by M M , M S and M D , respectively. M M includes policies for which k is only a function of z k for any k. M S is a subset of M M and includes policies for which k is time invariant (not dependent on k). This means that the probabilities that the control policy assigns to different actions only depend on the state and not the time. For example, for a PBN with transition probabilities defined in Equation (1) and any policy 2 M S , the underlying stochastic process becomes a stationary Markov chain with the set, QðÞ, of transition probabilities defined by</p><formula>q ij ðÞ ¼ X a2AðiÞ p ij ðaÞðajiÞ, ð2Þ</formula><p>for all i, j 2 S. The third class, M D , is the set of all stationary deterministic policies such that ðajiÞ is either 0 or 1 for every i 2 S. In this case, : S ! A is a single-valued transformation from the states to the actions. Usually in the context of MDP problems, minimizing an objective function (the infinite-horizon expected total discounted cost or the expected average cost) with no constraints, i.e. D ¼ 0, is carried out by formulating a set of dynamic programming functional equations, known as the Bellman optimality equations. Using these equations, it can be shown that the optimal control policies belong to the class M D of policies. Hence, instead of searching the entire space of all historydependent randomized control policies for the optimal solution, one can focus only on a set of coupled minimization problems over a (much smaller) set of actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Suboptimal phenotype alteration</head><p>Our goal is to find an intervention policy to maximally shift the long-run probability mass of undesirable states to desirable ones. Several algorithms have been proposed for intervention in Markovian GRNs that avoid using a user-defined cost function and work directly with the transition probabilities of the Markov chain associated with the network to approximate this goal. These algorithms are motivated by heuristics and obtain suboptimal policies. Owing to space limitations, here we only list the algorithms, with detailed descriptions being given in the Supplementary Material: (i) mean-first-passage-time (MFPT) control policy (<ref type="bibr" target="#b36">Vahedi et al., 2008</ref>), (ii) BOA control policy (<ref type="bibr" target="#b29">Qian et al., 2009</ref>), (iii) SSD control policy (<ref type="bibr" target="#b29">Qian et al., 2009</ref>) (iv) and conservative SSD (CSSD) control policy (<ref type="bibr" target="#b29">Qian et al., 2009</ref>). Under the MFPT, BOA, SSD and CSSD control policies, as well as for user-defined cost functions, there might be an introduction of significant mass at states representing complications and harmful side effects to healthy cells, even though these are classified in the set of desirable states because they are not undesirable relative to the particular pathology of interest. In Section 2.8.2, we will discuss a 10-gene network involving the gene WNT5A and explain why an intervention that downregulates WNT5A may have the beneficial effect of suppressing metastatic phenotypes. For this reason, networks involving WNT5A have been used in a number of control studies (<ref type="bibr" target="#b5">Datta et al., 2003;</ref><ref type="bibr" target="#b12">Faryabi et al., 2009;</ref><ref type="bibr" target="#b24">Pal et al., 2006</ref>). In particular, in<ref type="bibr" target="#b27">Qian and Dougherty (2008)</ref>, structural intervention consisting of a one-time change to the governing regulatory logic was applied to a seven-gene network containing WNT5A with the aim downregulating it in the long-run. Among the genes in the network, the minimum steadystate probability mass for upregulated WNT5A was obtained by perturbing the function determining the status of WNT5A. Unfortunately, this intervention had the effect of placing a large mass (40:4) at a state that had virtually no mass in the original SSD and in which STC2 is upregulated. Several studies have shown that STC2 plays a role in carcinogenesis. For instance, STC2 is upregulated in breast and ovarian cancer cells, following exposure to hypoxia (<ref type="bibr" target="#b21">Law and Wong, 2010a</ref>), and high levels of STC2 expression are associated with increased invasiveness and metastasis in ovarian cancer cells (<ref type="bibr" target="#b22">Law and Wong, 2010b</ref>). Hence, the unconstrained optimal structural intervention should be avoided. A better alternative would be to perturb the machinery governing RET1, where the results in<ref type="bibr" target="#b27">Qian and Dougherty (2008)</ref>show that an appropriate perturbation of its regulatory logic reduces the steady-state mass of the upregulated WNT5A states almost as much as direct WNT5A intervention, and without the side effect of significantly upregulating STC2. From a general perspective, it may be prudent to restrict the newly introduced mass to states associated with known healthy phenotypes. To achieve this end, the set D of desirable states can be further partitioned into two categories, D h representing known healthy states (those known to be associated with a healthy phenotype) and D a representing ambiguous states that may (or certainly will) lead to phenotypes that, although not undesirable relative to the pathology of immediate interest, are themselves known to be undesirable or of which nothing is known. The goal is to find a control policy that shifts the long-run probability mass of undesirable states as much as possible and at the same time keeps the longrun probability mass of each ambiguous state below some level. Being that phenotypes are associated with attractors, a conservative approach is to define the ambiguous states as those states in D that belong to the nonattractor states of the original network so that the control will not introduce new attractors (phenotypes). This approach is not only conservative but also does not require prior knowledge of which states in D are, or are not, associated with pathological phenotypes. In the WNT5A example just cited, the intervention leading to the high-mass state in which STC2 was upregulated would not have been allowed under this criterion. The constrained SSD (conSSD) and constrained CSSD (conCSSD) control policies aim to find such (suboptimal) interventions (<ref type="bibr" target="#b28">Qian and Dougherty, 2012</ref>). None of the six long-run-based heuristic algorithms use a rigorous optimization to find optimal intervention policies with respect to the objectives and constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Occupation measures and the primal LP</head><p>To proceed optimally in the case of constrained problems, we note that it has been shown that the objective functions for different cost criteria are a linear function of 'occupation measures' for stationary control policies. A salient consequence is that the original problem of finding the optimal cost and control policy can be transformed into an LP, referred to as the primal LP, where the optimization variables are the occupation measures (<ref type="bibr" target="#b7">Derman, 1970;</ref><ref type="bibr" target="#b19">Kallenberg, 1983</ref>). The optimal solutions to this primal LP determine, as a one-to-one relationship, the optimal stationary control policies (<ref type="bibr" target="#b0">Altman, 1999</ref>). Let us first state an assumption that we will make throughout the rest of this article. ASSUMPTION 1. The MDP is assumed to be unichain, meaning that for any 2 M D , the corresponding Markov chain described by the transition probabilities QðÞ, defined in Equation (2), has at most one ergodic class and a (perhaps empty) set of transient states. This assumption holds for the case of controlled PBNs, as the Markov chain corresponding to a given PBN is ergodic due to random gene perturbation. We now define the occupation measures. DEFINITION 5. For any given initial state i and policy , and any stateaction pair j and a 2 AðjÞ, the occupation measure is</p><formula>N ja ði, Þ ¼ 1 N þ 1 X N k¼0 P i ðZ k ¼ j, A k ¼ aÞ:</formula><p>In other words, under any policy and given Z 0 ¼ i, N ja ði, Þ is the expected frequency, up to time N, of entrances into state j when action a is taken. Let N ði, Þ denote the matrix of N ja ði, Þ over all j and a. Let Vði, Þ be the nonempty set of all limit points of the sequence f N ði, Þ, N ¼ 0, 1,. . .g. Then, for any i 2 S, 2 M and 2 Vði,</p><formula>Þ, X j2S X a2AðjÞ ja gðj, aÞ Gði, Þ,</formula><p>with equality holding for some 2 Vði, Þ—in particular, it holds when 2 M S (<ref type="bibr" target="#b0">Altman, 1999</ref>). Moreover, the union of all Vði, Þ over all 2 M, where the Vði, Þ are singletons, is equal to the union of all Vði, Þ over all 2 M S (<ref type="bibr" target="#b7">Derman, 1970</ref>). If 2 M S , then the Vði, Þ are all singletons and independent of the initial state i.Therefore, one only needs to search the space of M S for the optimal solution by solving the following LP problem (<ref type="bibr" target="#b0">Altman, 1999</ref>):</p><formula>min X j2S X a2AðjÞ ja gðj, aÞ, LP 2 : subject to P j2S P a2AðjÞ ja r d ðj, aÞ V d , d¼ 1, 2,. .. , D, P a2AðjÞ ja ¼ P i2S P a2AðiÞ ia p ij ðaÞ, j 2 S, P j2S P a2AðjÞ ja ¼ 1, ja ! 0</formula><p>, for all j 2 S, a 2 AðjÞ:</p><formula>8 &gt; &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; &gt; :</formula><p>Let Ã be a minimizing argument of the LP 2 problem. Under Assumption 1, one can recover an optimal randomized stationary policy Ã by</p><formula>Ã ðajjÞ ¼ Ã ja P a2AðjÞ Ã ja , ð6Þ</formula><p>whenever P a2AðjÞ Ã ja 40, and if P a2AðjÞ Ã ja ¼ 0, then Ã ðajjÞ ¼ 1 for some a 2 AðjÞ. As the Markov chain for a controlled PBN is ergodic, there are no transient states. Hence, P a2AðjÞ Ã ja 6 ¼ 0. THEOREM 1. (<ref type="bibr" target="#b0">Altman, 1999</ref>) The optimization problems OP 1 and LP 2 are equivalent, and there is a one-to-one correspondence between their feasible (and optimal) solutions. THEOREM 2. (<ref type="bibr" target="#b31">Ross, 1989</ref>) If LP 2 is feasible and Ã is an optimal policy constructed by the aforementioned procedure, then there exists a list of at most jSj þ D actions for Ã so that Ã requires randomization in at most D states. If there are no constraints on the expected average cost criteria, i.e. D ¼ 0, then there is no randomization and Ã 2 M D. The main result of this section can be summarized as follows: Under Assumption 1, for every policy in M, there exists a stationary policy in M S that achieves the same limit point for the occupation measures; hence, we only need to consider the set M S for any optimization problem involving occupation measures of state and action in its objective and constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Maximal phenotype alteration</head><p>We desire an intervention policy that maximally shifts the long-run probability mass of undesirable states to desirable states. This objective function essentially concerns the long-run behavior of the occupation measures marginalized over the actions. Thus, based on the discussion at the end of Section 2.4, we can limit the policy space to M S without loss of generality. Let A ¼ AðjÞ ¼ f0, 1g for all j 2 S. If policy 2 M S , then the amount of shift in the aggregated probability of undesirable states for a PBN controlled under is defined as</p><formula>Á U ðÞ ¼ X j2U j À X j2U j ðÞ, ð7Þ</formula><p>where and ðÞ are the unique vectors of the invariant probability measure for the Markov chains governed under the TPMs P and QðÞ, respectively, which also satisfy Equations (3) to (5). In general, À1 Á U ðÞ 1 and our goal is to maximize it. LEMMA 1. Á U is maximized by solving the LP 2 problem with the immediate cost function g being 1 for undesirable states and 0 otherwise. PROOF. It can be easily seen from Equation (7) that maximizing Á U ðÞ is equivalent to minimizing P j2U j ðÞ, as is fixed. Also, if we let the immediate cost function gðZ k , A k Þ take the form:</p><formula>gðj, aÞ ¼ 1, if j 2 U, 0, otherwise, we have X j2S X a2A ja ði, Þgðj, aÞ ¼ X j2U X a2A ja ði, Þ ¼ X j2U j ðÞ,</formula><p>for all i and any 2 M S , where we used Equation (3) for the second equality. Therefore, it can be verified that we need to again solve LP 2 , with the suggested choice of g, to find the optimal , which at the same time maximizes the shift Á U .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Unconstrained optimal intervention If there are no constraints</head><p>on the cost criteria (D ¼ 0) for the shift maximization problem, then we can rewrite LP 2 as</p><formula>LP 3 : min P j2U P a2A ja , subject to P a2A ja ¼ P i2S P a2A ia p ij ðaÞ, j 2 S, P j2S P a2A ja ¼ 1, ja ! 0, for all j 2 S, a 2 A: 8 &gt; &gt; &lt; &gt; &gt; :</formula><p>The unconstrained (UC) optimal intervention policy Ã uc can be constructed using Equation (6) when Ã yields the minimum in LP 3. As there are no constraints, Ã uc 2 M D so that Ã uc is stationary and deterministic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Phenotypically constrained optimal intervention The LP 3</head><p>problem aims to locate an optimal control policy inducing maximal shift from the undesirable mass to eradicate phenotypes associated with the pathology of interest. However, when there are ambiguous states in the network, the optimization problem can be stated as locating a control policy that maximizes the shift of undesirable mass while satisfying an upper bound constraint for newly introduced steady-state mass into ambiguous states in D a. Similar to the choice of g in the proof of Lemma 1, one can define r d for d ¼ 1, 2,. .. , jD a j, each corresponding to a state j d 2 D a. The phenotypically constrained (PC) optimization problem can be formulated as</p><formula>LP 4 : min P j2U P a2A ja , subject to P a2A j d a V d , d¼ 1, 2,. .. , jD a j, j d 2 D a , P a2A ja ¼ P i2S P a2A ia p ij ðaÞ, j 2 S, P j2S P a2A ja ¼ 1, ja ! 0, for all j 2 S, a 2 A: 8 &gt; &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; &gt; :</formula><p>One can assume that V d ¼ for all d. The PC optimal intervention policy Ã pc can be constructed using Equation (6) when Ã yields the minimum in LP 4. As there are jD a j additional constraints on the optimization problem, Ã pc 2 M S and it requires randomization in at most jD a j states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Computational complexity</head><p>In any optimization problem, computational complexity is a concern. In particular, how well does the algorithm scale to larger networks? In our case, there are jSj Â jAj decision variables and jSj equality constraints in both LP 3 and LP 4 problems. LP 4 has jD a j additional inequality constraints. We use IBM ILOG CPLEX Optimizer using a dual simplex method to solve both LP 3 and LP 4 problems. Although, the worst-case computational complexity of the simplex method has been shown to be exponential in the number of decision variables and constraints, probabilistic analyses of the simplex method have indicated that the average complexity of this method is polynomial. Moreover, it has been proven that solving an LP, in general, requires a number of operations polynomial in the number of decision variables and constraints. Specifically, Karmarkar's algorithm, which belongs to the general class of interior point methods, solves LPs in polynomial time with reasonable efficiency (<ref type="bibr" target="#b23">Megiddo, 1987</ref>). The computational complexities of all the suboptimal policies mentioned in the article are also reported to be either linear or polynomial. Besides the guaranteed optimality of our method over the greedy algorithms, the linear programming approach is particularly useful when optimization problems involving nonlinear functions or side constraints are considered (<ref type="bibr" target="#b7">Derman, 1970</ref>). In such cases, using a dynamic programming approach makes the analysis much more complicated and computationally prohibitive. Based on our estimates and the reported size of the linear programming problems that have been solved using IBM ILOG CPLEX Optimizer, it is possible with the current technology to find the optimal UC and PC policies for networks with 20 genes. Hence, it avoids the kinds of model reduction methodologies that have been developed in the context of GRN control (<ref type="bibr" target="#b16">Ghaffari et al., 2010;</ref><ref type="bibr" target="#b17">Ivanov et al., 2007</ref><ref type="bibr" target="#b18">Ivanov et al., , 2010</ref><ref type="bibr" target="#b30">Qian et al., 2010</ref>), thereby avoiding the loss of optimality engendered by reductions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Robustness</head><p>As with any optimization procedure, the algorithm is optimal so long as the assumed model is correct. In the case of GRNs, model fidelity is affected by several factors: data extraction, discretization, gene selection and network generation. Hence, robustness becomes an issue. Robustness refers to an algorithm's performance on models that are close to, but not equal to, the model on which it has been derived. The robustness of stationary control for PBNs has been considered in<ref type="bibr" target="#b25">Pal et al. (2008)</ref>, and a robust intervention strategy has been obtained by minimizing the worst-case cost over an uncertainty class of networks. Such a minimax control approach is typically conservative because it gives equal importance to extreme cases. Thus, a Bayesian approach was formulated in<ref type="bibr" target="#b26">Pal et al. (2009)</ref>. A Bayesian approach requires a prior distribution on the uncertainty class of networks and therefore is dependent on significant prior knowledge, which may not be available. Here, we describe the perturbation bounds discussed in<ref type="bibr" target="#b25">Pal et al. (2008)</ref>, where uncertainty is studied in the context of the transition probabilities. The intervention strategy is derived on the estimated TPM, P, and is applied to the actual network TPM, e P. The basic question is that, for a given control policy, how does the mismatch between P and e P affect the SSD of the controlled network? Although the discussion in<ref type="bibr" target="#b25">Pal et al. (2008)</ref>applies to stationary deterministic control and the equivalent and our general setting is of wider scope, both the UC and PC algorithms have stationary control so that the analysis of<ref type="bibr" target="#b25">Pal et al. (2008)</ref>is applicable. Given that the class of allowed interventions consists of flipping the value of a gene, application of a stationary policy derived from the uncontrolled estimated TPM P converts P to a controlled TPM QðÞ, where QðÞ ¼ TðÞP and TðÞ represents a stochastic matrix, which has at most jAj nonzero entries adding up to 1 in each row (these nonzero entries are found from the control policy ). Let and ðÞ denote the SSDs corresponding to P and QðÞ, respectively. With e P being the actual uncontrolled TPM, e QðÞ ¼ TðÞ e P is the controlled TPM resulting from applying TðÞ to e P. Let ~ and ~ ðÞ denote the SSDs of e P and e QðÞ, respectively. Robustness concerns the difference ~ ðÞ À ðÞ based on the estimation error</p><formula>E ¼ Á P À e P.</formula><p>Assuming that the actual and estimated networks possess the same state space, which allows for different topologies and different regulatory functions, the SSD difference can be bounded by À ~ j j q KjjEjj 1 where q ¼ 1 or 1 and K40 are some constants. K is called a condition number. Some condition numbers will yield tighter bounds than the others (<ref type="bibr" target="#b4">Cho and Meyer, 2001</ref>).<ref type="bibr" target="#b25">Pal et al. (2008)</ref>considered the ergodicity coefficient constituent BNs and gene perturbation probability defined, we directly calculate the TPM of an instantaneously random PBN without actually constructing it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.2">Metastatic melanoma network A metastatic melanoma net</head><p>work is derived from gene expression data collected in a study of metastatic melanoma (<ref type="bibr" target="#b1">Bittner et al., 2000;</ref><ref type="bibr" target="#b8">Dissanayake et al., 2008;</ref><ref type="bibr" target="#b37">Weeraratna et al., 2002</ref>). By manipulating the concentration level of WNT5A protein secreted by a melanoma cell line, one can directly affect the metastatic status of the cell as measured by the standard in vitro assays for metastasis. For intervention purposes, antibodies can be designed to bind with WNT5A and block it from activating its receptor. This will significantly weaken its ability to induce a metastatic phenotype, which suggests that reducing the WNT5A gene's action could reduce the chance of a melanoma metastasizing. Therefore, it is desirable to downregulate WNT5A as much as possible through appropriate intervention mechanisms (<ref type="bibr" target="#b5">Datta et al., 2003;</ref><ref type="bibr" target="#b27">Qian and Dougherty, 2008</ref>). We use a network composed of 10 genes from a set of 587 genes (<ref type="bibr" target="#b28">Qian and Dougherty, 2012</ref>). The genes, listed from the most significant bit to the least significant bit, are WNT5A, pirin, S100P, RET1, MMP3, PHOC, MART1, HADHB, synuclein and STC2. This ordering of genes is only for demonstration purposes and does not affect our analysis. The regulatory relationships between these genes are presented in<ref type="figure" target="#tab_1">Table 1</ref>. We construct a BNp with p ¼ 0.001 and assume that the upregulation of WNT5A is undesirable. For the control genes, we choose each gene in the network as the control gene and find the optimal and suboptimal intervention policies in addition to their effects on the steady-state shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.3">Mammalian cellcycle network</head><p>To characterize the dynamical behavior of normal mammalian cells during the cell cycle,<ref type="bibr" target="#b15">Faure et al. (2006)</ref>proposed a Boolean-logic regulatory network containing three key genes: Cyclin D (CycD), retinoblastoma (Rb) and p27. For a normal mammalian organism, cell division is coordinated with overall growth via extracellular signals controlling the activation of CycD. These signals indicate whether a cell should undergo cell division or remain in a resting state. Rb is a tumor-suppressor gene and is expressed in the absence of the cyclins that inhibit Rb by phosphorylation. Gene p27 is also active in the absence of the cyclins. An active p27 blocks the action of CycE or CycA and, hence, Rb can also be expressed, even in the presence of CycE or CycA, resulting in a stop in the cell cycle. In the wild-type cell-cycle network, when p27 is active, the cell cycle can be stopped. Following a proposed mutation for this network, we assume that p27 can never be activated (always OFF), thereby creating a situation where both CycD and Rb might be inactive (<ref type="bibr" target="#b15">Faure et al., 2006</ref>). Under these conditions, the cell can cycle in the absence of any growth factor, thereby causing undesirable proliferation. The mutated network has nine genes, CycD, Rb, E2F, CycE, CycA, Cdc20, Cdh1, UbcH10 and CycB, ordered from the most significant bit to the least significant bit in the binary representation. Similar to the metastatic melanoma network, this ordering is only for the sake of presentation.<ref type="figure">Table 2</ref>lists the regulatory functions of the mutated cell-cycle network following Boolean logic. We construct an instantaneously random PBN for this mutated network, where depending on the state of the extracellular signal that determines the state of CycD as being ON or OFF, there are two constituent BNs, which we assume to be equally likely. We set p ¼ 0.001. As cell growth in the absence of growth factors is undesirable, the undesirable states are those for which CycD and Rb are both downregulated (OFF). We consider all genes except CycD and Rb as the possible control gene and find the optimal and suboptimal intervention policies in addition to their effects on the steady-state shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head><p>The entire set of simulation results can be found in the Supplementary Material. Here, we provide some results that represent the general trends observed in the simulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Synthetic networks</head><p>We present results for the synthetic networks with seven genes. Corresponding results for six and eight genes are given in the Supplementary Material, where it is evident that the same trends are observed.<ref type="figure">Figure 1</ref>shows the shift in the probability mass of undesirable states induced by the optimal and suboptimal policies, Equation (7), averaged over all random networks with various structural properties and for different values of. These graphs clearly show the optimality of Ã uc and Ã pc compared with their suboptimal counterparts. In general, the suboptimal policy cssd yields the best results, close to optimal, among the suboptimal policies. However, concssd does not induce as much shift as Ã pc , which is due to the fact that the search space of conCSSD policy is M D , whereas it is M S in the LP 4 problem. The amount of average shift induced by Ã pc is significantly less than Ã uc owing to the additional constraints imposed on the optimization LP 4 problem.<ref type="figure">Figure 2</ref>shows the empirical CCDF of ÁðÞ for different suboptimal intervention policies , and for the UC and PC problems separately, across 2500 random PBNs with seven genes, ¼ 3 and p ¼ 0.001. The graphs on the left column indicate that UC optimal and CSSD policies induce similar amounts of shift with a high probability. However, for the constrained problem, it is clear that PC optimal policies outperform conCSSD policies with a (realistically) significant probability. For example, for optimal policy Ã pc , with probability 0.1, we achieve an improvement of 45% over concssd suboptimal policy. The results are somewhat different for BNps.<ref type="figure">Figure 3</ref>demonstrates the empirical CCDF of ÁðÞ for different suboptimal intervention policies , corresponding to the UC and PC problems, across 2500 randomly generated BNps with seven genes, ¼ 3 and p ¼ 0.001. With high probability, higher than those for PBNs, we achieve better performance by using optimal policies. For instance when ¼ 0:5, this figure shows that the optimal policy achieves an improvement of 45% over concssd with probability 0.2.</p><formula>v 2 ðv 1 ^ v 4 ^ v 5 ^ v 9 Þ E2F v 3 ðv 2 ^ v 5 ^ v 9 Þ CycE v 4 ðv 3 ^ v 2 Þ CycA v 5 ðv 3 ^ v 2 ^ v 6 ^ ðv 7 ^ v 8 ÞÞ _ðv 5 ^ v 2 ^ v 6 ^ ðv 7 ^ v 8 ÞÞ Cdc20 v 6 v 9 Cdh1 v 7 ðv 5 ^ v 9 Þ _ v 6 UbcH10 v 8 v 7 _ ðv 7 ^ v 8 ^ ðv 6 _ v 5 _ v 9 ÞÞ CycB v 9 ðv 6 ^ v 7 Þ</formula><formula>^ v 6 Þ pirin v 2 ðv 1 ^ v 3 ^ v 5 Þ _ ðv 1 ^ v 3 ^ v 5 Þ S100P v 3 v 7 RET1 v 4 ðv 1 ^ v 2 ^ v 4 Þ _ ðv 2 ^ v 4 Þ MMP3 v 5 ðv 4 ^ v 9 Þ _ ðv 9 Þ PHOC v 6 ðv 4 ^ v 7 Þ _ ðv 4 ^ v 7 ^ v 10 Þ MART1 v 7 v 7 HADHB v 8 ðv 1 ^ v 5 Þ _ ðv 5 ^ v 9 Þ _ ðv 1 ^ v 5 ^ v 9 Þ synuclein v 9 ðv 1 ^ v 7 ^ v 10 Þ _ ðv 4 ^ v 7 ^ v 10 Þ _ v 7 STC2 v 10 v 3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Real networks</head><p>As there is only one network, we cannot report the average shift or CCDF of ÁðÞ for different suboptimal intervention policies.<ref type="figure">Table 3</ref>shows the shifts made by all control policies for different potential control genes for the metastatic melanoma network. The aggregated probability mass of undesirable states for the uncontrolled network is P j2U j ¼ 0:1711. The maximum shift induced by the UC optimal policy occurs when either MMP3 or PHOC are the control genes. However, the maximum shift for the PC optimal policy occurs when MART1 is the control gene, which is an immunogen that the body sometimes recognizes and attacks via the immune system (<ref type="bibr" target="#b8">Dissanayake et al., 2008;</ref><ref type="bibr" target="#b28">Qian and Dougherty, 2012</ref>). A good amount of shift is achieved for both constrained and UC problems with MART1. Thus, MART1 can be viewed as a potential control gene for intervention. Overall, however, the results indicate that the best control gene depends on ones objectives and how much risk one is</p><formula>(a)</formula><p>(b)<ref type="figure">Fig. 1</ref>. Shift in the steady-state mass of undesirable states averaged across randomly generated networks with seven genes, various and gene perturbation probabilities p: (a) PBN; (b) BNp<ref type="figure">Fig. 3</ref>. Empirical CCDF of Á for different intervention policies across 2500 random BNps with seven genes, ¼ 3 and p ¼ 0.001. The left and right columns correspond to the UC and PC optimal policies, respectively<ref type="figure">Fig. 2</ref>. Empirical CCDF of Á for different intervention policies across 2500 random PBNs with seven genes, ¼ 3 and p ¼ 0.001. The left and right columns correspond to the UC and PC optimal policies, respectively willing to take. The seemingly intuitive choice of directly perturbing WNT5A to control WNT5A (first column) only produces the best result with the conSSD policy. This is because of feedback in the network. Not only can a direct approach absent constraint produce unwanted phenotypes, a direct approach may not even achieve the desired reduction in long-run probability mass of the target gene on account of complicated feedback loops. The aggregated mass of undesirable states for the uncontrolled mammalian cell cycle network is P j2U j ¼ 0:2012.<ref type="figure">Table 4</ref>gives the amount of shift made by all control policies for different control gene candidates. The table shows that choosing E2F as the control gene induces the maximum shift under different control policies. Thus, E2F can be considered as a potential control gene for intervention. It is also evident that the difference between the performances of PC optimal policies and conCSSD is significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUDING REMARKS</head><p>Heretofore, two external control approaches have been taken to shift the steady-state mass of a GRN: (i) use a subjectively defined cost function for which desirable shift of the steadystate mass is a by-product and (ii) use heuristics to design a greedy algorithm. The present article uses a linear programming approach to optimally shift the steady-state mass and therefore outperforms both of the preceding approaches. Moreover, it does with less computational overhead and therefore can be applied to larger networks. Owing to its generality, the same basic LP structure is used for both unconstrained and constrained optimization problems. Thus, at least in the case of</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Furthermore, for ja ði, Þ 2 Vði, Þ, the Markov chain with transition probabilities QðÞ, defined in Equation (2), has a unique invariant probability measure vector ðÞ, which satisfies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 2. Regulatory functions of a mutated mammalian cell-cycle network</figDesc><table>Gene 
Node 
Predictor functions 

CycD 
v 1 
Extracellular signal 
Rb 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1. Regulatory functions of a metastatic melanoma network</figDesc><table>Gene 
Node 
Predictor functions 

WNT5A 
v 1 
ðv 3 ^ v 5 ^ v 6 Þ _ ðv 5 </table></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Intervention in GRNs at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">M.R. Yousefi and E.R. Dougherty at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> ðPÞ ¼ sup x T j j 1 ¼1 x T 1¼0 x T P  1 , where 1 denotes a column vector of appropriate length having all entries equal to 1 (Seneta, 1988). If 1 ðPÞ 6 ¼ 1, then (Pal et al., 2008) ðÞ À ~ ðÞ  1 1 1 À 1 ðPÞ jjEjj 1 : Hence if, the error is small, then the SSD of the controlled actual process is close to the SSD of controlled estimated process from which the control policy has been derived, the bound depending on the ergodicity coefficient. Other perturbation bounds using different condition numbers were examined via simulations in Pal et al. (2008). Having discussed the general case of Markov chains, Pal et al. (2008) went on to relate the general results to PBNs by showing how different classes of possible uncertainties for a PBN would translate into uncertainties in the TPM for the corresponding Markov chain. 2.8 Simulation setup We design simulation studies on synthetically generated and two real networks. We find optimal and suboptimal control policies for both UC and constrained problems and calculate their performance under different parameter choices. To reduce the complexity of graphs and tables, we do not consider the MFPT and BOA policies. From the perspective of demonstrating the optimality of the UC and PC algorithms, there is no loss in this omission, as it has been amply demonstrated that the SSD and CSSD policies generally outperform the MFPT and BOA policies relative to the criterion of shifting the SSD (Qian et al., 2009). For constrained optimization problems, the set of ambiguous states, D a , and an upper-bound must be defined. In practice, these should be defined based on biomedical knowledge related to the GRN and treatment objectives. Here, we take an approach similar to Qian and Dougherty (2012). For PBNs, we define D a ¼ fi 2 D : i g, where is the invariant measure of the TPM of the uncontrolled network and is a userdefined threshold. We let ¼ 1=2 n and set ¼ max i2Da i. For BNps, ambiguous states are the states in D that belong to the nonattractor states of the original BNs so that the control will not introduce new attractors. 2.8.1 Synthetic networks We generate 2500 random PBNs and 2500 random BNps with different parameters and report the average performance across all networks as well as some statistics on the performance of each intervention policy. The performance of optimal policies might not substantially exceed that of suboptimal policies when averaged across randomly generated networks for a couple of reasons. First, randomly generated networks may have certain structures making them unresponsive to the intervention policies. Second, many networks might possess structure for which the suboptimal and optimal policies are almost identical. Be that as it may, the key point is that there are networks for which the optimal policy significantly outperforms the suboptimal ones. Here, we use the difference in the amounts of shifts made by optimal and suboptimal policies to quantify the gain made by using the optimal policy: ÁðÞ ¼ Á U ð Ã Þ À Á U ðÞ ¼ X j2U j ðÞ À X j2U j ð Ã Þ, where ð Ã Þ and ðÞ denote the invariant probability measures for the network under the optimal and suboptimal policies, respectively. Clearly, 0 ÁðÞ 1. For each network ÁðÞ is calculated for all previously discussed suboptimal policies, for the UC and constrained problems separately. As the networks are randomly generated, ÁðÞ is a random variable. To show the effectiveness of optimal policies, we graph the tail probabilities, i.e. the empirical complementary cumulative distribution function (CCDF), of ÁðÞ. To keep the computational time tractable, we consider instantaneously random PBNs, the states representing the GAPs at any given time, and n ¼ 6, 7 or 8 genes. The state space is S ¼ f0, 1, 2,. .. , 2 n À 1g and is generated from four equally likely constituent BNs with the maximum number of predictors (j i for all i) for each Boolean function set to two or three. The bias of each PBN is the probability that each Boolean regulatory function takes on the value 1. We assume that it is taken randomly from a beta distribution with mean 2 f0:25, 0:5, 0:75g and the standard deviation 0.01, thereby affecting the dynamics of a randomly generated BN. The gene perturbation probability is either 0.001 or 0.01. A similar setting is used for generating BNps, except that there is only one constituent BN. For any given BNp and PBN, the TPMs of the corresponding Markov chains are computed as explained in Section 2.1. We choose the control and target genes to be the least and most significant bits in the binary representation of states, respectively, and assume that downregulation of the target gene is undesirable. The actual construction is done in the following manner. For each constituent BN in a random PBN, we first randomly select the predictors of each gene with all genes having the same probability of being selected. The value of each gene given the values of its predictors is now determined by a Bernoulli random variable whose probability of being 1 equals the bias (the bias is also randomly generated from a beta distribution with a mean and a given standard deviation). This process will construct a random truth table corresponding to a BN. Having all the</note>

			<note place="foot">Markovian GRNs, in particular, PBNs, previously proposed methods can be abandoned whenever the goal is to optimally shift the steady-state mass. Conflict of Interest: none declared.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Constrained Markov Decision Processes</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Altman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Chapman &amp; Hall/CRC, Boca Raton, FL, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Molecular classification of cutaneous malignant melanoma by gene expression profiling</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bittner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">406</biblScope>
			<biblScope unit="page" from="536" to="540" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Steady-state probabilities for attractors in probabilistic Boolean networks</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Brun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal. Process</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1993" to="2013" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimal control policy for probabilistic boolean networks with hard constraints</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">K</forename>
				<surname>Ching</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="90" to="99" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Comparison of perturbation bounds for the stationary distribution of a Markov chain</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Cho</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Meyer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">335</biblScope>
			<biblScope unit="page" from="137" to="150" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">External control in Markovian genetic regulatory networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Datta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="169" to="191" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Introduction to Genomic Signal Processing with Control</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Datta</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Finite State Markovian Decision Processes</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Derman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
			<publisher>Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Wnt5a regulates expression of tumor-associated antigens in melanoma via changes in signal transducers and activators of transcription 3 phosphorylation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Dissanayake</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="10205" to="10214" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Genomic signal processing: diagnosis and therapy</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Datta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="107" to="112" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Stationary and structural control in gene regulatory networks: basic concepts</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="5" to="16" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">On approximate stochastic control in genetic regulatory networks</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Faryabi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="361" to="368" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Intervention in context-sensitive probabilistic Boolean networks revisited</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Faryabi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Bioinform. Syst. Biol</title>
		<imprint>
			<biblScope unit="page">360864</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">mutated mammalian cell-cycle network for different control genes and different control policies Control E2F CycE CycA Cdc20 Cdh1 UbcH10 CycB</title>
	</analytic>
	<monogr>
		<title level="m">Table 4. Shift in the steady-state mass of undesirable states of the</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Table 3. Shift in the steady-state mass of undesirable</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamical analysis of a generic Boolean model for the control of the mammalian cell cycle</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Faure</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="124" to="131" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">A CoD-based reduction algorithm for designing stationary control policies on Boolean networks</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Ghaffari</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1556" to="1563" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamics preserving size reduction mappings for probabilistic Boolean networks</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ivanov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="2310" to="2322" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Selection policy-induced reduction mappings for Boolean networks</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ivanov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="4871" to="4882" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Linear Programming and Finite Markovian Control Problems</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">C M</forename>
				<surname>Kallenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematisch Centrum</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<monogr>
		<title level="m" type="main">The Origins of Order: Self-Organization and Selection in Evolution</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">A</forename>
				<surname>Kauffman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Stanniocalcin-2 is a Hif-1 target gene that promotes cell proliferation in hypoxia</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Law</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp. Cell Res</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page" from="466" to="476" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Stanniocalcin-2 promotes epithelialmesenchymal transition and invasiveness in hypoxic human ovarian cancer cells</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Law</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Exp. Cell Res</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="page" from="3425" to="3434" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">On the complexity of linear programming Advances in Economic Theory: Fifth World Congress</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Megiddo</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page" from="225" to="268" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Optimal infinite-horizon control for probabilistic Boolean networks</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="2375" to="2387" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust intervention in probabilistic Boolean networks</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1280" to="1294" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Bayesian robustness in the control of gene regulatory networks</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="3667" to="3678" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Effect of function perturbation on the steadystate distribution of genetic regulatory networks: optimal structural intervention</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Qian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="4966" to="4976" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Intervention in gene regulatory networks via phenotypically constrained control policies based on long-run behavior</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Qian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE ACM Trans. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="123" to="136" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Intervention in gene regulatory networks via greedy control policies based on long-run behavior</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Qian</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">61</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">State reduction for network intervention with probabilistic Boolean networks</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Qian</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3098" to="3194" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Randomized and past-dependent policies for Markov decision processes with multiple constraints</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">W</forename>
				<surname>Ross</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="474" to="477" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Perturbation of the stationary distribution measured by ergodicity coefficients</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Seneta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="228" to="230" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic Boolean networks: a rule-based uncertainty model for gene regulatory networks</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Shmulevich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="261" to="274" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Gene perturbation and intervention in probabilistic Boolean networks</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Shmulevich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1319" to="1331" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Control of stationary behavior in probabilistic Boolean networks by means of structural intervention</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Shmulevich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biol. Syst</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="431" to="445" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Intervention in gene regulatory networks via a stationary mean-first-passage-time control policy</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Vahedi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="2319" to="2331" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Wnt5a signaling directly affects cell motility and invasion of metastatic melanoma</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">T</forename>
				<surname>Weeraratna</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Cell</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="279" to="288" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">The impact of function perturbations in Boolean networks</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Xiao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Dougherty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1265" to="1273" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Optimal intervention strategies for therapeutic methods with fixed-length duration of drug effectiveness</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Yousefi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="4930" to="4944" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>