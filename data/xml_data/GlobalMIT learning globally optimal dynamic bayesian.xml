
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GlobalMIT: learning globally optimal dynamic bayesian network with the mutual information test criterion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">19 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Nguyen</forename>
								<forename type="middle">Xuan</forename>
								<surname>Vinh</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gippsland School of Information Technology</orgName>
								<orgName type="department" key="dep2">Faculty of IT</orgName>
								<orgName type="institution">Monash University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Madhu</forename>
								<surname>Chetty</surname>
							</persName>
							<email>madhu.chetty@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Gippsland School of Information Technology</orgName>
								<orgName type="department" key="dep2">Faculty of IT</orgName>
								<orgName type="institution">Monash University</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ross</forename>
								<surname>Coppel</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Microbiology</orgName>
								<orgName type="department" key="dep2">Faculty of Medicine, Nursing and Health Sciences</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Victoria</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Pramod</forename>
								<forename type="middle">P</forename>
								<surname>Wangikar</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Chemical Engineering</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GlobalMIT: learning globally optimal dynamic bayesian network with the mutual information test criterion</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS APPLICATIONS NOTE</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="page" from="2765" to="2766"/>
							<date type="published" when="2011">19 2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr457</idno>
					<note type="submission">Systems biology Advance Access publication August 3, 2011 Received on June 8, 2011; revised on July 21, 2011; accepted on July 29, 2011</note>
					<note>[15:10 5/9/2011 Bioinformatics-btr457.tex] Page: 2765 2765–2766 Associate Editor: Trey Ideker Supplementary information: Supplementary data is available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Dynamic Bayesian networks (DBN) are widely applied in modeling various biological networks including the gene regulatory network (GRN). Due to the NP-hard nature of learning static Bayesian network structure, most methods for learning DBN also employ either local search such as hill climbing, or a meta stochastic global optimization framework such as genetic algorithm or simulated annealing. Results: This article presents GlobalMIT, a toolbox for learning the globally optimal DBN structure from gene expression data. We propose using a recently introduced information theoretic-based scoring metric named mutual information test (MIT). With MIT, the task of learning the globally optimal DBN is efficiently achieved in polynomial time. Availability: The toolbox, implemented in Matlab and C++, is available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Bayesian network (BN) has found applications in modeling various biological networks including the gene regulatory network (GRN). The two important limitations when applying static BN to these domain problems are: (i) BN does not have a mechanism for exploiting the temporal aspect of time-series data, such as time-series microarray data; and (ii) BN does not allow the modeling of cyclic phenomena, such as feedback loops, which are prevalent in biological systems (<ref type="bibr" target="#b11">Yu et al., 2004</ref>). These drawbacks have motivated the development of the so-called dynamic Bayesian network (DBN). Its simplest model, the first-order Markov stationary DBN, assumes that both the structure of the network and the parameters characterizing it remain unchanged over time. The value of a variable at time (t) is assumed to depend only on the value of its parents at time (t −1). DBN not only accounts for the temporal aspect of time-series data (i.e. an inter time-slice edge must always be directed forward in time), but it also allows the modeling of feedback loops. Since its inception, DBN has received particular interest from the bioinformatics community (<ref type="bibr" target="#b3">Husmeier, 2003</ref>; Kim * To whom correspondence should be addressed<ref type="bibr" target="#b5">Murphy and Mian, 1999;</ref><ref type="bibr" target="#b6">Perrin et al., 2003;</ref><ref type="bibr" target="#b10">Wilczynski and Dojer, 2009;</ref><ref type="bibr" target="#b11">Yu et al., 2004;</ref><ref type="bibr" target="#b12">Zou and Conzen, 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head><p>Most algorithms to date for learning DBN structure employ a local search strategy, such as hill climbing with random restart, or a meta stochastic global optimization framework such as genetic algorithm or simulated annealing, as exemplified by several softwares such as BANJO (<ref type="bibr" target="#b8">Smith et al., 2006</ref>) or bnlearn (<ref type="bibr" target="#b7">Scutari, 2010</ref>). This is due to several NP-hardness results in learning static BN structure (see, e.g.<ref type="bibr" target="#b0">Chickering, 1996</ref>). Recently, Dojer (2006) has shown otherwise that learning DBN structure, as opposed to static BN, does not necessarily have to be NP-hard. In particular, it was shown that, under some mild assumptions, there are algorithms using the minimum description length (MDL) and BDe scores, which find the globally optimal network with a polynomial worst-case time complexity. These algorithms have been realized within the BNFinder software (<ref type="bibr" target="#b10">Wilczynski and Dojer, 2009</ref>). In our experiments, we observed that BNFinder+MDL is very fast, whereas BNFinder+BDe is very time demanding: a single run on a dataset of 20 genes and 300 observations can take up to a day (<ref type="bibr" target="#b9">Vinh et al., 2011</ref>). This is in concordance with the theoretical worst-case complexity analysis, where the algorithm would have to exhaustively evaluate all possible parent sets of cardinality from 0 to p * −1. Let k be the number of discrete states of each variable, N be the number of experiments, then for MDL, p * MDL is given by log k N, while for BDe, p * BDe ==N log γ −1 k, where 0 &lt;γ&lt;1 is the network complexity penalty parameter (default value logγ −1 = 1 for BNFinder). In general, p * BDe scales linearly with the number of data items N, making its value of less practical interest, even for very small datasets. Although being more expensive, BNFinder+BDe is still recommended over BNFinder+MDL, 'due to its exactness in the statistical interpretation' (<ref type="bibr" target="#b10">Wilczynski and Dojer, 2009</ref>). Further, de Campos (2006) also showed that BDe seems to learn more accurate networks than MDL [which is also equivalent to the Bayesian Information Criterion (BIC)]. Mutual information test (MIT) is a recently introduced scoring metric for learning BN (<ref type="bibr" target="#b1">de Campos, 2006</ref>). To understand MIT, let X ={X 1 ,...,X n } denote the set of n variables with corresponding {r 1 ,...,r n } discrete states, D denote our dataset of N observations, G be a DBN, and Pa i ={X i1 ,...,X is i } be the set of parents of X i in G with corresponding {r i1 ,...,r is i } discrete states, s i =|Pa i |. The MIT score is then defined as:</p><formula>S MIT (G : D) = n i=1;Pa i =∅ {2N ·I(X i ,Pa i )− s i j=1 χ α,l i σ i (j) } where I(X i ,Pa i )</formula><p>is the mutual information between X i and its parents as estimated from D. χ α,l ij is the value such that p(χ 2 (l ij ) ≤ χ α,l ij ) = α (the chi-square distribution at significance level 1−α), and the term l iσ i (j) is defined as:</p><formula>l iσ i (j) = (r i −1)(r iσ i (j) −1) j−1 k=1 r iσ i (k) , j = 2...,s i (r i −1)(r iσ i (j) −1), j = 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N.X.Vinh et al.</head><p>where σ i ={σ i (1),...,σ i (s i )} is any permutation of the index set {1...s i } of Pa i , with the first variable having the greatest number of states, the second variable having the second largest number of states, and so on. MIT falls under the same category of information theory-based scores as the MDL, BIC and Akaike Information Criterion (AIC). Briefly speaking, under MIT, the goodness-of-fit of a network is measured by the total mutual information shared between each node and its parents, penalized by a term which quantifies the degree of statistical significance of this shared information. Through extensive experimental validation, de Campos (2006) suggested that, for the task of learning static BN, MIT can compete favorably with Bayesian scores (BDe), outperforms BIC/MDL and should be the score of reference within those based on information theory. However, as opposed to the other popular scoring metrics, to our knowledge MIT has not been considered for DBN learning. In our recent work (<ref type="bibr" target="#b9">Vinh et al., 2011</ref>), we have shown that under the same set of assumptions made in Dojer (2006), there exists a polynomial worst-case time complexity algorithm for learning the globally optimal DBN structure with MIT. We call this algorithm GlobalMIT. The polynomial worst-case time complexity of GlobalMIT is characterized by:</p><formula>p * MIT = argmin{p| p j=1 χ α,l iσ i (j) ≥ 2N ·logk},</formula><p>It can be seen that p * MIT depends only on α,k and N. In the worst case, our algorithm will have to examine all the possible parent sets of cardinality from 1 to p * MIT −1. Since there are O(n p * MIT ) subsets with at most p * MIT −1 parents, and each set of parents can be scored in polynomial time, globalMIT admits an overall polynomial worst-case time complexity in the number of variables (see also GlobalMIT user guide within the online supplementary material for further details). Our experimental evaluation in<ref type="bibr" target="#b9">Vinh et al. (2011)</ref>showed that GlobalMIT is very competitive in terms of network quality. In other words, GlobalMIT seems to combine the strength of both MDL (speed) and BDe (solution quality).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Implementation</head><p>The algorithm involves investigating, for each variable, every potential parent set of increasing cardinality (not exceeding p * MIT −1) until the globally optimal solution has been found. One important observation for the efficient implementation of GlobalMIT is the following decomposition property of the mutual information:</p><formula>I(X i ,Pa i ∪X j ) = I(X i ,Pa i )+I(X i ,X j |Pa i ).</formula><p>This implies that the mutual information can be computed incrementally, and suggests that, for efficiency, the computed mutual information values should be cached to avoid redundant computations. We provide an implementation of the GlobalMIT algorithm as a Matlab toolbox. The toolbox also supports simple data pre-processing functionalities, such as data discretization and mapping, and simple post-processing such as visualization and quality assessment. For improved performance, we also provide an implementation of GlobalMIT in C++. Our experiments showed that the C++ version of GlobalMIT is up to 40 times on average faster than the Matlab version. For seamless and easy use of GlobalMIT, interface modules provide connection between Matlab and the C++ version, allowing the users to perform all operations in Matlab. We experimentally compared the runtime of GlobalMIT to BNFinder (<ref type="bibr" target="#b10">Wilczynski and Dojer, 2009</ref>) with both the MDL and BDe metrics. The test was carried out on a synthetic dataset of 20 genes × 2000 observations, generated from a gene regulatory network (Network No. 1) as described in<ref type="bibr" target="#b11">Yu et al. (2004)</ref>. On a Core 2 Duo PC with 4 GB of main memory, GlobalMIT C++ and BNFinder + MDL took slightly &gt;1 h to analyze this dataset, while BNFinder+BDe took &gt;3 days. It is noted that currently GlobalMIT only learns DBN with intertime slice edges, i.e. edges from X</p><formula>(t−1) i to X (t)</formula><p>j. Learning DBN which allows both inter-and intratime slide edges falls back to an NPhard problem. However, intratime slice edges representing (almost) instantaneous genetic interactions, if of interest, can be learned separately using some BN learning algorithm, then combined with the intertime slice edges, followed by some post-processing for the final result. Our future work includes expanding GlobalMIT in this direction. Also, we are extending our framework to handle edges spanning either two or several time slices, which represent variable, longer time-delayed genetic interactions that are also abundant in genetic networks (<ref type="bibr" target="#b12">Zou and Conzen, 2005</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>[15:</head><figDesc>10 5/9/2011 Bioinformatics-btr457.tex] Page: 2766 2765–2766</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Funding: This research forms part of a project supported by an Australia-India strategic research fund (AISRF). Conflict of Interest: none declared.</figDesc></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks is NP-complete</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Chickering</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning from Data: Artificial Intelligence and Statistics V</title>
		<editor>Fisher,D. and Lenz,H.</editor>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A scoring function for learning bayesian networks based on mutual information and conditional independence tests</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">M</forename>
				<surname>De Campos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2149" to="2187" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks does not have to be NP-hard</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Dojer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Foundations of Computer Science Lecture Notes in Computer Science</title>
		<editor>Královic,R. and Urzyczyn,P.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">4162</biblScope>
			<biblScope unit="page" from="305" to="314" />
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Sensitivity and specificity of inferring genetic regulatory interactions from microarray experiments with dynamic Bayesian networks</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Husmeier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2271" to="2282" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Inferring gene networks from time series microarray data using dynamic Bayesian networks</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">Y</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinformat</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="228" to="235" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Modelling gene expression data using dynamic bayesian networks</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">P</forename>
				<surname>Murphy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mian</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Gene networks inference using dynamic Bayesian networks</title>
		<author>
			<persName>
				<forename type="first">B.-E</forename>
				<surname>Perrin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="138" to="148" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks with the bnlearn R package</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Scutari</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Soft</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Computational inference of neural information flow networks</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">A</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">161</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">A polynomial time algorithm for learning globally optimal dynamic Bayesian network and its applications in genetic network reconstruction</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">X</forename>
				<surname>Vinh</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">BNFinder: exact and efficient method for learning Bayesian networks</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Wilczynski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Dojer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="286" to="287" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Advances to Bayesian network inference for generating causal networks from observational biological data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="3594" to="3603" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A new dynamic Bayesian network (DBN) approach for identifying gene regulatory networks from time course microarray data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">D</forename>
				<surname>Conzen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="71" to="79" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>