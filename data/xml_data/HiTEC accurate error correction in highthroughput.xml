
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis HiTEC: accurate error correction in high-throughput sequencing data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Lucian</forename>
								<surname>Ilie</surname>
							</persName>
							<email>ilie@csd.uwo.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Western Ontario</orgName>
								<address>
									<postCode>N6A 5B7</postCode>
									<settlement>London</settlement>
									<region>ON</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Farideh</forename>
								<surname>Fazayeli</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Western Ontario</orgName>
								<address>
									<postCode>N6A 5B7</postCode>
									<settlement>London</settlement>
									<region>ON</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Silvana</forename>
								<surname>Ilie</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Western Ontario</orgName>
								<address>
									<postCode>N6A 5B7</postCode>
									<settlement>London</settlement>
									<region>ON</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alex</forename>
								<surname>Bateman</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Ryerson University</orgName>
								<address>
									<postCode>M5B 2K3</postCode>
									<settlement>Toronto</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis HiTEC: accurate error correction in high-throughput sequencing data</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">3</biblScope>
							<biblScope unit="page" from="295" to="302"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq653</idno>
					<note type="submission">Received on July 28, 2010; revised on November 22, 2010; accepted on November 23, 2010</note>
					<note>[09:23 19/1/2011 Bioinformatics-btq653.tex] Page: 295 295–302 Associate Editor: Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: High-throughput sequencing technologies produce very large amounts of data and sequencing errors constitute one of the major problems in analyzing such data. Current algorithms for correcting these errors are not very accurate and do not automatically adapt to the given data. Results: We present HiTEC, an algorithm that provides a highly accurate, robust and fully automated method to correct reads produced by high-throughput sequencing methods. Our approach provides significantly higher accuracy than previous methods. It is time and space efficient and works very well for all read lengths, genome sizes and coverage levels. Availability: The source code of HiTEC is freely available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>DNA sequencing technologies have produced a revolution in biological research. Since the introduction of the Sanger method (<ref type="bibr" target="#b28">Sanger et al., 1977</ref>), hundreds of bacterial and eucaryotic genomes have been sequenced, including several human genomes. This led to a significant number of biological discoveries. High-throughput sequencing technologies, such as Illumina's Genome Analyzer, ABI's SOLiD and Roche's 454, see e.g. (<ref type="bibr" target="#b24">Mardis, 2008</ref>), produce gigabytes of data in a single run, thus taking sequencing to a whole new level. They provide the ability to answer biological questions with revolutionary speed. Some of their many applications include whole-genome sequencing and resequencing, single nucleotide polymorphism (SNP) discovery, identification of copy number variations, chromosomal rearrangements, etc. The impact of these technologies for everyday life, yet to be fully understood, will be far reaching. Many algorithms and software tools have been created to deal with the large amount of data produced by these technologies. Two of the fundamental and most investigated problems are read mapping and genome assembly. The former assumes the existence of a reference genome and attempts to find the location of newly sequenced reads from a different genome of the same species (<ref type="bibr" target="#b3">Campagna et al., 2009;</ref><ref type="bibr" target="#b8">Eaves and Gao, 2009;</ref><ref type="bibr" target="#b11">Jiang and Wong, 2008;</ref><ref type="bibr" target="#b12">Jung Kim et al., 2009</ref>; * To whom correspondence should be addressed.<ref type="bibr" target="#b17">Langmead et al., 2009;</ref><ref type="bibr" target="#b20">Li and Durbin, 2009;</ref><ref type="bibr">Li et al., 2008a, b;</ref><ref type="bibr" target="#b21">Lin et al., 2008;</ref><ref type="bibr" target="#b22">Malhis et al., 2009;</ref><ref type="bibr" target="#b26">Rumble et al., 2009;</ref><ref type="bibr" target="#b29">Schatz, 2009;</ref><ref type="bibr" target="#b36">Smith et al., 2008</ref>). The latter attempts to reconstruct the genome that originated the reads (<ref type="bibr" target="#b2">Butler et al., 2008;</ref><ref type="bibr" target="#b4">Chaisson et al., 2009;</ref><ref type="bibr" target="#b5">Chen and Skiena, 2007;</ref><ref type="bibr" target="#b6">Chen, 2009;</ref><ref type="bibr" target="#b7">Dohm et al., 2007;</ref><ref type="bibr" target="#b9">Hernandez et al., 2008;</ref><ref type="bibr" target="#b10">Jeck et al., 2007;</ref><ref type="bibr" target="#b35">Simpson et al., 2009;</ref><ref type="bibr" target="#b37">Warren et al., 2007;</ref><ref type="bibr" target="#b39">Zerbino and Birney, 2008</ref>). In spite of the many different approaches, these tools employ to solve their problems, they all share several common issues, such as very large data size, repeats in genomes and sequencing errors. The first two cannot be changed and we shall concentrate here on sequencing errors. Attempts have been made to either correct such errors or discard the erroneous reads. Some assembly tools include a spectral alignment-based read correction preprocessing step (<ref type="bibr" target="#b2">Butler et al., 2008;</ref><ref type="bibr" target="#b4">Chaisson et al., 2009</ref>), whereas others pre-filter the reads (<ref type="bibr" target="#b7">Dohm et al., 2007</ref>). The very recent approaches of Salmela (2010);<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>;<ref type="bibr" target="#b34">Shi et al. (2010)</ref>are exclusively dedicated to read correction. The general idea for correcting reads is to use the high coverage of the current sequencing technologies in order to identify the erroneous bases in the reads. Each base is usually sampled many times and the correct value will prevail. The way such information is used can be spectral alignment (<ref type="bibr" target="#b34">Shi et al., 2010</ref>) or subtree weight in suffix trees (<ref type="bibr" target="#b33">Schroder et al., 2009</ref>). Whereas<ref type="bibr" target="#b34">Shi et al. (2010)</ref>provides an efficient implementation of the Euler-SR read correction algorithm of<ref type="bibr" target="#b4">Chaisson et al. (2009)</ref>by using CUDA-enabled graphics hardware (their program will subsequently be referred to as CUDA), the SHREC program by<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>uses a novel idea, by employing weighted suffix trees. The algorithm of Salmela (2010) is a generalization of SHREC to mixed sets of reads. Error correction is quickly identified as a key problem in highthroughput sequencing data. Another software, Reptile, has been developed by<ref type="bibr" target="#b38">Yang et al. (2010)</ref>simultaneously with ours. It is also based on the k-spectrum approach of Euler-SR and CUDA. Our High Throughput Error Correction (HiTEC) algorithm uses a thorough statistical analysis of the suffix array built on the string of all reads and their reverse complements. It is intuitively explained in Section 2.2 and fully analyzed in the remaining of Section 2. We have tested in Section 3 our algorithm on many datasets, simulated or real, from<ref type="bibr" target="#b33">Schroder et al. (2009</ref><ref type="bibr" target="#b34">), Shi et al. (2010</ref><ref type="bibr" target="#b38">) and Yang et al. (2010</ref>, as well as on several new ones. The accuracy of HiTEC is significantly higher than the accuracy of all the other programs. (The accuracy is the ratio between the number of corrected reads and the number of initially erroneous reads.) Further, our own testing reveals a significant difference between the accuracy obtained by running the SHREC program and that reported by<ref type="bibr" target="#b33">Schroder et al. (2009</ref>(We provide the values for both.) This is due to the fact that SHREC requires trying several parameter sets in order to find those providing the highest accuracy, which is likely not possible in real situations where the accuracy cannot be measured. HiTEC is not only more accurate but also more robust. Our algorithm works for a wide range of read lengths and coverage levels and it is the only one to do so with automatic adjustment, depending on the data set, based on our statistical analysis. In addition to high accuracy, the time and space complexities are very good. Our current serial implementation of HiTEC is comparable with Reptile and is about six times faster than the parallel implementation of SHREC on the four-processor machine we used for testing. The space consumption is comparable with Reptile and lower than that of SHREC for all tests. Nevertheless, we plan to improve the time and space of our algorithm by providing a parallel implementation. This and other further research directions are presented in Section 4 together with a summary of the achievements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Strings and suffix arrays</head><p>This section contains the basic definitions for strings and recalls the suffix array data structure. Consider the alphabet of four bases ={A,C,G,T}. A string is any finite sequence over. The set of all strings over is denoted by * . The length of a string s is denoted by |s| and, for 1 ≤ i ≤|s|, s<ref type="bibr">[i]</ref>is the i-th letter of s. A substring of s is any consecutive sequence of letters from s, i.e. s<ref type="bibr">[i..j]</ref>=s<ref type="bibr">[i]</ref>s<ref type="bibr">[i+1]</ref>...s<ref type="bibr">[j]</ref>; in particular, for |s|=m, s = s<ref type="bibr">[1..m]</ref>. For i = 1 we obtain a prefix and for j = m a suffix of s. The reverse complement ¯ s of s is obtained by first reversing s and then applying the transformation A ↔ T,C ↔ G. For example, if s = CAT, then ¯ s = ATG. Clearly, ¯ ¯ s = s. Let suf i denote the suffix s<ref type="bibr">[i..m]</ref>of s. Assuming a total order on the alphabet , the suffix array of s, denoted SA, gives the increasing lexicographical order of the suffixes of s, i.e. suf SA<ref type="bibr">[1]</ref>&lt; suf SA<ref type="bibr">[2]</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; ... &lt;</head><p>suf SA<ref type="bibr">[m]</ref>. For example, the suffix array of the string ACTAACACTG is shown in the second column of<ref type="figure">Figure 1</ref>. The suffix array is often used in combination with the longest common prefix (LCP) array that gives the length of the longest common prefix between consecutive suffixes of SA, i.e. LCP<ref type="bibr">[i]</ref>is the length of the longest common prefix of suf SA<ref type="bibr">[i]</ref>and suf SA<ref type="bibr">[i−1]</ref>; see the fourth column of<ref type="figure">Figure 1</ref>. By definition, LCP<ref type="bibr">[1]</ref>=0. The suffix array data structure has been introduced by<ref type="bibr" target="#b23">Manber and Myers (1993)</ref>; the SA array can be computed in O(m) time and space by any of the algorithms of<ref type="bibr" target="#b13">Kärkkäinen and Sanders (2003);</ref><ref type="bibr" target="#b15">Kim et al. (2005)</ref>;<ref type="bibr" target="#b16">Ko and Aluru (2005)</ref>; the LCP array can be computed also in O(m) time and space by the algorithm of<ref type="bibr" target="#b14">Kasai et al. (2001)</ref>. However, suboptimal algorithms exist that behave much better in practice. We have used the libdivsufsortthe reads came from is shown at the bottom. The letter (inside the frame) following the witness u = CTGTTGTCTC (underlined) should be T and not A. The support values are supp(u,T) = 5 and supp(u,A) = 1. If we omit the gray part, then the remaining suffixes are lexicographically sorted, as in SA. library of Yuta Mori 1 in our program. Also, since we need only bounded LCP values, we preferred a direct computation of the LCP, thus avoiding (<ref type="bibr" target="#b14">Kasai et al., 2001</ref>) altogether.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Basic idea for correcting errors</head><p>The basic idea for correcting errors in reads is intuitively explained below. Consider a genome G of length L that will be modeled as a random string over , where each letter appears with equal probability 0.25. Assume also that n reads, r 1 ,r 2 ,...,r n , each of length , have been produced from G with the per-base error p. That is, each read has been obtained by randomly choosing a substring of length of G and then changing each letter into any of the other three with equal probability p 3. (Reads containing any letter not in are discarded.) We call the position erroneous if its letter is different from the corresponding one in the genome and correct otherwise. We construct the string of all reads and their reverse complements</p><formula>R = r 1 $ ¯ r 1 $r 2 $ ¯ r 2 $ ... r n $ ¯ r n $ ,</formula><p>where $ is a letter not in. Denote the suffix array and longest common prefix array of R by SA and LCP, respectively. The basic idea for correcting an erroneous position in a read is as follows.</p><p>Assume that the read r i , sampled starting on position j of the genome, contains an error in position k and that the previous w positions, r i [k −w..k −1], are correct. That is r i = xuay, where x,u,y ∈ * ,|x|=k −w−1, |u|=w and a ∈. The letter a is different from the letter b = G [j +k −1] that actually appears in the genome. However, many other reads will have sampled that region correctly, i.e. they contain the correct substring ub. The fact that u is followed more often by b than by a will let us suspect that a should actually be b and, if the evidence is strong enough, we shall replace a by b. The string u is witnessing that a is an error and also that it should be changed into b. Formally, a witness is any substring u of R, of an a priori fixed length w, such that u contains no occurrence of $. For a ∈ , the support of u for a, supp(u,a), is the number of occurrences of the string ua in R. See<ref type="figure" target="#fig_0">Figure 2</ref>for an example. Our algorithm consists of computing the support values and using them, based on thorough statistical analysis, to correct erroneous bases. Note that our support values are similar with the weights of the suffix tree vertices in SHREC. The similarity with SHREC stops here as we use more efficient data structures for computation and completely different procedure for correcting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Statistical analysis</head><p>We now formalize the idea in the previous section. For a given witness u, we define the cluster of u as the set of all positions in R where an occurrence of u followed by a letter different from $ starts. The size of this cluster is clust(u) = a∈ supp(u,a) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 297 295–302</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HiTEC</head><p>All these positions are consecutive in SA and so are all occurrences of u supporting the same letter. This makes it easy to compute the support values and cluster size, given the suffix array. The clusters, corresponding to witnesses of a given length w, are easily found using the LCP values: a cluster consists of all consecutive positions with LCP values w or higher so that the (w+1)st letter is not $. In<ref type="figure" target="#fig_0">Figure 2</ref>, the occurrences of a witness are shown in the order in which they appear in the suffix array. Assume for now that any witness u of length w does not appear elsewhere in the genome since additional occurrences would make the identification of the errors more difficult. Due to repeats in the genome, this may not be possible but what we can do is reduce the probability of random occurrences in our Bernoulli model. We have two competing goals here. A long u will be less likely to appear again in G but will be covered by fewer reads, thus reducing its useful support. We shall return to this issue. We first estimate the support given by a witness u to a letter a following it. We need to distinguish between the case when the witness contains errors and when it does not. As a witness may appear with errors in some reads and without errors in others, precise definitions are needed. A witness is correct if it occurs as a substring of G and erroneous otherwise. Consider the case of a correct witness u = G [i..i+w−1] supporting a correct letter a = G<ref type="bibr">[i+w]</ref>. A read covering both has to start within the interval<ref type="bibr">[</ref></p><formula>Prob(R c = k) = n k q k c (1−q c ) n−k</formula><p>and thus the expected number of pairs (u,a), both u and a correct, given that supp(u,a) = k, is</p><formula>W c (k) = n k q k c (1−q c ) n−k L .</formula><p>Assume next that w is correct but a is an error. We now need those reads covering ua that have no error inside u but the original letter in a's position, say b, has been replaced by a. Again, there are −w positions where they can start but the probability that a given read starting in that interval has the errors exactly as specified is q e = −w</p><formula>Prob(R e = k) = n k q k e (1−q e ) n−k .</formula><p>The expected number of such (u,a) pairs, u correct, a erroneous, given that supp(u,a) = k, is</p><formula>W e (k) = n k q k e (1−q e ) n−k L .</formula><p>In the case when u is erroneous and a is correct, we may assume that u contains only one error, since otherwise the support is much lower. Then, we are interested in all the reads covering ua and containing the same error as u. Therefore, the reasoning is very similar with the one for the case when u is correct and a is erroneous. In the remaining case, when both u and a are erroneous, the support is much lower. The above analysis helps us compute a threshold, T , that will distinguish the support by a correct witness for a correct letter from the support when either the witness or the position, or both, are erroneous. Often, there is an interval of values k where both W e (k) and W c (k) are very small and any T in this interval is good. Also, this interval grows when the error rate decreases and hence a good value of T remains good when some of the errors have been corrected. An example is shown in<ref type="figure" target="#fig_2">Figure 3</ref>where the values of W e (k) and W c (k) are plotted for error 0.01 in the left plot; the right one shows the region where both W e (k) and W c (k) are very small. To cover also the case when such a region, with very low values of both W e (k) and W c (k), does not exist (as it happens for low coverage), we increase the value of T by an experimentally computed constant of two:</p><formula>T = min({k | W c (k) &gt; W e (k)})+2 .</formula><formula>(1)</formula><p>A problem is that some reads will have their errors distributed in such a way that there are no w consecutive correct positions. That makes it(k) and W e (k) for L = n = 4.2 mil., = 70, w = 21, p = 0.01 are shown in the left plot, whereas the right one shows the region of the left one where the values of both W c (k) and W e (k) are very low. The value of the threshold T in this example equals 9.</p><formula>f w (k,,) = ⎧ ⎪ ⎨ ⎪ ⎩ k , if &lt;w,</formula><formula>0, if k &lt; w , w i=1 f w (k −1,,−i), otherwise.</formula><p>Then, the expected number of such reads is</p><formula>f w (k,,)p k (1−p) −k n.</formula><p>These values for error rates 0.01, 0.02 and 0.03 are shown for a 4 MB genome in the left plot in<ref type="figure" target="#fig_3">Figure 4</ref>. The number of reads with k errors decreases with</p><formula>k but f w (k,</formula><p>,) increases and so the maximum is reached somewhere around 4–5 errors. We are interested in the total number of reads uncorrectable with a witness of length w, i.e.</p><formula>U(w) = k=1 f w (k,,)p k (1−p) −k n .</formula><p>The percentage this number represents, in our example in<ref type="figure" target="#fig_3">Figure 4</ref>, for a witness of length w = 21, out of the total number of expected erroneous reads, E e = (1−(1−p) )n, is 0.15 for p = 0.01, 0.87 for p = 0.02, and 2.56 for p = 0.03. We need to lower therefore the length of the witness in order to correct some of these reads. When the witness length is reduced to 18, the percentages drop to 0.02, 0.17 and 0.68, respectively (see the right plot in<ref type="figure" target="#fig_3">Fig. 4</ref>). However, another problem appears. The number of uncorrectable reads drops with the decrease of the witness length but the probability of the witness occurring more than once in the genome is no longer negligible causing correct positions to be wrongly changed as follows. Assume that ua appears in G and that ua is sampled by a read as va, that is, a is correct but u contains errors that change it into v. The length of v is also w and the Page: 298 295–302, for L = n = 4.2 mil., = 70 and p = 0.03. probability of v appearing in G is non-negligible. Assume v occurs in G at some position followed by b = a. Then the support given by v to b will be very large and to a very small, causing a to be changed, incorrectly, into b. We now approximate the number of such errors. We need that u has errors, a is correct, v appears in G and b = a. The probability for this to happen is</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Ilie et al.</head><formula>q w = (1−(1−p) w )(1−p) 1− 1− 1 4 w L 3 4 .</formula><p>The probability that at least one correct position in one read is changed this way is 1−(1−q w ) −w and the expected number of destructible reads, that is, correct reads the are turned erroneous this way is</p><formula>w m = argmin w (U(w)+D(w)) .</formula><formula>(2)</formula><p>It can be seen from<ref type="figure" target="#fig_4">Figure 5</ref>that the optimal values for p = 0.01,0.02,0.03 are w m = 19,17,16, respectively. Choosing w = w m provides, theoretically, the highest accuracy for the current iteration and a greedy strategy becomes apparent. However, it turns in out that a combination of values that are close to the optimal w m and the smallest w that causes essentially no correct reads to be changed, that is,</p><formula>w M = min({w | D(w) &lt; 0.0001E e }) ,</formula><formula>(3)</formula><p>works best in practice. While witnesses of length w M effectively correct all but the uncorrectable U(w M ) reads, those of length w m will create large enough stretches of consecutive correct positions inside an additional U(w M )−U(w m ) reads so that they become correctable by witnesses of length w M. Also, w M satisfies the conditions under which we computed the parameter T and hence it will be also used for this purpose. The sequence of witness lengths used in the HiTEC algorithm, denoted w seq = w seq<ref type="bibr">[1..9]</ref>, is:</p><formula>w m +1,w M +1,w M +1,w m ,w M ,w M ,w m −1,w M −1,w M −1 .</formula><formula>(4)</formula><p>Finally, some reads will contain several errors that often require several iterations of our correcting procedure. Instead of estimating at the beginning the number of iterations needed, it is more reliable to stop the process when the number of corrected positions in a single iterations drops below a certain threshold. Such an approach, with an experimentally computed value for the threshold will be used in our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">The algorithm</head><p>The pseudo code of the HiTEC algorithm that results from the above reasoning in shown in<ref type="figure" target="#fig_5">Figure 6</ref>. Note that only L and p are required as input parameters. An approximate value for L is probably known before the experiment. If not, then L can be estimated by a biological experiment or an expectation–maximization procedure [such as in (<ref type="bibr" target="#b25">Myers, 2005)]</ref>. An approximate value of p should be known from the machine that does the sequencing. HiTEC (r 1 ,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..,r n )</head><p>given: n reads r 1 ,...,r n (of length each); L and p output: n corrected reads(4) 7. construct R and compute SA and LCP 8. compute the clusters in SA for all witnesses of length w 9. for each witness u with clust(u) ≥ T +1 do 10. Corr ←{a | supp(u,a) ≥ T } 11. Err ←{a | supp(u,a) ≤</p><formula>. c ← c+1 21. i ← i+1 22. until ( c n &lt; 0.0001) or (i &gt; 9)</formula><p>23. return all r j 's from RAs previously mentioned, in Step 7, we used for the construction of the SA array the libdivsufsort library, the state-of-the-art algorithm for suffix array construction, which is significantly faster and more space efficient than the theoretically optimal algorithms. For the LCP array, we only need to check in Step 8 whether the LCP values are smaller or larger than w. We eliminate the need to store the LCP array by employing a direct computation of these values. Cache effects ensured that the time remains essentially the same. For each witness u with a large enough cluster, the sets of correct and erroneous letters supported by u are built in Steps 10–11. If there is no ambiguity, then we correct in Step 14. If there is ambiguity, then we check also the next two letters (Step 18) in order to decide how to correct. In either case, the position of a in the string R corresponds to a position inside a read r (which can be some r j or ¯ r j ) and we correct both r and its reverse</p><formula>complement ¯ r.</formula><p>The procedure stops when the number of bases changed during one iteration drops below 0.01% of the total number of bases (Step 22). In any case, no more than nine iterations are performed. This last condition is necessary since the ratio between the number of bases changed in one iteration and the total number of bases becomes less reliable as an indicator of the actual number of corrected reads when the number of iterations increases. One practical improvement not mentioned in the algorithm is that, due to the excellent performance of HiTEC for modest coverage, datasets of high coverage can be split into several sets of lower coverage that are independently corrected, thus saving space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Accuracy</head><p>The accuracy is defined as the ratio between the number of corrected reads and the number of initially erroneous reads. The erroneous/correct status of each read (before and after correcting) has been determined by a straightforward search (using suffix arrays) of all reads in the genome sequence. To be precise,. If we denote by TP,TN,FP,FN (true/false positive/negative) the number of erroneous reads that are corrected, correct reads that are left unchanged, correct reads that are wrongly changed and erroneous reads that are left unchanged, respectively, then we have err bef = TP +FN, err aft = FP +FN and therefore</p><formula>accuracy = err bef −err aft err bef = TP −FP TP +FN .</formula><p>We have compared the accuracy of our algorithm on quite a number of datasets, 2 including those of<ref type="bibr" target="#b33">Schroder et al. (2009</ref><ref type="bibr" target="#b34">), Shi et al. (2010</ref><ref type="bibr" target="#b38">) and Yang et al. (2010</ref>. All programs have been run with default parameters. Several bacterial genomes, see<ref type="figure" target="#tab_1">Table 1</ref>, were downloaded from GenBank under the accession numbers given. Later on we shall refer to these genomes by the IDs given in parentheses in the first column. To be precise, we constructed a number of datasets by uniformly sampling reads with given length, coverage and per-base error rate from the above genomes. The datasets can be considered identical with those of<ref type="bibr" target="#b33">Schroder et al. (2009) and</ref><ref type="bibr" target="#b34">Shi et al. (2010)</ref>because they have been generated from the same genomes with the same parameters. Experiments show that the differences between the accuracy of a program on different datasets generated with the same parameters as above are insignificant. The datasets used by<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>are shown in<ref type="figure" target="#tab_2">Table 2</ref>, those of<ref type="bibr" target="#b34">Shi et al. (2010)</ref>in<ref type="figure" target="#tab_3">Table 3</ref>, and<ref type="figure" target="#tab_4">Table 4</ref>contains a mixture of read lengths and coverage levels taken from the longest genome considered.<ref type="figure" target="#tab_5">Table 5</ref>contains several real sets of Illumina reads. The first real dataset was used also by<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>; it is available from www.genomic.ch/edena.php and it was previously used by<ref type="bibr" target="#b9">Hernandez et al. (2008)</ref>. Both the first and the second real datasets were used by<ref type="bibr" target="#b34">Shi et al. (2010)</ref>. The second one is available from sharcgs.molgen.mpg.de/download.shtml and it was used initially by<ref type="bibr" target="#b7">Dohm et al. (2007)</ref>. The third one is new and is available from clcbio.com/index.php?id=1290, the CLCbio website, as an example of NGS data. The reads in each of the first three dataset were selected using RMAP (<ref type="bibr" target="#b36">Smith et al., 2008</ref>) as previously done, according to Schmidt (Personal communication):The read length is 70 bp and coverage is 70 for all datasets.The read length is 35 bp and coverage is 70 for all datasets.</p><p>The per-base error rate was computed by counting the total number of mismatches from the output file of RMAP. The fourth real dataset has been suggested by one of the reviewers as a most recent example of Illumina reads. It has accession number ERA000206. Due to its very large size, the SHREC program could not produce any results. The performance of HiTEC is very high in spite of the fact that no selection of the reads using RMAP has been done such as for the previous three real datasets.<ref type="figure" target="#tab_6">Table 6</ref>contains the relevant datasets from<ref type="bibr" target="#b38">Yang et al. (2010)</ref>. A common feature of the sets of reads in the Sequence Read Archive (SRA, http://www.ncbi.nlm.nih.gov/sra) is that the sequence of the genome from which the reads were sequenced is not known and therefore, considering another genome instead can produce misleading results. Out of the datasets of<ref type="bibr" target="#b38">Yang et al. (2010)</ref>, the percentage of the reads that can be mapped on the indicated reference genome is around 97% for the first two datasets and around 60–70% for the other ones. This is a clear indication thatthe genomes for the last four datasets are not the actual genomes that produced the reads. Therefore, we could meaningfully use only the first two. In Tables 2–5, the 'SHREC' column gives the accuracy values we obtained by running the SHREC program, whereas the values in the 'SHRECpaper' column are taken from<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>. The values in the 'CUDA' column are taken from<ref type="bibr" target="#b34">Shi et al. (2010)</ref>, that is, we did not test the program. [The values are missing for tests not performed by<ref type="bibr" target="#b34">Shi et al. (2010)]</ref>. Several comments are in order. First, the accuracy of HiTEC is significantly higher than that of all the other programs for all experiments. The difference is significantly higher for the real datasets. While the accuracy of HiTEC is similar to the case of simulated data and is not affected by the error rate or coverage, CUDA's accuracy is much lower compared with the simulated data and SHREC's accuracy decreases dramatically with the increase of the error rate. Reptile's accuracy is comparable to that of SHREC when quality scores are unavailable (<ref type="figure" target="#tab_2">Table 2</ref>) and still significantly below the accuracy of HiTEC even when using quality scores (<ref type="figure" target="#tab_6">Table 6</ref>). HiTEC performs particularly better for lower coverage. Second, there is a significant difference, which increases with genome length and error rate, between the accuracy of SHREC as resulting from our testing of the software and that provided by<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>. This is due to the fact that Schroder et al.<ref type="bibr" target="#b33">Schroder et al. (2009)</ref>. Anyway, the accuracy of HiTEC is significantly higher than all the other accuracy values. Third, the SHREC program was run with the same number of iterations as ours, as resulted from the stopping criterion in Step 22. In most cases, the accuracy of HiTEC after one or two iterations is already higher than that of SHREC after nine iterations. Similarly with SHREC, the parameters of Reptile are fixed. That means they do not adapt to the data. As a result, Reptile could not correct any errors of the fourth dataset from<ref type="figure" target="#tab_5">Table 5</ref>. One last remark, our measure, accuracy, is different from the gain of<ref type="bibr" target="#b38">Yang et al. (2010)</ref>. For the datasets considered in<ref type="figure" target="#tab_6">Table 6</ref>, the gain for HiTEC is 83.33 and 82.22, respectively, whereas Reptile produces 82.81 and 72.53. So, gain indicates again that HiTEC has better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L.Ilie et al.</head><formula>(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Time and space</head><p>In addition to obtaining very high accuracy, our algorithm has also very good time and space complexities, due to the use of good data structures. The tests shown in<ref type="figure" target="#tab_7">Table 7</ref>were performed for the datasets in<ref type="figure" target="#tab_2">Table 2</ref>on a Sun Fire V440 Server, with four UltraSPARC IIIi processors at 1593 MHz, 4 GB RAM each, running SunOS 5.10. Our serial implementation of HiTEC is about six times faster than the multithreaded SHREC. The space required by our algorithm is comparable to that of Reptile and both are lower than SHREC's. Reptile is slightly faster; however, the running time of HiTEC includes many iterations. In fact, HiTEC achieves higher accuracy sooner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Very large genomes</head><p>We have also performed measurements to predict the ability of our algorithm to correct errors in the case of very large genomes. We plotted in<ref type="figure" target="#fig_9">Figure 7</ref>, the percentage of U(w)+D(w) (uncorrectable plus destructible reads) for genome size 1 GB. We used two common read lengths from Illumina: 75 and 100. In practice, the error rate increases with read length but so does our algorithm's performance, only faster. While for reads of size 35 the ratio of those that can be corrected decreases below 50% for very large genomes, the situation is much better already for read size 50. In a 1 GB genome, for an error rate of 0.01 and a read length 50, our algorithm can correct up to 97.72% of the erroneous reads but when we increase the read length to 100, we can correct up to 97.70% even for a very high error rate of 0.03.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION AND FUTURE RESEARCH</head><p>The main goal of this article is to provide an algorithm that is highly efficient at correcting the errors of high-throughput sequencing technologies. According to the extensive testing we have performed, our algorithm exceeds significantly the accuracy of previous algorithms. Also, a thorough statistical analysis makes our program the only one that is able to automatically adjust to the input data. The testing has been done on Illumina reads but the approach is suitable for any type of reads for which the errors consist mainly of substitutions. The ability of our program to correct increases with the length of the reads and, according to<ref type="bibr" target="#b40">Zhou et al. (2010)</ref>, the read length is going to grow with the third generation of sequencing technologies, such as single molecule sequencing or nanopore sequencing. We therefore hope that our program will be very competitive even with the rapid change of sequencing technologies. We plan to work on a parallel implementation which will be able to handle the even more massive outputs to come. The new implementation will be capable of dealing with all types of reads as well as with mixed sets of reads. Quality scores as well as additional knowledge of the bias of the sequencing devices concerning the actual distribution of the positions of the reads in the genome could help us improve further the accuracy of our algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.2.</head><figDesc>Fig. 2. An example of an error covered by six reads; the genome region where the reads came from is shown at the bottom. The letter (inside the frame) following the witness u = CTGTTGTCTC (underlined) should be T and not A. The support values are supp(u,T) = 5 and supp(u,A) = 1. If we omit the gray part, then the remaining suffixes are lexicographically sorted, as in SA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>The number R e of such reads has the probability distribution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. The values of W c (k) and W e (k) for L = n = 4.2 mil., = 70, w = 21, p = 0.01 are shown in the left plot, whereas the right one shows the region of the left one where the values of both W c (k) and W e (k) are very low. The value of the threshold T in this example equals 9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. The number of reads with a given number of errors and no error-free interval of length w for L = n = 4.2 mil. and = 70. The left plot uses w = 21 and the right w = 18. impossible to fit a correct witness at any position and therefore such reads cannot be corrected using the current procedure. We approximate first their number and then adjust the algorithm to correct most of those as well. Denote by f w (k,,) the number of possible ways to place k errors in a read of length such that any interval of length w contains at least one error. The value of f w (k,,) can be easily computed using this recursive formula:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.5.</head><figDesc>Fig. 5. The values of U(w)+D(w) as percentages of the total number of erroneous reads, E e , for L = n = 4.2 mil., = 70 and p = 0.03.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.6.</head><figDesc>Fig. 6. The HiTEC algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>The genomes used for comparison Reference genome (ID) Accession no. Len.(bp) Saccharomyces cerevisiae, Chr. 5 (S.cer5) NC_001137 576 869 Saccharomyces cerevisiae, Chr. 7 (S.cer7) NC_001139 1 090 946 Haemophilus influenzae (H.inf) NC_007146 1 914 490 Escherichia coli str.K-12 substr.MG1655 (E.coli) NC_000913 4 639 675 Escherichia coli str.K-12 substr.DH10B (E.coli2) NC_010473 4 686 137 Staphylococcus aureus (S.aureus) NC_003923 2 820 462 Helicobacter acinonychis (H.acinonychis) NC_008229 1 553 927 if the number of erroneous reads before and after correction is err bef and err aft , respectively, then accuracy is the ratio err bef −err aft err bef</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><figDesc>2009) try a number of parameters and the best accuracy obtained was reported. As already mentioned, in our testing we have not adjusted the parameters of any programs. Note also that the accuracy values from Shi et al. (2010) are higher than the values obtained by the tests of Euler-SR reported by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig.7.</head><figDesc>Fig. 7. The values of U(w)+D(w) as percentages they represent out of the total number of erroneous reads, E e , for L = n = 1 bil. The left plot uses read length = 75 and the right one = 100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>).</figDesc><table>L.Ilie et al. 

i SA[i] suf SA[i] 
LCP[i] 

1 
4 
AACACTG 
0 
2 
5 
ACACTG 
1 
3 
1 
ACTAACACTG 
2 
4 
7 
ACTG 
3 
5 
6 
CACTG 
0 
6 
2 
CTAACACTG 
1 
7 
8 
CTG 
2 
8 
10 
G 
0 
9 
3 
TAACACTG 
0 
10 
9 
TG 
1 

Fig. 1. The SA and LCP arrays for the string ACTAACACTG. The longest 
common prefixes of consecutive suffixes are underlined; their length gives 
the LCP values. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>i−+w+1..i] in G. The probability that a given read starts in this interval and contains no errors inside ua is q c = −w L (1−p) w+1. If R c is the number of such reads, then</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>D(w) = (1−(1−q w ) −w )(1−p) n. Thus, lowering the witness length w decreases the number U(w) of</figDesc><table>uncorrectable reads but increases the number D(w) of destructible reads. 
We therefore need the w that minimizes U(w)+D(w): 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>1. compute w M and w m // using (3) and (2), resp. 2. compute T // using (1) with w = w M 3. i ←</figDesc><table>1 
// iteration number 
4. repeat 
5. 
c ← 0 
// bases changed this iteration 
6. 
w ← w seq [i] 
// from </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>T −1} 12. for each a ∈ Err do 13. if (|Corr|=1) then 14. correct a to b ∈ Corr // change both r and ¯ r 15. c ← c+1 16. if (|Corr|≥2) then 17. for each b ∈ Corr do 18. if (ua, ub followed by same two letters) then 19. correct a to b // change both r and ¯ r 20</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 2. Accuracy comparison for the datasets of Schroder et al. (2009)</figDesc><table>Dataset 
Accuracy 

Genome Error (%) SHREC SHRECpaper CUDA Reptile HiTEC 

S.cer5 
1 
95.85 
95.70 
92.89 
99.79 
S.cer5 
2 
88.93 
90.50 
83.22 
99.55 
S.cer5 
3 
78.15 
84.00 
71.71 
99.40 
S.cer7 
1 
94.83 
95.30 
92.93 
99.74 
S.cer7 
2 
85.60 
90.00 
83.38 
99.58 
S.cer7 
3 
71.61 
83.30 
71.90 
99.39 
H.inf 
1 
91.21 
94.10 
87.50 93.00 
99.73 
H.inf 
2 
76.35 
88.20 
76.60 83.57 
99.50 
H.inf 
3 
55.84 
81.00 
63.60 72.08 
99.02 
E.coli 
1 
89.37 
93.50 
92.98 
99.75 
E.coli 
2 
71.38 
87.40 
83.45 
99.42 
E.coli 
3 
47.80 
80.00 
71.97 
99.22 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 3. Accuracy comparison for the datasets of (Shi et al., 2010)</figDesc><table>Dataset 
Accuracy 

Genome 
Error (%) 
SHREC 
CUDA 
HiTEC 

S.cer5 
1 
96.09 
83.50 
96.27 
S.cer5 
2 
93.43 
77.20 
96.90 
S.cer5 
3 
89.46 
69.90 
93.95 
S.cer7 
1 
95.31 
83.60 
95.76 
S.cer7 
2 
92.27 
77.20 
95.86 
S.cer7 
3 
88.13 
69.90 
93.48 
H.inf 
1 
93.34 
83.50 
96.39 
H.inf 
2 
89.45 
77.20 
94.80 
H.inf 
3 
83.93 
69.90 
89.83 
E.coli 
1 
91.50 
83.60 
94.41 
E.coli 
2 
87.06 
77.20 
94.37 
E.coli 
3 
80.76 
69.90 
91.13 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 4. Accuracy comparison between SHREC and HiTEC for a variety of read lengths, coverage levels and error rates sampled from the E.coli genome</figDesc><table>Dataset 
Accuracy 

Genome 
Read length 
Coverage 
Error (%) 
SHREC 
HiTEC 

E.coli 
70 
35 
1 
93.44 
99.75 
E.coli 
70 
35 
2 
87.87 
99.46 
E.coli 
70 
35 
3 
80.84 
99.25 
E.coli 
50 
50 
1 
93.44 
99.25 
E.coli 
50 
50 
2 
88.85 
98.75 
E.coli 
50 
50 
3 
83.65 
97.88 
E.coli 
50 
35 
1 
93.31 
99.27 
E.coli 
50 
35 
2 
89.20 
99.06 
E.coli 
50 
35 
3 
83.85 
97.91 
E.coli 
35 
50 
1 
91.60 
94.37 
E.coli 
35 
50 
2 
87.40 
94.37 
E.coli 
35 
50 
3 
82.32 
91.15 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>Table 5.</figDesc><table>Accuracy comparison for several real sets of Illumina reads 

Dataset 
Accuracy 

Genome 
Read Coverage Error SHREC SHRECpaper CUDA HiTEC 
length 
(%) 

S.aureus 
35 
42.5 
1.00 74.75 
88.30 
48.30 93.38 
H.acinonychis 36 
188.8 
1.60 34.83 
47.40 91.26 
E.coli2 
35 
17.8 
0.38 80.65 
90.40 
E.coli 
100 
574 
0.50 — 
87.49 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><figDesc>Table 6.</figDesc><table>Accuracy comparison between Reptile and HiTEC on two sets of 
reads from the E.coli genome that were used by Yang et al. (2010) 

Dataset 
Accuracy 

Accession number Read length Coverage Error (%) Reptile HiTEC 

SRX00429 
36 
160 
0.44 
84.32 86.17 
SRR001665_1 
36 
80 
0.38 
75.28 85.78 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> libdivsufsort: a lightweight suffix sorting library, http://code.google .com/p/libdivsufsort/.</note>

			<note place="foot" n="2"> Most of these tests were performed on the SHARCNET high performance computers: www.sharcnet.ca.</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [09:23 19/1/2011 Bioinformatics-btq653.tex]</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We would like to thank the anonymous reviewers for suggesting the fourth dataset inand for pointing out to us the Reptile program.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HiTEC</head><p>The read length is 70 bp and coverage is 70 for all datasets.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">09:23 19</title>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>btq653. .tex]</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">ALLPATHS: De novo assembly of whole-genome shotgun microreads</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Butler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="810" to="820" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">PASS: a program to align short sequences</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Campagna</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="967" to="968" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">De novo fragment assembly with short mate-paired reads: Does the read length matter?</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Chaisson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="336" to="346" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Assembly for double-ended short-read sequencing technologies Advances in Genome Sequencing Technology and Algorithms</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Skiena</surname>
			</persName>
		</author>
		<editor>Mardis,E. et al.</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Artech House Publishers</publisher>
			<biblScope unit="page" from="123" to="141" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">PerM: efficient mapping of short sequencing reads with periodic full sensitive spaced seeds</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2514" to="2521" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">SHARCGS, a fast and highly accurate short-read assembly algorithm for de novo genomic sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Dohm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1697" to="1706" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">MOM: maximum oligonucleotide mapping</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">H</forename>
				<surname>Eaves</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Gao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="969" to="970" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">De novo bacterial genome sequencing: millions of very short reads assembled on a desktop computer</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Hernandez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="802" to="809" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Extending assembly of short DNA sequences to handle error</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R</forename>
				<surname>Jeck</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2942" to="2944" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">SeqMap: mapping massive amount of oligonucleotides to the genome</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2395" to="2396" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">ProbeMatch: a tool for aligning oligonucleotide sequences</title>
		<author>
			<persName>
				<forename type="first">Jung</forename>
				<surname>Kim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1424" to="1425" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Simple linear work suffix array construction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kärkkäinen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Sanders</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICALP&apos;03</title>
		<meeting>ICALP&apos;03<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="943" to="955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Linear-time longest-common-prefix computation in suffix arrays and its applications</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kasai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CPM&apos;01</title>
		<meeting>CPM&apos;01<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="181" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Constructing suffix arrays in linear time</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">K</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Discrete Algorithms</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="126" to="142" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Space efficient linear time construction of suffix arrays</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Aluru</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Discrete Algorithms</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Ultrafast and memory-efficient alignment of short DNA sequences to the human genome</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Langmead</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Mapping short DNA sequencing reads and calling variants using mapping quality scores</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1851" to="1858" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">SOAP: short oligonucleotide alignment program</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="713" to="714" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast and accurate short read alignment with BurrowsWheeler transform</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1754" to="1760" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">ZOOM! Zillions of oligos mapped</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2431" to="2437" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Slider-maximum use of probability information for alignment of short sequence reads and SNP detection</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Malhis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="6" to="13" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Suffix arrays: a new method for on-line search</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Manber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="935" to="948" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">The impact of next-generation sequencing technology on genetics</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">R</forename>
				<surname>Mardis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Genet</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="133" to="141" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Building fragment assembly string graphs</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">SHRiMP: accurate mapping of short color-space reads</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">M</forename>
				<surname>Rumble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000386</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Correction of sequencing errors in a mixed set of reads</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Salmela</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1284" to="1290" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">DNA sequencing with chain-terminating inhibitors</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Sanger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="page" from="5463" to="5467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Cloudburst: highly sensitive read mapping with mapreduce</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Schatz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1363" to="1369" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">091</biblScope>
			<biblScope unit="page" from="23" to="42" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ilie</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">SHREC: a short-read error correction method</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schroder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2157" to="2163" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">A parallel algorithm for error correction in high-throughput shortread data on CUDA-enabled graphics hardware</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="603" to="615" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">ABySS: a parallel assembler for short read sequence data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1117" to="1123" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Using quality scores and longer reads improves accuracy of Solexa read mapping</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">D</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">128</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Assembling millions of short DNA sequences using SSAKE</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Warren</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Rl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="500" to="501" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Reptile: representative tiling for short read error correction</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2526" to="2533" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Velvet: algorithms for de novo short read assembly using De Bruijn graphs</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Zerbino</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Birney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="821" to="829" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">The next-generation sequencing technology: a technology review and future perspective</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. China</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="44" to="57" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>