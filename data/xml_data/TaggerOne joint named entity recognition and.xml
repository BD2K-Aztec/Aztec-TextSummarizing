
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining TaggerOne: joint named entity recognition and normalization with semi-Markov Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Robert</forename>
								<surname>Leaman</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information</orgName>
								<address>
									<addrLine>8600 Rockville Pike</addrLine>
									<postCode>20894</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Zhiyong</forename>
								<surname>Lu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information</orgName>
								<address>
									<addrLine>8600 Rockville Pike</addrLine>
									<postCode>20894</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining TaggerOne: joint named entity recognition and normalization with semi-Markov Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw343</idno>
					<note type="submission">Received on February 16, 2016; revised on May 2, 2016; accepted on May 26, 2016</note>
					<note>*To whom correspondence should be addressed. Associate Editor: Jonathan Wren Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Text mining is increasingly used to manage the accelerating pace of the biomedical literature. Many text mining applications depend on accurate named entity recognition (NER) and normalization (grounding). While high performing machine learning methods trainable for many entity types exist for NER, normalization methods are usually specialized to a single entity type. NER and normalization systems are also typically used in a serial pipeline, causing cascading errors and limiting the ability of the NER system to directly exploit the lexical information provided by the normalization. Methods: We propose the first machine learning model for joint NER and normalization during both training and prediction. The model is trainable for arbitrary entity types and consists of a semi-Markov structured linear classifier, with a rich feature approach for NER and supervised semantic indexing for normalization. We also introduce TaggerOne, a Java implementation of our model as a general toolkit for joint NER and normalization. TaggerOne is not specific to any entity type, requiring only annotated training data and a corresponding lexicon, and has been optimized for high throughput. Results: We validated TaggerOne with multiple gold-standard corpora containing both mention-and concept-level annotations. Benchmarking results show that TaggerOne achieves high performance on diseases (NCBI Disease corpus, NER f-score: 0.829, normalization f-score: 0.807) and chemicals (BioCreative 5 CDR corpus, NER f-score: 0.914, normalization f-score 0.895). These results compare favorably to the previous state of the art, notwithstanding the greater flexibility of the model. We conclude that jointly modeling NER and normalization greatly improves performance. Availability and Implementation: The TaggerOne source code and an online demonstration are available at: http://www.ncbi.nlm.nih.gov/bionlp/taggerone Contact: zhiyong.lu@nih.gov</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many tasks in biomedical information extraction rely on accurate named entity recognition (NER), the identification of text spans mentioning a concept of a specific class, such as disease or chemical. Recent research has demonstrated that a particular NER approach—namely, conditional random fields with a rich feature set— consistently achieves high performance on a variety of NER tasks when provided with an appropriate training corpus and a relatively small investment in feature engineering. This approach has been used to identify a wide variety of entities, including genes and proteins (<ref type="bibr" target="#b26">Leaman and Gonzalez, 2008;</ref><ref type="bibr" target="#b45">Wei et al., 2015a</ref>), diseases (<ref type="bibr" target="#b4">Chowdhury and Lavelli, 2010;</ref><ref type="bibr" target="#b25">Leaman et al., 2013</ref>), chemicals. (<ref type="bibr" target="#b29">Leaman et al., 2015b;</ref><ref type="bibr" target="#b38">Rocktaschel et al., 2012</ref>) and anatomic entities (<ref type="bibr" target="#b36">Pyysalo and Ananiadou, 2014</ref>). However many end-user tasks also require normalization (grounding), the identification of the concept mentioned within a controlled vocabulary or ontology, making the utility of NER on its own relatively low. We recently demonstrated DNorm, the first machine learning based method for disease normalization (<ref type="bibr" target="#b25">Leaman et al., 2013</ref>). This method used supervised semantic indexing (<ref type="bibr" target="#b1">Bai et al., 2010</ref>), trained with pairwise learning to rank, to score the mentions returned by a conditional random field NER system, BANNER (<ref type="bibr" target="#b26">Leaman and Gonzalez, 2008</ref>), against the disease names from a controlled vocabulary. The method focuses primarily on semantic term variation, such as when an author refers to the concept 'renal insufficiency' with the phrase 'decreased renal function.' Our experiments demonstrated the method to be highly effective for disease normalization. Like many normalization systems, however, DNorm uses a pipeline architecture: the tasks of NER and normalization are performed serially, making errors cascading from one component to the next a common problem. Our error analysis of DNorm, for example, demonstrated that over half of the overall system errors were caused by NER errors that the normalization component could not recover. One way to overcome cascading errors is to perform NER and normalization simultaneously. Dictionary systems do this by directly matching text to the names in a controlled vocabulary. Unfortunately, NER systems employing machine learning typically have higher performance. To the best of our knowledge, a machine learning method that trains a joint model of NER and normalization has not been previously proposed. In this work, we propose a model that simultaneously performs NER and normalization—focusing on term variation—during both training and prediction. We evaluate our model on two corpora containing both mention and concept annotations; one contains disease entities, the other contains both disease and chemical entities.<ref type="figure" target="#fig_0">Figure 1</ref>provides an example text with both disease and chemical annotations. We achieve state-of-the-art performance on both diseases and chemicals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Named entity recognition (NER) and normalization have long been recognized as important tasks within biomedical text mining. Both tasks have been the subject of community challenges (<ref type="bibr" target="#b15">Hirschman et al., 2005;</ref><ref type="bibr" target="#b19">Kim et al., 2009;</ref><ref type="bibr">Krallinger et al., 2015a,b;</ref><ref type="bibr" target="#b32">Morgan et al., 2008</ref>). The development of NER and normalization systems for diseases lagged behind genes and proteins for some time, primarily due to the lack of annotated corpora.<ref type="bibr" target="#b17">Jimeno et al. (2008)</ref>created a corpus of sentences that was expanded by<ref type="bibr" target="#b27">Leaman et al. (2009)</ref>; this was further expanded to become the NCBI Disease Corpus (<ref type="bibr" target="#b9">Do gan et al., 2014</ref>). Diseases were also included in the set of entities annotated in the CALBC silver standard corpus (<ref type="bibr" target="#b37">Rebholz-Schuhmann et al., 2010</ref>). Several rule or dictionary based systems have used these disease corpora for evaluation of NER (<ref type="bibr" target="#b3">Campos et al., 2013;</ref><ref type="bibr" target="#b40">Song et al., 2015</ref>) or normalization (<ref type="bibr" target="#b18">Kang et al., 2012</ref>). Our previous work DNorm demonstrated significantly higher normalization performance when using a machine learning model (supervised semantic indexing) trained with pairwise learning to rank (<ref type="bibr" target="#b25">Leaman et al., 2013</ref>). Most recently, the Chemical Disease Relation task at the BioCreative V community challenge included disease normalization as a subtask (<ref type="bibr" target="#b31">Li et al., 2015;</ref><ref type="bibr">Wei et al., 2015a,c</ref>). The development of chemical NER and normalization systems was initially enabled by rigorous standards for the chemical nomenclature. The OSCAR system normalizes many varieties of chemical mentions, and is intended for mining chemistry publications (<ref type="bibr" target="#b16">Jessop et al., 2011</ref>).<ref type="bibr" target="#b21">Kolarik et al. (2008)</ref>created the SCAI corpus of chemical mentions,<ref type="bibr" target="#b20">Klinger et al. (2008)</ref>used this to train and evaluate a machine learning approach for chemical NER.<ref type="bibr" target="#b38">Rocktaschel et al. (2012)</ref>expanded the machine learning approach with extensive lexical resources. Chemicals were also included in the CALBC silver standard corpus (<ref type="bibr">RebholzSchuhmann et al., 2010</ref>). The CHEMDNER task at BioCreative IV addressed chemical NER, releasing a large corpus of chemical mentions in PubMed abstracts (<ref type="bibr" target="#b22">Krallinger et al., 2015a</ref>), where our submission tmChem achieved the highest performance out of 27 teams (<ref type="bibr" target="#b29">Leaman et al., 2015b</ref>). The CHEMDNER task at BioCreative V also addressed chemical NER, but changed the domain to patents (<ref type="bibr" target="#b23">Krallinger et al., 2015b</ref>). Two recent surveys of the field are<ref type="bibr" target="#b44">Vazquez et al. (2011)</ref>and Eltyeb and Salim (2014). Our method builds successfully on previous work in NER and normalization. Cohen and<ref type="bibr" target="#b5">Sarawagi (2004)</ref>were the first to apply semi-Markov models to NER, motivated by a need to integrate softmatch dictionary features.<ref type="bibr" target="#b33">Okanohara et al. (2006)</ref>later applied semiMarkov models to the biomedical domain.<ref type="bibr" target="#b42">Tsuruoka et al. (2007)</ref>is a method for learning term variation, trained directly from a lexicon using similarity measures as features. DNorm instead learned the similarity between individual tokens directly from training data (<ref type="bibr" target="#b25">Leaman et al., 2013</ref>). The advantage of joint learning has been demonstrated for many tasks. For example, Finkel and Manning (2009) learned a joint model for parsing and NER in newswire text, while Durrett and Klein (2014) learned a model for joint coreference resolution, named entity classification and entity linking (disambiguation) when the named entity spans were provided as input. Recently,<ref type="bibr" target="#b24">Le et al. (2015)</ref>proposed a model that performs joint NER and normalization for diseases in biomedical text during prediction, but not during training. Our system is the first, to our knowledge, that performs joint NER and normalization during both training and prediction. In addition, our system is open source, trainable for arbitrary entity types and optimized for high throughput.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In this section we describe our model for joint NER and normalization. We describe the preprocessing steps used and the lexicons employed. We detail our joint model, describing the features used, how it is trained and used for prediction. We also describe the disambiguation steps performed. An overview of the TaggerOne system is provided in<ref type="figure" target="#fig_2">Figure 2</ref>. Finally, we describe the state-of-the-art open source systems used for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>We use Ab3P to identify abbreviations within each document (<ref type="bibr" target="#b39">Sohn et al., 2008</ref>), and then replace each instance of the short form (e.g.'CT') with the corresponding long form ('copper toxicosis'). We use SimConcept to identify composite mentions (e.g. 'cleft lip/palate') and resolve them into their component parts ('cleft lip' and 'cleft palate') (<ref type="bibr" target="#b45">Wei et al., 2015a</ref>). We also segment text into sentences. We use two tokenization approaches. For diseases, we segment tokens at whitespace and separate punctuation characters into individual tokens. For chemicals, we also separate tokens at letter/digit boundaries and lowercase to uppercase boundaries. When jointly modeling chemicals and diseases, we use the same strategy as for chemicals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Joint modeling of NER and normalization</head><p>NER is often handled as a sequence labeling problem and frequently addressed with Markov models. These models derive their name from the Markov property, which asserts that the current label in the output is independent of all other labels except the one preceding. Markov models assign a label to each token in the input sequence; an example text is shown in<ref type="figure">Figure 3</ref>. In this work, we approach joint NER and normalization using semi-Markov models. These models assign labels to contiguous subsequences (segments) of variable length, as shown in<ref type="figure">Figure 3</ref>. Like Markov models, semi-Markov models obey the Markov property between transitions, but—unlike Markov models—do not require a transition for each token. Because segmentation is part of the model, semi-Markov models enable features that integrate information across all tokens in the segment. We exploit this ability to simultaneously learn a normalization scoring function, enabling the creation of a practical model for joint NER and normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Problem statement</head><p>After preprocessing, our input consists of a sequence of tokens. The objective of our model is to divide this sequence into segments, each consisting of one or more tokens and assign a class to each. Since we are performing NER and normalization simultaneously, the class must indicate both the NER and normalization. Each segment must therefore specify the NER label (such as Disease) and both the name and entity mentioned by the text. We extend the formal problem statement of Cohen and Sarawagi (2004) describing semi-Markov models for NER to our task of joint NER and normalization. Specifically, let X ¼ X 1 ;. .. ; X X j j À Á represent an input text as a sequence of tokens. Let L be the set of NER labels (including a special non-entity label, Other). Let N ' and E ' be respectively the set of names and entities in the lexicon for label ' 2 L. Let entity : N ! E be the mapping defined by the lexicon from names to entities, which we assume to associate each name n 2 N ' with exactly one entity e 2 E '. Let Y ¼ Y 1 ;. .. ; Y Y j j be a segmentation of X. Each segment Y j 2 Y is a 5-tuple consisting of: 1. The index of the first token in the segment, a j : 0 a j X j j 2. The (exclusive) index of the last token, b j : a j &lt; b j X j j þ 1 3. The NER label, ' j 2 L 4. The lexicon name, n j 2 N 'j ; if ' j ¼ Other then n j ¼ 1 5. The entity, e j ¼ entityðn j Þ; if ' j ¼ Other then e j ¼ 1</p><p>Note that segmentations which have the same NER information (segment indices and NER labels) but differ in any of the normalization information (lexicon name or entity) are not equivalent. A segmentation is valid if all tokens from X are used exactly once, in order, and if the length of all segments with label Other is exactly one token. Let Y X ð Þ be the set of all valid segmentations of X. According to our definitions, the segmentation for the example text shown in<ref type="figure">Figure 3</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Model description</head><p>We define a scoring function over the set of valid segmentations Y X ð Þ, so that the task of prediction becomes finding the segmentation Y 2 Y X ð Þ with the highest score:</p><formula>f X ð Þ ¼ argmax Y2Y X ð Þ score Y; s; t; W ð Þ</formula><p>where s, t and W are the parameter weights of the model, to be defined. We define the score for a segmentation Y as the sum of the scores for each segment:</p><formula>score Y; s; t; W ð Þ¼ X Y j j j¼0 score Y j ; s; t; W À Á</formula><p>Under this formulation, the highest-scoring segmentation can be found efficiently using a modification of the Viterbi algorithm (fully described in the supplemental material). We perform NER and normalization simultaneously by defining the score for each segment Y j to be the sum of its NER and normalization scores:</p><formula>score Y j ; s; t; W À Á ¼ score NER Y j ; s À Á þ score Norm Y j ; t; W À Á</formula><p>We model the NER scoring function as a structured classification problem using a multi-class linear classifier, similar to previous work using structured perceptrons or support vector machines (<ref type="bibr" target="#b0">Altun et al., 2007;</ref><ref type="bibr" target="#b6">Crammer and Singer, 2001;</ref><ref type="bibr" target="#b41">Taskar et al., 2004</ref>) with a rich feature approach. This approach learns one weight vector per label ' j 2 L, constrained so that the correct label for any given segment willof NER and normalization is performed by scoring all text segments against each NER class and name in the lexicon<ref type="figure">Fig. 3</ref>. Example text labeled with both Markov and semi-Markov models. C labels refer to chemicals, D labels to diseases and O labels to non-entities. Markov models assign labels to individual tokens; semi-Markov models separate the input into segments of one or more tokens and assign a label to each TaggerOnebe the one with the highest score. Our rich feature approach for preparing the NER feature vectors is detailed in Section 2.2.3. If we let r j be the NER feature vector for segment Y j and let s 'j be the NER weight vector for ' j , then the NER score for Y j is their dot product:</p><formula>score NER Y j ; s À Á ¼ r T j s 'j</formula><p>Normalization is more difficult, however, due to the significantly greater number of categories (one per name n j 2 N 'j ). We use a supervised semantic indexing approach (<ref type="bibr" target="#b1">Bai et al., 2010;</ref><ref type="bibr" target="#b25">Leaman et al., 2013</ref>), which converts both the segments Y j and names n j 2 N 'j into vectors and then uses a weight matrix (W ' ) to score pairs of vectors. We describe the creation of the normalization vectors in Section 2.2.4. In this work we introduce an additional term for the cosine similarity, t '. If we let the normalization vector for Y j be u j and the normalization vector for name n j be v j , then the normalization score for Y j is:</p><formula>score Norm Y j ; t; W À Á ¼ t 'j u T j v j þ u T j W 'j v j</formula><p>Element i; j h i in matrix W ' can be interpreted as the correlation between token t i appearing in a text segment with NER label ' and token t j appearing in any concept name for ' from the lexicon. The model can thus learn a variety of relationships between tokens in text and names from the lexicon, including both synonymy and contrast. While the diagonal elements of W ' already model the same values represented by the cosine similarity parameter t ' , it represents the similarity between any token appearing in a text segment with NER label ' and the same token in the lexicon. The term can therefore be considered a 'base value' for all of the diagonal elements; it is also the only trained normalization parameter used for tokens not seen during training. We could also add an element to the scoring function that models the dependency of the current label (' j ) on the previous label (' jÀ1 ), as specified by the Markov property. The number of previous labels included (the order) can also be varied; order 1 and order 2 are common choices. We found, however, that conditioning the classification on any number of previous labels reduced performance. We use a scoring function that is independent of all other labels, making our model an order 0 semi-Markov model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">NER features</head><p>The NER features are prepared using a rich feature approach, with feature templates defined for either individual tokens or segments as needed. Token-level feature templates are similar to previous work in biomedical NER (<ref type="bibr" target="#b26">Leaman and Gonzalez, 2008;</ref><ref type="bibr" target="#b28">Leaman et al., 2015a</ref>), including:The NER feature vector for each segment is equal to the segment level feature values summed with each of the token level features for each token within the segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Normalization vector space</head><p>The normalization vector space is prepared similar to our previous work with the tokens from the lexicon (<ref type="bibr" target="#b25">Leaman et al., 2013</ref>), but now also contains all tokens in the training data. To create the set of tokens within the space, we process the names in the lexicon and all segments in the training data as follows:</p><p>@BULLET Conversion to lower case. @BULLET Punctuation removal. @BULLET Stop word removal; we use the same set of stop words as DNorm (<ref type="bibr" target="#b25">Leaman et al., 2013</ref>). @BULLET Stemming: diseases use the Porter stemmer (<ref type="bibr" target="#b34">Porter, 1980</ref>) while chemicals only remove plurals (<ref type="bibr" target="#b14">Hartman, 1991</ref>). We then define a corresponding vector space and create vectors within that space for each segment in the input data and each name in the lexicon. We use tf-idf weighting, modified so that the set of documents used for the idf calculation is the set of names in the lexicon. Tokens not present in the vector space (i.e. present in the evaluation set but not the training set) are represented as a unique 'unknown' token so that normalization scores reflect the reduced quality of the match. All normalization vectors are scaled to unit length, making the normalization score independent of the number of tokens in the text segment or lexicon name. This scaling requires information to be integrated across the text segment, and is therefore enabled by our use of semi-Markov models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training</head><p>We train our model using the margin-infused relaxed algorithm (MIRA) (<ref type="bibr" target="#b7">Crammer and Singer, 2003</ref>). Similar to the perceptron, MIRA is an online algorithm that performs no update if the instance is already correctly classified. Unlike the perceptron, the update does not use a fixed step size. Instead, MIRA determines the minimum change to the weights that would score the (correct) annotated segmentation higher than the (incorrect) segmentation currently given the highest score by the model by at least as much as the loss. If we use s 0 , x 0 and W 0 to respectively describe s, x and W after the update, then the size of the update (u) is the length of the difference of all weights in Euclidean space:</p><formula>u ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi ks 0 À sk 2 þ t 0 À t ð Þ 2 þ kW 0 À W ' k 2 q</formula><p>The goal of the MIRA update is to find the smallest update, subject to the constraint of correctly classifying the instance after the update:</p><formula>update ¼ argmin s 0 ;x 0 ;W 0 u þ c X n n k</formula><p>where n k are slack variables (n k ! 0) to ensure separability, the c parameter controls the size of the updates, and n is the number of constraints. We use the hinge loss and constrain the update so that the score for the annotated segmentation (Y þ ) will be higher than the score for the segmentation that currently has the highest score (Y À ¼ f ðXÞ) by at least as much as the loss:When the entity for the annotated segment Y þ j has multiple synonyms, we let the model determine which name should be used by selecting the name with the highest score according to the current model weights. Determining the smallest update that satisfies the constraints is a numerical optimization problem, specifically a quadratic program. While it has an exact solution, it contains more than one constraint and therefore must be solved numerically. We use an open source numerical optimizer (ojAlgo: http://ojalgo.org) to solve for the update. To keep a single instance from making large changes to the weights, we limit the change (k) to be at most m: k ¼ min m; u ð Þ. We empirically determine the value of c and m by performing a grid search using a randomly selected subset of the training data (100 documents). We iterate through all training instances in random order on each iteration. All weights are initialized to 0 at the start of training. To reduce overtraining, we use model averaging and also evaluate the performance on a holdout set after each training iteration. We use the harmonic mean of the NER and normalization f-scores (as described in Section 3) as the holdout performance measure. We output the current model if performance has improved over the previous iteration, and stop training when n ¼ 10 iterations have elapsed without a performance improvement. We then consider the last model output as the final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Disambiguation</head><p>Though our primarily normalization focus is term variation, if the highest-scoring name vector is the name for two or more entities then we perform two steps to disambiguate. First, if the name is marked as a synonym for one entity and the primary name for the parent of that entity, we prefer the parent. Second, we prefer the entities that appear more frequently in the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Lexical resources</head><p>In this work, the goal is to perform NER and normalization by learning a mapping to a specific lexicon, rather than maximizing performance by expanding the lexicon. We therefore exclusively use the disease and chemical vocabularies distributed by the Comparative Toxicogenomics Database project (CTD, http:// ctdbase.org). The CTD vocabulary for diseases, MEDIC, is derived from a combination of OMIM (http://www.omim.org) and the disease branch of MeSH (https://www.nlm.nih.gov/mesh) and lists 11 885 disease entities and 76 685 names. The CTD chemical vocabulary contains concepts from the MeSH chemical branch. We augmented this vocabulary slightly to ensure it included all chemical element names and symbols up to atomic number 103, resulting in a total of 158 721 chemical entities and 414 246 names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Comparison systems</head><p>We employ two open source systems with state-of-the-art performance for NER and normalization as comparison benchmarks. We use DNorm (<ref type="bibr" target="#b25">Leaman et al., 2013</ref>) for diseases; it has the highest published performance on the NCBI Disease Corpus and also achieved the highest performance in a previous disease challenge task (<ref type="bibr" target="#b28">Leaman et al., 2015a;</ref><ref type="bibr" target="#b35">Pradhan et al., 2015</ref>). We use tmChem (<ref type="bibr" target="#b29">Leaman et al., 2015b</ref>) for chemicals; it is an ensemble of two chemical NER/normalization systems and achieved the highest performance in the recent CHEMDNER challenge task for chemical NER at BioCreative IV (<ref type="bibr" target="#b22">Krallinger et al., 2015a</ref>). In this work we exclusively use Model 1, which is an adaptation of BANNER (<ref type="bibr" target="#b26">Leaman and Gonzalez, 2008</ref>) to recognize chemical mentions, combined with a dictionary approach for normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We validate TaggerOne by applying it to two corpora containing both mention-and concept-level annotations: the NCBI Disease corpus (<ref type="bibr" target="#b9">Do gan et al., 2014</ref>) and the BioCreative V Chemical Disease Relation task corpus (<ref type="bibr" target="#b31">Li et al., 2015</ref>). Overall statistics for each dataset are provided in<ref type="figure" target="#tab_1">Table 1</ref>. The NCBI Disease corpus consists of 793 PubMed abstracts separated into training (593), development (100) and test (100) subsets. The NCBI Disease corpus is annotated with disease mentions, using concept identifiers from either MeSH or OMIM. The BioCreative V Chemical Disease Relation (BC5CDR) corpus consists of 1500 PubMed abstracts, separated into training (1000) and test (500) sets. We created a holdout set by separating the sample set (50 abstracts) from the remainder of the training set. The BC5CDR corpus enables experiments simultaneously modeling multiple entity types; it is annotated with concept identifiers from MeSH for both chemical and disease mentions. We use two evaluation measures since our model performs both NER and normalization. The NER measure is at the mention level; we require the predicted span and entity type to exactly match the annotated span and entity type. The normalization measure is at the abstract level, comparing the set of concepts predicted for the document to the set annotated, independent of their location within the text. We report both measures in terms of micro-averaged precision, recall and f-score. We perform two sets of experiments. The first set of experiments evaluates the ability of the model to generalize to unseen text and whether joint NER and normalization improves performance over performing NER separately. This set of experiments models diseases and chemicals separately. The second set of experiments evaluates the ability of the model to simultaneously handle multiple entity types (both diseases and chemicals).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results for single-entity models</head><p>The results for training and evaluating TaggerOne on a single entity type can be found in<ref type="figure" target="#tab_2">Table 2</ref>for NER and<ref type="figure" target="#tab_3">Table 3</ref>for normalization. For each corpus, the model was trained on the training set, using the development (or sample) set as a holdout set, and evaluated on the official test set. The NER f-score is higher for the joint NERþ normalization model than for the NER-only model for all entity types and corpora. Specifically, the error rate for NCBI Disease is reduced by 8%, for BC5CDR (disease) by 15% and for BC5CDR (chemical) by 26%. In all cases the NER f-score is also higher for the joint NERþ normalization model of TaggerOne than for the comparison systems. Finally, we note that the normalization performance has increased TaggerOneover the comparison systems; specifically the error rate for NCBI Disease is 11% lower, BC5CDR (disease) is 16% lower and BC5CDR (chemical) is 17% lower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results for disease1chemical</head><p>The results of training and evaluating TaggerOne on two entity types simultaneously are described in<ref type="figure" target="#tab_4">Table 4</ref>. For this experiment we trained a single model on the BC5CDR corpus, simultaneously modeling both diseases and chemicals. We note that jointly modeling chemicals and diseases produces the same NER performance and very similar normalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>The single-entity performance demonstrates both that our model is effective and that jointly modeling NER and normalization improves performance. Our results significantly improve on DNorm for diseases and on tmChem for chemicals. Analyzing the DNorm and TaggerOne results provides insight into the advantage of joint prediction: DNorm often misses phrases that require term variation to be resolved for the phrase to be recognized as an entity, such as 'abnormal involuntary motor movements,' annotated as MeSH identifier D004409: Drug-induced Dyskinesia. The experiment jointly modeling chemicals and diseases demonstrates that the model maintains high performance while modeling multiple entity types. Modeling multiple entity types simultaneously may be advantageous when the entity types are more difficult to distinguish, such as with anatomical types (<ref type="bibr" target="#b36">Pyysalo and Ananiadou, 2014</ref>). Our results on the NCBI Disease corpus are the highest of which we are aware. The only normalization system with published results on the NCBI Disease corpus besides DNorm is the sieve-based system of D'<ref type="bibr">Souza and Ng (2015)</ref>. Their evaluation measure calculates the proportion of mentions correctly normalized given perfect NER. Using this measure, their system scored 0.847; TaggerOne scores 0.888. The recent disease subtask at the BioCreative V chemical disease relation task provides an excellent comparison for our system (<ref type="bibr" target="#b47">Wei et al., 2015c</ref>). The UET-CAM system (<ref type="bibr" target="#b24">Le et al., 2015</ref>) performs joint NER and normalization for prediction but unlike TaggerOne does not perform joint training; it achieved an f-score of 0.764. The highest performing system at the BC5CDR disease subtask achieved 0.896 precision, 0.835 recall, for 0.865 f-score (<ref type="bibr" target="#b30">Lee et al., 2015</ref>). We note that expanding the lexicon was a significant feature in most participating systems; in this manuscript our goal is to automatically learn the best mapping to an existing lexicon. These two approaches are complementary, however. We are not aware of any previous performance evaluations on the chemical entities of the BC5CDR corpus. We originally trained our model using an averaged perceptron; NER performance was similar but normalization performance was several percent lower (data not shown). We believe this was due to using the same update size for both the NER and normalization weights. Our use of semi-Markov models allows us to scale the normalization vectors for the mentions to unit length. Performance degrades significantly when this scaling is not performed (data not shown).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation</head><p>TaggerOne was implemented in Java as a general toolkit for biomedical NER and normalization. TaggerOne is not specific to any entity type, and is designed to simultaneously handle multiple entity types and lexical resources. The current implementation has an average throughput of 8.5 abstracts per second for diseases, compared to 3.5 for our previous work DNorm (using a single 2.80 Ghz 64-bit Xeon processor limited to 20 Gb memory). The supplementalmaterial describes optimizations critical for reducing the considerable computational cost of joint NER and normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Error analysis and limitations</head><p>We manually analyzed a random sample of both corpora for errors and describe the trends observed. False positives and negatives remain a significant source of error. Other entity types—particularly gene names (e.g. 'GAP 43')—are frequently confused with both diseases and chemicals. Diseases are particularly prone to error because of the high similarity to the general biomedical vocabulary (e.g. 'nephrostomy tube'), because individual tokens can change the meaning significantly (e.g. 'coproporphyrinogen oxidase' was identified as the disease 'coproporphyrinogen oxidase deficiency'), and because the model does not identify states considered desirable in context ('analgesia'). Coordination ellipsis and noun compounds also remain a significant source of error. This is an especially difficult problem for chemicals, since it can be difficult to distinguish the number of entities present within a text snippet (e.g. 'copper/zinc superoxide'). We found that our model tends to rely more on the lexicon when the vocabulary is previously unseen. Consistency with the lexicon sometimes comes at the expense of consistency with the annotated data, however. For example, the model identified 'familial renal amyloidosis' though the corpus only contains an annotation for the less specific 'amyloidosis.' Alternatively, segments are sometimes annotated to include tokens not found in the concept name. For example, the phrase 'isolated unilateral retinoblastoma' was annotated as a whole to 'retinoblastoma.' The model correctly found 'retinoblastoma' and included 'unilateral,' but missed 'isolated.' While primarily an NER issue, these sometimes cause difficulties with normalization (e.g. 'GI toxicity' was normalized to 'gastrointestinal disorder' instead of 'toxicity').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We conclude that jointly modeling named entity recognition and normalization results in improved performance for both tasks. Our model is not entity-specific and we expect it to generalize to arbitrary NER and normalization problems in biomedicine. In this work we have demonstrated this capability for both diseases and chemicals. In future work, we intend to integrate a more robust disambiguation method to allow entity types such as genes and proteins to be addressed. We are also interested in investigation its application to the general domain. While our goal has been to learn the best mapping to an existing lexicon, expanding the lexicon is a complementary approach used by many normalization systems (<ref type="bibr" target="#b45">Wei et al., 2015a</ref>,b,c). We anticipate that applying our method to an expanded lexicon would further increase performance (<ref type="bibr" target="#b2">Blair et al., 2014</ref>). An interesting research direction enabled by this work is the possibility of using data not annotated jointly (<ref type="bibr" target="#b13">Finkel and Manning, 2010</ref>). Sources of annotations at the document-level are significantly more abundant than annotations at the mention level (<ref type="bibr" target="#b43">Usami et al., 2011</ref>). We anticipate our model may enable entity-level distant supervision by providing a joint model of both NER and normalization that handles term variation.<ref type="figure" target="#tab_4">Table 4</ref>. TaggerOne results on the BC5CDR corpus when both disease and chemical mentions are trained within a single model. Precision, recall and f-score are micro-averaged and respectively abbreviated as P, R and F</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Example text with chemical and disease entity annotations, adapted from PMID 7420681. The outer boxes specify the annotated term and MeSH identifier</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Overview of the TaggerOne system. Joint modeling of NER and normalization is performed by scoring all text segments against each NER class and name in the lexicon Fig. 3. Example text labeled with both Markov and semi-Markov models. C labels refer to chemicals, D labels to diseases and O labels to non-entities. Markov models assign labels to individual tokens; semi-Markov models separate the input into segments of one or more tokens and assign a label to each</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>@BULLET Token text, token stem @BULLET Part of speech @BULLET Character 2, 3 and 4—grams @BULLET Patterns to recognize numbers and common variations in capitalization Feature templates defined at the segment level include: @BULLET The number of tokens in the segment @BULLET The characters and tokens surrounding the segment @BULLET The first and last token in the segment @BULLET Whether the segment contains unbalanced parenthesis @BULLET Patterns to recognize common representations of Greek letters, partial chemical formulas and amino acids. @BULLET Whether the start or end token is a member of a closed class in English</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>We found it useful to also add constraints focusing on the normalization. For each segment Y þ j in the annotated segmentation whose label is not Other, we add a constraint that the normalization with the highest score for that segment should be the one annotated:</figDesc><table>score Y þ ; s 0 ; t 0 ; W 0 
ð 
Þ À score Y À ; s 0 ; t 0 ; W 0 
ð 
Þ þ n 0 

! max 0; score Y À ; s; t; W 
ð 
Þ À score Y þ ; s; t; W 
ð 
Þ 
ð 
Þ 

score Norm Y þ 
j ; t 0 ; W 0 



À score Norm Y À 
j ; t 0 ; W 0 



þ n k 

! max 0; score NEN Y À ; t; W 
ð 
ÞÀscore Norm Y þ ; t; W 
ð 
Þ 
ð 
Þ 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 1.</figDesc><table>Statistics for the corpora used for training and evaluation, 
differentiated by entity type. 'Unique Mentions' and 'Unique 
Concepts' respectively refer to the number of annotations with 
unique text or unique identifiers 

Corpus and 
entity type 

Annotations 
Unique 
mentions 

Unique 
concepts 

NCBI Disease 
6892 
2135 
753 
BC5CDR (Disease) 
12864 
3271 
1082 
BC5CDR (Chemical) 
15933 
2630 
1274 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 2.</figDesc><table>NER results for the NCBI Disease and BC5CDR corpora. DNorm is the benchmark system for disease entities, tmChem model 1 the 
benchmark system for chemicals. Precision, recall and f-score are respectively abbreviated as P, R and F. The highest value for each is 
bolded 

System 
NCBI disease 
BC5CDR (disease) 
BC5CDR (chemical) 

P 
R 
F 
P 
R 
F 
P 
R 
F 

Benchmark system 
0.822 
0.775 
0.798 
0.820 
0.795 
0.807 
0.932 
0.840 
0.884 
TaggerOne (NER Only) 
0.835 
0.796 
0.815 
0.831 
0.764 
0.796 
0.924 
0.847 
0.884 
TaggerOne 
0.851 
0.808 
0.829 
0.852 
0.802 
0.826 
0.942 
0.888 
0.914 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 3.</figDesc><table>Normalization results for the NCBI Disease and BC5CDR corpora. DNorm is the benchmark system for disease entities, tmChem 
model 1 the benchmark system for chemicals. Precision, recall and f-score are respectively abbreviated as P, R and F. The highest value for 
each is bolded 

System 
NCBI disease 
BC5CDR (disease) 
BC5CDR (chemical) 

P 
R 
F 
P 
R 
F 
P 
R 
F 

Benchmark system 
0.803 
0.763 
0.782 
0.812 
0.801 
0.806 
0.950 
0.808 
0.873 
TaggerOne 
0.822 
0.792 
0.807 
0.846 
0.827 
0.837 
0.888 
0.903 
0.895 </table></figure>

			<note place="foot">R.Leaman and Z.Lu at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous reviewers for their comments and suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This research was supported by the National Institutes of Health Intramural Research Program, National Library of Medicine. Conflict of Interest: none declared.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Support vector machine learning for independent and structured output spaces Predicting Structured Data</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Altun</surname>
			</persName>
		</author>
		<editor>Bakir, G. et al.</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, Massachusetts, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to rank with (a lot of) word features</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Bai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retrieval</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="291" to="314" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Quantifying the impact and extent of undocumented biomedical synonymy</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Blair</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1003799</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A modular framework for biomedical concept recognition</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Campos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">281</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<monogr>
		<title level="m" type="main">Disease mention recognition with specific features. BioNLP Workshop</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">M</forename>
				<surname>Chowdhury</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lavelli</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="83" to="90" />
			<pubPlace>Uppsala, Sweden</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploiting Dictionaries in Named Entity Extraction: Combining Semi-Markov Extractions Processes and Data Integration Methods</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">W</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sarawagi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th ACM SIGKDD Int Conf on Knowledge Discovery and Data Mining</title>
		<meeting><address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">On the algorithmic implementation of multiclass kernel-based vector machines</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Crammer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Singer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="265" to="292" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Ultraconservative online algorithms for multiclass problems</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Crammer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Singer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="951" to="991" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Sieve-Based Entity Linking for the Biomedical Domain</title>
		<author>
			<persName>
				<forename type="first">D &apos;</forename>
				<surname>Souza</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">53rd ACL and 7th IJCNLP</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="297" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">NCBI disease corpus: A resource for disease name recognition and concept normalization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">I</forename>
				<surname>Do Gan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inf</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: coreference, typing and linking</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Durrett</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Klein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="477" to="490" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Chemical named entities recognition: a review on approaches and applications</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Eltyeb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Salim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cheminf</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Joint Parsing and Named Entity Recognition</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Finkel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Manning</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="326" to="334" />
			<pubPlace>Boulder, Colorado</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical Joint Learning: Improving Joint Parsing and Named Entity Recognition with Non-Jointly Labeled Data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Finkel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Manning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th ACL</title>
		<meeting><address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="720" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">How effective is suffixing?</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Hartman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of BioCreAtIvE: critical assessment of information extraction for biology</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hirschman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">OSCAR4: a flexible architecture for chemical textmining</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Jessop</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cheminf</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Assessment of disease named entity recognition on a corpus of annotated sentences</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Jimeno</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">S3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Using rule-based natural language processing to improve disease normalization in biomedical text</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Kang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inf. Assoc</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="876" to="881" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Overview of BioNLP&apos;09 shared task on event extraction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Kim</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Detection of IUPAC and IUPAC-like chemical names</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Klinger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Chemical names: terminological resources and corpora annotation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kolarik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC Workshop on Building and Evaluating Resources for Bbiomedical Text Mining</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">CHEMDNER: The drugs and chemical names extraction challenge</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Krallinger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cheminf</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">Overview of the CHEMDNER Patents Task. Fifth BioCreative Challenge Evaluation Workshop</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Krallinger</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="63" to="75" />
			<pubPlace>Seville, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title level="m" type="main">The UET-CAM System in the BioCreAtIvE V CDR Task</title>
		<author>
			<persName>
				<forename type="first">H.-Q</forename>
				<surname>Le</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="208" to="213" />
			<pubPlace>Seville, Spain</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">DNorm: Disease name normalization with pairwise learning-to-rank</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2909" to="2917" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">BANNER: an executable survey of advances in biomedical named entity recognition</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Gonzalez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac. Symp. Biocomput</title>
		<imprint>
			<biblScope unit="page" from="652" to="663" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Enabling recognition of diseases in biomedical text with machine learning: corpus and benchmark</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Symp on Languages in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="82" to="89" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Challenges in clinical natural language processing for automated disorder normalization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inf</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="28" to="37" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">tmChem: a high performance approach for chemical named entity recognition and normalization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cheminf</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">S3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">An Enhanced CRF-Based System for Disease Name Entity Recognition and Normalization on BioCreative V DNER Task</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">C</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc BioCreative Workshop</title>
		<imprint>
			<biblScope unit="page" from="226" to="233" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Annotating chemicals, diseases and their interactions in biomedical literature</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc BioCreative Workshop</title>
		<imprint>
			<biblScope unit="page" from="173" to="182" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Overview of BioCreative II gene normalization</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Morgan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">S3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Improving the scalability of semi-markov conditional random fields for named entity recognition</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Okanohara</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st Int Conf on Comp Ling and 44th ACL. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="465" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<monogr>
		<title level="m" type="main">An algorithm for suffix stripping. Program</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">F</forename>
				<surname>Porter</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Evaluating the state of the art in disorder recognition and normalization of the clinical narrative</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pradhan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inf. Assoc</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="143" to="154" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Anatomical entity mention recognition at literature scale</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pyysalo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ananiadou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="868" to="875" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">CALBC silver standard corpus</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rebholz-Schuhmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bioinf. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="163" to="179" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">ChemSpot: a hybrid system for chemical named entity recognition</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Rocktaschel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1633" to="1640" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Abbreviation definition identification based on automatic precision estimates</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sohn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">402</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">PKDE4J: Entity and relation extraction for public knowledge discovery</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Song</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inf</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="320" to="332" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">Max-margin Markov networks</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Taskar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv Neural Inf Process Syst</title>
		<editor>Thrun,S. et al.</editor>
		<meeting><address><addrLine>Cambridge, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning string similarity measures for gene/protein name dictionary look-up using logistic regression</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Tsuruoka</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2768" to="2774" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<monogr>
		<title level="m" type="main">Automatic acquisition of huge training data for biomedical named entity recognition. BioNLP Workshop</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Usami</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="65" to="73" />
			<pubPlace>Portland, Oregon</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">Text mining for drugs and chemical compounds: methods, tools and applications</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Vazquez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Inf</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="506" to="519" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">GNormPlus: an integrative approach for tagging genes, gene families, and protein domains</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Wei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioMed. Res. Int</title>
		<imprint>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">SimConcept: a hybrid approach for simplifying composite named entities in biomedical text</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Wei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Biomed. Health Inf</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1385" to="1391" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b47">
	<monogr>
		<title level="m" type="main">Overview of the BioCreative V Chemical Disease Relation (CDR) Task. BioCreative Workshop</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Wei</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="154" to="166" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>