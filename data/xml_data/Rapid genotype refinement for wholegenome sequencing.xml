
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rapid genotype refinement for whole-genome sequencing data using multi-variate normal distributions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Rudy</forename>
								<surname>Arthur</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Illumina Cambridge Ltd</orgName>
								<orgName type="institution" key="instit2">Chesterford Research Park</orgName>
								<address>
									<addrLine>Little Chesterford</addrLine>
									<postCode>CB10 1XL</postCode>
									<settlement>Essex</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jared</forename>
								<surname>O &apos;connell</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Illumina Cambridge Ltd</orgName>
								<orgName type="institution" key="instit2">Chesterford Research Park</orgName>
								<address>
									<addrLine>Little Chesterford</addrLine>
									<postCode>CB10 1XL</postCode>
									<settlement>Essex</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ole</forename>
								<surname>Schulz-Trieglaff</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Illumina Cambridge Ltd</orgName>
								<orgName type="institution" key="instit2">Chesterford Research Park</orgName>
								<address>
									<addrLine>Little Chesterford</addrLine>
									<postCode>CB10 1XL</postCode>
									<settlement>Essex</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Anthony</forename>
								<forename type="middle">J</forename>
								<surname>Cox</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Illumina Cambridge Ltd</orgName>
								<orgName type="institution" key="instit2">Chesterford Research Park</orgName>
								<address>
									<addrLine>Little Chesterford</addrLine>
									<postCode>CB10 1XL</postCode>
									<settlement>Essex</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rapid genotype refinement for whole-genome sequencing data using multi-variate normal distributions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw097</idno>
					<note type="submission">Received on November 11, 2015; revised on January 25, 2016; accepted on February 14, 2016</note>
					<note>Genetics and population analysis *To whom correspondence should be addressed. Associate Editor: Oliver Stegle Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Whole-genome low-coverage sequencing has been combined with linkage-disequilibrium (LD)-based genotype refinement to accurately and cost-effectively infer genotypes in large cohorts of individuals. Most genotype refinement methods are based on hidden Markov models, which are accurate but computationally expensive. We introduce an algorithm that models LD using a simple multivari-ate Gaussian distribution. The key feature of our algorithm is its speed. Results: Our method is hundreds of times faster than other methods on the same data set and its scaling behaviour is linear in the number of samples. We demonstrate the performance of the method on both low-and high-coverage samples. Availability and implementation: The source code is available at http://compbio.ddns.comp.nus.edu.sg/%7elipidgo/index.php.
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The 1000 Genomes Project (1000GP) has pioneered the approach of combining low-coverage whole-genome sequencing (LCWGS) with linkage disequilibrium (LD)-based genotype refinement to successfully build large panels of accurately genotyped individuals (<ref type="bibr">The 1000</ref><ref type="bibr">Genomes Project Consortium, 2010</ref>). This has provided a cost-effective alternative to sequencing many individuals at high-coverage. However, genotype refinement has a large computational burden. For example,<ref type="bibr" target="#b4">Delaneau et al. (2014)</ref>quote around 32 compute years to perform haplotype estimation on 1092 LCWGS individuals using the 1000GP haplotype estimation pipeline. This figure measures the cost of haplotype phasing (which our method does not address) as well as genotype refinement. Given increasing sample sizes, decreasing sequencing costs and the typically super-linear scaling of refinement algorithms, we are fast approaching a point where computation will account for a substantial proportion of the cost of such analyses. Low-coverage genotyping typically proceeds by calculating genotype likelihoods (GLs) at a fixed set of variants (SNPs and small indels) from read alignments, the variant list being created at an earlier variant discovery step. These GLs reflect the likelihood of the read data conditional on each of the three possible genotypes (assuming a bi-allelic site). These uncertain GLs are then refined into genotypes by exploiting LD, the correlation between physically close variants across individuals. This final step is often referred to as genotype refinement and involves one (or more) phasing and imputation algorithms. The most accurate phasing and imputation techniques typically employ hidden Markov models (HMMs) which are computationally demanding, examples include Beagle (<ref type="bibr" target="#b1">Browning and Browning, 2007</ref>), Thunder (<ref type="bibr" target="#b14">Li et al., 2011</ref>) and SHAPEIT (<ref type="bibr" target="#b2">Delaneau et al., 2012</ref><ref type="bibr" target="#b3">Delaneau et al., , 2013</ref>). The final genotypes of 1000GP were created using a combination of SHAPEIT and Beagle; starting haplotypes were generated with the faster Beagle method and then were further refined using the slower, and more accurate, SHAPEIT (<ref type="bibr" target="#b4">Delaneau et al., 2014</ref>). A closely related problem is the imputation of variants into study samples assayed on DNA microarrays from reference panels of sequenced individuals (<ref type="bibr" target="#b15">Marchini et al., 2007</ref>). Several very fast methods have recently emerged for this scenario (<ref type="bibr" target="#b6">Durbin, 2014;</ref><ref type="bibr" target="#b7">Fuchsberger et al., 2015;</ref><ref type="bibr" target="#b8">Howie et al., 2012</ref>). These rely on theavailability of phased haplotypes for both study and reference data and it is not clear such algorithms will generalize to the LCWGS use case. An alternative to HMM-based imputation is simply to predict genotypes as linear combinations of other genotypes at physically close flanking markers, modelling the correlation between variants as a multivariate normal (MVN) distribution. This idea was first introduced by Wen and Stephens (2010), where it was used in the more traditional setting of imputing genotypes into DNA microarray samples from a reference panel. Menelaou and<ref type="bibr" target="#b17">Marchini (2013)</ref>introduced a related approach, MVNcall, that performs imputation on LCWGS data for which the individual has also been assayed on a DNA microarray, exploiting the 'backbone' of confident microarray genotypes to improve genotypes at non-microarray sites. We introduce a new technique based on MVN representations of LD that extends these ideas to the LCWGS-only imputation scenario. The method exploits various efficient linear algebra operations, making it hundreds of times faster than the fastest HMM method. This speed comes with a decrease in accuracy compared with HMMs, but is still substantially more accurate than genotype calls made using no LD information. In the 'Methods' section, we outline the model and its implementation. In our 'Results' section, we contrast the speed and accuracy of our technique with Beagle on 2535 samples from 1000GP Phase 3 (LCWGS) and 3781 samples taken from the UK10K project (UK10K<ref type="bibr" target="#b21">Consortium et al., 2015;</ref><ref type="bibr" target="#b9">Huang et al., 2015</ref>). Finally, we demonstrate the applicability of LD-based genotype refinement in the high-coverage WGS setting, something that has not been investigated to date. The method is implemented in a software package called MarViN (MultiVariate Normal imputation) and is freely available under the GPLv3 license.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials and methods</head><p>We assume that N diploid individuals have been sequenced and used to detect M bi-allelic polymorphisms. We record the number of copies of the non-reference (alternate) allele in a matrix G ij 2 f0; 1; 2g;</p><formula>(1)</formula><p>where the indexes i and j label polymorphic sites and individuals respectively. We assume that we have been given GLs PðR ij jG ij ¼ kÞ;</p><formula>(2)</formula><p>where k 2 f0; 1; 2g and R ij denotes the reads aligning to site i in individual j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Single-site model</head><p>We now describe a simple Expectation-Maximization (EM) algorithm that we use to initialize our model. We apply Bayes' theorem to obtain posterior probabilities of genotypes:</p><p>PðG ij ¼ kjR ij Þ / PðG ij ¼ kÞPðR ij jG ij ¼ kÞ:</p><formula>(3)</formula><p>where P(G ij ¼ k) is the prior probability of seeing genotype k and is initialized asThis constitutes the E-step of our routine. The M-step involves reestimating our prior, P(G ij ¼ k). First, we estimate site allele frequencies as</p><formula>^ l i ¼ 1 2N X j G ij :</formula><formula>(5)</formula><p>Assuming Hardy-Weinberg equilibrium, our updated prior is then</p><formula>PðG ij ¼ kÞ ¼ ð1 À ^ l i Þ 2 k ¼ 0; 2^ l i ð1 À ^ l i Þ k ¼ 1; ^ l 2 i k ¼ 2: 8 &gt; &gt; &lt; &gt; &gt; :</formula><formula>(6)</formula><p>The E-step and M-step are iterated and generally converge rapidly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multi-site model</head><p>This EM algorithm gives an estimate of G ij that takes into account the population allele frequency at site i but ignores any correlation with flanking sites (i.e. LD). We now describe how to improve the estimate of G using LD. A simple way to encode LD is with the M Â M covariance matrix R, where</p><formula>R ii 0 ¼ 1 2N X j ðG ij À l i ÞðG i 0 j À l i 0 Þ:</formula><formula>(7)</formula><p>Following Wen and Stephens (2010), we make the assumption that the probability density for the vector of dosages g (j) for individual j, the jth column of the genotype matrix ðg ðjÞ i ¼ G ij Þ, is MVN: Pðg ðjÞ ¼ gÞ / exp 1 2 ðg À lÞ T R À1 ðg À lÞ</p><formula>(8)</formula><p>We can then ask 'what is the distribution for the dosage at site i of individual j conditional on the dosages at all other sites?' For the MVN, a closed form expression for this conditional probability exists:</p><formula>PðG ij ¼ kjG i 0 j ¼ g ðjÞ i 0 Þ / exp ðk À ij Þ 2 2r i ! (9)</formula><p>where g ðjÞ i' refers to all genotypes excluding site i and</p><formula>r i ¼ R ii þ X M l6 ¼i X M m6 ¼i R il ~ X ðiÞ lm R mi ; (10) ij ¼ l i þ X l6 ¼i X m6 ¼i R il ~ X ðiÞ lm ðG mj À l m Þ;</formula><formula>(11)</formula><p>and the matrix ~ X i is the inverse of the matrix formed by deleting the ith row and column from R. In words, what we are doing is using the genotype matrix to estimate allele frequencies and LD. Fixing these, we re-estimate the genotype matrix using the MVN assumption. The approach is similar to our single site EM algorithm, but with the simple population frequency prior in Equation (6) replaced with the more sophisticated population LD prior in Equation (9). Examining the terms closely, we see that r i is independent of the individual, as is the quantity</p><formula>t im ¼ X l6 ¼i R il ~ X ðiÞ lm : (12)</formula><p>Thus we need only calculate it once. Rewriting Equation (11), we see that updating the mean of individual j is achieved by evaluating</p><formula>ij ¼ l i þ X m6 ¼i t im ðG mj À l m Þ;</formula><formula>(13)</formula><p>at a cost of one dot product per site per individual.</p><p>Rapid genotype refinement for whole-genome sequencing data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Algorithm description</head><p>We initialize G using the single-site model described in Section 2.1. We then repeat the following steps for a default of five iterations: 1. Calculate l and R from G. 2. Calculate t im and r i for all sites i and m. 3. For all sites i and individuals j, calculate ij. 4. Update PðG ij ¼ kjR ij Þ using Equations (3) and (9). 5. Recalculate G.</p><p>We take the final estimate of G as our imputed genotypes. We could iterate steps 2 and 3, reusing the covariance matrix obtained at the beginning of the iteration but we found this to be unhelpful in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Calculating X</head><p>Computationally, step 1 is dominated by the calculation of R, which takes O(NM 2 ) operations. Step 2 requires a matrix vector product for every individual and so is also O(NM 2 ). However, a straightforward implementation of step 3 would be O(M 4 ), since a matrix must be inverted at each site at a cost of O(M 3 ) per inversion. To see how step 3 can be sped up, consider the case where we want to update the marker 1 while fixing the M À 1 markers to the right. We write the covariance matrix in the following form:</p><formula>R ¼ R 11 R 12 R 21 R 22 ! (14)</formula><p>where R 11 is 1 Â 1 and R 22 is ðM À 1Þ Â ðM À 1Þ. To calculate r 1 , we require</p><formula>r 1 ¼ R 11 þ R 12 R À1 22 R 21 (15)</formula><p>[compare Equation (10)]. The big overhead here is calculating R À1 22. We define</p><formula>X ¼ R À1 ¼ X 11 X 12 X 21 X 22 ! ; (16)</formula><p>where the blocks are sized to match the corresponding submatrices of R. By making an LDU decomposition, we can show that</p><formula>R À1 22 ¼ X 22 À X 21 X À1 11 X 12 ; (17)</formula><p>which is known as the Schur complement of X 11 in X. This gives us ~ X ð1Þ ¼ R À1 22 which we can use in Equation (12). Consider the variant at site i. The matrix we need to invert in order to evaluate the conditional expectation is the inverse of a submatrix of R formed by deleting the ith row and column of R. Swapping rows i and 1 and columns i and 1 of R puts the matrix we need the inverse of in the position of R 22 in Equation (14). A row and column can be swapped by pre-and post-multiplying with a permutation matrix P. R ! PRP T :</p><formula>(18)</formula><p>Because permutation matrices are orthogonal we have that</p><formula>ðPRP T Þ À1 ¼ P R ð Þ À1 P T ¼ PXP T : (19)</formula><p>The required inverse for variant i can be obtained by applying Equation (17) again on the permuted matrix. In practice we just swap rows and columns of the matrix the usual way, which is equivalent to the multiplication. This trades M matrix inverses for a single matrix inverse plus M matrix operations of complexity O(M 2 ) each (matrix-vector products), giving an O(M 3 ) overall cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Using a reference panel</head><p>If we have a small number of individuals to impute and a reference panel formed from a large number of individuals with hard genotypes assigned, we can impute individuals using the panel by following the procedure below: 1. Calculate allele frequencies l and the covariance matrix R from the panel. 2. Use the panel allele frequencies to obtain an initial estimate of G from the GLs. 3. Calculate t im and r i for all sites i. 4. For each individual with genotype g (j) to be imputed, the following steps are performed K times: 5. For all sites i, calculate v ij 6. Update PðgCalculating t im is O(M 3 ) and R is O(NM 2 ), both of which must be done once per panel. To impute each new individual then requires performing O(M 2 ) operations for each of K iterations, where K was be around 5 in practice, we found that performing more than five iterations did not improve the quality of the imputation in almost every case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Regularizing the covariance matrix</head><p>To guard against degeneracy due to perfect correlation and force the variance to be non-zero, we performed Tikhonov regularization on the covariance matrix, i.e. applied the transformation R ! R þ kI:</p><formula>(20)</formula><p>By scanning a range of possible values of k we found k ¼ 0:06 to be an effective value for the regularization parameter, the same value as found in Menelaou and Marchini (2013). Alternative regularization methods (such as adding a matrix proportional to the diagonal of the covariance matrix, as done in the Levenberg-Marquardt algorithm) were evaluated but were not found to confer a significant improvement. After Wen and Stephens (2010), we also modify the mean as follows:</p><formula>l i ! ð1 À hÞl i þ h 2 ; (21) where h ¼ X 2NÀ1 i i À1 À1 2N þ X 2NÀ1 i i À1 À1 :</formula><p>This correction is relevant in the case of small cohorts where the empirical mean may be a bad estimate of the true mean, the specific form above is derived in<ref type="bibr" target="#b22">Wen and Stephens (2010)</ref>using the model of<ref type="bibr" target="#b13">Li and Stephens (2003)</ref>. In our case, with cohorts of 2500 or more, the difference between this and the sample mean is very small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Implementation</head><p>We implemented our method in C þþ using the the Eigen matrix library (Ga€ el Guennebaud, Beno^ ıt Jacob and others, Eigen v3, http://eigen.tuxfamily.org) for matrix manipulations and HTSlib (<ref type="bibr" target="#b12">Li et al., 2009</ref>) for streaming the input VCF/BCF files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.1">Low-coverage data</head><p>We make use of two different publicly available large cohorts to evaluate our method in the low-coverage scenario. First, the 1000GP Phase 3 samples which consist of 2535 samples from a heterogeneous mix of 26 populations, each sample sequenced to an average of 7.4Â. Second, data from the UK10K control group, a more homogeneous cohort than the 1000GP samples comprising 3781 samples, each sequenced to around 7Â. We only evaluated SNPs with minor allele count &gt;1 in these comparisons. As validation data, we used freely available high-coverage (&gt;80Â) data from Complete Genomics (CG). A subset of the 1000GP samples (287) were also sequenced by CG. To create validation data for the UK10K samples, we took 63 of the European CG samples and calculated GLs at the UK10K sites for these samples from their respective low-coverage BAM files using bcftools (<ref type="bibr" target="#b12">Li et al., 2009</ref>). MarViN imputation was performed in 200 kbp windows with an overlap of 100kbp between windows. We performed a number of small timing experiments on a 2 Mbp region of chr20, and a more rigorous accuracy experiment using the entire chr20 for both cohorts. A summary of the samples and number of variants is in<ref type="figure" target="#tab_1">Table 1</ref>. On both these cohorts, we compared MarViN with two alternative genotype refinement schemes: Beagle 4.0 (r1399) (<ref type="bibr" target="#b1">Browning and Browning, 2007</ref>) and the 'no-LD' method we described in Section 2.1, which does not use LD information. We chose Beagle as a comparison due its popularity, ease-of-use and relative speed compared with other HMM routines. Notably the SHAPEIT pipeline (used to produce 1000GP Phase 3 haplotypes) requires running Beagle as a first step, and hence is more accurate but slower than Beagle. Given we expect MarViN to be substantially faster, but also less accurate, than Beagle, it is reasonable to conclude that MarViN will be faster (and less accurate) than other more computationally demanding HMM based routines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.2">High-coverage data</head><p>We took 50Â coverage of 100 bp-paired reads sequenced from the widely studied NA12878 sample (ENA AC:ERR194147). These were aligned with BWA-MEM 0.7.12 (<ref type="bibr" target="#b10">Li, 2013</ref>) and small variants were called according to GATK3.3-0 best practices (<ref type="bibr" target="#b0">Auwera et al., 2013;</ref><ref type="bibr" target="#b5">DePristo et al., 2011</ref>), the associated GLs were supplied to MarViN. If an alternate allele for a variant in the 1000GP reference panel was not detected in a given sample then we used the GL taken from the homozygous-to-reference interval in the gvcf file that overlapped the variant site. MarViN can only improve genotyping at variants seen in the reference panel (variants with LD and frequency information). Any variant called in an individual that has been seen in a curated panel such as 1000GP is likely to be real given sufficient coverage (some amount of false discovery in 1000GP notwithstanding), since these variants have already been carefully filtered. Variants called in an individual that are not present in 1000GP require more scrutiny, although we still expect tens to hundreds of thousands of novel (mostly rare) variants in a given sample. Hence we apply the hard filters described in Li (2015) to non1000GP variants using hapdip (http://bit.ly/HapDip). For variants called by GATK that intersect with 1000GP, we are less stringent, only filtering on the genotype quality (GQ) field, the phred-scaled probability that a genotype is incorrect. The GQ field is produced both by GATK and MarViN. When setting up the reference panel, we excluded NA12878 and all other CEPH1463 pedigree members from the 1000GP Phase 3 panel so as not to bias results. We only considered bi-allelic SNPs with an alternate allele count of at least five, reasoning that very rare variants were unlikely to benefit greatly from LD-based refinement. We ran MarViN for five iterations with a window size of 210 kbp with overlap of 5 kbp at each end (so each window overlaps by 10 kbp). As truth data, we used the highly accurate NA12878 call set from Platinum Genomes v7.0.0 (http://www.illumina.com/plati numgenomes). This consists of variants and confident homozygousreference intervals generated from multiple aligners/callers on the 17-member CEPH1463 pedigree. The reliability of the variant calls is enhanced by retaining only those calls whose inheritance pattern across the pedigree is consistent with Mendelian inheritance. GATK/ MarViN callsets were compared to this truth data using hap.py (https://github.com/Illumina/hap.py), a tool which compares variants via alignment and exact matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Low-coverage genotype refinement</head><p>We first evaluated each method's speed and accuracy as a function of sample size by sampling subsets of the UK10K cohort of sizes N ¼ {100,<ref type="bibr">200,</ref><ref type="bibr">500,</ref><ref type="bibr">1000,</ref><ref type="bibr">2000</ref>, 3844} and performing genotyping on a 2 Mbp window of chromosome 20 (35–37 Mbp) containing 14 416 SNPs. We measured the non-reference discordance (NRD) of each method, which is defined as (FP þ FN)/(FP þ TP þ FN), where TP, FP and FN count the number of true positive, false positive and false negative genotypes involving an alternate allele call. The advantage of NRD over discordance is that genotypes that are homozygous-reference (in both the imputed and truth set) are ignored, these counts are typically large and represent easy genotypes to call, causing a simple discordance metric to be overly optimistic. Timings were performed on a an Intel Xeon E5-2670v2 CPU with no other compute intensive processes running. We do not report compute times for no-LD as this process is dominated by I/O operations.<ref type="figure" target="#fig_1">Figure 1</ref>plots NRD (left) and compute time in hours (right) against sample size. When N ¼ 100; no-LD, MarViN and Beagle had NRD of 5.74, 5.20 and 1.26% meaning MarViN was substantially less accurate than Beagle. However, MarViNr, accuracy dramatically increases with sample size. MarViN had 0.71% NRD at N ¼ 1000 and 0.63% at N ¼ 3844 versus 0.59 and 0.38% for Beagle. Although still less accurate than Beagle, MarViN,e speed advantage widens with increasing N, it being 104Â and 1445Â faster than Beagle for N ¼ 1000 and 3844, respectively. Notably MarViNhad around 9-fold fewer errors than no-LD at N ¼ 3844 and required minimal compute resources (%14CPU 14 CPU minutes for N ¼ 3844). We then evaluated each method for both the 1000GP Phase 3 cohort (N ¼ 2535) and the UK10K (N ¼ 3844) for the entire chromosome 20 (1.63 and 0.49 million SNPs, respectively). To achieve a fair comparison of compute requirements, we gave each method exclusive use of a 20-core compute node (2 Â 10-core E5-2670v2 CPUs), running Beagle with 20 threads and running 20 simultaneous MarViN processes (concatenation time is included in the results).<ref type="figure" target="#tab_2">Table 2</ref>summarizes the accuracy and compute times. MarViN was 360Â faster than Beagle on UK10K and 46Â faster on 1000GP. MarViN.y speed advantage on 1000GP is decreased relative to UK10K due to a much larger number of SNPs. MarViN had higher NRD than Beagle with 1.66 versus 0.90% on 1000GP and 0.64 versus 0.41% on UK10K. Although these accuracy differences may seem small, the error rates are concentrated at low-frequency genotypes. For example, NRD for UK10K on MAF &lt;5% SNPs was 6.52, 2.66 and 1.20% for no-LD, MarViN and Beagle, a larger difference than when common variants are also considered. Nevertheless, MarViN has 4.64Â and 9.82Â fewer errors than the naive no-LD routine. We then investigated accuracy at different allele frequencies by binning genotypes by allele frequency and calculating Pearsonti correlation coefficient (r 2 ) between the imputed genotypes and the high-coverage validation genotypes within each bin.<ref type="figure">Figure 2</ref>plots r 2 against allele frequency (log 10 scale) for 1000GP (left) and UK10K (right). We see for common variants (AF ! 2%) Beagle and MarViN are roughly equal (and substantially better than no-LD). Beagle outperforms MarViN at lower allele frequencies.<ref type="figure">Figure 2</ref>and<ref type="figure" target="#tab_2">Table 2</ref>also suggest that MarViN performs less well on heterogeneous cohorts such as 1000GP, compared with relatively homogeneous cohorts like UK10K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">High-coverage genotype refinement</head><p>Figure 3 plots recall (proportion of PG SNPs detected and correctly genotyped) against precision (the proportion of called SNPs that are concordant with PG) for GATK before and after refinement with MarViN for increasingly liberal filters on the GQ field. MarViN refinement yields a modest, but consistent, improvement in SNP recall for a given level of precision (and vice versa).<ref type="figure" target="#tab_3">Table 3</ref>further breaks down these results. First, there were 243 381 SNPs called by GATK that were not in 1000GP (with minor allele count &gt;4), these were filtered using the hard filters in hapdip. Such SNPs cannot be further refined but we report them forTime is the compute time in hours on a 20-core (2ÂE5-2670v2 CPUs) server with 132GB RAM when using 20 threads. DIS is the percentage of discordant genotypes between the imputed genotypes and high-coverage genotypes on the CG validation samples. NRD is the discordance when not counting genotypes that were homozygous reference in both the imputed and high-coverage genotypes.Precision % Recall % GATK GATK+MarViN<ref type="figure">Fig. 2</ref>. Pearson.t correlation coefficient between imputed and true genotypes for different cohorts as a function of allele frequency for different data sets. Left: 1000GP Right: UK10Kcompleteness. Of these, 143 247 SNPs were validated in the Platinum Genomes dataset and a total of 2386 were classified as false positives due to having either incorrect genotypes, incorrect alleles or being called in a known homozygous-reference region. This yields a precision of 98.36%, which as one might expect, is lower than calls that intersect with 1000GP variants. For SNP calls that intersect 1000GP, we only applied a GQ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>96.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>The algorithm presented in this article is at least two orders of magnitude faster than Beagle on the UK10K cohort. Although this speed does come with a decrease in accuracy (particularly for rare variants), our method still makes nearly 10-fold fewer errors than a genotyping routine that does not take LD into account. The rapidly growing size of reference panels may soon preclude the use of super-linear complexity techniques such as Beagle, since computation will become too expensive. For example, the Haplotype Reference Consortium (<ref type="bibr" target="#b16">McCarthy et al., 2015</ref>) has collected 32 488 LCWGS samples to create a reference panel for imputation. Extrapolating from<ref type="figure" target="#fig_1">Figure 1</ref>, it seems unlikely it would be tractable to run Beagle on a cohort of this size. One possible use of MarViN would be to quickly generate an initial estimate of genotypes, which could then be supplied as starting values to a more sophisticated routine, reducing the number of iterations the latter needs to perform. MarViN might also be an ideal routine for intermediate coverage (%15Â) projects. The reduced accuracy of MarViN compared to Beagle at lower frequency variation is likely due to the limitations of modelling the population using one vector of allele frequencies and one covariance matrix. This simplistic model may not capture more subtle population substructure. Notably MarViN performs better on the more homogeneous UK10K cohort than on the 1000GP cohort which has far more population structure (although also has a smaller sample size). One possible way to improve this situation would be to add more flexibility to the MarViN model by using an MVN mixture distribution, but we leave this for future work. We have also demonstrated the efficacy of genotype refinement in the high-coverage scenario, the first such investigation to our knowledge. A modest gain in recall for SNPs was achieved at a cost of a negligible decrease in precision. We also attempted refining indels with this approach, gains in recall were indeed observed but were accompanied by unacceptable increases in the false-discovery rate (FDR). This may be due to a higher FDR in the 1000GP indels and could perhaps be solved via aggressive filtering. Although the improvements seen on high-coverage data are modest, we nevertheless believe it noteworthy that results achieved from high-coverage data can be improved at all by this method. Moreover the efficiency of our method means it adds little additional overhead to processing pipelines for WGS data, whereas genotype refinement using existing HMM-based methods would be a considerable computational undertaking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Performance of each method on UK10K cohort for increasing samples sizes (chr20:35M-37M). Left: NRD versus sample size for three different methods. Right: Total compute time in hours versus sample size (Color version of this figure is available at Bioinformatics online.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>.700 99.725 99.750 99.775 99.800 99.825</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>! filter. The GATK callset contained 3 387 126 SNPs, rising to 3 408 128 after refinement with MarViN. Of these, 3 309 226 and 3 317 953 were validated as correct in Platinum Genomes, meaning MarViN refinement yielded an additional 8727 correctly genotyped SNPs. In terms of effect on false positive rate, MarViN reduced the number of incorrect genotypes (with correct allele) from 1577 to 1318, as one might expect genotype refinement to do. However, MarViN also imputed a greater number of variants with incorrect alternate allele (96 versus 81) and SNPs in homozygous reference regions (1916 versus 1 037). This means MarViN had a slightly higher number of false positives than the raw GATK callset, 3330 versus 3087, bringing its precision to 99.902 versus 99.909% for GATK 99.902%. Given the gains in SNP recall, this seems a minor cost to pay.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2306 Bioinformatics, 32(15), 2016, 2306–2312 doi: 10.1093/bioinformatics/btw097 Advance Access Publication Date: 9 March 2016 Original Paper</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 1. Summary of the number of samples and SNPs for each LCWGS data set Sample size is the number of samples present in the input GLs, for UK10K this includes the UK10K control cohort (3781 samples) plus an additional 63 CG validation samples with GLs calculated from low coverage alignments. Number of SNPs is the number of non-singleton bi-allelic SNPs in each respective cohort on chromosome 20. The rightmost two columns count the number of samples and SNPs that are also in the CG validation data.</figDesc><table>Cohort 
Samples 
SNPs 
CG sample 
CG SNPs 

1000GP 
2535 
1 628 533 
287 
565 991 
UK10K 
3844 
489 278 
63 
223 528 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 2.</figDesc><table>Performance for each method on the 1000GP (N ¼ 2535) 
and UK10K (N ¼ 3844) chr20 data 

All SNPs 
MAF &lt; 5% 
Cohort Method Time 
Discordance 
(DIS) 

NRD DIS 
NRD 

1000GP no-LD 
— 
0.62 
7.71 
0.18 
11.28 
1000GP MarViN 19.03 
0.11 
1.41 
0.08 
4.74 
1000GP Beagle 
878.31 
0.07 
0.90 
0.04 
2.77 
UK10K no-LD 
— 
1.16 
6.35 
0.21 
6.52 
UK10K MarViN 
2.26 
0.11 
0.61 
0.09 
2.66 
UK10K Beagle 
812.52 
0.08 
0.44 
0.04 
1.20 

</table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">R.Arthur et al. at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank Stathis Kanterakis for providing GATK results. Conflict of Interest: All authors are employees of Illumina Cambridge Ltd., a public company that develops and markets systems for genetic analysis, and receive shares as part of their compensation.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">From FastQ data to high-confidence variant calls: the Genome Analysis Toolkit best practices pipeline</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">A</forename>
				<surname>Auwera</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Protoc. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">1110</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Rapid and accurate haplotype phasing and missing-data inference for whole-genome association studies by use of localized haplotype clustering</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Browning</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Browning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1084" to="1097" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A linear complexity phasing method for thousands of genomes</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Delaneau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="179" to="181" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Improved whole-chromosome phasing for disease and population genetic studies</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Delaneau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="5" to="6" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">1000 Genomes Project Consortium Integrating sequence and array data to create an improved 1000 Genomes Project haplotype reference panel</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Delaneau</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">3934</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">A framework for variation discovery and genotyping using next-generation DNA sequencing data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Depristo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="491" to="498" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient haplotype matching and storage using the positional Burrows Wheeler transform (PBWT)</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1266" to="1272" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">minimac2: faster genotype imputation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Fuchsberger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="782" to="784" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast and accurate genotype imputation in genome-wide association studies through pre-phasing</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="955" to="959" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Improved imputation of low-frequency and rare variants using the UK10K haplotype reference panel</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title level="m" type="main">Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM. arXiv preprint arXiv:1303.3997. https://sourceforge</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Fermikit: assembly-based variant calling for Illumina resequencing data</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="3694" to="3696" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">The sequence alignment/map format and SAMtools</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2078" to="2079" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Modelling linkage disequilibrium and identifying recombination hotspots using SNP data</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="page" from="165" to="2213" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Low-coverage sequencing: implications for design of complex trait association studies</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="940" to="951" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A new multipoint method for genome-wide association studies by imputation of genotypes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="906" to="913" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">A reference panel of 64,976 haplotypes for genotype imputation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mccarthy</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Genotype calling and phasing using next-generation sequencing reads and a haplotype scaffold</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Menelaou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="84" to="91" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A map of human genome variation from population-scale sequencing</title>
	</analytic>
	<monogr>
		<title level="m">The 1000 Genomes Project Consortium</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1061" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">An integrated map of genetic variation from 1,092 human genomes</title>
	</analytic>
	<monogr>
		<title level="m">The 1000 Genomes Project Consortium</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">The 1000 Genomes Project Consortium. (2015) A global reference for human genetic variation</title>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">526</biblScope>
			<biblScope unit="page" from="68" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">The UK10K project identifies rare variants in health and disease</title>
		<author>
			<persName>
				<forename type="first">Uk10k</forename>
				<surname>Consortium</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">526</biblScope>
			<biblScope unit="page" from="82" to="90" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Using linear predictors to impute allele frequencies from summary or pooled genotype data</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Wen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1158" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>