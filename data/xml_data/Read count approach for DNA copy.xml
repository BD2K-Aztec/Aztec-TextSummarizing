
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis Read count approach for DNA copy number variants detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Alberto</forename>
								<surname>Magi</surname>
							</persName>
							<email>albertomagi@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Medicine</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Lorenzo</forename>
								<surname>Tattini</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for the Study of Complex Dynamics (CSDC)</orgName>
								<orgName type="institution">University of Florence</orgName>
								<address>
									<postCode>50019</postCode>
									<settlement>Florence</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tommaso</forename>
								<surname>Pippucci</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Gyneacological</orgName>
								<orgName type="department" key="dep2">Medical Genetics Unit</orgName>
								<orgName type="institution" key="instit1">Obstetric and Paediatric Sciences</orgName>
								<orgName type="institution" key="instit2">University of Bologna</orgName>
								<address>
									<postCode>40138</postCode>
									<settlement>Bologna</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Francesca</forename>
								<surname>Torricelli</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Laboratory Department</orgName>
								<orgName type="department" key="dep2">Diagnostic Genetic Unit</orgName>
								<orgName type="institution">Careggi Hospital</orgName>
								<address>
									<postCode>5014</postCode>
									<settlement>Florence</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Matteo</forename>
								<surname>Benelli</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Center for the Study of Complex Dynamics (CSDC)</orgName>
								<orgName type="institution">University of Florence</orgName>
								<address>
									<postCode>50019</postCode>
									<settlement>Florence</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Laboratory Department</orgName>
								<orgName type="department" key="dep2">Diagnostic Genetic Unit</orgName>
								<orgName type="institution">Careggi Hospital</orgName>
								<address>
									<postCode>5014</postCode>
									<settlement>Florence</settlement>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">I.N.F.N, Sezione di Firenze</orgName>
								<address>
									<postCode>50100</postCode>
									<settlement>Florence</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alex</forename>
								<surname>Bateman</surname>
							</persName>
						</author>
						<title level="a" type="main">Genome analysis Read count approach for DNA copy number variants detection</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="issue">4</biblScope>
							<biblScope unit="page" from="470" to="478"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr707</idno>
					<note type="submission">Received on June 30, 2011; revised on October 18, 2011; accepted on December 19, 2011</note>
					<note>[15:17 9/2/2012 Bioinformatics-btr707.tex] Page: 470 470–478 Associate Editor: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The advent of high-throughput sequencing technologies is revolutionizing our ability in discovering and genotyping DNA copy number variants (CNVs). Read count-based approaches are able to detect CNV regions with an unprecedented resolution. Although this computational strategy has been recently introduced in literature, much work has been already done for the preparation, normalization and analysis of this kind of data. Results: Here we face the many aspects that cover the detection of CNVs by using read count approach. We first study the characteristics and systematic biases of read count distributions, focusing on the normalization methods designed for removing these biases. Subsequently, we compare the algorithms designed to detect the boundaries of CNVs and we investigate the ability of read count data to predict the exact number of DNA copy. Finally, we review the tools publicly available for analysing read count data. To better understand the state of the art of read count approaches, we compare the performance of the three most widely used sequencing technologies (Illumina Genome Analyzer, Roche 454 and Life Technologies SOLiD) in all the analyses that we perform. Contact:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Human genomes are characterized by genetic variants that range from the single base pair to large chromosomal events. Recent studies have clearly shown that human genomes differ more as a consequence of structural variants than of single-base pair differences (<ref type="bibr" target="#b6">Conrad et al., 2010;</ref><ref type="bibr" target="#b9">Durbin et al., 2010;</ref><ref type="bibr" target="#b12">Iafrate et al., 2004;</ref><ref type="bibr" target="#b14">Kidd et al., 2008;</ref><ref type="bibr" target="#b21">McCarroll et al., 2008;</ref><ref type="bibr" target="#b27">Pang et al., 2010;</ref><ref type="bibr" target="#b28">Redon et al., 2006;</ref><ref type="bibr" target="#b29">Sebat et al., 2004;</ref><ref type="bibr" target="#b30">Tuzun et al., 2005</ref>). Structural variants (SVs) are operationally defined as genomic events &gt;50 bp (<ref type="bibr" target="#b1">Alkan et al., 2011</ref>) that include copy number variants (CNVs) and balanced rearrangements such as inversions and translocations. With the sequencing of human genomes now becoming routine, the challenge is to discover the full extent of structural variations and understand its effect on human diseases, complex traits and * To whom correspondence should be addressed. evolution. The last few years have seen the emergence of several high-throughput sequencing (HTS) platforms that are based on various implementations of cyclic-array sequencing (<ref type="bibr" target="#b3">Bentley et al., 2008;</ref><ref type="bibr" target="#b22">McKernan et al., 2009;</ref><ref type="bibr" target="#b32">Wheeler et al., 2008</ref>). The commercial products that are based on this sequencing technology include the Roche's 454, the Illumina's Genome Analyzer (GA), and the Life Technologies's (LT) SOLiD. Although these platforms are quite diverse in sequencing biochemistry as well as in how the array is generated, all of them allow to sequence millions of short sequences (reads) simultaneously and are able to sequence a full human genome per week at a cost 200-fold less than previous methods. The advent of HTS platforms has opened many opportunities for the study of genomic variants. The first HTS-based approach to detect SVs was based on paired-end read mapping (PEM), which identifies insertions and deletions by comparing the distance between mapped read pairs to the average insert size of the genomic library. Although this method is able to identify deletions &lt;1 kb with high sensitivity, it does not allow for the discovery of insertions larger than the average insert size of the library and of the exact borders of SVs in complex genomic regions rich in segmental duplication (<ref type="bibr" target="#b7">Dalca et al., 2010;</ref><ref type="bibr" target="#b23">Medvedev et al., 2009</ref>). An altenative HTS-based approach is based on split-read (SR) methods that allows to detect deletions and small insertions on the basis of a split sequence-read signature: the alignment to the genome is broken and a continuous stretch of gaps in the read indicates a deletion or in the reference indicates an insertion. Although SRs approach can be devised to detect a wide range of SV classes with exact breakpoint resolution, it is currently reliable only in the unique regions of the genome. In this scenario, a very promising approach for the identification of SVs using HTS technologies consists in measuring the number of reads aligned to the human reference genome (<ref type="bibr" target="#b7">Dalca et al., 2010</ref>). Assuming the sequencing process is uniform, the number of reads mapping to a region is expected to be proportional to the number of times the region appears in the DNA sample. Following this assumption, the copy number of any genomic region can be estimated by counting the number of reads [read counts (<ref type="bibr">RCs)</ref>] aligned to that particular region.<ref type="bibr" target="#b4">Campbell et al. (2008) and</ref><ref type="bibr" target="#b5">Chiang et al. (2009)</ref>were the firsts to use this approach to detect copy number alterations between tumour and healthy samples of the same individual, while<ref type="bibr" target="#b34">Yoon et al. (2009)</ref>proposed to use RC data to look for genomic regions that differ in copy number between normal individuals of the 1000 Genomes Project (<ref type="bibr" target="#b9">Durbin et al., 2010</ref>). At present, few algorithms for RC analysis have been packagedPage: 471 470–478</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read counts and CNVs</head><p>into pipelines and are publicly available, including RDxplorer (<ref type="bibr" target="#b34">Yoon et al., 2009</ref>), ReadDepth (<ref type="bibr" target="#b24">Miller et al., 2011</ref>), CNAseg (<ref type="bibr" target="#b13">Ivakhno et al., 2010</ref>), CNV-seq (<ref type="bibr" target="#b33">Xie and Tammi, 2009</ref>), JointSLM (<ref type="bibr" target="#b20">Magi et al., 2011</ref>) and CNVnator (<ref type="bibr" target="#b0">Abyzov et al., 2011</ref>) (see<ref type="figure" target="#tab_1">Table 1</ref>and Supplementary Material). The analysis pipeline implemented in these packages for discovering CNVs is conceptually derived from array-CGH (aCGH) data analysis and can be divided into four fundamental steps:Data preparation consists in filtering and counting the number of mapped reads in non-overlapping genomic windows of length W. Once the RCs have been estimated, the first transformation applied to the data, referred to as normalization, adjusts the individual RC to appropriately mitigate systematic biases so that meaningful biological comparisons can be made. Normalized RCs are then sorted according to genomic position and statistical methods are applied to detect the boundaries of the regions with changed copy number. The last step of the analysis pipeline consists in estimating the DNA copy number of each region within breakpoints. In the present article, we face the many aspects that cover the detection of CNVs by using RCs approach. We study all the steps necessary to infer the copy number of a genomic segment: RC estimation, RC normalization, CNV regions detection and copy number estimation. To better understand the state of the art of RC approach, we compare the performance of the three most used sequencing technologies (Illumina GA, Roche 454 and Life Technologies SOLiD) by using both high (20–40×) and low coverage (4– 6×) sequencing data generated by the 1000 genomes project consortium (see<ref type="figure" target="#tab_2">Table 2</ref>and Supplementary Material for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data preparation</head><p>RC method belongs to the category of resequencing approaches, and the first fundamental step of this analysis consists in mapping the set of short reads against a reference genome by means of short read aligners (see Supplementary Material). Once short reads have been aligned to the reference genome, we need to perform a series of preparation steps before RC estimation. These steps include: @BULLET Removal of duplicated sequences. @BULLET Removal or flagging of sequences with low mapping quality (MQ). @BULLET Choice of the best window/bin size.</p><p>The main purpose of removing duplicates is to mitigate the effects of PCR amplification bias introduced during library construction. All the analyses performed in this article have been made on aligned data with duplicated reads removed by means of rmdup command of samtools (<ref type="bibr" target="#b17">Li et al., 2009</ref>) (Supplementary Material). After duplicated reads removal, low MQ sequences need to be taken into consideration: sequences with low MQ score usually fall in repetitive regions of the reference genome or have low base quality. For these reasons,<ref type="bibr" target="#b20">Magi et al. (2011) and</ref><ref type="bibr" target="#b34">Yoon et al. (2009)</ref>removed all the reads with MQ &lt; 30. Conversely,<ref type="bibr" target="#b0">Abyzov et al. (2011)</ref>used the reads with MQ score equal to zero to classify CNVs called in duplicated or retrotransposon regions of the reference genome. Finally, the best window/bin size needs to be estimated.<ref type="bibr" target="#b34">Yoon et al. (2009) and</ref><ref type="bibr" target="#b20">Magi et al. (2011)</ref>chose a window size of 100 bp for the high coverage data of the 1000 genomes project (20–40× coverage) because a larger window size would provide less precision in defining the breakpoints of CNVs and because at 30× coverage, the distribution of RCs of 100 bp windows are well approximated by a normal distribution, while RCs in smaller window sizes are not.<ref type="bibr" target="#b13">Ivakhno et al. (2010)</ref>used a bin size of 50 bp for the analysis of the COLO-829 malignant melanoma cell line sequenced at 40× coverage.<ref type="bibr" target="#b0">Abyzov et al. (2011)</ref>found that the optimal bin size, and thus breakpoint resolution accuracy, scales inversely with the coverage, resulting in ∼ 100 bp bins for 20–30× coverage, ∼ 500 bp bins for 4–6× coverage and ∼ 30 bp bins for 100× coverage. At present, only two papers have introduced a method to automatically estimate the best window size.<ref type="bibr" target="#b24">Miller et al. (2011)</ref>propose to estimate the best window size by modelling RCs by means of a negative binomial distribution. They generate a negative binomial distribution with mean μ = λ (with λ = N * W /G, where N is the total number of read, W is the bin size and G is the genome size), and size parameter θ = λ/(i−1), where i is the index of dispersion. Then they generate distributions using the expected number of reads with copy number of one, two and three, and choose a threshold value for gains and losses that minimizes the number of bins that are misclassified. The FDR can then be calculated as the number of misclassified bins divided by the total number of bins. Xie and<ref type="bibr" target="#b33">Tammi (2009)</ref>calculate the best possible resolution (i.e. the best possible window size) according to a preset value for significance level p and CNV detection threshold r (Supplementary Material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">RC biases and normalization</head><p>RCs data are affected by two main sources of bias: the local GC content and the genomic mappability. The correlation between read coverage and DNA<ref type="bibr" target="#b24">Miller et al., 2011</ref>) is due to the fact that the genome contains many repetitive elements and aligning reads to these positions leads to ambiguous mapping. In order to minimize the effect of these sources of variation and make data comparable within and between samples, RCs need to be normalized. At present, there are two approaches for correcting RC data for sequencing biases due to local GC content.<ref type="bibr" target="#b5">Chiang et al. (2009)</ref>proposed to mitigate the dependence between local GC content and RC by using the ratio of the number of reads in tumour DNA and its paired normal DNA, processed at the same time.<ref type="bibr" target="#b34">Yoon et al. (2009)</ref>proposed to adjust the RCs by using the observed deviation in coverage for a given GC percentage. In practice, for all the GC percentages (0, 1, 2, ... , 100%) they determined the deviation of coverage from the genome average and then corrected each RC according to the following formula:</p><formula>RC i = RC i · m m GC ,</formula><formula>(1)</formula><p>where RC i are read counts of the i-th window, m GC is the median RC of all the windows that have the same GC percentage as the i-th window, and m is the overall median of all the windows. Mappability normalization has been faced in two different papers.<ref type="bibr" target="#b24">Miller et al. (2011)</ref>proposed to correct for mappability by multiplying the number of reads in a given bin by the inverse of the percent mappability in that region, whrease<ref type="bibr" target="#b13">Ivakhno et al. (2010)</ref>proposed to use an undecimated discrete wavelet transform (DWT) to smooth RCs in the regions of low alignability. Here we propose to correct RC for mappability bias with a novel normalization scheme inspired by the GC content normalization of<ref type="bibr" target="#b34">Yoon et al. (2009)</ref>: RCs are corrected by using the observed deviation in coverage for a given mappability score. Each RC is corrected by the following formula:</p><formula>RC i = RC i · m m MAP .</formula><formula>(2)</formula><p>where RC i are RCs of the i-th window, m MAP is the median RC of all the windows that have the same mappability score as the i-th window, and m is the overall median of all the windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">CNVs detection algorithms</head><p>Once the RCs have been corrected for local GC content and mappability, the data that we obtain are mathematically very similar to the signal obtained from aCGH experiments. Deletions or duplications are identified as decrease or increase of RC across multiple consecutive windows. Moreover, like aCGH data, RC signals are affected by noise caused by mapping errors and random fluctuations in genome coverage. For these reasons, the events in RC data can be detected using the same algorithmic approaches that have been used for aCGH data. At present, few statistical methods have been developed and tested for the detection of CNVs from RC data. Some of these algorithms come from microarray literature while others have been tailored for this kind of data.<ref type="bibr" target="#b4">Campbell et al. (2008) and</ref><ref type="bibr" target="#b24">Miller et al. (2011)</ref>used the circular binary segmentation algorithm (CBS) (<ref type="bibr" target="#b26">Olshen et al., 2005</ref>), originally developed for genomic hybridization microarray data, and both applied it to sequencing data generated by the Illumina GA platform.<ref type="bibr" target="#b20">Magi et al. (2011)</ref>extended the shifting level model (SLM) (<ref type="bibr" target="#b19">Magi et al., 2010</ref><ref type="bibr" target="#b13">Ivakhno et al. (2010)</ref>introduced CNASeg, an HMM-based algorithm to segment the RC data, followed by a segment merging step. The CNASeg method was originally applied to cancer sequencing data generated by the Illumina GA platform. While the first four statistical methods require only one sample at once, the approaches of Xie and Tammi (2009) and<ref type="bibr" target="#b13">Ivakhno et al. (2010)</ref>need the sequencing data of two samples. The EWT and CNV-seq methods are sliding window approaches that converts RC data into a statistic (t-statistic for CNVseq and Z-score for EWT) and infer altered regions by using the distribution of that statistic. Conversely, the CBS, SLM, MSB and CNASeg algorithms are segmentation methods that allow to split RC data into segments, each containing the same number of DNA copies. Segments with an altered DNA copy number are detected by means of a simple threshold method (<ref type="bibr" target="#b4">Campbell et al., 2008;</ref><ref type="bibr" target="#b13">Ivakhno et al., 2010;</ref><ref type="bibr" target="#b20">Magi et al., 2011;</ref><ref type="bibr" target="#b24">Miller et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Copy number estimation</head><p>The statistical methods introduced in the previous section allow for the identification of genomic regions with altered DNA copy counts by detecting the border of consecutive windows with increased or reduced RCs. Once the limits of the altered region has been detected, the estimation of DNA copy number (genotyping) for those regions must be performed.<ref type="bibr" target="#b4">Campbell et al. (2008</ref><ref type="bibr" target="#b34">), Yoon et al. (2009</ref><ref type="bibr" target="#b20">) and Magi et al. (2011</ref>estimated DNA copy number by rounding the median of the RCs (normalized to copy number 2) of each detected region to the nearest integer, while<ref type="bibr" target="#b0">Abyzov et al. (2011)</ref>assigned copy number to each genomic region by calculating its RC signal normalized to the genomic average for the region of the same length. These simple estimation strategies follow the assumption that the sequencing process is uniform and consequently the number of read that maps to a genomic region is expected to be proportional to the number of times the regions appears in the DNA sample: a genomic region that has been deleted (duplicated) will have less (more) reads mapping to it than a region not deleted (duplicated).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read counts and CNVs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data filtering and bin size estimation</head><p>To understand the effect of removing sequences with low MQ on RC distributions, we calculated the signal to noise ratio (SNR) for different MQ threshold and different windows size W (see Supplementary Material for more details) and the results are reported in Supplementary<ref type="figure" target="#fig_3">Figure S1</ref>. The SNR has been calculated by means of the following formula:</p><formula>SNR = m σ 2 ,</formula><formula>(3)</formula><p>where m is the median value of the normalized RC of genomic regions predicted as two copies while σ 2 is the variance of the normalized RC of regions predicted to be one copy by<ref type="bibr" target="#b21">McCarroll et al. (2008)</ref>. The results of these analyses show that filtering out reads with low MQ slightly affects the SNR of RC data. These results suggest not to remove low MQ reads, since they can be used for subsequent analysis as in<ref type="bibr" target="#b0">Abyzov et al. (2011)</ref>. In order to investigate the performance of the two bin size estimation methods proposed by Xie and Tammi (2009) and<ref type="bibr" target="#b24">Miller et al. (2011)</ref>, we simulated sequencing data for different coverage for the three HTS platforms (see Supplementary Material for more details). The results of these analyses are reported in Supplementary<ref type="figure" target="#fig_5">Figure S2</ref>. As expected, the larger is the coverage of the sequencing data and the smaller is the bin size predicted by the two methods. The method proposed by Xie and Tammi (2009) estimates bins of similar size for the Illumina and SOLiD platforms. This is due to the fact that the Xie and Tammi estimation procedure does not take into account the overdispersion of RC distributions. Conversely, the approach proposed by<ref type="bibr" target="#b24">Miller et al. (2011)</ref>allows for a better estimation of the bin size for the three HTS technologies, taking advantage of the use of the index of dispersion. However, the bin sizes predicted by the two methods are not optimal: for Illumina platform, at 30× coverage, the Miller method estimate a bin size of 1000 bp, while at 5× coverage it estimates a bin size of 6600 bp. These estimates are at least 10 times higher than those reported by<ref type="bibr" target="#b34">Yoon et al. (2009</ref><ref type="bibr" target="#b20">), Magi et al. (2011</ref><ref type="bibr" target="#b0">) and Abyzov et al. (2011</ref>: for instance, by using a bin size of 100 bp for 20–30× coverage data, the JointSLM and EWT algorithms were able to detect CNV regions as small as 500 bp with a true positive rate &gt;0.8 and with a minor fraction of false positive events of this size (<ref type="bibr" target="#b20">Magi et al., 2011</ref>). The use of the bin sizes estimated by the method of<ref type="bibr" target="#b24">Miller et al. (2011)</ref>(i.e. 1000 bp for high coverage) does not allow for the detection of CNVs as small as 500 bp leading to a loss of resolution and accuracy in the discovery of genomic variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">RC distribution and biases</head><p>The detection of CNVs using RC analysis is based on the assumption that the reads are randomly and independently sampled from any location of the test genome with equal probability. Under this assumption, the distribution of the count of reads that map into a window of the reference genome should be Poissonian. However,<ref type="bibr" target="#b3">Bentley et al. (2008) and</ref><ref type="bibr" target="#b34">Yoon et al. (2009)</ref>have previously reported that RCs by Illumina GA follow a Poisson distribution with a slight overdispersion. In order to study the properties of RC distribution, we analysed high and low coverage sequencing data generated by the 1000 genomes project consortium and we used different values of W for the three HTS platforms (see Supplementary Material for moredetails). The results of these analyses are summarized in<ref type="figure" target="#fig_3">Figure 1</ref>and Supplementary<ref type="figure" target="#fig_6">Figure S3</ref>and clearly show that RC data can be modelled by means of a negative binomial distribution. According with the results of<ref type="bibr" target="#b3">Bentley et al. (2008) and</ref><ref type="bibr" target="#b34">Yoon et al. (2009)</ref>, we found that RC distribution for Illumina and SOLiD platforms exhibit an index of dispersion (ratio between variance and mean) largely greater than one. Conversely, 454 platform produces the RC data distribution with the lower ratio between variance and mean (Supplementary Tables S1 and S2). The overdispersion of RC data distributions can be accounted for to three main sources: @BULLET The existence of genomic regions of duplications and deletions (CNVs).) Correlation between RC data and region mappability for the three HTS platforms (GA, 454 and SOLiD). Upper border of the dashed lines represent the 90th percentile of the normalized RCs, while the lower border represent the 10th percentile. Upper border and lower border of the solid lines represent the 90th percentile and the 10th percentile, respectively, of the poisson distribution with mean = mean value of the RCs. To obtain the histograms without CNV (grey bar) of<ref type="figure" target="#fig_3">Figure 1a</ref>, d and g, we removed from RC data all the CNV regions that belong to the Database of Genomic Variants and the CNV regions previously identified by<ref type="bibr">McCarrol et al.</ref>fraction of the genome subject to variation of the copy number is ∼3.7% (<ref type="bibr" target="#b6">Conrad et al., 2010</ref>). This means that a considerable amount of genomic regions contains an average number of reads smaller or greater than the global average number of reads. The removal of genomic regions with known CNVs reduces the index of dispersion of RC data distribution for all the three HTS platforms for high and low coverage data. We investigated the relationship between RC and GC content (Supplementary Materials) for all the three HTS platforms and according with the results of<ref type="bibr" target="#b10">Harismendy et al. (2009</ref><ref type="bibr" target="#b8">), Dohm et al. (2008</ref><ref type="bibr" target="#b11">) and Hillier et al. (2008</ref>we observed that RC is maximum for values of GC content between 35% and 60% while it decreases at both extremes. In particular, we observed that GC content bias is larger for GA and SOLiD platforms, while it is smaller for the ROCHE data (see Figures 2b, e and h and Supplementary<ref type="figure" target="#fig_7">Fig. S4</ref>). This is confirmed by the statistics reported in Supplementary Tables S3 and S4, where the percent variation between the raw index of dispersion and the GC index of dispersion is much larger for GA and SOLiD data than for the Roche data. The analysis of regional mappability (<ref type="figure" target="#fig_5">Figure 2c</ref>, f and i and Supplementary<ref type="figure" target="#fig_7">Fig. S4</ref>) show a strong correlation between RC data and genome mappability: the RC distribution for high mappability score is closer to Poissonian than genomic regions with low mappability (low mappability regions show large RC overdispersion). Moreover, for GA and 454, the mappability has little effect on the mean number of aligned reads at each bin of mappability score, while, for SOLiD platform, the mappability strongly affect the RC mean value. Also these results are confirmed by the statistics reported in Supplementary Tables S3 and S4: the percent variation between the raw index of dispersion and the mappability index of dispersion is very large for the SOLiD platform (65% and 83% for high coverage and about 60% for low coverage) while it is comparable to other source of variation for GA and 454 platforms. This can also explain why SOLiD platform shows the highest value of the index of dispersion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">RC data normalization</head><p>In order to evaluate the performance of the five normalization approaches described in Section 2, we applied them to the high and low coverage data generated by the 1000 genomes project consortium and the results of these comparisons are reported in<ref type="figure" target="#fig_6">Figure 3</ref>and Supplementary<ref type="figure" target="#fig_8">Figure S5</ref>for GC content and in<ref type="figure" target="#fig_7">Figure 4</ref>and Supplementary<ref type="figure" target="#fig_11">Figure S6</ref>for mappability. The ratio approach proposed by<ref type="bibr" target="#b5">Chiang et al. (2009)</ref>(see<ref type="figure" target="#fig_6">Figure 3c</ref>, f and i and Supplementary<ref type="figure" target="#fig_8">Figure S5</ref>) is not able to remove the GC content effect for all the three HTS platforms, while it performs very well in mitigating the mappability bias also in the case of the SOLiD platform where the mappability effect is very strong (see<ref type="figure" target="#fig_7">Figure 4e</ref>, j and o and Supplementary<ref type="figure" target="#fig_11">Fig. S6</ref>). The GC content normalization approach proposed by<ref type="bibr" target="#b34">Yoon et al. (2009)</ref>(see<ref type="figure" target="#fig_6">Figure 3b</ref>, e and h and Supplementary<ref type="figure" target="#fig_8">Fig. S5</ref>) is able to properly remove the GC content effect for all the three HTS platforms. The comparison between the other three mappability normalization methods clearly show that the approaches proposed by<ref type="bibr" target="#b24">Miller et al. (2011)</ref>(see<ref type="figure" target="#fig_7">Figure 4c</ref>, h and m and Supplementary<ref type="figure" target="#fig_11">Fig. S6</ref>) and<ref type="bibr" target="#b13">Ivakhno et al. (2010)</ref>(see<ref type="figure" target="#fig_7">Figure 4d</ref>, i and n and Supplementary<ref type="figure" target="#fig_7">Fig. S4</ref>) are not able to completely correct the non-linear bias produced by genomic regions with low mappability. These analyses also demonstrate that the approach introduced by<ref type="bibr" target="#b24">Miller et al. (2011)</ref>generates additional biases and has the disadvantage that much data are discarded since RCs with extremely low mappability (&lt; 25%) are filtered out to prevent overcorrection. The additional bias generated by the<ref type="bibr" target="#b24">Miller et al. (2011)</ref>method is due to the assumption that RC is proportional to the percent of mappability: multiplying RC data by the inverse of percent mappability leads to overcorrection. Conversely, the mappability normalization scheme proposed in this article (<ref type="figure" target="#fig_7">Figure 4b</ref>, g and l and Supplementary<ref type="figure" target="#fig_11">Fig. S6</ref>) allows to correct this bias without filtering out RC data. Moreover, also in the case of the highly biased SOLiD data the median method permits correction of RC mean value. The results of all these analyses indicate that the normalization method by<ref type="bibr" target="#b34">Yoon et al. (2009)</ref>and the median method are the best strategies to remove GC content and mappability biases, respectively. Moreover,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 475 470–478</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read counts and CNVs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">CNV regions identification</head><p>To test the ability of different algorithms in detecting CNVs of different size, we made an intensive simulation based on synthetic chromosomes generated from RCs of the individuals NA12878 and NA19240 for high coverage sequencing data and the individuals NA11840, NA11830 and NA12043 for low coverage sequencing data. The principal aim of these simulations is to evaluate and compare the capability of each algorithm in detecting sudden shifts in the mean value of the signal as a function of the width of the shift. For this purpose, we have built a benchmark synthetic dataset generated by using GC-and mappability-adjusted RC data with the same normalization scheme: GC correction was performed by means of the<ref type="bibr" target="#b34">Yoon et al. (2009)</ref>normalization scheme, while the mappability bias was corrected by means of the median normalization scheme. Each synthetic chromosome was generated by sampling RC data windows from genomic regions previously predicted as two-copy and one-copy by<ref type="bibr" target="#b21">McCarroll et al. (2008)</ref>to simulate both normal copy count and altered regions (see Supplementary Material for more details). We compared the performance of the six algorithms described in Section 2: two sliding window methods (CNVseq, EWT) and four segmentation algorithms (CBS, SLM, MSB and the HMM of CNASeg). To evaluate the performance of the six algorithms, we used two different strategies. To test the capability of each algorithm in discovering CNVs, we used the approach previously used by<ref type="bibr" target="#b34">Yoon et al. (2009) and</ref><ref type="bibr" target="#b20">Magi et al. (2011)</ref>: a detected segment is considered a true positive (TP) if there is any overlap between the detected segment and the synthetic altered region, and is considered a false positive (FP) if there is no overlap with a synthetic altered region. To understand the accuracy of the six methods in detecting CNVs at the boundaries (breakpoints detection), we computed the receiver operating characteristic (ROC) curve as in<ref type="bibr">Lai et al. (2010)</ref>and we calculated the area under the ROC curve (AUC). The results of all the simulations are summarized in<ref type="figure" target="#fig_8">Figure 5</ref>and Supplementary<ref type="figure">Figure S7</ref>–S38. Globally, the algorithms that ensure the best results in terms of both sensitivity and specificity are the EWT and the SLM methods. The CBS and MSB algorithms obtain good results in detecting alterations made of a large number of windows (N = 50 and N = 100), while their performance reduces for alterations made of a small number of windows (N = 5 and N = 10). The HMM algorithm of the CNASeg package performs well on RCs generated from high coverage sequencing data while leads to modest results for low coverage data. The CNVseq method gives poor results for both high and low coverage data with all the bin size we simulated. The CNVs detection analyses (Supplementary Figures S31–S38) show that for high coverage data from GA platform the EWT and SLM algorithms are able to detect genomic alterations as small as 500 bp and 1 kb, respectively, with a TPR &gt;0.8 and with a minor number FP events. On the same data, the CBS, MSB and CNASeg methods enable the detection of CNVs as small as 2–5 kb with a TPR &gt;0.8 and small number of FP events. For low coverage data (Illumina GA platform), the EWT and SLM methods are able to discover genomic alterations as small as 5 kb, while CBS, MSB and CNASeg detect CNVs as small as 25 kb. The CNVseq algorithm identifies a very large number of FP events for both high and low coverage sequencing data making its use difficult for the detection of genomic regions involved in CNVs. The ROC curves reported in Supplementary Figures S11– S30 show that segmentation algorithms (SLM, CBS, MSB and the HMM of CNASeg) have low FPR at the expense of low TPR, while smoothing algorithms (EWT and CNVseq) have high TPR at the expense of high FPR. Moreover, as reported in<ref type="bibr">Lai et al. (2010)</ref>, ROC curves are informative in understanding how an algorithm performs in estimating the boundary of the altered region. When the algorithm over-estimates the boundary, FPR increases while TPR remains fixed. Conversely, when an algorithm under-estimates the boundary, TPR decreases while FPR remains fixed. Bearing this in mind, the ROC curves reported in Supplementary Figures S11–S30 suggest that segmentation methods (SLM, CBS, MSB and the HMM of CNASeg) tend to under-estimate the boundaries of CNV, while the EWT algorithm tend to over-estimate the boundaries of the CNV Page: 476 470–478, CNAseg, CBS, SLM and MSB) are compared in the analysis of synthetic chromosomes. Synthetic chromosomes are obtained from high and low coverage sequencing data of the three HTS platforms for bin size of different length (W = 100 bp, W = 500 bp, W = 1000 bp and W = 2000 bp). For each algorithm, the area under the curve is averaged across 1000 simulations. Each bar of the plot is obtained averaging the performance of each algorithm for all the alteration widths simulated (N = 5, N = 10, N = 20, N = 50, N = 100).regions. According to the AUC results, the CNVseq algorithm obtain poor results in terms of both sensitivity and specificity. All these results reflect the algorithmic nature of each method: as reported in aCGH literature, smoothing approaches allow for the detection of small genomic events but with low breakpoint resolution, while segmentation strategies are more suited for the identification of larger events with high breakpoint resolution. The barplots of<ref type="figure" target="#fig_8">Figure 5</ref>and Supplementary<ref type="figure">Figures</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.Magi et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read counts and CNVs</head><p>bin sizes we studied. Moreover, we found that the detection of DNA alterations in samples with low sequencing coverage is identical to analysing samples with high sequencing coverage if a bin size is larger. In particular, we found that the Illumina platform obtains high accuracy for bin size W = 100 bp at high coverage and W = 500 bp at low coverage, while the 454 and SOLiD platforms give good results for bin size W = 500 bp for high coverage and W = 1000 bp for low coverage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Copy number estimation</head><p>To study the relationship between DNA copy number and RCs data, we examined several broad genomic regions that were previously reported to have copy numbers equal to 0, 1, 2, 3 and 4 by<ref type="bibr" target="#b21">McCarroll et al. (2008)</ref>(Supplementary Material). We analysed RC data of these regions for different window sizes for the high and low coverage sequencing data generated with the three HTS platforms. The results of all these analyses are reported in<ref type="figure" target="#fig_11">Figure 6</ref>(high coverage data) and Supplementary<ref type="figure" target="#fig_3">Figure S11</ref>(low coverage data) and clearly reflect the overdispersion of the RC distributions generated by the three sequencing technologies. For GA and 454 platforms, we observed an excellent agreement between mean RCs and DNA copy number for high coverage data for all the bin sizes we analysed, while for SOLiD platform we found that RC are not well correlated with validated DNA copy number. For low coverage data, we found a smaller correlation coefficient for all the HTS platforms. However, also in this case GA and 454 technologies better predict the absolute value of DNA copy number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION AND CONCLUSION</head><p>The use of RC of sequences aligned to a reference genome is, at present, the most powerful method to accurately predict absolute copy numbers of genomic regions. Although this computational strategy has been recently introduced in literature, much work has been already done for the preparation, normalization and analysis of this kind of data. Normalization methods allow to remove systematic biases due to local GC content and region mappability: the results reported here clearly show that the best way to remove local GC content bias is the Yoon et al. approach, while the best scheme to correct mappability bias is the median method proposed in the present article. CNVs detection algorithms can be exploited to detect CNVs with an unprecedented resolution that in the best case reaches the order of hundreds of base pair. In all the simulations, we performed we found that the EWT and SLM algorithms give the best results in terms of both sensitivity and specificity. The resolution of CNV detection can be improved by increasing the SNR of RC signals: reducing the sequencing error rate or increasing the coverage of the sequencing experiments will improve the performance of statistical methods in detecting small shifts in the signals. Automatic strategies for bin size calculation fail in estimating the optimal bin size whatever the coverage. Although the method proposed by<ref type="bibr">Miller et al.</ref>models RC data by means of a negative binomial distribution, it overestimates the bin size leading to a loss of resolution accuracy. After an intensive simulation on synthetic data, we found that the best way to choose the optimal bin size is following the suggestion of<ref type="bibr">Abyzov et al.:</ref>100 bp window for 20–30× coverage, 500 bp window for 4–6× coverage and 50 bp window for 100× coverage. The comparison between the three HTS platforms clearly showsthat the Illumina platform allow to obtain the best level of accuracy and resolution in the discovery of genomic regions involved in CNV and the prediction of absolute DNA copy number. Although RC approach is the only sequencing-based method to accurately predict absolute DNA copy numbers, it has distinct advantages and disadvantages over other approaches in detecting certain classes of SVs and the breakpoint resolution is often poor with respect to other sequencing-based methods. The analyses employed with different approaches [PEM, SR (<ref type="bibr" target="#b25">Mills et al., 2006</ref>) and RC] on the same data in the framework of the 1000 Genomes Project show that RC-based approach can better ascertain CNVs in segmental duplication than PEM-based methods. Conversely, RC methods mostly miss CNVs consisting entirely of a single retrotransposon (LINE, SVA or HERV-K) that are easily detected by PEM and SR approaches. Additionally, RC analysis is not able to detect balanced rearrangements that can be instead discovered by PEM and split read methods. The comparison with the CNVs identified by microarray technologies shows that the great majority of the calls overlapped between the two methods (<ref type="bibr" target="#b1">Alkan et al., 2011;</ref><ref type="bibr" target="#b20">Magi et al., 2011;</ref><ref type="bibr" target="#b34">Yoon et al., 2009</ref>). Despite the great overlap Page: 478 470–478</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.Magi et al.</head><p>between RC and microarray calls, RC is better than microarray at detecting smaller events and does not suffer from oversaturation at high copy counts, allowing a more accurate estimation of very high copy counts. While the sections discussed above describe the great progress achieved over the last 3 years in using RC data to discover CNVs, much work remains. When RC data are used to analyse tumour samples, statistical approach to infer copy number should take into account cellularity and tumoural heterogeneity and for this reason we would need a more sophisticated approach similar to CGHcall (van de<ref type="bibr" target="#b31">Wiel et al., 2007</ref>) or FastCall (<ref type="bibr" target="#b2">Benelli et al., 2010</ref>) instead of using the simple rounding to the closest integer. Finally, the breakpoint resolution of RC methods is often poor with respect to other sequencing-based approaches. However, given the approximate CNV breakpoint detected by an RC approach, the detection precision can be brought to 1 base resolution by refining the breakpoint by means of SRs techniques. The ultimate way to accurately detect all forms of genomic structural variants is de novo assembly (<ref type="bibr">Levy et al., 2010;</ref><ref type="bibr" target="#b18">Li et al., 2011</ref>). Nevertheless, assembly approaches are still in their early stages and are capable to type structural variants only if the sequence reads are long and accurate enough to allow de novo assembly. Moreover, assembly algorithms have been shown to collapse in highly repeated and highly duplicated genomic regions (<ref type="bibr" target="#b1">Alkan et al., 2011</ref>). Albeit assembly approaches show a lot of potential (facilitating the pairwise genome comparison) their application as routine methods still need further efforts, in both computational and technological developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[15:17 9/2/2012 Bioinformatics-btr707.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>) algorithm to detect recurrent CNVs across multiple samples and tested its performance on Illumina high coverage data from 1000 genomes project samples. Abyzov et al. (2011) exploited a mean-shift algorithm (MSB), previously applied to the analysis of aCGH data, to partition RC signals to the end of detecting CNVs. MSB was tested on data produced by Illumina and SOLiD platforms. Yoon et al. (2009) developed a new method based on significance testing (EWT) that works on intervals of data points: EWT searches the entire genome for specific classes of small events that meet criteria of statistical significance, and then clusters of small events are grouped into larger events. EWT was applied to high coverage Illumina data produced by the 1000 genome project consortium. Xie and Tammi (2009) used a sliding window approach, named CNV-seq, to analyse the ratios between RCs from two individuals (Normal and Tumour). The observed ratios are assessed by the computation of the probability of a random occurrence, given no CNV. Xie and Tammi (2009) tested their algorithm on shotgun sequencing data of Dr Craig Venter and Dr James D. Watson generated by Sanger and 454 platforms, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.1.</head><figDesc>Fig. 1. RC distributions for the three HTS platforms at high-sequencing coverage. The plot reports the histogram of the RC distributions for the three HTS platforms [Illumina GA (a), Roche 454 (b) and LT SOLiD (c)] for three different window size (W = 1000 bp, W = 2000 bp and W = 5000 bp). For each window size is also reported the Poisson distribution (dashed line) with mean = μ and the negative binomial distribution (solid line) with mean = μ and variance = σ 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>@BULLET</head><figDesc>The correlation between read coverage and the DNA local GC content. @BULLET The correlation between read coverage and the mappability (i.e. the inability to map reads into repetitive regions of the genome). The effect of CNV regions on the distribution of RC data are reported in Figure 2a, d and g, in Supplementary Figure 4a,d and g and in Supplementary Tables S3 and S4. The current estimation of the Page: 474 470–478 A.Magi et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.2.</head><figDesc>Fig. 2. Sources of Overdispersion of RC distribution for high sequencing coverage. (a, d, g) Histograms of the RC with (white bar) and without (grey bar) CNVs regions for Illumina, 454 and SOLiD platforms, respectively. (b, e, h) Correlation between RC data and GC content for the three HTS platforms (GA, 454 and SOLiD). (c, f, i) Correlation between RC data and region mappability for the three HTS platforms (GA, 454 and SOLiD). Upper border of the dashed lines represent the 90th percentile of the normalized RCs, while the lower border represent the 10th percentile. Upper border and lower border of the solid lines represent the 90th percentile and the 10th percentile, respectively, of the poisson distribution with mean = mean value of the RCs. To obtain the histograms without CNV (grey bar) of Figure 1a, d and g, we removed from RC data all the CNV regions that belong to the Database of Genomic Variants and the CNV regions previously identified by McCarrol et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.3.</head><figDesc>Fig. 3. Local GC content normalization methods. Effect of median normalization of Yoon et al. and ratio normalization of Chiang et al. on the local GC content for high sequencing coverage data. (a, d, g) Dependencies between RC data and local GC content for the three HTS platforms [GA (a), 454 (d), SOLiD (g)]. (b, e, h) Effect of the median method proposed by Yoon et al. for the removal of the local GC content bias for the three HTS platforms [GA (b), 454 (e), SOLiD (h)]. (c, f, i) Effect of ratio normalization proposed by Chiang et al. for the mitigation of the local GC content bias for the three HTS platforms [GA (c), 454 (f), SOLiD (i)]. Upper border of the dashed lines represent the 90th percentile of the normalized RCs, whereas the lower border represent the 10th percentile.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.4.</head><figDesc>Fig. 4. Mappability normalization. Comparison between the four mappability normalization methods (median correction, Miller et al., Ivakhno et al. and ratio normalization) on the high sequencing coverage data of the three HTS platforms. (a, f, k) Dependencies between RC data and region mappability for the three HTS platforms [GA (a), 454 (f), SOLiD (k)]. (b, g, l) Results of the median correction method for the removal of the region mappability bias for the three HTS platforms [GA (b), 454 (g), SOLiD (l)]. (c, h, m) Results of the Miller et al. correction method for the removal of the region mappability bias for the three HTS platforms [GA (c), 454 (h), SOLiD (m)]. (d, i, n) Results of the Ivakhno et al. wavelet-based correction method for the removal of the region mappability bias for the three HTS platforms [GA (d), 454 (i), SOLiD (n)]. (e, j, o) Results of the ratio correction method for the removal of the region mappability bias for the three HTS platforms [GA (e), 454 (j), SOLiD (o)]. Upper border of the dashed lines represent the 90th percentile of the normalized RCs, whereas the lower border represent the 10th percentile.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.5.</head><figDesc>Fig. 5. Comparison between CNV detection algorithms. Six CNV detection algorithms (EWT, CNVseq, CNAseg, CBS, SLM and MSB) are compared in the analysis of synthetic chromosomes. Synthetic chromosomes are obtained from high and low coverage sequencing data of the three HTS platforms for bin size of different length (W = 100 bp, W = 500 bp, W = 1000 bp and W = 2000 bp). For each algorithm, the area under the curve is averaged across 1000 simulations. Each bar of the plot is obtained averaging the performance of each algorithm for all the alteration widths simulated (N = 5, N = 10, N = 20, N = 50, N = 100). (a) Illumina GA high coverage. (b) Roche 454 high coverage. (c) LT SOLiD high coverage. (d) Illumina GA low coverage. (e) Roche 454 low coverage. (f ) LT SOLiD low coverage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><figDesc>Fig. 5. Comparison between CNV detection algorithms. Six CNV detection algorithms (EWT, CNVseq, CNAseg, CBS, SLM and MSB) are compared in the analysis of synthetic chromosomes. Synthetic chromosomes are obtained from high and low coverage sequencing data of the three HTS platforms for bin size of different length (W = 100 bp, W = 500 bp, W = 1000 bp and W = 2000 bp). For each algorithm, the area under the curve is averaged across 1000 simulations. Each bar of the plot is obtained averaging the performance of each algorithm for all the alteration widths simulated (N = 5, N = 10, N = 20, N = 50, N = 100). (a) Illumina GA high coverage. (b) Roche 454 high coverage. (c) LT SOLiD high coverage. (d) Illumina GA low coverage. (e) Roche 454 low coverage. (f ) LT SOLiD low coverage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><figDesc>S7–S10 show that the Illumina platform outperforms the other two sequencing technologies in the detection of alterations made of small number of windows for all the Page: 477 470–478</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig.6.</head><figDesc>Fig. 6. Correlation between DNA copy number and normalized RC. DNA copy number of genomic regions previously genotyped by McCarroll et al. are compared with the normalized RCs of the high coverage sequencing data produced by the 1000 genomes project for the three HTS platforms. (a, d, g) GA platform. (b, e, h) 454 platform. (c, f, i) SOLiD platform. The analyses have been performed for three different window sizes W. (a– c) W = 100 bp. (d–f) W = 1000 bp. (g–i) W = 2000 bp. R is the Pearson's correlation coefficient.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><figDesc>We thank the 1000 Genomes Consortium that provided all the data used in this study (http://www.1000genomes.org).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><figDesc>Funding: This study was supported by the project " Gene expression profile and therapeutic implication in gastric cancer. From the clinical overview to the translational research " of the Istituto Toscano Tumori (ITT). Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>@BULLET RC data preparation.</figDesc><table>@BULLET Data normalization. 

@BULLET CNV regions identification. 

@BULLET Copy number estimation. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Summary of the publicly available tools for the analysis of RC data (see Supplementary Materials for more details)</figDesc><table>Tool 
Reference 
Platform 
Input 
Sample 
Output 

RDxplorer 
Yoon et al. (2009) 
R/Java 
.bam 
One sample 
P/T 
ReadDepth 
Miller et al. (2011) 
R 
.bam 
One sample 
T 
CNAseg 
Ivakhno et al. (2010) 
R 
.bam/RC data 
Two sample 
T 
CNV-seq 
Xie and Tammi (2009) 
R 
tab-delimited 
Two sample 
P 
JointSLM 
Magi et al. (2011) 
R 
RC data 
One sample 
P/T 
CNVnator 
Abyzov et al. (2011) 
C++ 
.bam 
One sample 
T/V 

P, output as a plot of the detected alterations; T, output as a tab-delimited file with all the detected variants; V, Command 
visualization. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2.</figDesc><table>Summary of the experiments used in the analyses 

Sample 
Platform 
Read length Milions of reads Coverage 

Illumina GA 
35 
2738.03 
39.1× 
NA19240 Roche 454 
200 
45.05 
3.7× 
LT SOLID 
25 
2550.73 
2.6× 

Illumina GA 
35 
2510.6 
3 5 .8× 
NA12878 Roche 454 
200 
187.9 
1 5 .3× 
LT SOLID 
25 
1775.37 
18.1× 

NA11830 
Illumina GA 
35 
149.96 
2.1× 
LT SOLiD 
25 
269.17 
2.7× 

NA11840 
LT SOLiD 
25 
316.1 
3 .2× 
Roche 454 
200 
17.48 
1.4× 

NA12043 
Illumina GA 
35 
163.25 
2.3× 
Roche 454 
200 
13.44 
1.1× 

All the data were first used by Durbin et al. (2010). 

GC content has been reported in several papers: Harismendy et al. (2009) 
analysed human sequences generated by the Roche 454, Illumina GA and the 
LT SOLiD technologies for the same 260 kb in four individuals concluding 
that read depth of coverage decreases with increasing AT content for all the 
three platforms. Similar results were found by Dohm et al. (2008) and Hillier 
et al. (2008). Mappability bias (</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">CNVnator: an approach to discover, genotype, and characterize typical and atypical CNVs from family and population genome sequencing</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Abyzov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="974" to="984" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Genome structural variation discovery and genotyping</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Alkan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="363" to="376" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A very fast and accurate method for calling aberrations in array-CGH data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Benelli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="515" to="518" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Accurate whole human genome sequencing using reversible terminator chemistry</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Bentley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">456</biblScope>
			<biblScope unit="page" from="53" to="59" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Identification of somatically acquired rearrangements in cancer using genome-wide massively parallel paired-end sequencing</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Campbell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="722" to="729" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">High-resolution mapping of copy-number alterations with massively parallel sequencing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">Y</forename>
				<surname>Chiang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="99" to="103" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Origins and functional impact of copy number variation in the human genome</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">F</forename>
				<surname>Conrad</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">464</biblScope>
			<biblScope unit="page" from="704" to="712" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Genome variation discovery with high-throughput sequencing data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">V</forename>
				<surname>Dalca</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Brudno</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3" to="14" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Substantial biases in ultra-short read data sets from highthroughput DNA sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Dohm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A map of human genome variation from population-scale sequencing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">7319</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluation of next generation sequencing platforms for population targeted sequencing studies</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Harismendy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Whole-genome sequencing and variant discovery in C. elegans</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">W</forename>
				<surname>Hillier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="183" to="188" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection of large-scale variation in the human genome</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Iafrate</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="949" to="951" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">CNAseg-a novel framework for identification of copy number changes in cancer from second-generation sequencing data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ivakhno</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3051" to="3058" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Mapping and sequencing of structural variation from eight human genomes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Kidd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="page" from="56" to="64" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Comparative analysis of algorithms for identifying amplifications and deletions in array-CGH data</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R R</forename>
				<surname>Lai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3763" to="3770" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The diploid genome sequence of an individual human</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Levy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">254</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">The Sequence alignment/map (SAM) format and SAMtools</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Project Data Processing Subgroup Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2078" to="2079" />
			<date type="published" when="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Structural variation in two human genomes mapped at singlenucleotide resolution by whole genome de novo assembly</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="723" to="730" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A shifting level model algorithm that identifies aberrations in array-CGH data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Magi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="265" to="280" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Detecting common copy number variants in high-throughput sequencing data by using JointSLM algorithm</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Magi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Integrated detection and population-genetic analysis of SNPs and copy number variation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mccarroll</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1166" to="1174" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequence and structural variation in a human genome uncovered by short-read, massively parallel ligation sequencing using two-base encoding</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">J</forename>
				<surname>Mckernan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1527" to="1541" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Computational methods for discovering structural variation with next-generation sequencing</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Medvedev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="13" to="20" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">ReadDepth: a parallel R package for detecting copy number alterations from short sequencing reads</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">A</forename>
				<surname>Miller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">16327</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">An initial map of insertion and deletion (INDEL) variation in the human genome</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">E</forename>
				<surname>Mills</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1182" to="1190" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Circular binary segmentation for the analysis of array-based DNA copy number data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">B</forename>
				<surname>Olshen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="557" to="572" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards a comprehensive structural variation map of an individual human genome</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">W</forename>
				<surname>Pang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Global variation in copy number in the human genome</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Redon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">444</biblScope>
			<biblScope unit="page" from="444" to="454" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Large-scale copy number polymorphism in the human genome</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sebat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="page" from="525" to="528" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Fine-scale structural variation of the human genome</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Tuzun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="727" to="732" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">CGHcall: calling aberrations for array CGH tumor profiles</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Van De Wiel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="892" to="894" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">The complete genome of an individual by massively parallel DNA sequencing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Wheeler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">452</biblScope>
			<biblScope unit="page" from="872" to="876" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">CNV-seq, a new method to detect copy number variation using high-throughput sequencing</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Xie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">T</forename>
				<surname>Tammi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinf</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Sensitive and accurate detection of copy number variants using read depth of coverage</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Yoon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1586" to="1592" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>