
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining DNorm: disease name normalization with pairwise learning to rank</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Robert</forename>
								<surname>Leaman</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information</orgName>
								<address>
									<addrLine>8600 Rockville Pike</addrLine>
									<postCode>20894</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Biomedical Informatics</orgName>
								<orgName type="institution">Arizona State University</orgName>
								<address>
									<addrLine>13212 East Shea Blvd</addrLine>
									<postCode>85259</postCode>
									<settlement>Scottsdale</settlement>
									<region>AZ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Rezarta</forename>
								<surname>Islamaj</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Dog</forename>
								<forename type="middle">˘</forename>
								<surname>An</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information</orgName>
								<address>
									<addrLine>8600 Rockville Pike</addrLine>
									<postCode>20894</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Zhiyong</forename>
								<surname>Lu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information</orgName>
								<address>
									<addrLine>8600 Rockville Pike</addrLine>
									<postCode>20894</postCode>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining DNorm: disease name normalization with pairwise learning to rank</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">22</biblScope>
							<biblScope unit="page" from="2909" to="2917"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt474</idno>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Despite the central role of diseases in biomedical research, there have been much fewer attempts to automatically determine which diseases are mentioned in a text—the task of disease name normalization (DNorm)—compared with other normalization tasks in biomedical text mining research. Methods: In this article we introduce the first machine learning approach for DNorm, using the NCBI disease corpus and the MEDIC vocabulary, which combines MeSH Õ and OMIM. Our method is a high-performing and mathematically principled framework for learning similarities between mentions and concept names directly from training data. The technique is based on pairwise learning to rank, which has not previously been applied to the normalization task but has proven successful in large optimization problems for information retrieval. Results: We compare our method with several techniques based on lexical normalization and matching, MetaMap and Lucene. Our algorithm achieves 0.782 micro-averaged F-measure and 0.809 macro-averaged F-measure, an increase over the highest performing baseline method of 0.121 and 0.098, respectively. Availability: The source code for DNorm is available at http://www. ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/DNorm, along with a web-based demonstration and links to the NCBI disease corpus. Results on PubMed abstracts are available in PubTator: http://www.ncbi.nlm. nih.gov/CBBresearch/Lu/Demo/PubTator</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Diseases are central to many lines of biomedical research, and enabling access to disease information is the goal of many information extraction and text mining efforts (Islamaj Dog˘ an and<ref type="bibr" target="#b15">Lu, 2012b;</ref><ref type="bibr" target="#b17">Kang et al., 2012;</ref><ref type="bibr" target="#b28">Ne´veólNe´veól et al., 2012;</ref><ref type="bibr" target="#b40">Wiegers et al., 2012</ref>). The task of disease normalization consists of finding disease mentions and assigning a unique identifier to each. This task is important in many lines of inquiry involving disease, including etiology (e.g. gene–disease relationships) and clinical aspects (e.g. diagnosis, prevention and treatment). Disease may be defined broadly as 'any impairment of normal biological function' (<ref type="bibr" target="#b13">Hunter, 2009</ref>). Given the wide range of concepts that may thus be categorized as diseases—their respective etiologies, clinical presentations and their various histories of diagnosis and treatment—disease names naturally exhibit considerable variation. This variation presents not only in synonymous terms for the same disease, but also in the diverse logic used to create the disease names themselves. Disease names are often created by combining roots and affixes from Greek or Latin (e.g. 'hemochromatosis'). A particularly flexible way to create disease names is to combine a disease category with a short descriptive modifier, which may take many forms, including anatomical locations ('breast cancer'), symptoms ('cat-eye syndrome'), treatment ('Dopa-responsive dystonia'), causative agent ('staph infection'), biomolecular etiology ('G6PD deficiency'), heredity ('X-linked agammaglobulinemia') or eponyms ('Schwartz-Jampel syndrome'). Modifiers are also frequently used to provide description not part of the name (e.g. 'severe malaria'). When diseases are mentioned in text, they are frequently also abbreviated, exhibit morphological or orthographical variations, use different word orderings or use synonyms. These variations may involve more than single word substitutions. For example, because affixes are often composed, a single word ('oculocerebrorenal') may correspond to multiple words ('eye, brain and kidney') in another form. The disease normalization task is further complicated by the overlap between disease concepts, forcing systems that locate and normalize diseases in natural language text to balance handling name variations with differentiating between concepts to achieve good performance. Previous works addressing disease name normalization (DNorm) typically use a hybrid of lexical and linguistic approaches (Islamaj Dog˘ an and Lu, 2012b;<ref type="bibr" target="#b16">Jimeno et al., 2008;</ref><ref type="bibr" target="#b17">Kang et al., 2012</ref>). While string normalization techniques (e.g. case folding, stemming) do allow some generalization, the name variations in the lexicon always impose some limitation. Machine learning may enable higher performance by modeling the language that authors use to describe diseases in text; however, there have been relatively few attempts to use machine learning in normalization, and none for disease names. In this work we use the NCBI disease corpus (Islamaj Dog˘ an and<ref type="bibr" target="#b14">Lu, 2012a</ref>), which has recently been updated to include concept annotations (Islamaj Dogan et al., unpublished data), to consider the task of disease normalization. We describe the task as follows: given an abstract, return the set of disease concepts mentioned. Our current purpose is to support entityspecific semantic search of the biomedical literature () and computer-assisted biocuration, especially document triage (<ref type="bibr" target="#b19">Kim et al., 2012</ref>In this article we introduce DNorm, the first machine learning method to normalize disease names in biomedical text. Our technique learns the similarity between mentions and concept names directly from the training data, thereby focusing on the candidate generation phase of normalization. Our technique can learn arbitrary mappings between mentions and names, including synonymy, polysemy and relationships that are not 1-to-1. Moreover, our method specifically handles abbreviations and word order variations. Our method is based on pairwise learning to rank (pLTR), which has been successfully applied to large optimization problems in information retrieval (<ref type="bibr" target="#b1">Bai et al., 2010</ref>), but to the best of our knowledge has not previously been used for concept normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Biomedical named entity recognition (NER) research has received increased attention recently, partly owing to BioCreative (<ref type="bibr" target="#b10">Hirschman et al., 2005b</ref>) and BioNLP (<ref type="bibr" target="#b18">Kim et al., 2009</ref>) challenges on recognition of genes, proteins and biological events in the scientific literature, as well as TREC (<ref type="bibr" target="#b36">Voorhees and Tong, 2011</ref>) and i2b2 (<ref type="bibr" target="#b35">Uzuner et al., 2011</ref>) challenges on identification of drugs, diseases and medical tests in electronic patient records. The problem of concept normalization has seen substantial work for genes and proteins, as a result of a series of tasks that were part of the BioCreative competitions (<ref type="bibr" target="#b9">Hirschman et al., 2005a;</ref><ref type="bibr" target="#b27">Morgan et al., 2008</ref>). A variety of methods including pattern matching, dictionary lookup, machine learning and heuristic rules were described for the systems participating in these challenges. Articles have also discussed the problem of abbreviation definition and expansion, rule-based procedures to resolve conjunctions of gene names, lexical rules to address term variation in gene names, enhanced dictionaries, approximate string matching and filtering approaches to reduce false positives. A large portion of concept normalization work relies, at least partially, on dictionary lookup techniques and various string matching algorithms to account for term variation. Although machine learning components have been implemented, the majority of the investment in this line of work has been the establishment of various filtering techniques to select the right candidates for normalization. For example,<ref type="bibr" target="#b4">Buyko et al. (2007)</ref>used conditional random fields to solve the problem of gene mention coordination,<ref type="bibr" target="#b34">Tsuruoka et al. (2007)</ref>used a logistic regression method for learning a string similarity measure from a dictionary and<ref type="bibr" target="#b39">Wermter et al. (2009)</ref>incorporate a semantic similarity scoring module in their GeNo gene-name normalization system. Listwise learning to rank techniques, which learn the best list of objects to return rather than the best single object, have been used for gene name normalization in<ref type="bibr" target="#b11">Huang et al. (2011a)</ref>and in MeSH Õ term selection for indexing in<ref type="bibr" target="#b12">Huang et al. (2011b)</ref>. While the listwise approach is useful when the notion of relevance for the task is multifaceted or involves varying degrees of relevance, in this work we use pLTR because our interest is in the single best name for each mention. Recently, Islamaj Dog˘ an and Lu (2012b) successfully built a rule-based inference method with application to disease name normalization to MeSH and OMIM terminology.</p><p>Disease name recognition and disease concept identification has received less attention when compared with other biomedical concept recognition tasks, possibly owing to the fact that there is no gold standard that can be used to evaluate existing techniques and/or build new ones focusing on the identification of diseases in text. Several terminology resources are available that provide disease terms, such as MeSH, National Cancer Institute thesaurus, SNOMED-CT (<ref type="bibr" target="#b32">Stearns et al., 2001</ref>), UMLS, Disease Ontology (<ref type="bibr" target="#b29">Schriml et al., 2012</ref>) and MEDIC (<ref type="bibr" target="#b6">Davis et al., 2012</ref>). The UMLS Metathesaurus covers much more than any of the other resources because its main purpose is the comprehensive coverage of medical terminology terms. The UMLS was used in the corpus developed by<ref type="bibr" target="#b16">Jimeno et al. (2008)</ref>, which evaluated several normalization methods at the sentence level; the highest performing method was a dictionary lookup method, which achieved 0.684 in F-measure. The corpus of Jimeno et al. was then extended by<ref type="bibr" target="#b22">Leaman et al. (2009)</ref>, and subsequently used by<ref type="bibr" target="#b17">Kang et al. (2012)</ref>to achieve an F-measure of 0.736 on concept identifier matching. Recently, a new disease lexicon, namely MEDIC (<ref type="bibr" target="#b6">Davis et al., 2012</ref>), was created by the Comparative Toxicology Database for indexing diseases in biomedical literature during biocuration. MEDIC merges OMIM into the disease branch of MeSH, making it a natural choice for indexing purposes, and is therefore used as the lexicon for the NCBI disease corpus (Islamaj Dog˘ an and Lu, 2012a), which consists of nearly 800 PubMed abstracts manually annotated with respect to diseases. Such a corpus provides a large-scale resource for enabling the development of more precise tools that address disease name recognition and normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>We use the NCBI disease corpus, which consists of 793 PubMed abstracts, split into three subsets as described in<ref type="figure" target="#tab_1">Table 1</ref>. Each abstract was annotated by two human annotators for disease mentions, as well as their corresponding concept identifiers in MEDIC (inter-annotator agreement: 87.5%). Each abstract contains an average of 5.08 disease mentions and 3.28 disease concepts. In this research, we use the December 6, 2012 version of MEDIC, which contains 11 583 MeSH identifiers and 3990 OMIM identifiers, grouped into 13 339 disease concepts. This version contains 75 761 names, including synonyms. The average number of names per concept is 5.72 and the average number of concepts per name is 1.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Processing pipeline</head><p>We process PubMed abstracts using a pipeline architecture summarized in<ref type="figure" target="#fig_0">Figure 1</ref>. Abstracts are processed first by breaking into sentences using the built-in Java class for sentence segmentation. We improved the accuracy of the segmentation by disallowing sentence breaks within parenthesis. Disease mentions are then located using the BANNER named entity recognizer (<ref type="bibr" target="#b21">Leaman and Gonzalez, 2008</ref>). BANNER is a trainable system, using conditional random fields (<ref type="bibr" target="#b20">Lafferty et al., 2001</ref>) and a rich feature set approach. As in previous work for disease name recognition, our feature set that included a dictionary of disease names derived from the UMLS Metathesaurus (<ref type="bibr" target="#b22">Leaman et al., 2009</ref>). For this project, we used a BANNER model trained on the training subset of the NCBI disease corpus. Mentions output by BANNER are then subjected to additional string processing. Abbreviation definitions are located in the abstract (<ref type="bibr" target="#b31">Sohn et al., 2008</ref>), and short-form abbreviations found in mentions are replaced with their long form. If the mention already includes the long form, however, the abbreviation is instead dropped. Mentions are then tokenized at whitespace and punctuation. Punctuation and stop words listed in the default set of English stop words in the information retrieval library Lucene (http://lucene.apache.org) are removed, while digits are retained. Tokens are then converted to lower case ASCII and stemmed using the Porter stemmer implementation provided by Lucene. The next step is to generate candidate concepts for each mention. Our method finds the best match between the mention and the disease names in MEDIC by defining a vector space, converting both mentions and concept names to vectors within that space, then searching for the name that maximizes a scoring function learned from the training data. We describe our technique in detail in Section 2.2 and Section 2.3. The final step before returning results is disambiguation: we identify whether the name is listed as the primary name or a synonym for the disease concept, and filter matches to a synonym if a parent uses the same name as a primary name. After filtering, we return the disease concept associated with the highest scoring name, breaking ties arbitrarily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pairwise learning to rank</head><p>We formalize the normalization problem as follows: Let M represent a set of mentions from the corpus, C represent a set of concepts from a controlled vocabulary such as MEDIC and N represent the set of concept names from the controlled vocabulary (the lexicon). We assume that each mention m 2 M in the dataset is annotated with exactly one concept c 2 C. We also assume that the controlled vocabulary describes a manyto-many mapping between concepts c 2 C and names n 2 N. To represent these relationships, we define the function annotation : M ! C such that given a mention m 2 M, it returns the annotated concept c 2 C in the dataset. We also define names : C ! P N ð Þ, where P is the power set function, so that given a concept c 2 C, it returns the subset of N specified in the controlled vocabulary as the set of names associated with c. Under these definitions, the candidate generation task can be modeled as the task of ranking pairs of mentions and concept names. We create a function that returns a numeric score for any tuple hm, ni, m 2 M, n 2 N , that is score : M Â N ! R. We can then generate candidate concepts for a given mention by iterating through all names, finding the name with the highest score and returning the associated disease concept. The primary effort therefore becomes the creation of an appropriate scoring function. We use the training data to learn a function that will return a higher score for matching pairs than for mismatched pairs. That is, given mention m 2 M, concept c ¼ annotationðmÞ, name n þ 2 namesðcÞ and name n À 2 N À namesðcÞ, we would like a scoring function that generally obeys the constraint score m, n þ ð Þ4score m, n À ð Þ (<ref type="bibr" target="#b1">Bai et al., 2010</ref>). We define a set of tokens T containing the tokens from all mentions m 2 M and all names n 2 N. We define a vector space of dimensionality T j j and represent both mentions and names as Term Frequency-Inverse Document Frequency (TF-IDF) vectors within that space (<ref type="bibr" target="#b26">Manning et al., 2008</ref>). We calculate the TF for each element in the vector as the number of times the corresponding token appears in the mention or name. The IDF for each element in mention and name vectors is calculated from the number of names in the lexicon that contain the corresponding token, as follows:</p><formula>IDF t, N ð Þ¼log N n 2 N : t 2 n È É þ 1</formula><p>All vectors are normalized to unit length. To simplify the notation, we use m to represent both the token list form and the TF-IDF vectors of mentions, and n to represent the same for names. In this work we choose the scoring function to be a linear function of all possible pairs of tokens between mention m and name n. We introduce a matrix, W, to contain the weights of the linear function, and express the scoring function in matrix form as:</p><formula>score m, n ð Þ¼m T Wn ¼ X T j j i, j¼1 m i W ij n j</formula><p>In this model, entry w ij in the weight matrix W represents the correlation between token t i appearing in a mention and token t j appearing in a concept name from the lexicon. This model has several useful properties. It is capable of representing both positive and negative correlations between tokens, and models both synonymy and polysemy. The model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2911</head><p>DNorm: Disease name normalization with pairwise learning to rank also does not assume that the token distributions are the same between the mentions and the names. Our method finds the best potential matches for mention m 2 M by iterating through all n 2 N and then passing the names with the highest values for score m, n ð Þ to the disambiguation component. We also set a threshold so that names given a score less than or equal to 0 are not returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Model training</head><p>We train the weight matrix W by adjusting W so that m T Wn þ 4m T Wn À , representing the idea that correct name n þ should be ranked higher for the mention m than incorrect name n À. Following (<ref type="bibr" target="#b1">Bai et al., 2010</ref>), we use the margin ranking loss (<ref type="bibr" target="#b8">Herbrich et al., 2000</ref>), making our model a margin ranking perceptron (<ref type="bibr" target="#b5">Collins and Duffy, 2002</ref>). Given m 2 M, c ¼ annotationðmÞ, n þ 2 namesðcÞ and n À 2 N À namesðcÞ, we choose W as follows:</p><formula>W ¼ argmin W X m X n þ X n À max 0, 1 À m T Wn þ þ m T Wn À À Á</formula><p>We perform this optimization via stochastic gradient descent (SGD) (<ref type="bibr" target="#b3">Burges et al., 2005</ref>). In SGD, a training instance is selected and classified according to the current parameters of the model. If the instance is classified incorrectly, then the parameters are updated by taking a step in the direction of the gradient. In our formulation of pLTR, each instance is a tuple m, n þ , n À , where m is a mention vector, n þ is a name vector that is a correct match for m and n À is a name vector that is an incorrect match for m. If m T Wn þ À m T Wn À 51, W is updated as W W þ m n þ ð Þ T Àm n À ð Þ T , where is the learning parameter controlling the size of the change to W. Because SGD is a stochastic method, the order of the training instances is randomized after each iteration; the final W and performance therefore vary slightly. We evaluated a wide range of values for the learning parameter using the development subset of the NCBI disease corpus. We found that while the performance responds to changes in the order of magnitude of , it is relatively insensitive to smaller changes (see Section 4 for details). SGD also requires an initial value for the parameters being updated, in this case the matrix W. We choose W ¼ I, the identity matrix, as the initial value for W, so that the function is initially equivalent to standard cosine similarity. The number of features in this model is the number of token pairs, T j j 2. This large capacity makes overfitting a concern. We avoid overfitting through early stopping using the development subset of the NCBI disease corpus as a holdout set. This implies a preference for solutions where W is close to its initial value. We measure performance on the holdout set as the average of the rank of the correct concept for each mention, or 1000, whichever is smaller. We calculate the average rank after each iteration through the training data, and stop training when it increases over the previous iteration. There are several small differences between our theoretical model and its application. The most significant difference is that our training data are expressed in terms of concepts rather than names. For any given mention m there are typically several names which could be used as n þ , as each concept is usually associated with multiple names. Instead of iterating through all possible combinations of m, n þ , n À , which would be prohibitive, we instead iterate through all combinations of m, c þ , c À , where c þ is fixed as c þ ¼ annotation m ð Þ and c À 2 C À c þ. Because we intend the name for c þ that best matches the mention to be ranked higher than the best-matching name for any other concept c À , we determine n þ and n À as follows:</p><formula>n þ ¼ argmax n2names c þ ð Þ score m, n ð Þ n À ¼ argmax n2names c À ð Þ score m, n ð Þ</formula><p>Names associated with multiple concepts do not receive any special handling, however. The second difference is that $1.9% of the mentions in the NCBI disease corpus are annotated with a disjunction of multiple concepts. Disjunction annotations, such as 'D001943jD010051' for 'breast or ovarian cancer', indicate that a single text span contains multiple mentions. We handle these mentions during training by using the original mention as m but iterating through the concepts, allowing each to take a turn as c þ. The mention 'breast or ovarian cancer' would therefore be used twice, first using c þ ¼ 'D001943' and then c þ ¼ 'D010051'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Baseline techniques</head><p>We compared DNorm against several strong baseline methods. An exact string-matching method checks for matches of the disease names in text with controlled terminology terms and is therefore expected to have difficulty with term variability, especially if such variations were not foreseen during the creation of the lexicon. In addition, precision may be affected by ambiguous or nested terms. Norm, from the SPECIALIST lexical tools (http://lexsrv3.nlm.nih.gov/LexSysGroup/Projects/lvg/2013/docs/ userDoc/tools/norm.html) is a publically available resource of the National Library of Medicine, and is designed to address these issues by normalizing case, plurals, inflections and word order. We used Norm to process all disease names and synonyms in MEDIC and also the set of all strings and substrings of any given PMID document in the NCBI disease corpus. When a text string found in a PubMed abstract in the NCBI testing set was mapped by Norm to a disease name in the MEDIC lexicon, that disease mention is grounded with the corresponding MEDIC concept. For nested disease mentions we kept the longest string that produced a mapping to a MEDIC entry term or synonym. The results of this string matching method are reported as NLM Lexical Normalization in the 'Results' section. Our second baseline method applied MetaMap (<ref type="bibr" target="#b0">Aronson, 2001</ref>). MetaMap is another public resource of the National Library of Medicine, and the state-of-the-art natural language processing tool for identifying UMLS Metathesaurus concepts in biomedical text. MetaMap first splits the input text into sentences, and then splits the set of sentences into phrases. For each phrase, MetaMap identifies possible mappings to UMLS based on lexical lookup and on variants by associating a score with each one of them. MetaMap identifies several possible mappings in each phrase and several candidates for each one. In this work, we used MetaMap to identify all UMLS concept identifiers (CUI) in the PubMed abstracts composing the NCBI disease corpus. Then, for each abstract, we used UMLS to map the CUIs to their respective MeSH descriptors and OMIM identifiers. We retained the CUIs we were able to map to either MeSH or OMIM IDs in MEDIC and dropped all others. These results are reported as MetaMap. We also compare with the benchmark results on the NCBI disease corpus, obtained using the Inference method (Islamaj Dog˘ an and Lu, 2012b). This method was developed on a manually annotated set of PubMed abstract sentences that reflected the consensus annotation agreement of the EBI disease corpus and the AZDC disease corpus (the only available data at the time). The Inference method showed F-measure results of 79%, and it was able to link disease mentions to their corresponding medical vocabulary entry with high precision. Its basis was a Lucene search that first mapped a disease mention against the MEDIC vocabulary. Next, the Inference method makes use of a combination of rules that were used to re-rank the results to report the top ranked one. The core of the Inference method was built as a combination of string matching rules that mapped the text annotated strings to the controlled vocabulary terms. A strong advantage of the Inference method was its incorporation of abbreviation definition detection and the successful use of the fact that the long form of the disease is usually defined elsewhere in the same document. Once the abbreviation was resolved, the knowledge of the mapping of the long form of the disease was used to infer the mapping of the abbreviated mention. To evaluate the Inference method's performance, BANNER was first applied to each PubMed abstract to identify disease name strings, the Inference method was then applied to normalize each mention to a MEDIC concept. Our next baseline method uses the same processing pipeline as our DNorm method but replaced our candidate generation method with Lucene, an important component in several previous systems for normalizing biomedical entities (<ref type="bibr" target="#b11">Huang et al., 2011a;</ref><ref type="bibr" target="#b39">Wermter et al., 2009</ref>). We loaded MEDIC into a Lucene repository, creating one Lucene document for each concept–name pair. Mentions and names are both processed with the same tokenization and string normalization used in DNorm. A Boolean query is created from the resulting tokens, and the concept for the highest-scoring name is the one returned. We refer to this method as BANNER þ Lucene. Our final baseline method, which we refer to as BANNER þ cosine similarity, also uses the same processing pipeline as DNorm. However, this method also uses the same TF-IDF vectors as DNorm for the mentions and names, so that the only difference is the scoring function. The cosine similarity scoring function is as follows:</p><formula>cosine similarity m, n ð Þ¼m T n ¼ X T j j i¼1 m i n i</formula><p>Because this method is equivalent to DNorm with W ¼ I, the identity matrix, and I is the value of W before training, this method isolates the improvement provided by training the W matrix with pLTR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>During development, all techniques were evaluated using the development subset of the NCBI disease corpus. Varying the learning rate demonstrated ¼ 10 À4 to provide the highest performance on the development set, and this is the setting used for all experiments reported in this section. Final evaluation was performed using the test subset of the NCBI disease corpus. Our evaluation considers only the set of disease concepts found within each abstract, ignoring the exact location(s) where each concept was found. Thus, the number of true positives in an abstract is the size of the intersection between the set of concepts annotated in the gold standard and the set of concepts returned by the system. The number of false negatives and false positives are defined analogously. Our result measures are precision, recall and F-measure, which were calculated as follows:</p><formula>p ¼ tp tp þ fp r ¼ tp tp þ fn f ¼ 2pr p þ r</formula><p>Micro-averaged results were calculated by summing the number of true positives, false positives and false negatives over the entire evaluation set. Macro-averaged results were determined from the number of true positives, false positives and false negatives for each abstract, and the mean result was calculated across all abstracts.<ref type="figure" target="#tab_2">Table 2</ref>reports the evaluation results for DNorm and all baseline methods, using micro-averaged performance.<ref type="figure" target="#tab_3">Table 3</ref>reports the results for the same experiments using macroaveraged performance.<ref type="figure" target="#fig_1">Figure 2</ref>reports the recall for the BANNER þ Lucene, BANNER þ cosine similarity and DNorm (BANNER þ pLTR) experiments if we return more than the highest scoring result from the candidate generation. We created our own implementation of pLTR using the COLT matrix library (http://acs.lbl.gov/software/colt). The implementation enables high performance by taking advantage of the sparsity of the mention and name vectors, training on the NCBI disease corpus training subset in 51 h using a single 2.80 GHz Intel Xeon processor, limited to 10 GB memory. Our implementation scores one mention against the nearly 80 000 names in the lexicon in $25 ms using the same equipment. We have applied DNorm to all PubMed abstracts and made the results publicly available in PubTator (<ref type="bibr" target="#b37">Wei et al., 2012</ref><ref type="bibr" target="#b38">Wei et al., , 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>Though the NLM Lexical Normalization method has higher recall than any method besides DNorm, the precision remainsThe remaining methods use separate stages for NER and normalization; because all use BANNER for NER, the errors caused by the NER component are the same. The remaining methods also use abbreviation resolution, significantly reducing the number of false positives caused by ambiguous abbreviations. The Inference method handles term variations by using string similarity and Lucene search, though it tends to select highly specific concepts, such as mapping 'inherited disorders' to Blood Coagulation Disorders, Inherited (MESH:D025861). Analyzing the errors made by BANNER þ Lucene but not by BANNER þ cosine similarity shows that most are due to the Lucene scoring function insufficiently penalizing lexicon names containing tokens not present in the mention. The majority of the errors made by BANNER þ cosine similarity but not by DNorm are due to term variation. Because BANNER þ Lucene, BANNER þ cosine similarity and DNorm (BANNER þ pLTR) use the same processing pipeline, the performance difference between these methods is solely due to the normalization methodology. In addition, because the scoring function for cosine similarity is equivalent to the one used by DNorm before training, the performance difference between these methods is solely due to the weights learned during training. To further isolate the effect of pLTR training on performance, we performed a normalization experiment comparing Lucene, cosine similarity and pLTR using the gold-standard mentions from the NCBI disease corpus test subset as input instead of the mentions found by BANNER. We again used the pLTR model trained using ¼ 10 À4. In this comparison, we count a result as correct if the concept associated with the lexicon name scored highest by DNorm matched the annotated concept for the mention. Out of the 960 mentions, Lucene found 674 (70.2%), cosine similarity found 687 (71.6%) and pLTR found 789 (82.2%). This experiment confirms the effectiveness of the novel learning procedure used by DNorm. We performed an experiment to demonstrate the effect that varying the learning rate () has on training time and performance. We varied exponentially between 10 À2 and 10 À8 , and report the results in<ref type="figure">Table 4</ref>. The best performance was achieved with ¼ 10 À4 , which required a training time of 48.8 min and resulted in a micro-averaged F-measure of 0.782. While the final performance is similar over a wide range of values for , the training time varied widely, ranging from 511 min to 477 h, with smaller values requiring longer training times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Error analysis of DNorm results</head><p>We analyzed the errors made by DNorm, using the model with ¼ 10 À4 , on the test subset. We considered an error to be either a false positive or false negative; errors were grouped first by the component most responsible for the error and second by the type of error. A chart summarizing the error analysis is presented in<ref type="figure" target="#fig_2">Figure 3</ref>. The majority of the errors (54.8%) were traced to the NER component, underscoring the importance of this task in biomedical information extraction. Twenty-three percent of the total errors were due to NER false negatives, predominantly specific diseases (e.g. 'neisserial infection') and disease classes (e.g. 'complement deficiency'), whereas 12.2% of the total errors were due to NER false positives, including 'molecular defects', 'deficiency 879delG' and 'cardiac troponin T', a type of RNA. The remainder of the NER errors, 19.6% of the total errors, resulted from tagging partially correct spans. Examples of the span missing tokens include 'congenital absence' instead of 'congenital absence of the iris' and 'breast cancer' instead of 'male and female breast cancer'. Errors due to the span capturing extra tokens were less common, as it is easier for the normalization component to recover from extra tokens than missing ones. Examples include 'paternal uniparental disomy' instead of 'uniparental disomy' and 'sporadic T-cell leukaemia' instead of 'T-cell leukaemia'. The next largest source of error was the candidate generation using our ranking technique, which contributed 41.2% of the total errors. Of the total errors, 12.2% were due to token pairs not being recognized as having closely related meanings. Many of these were adjective forms, such as 'cardiac' meaning 'heart' or 'colorectal' meaning both 'colon' and 'rectum'. We also found some spelling differences ('tumour' versus 'tumor') and stemming errors ('adrenocorticotropic' stems to 'adrenocorticotrop-' but 'adrenocorticotrophin' stems to 'adrenocorticotrophin'). Unrecognized hypernyms also contributed to the ranking errors, accounting for 6.1% of the total. This is expected because the annotation guidelines for the NCBI disease corpus instructed the human annotators to annotate any mention that does not exactly match a concept in MEDIC with the closest concept that includes it. While some of the unrecognized hypernyms were semantically close, such as 'hypomania' being a type of 'mood disorder', others were relatively distant, including 'disorder of glycoprotein metabolism' being a kind of 'inborn metabolism error' and 'gastrulation defect' being annotated simply as 'disease'. Difficulties in ranking coordinations were the cause of 6.8% of the total errors. These errors are predominantly false negatives because the ranking component only returns the single bestdisease concept for each mention. For example, in the mention 'leukemia and/or lymphoma' the ranking correctly found 'leukemia' but missed 'lymphoma'. In addition, complex coordinations such as 'breast, brain, prostate and kidney cancer' occasionally also caused false positives, in this case to 'prostate cancer/brain cancer susceptibility' (OMIM:603688). The greatest number of ranking errors, 16.2% of the total errors, were not attributable to a single qualitative error, but were instead due to an incorrect relative weighting. For example, the mention 'ptosis' refers to a drooping of the eyelid, but the method ranked 'X-linked ptosis' (OMIM:300245) higher than the correct annotation of 'eyelid ptosis' (MESH:D001763). This ranking occurred because 'X-linked' is much more common in the lexicon than 'eyelid', causing 'X-linked' to be given a lower TF-IDF weight, and its absence therefore considered less significant. Another example includes 'adenomatous polyps' being matched to 'adenomatous polyposis coli' (MESH:D011125) instead of to the disease with the same name ('adenomatous polyps', MESH:D018256) because the ranking model learned during training that the token 'polyps' is strongly associated with each token in the name 'adenomatous polyposis coli'. Only 3.4% of the errors were due to the disambiguation component. An example includes 'neurohypophyseal diabetes insipidus', which is a valid name for two concepts that share a parent but are not themselves in a parent–child relationship. Abbreviation processing was the major component that contributed the fewest total errors, 0.7%. An example includes 'IDMS', which the abstract defined as 'isolated DMS', and where 'DMS' had been defined previously as 'Denys-Drash syndrome'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis of learned weights matrix</head><p>Analyzing the entries in the matrix produced some additional insight into the normalization task and why this technique works. As discussed in the 'Methods' section, entry w ij in the weight matrix W represents the correlation between token t i appearing in a mention and token t j appearing in a concept name from the lexicon. These correlations may be positive or negative. In addition, the matrix is initialized as the identity matrix I, so that non-diagonal entries with a value other than 0 are due to training updates. The non-diagonal entries with the highest values represent the strongest correlations. As expected, the relationship we found most frequently were synonyms, such as 'inherited' ! 'hereditary' or near-synonyms such as 'disorder' ! 'disease'. We also found many entries reflecting other semantic relationships, including hypernymy ('recessive' ! 'hereditary') and others ('BRCA1' ! 'ovarian'). We found many examples of terms with morphological variations not handled by stemming, such as 'gonococcal' ! 'gonorrhea' and 'osteomata' ! 'osteoma'. We also noted spelling variations, such as 'haemoglobinuria' ! 'hemoglobinuria'. Finally, we found many examples of words that appear together frequently (collocations), such as 'dystrophy' ! 'muscular' and 'disease' ! 'hereditary'. We also analyzed the entries in the weight matrix with the lowest values, all negative, representing the strongest negative associations. The most common relationship found always included a head word strongly associated with disease. The head word was typically either paired with another head word (e.g. 'deficiency' ! 'infection') or an adjective ('abnormal' ! 'infection'), though others were also observed ('limb' ! 'disease'). These relationships suggest the existence of several broad categories of disease, and indicate an attempt to exclude some of these as possibilities. The next most common relationship we found was between words that frequently appear together, or collocations, such as 'autosomal' ! 'dominant'. This type of negative correlation reduces the weight of the complete phrase while allowing the weight between each individual token and itself (e.g. 'autosomal' ! 'autosomal') to remain high. We found some evidence of second-order relationships such as 'fragile' ! 'linked', both of which commonly appear with the token 'X', as in 'fragile X' and 'X linked'. Thus the pair 'fragile' ! 'linked' reduces the score of a mention containing the phrase 'fragile X' with a concept name containing the phrase 'X linked'. Finally, we also found some antonym relationships, such as 'dominant' ! 'recessive'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Limitations and future work</head><p>As the first work to use the pLTR model for normalization, there are remaining questions. While DNorm consists of separate steps for mention and concept finding, this article aggregates the mention-level results into the abstract level for evaluation. Thus additional assessment would be needed when applying DNorm to other text mining tasks such as relationship extraction between gene variants, drugs, disease and adverse reactions (<ref type="bibr" target="#b7">Hakenberg et al., 2012</ref>). While our evaluation only applied DNorm to one dataset, we recently also applied DNorm to the ShARe/CLEF eHealth Task 1b, a disease normalization task in clinical notes involving diseases and disorders from the clinical vocabulary SNOMED-CT (<ref type="bibr" target="#b32">Stearns et al., 2001</ref>). DNorm placed first among 17 international teams (<ref type="bibr" target="#b23">Leaman et al., 2013;</ref><ref type="bibr" target="#b33">Suominen et al., 2013</ref>). This is encouraging evidence of our method being more generally applicable, though additional evaluation should be performed to verify the effectiveness of our method in other applications, such as full text articles.Because the scores returned by our model are ordinal values, the model naturally only returns one concept per mention. This poses a difficulty for mentions annotated with more than one concept. We found that the difficulty was not great for mentions annotated with disjunctions, as these often appear independently in other mentions in the abstract. However, an additional 0.5% of the mentions in the NCBI disease corpus are annotated with a conjunction of multiple concepts, indicating that a single mention implies multiple concepts simultaneously. For example, the mention 'inherited neuromuscular disease', was annotated as 'D009468þD030342' ('Neuromuscular disease' and 'Genetic Diseases, Inborn'). In the present work, conjunction annotations were ignored during training and always counted as false negatives in our evaluation—we made no attempt to give partial credit. While there are relatively few of these mentions in the NCBI disease corpus, additional techniques will be required in tasks where conjunction annotations are critical. On a more fundamental level, there is no universally agreed definition of disease in general (<ref type="bibr" target="#b30">Scully, 2004</ref>). Likewise, specific diseases may be classified differently by different clinicians owing to variations in the presentation of diseases within a syndrome family, differing degrees of granularity or even variations in word meaning (<ref type="bibr" target="#b2">Biesecker, 2005</ref>). Even so, disease classifications are constantly being refined, and separating diseases into subtypes can improve the clinical utility of the disease description. There is some evidence of this stratification in the NCBI disease corpus: PMID 9056547 describes a clinically relevant variant of Pelizaeus-Merzbacher disease, for example. While our method does learn the language variations used to refer to diseases, this represents only an early step toward the more difficult problems of handling variations in disease classification or recognizing new subtypes. Our immediate future work includes applying our method to additional entity types. It would be interesting to compare our technique with existing methods for normalizing gene names. Because the disambiguation step is important for gene names (), we expect it would require a more comprehensive approach than we used here. Because disambiguation is largely orthogonal to the main effort in this article, however, we believe the learning to rank technique may prove useful to gene names as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We have shown that pLTR successfully learns a mapping from disease name mentions to disease concept names, resulting in a significant improvement in normalization performance. We have also shown that the training time requirements are modest and that inference time is fast enough for use online. Our approach models many kinds of term variations, learning the patterns directly from training data. Our error analysis showed that NER is a continued concern, and the analysis of the learned weight matrix showed that morphological analysis is important for this problem. Our technique primarily addresses the candidate generation step in normalization, and could be paired with more sophisticated techniques for disambiguation. We believe that pLTR may prove to be sufficiently useful and flexible to be applicable to normalization problems in general.</p><p>While general applicability should be verified in future work, the present article represents an attempt to move toward a unified framework for normalizing biomedical entity mentions with machine learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. The DNorm disease normalization pipeline, with examples, as described in Section 2.1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Comparison between BANNER þ Lucene, BANNER þ cosine similarity and DNorm (BANNER þ pLTR) of the micro-averaged recall when considering a concept to be found if it appears in the top n ranked results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Summary of error analysis. Errors in the NER and ranking components contributed 495% of the total errors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>). *To whom correspondence should be addressed. ß The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Size of the NCBI disease corpus</figDesc><table>Setup 
Abstracts 
Mentions 
Concepts 

Training subset 
593 
5145 
670 
Development subset 
100 
787 
176 
Test subset 
100 
960 
203 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2. Micro-averaged performance comparing the pLTR method against several baseline approaches, with the highest value in bold</figDesc><table>Setup 
Precision 
Recall 
F-measure 

NLM Lexical Normalization 
0.218 
0.685 
0.331 
MetaMap 
0.502 
0.665 
0.572 
Inference method 
0.533 
0.662 
0.591 
BANNER þ Lucene 
0.612 
0.647 
0.629 
BANNER þ cosine similarity 
0.649 
0.674 
0.661 
DNorm (BANNER þ pLTR) 
0.803 
0.763 
0.782 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 4. Effect of varying the learning rate () on the number of training iterations performed, total training time and the resulting micro-averaged F-measure. The highest performance is shown in bold</figDesc><table>Iterations 
Time (min) 
F-measure 

10 À2 
4 
10.7 
0.743 
10 À3 
4 
13.3 
0.765 
10 À4 
4 
48.8 
0.782 
10 À5 
2 
124.0 
0.762 
10 À6 
8 
986.6 
0.775 
10 À7 
17 
4656.5 
0.770 </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">R.Leaman et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors thank Chih-Hsuan Wei for his help preparing the demonstration Web site and loading DNorm results into PubTator, both Alan Aronson and Jim Mork for help with MetaMap and the anonymous reviewers for their insightful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">R</forename>
				<surname>Aronson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to rank with (a lot of) word features</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Bai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="291" to="314" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Mapping phenotypes to language: a proposal to organize and standardize the clinical descriptions of malformations</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">G</forename>
				<surname>Biesecker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Genet</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="320" to="326" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to rank using gradient descent</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Burges</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Machine learning</title>
		<meeting>the 22nd International Conference on Machine learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Resolution of coordination ellipses in biological named entities using conditional random fields</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Buyko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics</title>
		<meeting>the 10th Conference of the Pacific Association for Computational Linguistics<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<publisher>Pacific Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="163" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Collins</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Duffy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">MEDIC: a practical disease vocabulary used at the comparative toxicogenomics database</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">P</forename>
				<surname>Davis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">A SNPshot of PubMed to associate genetic variants with drugs, diseases, and adverse reactions</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hakenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="842" to="850" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title level="m" type="main">Large margin rank boundaries for ordinal regression Advances in Large Margin Classifiers</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Herbrich</surname>
			</persName>
		</author>
		<editor>Smola,A.J., et al.</editor>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="115" to="132" />
			<pubPlace>Cambridge, Massachusetts, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of BioCreAtIvE task 1B: normalized gene lists</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hirschman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Overview of BioCreAtIvE: critical assessment of information extraction for biology</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hirschman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">GeneTUKit: a software for document-level gene normalization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1032" to="1033" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Recommending MeSH terms for annotating biomedical articles</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="660" to="667" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">The Processes of Life: An Introduction to Molecular Biology</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">E</forename>
				<surname>Hunter</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Massachusetts, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">An improved corpus of disease mentions in PubMed citations</title>
		<author>
			<persName>
				<forename type="first">Islamaj</forename>
				<surname>Dog˘ An</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Workshop on Biomedical Natural Language Processing</title>
		<meeting>the 2012 Workshop on Biomedical Natural Language Processing<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">An Inference Method for Disease Name Normalization</title>
		<author>
			<persName>
				<forename type="first">Islamaj</forename>
				<surname>Dog˘ An</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI 2012 Fall Symposium on Information Retrieval and Knowledge Discovery in Biomedical Text</title>
		<meeting>the AAAI 2012 Fall Symposium on Information Retrieval and Knowledge Discovery in Biomedical Text</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="8" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Assessment of disease named entity recognition on a corpus of annotated sentences</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Jimeno</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">9 S3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 3</note>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Using rule-based natural language processing to improve disease normalization in biomedical text</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Kang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="876" to="881" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Overview of BioNLP&apos;09 shared task on event extraction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL-HLT 2009 Workshop on BioNLP</title>
		<meeting>the NAACL-HLT 2009 Workshop on BioNLP<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Prioritizing PubMed articles for the Comparative Toxicogenomic Database utilizing semantic information</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Conditional random fields: probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Lafferty</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning</title>
		<meeting>the Eighteenth International Conference on Machine Learning<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">BANNER: an executable survey of advances in biomedical named entity recognition</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Gonzalez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac. Symp. Biocomput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="652" to="663" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Enabling recognition of diseases in biomedical text with machine learning: corpus and benchmark</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Symposium on Languages in Biology and Medicine</title>
		<meeting>the 2009 Symposium on Languages in Biology and Medicine</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="82" to="89" />
		</imprint>
	</monogr>
	<note>South. Korea</note>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">NCBI at 2013 ShARe/CLEF eHealth Shared Task: Disorder Normalization in Clinical Notes with DNorm</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Leaman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference and Labs of the Evaluation Forum</title>
		<meeting>the Conference and Labs of the Evaluation Forum</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>To. appear</note>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">PubMed and beyond: a survey of web tools for searching biomedical literature</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">The gene normalization task in BioCreative III</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Suppl. . 8</note>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Introduction to Information Retreival</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Manning</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Overview of BioCreative II gene normalization</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Morgan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Linking multiple disease-related resources through UMLS</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ne´veólne´veól</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium</title>
		<meeting>the 2nd ACM SIGHIT International Health Informatics Symposium<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="767" to="772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Disease Ontology: a backbone for disease semantic integration</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">M</forename>
				<surname>Schriml</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="940" to="946" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<monogr>
		<title level="m" type="main">What is a disease? EMBO Rep</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Scully</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="650" to="653" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Abbreviation definition identification based on automatic precision estimates</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sohn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">402</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">SNOMED clinical terms: overview of the development process and project status</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">Q</forename>
				<surname>Stearns</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="662" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Three shared tasks on clinical natural language processing</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Suominen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference and Labs of the Evaluation Forum</title>
		<meeting>the Conference and Labs of the Evaluation Forum</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>To. appear</note>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning string similarity measures for gene/protein name dictionary look-up using logistic regression</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Tsuruoka</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2768" to="2774" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Uzuner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="552" to="556" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2011 medical records track</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Voorhees</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The tenth Text REtrieval Conference. National Institute of Standards and Technology</title>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Accelerating literature curation with text-mining tools: a case study of using PubTator to curate genes in PubMed abstracts</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Wei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">PubTator: a web-based text mining tool for assisting biocuration</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Wei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="page" from="41" to="518" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Web. server</note>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">High-performance gene name normalization with GeNo</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wermter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="815" to="821" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Collaborative biocuration–text-mining development task for document prioritization for curation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">C</forename>
				<surname>Wiegers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<monogr>
		<title level="m" type="main">DNorm: Disease name normalization with pairwise learning to rank</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>