
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lower confidence bounds for prediction accuracy in high dimensions via AROHIL Monte Carlo</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Kevin</forename>
								<forename type="middle">K</forename>
								<surname>Dobbin</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Epidemiology and Biostatistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Stephanie</forename>
								<surname>Cooke</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Epidemiology and Biostatistics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alfonso</forename>
								<surname>Valencia</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Bioinformatics</orgName>
								<orgName type="institution">University of Georgia</orgName>
								<address>
									<settlement>Athens</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lower confidence bounds for prediction accuracy in high dimensions via AROHIL Monte Carlo</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">22</biblScope>
							<biblScope unit="page" from="3129" to="3134"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr542</idno>
					<note type="submission">Gene expression Advance Access publication September 28, 2011 Received on January 11, 2011; revised on June 13, 2011; accepted on September 25, 2011</note>
					<note>[17:42 20/10/2011 Bioinformatics-btr542.tex] Page: 3129 3129–3134 Associate Editor: Contact: dobbinke@uga.edu Supplementary Information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Implementation and development of statistical methods for high-dimensional data often require high-dimensional Monte Carlo simulations. Simulations are used to assess performance, evaluate robustness, and in some cases for implementation of algorithms. But simulation in high dimensions is often very complex, cumbersome and slow. As a result, performance evaluations are often limited, robustness minimally investigated and dissemination impeded by implementation challenges. This article presents a method for converting complex, slow high-dimensional Monte Carlo simulations into simpler, faster lower dimensional simulations. Results: We implement the method by converting a previous Monte Carlo algorithm into this novel Monte Carlo, which we call AROHIL Monte Carlo. AROHIL Monte Carlo is shown to exactly or closely match pure Monte Carlo results in a number of examples. It is shown that computing time can be reduced by several orders of magnitude. The confidence bound method implemented using AROHIL outperforms the pure Monte Carlo method. Finally, the utility of the method is shown by application to a number of real microarray datasets. Availability: The R computer program for forming confidence bounds is freely available for download at the URL http://dobbinke .myweb.uga.edu/RprogramAROHILloweraccuracybound.txt.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>This article presents a novel approach to Monte Carlo simulations in high dimensions. The approach permits routines to be written in simpler and faster code using mathematical modeling. The savings comes from reducing the computational dimension of the Monte Carlo simulation from very high dimension to a much lower dimensional space. As we will show, this computational savings makes it possible to provide R functions to perform statistical analyses that previously required a compiled language such as C++. Moreover, the R programs are significantly faster and more transparent (enhancing reproducibility) than the compiled programs, because the underlying models have been streamlined. We make * To whom correspondence should be addressed. available such a program with this publication. More generally, this approach, by providing a faster method for performing simulations, can enable method developers to consider the robustness of novel procedures across a wider range of simulation scenarios than would otherwise be feasible. Monte Carlo simulations are commonly encountered in papers on high-dimensional methodologies. Perhaps the most common use of Monte Carlo simulations is to evaluate the performance characteristics of novel statistical procedures, such as the performance of classifiers based on partial least squares (<ref type="bibr" target="#b12">Nguyen and Rocke, 2004</ref>), regularization methods for variable selection (<ref type="bibr" target="#b24">Zou and Hastie, 2005</ref>) or evaluation of multiple hypothesis testing error control methods (<ref type="bibr" target="#b6">Dudoit et al., 2003</ref>). The advantages of Monte Carlo investigations are that the truth can be known exactly, and model assumptions can be violated in systematic ways to explore the limits of robustness. Some other methodologies also use Monte Carlo simulations as part of their algorithms. This new simulation procedure is called Adequate Representation Of High dimensions In Low dimensions (AROHIL) Monte Carlo. There are two types of AROHIL Monte Carlo. The first type does not involve any resampling. The basic idea behind this type of Monte Carlo is to split the Monte Carlo simulation into two subsimulations. One simulation represents the dimension-reducing feature selection step. The second simulation represents the conditional distribution of the features given that they were selected, and can typically be carried out in a space with dimension similar to the number of features selected. The second type of AROHIL Monte Carlo does involve resampling, such as bootstrap or cross-validation. In this case, resampling creates complex inter-relationships among the resampled datasets. To capture these inter-relationships, we propose a relatively simple hierarchical model that requires generation of a single highdimensional vector, and then a series of low-dimensional vectors conditionally generated given the high-dimensional vector. To our knowledge, there has not been work to develop a general methodology along the lines presented here. Work with a similar spirit can be seen in the high-dimensional literature. For example, Venkatraman and Olshen (2007) developed a faster version of their earlier method (<ref type="bibr" target="#b13">Olshen et al., 2004</ref>) for performing circular binary segmentation. Monte Carlo methods for estimating the distribution of functionals in complex statistical models have a longer history, and include rejection sampling, importance sampling (e.g.<ref type="bibr" target="#b16">Ripley, 1987</ref>), Markov chain Monte Carlo (e.g.<ref type="bibr" target="#b17">Robert and Casella, 2004</ref>) and related algorithms such as the Gibbs sampler (<ref type="bibr" target="#b7">Geman and Geman, 1984</ref>). But these methods do not achieve the reduction in the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>AROHIL requires that the high-dimensional model be converted into two submodels: (i) a feature selection model and (ii) a conditional distribution in the reduced-dimensional space model. The feature selection model (i) reflects the transition from a high dimensional space to a low dimensional space. The conditional distribution model (ii) reflects the distribution of lowdimensional statistics conditional on their inclusion in the feature selection model—that is, the distribution induced by the feature selection step. Below, we discuss examples of each for settings in which there is no resampling, and in which resampling is involved. The complexity of modeling either step will vary with the probability model and the prediction algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Applicability</head><p>The computer program and related working examples presented in this article are complicated implementations of results in Dobbin (2009). The complexity may obscure the range of applicability of the method.<ref type="figure" target="#tab_1">Table 1</ref>presents some simpler contexts for AROHIL Monte Carlo. The first row of the table are the feature selection models. The second row of the table are the conditional distribution models. The columns of the table represent different multivariate normal data models. The compound covariate predictor (<ref type="bibr" target="#b15">Radmacher et al., 2002</ref>) is the prediction algorithm. Modifications can be made to adjust for different multivariate data distributions and prediction algorithms, although these may be non-trivial in some cases. The first row of<ref type="figure" target="#tab_1">Table 1</ref>presents the selection models. For example, consider the cell with 'Indep. Bernoulli R.V.'s'. It indicates that independent Bernoulli random variables can be used when data are multivariate normal, with diagonal covariance matrix, and genes are selected one-at-a-time based on t-test P-values being below a threshold (such as 0.001). The success probability is the power if the gene is differentially expressed, or the significance level if the gene is not differentially expressed. On the other hand, as indicated in the cells with 'Fixed number k', if the top k features are selected for the model, where k is fixed, then the selection 'model' is deterministic and just returns the number k always. Finally, in the setting of a more complex covariance structure, the selection model needs further refinement. Nevertheless, even in the most general setting of a positive definite covariance matrix of arbitrary form (cell with 'MVN and Wishart</p><p>Model'), a single multivariate normal variate and a single Wishart variate are all that are required. Details are provided in the Supplementary Material. The second row of<ref type="figure" target="#tab_1">Table 1</ref>presents the conditional distribution models. For example, consider the cell with 'Indep truncated distn's'. Here, the covariance is diagonal and a P-value cutoff is used to select features. Weights for the CCP are t-test statistics. Thus, the distribution of the predictor in the reduced space is the same as a set of independent, truncated, non-central Student's t distributions. Non-centrality parameters can be calculated from the model parameters. Truncation points are determined by the feature selection stringency used. The distribution of the CCP cutpoint for classification can be generated in a fairly simple way. Details are described in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Working example</head><p>The computer program provided with this article uses AROHIL Monte Carlo for several objectives. When no resampling is required, models are similar to the example in Column 1 of<ref type="figure" target="#tab_1">Table 1</ref>, and details are given in Section 5 of the Supplementary Material. The discussion below will focus on the more challenging context of high-dimensional resampling. The objective will be to obtain the quantiles of the distribution of the predictive accuracy estimate from leave-one-out cross-validation. This working example of resamplingbased AROHIL Monte Carlo is motivated by previous work (<ref type="bibr" target="#b3">Dobbin, 2009</ref>). In our working example, the Monte Carlo simulation data are from the homoscedastic multivariate normal model</p><formula>x i ∼ MVN(μ x ,D),i = 1,...,n/2 y i ∼ MVN(μ y ,D),i = 1,...,n/2 (1)</formula><p>where D is a diagonal covariance matrix. Let 2δ j be the j-th element of μ x −μ y , and σ 2 j the j-th diagonal element of D. Features are selected with pooled variance t-test P-values below a threshold α. Selected features are given weights equal to the pooled variance t-test statistic, and unselected feature are given weight zero. LetˆLLetˆ LetˆL be the p×1 vector of weights. Let w be a p×1 future observation. The classification rule is</p><formula>c = 1 2 ˆ L ¯ X + ˆ L ¯ Y CCP(w) = C x 1 {( ˆ L w−c)( ˆ L ¯ X−c)&gt;0} + C y 1 {( ˆ L w−c)( ˆ L ¯ X−c)≤0}</formula><p>where 1 A is the indicator function of event A, and C x is the class of x's and C y the class of y's.</p><p>Page: 3131 3129–3134</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy bounds by AROHIL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">AROHIL Monte Carlo models for resampling-based feature selection</head><p>The feature selection step in the context of traditional Monte Carlo resampling requires generating data from the probability model X ∼ F where X is n×p (Supplementary Figs S3 and S4). The next step is to resample from X to produce˜Xproduce˜ produce˜X which isñ×pis˜isñ×p. For example, in LOOCVñLOOCV˜LOOCVñ = n−1; in bootstrap, usuallyñusually˜usuallyñ = n. Theñ T MC = g( ˜ X) is a vector of statistics used for feature selection, and˜Sand˜ and˜S MC = h( ˜ T MC ) a binary vector of feature selection indicators. Then, the same dataset is resampled from multiple times, denoted r times, producing˜Sproducing˜ producing˜S 1 MC ,..., ˜ S r MC ; for example, in LOOCV r = n; in bootstrap, r = B where B is the number of bootstrap samples. Ideally, the AROHIL approach will produce a set of indicator vectors˜S vectors˜ vectors˜S 1 AROHIL ,...,</p><formula>˜ S r AROHIL such that ⎡ ⎣ ˜ S 1 AROHIL ... ˜ S r AROHIL ⎤ ⎦ d = ⎡ ⎣ ˜ S 1 MC ... ˜ S r MC ⎤ ⎦ .</formula><p>One way to do this is to generate first ⎡</p><formula>⎣ ˜ T 1 AROHIL ... ˜ T r AROHIL ⎤ ⎦ d = ⎡ ⎣ ˜ T 1 MC ... ˜ T r MC ⎤ ⎦ .</formula><formula>(2)</formula><p>Let B full be a vector of statistics for feature selection based on the full dataset. Consider the following hierarchical model,</p><formula>B full ∼ F B ⎡ ⎣ ˜ T 1 AROHIL ... ˜ T r AROHIL ⎤ ⎦ B full ∼ F T (·|B)</formula><p>if the distribution functions F B and F T (·|B) can be derived from the model, then this can ensure Equation (2) is satisfied. For the working example, the backbone vector B full is the P-dimensional vector of pooled T statistics from the full dataset. The distribution of the each element of B full is independent: Student's t with n−2 degrees of freedom and non-centrality parameter calculated from the model parameters. Therefore, generating B full is straightforward. Let ¯ X (i) and D (i) be the mean and pooled covariance estimates when sample i is left out from the X's. It is shown in the Supplementary Material that for large n we have the approximation,</p><formula>¯ X (i) − ¯ Y ˆ D −1 (i) |B full ∼ MVN B full , 4 n(n−2) .</formula><p>Then the powers can be calculated for feature g by</p><formula>q g ≈ 1− n(n−2)</formula><formula>4/n t α/2,n−2 −B full,g + n(n−2) − 4/n t α/2,n−2 −B full,g</formula><p>where B full,g is the g-th element of B full. Finally, each S r AROHIL |B full is a vector of independent (conditional on B full ) Bernoulli random variables, where the g-th entry has success probability q g .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">AROHIL Monte Carlo models for resampling-based conditional distributions</head><p>After gene selection, traditional Monte Carlo works in the reduced dimensional space. Let k(r) be the dimension of the reduced space on resampled dataset r, and T MC,k(r) the vector of statistics in the reduced dimensional space. The objective function of interest is</p><formula>Q MC,k(r) = h(T MC,k(r)</formula><p>). AROHIL Monte Carlo generates T AROHIL,k(r) directly from a probability model. Then Q AROHIL,k(r) = h(T AROHIL,k(r) ) and ideally one</p><formula>wants, ⎛ ⎜ ⎝ Q 1 AROHIL,k(1) ... Q r AROHIL,k(r) ⎞ ⎟ ⎠ d = ⎛ ⎜ ⎝ Q 1 MC,k(1) ... Q r MC,k(r) ⎞ ⎟ ⎠.</formula><p>Let B full be a vector of statistics for feature selection based on the full dataset. Then AROHIL modeling can use the hierarchical model,</p><formula>B full ∼ F B ⎡ ⎣ ˜ Q 1 AROHIL ... ˜ Q r AROHIL ⎤ ⎦ B full ∼ F Q (·|B full ).</formula><p>In the working example, B full is the vector of pooled variance t-statistics. The gene selection model reduces the dimension of the space using B full. The elements of Q i AROHIL are thenˆLthenˆ thenˆL k elements, plus a classification cutpoint. ThêThê L k elements are generated from truncated Student's t distributions with n−3 degrees of freedom and non-centrality parameter calculated from the model. (Another approach would be to generate thê L k elements by adding noise to the corresponding elements of B full. But this led to computational problems due to the fact that the sum must be truncated so as to ensure coherence with the selection model.) This leads to the approach that Q i AROHIL is generated by:</p><formula>ncp = μ x −μ y D −1 √ 4/n Q i AROHIL ∼ truncMVT t α/2,n−3 ,ncp,n−3</formula><p>where truncMVT (a,b,c) is a vector of independent Student T random variables, truncated away from zero at ±a, with non-centrality vector b, and with degrees of freedom c. See Section 5 in Supplementary Material for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>AROHIL Monte Carlo was applied in multiple places to the algorithm of Dobbin (2009). Briefly, the method of Dobbin (2009) constructs a lower confidence bound for the true prediction accuracy of a classifier developed on high-dimensional data. This bound provides an estimate of the variability in the leave-one-out estimate of prediction accuracy which is otherwise problematic to assess. The motivation was to convert the method of Dobbin (2009) from a set of C++ programs, to a single R program, while at the same time reducing the computation time. We first compare pure Monte Carlo to AROHIL Monte Carlo computation times in some simple settings. Then we turn to the implementation of the method of Dobbin (2009) and analyze some of the results to validate the AROHIL method, and to show how intermediate steps of AROHIL Monte Carlo algorithms can be checked. We first performed a set of simulations to benchmark the computational savings of AROHIL Monte Carlo compared with traditional Monte Carlo on some simple examples. Results are presented in<ref type="figure" target="#tab_2">Table 2</ref>. As can be seen from the table, computational costs in high dimensions can be reduced several orders of magnitude by using AROHIL Monte Carlo instead of traditional Monte Carlo. On the fourth row of the table, representing a 5000 dimensional space, the computation time is reduced from over a day to under a minute. Also note that the estimates from the two methods are practically identical. Now we turn to the AROHIL program implementation. Three key intermediate steps in the application of the AROHIL method to the algorithm of Dobbin (2009) are as follows:</p><p>(1) Generate the distribution of cutpoints used for classification of samples.</p><p>(2) Generate mean accuracies corresponding to a particular highdimensional Mahalanobis distance between the class means.of the parameters, with α = 0.001, δ = 1, P dimensions, n = 60, using CCP predictor over 500 simulations. When Sim = Resampling, simulations are estimating the 90th percentile of the leave-one-out cross-validated prediction accuracy distribution for fixed values of the parameters, with α = 0.001, δ = 1, P dimensions, n = 60, using CCP prediction over 1000 simulations. No Resamplings done in R on a 32-bit operating system, Resamplings done in R on a 64 bit operating system. No Resampling estimates include standard deviations in parentheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K.K.Dobbin and S.Cooke</head><p>(3) Generate the lengths of predictors,<ref type="figure" target="#tab_3">Table 3</ref>, coverage probabilities are quite close to nominal over a wide range of settings, and appear to improve over Dobbin (2009) by being less conservative. The AROHIL method was used to evaluate coverage probabilities in the presence of violations of model assumptions. Results are shown in<ref type="figure" target="#tab_4">Table 4</ref>. As can be seen in the table, the coverage probabilities do break down in extreme cases, particularly for very heavy tailed distributions, such as the Student's t distribution with 1 degree of freedom (where the variance is infinite). But overall the method is quite robust. In<ref type="figure" target="#tab_5">Table 5</ref>, the method was applied to five datasets evaluated in<ref type="bibr" target="#b10">Michiels et al. (2005)</ref>to construct lower confidence bounds for prediction accuracy. Datasets were downloaded from the BRB Array Tools data archive (<ref type="bibr" target="#b23">Zhao and Simon, 2008</ref>). Note that for three of the five datasets, a 90% lower confidence bound does not contain 50%, indicating better than chance classification. The more conservative 97.5% lower bound is above 50% for two of the datasets. This is in contrast to<ref type="bibr" target="#b10">Michiels et al. (2005)</ref>, in which all their 95% two-sided intervals (equivalent to our one-sided 97.5% interval) contained 50%. Importantly, these two datasets (<ref type="bibr" target="#b18">Rosenwald et al., 2002 and</ref><ref type="bibr">van't Veer et al., 2002</ref>) have found supporting evidence in subsequent publications (<ref type="bibr" target="#b0">Bea et al., 2005 and</ref><ref type="bibr" target="#b22">Wittner et al., 2008</ref>), which seems to suggest that the method of<ref type="bibr" target="#b10">Michiels et al. (2005)</ref>is overly conservative compared with our AROHIL Monte Carlo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>We have presented a mathematical modeling approach to speed up high-dimensional Monte Carlo simulations by reducing the effective dimension of the space in which the simulations are performed. We have described in a general way how this approach can be usedin the case of simple Monte Carlo simulations, and also Monte Carlo simulations that require resampling, such as bootstrap or crossvalidation. The modification for the resampling setting is achieved by constructing a hierarchical model for which the distributions of the functionals of interest match (or approximately match) the pure Monte Carlo distributions. This new method is called AROHIL, and can enable complex and slow high-dimensional simulations to be converted into simpler and much faster low-dimensional simulations. We have discussed how this method can be used to improve robustness evaluations and to disseminate software. As an example, we are disseminating an AROHIL program with this article, and have presented a robustness evaluation of this previously published method. In the discussion below, we discuss AROHIL Monte Carlo generally first, and then the implementation program provided in this article. We have discussed one detailed example of how high-dimensional leave-one-out cross-validation Monte Carlo can be converted into an AROHIL Monte Carlo. Generalizing this to other cross-validations, such as 10-fold cross-validation, is straightforward. Bootstrapping by AROHIL would require a further modification. We showed in this article that AROHIL for cross-validation is performed by calculating the distribution of a backbone vector of statisticsis the effect size for individual differentially expressed features. ρ is the correlation parameter for CS and AR(1). '¯ a" is the mean true accuracy over all simulations. '90% LB Coverage' is the coverage probability of 90% lower confidence bound, using either AROHIL or an exact binomial confidence interval constructed (naively/incorrectly) from the LOOCV accuracy estimate.Applications to real datasets used in<ref type="bibr" target="#b10">Michiels et al. (2005)</ref>. ˆ a loocv is the leave-one-out cross-validation accuracy. Dim is the number of features, n 1 and n 2 are the number from each class. '90% LB' is the 90% lower confidence bound computed by AROHIL Monte Carlo; and similarly '97.5% LB' is a 97.5% LB, comparable to the 95% twosided intervals used in<ref type="bibr" target="#b10">Michiels et al. (2005)</ref>. For the<ref type="bibr" target="#b18">Rosenwald et al. (2002)</ref>dataset, the outcome is survival status at 3 years. For the van't<ref type="bibr" target="#b19">Veer et al. (2002)</ref>dataset, outcome is 5-year metastases-free survival. For the<ref type="bibr" target="#b1">Beer et al. (2002)</ref>dataset, outcome is survival status. For the<ref type="bibr" target="#b14">Pomeroy et al. (2002)</ref>dataset, outcome is survival status. For the<ref type="bibr" target="#b2">Bhattacharjee et al. (2001)</ref>dataset, outcome is survival status. For all datasets, the significance level for gene selection was α = 0.001. that represents the full dataset, then calculating the conditional distribution of key cross-validation statistics when a sample is left out. For bootstrapping, an extra level would need to be added to the hierarchical model that would represent the overlap pattern between the bootstrap samples. This pattern could be represented by a simple multinomial model with probability 1/n on each of the n samples for each of the bootstrap draws (sampling with replacement). Then the conditional distribution given the backbone vector and the pattern can be derived in a straightforward way and used to generate the bootstrap sample. We have discussed that sometimes AROHIL models will require approximations to the pure Monte Carlo distribution. Importantly, such approximations must be checked carefully to ensure that they are true to the original model. On the other hand, it does not seem reasonable to 'throw the baby out with the bathwater' and abandon AROHIL Monte Carlo when any approximations are required. In many cases, these approximations are straightforward to check over the range of simulation settings that are of interest. We have termed the dimension reduction step of AROHIL as adequate, and not attempted here to define this idea exactly. Dimension reduction could be based on more general notions such as sufficiency. A potential area of future research is to find a more formal approach to the dimension reduction step which would establish that the statistics used by the AROHIL Monte Carlo are capturing all the key aspects of the pure Monte Carlo. A potential critique of the AROHIL approach is that it requires some work to build the mathematical models used to reduce dimension. While it is true that this method requires some extra work, which is not generally worth the trouble in lower dimensional settings, the computational savings in high dimensions is so large that it can not only be worthwhile but also critical. Furthermore, very complex high-dimensional procedures can be challenging to implement, and thoroughly checking for coding bugs, information leak or inadvertent neglect of specification of all parameters and assumptions, can be fraught with difficulties. An important aspect of AROHIL is that implementation is simplified, i.e. the added complexity of the mathematics is often more than compensated for by the greater simplicity and transparency of the computer code. We argue that this results in a cleaner and overall simpler procedure than traditional brute force Monte Carlo, where any errors are often buried in long computer code scripts. We have found that the AROHIL Monte Carlo approach results in very short and simple code compared with pure Monte Carlo. For example, the R script we are providing with this publication is much shorter and simpler than the original code from Dobbin (2009), consisting of multiple C++ programs and steps to integrate the outputs together. The resulting simplification of the code is likely to greatly enhance reproducibility of high-dimensional studies, which has been a continuing challenge to this area. The accompanying AROHIL program is implemented with one informative feature, which was used in all the coverage probability simulations in this article. The program is also available with a userselected number of features. The number of informative features has relatively small effect on the confidence interval bound, and the number of informative features is unknown. Hence, it is preferable to have a program in which the user does not have to come up with this unknown quantity. See Section 6 in Supplementary Material for the table of simulation results showing the stability of bounds across different numbers of informative features. An alternative approach would be to search over different possible numbers of informative features to find a worst-case scenario setting, resulting in more conservative confidence bounds. The accompanying AROHIL program is implemented with a diagonal covariance matrix. This is done not because the true covariance for high-dimensional data is likely to be diagonal, but because it is generally not possible to estimate the covariance matrix</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy bounds by AROHIL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K.K.Dobbin and S.Cooke</head><p>well in high dimensions. Covariance matrices may be estimated with a shrinkage estimate of the formˆshrinkformˆ formˆshrink = w×Diag( ˆ )+(1−w)× ˆ (<ref type="bibr">Ledoit and Wolfe, 2004;</ref><ref type="bibr" target="#b19">Schafer and Strimmer, 2005</ref>), as was done for<ref type="figure" target="#tab_3">Table 3</ref>. An area of potential future work is to use covariance estimates to better tune this method to a given set of data. Finally, there are a few additional comments on the program implementation provided in this article. This program provides a lower confidence bound on prediction accuracy, taking as input the observed leave-one-out cross-validated accuracy, the dimension of the feature space, the number of differentially expressed features and the stringency used for feature selection. This program implements the method of Dobbin (2009), which is a Monte Carlo-based method that assumes a multivariate normal distribution. While the simulations presented in this article and Supplementary Material suggest that the method is quite robust to model violations, it should be noted that the gold standard in high dimensions is generally considered to be non-parametric resampling-based methods. For example,<ref type="bibr" target="#b8">Jiang et al. (2008)</ref>have developed a bootstrap method for constructing confidence intervals for prediction accuracy. This bootstrap method could serve as a more robust check on the interval constructed with the AROHIL program provided here. One can also note that in evaluating whether a classifier is statistically significantly better than chance, permutation tests (<ref type="bibr" target="#b21">Westfall and Young, 1993</ref>) are probably more appropriate than confidence-boundbased approaches. One should also not use this method in a vacuum, but note that previous work has been done. For example,<ref type="bibr" target="#b11">Mukherjee et al. (2003) and</ref><ref type="bibr" target="#b5">Dobbin et al. (2008)</ref>have presented sample size guidelines for studies that may indicate whether one should expect a confidence bound to be reasonably tight. Also, if the class prevalences are highly imbalanced (e.g. 90% from one class and 10% from the other), then overall classification accuracy is probably not as important as other quantities, such as positive or negative predictive values. See Dobbin and Simon (2011) for discussion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>[17:</head><figDesc>42 20/10/2011 Bioinformatics-btr542.tex] Page: 3132 3129–3134</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1. AROHIL Monte Carlo applicability for some simple settings AROHIL Monte Carlo modeling for homoscedastic multivariate normal data. The predictor development algorithm in each case is the compound covariate predictor (CCP). Settings do not involve resampling. Details are provided in the Supplementary Material. dimension of the computation space, which is the key computational advantage of AROHIL Monte Carlo. Section 2 discusses applicability of the method, presents the AROHIL method and uses examples to display the approach. Section 3 presents the results of the simulations and applications to real datasets. Section 4 discusses the conclusions and potential areas for future work.</figDesc><table>Covariance matrix 
diagonal 
positive definite 

Selection process 
P-value cutoff 
Top k 
P-value cutoff 
Top k 

AROHIL Models 

Selection model 

Indep. 
Fixed 
MVN and 
Fixed 
Bernoulli 
number 
Wishart 
number 
R.V.'s 
k 
Model 
k 

Cond. Distn. model 

Indep 
Top k 
MVN and 
MVN and Wishart 
truncated 
order 
Wishart trunc. 
model, top k 
distn.'s 
statistics 
distn. model 
order stats. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2. Benchmark simulations Sim P Computing time</figDesc><table>Pure MC 
AROHIL MC (s) 
Times ratio 
Pure MC 
AROHIL MC 

No Resampling 
5000 
32 min 45.13 s 
0.50 
3930 
0.753 (0.032) 
0.753 (0.034) 
No Resampling 
1000 
4 min 55.9 s 
1.11 
267 
0.816 (0.020) 
0.818 (0.022) 
No Resampling 
100 
25.65 s 
0.70 
37 
0.837 (0.010) 
0.838 (0.009) 

Resampling 
5000 
1 day 12 h 5 min 28.01 s 
53.01 
2451 
0.850 
0.850 
Resampling 
1000 
7 h 11 min 12.7 s 
33.94 
762 
0.883 
0.883 
Resampling 
100 
43 min 27.07 s 
28.97 
90 
0.900 
0.900 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>ˆ L conditional on a true accuracy a true of the full-dataset predictor. Each of these steps was reimplemented using AROHIL Monte Carlo and these intermediate results were carefully checked. Results are presented in Section 3 in Supplementary Material. The critical test is the performance of the AROHIL Monte Carlo method in terms of maintaining coverage probabilities compared with the method of Dobbin (2009). This requires estimating quantiles of the leave-one-out cross-validation distribution. As shown in</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 3. Coverage probability assessment = 1000 features, n 1 = n 2 = 30 per class,'DE Features' are differentially expressed features; compound covariate predictor with gene selected based on significance cutoff α = 0.011.</figDesc><table>DE 
MAHD/2 
¯ a 
90% LB 
90% LB naive 
features 
coverage 
bin coverage 

1 
2.5 
99% 
1.000 
1.000 
1 
2.0 
95% 
0.895 
0.860 
1 
1.5 
87% 
0.918 
0.917 
1 
1.0 
73% 
0.902 
0.864 

5 
2.5 
99% 
1.000 
1.000 
5 
2.0 
95% 
0.941 
0.962 
5 
1.5 
87% 
0.931 
0.925 
5 
1.0 
70% 
0.897 
0.867 

Coverage probabilities calculated from 1000 replications. Model settings are P </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 4. Robustness assessment of coverage probabilities</figDesc><table>Distn 

DEG 
δ 
ρ 
¯ a 
90% LB coverage 

AROHIL 
Bin 

MVN 
CS 
5 
3.0 
0.6 
0.94 
0.97 
0.97 
MVN 
CS 
5 
2.0 
0.6 
0.84 
0.98 
0.95 
MVN 
CS 
5 
1.0 
0.6 
0.65 
0.90 
0.88 

MVN 
AR(1) 
30 
4.0 
0.8 
0.92 
1.00 
0.97 
MVN 
AR(1) 
30 
3.0 
0.8 
0.85 
0.99 
0.98 
MVN 
AR(1) 
30 
2.0 
0.8 
0.72 
0.96 
0.95 

MVN 
Emp 
1 
3.0 
NA 
0.90 
0.97 
0.96 
MVN 
Emp 
1 
2.0 
NA 
0.79 
0.95 
0.92 
MVN 
Emp 
1 
1.0 
NA 
0.60 
0.87 
0.85 

MVT1 
Diag. 
1 
5.0 
0 
82% 
0.934 
0.940 
MVT1 
Diag. 
1 
3.0 
0 
65% 
0.876 
0.869 
MVT1 
Diag. 
1 
2.0 
0 
58% 
0.866 
0.870 

MVT3 
Diag. 
1 
3.0 
0 
95% 
0.960 
0.989 
MVT3 
Diag. 
1 
2.0 
0 
85% 
0.928 
0.912 
MVT3 
Diag. 
1 
1.0 
0 
63% 
0.878 
0.851 

Coverage probabilities under model violations. Columns are as follows: 'Distn' is 
the high-dimensional distribution of the data, multivariate normal or multivariate T 
with 1 or 3 degrees of freedom. is the form of the covariance matrix, CS for 
block compound symmetric, AR(1) for block autoregressive order 1, Empirical for 
empirically estimated using shrinkage from Rosenwald et al. (2003) data, Diag for 
diagonal. 'DEG' is the number of differentially expressed features. δ/ 
√ 
DEG </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 5. Applications to real datasets</figDesc><table>Dataset 
Dim 
Dead AlivêAlivê 
a loocv 
90% LB 97.5% LB 

Rosenwald 
7399 
112 
116 
61% 
0.53 
0.53 
van't Veer 
24 481 
51 
46 
65% 
0.58 
0.52 
Beer 
7129 
24 
60 
56% 
&lt;0.50 
&lt;0.50 

Pomeroy 
7129 
21 
39 
62% 
0.52 
&lt;0.50 

Bhattacharjee 12 600 
53 
74 
53% 
&lt;0.50 
&lt;0.50 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank the referees who provided insightful suggestions that improved this article.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Diffuse large B cell lymphoma subtypes have distinct genetic profiles that influence tumor biology and improve gene expression-based survival prediction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bea</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Blood</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="3183" to="3190" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Gene-expression profiles predict survival of patients with lung adenocarcinoma</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">G</forename>
				<surname>Beer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="816" to="824" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Classification of human lung adenocarcinomas by mRNA expression profiling reveals distinct adenocarcinoma subclasses</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bhattacharjee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 98</title>
		<meeting>. Natl Acad. Sci. USA, 98</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="13790" to="13795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A method for constructing a confidence bound for the actual error rate of a prediction rule in high dimensions</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">K</forename>
				<surname>Dobbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="282" to="296" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimally splitting cases for training and testing high dimensional classifiers</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">K</forename>
				<surname>Dobbin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Simon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Med. Genom</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">How large a training set is needed to develop a classifier for microarray data? Clin</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">K</forename>
				<surname>Dobbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="108" to="114" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Multiple hypothesis testing in microarray experiments</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dudoit</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="71" to="103" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions, and Bayesian restoration of images</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Geman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Geman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="774" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Calculating confidence intervals for prediction error in microarray classification using resampling</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Article. 8</note>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A well-conditioned estimator for large-dimensional covariance matrices</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Ledoit</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wolf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Multivar. Anal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="365" to="411" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Prediction of cancer outcome with microarrays: a multiple random validation strategy</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Michiels</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lancet</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page" from="488" to="492" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Estimating dataset size requirements for classifying DNA microarray data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mukherjee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="119" to="142" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">On partial least squares dimension reduction for microarray-based classification: a simulation study</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">V</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Rocke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="407" to="425" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Circular binary segmentation for the analysis of array-based DNA copy number data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">B</forename>
				<surname>Olshen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="557" to="572" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Prediction of central nervous system embryonal tumor outcome based on gene expression</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">L</forename>
				<surname>Pomeroy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="page" from="436" to="442" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A paradigm for class prediction using gene expression studies</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">D</forename>
				<surname>Radmacher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1462" to="1469" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<monogr>
		<title level="m" type="main">Stochastic Simulation</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">D</forename>
				<surname>Ripley</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Wiley and Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<monogr>
		<title level="m" type="main">Monte Carlo Statistical Methods</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">P</forename>
				<surname>Robert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Casella</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rosenwald</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">346</biblScope>
			<biblScope unit="page" from="1937" to="1947" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A shrinkage approach to large-scale covariance matrix estimation and applications for functional genomics Gene expression profiling predicts clinical outcome of breast cancer</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schafer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">J</forename>
				<surname>Veer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Apps. Genetics Mol. Biol. Nature</title>
		<imprint>
			<biblScope unit="volume">415</biblScope>
			<biblScope unit="page" from="530" to="536" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A faster circular binary segmentaion algorithm for the analysis of array CGH data</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">S</forename>
				<surname>Venkatraman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">B</forename>
				<surname>Olshen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="657" to="663" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<monogr>
		<title level="m" type="main">Resampling-Based Multiple Testing</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">H</forename>
				<surname>Westfall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">S</forename>
				<surname>Young</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Analysis of the MammaPrint breast cancer assay in a predominantly postmenopausal cohort</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">S</forename>
				<surname>Wittner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Cancer Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="2988" to="2993" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">BRB ArrayTools Data Archive for Human Cancer Gene Expression: A Unique and Efficient Data Sharing Resource</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Simon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Informatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="9" to="15" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Regularization and variable selection via the elastic net</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hastie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>