
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Near-optimal experimental design for model selection in systems biology</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">20 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Alberto</forename>
								<forename type="middle">Giovanni</forename>
								<surname>Busetto</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Competence Center for Systems Physiology and Metabolic Diseases</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alain</forename>
								<surname>Hauser</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Gabriel</forename>
								<surname>Krummenacher</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Mikael</forename>
								<surname>Sunnå Ker</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Competence Center for Systems Physiology and Metabolic Diseases</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Sotiris</forename>
								<surname>Dimopoulos</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Competence Center for Systems Physiology and Metabolic Diseases</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Soon</forename>
								<surname>Cheng</surname>
							</persName>
						</author>
						<author>
							<persName>
								<surname>Ong</surname>
							</persName>
							<affiliation key="aff5">
								<orgName type="department">Associate Editor: Igor Jurisica</orgName>
								<orgName type="institution">National ICT Australia</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jö</forename>
								<surname>Rg Stelling</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Biosystems Science and Engineering</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Joachim</forename>
								<forename type="middle">M</forename>
								<surname>Buhmann</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">ETH Zurich</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Competence Center for Systems Physiology and Metabolic Diseases</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Systems biology Near-optimal experimental design for model selection in systems biology</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="page" from="2625" to="2632"/>
							<date type="published" when="2013">20 2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt436</idno>
					<note type="submission">Received on May 6, 2013; revised on July 10, 2013; accepted on July 24, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Biological systems are understood through iterations of modeling and experimentation. Not all experiments, however, are equally valuable for predictive modeling. This study introduces an efficient method for experimental design aimed at selecting dynamical models from data. Motivated by biological applications, the method enables the design of crucial experiments: it determines a highly informative selection of measurement readouts and time points. Results: We demonstrate formal guarantees of design efficiency on the basis of previous results. By reducing our task to the setting of graphical models, we prove that the method finds a near-optimal design selection with a polynomial number of evaluations. Moreover, the method exhibits the best polynomial-complexity constant approximation factor, unless P ¼ NP. We measure the performance of the method in comparison with established alternatives, such as ensemble non-centrality, on example models of different complexity. Efficient design accelerates the loop between modeling and experimentation: it enables the inference of complex mechanisms, such as those controlling central metabolic operation. Availability: Toolbox &apos;NearOED&apos; available with source code under GPL on the Machine Learning Open Source Software Web site</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>At the present level of development, investigations in biology require setting up complicated and expensive experiments (<ref type="bibr" target="#b18">Kitano, 2002</ref>). Advances in measurement techniques prompted the recent growth of detailed mathematical models, which capture biological phenomena at different levels of detail. However, the employment of novel measurement techniques by itself is insufficient to achieve high predictive power. Experimental design provides the necessary guidance to determine crucial observations. Often, in fact, an important task is the selection of the most informative experiments. In systems biology, dynamical models express cause–effect relations between interacting components (<ref type="bibr" target="#b18">Kitano, 2002</ref>). Designing optimal experiments for parameter estimation is challenging, but also well studied. At present, there already exist conclusive results and ready-to-use procedures (<ref type="bibr" target="#b4">Bandara et al., 2009;</ref><ref type="bibr" target="#b15">Faller et al., 2003</ref>). In contrast, modern research often consists of discriminating between alternative models (<ref type="bibr" target="#b6">Box and Hill, 1967;</ref><ref type="bibr" target="#b27">Kuepfer et al., 2007</ref>), a task for which several questions remain open (<ref type="bibr" target="#b15">Faller et al., 2003;</ref><ref type="bibr" target="#b24">Kreutz and Timmer, 2009;</ref><ref type="bibr" target="#b30">Myung and Pitt, 2009</ref>). Design optimization for the selection of dynamic models proves especially challenging in the presence of nonlinear behavior (<ref type="bibr" target="#b3">Balsa-Canto et al., 2008;</ref><ref type="bibr" target="#b18">Kitano, 2002</ref>). In classical statistics, ensemble non-centrality constitutes the reference technique to design experiments for model selection (<ref type="bibr" target="#b0">Atkinson and Fedorov, 1975</ref>; Ponce De<ref type="bibr" target="#b32">Leon and Atkinson, 1991;</ref><ref type="bibr">Skanda and Lebiedz, 2012</ref>). Recently, Bayesian techniques have been applied with success to neuroimaging and biochemical modeling (<ref type="bibr" target="#b10">Busetto et al., 2009;</ref><ref type="bibr" target="#b12">Daunizeau et al., 2011;</ref><ref type="bibr" target="#b20">Kramer and Radde, 2010;</ref><ref type="bibr" target="#b28">Liepe et al., 2013;</ref><ref type="bibr" target="#b35">Steinke et al., 2007</ref>). Existing methods are primarily limited by computational bottlenecks, as optimization is often practically intractable. This study introduces an efficient method to design informative experiments for selecting biological dynamical systems. Building on previous results (<ref type="bibr" target="#b22">Krause and Guestrin, 2005</ref>), we go beyond current limitations by constructing a method that yields near-optimal combinations of time points and measurable readouts. Formal efficiency guarantees of the method are proved by reduction to a well-studied general setting (<ref type="bibr" target="#b16">Feige, 1998;</ref><ref type="bibr" target="#b22">Krause and Guestrin, 2005;</ref><ref type="bibr" target="#b31">Nemhauser et al., 1978</ref>). The method is generally applicable and has been primarily motivated by questions arising from the biological domain. We empirically evaluate the performance of the method with models of glucose tolerance and cell signaling. We apply the method to address challenging open problems of biological and medical relevance. The manuscript is organized as follows. We start by introducing relevant facts and notions to be used in the rest of the article. Theoretical results are followed by empirical evaluation and numerical comparison with competing techniques. Finally, the method is evaluated and verified with glucose tolerance and cell signaling. Further details are presented in the Supplementary material. *To whom correspondence should be addressed. ß The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>We distinguish three entities: the studied system, the researcher and the measurement apparatus. The system is modeled by the researcher, who learns from the data and designs experiments by tuning the measurement apparatus. In this study, learning and reasoning follow the rules of probability theory (<ref type="bibr" target="#b2">Baldi and Itti, 2010</ref>). Let admissible configurations of the system be called states xðtÞ 2 X R n. States are time-varying representations evolving over time t 2 T R. We define the 'true model' as f Ã , the function that governs the evolution of the system. Modeling with systems of ordinary differential equations (ODEs), we have dxðtÞ dt ¼ f Ã ðxðtÞ, Þ ð 1Þ with a certain known initial condition xðt 0 Þ. The function f Ã defines how infinitesimal state increments depend on current states and parameters 2 Â R d of the system. In biochemical and physiological applications, each state component quantifies molecules, concentrations or other physiological measures. In practice, parameters consist of acceptable values for reaction rates and other kinetic constants (<ref type="bibr" target="#b18">Kitano, 2002;</ref><ref type="bibr" target="#b40">Zhong et al., 2012</ref>). Calculating the trajectory of the system in Equation (1) from a certain starting point is an initial value problem (IVP). The 'true model' f Ã and its parameters are unknown to the researcher. The goal of modeling is to select the most predictive model, and to estimate parameters and initial conditions. In this study, model selection is inference, that is deductive learning from data. The lack of knowledge of the researcher is not absolute. First, the researcher has access to a set of candidate models, which we call the hypothesis class F. We denote a generic candidate model as f 2 F. The 'true model' is not necessarily a candidate model available to the researcher. Let us call the scenario in which f Ã 2 F as realizable, and non-realizable otherwise. This study considers both realizable and non-realizable scenarios. Second, the researcher benefits from previous experiments, published results and domain knowledge. All these pieces of information form the a priori knowledge, that is the prior probability p( f ). Such probability is defined over the candidate models before observing the data. Experimental measurements consist of readouts yðt i Þ :¼ y 1 ðt i Þ,. .. , y n ðt i Þ ½  T 2 R n ð2Þ obtained through sampling. Sampling can be performed at arbitrary time points t 1 ,. .. , t s. We denote the range of indexes for time points as S :¼ f1,. .. , sg and the range for the readout variables as N :¼ f1,. .. , ng, such that the index pair ði, j Þ 2 S Â N refers to the individual measurement y j ðt i Þ :¼ x j ðt i Þ þ " ij , ð3Þ whose noise is denoted by " ij. Noise terms are independent random variables sampled from known distributions N ij. Individual measurements can be grouped into datasets Y :¼ fy j ðt i Þ 2 R n : ði, j Þ 2 S Â N g, ð4Þ whose elements are defined by the indexes in experiment , which is, more generally, a multiset. Adopting the Bayesian viewpoint, the researcher performs inference by calculating the probability of the models given the data, as visualized in<ref type="figure">Figure</ref>Probabilities are revised and updated for each model in F as more evidence is accumulated. The likelihood function pðY j f Þ is the probability of generating a specific instance of the data with a candidate model. By construction, measurements are conditionally independent given the model, and hence the likelihood factorizes as pðY j f Þ ¼ Y ði, j Þ2 pðy j ðt i Þj f Þ ð 6Þ for given. Because of conditional independence, posteriors from previous inference are priors for subsequent experiments. This property is useful when single experiments do not yield sufficient evidence, but sequences might provide conclusive results. In practice, this advantage might prove essential to select predictive models (<ref type="bibr" target="#b39">Xu et al., 2010</ref>). Here, the primary aim is to select models, not parameters. Nonetheless, it is useful to assume a certain degree of uncertainty regarding the parameters. The model posterior is such cases obtained by marginalizing over the parametersNote that models with alternative parameter values and initial conditions can be treated as alternative models. The probability of each state follows the drift equation @pðxðtÞÞ @t ¼ r Á ½ f ðxðtÞ, ÞpðxðtÞÞ ð8Þ where rÁ denotes the divergence operator. The equation determines the evolution over time of the state uncertainty. Conceptually, it constrains the probability of observing a certain state in the future on the basis of the dynamical properties of the system. Equation</p><formula>pð f jY Þ ¼ Z Â pð f , jY Þd ¼ Z Â pðY jf, Þpð f , Þ pðY Þ d ð7Þ</formula><p>(8) can be extended to the parameter space to perform inference (<ref type="bibr" target="#b8">Busetto and Buhmann, 2009a;</ref><ref type="bibr" target="#b10">Busetto et al., 2009</ref>).<ref type="figure" target="#fig_0">Figure 1</ref>schematically illustrates Bayesian inference with two updates from prior to posterior probabilities. In the example, the hypothesis class consists of jF j ¼ 4 models. Informative probability distributions exhibit 'narrow' peaks, as they concentrate substantial mass on few models. The smaller the subset of models, the higher is the informativeness, as the data discard all other candidates. In contrast, 'flat' distributions indicate high uncertainty and no preference for a specific selection of models. This intuition is formalized by information theory, which offers Shannon entropy as a fundamental measure of uncertainty (<ref type="bibr" target="#b11">Cover and Thomas, 2012</ref>). For the purpose of learning, the researcher is not only interested in the uncertainty expressed by probabilities at a specific point in time. In contrast, the aim is to maximize the information gain, that is the additional amount of valuable information provided by new data.<ref type="figure" target="#fig_0">Figure 1</ref>illustrates the concept with two examples. In the update on the top, the information gain is low because the posterior is almost identical to the prior. In contrast, the update on the bottom shows an informative posterior obtained from an uninformative prior. Hence, the information gain is high: the assimilated dataset yields a substantial decrease in uncertainty. At this point, the question is how to measure the gain in information. The gain yielded by a dataset is given by the relative entropy (also known as Kullback–Leibler divergence) between prior and posterior probabilities (<ref type="bibr" target="#b2">Baldi and Itti, 2010;</ref><ref type="bibr" target="#b28">Liepe et al., 2013</ref>)</p><formula>D KL ½pð f jY Þ k pð f Þ ¼ X f2F pð f jY Þ log 2 pð f jY Þ pð f Þ ð9Þ</formula><p>In the context of modeling, the relative entropy has a precise interpretation based on the analogy between learning and communication. The information gain corresponds to the expected number of extra bits that are lost if the dataset Y is neglected. As highlighted by the example, information gain is thus a datadependent quantity. The example in<ref type="figure" target="#fig_0">Figure 1</ref>shows that high gain is obtained when probabilities strongly revise the belief of the researcher, that is when extraordinary evidence is incorporated. Because it depends on the future outcome Y of the experiment, the gain is a quantity unknown a priori to the researcher. Nonetheless, prior probabilities and likelihoods are enough to predict its value in expectation. Formally, information gain can be maximized in expectation, where the expectation is taken over all possible outcomes of the experiment. To reflect the a priori information and the known properties of the models, information gain is weighted according to the respective measurement probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THEORETICAL RESULTS</head><p>The objective of our experimental design is to maximize the information gain in expectation, that is the mutual informationThe budget 2 N is determined by the researcher and constrains the maximum number of allowed measurements (<ref type="bibr" target="#b10">Busetto et al., 2009</ref>). In practice, the design always selects the maximum allowed number of measurements, thus justifying the choice of a limited budget. The incorporation of extra measurements, in fact, invariably adds non-negative contributions to the information obtained from the experiment. As an objective, mutual information measures the expected ability of a model to predict the data. Such an objective is not only appealing to intuition, but also theoretically justified (<ref type="bibr" target="#b11">Cover and Thomas, 2012</ref>), and strongly supported by evidence (<ref type="bibr" target="#b2">Baldi and Itti, 2010</ref>). The introduced method for optimal design jointly selects with two aspects of the design: time points (when to measure) and readouts (what to measure). The method starts by solving the IVP for each candidate model in F. Then, it proceeds with the optimization, which consists of maximizing the objective with the maximum budget of measurements (<ref type="bibr" target="#b7">Busetto, 2012</ref>). The experimental outcomes are averaged and weighted to estimate the expected information gain of the particular experiment under evaluation. For computational efficiency, optimization is performed greedily: observations are incrementally added to construct the near-optimal approximation " of the optimal design Ã. Given pð f Þ, , xðt 0 Þ, , and by initializing 0 ¼ ;, the process of optimization proceeds as follows. Iterating over k from 1 to ,</p><formula>k ¼ kÀ1 [ arg max ði, j Þ2SÂN n kÀ1 IðY [fði, j Þg , f Þ ð 12Þ</formula><p>The procedure yields the final approximation " ¼ of Ã. The formal worst-case performance guarantees for the method are obtained on the basis of previous results for submodular optimization in the context of active learning (<ref type="bibr" target="#b16">Feige, 1998;</ref><ref type="bibr" target="#b22">Krause and Guestrin, 2005;</ref><ref type="bibr" target="#b31">Nemhauser et al., 1978</ref>). The proof is based on a reduction to the more general setting of graphical models (<ref type="bibr" target="#b22">Krause and Guestrin, 2005</ref>), which in turn builds on previous approximation bounds for submodular optimization (<ref type="bibr" target="#b16">Feige, 1998;</ref><ref type="bibr" target="#b31">Nemhauser et al., 1978</ref>). THEOREM. The greedy method that selects up to informative readouts and time points to discriminate dynamical systems yields the near-optimal design " such that IðY " , f Þ ! 1 À select experiments that are provably near-optimal. It is worth noting that the yielded information is always guaranteed to be at least ð1 À e À1 Þ463% of the optimal value, that is the total experimentally achievable information. Furthermore, the empirical results introduced in the next section demonstrate that in practice, it is possible to achieve even better results in cases of concrete interest. From the computational point of view, each evaluation of the information gain requires the calculation of the posterior, which in turn requires the integral solutions of the systems of ODEs. For non-linear systems, closed-form solutions are typically unavailable (or might not even exist), thus one has to numerically approximate the solutions. Calculating the posterior is, however, as tractable as filtering for system identification. For efficiency, Sequential Monte Carlo (SMC) methods and unscented Kalman filtering may be used to perform approximate inference (Doucet and Tadic´,Tadic´, 2003). Whereas the former technique is more general and able to deal with arbitrary multimodal distributions (<ref type="bibr" target="#b9">Busetto and Buhmann, 2009b</ref>), the latter is particularly advantageous in the case of unimodal distributions. Approximate Bayesian computation might further extend the scope of applicability of the method (Sunna˚kerSunna˚ker et al., 2013b). For further details and comparison of SMC and filtering approaches, see 'Comparison of Different Methods for Uncertainty Propagation' in Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EMPIRICAL AND APPLIED RESULTS</head><p>This section reports empirical and applied results in the domain that motivated this study: systems biology (<ref type="bibr" target="#b7">Busetto, 2012;</ref><ref type="bibr" target="#b17">Hauser, 2009;</ref><ref type="bibr" target="#b26">Krummenacher, 2010</ref>). First, we verify the introduced method on the Bergman glucose tolerance model. We perform frequency and time point selection, showing that near-optimal solutions yield tight approximations of the global optimum (and provide similar designs, too). Second, we identify the most informative readouts to elucidate the pathway for Target-of-Rapamycin (TOR) signaling from hundreds of candidate models. Third, results are compared with other established design techniques. The results are particularly relevant to experimentalists interested in understanding metabolic control operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dynamics of glucose tolerance</head><p>The Bergman glucose tolerance models constitute the first systematic attempt aimed at explaining the role of insulin in the degradation of blood glucose (<ref type="bibr" target="#b5">Bergman et al., 1979</ref>). This class of phenomenological models aims at identifying the mechanisms involved in reduced glucose tolerance in patients suffering from diabetes mellitus. Bergman's models constitute a set of empirical models, regarded as the conventional reference for modeling glucose homeostasis (<ref type="bibr" target="#b19">Kova´csKova´cs et al., 2010</ref>). The models are highly predictive, well understood and non-linear.<ref type="figure" target="#fig_2">Figure 2</ref>highlights the different structural properties of the models, and<ref type="figure" target="#fig_4">Figure 3</ref>exemplifies their glucose dynamics.<ref type="figure" target="#fig_3">Figure 4</ref>shows the normalized information yielded by glucose sampling frequencies in the range between 0 and 1 samples/min. More than 90% of the experimentally available information is already reachable at the uniform sampling frequency of 1=300 Hz (0.2 min À1 ). Also with respect to growing frequency, the mutual information follows a law of diminishing returns and,<ref type="bibr" target="#b5">Bergman et al., 1979</ref>). P is the hepatic glucose production rate. I is the plasma insulin concentration; its time course is not determined by the ODEs, but supplied to the models. I 0 is the insulin concentration in a compartment remote from plasma. Models IV and V assume a constant production rate of glucose (G); in model VI, this rate is assumed to be dependent on insulin concentration. Model VI also accounts for the disappearance of glucose into peripheral tissues ('periph.')</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>consistent</head><p>with the expectation from<ref type="figure" target="#fig_4">Figure 3</ref>, it grows rapidly and then saturates. The theoretical maximum of log 2 jF j ¼ 2 bits is rapidly approached for frequencies above 1/400 Hz (0.15 min À1 ). We also consider the case in which a glucose injection is performed as a physiological intervention. We measure the information at each individual time point to find the most informative time interval. In fact, it is possible to consider the heuristic approach of measuring with a sample frequency that is local rather than uniform and constant. The most informative region does not coincide with the beginning of the glucose degradation, but rather with the initial transition towards the steady state, as visible in<ref type="figure" target="#fig_4">Figure 3</ref>; the maximum of the information is reached at approximately 30 min from the injection. After the tipping point, the informativeness decreases while the system finally reaches the steady state. After that, residual information comes exclusively from the heterogeneous steady levels of glucose. Information is estimated with unscented propagation, which outperforms linear and SMC approximations (details in the Supplementary Material). For standard errors of 10 À2 nats (% 1:44 Á 10 À2 bits), the unscented approximation is between 40 and 400 times faster than that obtained with particles (which require storage and update of at least 10 4 samples). By selecting quintuplets from a pool of 20 time points, it is possible to estimate how close the near-optimal design is to the optimal. Optimal solutions are calculated by exhaustive search, which is extremely time-consuming, as it requires the evaluation of 20 5 410 4 experiments.<ref type="figure" target="#tab_1">Table 1</ref>compares optimal and nearoptimal designs for ¼ 3, 4, 5. Notably, near-optimal solutions are effectively indistinguishable from the optimal ones in all cases. Not only the yielded information is practically the same (below error tolerance), but also the selections differ by a single sample over. As a consequence, optimal and near-optimal design exhibit indistinguishable probability of selecting the 'true model' from the data. For all practical purposes, the near-optimal selections are optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TOR pathway</head><p>The TOR pathway is a highly conserved cell signaling structure, whose mammalian homolog is implicated in cancer, cardiovascular diseases, autoimmunity and metabolic disorders (<ref type="bibr" target="#b27">Kuepfer et al., 2007</ref>). For budding yeast, a set of 18 elementary extensions have been previously proposed in combination with a consensus core model (<ref type="bibr" target="#b27">Kuepfer et al., 2007</ref>). The elementary extensions incorporate a set of additional reactions. Combined with the core model, they represent putative mechanistic configurations of the biochemical system. The core model consists of experimentally validated molecular interactions from inhibition of TOR kinases to the activation of protein phosphatase 2A (PP2A). In principle, the elementary extensions are not mutually exclusive (<ref type="bibr" target="#b33">Raman and Wagner, 2011</ref>). In the evaluation, the hypothesis class F consists of 200 model prototypes. Each hypothesis corresponds to a system of ODEs with heterogeneous model complexity (from individual reactions to interlocked non-linear feedback). All 24 shared chemical species are considered measurable quantities for the experimental design. Readout selection is performed with a maximum of s ¼ 50 regularly spaced time points in a relative time scale from 0 to 1.4 [time units of (<ref type="bibr" target="#b27">Kuepfer et al., 2007)]</ref>. Uniform spacing has been chosen for simplicity of description; the design method is directly applicable to any distribution of the time points. In this setting, the number of candidate experiments amounts to jS Â N j ¼ 1200. In<ref type="figure">Figure 5</ref>, the expected information gain is plotted as a function of the incremental design k as in Equation (12), together with bounds showing tightness of approximation. The offline bound is calculated by multiplying for the approximation factor e=ðe À 1Þ % 1:58 and is thus available a priori. The online bounds, in contrast, are iteratively calculated by using submodularity to bind the additive improvements of the objective from the current selection. The bound is</p><formula>IðY Ã , f Þ IðY , f Þ þ X q l¼1 wq ð14Þ</formula><p>where the incremental value is w :¼ IðY [fwg , f Þ À IðY , f Þ for each of the top q measurements w not considered yet (<ref type="bibr" target="#b21">Krause and</ref><ref type="bibr">Guestrin, 1999/2007</ref>). The optimal information value is, hence, always between the achieved objective and the bound. Whereas offline bounds are trivial to compute, online bounding requires few additional calculations, but is often preferable because it yields tighter bounds. Both bounds are useful to predict<ref type="figure">5</ref>. Expected information gain for increasingly large sets of selected measurements (green), each consisting of jointly selected species and time points. Online and offline bounds appear in blue and red, respectivelyNote: The measurement time points are selected from 60=3 candidates from the set S ¼ f1, 4,. .. , 60}. Optimal and near-optimal solutions practically coincide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2629</head><p>Near-OED for model selection in systems biology quasi-plateaux of information due to saturation effects, and to evaluate the quality of the optimized (but not necessarily optimal) design (<ref type="bibr" target="#b21">Krause and</ref><ref type="bibr">Guestrin, 1999/2007;</ref><ref type="bibr" target="#b29">Minoux, 1978</ref>). Tap42pP-PP2A exhibits the highest information content and is thus the best discriminative candidate. Such a species is the complex between PP2A and the phosphorylated protein Tap42p, an essential protein of the TOR signaling pathway (<ref type="bibr" target="#b14">Du¨velDu¨vel et al., 2003</ref>). The species is known for its central role, and yet there exist substantial uncertainty regarding its precise interactions in the biochemical network (<ref type="bibr" target="#b27">Kuepfer et al., 2007</ref>). The information associated with each species is represented by<ref type="figure" target="#fig_6">Figure 6</ref>, which overlays the diagram of the core model with the mean information over time. The theorem states that the method dominates all other efficient techniques in terms of information yield. For completeness, we also assess the performance with respect to the empirical success rate, an external score. This measure is consistent with the research goal of finding the best model and allows the comparison of the greedy approach with the available non-Bayesian alternative, that is ensemble non-centrality (<ref type="bibr" target="#b1">Atkinson et al., 2007</ref>). We evaluate the method in two benchmark scenarios: realizable and non-realizable. The success rate is the ratio of successful selections over 10 3 runs. Model selection is considered successful when the best model is selected a posteriori from the data through the designed experiment. In the realizable scenario, the best model is the true model f Ã , because this model is available as a candidate. In the non-realizable scenario, however, the 'true model' is not a candidate because f Ã =<ref type="figure">Fig. 7</ref>. Comparison of success rates for the identification of the TOR pathway. Rates range from 0 (complete lack of success) to 1 (complete success). Realizable (f Ã 2 F) and non-realizable (f Ã = 2F ) scenarios appear on left and right plots, respectively. Expected information gain, ensemble non-centrality and sum of Euclidean distances are, respectively, abbreviated as EIG, ANC and EUD. The plot on the right offers the interpretation of relative success with respect to chance (dashed horizontal line), as the maximal rate achievable for a given sample size is unknown<ref type="bibr">, 2010</ref>). As in the realizable scenario, the introduced approach yields significantly higher success rates. In contrast to the realizable case, success should be seen as a relative quantity, as the finite sample size induces an unknown scaling for the maximal rate of practical success. The results also highlight that multiple models achieve comparable predictive power and are, thus, difficult to exactly discriminate from the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In a complex field in which noisy data and expensive experiments constitute the norm, it is crucial to guide experimentation through rational design. Here, our main contribution is the introduction of a method that guarantees high informativeness with a polynomial number of evaluations of the information objective. The main motivation of this study is biological, but it is worth noting that the presented results for readout and time point selection are applicable to general dynamical systems. As a consequence of previous results from submodular optimization (<ref type="bibr" target="#b16">Feige, 1998;</ref><ref type="bibr" target="#b22">Krause and Guestrin, 2005;</ref><ref type="bibr" target="#b31">Nemhauser et al., 1978</ref>), we could prove that the greedy method exhibits the best constant approximation factor (unless P ¼ NP) to design experiments for the selection among alternative dynamical systems. This study proves that entirely rational selections can be made a priori with efficiency and solely on the basis of the accumulated domain knowledge. Reported results show that near-optimal experiments are effectively optimal in the application to glucose tolerance. The method outperforms the available alternatives in terms of empirical success rate, as shown for TOR modeling. In a practical application, we used the method presented here in a study revealing nuclear phosphorylation as the key control mechanism for the transcription factor Msn2 on stress release in Saccharomyces cerevisiae (<ref type="bibr" target="#b36">Sunna˚kerSunna˚ker et al., 2013a</ref>). By optimization of Equation (10), the experimental design was targeted to enable informative selection among 12 models representing various hypothetical mechanisms for the short-term Msn2 dynamics. In this application, the combination of experimental design and model selection led to identification, and prediction, of previously unknown and potentially generic principles for transcription factor dynamics (<ref type="bibr" target="#b36">Sunna˚kerSunna˚ker et al., 2013a</ref>). A distinct but relevant question remains open: how to reliably identify the parameters of the candidate models? This issue goes beyond the scope of this study, as it strictly belongs to the domain of system identification (<ref type="bibr" target="#b8">Busetto and Buhmann, 2009a</ref>). At the same time, it is an aspect that deserves special attention, as design and modeling are part of the same hypothetico-deductive process. We conclude that the introduced method may be useful to guide intuition through quantitative indicators and thus accelerate scientific discovery.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1.</head><figDesc>The posterior probability is related to priors and likelihood through Bayes' rule</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. This example compares probability updates for four models. The updates are induced by two different datasets. On the top, both initial and final belief states are uninformative: the update yields low information gain. This is in contrast to the bottom plot, which shows a highly informative update: starting from an uninformative prior, the posterior concentrates the probability mass on a single model (Busetto, 2012)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Insulin-dependent models of glucose metabolism (Bergman et al., 1979). P is the hepatic glucose production rate. I is the plasma insulin concentration; its time course is not determined by the ODEs, but supplied to the models. I 0 is the insulin concentration in a compartment remote from plasma. Models IV and V assume a constant production rate of glucose (G); in model VI, this rate is assumed to be dependent on insulin concentration. Model VI also accounts for the disappearance of glucose into peripheral tissues ('periph.')</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. For the identification of glucose tolerance dynamics, 90% of the experimentally available information (dashed line) can be obtained with a sampling frequency of 0.2 min À1. Higher sampling rates yield negligible contributes to physiological modeling. Standard errors are too small to be drawn (% 1:44 Á 10 À2 bits)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. On the left, mean values (solid lines) and standard deviation of the distributions approximated by the unscented transform (dashed lines) of the glucose measurements predicted by models I, IV, V and VI. On the right, the mutual information (normalized by the entropy) for each time point</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.</head><figDesc>Fig. 5. Expected information gain for increasingly large sets of selected measurements (green), each consisting of jointly selected species and time points. Online and offline bounds appear in blue and red, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.6.</head><figDesc>Fig. 6. Diagram representing the individual mean mutual information over time for each chemical species in the core of the TOR pathway (Kuepfer et al., 2007). Information is measured in bits and also visualized with colors ranging from blue to red</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1.</figDesc><table>Expected information gain for subsets of measurement time 
points of different cardinality for the insulin-dependent models of 
glucose metabolism 


" 
(near-optimal) 
Ã (optimal) 
IðY " 
, f Þ 
IðY Ã , f Þ 

3 f31, 34, 37g 
f 34, 37, 40g 
1:0004 AE 0:004 1.0009 
4 f13, 31, 34, 37g 
f 10, 34, 37, 40g 
1:0910 AE 0:004 1.0940 
5 f10, 31, 34, 37, 40g f10, 34, 37, 40, 43g 1:1564 AE 0:016 1.1585 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> e  max SÂN :jj IðY , f Þ ð 13Þ with a polynomial number of evaluations of the objective; moreover, such a constant approximation factor is the best in polynomial time, unless P ¼ NP. Informally, the theorem states the following: selecting the optimal experiment might be hard, and yet it is possible to easily 2627 Near-OED for model selection in systems biology at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="2"> F. The best model then is the closest one to the &apos;true model&apos; in terms of predictive power measured as relative entropy. In each test run, the method selects noisy readouts from the TOR models. In turn, each candidate model is assumed to generate data with additive independent normal noise (standard deviation corresponding to half of the concentration). On the left of Figure 7, near-optimal design achieves a substantially higher success rate compared with ensemble non-centrality. The evaluation highlights one of the main practical disadvantages of ensemble methods: the huge computational demands. Precisely, parameter fitting is the computational bottleneck: the step is repeated for all tested parameter configurations against what is assumed to be the correct model. Each iteration of cost minimization requires numerical solutions of non-linear ODEs, testing every model combination. This procedure is so resource-intensive that the hypothesis class has to be limited to only four models with two unknown parameters and two unknown initial conditions. The exact computational complexity of the ensemble non-centrality is unknown. However, it heavily relies on non-linear optimization, which is generally considered hard or even intractable (Nelles, 2001). It is possible, nonetheless, to calculate the number of non-linear optimization tasks involved, which follows OðjF j 2 ns  Þ, where is the number of samples employed for the approximation of the integral solution. In contrast, the greedy approach is bounded by OðnsÞ evaluations for the objective, which in turn relies on the solution of jF j uncertainty propagation equations such as Equation (8). Combining flow propagation and Bayesian learning can be performed with the unscented Kalman filtering, which requires the solution of 2ðn þ dÞ þ 1 individual IVPs, where d is the number of free parameters in. This number is approximately proportional to the expected degree of the network, which follows a Zipf distribution, making it independent of network size (Szaíla´Szaíla´si et al., 2006). Detailed analysis and comparison with other filtering approaches is reported in Supplementary Material. The analysis proceeds with the non-realizable scenario, which captures the fact that hypothesis classes are mere approximations of reality. Ensemble non-centrality is not directly applicable in this case because it assumes that the true model is among the candidates (and performs selections with respect to it). Taking</note>

			<note place="foot">A.G.Busetto et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors thank Andreas Krause, Andreas Wagner, Karthik Raman, Elias Zamora-Sillero, Kay Henning Brodersen, Jean Daunizeau, Heinz Koeppl, Elias August, Volker Roth, Marcus Hutter and Simonetta Scola for insightful discussions and helpful comments, and mloss.org.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimal design: experiments for discriminating between several models</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Atkinson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">V</forename>
				<surname>Fedorov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="289" to="303" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Atkinson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimum Experimental Designs, with SAS</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2007" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Of bits and wows: a Bayesian theory of surprise with applications to attention</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Baldi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Itti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="649" to="666" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Computational procedures for optimal experimental design in biological systems</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Balsa-Canto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="163" to="172" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimal experimental design for parameter estimation of a cell signaling model</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bandara</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000558</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Quantitative estimation of insulin sensitivity</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">N</forename>
				<surname>Bergman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Physiol</title>
		<imprint>
			<biblScope unit="volume">236</biblScope>
			<biblScope unit="page" from="667" to="677" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Discrimination among mechanistic models</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E P</forename>
				<surname>Box</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Hill</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="57" to="71" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Information theoretic modeling of dynamical systems</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">G</forename>
				<surname>Busetto</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Zurich, Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Stable Bayesian parameter estimation for biological dynamical systems</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">G</forename>
				<surname>Busetto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Buhmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Science and Engineering, CSE 2009</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="148" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Structure identification by optimized interventions</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">G</forename>
				<surname>Busetto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Buhmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Machine Learning Research Proceedings of the International Conference on Artificial Intelligence and Statistics</title>
		<meeting><address><addrLine>Clearwater Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimized expected information gain for nonlinear dynamical systems</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">G</forename>
				<surname>Busetto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">M</forename>
				<surname>Cover</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Thomas</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>WileyInterscience</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimizing experimental design for comparing models of brain function</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Daunizeau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1002280</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Parameter estimation in general state-space models using particle methods</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Doucet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Tadic´</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">B</forename>
				<surname>Tadic´</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Inst. Stat. Math</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="409" to="422" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiple roles of Tap42 in mediating rapamycin-induced transcriptional changes in yeast</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Du¨veldu¨vel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Cell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1467" to="1478" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Simulation methods for optimal experimental design in systems biology</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Faller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Simulation</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="717" to="725" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">A threshold of ln(n) for approximating set cover</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Feige</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="634" to="652" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<monogr>
		<title level="m" type="main">Entropy-based experimental design for model selection in systems biology</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hauser</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Zurich, Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Computational systems biology</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kitano</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">420</biblScope>
			<biblScope unit="page" from="206" to="210" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">New principles and adequate robust control methods for artificial pancreas</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Kova´cskova´cs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Computational Intelligence in Engineering</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="75" to="86" />
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards experimental design using a Bayesian framework for parameter identification in dynamic intracellular network models</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kramer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Radde</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1645" to="1653" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">SFO: a toolbox for submodular function optimization</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Krause</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1141" to="1144" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Near-optimal nonmyopic value of information in graphical models</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Krause</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Guestrin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-first Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title level="m" type="main">Near-optimal observation selection using submodular functions</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Krause</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Guestrin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>AAAI Press</publisher>
			<pubPlace>Vancouver, BA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Systems biology: experimental design</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kreutz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Timmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FEBS J</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="923" to="942" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title level="m" type="main">Near-OED for model selection in systems biology at :: on</title>
		<imprint>
			<date type="published" when="2016-08-30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Large-scale experimental design toolbox for systems biology</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Krummenacher</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Zurich, Switzerland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Ensemble modeling for analysis of cell signaling dynamics</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Kuepfer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1001" to="1006" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Maximizing the information content of experiments in systems biology</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Liepe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1002888</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">Accelerated greedy algorithms for maximizing submodular set functions. In: Optimization Techniques</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Minoux</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="234" to="243" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimal experimental design for model discrimination</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">I</forename>
				<surname>Myung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Pitt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">499</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Nonlinear System Identification An analysis of approximations for maximizing submodular set functions</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Nelles</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Berlin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">L</forename>
				<surname>Nemhauser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programs</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="265" to="294" />
			<date type="published" when="1978" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Optimum experimental design for discriminating between two rival models in the presence of prior information</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Ponce De Leon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Atkinson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="601" to="608" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Evolvability and robustness in a complex signalling circuit</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Raman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Wagner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. BioSyst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1081" to="1092" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">An optimal experimental design approach to model discrimination in dynamic biochemical systems</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Skanda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lebiedz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="939" to="945" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Experimental design for efficient identification of gene regulatory networks using sparse Bayesian models</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Steinke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Automatic generation of predictive dynamic models reveals nuclear phosphorylation as the key Msn2 control mechanism</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sunna˚kersunna˚ker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Signal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Approximate Bayesian computation</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sunna˚kersunna˚ker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1002803</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<monogr>
		<title level="m" type="main">System Modeling in Cell Biology: From Concepts to Nuts and Bolts</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Szaíla´szaíla´si</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Inferring signaling pathway topologies from multiple perturbation measurements of specific biochemical species</title>
		<author>
			<persName>
				<forename type="first">T.-R</forename>
				<surname>Xu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Signal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised modeling of cell morphology dynamics for time-lapse microscopy</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Zhong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="711" to="713" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>