
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequence analysis Topological entropy of DNA sequences</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011 . 2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">David</forename>
								<surname>Koslicki</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Pennsylvania State University</orgName>
								<address>
									<addrLine>State College</addrLine>
									<postCode>16801</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sequence analysis Topological entropy of DNA sequences</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Bioinformatics BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">113</biblScope>
							<biblScope unit="issue">27 8</biblScope>
							<biblScope unit="page" from="28" to="49"/>
							<date type="published" when="2011">2011 . 2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr077</idno>
					<note type="submission">Received on October 29, 2010; revised on January 17, 2011; accepted on February 4, 2011</note>
					<note>Associate Editor: John Quackenbush Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Topological entropy has been one of the most difficult to implement of all the entropy-theoretic notions. This is primarily due to finite sample effects and high-dimensionality problems. In particular, topological entropy has been implemented in previous literature to conclude that entropy of exons is higher than of introns, thus implying that exons are more &apos;random&apos; than introns. Results: We define a new approximation to topological entropy free from the aforementioned difficulties. We compute its expected value and apply this definition to the intron and exon regions of the human genome to observe that as expected, the entropy of introns are significantly higher than that of exons. We also find that introns are less random than expected: their entropy is lower than the computed expected value. We also observe the perplexing phenomena that introns on chromosome Y have atypically low and bimodal entropy, possibly corresponding to random sequences (high entropy) and sequences that posses hidden structure or function (low entropy). Availability: A Mathematica implementation is available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Entropy, as a measure of information content and complexity, was first introduced by<ref type="bibr" target="#b18">Shannon (1948)</ref>. Since then entropy has taken on many forms, namely topological, metric (due to Shannon), Kolmogorov–Sinai and Rènyi entropy. These entropies were defined for the purpose of classifying a system via some measure of complexity or simplicity. These definitions of entropy have been applied to DNA sequences with varying levels of success. Topological entropy, in particular, is infrequently used due to highdimensionality problems and finite sample effects. These issues stem from the fact that the mathematical concept of topological entropy was introduced to study infinite length sequences. It is universally recognized that the most difficult issue in implementing entropy is the convergence problem due to finite sample effects (<ref type="bibr" target="#b22">Vinga and Almeida, 2004;</ref><ref type="bibr" target="#b12">Kirillova, 2000</ref>). A few different approaches to circumvent these problems with topological entropy and adapt it to finite length sequences have been attempted before. For example, in<ref type="bibr" target="#b21">Troyanskaya et al. (2002)</ref>, linguistic complexity (the fraction of total subwords to total possible subwords) is utilized to circumvent finite sample problems. This leads to the observation that the complexity/randomness of intron regions is lower than the complexity/randomness of exon regions. However in<ref type="bibr" target="#b3">Colosimo and de Luca (2000)</ref>, it is found that the complexity of randomly produced sequences is higher than that of DNA sequences, a result one would expect given the commonly held notion that intron regions of DNA are free from selective pressure and so evolve more randomly than do exon regions. Also, little has been done in the way of mathematically analyzing other finitary implementations of entropy due to most previous implementations using an entire function instead of a single value to represent entropy (thus the expected value would be very difficult to calculate). In this article, we focus on topological entropy, introducing a new definition that has all the desired properties of an entropy and still retains connections to information theory. This approximation, as opposed to previous implementations, is a single number as opposed to an entire function, thus greatly speeding up the calculation time and removing high-dimensionality problems while allowing more mathematical analysis. This definition will allow the comparison of entropies of sequences of differing length, a property no other implementation of topological entropy has been able to incorporate. We will also calculate the expected value of the topological entropy to precisely draw out the connections between topological entropy and information content. We will then apply this definition to the human genome to observe that the entropy of intron regions is in fact lower than that of exon regions as one would expect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definitions and preliminaries</head><p>We restrict our attention to the alphabet A ={A,C,T ,G}. For a finite sequence w over the alphabet A, we use |w| to denote the length of w. Of primary importance in the study of topological entropy is the complexity function of a sequence w (finite or infinite) formed over the alphabet A.</p><p>Definition 1 (complexity function). For a given sequence w, the complexity function p w : N → N is defined as p w (n) =|{u :|u|=n and u appears as a subword of w}|</p><p>That is, p w (n) represents the number of different n-length subwords (overlaps allowed) that appear in w. Now the traditional definition of topological entropy of an infinite word w is the asymptotic exponential growth rate of the number of different subwords:</p><p>Definition 2. For an infinite sequence w formed over the alphabet A, the topological entropy is defined as</p><formula>lim n→∞ log 4 p w (n) n</formula><p>Due to the limit in the above definition, it is easily observed that this definition will always lead to an answer of zero if applied directly to finite length sequences. This is due to the fact that the complexity function of<ref type="bibr">[</ref>infinite length sequences is non-decreasing, while of finite length sequences it is eventually zero. We include in Figures 1 and 2 a log-linear plot of the complexity functions for the gene ACSL4 found on ChrX:108906440108976621 (hg19) as well as for an infinite string generated by a Markov chain on four states with equal transition probabilities. The graph of the complexity function of the gene found in<ref type="figure">Figure 1</ref>is entirely typical of the graph of a complexity function for a finite sequence. The precise description of the shape of the complexity function can be found in the nice summary by Colosimo and de Luca (2000). In essence, on three disjoint intervals the complexity function p w (n) is strictly increasing, then non-decreasing,and then decreasing at a slope of −1. Now for a finite sequence w, we desire that an approximation of topological entropy H top (w) should have the following properties:</p><formula>(1) 0 ≤ H top (w) ≤ 1</formula><p>(2) H top (w) ≈ 0 if and only if w is highly repetitive (contains few subwords)</p><p>(It should be noted that item 4 on this list is of utmost importance when implementing topological entropy. It is very important to normalize with respect to length since otherwise when counting the number of subwords, longer sequences will appear artificially more complex simply due to the fact that since the sequence is longer, there are more chances for subwords to show up. This explains the 'linear correlation' between sequence length and the implementations of topological entropy used in<ref type="bibr" target="#b11">Karamanos et al. (2006) and</ref><ref type="bibr" target="#b12">Kirillova (2000)</ref>. This also hints at the incomparability of the notions of entropy contained in<ref type="bibr" target="#b11">Karamanos et al. (2006)</ref>, Colosimo and de Luca (2000), Kirillova (2000), and Schmitt and Herzel (1997). Since topological entropy should give an approximate asymptotic exponential growth rate of the number of subwords, the only pertinent values of p w (n) are those in the interval where p w (n) is strictly increasing. With an alphabet of four letters, the maximal such value occurs at the smallest n such that |w| &lt; 4 n+1 +(n+1)−1. We define the approximation to topological entropy as follows:</p><formula>H top (w) := log 4 (p w 4 n +n−1 1 (n)) n</formula><p>The reason for concatenating w to the first 4 n +n−1 letters is due to the following two facts whose proofs can be found in the Supplementary Material. Lemma 1. A sequence w over the alphabet {A,C,T ,G} of length 4 n +n−1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>can contain at most 4 n subwords of length n. Conversely, if a word w is to have 4 n subwords, it must have length at least 4 n +n−1.</head><p>Thus, if we had taken an integer m &gt; n in the above definitions and instead utilized</p><formula>log 4 (pw(m)) m</formula><p>, w would not be long enough to contain all different possible subwords.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2. Say a sequence w has length 4 n +n−1 for some integer n,</head><p>if w contains all possible subwords of length n formed on the alphabet {A,C,T ,G}, then H top (w) = 1. Thus, if a sequence of length 4 n +n−1 is 'as random as possible' (i.e. contains every possible subword), its topological entropy is 1, just as we would expect in the infinite sequence case. Similarly, if w is 'as non-random as possible', that is, if w is simply the repetition of a single letter 4 n +n−1 times, then H top (w) = 0. Furthermore, if we had not used truncation in definition 3, then for a sequence v such that |v| &gt; |w|, the topological entropy of v would on average be artificially higher due to v being a longer sequence and thus has more opportunity for the appearance of subwords. By truncating, we have allowed sequences of different lengths to have comparable topological entropies. This definition of topological entropy serves as a measure of the randomness of a sequence: the higher the entropy, the more random the sequence. The justification for this finite implementation giving an approximate characterization of randomness is given in Ornstein and Weiss (2007) in which it is shown that functions of entropy are the only finitely observable invariants of a process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Expected value</head><p>While topological entropy has been well studied for infinite sequences, very little has been done by the way of mathematically analyzing topological entropy for finite sequences. This lack of analysis is most likely due to topological entropy as in the literature (<ref type="bibr" target="#b4">Crochemore and Vèrin 1999;</ref><ref type="bibr" target="#b12">Kirillova 2000;</ref><ref type="bibr" target="#b17">Schmitt and Herzel 1997</ref>) being considered not as a single number to be associated to a DNA sequence, but rather the entire function log 4 pw(n) n is considered for every n. This approach turns topological entropy (which should be just a single number associated to a DNA sequences) into a very high-dimensional problem. In fact, as many dimensions as is the length of the DNA sequence under consideration. Our approximation (Definition 3)</p><p>Page: 1063 1061–1067</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topological entropy of DNA sequences</head><p>does in fact associate just a single number (instead of an entire function) to a sequence, and so is much more analytically tractable. We now utilize the results of Gheorghiciuc and Ward (2007) to compute the expected value of topological entropy. This will assist in determining what constitutes 'high' or 'low' entropy. First, we calculate the expected value of the complexity function p w (n). As is commonly assumed (<ref type="bibr" target="#b9">Hasegawa et al., 1985;</ref><ref type="bibr" target="#b10">Jukes and Cantor, 1969</ref>), we now assume that DNA sequences evolve in the following way: each state in a Markov fashion independent of neighboring states. We do not assume a single model of molecular evolution, but rather just assume that there is some set of probabilities</p><formula>{π A ,π C ,π T ,π G }</formula><p>such that the probability of appearance of a sequence w is given by the following: for n A the number of occurrences of the letter A in w, n C the number of occurrences of the letter C in w, etc., the probability of the sequence w appearing is given by:</p><formula>P(w) = π n A A π n C C π n T T π n G G</formula><p>This assumption regarding the probability of appearance of a DNA sequence is used only to procure a distribution against which we may calculate the expected number of subwords. The actual calculation of topological entropy as in Definition 3 does not make any such assumption about the probability of appearance.</p><formula>E[p w (n)]=4 n − w (1−P(w)) k +O(k − µ n ) (1)</formula><p>where the summation is over all sequences w of length n, 0 &lt;&lt;&lt;1, and µ&lt;1<ref type="bibr">[</ref>Proof. See (<ref type="bibr" target="#b7">Gheorghiciuc and Ward, 2007</ref>). This theorem has a particularly nice reduction [Gheorghiciuc and Ward (2007), Corollary 2.2] when one assumes that the probability of appearance of each subletter is the same (equivalent to the the expected value being computed with a uniform distribution on the set of all sequences of a certain length). While clearly there is a mononucleotide bias for different genomic regions and DNA sequences do not occur uniformly randomly, we do assume equal probability of appearance of each nucleotide as then the calculation of the expected number of subwords reduces in computational complexity from exponential to linear in the length of the sequence. It is a straightforward calculation to combine Corollary 2.2 in<ref type="bibr" target="#b7">Gheorghiciuc and Ward (2007)</ref>with Definition 3 and compute the constants and µ. Doing so, we obtain the following expected value for the topological entropy.</p><p>Theorem 2 (expected value of topological entropy). The expected value of topological entropy taken over sequences of length |w|=4 n +n−1 is given by</p><formula>E[H top ]= log 4 (4 n −4 n (1−1/4 n ) 4 n +O(( 1 √ 2 )) n ) n (2)</formula><p>We now present in<ref type="figure" target="#tab_1">Table 1</ref>the calculated estimation of the expected value of H top using the above formula. Keep in mind that the convergence of this calculation to the actual expected value is exponentially quick as n increases (and so also the length of the sequence). We thus ignore the O(</p><formula>( 1 √ 2</formula><p>)</p><p>) n term in the following calculation. For comparison's sake, we present in<ref type="figure" target="#tab_2">Table 2</ref>the sampled expected values for n = 1,...,9 along with sampled SDs (the calculation were made by explicitly computing the topological entropy of uniformly randomly selected sequences). Summarizing this table, the topological entropy of randomly selected sequences is tightly centered around the expected value which itself is close to one. Furthermore, the distribution of topological entropy is very close to a normal distribution as can be observed from the histogram of topological entropy for sequences of length 4 9 +9−1 included in<ref type="figure" target="#fig_0">Figure 3</ref>. The skewness and kurtosis are 0.0001996 and 2.99642, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>An implementation of this approximation to topological entropy is available at: http://www.math.psu.edu/koslicki/entropy.nb We mention a few notes regarding this estimation of topological entropy. First, if a sequence w in consideration has a length such that for some n, 4 n +n−1|w| &lt; 4 n+1 +n, it will be more accurate to use a sliding window to compute the topological entropy. For Page: 1064 1061–1067</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.Koslicki</head><p>example, if |w|=16 000, we would normally truncate this sequence to the first 4101 letters. This might misrepresent the actually topological entropy of the sequence. Accordingly, we could instead compute the average of the topological entropy of the following sequences (where w m n means the subsequence of w consisting of the n-th to m-th letters of w):</p><formula>w 4101 1 ,w 4102 2 ,w 4103 3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>,...,w 16000 11899</head><p>This is computationally intensive, so for longer sequences, one might instead choose to take non-overlapping windows. That is, finding the average of the topological entropy of the sequences</p><formula>w 4101 1</formula><p>,w 8203 4102 ,w 12305 8204 ,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..</head><p>The above web site includes serial and parallel versions of the algorithm. The fastest version utilizes Nvidia CUDA GPU computing, has complexity O(n) for a sequence of length n and takes an average of 5.2 s to evaluate on a DNA sequence of length 16 777 227 when using an Intel i7-950 3.6 GHz CPU and an Nvidia GTX 460 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison to traditional measures of complexity</head><p>Other measures of DNA sequence complexity similar to this approximation of topological entropy include: previous implementations of topological entropy (<ref type="bibr" target="#b12">Kirillova, 2000</ref>), special factors (Colosimo and de Luca, 2000), Shannon's metric entropy (<ref type="bibr" target="#b5">Farach et al., 1995;</ref><ref type="bibr" target="#b12">Kirillova, 2000</ref>), Rènyi continuous entropy (<ref type="bibr" target="#b16">Rènyi, 1961;</ref><ref type="bibr" target="#b22">Vinga and Almeida, 2004</ref>) and linguistic complexity (LC) (<ref type="bibr" target="#b6">Gabrielian and Bolshoy, 1999;</ref><ref type="bibr" target="#b21">Troyanskaya et al., 2002</ref>). The implementation of topological entropy in Kirillova (2000) does not produce a single number representing entropy, but rather an entire sequence of values. Thus, while the implementation of Kirillova (2000) does distinguish between artificial and actual DNA sequences, Kirillova notes that the implementation is hampered by high-dimensionality and finiteness problems. In Colosimo and de Luca (2000), it is noted that the special factors approach does not differentiate between introns and exons. Note also that the convergence of our approximation of topological entropy is even faster than that of Shannon's metric entropy. Shannon's metric entropy of the sequence u for the value n is defined as</p><formula>H met (u,n) = −1 n w µ u (w)log(µ u (w))</formula><p>where the summation is over all words of length n and µ u (w) is the probability (frequency) of the word w appearing in the given sequence u. Thus, Shannon's metric entropy requires not just the appearance of subwords, but for the actual frequency of appearance of the subwords to converge as well. As can be seen from Definition 3, our notion of topological entropy does not require the use of the actual subword frequencies. So topological entropy will in general be more accurate than Shannon's metric entropy for shorter sequences. Accordingly, the convergence issues mentioned in<ref type="bibr" target="#b5">Farach et al. (1995)</ref>(even with the clever Lempel–Ziv estimator) can be circumvented. Furthermore, it is not difficult to show<ref type="bibr">[as in Blanchard et al. (2000), Proposition 1.2.5]</ref>what is known as the Variational Principle, that is, topological entropy dominates metric entropy: for any sequence u (finite or not) and integer n</p><formula>H met (u,n) ≤ H top (u,n) (3)</formula><p>Thus, topological entropy retains connections to the information theoretic interpretation of metric entropy as set forth by Shannon (1948). Since topological entropy bounds metric entropy from above:</p><p>Low topological entropy of a sequence implies that it is 'less chaotic' and is 'more structured'. This connection to information theory is also an argument for the use of topological entropy over Rènyi continuous entropy of order α<ref type="bibr">[</ref><ref type="bibr">, 2004</ref>), one cannot conclude that higher/lower Rènyi continuous entropy for α = 1 implies more/less information content or complexity in the usual sense. Thus, LC is the only other similar measurement of sequence complexity that produces a single number representing the complexity of a sequence. Like our implementation of topological entropy, the implementation of LC contained in<ref type="bibr" target="#b21">Troyanskaya et al. (2002)</ref>also runs in linear time. A comparison of our implementation of topological entropy and LC is contained in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATION TO EXONS/INTRONS OF THE HUMAN GENOME</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Method</head><p>We now apply our definition of topological entropy to the intron and exon regions of the human genome. We retrieved the February 2009 GRCh37/ hg19 human genome assembly from the UCSC database and utilized Galaxy (<ref type="bibr" target="#b1">Blankenberg et al., 2007</ref><ref type="bibr" target="#b2">Blankenberg et al., , 2010</ref>) to extract the nucleotide sequences corresponding to the introns and exons of each chromosome (including ChrX and ChrY). Now even though as argued above, topological entropy converges more quickly than metric entropy, one must be careful to not use this definition of topological entropy on sequences that are too short as this would lead to significant noise. For example, the UCSC database contains exons that consist of a single base and it is meaningless to attempt to measure topological entropy of such sequences. Hence, we selected the longest 100 different intron and exon sequences from each chromosome. After ensuring that each sequence consisted only of letters from {A,C,T ,G}, we then applied the approximation of topological entropy found in Definition 3 to the resulting sequences. For comparison's sake, we also applied the approximation of topological entropy to the longest 50, 200 and 400 sequences, as well as to all the intron and exon sequences. The salient observed features persist throughout. Though as expected, when shorter sequences are allowed, the results become noisier. These error bar plots are available in the Supplementary Material. To investigate in more detail the relationship between regions under selective pressure and the value of topological entropy, we also selected each 5 and 3 UTR on chromosome Y that consisted of more than 4 3 +3−1 = 66 bp.<ref type="figure" target="#fig_4">Figure 7</ref>displays the error bar plot for the longest 100 exons and introns. The error bar plots for the longest 50, 200 and 400 sequences, as well as the plot for all the intron and exon sequences, are available in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 1065 1061–1067</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topological entropy of DNA sequences</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis and discussion</head><p>We first discuss the results regarding intron and exon regions. As<ref type="figure" target="#fig_4">Figure 7</ref>demonstrates, the topological entropies of intron regions of the human genome are larger than the topological entropies of the exon regions. For example, the mean of the entropies of the introns on chromosome 21 is more than 11 SDs away from the mean of the entropy of the exons on the same chromosome. This result supports the commonly held notion that intron regions of DNA are mostly free from selective pressure and so evolve more randomly than do exon regions. We thus suggest that the observation of<ref type="bibr" target="#b11">Karamanos et al. (2006</ref><ref type="bibr" target="#b21">), Troyanskaya et al. (2002</ref><ref type="bibr" target="#b14">), Mantegna et al. (1995</ref>, and<ref type="bibr" target="#b20">Stanley et al. (1999)</ref>that intron entropy is smaller than exon entropy is due to the aforementioned finite sample effects and highdimensionality problems related to previous implementations of entropy. Interestingly, even though we observe that intron entropy is larger than exon entropy, the entropies of both regions are much lower than expected (here expectation is as calculated in<ref type="figure" target="#tab_1">Table 1</ref>). Indeed, of the longest 100 sequences, the average intron length is 180 880 and the average exon length is 2059, so according to Tables 1 and 2, we would expect the entropies to be 0.966914 and 0.933853, respectively. We find, though, that the average entropy for introns is 0.9323166 and for exons is 0.897451. Note that the largest intron sequence entropy (H top = 0.943627 for an intron of length 1.1 Mb found on chromosome 16) is significantly lower than the expected value of 0.969921 (at least 60 SDs from the expectation). This is not too surprising considering that the expectation as calculated in Theorem 2 uses the uniform distribution. This supports the conclusion that while intron regions do evolve more randomly than exon regions, introns do not evolve uniformly randomly. Note the disparity between the entropies of the sex chromosomes: the entropy of chromosome X in both intron and exon regions is significantly higher than in chromosome Y. In fact, the mean of chromosome X intron entropies is 3.5 SDs higher than the mean of chromosome Y intron entropies; the mean of chromosome X exon entropies is 1 SD higher than the mean of chromosome Y exon entropies. Thus, the X chromosome has intron and exon entropy similar to that of the autosomes, but chromosome Y has significantly differing exon and intron entropy. This is a particularly puzzling result considering that chromosome Y is known to have a high mutation rate and a special selection regime (<ref type="bibr" target="#b8">Graves 2006</ref>; Wilson and Makova 2009a, b), and so one would expect the entropy of chromosome Y (both intron and exon regions) to be much higher than it is. In fact, the chromosome Y introns have the lowest mean topological entropy of any intron region across the entire genome. This would suggest that the accumulation of 'junk' DNA and the massive accumulation of retrotransposable elements mentioned in Graves (2006) have some underlying function or structure. More specifically, it appears that the intron regions in chromosome Y might fall into two categories: the truly 'junk' DNA consisting of the introns with topological entropy greater than 0.910, and the introns that have hidden structure consisting of those sequences with entropy 0.84 0.86 0.88 0.90 0.92 H top 5 10 15Remaining on chromosome Y, we now present evidence that topological entropy can be used to detect sequences that are under selective pressure. Note that<ref type="bibr" target="#b19">Siepel et al. (2005)</ref>showed that both 5 and 3 UTRs are among the most conserved elements in vertebrate genomes. Thus, one would expect that the topological entropy of these regions would be very low (as this is indicative of a high degree of structure). As indicated in<ref type="figure" target="#fig_3">Figure 6</ref>, the entropy of both the 5 and 3 region are low in comparison to the entropy of the intron and exon regions across the autosomes. Compare, for example,<ref type="figure" target="#fig_1">Figure 4</ref>and 5. In fact, the mean of the topological entropy of the 5 and 3 UTRs (0.871545±0.0290619 and 0.879163±0.0219371) are lower than the mean entropy of any intron or exon region across every chromosome. The lowest mean topological entropy for an autosome is 0.927802±0.00539 on chromosome 19, this is more than 9 SDs higher than the mean of topological entropy for either the 3 or 5 UTRs. This lends support to the assertion that topological entropy can be used to detect functional regions and regions under selective constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 1066 1061–1067</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.Koslicki</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison to LC</head><p>As mentioned in Section 3.1, LC is the only other similar measurement of sequence complexity that produces a single number to represent the complexity of a sequence. We applied the algorithm described in<ref type="bibr" target="#b21">Troyanskaya et al. (2002)</ref>and written by<ref type="bibr" target="#b13">Larsson (1999)</ref>to the same dataset contained in Section 4.1 of this article. To obtain directly comparable results, we used a window size as big as the given sequence is long. As can be seen in the Supplementary Material, LC does distinguish between introns and exons to an extent, though not to the same quality of resolution as that of topological entropy (compare with<ref type="figure" target="#fig_4">Fig. 7</ref>). For example, while topological entropy consistently measures introns as more random than exons, LC does not. This discrepancy is most likely due to linguistic complexity being effectively utilized (<ref type="bibr" target="#b21">Troyanskaya et al., 2002</ref>) as a sliding window method to detect repetitive motifs, not as a holistic measure of sequence information content. So we also applied LC using a sliding window of 2000 bp, taking the average value of LC on a given sequence, and then averaging on a given chromosome. Using the sliding window, LC does give a higher value to introns than to exons (except on chromosome 5). While the separation between the LC of introns and exons becomes more pronounced, the resolution is still not nearly as clear as with topological entropy since a large amount of error persists. The LC values among introns and exons are well within 1 SD of each other across the entire genome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 1067 1061–1067</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topological entropy of DNA sequences</head><p>Chr</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.3.</head><figDesc>Fig. 3. Histogram of topological entropy of randomly selected sequences of length 4 9 +9−1 = 262152.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.4.</head><figDesc>Fig. 4. Histogram of topological entropy of introns in chromosome Y.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.5.</head><figDesc>Fig. 5. Histogram of topological entropy for 5 and 3 UTRs in chromosome Y.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.6.</head><figDesc>Fig. 6. Error bar plot of chromosome Y 5 and 3 UTRs longer than 66 bp long.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.7.</head><figDesc>Fig. 7. Error bar plot of average topological entropy for the longest 100 introns and exons in each chromosome.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>3) H top (w) ≈ 1 if and only if w is highly complex (contains many subwords) (4) For different length sequences v,w, H top (w) and H top (v) should be comparable</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Definition 3 (topological entropy). Let w be a finite sequence of length |w|, let n be the unique integer such that 4 n +n−1 ≤|w| &lt; 4 n+1 +(n+1)−1 Then for w 4 n +n−1 1 the first 4 n +n−1 letters of w,</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 1. Calculated expected value of topological entropy n 4 n +n−1 Calculated expected value of H top</figDesc><table>1 
4 
0.725606 
2 
17 
0.841242 
3 
66 
0.890810 
4 
249 
0.917489 
5 
1028 
0.933868 
6 
4101 
0.944865 
7 
16390 
0.952736 
8 
65543 
0.958642 
9 
262152 
0.963237 
10 
1048585 
0.966914 
11 
4194315 
0.969921 
12 
16777227 
0.972428 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 2. Sampled expected value and SD of topological entropy n 4 n +n−1 Sampled expected value of H top</figDesc><table>Sampled SD 
Sample size 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>see Vinga and Almeida (2004) for more details]. Rènyi (1961) showed that for α = 1, one cannot define conditional and mutual information functions and hence Rènyi continuous entropy does not measure 'information content' in the usual sense. So while Rènyi entropy does allow for the identification of statistically significant motifs (Vinga and Almeida</figDesc><table></table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="5"> CONCLUSION This implementation of topological entropy is free from issues that other implementations have encountered. Namely, this definition allows for the comparison of sequences of different length and does not suffer from multidimensionality complications. Since this definition supplies a single value to characterize the complexity of a sequence, it is much more capable of being mathematically analyzed. Beyond measuring the complexity or simplicity of a sequence, we presented evidence that our approximation to topological entropy might detect functional regions and sequences free from or under selective constraint. The speed and simplicity of this implementation of topological entropy makes it very suitable for utilization in detecting regions of high/low complexity. For example, we observe the novel phenomena that the introns on chromosome Y have atypically low and bimodal entropy, possibly corresponding to random sequences and sequences that posses hidden structure or function.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The author would like to thank Manfred Denker, Kateryna Makova and Francesca Chiaromonte for their assistance and fruitful discussion regarding this article. Funding: National Science Foundation (grant number DMS1008538).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict</head><p>of Interest: none declared.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Topics in Symbolic Dynamics and Applications Lecture Note Series 279</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Blanchard</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>London Mathematical Society Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A framework for collaborative analysis of ENCODE data: making large-scale analyses biologist-friendly</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Blankenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="960" to="964" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Galaxy: a web-based genome analysis tool for experimentalists</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Blankenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Protocol. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Special factors in biological strings</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Colosimo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>De Luca</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page" from="29" to="46" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Zones of low entropy in genomic sequences</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Crochemore</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Vèrin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Chem</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="275" to="282" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">On the entropy of DNA: algorithms and measurements based on memory and rapid convergence</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Farach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth annual ACM-SIAM symposium on discrete algorithms. SIAM</title>
		<meeting>the sixth annual ACM-SIAM symposium on discrete algorithms. SIAM<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="48" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Sequence complexity and DNA curvature</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gabrielian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bolshoy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Chemistry</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">On correlation polynomials and subword complexity</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Gheorghiciuc</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">D</forename>
				<surname>Ward</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Analysis of Algorithms</title>
		<meeting><address><addrLine>Nancy, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Sex chromosome specialization and degeneration in mammals</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A M</forename>
				<surname>Graves</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="901" to="914" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Dating of the human-ape splitting by a molecular clock of mitochondrial DNA</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hasegawa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Evol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="160" to="174" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<monogr>
		<title level="m" type="main">Evolution of protein molecules</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">H</forename>
				<surname>Jukes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">R</forename>
				<surname>Cantor</surname>
			</persName>
		</author>
		<editor>Munro,H.N.</editor>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Mammalian Protein Metabolism. Academic Press</publisher>
			<biblScope unit="page" from="21" to="132" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical compressibility analysis of DNA sequences by generalized entropy-like quantities: towards algorithmic laws for Biology</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Karamanos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th WSEAS Int</title>
		<meeting>. 6th WSEAS Int</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="481" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Entropy concepts and DNA investigations</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">V</forename>
				<surname>Kirillova</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">274</biblScope>
			<biblScope unit="page" from="247" to="253" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">Structures of String Matching and Data Compression</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Larsson</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Sweden</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Systematic analysis of coding and noncoding DNA sequences using methods of statistical linguistics</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">N</forename>
				<surname>Mantegna</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="2939" to="2950" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Entropy is the only finitely observable invariant</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ornstein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Weiss</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mod. Dyn</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="93" to="107" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">On measures of information and entropy</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rènyi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Berkely Symposium on Mathematical Statistics and Probability</title>
		<meeting>the 4th Berkely Symposium on Mathematical Statistics and Probability<address><addrLine>Berkely, CA</addrLine></address></meeting>
		<imprint>
			<publisher>I. University of California Press</publisher>
			<date type="published" when="1961" />
			<biblScope unit="page" from="547" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimating the entropy of DNA sequences</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">O</forename>
				<surname>Schmitt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Herzel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="page" from="369" to="377" />
			<date type="published" when="1888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A Mathematical theory of communication</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">E</forename>
				<surname>Shannon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech. J</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Evolutionarily conserved elements in vertebrate, insect, worm, and yeast genomes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Siepel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1034" to="1050" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Scaling features of noncoding DNA</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">E</forename>
				<surname>Stanley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. A</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequence complexity profiles of prokaryotic genomic sequences: a fast algorithm for calculating linguistic complexity</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">G</forename>
				<surname>Troyanskaya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="679" to="688" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Rènyi continuous entropy of DNA sequences</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Vinga</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Almeida</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="volume">231</biblScope>
			<biblScope unit="page" from="377" to="388" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Genomic analyses of sex chromosome evolution</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Wilson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">D</forename>
				<surname>Makova</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Genome Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="333" to="354" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title level="m" type="main">Evolution and survival on eutherian sex chromosomes</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Wilson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">D</forename>
				<surname>Makova</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>PLoS, 5, e1000568</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>