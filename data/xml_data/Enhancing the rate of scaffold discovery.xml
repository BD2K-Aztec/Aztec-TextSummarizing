
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Enhancing the rate of scaffold discovery with diversity-oriented prioritization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">S</forename>
								<forename type="middle">Joshua</forename>
								<surname>Swamidass</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Laboratory and Genomic Medicine</orgName>
								<orgName type="department" key="dep2">Department of Pathology and Immunology</orgName>
								<orgName type="institution">Washington University School of Medicine</orgName>
								<address>
									<settlement>St Louis</settlement>
									<region>MO</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Chemical Biology/Novel Therapeutics</orgName>
								<orgName type="institution">The Broad Institute of Harvard and MIT</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Bradley</forename>
								<forename type="middle">T</forename>
								<surname>Calhoun</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Division of Laboratory and Genomic Medicine</orgName>
								<orgName type="department" key="dep2">Department of Pathology and Immunology</orgName>
								<orgName type="institution">Washington University School of Medicine</orgName>
								<address>
									<settlement>St Louis</settlement>
									<region>MO</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Joshua</forename>
								<forename type="middle">A</forename>
								<surname>Bittker</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Chemical Biology/Novel Therapeutics</orgName>
								<orgName type="institution">The Broad Institute of Harvard and MIT</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Nicole</forename>
								<forename type="middle">E</forename>
								<surname>Bodycombe</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Chemical Biology/Novel Therapeutics</orgName>
								<orgName type="institution">The Broad Institute of Harvard and MIT</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Paul</forename>
								<forename type="middle">A</forename>
								<surname>Clemons</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Chemical Biology/Novel Therapeutics</orgName>
								<orgName type="institution">The Broad Institute of Harvard and MIT</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Enhancing the rate of scaffold discovery with diversity-oriented prioritization</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">16</biblScope>
							<biblScope unit="page" from="2271" to="2278"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr369</idno>
					<note type="submission">Received on April 18, 2011; revised on June 10, 2011; accepted on June 14, 2011</note>
					<note>[15:26 23/7/2011 Bioinformatics-btr369.tex] Page: 2271 2271–2278 Associate Editor: Martin Bishop Contact: swamidass@wustl.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: In high-throughput screens (HTS) of small molecules for activity in an in vitro assay, it is common to search for active scaffolds, with at least one example successfully confirmed as an active. The number of active scaffolds better reflects the success of the screen than the number of active molecules. Many existing algorithms for deciding which hits should be sent for confirmatory testing neglect this concern. Results: We derived a new extension of a recently proposed economic framework, diversity-oriented prioritization (DOP), that aims—by changing which hits are sent for confirmatory testing— to maximize the number of scaffolds with at least one confirmed active. In both retrospective and prospective experiments, DOP accurately predicted the number of scaffold discoveries in a batch of confirmatory experiments, improved the rate of scaffold discovery by 8–17%, and was surprisingly robust to the size of the confirmatory test batches. As an extension of our previously reported economic framework, DOP can be used to decide the optimal number of hits to send for confirmatory testing by iteratively computing the cost of discovering an additional scaffold, the marginal cost of discovery.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>All screeners must decide which initial positives ('hits') from a high-throughput screen (HTS) to submit for confirmatory experiments (<ref type="bibr" target="#b19">Makarenkov et al., 2007;</ref><ref type="bibr" target="#b20">Nicholls, 2008;</ref><ref type="bibr" target="#b22">Rocke, 2004;</ref><ref type="bibr" target="#b27">Storey et al., 2007</ref>). In HTS of small molecules for biological activity, several hits are often experimentally confirmed by ensuring they exhibit the characteristic dose–response behavior common to true actives. Sending the wrong molecules for confirmatory testing wastes resources, reducing the amount of useful information in screening results; this is especially true in the context of small molecule screens which are often very noisy. * To whom correspondence should be addressed.</p><p>Most commonly used hit selection methods focus on maximizing the number of successfully confirmed molecules in subsequent confirmatory experiments. These methods include correcting time-and well position-dependent systematic error in measurements (<ref type="bibr" target="#b19">Makarenkov et al., 2007</ref>), exploiting chemical information (<ref type="bibr" target="#b12">Glick et al., 2004</ref><ref type="bibr" target="#b13">Glick et al., , 2006</ref><ref type="bibr" target="#b21">Posner et al., 2009</ref>), better normalizing screening data (<ref type="bibr" target="#b32">Zhang et al., 2005</ref>), choosing better experimental controls (<ref type="bibr" target="#b25">Seiler et al., 2008</ref>) or bypassing hit selection entirely by testing all molecules in dose–response experiments (<ref type="bibr" target="#b15">Inglese et al., 2006</ref>). These methods are effective, increasing the number of successful confirmations, but largely ignore the fact that screeners are often looking to maximize the total number of clusters– groups of molecules with similar structure–containing examples with confirmed activity (<ref type="bibr" target="#b5">Clark and Webster-Clark, 2008</ref>). Some methods use molecular clustering to improve the design of HTS experiments. For example, molecular clusters have been used to reduce the total number of molecules in the primary screen by about two-thirds (<ref type="bibr" target="#b16">Karnachi and Brown, 2004</ref>). Similarly, other studies pick molecules for follow-up using statistical tests on the data from a single-dose screen to find clusters of active molecules (<ref type="bibr" target="#b29">Varin et al., 2010;</ref><ref type="bibr" target="#b31">Yan et al., 2005</ref>). These methods favor clusters that contain several active molecules, and attempt to send all these active molecules for confirmatory testing. As intended, these methods successfully increase the number of active molecules identified in confirmatory testing. In contrast, diversity-oriented prioritization (DOP) aims to maximize the diversity of confirmed actives by maximizing the number of clusters with at least one successfully confirmed active. Rather than picking groups of similar molecules, DOP picks molecules from as many different groups as possible given the cost constraint. This aim is motivated by the fact that screeners often cluster confirmed active molecules to pick series of molecules to optimize, and that the number of series with at least one confirmed active is a reasonable way of measuring the information obtained from a screen (<ref type="bibr" target="#b5">Clark and Webster-Clark, 2008</ref>). The DOP method extends a recently described economic framework for interpreting HTS data, initially introduced to decide how many hits to send for confirmatory testing (<ref type="bibr" target="#b28">Swamidass et al., 2010</ref>). This framework is used to iteratively choose each batch of hits to be sent for confirmatory testing so as to maximize the expected surplus of the batch. The expected surplus is computed using three mathematical models: utility, cost and predictive. The utility model specifies the preferences of the screener, the cost model tracks</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.J.Swamidass et al.</head><p>the cost of running a confirmatory experiment and the predictive model guesses the outcome of future confirmatory experiments. DOP extends this framework by introducing a new utility model, from which we derive a new method of prioritizing hits. We validated the DOP methodology and the algorithm that implements it with both retrospective and prospective experiments. These experiments demonstrate that DOP can substantially increase the number of active scaffolds discovered in a HTS experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DATA</head><p>The technical details of the assay and subsequent analysis can be found in PubChem (PubChem AIDs 1832 and 1833). For ∼300000 small molecules screened in duplicate, we defined activity as the mean of final, corrected percent inhibition. After molecules with autofluorescence and those without additional material in stock were filtered out, 1322 with activity greater than 25% were labeled 'hits' and tested for dose–response behavior in the first batch. Of these tested molecules, 839 yielded data consistent with inhibitory activity. Each hit was considered an 'active' if the effective concentration at half maximal activity (EC50) was less than or equal to 20 µM. Using this criterion, we determined 410 molecules to be active.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Scaffold clusters</head><p>There are two common strategies used to cluster small molecules: similaritybased and scaffold-based clusterings (<ref type="bibr" target="#b1">Bemis and Murcko, 1996;</ref><ref type="bibr" target="#b3">Butina, 1999;</ref><ref type="bibr" target="#b4">Clark and Labute, 2008;</ref><ref type="bibr" target="#b6">Downs et al., 1994;</ref><ref type="bibr" target="#b24">Schuffenhauer et al., 2007;</ref><ref type="bibr" target="#b26">Shemetulskis et al., 1995;</ref><ref type="bibr" target="#b30">Willett, 2006</ref>). Similarity-based clustering groups structurally similar molecules—as measured by fingerprint similarity—together. Within each cluster, molecules' structures are very close, but it may not be possible to align molecules because there may not be substructures common to all the molecules in the cluster. In contrast, scaffold-based clustering groups molecules into clusters with a well-defined common substructure. Therefore, within each scaffold cluster, molecules are easily aligned (<ref type="bibr" target="#b4">Clark and Labute, 2008</ref>). Often, HTS campaigns aim to identify as many new scaffolds as possible. Sometimes intellectual property concerns dictate both avoiding particular scaffolds and defining discoveries using the scaffold concept. Scaffolds are often the starting points from which lead-refinement proceeds (<ref type="bibr" target="#b5">Clark and Webster-Clark, 2008;</ref><ref type="bibr" target="#b14">Good and Oprea, 2008;</ref><ref type="bibr" target="#b24">Schuffenhauer et al., 2007</ref>). Therefore, we focused on scaffold-based clustering. Nonetheless, our methods can be easily adapted to similarity-based clustering. We computed scaffolds from the structure of each molecule using the molecular framework algorithm described by Bemis and Murcko (1996): contiguous ring systems and the chains that link two or more rings together. Molecular frameworks are only an approximation of a medicinal chemists subjective concept of a scaffold (<ref type="bibr" target="#b4">Clark and Labute, 2008;</ref><ref type="bibr" target="#b24">Schuffenhauer et al., 2007</ref>). Nonetheless, frameworks are commonly used in chemical informatics because they are clearly defined and easy to compute. Although we define scaffolds as molecular frameworks, DOP is compatible with more sophisticated scaffold detection algorithms; all it requires is that molecules are grouped appropriately. In order to ensure our findings were not overly dependent on the choice of scaffold definition, all experiments in this study were replicated using a modification of each scaffold that replaces every atom in the scaffold with a carbon. The results of this variation are not presented because they are not notably different. This observation suggests that similar results would also be observed with other scaffold-detection algorithms, though we have not directly verified this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Utility model</head><p>The preferences of screeners are difficult to assess and often inconsistent between different experts (<ref type="bibr" target="#b17">Lajiness et al., 2004</ref>). Nonetheless, some parts of their preferences can be modeled. In this study, a scaffold was considered to be 'active' if at least one example of the scaffold was confirmed as active. Consistent with prior work (<ref type="bibr" target="#b5">Clark and Webster-Clark, 2008</ref>), one unit of discovery was defined as a single active scaffold. Of course, more robust definitions of an active scaffold are possible—for example, defining scaffolds active if they have two or three confirmed active examples—however, these definitions require more complicated algorithms to implement and will be elaborated in future work. The utility model U(D) was defined as a function of the total discovery so far, D: the number of scaffolds with at least one example confirmed active, corresponding with maximizing the number of scaffolds identified, giving chemists maximally diverse candidate starting points for follow-up chemistry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cost model</head><p>The cost model used is relevant to the implementation of DOP in two ways. First, in some scenarios, the cost of acquiring different molecules varies. In the context of HTS, however, molecules under consideration are usually equally accessible. Therefore, we assumed that it costs the same amount to send each molecule for confirmatory testing. Second, there are both large fixed and smaller variable costs associated with sending molecules for confirmatory tests. Under these circumstances, confirmatory tests are most efficiently performed in large batches, just as is done in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Predictive model</head><p>We considered two predictive models: a logistic regressor (LR) (<ref type="bibr" target="#b10">Dreiseitl and Ohno-Machado, 2002</ref>) and a neural network with a single hidden node (NN1) (<ref type="bibr" target="#b0">Baldi and Brunak, 2001</ref>). Both are structured to use the screen activity as the single independent variable and the result of the associated confirmatory experiment as the single dependent variable. Networks with more hidden layers work as well, but do not yield substantially better results. Both the LR and NN1 models were trained using gradient descent on the crossentropy error using the monotonic prior defined in the Appendix A (with k = 2 and θ = 0.5) along with a Gaussian prior on weights not addressed by the monotonic prior (<ref type="bibr" target="#b0">Baldi and Brunak, 2001</ref>). In general, such a protocol yields models whose outputs are interpretable as a probabilities,</p><formula>P(x) ⎧ ⎪ ⎨ ⎪ ⎩ 1</formula><p>if molecule x is confirmed active 0 if molecule x is confirmed inactive, z x if molecule x has not been tested</p><formula>(1)</formula><p>where z x is the output of the predictive model on the molecule x. There is little distinction between LR and NN1 in practice and, in fact, virtually any probabilistic method can be used by the DOP method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Prioritization algorithm</head><p>The economic framework prescribes choosing the next batch to maximize the expected surplus (ES) after the next batch is screened,</p><formula>E U(D +D) −(C +C ) (2)</formula><p>where D is the number of scaffolds in the next batch, D is the number of scaffolds discovered so far, C is the cost expended confirming molecules so far and C is the cost of screening the next batch. Removing the cost terms, which are constant across all molecules, shows that maximizing the ES is equivalent to maximizing expected utility (EU),</p><formula>E U(D +D) .</formula><formula>(3)</formula><p>Furthermore, because U(·) is likely to be approximately linear over the narrow distribution of D , this equation is well approximated by,</p><formula>U E[D ]+D ,</formula><formula>(4)</formula><p>a well-studied approximation from the economics literature (<ref type="bibr" target="#b18">Levy and Markowitz, 1979;</ref><ref type="bibr" target="#b23">Schoemaker, 1982</ref>). Because U(</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>·) is monotonically</head><p>Page: 2273 2271–2278</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversity-oriented prioritization</head><p>increasing, maximizing the EU—and also maximizing ES—is approximately equivalent to maximizing the expected marginal discovery (EMD)</p><formula>E[D ],</formula><formula>(5)</formula><p>and therefore we propose prioritizing molecules by choosing the next batch of molecules so as to maximize the EMD of the batch. A different protocol is required to select the molecules in the first batch because it is impossible to compute the EMD without knowing the results of at least some confirmatory experiments. For the first batch, we chose molecules with the top activity in the screen while at the same time assuring that no more than one example of each scaffold was selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Computing EMD</head><p>The algorithm for computing the EMD requires the output from the predictive model and assumes that each probability of successful confirmation is independent of the others, and that within a scaffold group each molecule is screened in the order of decreasing probability of activity. With these assumptions, the EMD of the x-th molecule in the scaffold is EMD(x) = P(x-th is first active),</p><formula>(6)</formula><p>where P(x-th is first active) is the probability molecule x is the first confirmed active within its scaffold group, and the total EMD of the next batch E<ref type="bibr">[D ]</ref>is computed as the sum of the EMDs associated with each molecule in the batch. To do this, we used an algorithm to compute P(x-th is first active). For each group of molecules with a common scaffold, we defined the probability that each molecule is active using Equation (1). The molecules in the group were sorted in decreasing order of probability so that {P(1) ≥ P(2) ≥ P(3) ≥ ...}. Assuming the untested molecules must be prioritized in this order, the probability that the j-th molecule in this list is the first active is EMD(j) = P(j is first active</p><formula>) = P(j) j−1 k=1 1−P(k) ,</formula><formula>(7)</formula><p>where the probability that molecule j is active, P(j), is multiplied by the probability that all prior molecules in the scaffold group are inactive, j−1 k=1 [1−P(k)]. The EMD of the next batch was thus maximized by choosing the untested molecules with highest EMD. These EMD's remain ordered in decreasing order so that {EMD(1) ≥ EMD(2) ≥ EMD(3) ≥ ...}. Within a scaffold group, therefore, untested molecules were prioritized in the same order as their initial HTS activity. Depending on how many total molecules are to be tested, the algorithm will usually pick one molecule from each scaffold but will occasionally choose more than one. With respect to molecules from other scaffold groups, however, their order may be shuffled: exactly the behavior we seek.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Scaffold distribution</head><p>The skewed distribution of scaffolds in HTS data motivated our approach. Ignoring this distribution, resources would be wasted trying to confirm examples of scaffolds that have already been discovered; in other words, there is significant redundancy both in HTS libraries and the hits from screens of these libraries. We considered three sets of molecules: the full set of molecules from the screen (the Library), the first batch sent for dose–response confirmation (the Dosed) and the molecules subsequently confirmed as active (the Active). There were 301 617, 1322 and 410 molecules, and 84 440, 1043 and 331 scaffolds, respectively, in each of these sets. Each scaffold is represented by, on average, 3.57, 1.27 and 1.24 examples. The molecules are not distributed evenly amongThe 'Library' is the approximately 300 000 molecules screened in the initial HTS assay, 'Dosed' are the molecules that were sent for dose-response confirmation in the first batch, and 'Active' are those molecules subsequently confirmed as active. For each set of molecules, the top table displays the frequency of the top five most common scaffolds and the percentage of the total dataset that each scaffold group represents. The bottom table displays the number of scaffolds with exactly 1, 2, 3, 4 or 5 examples in the data (frequency) and the percentage of data that these scaffold groups represent. scaffolds; a few scaffolds are disproportionately frequent, but &gt; 50% of the Dosed set is composed of scaffolds with only one example (<ref type="figure" target="#tab_1">Table 1</ref>). These results reflect the prior observation that molecules follow a power-law distribution when clustered (<ref type="bibr" target="#b2">Benz et al., 2008</ref>). Similar distributions would be expected if the structures had been clustered by almost any other clustering algorithm. The scaffold distribution sets an upper bound on DOP's efficiency. Of the 1322 molecules sent for dose–response experiments, only 79% could be, in a best-case scenario, the first example of their scaffold group. Therefore, at most we could expect a 21% reduction in the number of confirmatory experiments required to discover a fixed number of scaffolds. This estimation is based on one dataset and would need to be revised upwards or downwards with other datasets. Furthermore, this estimate only considers the proportion of singletons; more accurate predictions could be constructed. Nonetheless, it provides a useful theoretical baseline against which to gauge DOP's empirical performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Predicting yield</head><p>One test of the DOP algorithm is to assess whether it can accurately predict yield—the number of scaffold discoveries in a batch of experiments—using Equations (6) and (7) in conjunction with either of the two predictive models, LR and NN1. In this experiment, 1322 molecules with known dose–response outcomes were ordered by their initial HTS activity. They were then divided into plates of 30 molecules each. The yield of each plate was predicted by training a predictive model (LR or NN1) on the outcome of all prior confirmatory tests, as described in the Section 3. The predicted probabilities of activity were then used in conjunction with Equations (6) and (7) to yield a final prediction. The predicted yield is close to the empirical number of discoveries (<ref type="figure" target="#fig_1">Fig. 1</ref>).This experiment demonstrates that the DOP algorithm can predict the number of scaffold discoveries in a plate. There is some systematic inaccuracy in these predictions; both LR or NN1 seem to overestimate the number of discoveries by a small amount. It is possible that this systematic error is due to dependencies in the data ignored by our model: for example, successfully confirmed actives are likely to share a common scaffold. Nonetheless, the predictions are close to the observed yield.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Reordering hits</head><p>Another test of DOP is to verify that it modifies the order in which molecules are sent for confirmatory testing. Furthermore, because confirmatory experiments are usually batched in large groups, it is important to study how the DOP rankings change as the batch sizes are varied. In this experiment, we compared the order of molecules ranked by initial HTS activity with the ordering generated by the DOP algorithm. For comparison, the DOP algorithm was run six times using two different predictive models and three different batch sizes: 1 (unbatched), 30 and 300. This experiment yields several important observations. First, both NN1 and LR yielded almost identical rankings (R 2 = 0.999). This is an important result that suggests that DOP is robust to the predictive model: subtle differences in the predictive model may not dramatically affect how molecules are ordered. Second, DOP may be surprisingly robust to batch size. Using a batch size of 30 was virtually identical to the unbatched DOP (<ref type="figure" target="#fig_2">Fig. 2</ref>). There were more noticeable differences with unbatched DOP and DOP using a batch size of 300. Nonetheless, using DOP with a batch size of 300 yielded rankings much closer to the unbatched DOP rankings than to the original HTS rankings. Finally, in all cases, ∼200 molecules were not ranked because their EMDs were equal to zero before they were prioritized. This is exactly the desired behavior; testing these 200 molecules would be redundant because they have scaffolds that had already been confirmed active.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Increasing scaffold discovery rate</head><p>The most important in silico test of DOP is to verify that it increases the rate of scaffold discovery. While it is clear that DOP reorders molecules relative to the HTS activity, the rate at which scaffolds are discovered must increase in order to conclude that DOP is preferable to ordering molecules by HTS activity. In this experiment, molecules were prioritized by DOP in batches of 30. Compared with prioritizing by HTS activity, the total number of scaffolds discovered was plotted against the total number of confirmatory experiments (<ref type="figure" target="#fig_3">Fig. 3</ref>). DOP shifts the curve upward, indicating that for any specific number of confirmatory experiments, more scaffolds were discovered using DOP. On average, DOP discovered 1.18 more scaffolds per batch than HTS activity prioritization. DOP increased the scaffold discovery rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Effect of batch size</head><p>For DOP to be useful in practice, it must be robust to large batch sizes. We might expect a trade-off between batch size and efficiency; larger batch sizes might decrease DOP efficiency due to inaccuracies in the predictive model and uncertain outcomes in confirmatory experiments. However, the ranking data suggest that DOP may be robust to batch size. We performed a more comprehensive test to resolve these conflicting expectations. In this experiment, DOP was run with several different batch sizes using both predictive models. Compared with ordering molecules by HTS activity, the number of confirmatory experiments required to discover 50, 75 and 100% of the scaffolds was reduced by 8–17% (<ref type="figure">Table 2</ref>). Surprisingly, these numbers were largely consistent (and often identical) across all batch sizes and predictive models. Batch size did not appreciably affect the rate at which scaffolds are discovered; DOP is robust to batch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Prospective validation</head><p>Although these retrospective experiments are promising, the most important test of DOP is a prospective experiment. In this experiment, we used a batch size of 500 molecules. DOP, using both LR and NN1, was used to pick the next 500 molecules to test. These two lists of candidates were compared with the next batch of 500 molecules selected by HTS activity. The yield of all three lists was predicted and as many molecules as were available were obtained and sent for confirmatory testing. In this case, of the 500 compounds suggested, 479 from the LR and NN1 batches and 477 from the HTS batch were sent for testing. Even without the results of the confirmatory tests, this experiment reinforced several results from the retrospective experiments. First, the batches suggested by LR and NN1 were almost identical, with only 10 molecules different, corresponding with the observation that LR and NN1 yielded almost identical rankings in the retrospective experiments. Second, both DOP batches were substantially different than the HTS batch, with 105 molecules different in the LR list and 95 different in the NN1 list, again corresponding with similar observations from the retrospective experiments. More importantly, LR predicted a 12.5% increase in scaffold discovery (126 compared with 112). Likewise, NN1 predicted a similar 8.7% increase in the rate of scaffold discovery (113 compared with 104). The results of the confirmatory testing also correspond with the results from the retrospective experiments. First, and most importantly, more scaffolds were discovered in the DOP batches; 170 and 166 scaffolds were discovered in the LR and NN1 batches, compared with 153 scaffolds in the HTS batch. Finally, the predicted yield was close to, but still underestimated, the actual Page: 2275 2271–2278The order of selection for confirmatory experiment given by NN1 (same as order of selection by LR). 'HTS' is the scaffolds discovered when tested in the order of their HTS results. number of scaffolds discovered: LR predicted DOP to discover 126 (actual 170) and HTS to discover 112 (actual 153). NN1 predicted DOP to discover 113 (actual 166) and HTS to discover 104. The predictions are underestimations of the actual yields. Predicted increase in scaffold discovery were more accurate. LR predicted 12.5% more scaffolds discovered in DOP than HTS (actual 11.1%). NN1 predicted 8.7% more (actual 8.5%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversity-oriented prioritization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>In both retrospective and prospective experiments, DOP increased the rate of scaffold discovery from an HTS experiment. The key result of this study is that screeners preferences, when more accurately modeled, can be applied to change the order in which molecules are tested so as to increase the rate at which active scaffolds are discovered.Confirmatory tests run on the same set of molecules, sorted by DOP with different batch sizes. The table indicates the number of confirmatory experiments required before some percentage (75 or 100%) of the total active scaffolds in the set were discovered. Percentages in parenthesis indicate improvement with respect to confirmatory tests run in order of HTS results.</p><p>Several additional issues arise when using DOP in practice. First, there will be several molecules that are very likely active but will not be sent for confirmatory testing. These molecules are de-prioritized because they belong to scaffold groups with at least one example already confirmed active. This is not the behavior some might expect from a prioritization algorithm. One extension to address this concern would be to report the probability of activity—the output of LR or NN1—for all the molecules from scaffold groups with at least one confirmed active. A succinct way to summarize this information is to report the total number of actives and inactives expected if all the molecules in the group had been tested (<ref type="figure" target="#fig_5">Fig. 4</ref>). DOP could be used as the first stage of a two-stage prioritization protocol, where the first few batches are selected to maximize scaffold discovery. In the second stage, with the screener's input, a number of scaffolds could then be selected for follow-up experiments based on their structures, the initial results from the confirmatory experiments and the predicted number of actives and inactives associated with them. Additional examples of the selected scaffold would then be sent for confirmatory testing to build enough</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Monotonic models</head><p>Models like LR and NN1 estimate the correct weights by using gradient descent to maximize the log likelihood of the model with respect to the training data:</p><formula>L = i t i logz i (w)+(1−t i )log 1−z i (w) ,</formula><formula>(8)</formula><p>where i ranges over the training data, t i ∈{1,0} is the outcome of the confirmation experiment on the i-th training example, z i is the output of the model on the i-th training example and w is the weight vector whose elements are chosen to maximize the log likelihood L. Sometimes this process yields weights that are inaccurately estimated. Usually, the inaccuracy only subtly affects the model's yield predictions and the order in which molecules are prioritized. Occasionally, when trained on small amounts of data, this inaccuracy can be more dramatic. The worst failure occurs when a model inaccurately learns that the molecules with the worst activity in the initial screen are the most likely to be active in the confirmatory experiment. This, in turn, prioritizes the most clearly inactive molecules from the initial screen above all others. This failure can be prevented by ensuring that the model is positive monotonic: that its output always increases as its input—the activity in the initial screen—increases. We accomplish this by adding a gamma prior to components of the weight vector. In the case of LR, the prior is placed on the weight multiplied by the input data, but not on the weight added to the product of this multiplication. In the case of NN1, the prior is placed on the weights that multiply either input or hidden nodes, but not on any of the threshold weights. Gamma priors on these weights ensure that trained models will always be positively monotonic with respect to their inputs no matter what the training data. The gamma prior is implemented by defining a probability distribution over select weights in the model,</p><formula>P(w) = j w k−1 j e −w j /θ θ k (k) ,</formula><formula>(9)</formula><p>where j ranges over the components of w to which the gamma priors are applied. k and θ are the position and shape parameters of the distribution, and (·) is the gamma function. This amounts to changing the objective of the training algorithm to maximize likelihood,</p><formula>L = j (k −1)logw j − w j θ + i t i logz i (w)+(1−t i )log 1−z i (w) .</formula><formula>(10)</formula><p>Notably, the likelihood is undefined when any of the weights with a gamma prior are &lt;0, ensuring that the weights which maximize the likelihood will always yield a monotonic model. Care must be taken to use an optimization algorithm that appropriately handles undefined output from the objective function. Alternatively, in conjunction with the gamma prior, each w j can be reparameterized to use a new set of variables v such that w j (v j ) = e v j for the weights with gamma priors and w j (v j ) = v j for the rest. Now, instead of maximizing the likelihood by adjusting each w j , the optimization algorithm adjusts each v j. The mathematical details of this strategy yield the objective,</p><formula>L = j (k −1)v j − e v j θ + i t i logz i w(v) +(1−t i )log 1−z i w(v) ,</formula><formula>(11)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.J.Swamidass et al.</head><p>where v is optimized by the gradient descent algorithm. Assuming that the gradient of w is computable, the gradient of v is computed using the chain rule,</p><formula>∂L ∂v j = ∂L ∂w j e v j +k −1+ e v j θ ,</formula><formula>(12)</formula><p>for the the weights with a gamma prior and ∂L</p><formula>∂v j = ∂L ∂w j ,</formula><formula>(13)</formula><p>for the rest of the weights. Finally, the optimal w can be computed from the optimal v after training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Predicted confirmation rate of scaffolds. The per-batch predicted discoveries of active scaffolds (LR and NN1) along with observed discoveries (labeled 'Data').</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Changes in rank. Comparison of ranking by DOP selection to ranking by HTS results. 'Initial Activity' is the order of molecules ranked by HTS results. 'Unbatched' shows the rankings of DOP computed in a molecule-by-molecule protocol (e.g. batch size of 1), while 'Batched' corresponds to DOP computed using more realistic batch sizes of (left) 30 and (right) 300 molecules. Identical results are produced by both NN1 and LR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Improvement in scaffold discovery rate. 'DOP'indicates the scaffolds discovered using DOP, done in batches of 30 molecules. The order of selection for confirmatory experiment given by NN1 (same as order of selection by LR). 'HTS' is the scaffolds discovered when tested in the order of their HTS results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. This display is sufficiently informative to enabled chemists to prioritize singletons for follow-up after a screen. All four scaffolds have only one confirmed active (dark red block), with the predicted number of actives (light red bars and left numbers) and inactives (blue bars and right numbers) displayed below each structure. These predictions are fractional, reflecting the expected number of actives and inactives for each scaffold. The top-left scaffold's structure and predicted number of actives were both favorable to a particular medicinal chemist. The bottom-left scaffold's questionable structure was outweighed by the number of predicted actives. The right scaffolds' structures were so unfavorable that they were considered undesirable regardless of the number of actives confirmed; the chemist believed that they were more difficult to chemically modify. Of course, other medicinal chemists might rank these structures differently based on their experience and intentions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>[15:</head><figDesc>26 23/7/2011 Bioinformatics-btr369.tex] Page: 2278 2271–2278</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Scaffold distributions</figDesc><table>Rank 
Number of examples 
Percentage of data 

Library Dosed Active 
Library Dosed Active 

1 
7215 
19 
6 
2.3 
1.4 
1.5 
2 
1104 
10 
5 
0.4 
0.8 
1.2 
3 
886 
8 
5 
0.3 
0.6 
1.2 
4 
797 
8 
5 
0.3 
0.6 
1.2 
5 
704 
7 
4 
0.2 
0.5 
1.0 

Frequency Number of scaffolds 
Percentage of data 

Library Dosed Active 
Library Dosed Active 

1 
42889 
887 
285 
14.2 
67.1 
69.5 
2 
14599 
101 
26 
9.7 
15.3 
12.7 
3 
8065 
30 
12 
8.0 
6.8 
8.8 
4 
5132 
10 
4 
6.8 
3.0 
3.9 
5 
3382 
9 
3 
5.6 
3.4 
3.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. Batch size and discovery rate</figDesc><table>Batch size 
75% sensitivity 
100% sensitivity 

LR (%) 
NN1 (%) 
LR (%) 
NN1 (%) 

1 
502 (14) 
501 (14) 
1124 (14) 
1124 (14) 
30 
501 (14) 
501 (14) 
1124 (14) 
1124 (14) 
100 
499 (14) 
499 (14) 
1124 (14) 
1124 (14) 
200 
498 (15) 
498 (15) 
1121 (15) 
1119 (15) 
300 
504 (14) 
504 (14) 
1117 (15) 
1119 (15) 
400 
498 (15) 
498 (15) 
1132 (14) 
1136 (13) 
500 
514 (12) 
514 (12) 
1123 (14) 
1126 (14) 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">evidence to establish the scaffold as a true active. Such a twostep protocol, first maximizing scaffold discovery then confirming more examples of interesting scaffolds, provides an example of how our methods could be modified to better model screeners&apos; preferences. Better utility functions might seek to maximize the number of scaffolds with a clique of at least two or three confirmed actives. Clique-oriented prioritization (COP), however, requires a more complicated algorithm that will be presented in future work. Importantly, DOP can and should be used simultaneously with other HTS analysis algorithms. For example, other prioritization methods designed to reduce false positives—by using better controls, chemical information, or other strategies—are all compatible with DOP; the priorities generated by these methods can either be substituted for the HTS activity or be presented as an additional independent variable to the predictive model. Furthermore, DOP is a direct extension of a previously defined economic framework and can, therefore, be used to compute the marginal cost of discovery (MCD) (Swamidass et al., 2010). The MCD is the cost required to discover one more scaffold, and yields an optimal strategy for deciding how many and which molecules should be sent for confirmatory testing. The MCD is effectively the price of the next active, and the screener should keep screening molecules until the MCD rises too high and the utility of the next scaffold is not worth the cost of finding it. DOP is not without limitations. Most importantly, DOP relies on a definition of an active scaffold that may not be optimal. Furthermore, DOP requires that the results from enough confirmatory experiments are known for the predictive model to be trained. In contrast, most other HTS hit selection methods are applied to primary HTS data without knowing anything about the outcome of any confirmatory experiments (Karnachi and Brown, 2004; Varin et al., 2010; Yan et al., 2005). This limitation essentially requires HTS to proceed iteratively, with at least two batches. Future work will include methods of circumventing this limitation by using predictive models that do not require confirmatory experiments to be parameterized. Also, as presented, DOP assumes that there are no errors in the confirmatory experiment, that each molecule&apos;s potency is measured accurately in the dose–response experiment. However, just like the primary screen, there can be substantial noise in the confirmatory experiment (Eastwood et al., 2006). One method of accounting for errors in the confirmatory experiment is by labeling molecules by their probability of having a satisfactory potency when taking the noise of the assay into account. This strategy would, likely, improve the quality of the predictive models and more comprehensively address the problem of noise in HTS projects. A detailed description and evaluation of this approach will be considered in future work. 6 CONCLUSION When screeners&apos; preferences are modeled, they can be applied to change which hits are selected from a high-throughput screen and sent for confirmatory testing. For example, DOP relies on the observation that screeners are looking for active scaffolds more than they are looking for active molecules. In this study, both retrospective and prospective experiments demonstrate that DOP can increase the rate of scaffold discovery from 8% to 17%. DOP is robust to batch size, and can be applied even when using very large batch sizes common in HTS experiments. More accurate models of screeners&apos; preferences may prove even more useful.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Bioinformatics: The Machine Learning Approach</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Baldi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Brunak</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">The properties of known drugs. 1. Molecular frameworks</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">W</forename>
				<surname>Bemis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Murcko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Chem</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2887" to="2893" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Discovery of power-laws in chemical space</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Benz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Iinform. Model</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page">1138</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised data base clustering based on daylight&apos;s fingerprint and Tanimoto similarity: a fast and automated way to cluster small and large data sets</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Butina</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="747" to="750" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Detection and assignment of common scaffolds in project databases of lead molecules</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Clark</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Labute</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Chem</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="469" to="483" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Managing bias in ROC curves</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Clark</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Webster-Clark</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Aided Mol. Des</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="141" to="146" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Similarity searching and clustering of chemical-structure databases using molecular property data</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Downs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1094" to="1102" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page" from="26" to="49" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2277" to="2271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">Diversity-oriented prioritization</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Logistic regression and artificial neural network classification models: a methodology review</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dreiseitl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ohno-Machado</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="352" to="359" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">The minimum significant ratio: a statistical parameter to characterize the reproducibility of potency estimates from concentrationresponse assays and estimation by replicate-experiment studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Eastwood</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">253</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Enrichment of extremely noisy high-throughput screening data using a naive Bayes classifier</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Glick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">32</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Enrichment of high-throughput screening data with increasing levels of noise using support vector machines, recursive partitioning, and Laplacianmodified naive Bayesian classifiers</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Glick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Model</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="193" to="200" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimization of CAMD techniques 3. Virtual screening enrichment studies: a help or hindrance in tool selection?</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Good</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Oprea</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Aided Mol. Des</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="169" to="178" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Quantitative high-throughput screening: a titration-based approach that efficiently identifies biological activities in large chemical libraries</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Inglese</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA, 103</title>
		<meeting>. Natl Acad. Sci. USA, 103</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">11473</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Practical approaches to efficient screening: information-rich screening protocol</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Karnachi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Brown</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">678</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Assessment of the consistency of medicinal chemists in reviewing sets of compounds</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lajiness</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Chem</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="4891" to="4896" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Approximating expected utility by a function of mean and variance</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Levy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Markowitz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Econ. Rev</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="308" to="317" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">An efficient method for the detection and elimination of systematic error in high-throughput screening</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Makarenkov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">1648</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">What do we know and when do we know it?</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Nicholls</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Aided Mol. Des</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="239" to="255" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Enhanced HTS hit selection via a local hit rate analysis</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">A</forename>
				<surname>Posner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Model</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="2202" to="2210" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Design and analysis of experiments with high throughput biological assay data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rocke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Seminars in Cell and Developmental Biol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="703" to="713" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">The expected utility model: its variants, purposes, evidence and limitations</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Schoemaker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Lit</title>
		<imprint>
			<biblScope unit="page" from="529" to="563" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">The scaffold tree-visualization of the scaffold universe by hierarchical scaffold classification</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Schuffenhauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Model</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="47" to="58" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">ChemBank: a small-molecule screening and cheminformatics resource database</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Seiler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">351</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Enhancing the diversity of a corporate database using chemical database clustering and analysis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Shemetulskis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Aided Mol. Des</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">The optimal discovery procedure for large-scale significance testing, with applications to comparative microarray experiments</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Storey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">414</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">An economic framework to prioritize confirmatory tests after a high-throughput screen</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">J</forename>
				<surname>Swamidass</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="680" to="686" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Compound set enrichment: a novel approach to analysis of primary HTS data</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Varin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Model</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="277" to="279" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Similarity-based virtual screening using 2D fingerprints</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Willett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug Discov. Today</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1046" to="1053" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Novel statistical approach for primary high-throughput screening hit selection</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Yan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Inform. Model</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1784" to="1790" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Probing the primary screening efficiency by multiple replicate testing: a quantitative analysis of hit confirmation and false screening results of a biochemical assay</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="695" to="704" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>