
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequence analysis Adaptive reference-free compression of sequence quality scores</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Lilian</forename>
								<surname>Janin</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computational Biology Group</orgName>
								<orgName type="institution">Illumina Cambridge Ltd</orgName>
								<address>
									<addrLine>Little Chesterford</addrLine>
									<postCode>CB10 1XL</postCode>
									<settlement>Chesterford Research Park, Essex</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Giovanna</forename>
								<surname>Rosone</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Dipartimento di Matematica e Informatica</orgName>
								<orgName type="institution">University of Palermo</orgName>
								<address>
									<addrLine>Via Archirafi 34</addrLine>
									<postCode>90123</postCode>
									<settlement>Palermo</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Anthony</forename>
								<forename type="middle">J</forename>
								<surname>Cox</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computational Biology Group</orgName>
								<orgName type="institution">Illumina Cambridge Ltd</orgName>
								<address>
									<addrLine>Little Chesterford</addrLine>
									<postCode>CB10 1XL</postCode>
									<settlement>Chesterford Research Park, Essex</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sequence analysis Adaptive reference-free compression of sequence quality scores</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">1</biblScope>
							<biblScope unit="page" from="24" to="30"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt257</idno>
					<note type="submission">Received on March 17, 2013; revised on April 22, 2013; accepted on April 30, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Michael Brudno</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Rapid technological progress in DNA sequencing has stimulated interest in compressing the vast datasets that are now routinely produced. Relatively little attention has been paid to compressing the quality scores that are assigned to each sequence, even though these scores may be harder to compress than the sequences themselves. By aggregating a set of reads into a compressed index, we find that the majority of bases can be predicted from the sequence of bases that are adjacent to them and, hence, are likely to be less informative for variant calling or other applications. The quality scores for such bases are aggressively compressed, leaving a relatively small number at full resolution. As our approach relies directly on redundancy present in the reads, it does not need a reference sequence and is, therefore, applicable to data from metagenomics and de novo experiments as well as to re-sequencing data. Results: We show that a conservative smoothing strategy affecting 75% of the quality scores above Q2 leads to an overall quality score compression of 1 bit per value with a negligible effect on variant calling. A compression of 0.68 bit per quality value is achieved using a more aggressive smoothing strategy, again with a very small effect on variant calling. Availability: Code to construct the BWT and LCP-array on large genomic data sets is part of the BEETL library, available as a github repository at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The raw output of a DNA sequencer is converted by a program known as a base caller into nucleotide bases, each of which is typically assigned a quality score that estimates the probability that the base has been sequenced correctly. Quality scores have long been used to trim the low-quality ends of reads and for accurate consensus sequence determination (<ref type="bibr" target="#b6">Bonfield and Staden, 1995;</ref><ref type="bibr" target="#b23">Marth et al., 1999</ref>). More recently, they have enabled more accurate alignments of the shorter sequences produced by 'next-generation' technologies, by allowing the aligner to give lower weight to mismatches at less reliable base positions (<ref type="bibr" target="#b21">Li et al., 2008;</ref><ref type="bibr" target="#b27">Smith et al., 2008</ref>). Often quality scores are expressed on an integer scale derived from the error probability P via the formula À10log 10 p, a scoring scheme named after the Phred base caller (<ref type="bibr" target="#b13">Ewing and Green, 1998</ref>) that first used it.</p><p>The widely used FASTQ format (<ref type="bibr" target="#b8">Cock et al., 2010</ref>) stores the sequence and metadata of a set of DNA reads as ASCII text, together with one-character-per-score quality strings that encode the Phred scores of their bases. The different properties of these three data types have meant that many FASTQ compression methods have treated them as three distinct data streams and applied separate compression strategies to each. The metadata field tends to be formatted in ways that are specific to the technology that was used to generate the sequence, and some FASTQ compressors have exploited such structure to improve compression. However, there is no global format specification for the metadata; therefore, any universally applicable method for its compression must necessarily be a generic exercise in the compression of ASCII text. Although standard text compressors, such as gzip (www.gzip. org, Jean-loup Gailly and Mark Adler), do not significantly outperform a naı¨venaı¨ve 2 bits per base encoding on DNA sequence data, applications such as re-sequencing and de novo assembly typically rely on a 20-fold or more oversampling of the underlying genome, and this redundancy can be exploited to improve compression of the sequences themselves. Reference-based compression tools, such as CRAM (<ref type="bibr" target="#b14">Fritz et al., 2011</ref>), encode reads in terms of differences between their sequences, and the sites they align to on a reference sequence. Sorting the reads by the coordinates of these alignments saves most of the overhead of storing their positions and is a convenient ordering for applications, such as SNP calling and visualization. Despite these advantages, reference-based compression suffers when the reference is incomplete (reads that do not align cannot be compressed), subject to change or not present at all (as in metagenomics), motivating an interest in reference-free compression methods. The tool QUIP (<ref type="bibr" target="#b17">Jones et al., 2012</ref>) creates an onthe-fly de novo assembly to perform reference-based compression against, whereas SCALCE (<ref type="bibr" target="#b15">Hach et al., 2012</ref>) places similar reads near to each other in a sorted file, facilitating good performance by standard tools such as gzip that operate on a buffer of text at a time. Another widely used generic compression tool bzip2 (www. bzip.org, Julian Seward) exemplifies Burrows–Wheeler transform (BWT) compression: text is split into 900 kb blocks, and the BWT of each block is computed. The BWT is a reversible permutation of the text that acts as a compression booster for the pipeline of standard compression steps that bzip2 subsequently applies. In<ref type="bibr" target="#b9">Cox et al. (2012a)</ref>, two of the present authors showed that although bzip2 performs comparably with gzip on DNA sequence reads, the compression achieved by BWT-based methods improves by 43-fold if the BWT of the entire read set is built, as *To whom correspondence should be addressed. this captures redundancy between reads that were widely spaced in the original file. It was shown that compression can be further boosted by pre-sorting the reads or applying an implicit sorting strategy while the BWT is being built, enabling compression of better than 0.5 bits per base to be achieved. Lossless approaches to the compression of quality scores have exploited empirical relationships between the scores assigned to bases within a read: for instance, Illumina quality scores tend to be monotone decreasing along a read with a decrease in scores between adjacent bases that is usually small. An overreliance on such observations potentially ties a compression scheme to a given sequencing technology and makes it sensitive to changes in sequencing protocol. Moreover, it is likely that Illumina quality scores at their full resolution contain a proportion of random noise that is impossible to compress: striking evidence for this is given by<ref type="figure">Table 4</ref>in Bonfield and Mahoney (2013), which shows multiple entrants to the SequenceSqueeze competition for FASTQ compression achieving similar lossless compressions of $2.94 bits per score on a test dataset, but that no entrants were able to improve on this figure. It is undesirable that when compressed, the quality scores should take up several times more space than the sequences themselves; therefore, we are led to consider compressing them in a lossy way.<ref type="bibr" target="#b18">Kozanitis et al. (2010)</ref>found that a global reduction in the resolution of the scores from 40 to 8 values (thus permitting each score to be stored in 3 bits) had no significant impact on the quality of variant calls, whereas strategies for global re-quantization of quality scores were studied in more detail by<ref type="bibr" target="#b28">Wan et al. (2012)</ref>. However, treating all scores in the same way ignores the fact that most of them could likely be reduced in resolution or even discarded entirely with little impact on our ultimate goal of ensuring that analyses performed with the reduced scores closely reflect the results obtained from the original data. In a human re-sequencing context, for example, if a large coverage of highquality bases unanimously supports a homozygous match to the reference genome, then a confident call can be made without the full-resolution quality scores of each individual base needing to be kept. With this in mind, CRAM allows an adaptive approach where only quality scores that contribute to variant calls that do not match the reference are kept. This enables the vast majority of scores to be omitted, but it means compression cannot take place until analysis has been finalized. This means any preanalysis transfer or storage of the data will not benefit from compression and is potentially problematic if the data subsequently need to be re-analysed. Here, we present an adaptive and reference-free approach to lossy quality-score compression. Our central premise is that if a base in a read can, with high probability, be predicted by the context of bases that are next to it, then the base itself is imparting little additional information, and its quality score can be discarded or aggressively compressed at little detriment to downstream analysis. Such predictions are made by considering all possible contexts present in the reads: if every occurrence of some string Q is followed by the same character p then the presence of a context Q in a read can be said to predict that p will come next. In the rest of this article, we formalize this intuition and give algorithms that use the BWT of a set of reads to identify non-essential quality scores. The BWT places all characters that precede a given context next to each other in a permuted string, whereas another standard data structure the longest common prefix array (LCP) then allows stretches of characters that precede contexts of a given length to be enumerated in a single pass through the two data structures. This enables the majority of scores to be smoothed to an average value, greatly improving compression. We derive a formula to quantify the information lost during this smoothing process and justify our compression scheme empirically by showing that results using the compressed scores closely match the original data when our scheme is applied to whole-genome re-sequencing data. We also show that we can use the BWT alone to compress quality scores in a way that is almost as effective as BWT/LCP compression, thus avoiding the overhead of computing the LCP array. Moreover, we demonstrate that our methods can be used in tandem with other approaches to boost the compression obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definitions</head><p>Given a string s of k symbols drawn from some finite ordered alphabet AE, we mark the end of s by appending an additional end marker $ such that $5c for any symbol c in AE. Starting at each position of s and reading rightwards, we obtain k þ 1 distinct suffixes. We say that each suffix is associated with the character that precedes it in s (one such suffix comprises the entirety of s, for which we 'wrap around' and associate it with $). Ordering the suffixes of s alphabetically then replacing them by their associated symbols defines a permutation s ! BWTðsÞ of the symbols of s known as the BWT of s (<ref type="bibr" target="#b7">Burrows and Wheeler, 1994</ref>). Perhaps the two most important of its many interesting properties are that the BWT is reversible, in the sense that s can be reconstructed from BWTðsÞ with no additional information (<ref type="bibr" target="#b0">Adjeroh et al., 2008</ref>) and the clustering effect of the produced output, i.e. BWT tends to group together characters that occur in similar contexts in the input text, making the output more compressible even by simple compressors (for instance see<ref type="bibr" target="#b24">Restivo and Rosone, 2011</ref>). A way to generalize the BWT to a set S ¼ fs 1 , s 2 ,. .. , s n g of strings is simply to append distinct end markers $ i to each s i such that $ 1 5. .. 5$ n 5c for any c in AE. For a single string, the permutation s ! BWTðsÞ provides a relation to the suffix array of s, which is defined by applying the same permutation to the integers 0,. .. , jsj À 1, so as to arrange the starting positions of the suffixes of s into lexicographical order. The BWT of a collection is related to its generalized suffix array in an analogous way. Formally, the GSA is defined such that GSAðSÞ½j gives the position of the jth smallest suffix of the strings in S, which is encoded as a pair ðt, iÞ denoting that the suffix starts at position t of s i. In particular, if GSAðSÞ½j ¼ ðt, iÞ then BWTðSÞ½j ¼ s i ½ðt À 1Þmodjs i j. Now we suppose the elements of S are DNA sequences that are accompanied by strings Q ¼ fq 1 , q 2 ,. .. , q n g such that the symbol q i ½j encodes the quality score of s i ½j—the alphabet used by Q and the means of encoding are not relevant at this point. We apply the same permutation S ! BWTðSÞ to Q (which we emphasize is not the same as computing the BWT of Q itself) to obtain a string QV such that QV½i encodes the quality score associated with the symbol BWTðSÞ½i. The longest common prefix array (denoted by LCP) of a collection S of strings stores the length of the longest common prefixes between two consecutive suffixes of S in the lexicographic order. For every j ¼ 1,. .. , n À 1, if GSAðSÞ½j À 1 ¼ ðp 1 , p 2 Þ and GSAðSÞ½j ¼ ðq 1 , q 2 Þ, LCPðSÞ½j is the length of the longest common prefix of suffixes starting at positions p 1 and q 1 of the words s p2 and s q2 , respectively. We set LCPðSÞ½0 ¼ 0. Note that we do not need to compute explicitly the generalized suffix array to obtain the BWT and LCP. Methods suitable for computing BWTðSÞ and LCPðSÞ where S is a large collection of DNA sequences and without the use of the GSA of S were given in<ref type="bibr" target="#b2">Bauer et al., (2011</ref><ref type="bibr" target="#b3">Bauer et al., ( , 2012</ref><ref type="bibr" target="#b4">Bauer et al., ( , 2013</ref>), and it is straightforward to adapt them to compute QV at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Smoothing strategy</head><p>A crucial consequence of the definition of the BWT is that the symbols associated with suffixes that begin with some string w will form a contiguous substring in BWTðSÞ, we call this the w-interval. If all symbols in the w-interval take the same value c, then every occurrence of w in S is preceded by c: seeing w in a read predicts that c will come before it. For a fixed length k, a linear scan through the LCP array allows us to identify LCP-intervals, which are maximal intervals ½i, j that satisfy LCP½r ! k for i r j and whose associated suffixes, therefore, share at least the first k bases. We set thresholds on the minimum length of the predicting context k and the minimum number of times j À i þ 1 it must occur in S. If these are both exceeded and the symbols in BWTðSÞ½i, j are all the same, then we smooth the corresponding quality scores in QVðSÞ½i, j. As each score in QVðSÞ½i, j implies an error probability for its associated base, one way to do the smoothing would be to take the mean of these error rates across QVðSÞ½i, j and convert this to a score with which we replace all scores in QVðSÞ½i, j (which we note is not the same as taking the mean of the scores). However, better compression is obtained by replacing the smoothed scores with the score implied by the mean error rate of all bases whose scores are smoothed. Moreover, we empirically observed that almost as good results are achieved just by smoothing all quality scores in QV that are associated with runs of a given symbol in BWTðSÞ whose lengths exceed a threshold, which has the practical benefit of not needing the LCP array.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Measuring the information loss because of smoothing</head><p>The probability distribution of a randomly chosen symbol from a string s is pðsÞ ¼ ðn 1 =jsj,. .. , n jAEj =jsjÞ, where n 1 ,. .. , n jAEj count the occurrences of the symbols of AE in s. Applying the Shannon entropy transformation</p><formula>H : ðp 1 ,. .. , p n Þ ! À P i p i logðp i Þ</formula><p>to this distribution (<ref type="bibr" target="#b25">Shannon, 1948</ref>) yields</p><formula>H 0 ðsÞ ¼ HðpðsÞÞ ¼ À X i2AE n i jsj log n i jsj , ð1Þ</formula><p>a quantity known as the zero-order empirical entropy of s (we assume 0 log 0 ¼ 0 and adopt the convention that all logarithms are taken to the base 2). Let bðw, sÞ be the string formed by concatenating the symbols that immediately precede the occurrences of some substring w of s. For a positive integer k, we define the kth order empirical entropy of s as</p><formula>H k ðsÞ ¼ 1 jsj X w2AE k jbðw, sÞjH 0 ðbðw, sÞÞ ¼ 1 jsj X w2AE k jbðw, sÞjHðpðbðw, sÞÞÞ: ð2Þ</formula><p>This can be thought of as the mean entropy across all symbols of s when a context of k bases is taken into consideration. The computations of H 0 ðSÞ and H k ðSÞ for a collection S are identical to the single-string case. We note here the connection with BWTðSÞ and LCPðSÞ: the strings bðw, SÞ form disjoint substrings in BWTðSÞ whose order in the BWT matches the lexicographic order of their associated k-mers w (see also<ref type="bibr" target="#b22">Manzini, 2001</ref>). The coordinates of the strings bðw, SÞ in S are precisely the LCP-intervals of length k, which we have observed can be computed by a single pass through LCPðSÞ. We can view H 0 ðbðw, SÞÞ as the Shannon entropy of the distribution pðbðw, SÞÞ obtained by assuming each symbol of bðw, SÞ is exactly known (so that e.g. a 'G' corresponds to a distribution pðA, C, G, TÞ ¼ ð0, 0, 1, 0Þ) and then computing the mean of these distributions across all symbols of bðw, SÞ. With this in mind, we can generalize H 0 ðbðw, SÞÞ to imprecisely known symbols by replacing these exact symbol-level distributions with the ones that are implied by the quality values that are associated with the elements of bðw, SÞ. For example, a Q20 'G' receives a distribution pðA, C, G, TÞ ¼ ð0:01=3, 0:01=3, 0:99, 0:01=3Þ—we assume the three error bases are equiprobable. Taking the mean of these gives a new 'quality-aware' distribution qðbðw, SÞ, QÞ for the symbol expected to precede w, from which we can compute modified entropy H 0 ðbðw, SÞ, QÞ ¼ Hðqðbðw, SÞ, QÞ via the Shannon formula. This in turn implies a generalization of the kth order empirical entropy:</p><formula>H k ðS, QÞ ¼ 1 jSj X w2AE k jbðw, SÞjH 0 ðbðw, SÞ, QÞ ¼ 1 jSj X w2AE k jbðw, SÞjHðqðbðw, sÞ, QÞÞ: ð3Þ</formula><p>We give two ways to describe the effect of smoothing Q to obtain a new set of scores Q 0. First, the improvement in compression is measured by comparing the size of the files produced when standard compression tools are applied to the BWT-permuted quality scores QV and QV 0. Second, the information loss is quantified by the relative entropy (or Kullback-Liebler divergence), which measures the information loss when a distribution p 0 ¼ ðp 0 1 ,. .. , p 0 n Þ is used to approximate a distribution p ¼ ðp 1 ,. .. , p n Þ and is defined by</p><formula>REðpjjp 0 Þ ¼ X i p i log p i p 0 i : ð4Þ</formula><p>In much the same way as H k ðSÞ is defined from H 0 ðSÞ, we may define the kth order empirical relative entropy REðQjjQ 0 Þ as (see also<ref type="bibr" target="#b12">Epifanio et al., 2011</ref>)</p><formula>1 jSj X w2AE k jbðw</formula><p>, SÞjREðqðbðw, SÞ, QÞjjqðbðw, SÞ, Q 0 ÞÞ ð5Þ</p><p>Similar to H k ðSÞ, a single pass through LCPðSÞ allows us to compute REðQjjQ 0 Þ by enumerating the w-intervals associated with each k-mer: this time, we need the w-intervals in BWTðSÞ plus the corresponding scores in QV and QV 0 to compute the terms REðqðbðw, SÞ, QÞjjqðbðw, SÞ, Q 0 ÞÞ. Given two smoothings Q ! Q 0 and Q ! Q 00 , the smaller of REðQjjQ 0 Þ and REðQjjQ 00 Þ suggests the smallest loss in information content. It can be verified that REðQjjQ 0 Þ ! 0 and that REðQjjQ 0 Þ is only zero when the distributions qðbðw, SÞ, QÞ and qðbðw, SÞ, Q 0 Þ are identical for all k-mers w in S. The smoothing scheme we gave in Section 2.2 can be understood in this context. If all of bðw, SÞ support the same base call, then it must be true that qðbðw, SÞ, QÞ assigns some probability p to that call and probability 1 À p=3 to the remaining bases. Replacing all the quality scores in bðw, SÞ with the score corresponding to p will create a smoothed set of scores Q 0 for which qðbðw, SÞ, QÞ ¼ qðbðw, SÞ, Q 0 Þ; hence, REðQjjQ 0 Þ ¼ 0. In practice, the integer nature of the Phred scoring scheme means the value used to overwrite the smoothed scores will typically be a slight approximation to the score that corresponds to p. However, we found that p did not vary much between different intervals bðw, SÞ, and that small changes to its value had little effect on results. We, therefore, chose to improve compression by replacing all smoothed scores with a globally chosen replacement value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parameter sweep</head><p>Using Caenorhabditis elegans data allowed us to study the effect of compression on variant calls made using whole-genome shotgun sequences from a diploid genome, while permitting more extensive parameter sweeps than would be tractable for human data. We chose a dataset SRR065390_1 comprising 33 808 546 reads of length 100 (33:6Â coverage of the genome) that has been previously studied by the Sequence Squeeze entrants. For our computational pipeline, we chose bwa [bwa version 0.6.1 with parameters-t 12-q 15 (<ref type="bibr" target="#b20">Li and Durbin, 2009</ref>)] followed by GATK [GATK version 1.6 (<ref type="bibr" target="#b11">DePristo et al., 2011)]</ref>. Only the variants marked as 'PASS' by GATK (using UnifiedGenotyper and Variant Quality Score Recalibration) are considered. We treat the results of this pipeline on uncompressed data as 'ground truth' (i.e. we do not try to distinguish false positive or false negative calls in the uncompressed data, as we would on a simulated dataset), as we wish results derived from compressed data to reflect the original data as closely as possible. We chose to measure the proportion of reads that were differentially mapped and the proportion of variant calls that were different. We calculated sensitivity and specificity values and combined the two into an F-statistic. Qualities are distributed as shown in<ref type="figure" target="#fig_0">Figure 1</ref>. We notice an overrepresentation of Q2 scores (8.3%) because of end-of-reads trimming. A negligible number of 'N' bases (0.07%) are also associated to Q0 scores. We verified that better results were obtained when these Q0 and Q2 scores were conserved, and all the results presented later in the text keep these two Q scores unchanged. To gain an idea of 'worst case scenario' behaviour, we first computed the mean estimate error rate by converting each quality score (ignoring Q0 and Q2) to an error probability, taking the mean of these values and converting back to Phred score (which we note is not the same as taking the mean of the quality scores). We obtained a mean Q score of 28.36 (as a comparison, the mean of the Q scores is 32.74). We then replaced every Q score by this mean value and reran our pipeline. This caused 15% of variant calls to change (2.3% missing calls and 12.7% new variants calls), also characterized by the worst-case F-score of 92.8%. We then compressed the quality scores using various values for the two parameters of our quality smoothing algorithm: LCP cut threshold and minimum stretch length. All stretches (in BWT-space) of same BWT letter longer than (or equal to) the minimum stretch length, and for which the LCP value stays above (or equal to) the LCP cut threshold gets 'smoothed', i.e. its associated qualities get reset to a constant quality score value (except for Q0 and Q2, which stay at their current values but are still allowed to contribute to stretches). In theory, as each set of parameters leads to different numbers of quality values being smoothed, the average Q score that should be used as a replacement should not be constant across runs: to strictly follow the Q score definition associated with error rates, we recalculated for each run the Q score that would lead to the same mean error rate and used it as a replacement. However, we noticed that it only varied between 28.36 and 30.46, and that its effect on variant calling was negligible. For this reason, the results presented below are using a fixed replacement Q score of 29 for all runs.<ref type="figure" target="#tab_1">Table 1</ref>summarizes the results obtained for a sweep of parameters. In this table, the results of the 'LCP-free' smoothing appears when 'LCP cut threshold ¼ 0'. For each combination of parameters, we compressed the BWT-ordered smoothed qualities using bzip2 and 7-Zip's PPMd algorithm (7-Zip with parameters-m0 ¼ PPMd; http://www.7-zip.org). The 7-Zip compression was always better and is the one reported in the table, in bits per quality value, in BWT-space (column 3) and in readspace (column 4). We also calculated F-scores (column 5) based on the number of false-positive and false-negative variant calls. We notice that minimum stretch length is the parameter having the most influence on both the compression rate and the fidelity of variant calling. A minimum stretch length of 10, meaning that 10 consecutive identical BWT letters must share the same following k-mer (whose length depends on the LCP cut threshold) to get smoothed, already leads to 76% of the qualities getting replaced (excluding Q0 and Q2). In this situation, the quality string in BWT-space gets compressed at 1.28 bits per quality value, and in read-space (i.e. same as the original FASTQ) at 1 bit per base. The effect on variant calling is minimal, as the F-score of 99% corresponds to 30 variants getting missed (i.e. false negatives) from the original 3208 called and 40 variants being created (i.e. false positives). However, in all the cases, the false-negative and false-positive calls are present in the opposite variants file but did not pass filter because of a quality slightly below the required threshold. The LCP cut threshold has marginal effect on both the compression rate and the variant calling. In fact, it has unpredictable effect on variant calling, where reduction of the threshold sometimes leads to slightly better and sometimes to slightly worse results. An interesting observation is that reducing the LCP cut threshold to zero, i.e. when the LCP value is not used at all, does not affect the results as negatively as we expected: in this situation, any stretch of consecutive identical BWT letters gets smoothed even if the letters do not share a common following k-mer (as the minimal length of this k-mer is zero). This is explained by the relatively low number of occurrences of such stretches:<ref type="figure" target="#tab_1">Table 1</ref>column 3 reveals that only 0.2% of the bases get affected by a change of LCP cut threshold from 5 to 0 in the most interesting case where min stretch length is 5. Another interesting observation is the better compression obtained in read-space than in BWT-space. This is explained by thetendency for bases to stay constant from one cycle to the next (a property observable in read-space), but do not have any reason to stay constant across reads sharing the same suffix. This makes compression in BWT-space more difficult. We also wished to verify that randomly smoothing qualities had a more detrimental effect on variant calling. Based on the distribution of smoothed stretch lengths obtained with LCP cut threshold ¼ 5 and minimal stretch length ¼ 5, we smoothed random stretches of the original dataset in such a way as to achieve the same final distribution. After running our computational pipeline on this randomly smoothed dataset, we obtained the statistics shown in<ref type="figure">Table 2</ref>: same compressibility in BWTspace, but much worse in read-space, and worse variant calling F-score. The lower compressibility in read space is explained by the fact that the qualities being replaced are now distributed less consecutively than before in read space: our smoothing strategy, even though applied in BWT space, is occurring at specific places that are permuted into consecutive positions in read space. Instead, the smoothing of random BWT stretches does not get permutated into consecutive positions in read space and leads to a worse compression rate. It can be noted that some compression still happens because 85.9% of the qualities, which had various values before smoothing, are reduced to a single value and, therefore, become more compressible. Finally,<ref type="figure" target="#fig_1">Figure 2</ref>depicts the kth order relative entropy between the full-resolution quality scores and a subset of the compression schemes mentioned in Tables 1 and 2. We would expect the worst-case information loss to occur when all quality scores are replaced by a constant value and the 'c0s1' curve behaves accordingly, exhibiting the highest relative entropy. The 'c5s5' and 'c5s10' curves correspond to the 'stretch length 5' and 'stretch length 10' entries in<ref type="figure" target="#tab_1">Table 1</ref>for an LCP cut threshold of 5. As we would expect, the more aggressive of the two schemes 'c5s5' has higher relative entropy with respect to the original scores, suggesting a greater loss of information. The curve for 'c5s5' contrasts with the 'c5s5 (rand)' curve for the randomly smoothed dataset compared with it in<ref type="figure">Table 2</ref>. Although<ref type="figure">Table 2</ref>shows nearly identical compression for the two datasets,<ref type="figure" target="#fig_1">Figure 2</ref>reveals that randomly smoothing the quality scores has caused a much greater loss of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Details and re-quantization</head><p>The F-scores presented in the previous section, although good at summarizing the overall impact of compression on variant calling, are abstracting away some important details. In this section, we use QQ plots to show the correlation between variant call qualities (QUAL field reported by GATK) with and without compression. These QQ plots are also highlighting someOriginal cut5 stretch5 1.06 0.68 97.8 R a n d o m s a m e d i s t. 1. 0 5 1. 0 9 9 4. 8 interesting differences between our BWT-based compression strategy and the re-quantization strategy (reduction from 40 to 8 quality scores) at similar compression and F-score rates. Considering our smoothing strategy with parameters (cut threshold ¼ 5, min stretch length ¼ 10), which was leading to a compression rate of 1.28 bits/Q in BWT space and 0.99 bit/Q in read space and was associated to a F-score of 99.1%,<ref type="figure" target="#fig_2">Figure 3</ref>shows for each variant called its quality before (x-axis) and after compression (y-axis). We distinguish three classes of variants: true positives (TP) are those called as 'passing filter' (as defined by GATK) before and after compression; false positives (FP) are those passing filter after compression but not before; false negatives (FN) are those passing filter before compression but not after. FP and FN calls, although passing filter in only one of the two GATK runs, always happen to be present in both call sets, allowing us to plot their quality values.<ref type="figure" target="#fig_2">Figure 3</ref>shows 36 FP, 25 FN and 3183 TP calls. We notice that the majority of stray points are FP calls whose quality has been enhanced by our algorithm. In fact, all the qualities considered in this QQ plot, before and after compression, are above the filter threshold of quality 30 (the x-and y-axis start at Q ¼ 30). The reason for calls not passing filter in the original dataset is most often because of the LowQD filter, but a direct link to the aligner's mapping quality of reads or number thereof has not been established. For comparison with another compression strategy,<ref type="figure" target="#fig_3">Figure 4</ref>shows the QQ plot obtained after re-quantization of the original dataset to eight Qscore bins. This led to the same compression rate as the c5s10 strategy (which was in fact chosen for this reason): 1.29 bits/Q in BWT space. The F-score of requantization, 98.8%, was also similar to c5s10's. However, requantization achieves this F-score with 27 FP, 51 FN and 3157 TP calls, which is much more biased towards FN, whereas c5s10 (and all our other observed results from this smoothing strategy) was more pronounced towards FP. Because of the dataset used in this article, we have not reached any conclusion regarding the quality of those FP and FN calls: some FP calls may introduce real false-positive calls, whereas others may reveal some real variants that had not been called in the original dataset. Similarly, re-quantization's FN calls may be correct pruning of previously incorrect calls, as well as real false negatives. We intend to run the same analysis on a simulated dataset where we will have previous knowledge of the correctness of calls. Finally,<ref type="figure" target="#fig_4">Figure 5</ref>shows the distribution of 108 FP, 44 FN and 3164 TP obtained with c0s5 smoothing. Relatively to c5s10, the number of FP increases faster than the number of FN, and this trend continues when we push the smoothing parameters towards lower min stretch size and higher compression rates. Also, confirming an expected behaviour, the FP calls present after c5s10 smoothing are still present as FP calls after the more compressed c0s5 smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>This article aims to introduce the general idea of smoothing quality scores based on the BWT and LCP of their associated reads. Section 2.2 describes perhaps the simplest and most conservative approach to this, but the theoretical framework presented in Section 2.3 allows comparison of future more sophisticated quality smoothing strategies. Note that the effect of smoothing or otherwise adjusting the quality scores is to change the weightings of the different nucleotides in the distributions Xðw, QVÞ. We can take a step further and consider adjusting low-probability bases in Xðw, QVÞ to zero. Our work can thus be extended to a new quality-based view on de novo error correction that may provide an interesting alternative to existing approaches, many of which are based on the counting of k-mers (as surveyed by<ref type="bibr" target="#b29">Yang et al., 2013</ref>). Such a strategy could be thought of as a quality-aware extension of the HiTEC algorithm (<ref type="bibr" target="#b16">Ilie et al., 2011</ref>), while enjoying the considerable space advantage of being based on a (potentially compressed) BWT instead of a suffix array. Although it is an advantage that the relative entropy measures the information lost by quality smoothing in an application-neutral way, we also recognize that a single numerical quantity cannot fully model the effect of quality smoothing on the often complex multi-step analysis pipelines that are applied to sequence data. We investigated this by measuring the effect of smoothed quality scores on the results of widely accepted tools for a well-understood application. Transforming the smoothed scores back into their original reads added a significant boost to the compression already achieved by 7-Zip from exploiting similarities between the quality scores of individual read. It is equally simple to combine our approach with the application to the unsmoothed scores of one of the lossy re-quantization schemes studied by<ref type="bibr" target="#b28">Wan et al. (2012)</ref>. However, using our method in this way involves building the BWT (and possibly LCP) of a set of reads and then applying the inverse BWT permutation to the quality scores to obtain a smoothed quality string for each read. The overhead of these tasks may limit its practicality for downstream applications that operate on reads and does not use the potential of the BWT. As well as allowing excellent lossless compression, storing sequences in BWT form also facilitates rapid analysis: the sga (<ref type="bibr" target="#b26">Simpson and Durbin, 2012</ref>) and Fermi (<ref type="bibr" target="#b19">Li, 2012</ref>) assemblers both operate directly on BWT-based compressed indexes of sets of reads, and we ourselves have shown that similar data structures can be the basis of both RNA-Seq (<ref type="bibr" target="#b10">Cox et al., 2012b</ref>) and metagenomic (<ref type="bibr" target="#b1">Ander et al., 2013</ref>) analyses. Although the compression achieved on BWT-space reads is less than in read-space (although the difference may be less clear-cut on a dataset where the Q2-masking of read ends is less prevalent or has been switched off), we, therefore, envisage that a key application of our work is to allow quality scores to be used in a BWT-space context while being stored in as compact a manner as the reads themselves. Conflict of Interest: L.J. and A.J.C. are employees of Illumina Inc., a public company that develops and markets systems for genetic analysis. They receive shares as part of their compensation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Histogram of C.elegans SRR065390_1 Q scores</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. The kth order empirical relative entropy between the original and compressed quality scores of SRR065390_1, for various quality-score compression schemes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Correlation of variant call qualities before/after c5s10 compression</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. Correlation of variant call qualities before/after re-quantization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.5.</head><figDesc>Fig. 5. Correlation of variant call qualities before/after c0s5 compression</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Statistics after quality smoothing</figDesc><table>LCP cut threshold 
Min stretch length 
%Q3 þ cut 
BWT-space 
compress (bits/Q) a 

Read-space 
compress (bits/Q) b 

Variant calling 
F-score (%) 

Uncut 
0 
2.51 
1.67 
100 
10 
10 
76.7 
1.28 
1.00 
99.1 
5 
10 
76.8 
1.28 
0.99 
99.1 
0 c 
10 
76.8 
1.28 
0.99 
98.8 
5 
5 
85.9 
1.06 
0.68 
97.8 
1 
5 
86.1 
1.06 
0.68 
97.9 
0 c 
5 
86.1 
1.06 
0.68 
97.7 
5 
1 
96.9 
0.50 
0.20 
92.3 
1 
1 
99.3 
0.39 
0.11 
92.9 
0 c,d 
1 
100 
0.37 
0.06 
92.8 

a 

Compression in BWT-space in bits per quality value. b Compression in read space (i.e. same as FastQ file) in bits per quality value. c LCP cut threshold ¼ 0 does not use LCP. 

d 

All cut except Q0 and Q2, which are kept intact in all cases. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2. Comparison with random smoothing of same stretch lengths distribution</figDesc><table>Smoothing strategy 
BWT-space 
compression 
(bits/Q) 

Read-space 
compression 
(bits/Q) 

Variant 
calling 
F-score (%) 

</table></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Adaptive reference-free compression of sequence quality scores at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">L.Janin et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">The Burrows-Wheeler Transform: Data Compression, Suffix Arrays, and Pattern Matching</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Adjeroh</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer Publishing Company</publisher>
		</imprint>
	</monogr>
	<note>1st. edn</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">metaBEETL: high-throughput analysis of heterogeneous microbial populations from shotgun DNA sequences</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ander</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="14" to="16" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Suppl. . 5</note>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Lightweight BWT construction for very large string collections</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<editor>CPM 2011</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6661</biblScope>
			<biblScope unit="page" from="219" to="231" />
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Lightweight LCP construction for next-generation sequencing datasets</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WABI 2012</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="326" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Lightweight algorithms for constructing and inverting the BWT of string collections</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">483</biblScope>
			<biblScope unit="page" from="134" to="148" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Compression of FASTQ and SAM format sequencing data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">K</forename>
				<surname>Bonfield</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">V</forename>
				<surname>Mahoney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">59190</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">The application of numerical estimates of base calling accuracy to DNA sequencing projects</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">K</forename>
				<surname>Bonfield</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Staden</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1406" to="1410" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">A block sorting data compression algorithm</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Burrows</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Wheeler</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">The sanger FASTQ file format for sequences with quality scores, and the Solexa/Illumina FASTQ variants</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Cock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1767" to="1771" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale compression of genomic sequence databases with the Burrows-Wheeler transform</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1415" to="1419" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Comparing DNA sequence collections by direct comparison of compressed text indexes</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Cox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WABI 2012</title>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="214" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A framework for variation discovery and genotyping using next-generation DNA sequencing data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Depristo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="491" to="498" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Novel Combinatorial and Information-Theoretic AlignmentFree Distances for Biological Data Mining</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Epifanio</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<biblScope unit="page" from="321" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Base-calling of automated sequencer traces using Phred. II. error probabilities</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Ewing</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Green</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="186" to="194" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient storage of high throughput DNA sequencing data using reference-based compression</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">H</forename>
				<surname>Fritz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="734" to="740" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">SCALCE: boosting sequence compression algorithms using locally consistent encoding</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Hach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3051" to="3057" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">HiTEC: accurate error correction in high-throughput sequencing data</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ilie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="295" to="302" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Compression of next-generation sequencing reads aided by highly efficient de novo assembly</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">C</forename>
				<surname>Jones</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Compressing genomic sequence fragments using SlimGene</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kozanitis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6044</biblScope>
			<biblScope unit="page" from="310" to="324" />
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploring single-sample SNP and INDEL calling with whole-genome de novo assembly</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1838" to="1844" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast and accurate short read alignment with BurrowsWheeler transform</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1754" to="1760" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Mapping short DNA sequencing reads and calling variants using mapping quality scores</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1851" to="1858" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">An analysis of the Burrows-Wheeler transform</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Manzini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. ACM</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="407" to="430" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A general approach to single-nucleotide polymorphism discovery</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">T</forename>
				<surname>Marth</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="452" to="456" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Balancing and clustering of words in the BurrowsWheeler transform</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Restivo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Rosone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">412</biblScope>
			<biblScope unit="page" from="3019" to="3032" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">A mathematical theory of communication</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">E</forename>
				<surname>Shannon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Syst. Tech.ical J</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="379" to="423" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient de novo assembly of large genomes using compressed data structures</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="549" to="556" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Using quality scores and longer reads improves accuracy of Solexa read mapping</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">128</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Transformations for the compression of FASTQ quality scores of next-generation sequencing data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Wan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="628" to="635" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">A survey of error-correction methods for next-generation sequencing</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="56" to="66" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>