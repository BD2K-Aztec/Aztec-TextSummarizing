
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PANNZER: high-throughput functional annotation of uncharacterized proteins in an error-prone environment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Patrik</forename>
								<surname>Koskinen</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosciences</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<postCode>00014</postCode>
									<settlement>Helsinki</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Petri</forename>
								<surname>Tö Rö Nen</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Biotechnology</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<postCode>00014</postCode>
									<settlement>Helsinki</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jussi</forename>
								<surname>Nokso-Koivisto</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Biotechnology</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<postCode>00014</postCode>
									<settlement>Helsinki</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Liisa</forename>
								<surname>Holm</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biosciences</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<postCode>00014</postCode>
									<settlement>Helsinki</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Biotechnology</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<postCode>00014</postCode>
									<settlement>Helsinki</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PANNZER: high-throughput functional annotation of uncharacterized proteins in an error-prone environment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu851</idno>
					<note type="submission">Received on June 17, 2014; revised on December 11, 2014; accepted on December 24, 2014</note>
					<note>Sequence analysis *To whom correspondence should be addressed Associate Editor: John Hancock † The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors. Contact: patrik.koskinen@helsinki.fi Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The last decade has seen a remarkable growth in protein databases. This growth comes at a price: a growing number of submitted protein sequences lack functional annotation. Approximately 32% of sequences submitted to the most comprehensive protein database UniProtKB are labelled as &apos;Unknown protein&apos; or alike. Also the functionally annotated parts are reported to contain 30–40% of errors. Here, we introduce a high-throughput tool for more reliable functional annotation called Protein ANNotation with Z-score (PANNZER). PANNZER predicts Gene Ontology (GO) classes and free text descriptions about protein functionality. PANNZER uses weighted k-nearest neighbour methods with statistical testing to maximize the reliability of a functional annotation. Results: Our results in free text description line prediction show that we outperformed all competing methods with a clear margin. In GO prediction we show clear improvement to our older method that performed well in CAFA 2011 challenge. Availability and implementation: The PANNZER program was developed using the Python programming language (Version 2.6). The stand-alone installation of the PANNZER requires MySQL database for data storage and the BLAST (BLASTALL v.2.2.21) tools for the sequence similarity search. The tutorial, evaluation test sets and results are available on the PANNZER web site. PANNZER is freely available at http://ekhidna.biocenter.helsinki.fi/pannzer.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A correctly annotated proteome is the cornerstone of a successful genome research project and therefore accurate and reliable functional annotation tools are needed. However, due to the huge amount of various sequence data and diverse methods used in the functional annotation processes, a large part of these sequences are at risk of being annotated incorrectly (<ref type="bibr" target="#b9">Hadley, 2003;</ref><ref type="bibr" target="#b19">Naumoff et al., 2004;</ref><ref type="bibr" target="#b22">Punta and Ofran, 2008</ref>). The last decade has seen an explosion in the number of genomes being sequenced, and the near future will increase the number far higher. Experimental characterization is not a viable option for<ref type="bibr" target="#b29">Schnoes et al., 2013</ref>). Low-throughput methods are time consuming, complex and expensive and therefore restricted only to small subsets of proteins of interest (<ref type="bibr" target="#b25">Sboner et al., 2011</ref>). Annotations are also generated by biocurators by interpretation of experiments from literature. The quality of these literature-based annotations relies heavily on the expertise of biocurators (<ref type="bibr" target="#b2">Brenner, 1999;</ref><ref type="bibr" target="#b28">Schnoes et al., 2009</ref><ref type="bibr" target="#b29">Schnoes et al., , 2013</ref>). While experimental methods have problems, the computational methods struggle on a whole new level of challenges. The error rate of computationally annotated databases has been increasing rapidly in recent years. A recent study estimates the error level has risen from 5 to 40% within the last decade (<ref type="bibr" target="#b28">Schnoes et al., 2009</ref>). In the Gene Ontology (GO) databases the error levels grow even higher: among computationally created GO annotations, the error level has been estimated to be as high as 49% and even within manually curated GO annotations between 28 and 30% (<ref type="bibr" target="#b10">Jones et al., 2007</ref>). The increasing error rate in these databases is believed to stem mostly from the propagation of erroneous annotations with usage of poorly performing in silico functional annotation tools (<ref type="bibr" target="#b32">Wieser et al., 2004;</ref><ref type="bibr" target="#b6">Gilks et al., 2002</ref><ref type="bibr" target="#b7">Gilks et al., , 2005</ref>). We have designed a high-throughput annotation tool called Protein ANNotation with Z-score (PANNZER) in order to create more reliable annotations and thereby reduce further error propagation in annotation projects. PANNZER uses the whole sequence similarity neighbourhood and weighted statistical testing in the annotation process in an attempt to maximize the evidence for correct annotation. In doing so, PANNZER prevents function transfer from incorrectly annotated sequences to an uncharacterized sequence. Here, we evaluate PANNZER in two separate tasks: in the prediction of free text description lines (DE) and in the prediction of GO classes. The description line is a free text sentence about the protein function. Written by biologists, it contains valuable information in human readable format. Therefore, it is surprising how little attention correct DE annotation has gotten in recent years. Some methods do exists, e.g. GeneQuiz (<ref type="bibr" target="#b26">Scharf et al., 1994</ref>), PEDANT (<ref type="bibr" target="#b5">Frishman et al., 2001</ref>), AutoFACT (<ref type="bibr" target="#b12">Koski et al., 2005</ref>) and Blannotator (<ref type="bibr" target="#b11">Kankainen et al., 2012</ref>). We introduce a principled metric for the evaluation of description prediction, which allows numerical comparison of description similarities. In the prediction of free text description line, we show a clear improvement to other existing methods. The GO functional annotation has become the standard tool in computationally based bioinformatics analyses. Due to this, the majority of method development in functional annotation is nowadays focused on GO classes, e.g. GOtcha (<ref type="bibr" target="#b16">Martin et al., 2004</ref>), Argot 2 (<ref type="bibr" target="#b4">Falda et al., 2012</ref>) and Blast2GO (<ref type="bibr">Gö tz et al., 2008</ref>). A more comprehensive list of GO prediction tools can be found from<ref type="bibr" target="#b23">Radivojac et al. (2013)</ref>. Our results show an improved performance over alternative scoring methods and we also show improvement to our earlier version of PANNZER that was ranked third in Critical Assessment of protein Function Annotation algorithms (CAFA) 2011 challenge (<ref type="bibr" target="#b23">Radivojac et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The PANNZER method predicts protein function using a weighted k-nearest neighbours approach with statistical testing.</p><p>The functional annotation can be predicted as description lines or GO classes. PANNZER starts with a sequence search against the sequence database. The resulting Sequence Similarity Result List (SSRL) provides the candidate descriptions. The SSRL is then partitioned into clusters according to description similarity. The support for the candidate clusters is evaluated using a sophisticated regression model. The description prediction outputs the most representative description. The GO prediction performs an enrichment analysis of GO classes in the SSRL. These steps are outlined in<ref type="figure" target="#fig_0">Fig. 1</ref>and described in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Sequence search and filtering of results</head><p>PANNZER starts the analysis with a sequence similarity search against UniProtKB database (<ref type="bibr" target="#b15">Magrane and Consortium, 2011</ref>). Here we have used standard BLAST (<ref type="bibr" target="#b0">Altschul et al., 1997</ref>) search, but other sequence search methods could be used (e.g. SANS—<ref type="bibr" target="#b13">Koskinen and Holm, 2012</ref>). A large number of locally similar but globally dissimilar sequences in the result list sometimes biases results towards large sequence families. Therefore, we limit the number of sequences taken to the analysis and focus only on the sequences that obtained the strongest results from the sequence scoring and apply pre-set filtering thresholds on alignment coverage, identity percentage, sequence length and informative descriptions. The alignment coverage values are obtained by evaluating the sequence alignment areas covered in the query and target sequence. The information density threshold restricts sequences monitored only to the sequences with informative descriptions and omits uninformative descriptions like 'putative uncharacterized protein'. The selection of informative descriptions is based on Information Density Score (IDS):</p><formula>IDS ¼ 1 n X n i¼1 idfðw; DÞ 2 ; (1)</formula><p>where w is a word in description D and n is the number of words in a description D. idf(w, D) is an Inverse Document Frequency score for a word: idfðw; DÞ ¼ log jDj jfd 2 D : w 2 dgj ;</p><formula>(2)</formula><p>Sequencewhere jDj is the total number of descriptions in the corpus (i.e. database), and jfd 2 D : w 2 dgj is the number of descriptions d where the word w occurs. IDS emphasizes the descriptions that contain specific terms over descriptions containing only general terms. The assumption here is that the words conveying specific functional information are rarer in corpus than the general words. Filtering thresholds are shown in the Supplementary Material. These values were optimized against the training set. The filtered SSRL is used in later steps of PANNZER (see<ref type="figure" target="#fig_0">Fig. 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Non-linear weighting of taxonomic distances</head><p>One information source that is omitted by the standard sequence search is the evolutionary distance between the query and target species. It is intuitive to give more emphasis to sequence matches found from species that have smaller evolutionary distance. Unfortunately we do not have evolutionary distances available across all the species and therefore we decided to use the distances in the NCBI taxonomic tree as an approximation for the evolutionary distances. Correlation between these distances and description similarities were not linear since according to the general paradigm, paralogs are more likely functionally differentiated. This was corrected with a non-linear similarity function between the descriptions of compared query and target sequence. More details on this process can be found in the Supplementary Material. The output from this process, non-linear taxonomic distance score, was one of the inputs for the re-scoring of sequence hits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Re-scoring sequence hits</head><p>In the second step of the PANNZER pipeline we re-score the sequence hits using a sparse regression model that combines various signals from sequence alignment and the signal from the non-linear taxonomic distance score. All regression models were created in the R analysis environment using Lasso and LEAPS packages (<ref type="bibr" target="#b18">Miller, 2012;</ref><ref type="bibr" target="#b24">Robert, 1996</ref>). We computed for each found sequence match various values that measure the goodness of the match to the target sequence. These are the BLAST bit score, the BLAST e-value, the sequence identity, the query alignment coverage and the target alignment coverage. In addition, we had the taxonomic distance-based weight score. The regression model was trained against the Description Similarity Measure (DSM) of training data (see Supplementary Material on training). We found that the BLAST bit score or the e-value alone are not the best correlating scores against the functional annotation. The final model, RegressionModel1, combines several measures: RegressionModel1 ¼ 0:21 Â log 10 ðidpÞ þ 0:26 Â ðCov q Â Cov t Þ þ 0:40 Â ðCov t Â TaxDist q;t Þ;</p><formula>(3)</formula><p>where idp is the alignment identity percentage and Cov is the alignment coverage in query (q) and target (t) sequences. The TaxDist (Supplementary<ref type="figure" target="#fig_0">Fig. S1</ref>) is the non-linear taxonomic distance score between query and target species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Description similarity measure</head><p>In PANNZER we use the DSM to cluster candidates in the SSRL. The DSM is based on the Term Frequency-Inverse Document Frequency (tfidf) which is a standard information retrieval and text mining method and is commonly used in clustering related documents in e.g. web search engines. The tfidf is a weighting scheme for measuring how important a word is to a document in a corpus.</p><p>The score upweights words which are frequent in the document and at the same time downweights words which are frequent in the corpus. This kind of an approach helps to control the fact that some words are generally more common than others and therefore possibly have a trivial meaning. For example, the word 'protein' is frequently used in non-related cases in biological databases and is not very informative to a functional description, whereas the word 'hydroxyltransferase' occurs rarely and only in certain descriptions and is therefore more descriptive. tfidf is defined as: tfidf ðw; d; DÞ ¼ tfðw; dÞ Â idfðw; DÞ;</p><formula>(4)</formula><p>where tf(w, d) is the frequency of word w in document d. D is the corpus (i.e. database). To measure how similar two descriptions are to each other, the tfidf is used to weight common words in descriptions. In PANNZER the description similarity is calculated by using the tfidf weighting in a cosine similarity function. The cosine similarity is a dot product of the tfidf scores of common terms between two descriptions. It is calculated using the following equation:</p><formula>DSM ¼ X n i¼1 A i Â B i ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi X n i¼1 A 2 i Â X n i¼1 B 2 i q ; (5)</formula><p>where A and B are vectors holding tfidf weights of common words between two descriptions. Examples of DSM scores between descriptions are presented in<ref type="figure" target="#tab_1">Table 1</ref>. In the PANNZER methodology the DSM is used to generate description clusters of SSRL hits by using hierarchical clustering with average linkage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Selecting the best cluster</head><p>The next step in PANNZER methodology is to select one of the clusters as the best representative for the query sequence. We define a relevance score that is used to separate good representative clusters from the randomly occurring clusters. It would be intuitive to use a single score function for cluster voting. We, however, propose a combination of score functions that is obtained with sparse regression by training the model against the DSM (see Supplementary Material). The relevance score (Equation 6) uses output from three score functions: GSZ (<ref type="bibr" target="#b30">Toronen et al., 2009</ref>), word score (WS) (<ref type="bibr" target="#b1">Andrade and Valencia, 1998;</ref><ref type="bibr" target="#b11">Kankainen et al., 2012</ref>) and weighted word score (WWS) as an input (Equations. 8–10). RegressionModel2 ¼ 0:59 þ 0:53 Â log trunk ðWSÞ þ 0:02 Â WWS þ 0:0004 Â GSZ cluster ;</p><formula>(6)</formula><p>where</p><formula>( (7)</formula><p>Each score function in Equation 6 was tested for preprocessing before regression with simple function (X, X 2 , ffiffiffiffi X p ; log trunk ðXÞ, etc.). These improved the performance of regression model (see Supplementary Material). GSZ, WS and WWS are defined below. The GSZ cluster evaluates the overlap of two sets of sequences: (A) the SSRL (i.e. the BLAST result list) and (B) the set of sequences in the database that have one of the clustered descriptions (functionally related sequences). GSZ analyses overlap in a weighted manner and takes the sum of regression score values (Equation 3) for sequences that are in the cluster and creates a Z-score normalization with the mean and STD estimates discussed in the Supplementary Material and in earlier publication (<ref type="bibr" target="#b30">Toronen et al., 2009</ref>). This emphasizes clusters of descriptions that are common in SSRL but rare in the background. For WS we first calculate WS w for every unique word w that occurs in SSRL descriptions d:</p><formula>WS w ¼ X m2Sw Bit m X m2SSRL Bit i ; (8)</formula><p>where S w is the subset of SSRL sequences that have the word w in the description and Bit is the BLAST bit score. The WS score used in Equation 6 is an average of WS w scores over the description d. This score function emphasises descriptions containing words that are frequently seen in the descriptions in SSRL. This kind of a word scoring scheme has proved to perform well in previous studies (<ref type="bibr" target="#b1">Andrade and Valencia, 1998;</ref><ref type="bibr" target="#b11">Kankainen et al., 2012</ref>). The WWS w for word w is derived from WS w , but is weighted by Jaccard Similarity Coefficient JSC w : JSC w ¼ jA \ Bj jA [ Bj ;</p><formula>(9)</formula><p>where A is the SSRL and B is the set of descriptions where the word w occurs in the whole database D. Note that A \ B is the subset of descriptions where the word w occurs in SSRL. WWS w is:</p><formula>WWS w ¼ JSC w Â WS w (10)</formula><p>This function emphasises words that are frequent in the SSRL and are not frequent in the background. The WWS score used in Equation 6 is a average of WWS w scores over the description d. The selected score functions differed in the way how they analyse the SSRL. Two score functions, GSZ and the WWS in Equation 6, do standard statistical testing against the background (i.e. whole database). Only WS does not consider background. Score functions can also be split into two other groups: GSZ uses a group of sequences with similar descriptions (description cluster) as input, whereas WS and WWS define first a score for each single word observed in descriptions and then combine the score of single words to generate the signal of whole description. Having selected the best cluster according to Equation 6, the PANNZER method selects one of the descriptions as a representative for the whole cluster. The representative description is the most frequent description in the cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Scoring GO classes</head><p>A second form of annotation is the prediction of GO classes. Here we use a method that resembles the description prediction above. First, the direct GO annotations as well as parent classes are collected from UniProt-GOA database for all the sequences in the SSRL. We collected different variables for SSRL and each GO class. These variables include the count of GO class members in the SSRL, the size of GO class in the whole database, the sum of RegressionModel1 scores within GO class members in SSRL, size of SSRL, size of whole database, etc. These in turn are used to define a various score values for each of GO classes. Earlier similar works (<ref type="bibr" target="#b4">Falda et al., 2012;</ref><ref type="bibr" target="#b16">Martin et al., 2004;</ref><ref type="bibr" target="#b31">Vinayagam et al., 2004</ref>) have selected a single score function to estimate the score value for each GO class. We decided to use a weighted sum of score functions also here. Again the motivation is to emphasize the common signal in different score functions and lessen the different noise signals. The weighted sum was obtained using sparse regression. We optimized the regression against weightedLin similarity (see GO semantic distances below). WeightedLin was used to test how similar the predicted GO class was to nearest correct GO class. In the final regression model, we excluded all terms that had negative correlation with predicted variable from the model. These terms create non-linear signal that causes non-monotonic behaviour in the model and they constitute a small subset of total signal. The training and evaluation datasets are described later. The regression model that we obtained was: RegressionModel3 ¼ 0:36 þ 0:01 Â logðJSCÞ þ 0:02 Â log mod ðGSZÞ þ ðÀ3:67 Â 10 À5 Þ Â ffiffiffiffiffiffiffiffiffiffiffi jGOj p À 0:007</p><formula>Â ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi jSSRLj; p (11)</formula><p>where log mod ðxÞ ¼ signðxÞ Â logðabsðxÞÞ þ 1 ; if absðxÞ &gt; 1 x; ; if absðxÞ 1 (</p><formula>(12)</formula><p>and jXj is the size of set X. JSC is the Jaccard Similarity Coefficient between the GO class hits in SSRL and GO class occurrences in the whole UniProtKB database and GSZ is a weighted version of hypergeometric Z-score. It is calculated for GO class members in the SSRL using the scores from RegressionModel1 as weights. GSZ is explained in the Supplementary Material and in previous publications (<ref type="bibr" target="#b30">Toronen et al., 2009</ref>). In addition, Equation 11 uses various simple functions, like squareroot, log and modified log (log mod ) to improve the regression performance (see Supplementary Material for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7.">GO semantic distances</head><p>The optimization of regression models for GO classes required a similarity measure that estimates how close two GO classes,predicted and correct, are in the GO tree. The GO similarity methods give the strongest similarity when predicted and correct GO class are exactly the same and weakening similarity when two classes move away from each other in the GO structure (<ref type="bibr" target="#b21">Pesquita et al., 2009</ref>). We used two previously published GO semantic similarity measures, Lin-score (<ref type="bibr" target="#b14">Lin, 1998</ref>) and weighted Lin-score (<ref type="bibr" target="#b27">Schlicker et al., 2006</ref>) for regression model training and evaluation. We also used two modified versions of Lin-score and weighted Linscore, called Path Lin-score and weighted Path Lin-score. We also used a simple Jaccard similarity (Equation 9) that compared parental classes of two tested GO classes. GO semantic distances are discussed more in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.">Training and evaluation datasets for description prediction</head><p>In the PANNZER project we used training datasets to find parameters for the sparse regression model and evaluation test sets to compare prediction accuracy. The test sets used in training and evaluation are separate and the training data were never used in evaluation. Sequences were selected from UniProtKB/SwissProt (downloaded November 14, 2012) to test and evaluation datasets so that: (i) they have high-quality annotation, (ii) they do not have considerable sequence similarity with each other and (iii) they do not have strong similarity in description line with each other. More details on this process are shown in the Supplementary Material. The evaluation dataset was further divided into the eukaryote and prokaryote datasets. Viruses, environmental samples and unclear taxonomic cases were excluded from the analysis. These evaluation datasets allow the analysis of methods at different parts of evolutionary tree. Our final evaluation datasets were 2954 prokaryotic sequences and 5115 eukaryotic sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9.">Training and evaluation dataset for GO prediction</head><p>GO regression training and evaluation sets were created using the same rules as description test sets above. We first selected only the sequences that had a manually curated GO annotations (i.e. GO annotations with non-IEA evidence code). Second, we excluded sequences that had annotations only in very large GO classes. Large GO classes are the ones that have many members in the GOA database. Third, the sequences were filtered for mutual sequence similarities starting from randomly selected sequence. The final training set included 8003 sequences and final evaluation set had 80 027. More detailed description is represented in Supplementary Material. Methods were also evaluated without the GO annotations with ISS evidence code. However, qualitatively the differences between the methods stayed the same. The GO evaluation only considered GO annotations that were observed in the annotations of sequences in the BLAST results. Our scoring used only these GO annotations as True Positive set. Although this alters recall values, it does not affect the ordering of the methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.10.">Evaluation databases</head><p>Sequence similarity searches were conducted against a UniProtKB (<ref type="bibr">downloaded November 14, 2012</ref>) database from which the evaluation and training sets were removed. This imitates the situation with novel sequence that cannot be found from database. This also ensures that there is no circular logic in the test, where simple matching of the query with itself in the database would always lead to optimal end result. This was called the NOSELF evaluation database. This was also used in the GO evaluation task. With well-annotated sequences, like we had in our test sets, there is always the risk that annotations have already propagated to other sequence neighbours creating an annotation cloud around the query sequence. To ensure that we can test also sequences that would not have exactly matching description in their sequence neighbourhood we modified our evaluation database so that we selected first the sequence neighbourhood for each query sequence and removed every sequence from the neighbourhood that were at least 90% identical to query sequence and has an identical description annotation. This database version was called NOCLOUD. More details on the process can be found in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.11.">Comparison to other description prediction methods</head><p>In the description prediction we used two different evaluation test sets: prokaryote and eukaryote. The eukaryote test set was found to be more difficult to functionally annotate correctly than the prokaryote set. We did the prediction for the prokaryote test set with BLAST-based methods: Best BLAST Hit (BBH), Best Informative BLAST Hit (BIBH), Blannotator (<ref type="bibr" target="#b11">Kankainen et al., 2012</ref>) and PANNZER using NOSELF and NOCLOUD databases. We also made the prediction using RAST (Rapid Annotation using Subsystem Technology) server (<ref type="bibr" target="#b20">Overbeek et al., 2013</ref>) that uses FIGfam database (<ref type="bibr" target="#b17">Meyer et al., 2009</ref>) in functional annotation. It is noteworthy that the PANNZER tool is the only method from these that does statistical testing in prediction. The BIBH was derived by going through SSRL in best first order and removing following words from descriptions: 'hypothetical',<ref type="bibr">'uncharacterized', 'putative', 'contig', 'predicted', 'probable', 'fragment', 'genome', 'protein', 'chromosome', 'possible', 'similar', 'homolog', 'conserved', 'homologous', 'complete', '</ref>shotgun', 'cdna' and 'family'. If after word removal there were no words left in description, the description was skipped and the procedure was repeated to the next description in SSRL until an informative description is found. RAST and Blannotator are designed for prokaryotic annotation. Therefore for the eukaryote dataset were predicted by using only BBH, BIBH and PANNZER using NOSELF and NOCLOUD databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.12.">Comparison to other GO prediction methods</head><p>We show two different types of evaluations. One is the comparison with GO semantic similarities. This shows the performance of the generated regression models: How good they are at estimating the distance of GO classes observed in the SSRL from the correct GO classes. The other evaluation was based on classifier evaluation using Receiver Operating Characteristics (ROC) curves and Precision-Recall (PR) curves. These were also used to calculate Area Under Curve (AUC) values from ROC curves and maximum F-measure values from PR curves. Evaluation of GO classifications has one significant problem: Extremely varying GO class sizes. This results in a situation where naive prediction that simply ranks GO classes in their size order performs really well (<ref type="bibr" target="#b23">Radivojac et al., 2013</ref>). This problem can be corrected by (a) evaluating each GO class separately and combining them, (b) excluding largest GO classes and/or (c) weighting each GO class prediction with its Information Content. Information Content is negative log of probability of the class (IC ¼ Àlogðp class Þ). It is used extensively in GO distances (<ref type="bibr" target="#b21">Pesquita et al., 2009</ref>) and it was proposed for PR and ROC curves in the CAFA challenge. We used combination of b and c in our analysis. We excluded GO classes that were larger than 1/3 of the whole data from the analysis and we weighted the remaining classes with IC in the result analysis (Supplementary Material explains this task more in detail).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The evaluation of the PANNZER method performance was conducted using description prediction and also prediction of GO classes. For the description prediction and the GO prediction we used evaluation test sets described in Section 2. We did the GO evaluation to estimate the performance improvement of our latest version of PANNZER against the PANNZER version that participated in the CAFA 2011 challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Description prediction</head><p>Textual annotation, or descriptions of protein functions in biological databases, provides a concise source of knowledge about protein function and subcellular location. The computational evaluation of textual annotations has been considered to be too difficult due to usage of free text in descriptions. Here we present one approach to perform computational evaluation of free text annotations. In this study we used the DSM (Equation 5) to calculate similarity between descriptions. The description pairs are divided into bins according to the DSM. In following results 'correct' (DSM &gt; 0.7) includes the very similar to original annotations and 'incorrect' (DSM &lt; 0.3) completely different descriptions. The bins between 'correct' and 'incorrect' (DSM 0.7 À 0.3) are intermediate bins where we cannot say for sure if the annotation means the same as original or not.<ref type="figure" target="#tab_1">Table 1</ref>shows examples at various DSM levels. We also show how these different categories distribute in the BLAST results (<ref type="figure">Figs</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Description prediction of prokaryotes</head><p>The first functional annotation prediction with BLAST-based methods was done against the NOSELF database and the second prediction was done against the NOCLOUD database. The results indicate that the PANNZER method is able to find remarkably more hits that fall into category 'correct' than any other competing method (<ref type="figure" target="#tab_2">Table 2</ref>). In NOSELF category PANNZER is able predict 5–24% more correct functional annotations than competing methods and in NOCLOUD category the improvement is between 6 and 16%. The PANNZER method also proved to be much faster than Blannotator. An average run time for a single query was 1.3 s with PANNZER and 39 s with Blannotator, making PANNZER about 30 times faster. It is notable that RAST annotation was done against FIGfam database where the self hits and propagation cloud was not removed. Therefore the RAST results are not directly comparable to other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Description prediction of eukaryotes</head><p>Using BLAST-based methods the eukaryotic test set proved to be more difficult to annotate correctly than prokaryotic test set. Especially with the eukaryotes the PANNZER method outperforms BLAST-based methods clearly (<ref type="figure" target="#tab_3">Table 3</ref>). In case of eukaryotes against the NOSELF the PANNZER method predicts 37% more 'correct' annotations than BBH and 12% more than BIBH. In 'incorrect' annotations there are 44% less hits than with BBH and 14% less than with BIBH. When compared with NOCLOUD the differences grow even higher in favour of PANNZER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">GO prediction</head><p>A previous version of PANNZER method participated in CAFA 2011 challenge that provided an independent large-scale blind testing of GO prediction methods. PANNZER was ranked in top three over 54 competing methods (<ref type="bibr" target="#b23">Radivojac et al., 2013</ref>). The differences in the prediction accuracy was very small between best performing methods; Jones-UCL (<ref type="bibr" target="#b3">Cozzetto et al., 2013</ref>), Argot 2 (<ref type="bibr" target="#b4">Falda et al., 2012</ref>) and PANNZER. Since the Jones-UCL and the Argot 2 have no publicly available stand-alone version, we were not able to compare new PANNZER against these methods directly using our NOSELF database. Therefore we decided to only evaluate our latest version of PANNZER against the version that participated in the CAFA 2011 challenge. We compare how results from new and old methods correlate with various GO semantic distances. The overall improvement of the PANNZER performance is between 28 and 47%, depending on which semantic similarity measure was used (<ref type="figure" target="#tab_4">Table 4</ref>).In addition, we show GO analysis with three separate score functions: hypergeometric P-value, Jaccard and GSZ. This compares how different enrichment scoring functions rank GO classes for class prediction. Jaccard and GSZ were inputs to our PANNZER model training, whereas hypergeometric P-value has been used before in the GO prediction (<ref type="bibr">Gö tz et al., 2008</ref>). We also include two reference methods that were also used in CAFA competition: Best BLAST and Naive prediction. Best BLAST selects the maximum Bit score reported for GO class members. Naive prediction reports simply GO classes in their size order starting from largest class. These test whether our regression outperforms single score functions and reference methods from CAFA competition. We also evaluated the GO-prediction using PR and ROC-curves. Here the GO evaluation dataset is divided into Biological Process, Cellular Component and Molecular Function GO categories. The latest version of PANNZER outperforms the old version in prediction accuracy especially in BP (Figs 4 and 5). Difference between PANNZER versions is clearer from<ref type="figure" target="#tab_5">Table 5</ref>. In addition the individual score functions show weaker performance, although the difference to GSZ is quite small. Reference methods show clearly weaker performance than other methods. Especially Best BLAST is even weaker than naive prediction. This again underlines the fact that straight analysis of SSRL without any summarization of hits is sub-optimal annotation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>As the amount of newly submitted sequences grow rapidly in public databases, and the functional annotation is critical step before studying these sequences, we need more reliable methods for in silico functional annotation. The PANNZER method outperforms competing methods in functional annotation prediction accuracy and brings novel statistical testings to the analysis. In particular, the k-nearest neighbour clustering with statistical testings bring major advantages over traditionally used nearest neighbour method (e.g. Best BLAST Hit). Our results in description prediction show that the use of the nearest neighbour does not bring any advantage in functional annotation. It is remarkable how evenly 'correct' and 'incorrect' description hits are distributed over the BLAST result lists. In the standard BLAST (using default parameters) against the NOSELF database, the 'correct' hit count does not rise above 'incorrect' count in any index of the result list, including the best hit (<ref type="figure" target="#fig_3">Figs 2 and 3</ref>). It seems that the probability of having correct annotation from the best hit is no different to any other hit in a BLAST result list. Free text description is the most comprehensive way to describe functionality of a protein and is required for every protein sequence that is submitted to a public sequence database. The current release of UniProtKB contains more than 1.5 million unique descriptions about protein functions and GO annotations that contain today 40 000 non-obsolete live terms. Despite a large fraction of synonymous descriptions, the difference is considerable. GO annotation suffers of biased usage of large and general GO terms which explains the unexpectedly good performance of the Naive GO prediction method (Figs 4 and 5). According to our results Naive method outperforms the Best BLAST Hit method clearly. This highlights the fact that closest neighbour-based methods should be avoided. Surprisingly description prediction has obtained recently very little attention in the bioinformatics community. This could be because the free text annotation is seen as an ill-defined problem without effective evaluation metrics and difficulties in handling synonyms and homonyms. To alleviate these shortcomings to some extent, we propose DSM as a new standard in description evaluation. Since descriptions and GOs are used in different contexts, both annotations are needed. DE annotations are used by the biologists andThe improvement of the PANNZER method compared with version that participated in CAFA 2011 challenge are shown. other non-computationally related researchers, whereas GO terms are frequently used in computational functional analysis and have become the standard in, e.g. enrichment analysis. PANNZER is the only tool to our knowledge that does both types of prediction.Functional annotation of uncharacterized proteins in an error-prone environment</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Schema of the PANNZER methodology. Input for the PANNZER is indicated with asterisk (*) and outputs with hash symbols (#)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Functional annotation of uncharacterized proteins in an</head><figDesc>error-prone environment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>2 and 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Distribution of correct and incorrect descriptions in prokaryote BLAST result list. The figure is based on 2954 BLAST results from prokaryote evaluation set. It is noteworthy how evenly correct (DSM ! 0.7) and incorrect (DSM 0.3) descriptions are located throughout the result list. The ratio between correct and incorrect descriptions is approximately same from the first index to the last index of the list</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Distribution of correct and incorrect descriptions in eukaryote BLAST result list. The figure is based on 5115 BLAST results from the eukaryote evaluation set. Figure shows how correct (DSM ! 0.7) descriptions are small minority throughout the whole result list. As with the prokaryote dataset the ratio between correct and incorrect descriptions stays almost the same from the first index to the last index of the result list</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. PR curves. The performance of the two PANNZER regression models, three individual statistics (Jaccard, hypergeometric and GSZ) and two reference methods (Naive and best BLAST score) is shown. New PANNZER model outperforms other methods especially in Biological Process. Note also how new model is better at the beginning parts of curves. See text for more details</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.5.</head><figDesc>Fig. 5. ROC curves for the compared methods. Methods are the same as in Fig. 4. Results confirm the earlier results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 1544 Bioinformatics, 31(10), 2015, 1544–1552 doi: 10.1093/bioinformatics/btu851 Advance Access Publication Date: 8 January 2015 Original Paper</figDesc><table>large-scale functional annotation of whole proteomes or large 
environmental samples. High-throughput experiments using, e.g. 
mass-spectrometry or RNAi methods yield biased and less specific 
information about protein function than low-throughput methods 
(</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 1. Examples of DSM scores between different descriptions</figDesc><table>Description 1 
DSM 
Description 2 

AMY-1-associating protein expressed in testis 1 
0.97 
AMY-1-associating protein expressed in testis 1-like 
Putative aryl-alcohol dehydrogenase AAD15 
0.82 
Similar to aryl-alcohol dehydrogenase 
Acetoacetyl-CoA synthetase 
0.71 
Acetoacetyl-coenzyme A synthetase 
Biotin carboxylase, chloroplastic 
0.64 
Acetyl-CoA carboxylase, biotin carboxylase 
Xanthoxin dehydrogenase 
0.56 
Alcohol dehydrogenase 
Benzoate–CoA ligase, peroxisomal 
0.44 
3-methylmercaptopropionyl-CoA ligase 
Ethylene-responsive transcription factor ABR1 
0.35 
Wound-responsive AP2 like factor 1 
Agamous-like MADS-box protein AGL18 
0.24 
Putative MADS domain transcription factor GGM9 
Adrenodoxin-like protein, mitochondrial 
0.15 
Probable YAH1-Ferredoxin of the mitochondrial matrix 
Protein arginine N-methyltransferase 
0.05 
Putative uncharacterized protein 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 2. Description prediction results with Prokaryote dataset</figDesc><table>RAST a 
BBH 
BIBH 
Blannotator 
PANNZER 

NOSELF 
Correct (%) 
32 
43.8 
47 
51 
56 
Incorrect (%) 
45 
39 
35 
32 
29 
t test* 
1.12 Â 10 À94 
1.91 Â 10 À36 
6.71 Â 10 À22 
0.002 
NOCLOUD 
Correct (%) 
32 
31 
33 
42 
48 
Incorrect (%) 
45 
48 
44 
37 
35 
t test* 
7.62 Â 10 À27 
2.62 Â 10 À52 
8.46 Â 10 À35 
0.005 

The highest correct and lowest incorrect predictions are shown in bold. 
*P-value from pairwise Student's t test (2-tailed) against PANNZER. 

a 

Please note that the RAST was done against the FigFam database, not NOSELF or NOCLOUD. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>Table 3.</figDesc><table>Description prediction results with Eukaryote dataset 

BBH 
BIBH 
PANNZER 

NOSELF 
Correct (%) 
15 
40 
52 
Incorrect (%) 
81 
51 
37 
t test* 
&lt;10 À300a 
3.52 Â 10 À115 
NOCLOUD 
Correct (%) 
8 
27 
48 
Incorrect (%) 
87 
62 
40 
t test* 
&lt;10 À300a 
8.45 Â 10 À226 

The highest correct and lowest incorrect predictions are shown in bold. 
*P-value from paired Student's t test (2-tailed) against the PANNZER. 

a 

Value is too small causing number underflow. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 4.</figDesc><table>Correlations to GO semantic similarities 

PANNZER 
(new) 

PANNZER 
(old) 

Improvement 
of correlation (%) 

WeightedLin 
0.38 
0.26 
47 
Lin 
0.38 
0.26 
47 
WeightedPathLin 
0.29 
0.23 
26 
PathLin 
0.29 
0.23 
26 
Jaccard 
0.28 
0.22 
28 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">P.Koskinen et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Petri Auvinen for critical reading of the manuscript and Teija Ojala for the artistic eye. We would also like to thank the anonymous reviewers for their constructive comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Gapped blast and psi-blast: a new generation of protein database search programs</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3389" to="3402" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic extraction of keywords from scientific text: application to the knowledge domain of protein families</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Andrade</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Valencia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="600" to="607" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Errors in genome annotation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">E</forename>
				<surname>Brenner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Genet</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="132" to="133" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Protein function prediction by massive integration of evolutionary analyses and multiple data sources</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Cozzetto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="14" to="15" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Suppl. . 3</note>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Argot2: a large scale function prediction tool relying on semantic similarity of weighted gene ontology terms</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Falda</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Suppl. . 4</note>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Functional and structural genomics using pedant</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Frishman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="44" to="57" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Modeling the percolation of annotation errors in a database of protein sequences</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R</forename>
				<surname>Gilks</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1641" to="1649" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Percolation of annotation errors through hierarchically structured protein sequence databases</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R</forename>
				<surname>Gilks</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Biosci</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">High-throughput functional annotation and data mining with the blast2go suite</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gö Tz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="3420" to="3435" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Righting the wrongs</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Hadley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO Rep</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="829" to="831" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Estimating the annotation error rate of curated go database sequence annotations</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">E</forename>
				<surname>Jones</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Blannotator: enhanced homology-based function prediction of bacterial proteins</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kankainen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Autofact: an automatic functional annotation and classification tool</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">B</forename>
				<surname>Koski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">151</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Sans: high-throughput retrieval of protein sequences allowing 50 mismatches</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">P</forename>
				<surname>Koskinen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Holm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="438" to="443" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">An information-theoretic definition of similarity</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">UniProt knowledgebase: a hub of integrated protein data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Magrane</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Consortium</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database (Oxford)</title>
		<imprint>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Gotcha: a new method for prediction of protein function assessed by the annotation of seven genomes</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Martin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">178</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Figfams: yet another set of protein families</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Meyer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="6643" to="6654" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title level="m" type="main">Subset Selection in Regression</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, Florida, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Retrieving sequences of enzymes experimentally characterized but erroneously annotated: the case of the putrescine carbamoyltransferase</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">G</forename>
				<surname>Naumoff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">The seed and the rapid annotation of microbial genomes using subsystems technology (rast)</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Overbeek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="206" to="214" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic similarity in biomedical ontologies</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Pesquita</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000443</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">The rough guide to in silico function prediction, or how to use sequence and structure information to predict protein function</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Punta</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Ofran</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">A large-scale evaluation of computational protein function prediction</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Radivojac</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="221" to="227" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Robert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">The real cost of sequencing: higher than you think</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sboner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Genequiz: a workbench for sequence analysis</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Scharf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligent Systems for Molecular Biology (ISMB)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="348" to="353" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">A new measure for functional similarity of gene products based on gene ontology</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Schlicker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">302</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Annotation error in public databases: misannotation of molecular function in enzyme superfamilies</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Schnoes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000605</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Biases in the experimental annotations of protein function and their effect on our understanding of protein function space</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Schnoes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1003063</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust extraction of functional signals from gene set analysis using a generalized threshold free scoring function</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Toronen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">307</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Applying support vector machines for gene ontology based gene function prediction</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Vinayagam</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">116</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Filtering erroneous protein annotation</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Wieser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="342" to="347" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>