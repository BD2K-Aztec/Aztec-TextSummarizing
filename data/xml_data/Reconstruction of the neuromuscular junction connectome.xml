
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reconstruction of the neuromuscular junction connectome</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010">2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Ranga</forename>
								<surname>Srinivasan</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Qing</forename>
								<surname>Li</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Houston</orgName>
								<address>
									<postCode>77004</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Xiaobo</forename>
								<surname>Zhou</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Ju</forename>
								<surname>Lu</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Biology</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jeff</forename>
								<surname>Lichtman</surname>
							</persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Molecular and Cellular Biology</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<postCode>02138</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Stephen</forename>
								<forename type="middle">T C</forename>
								<surname>Wong</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Ting</forename>
								<surname>Tsung</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Wei</forename>
								<forename type="middle">Fong</forename>
								<surname>Chao</surname>
							</persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Center for Bioinformatics Research and Imaging in Neurosciences (BRAIN)</orgName>
								<orgName type="institution">The Methodist Hospital Research Institute</orgName>
								<address>
									<postCode>77030</postCode>
									<settlement>Houston</settlement>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Reconstruction of the neuromuscular junction connectome</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="64" to="70"/>
							<date type="published" when="2010">2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq179</idno>
					<note>[11:01 12/5/2010 Bioinformatics-btq179.tex] Page: i64 i64–i70 BIOINFORMATICS</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Unraveling the structure and behavior of the brain and central nervous system (CNS) has always been a major goal of neuroscience. Understanding the wiring diagrams of the neuromuscular junction connectomes (full connectivity of nervous system neuronal components) is a starting point for this, as it helps in the study of the organizational and developmental properties of the mammalian CNS. The phenomenon of synapse elimination during developmental stages of the neuronal circuitry is such an example. Due to the organizational specificity of the axons in the connectomes, it becomes important to label and extract individual axons for morphological analysis. Features such as axonal trajectories, their branching patterns, geometric information, the spatial relations of groups of axons, etc. are of great interests for neurobiologists in the study of wiring diagrams. However, due to the complexity of spatial structure of the axons, automatically tracking and reconstructing them from microscopy images in 3D is an unresolved problem. In this article, AXONTRACKER-3D, an interactive 3D axon tracking and labeling tool is built to obtain quantitative information by reconstruction of the axonal structures in the entire innervation field. The ease of use along with accuracy of results makes AXONTRACKER-3D an attractive tool to obtain valuable quantitative information from axon datasets. Availability: The software is freely available for download at http://www.cbi-tmhs.org/AxonTracker/ Contact: stwong@tmhs.org</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The modern microscopic image acquisition techniques provide the neuroscientists the visual perception of axons in 3D space. Of particular interest is the knowledge of connectivity of the neuronal components of the nervous system, the connectome. Analyzing neuronal structures is instrumental in completely understanding the functional properties of the mammalian central nervous system (<ref type="bibr" target="#b22">White et al., 1986</ref>). One such phenomenon that can be studied is the developmental reorganization of connectivity in the mammalian nervous system, also known as synapse elimination (<ref type="bibr" target="#b16">Purves and Lichtman, 1980</ref>). Pruning of synaptic connections through competitive interactions during neurodevelopment and its effect on the neuronal connectivity is one such example. A study of connectomes over various time points during brain development can reveal the mysteries about how the neural circuits are established and the way it changes over the lifespan of the animal * To whom correspondence should be addressed. under study. Moreover, mapping wiring diagram mouse models can help understand how an abnormality in the neural circuits can lead to psychiatric disorders, such as schizophrenia and autism (<ref type="bibr" target="#b9">Lichtman et al., 2008</ref>). Another potential application is in the study of the effect of new drugs on the mammalian connectomes. Analysis of the connectomes at different time points during the drug-testing could lead to valuable insights into the effectiveness of the new drugs designed to treat disorders related to brain and central nervous system. The wiring diagram of the neuromuscular circuit is believed to be a good starting point for this, as it might lead to discoveries valuable to this study. The neuromuscular circuits are well-isolated and accessible. Its connectome is well defined. Due to the large size of the adult motor neurons (2–10 µm in diameter), which are separated from neighboring axons by Schwann cells, and the large size of neuromuscular junctions (∼20 µm in length), the neuromuscular connectome is easier to resolve, analyze and can be easily visualized. Moreover, since the morphological features of the neuromuscular connectome can be directly linked with its functional properties; for example the morphology of individual neuromuscular junction has been found to be directly related to its synaptic strength (<ref type="bibr" target="#b6">Herrera et al., 1985</ref>), it renders itself as an attractive platform to conduct connectome studies. Many questions related to synapse elimination can be answered from the study of mammalian neuromuscular connectome. As the spatial organization of the axons is very specific in nature, down to the level of individual axons, it becomes important to isolate each axon from the connectomes for extraction of morphological features for these studies. Studies in neuronal connections are believed to help unravel the functional properties of the nervous system. The manual effort needed, however, is excessive, as the neurobiologist has to manually track individual axons from a large set of data (∼30–50 GB of volumetric data). This might amount to a few months of painstaking labor. Of note are similar researches in the mapping of neural circuits for the study of neuronal connectivity. A study of potential connectivity among neurons was done based on neuron reconstructions of the cortical circuits in cat primary visual cortex (<ref type="bibr" target="#b20">Stepanyants et al., 2008</ref>). Probabilistic synaptic density maps were derived from the neural circuitry of the olfactory centers of drosophila to predict connectivity (<ref type="bibr" target="#b7">Jefferis et al., 2007</ref>). Drosophila olfactory circuits were mapped and rendered to study the mechanisms of olfactory coding in higher brain centers (<ref type="bibr" target="#b10">Lin et al., 2007</ref>). Significant research efforts have been attempted to extract the geometric structure of axons from microscopic image stacks.Page: i65 i64–i70</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reconstruction of the neuromuscular junction connectome</head><p>Some of the algorithms proposed in literature that are directly related to the work in this article are the Kalman filter-based axon tracking (<ref type="bibr" target="#b8">Jurrus et al., 2006</ref>), 3D template matching approach to detect neuronal structures (<ref type="bibr" target="#b1">Al-Kofahi et al., 2002</ref>), 3D rayburst sampling for detection of neuron structures (<ref type="bibr" target="#b17">Rodriguez et al., 2006</ref>), voxel coding for detection of centerlines from segmented neurons (<ref type="bibr" target="#b21">Vasilkoski and Stepanyants, 2009</ref>) and use of generalized cylinders for semi-automatic 3D reconstruction of neurons (<ref type="bibr" target="#b18">Schmitt et al., 2004</ref>). As the problems exhibited by our datasets are completely different from the datasets for which these methods were proposed and due to the sheer complexity of the datasets presented in the articl, none of these methods can be directly applied to label individual axons. The authors' labs have also published their research work in this long-standing problem of extraction and visualization of the geometrical features and topological characteristics of axons. Repulsive force based snake algorithm (<ref type="bibr" target="#b2">Cai et al., 2006</ref>) was proposed to solve the close lying axons in a sequence of crosssectional images. Although this method works for axons that run approximately perpendicular to the cross-sectional plane, it is unsuitable to complicated structures. Probabilistic region growing algorithm (<ref type="bibr" target="#b19">Srinivasan et al., 2007</ref>) was proposed to optimize the time taken to track the axons by utilizing a pseudo-3D approach. This method tracks the centerlines of the axons in the maximum intensity projection (MIP) image and switches to the cross-sectional domain in case of ambiguity. This method is suitable for datasets where the axons are somewhat distinguishable in the MIP image and is also unsuitable for use in the datasets presented in this article. Dynamic programming algorithm (<ref type="bibr" target="#b25">Zhang et al., 2008</ref>) introduces an approach to track the axons using constraints for smoothness and continuity in the cross-sectional images along with marker-controlled Watershed algorithm. This approach also requires the axons to run in bundles and roughly maintain their orientation throughout the dataset, and hence, cannot be directly applied to our case. Semi-automated reconstruction in serial images (<ref type="bibr" target="#b11">Lu et al., 2009</ref>) was introduced as an extension to the already existing software; Reconstruct (<ref type="bibr" target="#b4">Fiala, 2005</ref>), to interactively segment the axons in a sequence of cross-sectional images. This approach requires a re-sampling of the datasets so that majority of the axons appear in the cross-sections. This is not always achievable, especially in the datasets presented in this article, as the axons do not exhibit a specific orientation pattern. Freely available image processing software, such as ImageJ (<ref type="bibr" target="#b0">Abramoff et al., 2004</ref>) and Reconstruct (<ref type="bibr" target="#b4">Fiala, 2005</ref>), either deal with 2D images/sequence of 2D images in a semi-automatic fashion or fail in case of sharp change in axon orientation, which makes it extremely time consuming and infeasible to track complex structures. On the other hand, commercially available software, such as Imaris (http://www.bitplane.com/go/products/imaris), assumes the dataset to have an excellent contrast and cannot scale up for tracking large neuronal circuitry. Due to the unpredictable orientation change, connection complexity and low-contrast signal of axons, none of current methods or approaches offer an efficient pipeline for tracking and reconstructing wiring diagram of axons in a large-scale, quantitative neurobiology studies. In this work, we introduce a new tool, AxonTracker-3D, which does not require any parameter adjustment by the user and can drastically reduce the effort and time required to obtain valuable quantitative information from volumetric axon imagery. From our study, the AxonTracker-3D, which incorporates a 3D, real-time tracking approach based on diffusion, greatly reduces the time required in processing the large volumes of axon images from months via manual analysis to minutes on personal computers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>The interscutularis muscles were removed from thy-1-YFP-16 transgenic mice (<ref type="bibr" target="#b3">Feng et al., 2000</ref>) for diffraction-limited confocal imaging of entire motor axonal connectomes. For identification of muscle fiber type, muscles were removed and post fixed with 1% PFA for 7 min, frozen and sectioned at 20 µm using a Leica Cryostat (Leica, Germany). Following that, sections were incubated with blocking solution (2% BSA + 1% goat serum + 0.3% triton) at 25 @BULLET C for 3 h, and incubated with monoclonal antibodies against myosin type I and 2A (mouse anti-myosin I IgG1, 1 : 20, Novocastra, UK; mouse anti-myosin 2A IgG1, 1:10, Iowa Hybridoma Bank, USA) at 4 @BULLET C for 6–8 h. After several washes in 0.1% PBS-triton, samples were incubated with secondary antibody (Alexa-488 anti-mouse IgG1, 1:1000; Molecular Probes, USA) for 3 h. Finally, muscle sections were rinsed in PBS (25 @BULLET C, 20 min ×2) and mounted on slides with Vectashield mounting medium. The motor neurons expressed yellow fluorescent proteins (YFP) uniformly inside each cell. The YFP was excited with a 488 nm line of argon laser using a 60× (1.4NA) oil objective and detected with a 520–550 nm bandpass emission filter. The images were sampled at Nyquist limit in the x −y direction and oversampled by a factor of 1.5 in the z direction (voxel size = 0.1 µm ×0.1 µm × 0.2µm) with a 12 bit dynamic range. In order to obtain the complete connectome (consisting of ∼200 stacks), the motorized stage controlled by the MutliTimeZ macro, developed by Zeiss, was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM AND IMPLEMENTATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Workflow and user interface</head><p>Tracking and segmentation are the two major steps in solving the connectome and extracting quantitative information from these datasets. In this article, AxonTracker-3D, a tool incorporating the tracking and visualization of axons, has been developed to facilitate the connectome function analysis in large-scale, quantitative neurobiology studies. The datasets are processed oneby-one and are then stitched together to form a collage for further analysis. A segmentation approach is also proposed, which uses the tracking results from AxonTracker-3D. The workflow is described in<ref type="figure" target="#fig_1">Figure 1</ref>.in the visualization window is updated in real-time as the tracking is being done. The centers can also be seen in the three orthogonal views (shown in<ref type="figure" target="#fig_3">Fig. 3</ref>) in real time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i65</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R.Srinivasan et al.</head><p>The user first loads the dataset that needs to be tracked, which is followed by preprocessing for noise removal. The user then selects starting points for all the axons present in the dataset followed by the initiation of the tracking algorithm. The initialization of the algorithm consists of computation of the candidate center points for all the axons present in the dataset, which is done automatically. As the tracking proceeds, the results can be viewed as an overlay on the rendered data in 3D in real time. In case of a problem in tracking due to low contrast, dramatic change in the orientation of the axons or due to very low voxel intensity, the algorithm stops and prompts the user for correction and guidance. The interactive tracking has the provision of deletion of wrongly tracked points and addition of new points to the centerline. After the user guides the algorithm by clicking a few new points along the centerline, the algorithm resumes the tracking process. Once the tracking is complete, the datasets are stitched together to obtain the big picture (the connectome). The centerlines can be used to segment the axons and visualize them in 3D space. The user interface of AxonTracker-3D, which has been developed using C++, ITK, VTK and QT on a PC with 1.86 GHz Intel® Core™2 CPU and 2 GB of RAM configuration, is shown in<ref type="figure" target="#fig_2">Figure 2</ref>. In a few cases when the algorithm fails to find the correct center due to bad contrast between adjacent axons or low intensity, a provision for manual intervention is provided in the software, using which, the user can add or delete the center points of the axons to guide the algorithm. AxonTracker-3D can display the three orthogonal views of the current location of the centerline along with a visualization of the tracking results (<ref type="figure" target="#fig_3">Fig. 3</ref>). The user can then add or remove voxels from the centerline, hence guiding the software to accurately track the centerlines of the axons. After all the axons in the dataset are tracked, segmentation can be performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Centerline extraction</head><p>The raw image datasets obtained are prone to noise and need to be preprocessed. We use anisotropic diffusion image filtering (<ref type="bibr" target="#b12">Perona and Malik, 1990</ref>) to reduce the noise while preserving contrast near the edges of the axons. In order to extract the structures from the datasets for quantitative analysis, centerlines or the backbones of the objects have to be extracted first, which can then be used for segmentation. The process of centerline extraction involves the estimation of most likely voxels in the dataset that belong to the medial axis of the axons. From the initial point (defined manually), we employ a tracking method to extract the centerlines of each axon present in the dataset. In order to compute the candidate center points of the axons, we define a scoring method for the voxels in the dataset using a combination of the gradient vector flow (GVF) (<ref type="bibr" target="#b23">Xu and Prince, 1997</ref>) and object orientation vectors. In their original work, these forces were generated to guide the initial contour to the boundaries of the objects. We use the inverse of the approach where the forces help the boundaries to collapse to the center. To generate these candidate points, we first compute the GVF in all the cross-sectional images along the three orthogonal directions, along the x-, y-and z-axes, respectively. Each cross-sectional image along a particular axis is then binarized and the boundaries of the structures present in the cross-section are shrunk based on the forces of the GVF. An example is shown in<ref type="figure" target="#fig_6">Figure 4</ref>. As seen in<ref type="figure" target="#fig_6">Figure 4c</ref>, the resulting scores contain noise around the actual center and hence, non-maxima suppression is used. Once the computation of possible centers along all three directions is complete, we merge them together using a directional vector-based approach. The entire dataset is binarized and is first divided into smaller subsets. In each such portion, the geometrical orientation vector of the binarized objects contained in the small dataset is computed. The orientation of an object in 3D space can be computed using moment of inertia matrix. The elements of the matrix are the moment of inertia the mass exhibits in 3D space about different combinations of the three orthogonal axes (x, y and z). By computing the eigensystem of the matrix and by looking at the eigenvector with the least eigenvalue, we can determine the direction in which the mass exhibits the least amount of inertia. In other words, this direction is nothing but the orientation of the mass present inside i66Page: i67 i64–i70</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reconstruction of the neuromuscular junction connectome</head><p>(a) (is the distance of the voxel, r, from the center of mass of the binarized volume; andV (r) is the value of the voxel at r in the binarized volume. We compute the eigenvalues and the corresponding eigenvectors of the system and select the eigenvector with the lowest absolute eigenvalue as the orientation of the object in the sub-volume. Intuitively, based on the projection of this vector along the three axes (x, y and z), the three scores along orthogonal directions are combined using:</p><formula>Score GVF = t x Score x GVF +t y Score y GVF +t z Score z GVF , where t = [t x ,t y ,t z ]</formula><p>is the orientation vector of the sub-volume. This score is an indication of likelihood of a voxel belonging to the axon centerline.<ref type="figure" target="#fig_8">Figure 6b</ref>–d are examples of candidate center points calculated using GVF along the x, y and z-axes for a dataset. We can see these candidate center points are very close to actual center points even in a complicated dataset shown in the figure.<ref type="figure" target="#fig_8">Figure 6e</ref>is obtained after combining the scores in (b–d). Once the candidate centerlines are computed, the tracking process starts with the manually chosen initial point for each axon. The centerlines of the axon are traced using a moving sphere whose center always lies on current center of the centerline that has been traced so far. To compute the next center on the centerline, the directional vector for the sphere (computed using the current center and nine previous centers) is computed. The radius of the sphere in our study has been set to five voxels. The search for the next center is performed in a preset angle range (set to 45 @BULLET in our case) about the directional vector inside the sphere so that the centerline does not trace back itself. In each step, inside the search region, the voxel with the highest GVF score is chosen as the next center. If manyvoxels are found to have the same value, we resolve them using:</p><formula>C i+1 = argmin r∈R a 1−G r +b D r ,</formula><p>where C i+1 is the (i+1)-th center (or the new center on the centerline to be determined); R is the set of all the candidate voxels that need to be resolved; G r is the normalized value of the maximum value of gradient along the path connecting C i (current center on the centerline) and r;</p><formula>which D r = − → t i × − − → t i+1</formula><p>is a smoothness term based on the dot product of the directional vectors (the directional vector of the sphere and the directional vector formed between the current center and the voxel under consideration respectively); a and b are the weights that denote accuracy and smoothness of the centerline. In our study, these parameters have been set as 0.65 and 0.35, respectively. An illustration of the tracking algorithm is shown in<ref type="figure" target="#fig_7">Figure 5</ref>. The shaded conical region inside the spheres shown in<ref type="figure" target="#fig_7">Figure 5</ref>are the search region at different points along the centerline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Segmentation of axons</head><p>In many cases, axons twist and turn, and lie close to each other in the image stack. The challenges in segmentation include weak boundaries between close-lying axons and large intensity variations in some axons, which cause many segmentation methods to fail. In order to deal with this problem, the segmentation scheme consists of two steps. In the first step, local threshold 3D region growing is applied to get the rough segmentation result which will be used as the initial segmentation for the subsequent step. The local region is defined as spheres with certain radius (set to two to five voxels in our study), and the centers of the spheres are located on these center points. This radius was determined based on the radius of the thinnest axon present in the datasets. Once the rough segmentation of axons is obtained, an interactive level set model (<ref type="bibr" target="#b24">Yan et al., 2008</ref>) was adopted to detect boundaries in 3D space. The interaction involves two types of mechanisms: repulsion and competition. The repulsion term is for separating the touching axons and the competition is for defining the axon boundaries. These mechanisms were formulated as an energy functional, which is then minimized by using the multiphase level set method.<ref type="figure" target="#fig_8">Figure 6g</ref>shows the segmentation result obtained using the centerlines of the axons from<ref type="figure" target="#fig_8">Figure 6f</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i67</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R.Srinivasan et al.</head><formula>(a) (b) (c) ( d) (e) (f) ( g)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Stitching of datasets</head><p>After the datasets have been segmented, they are stitched together to form a collage. As the datasets are contiguous with a variable amount of overlap between them, we process the dataset stack by stack to form a montage by using the normalized cross-correlation measure to determine contiguous stacks and the extent of overlap between them. The cross-correlation measure between an image, I, and a template, t, is defined as:</p><formula>C (u,v ) = x,y [I (x,y )− ¯ I u,v ] [t (x −u,y−v )−¯ t ] x,y [I (x,y )− ¯ I u,v ] 2 x,y [t (x −u,y−v )−¯ t ] 2 ,</formula><p>where (u,v) is the coordinate where the template is centered at; I(x,y) is the image region under the moving template; t is mean of the template; and ¯ I u,v is the mean of the image region under the template. The cross-correlation measure has been applied in xy plane and then in xz plane to complete the alignment in 3D. This reduces the computational time involved in alignment as opposed to a completely 3D alignment. As the datasets were down-sampled by a factor of 2, an alignment error of one voxel is unavoidable during alignment. To record morphological properties of neuronal processes, images were acquired from neonatal mice using laser scanning immunofluorescent confocal microscopes. The connectome of interscutularis muscle of the mouse was used for this study. The complete connectome consisted of ∼200 data stacks. Adjacent stacks had an overlap of around 10% for alignment to form the montage. The data acquisition lasted around 24–48 h and accumulated ∼50 GB of data. The datasets that did not contain any axons were discarded. The resulting set of datasets contained 154 stacks which amounted to around 35 GB of data. The volumetric datasets are a large number of 3D axon image stacks, each typically being 1024 × 1024 × (100–200) voxels in size (voxel size of 0.1 µm × 0.1 µm × 0.2 µm), which when put together form a collage of the connectome. The datasets were down-sampled along the xy direction, yielding datasets that were 512 × 512 ×(100– 200) voxels in size (voxel size of 0.2 µm × 0.2 µm × 0.2 µm), which improved the tracking and segmentation speed without losing accuracy and lowered the computer memory requirement.<ref type="figure" target="#fig_10">Figure 7</ref>shows the tracking and segmentation results of 30 contiguous stacks from the collage. The centerlines were tracked and segmented automatically using AxonTracker-3D. The datasets were then stitched together using the cross-correlation measure and are visualized together as shown in<ref type="figure" target="#fig_10">Figure 7b</ref>. The results show that touching axons and axons with short turns can be accurately extracted by the software. On an average, each axon takes &lt;30 s to track if no manual intervention/correction is required. Owing to the complexity of axon, each dataset had ∼25–40% of the axons that needed manual correction at three to four places for tracking. The average reconstruction time for one image stack is ∼10–15 min. Once tracked, each dataset in the collage took 5 min for segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>In this article, we presented a novel interactive tool to extract and reconstruct axons obtained from 3D confocal microscopy image stacks. Compared to the previously proposed methods, our algorithm has two major contributions: firstly, the software can successfully extract centerlines of axons with minimal user intervention. Rendering of the data in 3D along with overlay of tracking results in real-time is a useful feature offered by the software. By introducing user interaction, we can see that our algorithm can successfully extract and reconstruct touching axons and axons with dramatic orientation changes. Secondly, by using local region growing and interactive level set segmentation methods, we can get the actual boundary of each axon which can provide us valuable quantitative information such as the length, radius for axon function and connectivity analysis. As a continuation of the work presented in this article, we will discuss algorithms to detect and track branches in order to minimize user-intervention needed for AxonTracker-3D. The following are the planned improvements to the current version of the software. Axons in the connectome of neuro-muscular junctions tend to branch into complex patterns. The current version of AxonTracker3D does not have a provision to automatically detect branches. At branch points, the centerlines were joined together manually to complete the wiring circuitry of the axons. As an extension to our current work, we plan to design and implement new algorithms to detect branching points along the axons. Methods such as AdaBoost classifier (<ref type="bibr" target="#b5">Freund and Schapire, 1999</ref>) could be a potential solution to this problem. This consists of three steps: (i) re-slice the axon tubes along its orientation; (ii) extract 2D and 3D features from the slices and spheres rounding the center points; (iii) select samples to train AdaBoost classifier (manual selection of ∼100 samples for training). The AdaBoost method can be used to classify positive training examples from negative i68Page: i69 i64–i70</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reconstruction of the neuromuscular junction connectome</head><p>(a) (b)examples by selecting a small number of critical features from a huge feature set previously designed and creating a weighted combination of them to use as a strong classifier to detect the branch points along axons. We will include a provision for manual intervention in branch detection as well, but the need for it will be rather minimal. AxonTracker-3D has been designed such that the user interface and interaction is kept as simple, intuitive and user-friendly as possible. Any addition or modification to AxonTracker-3D modules will not affect the basic work-flow as described in<ref type="figure" target="#fig_1">Figure 1</ref>. The current version of the software does not make use of multithreading, and hence there is a good scope of increasing the execution speed manifolds by making use of multiple CPU's if available on the PC. As the size and number of the datasets in the collages are huge, a major improvement to the existing software would be to include a provision for batch processing. The datasets in the collage could be processed automatically as much as possible to reduce the time and effort needed for tracking the connectome. Along with this, the existing algorithms will also be improved to increase automation without compromising accuracy of results. Most importantly, using the quantitative data available from tracking and segmentations of complete connectomes, many biological questions can be generated, such as: (i) the relationship between the number of branches and the length of each segment in a population of axons; and (ii) the spatial distribution of motor neurons or the optimal layout of the motor neurons in a population of axons. Questions such as whether the spatial distribution of the axons are random in nature or follow a certain pattern can be answered. We intend to employ data mining and biostatistics methodologies on the datasets and wiring diagrams extracted from AxonTracker-3D to address these questions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[11:01 12/5/2010 Bioinformatics-btq179.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Workflow of the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Tracking interface of AxonTracker-3D: the interactive visualization window is shown with the axons in a dataset. One of the axons that have been tracked is shown in red. Provision for manual intervention is provided on the left side of the interface. The centerline in the visualization window is updated in real-time as the tracking is being done. The centers can also be seen in the three orthogonal views (shown in Fig. 3) in real time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. The orthogonal views of a dataset showing provision for editing the centerlines detected by the algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>[11:01 12/5/2010 Bioinformatics-btq179.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.4.</head><figDesc>Fig. 4. Identification of candidate centers: (a) raw image, (b) gradient forces shown by vectors, and (c) candidate centers found by collapsing the boundary of the binarized version of (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.5.</head><figDesc>Fig. 5. An illustration demonstrates the tracking process inside the axon.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.6.</head><figDesc>Fig. 6. Computation of center point candidates using GVF. (a) MIP of the original dataset. (b–d) MIP of the GVF dataset computed along the x-, y-and z-axes, respectively. (e) Visualization (3D) of the combined GVF datasets using vector approach. (f) Centerlines computed by our tracking algorithm based on the centerline candidates. (g) 3D rendering of the segmentation results using the centerlines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><figDesc>[11:01 12/5/2010 Bioinformatics-btq179.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.7.</head><figDesc>Fig. 7. (a) An example shows 30 stacks aligned automatically. (b) Segmentation and labeling using AxonTracker-3D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>⎤ ⎦ where I xx = r∈R V (r ) (d (r ) 2 y +d (r ) 2 z ) and similarly I yy and I zz are defined; I xy = I yx = − r∈R V (r )d (r ) x d (r ) y and similarly, I yz = I zy and I zx = I xz are defined in a symmetrical way; R is the set of all the voxels in the binarized volume under consideration; d(r) = [d(r) x , d(r) y , d(r) z ]</figDesc><table>I = 

⎡ 

⎣ 
I xx I xy I xz 
I yx I yy I yz 
I zx I zy I zz 

</table></figure>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">i70 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors would like to thank various members of the Wong lab at The Methodist hospital Research Institute and of the Lichtman lab at Harvard University for their technical comments over the years on the AxonTracker-3D project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Image processing with ImageJ</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">D</forename>
				<surname>Abramoff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biophotonics Int</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="36" to="42" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Rapid automated three-dimensional tracing of neurons from confocal image stacks</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">A</forename>
				<surname>Al-Kofahi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="171" to="187" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Repulsive force based snake model to segment and track neuronal axons in 3D microscopy image stacks</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Cai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1608" to="1620" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Imaging neuronal subsets in transgenic mice expressing multiple spectral variants of GFP</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Feng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="51" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Reconstruct: a free editor for serial section microscopy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Fiala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Microsc</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="52" to="61" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">A short introduction to boosting</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Freund</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">E</forename>
				<surname>Schapire</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Japanese Soc. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="771" to="780" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Ultrastructural correlates of naturally occurring differences in transmitter release efficacy in frog motor nerve terminals</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Herrera</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurocytol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Comprehensive maps of drosophila higher olfactory centers: spatially segregated fruit and pheromone representation</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">S X E</forename>
				<surname>Jefferis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="1187" to="1203" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Axon tracking in serial block-face scanning electron microscopy</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Jurrus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image. Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="180" to="188" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A technicolour approach to the connectome</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Lichtman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Neurosci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="417" to="422" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A map of olfactory representation in the drosophila mushroom body</title>
		<author>
			<persName>
				<forename type="first">H.-H</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="1205" to="1217" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-automated reconstruction of neural processes from large numbers of fluorescence images</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5655</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Perona</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Malik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern. Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990-08-31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">bioinformatics.oxfordjournals.org/ Downloaded from Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>btq179. .tex</note>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="70" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Srinivasan</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Elimination of synapses in the developing nervous system</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Purves</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Lichtman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page" from="153" to="157" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Rayburst sampling, an algorithm for automated threedimensional shape analysis from laser scanning microscopy images</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rodriguez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Protocols</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2152" to="2161" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">New methods for the computer-assisted 3-D reconstruction of neurons from confocal image stacks</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Schmitt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1283" to="1298" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Automated axon tracking of 3D confocal laser scanning microscopy images using guided probabilistic region merging</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Srinivasan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="189" to="203" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Local potential connectivity in cat primary visual cortex</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Stepanyants</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cereb. Cortex</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="13" to="28" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Detection of the optimal neuron traces in confocal microscopy images</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Vasilkoski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Stepanyants</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page" from="197" to="204" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">The structure of the nervous system of the nematode Caenorhabditis elegans</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">G</forename>
				<surname>White</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. R. Soc. Lond. B</title>
		<imprint>
			<biblScope unit="volume">314</biblScope>
			<biblScope unit="page" from="1" to="340" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient vector flow: a new external force for snakes</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Xu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Prince</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Visual Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Visual Pattern Recognition (CVPR)<address><addrLine>Los Alamitos</addrLine></address></meeting>
		<imprint>
			<publisher>Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic segmentation of high-throughput RNAi fluorescent cellular images</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Yan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="109" to="117" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">3D axon structure extraction and analysis in confocal fluorescence microscopy images</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural. Comput</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1899" to="1927" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>