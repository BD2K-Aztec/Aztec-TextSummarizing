
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Obtaining better quality final clustering by merging a collection of clusterings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1920">. 20 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Selim</forename>
								<surname>Mimaroglu</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Bahcesehir University</orgName>
								<address>
									<addrLine>Ciragan Caddesi</addrLine>
									<postCode>34353</postCode>
									<settlement>Besiktas, Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ertunc</forename>
								<surname>Erdil</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Bahcesehir University</orgName>
								<address>
									<addrLine>Ciragan Caddesi</addrLine>
									<postCode>34353</postCode>
									<settlement>Besiktas, Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Obtaining better quality final clustering by merging a collection of clusterings</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS APPLICATIONS NOTE</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="2645" to="2646"/>
							<date type="published" when="1920">. 20 2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq489</idno>
					<note>[18:26 20/9/2010 Bioinformatics-btq489.tex] Page: 2645 2645–2646 Associate Editor: John Quackenbush</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Clustering methods including k-means, SOM, UPGMA, DAA, CLICK, GENECLUSTER, CAST, DHC, PMETIS and KMETIS have been widely used in biological studies for gene expression, protein localization, sequence recognition and more. All these clustering methods have some benefits and drawbacks. We propose a novel graph-based clustering software called COMUSA for combining the benefits of a collection of clusterings into a final clustering having better overall quality. Results: COMUSA implementation is compared with PMETIS, KMETIS and k-means. Experimental results on artificial, real and biological datasets demonstrate the effectiveness of our method. COMUSA produces very good quality clusters in a short amount of time.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Clustering is the process of organizing objects into groups which have similar members; a distance metric is used for evaluating the similarity. Clustering is also known as unsupervised classification in the literature. Clustering has a long and rich history in a variety of scientific fields (<ref type="bibr" target="#b1">Jain, 2010</ref>). Taxonomists, social scientists, psychologists, biologists, statisticians, mathematicians, engineers, computer scientists, medical researchers and others who collect and process real data have all contributed to clustering methodology. There are many well-known clustering algorithms, as stated earlier. Each clustering method provides some benefits. Therefore, multiple clusterings can be obtained for the same dataset, and these benefits can be combined into a final clustering. COMUSA takes a collection of clusterings as input, and it creates a final clustering with better overall quality. In other words, COMUSA combines the benefits of multiple clusterings into a final clustering. COMUSA is a general purpose software; it can be used on biological and non-biological datasets. However, in this article, we will evaluate COMUSA's performance on biological datasets. * To whom correspondence should be addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">APPROACH</head><p>A collection of clusterings is provided as input to COMUSA. Using this input, COMUSA creates a similarity graph of objects. Similarity graph is an undirected and weighted graph that represents the co-association of objects. Similarity graph is constructed by accumulating the evidence in multiple clusterings. In this graph, an edge incident to vertices v i and v j represents the number of times these vertices are assigned to the same cluster and it is shown as weight(v i , v j ). Each vertex (object) v i is represented by a pair: First component of a vertex, df(v i ), is the number of edges that are incident to the vertex, called degree of freedom. Second component, sw(v i ), is the total sum of weights of these edges, called sum of weights. The attachment of a vertex v i is defined</p><formula>as attachment(v i ) = sw(v i ) df(v i ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COMUSA</head><p>Below, we explain the general characteristics of COMUSA. An unmarked object v p having the highest attachment values is selected as pivot (seed) for starting a new cluster. High values of degree of freedom mean that the node is connected to many other vertices. Similarly, large values of sum of weights indicate high similarity with several other vertices. The ratio, sum of weights over degree of freedom, indicates attachment. Therefore, an object having high attachment value is strongly connected to somewhere. A vertex v i is added to the cluster of v p if it is more closely attached to v p than to any other vertex. For the multiple clusterings of a dataset in<ref type="figure">Table 1</ref>, the similarity graph is constructed as shown<ref type="figure" target="#fig_0">Figure 1a</ref>. Nodes having the highest attachment value (2.0) are d 3 and d 6. Randomly, d 3 is picked</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Mimaroglu and E.Erdil</head><p>(a) ( b)as pivot for starting a new cluster. Next, objects that will be in the same cluster with d 3 are discovered. Starting from the nearest neighbors, we have to evaluate the edge weights and include objects into first cluster if they are strongly connected to d 3. Immediate neighbors of d 3 are d 6 and d 1. d 6 is added to the cluster since weight(d 3 ,</p><formula>d 6 ) ≥ weight(d 6 , d 1 ). d 1</formula><p>is not included in the first cluster, because weight(d 3 ,</p><formula>d 1 ) ≥ weight(d 1 , d 4 ) [similarly, weight(d 3 , d 1 ) ≥ weight(d 1 , d 2 )]</formula><p>. First cluster, which is shown in dashed pattern in<ref type="figure" target="#fig_0">Figure 1b</ref>, has two objects</p><formula>C 1 ={d 3 , d 6 }.</formula><p>Since there are objects that are not included in any cluster, COMUSA keeps running. Next, d 2 is selected as a pivot, because among all the unlabeled objects it has the highest attachment value. COMUSA extends the cluster in the same way as explained earlier and produces the second cluster:</p><formula>C 2 ={d 2 , d 1 , d 4 , d 8 }</formula><p>, which is shown in<ref type="figure" target="#fig_0">Figure 1b</ref>in dotted pattern. Finally, COMUSA merges d 5 and d 7 and halts. Third cluster, C 3 ={d 5 , d 7 }, is shown in bold straight line in<ref type="figure" target="#fig_0">Figure 1b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND DISCUSSION</head><p>Selecting a pivot (seed) object for initiating a new cluster is essential in COMUSA. An unmarked object having the highest attachment value is selected as pivot for starting a new cluster. Initially each cluster is a singleton. Pivot object expands the cluster by considering all the immediate neighbors. A neighbor is included in a pivot's cluster if it is most similar to the pivot. Once a neighbor is included, it is marked and then it acts like a pivot by considering its immediate neighbors for further expansion. Expansion of a cluster comes to a stop if pivots cannot add any other objects into the cluster. If there are unmarked objects left, COMUSA starts a new cluster by choosing a new pivot. COMUSA halts when all the objects belong to a cluster. Arbitrary shape clusters can be found by our algorithm, and we do not make any assumptions about the input dataset. COMUSA works very well because pivot objects are good starting points, and an object is included into a cluster if the object is most similar to a pivot in that cluster.</p><p>In some cases it is desirable to have larger clusters: user input relaxation rate is used to achieve this, which is defined as follows. On a set of edge weights {w 1 , w 2 ,..., w n }, w k is said to have maximum value with relaxation r, if ∀ i (w k +w k .r ≥ w i ) holds. Maximum edge weight constraint is relaxed with the relaxation value, r. COMUSA produces very good results on real and synthetically produced datasets, as well as on biological datasets. Experimental results are shown at the home page in great detail. On Escherichia coli dataset, COMUSA produces excellent results with respect to adjusted rand index (ARI) (<ref type="bibr" target="#b0">Hubert and Arabie, 1985</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Constructing clustering using Table 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. , a collection of clusterings in binary format Clustering ID Cluster ID d 1 d 2 d 3 d 4 d 5 d 6 d 7 d 8</figDesc><table>1 

1 
1 
0 
1 
0 
0 
1 
0 
0 
2 
0 
0 
0 
1 
1 
0 
0 
0 
3 
0 
1 
0 
0 
0 
0 
1 
1 

2 

4 
1 
1 
0 
1 
0 
0 
0 
0 
5 
0 
0 
0 
0 
0 
0 
0 
1 
6 
0 
0 
0 
0 
1 
0 
1 
0 
7 
0 
0 
1 
0 
0 
1 
0 
0 

3 

8 
0 
0 
1 
0 
0 
1 
0 
0 
9 
1 
1 
0 
1 
0 
0 
0 
1 
10 
0 
0 
0 
0 
1 
0 
1 
0 

</table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2645 at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from [18:26 20/9/2010 Bioinformatics-btq489.tex] Page: 2646 2645–2646</note>

			<note place="foot" n="5"> CONCLUSION Using a collection of clusterings produced by various methods, COMUSA produces a final clustering which has better overall quality. COMUSA creates a similarity graph by using the evidence accumulated from the clusterings. By using the similarity graph, COMUSA computes pivot objects for starting a new cluster, and expands the clusters as much as possible. Number of clusters is automatically found by our algorithm with respect to relaxation rate. COMUSA is partitional, exclusive and complete. Extensive experimental evaluations on many real and artificial datasets demonstrate that COMUSA: (i) finds arbitrary shape clusters, (ii) is not affected by the cluster size, (iii) is not affected by noise and outliers, (iv) is not affected by the sparseness of the dataset, (v) is order independent, (vi) is deterministic and (vii) scales well. Conflict of Interest: none declared.</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hubert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Arabie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Classif</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Data clustering: 50 years beyond k-means</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Jain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogni. Lett</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="651" to="666" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>