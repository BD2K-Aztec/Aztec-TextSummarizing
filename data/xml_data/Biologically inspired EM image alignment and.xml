
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structural bioinformatics Biologically inspired EM image alignment and neural reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Seymour</forename>
								<surname>Knowles-Barley</surname>
							</persName>
							<email>seymour.kb@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">The University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Nancy</forename>
								<forename type="middle">J</forename>
								<surname>Butcher</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Life Sciences Centre</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<region>Nova Scotia</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ian</forename>
								<forename type="middle">A</forename>
								<surname>Meinertzhagen</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Life Sciences Centre</orgName>
								<orgName type="institution">Dalhousie University</orgName>
								<address>
									<settlement>Halifax</settlement>
									<region>Nova Scotia</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">J</forename>
								<surname>Douglas Armstrong</surname>
							</persName>
							<email>douglas.armstrong@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">The University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structural bioinformatics Biologically inspired EM image alignment and neural reconstruction</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">16</biblScope>
							<biblScope unit="page" from="2216" to="2223"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr378</idno>
					<note type="submission">Received on March 11, 2011; revised on May 13, 2011; accepted on June 1, 2011</note>
					<note>[12:29 22/7/2011 Bioinformatics-btr378.tex] Page: 2216 2216–2223 Associate Editor: Anna Tramontano Availability: An open-source reference implementation is available in the Supplementary information. Contact: Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Three-dimensional reconstruction of consecutive serial-section transmission electron microscopy (ssTEM) images of neural tissue currently requires many hours of manual tracing and annotation. Several computational techniques have already been applied to ssTEM images to facilitate 3D reconstruction and ease this burden. Results: Here, we present an alternative computational approach for ssTEM image analysis. We have used biologically inspired receptive fields as a basis for a ridge detection algorithm to identify cell membranes, synaptic contacts and mitochondria. Detected line segments are used to improve alignment between consecutive images and we have joined small segments of membrane into cell surfaces using a dynamic programming algorithm similar to the Needleman–Wunsch and Smith–Waterman DNA sequence alignment procedures. A shortest path-based approach has been used to close edges and achieve image segmentation. Partial reconstructions were automatically generated and used as a basis for semi-automatic reconstruction of neural tissue. The accuracy of partial reconstructions was evaluated and 96% of membrane could be identified at the cost of 13% false positive detections.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Serial-section transmission electron microscopy (ssTEM) can produce reconstructions of neuronal morphology at very high resolution, including synaptic organelles and the contacts between neurons that constitute circuits. Alignment and reconstruction of ssTEM images is currently performed manually or semiautomatically, with the aid of computer software, to generate a 3D model of the imaged neuron and, with other such neurons, of the synaptic circuits to which that neuron contributes (<ref type="bibr" target="#b26">Meinertzhagen and O'Neil, 1991;</ref><ref type="bibr" target="#b40">Takemura et al., 2008;</ref><ref type="bibr" target="#b44">White et al., 1976</ref>). In some * To whom correspondence should be addressed. cases, approximate alignment can be achieved automatically but, even so, high-quality circuit reconstructions still require many hours of manual tracing and annotation, and are highly dependent upon the interpretative skill of the human observer and the complexity of neuronal arborizations being reconstructed (<ref type="bibr" target="#b4">Briggman and Denk, 2006;</ref><ref type="bibr" target="#b12">Eisenstein, 2009;</ref><ref type="bibr" target="#b37">Smith, 2007</ref>). For example, neurites are simple and have been completely reconstructed by manual means in the nematode Caenorhabditis elegans (<ref type="bibr" target="#b44">White et al., 1976</ref>) but are complex, highly branched and reconstructed only with great difficulty or incompletely in the fruit fly Drosophila melanogaster (<ref type="bibr" target="#b40">Takemura et al., 2008</ref>). Existing methods of image alignment usually rely on a control point selection method. Semi-automatic alignment can be carried out by identifying control points manually and aligning these by means of a particular algorithm (<ref type="bibr" target="#b13">Fiala, 2005;</ref><ref type="bibr" target="#b22">Kremer et al., 1996</ref>). Automatic alignment can be carried out with control point detection algorithms (<ref type="bibr" target="#b0">Anderson et al., 2009;</ref><ref type="bibr" target="#b36">Saalfeld et al., 2010</ref>), and works best when image quality is consistent throughout the dataset, but performance can be degraded when artefacts such as gaps, noise, differing levels of brightness and/or contrast are present in the images being aligned. Such artefacts are unfortunately fairly common in ssTEM because of the complicated preparative procedures and increase as the series of images becomes longer. Most currently used systems for automatically annotating electron microscopy (EM) data rely on some variant of the watershed algorithm to detect boundaries between cells (<ref type="bibr" target="#b3">Beucher, 1991;</ref><ref type="bibr" target="#b11">Chklovskii et al., 2010</ref>). This method usually results in oversegmentation, and several methods have been identified to reunite incorrectly over-segmented areas after the watershed algorithm is run (<ref type="bibr" target="#b1">Andres et al., 2008;</ref><ref type="bibr" target="#b20">Jurrus et al., 2008;</ref><ref type="bibr" target="#b27">Mishchenko, 2009</ref>). A commonly used method to detect membrane present in an image is to pre-process the image by a Gaussian blur combined with image derivative or Hessian matrix analysis. Also called Gaussian smoothed Hessian (GSH), this method is effective at filtering out noise while retaining membrane edges in the image (<ref type="bibr" target="#b27">Mishchenko, 2009;</ref><ref type="bibr" target="#b43">Venkataraju et al., 2009</ref>). Random forest classifiers have also been used to successfully combine outputs from a range of generic feature detectors (<ref type="bibr" target="#b21">Kaynig et al., 2010;</ref><ref type="bibr" target="#b39">Sommer et al., 2011</ref>). GSH, and other generic feature detectors, are efficient to implement and make reasonable assumptions when membrane profiles are Gaussian, but when line profiles are predictable the construction of a specific filter may improve performance (<ref type="bibr" target="#b25">Lorenz et al., 1997;</ref><ref type="bibr" target="#b45">Ziou, 1991</ref>). For this reason, we have customized a set of receptive fields to specific features visible in EM images.Page: 2217 2216–2223<ref type="bibr" target="#b23">Leiss et al., 2009</ref>). Four categories have been annotated: sharp membranes that pass vertically through the section thickness (a), blurred images of obliquely sectioned membrane (b), synaptic profiles (c) and mitochondria (d). Each image patch is 227×227 nm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biologically inspired neural reconstruction</head><p>Here, we explored a novel approach based on receptive fields to identify the likely locations for cell membranes, and a ridge detection approach to identify lines within the receptive field responses. We have then used a shortest path approach to close the edges detected in the image. Lines of cell membranes are aligned in 3D to improve the image alignment and generate partial 3D reconstructions. Detected membrane points are further analysed to identify likely organelle and synapse locations within the ssTEM images. Receptive fields are a well-studied feature of many sensory interneurons, especially in visual systems, and define a region within which the neuron responds to a particular stimulus, such as a line segment at a particular orientation (<ref type="bibr" target="#b2">Angelucci et al., 2002;</ref><ref type="bibr" target="#b14">Fitzpatrick, 2000;</ref><ref type="bibr" target="#b16">Hubel and Wiesel, 1959;</ref><ref type="bibr" target="#b29">O'Carroll, 1993</ref>). Computational models of the brain also use receptive fields to further understand the visual system (<ref type="bibr" target="#b8">Carandini et al., 2005;</ref><ref type="bibr">Field, 1996, 2005</ref>). In the system presented here, receptive fields are learnt from examples of image patches taken from ssTEM training data using supervised learning techniques. The resulting Gabor-like receptive fields are applied to ssTEM data images to annotate automatically neuronal membranes, synaptic connections and organelles such as mitochondria. Objects recognized by the system are then used to improve the alignment of consecutive images and produce partial 3D reconstructions as a starting point for manual annotation. Using this biologically inspired approach to analyse and understand biological images has the potential for further improvements in semi-automatic segmentation by applying additional properties of biological vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Receptive fields</head><p>Over 500 examples of membrane, synapses and mitochondria from serial 50 nm thick sections of the mushroom body calycal neuropiles of Drosophila were manually annotated (<ref type="figure" target="#fig_1">Fig. 1</ref>). The images were generated by Zhiyuan Lu and Ian Meinertzhagen, Dalhousie University, see<ref type="bibr" target="#b23">Leiss et al. (2009)</ref>for details.Training images were first normalized to have a range between −1 and 1. Then line detection Gabor filters at different orientations were used to detect the best orientation for each image automatically. Images were rotated so that a vertical Gabor patch produced the largest response. In the case of images of mitochondria and synapses, rotation was performed to orientate the darkest half of the image to the left. Examples of resulting image patches are shown in<ref type="figure" target="#fig_1">Figure 1</ref>. In the next step, a neural network was trained on the manually annotated image patches, randomly split into training and test groups, and a selection of 400 random images from the same dataset. A standard feed forward back propagation neural network was used, with a single input per pixel and as many outputs as target classes. All weights and biases in the network were initialized to zero and mean-squared error was used as the error function. Membrane receptive fields were trained by specifying just one target class and training on membrane (or oblique membrane) from the training images with random images provided as negative examples. Synapse and mitochondria receptive fields were trained at the same time by specifying two target classes and training on positive examples from the manually annotated dataset, with membrane and random images used as negative examples. Training continued until classification performance on the test images stopped improving, typically after 10–20 iterations. Resulting weight matrices for each class are shown in<ref type="figure" target="#fig_2">Figure 2a</ref>. Note that a self-organizing map (SOM) learning system also produced similar results and was able to identify membrane, synapse and mitochondria classes unsupervised, as shown in<ref type="figure" target="#fig_2">Figure 2b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Membrane detection</head><p>Space-filling 3D reconstructions require us to identify the surfaces of neurons. These are necessary as the first step in identifying sites of contact between reconstructions of neighbouring neurons. As the basis to detect membranes, we therefore used the membrane weight matrices from the neural network training to build a membrane detection tool. Weights were multiplied with a Gaussian probability density having a standard deviation chosen so that a constant background input produced a response of 0. The resulting Gabor-like patches were rotated to create a filter bank of membrane receptive fields. A total of 36 orientations was sufficient to produce reasonable accuracy to detect membranes (<ref type="figure">Table 1</ref>). Filters were convolved over large image patches from the same data to produce filter response images as shown in<ref type="figure" target="#fig_3">Figure 3B</ref>. Membrane detection based on these responses was carried out by choosing high-scoring local maxima as seed points and then searching for neighbouring areas of high response and similar orientation. The search area was modified so that response scores very near the seed point were inhibited and responses with similar orientation to the seed point, in the Page: 2218 2216–2223</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Knowles-Barley et al.</head><p>A B Cexpected direction, were facilitated (or received less inhibition). Modifying the scores for nearby receptive field responses in this way can also be thought of as an approximation to the lateral inhibition and excitation observed in biological visual systems (<ref type="bibr" target="#b15">Hartline et al., 1956;</ref><ref type="bibr" target="#b17">Ichida et al., 2007;</ref><ref type="bibr" target="#b32">Ozeki et al., 2004</ref><ref type="bibr" target="#b33">Ozeki et al., , 2009</ref><ref type="bibr" target="#b34">Palagina et al., 2009</ref>). This search was repeated in a stepwise manner to propagate the current line of membrane progressively until a lower bound at some limit was reached. Neighbouring areas of high response with different orientations were marked as potential junction points and investigated in the same manner. An example from this membrane detection process is shown in<ref type="figure" target="#fig_3">Figure 3</ref>. Dataset S2 contains an open-source reference implementation of the membrane detection algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Feature detection</head><p>Each point of membrane so detected was then classified as synaptic profile, mitochondrion or normal membrane. Filter banks were created by rotating synapse and mitochondron weight matrices to the same orientations to which the membrane Gabor-like patches were rotated. Note that twice the number of orientations were required, because these weight matrices were not symmetrical. At each point of detected membrane, synapse and mitochondria filter responses were calculated by element-wise multiplication and summation. Only two filter responses were calculated for each feature; one at the same orientation of rotation as the detected membrane, and one at the same orientation plus 180 @BULLET. Filter response thresholds were chosen to achieve acceptable error rates for synapse or mitochondria classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Edge closure</head><p>Membranes detected in this way usually failed to produce a fully segmented profile because many lines from obliquely sectioned membranes remained unclosed. We were able to complete closure by identifying end points and joining them to neighbouring lines based on the shortest path through the energy function of the receptive field responses. Dijkstra's shortest path algorithm was used to calculate the shortest path over a four-connected image graph based on the distance function shown in Equation (1), where R x,θ represents the filter response at angle θ, centred at pixel x.</p><formula>Dist xy = max θ R x,θ * max φ R y,φ (1)</formula><p>For correctly detected edges, reasonable closure was achieved with this method, but incorrectly detected edges introduced additional edge errors when closing lines were added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Alignment improvement</head><p>Sequential images can be manually aligned by selecting several pairs of control points corresponding to the same x,y location for consecutive images z1 and z2. This approach is adopted by widely used software, Reconstruct (<ref type="bibr" target="#b13">Fiala, 2005</ref>). Automatic selection of control points is also possible by searching for unique image features in both images, as demonstrated by software TrakEM2 (<ref type="bibr" target="#b9">Cardona et al., 2010a;</ref><ref type="bibr" target="#b36">Saalfeld et al., 2010</ref>). Automatic methods are usually effective at performing a global alignment, but significant local errors can be introduced when too few control points are detected, or when image features are inconsistent between images, as when sections have been locally distorted during microtomy or imaging, resulting in the need for manual correction (<ref type="bibr" target="#b9">Cardona et al., 2010a</ref>). Lines of detected membrane are a useful means to improve an existing image alignment. Because membrane is abundant in EM images, many potential control points can be found by aligning ridge detection results. Drawing on experience with the linear alignment of other biological structures for this purpose, we therefore developed a dynamic programming algorithm, similar to the Needleman–Wunsch (<ref type="bibr" target="#b28">Needleman and Wunsch, 1970</ref>) and Smith–Waterman (<ref type="bibr" target="#b38">Smith and Waterman, 1981</ref>) DNA sequence alignment procedures, with a cost metric based on the euclidean distance and angular subtense. The algorithm also has similarities with sequence matching algorithms implemented in 2D for curve morphing (<ref type="bibr" target="#b19">Jiang et al., 2002</ref>) and in 3D for neuron shape recognition (<ref type="bibr" target="#b10">Cardona et al., 2010b</ref>). We introduced a different cost metric and a modified three-pass alignment procedure that could perform many-to-many alignments and allows branching to occur within sequences. Combinations of this new alignment procedure with the existing application areas allowed morphing of multiple curves at once, and recognition of branching neuron shapes or even networks of branching neurons. Dataset S2 includes an open-source reference implementation of the alignment procedure that can be easily modified for application to other alignment problems such as these. Two consecutive images (z1, z2) from the image stack were aligned by matching sections of detected membrane in z1 with sections in z2, so that the Page: 2219 2216–2223</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biologically inspired neural reconstruction</head><p>distance and angular subtense between all matched points were minimized. This problem was similar to a many-to-many ends-free DNA sequence alignment with the cost metric shown in Equation (2), where d(p 1 ,p 2 ) is the euclidean distance between points p 1 and p 2 , and a is an arbitrary angle constant (a = 20 for our implementation). In principle, alignment can occur in either the forwards or backwards direction, so that low-cost diagonal lines in the cost matrix indicate the best alignment. Similarity matrix H was calculated and the traceback procedure (<ref type="bibr" target="#b28">Needleman and Wunsch, 1970</ref>) used to find the best alignment of points in z1 to points in z2. An example ofa cost matrix and the corresponding alignment points is shown in<ref type="figure" target="#fig_4">Figure 4</ref>. Further details, including the calculation of the similarity matrix, are included in Supplementary Text S1.</p><formula>Cost p 1 ,p 2 = d p 1 ,p 2 +a|p 1θ −p 2θ | (2)</formula><p>Once alignment was complete, the average offset between aligned points was calculated and used to improve alignment between z1 and z2. This process was repeated until the average directional offset was &lt;1 pixel. The result from a single alignment is shown in<ref type="figure" target="#fig_5">Figure 5</ref>. This alignment method assumes that the direction of membrane movement between consecutive images, when averaged over a sufficiently large area, is close to zero. For example, in a given alignment the amount of membrane moving to the left is assumed to be approximately equal to the amount of membrane moving to the right. Depending on the angle of ultrathin sectioning and the particular area of neural tissue being imaged, it is possible that there will be a bias in the direction of overall membrane movement. This bias may exist for the entire image, or for small sections of it, especially where there are large bundles of neurites all running in the same direction. Image alignment in this case does not differentiate between distortions due to preparation or imaging artefacts and areas of bias resulting from membrane movement. Ideally, we would like to correct for distortions while preserving any movement bias. However, considering 2D control points alone makes this problem ambiguous without further information. One solution to this ambiguity is to perform membrane alignment only on the highest-scoring sections of membrane; these sections of membrane have clearer, thinner profiles in the image and are expected to be perpendicular to the cutting plane. In this way, we can assume that any alignment errors are more likely to be from distortions rather than membrane movement and can use a deformation transform with greater confidence. However, this method can still introduce small errors that accumulate, resulting in large errors over many sections. A second solution is to simply use linear translation and rotation for the alignment to ensure that no unwanted distortions are introduced. This method may result in poor alignment where there are large areas of imaging artefacts. Alignment results are considered as the surfaces of cell membranes or organelles in 3D. By combining multiple alignment results, it was possible to generate partial 3D reconstructions as shown in<ref type="figure" target="#fig_6">Figure 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B C</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Knowles-Barley et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>Manual reconstructions of EM data are difficult to compare directly with segmentation derived from algorithms. Reconstructions areusually performed with the intention of tracing the neuron correctly over many sections rather than identifying the exact location of the cell membrane in every image. With these goals in mind, manual reconstructions generate the general shape of the neuron and overall neuron morphology along with the contacts made with other neurons correctly, but with the exact location of membrane not necessarily accurate in all places. In areas where a membrane runs obliquely in the section and appears blurred in its corresponding projection image, or where a large presynaptic density is present (<ref type="figure" target="#fig_1">Fig. 1b</ref>and c), membrane signal can occupy a width of 20 pixels or more at a resolution of 3.7 nm per pixel. For the same dataset, tracing variation between experts can be up to 20 pixels, or 74 nm, depending on both the acceptable level of accuracy of tracing with a manually controlled mouse and true uncertainty in the location of oblique membranes (data not shown). This looseness in manual tracing makes direct comparison between manual and automatic tracing methods difficult to achieve. Choosing a performance metric that recognizes topological correctness rather than small differences in boundary locations (<ref type="bibr" target="#b18">Jain et al., 2010</ref>) and using high-quality datasets against which to assess automatic tracing are both important considerations. To overcome the problem of the disparity between manual and automatic tracing methods, an interactive web interface was developed to view and correct membrane automatically traced from EM images that had previously been annotated manually. Errors made by the algorithm were classified as either false positives (locations where membrane was detected by the algorithm but was not actually present) or false negatives (where membrane was present but not detected) as shown in<ref type="figure" target="#fig_7">Figure 7</ref>. Using the web interface, we identified false positive lines by clicking on them,and drawing in manually the missing, or false negative, lines. Using this method, all errors were identified and a fully traced membrane dataset was constructed within a small volume (Dataset S1). Selected trace results and alignment improvements were imported into manual reconstruction software, Reconstruct (<ref type="bibr" target="#b13">Fiala, 2005</ref>), for direct visual comparison with manual tracing. 3D renderings of results are shown in<ref type="figure" target="#fig_8">Figure 8</ref>. Alignment improvement and semiautomatic tracing produced a more accurate representation of the reconstructed bouton of a projection neuron, the main input neuron to the mushroom body calyx. The semi-automatic annotation is smoother and small misalignments in the z direction are corrected. The correlation coefficient between pairs of consecutive images was also calculated for the volume shown in<ref type="figure" target="#fig_8">Figure 8</ref>. The average correlation coefficient was 0.29 after manual alignment, and 0.32 after alignment improvement using a linear transformation. Note that this level of accuracy can also be achieved by careful manual annotation but would take much longer time to complete. Exact membrane accuracy is usually traded for faster, less accurate tracing that preserves topological correctness. The fully traced membrane dataset was used to optimize and test algorithm performance. Convolutions necessary for the line detection algorithm were implemented on a graphics processing unit (GPU) to improve algorithm speed. Edge detection parameters were first estimated empirically, and then optimized by simplex or gradient descent optimization to maximize metric scores. The Rand index, a commonly used measure of segmentation performance (<ref type="bibr" target="#b35">Rand, 1971;</ref><ref type="bibr" target="#b41">Turaga et al., 2009;</ref><ref type="bibr" target="#b42">Unnikrishnan et al., 2007</ref>), was used to assess performance, as shown in<ref type="figure">Table 1</ref>. Performance was also measured by the number of separating pixels between segments that were correct or incorrect as a proportion of total true positive separating pixels, as shown in<ref type="figure">Table 1</ref>and displayed inRand index is expressed as a measure of similarity, with 1 being identical to the manually corrected segmentation. Separating pixel true positive (Tp) false positive (Fp) and false negative (Fn) rates are shown as a proportion of the total true positive separating pixels. Algorithm parameters were optimized by simplex or gradient descent to find ∼10 times more false positives than false negatives or to maximize the Rand index score. The 5-fold cross-validation was used to validate Rand index scores.Results were assessed before and after edge closure (open edges and closed edges, respectively). Performance is compared against the watershed algorithm applied to an optimized GSH, and to a manually trained random forest classifier (Ilastik). False positives are expressed as a percentage of true separating pixels, as determined by manual annotation. a receiver operator characteristic (ROC) in<ref type="figure" target="#fig_9">Figure 9</ref>. Membrane detected within 10 pixels of manually annotated membrane was considered correct, because for the dataset used here this width would correspond to a flat section of membrane at an oblique angle of 36 @BULLET. Performance was benchmarked against GSH (<ref type="bibr" target="#b27">Mishchenko, 2009;</ref><ref type="bibr" target="#b43">Venkataraju et al., 2009</ref>) and a freely available random forest classifier, ilastik (<ref type="bibr" target="#b39">Sommer et al., 2011</ref>), manually trained on a range of generic features to identify cell membrane. Scores from both these benchmarks were segmented by the watershed algorithm. Parameters were optimized to maximize metric scores in both cases. Responses of the Gabor-like receptive fields were robust to several types of noise sometimes encountered in ssTEM images such as lowcontrast images, blurred or out-of-focus areas and sudden or gradual changes in brightness. After optimization, the ridge detection and edge closure methods were able to join gaps where noise such as oblique membrane or stitching artefacts obscured the receptive field responses. Line segments identified by edge detection and edge closure operations were further classified as enclosing the profile of either a synapse or a mitochondrion by the receptive fields shown in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biologically inspired neural reconstruction</head><p>Page: 2222 2216–2223<ref type="figure" target="#fig_1">Figure 10</ref>. False positive rates were higher than those for membrane detection; however, many false positives were identified in regions near an actual synapse or mitochondria. This level of performance could be useful for narrowing down search areas for manual classification of such biologically significant features. We also trained the ilastik classifier using the membrane receptive field responses as input features. When trained on receptive field responses alone, results were slightly better than those when trained on generic features (0.72 Rand index). Results improved further when trained on both receptive field responses and generic features (0.74 Rand index).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Knowles-Barley et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>We have presented a set of computational methods for EM image alignment and reconstruction, based on a set of receptive fields learnt from EM image data. The identification of many control points for aligning consecutive images can improve upon manual alignment methods and is robust to many types of noise encountered in EM images. Closing edges based on a shortest path algorithm can also achieve a full segmentation of images and additional receptive fields can be used to identify the profiles of synapses and other organelles present in ssTEM images. The ridge detection approach is complementary to existing regional or watershed-based methods, and achieves similar or superior results. Aligning points of membrane by the dynamic programming algorithm is also complementary to existing control point-based alignment methods and can improve upon these in some cases, especially at places where areas of noise or imaging artefacts affect control point properties. An open-source reference implementation of the ridge detection and alignment algorithms is available for download in Dataset S2. The manual alignment and segmentation of detailed ssTEM images is very time consuming, but information on synaptic connections obtained by these means is essential for research in systems neuroscience (<ref type="bibr" target="#b4">Briggman and Denk, 2006</ref>). This reawakened need has recently received renewed recognition, identified in the recently designated field of connectomics (<ref type="bibr" target="#b24">Lichtman and Sanes, 2008</ref>). Inspired by the example of tools used in biology for molecular alignment, the set of methods we report for improved alignment and detection of membrane is able to assist in the time-consuming process of manual annotation. Further information about likely membrane locations is also available from consecutive images in the stack. Areas where membrane alignment is poor between two images in the z-axis may indicate a false positive or false negative identification in either image. Utilization of this additional information and further improvements in both image processing techniques and image quality will help lead to the complete automation of neuronal reconstruction in 3D, and the complete identification and definition of circuits constituted by such reconstructed neurons. Approaches to image analysis based on receptive fields are inspired by research into the visual systems especially of mammals (<ref type="bibr" target="#b16">Hubel and Wiesel, 1959</ref>) and insects (O'<ref type="bibr">Carroll, 1993</ref>), in which visual interneurons have been shown to respond to bars, lines or edges. That area of vision research is under constant evaluation, and advances in it can lead to improved accuracy for segmentation and feature detection. Future avenues of research include identifying additional useful receptive field types and combining outputs from different receptive fields into a layered system for more accurate detection of cell membranes and other organelles. Applying these techniques to ssTEM data offers for the future an improved understanding not only of visual systems but in turn also a further improvement of such computational techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[12:29 22/7/2011 Bioinformatics-btr378.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Examples of manually annotated training image patches from 50 nm thick EM images of the calycal neuropiles of the Drosophila mushroom body (Leiss et al., 2009). Four categories have been annotated: sharp membranes that pass vertically through the section thickness (a), blurred images of obliquely sectioned membrane (b), synaptic profiles (c) and mitochondria (d). Each image patch is 227×227 nm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Weight matrices obtained after training on over 500 manually annotated image patches, such as those in Figure 1, and 400 randomly selected image patches from the same dataset. Supervised learning using a pattern recognition neural network produced results shown in (a). Unsupervised learning using SOM produced similar results (b). Weight matrices from (a) were used as a basis for the membrane detection algorithm. Pixel colours represent weights from input pixels, as shown in the right-hand keys.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Membrane detection steps. (A) Original EM image. (B) Maximum filter responses (combined over all angles). (C) Results from automatic membrane detection and mitochondria / synapse classification results. Green lines indicate automatically detected membrane, red circles highlight automatically detected membrane that is classified as organelle (and therefore possibly false positive) and blue circles highlight automatically detected membrane that is classified as synapse. Each image is 1.4×1.4µm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Cost matrix obtained by calculating distance cost in Equation (4) (a = 20) for each combination of points between z1 and z2. Points of membrane from consecutive images z1 and z2 were ordered into two sequences preserving individual line segments, as described in Supplementary Material S1. Each row corresponds to a point in z1 and each column corresponds to a point in z2. Cost matrix entries (orange to yellow) give the cost of matching points from z1 and z2. The best matching line segments appear as low cost (yellow) diagonal lines in this matrix. Blue dots highlight the resulting alignment after calculating similarity matrix H (data not shown) and performing the traceback procedure. This alignment corresponds to the alignment shown in Figure 5B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. Alignment is improved by minimizing the average distance between all pairs of aligned points. (A) Start state. Points from z1(×) and z2(@BULLET) are shown before alignment. (B) Alignment results based on Figure 4. Each pair of aligned points is shown as connected dots. Unmatched points remain as × or @BULLET. A transformation was applied to z1 to minimize the distance between pairs of aligned points. (C) End state after repeated iteration of the alignment algorithm. Average directional offset between all aligned points is &lt;1 pixel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.6.</head><figDesc>Fig. 6. 3D rendering of membrane based on images from Figures 3 and 5. Segments of membrane aligned by the algorithm are represented as surfaces in this image. Six consecutive image patches were used. Surface colour (green to blue) represents z depth. Volume reconstructed is 1.4×1.4× 0.3 µm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.7.</head><figDesc>Fig. 7. Segmentation evaluation. (A) Test EM image. (B) After ridge detection, edge closure and manual correction. True positives (green, 97.4%) false positives (red, 14.9%), false negatives (blue 2.6%). Image size is 2.8×2.8 µm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.8.</head><figDesc>Fig. 8. 3D renderings of a reconstructed bouton and axon of a mushroom body calycal projection neuron. Left: manual alignment and tracing. Right: the same volume after alignment improvement and semi-automatic tracing. Small alignment errors are improved, resulting in a less jagged surface profile. Scale bars: 0.5 µm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig.9.</head><figDesc>Fig. 9. ROC curve for membrane detection performance after optimization. Results were assessed before and after edge closure (open edges and closed edges, respectively). Performance is compared against the watershed algorithm applied to an optimized GSH, and to a manually trained random forest classifier (Ilastik). False positives are expressed as a percentage of true separating pixels, as determined by manual annotation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.10.</head><figDesc>Fig. 10. ROC curve for feature detection performance of synapse and mitochondria profiles. Line segments found by the edge detection and edge closure were classified as either synapses or mitochondria, and results were manually corrected. False positive rates are expressed as a percentage of line segments not in the target class (line segments that do not form part of any synapse or mitochondria).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure2a.</head><figDesc>Figure 2a. Feature detection performance is shown in Figure 10. False positive rates were higher than those for membrane detection; however, many false positives were identified in regions near an actual synapse or mitochondria. This level of performance could be useful for narrowing down search areas for manual classification of such biologically significant features. We also trained the ilastik classifier using the membrane receptive field responses as input features. When trained on receptive field responses alone, results were slightly better than those when trained on generic features (0.72 Rand index). Results improved further when trained on both receptive field responses and generic features (0.74 Rand index).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Membrane detection performance</figDesc><table>Rand index 
Tp 
Fp 
Fn 

Open edges 
0.791 
0.976 
0.254 
0.024 
Closed edges 
0.762 
0.978 
0.282 
0.022 
Ilastik/watershed 
0.711 
0.973 
0.283 
0.027 
GSH/watershed 
0.718 
0.948 
0.521 
0.052 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>We thank Zhiyuan Lu for cutting and imaging the series of ultrathin sections used in our analysis.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">A computational framework for ultrastructural mapping of neural circuitry</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Anderson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1000074" to="0493" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Segmentation of SBFSEM volume data of neural tissue by hierarchical classification</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Andres</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Lecture Notes in Computer Science</title>
		<editor>Rigoll,G.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">5096</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="142" to="152" />
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Anatomical origins of the classical receptive field and modulatory surround field of single neurons in macaque visual cortical area V1</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Angelucci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progr. Brain Res</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="373" to="388" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">The watershed transformation applied to image segmentation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Beucher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scanning Microscopy International</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards neural circuit reconstruction with volume electron microscopy techniques</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">L</forename>
				<surname>Briggman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Denk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="562" to="570" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="29" to="51" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2223" to="2216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Biologically inspired neural reconstruction</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Do we know what the early visual system does?</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Carandini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="10577" to="10597" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">An integrated micro-and macroarchitectural analysis of the Drosophila brain by computer-assisted serial section electron microscopy</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cardona</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1000502" to="1000503" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Identifying neuronal lineages of Drosophila by sequence analysis of axon tracts</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cardona</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="7538" to="7553" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Semi-automated reconstruction of neural circuits using electron microscopy</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">B</forename>
				<surname>Chklovskii</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="667" to="675" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural circuits: putting neurons on the map</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Eisenstein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">461</biblScope>
			<biblScope unit="page" from="1149" to="1152" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Reconstruct: a free editor for serial section microscopy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Fiala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Microsc</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="52" to="61" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Pt. 1</note>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Seeing beyond the receptive field in primary visual cortex</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Fitzpatrick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="438" to="443" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Inhibition in the eye of Limulus</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">K</forename>
				<surname>Hartline</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Gen. Physiol</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="651" to="673" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Receptive fields of single neurones in the cat&apos;s striate cortex</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H</forename>
				<surname>Hubel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">N</forename>
				<surname>Wiesel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Physiol</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="574" to="591" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Response facilitation from the &apos;Suppressive&apos; receptive field surround of Macaque V1 neurons</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Ichida</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="2168" to="2181" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Machines that learn to segment images: a crucial technology for connectomics</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Jain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="653" to="666" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Curve morphing by weighted mean of strings</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 16th International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="192" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">An optimal-path approach for neural circuit reconstruction</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Jurrus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Biomedical Imaging: From Nano to Macro</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1609" to="1612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Neuron geometry extraction by perceptual grouping in ssTEM images</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Kaynig</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2902" to="2909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Computer visualization of three-dimensional image data using IMOD</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Kremer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Struct. Biol</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="71" to="76" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Synaptic organization in the adult Drosophila mushroom body calyx</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Leiss</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Neurol</title>
		<imprint>
			<biblScope unit="volume">517</biblScope>
			<biblScope unit="page" from="808" to="824" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Ome sweet ome: what can the genome tell us about the connectome?</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Lichtman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Sanes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="346" to="353" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">A multi-scale line filter with automatic scale selection based on the Hessian Matrix for medical image segmentation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lorenz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Scale-Space Theory in Computer Vision, SCALE-SPACE &apos;97</title>
		<meeting>the First International Conference on Scale-Space Theory in Computer Vision, SCALE-SPACE &apos;97<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="152" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Synaptic organization of columnar elements in the lamina of the wild type in Drosophila melanogaster</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">A</forename>
				<surname>Meinertzhagen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O &apos;</forename>
				<surname>Neil</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">D</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Neurol</title>
		<imprint>
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="page" from="232" to="263" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Automation of 3D reconstruction of neural tissue from large volume of conventional serial section transmission electron micrographs</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Mishchenko</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="276" to="289" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A general method applicable to the search for similarities in the amino acid sequence of two proteins</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">B</forename>
				<surname>Needleman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Wunsch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="443" to="453" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Feature-detecting neurons in dragonflies</title>
		<author>
			<persName>
				<forename type="first">O &apos;</forename>
				<surname>Carroll</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page" from="541" to="543" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">A</forename>
				<surname>Olshausen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Field</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="page" from="607" to="609" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">How close are we to understanding V1?</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">A</forename>
				<surname>Olshausen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Field</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1665" to="1699" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Relationship between excitation and inhibition underlying size tuning and contextual response modulation in the cat primary visual cortex</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Ozeki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1428" to="1438" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Inhibitory stabilization of the cortical network underlies visual surround suppression</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Ozeki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="578" to="592" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Strengthening of lateral activation in adult rat visual cortex after retinal lesions captured with voltage-sensitive dye imaging in vivo</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Palagina</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="8743" to="8747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">M</forename>
				<surname>Rand</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">As-rigid-as-possible mosaicking and serial section registration of large ssTEM datasets</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Saalfeld</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="57" to="63" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Circuit reconstruction tools today</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">J</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurobiol</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="601" to="608" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Identification of common molecular subsequences</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">F</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Waterman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="195" to="197" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">ilastik: Interactive Learning and Segmentation Toolkit</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sommer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Biomedical Imaging: From Nano to Macro IEEE International Symposium on</title>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="230" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Synaptic circuits of the Drosophila optic lobe: the input terminals to the medulla</title>
		<author>
			<persName>
				<forename type="first">S.-Y</forename>
				<forename type="middle">Y</forename>
				<surname>Takemura</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Neurol</title>
		<imprint>
			<biblScope unit="volume">509</biblScope>
			<biblScope unit="page" from="493" to="513" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">Maximin affinity learning of image segmentation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">C</forename>
				<surname>Turaga</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1865" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Toward objective evaluation of image segmentation algorithms</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Unnikrishnan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="929" to="944" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Automatic markup of neural cell membranes using boosted decision stumps</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">U</forename>
				<surname>Venkataraju</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth IEEE international conference on Symposium on Biomedical Imaging</title>
		<meeting>the Sixth IEEE international conference on Symposium on Biomedical Imaging</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1039" to="1042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">The structure of the ventral nerve cord of Caenorhabditis elegans</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">G</forename>
				<surname>White</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. R. Soc. London Ser. B Biol. Sci</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="327" to="348" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">Line detection using an optimal IIR filter</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ziou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="465" to="478" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>