
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-11T00:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining Two effective methods for correcting experimental high-throughput screening data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">. 13 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Plamen</forename>
								<surname>Dragiev</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Département d&apos;Informatique</orgName>
								<orgName type="institution">Université du Québec à Montréal</orgName>
								<address>
									<addrLine>C.P.8888, s. Centre-Ville</addrLine>
									<postCode>H3C-3P8</postCode>
									<settlement>Montréal</settlement>
									<region>QC</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Genome Quebec Innovation Centre</orgName>
								<address>
									<addrLine>740 Dr. Penfield Ave</addrLine>
									<postCode>H3A-1A4</postCode>
									<settlement>Montreal</settlement>
									<region>QC</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Robert</forename>
								<surname>Nadon</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Genome Quebec Innovation Centre</orgName>
								<address>
									<addrLine>740 Dr. Penfield Ave</addrLine>
									<postCode>H3A-1A4</postCode>
									<settlement>Montreal</settlement>
									<region>QC</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Human Genetics</orgName>
								<orgName type="institution">McGill University</orgName>
								<address>
									<addrLine>1205 Dr. Penfield Ave</addrLine>
									<postCode>N5/13, H3A-1B1</postCode>
									<settlement>Montreal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Vladimir</forename>
								<surname>Makarenkov</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Département d&apos;Informatique</orgName>
								<orgName type="institution">Université du Québec à Montréal</orgName>
								<address>
									<addrLine>C.P.8888, s. Centre-Ville</addrLine>
									<postCode>H3C-3P8</postCode>
									<settlement>Montréal</settlement>
									<region>QC</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining Two effective methods for correcting experimental high-throughput screening data</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="1775" to="1782"/>
							<date type="published" when="2012">. 13 2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts262</idno>
					<note type="submission">Received on January 26, 2012; revised on April 3, 2012; accepted on April 30, 2012</note>
					<note>Copyedited by: TRJ MANUSCRIPT CATEGORY: ORIGINAL PAPER [16:53 13/6/2012 Bioinformatics-bts262.tex] Page: 1775 1775–1782 Associate Editor: Martin Bishop Contact: makarenkov.vladimir@uqam.ca Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Rapid advances in biomedical sciences and genetics have increased the pressure on drug development companies to promptly translate new knowledge into treatments for disease. Impelled by the demand and facilitated by technological progress, the number of compounds evaluated during the initial high-throughput screening (HTS) step of drug discovery process has steadily increased. As a highly automated large-scale process, HTS is prone to systematic error caused by various technological and environmental factors. A number of error correction methods have been designed to reduce the effect of systematic error in experimental HTS (Brideau et al., 2003; Carralot et al., 2012; Kevorkov and Makarenkov, 2005; Makarenkov et al., 2007; Malo et al., 2010). Despite their power to correct systematic error when it is present, the applicability of those methods in practice is limited by the fact that they can potentially introduce a bias when applied to unbiased data. We describe two new methods for eliminating systematic error from HTS data based on a prior knowledge of the error location. This information can be obtained using a specific version of the t-test or of the χ 2 goodness-of-fit test as discussed in Dragiev et al. (2011). We will show that both new methods constitute an important improvement over the standard practice of not correcting for systematic error at all as well as over the B-score correction procedure (Brideau et al., 2003) which is widely used in the modern HTS. We will also suggest a more general data preprocessing framework where the new methods can be applied in combination with the Well Correction procedure (Makarenkov et al., 2007). Such a framework will allow for removing systematic biases affecting all plates of a given screen as well as those relative to some of its individual plates.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A typical drug development project starts with a candidate identification phase in which a large chemical compound library is tested against a given biological target (<ref type="bibr" target="#b9">Malo et al., 2006</ref>). Complex high-throughput screening equipment is employed at this * To whom correspondence should be addressed. stage to obtain precise estimates of compound activity levels. The collected data are then used to identify the compounds that show the most promising 'drug-like' activity behavior (<ref type="bibr" target="#b0">Brideau et al., 2003;</ref><ref type="bibr" target="#b9">Malo et al., 2006</ref>). The selected compounds, called hits, typically undergo further testing to confirm their reproducibility and suitability for drug development. Depending on the nature of the study, the hits may be compounds with the highest activation capacity (i.e. activation assays), inhibition capacity (i.e. inhibition assays) or both. The hit selection process assumes that the measurements taken by HTS equipment accurately represent the activity levels of the tested compounds. An important consideration for this to be true is that experimental conditions are the same for all compounds of the screen. Biases in the measurements can nonetheless appear, due to inconsistencies in the environmental factors, such as electricity, temperature, humidity or lighting changes (<ref type="bibr" target="#b5">Heyse, 2002;</ref><ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>). Organizational factors can also have a significant systematic impact on the results of an HTS campaign. For example, differences in the incubation time allow the solvent evaporation to cause unintended variations in the solution concentrations. Highly sensitive readers in particular can detect subtle differences among the tested molecules which misdirect follow-up efforts when they are due to bias rather than to biology. As a result of systematic bias causing under-or over-estimation of biological activity, inactive compounds may be incorrectly selected as hits (false positives), whereas promising (active) compounds may remain undetected (false negatives). In HTS, systematic error is usually column or row dependent (<ref type="bibr" target="#b0">Brideau et al., 2003;</ref><ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>). It is important to note that systematic error can either affect compounds placed in the same well, column or row location in all plates of the screen (i.e. screen-specific error) or affect a column or row of a specific single plate of the screen (i.e. plate-specific error).<ref type="figure">Figure 1</ref>illustrates the presence of positional effects in two publicly available experimental HTS datasets: McMaster Test dataset, used as a benchmark for the McMaster Data Mining and Docking Competition (<ref type="bibr" target="#b3">Elowe et al., 2005</ref>; it contained the compounds intended to inhibit the Escherichia coli Dihydrofolate reductase, DHFR) and a dataset provided by the Chemistry Department of Princeton University and consisting of a screen of compounds meant to inhibit the glycosyltransferase MurG function of E. coli (<ref type="bibr" target="#b4">Helm et al., 2003</ref>).<ref type="figure">Figures</ref>examples demonstrate that systematic biases in HTS may have different screen-specific and plate-specific systematic deviations. For instance, in the McMaster dataset, the measurements in the column 10 are globally over-estimated (<ref type="figure">Fig. 1a</ref>), but in plate 1036 they are rather under-estimated (<ref type="figure">Fig. 1b</ref>). Similarly,<ref type="figure">Figure 1c</ref>reveals apparent 'edge effects' in the Princeton dataset with the values of the outer rows and columns being below the screen average. This effect was not observed, however, for all plates of the Princeton screen, with an evident over-estimation of the first column measurements detected in plate 144 (<ref type="figure">Fig. 1d</ref>). Thus, systematic error correction methods should be able first to recognize the character of systematic error affecting the data at hand and then remove it either from the whole assay and/or only from the specific plates where it was detected. In this article, we describe two new methods for eliminating plate-specific systematic error and show how these methods can be applied in a more general correction framework that also includes the Well Correction procedure (<ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>) which allows for removing screen-specific systematic biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data preprocessing in HTS</head><p>To analyze experimental HTS assays, a data preprocessing treatment should be performed before the hit selection. Several data normalization and correction techniques, including the step of the quality control, have been proposed to preprocess experimental HTS data (<ref type="bibr" target="#b0">Brideau et al., 2003;</ref><ref type="bibr" target="#b1">Carralot et al., 2012;</ref><ref type="bibr" target="#b2">Dragiev et al., 2011;</ref><ref type="bibr" target="#b6">Kevorkov and Makarenkov, 2005;</ref><ref type="bibr" target="#b8">Makarenkov et al., 2007;</ref><ref type="bibr" target="#b9">Malo et al., 2006</ref><ref type="bibr" target="#b10">Malo et al., , 2010</ref><ref type="bibr" target="#b11">Shun et al., 2011;</ref><ref type="bibr" target="#b13">Zhang, 2008;</ref><ref type="bibr" target="#b14">Zhang et al., 1999</ref>). The most popular data normalization procedures used in HTS are as follows: Percent of control that normalizes the given compound measurements relative to the mean value of the plate's positive controls; Normalized percent inhibition in which the normalization is carried out relative to both positive and negative controls; and Z-score that consists in a zero mean and unit SD normalization of the plate's measurements (<ref type="bibr" target="#b9">Malo et al., 2006</ref>). Regarding data correction, mention the B-score (<ref type="bibr" target="#b0">Brideau et al., 2003</ref>) and Well Correction (<ref type="bibr" target="#b7">Makarenkov et al., 2006</ref><ref type="bibr" target="#b8">Makarenkov et al., , 2007</ref>) methods which will be considered in this study. Their main steps of these methods are as follows: B-score (<ref type="bibr" target="#b0">Brideau et al., 2003</ref>) is a robust normalization procedure commonly used in experimental HTS. Similarly to the above-mentioned normalizations, B-score sensibly handles plate-to-plate variability. In addition, it also corrects the raw plate measurements by removing the existing row and column positional effects. It assumes the following statistical model of HTS measurements [Equation (1)]:</p><formula>x ijp = μ p +R ip +C jp +ε ijp ,</formula><formula>(1)</formula><p>where x ijp is the raw measurement of the compound in well (i, j) of a given plate p, μ p is the plate average, R ip is the systematic error affecting row i, C jp is the systematic error affecting column j and ε ijp is the random noise affecting well (i, j) of this plate. B-score first uses a two-way median polish (MP) procedure (<ref type="bibr" target="#b12">Tukey, 1977</ref></p><formula>ˆ x ijp = ˆ μ p + ˆ R ip + ˆ C jp .</formula><formula>(2)</formula><p>The residual, r ijp , for the measurement in well (i, j) is then calculated as the difference between the raw measurement x ijp and its fitted valuê x ijp : r ijp = x ijp − ˆ x ijp. Finally, the raw compound measurement is replaced with the corresponding residual adjusted by the plate's median absolute deviation<ref type="bibr">[</ref>where x ijp is the normalized measurement value. Well Correction (<ref type="bibr" target="#b7">Makarenkov et al., 2006</ref><ref type="bibr" target="#b8">Makarenkov et al., , 2007</ref>) is another combined data normalization and correction method designed to compensate for positional effects affecting rows, columns or individual wells, and appearing in all plates of the screen (i.e. screen-specific error). Well Correction includes the two following steps:</p><p>(1) For each well location of the screen, a linear or polynomial leastsquares approximation is carried out for the compound measurements located in that well over all plates of the screen. This approximation is performed separately for each well location.</p><p>(2) The approximated entities within the same well location are then normalized over all plates of the screen using Z-score. This normalization is performed separately for each well location. Once the data normalization and correction steps are completed, a hit selection procedure, meant to identify the compounds that will be promoted to leads, is carried out. The most popular strategy for hit selection proceeds by the identification of the compounds whose activity levels exceed a predefined threshold (<ref type="bibr" target="#b9">Malo et al., 2006</ref>). Typically, the hit selection threshold is expressed in terms of the mean, μ, and the SD of the observed measurements. A commonly used approach selects as hits the compounds whose activity levels deviate from the mean value μ for &gt;3SD. Despite their ability to eliminate systematic error, HTS preprocessing techniques cannot guarantee the recovery of correct hits. In our previous works (<ref type="bibr" target="#b2">Dragiev et al., 2011;</ref><ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>), we showed that a misapplication of error correction methods on error-free HTS data introduces a significant bias that affects very negatively the accuracy of the hit selection process. For instance, a simulation study described in<ref type="bibr">Makarenkov et al.</ref>Copyedited by: TRJ MANUSCRIPT CATEGORY: ORIGINAL PAPER<ref type="bibr">[</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correction of experimental screening data</head><p>(2007) suggests that the B-score method is unable to cope with screenspecific systematic error (Figs 2 and 3 in the latter study) and that the Well Correction method is not suited for eliminating plate-specific systematic error (<ref type="figure" target="#fig_4">Fig. 4</ref>in the latter study). Hence, error correction methods should be used with caution and only when the presence of systematic noise in the data has been confirmed by statistical tests. In our recent work (<ref type="bibr" target="#b2">Dragiev et al., 2011</ref>), we described how individual HTS plates can be assessed for presence of systematic error, thus facilitating the decision regarding the application of data correction techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Two new data correction methods</head><p>Here we present two new methods for HTS systematic error correction, called Matrix Error Amendment (MEA) and Partial Mean Polish (PMP). Both methods rely on prior information concerning the location of rows and columns of individual plates that are systematically over-or under-estimated. Such information might be available through the analysis of an individual plate (or entire screen) background (<ref type="bibr" target="#b6">Kevorkov and Makarenkov, 2005</ref>) or can be acquired using a specific version of the t-test or of the χ 2 goodnessof-fit test (<ref type="bibr" target="#b2">Dragiev et al., 2011</ref>; see also the Supplementary Materials section for the application of these tests in the HTS context). Both MEA and PMP methods are applied on a plate-by-plate basis. Let X be a plate of HTS measurements with m rows and n columns. Let x ij be the measurement of the compound located in well (i, j) of X and let μ be the mean value of all measurements of plate X that are not affected by systematic error. In the case when plate X is free of systematic error, we can expect that the mean of the values in a given row i (i = 1, …, m) does not deviate substantially from μ, which in this case is the mean of all measurements on the plate: n j=1 x ij ≈ nμ. Similarly, for a given column j (j = 1, …, n) of X , we expect that: m i=1 x ij ≈ mμ.</p><p>Assume that X is affected by systematic error. Let r 1 , r 2 ,…, r p (p &lt; m) be the set of rows of X , and c 1 , c 2 ,…,c s (s &lt; n) be the set of columns of X , where the presence of systematic error has been confirmed. It is worth noting that the set r 1 , r 2 , …, r p can represent any subset of the complete set of rows 1, 2, …, m and the set c 1 , c 2 , …, c s can represent any subset of the complete set of columns 1, 2, …, n of plate X. The only necessary condition for the application of the new methods is the presence in X of at least one row and at least one column not affected by systematic error. Let e r i be the unknown value of systematic error affecting row r i and e c j be the unknown value of systematic error affecting column c j. The following 4-fold set of linear equations can be composed:</p><formula>n j=1 x r i j −ne r i − s j=1 e c j = nμ,</formula><formula>(4) m i=1 x ic j −me c j − p i=1 e r i = mμ,</formula><formula>(5) n j=1 x ij − s j=1 e c j = nμ,</formula><formula>(6) m i=1 x ij − p i=1 e r i = mμ,</formula><formula>(7)</formula><p>where Equation (4) corresponds to rows r 1 ,r 2 ,...,r p affected by row systematic error, Equation (5) to columns c 1 , c 2 ,…, c s affected by column systematic error, Equation (6) to rows not affected by row systematic error and Equation (7) to columns not affected by column systematic error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MEA method</head><p>Systematic error in HTS does not typically affect all the columns and rows of a plate. The affected columns and rows are often those located on the plate edges (<ref type="bibr" target="#b0">Brideau et al., 2003;</ref><ref type="bibr" target="#b6">Kevorkov and Makarenkov, 2005</ref>). Thus, typically, p is much smaller than m and s is much smaller than n. The presence of rows and columns not affected by systematic error allows us to estimate μ and leaves e r i and e c j the only unknowns in the linear system of equations</p><p>(4)–(7), which have m+n equations and fewer than m+n unknowns. The MEA method consists of the two following steps:</p><p>(1) Estimate the values of the row and column systematic errorsêerrorsˆerrorsê r i andê andˆandê c j (i = 1, …, p and j = 1, …, s), independently for every plate of the assay, by solving the system of linear equations (4)–(7).Two approaches of solving the system of linear equations (4)–(7) were tested in our study. First, by combining all Equations (4)–(7), we composed an over-determined system of linear equations Ae=b with m+n equations and fewer than m+n unknowns, where A was the matrix of the coefficients for the unknowns e r i and e c j (i = 1, …, p and j = 1, …, s) combined in the vector e of size p+s, and b was the vector of free terms. We found that in all cases the matrix A T A was singular, thus rendering inapplicable the standard least-square approximation method for solving over-determined systems of linear equations. We were able, however, to find an approximate solution of this system by using the singular value decomposition (SVD) method. Second, we also tested a simpler and computationally less intensive approach consisting of combining only Equations (4) and (5) into the linear system (8), having exactly m+n equations and m+n unknowns. When m+n &gt; 5, the system (8) always has a unique solution which can be found using standard methods for solving linear equations systems (e.g. Gaussian elimination).</p><formula>⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ n 0 ... 0 0 1 1 ... 1 1 0 n ... 0 0 1 1 ... 1 1 . . . . . . .. . . . . . . . . . . . . . .. . . . . . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">... n 1 1 ... 1 1 ... n 1 1 ... 1 1 1 1 ... 1 1 m ... 1 1 ... 1 1 m ... 0</head><formula>0 . . . . . . .. . . . . . . . . . . . . . .. . . . . . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">... 0 0 ... m 0 ... 0 0 ... 0 m</head><formula>⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ e r 1 e r 2 . . . e r p−1 e rp e c 1 e c 2 . . . e c s−1 e cs ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ = ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ b r 1 b r 2 . . . b r p−1 b rp b c 1 b c 2 . . . b c s−1 b cs ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ,</formula><formula>(8)</formula><p>where b r i = n j=1 x r i j −nμ and b c j = m j=1 x ic j −mμ. According to our simulation study, the second approach, which requires less computer power, generally provided better results in terms of systematic error identification (i.e. it yielded a higher hit detection rate, see Section 3.1). Thus, its detailed results are presented in Section 3. The final step of the MEA method proceeds by subtracting the obtained systematic error estimatesêestimatesˆestimatesê r i andêandˆandê c j from the raw plate measurements [Equations (9)–<ref type="bibr">(10)]</ref>. For all rows r i (i = 1, …, p) affected by systematic error, we have:</p><formula>x r i j = x r i j − ˆ e r i , for all j : 1 j n,</formula><formula>(9)</formula><p>and for all columns c j (j = 1, …, s) we have:</p><formula>x ic j = x ic j − ˆ e c j , for all i : 1 i m.</formula><formula>(10)</formula><p>PMP method Denote by μ i the mean value of all measurements in row i and by μ j the mean value of all measurements in column j of plate X :</p><formula>μ i = 1 n n j=1 x ij and μ j = 1 m m i=1 x ij .</formula><p>Equations (4) and</p><p>(5) can be rewritten as Equations (11) and</p><p>(12):</p><formula>ne r i = n j=1 x r i j −nμ− s j=1 e c j ,</formula><formula>(11)</formula><formula>me c j = m i=1 x ic j −mμ− p i=1 e r i ,</formula><formula>(12)</formula><p>where μ is the mean value of all measurements of X not affected by systematic error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.Dragiev et al.</head><p>Dividing Equations (11) and</p><p>(12) by n and m, respectively, we obtain:</p><formula>e r i = μ r i −μ− 1 n s j=1 e c j ,</formula><formula>(13)</formula><formula>e c j = μ c j −μ− 1 m p i=1 e r i .</formula><formula>(14)</formula><p>Since systematic error usually affects only a few columns and rows of HTS plates [e.g. row and column measurements on plate edges are often biased; for more details see<ref type="bibr" target="#b0">Brideau et al. (2003)</ref>or Kevorkov and<ref type="bibr" target="#b6">Makarenkov (2005)]</ref>and causes an over-or under-estimation of the affected measurements (i.e. the error values can be negative or positive), we can assume that the term consisting of the total column error divided by the number of columns has a negligible impact compared with the other terms in Equation (13) and thus that the row systematic error of row r i can be estimated as the difference between the mean value of the entities in that row and the mean value μ of the plate measurements that are not affected by systematic error:</p><formula>ˆ e r i = μ r i −μ.</formula><formula>(15)</formula><p>Similarly, for the column c j , we can expect that:</p><formula>ˆ e c j = μ c j −μ.</formula><formula>(16)</formula><p>Based on the assumptions above, we can formulate the PMP iterative procedure (only a part of the plate's rows and columns, i.e. those affected by systematic bias, will be 'polished' by the method). The means in this procedure can be easily replaced by the medians giving rise to the Partial Median Polish method which could be viewed as an extension of a wellknown Median Polish procedure by<ref type="bibr" target="#b12">Tukey (1977)</ref>for the case when the error locations are known. The main steps of the PMP method are the following:</p><p>(1) Compute the mean value μ of all entities of the given plate that are not affected by systematic error: μ = i / ∈R,j / ∈C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>x ij</head><p>(m−p)(n−s) , where R ={r 1 ,r 2 ,...,r p |0 ≤ p &lt; m} is a set of rows of X affected by systematic error and C ={c 1 ,c 2 ,...,c s |0 ≤ s &lt; n} is a set of columns of X affected by systematic error.</p><p>(2) For each i (1 ≤ i ≤ p), compute the mean value, μ r i , of row r i as</p><formula>μ r i = 1 n n j=1 x r i j</formula><p>, and then, using Equation (15), the estimate of the row biasêbiasˆbiasê r i as: ˆ e r i = μ r i −μ. For each j (1 ≤ j ≤ s) compute the mean value, μ c j , of column c j as</p><formula>μ c j = 1 m m i=1 x ic j ,</formula><p>and then, using Equation (16), the estimate of the column biasêbiasˆbiasê c j as:</p><formula>ˆ e c j = μ c j −μ.</formula><p>(3) For all rows affected by systematic bias, adjust their measurements using the error estimates determined in Step 2, i.e. for each i (1 ≤ i ≤ p), and for each j (1 ≤ j ≤ n):</p><formula>x r i j = x r i j − ˆ e r i .</formula><p>For all columns affected by systematic error, adjust their measurements using the error estimates determined in Step 2, i.e. for each j (1 ≤ j ≤ s), and for each i</p><formula>(1 ≤ i ≤ m): x ic j = x ic j − ˆ e c j .</formula><p>(4) Compute the value of the convergence parameter δ:</p><formula>δ = p i=1 | ˆ e r i |+ s j=1 | ˆ e c j |.</formula><p>(5) If δ &lt;ε, where ε is a selected convergence threshold, or if a fixed maximum number of iterations has been already carried out, then return X , otherwise, repeat Steps 2–5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head><p>To evaluate the performances of the two introduced systematic error correction methods we first carried out simulations with artificially generated HTS measurements. We also applied both MEA and PMP methods to analyse the 1250-plate HTS screen produced at the HTS Laboratory of McMaster University (i.e. the Test dataset proposed as a benchmark for the McMaster Data Mining and Docking Competition, see<ref type="figure">Fig. 1</ref>and<ref type="bibr" target="#b3">Elowe et al., 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simulation study</head><p>The simulated data also consisted of 1250-plate assays. Plate sizes were 96-well plates (8 rows × 12 columns), 384-well plates (16 rows × 24 columns) and 1536-well plates (32 rows × 48 columns). Inactive compound measurements were generated according to the standard normal distribution. Active compounds (hits) were added randomly to the plates to form assays with the following hit percentages: 0, 0.5, 1, 2, 3, 4 and 5%. Hit locations were chosen randomly within each plate (i.e. the probability that a given well contained a hit compound was the same for all wells of the plate, regardless of the well location within the plate). The hit measurements were generated according to the normal distribution with parameters ∼N (μ–5SD, SD), where μ and SD were the mean and standard deviation of the original dataset (obtained before the addition of hits; i.e. μ = 0 and SD = 1). Systematic row and column errors were added to randomly selected rows and columns of each plate. The rows and columns affected by systematic error were selected separately for each plate, and thus their locations differed from plate to plate. The values of systematic bias followed a normal distribution with parameters ∼ N (0, C). The following values of the error, C, were considered to generate assays affected by different degree of systematic error: 0, 0.6, 1.2, 1.8 and 2.4SD. To mimic empirical HTS data, in our first simulations the effect of systematic error was limited to a few rows and columns only. Thus, at most@BULLET PMP method performed under the assumption that the exact locations of the error-affected rows and columns on each plate of the assay are known; @BULLET PMP method performed for the rows and columns where systematic error was detected by the t-test (for more details, see<ref type="bibr" target="#b2">Dragiev et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correction of experimental screening data</head><p>In all experiments, we assessed the performances of the six data preprocessing methods by measuring the total number of false positives and false negatives, and by estimating the methods hit detection rate (i.e. true positive rate). We conducted two series of experiments to evaluate the methods performances depending on the hit percentage and the variance of systematic error. The first series of experiments used datasets with the fixed systematic error of 1.2SD and the hit percentage rate varying from 0% to 5% (there are no true positives for the case of 0% of hits; see Figs 2–4a). The second series of experiments considered datasets with the fixed hit percentage of 1% and the systematic error varying from 0 to 2.4SD. Some 500 datasets were generated for both series of experiments and for each parameter combination. Figures 2–4 present the average results obtained for the two series of experiments for the 96-well, 384-well and 1536-well plates, respectively. Furthermore, we conducted additional simulations to assess the performances of the MEA and PMP methods in the situation when up to 50% of the plates' rows and columns were affected by systematic bias. The graphics depicting relative performances of the MEA, PMP, B-score and no-correction strategies in this case are presented in Supplementary Figures 1S–3S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.Dragiev et al.</head><p>of the plate's total number of rows and columns (see Supplementary Figs 1S–3S), the MEA and PMP methods generally yielded better results than B-score when the hit percentage was under 3% (see Supplementary Figs 1S–3S, cases a and b) or when the level of systematic error was under 1.8SD (see Supplementary Figs 1S–3S, cases c and d). However, in the situations when the hit percentage or systematic error variance was high, the B-score procedure generally showed a more stable behavior than the new methods. This was largely due to the fact that the performance of the t-test, carried out prior to MEA and PMP, decreases as the amount of data affected by systematic error grows (<ref type="bibr" target="#b2">Dragiev et al., 2011</ref>). In general, the MEA method turned out to be the best performing method for correcting systematic error within 96-well plates when the systematic error variance or the hit percentage was low (see<ref type="figure" target="#fig_0">Fig. 2</ref>and Supplementary<ref type="figure">Fig. 1S</ref>), whereas the PMP method provided better results than MEA for the 96-well plates when the systematic error variance or the hit percentage was elevated as well as for the 384-and 1536-well plates (see Figs 3 and 4; Supplementary Figs 2S and 3S). It is worth noting that the B-score method was very prone to generating false positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analysis of the McMaster Test assay</head><p>We carried out the MEA and PMP methods to analyse the McMaster Data Mining and Docking Competition Test assay (see<ref type="bibr" target="#b3">Elowe et al., 2005 and</ref><ref type="figure">Fig. 1a</ref>and b). We examined their impact on the hit identities determined during the HTS phase of the project. This dataset consisted of 625, 96-well plates (with 8 rows and 12 columns) screened in duplicate. Columns 1 and 12 of all plates contained controls and thus were not considered in our study. The assay conditions were identical for all plates. They were as follows: Each 200 μl reaction mixture contained 40 μM NADPH, 30 μM DHF, 5 nM DHFR, 50 mM Tris (pH 7.5), 0.01% (w/v) Triton and 10 mM β-mercaptoethanol. The compounds from the screening library were added to the reaction before initiation by enzyme at a final concentration of 10 μM. All measurements were taken at 25 @BULLET C. The threshold of μ–2.29SD was used to identify hits. This threshold led to the identification of 96 average hits which were reported by the competition organizers (<ref type="bibr" target="#b3">Elowe et al., 2005</ref>). Our previous works showed that the measurements in the McMaster Test dataset were affected by systematic error (<ref type="bibr" target="#b2">Dragiev et al., 2011;</ref><ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>), especially when some higher hit selection thresholds were used (e.g. μ–SD or μ–2SD). The hit sets provided by the six following methods were compared: uncorrected data processing, B-score, and the introduced MEA and PMP methods applied as such and in the combination with the Well Correction procedure (<ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>) allowing for removing screenspecific systematic error. Both MEA and PMP methods were carried out on a plate-by-plate basis and were preceded by the t-test, which was necessary to recover systematic error row and column locations. The t-test was performed with the α parameter value set to 0.01 (see Supplementary Materials). As the McMaster Test dataset contained replicates, the hit selection procedure was adjusted to search for average hits (i.e. the average of the two measurements of every compound was calculated and the obtained result was supplied to the hit selection procedure). The totals of hits retraced by the six considered methods are presented in<ref type="figure" target="#tab_1">Table 1</ref>and Supplementary Tables S1–S12 (the detailed results). Both proposed methods identified more potential hits (100 for MEA and 115 for PMP) than the organizers of the McMasterThe hit selection threshold of μ–2.29SD was used. competition (i.e. 96 hits for the uncorrected dataset), while rejecting a few of the original hits as false positives. The MEA method found 8 extra hits, while rejecting 4 of the original hits as false positives. The PMP method extended the set of original hits with 24 new hits, while rejecting only 5 of them. In contrast, the B-score method rejected 28 original hits, and provided 118 new potential hits (according to our simulation results, many of those new hits can be in fact false positives). The total overlap of all the six considered methods consisted in 55 consensus average hits that could be recommended for further testing including the structureactivity relationships (SARs) analysis and various clinical trials. As shows the example of the consensus hits set of the McMaster Test assay<ref type="bibr">[see Elowe et al. (2005)</ref>or Table 9sm in Makarenkov et al.</p><formula>(2007)]</formula><p>, consensus hits can also contain an important percentage of false negatives and false positives. The consensus hits list of this assay, which included 42 hit compounds in total, comprised only 14 of 26 hit compounds confirmed by the SAR analysis conducted by the McMaster competition organizers (i.e. 12 of 26 confirmed hits were false negatives and 28 of 42 consensus hits were false positives). Thus, SAR investigations should be always conducted in conjunction with data correction and hit selection techniques to confirm the selected hits. It is worth also noting that MEA and PMP agreed on most of the hits they selected (i.e. 92 of the hits identified by MEA were also detected by PMP). Furthermore, after the application of Well Correction, the MEA and PMP methods provided an identical set of 109 hits.<ref type="figure" target="#fig_6">Figure 5</ref>and Supplementary Tables 1S–12S present the hit distribution surfaces (i.e. hit totals obtained for each well location and computed over all plates of the given assay) of the Master Test assay obtained for the hit selection thresholds μ–SD and μ–2.29SD. The consecutive application of two data correction methods: Well Correction and MEA (<ref type="figure" target="#fig_6">Fig. 5i</ref>and j) or Well Correction and PMP (<ref type="figure" target="#fig_6">Fig. 5k and l</ref>), allowed us to eliminate screen-specific systematic error, first, and plate-specific systematic error, second (see also Supplementary Tables 9S to 12S). For instance, the MEA and PMP hit distribution surfaces provide better fits to the corresponding plain surfaces (which represent a perfect uniform distribution of the assay hits across all well locations) when Well Correction is applied beforehand (<ref type="figure" target="#fig_6">Fig. 5i and k</ref>). After the application of Well Correction, the hit distribution surface χ 2 goodness-offit statistic for the hit selection thresholds μ–SD decreased from 1178.53 (<ref type="figure" target="#fig_6">Fig. 5e</ref>and Supplementary<ref type="figure" target="#tab_5">Table S5</ref>) to 203.18 for MEA (<ref type="figure" target="#fig_6">Fig. 5i</ref>and Supplementary<ref type="figure">Table 9S</ref>) and from 994.27 (<ref type="figure" target="#fig_6">Fig. 5g</ref>and Supplementary<ref type="figure">Table 7S</ref>) to 198.68 for PMP (<ref type="figure" target="#fig_6">Fig. 5k</ref>and Supplementary<ref type="figure" target="#tab_1">Table 11S</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correction of experimental screening data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>We described two new methods, called MEA and PMP, allowing for elimination of plate-specific systematic error from experimental HTS data. Both methods rely on the prior information concerning the location of the rows and columns of the given plate affected by systematic bias. Such information can be obtained by using the methodology described in<ref type="bibr" target="#b2">Dragiev et al. (2011)</ref>. We conducted a simulation study with different HTS plate sizes, hit percentages and systematic error magnitudes. In this study, the MEA and PMP methods were compared with the B-score (<ref type="bibr" target="#b0">Brideau et al., 2003</ref>) and no-correction strategies. Both new methods always outperformed the B-score and no-correction procedures when the number of the plate's rows and columns affected by systematic error was low (<ref type="figure" target="#fig_0">Figs 2</ref>–4). In the simulations where the number of rows and columns affected by systematic error could reach 50% of the plate's total number of rows and columns (<ref type="figure">Figs 1S</ref>–3S), the MEA and PMP methods generally yielded better results than Bscore when the hit percentage was under 3% (in a typical HTS campaign the hit percentage is usually under 1%) or when the level of systematic error was under 1.8SD. The B-score method showed a more stable behavior than MEA and PMP only when the number of rows and columns affected by systematic error, hit percentage and systematic error variance were high (mainly due to a mediocre performance of the t-test in this case). MEA was generally the best method for correcting systematic error within 96well plates, whereas PMP performed better for 384 and 1536-well plates. The analysis of the McMaster Data Mining and Docking Competition Test assay (<ref type="bibr" target="#b3">Elowe et al., 2005</ref>) showed that the new methods can be also applied in the combination with the Well Correction technique (<ref type="bibr" target="#b8">Makarenkov et al., 2007</ref>) aiming to remove screen-specific systematic error. Hence, a general data correction phase in HTS, permitting for the elimination of both screen-and plate-specific systematic biases, can be conducted in the following way:</p><p>(1) Normalize the raw measurements using Percent of control, Normalized percent inhibition or Z-score transformation. This normalization step can be carried out either on a plate-byplate basis or for all assay measurements together (i.e. when all plates have been processed under the same experimental conditions);</p><p>(2) Perform the t-test or χ 2 goodness-of-fit test on the hit distribution surface for the selected hit selection threshold; if systematic error is detected then carry out the Well Correction method;</p><p>(3) Perform the t-test or χ 2 goodness-of-fit test on each individual plate of the assay to identify its rows and columns affected by systematic error as well as the error locations;</p><p>(4) For all plates where systematic error is detected: Correct the plate measurements by carrying out the PMP or MEA method (or, alternatively, the B-score procedure).</p><p>In this study, we addressed the issue of the commonly considered additive systematic artifact that can be described using Equation (17). It is worth noting that the multiplicative type of systematic bias affecting well (i,j) of plate p and defined by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P.Dragiev et al.</head><p>Equation</p><p>(18):</p><formula>x ijp = x ijp ×e r ip ×e c jp +rand ijp ,</formula><formula>(18)</formula><p>can be also treated using the proposed methods. Whereas the MEA method should undergo substantial changes to treat multiplicative type of systematic error because the linear equations systems</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(2)</head><figDesc>Adjust the measurements of all compounds located in rows and columns of the plates affected by systematic error using the error estimatesêestimatesˆestimatesê r i andêandˆandê c j determined in Step 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Copyedited by: TRJ MANUSCRIPT CATEGORY: ORIGINAL PAPER [16:53 13/6/2012 Bioinformatics-bts262.tex] Page: 1779 1775–1782</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. True positive rate and total number of false positive and false negative hits (i.e. total number of false conclusions) per assay for 96-well plate assays estimated under the condition that at most two rows and two columns of each plate were affected by systematic error. Panels (a) and (b) present the results obtained for datasets with the fixed systematic error SD of 1.2SD. Panels (c) and (d) present the results for datasets with the fixed hit percentage rate of 1%. Methods legend: no-correction (), B-score (), MEA (2), t-test and MEA (♦), PMP (+), t-test and PMP (×)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. True positive rate and total number of false positive and false negative hits per assay for 384-well plate assays estimated under the condition that at most four rows and four columns of each plate were affected by systematic error. Figure 2 panel description applies here</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. True positive rate and total number of false positive and false negative hits per assay for 1536-well plate assays estimated under the condition that at most of eight rows and eight columns of each plate were affected by systematic error. Figure 2 panel description applies here</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>[16:53 13/6/2012 Bioinformatics-bts262.tex] Page: 1781 1775–1782</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.5.</head><figDesc>Fig. 5. Hit distribution surfaces of the McMaster Test dataset for the hit selection thresholds μ–SD (cases a, c, e, g, i and k) and μ–2.29SD (cases b, d, f, h, j and l) obtained for: the raw (i.e. uncorrected) data (a, b), and the data corrected by B-score (c, d), MEA (e, f), PMP (g, h), Well Correction + MEA (i, j) and Well Correction + PMP (k, l)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><figDesc>Copyedited by: TRJ MANUSCRIPT CATEGORY: ORIGINAL PAPER [16:53 13/6/2012 Bioinformatics-bts262.tex] Page: 1782 1775–1782</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>1a, c show activity levels averaged across all plates (i.e. assay background surfaces), whereas Figures 1b, d show the activity levels of two selected single plates (from the McMaster and Princeton datasets, respectively). These</figDesc><table>Copyedited by: TRJ 

MANUSCRIPT CATEGORY: ORIGINAL PAPER 

[16:53 13/6/2012 Bioinformatics-bts262.tex] 
Page: 1776 1775–1782 

P.Dragiev et al. 

Fig. 1. Hit maps showing the presence of positional effects in the McMaster 
1250-plate assay (Elowe et al. 2005)—(a) whole assay background surface, 
(b) plate 1036 measurements; and in the Princeton 164-plate assay 
(Helm et al. 2003)—(c) whole assay background surface, (d) plate 144 
measurements. Color intensity is proportional to the compounds' signal 
levels (higher signals, i.e. potential target inhibitors, are shown in red) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>) to obtain the estimated values of x ijp , μ p , R ip and C jp [Equation (2)]:</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>MAD p , Equation (3)]: x ijp = r ijp MAD p , MAD p = median {|r ijp −median (r ijp )|}, (3)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 1. Number of hits selected by the six data correction methods for the McMaster Test dataset</figDesc><table>Data correction method 
Number of hits 

No-correction 
96 
B-score 
186 
Matrix Error Amendment (MEA) 
100 
Partial Mean Polish (PMP) 
115 
Well Correction + MEA 
109 
Well Correction + PMP 
109 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="2"> rows and 2 columns for 96-well plates, at most 4 rows and 4 columns for 384-well plates and at most 8 row and 8 columns for 1536-well plates were affected by systematic bias. A small random error was also added to both hit and non-hit measurements. The random error in all datasets followed a normal distribution with parameters ∼ N (0,0.6SD). Equation (17) specifies the model we used to generate an erroraffected measurement of the compound located in well (i, j) of plate p: x ijp = x ijp +e r ip +e c jp +rand ijp , (17) where x ijp is the resulting measurement value, x ijp is the original error-free measurement, e r ip is the systematic error affecting row i of plate p, e c jp is the systematic error affecting column j of plate p and rand ijp is the random error in well (i, j) of plate p. Six data correction/hit selection methods were tested in our simulations. All tested methods comprised an identical hit selection step, but differed in the way the data were processed before the hit selection. The hits were selected globally for each assay using the hit selection threshold of μ hs −3SD hs (i.e. all compounds with the measurements lower than μ hs −3SD hs were declared hits, where μ hs and SD hs were, respectively, the mean and SD of the entire assay after the addition of hits and systematic error). The six methods evaluated in our simulation study were the following: • Original data processing without any data correction; • B-score correction method (Brideau et al., 2003); • MEA method performed under the assumption that the exact locations of the error-affected rows and columns on each plate of the assay are known; • MEA method performed for the rows and columns where systematic error was detected by the t-test (for more details, see Dragiev et al., 2011);</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Improved statistical methods for hit selection in HTS</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brideau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="634" to="647" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A novel specific edge effect correction method for RNA interference screenings</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">P</forename>
				<surname>Carralot</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="261" to="268" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Systematic error detection in experimental high-throughput screening</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Dragiev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Experimental screening of dihydrofolate reductase yields a &apos;Test Set&apos; of 50,000 small molecules for a computational data-mining and docking competition</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">H</forename>
				<surname>Elowe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="653" to="657" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Identification of active-site inhibitors of MurG using a generalizable, high-throughput glycosyltrans-ferase screen</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Helm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Chem. Soc</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="11168" to="11169" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Comprehensive analysis of high-throughput screening data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Heyse</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of SPIE</title>
		<imprint>
			<biblScope unit="page" from="4626" to="535" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical analysis of systematic errors in HTS</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kevorkov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Makarenkov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="557" to="567" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">HTS-Corrector: new application for statistical analysis and correction of experimental data</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Makarenkov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1408" to="1409" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistical analysis of systematic errors in HTS</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Makarenkov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1648" to="1657" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistical practice in high-throughput screening data analysis</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Malo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="167" to="175" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Experimental design and statistical methods for improved hit detection in high-throughput screening</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Malo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="990" to="1000" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Identifying actives from HTS data sets: practical approaches for the selection of an appropriate HTS data processing method and quality control review</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">Y</forename>
				<surname>Shun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Exploratory Data Analysis</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Tukey</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Addison Wesley</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Novel analytic criteria and effective plate designs for quality control in genome-scale RNAi screens</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<forename type="middle">D</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="363" to="377" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">A simple statistical parameter for use in evaluation and validation of high-throughput screening assays</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomol. Screen</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="67" to="73" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>