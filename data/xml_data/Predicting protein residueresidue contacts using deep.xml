
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structural bioinformatics Predicting protein residue–residue contacts using deep networks and boosting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Jesse</forename>
								<surname>Eickholt</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Jianlin</forename>
								<surname>Cheng</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="institution">Informatics Institute</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">C. Bond Life Science Center</orgName>
								<orgName type="institution">University of Missouri</orgName>
								<address>
									<postCode>65211</postCode>
									<settlement>Columbia</settlement>
									<region>MO</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Structural bioinformatics Predicting protein residue–residue contacts using deep networks and boosting</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="issue">23</biblScope>
							<biblScope unit="page" from="3066" to="3072"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts598</idno>
					<note type="submission">Received on June 28, 2012; revised on September 27, 2012; accepted on September 30, 2012</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Anna Tramontano available at http://iris.rnet.missouri.edu/dncon/. Contact: chengji@missouri.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Protein residue–residue contacts continue to play a larger and larger role in protein tertiary structure modeling and evaluation. Yet, while the importance of contact information increases, the performance of sequence-based contact predictors has improved slowly. New approaches and methods are needed to spur further development and progress in the field. Results: Here we present DNCON, a new sequence-based residue– residue contact predictor using deep networks and boosting techniques. Making use of graphical processing units and CUDA parallel computing technology, we are able to train large boosted ensembles of residue–residue contact predictors achieving state-of-the-art performance. Availability: The web server of the prediction method (DNCON) is</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The prediction of protein residue–residue contacts is seen by many as an important intermediate step for gaining traction on the challenging task of tertiary structure prediction. This idea has been spurred further recently by encouraging results that demonstrate that predicted contact information can indeed be used to improve tertiary structure prediction and effectively transform some unfolded structures into their folded counterpart (<ref type="bibr" target="#b50">Wu et al., 2011</ref>). The addition of a contact guided structure modeling category in the Critical Assessment of Techniques for Protein Structure Prediction (CASP) on a rolling basis has also aided in sparking interesting in residue–residue contact prediction. Beyond the scope of tertiary structure prediction, protein residue–residue contacts have been used in drug design (<ref type="bibr" target="#b33">Kliger et al., 2009</ref>), model evaluation (<ref type="bibr" target="#b48">Wang et al., 2011</ref>) and model ranking and selection (<ref type="bibr" target="#b36">Miller and Eisenberg, 2008;</ref><ref type="bibr" target="#b45">Tress and Valencia, 2010</ref>). Existing methods for residue–residue contact prediction can be broadly categorized as sequence based or template/structure based. Sequence-based methods attempt to predict contacts from the primary sequence or information that can be derived directly from the sequence. A number of these sequence-based methods use various machine learning methods such as support vector machines (<ref type="bibr" target="#b15">Cheng and Baldi, 2007;</ref><ref type="bibr" target="#b51">Wu and Zhang, 2008</ref>), neural networks (<ref type="bibr" target="#b21">Fariselli et al., 2001;</ref><ref type="bibr" target="#b25">Hamilton et al., 2004;</ref><ref type="bibr" target="#b42">Pollastri and Baldi, 2002;</ref><ref type="bibr" target="#b44">Tegge et al., 2009;</ref><ref type="bibr" target="#b49">Walsh et al., 2009;</ref><ref type="bibr" target="#b52">Xue et al., 2009</ref>), hidden Markov models (<ref type="bibr" target="#b14">Bjorkholm et al., 2009</ref>), Markov logic networks (<ref type="bibr" target="#b35">Lippi and Frasconi, 2009</ref>), random forests (<ref type="bibr" target="#b34">Li et al., 2011</ref>) and deep architectures (<ref type="bibr" target="#b18">Di Lena et al., 2012</ref>) to make residue–residue contact predictions. Other sequence-based approaches have used evolutionary information contained in multiple sequence alignments (MSAs) to identify possible contacts (<ref type="bibr" target="#b23">Gobel et al., 1994;</ref><ref type="bibr" target="#b41">Olmea and Valencia, 1997;</ref><ref type="bibr" target="#b47">Vicatos et al., 2005</ref>). Methods using MSAs were among the first sequence-based approaches tried but suffered from low accuracies caused by indirect or transitive correlations. More recent developments by<ref type="bibr" target="#b32">Jones et al. (2012)</ref>using large MSAs and sparse covariance matrices have been better able to identify contacting residues from the alignments and resulted in significant improvements in accuracy. Template-/structurebased methods operate by extracting contact information from structural data. For template-based methods, this structural data comes in the form of templates (i.e. homologous proteins with known structure). Once templates have been found and aligned, residue–residue contacts are predicted using the contacts found in the structures (<ref type="bibr" target="#b51">Wu and Zhang, 2008</ref>). Given the relatively high quality of the tertiary structure models generated by template-based techniques, residue–residue contact data is most useful when dealing with hard targets (i.e. those for which a structural template does not exists or hard to identify by sequence alone). For hard targets, the conformational search is much larger and overall model quality is usually much lower. Thus, there is great interest in high quality sequence-based residue–residue contact predictors that do not rely on template data. Such contact predictors would be able to provide additional information when generating models for hard targets. Unfortunately, recent assessments of state-ofthe-art sequence-based contact predictors routinely report average accuracies in the 20–30% range, indicating a need for further development and new methods and ideas (<ref type="bibr" target="#b20">Ezkurdia et al., 2009;</ref><ref type="bibr" target="#b31">Izarzugaza et al., 2007;</ref><ref type="bibr" target="#b39">Monastyrskyy et al., 2011</ref>). Here we present a new sequence-based residue–residue contact predictor using deep networks (DNs) and boosting. Our method differs from other implementations of deep architectures owing to its boosted nature, overall network architecture and training procedure. More specifically, for training, we initially use an unsupervised approach to learn patterns in the data and initialize *To whom correspondence should be addressed. parameters and then fine tune them with back propagation. Furthermore, by using the computational power of graphical processing units (GPUs) and CUDA, we were able to train large boosted ensembles of DN classifiers achieving state-ofthe-art performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets and evaluation metrics</head><p>Several datasets were used to train and evaluate our residue–residue contact predictor. The primary dataset, DNCON, was formed by an advanced search of the Protein Data Bank filtering the results by 30% sequence similarity and a resolution of 0–2 A ˚ (<ref type="bibr" target="#b13">Berman et al., 2000</ref>). The results from this initial search were then filtered by sequence length and disorder content, retaining sequences that were 30–300 residues in length and contained fewer than 20% disordered residues (i.e. coordinates were missing for fewer than 20% of the residues in the experimentally determined structure). The resulting set of proteins was then merged with the training set from SVMcon and then filtered by three existing datasets D329, SVMCON_TEST and CASP9, which were used as evaluation sets. The filtering process ensured that the pairwise sequence identity between the merged dataset and any sequence in the evaluation sets was 25%. The end result of the search and filter process was our primary dataset, DNCON, consisting of 1426 proteins. This dataset was then randomly split into two sets: DNCON_TRAIN consisting of 1230 proteins and DNCON_TEST consisting of 196 proteins. Supplementary<ref type="figure">Figure S1</ref>illustrates the entire dataset generation and filtering process. The evaluation datasets used included D329, a set of 329 proteins used to evaluate ProC_S3 (<ref type="bibr" target="#b34">Li et al., 2011</ref>); SVMCON_TEST, a set of 48 short to medium length proteins used to evaluate SVMcon (<ref type="bibr" target="#b15">Cheng and Baldi, 2007</ref>); CASP9, a set of 111 targets used during the ninth Critical Assessment of Techniques for Protein Structure Prediction (<ref type="bibr" target="#b40">Moult et al., 2011</ref>); CASP9_HARD, a subset of 16 targets taken from the CASP9 set that are solely composed of free modeling (FM) or free modeling/template-based modeling (FM/TBM) domains; and DNCON_ TEST. Owing to the filtering process used in the creation of our dataset, all evaluation datasets are independent (i.e. 525% sequence identity) to the training set. In this study, two amino acid residues are said to be in contact if the distance between their C atoms (C for glycine) in the experimental structure is 58 A ˚. Short-range contacts are defined as residues in contact whose separation in the sequence is !6 and512. Likewise, medium-range contacts are residues in contact whose separation in sequence is !12 but 524 and long-range contacts are defined as having separation in the sequence !24 residues. These definitions are in agreement with recent studies and CASP residue–residue contact assessments (<ref type="bibr" target="#b19">Eickholt et al., 2011;</ref><ref type="bibr" target="#b20">Ezkurdia et al., 2009;</ref><ref type="bibr" target="#b24">Grana et al., 2005;</ref><ref type="bibr" target="#b31">Izarzugaza et al., 2007;</ref><ref type="bibr" target="#b34">Li et al., 2011;</ref><ref type="bibr" target="#b39">Monastyrskyy et al., 2011;</ref><ref type="bibr" target="#b44">Tegge et al., 2009</ref>). A common evaluation metric for residue–residue contact predictions is the accuracy of the top L/5 or L/10 predictions where L is the length of the protein in residues. In this context, accuracy (Acc) is defined as the number of correctly predicted residue–residue contacts divided by the total number of contact predictions evaluated. We also considered the coverage (Cov) of residue–residue contact predictions, which is defined as the number of correctly predicted contacts divided by the number of true contacts. As predicting short-, medium-and long-range contacts have varying degrees of difficulty, it is common to separate predicted contacts by sequence separation and then calculate the accuracy and coverage of the top L and L/5 predictions for each range. Note that this evaluation is done on a per target basis and irrespective of the domain architecture. Estimates for the standard error for accuracy and coverage were calculated using the sample mean and sample variance of the per-target accuracies and coverages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Restricted Boltzmann machine and deep belief network</head><p>The general framework used for classifying residue–residue contacts was a combination of restricted Bolzmann machines (RBMs) trained to form DNs. A RBM is a two-layer network that can be used to model a distribution of binary vectors. In this model, a layer of stochastic binary nodes representing feature detectors are connected via symmetric weights to stochastic binary nodes that take on the values of the vectors to be modeled (<ref type="bibr" target="#b27">Hinton, 2002;</ref><ref type="bibr" target="#b43">Smolensky, 1986</ref>). Conceptually, the layer of stochastic nodes corresponding to the feature detectors can be viewed as the 'hidden' or 'latent' data and the other layer of nodes as the 'visible' data. The energy of a particular configuration of this network can be defined by</p><p>Eðv, hÞ</p><formula>¼ À X i b i v i À X j c j h j À X i, j h j v j w ij ð1Þ</formula><p>where v i and h j are the states of the i th and j th nodes, b i is the bias for the i th visible node, c j is the bias for the j th hidden node and w ji is the weight of the connection between the i th visible and j th hidden nodes. A probability can then be assigned to a configuration of visible data by</p><formula>pðvÞ ¼ X h e ÀEðv, hÞ Z ð2Þ</formula><p>where Z is a normalizing constant and the sum is over all possible configurations of h. Training consists of adjusting the weights of the model such that real data (e.g. training data) has a higher probability than arbitrarily chosen configurations of visible nodes. This can be done using a process called contrastive divergence, which adjusts the weights in a manner that seeks to minimize an approximation to a difference of Kullback–Leibler divergences (<ref type="bibr" target="#b27">Hinton, 2002</ref>). The use of contrastive divergence learning as opposed to maximum likelihood learning has to do with a problematic term in the gradient of average log likelihood function, which is exponential in nature and difficult to approximate. With contrastive divergence, the problematic term cancels out. Full details are provided in Hinton's presentation on training products of experts (2002). In this work, the weights in the n-th epoch of training were updated as follows:</p><formula>Á ðnÞ w ij ¼ " ð5v i p ð0Þ j 4 data À 5p ð1Þ i p ð1Þ j 4 recon Þ À w ij n o þ vw ðnÀ1Þ ij ð3Þ Á ðnÞ a i ¼ " ð5v i 4 data À 5p ð1Þ i 4 recon Þ n o þ va ðnÀ1Þ i ð4Þ Á ðnÞ b j ¼ " ð5p ð0Þ j 4 data À 5p ð1Þ j 4 recon Þ n o þ vb ðnÀ1Þ j ð5Þ</formula><p>In these equations, the angle brackets represent averages over the batch. The subscripts 'data' and 'recon' are descriptors that illustrate that the first average is taken over the data and the second average over reconstructions of the data after one round of Gibbs sampling. For 54 data , p ð0Þ j is the probability that the j-th hidden unit will be activated when driven by the data and calculated as</p><formula>p ð0Þ j ¼ X i v i w ij þ b j ! ð6Þ where ()</formula><p>is the sigmoid function. For 54 recon , p ð1Þ i is the probability that the i th visible unit will be activated and is calculated as</p><formula>p ð1Þ i ¼ X j h j w ij þ a i ! ð7Þ</formula><p>where h j is a binary value set to 1 with probability p ð0Þ j. The final value to be computed is p ð1Þ j , which is the probability that the j-th hidden unit will be activated when driven by the probabilities of the reconstructed visible nodes and calculated as</p><formula>p ð1Þ j ¼ X i p ð1Þ i w ij þ b j ! ð8Þ</formula><p>In Equations 3, 4 and 5, " is the learning rate, is the weight cost and the momentum. These parameters and update equations were used in accordance with recent findings on how to train RBMs in practice (<ref type="bibr" target="#b26">Hinton, 2010</ref>). In our study, the learning rate " was set to 0.01 for w and 0.1 for the biases, and the weight cost was set to 0.0002. The momentum was initially set to 0.5 and after 5 epochs of training increased to 0.9. Training a RBM was done using batches of 100 training examples over 20 epochs. During training, the average free energy of the training data was compared with that of a small holdout set taken from DNCON_TEST to confirm that the RBM was not over-fitting the training data (<ref type="bibr" target="#b26">Hinton, 2010</ref>). RBMs are particularly useful to initialize weights in DNs. This can be done by learning RBMs in a stepwise unsupervised fashion. After training the first RBM, it is applied to the training data and for each training example, the probabilities for activating each hidden node can be calculated and used to train another RBM. This process of training a RBM and then using the hidden activation probabilities as inputs to the next level can be repeated several times to create a multilayer network. For the last level, a one-layer neural network can be added. All the nodes can then be treated as real-value deterministic probabilities and the entire network can be fine tuned using a standard back propagation algorithm to adjust the parameters (<ref type="bibr" target="#b29">Hinton et al., 2006;</ref><ref type="bibr" target="#b29">Hinton and Salakhutdinov, 2006</ref>). To facilitate working with large RBMs and DNs, we implemented the training and classification procedures in terms of matrix operations and used CUDAMat (<ref type="bibr" target="#b38">Mnih, 2009</ref>), a python library that provides fast matrix calculations on CUDA-enabled GPUs. CUDA is a parallel computing platform that provides high-level access to the computing cores of certain graphics processing units (http://www.nvidia.com/object/cuda_home. html). Using CUDAMat and GPUs allowed us to train DN classifiers with on the order of 1 million parameters in under an hour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Prediction of medium-/long-range contacts</head><p>For the prediction of medium-and long-range contacts, we trained multiple ensembles of DNs. The inputs for each DN included sequence-specific values for the residues in two windows centered around the residue–residue contact pair in question, several pairwise potentials, global features and values characterizing the sequence between the contact pair (see Section 2.7 for details). The target was a single binary value that represented the pair being in contact or not. For the size of the windows, we tried lengths of 7, 9, 11, 13, 15, 17 and 19. The overall size of the input feature vector varies from 595 (for windows 7 residues long) to 1339 (for windows 19 residues in length). The variability in the size of the input vector stems from the fact that several features used are residue specific, and consequently, as the number of residues included in the input window grows so does the size of the input vector. The overall architecture of the DN was (595–1339)-500-500-350-1 (see Supplementary<ref type="figure">Fig. S2</ref>). Each layer was trained in a stepwise fashion as a RBM using the previously described process with the exception of the last layer, which was trained as a one-layer neural network. The entire network was fine tuned using back propagation to minimize the cross-entropy error and done over 25 epochs with mini batches of 1000 training examples (see Supplementary<ref type="figure">Fig. S3</ref>). To create boosted ensembles of classifiers, we trained several DNs in series using a sample of 90 000 medium-/long-range residue–residue pairs from a larger pool. The pool of training examples used came from the training dataset, DNCON_TRAIN, and consisted of all medium-and long-range contacts up to 120 residues in sequence separation and a random sample of approximately twice as many non-contacting pairs. Initially, the residue–residue pairs in the training pool were uniformly distributed and had an equal chance of being included in the training sample. After each round, the training pool was evaluated using the new classifier and the pool was reweighted based on the performance of the classifier. The probability of training data that was misclassified was increased, whereas correctly classified data had its probability of selection decreased. This was done using a variant of AdaBoost (<ref type="bibr" target="#b22">Freund and Schapire, 1997</ref>). More specifically, let x i represent the i-th example in the training pool and y i " {0, 1} be the class of the i-th example. Also, let W t (i) be the probability of selecting the i-th example from the training pool in the t-th round of boosting and call the DN classifier trained in round t to be m t (), which outputs a value between 0 and 1. Now, after each round of boosting, W t (i) is updated via " t , t and h t () in the following manner.</p><formula>h t ðiÞ ¼ 0 if m t ðx i Þ50:5 1 if m t ðx i Þ ! 0:5 ð9Þ " t ¼ X htðxiÞ6 ¼yi W t ðiÞ ð 10Þ t ¼ 1 2 1 À " t " t ð11Þ W tþ1 ðiÞ ¼ W t ðiÞ Z t Ã e Àt if h t ðx i Þ ¼ y i e t if h t ðx i Þ 6 ¼ y i ð12Þ</formula><p>After 35 rounds of boosting, the final prediction for an input x i is given by H(x i ) and is a value between 0 and 1.</p><formula>Hðx i Þ ¼ P ðmtðxiÞ40:5Þ t P t t ð13Þ</formula><p>Supplementary<ref type="figure">Figure S4</ref>shows a boosted ensemble. Additionally, we found that after several rounds of boosting, the weights of a number of particularly difficult training examples became disproportionately large and dominated the selected training data. Models trained on these sets did not generalize well and prohibited boosting beyond 10 rounds. This phenomenon is not new and has been studied elsewhere (<ref type="bibr" target="#b46">Vezhnevets and Barinova, 2007</ref>). One solution was to reinitialize the weights on all the training examples after 7 rounds, which in effect joins bagging with several rounds of boosting. Another solution was to combine reinitializing the weights with a trimming procedure, which removed up to 30% of the hard training cases. This was achieved by removing (i.e. trimming) those training examples that were 5 times more likely to be selected than by chance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Consensus predictions for medium-/long-range contacts</head><p>In addition to training ensembles for various fixed-length windows, we also averaged the prediction scores for contacts across ensembles. In all, there were 490 classifiers with 35 coming from each possible combination of window size (7, 9, 11, 13, 15, 17 or 19) and sampling scheme (reweighted or reweighted with trimming).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Prediction of short-range contacts</head><p>For the prediction of short-range contacts, we trained one ensemble of DNs. The input for each DN was a window 12 residues in length and the target was all short-range contacts whose residue pairs were contained in the window. In all, 400 features were used for each window and the target contained 21 predictions. The overall architecture of the DN was 400-500-500-250-21 (Supplementary<ref type="figure">Fig. S5</ref>). Each layer was trained as a RBM using the previous described process, and the entire network was fine tuned using back propagation to minimize the cross-entropy error and done over 20 epochs with mini-batches of 1000 training examples. As the 12 residue window slides across the sequence, most short-range residue pairings appear and are predicted multiple times and the final prediction for a residue–residue pair is calculated by averaging the predicted values across all windows. To create an ensemble of short-range predictors, we trained 30 DNs. When selecting the training set for each model, we randomly sampled 80 000 short-range windows from a pool. For the short-range predictor, the training pool consisted of all possible 12 residue windows contained in the training dataset, DNCON_TRAIN. This resulted in a pool of 198 333 training examples. The initial probability of choosing a training example was uniform and the probability of being selected was updated after each round using a procedure similar to that outlined for the medium-/longrange predictors. The only difference was in how the probabilities were updated. As the output for short-range predictions had multiple values, the probability of an example was increased in a way that was proportional to the number of incorrectly classified targets for the example. Equation 13 indicates how the weights were updated. is the percentage of the 21 short-range targets that were misclassified for a training example.</p><formula>W tþ1 ðiÞ ¼ W t ðiÞ Z t Ã e Àt if h t ðx i Þ ¼ y i e Ãt if h t ðx i Þ 6 ¼ y i ð14Þ</formula><p>The predicted value for a short-range residue–residue pair was the average of the predictions across the ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">DNCON</head><p>The sum of the aforementioned components is DNCON. It is a sequencebased residue–residue contact predictor capable of predicting short-, medium-and long-range contacts. For medium-and long-range prediction, DNCON uses a consensus from the medium-/long-range boosted ensembles. For short-range predictions, DNCON uses the short-range ensemble trained on fixed windows of 12 residues. The entire boosted network is used when making residue–residue contact predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Features used and generation</head><p>The features we used for training our residue–residue contact predictors are consistent with those used by many other predictors (<ref type="bibr" target="#b15">Cheng and Baldi, 2007;</ref><ref type="bibr" target="#b34">Li et al., 2011;</ref><ref type="bibr" target="#b42">Pollastri and Baldi, 2002;</ref><ref type="bibr" target="#b44">Tegge et al., 2009</ref>). These included predicted secondary structure and solvent accessibility, values from the position-specific scoring matrix (PSSM) and several pre-computed statistical potentials. To obtain the PSSM, PSI-BLAST (<ref type="bibr" target="#b11">Altschul et al., 1997</ref>) was run for three iterations against a non-redundant version of the nr sequence database filtered at 90% sequence similarity. The secondary structure and solvent accessibility were predicted using SSpro and ACCpro from the SCRATCH suite (<ref type="bibr" target="#b16">Cheng et al., 2005</ref>). The Acthely factors are scaled representations of five numerical values that characterize a residue by electrostatic charge, codon diversity, volume, polarity and secondary structure (<ref type="bibr" target="#b12">Atchley et al., 2005</ref>). Finally, we mention that all features which took values outside the range from 0 to 1 were rescaled to be from 0 to 1 so as to be compatible with the input layer of the RBM.alpha helix and beta sheet residues, and 1 input for the relative position of the center of the window with respect to the sequence length (i.e. midpoint/protein length). Thus for short-range predictions, there were a total of 400 features (12 Â 31 local features þ 28 global features). For medium-and long-range contacts, we used features coming from two windows centered on the residue pair in question as well as pairwise and global features. For each residue in a window, we used the same features as in the short-range residue window (i.e. predicted secondary structure and solvent accessibility, information and likelihoods from the PSSM and Acthley factors). We also encoded these features for a small window of five residues centered at the midpoint between the residue pair to be classified. For global features, we used the same global feature set as described for the short-range contact predictor (i.e. protein length, relative position of contacting pair, percentage of predicted exposed, alpha helix and beta sheet residues) and an additional set of 11 binary features to encode the separation of the residue pair in sequence (1–12, 13–18, 19– 26, 27–38, 39–50, 51–62, 63–74, 75–86, 87–98, 99–110, and 111–120). Finally, we used a number of pairwise features that depended on the residue pair, and these included Levitt's contact potential (<ref type="bibr" target="#b30">Huang et al., 1996</ref>), Jernigan's pairwise potential (<ref type="bibr" target="#b37">Miyazawa and Jernigan, 1999</ref>), Braun's pairwise potential (<ref type="bibr" target="#b53">Zhu and Braun, 1999</ref>), the joint entropy of the contact pair calculated from the residue frequency counts in the PSSM, the Person correlation coefficient and cosine calculated on the residue frequency counts for the pair in the PSSM and the four-order of weighted means for secondary structure and solvent accessibility for the sequence segment between the residue pair (<ref type="bibr" target="#b34">Li et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Performance of DNCON</head><p>To evaluate our residue–residue contact predictor, we evaluated its performance on a number of datasets and compared it with two state-of-the-art contact predictors, ProC_S3 and SVMcon. These methods were ranked as the best sequence-based residue– residue contact predictors in CASP9 (<ref type="bibr" target="#b39">Monastyrskyy et al., 2011</ref>).<ref type="figure" target="#tab_1">Table 1</ref>shows accuracy and coverage of the top L/5 and top L predictions for ProC_S3, SVMcon and DNCON. The predictions for SVMcon and ProC_S3 were downloaded from the official CASP website (http://predictioncenter.org/download_area/ CASP9/predictions/). The evaluation dataset for this comparison was CASP9_HARD, a set of 16 proteins that were comprised solely of domains classified as FM or FM/TBM by CASP9 assessors. The FM and FM/TBM classification indicates that template-based information was scant or difficult to obtain for these targets. As seen in<ref type="figure" target="#tab_1">Table 1</ref>, DNCON performed well on these targets, achieving state-of-the-art performance for accuracy and converge of long-range contacts when considering the top L or L/5 contact predictions. Given the comparable performances of the methods, we also examined if the methods were identifying the same contacts or if they were in some sense complementary. We discovered that while there was some overlap between prediction sets ($18–30%), each method was identifying a number of unique true contacts among those selected (see Supplementary Tables S1–S3 for full details). While evaluating residue–residue contacts on hard targets is arguably the best means of evaluation (i.e. it is on these types of targets that contact information may have the largest impact), the drawback is that these datasets are usually composed of a small number of targets. To increase the robustness of our evaluation, we also compared DNCON with SVMcon and ProC_S3 on larger datasets, namely SVMCON_TEST and D329.<ref type="figure" target="#tab_2">Table 2</ref>presents the accuracy and coverage of the top L/5 and top L predictions for SVMcon and DNCON on the SVMCON_TEST, the dataset used to evaluate SVMcon. Similarly,<ref type="figure" target="#tab_3">Table 3</ref>presents the results for ProC_S3 and DNCON on the D329, a dataset used to evaluate ProC_S3. The predictions for SVMcon on the SVMCON_TEST dataset were obtained by downloading SVMcon and made locally and evaluated with our pipeline. Note that the values for ProC_S3 on the D329 dataset are those reported by<ref type="bibr" target="#b34">Li et al. (2011)</ref>in their assessment of their method. Both of these evaluations show that the performance of DNCON is on par with the two state-of-the-art contact predictors (<ref type="figure" target="#tab_3">Table 3</ref>). As an additional comparison between DNCON, ProC_S3 and SVMcon, we evaluated each method on all valid CASP9 targets. Again, the predictions for SVMcon and ProC_S3 were downloaded from the official CASP website. Note that this evaluation was done using the entire protein and meant to complement the assessment technique used by CASP assessors, which evaluates predictions on a per domain basis. Tables 4 and 5 show the results of the three methods when evaluated on long-and medium-range contacts. Once again, DNCON performs competitively against SVMcon and ProC_S3. The final evaluation set used was DNCON_TEST, an evaluation set of 196 proteins from the dataset that we curated.<ref type="figure">Table 6</ref>shows the performance DNCON on our evaluation set. We also calculated the sensitivity of DNCON on DNCON_TEST at the 95% specificity rate. For long-range contacts, 38% of the true long-range contacts can be recovered at the 95% specificity rate (i.e. 95% of non contacts are recovered). For medium-range contacts, the sensitivity is 44% at the 95% specificity level. In addition to the evaluation on the entire DNCON_TEST dataset, we also evaluated our method on three subsets of DNCON_TEST. Using the CATH structure classification database (<ref type="bibr" target="#b17">Cuff et al., 2011</ref>), we indentified and grouped 140 of the proteins in DNCON_TEST as mainly alpha, (29), mainly beta,(30) and alpha beta, (81). These results are summarized in<ref type="figure">Table 7</ref>. Interestingly, our method appears to have more difficulty with mainly alpha proteins than with the mainly beta or alpha beta mix. Difficulty in predicting mainly alpha proteins has been noted elsewhere (<ref type="bibr" target="#b15">Cheng and Baldi, 2007;</ref><ref type="bibr" target="#b18">Di Lena et al., 2012</ref>) and is a starting point for future study. Finally, we assessed our contact predictor by evaluating its performance when considering neighborhoods. In this setting, a predicted contact is considered correct if there is a true residue–residue contact with AE residues for small values of (e.g. for ¼ 1, a predicted contact<ref type="bibr">[i,j]</ref>would be counted correct if there were a true contact at<ref type="bibr">[i,j]</ref>, [iAE1,j], [i,jAE1] or<ref type="bibr">[iAE1,jAE1]</ref>).<ref type="figure">Table 8</ref>states the accuracy of DNCON on the DNCON_TEST dataset for ¼ 1 and ¼ 2. These results demonstrate that while the predictions contain some noise, which prohibits residue-level precision, in general, the contact predictions are accurate and contain a strong signal. This strong signal, particularly at the short and medium range, could provide valuable local information, which could be propagated and incorporated into the prediction of longer range contacts. Recent work by Di Lena et al., has demonstrated that propagating neighboring contact predictions can indeed increase performance (2012). Given the flexibility of the DN architecture and its ability to handle a large number of input features, this type of local contact information could easily be included for longer range predictions. This is a line of investigation we are currently pursuing for a future work. As for long-range contact predictions, these too exhibit a strong relatively accurate contact signal, which may prove more useful than the residue-specific accuracies indicate, particularly for the purposes of guiding a search through the protein conformation space. An evaluation of SVMcon and ProC_S3 on DNCON_TEST using the neighborhood criteria found that ProC_S3 and DNCON perform comparably and both outperform SVMcon (data not shown).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Value of boosting and ensembles</head><p>To determine the value of the boosted ensembles and the consensus approach, we studied the performance of the predictions for various configurations of ensembles and across rounds of boosting.<ref type="figure">Figure 1</ref>characterizes the affect of boosting on the accuracy of the top L and L/5 long-range predictions (see Supplementary<ref type="figure">Fig. S6</ref>for effect on medium-range predictions). These particular figures are of the ensemble with windows of 13 residues in length and with the reweighted sampling scheme. They show the benefit of boosting and are typical of the affect seen in other ensembles. To determine the effect of the window size on the method's performance, we evaluated the performance using ensembles comprising DNs with only one window size and reweighting scheme. It is interesting to note that while all of the ensembles perform roughly the same, there is a marked difference in the performance of the individual ensembles and the consensus prediction for top L/5 predictions. Accuracies for the individual ensembles are in the range of 0.24–0.28 for the top L/5 longrange predictions, whereas the accuracy of their consensus is 0.34 (Supplementary<ref type="figure">Table S4</ref>). Similarly, for the top L/5 mediumrange predictions, the accuracy jumps from the 0.32 to 0.34 range to 0.38.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSION</head><p>In this work, we have presented DNCON, a new method for protein residue–residue prediction. The approach is based on two concepts, boosted ensembles and DNs, which are novel in<ref type="figure">Fig. 1</ref>. Accuracy of the top L and L/5 long-range contact predictions for a boosted ensemble (13-win). The graph plots accuracy as a function of the number of rounds of boostingShort ( ¼ 1) 0.789 0.657 0.532 Medium ( ¼ 1) 0.648 0.552 0.463 Medium ( ¼ 2) 0.749 0.678 0.607 Long ( ¼ 1) 0.550 0.476 0.415 Long ( ¼ 2) 0.638 0.578 0.552 the context of residue–residue contact prediction. When compared with the current state-of-the-art, DNCON performs favorably, achieving state-of-the-art performance in the critical area of accuracy on top medium and long range contact predictions. When allowing for less than residue level precision, the performance of DNCON is even more impressive. Given the strong contact signal present for short-and medium-range contacts and the fast flexible architecture of DNs, in the future, we plan on modifying the DNs such that they can incorporate and propagate predicted short-to medium-range contacts when making longer range predictions. We also plan on refining the parameters and network architecture used to increase performance. The method is available as a web service at http://iris.rnet.missouri.edu/ dncon/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>For short-range contact prediction, for each residue in the window, we used 3 binary inputs to encode the predicted secondary structure (helix: 100, beta: 010, coil: 001), 2 binary inputs for solvent accessibility at the 25% threshold (exposed: 10, buried: 01), from the PSSM obtained from PSI-BLAST we obtained 1 input for the information score of the residue and 20 inputs for the likelihoods of each amino acid type at that position, and 5 inputs for Acthley factors. Additional global features included 4 binary inputs to encode protein length (575: 1000, 75–150: 0100, 150–225: 0010,4225: 0001), 20 inputs for the percent representation of each amino acid in the sequence, 3 inputs for the percentage of predicted exposed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Funding: The work was partially supported by a National Library of Medicine Biomedical and Health Informatics Training fellowship (to J.E.) and a NIH NIGMS grant (R01GM093123 to J.C.). Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 3. Performance of DNCON and ProC_S3 for medium and long-range contact prediction on the D329 dataset</figDesc><table>Method 
Acc(L) 
Acc(L/5) 
Cov(L) 
Cov(L/5) 

DNCON[L] 
0.191(0.005) 0.326(0.011) 0.149(0.005) 0.052(0.002) 
ProC_S3[L] a 0.180 
0.297 
0.151 
0.056 
DNCON[M] 0.196(0.006) 0.368(0.011) 0.511(0.009) 0.190(0.005) 
ProC_S3[M] a 0.209 
0.410 
0.520 
0.227 

a 

These values are reported by Li et al. (2011) using same evaluation metrics. No 
error estimates provided. Estimates of standard error are provided in parenthesis. 
Contact range is denoted within brackets, L for long range and M for medium 
range. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2.</figDesc><table>Performance of DNCON and SVMcon for long-and 
medium-range contact predictions on the SVMCON_TEST dataset </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 7. Performance of DNCON on structurally defined subsets of the DNCON_TEST dataset</figDesc><table>Range 
Type 
Acc(L) 
Acc(L/5) 
Cov(L) 
Cov(L/5) 

Short 

0.171 
0.440 
0.714 
0.364 

0.285 
0.612 
0.748 
0.318 

0.201 
0.512 
0.723 
0.350 
Medium 

0.132 
0.257 
0.570 
0.220 

0.255 
0.448 
0.487 
0.170 

0.222 
0.420 
0.543 
0.203 
Long 

0.111 
0.156 
0.112 
0.031 
B 
0.222 
0.322 
0.147 
0.042 

0.234 
0.384 
0.169 
0.053 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 8.</figDesc><table>Performance of DNCON for short-, medium-and long-range 
contact prediction on the DNCON_TEST dataset when considering 
small neighborhoods 

Range 
Acc(L/5) 
Acc(L/2) 
Acc(L) 

</table></figure>

			<note place="foot">ß The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Predicting protein residue–residue contacts at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">J.Eickholt and J.Cheng at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="m">Method Acc(L) Acc(L/5) Cov(L) Cov</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Svmcon</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Svmcon</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Estimates for standard error are provided in parenthesis. Contact range is denoted within brackets, L for long range and M for medium range</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Table 1. Performance of DNCON, ProC_S3 and SVMcon for long-range contact prediction on CASP9_HARD, a set of 16 CASP9 targets that are solely composed of FM and FM</title>
	</analytic>
	<monogr>
		<title level="m">TBM domains Method Acc(L) Acc(L/5) Cov(L) Cov</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<monogr>
		<title level="m" type="main">Estimates for standard error are provided in parenthesis</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Table 5. Performance of DNCON, ProC_S3 and SVMcon for medium-range contact prediction on the</title>
	</analytic>
	<monogr>
		<title level="m">CASP9 dataset Method Acc(L) Acc(L/5) Cov(L) Cov</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<monogr>
		<title level="m" type="main">Estimates of standard error are provided in parenthesis</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Table 4. Performance of DNCON, ProC_S3 and SVMcon for long-range contact prediction on the</title>
	</analytic>
	<monogr>
		<title level="m">CASP9 dataset Method Acc(L) Acc(L/5) Cov(L) Cov</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">Estimates of standard error are provided in parenthesis</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Table 6. Performance of DNCON for short-, medium-and long-range contact prediction on the DNCON_TEST</title>
	</analytic>
	<monogr>
		<title level="m">dataset Range Acc(L) Acc(L/5) Cov(L) Cov</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3389" to="3402" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Solving the protein sequence metric problem</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R</forename>
				<surname>Atchley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="6395" to="6400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">The Protein Data Bank</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">M</forename>
				<surname>Berman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="235" to="242" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Using multi-data hidden Markov models trained on local neighborhoods of protein structure to predict residue-residue contacts</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Bjorkholm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1264" to="1270" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Improved residue contact prediction using support vector machines and a large feature set</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Cheng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Baldi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">113</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">SCRATCH: a protein structure and structural feature prediction server</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Cheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="72" to="76" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Extending CATH: increasing coverage of the protein structure universe and linking structure with function</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Cuff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="420" to="426" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep architectures for protein contact map prediction</title>
		<author>
			<persName>
				<forename type="first">Di</forename>
				<surname>Lena</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2449" to="2457" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A conformation ensemble approach to protein residueresidue contact</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Eickholt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Struct. Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Assessment of domain boundary predictions and the prediction of intramolecular contacts in CASP8</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Ezkurdia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="196" to="209" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Suppl. . 9</note>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Prediction of contact maps with nueral networks and correlated mutations</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Fariselli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Eng</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="835" to="843" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Freund</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">E</forename>
				<surname>Schapire</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Correlated mutations and residue contacts in proteins</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Gobel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="309" to="317" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">CASP6 assessment of contact prediction</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Grana</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="page" from="61" to="214" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 7</note>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Protein contact prediction using patterns of correlation</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Hamilton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="679" to="684" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">A practical guide to training restricted Boltzmann machines</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2010" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">E</forename>
				<surname>Hinton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">R</forename>
				<surname>Salakhutdinov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Using a hydrophobic contact potential to evaluate native and near-native folds generated by molecular dynamics simulations</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">S</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">257</biblScope>
			<biblScope unit="page" from="716" to="725" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Assessment of intramolecular contact predictions for CASP7</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Izarzugaza</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="152" to="158" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Suppl. . 8</note>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">PSICOV: precise structural contact predictin using sparce inverse covariance estimation on loarge multiple sequence alignments</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">T</forename>
				<surname>Jones</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="184" to="190" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Peptides modulating conformational changes in secreted chaperones: from in silico design to preclinical proof of concept</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kliger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="13797" to="13801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting residue-residue contacts using random forest models</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3379" to="3384" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Prediction of protein beta-residue contacts by Markov logic networks with grounding-specific weights</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lippi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Frasconi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2326" to="2333" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Using inferred residue contacts to distinguish between correct and incorrect protein models</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">S</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Eisenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1575" to="1582" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">An empirical energy potential with a reference state for protein fold and sequence recognition</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Miyazawa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">L</forename>
				<surname>Jernigan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="357" to="369" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<monogr>
		<title level="m" type="main">CUDAmat: a CUDA-based matrix class for Python</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Mnih</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Toronto</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Evaluation of residue–residue contact predictions in CASP9</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Monastyrskyy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="119" to="125" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Critical assessment of methods of protein structure prediction (CASP)—round IX</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Moult</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Suppl. . 10</note>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">Improving contact predictions by the combination of correlated mutations and other sources of sequence information</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Olmea</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Valencia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fold. Des</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Prediction of contact maps by GIOHMMs and recurrent neural networks using lateral propagation from all four cardinal corners</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Pollastri</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Baldi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="18" to="62" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Information processing in dynamical systems: foundations of harmony theory</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Smolensky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="194" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">NNcon: improved protein contact map prediction using 2D-recursive neural networks</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">N</forename>
				<surname>Tegge</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="515" to="518" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">Predicted residue-residue contacts can help the scoring of 3D models</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Tress</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Valencia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1980" to="1991" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">Avoiding Boosting Overfitting by Removing Confusing Samples</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Vezhnevets</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Barinova</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th European conference on Machine Learning</title>
		<meeting>the 18th European conference on Machine Learning<address><addrLine>Warsaw, Poland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="430" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b47">
	<analytic>
		<title level="a" type="main">Prediction of distant residue contacts with the use of evolutionary information</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Vicatos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="935" to="949" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b48">
	<analytic>
		<title level="a" type="main">APOLLO: a quality assessment service for single and multiple protein models</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1715" to="1716" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b49">
	<analytic>
		<title level="a" type="main">Ab initio and template-based prediction of multi-class distance maps by two-dimensional recursive neural networks</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Walsh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Struct. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b50">
	<analytic>
		<title level="a" type="main">Improving protein structure prediction using multiple sequence-based contact predictions</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structure</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1182" to="1191" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b51">
	<analytic>
		<title level="a" type="main">A comprehensive assessment of sequence-based and template-based methods for protein contact prediction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Wu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="924" to="931" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b52">
	<analytic>
		<title level="a" type="main">Predicting residue-residue contact maps by a two-layer, integrated neural-network method</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Xue</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="176" to="183" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b53">
	<analytic>
		<title level="a" type="main">Sequence specificity, statistical potentials, and three-dimensional structure prediction with self-correcting distance geometry calculations of beta-sheet formation in proteins</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Zhu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Braun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="326" to="342" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>