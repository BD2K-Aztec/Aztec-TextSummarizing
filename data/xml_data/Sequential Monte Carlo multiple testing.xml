
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis Sequential Monte Carlo multiple testing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName>
								<forename type="first">Geir</forename>
								<forename type="middle">Kjetil</forename>
								<surname>Sandve</surname>
							</persName>
							<email>geirksa@ifi.uio.no</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Oslo</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Egil</forename>
								<surname>Ferkingstad</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Statistics for Innovation</orgName>
								<orgName type="department" key="dep2">Norwegian Computing Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ståle</forename>
								<surname>Nygård</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Bioinformatics Core Facility</orgName>
								<orgName type="department" key="dep2">Institute of Medical Informatics</orgName>
								<orgName type="institution" key="instit1">University of Oslo</orgName>
								<orgName type="institution" key="instit2">Oslo University Hospital</orgName>
								<address>
									<settlement>Oslo</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alex</forename>
								<surname>Bateman</surname>
							</persName>
						</author>
						<title level="a" type="main">Genome analysis Sequential Monte Carlo multiple testing</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">23</biblScope>
							<biblScope unit="page" from="3235" to="3241"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr568</idno>
					<note type="submission">Received on July 1, 2011; revised on September 8, 2011; accepted on October 6, 2011</note>
					<note>Page: 3235 3235–3241 Norway Associate Editor: Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: In molecular biology, as in many other scientific fields, the scale of analyses is ever increasing. Often, complex Monte Carlo simulation is required, sometimes within a large-scale multiple testing setting. The resulting computational costs may be prohibitively high. Results: We here present MCFDR, a simple, novel algorithm for false discovery rate (FDR) modulated sequential Monte Carlo (MC) multiple hypothesis testing. The algorithm iterates between adding MC samples across tests and calculating intermediate FDR values for the collection of tests. MC sampling is stopped either by sequential MC or based on a threshold on FDR. An essential property of the algorithm is that it limits the total number of MC samples whatever the number of true null hypotheses. We show on both real and simulated data that the proposed algorithm provides large gains in computational efficiency. Availability: MCFDR is implemented in the Genomic HyperBrowser (http://hyperbrowser.uio.no/mcfdr), a web-based system for genome analysis. All input data and results are available and can be reproduced through a Galaxy Pages document at:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The development of novel experimental techniques is rapidly increasing the generation of data in many fields in biology, in particular in genomics with the advent of high-throughput sequencing (<ref type="bibr" target="#b19">McPherson, 2009;</ref><ref type="bibr" target="#b35">Shendure and Ji, 2008</ref>). Chromatin immunoprecipitation (ChIP) technology combined with nextgeneration sequencing generates high-resolution data along the genome on DNA methylation, histone modifications, transcription factor binding and more (<ref type="bibr" target="#b13">Horner et al., 2010</ref>). The large amount of data generated by these techniques opens up for statistical studies of relations between genomic properties, both globally and locally along the genome. An example of such a local analysis is the study of how the relation between histone modifications and repeating elements varies across chromosomes (<ref type="bibr" target="#b26">Pauler et al., 2009</ref>). A natural approach to such an investigation is to split the genome into bins along the genome, e.g. one bin per chromosome, cytoband or gene, and then perform a statistical test of a null hypothesis H0 versus an alternative hypothesis H1 for each bin. At the same time, due to the complex structural properties of the genome, it is often inappropriate to make simplified assumptions that would enable analytic evaluation of significance (<ref type="bibr" target="#b6">Ewan Birney et al., 2007</ref>). Instead, Monte Carlo (MC) sampling is often needed, resorting to computationally expensive reshuffling of genomic elements for each MC sample. As a consequence, Monte Carlo in multiple testing settings is rapidly becoming important (<ref type="bibr" target="#b32">Sandve et al., 2010</ref>). With tests being performed for a large number of bins locally along the genome, the computational requirements may become extremely high, as the effort needed is basically the multiple of a very large number of test by a (possibly also very large) number of MC samples. Several papers have considered ways to reduce the number of samples during MC-based P-value computation for individual tests.<ref type="bibr" target="#b2">Besag and Clifford (1991)</ref>propose a sequential MC algorithm for P-value computation, reducing the needed number of MC samples for tests that are anyway insignificant. Other papers consider alternative ideas for P-value estimation, such as controlling resampling risk (<ref type="bibr" target="#b9">Gandy, 2009</ref>), and prediction of P-values using Random Forest models (<ref type="bibr" target="#b16">Kustra et al., 2008</ref>). Also, there has been some work on Monte Carlo approaches for multiple testing in cases where P-values can be calculated analytically (<ref type="bibr" target="#b18">Lin, 2005;</ref><ref type="bibr" target="#b34">Seaman and Müller-Myhsok, 2005</ref>). In this article, we propose an algorithm that limits the total number of needed MC samples, regardless of how many tests are truly H0. In Section 2, we describe our algorithm, in which MC sampling is stopped either according to the sequential MC stopping rule or when we reach a given multiple testing significance threshold. Then, in Section 3, we show on both simulated and real data that this method can lead to a drastically reduced total number of MC samples. Finally, Section 4 presents a discussion and some conclusions. Further details are provided in the accompanying Galaxy Pages (<ref type="bibr" target="#b10">Goecks et al., 2010</ref>) document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>A commonly used multiple testing analogue to the classical P-value is the so-called q-value (<ref type="bibr" target="#b36">Storey, 2002</ref>). The q-value of an individual test is defined as the minimal false discovery rate (FDR) (<ref type="bibr" target="#b1">Benjamini and Hochberg, 1995</ref>) at which the test is called significant. P-values relate to q-values by a factor which is proportional to the number of tests for which H0 is true. Denote an MC sample of the test statistic as 'extreme' if it is further to the H1-tail of the null distribution than the observed test statistic. When most tests are from H0, the correction factor is large. Then, for an individual test to become significant, many MC samples are needed. Note, however, that in such a situation most tests would have many extreme samples (as they come from H0), implying that for these tests the MC<ref type="bibr">[</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.K.Sandve et al.</head><p>sampling would have been stopped early if a sequential MC stopping criterion were adopted. In the opposite scenario, when most tests are from H1, the multiple testing correction factor is small, and fewer MC samples are needed in order to obtain a significant q-value for each individual test. But then few tests have many extreme samples, and few tests would have been stopped early by sequential MC. Consider testing m null hypotheses H 01 ,...,H 0m with corresponding test statistics T i = t i , i = 1,...,m, where large values of t i constitutes evidence against H 0i. Each test is performed by MC simulation: for test i = 1,...,m, we simulate n i independent datasets under the null hypothesis, yielding simulated test statistics t * ij for j = 1,...,n i. Let k i be the number of simulated test statistics that are greater than or equal to t i. The Monte Carlo P-value p mc (<ref type="bibr" target="#b4">Davison and Hinkley, 1997;</ref><ref type="bibr" target="#b29">Phipson and Smyth, 2010</ref>) is then given by</p><formula>P mc = Pr(T i ≥ t i |H 0i ) = k i +1 n i +1 ,</formula><formula>since under H 0i , all n i +1 values t i ,t * i1 ,...,t * in i</formula><p>are equally likely values of T i , and k i +1 of these are greater than or equal to the observed t i. Our concern is with choosing the number of needed MC samples, n i , for each test i [cf. the discussion in<ref type="bibr" target="#b12">Hope (1968)]</ref>. To begin, consider the case of a single test, m = 1, and assume that we observe k 1 = 0. Then P mc = (n i +1) −1 , and for a given significance threshold α, we need n i ≥ 1 α −1 to have a possibility of rejecting H 0. Thus, the stricter we make the significant threshold, the more MC samples are needed. For example, for α = 0.05, we only need n i ≥ 19, but for α = 0.001 we need n i ≥ 999. For a moderate to large number m of tests, computational problems arise for two reasons: first, simply because m itself is large; second, because of the need to correct for multiple testing. As an example, assume that n i = n for each i, and that we use Bonferroni corrected P-values to account for multiple testing, with an overall family-wise error rate of α. Then, each test has significance threshold α/m, and m m α −1 samples are needed in total. For m = 1000 and α = 0.05, this means that nearly 20 million MC samples are needed. Since each MC sample typically involves a complex reshuffling of genomic elements, the computational cost is extremely high.<ref type="bibr" target="#b2">Besag and Clifford (1991)</ref>propose a sequential MC method for hypothesis testing. Their basic idea is to stop MC sampling at the point that it becomes clear that the null hypothesis will never be rejected. Assume that large values of the test statistic constitute evidence against H0. Instead of using a fixed MC sample size, sampling is continued until either a pre-determined number h of values larger than the observed test statistic t i (i.e. extreme MC samples according to our definition) has been obtained (at MC sample size l, say), or until some maximum number n of MC samples have been calculated. Let g be number of values exceeding t i when this algorithm terminates. Then, the sequential P-value P smc is given by</p><formula>P smc = h/l (g = h),</formula><formula>(g+1)/(n+1) (g &lt; h).</formula><p>Besag and Clifford (1991) suggest setting h = 10 or 20. For the multiple testing setting, we propose to augment this procedure by adding a third stopping criterion, namely a q-value threshold α, aiming to run just as many samples as are needed to obtain an accept/reject decision for each test. For m tests with observed test statistics t 1 ,t 2 ,...,t m , our proposed Monte Carlo False Discovery Rate (MCFDR) algorithm is as follows:</p><p>(1) Let A ={1,2,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..,m} and B =∅</head><p>(2) Until A =∅:</p><p>(a) For each i ∈ A, calculate/update p i by sequential MC, using an additional MC sample. If a total of h samples exceeding t i are then obtained, move i from A to B.</p><p>(b) Calculate q-values (see below) q 1 ,q 2 ,...,q m based on the current P-values P 1 ,P 2 ,...,P m. If q i &lt;α for all i ∈ A, then move all i ∈ A to B.</p><p>Instead of adding only a single MC sample in Step 2a, a batch of N &gt; 1 additional MC samples may be added.</p><p>In Step 2b above, we calculate q-values based on the current P-values. The q-values mainly depend on the proportion π 0 of true null hypotheses among the m tests. Let P (1) ≤ P (2) ≤ ··· ≤ P (m) be the ordered, observed P-values. For a given estimatê π 0 of π 0 , q (i) = q-value(P (i) ) can be easily estimated asˆq</p><formula>asˆ asˆq (i) = min i≤j≤m m * ˆ π 0 * P (j) /j.</formula><p>Thus, the main issue is estimating π 0. Many methods for estimating π 0 have been proposed in the literature (<ref type="bibr" target="#b3">Celisse and Robin, 2010;</ref><ref type="bibr" target="#b7">Finner and Gontscharuk, 2009;</ref><ref type="bibr" target="#b8">Friguet and Causeur, 2011;</ref><ref type="bibr" target="#b14">Hwang, 2011;</ref><ref type="bibr" target="#b15">Jiang and Doerge, 2008;</ref><ref type="bibr" target="#b17">Langaas et al., 2005;</ref><ref type="bibr" target="#b20">Nettleton et al., 2006;</ref><ref type="bibr" target="#b36">Storey, 2002</ref>;<ref type="bibr" target="#b37">Tamhane and Shi, 2009;</ref><ref type="bibr" target="#b39">Zhang, 2011</ref>). Most methods assume that P-values are continuous and uniformly distributed on (0,1) under H 0. However, in the sequential MC case, P-values are discrete and uniformly distributed on the set H ={1,h/(h+1),...,h/(n−1),h/n,(h−1)/n,...,1/n}.<ref type="bibr" target="#b30">Pounds and Cheng (2006)</ref>have proposed a very simple estimator of π 0 :</p><formula>ˆ π 0 = min(1, 2 m m i=1 p i</formula><p>). This estimator can be shown to give conservative estimates for both discrete and continuous P-values, and we have therefore chosen to use this estimator in our algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simulations</head><p>In order to investigate the correctness and efficiency of the proposed scheme, we perform a simulation study. The uniform (0,1) distribution is used to generate P-values from tests for which H0 is true, and a Beta distribution with more mass on lower values is used to generate P-values under H1, giving a Uniform-Beta mixture distribution of underlying P-values for tests (<ref type="bibr" target="#b31">Pounds and Morris, 2003</ref>). By definition, the probability that a test statistic randomly sampled under H 0 is more extreme than the observed test statistic is given by the P-value. Let P i be the P-value corresponding to test i. Then, instead of drawing test statistics directly, we may draw Bernoulli variables with parameter P i as indicators of whether a randomly drawn test statistic would be more extreme than the observed test statistic. Accordingly, simulation for a single test i may be performed by drawing n sim MC samples Y ij , j = 1,...,n sim of a Bernoulli variable with parameter P i , with Y ij = 1 corresponding to an extreme sample. For standard non-sequential MC we draw a fixed number of samples for each test. For sequential MC, samples are drawn until a given number of extreme samples is observed or until a maximum number of samples is reached. For the MCFDR scheme, samples are drawn either until a given number of extreme samples is observed or until the estimated FDR-value falls below a given threshold. The simulation procedure is summarized below:</p><p>(1) Draw mπ 0 samples from the Uniform distribution, and m(1−π 0 ) samples from the Beta (α,β) distribution.</p><p>(2) For each test i, i = 1,...,m</p><p>(a) Set g = 0 (b) While g is smaller than a limit specified by the stopping criterion (differently defined in the basic scheme, the sequential MC scheme, and the MC-FDR scheme)</p><formula>(1) Generate Y ∼ Bernoulli (p i ) (2) If Y = 1, let g = g+1</formula><p>As the main simulation, we ran 5000 tests, with α = 0.25,β = 25, h = 20, a maximum of 50 000 samples for standard and sequentialMC, and with π 0 varying between 0 and 1. The maximum number of samples was chosen to ensure the possibility of significant results after multiple testing correction.<ref type="figure" target="#fig_2">Figure 1</ref>shows the resulting total number of samples for sequential MC and MCFDR, respectively, as a function of the number of true H1.<ref type="figure">Figure 2a</ref>shows that the number of rejected tests, as a function of the number of true H1, is very similar across all three schemes. When the number of true H1 is low, stronger multiple testing correction is needed, leading to lower power and under-rejection. When the number of true H1 increases, more rejections can be made, while still controlling the FDR. For example, when 4500 of the 5000 hypotheses are truly from H1, rejecting all 5000 null hypotheses would give an FDR of exactly (5000−4500)/5000 = 0.1. Note that these are general features of the FDR; this behavior is not specific to our approach.<ref type="figure">Figure 2b</ref>shows that the empirical FDR is also very similar across schemes, and very close to the chosen FDR threshold. In order to inspect the behavior of the schemes more closely, it is necessary to look at the number of samples and estimated P-values at individual settings of true H1.<ref type="figure">Figure 3a</ref>shows underlying and estimated P-values in a collection where 10% of tests come from H1.<ref type="figure">Figure 3b</ref>shows the number of needed samples per test, with tests sorted in the same order as in<ref type="figure">Figure 3a</ref>. A few tests (seen at the left side of the plot) corresponding to very low P-values, need a large number of samples to become significant since they are subject to strong multiple testing correction (due to the relatively high π 0 ). However, the remaining (majority of) tests are stopped early by the sequential MC threshold. The other end of the spectrum, with a large proportion of true H1, is shown in<ref type="figure" target="#fig_3">Figure 4a</ref>and<ref type="figure" target="#fig_3">Figure 4b</ref>.<ref type="figure" target="#fig_3">Figure 4a</ref>shows underlying and estimated P-values in a simulation where 80% of tests come from H1. Here, most Pvalues are small, and estimated with reasonable accuracy.<ref type="figure" target="#fig_3">Figure 4b</ref>shows the corresponding number of needed samples. Only a few of the P-values are large enough to stop early by the sequential MC criterion. However, the mild multiple testing correction (due to the relatively low π 0 ) means that a limited number of samples is needed to reach q-values below the chosen threshold (0.1). In order to further investigate the generalizability of the simulation results, we performed additional simulations with varying h (detailed plots are provided in the accompanying Galaxy Pages document). As expected, both the number of samples and the precision of estimated P-values increased as a function of increasing h, for both sequential MC and the MCFDR scheme. Apart from this, the behavior and relation between the schemes were as for the main simulations (using h = 20). We have also tried simulations with a range of different settings for various other parameters, without observing any unexpected behavior. Thus, we are not aware of any setting for which the MCFDR scheme would fail to work as intended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Real data</head><p>The regulatory role of epigenetic modifications is gaining increasing attention, to a large degree driven by the increased availability of high resolution, genome-wide data on such modifications (<ref type="bibr" target="#b0">Barski et al., 2007</ref>). A recent study by<ref type="bibr" target="#b28">Pekowska et al. (2010)</ref>investigates how profiles of H3K4me2-modifications in T-Cells (<ref type="bibr" target="#b38">Wang et al., 2008</ref>) are distributed within genes. Based on a clustering of H3K4me2-profiles, five classes of genes are distinguished. A main distinction between these classes is whether H3K4me2 is localized around the transcription start site or to a larger degree spread throughout the gene body.<ref type="bibr" target="#b28">Pekowska et al. (2010)</ref>proceed to discuss implications of these patterns for expression and tissue specificity. The distributive aspect of H3K4me2-modifications is in<ref type="bibr" target="#b28">Pekowska et al. (2010)</ref>mainly considered on a per class basis, where clustering allows patterns to be seen across a large number of genes. An alternative is to ask, individually for each gene, whether H3K4me2-modifications appears significantly more at the upstream end of the gene. This requires a precise hypothesis to be evaluated statistically for each gene. A natural test statistic is the average relative positioning of modifications within the gene. As histone modifications are connected to nucleosomes, which favor certain inter-spacings along DNA, the empirical inter-point length distribution should be preserved in a null hypothesis (<ref type="bibr" target="#b32">Sandve et al., 2010</ref>). This requires a Monte Carlo based hypothesis test, where H3K4me2-modifications are permuted while preserving inter-point distances, and where the test statistic is the average relative position within a gene. To focus on genes where there should be enough data to support conclusions to be drawn, we consider the 3466 Ensembl genes that include 10 or more histone modifications. We find that 2747 (79%) of the considered genes have significantly more H3K4me2modifications at the upstream end of the gene, confirming that the H3K4me2-modifications preferentially localize close to the transcription start site. For any particular gene, we may also ask the opposite question: does H3K4me2 localize preferentially at the downstream end of the gene? We find four Ensembl genes with significantly more H3K4me2 modifications downstream in the gene. Although the preferential localization downstream in these genes could represent a distinct regulatory signal targeting this gene set, a more plausible explanation is that the genes in question are overlapping other genes (or gene variants) that drive the association to H3K4me2 modifications. Manual inspection of these particular regions supports this latter explanation. Two of the genes overlapwith an alternative gene variant, where the methylations display a typical pattern in reference to this alternative variant. A third gene is overlapping with another (Ensembl) gene at the opposite strand (<ref type="figure" target="#fig_5">Fig. 5</ref>).</p><p>When asking whether H3K4me2-modifications appears significantly more at the upstream end of the gene, there is a high proportion of very low P-values. Therefore, the sequential MC threshold on number of extreme samples does not apply early<ref type="bibr">,402,136154,609,693</ref>), visualized by the UCSC Genome Browser. In reference to the above-mentioned gene (corresponding to Ensembl transcript ID ENST00000337049 in the<ref type="figure">figure)</ref>, H3K4me2 modifications occur significantly more downstream in the gene. However, in reference to the gene corresponding to ID ENST00000367220, which is shorter and at the opposite strand, the H3K4me2 modifications are preferentially located close to TSS, occur gradually less frequently throughout the gene body and stop appearing after the gene body.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MC multiple testing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.K.Sandve et al.</head><p>where the assumption is clearly wrong. The case with relatively few true null hypotheses leads to the largest computational burden using current algorithms, such as sequential MC. We speculate that such cases will become increasingly common in the future, with the advent of more elaborate study designs and research questions—in particular when doing local analysis of a generic question, such as investigating a specific relation between genomic features in bins along the genome. Our method assumes that the user is mainly interested in an FDRbased accept/reject decision for each test, and aims to stop MC sampling when further sampling would not change the decision. In such a setting, the concept of resampling risk due to Gandy (2009) is relevant. Attempting to control resampling risk for q-values would be an interesting undertaking, though not straightforward as it would require taking uncertainty (variance) of the FDR into account (<ref type="bibr" target="#b25">Owen, 2005</ref>).<ref type="bibr" target="#b16">Kustra et al. (2008)</ref>aims to improve computational efficiency of P-value estimation in specific MC settings. Although beyond the scope of the present article, it would be interesting to study the adoption of our FDR-based stopping criterion also to the methods of Gandy (2009) and<ref type="bibr" target="#b16">Kustra et al. (2008)</ref>. We have here considered the MC-based P-values as the values of direct interest, as these indeed satisfy the criteria for valid P-values (<ref type="bibr" target="#b4">Davison and Hinkley, 1997;</ref><ref type="bibr" target="#b29">Phipson and Smyth, 2010</ref>). An alternative view is to think of the MC computed P-values as estimates of an underlying true P-value. Then, the MC P-value estimate follows a binomial distribution around the underlying P-value (<ref type="bibr" target="#b21">North et al., 2002</ref>). As new samples are added, this estimated P-value will change, although it will still be highly dependent on the previous estimate. A possible variation of our MCFDR algorithm would be to stop sampling individually as each test reaches the specified q-value threshold: at Step 2b in the MCFDR algorithm as described in Section 2, for each i ∈ A, move i from A to B if q i &lt;α. Although even less computationally demanding, this could introduce a bias toward stopping sampling at estimates lower than the underlying P-value. The reason for this is the tendency to stop sampling at 'opportune' times, when the estimate happens to be at left-hand side of the binomial distribution around the underlying P-value. This is less likely to happen when using the global criterion, as it would need to happen for several estimates simultaneously. Simulations (described in the Galaxy Pages document) confirm this empirically. Both simulations and applications of the MCFDR algorithm is available through the Genomic HyperBrowser. A simple web tool allows anyone to run simulations at different parameter settings, providing detailed inspection of the properties of the algorithm. MCFDR is integrated into the main analysis engine of the Genomic HyperBrowser, allowing anyone to make use of the algorithm for analyses on their own data, or reproduce our biological findings (see the Galaxy Pages document referred to in the abstract). Furthermore, due to the inherent simplicity of the algorithm, it is easy to apply to any computational investigation that involves MC and multiple testing. Although modern technologies for data generation and computation is neither a necessity for MC estimation (<ref type="bibr" target="#b11">Hammersley and Morton, 1954</ref>) nor for multiple testing (<ref type="bibr" target="#b33">Schweder and Spjøtvoll, 1982</ref>), it seems clear that their adoption has been driven by increased computer power and data generation technologies such as microarrays. In the same way, although the ideas here presented on MC in multiple testing settings are general, we believe their relevance will increase strongly along with the future developments in e.g. next-generation sequencing, making them an important part of a bioinformaticians toolbox in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[17:18 29/10/2011 Bioinformatics-btr568.tex] Page: 3237 3235–3241</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.1.</head><figDesc>Fig. 1. Total number of samples for sequential MC and MCFDR, respectively, as a function of the number of true H1. When the proportion of true H1 is low, most tests are stopped by the sequential MC criterion, resulting in a similar number of samples for both schemes. At larger proportions of true H1, the multiple testing correction becomes milder, and thus fewer samples are needed to reach the FDR threshold. Thus, for the MCFDR scheme the total number of needed samples decreases with higher true H1 proportions. In contrast, for the sequential MC scheme, the number of needed samples increases linearly with increasing proportion of true H1. For standard MC, a large, constant number of samples is needed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.4.</head><figDesc>Fig. 4. Test collection at π 0 = 0.2. (a) Underlying and estimated P-values (sorted by underlying P-value). (b) Number of samples drawn per test, as well as the number of extreme samples among these, with tests sorted in the same order as in panel (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.5.</head><figDesc>Fig. 5. H3K4me2 modifications and Ensembl genes occurring in gene region corresponding to Ensembl gene ID ENSG00000112038 (chr6:154,402,136154,609,693), visualized by the UCSC Genome Browser. In reference to the above-mentioned gene (corresponding to Ensembl transcript ID ENST00000337049 in the figure), H3K4me2 modifications occur significantly more downstream in the gene. However, in reference to the gene corresponding to ID ENST00000367220, which is shorter and at the opposite strand, the H3K4me2 modifications are preferentially located close to TSS, occur gradually less frequently throughout the gene body and stop appearing after the gene body.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>(sorted by underlying P-value). The small P-values, mostly from H1, are accurately estimated. Larger P-values, mainly from H0, are</figDesc><table>Page: 3238 3235–3241 

G.K.Sandve et al. 

0 
1000 
2000 
3000 
4000 
5000 

0 
1000 2000 3000 4000 5000 

Number of true H1s 

Number of rejected tets 

Basic MC 
Seq MC 
MCFDR 

(a) 
( b) 

0 
1000 
2000 
3000 
4000 
5000 

0 
1000 2000 3000 4000 5000 

Number of true H1s 

FDR 

Basic MC 
Seq MC 
MCFDR 

Fig. 2. Behavior of the sequential MC and MCFDR schemes as a function of the number of true H1. (a) Number of rejected tests as a function of the number 
of true H1. (b) Empirical FDR on test collections as a function of the number of true H1. 

(a) 
( b) 

0 
1000 
2000 
3000 
4000 
5000 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Ordered tests 

P−value 

Underlying P 
Estimated P 

0 
1000 
2000 
3000 
4000 
5000 

0 
1000 2000 3000 4000 5000 

Ordered tests 

Number of samples 

Number of samples 
Number of extreme samples 

Fig. 3. Test collection at π 0 = 0.9. (a) Underlying and estimated P-values less accurately estimated, as for sequential MC. (b) Number of samples drawn per test, as well as the number 
of extreme samples among these, with tests sorted in the same order as in panel (a). 

0 
1000 
2000 
3000 
4000 
5000 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Ordered tests 

P−value 

Underlying P 
Estimated P 

0 
1000 
2000 
3000 
4000 
5000 

0 
20 40 60 80 100 

Ordered tests 

Number of samples 

Number of samples 
Number of extreme samples 

(b) 
(a) 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">for the majority of tests. An unlimited sequential MC run was still running after 2 weeks, having surpassed 1.5 million samples for some tests. We therefore imposed a ceiling on the maximum number of samples for sequential MC, set to 50 000 to ensure the possibility of significant results after multiple testing correction (indeed, using a maximum of 10 000 samples for sequential MC missed all significant results when asking about overrepresentation of H3K4me2 downstream in genes). Many of the tests hit the imposed ceiling on maximum number of samples, with a total number of &gt;30 million samples across tests. In the MCFDR scheme, using a FDR-threshold of 0.1, the total number of samples was &lt;350 000, almost a factor 100 less than with sequential MC (running time were for MCFDR &lt;5 min, as compared to &gt;9 h for sequential MC). As a large proportion of the null hypotheses end up rejected, the number of samples needed to reach q-values below the chosen threshold is limited. When investigating whether H3K4me2 modifications are preferentially located downstream in genes, there is a very low proportion of rejected tests. Most of the tests stop early by the sequential MC threshold, making the two schemes behave very similarly. The few rejected tests are subject to a very strong multiple testing correction, and as discussed above needs &gt;10 000 samples to at all allow any test to beat the FDR threshold. When applying a ceiling of 50 000 samples to both schemes, the total number of samples are essentially similar. If the ceiling is removed, the total number of samples increases only slightly for MCFDR, while it increases substantially for sequential MC (surpassing one million samples for some of the tests). Details are provided in the Galaxy Pages document. 4 DISCUSSION AND CONCLUSIONS We have provided a simple and efficient method for MC-based multiple testing. The method is freely available as part of the Genomic HyperBrowser, an open source, generic web-based system for statistical analysis of genomic annotation data. The method has been shown to work well on simulated data, and also to be highly useful for a realistic example, with computation times reduced by a factor of nearly one hundred. MC-based hypothesis testing is often needed for genomic data. In our example of H3K4me2-modifications, the simplifying assumptions that would be needed to do analytic tests would be highly unreasonable. As discussed in Ewan Birney et al. (2007), assuming Poisson distributed positions of H3K4me2-modifications (as would be needed for an analytic test) gives an unrealistically small variance of the null distribution, and hence leads to false positives. Indeed, the analytic version of the test gave 112 significant findings for the downstream positioning test, as opposed to only four findings when preserving inter-point distances in the MC version. Increasingly, we see applications where the calculation of each single MC sample is quite computationally expensive, and where the problem is further compounded by the need to do thousands of hypothesis tests (Ewan Birney et al., 2007; Sandve et al., 2010). In general, we must consider both statistical and computational efficiency. The FDR was introduced with the aim to improve statistical efficiency (as compared with e.g. Bonferroni correction): reject as many null hypotheses as possible, while controlling a reasonable error rate. As we have shown, taking the FDR into account during MC sampling can also greatly improve computational efficiency when we need to do MC-based multiple tests. As shown by both our simulation study and our real data example, our method is particularly useful in the case where many tests are truly H1, while still giving correct results if few or no tests are truly H1. Much work on multiple hypothesis testing and FDR has (implicitly or explicitly) assumed that the proportion of true null hypotheses is close to one (Efron, 2004). While this may be a natural assumption in the oft-studied case of testing for differential gene expression, we see no reason why it should be made in general. In fact, our study of H3K4me2-modifications provides an example</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank Arnoldo Frigessi for very helpful comments and discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">High-resolution profiling of histone methylations in the human genome</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Barski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="823" to="837" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: a practical and powerful approach to multiple testing</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Benjamini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Hochberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Sequential Monte Carlo p-values</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Besag</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Clifford</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="78" to="301" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A cross-validation based estimation of the proportion of true null hypotheses</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Celisse</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Robin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Plan. Inf</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page" from="3132" to="3147" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<monogr>
		<title level="m" type="main">Bootstrap Methods and their Application</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Davison</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Hinkley</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Large-scale simultaneous hypothesis testing: the choice of a null hypothesis</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Efron</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="96" to="104" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Identification and analysis of functional elements in 1% of the human genome by the encode pilot project</title>
		<author>
			<persName>
				<forename type="first">Ewan</forename>
				<surname>Birney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">447</biblScope>
			<biblScope unit="page" from="799" to="816" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Controlling the familywise error rate with plugin estimator for the proportion of true null hypotheses</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Finner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Gontscharuk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1031" to="1048" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Estimation of the proportion of true null hypotheses in high-dimensional data under dependence</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Friguet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Causeur</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Stat. Data Anal</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="2665" to="2676" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequential implementation of Monte Carlo tests with uniformly bounded resampling risk</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gandy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="1504" to="1511" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Goecks</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">86</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Poor man&apos;s Monte Carlo</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hammersley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Morton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="23" to="38" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A simplified Monte Carlo significance test procedure</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hope</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="582" to="598" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Bioinformatics approaches for genomics and post genomics applications of next-generation sequencing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">S</forename>
				<surname>Horner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="181" to="197" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparisons of estimators of the number of true null hypotheses and adaptive FDR procedures in multiplicity testing</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Hwang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Comput. Simul</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="207" to="220" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Estimating the proportion of true null hypotheses for multiple comparisons</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Doerge</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Informat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient p-value estimation in massively parallel testing problems</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kustra</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">601</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Estimating the proportion of true null hypotheses, with application to DNA microarray data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Langaas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="555" to="572" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">An efficient Monte Carlo approach to assessing statistical significance in genomic studies</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="781" to="787" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Next-generation gap</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Mcpherson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2" to="5" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Estimating the number of true null hypotheses from a histogram of p values</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Nettleton</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Agri. Biol. Environ. Stat</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="337" to="356" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">A note on the calculation of empirical p values from Monte Carlo procedures</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>North</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">439</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">1710</biblScope>
			<biblScope unit="page" from="18" to="29" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Page</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="3235" to="3241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Mc</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Testing</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Variance of the number of false discoveries</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Owen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="411" to="426" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">H3K27me3 forms BLOCs over silent genes and intergenic regions and specifies a histone banding pattern on a mouse autosomal chromosome</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">M</forename>
				<surname>Pauler</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Genome Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="221" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">A unique H3K4me2 profile marks tissue-specific gene regulation</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Pekowska</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1493" to="1502" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Permutation p-values should never be zero: Calculating exact p-values when permutations are randomly drawn</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Phipson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Smyth</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Robust estimation of the false discovery rate</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pounds</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Cheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1979" to="1987" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Estimating the occurrence of false positives and false negatives in microarray studies by approximating and partitioning the empirical distribution of p-values</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pounds</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Morris</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1236" to="1242" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">The Genomic HyperBrowser: inferential genomics at the sequence level</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">K</forename>
				<surname>Sandve</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Plots of p-values to evaluate many tests simultaneously</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Schweder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Spjøtvoll</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="493" to="502" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Rapid simulation of p values for product methods and multiple-testing adjustment in association studies</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Seaman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Müller-Myhsok</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="399" to="408" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Next-generation DNA sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shendure</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1135" to="1145" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">A direct approach to false discovery rates</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Storey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="479" to="498" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Parametric mixture models for estimating the proportion of true null hypotheses and adaptive control of FDR</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Tamhane</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lect. Notes Monograph Ser</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="304" to="325" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Combinatorial patterns of histone acetylations and methylations in the human genome</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="897" to="903" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Towards accurate estimation of the proportion of true null hypotheses in multiple testing</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">18874</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>