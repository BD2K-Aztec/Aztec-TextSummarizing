
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequence analysis Reptile: representative tiling for short read error correction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1920">. 20 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Xiao</forename>
								<surname>Yang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Bioinformatics and Computational Biology Program</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Karin</forename>
								<forename type="middle">S</forename>
								<surname>Dorman</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Bioinformatics and Computational Biology Program</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Statistics</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Genetics, Development &amp; Cell Biology</orgName>
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<postCode>50011</postCode>
									<settlement>Ames</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Srinivas</forename>
								<surname>Aluru</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Bioinformatics and Computational Biology Program</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Genetics, Development &amp; Cell Biology</orgName>
								<orgName type="institution">Iowa State University</orgName>
								<address>
									<postCode>50011</postCode>
									<settlement>Ames</settlement>
									<region>IA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Indian Institute of Technology Bombay</orgName>
								<address>
									<postCode>400076</postCode>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sequence analysis Reptile: representative tiling for short read error correction</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">26</biblScope>
							<biblScope unit="page" from="2526" to="2533"/>
							<date type="published" when="1920">. 20 2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq468</idno>
					<note type="submission">Received on March 16, 2010; revised on August 9, 2010; accepted on August 10, 2010</note>
					<note>[14:40 29/9/2010 Bioinformatics-btq468.tex] Page: 2526 2526–2533 Associate Editor: Joaquin Dopazo</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Error correction is critical to the success of next-generation sequencing applications, such as resequencing and de novo genome sequencing. It is especially important for high-throughput short-read sequencing, where reads are much shorter and more abundant, and errors more frequent than in traditional Sanger sequencing. Processing massive numbers of short reads with existing error correction methods is both compute and memory intensive, yet the results are far from satisfactory when applied to real datasets. Results: We present a novel approach, termed Reptile, for error correction in short-read data from next-generation sequencing. Reptile works with the spectrum of k-mers from the input reads, and corrects errors by simultaneously examining: (i) Hamming distance-based correction possibilities for potentially erroneous k-mers; and (ii) neighboring k-mers from the same read for correct contextual information. By not needing to store input data, Reptile has the favorable property that it can handle data that does not fit in main memory. In addition to sequence data, Reptile can make use of available quality score information. Our experiments show that Reptile outperforms previous methods in the percentage of errors removed from the data and the accuracy in true base assignment. In addition, a significant reduction in run time and memory usage have been achieved compared with previous methods, making it more practical for short-read error correction when sampling larger genomes. Availability: Reptile is implemented in C++ and is available through the link: http://aluru-sun.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>High-throughput sequencing is profoundly changing the way genetics data are collected, stored and processed (<ref type="bibr" target="#b11">Shendure and Ji, 2008</ref>). The advantages of the new technology have led to revitalization of old techniques and discovery of novel uses, with growing applications in resequencing, de novo genome assembly, metagenomics and beyond (<ref type="bibr" target="#b0">Ansorge, 2009;</ref><ref type="bibr" target="#b7">Marguerat et al., 2008</ref>). New technology inevitably comes with challenges. For many next-generation sequencers, the advantage of deeper and cheaper * To whom correspondence should be addressed. coverage comes at the cost of shorter reads with higher error rates compared with the Sanger sequencing they replace. Genome assembly, the de novo inference of a genome without the aid of a reference genome, is challenging. Sanger reads, typically 700–1000 bp in length, are long enough for overlaps to be reliable indicators of genomic co-location, which are used in the overlap-layout-consensus approach for genome assembly. However, this approach does poorly with the much shorter reads of many next-generation sequencing platforms (e.g. 35–100 bp for Illumina Genome Analyzer II). In this context, de Bruijn graph (<ref type="bibr" target="#b4">Idury and Waterman, 1995</ref>) and string graph (<ref type="bibr" target="#b8">Myers, 2005</ref>) based formulations that reconstruct the genome as a path in a graph perform better due to their more global analysis and ability to naturally accommodate paired read information. As a result, they have become de facto models for building short-read genome assemblers, e.g. ALLPATHS (<ref type="bibr" target="#b1">Butler et al., 2008</ref>), Velvet (<ref type="bibr" target="#b15">Zerbino and Birney, 2008</ref>), ABySS (<ref type="bibr" target="#b12">Simpson et al., 2009</ref>) and Yaga (<ref type="bibr" target="#b5">Jackson et al., 2010</ref>). Error correction has long been recognized as a critical and difficult part of these graph-based assemblers. It also has significant impact in other next-generation sequencing applications such as resequencing. We give a brief review of several well-known error correction methods. Alignment-based error correction methods, such as MisEd (<ref type="bibr" target="#b14">Tammi et al., 2003</ref>) for Sanger reads, require refined multiple read alignments and assume unusually isolated bases to be read errors. Like the Sanger-motivated assembly algorithms, these approaches do not adapt well to short reads. Hence,<ref type="bibr" target="#b2">Chaisson et al. (2004)</ref>proposed the spectral alignment problem (SAP): in a given dataset, a kmer is considered solid if its multiplicity exceeds a threshold, and insolid otherwise. Reads containing insolid kmers are corrected using a minimum number of edit operations so that they contain only solid kmers post-correction. Similar approaches have been adapted and used by others (<ref type="bibr" target="#b1">Butler et al., 2008</ref>). To overcome the typically long run times of SAP-based approaches,<ref type="bibr" target="#b10">Schröder et al. (2009)</ref>proposed SHREC, a method based on a generalized suffix tree constructed from short-read data using both forward and reverse complementary strands. SHREC compares the multiplicity of a substring, represented by a node in the suffix tree, with its expected frequency of occurrence calculated analytically, assuming uniform sampling of the genome and uniformly distributed sequencing errors. The nodes with observed counts that deviate beyond a tolerable threshold from their expected values are considered erroneous. An erroneous node is corrected to a sibling when applicable, and all its descendants are transferred to the selected sibling. Well-engineered code is necessary to cope with the largePage: 2527 2526–2533</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reptile</head><p>memory requirement of the suffix tree data structure. Unlike these general purpose error correction methods, FreClu (<ref type="bibr" target="#b9">Qu et al., 2009</ref>) targets transcriptome data. The error rates for each position of a read are estimated in the same experiment via a set of control reads of a known bacterial artificial chromosome (BAC) sequence. Reads are clustered using the estimated error rates, and after error correction, FreClu could map ∼5% more reads back to the reference genome. Error correction of short-read data is particularly challenging because of the massive datasets, non-uniformly distributed read errors introduced at relatively high rates, and non-uniform coverage of the target genome. Next-generation short-read sequencers produce hundreds of millions of reads in a single run, and this trend of fast, massive data generation is continuing to accelerate. To process these data, even an efficient linear space algorithm could easily exceed available memory on a standard desktop computer. The high rate of sequencing errors also significantly increases memory usage due to the introduction of numerous erroneous kmers that are not present in the genome. Errors are typically identified as the unusual reads or kmers occurring less frequently than a threshold calculated under the assumptions of uniform coverage and error distribution. Neither assumption holds true in real data, leading to an excess of false error predictions. In this article, we present Reptile, a scalable short-read error correction method that effectively addresses the above challenges. We draw upon the k-spectrum approach pioneered in earlier results, but explore multiple alternative kmer decompositions of an erroneous read and use contextual information specified by neighboring kmers to infer appropriate corrections. Reptile also incorporates quality score information when available. We present algorithmic strategies to store kmer Hamming distance graphs and efficiently retrieve all graph neighbors of a kmer as candidates for correction. We compare our results with SHREC (<ref type="bibr" target="#b10">Schröder et al., 2009</ref>), a high-quality short-read error correction method, and one of the more recent in a line of continuously improving error correction protocols. In all experiments with Illumina datasets, Reptile outperforms SHREC in percentage of errors corrected and accuracy of true base assignment. Futhermore, a significant reduction in memory usage and run time makes Reptile more applicable to larger datasets. As with most current approaches including SHREC, Reptile is targeted to short reads with substitution errors, assuming insertion and deletion errors are rarely produced by short-read sequencing technology (<ref type="bibr" target="#b3">Dohm et al., 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">NOTATIONS</head><p>Let R ={r 1 ,r 2 ,...,r n } be a collection of short reads sequenced from genome G. For simplicity (but without loss of generality), we assume each read r i has a fixed length L. The coverage of the genome by the reads is given by Cov = nL |G| , where |G| denotes the genome length. Define the k-spectrum of a read r to be the set r k ={r[i : i+k −1]|0 ≤ i &lt; L −k +1}, where r<ref type="bibr">[i : j]</ref>denotes the substring from position i to j in r. We index the positions of a string starting from 0. The kspectrum of R is given bywhether or not they occur in R k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>The success of any error correction method relies on an adequate coverage of the target genome. If we know the genomic location of every read, we could layout all reads that contain a specific genomic position into a multiple alignment (<ref type="figure">Fig. 1</ref>) and correct all erroneous bases to the consensus base under the reasonable assumption that errors are infrequent and independent. For instance, base T in r 3 would be considered a sequencing error to be corrected to the consensus base A. The main idea underlying Reptile is to create approximate multiple alignments, with the possibility of substitutions, in the absence of location information. Multiple alignments with substitutions could be created by considering all reads with pairwise Hamming distance less than some threshold, but such alignments are already hard (<ref type="bibr" target="#b6">Manthey and Reischuk, 2005</ref>) and even in high coverage situations, the occurrence of many exactly coincident reads, e.g. r 0 and r 1 in<ref type="figure">Figure 1</ref>, are rare. We therefore resort to alignments on subreads, the substrings of a read. Storing R, let alone all its subreads, could be memory intensive, not to mention the memory required to store information required for error correction. Inspired by the idea for bounding memory usage with de Bruijn graphs in short-read assembly, we work with kmer subreads of input data, where the memory of storing the k-spectrum R k is bounded by O(min(4 k ,n(L −k +1))). Typically, k is chosen so that the expected number of occurrences of any kmer in the genome should be no more than one, i.e. 4 k &gt; |G|. Therefore, choosing 10 ≤ k ≤ 16 is sufficient for microbial or human genomes, in which case the k-spectrum would fit within 4 GB RAM regardless of input size. Focusing on reasonably short kmers has several advantages. First, we expect an adequate number of kmers to align to the same position along the genome even with relatively low coverage (e.g. 40×). High local coverage is needed to identify erroneous bases. For instance, in<ref type="figure">Figure 1</ref>, there exist five subreads, four copies of α 2 and one copy of α 2 , aligning to the same starting position in the genome, but this number reduces to three for the longer subread α 2 || 0 α 3. Second, it is less compute intensive to identify N d i when k is small, since there are fewer ways to select d out of k positions. Last, sequencing errors in kmers are much less frequent compared with full-length reads, so d need not be large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. G</head><p>is the target genome, shown as a bold line; r i 's (0 ≤ i ≤ 8) represent reads, shown as thin lines; α j (0 ≤ j ≤ 8), α 2 and α 2 are kmer instances in the reads, shown as rectangles. Every read is drawn aligned to its origin of sequencing position on the target genome. The bases at two positions in the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X.Yang et al.</head><p>Nevertheless, relying solely on short kmers can easily lead to ambiguities when resolving erroneous bases. For instance, in<ref type="figure">Figure 1</ref>, without knowing the alignment, it is unclear if α 2 should be corrected to α</p><formula>≥ 1 (1 ≤ i &lt; m).</formula><p>Note that if t i is specified as r<ref type="bibr">[j : j ]</ref>, then the overlaps between consecutive tiles can be inferred; i.e. l i 's can be derived from t i 's. Multiple tilings exist for any read. For example, both ((If read r contains errors and T r is a tiling of r, then we expect to find a tiling T s of the true read s as one of the d-mutant tilings of T r , where constituent tiles of T s have higher coverage than those of T r. However, in some cases, T s will not be found among the d-mutant tilings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The algorithm</head><p>For ease of presentation, we assume R can fit in main memory (this requirement will be relaxed later). The algorithm consists of two major phases. We first provide a brief overview, and subsequently describe the algorithm in more detail and analyze its time and space complexity.</p><p>(1) Information extraction.</p><formula>(a) Derive the k-spectrum R k of R.</formula><p>(b) Derive Hamming graph</p><formula>G H = (V H ,E H ), where v i ∈ V H represents α i ∈ R k and ∃ e ij = (v i ,v j ) ∈ E H ⇐⇒ hd(v i ,v j ) ≤ d, for a given threshold d.</formula><p>(c) Compute tile occurrences.</p><p>(2) Individual read error correction.</p><p>(a) Place an initial tile t at the beginning of the read.</p><p>(b) Identify d-mutant tiles of t.</p><p>(c) Correct errors in t as applicable.</p><p>(d) Adjust tile t placement and go to step 2b, until tile placement choices are exhausted.</p><p>Given a read r ∈ R, any of its constituent kmers α is a vertex v in the Hamming graph. The d-neighborhood of α is accessible via the edges incident to v. Hence, if α contains at most d substitution sequencing errors, the kmer it should be corrected to exists in its d-neighborhood. By building local, approximate alignments of tilings constructed from d-neighborhoods, our strategy identifies a tiling of the true read as a high frequency tiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Phase 1: information extraction</head><p>Constructing R k involves one linear scan of each read in R. This takes O(nL) time. We maintain R k in sorted order using O(|R k |log|R k |) time. The space requirement for R k is given by |R k |=O(min(4 k ,n(L −k +1)). Any non-ACGT characters (due to difficulty in base calling) are initially converted to A, which will be validated or corrected later by the algorithm. During error correction, it is important to have fast access to the dneighborhood of any kmer, ideally in constant time per neighboring kmer. One could do so by storing the entire Hamming graph G H , but it would require large amount of memory. If we assume G as a random string, and errors accumulate independently with probability p e , then the probability that a node is linked to another is</p><formula>p k = d e=1 k e [0.25 k−e 0.75 e +(1−p e ) k−e p e e ]</formula><p>, including the chance that another random kmer in the genome is within d Hamming distance of the current kmer and the chance that the current kmer contains up to d errors. Thus, the expected memory usage is O</p><formula>|R k | 2 p k .</formula><p>Alternatively, we could recover all edges associated with a given kmer α i by checking whether each kmer in its complete neighborhood, α j ∈ N d ci , exists in R k. If α j ∈ R k , then there is an edge between v i and v j in theTo reduce the average time for inferring N d i of α i , we replicate R k in memory and sort each replicate on a different subset of positions in the kmer string, using the following strategy:</p><p>(a) Store indices 0 to k −1 in a vector A.</p><p>(b) Divide A evenly into c (d &lt; c ≤ k) chunks, each of size k/c or k/c.</p><p>(c) For every choice of c d chunks, sort R k by masking the indices from selected chunks and store the sorted results separately.</p><p>To identify N d i of α i , we query α i against each sorted k-spectrum R k j (0 ≤</p><formula>j &lt; c d</formula><p>) by binary search considering only indices used for sorting R k j. All kmers that belong to the d-neighborhood of α i are adjacent to α i in at least one R k j. If sequencing errors accumulate independently, then the expected number of elements of N d i found in every R k j is h =|R k |/4 k−dk/c. Hence, we need approximately c d h|R k |log|R k | expected time to recover all edges of the Hamming graph, i.e. O(|R k |log|R k |) time assuming both c d and h are constants. Typically, |R k | &lt;&lt; 4 k , therefore, choosing a larger c value will use more memory, but less expected run time. As an example, in a real Escherichia coli dataset with 160× coverage, storing 13 copies of R k required only ∼560 MB memory, but the average number of hits per 13mer in each 13-spectrum was less than one. Therefore, identifying each element of N 1 for a 13mer took constant time on average. The above method provides an exact solution for identifying all edges in the Hamming graph. Alternatively, a simpler recursive approximation derives N d by inferring N 1 for every element in N d−1. This stategy might be more biologically meaningful (<ref type="bibr" target="#b9">Qu et al., 2009</ref>), but is only an approximation since an edge between two vertices v i and v j could be recovered only if there exists a path connecting them such that adjacent vertices represent kmers that differ by exactly one position. In this case, choosing a smaller k, using a larger dataset, or having a higher sequencing error rate all improve the chance to identify all edges. Tiles are l-concatenations of consecutive or overlapping kmers found in reads. Here, we use one fixed value of l but several different values of l can be used to consider tiles with different lengths. We compute the multiplicities of tiles by a linear scan of every read to record all tiles, followed by a sort of the collected tiles and one linear scan of the sorted list. This process takes O(|R 2k−l |log|R 2k−l |) time, where |R 2k−l |=O(min(4 2k−l ,n(L −2k +l +1))). Meanwhile, we record the number of occurrences of each tile, where every position has a quality score exceeding some threshold Q c. Typically, a quality score is associated with every base of a short read. The score indicates the probability p e that the corresponding base is sequenced incorrectly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reptile</head><p>For instance, Illumina GenomeAnalyzer encodes the quality score as Q = −10log 10 (p e /1−p e ). A higher score indicates a more reliable base call. To deal with the double strandedness of the target genome, we consider both the forward and reverse complementary strands of every read. Edge identification in the Hamming graph takes twice the time, but no additional memory is needed since R k is already generated using both strands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Phase 2: error correction</head><p>We use the contextual information in read r to identify sequencing errors through the process of choosing a tiling T r and comparing it with its d-mutant tilings. In particular, if r contains x errors, and we choose any tiling T r , then an error-free tiling T s belongs to the collection of d-mutant tilings of T r if d ≥ x. Under the standard assumption of uniform coverage, the tiles of T s should be substantially more abundant than at least some of the tiles of T r with errors. After T s is identified, the true read s can be readily inferred from T s. In practice, x could be large, and sequencing errors tend to cluster toward the 3 end of a read. Since we prefer d to be small to limit memory usage, run time and false error detection, it is entirely possible that T s is not one of the d-mutant tilings of T r. On the other hand, an alternate tiling r of r may lower the maximum number of mutations per kmer to below d such that s with high frequency tilings is one of the d-mutant tilings of r. In the case that there is no such tiling r , we examine a subset of constituent tiles in r. If a high coverage path of these selected tiles is present, the tiles are corrected. With some errors removed, a tiling may now exist that contains the true read among its d-mutant tilings. These observations are sufficient to motivate the following procedure for identifying and correcting read errors. Place a tile t on r and attempt to correct t via comparisons with its d-mutant tiles (tile correction). If t is validated or corrected, move to the next tile in the standard tiling and repeat. If t cannot be corrected or validated, look for an alternative tiling, presumably one that avoids clusters of more than d errors that are thwarting attempts to find error-free tiles within the d neighborhoods. We first describe tile correction in Algorithm 1, then the overall procedure for read correction in Algorithm 2. Tile correction. For each tile in R, we have recorded its multiplicity O c in R and the number O g of those instances where the quality score of every base exceeds Q c. If a short read dataset comes with unreliable or missing quality score information, we set O g = O c. Otherwise, O g is a better estimate of the number of error-free occurrences of each tile. The tile correction procedure is given in Algorithm 1. A decision to correct tile t is based on a comparison of the high-quality occurrence counts O g of t compared with its d-mutant tiles. As a rule of thumb, there must be compelling evidence before a correction is made. Any tile is automatically validated if its occurrence count exceeds an upper threshold C g (lines 1–2). A low occurrence tile with no d-mutant tiles is validated only if it occurs more than a low threshold C m times (lines 4–6). When there exist d-mutant tiles of t with much higher frequencies (at least C r times, C r &gt; 1) than t and which differ at low-quality bases (&lt; Q m ) in t, it is likely that t contains error(s) and the true tile is one of its d-mutant tiles. In such cases, a correction is possible only if there is a unique d-mutant tile with the closest Hamming distance, including a mutation at a low-quality base in t (line 14). We will replace t with this tile. Otherwise, we choose not to modify t to avoid false corrections. Similar reasoning applies to t with very low multiplicity (lines 17 and 18). Since there exist a constant number of d-mutant tiles of t, and correcting t requires comparison of every base between t and t ∈ T , Algorithm 1 takes constant time. Read correction. The overall procedure for correcting a read is given in Algorithm 2. In line 1, an initial tile is chosen and d 1 and d 2 , two parameters specifying the maximum Hamming distance allowed in the two constituent kmers while identifying mutant tiles, are initialized to d. The algorithm terminates when no more plausible tiles can be identified. Within the while loop, d-mutant tiles are identified for the current tile (line 3), which is validated or corrected using Algorithm 1 (line 4). The new placement of tile t next is chosen according to which of the three decisions is made by Algorithm 1 (line 4). Repeated placement of t next according to decisions,<ref type="bibr">[D1]</ref>Algorithm</p><formula>if O g (t) ≥ C m then 6.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t</head><p>is valid; return.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>end if</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8.</head><p>return due to insufficient evidence.</p><formula>9. end if 10. if O g (t) ≥ C m then 11. Select d-mutant tiles T ={t | O g (t ) O g (t) ≥ C r }. 12.</formula><p>If T =∅, t is valid; return.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13.</head><p>For every t ∈ T , record those positions differed from t and corresponding quality scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14.</head><p>Correct t to t and return</p><formula>if 1) hd(t,t ) ≤ hd(t,t</formula><p>) for all t ∈ T. 2) at least one of the corrected bases has quality score less than Q m in t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15.</head><p>If t is not unique, return due to insufficient evidence (ambiguities).Correct t to t ; return.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>else</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>end if 22. end if</head><p>through<ref type="bibr">[D3]</ref>(lines 6–8), gradually forms a validated or corrected tiling of read r, although some reads may never be fully validated. To better understand how the rules in lines 6–8 choose a tiling, we illustrate with an example in<ref type="figure">Figure 2</ref>for d = 1. An initial tile t 0 is chosen as shown. Since there exists one error in each of the constituent kmers, t 0 can be corrected. Tile t 1 is chosen as the next tile according to<ref type="bibr">[D2]</ref>, but two sequencing errors within the second kmer of t 1 lead to an inconclusive decision. Hence, t 1 is not selected in the tiling and an alternative tile τ 1 is chosen according to<ref type="bibr">[D3(a)]</ref>. The algorithm iterates and if tiles can be validated or corrected at every stage, we are able to complete a tiling moving from 5 to 3 along the read. Unfortunately, non-uniform coverage and the existence of more than one reasonable d-mutant tile can lead to an inconclusive decision in Algorithm 1 regardless of tiling choice. In<ref type="figure">Figure 2</ref>, the 5 to 3 tiling encounters an inconclusive dead-end at arrow a 3. To move past dead-end tiles, a non-overlapping tile τ 2 is chosen by<ref type="bibr">[D3(b)</ref>]. A small unvalidated gap is left in the middle of the 5 to 3 tiling of this read. The example shows only the tiling from 5 to 3. The same strategy is applied in the 3 to 5 direction. We briefly analyze the run time of Algorithm 2. Tiles are sorted, so tile information is accessed in O(log(nL)) time. Therefore, line 3 requires O(log(nL)) time. Once some tiles have been corrected, the search space for new d-mutant tiles shrinks when d 1 or d 2 is set to 0 in line 5. The maximum number of non-overlapping tiles in a tiling is the constant L/|t|. Hence, the time spent in correcting each read is O(log(nL)), and the overall run time of Algorithm 2 is O(nLlog(nL)).Based on the decisions made on t in the former step, tile t next of r will be chosen according to<ref type="bibr">[D1]</ref>–<ref type="figure">Fig. 2</ref>. An illustration of choosing a tiling of a read for d = 1. A read is represented on top by a concatenation of rectangles, where each rectangle denotes a kmer. Each tile is represented by a concatenation of two adjacent arrows, which denote its kmer composition. For simplicity of illustration, we choose the read length to be divisible by k and each tile is a 0-concatenation of two adjacent kmers. X's denote sequencing errors. Each bold arrow, a i (1 ≤ i ≤ 4), denotes tile with insufficient evidence for correction. The placement of an alternative tile is indicated by a dotted arrow. be adjusted to consider the error rates of the particular next-generation sequencing equipment in use. Given Q c and counts of high-quality tile ocurrences, we choose C g so that only a small percentage (e.g. 1–3%) of tiles have high-quality multiplicity greater than C g. C m is chosen so that a larger percentage (e.g. 4–6%) of tiles occur more than C m times in R. As C m value decreases, more errors are corrected at the cost of an increased risk of false error correction. The specific values chosen depend on the histogram of tile occurrences. By default, we set C r = 2 such that a low frequency tile could only be corrected to a tile with at least twice the frequency. Increasing C r improves the confidence in error correction. Finally, we choose k ==log 4 |G|| when an estimate of the length of the genome is available, otherwise, a number between 10 and 16 should work. Tile size is ∼2k, so kmer overlap is 0 to a few bases. The maximum Hamming distance d is set to one by default. But when k is chosen to be relatively large (e.g. 14 to 16), increasing d allows us to identify more sequencing errors but incurs a longer run time and increases the risk of false error prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Choosing parameters</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Overall complexity</head><p>Combining the analysis for each step, the overall run time is O(nLlog(nL)) and the space usage is O(|R k |+|R |t| |). When the collection of input short reads R does not fit in main memory, we propose a divide and merge strategy where R is partitioned into chunks small enough to occupy just a portion of main memory. For each chunk, we stream through each read and record the k-spectrum and tile information, merging it with the data from previous chunks. Reads need not be stored in memory after they have been processed. A similar strategy is applied for error correction: R is reloaded into memory in chunks, tilings and d-mutant tilings are inferred for each read, and errors are corrected as warranted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We evaluated Reptile on several Illumina/Solexa datasets and compared the results with SHREC (<ref type="bibr" target="#b10">Schröder et al., 2009</ref>) version 2.0, a recent high-quality short-read error correction method that is itself shown to give superior results over prior k-spectrum approaches. We omitted evaluation on simulated data because simulations with random errors or synthetic genomes do not accurately reflect actual short-read sequencing errors (<ref type="bibr" target="#b3">Dohm et al., 2008</ref>), and could even be misleading. Our test datasets are Illuminagenerated short reads of well-characterized, Sanger assembled bacterial genomes. Knowledge of the genomes is needed for determining the accuracy of the error correction methods. The six experimental datasets, downloaded from the sequence read archive at NCBI, are listed in<ref type="figure" target="#tab_1">Table 1</ref>. Datasets D1 (Accession Number: SRX000429), D2 (SRR001665_1), D5 (SRR022918_1) and D6 (SRR034509_1) are Illumina reads from the E.coli str. K-12 substr (NC_000913) genome (∼4.64 Mbp); datasets D3 (SRR006332) and D4 are Illumina reads from the Acinetobacter sp. ADP1 (NC_005966) genome (∼3.6 Mb). The first four datasets are generated by Solexa 1G Genome Analyzer, where each read has the same length 36 bp. The latter two datasets are generated using the more recent Illumina Genome Analyzer II, with read lengths of 47 bp in D5 and 101 bp in D6. D1 has high coverage and low error rate. D2 has typical coverage and low error rate. D3 has high coverage and high error rate. D4 is derived from D3 by randomly selecting short reads amounting to 40× coverage. This is done for evaluating performance on a low coverage, high error rate dataset. Both D5 and D6 have higher error rates. In addition, &gt;13.9% of the reads in D6 contain ambiguous nucleotides, denoted by character N. Since SHREC cannot process non-ACGT characters, we eliminated all reads with ambiguous bases, even though Reptile has no such limitation. The number of discarded reads is indicated in column 5,<ref type="figure" target="#tab_1">Table 1</ref>. Similar to<ref type="bibr" target="#b10">Schröder et al. (2009)</ref>, we evaluated error correction results with the aid of RMAP (v2.05) (<ref type="bibr" target="#b13">Smith et al., 2008</ref>), which maps short reads to a known genome by minimizing mismatches. We allowed up to five mismatches per read in the first four datasets Page: 2531 2526–2533Error rate is estimated by mapping the reads to the corresponding genome using RMAP, and finding mismatches based on uniquely mapped reads.and allowed up to 10 mismatches (default value of RMAP) in D5 and fifteen mismatches in D6 since the reads are longer in the latter two datasets. Reads that could not be mapped to the genome, or that map to multiple locations, are discarded. The mismatches between uniquely mapped reads and the genome are considered read errors. Quality of the datasets varied as shown in<ref type="figure" target="#tab_2">Table 2</ref>, with the percentage of reads that are uniquely mapped ranging from 62.5 to 96.7%. The large percentage of unmappable reads, the higher error rates as well as the large percentage of reads with ambiguous bases indicate that D5 and D6 have lower quality than D1 to D4. Since the goal of error correction is to identify and correct each erroneous nucleotide, we assess the quality of error correction at the base level. A true positive (TP) is any erroneous base that is changed to the true base, a false positive (FP) is any true base changed wrongly, a true negative (TN) is any true base left unchanged, and a false negative (FN) is any erroneous base left unchanged. Then Sensitivity = TP/(TP + FN) and Specificity = TN/(TN + FP). Note that these definitions are different from those used by<ref type="bibr" target="#b10">Schröder et al. (2009)</ref>, which target read-level error detection (whether a read is flagged as containing an error or not). This is a less stringent measure because any read containing errors was classified as TP provided at least one of its errors was detected and irrespective of whether they were accurately corrected or not. We propose two additional measures for assessing the quality of error correction: @BULLET Erroneous base assignment (EBA): let n e denote the number of erroneous bases that are correctly identified but changed to a wrong base. Then, EBA = n e /(TP+n e ) reflects how well we are able to correct an erroneous base to the true base after a sequencing error has been identified. A lower value of EBA indicates a more accurate base assignment. @BULLET Gain: (TP − FP)/(TP + FN). This measures the percentage of errors effectively removed from the dataset, which is equivalent to the number of errors before correction minus the number of errors after correction divided by the number of errors before correction. Clearly, Gain should approach one for the best methods, but may be negative for methods that actually introduce more errors than they correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reptile</head><p>We regard these measures as important because they penalize failing to detect an erroneous base, correctly detecting an erroneous base but wrongly correcting it, and characterizing a correct base to be an erroneous base. In particular, we strongly advocate the Gain measure as it captures data quality post-error correction compared with the quality prior to the correction. The results of running Reptile and SHREC on the six datasets are summarized in<ref type="figure" target="#tab_3">Table 3</ref>. Due to the larger memory usage of the SHREC program, we were not able to obtain results for D3, D5 and D6. In all other cases, Reptile had higher Gain and lower EBA than SHREC. With other parameters fixed in Reptile, we varied maximum d value used for inferring Hamming graph in D1 and D2. As expected, the run time significantly increased as d increased, since the size of d-neighborhood for each kmer increased. Also, we see an increase in both TP and FP and four to five times higher EBA, indicating that when we increase the search space, we run the risk of false error detection and correction but increase the chance to identifying more errors. An inherent difficulty in using any method is the challenge of choosing optimal parameters. The results reported in<ref type="figure" target="#tab_3">Table 3</ref>are obtained when using the parameter choices suggested in Section 3. To show that even better performance is possible, we applied a series of parameter choices to dataset D3 (<ref type="figure">Fig. 3</ref>). Gain improved from 63% with the default parameters to as high as 72%. We chose to report on Reptile using the default parameters for all cases in<ref type="figure" target="#tab_3">Table 3</ref>because it is unfair to choose optimal parameters for each individual case based on our knowledge of the genome, which would generally not be known. Similarly, we used the default parameter settings for SHREC. Using a different combination of parameters may vary the results of both SHREC and Reptile. In this article, we have presented a method to select parameters for Reptile based on known quantities such as kmer frequency and quality score histograms. A similar guidance is needed for the SHREC program and is beyond the scope of the article. Note that we do not take into account improved results that can only be obtained by the knowledge of the genome (<ref type="figure">Fig. 3</ref>). One can observe that our method of parameter estimation based on statistics from the dataset is performing better than analytical calculations based on the assumptions of uniform error distribution and uniform coverage of genome by reads. In addition, we compared the run time and memory usage of SHREC and Reptile. SHREC is a multi-threaded program while the current release of Reptile can only use a single core. Hence, we report run times in total CPU hours. Both methods were run on a SUN Fire X2200 workstation with dual quad-core 2.3 GHz AMD Barcelona three processors with 8 GB RAM and 4 GB swap memory, running Debian GNU/Linux x86_64. Results in<ref type="figure" target="#tab_3">Table 3</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X.Yang et al.</head><formula>D3 SHREC − − − – – – – – – –</formula><formula>D5 SHREC − − − – – – – – – – (71x)</formula><formula>D6 SHREC − − − – – – – – – – (193x)</formula><formula>, (8, 60), (8, 55), (8, 50), (8, 45), (7, 45), (6, 45), (5</formula><p>, 45), respectively. The last sample point uses parameters</p><formula>(k = 12,d = 2,|t|=24,C m = 8,Q c = 45).</formula><p>(compare D1 and D2), while the memory usage of SHREC increased with the number of reads, genome length and sequencing errors. In addition, although D1 contains many more reads (20.8M) than D3 (17.7M), the higher error rate significantly increased memory usage in both methods. To enable fair comparison with SHREC, the above experiments were carried out by excluding all reads containing ambiguous bases. However, Reptile does have functionality to deal with ambiguous bases, which is useful in the following cases: (i) if a read contains few ambiguous bases, the surrounding high-quality regions provide sufficient information to infer correct bases by referencing the k-spectrum; (ii) in some datasets, neglecting reads containing ambiguous bases leads to excessive loss of data, which further distorts uniformity of the sampling. For instance, as much as 13.9% reads in dataset D6 contain N's. Reptile attempts to correct ambiguous bases in regions where their density is low. If a read contains too many ambiguous bases, it is low quality and untrustworthy. Some reads may have ambiguous bases clustered in some region, e.g. the 3 region, while otherparts may still be of good quality. It is more meaningful to try correcting ambiguous bases in the latter parts alone, since a cluster of ambiguous nucleotides in a read makes it unlikely to pinpoint other reads that have the same genomic co-location. Formally, Reptile attempts to correct an ambiguous base b of read r, if in any substring r<ref type="bibr">[i : i+w−1]</ref>that contains b, there are no more than d ambiguous bases. The ratio of d to w constrains the maximum density of ambiguous bases allowed in attempting error correction. By default, w is set to k (to equal kmer length), while d is set to the maximum Hamming distance allowed (Section 3). To implement the above idea, all ambiguous bases satisfying the density constraint are changed to one of the bases from the set {A, C, G, T} initially (default 'A'), and will be validated or corrected later by the algorithm. To test the accuracy of this procedure as well as study the effect of the choice of the default base, we conducted Reptile runs on the full datasets of D2 (36 bp) and D6 (101 bp) by setting the ambiguous bases to the chosen default. The results are presented in<ref type="figure" target="#tab_4">Table 4</ref>. The default base used is shown under Column 'N'. Accuracy is defined to be the percentage of ambiguous bases that have been successfully corrected (again, only reads uniquely mapped by RMAP are considered as truth is unknown otherwise). The last four<ref type="figure" target="#tab_4">Table 4</ref>, (i) the accuracy of ambiguous base correction is high and consistent with the overall EBA rate, (ii) changing the default base slightly influenced the results due to the resulting differences in k-spectrum composition and (iii) the sensitivity and Gain values are slightly lower than reported in<ref type="figure" target="#tab_3">Table 3</ref>, mainly because the ambiguous bases that were left uncorrected by Reptile could sometimes be uniquely mapped to the reference genome using RMAP, hence increasing the FN value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>The proposed error correction algorithm is conservative because it avoids changing bases unless there is a compelling underrepresentation of a tile compared with its d-mutant tiles. Actual errors in read r cannot be corrected if r occurs in a very low coverage region of the genome or there exist multiple candidate d-mutant tiles, probably because of genome repetition. On the other hand, a tile may be miscorrected if it contains a minor variant of a highly repetitive element in the genome or it traverses a low coverage region that is similar to other regions with normal coverage. Our method is not unique in being challenged by non-uniform coverage on repetitive genomes. Error correction for highly repetitive genomes is essential for successfully assembling larger eukaryotic genomes but none of the existing methods successfully addresses this problem, including Reptile. Short-read mapping provides a reasonable method to evaluate error correction methods in well-assembled, low repetition genomes. Nevertheless, it is not possible to unambiguously determine all errors. There are natural polymorphisms among bacterial lines, and some presumed polymorphisms may be unrecognized assembly errors. Furthermore, the mapping software chooses among alternative mappings by invoking parsimony, but there is some chance that the true number of errors is less than the minimum. Lastly, mapping software cannot map reads that contain more than a constant number of substitutions, typically just two, with full sensitivity, although we considered 5 here and tested as many as 15 with similar results. Despite these limitations, we believe that most errors are correctly identified, and this approach can provide a fair comparison of error correction methods. We and others (<ref type="bibr" target="#b13">Smith et al., 2008</ref>) have found that sequence quality scores provide valuable information. Our use of quality scores probably helped us account for the error patterns in nextgeneration sequencing data (<ref type="bibr" target="#b3">Dohm et al., 2008</ref>) without explicitly modeling them. However, it has been observed (<ref type="bibr" target="#b3">Dohm et al., 2008</ref>) that high quality scores may be too optimistic and low quality scores too pessimistic in estimating sequencing errors in Solexa data. Since quality scores may not be precise measures of misread probabilities, the current version of Reptile uses quality score information in a very simple manner, but can be modified to make more sophisticated use of quality scores if warranted. Finally, although quality scores are needed to run Reptile, it can be run effectively without scores by setting all quality scores and the threshold Q c to the same value. There remain several additional challenges in next-generation sequencing error correction. One challenge is to distinguish errors from polymorphisms, for example, single nucleotide polymorphisms (SNPs). Reptile could accommodate SNP prediction with modification in the tile correction stage (Algorithm 1), where ambiguities may indicate polymorphisms. Another challenge is the growing read length of upcoming high-throughput sequencers. Currently, we define tiles as concatenations of two kmers. it might prove useful to extend the tile definition to more than two kmers in order to address error correction in much longer reads.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[14:40 29/9/2010 Bioinformatics-btq468.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>[14:40 29/9/2010 Bioinformatics-btq468.tex] Page: 2529 2526–2533</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>show Reptile is 3–10 times faster and uses 8–11 times less memory than SHREC. As expected, memory usage of Reptile is associated with the length of the genome and the number of errors in the data Page: 2532 2526–2533</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Page: 2533 2526–2533 Reptile columns are as defined in Table 3. As can be observed from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Funding: This research is funded in part by the Iowa State University Plant Sciences Institute Innovative Research Grants program. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>R k = n i=1 r k i. Let α and β be two strings such that α[(|α|−l) : (|α|−1)]=β[0 : (l −1)] for some 0 ≤ l &lt; min(|α|,|β|). We define the l-concatenation of α and β, denoted α|| l β, to be the string γ of length |α|+|β|−l such that γ[0 : (|α|−1)]=α and γ[(|γ|−|β|) : (|γ|−1)]=β. The Hamming distance between two strings α 1 and α 2 for |α 1 |=|α 2 |, denoted hd(α 1 ,α 2 ), is the number of positions at which they differ. For a kmer α i ∈ R k , define its d-neighborhood N d i ={α j ∈ R k | hd(α i ,α j ) ≤ d}. Its complete d-neighborhood N d ci = {α j | hd(α i ,α j ) ≤ d} contains all kmers within Hamming distance d,</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>kmers α 2 , α 2 and α 2 are shown. All other positions in these kmers match across all three variants.</figDesc><table>Page: 2528 2526–2533 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>2 or α 2 , since both hd(α 2 ,α 2 ) = hd(α 2 ,α 2 ) = 1 and α 2 and α 2 have a similar higher frequency. However, the contexual information of α 2 available from read r 3 (in this case, α 1 ) uniquely identifies α 2 as the right correction. We seek a way to use contextual information to help resolve errors without increasing k and lowering local coverage. Contextual information is provided by noting which kmers co-exist in observed reads. For instance, α 1 || 0 α 2 exists in r 0 , r 1 or r 4 , and α 5 || .5k α 6 exists in r 5 in Figure 1. The following definitions formalize the notion of contextual information. Definition 1. t = α 1 || l α 2 (0 ≤ l &lt; k) is a tile of read r if t is a substring of r, and |α 1 |=|α 2 |=k. Definition 2. t = α || l β is a d-mutant tile of t = α|| l β if hd(α,α ) ≤ d and hd(β,β ) ≤ d. Definition 3. T r = (t 1 ,t 2 ,...,t m ) is a tiling of read r if r = t 1 || l 1 t 2 ...|| l m−1 t m such that (1) t i (1 ≤ i ≤ m) is a tile of r, and (2) l i</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>α 7 || .5k α 4 ),(α 5 || .5k α 6 )) and ((α 7 || 0 α 8 ),(α 8 || 0 α 6 )) are tilings of r 5. We also extend the concept of d-mutant tiles to tilings. For instance, we can think of ((α 1 || 0 α 2 ),(α 2 || 0 α 3 )) as a one-mutant tiling of T r 0 = ((α 1 || 0 α 2 ),(α 2 || 0 α 3 )). Similarly, ((α 1 || 0 α 2 )(α 2 || 0 α 3 )) is a two-mutant tiling of T r 0. Formally: Definition 4. A d-mutant tiling of T r = (t 1 ,t 2 ,...t m ) of read r is a sequence of tiles (t 1 ,t 2 ,...t m ) such that (1) |t i |=|t i | and |t i || l i t i+1 |=|t i || l i t i+1 |, where l i is implicitly determined by r for 1 ≤ i &lt; m, and (2) t i is a d-mutant tile of t i for 1 ≤ i ≤ m.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Hamming graph. This takes O(log|R k |) time using binary search. There are k d 4 d possible candidate mutant kmers for each α i ∈ R k , so it takes O k d 4 d |R k |log|R k | time to identify all edges.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>1 Tile t error correction. 1. if O g (t) ≥ C g then 2. t is valid; return. 3. end if 4. if t has no d-mutant tiles t then</figDesc><table>5. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>20. due to insufficient evidence.</figDesc><table>return 21. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Although analytical calculations like those adopted in existing methods can be used to choose parameters of Algorithm 1, we choose their values based on the input data to help avoid the unrealistic assumptions of uniformly distributed read errors and uniform genome coverage. Given short-read data R, we examine the empirical distribution of quality scores and choose threshold Q c such that a given percentage (e.g. 15–20%) of bases have quality score value below Q c. This value could Algorithm 2 Read error correction. 1. Initialize: t ← t 0 , where t 0 is a prefix of r; d 1 ,d 2 ← d. 2. while t =∅ do 3. Identify d-mutant tiles of t = α 1 || l α 2 as the set {t = α 1 || l α 2 | (α 1 ,α 2 ) ∈ N d 1 1 ×N d 2 2 }.</figDesc><table>[14:40 29/9/2010 Bioinformatics-btq468.tex] 

Page: 2530 2526–2533 

X.Yang et al. 

4. 

Correct t (Algorithm 1). 

5. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>[D3] as follows. If there is insufficient space to place a tile toward the end of a read r, t next will be chosen as the suffix of r. 6. [D1] t is valid: select t next such that the suffix–prefix overlap between t and t next equals α 2 ; d 1 ← 0. was corrected to t = α 1 || l α 2 and t is replaced with t in r: select t next such that the suffix–prefix overlap between t and t next equals α 2 ; d 1 ← 0. set t next to be one of the following. Let r[i 1 : i 2 ] be a maximal validated or corrected region of r that overlaps with the 5 region of t, where i 2 − i 1 +1 ≥|t|, and r[i 2 +1 : i 3 ] be a maximal uncorrected region from previous iterations due to insufficient evidence. a. If r[i 2 +1 : i 3 ]=∅, then t next ← r[i 2 −|t|+2,i 2 +1] and d 1 ← 1. b. If r[i 2 +1 : i 3 ] =∅, then t next ← r[i 3 +1,i 3 +|t|]. Similarly, if r[i 1 : i 2 ] overlaps with 3 end of t and r[i 3 : i 1 −1] is a maximal uncorrected region from previous iterations, then if r[i 3 : i 1 −1]=∅, set t next ← r[i 1 −1 :|t|+i 1 −2] and d 2 ← 1. In above cases, t next is valid only if it was not assigned with the same value in previous iterations (unless t next became the suffix of r). If such a choice does not exist, t next ←∅. 9. t ← t next. 10. end while</figDesc><table>7. 

[D2] t 8. 

[D3] Insufficient evidence to correct t: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><figDesc>Table 1. Experimental datasets</figDesc><table>Data Genome Read 
Number 
Discarded Cov. Error 
length (bp) of reads (M) reads 
rate (%) 

D1 
E.coli 
36 
20.8 
107.7 K 
160× 0.6 
D2 
E.coli 
36 
10.4 
48.3 K 
80× 0.6 
D3 
A. sp. 
36 
17.7 
456 K 
173× 1.5 
D4 
A. sp. 
36 
4.0 
0 
40× 1.5 
D5 
E.coli 
47 
7.0 
32.7 K 
71× 3.3 
D6 
E.coli 
101 
8.9 
1.44 M 
193× 2.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="true"><figDesc>Table 2. Results of mapping each dataset to the corresponding genome using RMAP</figDesc><table>Data Allowed 
Number 
Uniquely 
Ambiguously 
mismatches of reads a 
mapped reads (%) mapped reads (%) 

D1 
5 
20708709 96.5 
2.5 
D2 
5 
10359952 96.7 
2.5 
D3 
5 
17675271 79.9 
1.5 
D4 
5 
4000000 84.1 
1.6 
D5 
10 
7049153 62.5 
1.5 
D6 
10 
8874761 63.5 
1.2 
15 
68.8 
1.4 

a Number of reads containing no ambiguous bases. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="true"><figDesc>Table 3. Results of Reptile and SHREC on Illumina sequenced short reads</figDesc><table>Data 
Method (d) TP 
FN 
FP 
TN 
EBA (%) Sensitivity (%) Specificity (%) Gain (%) CPU 
Memory 
(Cov) 
Hours (GB) 

D1 
SHREC 
2819754 1183861 
667435 740 842 474 1.794 
70.4 
99.9 
53.8 
-
&gt; 8 

(160x) 
Reptile (1) 
3164394 
839221 
133558 741 376 351 0.007 
79 
99.9 
75.7 
0.79 
1.1 
Reptile (2) 
3457717 
545898 
245417 741 264 492 0.028 
86.4 
99.9 
80.2 
2.49 
1.1 

D2 
SHREC 
1303505 
422337 
251228 370 981 202 1.549 
75.5 
99.9 
61.0 
3.6 
7.1 
(79.5x) 
Reptile (1) 
1169256 
556586 
44959 371 187 471 0.009 
67.8 
99.9 
65.2 
0.35 
0.84 
Reptile (2) 
1315277 
410565 
91205 371 141 225 0.042 
76.2 
99.9 
70.9 
1.23 
0.84 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" validated="true"><figDesc>Table 4. Quality of ambiguous base correction using Reptile</figDesc><table>Data 
N 
Accuracy 
Sensitivity 
Specificity 
Gain 
EBA 
(%) 
(%) 
(%) 
(%) 
(%) 

D2 
A 
99.98 
66.4 
100 
63.7 
0.01 
C 
100 
66.4 
100 
63.8 
0.01 
G 
100 
66.4 
100 
63.7 
0.01 
T 
100 
66.3 
100 
63.7 
0.01 

D6 
A 
99.99 
85.1 
99.8 
78.5 
0.01 
C 
99.99 
85.2 
99.8 
78.4 
0.009 
G 
100 
85.3 
99.8 
78.5 
0.01 
T 
99.99 
85.3 
99.8 
78.5 
0.009 

</table></figure>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Next-generation DNA sequencing techniques</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Ansorge</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="195" to="203" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">ALLPATHS: de novo assembly of whole-genome shotgun microreads</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Butler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="810" to="820" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Fragment assembly with short reads</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chaisson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2067" to="2074" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Substantial biases in ultra-short read data sets from highthroughput DNA sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Dohm</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">105</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A new algorithm for DNA sequence assembly</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Idury</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Waterman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="291" to="306" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Parallel de novo assembly of large genomes from high-throughput short reads</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">G</forename>
				<surname>Jackson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th IEEE International Parallel &amp; Distributed Processing Symposium</title>
		<meeting><address><addrLine>Atlanta, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">The intractability of computing the Hamming distance</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Manthey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Reischuk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">337</biblScope>
			<biblScope unit="page" from="331" to="346" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Next-generation sequencing: applications beyond genomes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Marguerat</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochem. Soc. Trans</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1091" to="1096" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">The fragment assembly string graph</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient frequency-based de novo short-read clustering for error trimming in next-generation sequencing</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Qu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1309" to="1315" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">SHREC: a short-read error correction method</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schröder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2157" to="2163" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Next-generation DNA sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shendure</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Ji</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1135" to="1145" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">ABySS: a parallel assembler for short read sequence data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">T</forename>
				<surname>Simpson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1117" to="1123" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Using quality scores and longer reads improves accuracy of solexa read mapping</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Correcting errors in shotgun sequences</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">T</forename>
				<surname>Tammi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="4663" to="4672" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Velvet: algorithms for de novo short read assembly using de Bruijn graphs</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">R</forename>
				<surname>Zerbino</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Birney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="821" to="829" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>