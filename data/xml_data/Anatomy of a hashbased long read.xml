
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sequence analysis Anatomy of a hash-based long read sequence mapping algorithm for next generation DNA sequencing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Sanchit</forename>
								<surname>Misra</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<addrLine>2145 Sheridan Road</addrLine>
									<postCode>60208</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ankit</forename>
								<surname>Agrawal</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<addrLine>2145 Sheridan Road</addrLine>
									<postCode>60208</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Wei-Keng</forename>
								<surname>Liao</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<addrLine>2145 Sheridan Road</addrLine>
									<postCode>60208</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alok</forename>
								<surname>Choudhary</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<addrLine>2145 Sheridan Road</addrLine>
									<postCode>60208</postCode>
									<settlement>Evanston</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sequence analysis Anatomy of a hash-based long read sequence mapping algorithm for next generation DNA sequencing</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="189" to="195"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq648</idno>
					<note type="submission">Received on July 29, 2010; revised on October 27, 2010; accepted on November 14, 2010</note>
					<note>[13:27 16/12/2010 Bioinformatics-btq648.tex] Page: 189 189–195 Associate Editor: Joaquin Dopazo Contact: smi539@eecs.northwestern.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Recently, a number of programs have been proposed for mapping short reads to a reference genome. Many of them are heavily optimized for short-read mapping and hence are very efficient for shorter queries, but that makes them inefficient or not applicable for reads longer than 200 bp. However, many sequencers are already generating longer reads and more are expected to follow. For long read sequence mapping, there are limited options; BLAT, SSAHA2, FANGS and BWA-SW are among the popular ones. However, resequencing and personalized medicine need much faster software to map these long sequencing reads to a reference genome to identify SNPs or rare transcripts. Results: We present AGILE (AliGnIng Long rEads), a hash table based high-throughput sequence mapping algorithm for longer 454 reads that uses diagonal multiple seed-match criteria, customized q-gram filtering and a dynamic incremental search approach among other heuristics to optimize every step of the mapping process. In our experiments, we observe that AGILE is more accurate than BLAT, and comparable to BWA-SW and SSAHA2. For practical error rates (&lt; 5%) and read lengths (200−1000 bp), AGILE is significantly faster than BLAT, SSAHA2 and BWA-SW. Even for the other cases, AGILE is comparable to BWA-SW and several times faster than BLAT and SSAHA2.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent advances in next-generation sequencing (NGS) technology have led to affordable desktop-sized sequencers with low running costs and high throughput. These sequencers produce small fragments of the genome being sequenced as a result of the sequencing process. By mapping these small fragments (reads) to a reference genome, we can sequence the DNA of a new individual. The NGSs are making it possible for these studies to be conducted at a mass scale. These advances will usher an era of personal genomics when each individual can have his/her DNA sequenced and studied * To whom correspondence should be addressed. to develop more personalized ways of anticipating, diagnosing and treating diseases (<ref type="bibr" target="#b11">Patrick, 2007</ref>). Studies of this nature have already begun. Scientists have found the genetic causes of diseases like Charcot–Marie–Tooth (<ref type="bibr" target="#b7">Lupski et al., 2010</ref>) and Miller syndrome (<ref type="bibr" target="#b15">Roach et al., 2010</ref>) by sequencing the genomes of patients. These studies have been made possible by plunging costs and increasing speeds of high-throughput sequencing. Next generation sequencers (NGSs) sequence the DNA by generating small substrings of the DNA called reads. With rapid improvements in sequencing technologies, the lengths of the reads are constantly increasing.The rate of throughput as well as read lengths of these NGSs are increasing at a pace that puts even the Moore's law to shame. Hence, there is a growing need for tools that can work for longer reads and can still match the pace of the NGSs. A number of tools have been developed for shorter illumina queries. These include MAQ (<ref type="bibr" target="#b5">Li et al., 2008a</ref>), ELAND, SOAP (<ref type="bibr" target="#b6">Li et al., 2008b</ref>), BowTie (<ref type="bibr" target="#b3">Langmead et al., 2009</ref>), Mosaik, PASS (<ref type="bibr" target="#b1">Campagna et al., 2009</ref>), and SHRiMP (<ref type="bibr" target="#b17">Rumble et al., 2009</ref>). However, most of these tools work only for read lengths &lt; 200. Also, they allow very few number of mismatches (usually &lt; 2) and many of them do not allow any gaps. However, as the lengths of reads are rapidly increasing, we need tools that can work for longer read lengths. Moreover, these new tools for longer reads should be able to handle a larger number of gaps and mismatches. To the best of our knowledge, the only other tools specifically designed to work for longer reads are BWA-SW (<ref type="bibr" target="#b4">Li and Durbin, 2010</ref>) and FANGS (<ref type="bibr" target="#b8">Misra et al., 2009</ref>). BWA-SW is a package based on Burrows– Wheeler Transform (BWT). It supports gapped global alignment with respect to queries and is one of the fastest long read alignment algorithms while also finding suboptimal matches. Hash tables have been used extensively for short-read mapping and many other related problems (<ref type="bibr" target="#b0">Altschul et al., 1990;</ref><ref type="bibr" target="#b2">Kent, 2002;</ref><ref type="bibr" target="#b6">Li et al., 2008b;</ref><ref type="bibr" target="#b10">Ning et al., 2001;</ref><ref type="bibr" target="#b12">Pearson and Lipman, 1988;</ref><ref type="bibr" target="#b19">Smith et al., 2008</ref>). Hence, it may appear that we have exhausted all possible uses of hash tables for sequence mapping. However, we will find that with proper heuristics, hash tables can give excellent speedups for sequence mapping of longer reads as well. The general structure of any hash table-based sequence mapping algorithm is as follows:</p><p>(i) create a hash table index of the genome; (ii) use the index to find regions in the genome that can potentially be homologous; (iii) examine each region in more detail and output regions that are<ref type="bibr">[</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Misra et al.</head><p>indeed homologous. The execution time of existing hash table-based algorithms is dominated by stage (iii). The processing time of this stage is directly proportional to the number of regions found. FANGS is also a hash table-based tool. It uses q-gram filtering and pigeon hole principle to filter out many of the regions to rapidly map 454 reads with nearly 100% sensitivity. However, FANGS is inefficient for error rates greater than 1%. Using techniques in addition to the ones used by FANGS to quickly filter out regions that are not homologous will greatly reduce the time taken. We follow this path. In this article, we will discuss five different techniques to filter out non-homologous regions and their adaptations to the highthroughput long read sequence mapping problem. Subsequently, we present AGILE—yet another hash table-based tool for sequence mapping—in which we have used these filtering techniques to optimize every step of the sequence mapping process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">HIGH-THROUGHPUT SEQUENCE MAPPING</head><p>In the context of NGS, sequence mapping problem involves searching for a small DNA sequence (read) in the reference genome allowing a small number of differences. The reference genome is obtained from an organism of the same species as the reads, implying a high level of similarity between the read and the reference genome. The small number of differences are allowed, to account for differences between individual organisms and sequencing errors. Given a string S over a finite alphabet , we use |S| to refer to the length of S, S<ref type="bibr">[i]</ref>to denote the i-th character of S and S<ref type="bibr">[i : j]</ref>to denote the substring of S which starts at position i and ends at position j. A q-gram of S is defined as a substring of S of length q &gt; 0. A q-hit between two strings S 1 and S 2 is defined as the tuple (x,y) such that S 1 [x : x +q−1]=S 2<ref type="bibr">[y : y+q−1]</ref>. The unit cost edit distance (Levenshtein distance) (<ref type="bibr" target="#b14">Rasmussen et al., 2006</ref>) between two strings S 1 and S 2 is defined as the minimum number of substitutions, insertions and deletions required to convert S 1 to S 2. We will use E(S 1 ,S 2 ) to refer to the unit cost edit distance between S 1 and S 2. It can be calculated by using dynamic programming in O(|S 1 ||S 2 |) time (<ref type="bibr" target="#b9">Needleman and Wunsch, 1970;</ref><ref type="bibr" target="#b18">Smith and Waterman, 1981</ref>). For a string S, we will refer to the natural decimal representation of S over as D(S,,). For example, for ={A,C,G,T }, the nucleotides A,C,G,T can be mapped to the numbers 0,1,2,3, respectively. Therefore:</p><formula>D(S,{A,C,G,T }) = |S|−1 i=0 4 i f (S[i]),</formula><p>where f (A) = 0,f (C) = 1,f (G) = 2,f (T ) = 3. This brings us to the formal definition of the sequence mapping problem. We can represent every genomic sequence as a string over the alphabet ={A,C,G,T }. Given a genomic database G of subject sequences {S 1 , S 2 , ···, S l }, a query sequence (read) Q of length |Q|, the genome sequencing problem is to find the substring α of G that has the minimum value of E(α,Q) for all α. This problem can be reduced to finding the best match α for a query such that E(α,Q) is less than a certain bound. We can keep on increasing the bound till we find a match. Moreover, for a given sequencing error rate, larger reads tend to have more differences in the alignment as compared with shorter reads. Hence, having an absolute bound on the number of differences in an alignment is inappropriate as the length of the reads can vary. The bound should be a fraction of the read length. Hence, we define the-match sequence mapping problem: Given a genomic database G of subject sequences {S 1 , S 2 , ..., S l }, a query sequence (read) Q of length |Q| and an error rate find the substring α of G, such that E(α,Q) is minimum and E(α,Q) ≤ |Q|.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>Most sequence mapping algorithms divide the problem into two stages: search stage and alignment stage. The search stage finds regions in thegenome that can potentially be homologous to the read. The alignment stage verifies these regions to check if they are indeed homologous. The alignment stage is usually more computationally intensive than the search stage and the time taken is directly proportional to the number of regions found in the search stage. Hence, the best strategy to a fast sequence mapping algorithm is to filter out as many candidate regions as possible before the alignment stage. Various programs try to achieve this with the use of welldesigned filters for the specific problem ranges. In this section, we describe the AGILE algorithm that can achieve such filtering for a wide range of read lengths and error rates through a number of carefully designed filters. Some of these filters are generic and work for the entire range of read lengths and error rates, while others cater to a specific subset. However, combining these filters can achieve faster speeds over a wide range. We start by dividing the genome into non-overlapping q-grams and storing the locations of the q-grams in a q-gram index (hash table). Using the q-gram index, we find the list of q-hits between the read and the genome. Each q-hit can be extended on either side to create a candidate region. Regions with a large overlap with each other represent the same alignment and hence can be merged together. This gives us a very large number of regions. In the following subsections, we describe the filtering techniques used in AGILE that we apply to these regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Contiguous perfect matches</head><p>Two strings of length m with n differences share a common (exactly matching) substring of length at least m n+1 (<ref type="bibr" target="#b13">Pevzner and Waterman, 1995</ref>). FANGS adapted the above formula to note that—given a read Q and genome G, if a substring α of G is such that E(Q,α) ≤ |Q|, then Q and α have a perfectly matching substring of length T q-grams, where T is given by:</p><formula>T == |Q| |Q|+1 −(q−1) q</formula><p>where q is the length of the q-grams. Therefore, we only consider regions in the genome that have a common substring of length T q-grams with the read. This filtering criteria significantly reduces the search space for finding homologous regions. However, as<ref type="figure" target="#tab_1">Table 1</ref>demonstrates, the value of T quickly becomes zero beyond a certain percentage of errors. Hence this filtering scheme does not help much if we consider a larger error rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multiple perfect matches</head><p>Kent (2002) had discussed the possibility of using multiple perfect matches as a filter. Each q-hit is a perfect match. The matches need not be contiguous. Let q = 16. Consider, for example, two q-hits—one starts at position 20 in the read and position 10 020 in the genome and second starting at position 52 in the read and position 10 052 in the genome. Since there is equal gap between the q-hits in the read as well as the genome, they can easily be part of one alignment. Notice that 'genome-position'−'read-position'= 10 000 for both the reads. This value is called the diagonal. We can filter out a large number of regions by keeping a minimum cutoff on the number of q-hits with equal or slightly different diagonal.<ref type="figure" target="#tab_2">Table 2</ref><ref type="figure" target="#tab_0">90  71  81  87  94  0  2  3  5  0  0  0  1  0  0  0  0  95  215  229  237  246  9  13  16  18  2  4  5  7  0  0  1  2  97  324  338  346  355 19  24  26  29  6  9  11  13  0  1  2  3</ref>The first column lists the sequence similarity M. In each subsequent column, we report the maximum value of N for the given read length such that P N &gt; sensitivity. Let M be the sequence similarity between the read and the corresponding homologous region in the genome. Assuming that each letter is independent of the previous letter, the probability that a specific q-gram in the read matches a q-gram in a homologous region in the genome is given by:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anatomy of a hash-based long read sequence mapping algorithm</head><formula>p 1 = M q</formula><p>The match of the read in the genome will be of the same length as the read. Number of non-overlapping q-grams in the homologous region is given by:</p><formula>K ==|Q|/q</formula><p>The probability that there are exactly n matches in the homologous region is:</p><formula>P n = K n p 1 n (1−p 1 ) K−n</formula><p>and the probability that there are N or more matches is the sum:</p><formula>P N = P N +P N+1 +.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..+P K</head><p>James Kent discussed the idea of using two perfect matches as a filtering criteria as opposed to here we use a larger number of perfect matches for the same.<ref type="figure" target="#tab_2">Table 2</ref>displays the values of N that can be used for different values of sequence similarity and read lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ignore q-grams with high frequency</head><p>In both the optimizations above, we are applying theoretical constraints to the q-hits between reads and genome in order to filter out unwanted regions. However, some q-grams appear much more frequently than many others. As a result, we get a very large number of q-hits for some reads. Moreover, if a particular q-gram appears very frequently in the genome, then it will produce a lot of matches at undesired places wasting time in processing them. A less frequent q-gram is much more useful in pinpointing a match. Hence, our heuristic ignores all q-grams with frequency more than a certain cutoff frequency F to save time. To ensure that the contiguous perfect match criteria still works, we give a wildcard to all q-grams with frequency greater than F as done in FANGS. In principle, we need to reduce the values of N so that we are still able to find all the homologous regions. A theoretical model may not be accurate unless we take into account the exact probability of each q-gram, which makes the model very complex. Hence, we decided to do empirical analysis using synthetic queries for which the correct answers are already known.<ref type="figure" target="#tab_3">Table 3</ref>shows results of such experiments for read length 1000. Clearly, for a fixed value of N, higher value of F should result in more regions to process in the alignment stage and more correctly mapped regions. For example, for N = 1, even F = 4 passes 35 670 70 regions to the alignment stage. While with N = 2 and F = 17, AGILE correctly maps more reads and filters out more regions. For N = 1, if F is reduced, that will further reduce correctly mapped regions. On the other hand, if F is increased, that will increase the time taken. Comparing N = 2 case with N = 3 case, even with F = 64, N = 3 case correctly maps less number of reads but costs more time. Hence for a read length of 1000 and error rate of 10%, N = 2 works the best. With N = 2 and F = 17, AGILE correctly maps 99.8% of the queries. As compared to F = 17, F = 29 takes 130 extra seconds to increase the number ofOf total, 10 000 reads of length 1000 were synthetically generated by sampling the human genome. We introduced errors in the reads using an error rate of 10%. For a read length of 1000 and error rate of 10%, N = 2 and F = 17 work the best. The genome used is human genome.</p><p>correctly mapped reads by just 2. Hence, there is a trade-off between the time taken and the number of correctly mapped queries. In this particular case, N = 2 and F = 17 seems a relatively better choice. Using similar analysis, for a read length of 10 000 and error rate of 10%, N = 32 and F = 4 turns out to be a good choice. This filtering criteria works very well for large read lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Customized q-gram filtering</head><p>Another filter that we have applied in AGILE is keeping a minimum cutoff on the number of q-hits between the read and the region. This is called q-gram filtering. To estimate the effect of q-gram filtering, we conducted experiments with synthetic reads. For each read, we calculated the number of q-hits in each region and also whether the region is actually homologous or not. As shown in<ref type="figure" target="#fig_3">Figures 1</ref>and 2, homologous regions tend to have larger number of q-hits while non-homologous regions tend to have smaller number of qhits. Hence, with a carefully chosen cutoff on the number of q-hits, we can filter out non-homologous regions. However, some queries can have more frequently appearing q-grams than others. In that case, those queries with more frequently appearing q-grams can have many hits in each region. On the other hand, queries with less frequent q-grams can have only a few hits even in a homologous region. Hence, a generic cutoff is not appropriate. In AGILE, we dynamically choose the cutoff for each read. For each read, we find the maximum of the number of q-hits in all regions, say C. We keep the cutoff as a fraction f of C. Hence, if a region has ≥ fC q-hits, only then it is processed further. The best value of f can filter out the maximum number of non-homologous regions while keeping the number of correctly mapped reads the same. As an example,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Selecting the error rate</head><p>All the above optimizations assume that we already know , to filter out the regions. However, the percentage error of a particular read cannot be known in advance. Reads from different sources can have varying error percentages. Even reads from the same source can have variations in error. To account for this, we apply the following heuristics. For each query, we start with a small value of , say 3%. We keep increasing the value until we find a match. There are various ways in which the value can be increased. We can increase by 1% each time (e.g. 3, 4, 5, etc.), or by a larger constant interval (e.g. 3, 8, 13, 18, etc.), we can increase the value of the increment by one each time (e.g. 3, 4, 6, 9, 13, etc.), we can double the value of increment each time (e.g. 3, 4, 6, 10, 18, etc.). Through our experiments, we found that doubling the value of increment each time (exponential increment) works faster than the other strategies mentioned above. Choosing an appropriate starting value of is extremely crucial for the above step and depends on the error distribution of the reads. If the errors in the reads are distributed in a very small band on the lower side of the spectrum, choosing a higher initial value of will lead to a lot of extra time wasted in unnecessary processing. On the other hand, if the errors in the reads are distributed over a very small band on the higher side of the spectrum, choosing a smaller initial value of will mean that we will not find any match for the initial few values of. Hence, we will waste time in unnecessary and unfruitful processing. In order to 'guess' a good initial value of n to start with, we dynamically adjust the by learning from the# Regions is the number of regions passed as a result of the previous filters. # Regions processed is the number of regions with number of q-hits ≥ fC for that read. Hence, these are the number of regions processed by the alignment stage. The genome used is human genome. 10 000 reads of length 1000 were synthetically generated by sampling the human genome. We introduced errors in the reads using an error rate of 10%. Clearly, f = 0.5 works best for this case.previous queries. We take the average of the edit distance per unit length of all the previous queries as the initial value of for the next query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AGILE IMPLEMENTATION</head><p>Our implementation takes as input the genome FASTA file and a query FASTA file. The query file typically contains a batch of many queries. In the output, we report locations in the genome where the full length of the read matches along with mapping quality and score of the match. The high level workflow of AGILE is depicted in<ref type="figure" target="#fig_5">Figure 3</ref>. AGILE uses the fact that 454 sequencers have a very small error rate (<ref type="bibr" target="#b16">Rothberg and Leamon, 2008</ref>). Hence, we divide the problem of finding the best match α of a read |Q| that minimizes E(α,Q) into multiple problems, allowing different values of edit distance. Each such problem is now of the form—find a substring α of G such that E(α,Q) &lt;&lt;|Q|. We start with allowing a small value of. If we find a match, we output that match and move to the next read. If we do not find a match, we increase the value of and try again. AGILE uses a q-gram index of the genome to map queries. We process the input reads one by one. Since the read can be from any strand of the DNA, AGILE processes both the read and reverse complement of the read to search for matches. For any sequence, we start by identifying the regions in the reference genome that can potentially be homologous to the read. In the next step, we filter out many of the regions using the heuristics discussed in the previous section. Each homologous region in the filtered list is further processed by using dynamic programming by creating the edit distance matrix to check if the region actually has an edit distance ≤ |Q|.<ref type="bibr">Page: 193 189–195</ref>Since the edit distance is bounded by |Q|, we only need to calculate a diagonal band of width 2|Q|+1 of the matrix. If at any stage, all paths in the edit distance matrix have an edit distance of more than |Q|, we stop further processing and discard the region. This pruning policy greatly reduces the time taken by the algorithm as many regions are discarded after the first few rows are processed.<ref type="figure" target="#tab_5">Table 5</ref>demonstrates the speed benefit obtained by this optimization. We have run extensive experiments in order to find the most efficient parameter values for different read lengths and values. Based on these experiments, for each query we automatically set the optimal values of these parameters. Also, as explained in Section 3.5, we dynamically select the most appropriate starting values of and increment until we find a match. Automatic selection of parameter values makes it easier for users to use the program as they do not need to worry about deciding the appropriate parameter settings. In addition, having tailored values of parameter settings for different scenarios makes it possible to run real queries that can be of varied lengths and error rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anatomy of a hash-based long read sequence mapping algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Mapping quality calculation</head><p>The concept of mapping quality was coined by<ref type="bibr" target="#b5">Li et al. (2008a)</ref>to estimate the probability that the read sequence has been mapped at the correct place or not.<ref type="bibr" target="#b4">Li and Durbin (2010)</ref>approximated the mapping quality as 250(S 1 −S 2 )/S 1 , where S 1 is the score of the best alignment and S 2 is the score of the second best alignment. We adopt the same approach in our experiments for calculating the mapping quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on synthetic data</head><p>To create synthetic queries, we used WGSIM script provided in the SAMTOOLS package. The script was modified to adapt to 454 data. We created reads of a total of 10 million bp of different read lengths. For each read length, we introduced 2, 5 and 10% errors. Of total, 20% of the errors were indels. We aligned these simulated reads to the human genome hg19 using AGILE, BWA-SW, BLAT (option-fastMap), SSAHA2 (option-454), Mosaik and PASS. Since these are synthetic reads, we know their coordinates in the genome. Hence, we compared the aligned coordinates to the known coordinates to calculate the alignment error. SSAHA2, BWA-SW and AGILE report mapping quality. However, in the cases when a tool is unable to pick the best and second best alignments, the corresponding mapping quality will be incorrect. Hence, comparing mapping quality values reported by different tools may be invalid as some tools might find a larger number of second best alignments than others. To solve this problem, we calculate mapping quality for each tool using alignments reported by all the tools. For each tool, let S 1 be the score of the best alignment α found by that tool. We take S 2 as the score of the best alignment (other than α) found by any tool. We compute the mapping quality using S 1 and S 2 in the similar manner as described in Section 5.1. For our evaluation, we ran all the experiments on Intel Xeon quad core E5430 2.66 GHz processor with 2×6 MB cache and 32 GB RAM running a Linuxbased operating system. Each tool was run in single-threaded mode.<ref type="figure" target="#tab_6">Table 6</ref>shows the CPU time, percentage of confidently (mapping quality &gt; 20) aligned reads and percentage of reads incorrectly aligned for AGILE (version 0.3.0), BWA-SW (version 0.5.7), BLAT (version 34) and SSAHA2 (version 2.5.1) for different values of read length and sequencing error rates. We have reported the comparison of AGILE against Mosaik and PASS in the Supplementary Table SI. We used the default command line options for each program unless necessary otherwise. Carefully selected command line options might yield better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">AGILE vs BWA-SW It</head><p>is observed from<ref type="figure" target="#tab_6">Table 6</ref>that AGILE is more accurate than BWA-SW especially for reads with shorter lengths and more error rates. However, AGILE is also slower than BWA-SW for the same case—reads with shorter lengths and more error rates. For smaller error rates, AGILE is significantly faster than BWA-SW (upto 5 times faster). AGILE is most efficient for read lengths of about 1000. With the rate at which the 454 read lengths are increasing, 1000 bp reads will soon be the norm.<ref type="figure" target="#tab_6">Table 6</ref>, it is clear that AGILE is significantly faster (upto 30 times faster) than BLAT while still being much more accurate in most cases; most importantly, the cases with larger error rates. Even in cases where AGILE is less accurate than BLAT, it is not much worse. BLAT's lack of accuracy is also due to the '-fastMap' option. However, with default parameters BLAT is more than an order of magnitude slower than with '-fastMap' option.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">AGILE vs BLAT From</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">AGILE vs SSAHA2</head><p>AGILE is several times faster than SSAHA2 on all inputs. Also, AGILE is either comparable or more accurate than SSAHA2 for all inputs apart from the case when the read length is 100 and the error rate is 2%. SSAHA2 does not work well for 10 kb reads as it is not designed for such read lengths and thus could not be tested on them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Memory comparison</head><p>As far as memory usage is concerned, for mapping reads against human genome, BLAT and BWA-SW use about 4 GB memory. The peak memory requirement of SSAHA2 is about 5.6 GB. For AGILE, the q-gram index requires about 3.5 GB memory and the genome itself requires about 3 GB memory. Memory required by each query is insignificant with respect to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on real data</head><p>It is difficult to evaluate on real data because of the lack of ground truth. However, if two algorithms output the same alignment for a read, it is most likely correct. If two aligners X and Y output different alignments for a read, if X and Y both report low mapping quality, then the alignment is ambiguous and it does not matter which one is wrong. If X reports high mapping quality for a read and X alignment score is worse than or slightly better than Y, X mapping quality is<ref type="bibr">Page: 194 189–195</ref>We mapped 100 000 reads uniformly selected from SRR005010 (pre-filtered to remove any reads smaller than 100 bp) against the human genome hg19 with BWA-SW and AGILE, respectively. We call a read inconsistently mapped if the left most position of the alignments found by BWA-SW and AGILE differ by more than the length of the read. For each alignment, we calculated the score [number of matches—three times the number of differences (edit distance)]. We call a AGILE alignment plausible if 250 (AGILE score − BWASW score)/(AGILE score)≥ 20 (i.e. using BWA alignment as the next best alignment, AGILE mapping quality &gt; 20). Essentially, this means that the AGILE alignment is sufficiently better. Otherwise, we call an AGILE alignment questionable. We use similar definitions of plausible and questionable for BWA-SW alignments. In adddition, 'AGILE≥ 20' is defined as AGILE alignments with mapping quality ≥ 20. wrong and X is not aware of an equally probable alignment. This analysis is similar to the one reported in Li and Durbin (2010). We ran BWA-SW and AGILE on real queries obtained from the NCBI short read archive SRR005010. We filtered the read set to remove queries smaller than 100 bp long and uniformly selected 100k read with an average length of 338 bp. AGILE took 283 CPU seconds and BWA-SW took 939 CPU seconds. Both tools found 96 293 common alignments. Of total, 357 reads were not mapped by any of the tools.<ref type="figure" target="#tab_7">Table 7</ref>shows breakup of reads that are aligned by only one aligner or mapped to different places, and are assigned mapping quality ≥20 for either BWA-SW or AGILE. Overall, BWASW misses 203 + 247 = 450 alignments that AGILE maps well. AGILE misses 95 (46+49) alignments that are aligned well by BWA-SW. Note that, even though the average read length of the entire read set is 338, the inconsistencies come mostly in the case of smaller read lengths (average length 286 or smaller). This is in accordance with the results on synthetic reads as both aligners tend to make more mistakes in aligning reads of shorter lengths. BWASW tends to miss more alignments in even shorter (140–170) read length range, while AGILE misses more alignments for a bit longer (250–286) reads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.Misra et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">ANALYSIS</head><p>AGILE is similar to BLAT, SSAHA2, FANGS, Mosaik, PASS and BWA-SW in sharing the seed and extend strategy to get candidate regions. However, the major difference lies in the way heuristics are employed to reduce the number of regions to be processed. BLAT and SSAHA2 consider short (10–15 bp) exact matches as seeds. BLAT also provides functionality to use short inexact match<ref type="bibr">Page: 195 189–195</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anatomy of a hash-based long read sequence mapping algorithm</head><p>(one mismatch allowed) or two exact matches slight differing in diagonal values. For longer reads, both these techniques result in a very large number of candidate regions. AGILE filters the candidates by allowing longer seeds (upto 28 bp). It also uses a cutoff on the minimum number of contiguous exact seed matches and larger cutoff on the minimum number of exact matches with equal or slightly different diagonal values. To the best of our knowledge, no other tool uses multiple perfect match filtering criteria with a cutoff of more than two matches. This is similar to using a long gapped seed. BWASW also uses long gapped seeds for the similar reason. The main difference between BWA-SW and AGILE is the way long gapped seed is implemented. While BWA-SW uses Prefix Trie and Prefix DAWG, AGILE relies on a much simpler data structure q-gram index (hash table) and diagonal coordinates. Both BWA-SW and AGILE further use different heuristics in order to reduce the search space. The heuristics used by AGILE are similar to the ones used in string matching or sequence mapping algorithms. For each heuristic, AGILE adapts it to the problem of long read mapping. Customized q-gram filtering is an example. Q-gram filtering is a well-known technique for filtering out unwanted regions. However to the best of our knowledge, no algorithm has used q-gram filtering with the cutoff customized for each read. Another major contribution of AGILE is the gradual increase of the allowed error rate till we find a match. Most tools use the allowed error rate to decide thresholds for pruning the search space. However, many reads have a small number of errors. Since these tools use a fixed value of the allowed error rate, they end up using a larger value of the allowed error rate for all reads in order to also map the reads with larger errors, resulting in a loss of efficiency. Hence, gradually increasing the allowed error rate in mapping can have tremendous effects on the efficiency of these tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Advances in sequencing techniques necessitate the development of high performance, scalable algorithms to extract biologically relevant information from these datasets. Research on developing sequence mapping algorithms has been largely focused on mapping short reads, and little work has been done for longer 454 reads. AGILE is a hash-based sequence mapping algorithm that rapidly maps long reads using efficient heuristics to optimize different steps of the mapping process. AGILE can handle very large genome sizes and read lengths. It is flexible in that it allows a large number of mismatches and insertions/deletions in mapping and provides command line parameters to control every step of the mapping process. The best sensitivity and specificity of AGILE is achieved when the reads are longer and the error rate is small. Considering that with the improvement in sequencing technology, the read lengths will increase further and the error rates will decrease, AGILE should be even more useful in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>For example, the lengths of 454 reads increased from about 250 bp in 2007 to about 500 bp in 2009. The length of illumina reads increased from about 30–50 bp in 2007 to about 100 bp in 2009. Pacific Biosciences also announced 1000 bp long reads in 2009.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>[13:27 16/12/2010 Bioinformatics-btq648.tex] Page: 191 189–195</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>.</head><figDesc>The highest value of minimum number of perfect matches to get a particular sensitivity for different values of read lengths and sequence similarity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.1.</head><figDesc>Fig. 1. Histogram of the number of regions that are homologous and number of q-hits they share with the reads. This demonstrates that the homologous regions have larger number of q-hits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.2.</head><figDesc>Fig. 2. Histogram of the number of regions that are not homologous and number of q-hits they share with the reads. This demonstrates that the nonhomologous regions have smaller number of q-hits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.3.</head><figDesc>Fig. 3. AGILE workflow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>Funding: This work was supported in part by National Science Foundation award numbers: CCF-0621443, SDCI OCI-0724599, CNS-0551639, IIS-0536994, and HECURA-0938000. This work was also partially supported by Department of Energy grants DE-FC02-07ER25808 and DE-FG02-08ER25848. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. The value of threshold T for different values of error rate and read length (q = 16)</figDesc><table>Error rate (%) 
Read length 

100 
200 
500 
1000 
10 000 

1 
2 
3 
4 
4 
5 
2 
1 
1 
1 
2 
2 
3 
0 
0 
1 
1 
1 
5 
0 
0 
0 
0 
0 
1 0 
0 
0 
0 
0 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 3. Experiments to find the most appropriate values of F and N so as to maximize the number of reads correctly mapped and minimize the number of regions sent to the alignment stage (hence minimize the time taken) F N Correctly mapped Number of regions Time taken (CPU in s)</figDesc><table>4 1 9978 
35 670 70 
1790.73 
16 2 9979 
140 453 
166.39 
17 2 9980 
150 242 
176.28 
18 2 9980 
159 895 
185.91 
19 2 9980 
170 223 
196.15 
20 2 9981 
180 430 
206.27 
28 2 9981 
266 621 
294.38 
29 2 9982 
279 457 
307.4 
32 3 9969 
102 282 
171.42 
64 3 9974 
239 962 
391.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 4 demonstrates the effect of</figDesc><table>Page: 192 189–195 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 4.</figDesc><table>Effect of the value of f 

f 
# Regions # Regions processed # Correctly mapped Time taken (s) 

0 180 430 
180 430 
9981 
206.27 
0.1 180 430 
160 168 
9981 
193.26 
0.2 180 430 
110 497 
9981 
152.44 
0.3 180 430 
90 342 
9981 
133.81 
0.4 180 430 
79 593 
9981 
122.13 
0.5 180 430 
69 008 
9981 
111.45 
0.6 180 430 
52 900 
9979 
96.16 
0.7 180 430 
32 728 
9975 
77.46 
0.8 180 430 
29 490 
9967 
73.92 
0.9 180 430 
28 089 
9957 
72.21 
1 180 430 
27 647 
9938 
71.46 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 5. Effect of pruning</figDesc><table>Query 
length 

% similarity 
Without pruning 
With pruning 

Time 
Correctly 
Time 
Correctly 
taken 
mapped 
taken 
mapped 

1000 
98 
137.01 
9975 
77.89 
9975 
1000 
95 
160.64 
9982 
92.84 
9982 
1000 
90 
164.52 
9981 
111.45 
9981 
10 000 
98 
175.42 
1000 
144.58 
1000 
10 000 
95 
205.77 
999 
188.1 
999 
10 000 
90 
285.47 
1000 
270.57 
1000 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 6. Results on synthetic reads</figDesc><table>Read length (bp) Program 
AGILE 
BWA-SW 
BLAT 
SSAHA2 

Error rate CPU (s) Q20% errAln% CPU (s) Q20% 
errAln% CPU (s) Q20% errAln% CPU (s) Q20% 
errAln% 

100 
2 
112.75 93.39 
5.05 
161 
93.66 
4.74 
430.54 89.41 16.37 
2014.92 93.94 
2.05 
5 
191.94 91.62 
2.94 
135 
90.63 
12.8 
327.2 78.75 51.71 
2857.75 93.9 
4 .42 
10 
350.93 79.54 
8.98 
104 
77.2 
3 8 .03 
261.96 62.56 86.47 
3567.85 92.22 
8.45 

200 
2 
77.27 95.54 
0.72 
223 
95.68 
4.43 
565.83 95.52 
2.57 
1064.29 95.43 
3.57 
5 
142.06 95.36 
1.01 
189 
95.41 
8.39 
392.38 92.99 19.64 
1049.98 95.51 
7.02 
10 
395.06 92.83 
2.42 
145 
91.39 
17.7 
278.78 78.95 68.39 
1613.21 95.54 
10.14 

500 
2 
56.97 97.2 
0.22 
277 
97.2 
0 .53 
900.65 97.19 
0.01 
1256.23 96.78 
0.47 
5 
111.39 
97.33 
0.37 
205 
97.34 
0.69 
583.64 97.19 
0.83 
1078.03 96.67 
0.74 
10 
277.72 96.73 
0.61 
160 
96.59 
1.4 
326.71 93.87 32.76 
844.04 96.06 
0.95 

1000 
2 
69.34 97.38 
0.26 
243 
97.38 
0.4 
1107.92 97.37 
0.01 
1585.27 97.04 
0.34 
5 
7 8 .38 98.02 
0.23 
201 
98.02 
0.35 
808.55 97.96 
0.07 
1359.22 97.02 
1.02 
10 
86.52 97.56 
0.19 
135 
97.52 
0.5 
392.9 96.09 
9.93 
1077.6 95.77 
1.89 

10 000 
2 
122.57 98.2 
0.1 
160 
98.2 
0 .1 
3016.57 98.2 
0 
– 
– 
– 
5 
139.58 99 
0.1 
136 
99 
0.1 
1654.69 99 
0 
– 
– 
– 
10 
197.78 98.2 
0.1 
125 
98.2 
0 
757.92 98.2 
0 
– 
– 
– 

We created reads of a total of 10 million bp of different read lengths. Q20%, percentage of reads with mapping quality &gt;20; errAln%, percentage of reads incorrectly aligned. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><figDesc>Table 7.</figDesc><table>Breakup of alignments that are mapped inconsistently between BWA-SW and AGILE 

Condition 
Count 
Average read 
BWA-SW 
AGILE 

Average mapping length 
Average 
Average mapping 
Average 
quality 
difference 
quality 
difference (%) 

BWA-SW≥ 20; AGILE unmapped 
46 
285.89 
122.61 
11.21 
– 
– 
BWA-SW≥ 20 plausible; AGILE&lt; 20 
49 
250.31 
60.53 
5.65 
3.16 
12.1 
BWA-SW≥ 20 questionable 
6 
268.33 
25.5 
5 .45 
125 
6.32 

AGILE≥ 20; BWA-SW unmapped 
203 
140.34 
– 
– 
250 
9.46 
AGILE≥ 20 plausible; BWA-SW&lt; 20 
247 
175.3 
1 .93 
11.8 
249.07 
8.23 
AGILE≥ 20 questionable 
413 
273.69 
0.61 
3.95 
250 
3.45 

</table></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Basic local alignment search tool</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="page" from="403" to="410" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Pass: a program to align short sequences</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Campagna</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="967" to="968" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Blat–the blast-like alignment tool</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Kent</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="656" to="664" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Ultrafast and memory-efficient alignment of short dna sequences to the human genome</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Langmead</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast and accurate long read alignment with burrows-wheeler transform</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="589" to="595" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Mapping short dna sequencing reads and calling variants using mapping quality scores</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1851" to="1858" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Soap: short oligonucleotide alignment program</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="713" to="714" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Whole-genome sequencing in a patient with charcot-marietooth neuropathy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Lupski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">N. Engl. J. Med</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page" from="1181" to="1191" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Fangs: high speed sequence mapping for next generation sequencers</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Misra</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Symposium of Applied Computing</title>
		<meeting>ACM Symposium of Applied Computing<address><addrLine>Sierre, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A general method applicable to the search for similarities in the amino acid sequence of two proteins</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">B</forename>
				<surname>Needleman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Wunsch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="443" to="453" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Ssaha: a fast search method for large dna databases</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Ning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1725" to="1729" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">454 life sciences: illuminating the future of genome sequencing and personalized medicine</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">L</forename>
				<surname>Patrick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Yale J. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="191" to="194" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved tools for biological sequence comparison</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">R</forename>
				<surname>Pearson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Lipman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="2444" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Multiple filtration and approximate pattern matching</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Pevzner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Waterman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Algorithmica</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="135" to="154" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient q-gram filters for finding all epsilon-matches over a given length</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">R</forename>
				<surname>Rasmussen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="296" to="308" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Analysis of genetic inheritance in a family quartet by wholegenome sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Roach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="page" from="636" to="639" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The development and impact of 454 sequencing</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Rothberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Leamon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1117" to="1124" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Shrimp: accurate mapping of short color-space reads</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">M</forename>
				<surname>Rumble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000386</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Identification of common molecular subsequences</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">F</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Waterman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="195" to="197" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Using quality scores and longer reads improves accuracy of solexa read mapping</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">D</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">128</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>