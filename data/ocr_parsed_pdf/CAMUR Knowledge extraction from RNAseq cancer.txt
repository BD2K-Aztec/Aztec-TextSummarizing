Bioinformatics, 32(5), 2016, 697—704

doi: 10.1093/bioinformatics/btv635

Advance Access Publication Date: 30 October 2015
Original Paper

 

Gene expression

CAMUR: Knowledge extraction from RNA-seq
cancer data through equivalent
classification rules

Valerio Cestarelli”, Giulia FisconI'Z'T, Giovanni Felici1, Paola Bertolazzi1
and Emanuel Weitschek1'3'*

1Institute of Systems Analysis and Computer Science — National Research Council, 00185, Rome, Italy,
2Department of Computer, Control, and Management Engineering — Sapienza University, 00185, Rome, Italy and
3Department of Engineering — Uninettuno International University, Corso Vittorio Emanuele 11,39 — 00186 Rome, Italy

*To whom correspondence should be addressed.
TThe authors wish it to be known that, in their opinion, these authors should be regarded as Joint First Authors.
Associate Editor: Ziv Bar-Joseph

Received on June 10, 2015; revised on October 8, 2015; accepted on October 24, 2015

Abstract

Motivation: Nowadays, knowledge extraction methods from Next Generation Sequencing data are
highly requested. In this work, we focus on RNA—seq gene expression analysis and specifically on
case—control studies with rule—based supervised classification algorithms that build a model able to
discriminate cases from controls. State of the art algorithms compute a single classification model
that contains few features (genes). On the contrary, our goal is to elicit a higher amount of know—
ledge by computing many classification models, and therefore to identify most ofthe genes related
to the predicted class.

Results: We propose CAMUR, a new method that extracts multiple and equivalent classification
models. CAMUR iteratively computes a rule—based classification model, calculates the power set of
the genes present in the rules, iteratively eliminates those combinations from the data set, and per—
forms again the classification procedure until a stopping criterion is verified. CAMUR includes an
ad—hoc knowledge repository (database) and a querying tool.

We analyze three different types of RNA—seq data sets (Breast, Head and Neck, and Stomach
Cancer) from The Cancer Genome Atlas (TCGA) and we validate CAMUR and its models also on non—
TCGA data. Our experimental results show the efficacy of CAMUR: we obtain several reliable equiva—
lent classification models, from which the most frequent genes, their relationships, and the relation
with a particular cancer are deduced.

Availability and implementation: dmb.iasi.cnr.it/camur.php

Contact: emanuel@iasi.cnr.it

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

 

Among next generation sequencing experiments, RNA-seq gene
expression profiling stands out as the process of quantifying the
transcriptome abundance by counting the RNA fragments (reads)
that are aligned on a reference genome (Wang et (11., 2009).

(C7 The Author 2015. Published by Oxford University Press.

In this work, we propose a new method for classifying RNA-seq
case—control samples, which is able to compute multiple human
readable classification models. We call this method and its software
implementation CAMUR — Classifier with Alternative and MUltiple
Rule-based models. Although RNA-seq data analysis tools (Howe

697

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/Iicenses/by-nc/4.0/),
which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact

journals.permissions@oup.com

/310‘srcumo[p10}xo‘sopcuHOJHtotq/ﬁdnq

698

V. Cestarelli et al.

 

et al., 2011; Kuehn et al., 2008) are widely used in case—control
studies, the novelty of CAMUR consists in the extraction of several al—
ternative and equivalent rule—based models, which represent relevant
sets of genes related to the case and control samples. CAMUR extracts
multiple classification models by adopting a feature elimination
technique and by iterating the classification procedure.

CAMUR is based on the supervised learning approach (also called
classiﬁcation (Mehta et al., 1996)), the task of inferring a function
from labeled training data (Tan et al., 2005b). Two data sets are
required: (i) the training set, which consists of a group of training
labeled samples, and hence each sample is a pair consisting of an in—
put object — that can be a vector of features (attributes) — and its
associated class label; (ii) the test set, which is used to classify new
samples, after the inferred function is built; the test data may con—
sists of a set of samples, whose class is known, but hidden and used
only for verification purpose. Starting from the training set, a
supervised machine learning algorithm builds the classification
model based on the general hypotheses inferred from the features.
Then, through this model, the classifier is able either to evaluate the
model reliability on the test set, or to make predictions on new
data. In other words, we can describe the classiﬁcation problem as
the process through which a system learns a mapping function (also
called model) that assigns a sample to a class (Tan et al., 2005b). A
classifier is the output of a supervised machine learning algorithm.
There are many different state of the art classification algorithms:
decision trees (Quinlan, 1993), rule—based (Boros et al., 2005;
Cohen, 1995; Felici and Truemper, 2002; Frank and Witten, 1998;
Gaines and Compton, 1995), ensembles (Bagging, Boosting,
Random forest) (Dietterich, 2000), k—Nearest Neighbour
(Dasarathy, 1990), linear regression (Seber and Lee, 2012), Naive
Bayes (McCaIIum et al., 1998), neural networks (Haykin et al.,
2009), Perceptrons (Riedmiller, 1994), Support Vector Machines
(SVM) (Vapnik, 1998) and Relevance Vector Machine (RVM)
(Tipping, 2001). For further details about the supervised learning
paradigm and the algorithms the reader may refer to (Weitschek et
al., 2014). Classification algorithms are frequently used in gene ex—
pression profiles analysis (Golub et al., 1999; Li et al., 2004;
Nogueira et al., 2003; Park et al., 2014; Pirooznia et al., 2008;
Shaik and Ramakrishna, 2014; Shipp et al., 2002; Tan and Gilbert,
2003; Tothill et al., 2015), in particular for experimental samples
classification, i.e. the automatic assignment of each sample to its
belonging class (e.g. case—control) after examining its profile. Rule—
based classification algorithms are widespread for analyzing gene
expression profiles (Dennis and Muthukrishnan, 2014; Geman et
al., 2004; Hvidsten et al., 2003; Tan et al., 2005a; Weitschek et al.,
2015; Zhou et al., 2003). These types of algorithms produce a
classification model composed of logic formulas that provide an im—
mediate relationship between the class and one or more fea—
tures (genes). The assignment of a given class to each sample is
performed by taking into account the satisfiability of the rules. In
particular, the classifier uses logic propositional formulas in dis—
junctive (or conjunctive) normal form (‘if then rules”) for classifying
the given records. Each classification rule (r) can be represented as:
r,: Antecedent—> Consequent (e.g. feature1 > 0.7 /\ feature; < 0.4
V feature3 > 0.9 :> control). The antecedent contains a conjunction
of attribute tests, each one known as literal (e.g. feature1 > 0.7),
the consequent represents the covered class (e.g. control). Examples
of rule—based classifiers are RIPPER (Cohen, 1995), LSQUARE
(Felici and Truemper, 2002), LAD (Boros et al., 2005), RIDOR
(Gaines and Compton, 1995) and PART (Frank and Witten, 1998).

We chose to analyze RNA—seq data with rule—based algorithms,
because of their human readability, i.e. the investigator is provided

with a list of meaningful features (genes) that appear in the rules.
Specifically, among the state of the art classifiers we implement our
method relying on the Repeated Incremental Pruning to Produce
Error Reduction — RIPPER algorithm, because it is a robust and ef—
fective rule—based approach that provides reliable case—control mod—
els in terms of classification rates and computational performances
(Lehr et al., 2011). In RNA—seq, rule—based algorithms may provide
a low number of features (genes) into the resulting rules. For ex—
ample, in a binary classification problem the classifier can build a
model made of only two rules, with two or three features (e.g.
gene1 > 0.7 Agenez < 0.4 V geneg > 0.9 :> control). Although this
fact does not affect the classification performances, many other fea—
tures that have discriminant power may not be present in the classi—
fication model. Therefore, our aim is to extract a comprehensive
amount of knowledge from the analyzed data composed of equiva—
lent and alternative classification models (i.e. rules). For example, to
maximize the knowledge extraction in RNA—seq samples classifica—
tion, we aim to detect all the genes that are implied with the ana—
lyzed disease, i.e. the discriminant genes that appear in alternative
classification models. For extracting multiple classification solu—
tions, one approach is presented in (Deb and Reddy, 2003), where
the authors found 352 different three—gene combinations providing
a 100% correct classification to the Leukemia gene expression pro—
file data available at (Golub et al., 1999), by extending a genetic al—
gorithm (Deb et al., 2002) into a multi—objectives evolutionary one
that finds multiple and multimodal solutions in one single run
(Miettinen, 1999). Those are defined as solutions that have identical
objective values, but they differ in their format. Furthermore, an—
other classification approach is presented in (Gholami et al., 2012)
and relies on a feature elimination method, which consists of choos—
ing features and then, removing those that do not match an assump—
tion criteria. The deletion is performed in order to obtain a smaller
set of features that can perform as well as the larger one, and hence
the computational overhead is reduced. However, the authors aim is
not to extract alternative and equivalent classification models.
Conversely, we aim to obtain more than one reliable classification
model by performing an iterative feature elimination without imple—
menting an optimization method.

2 Materials and methods

First, the terminology adopted in the paper is introduced. We collect
n samples, each one described by its m features (gene expression pro—
files) and labeled with a class (condition), e.g. normal — tumoral (We
adopt The Cancer Genome Atlas terminology (i.e. normal — tumoral),
where normal corresponds to a healthy sample (control) and tumoral
to a diseased one (case).). The ith sample of the data set is represented

Table 1. Example of the breast cancer RNA-seq data matrix ex-
tracted from The Cancer Genome Atlas (TCGA)

 

 

SampleID AN08 C10rf27 TRPM6 ‘ r ‘ Class

A8-A09D 2.64 5.42 0.38 r r ‘ Breast cancer
BH-AODH 1.46 6.47 0.76 x x ‘ Normal
GM-AZDC 2.22 22.50 0.53 Breast cancer
GM-A2D9 3.13 14.21 0.61 Breast cancer
GM-AZDB 3.86 5.15 0.59 Breast cancer

 

The rows correspond to the samples and the columns to their features (gene
expression proﬁles). The cells contain the gene expression measure Reads Per
Kilobase per Million mapped reads (RPKM) explained in Section 2.3.

/310‘s112umo[p10}xo‘sopcuHOJIItotq/ﬁdnq

CAMUR

699

 

by the vector g, : (g,1,g,2, . . . ,g,,,,,g,~,), where g,,- E R, i: 1,. . . ,n,
j : 1,. . . ,m and g,, 6 {normal, tumoral}. Therefore, the vectors g1,
g2, - - - , gn compose the data matrix, whose rows correspond to the
samples and whose columns to their features. The reader may refer
to Table 1 for an example.

2.1 CAMUR: classifier with alternative and multiple rule—
based models

In this section, we describe CAMUR, a method and a software de—
signed to find alternative and equivalent solutions for a classification
problem. CAMUR is based on:

a rule—based classiﬁer (i.e. in this work RIPPER);

an iterative feature elimination technique;

a repeated classiﬁcation procedure;

an ad-laoc storage structure for the classiﬁcation rules (CAMUR
database).

+P’Pi‘

In brief, the method iteratively computes a rule—based classification
model through the supervised RIPPER algorithm, calculates the
power set (or a partial combination) of the features present in the
rules, iteratively eliminates those combinations from the data set,
and performs again the classification procedure until a stopping cri—
terion is verified.

In greater details, CAMUR executes at first the RIPPER algorithm,
which extracts from a training set the classification model that con—
tains rules with a number of features (i.e. genes) and their values (i.e.
quantification levels). Accuracy and F — measure (see Eq. 1) are used
on a test set to evaluate the extracted classification model. Then,
CAMUR stores the classification model and the results into a database
and extracts the features from the generated model. We call this set
of features S, (where t is the current iteration) and we define the list
where those features are memorized as FL. After that, CAMUR com—
putes the power set of the features P, by storing all the combinations
into the main memory. In the following, we refer to the Original
Data Set of features as ODS. Starting from P,, the software performs
a feature elimination by deleting from ODS one combination of fea—
tures at time (i.e. an item of the power set) and executes the RIPPER
classification algorithm on the new data set (ODS — 17),) with 17,,
E P, (17,, is the ith element of P, and i : 1, . . . , (PA). All the results of
the elimination and classification steps are memorized in the CAMUR
database. These operations are iterated on the new generated data
sets (ODS — 17),) with 17,, 9E pk, where k <t and l: 1,. . . , (Pk),
updating FL at each iteration. We highlight that the power set (P,+1)
generation on the new feature sets S,“ is performed by not taking
into account duplicate combinations that occurred in previous
power sets P2 with k E [1, t + 1). CAMUR terminates the execution
when one of the following conditions is satisfied:

1. the reliability of the classiﬁcation models is below a given thresh—
old, e.g. F — measure (see Eq. 1) lower than 0.85;

2. the list of features FL has been completely processed;

3. the maximum number of iterations has been reached.

At the end of this procedure, we have a collection of alternative clas—
sification models composed of several features that are able to dis—
tinguish the samples with high reliability. For evaluating the
classification models and consequently to terminate the procedure,
we adopt the accuracy and the F — measure (refer to Eq. 1). Given
True Positives (TP), objects of that class recognized in the same
class; False Positives (FP), objects not belonging to that class recog—
nized in that class; True Negatives (TN), objects not belonging to
that class and not recognized in that class; False Negatives (FN),

objects belonging to that class and not recognized in that class, the
measures are defined as follows:
F — measure :  ' Accuracy : —TP + TN (1)
P+R’ TP+TN+FP+FN
where P :  is the Precision and R :  is the Recall.

In the following, we provide an execution example of the algo—
rithm. Given a data set composed of 10 features (genes) and 10 sam—
ples — 5 tumoral and 5 normal —, CAMUR extracts through the first
execution of RIPPER a classification model composed of a set of
rules (e.g. gene1 > 0.7/\gene2 < 0.4 V gene3 > 0.9 :> normal).
The rules contain a set of three features S1 : {gene1, gene2, geneg}
which is stored in the features list FL. Starting from S1 the
power set (except the empty set) P1 is computed: P1 : {{gene1},
{gene2}, {geneg}, {gene1,gene2}, {gene1,gene3}, {gene2,gene3},
{gene1,gene2, gene3}}. The first item of the power set is elimi—
nated from the data set and the classification procedure is per—
formed, which provides a new set of features, e.g.
S2 : {gene3, gene4}. The first power set P1 is completely pro—
cessed, generating a number of feature sets S, which are stored in
FL. After the processing of P1, the power set P2 from S2 is com—
puted and the classification is performed. The algorithm con—
tinues until one of the stopping criteria is verified. To speed up
the procedure, it is worth noting that the next power set is com—
puted and processed only when the current power set has been
completely examined.

The computational time depends on: (i) the size of the power sets,
which are related to the size of the feature sets S, — if the cardinality of
the feature set is equal to m (m : (Sil), then the power set generation
requires in the worst—case 0(2’“); (ii) the worst—case complexity of
RIPPER, i.e. O(nlog2n) with n number of samples in the training set.
Therefore, the total complexity of CAMUR is O(2mnlog2n). We high—
light that usually the number of features present in rule—based classifi—
cation models is limited, especially when dealing with two—class
classification problems, as case—control studies.

Additionally, we investigate the possibility to iterate the feature
elimination in different ways, and hence our algorithm can be exe—
cuted as follows: loose mode, strict mode, double mode.

In the loose feature elimination mode, the algorithm performs
a combined iterative feature elimination. As above—mentioned, this
execution mode takes the model and the results from the first
classification and builds the power set of the found features, whose
combinations are iteratively eliminated from the data set. A classifi—
cation step follows each elimination of the feature combinations.
The new extracted features that are present in the current model are
added to the features list FL and are going to be processed in the
next iterations.

In the strict feature elimination mode, the algorithm performs
a single iterative feature elimination. First, a classification with the
RIPPER algorithm is performed, the features that appear into the
rules are extracted, and then eliminated one by one. The classifica—
tion is iterated after each elimination on the resulting data set. In
contrast to the loose mode, once a feature is eliminated, it is never
inserted again into the data set. Referring to the example given
above, in the strict mode the execution is straightforward.
Starting from the above—mentioned feature set S1, CAMUR proceeds
with the elimination of gene, from the original data set ODS and
performs the classification on the new data set, obtaining
S2 : {gene3, gene4}. Then, it eliminates gene2 from ODS — {gene1}
and performs the classification again, obtaining S3. It finishes to pro—
cess S1, and then all the other ones contained in FL if a proper stop—
ping criteria is satisfied.

[BJO'SWHIHOIPJOJXO'SOplZIIJJOJLItOIQ/[idnq

Figure I

 

supplementar) d ata 51

Figure 2

/310'SIBan0IpJOJx0"soiwuiJOJuioiqﬂ:duq

2013

 

W’einstein (7/ al.,

Table 2

bdoi‘tazmi (7/ al.,
2008

Li and Dewe),
201 l

\Xhlz (7/ al., 2015

/310'SIBan0IpJOJx0"soiwuiJOJuioiqﬂ:duq

al., 2005b

supplementary data 52

Ta bl

C.)

Tan el

2015

 

Table 4

Table 6

Figure 3

Table 5

Uhlen el al.,

Storey and Tibshirani, 2003

1? [:36 | 1315 |
\

/810'sleumofp103xo"soiJBuiJOJuioiq//:duq

CAMUR

703

 

and that provides a list of statistically significant genes related to
case—control samples, by applying Benjamini—Hochberg correction
(Benjamini and Hochberg, 1995 ) to estimate a False Discovery Rate
(FDR)—adjusted p—value. We extracted a list of 1851, 787, 1296
genes with a P—value $0.001 for BRCA, HNSC and STAD, respect—
ively. The above—mentioned lists were compared with those ex—
tracted by CAMUR. We found 36 for BRCA, 11 for HNSC, 99 for
STAD genes that are shared in both lists (panel b of Fig. 3). The lists
of shared genes are available as supplementary data 53. It is worth
noting that the size of the lists extracted by CAMUR is smaller, and
hence our approach allows to focus on few core genes related to the
investigated disease. Additionally, most of those genes are not se—
lected by the differential expression analysis enhancing the novelty
of our approach.

Additionally, we ran several tests to validate CAMUR, its classifi—
cation models, and its performances. The detailed results are avail—
able as supplementary data 54. First, we randomly selected ten
BRCA rules extracted by CAMUR and verified them on two external
breast cancer RNA—seq data sets of GEO (GSE56022 and
GSM1308330). Most of the rules succeed in the identification of
the diseased samples confirming the validity of our method: 9 out
of 10 correctly cover the GSM1308330 samples, 7 out of 10 the
GSE56022 ones (but we remark that 2 of the not successful rules
cannot be applied because a gene is not present in the data set).
Second, we tested CAMUR on a non—TCGA data set: the Wilms
Tumor (WT) (Walz et al., 2015) of the (TARGET) project. It con—
sists of 94 tissues (82 tumoral, 12 normal) and 58450 mRNA gene
expression values normalized with the RPKM method. CAMUR per—
formed 320 runs (212 loose and 108 in strictmode) finding
231 different genes with an average F—measure of 0.98. Third, we
validated CAMUR on RNA—seq data of BRCA normalized with the
RSEM method. CAMUR executed 2048 classification experiments
(1895 loose and 153 in strict mode) and extracted 986 differ—
ent genes with an average F-measure of 0.99. Finally, we per—
formed a comparative analysis of CAMUR with respect to the SVM
classifier by computing the same number of classification runs:
both methods reached high reliable results (average F-measure of
0.97 for SVM, 0.99 for CAMUR) on all data sets. We remark that
SVM outputs just a single classification model that cannot be easily
interpreted by human experts.

4 Conclusion

In this work, we presented CAMUR, a new method for multiple solu—
tions extraction in rule—based classification problems. We showed
that the amount of knowledge extracted by our algorithm is higher
than a standard supervised classification. We described the two
parts of CAMUR software package: MSE that performs the classifi—
cation procedure and MSA that analyzes the obtained results.
Additionally, we designed and developed a database for an effect—
ive and comprehensive knowledge extraction. We proved the effi—
cacy of our algorithm on large sets of RNA—seq data, focusing on
Breast, Head and Neck and Stomach Cancer from TCGA, and vali—
dating it on external data sets from TARGET and GEO. To con—
clude, CAMUR results as a reliable technique for solving
classification problems by extracting many alternative and equally
accurate solutions.

In future, we intend to test our method on other RNA—seq data
sets in order to build a large knowledge repository of classification
models related to a particular disease. The extracted genes may then
be analyzed by domain experts with functional and enrichment ana—
lyses (D’Andrea et al., 2013). It would be also interesting to perform

a simulation study for evaluating the performance of CAMUR under
different scenarios in a quantitative manner. Additionally, we plan
to integrate in our software other rule—based classifiers, as well as to
enrich the software with new functions and higher performances.
Finally, we plan to extend the analysis to other biological data sets
as sequences classification, e.g. DNA—Barcoding.

Acknowledgements

We wish to thank Prof. Riccardo Torlone and Paolo Atzeni for supporting this
work during the master of science in computer engineering and during the big
data course. The authors’ contributions can be found in supplementary data.

Funding

This work was supported by the Italian PRIN ‘GenData 2020’
[2010RTFWBH], the FLAGSHIP ‘InterOmics’ [PB.P05] project, and The
Epigenomics Flagship Project ‘EPIGEN’ [PB.PO1].

Conﬂict of Interest: none declared.

References

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: a
practical and powerful approach to multiple testing. ]. R. Stat. Soc. Ser. B
(Methodological), 57, 289—300.

Boros,E. et al. (2005) Logical Analysis of Data. In: Wang,]. (ed), Encyclopedia
of Data Warehousing and Mining, Hershey, PA, USA: Idea Group
Reference, pp. 689—692.

Cohen,W.W. (1995) Fast effective rule induction. In Proceedings of the
Twelfth International Conference on Machine Learning, pp. 115—123.

D’Andrea,D. et al. (2013) Fidea: a server for the functional interpretation of
differential expression analysis. Nucleic Acids Res., 41, W84—W88.

Dasarathy,B.V. (1990) Nearest Neighbor (NN) Norms: NN Pattern
Classiﬁcation Techniques. IEEE Computer Society Press, 2001 L Street
N.W., Suite 700 Washington, USA.

Deb,K. and Reddy,A.R. (2003) Reliable classiﬁcation of two-class cancer data
using evolutionary algorithms. BioSystems, 72, 111—129.

Deb,K. et al. (2002) A fast and elitist multiobjective genetic algorithm: nga-
ii. IEEE Trans. Evol. Comput., 6, 182—197.

Dennis,B. and Muthukrishnan,S. (2014) Agfs: adaptive genetic fuzzy system
for medical data classiﬁcation. Appl. Soft Comput., 25, 242—252.

Dietterich,T.G. (2000) Ensemble methods in machine learning. In: Multiple
classiﬁer systems. Springer New York, USA, pp. 1—15.

Felici,G. and Truemper,K. (2002) A minsat approach for learning in logic do-
mains. INFORMS]. Comput., 13, 1—17.

Frank,E. and Witten,I.H. (1998) Generating accurate rule sets without global
optimization. In Proceedings of the 15th International Conference on
Machine Learning. Morgan Kaufmann.

Gaines,B.R. and Compton,P. (1995) Induction of ripple-down rules applied to
modeling large databases. ]. Intell. Inf. Syst., 5, 211—228.

Geman,D. et al. (2004) Classifying gene expression proﬁles from pairwise
mrna comparisons. Stat. Appl. Genet. Mol. Biol., 3, 1—19.

Gholami,B. et al. (2012) Recursive feature elimination for brain tumor classiﬁ-
cation using desorption electrospray ionization mass spectrometry imaging.
In Engineering in Medicine and Biology Society (EMBC), 2012 Annual
International Conference ofthe IEEE, pp. 5258—5261.

Golub,T.R. et al. (1999) Molecular classiﬁcation of cancer: class discovery
and class prediction by gene expression monitoring. Science, 286, 531—537.

Haykin,S.S. et al. (2009) Neural networks and learning machines. Vol. 3.
Pearson Education, Upper Saddle River, NJ, USA.

Howe,E.A. et al. (2011) RNA-seq analysis in mev. Bioinformatics, 27,
3209—3210.

Hvidsten,T.R. et al. (2003) Learning rule-based models of biological process
from gene expression time proﬁles using gene ontology. Bioinformatics, 19,
1 1 16—1 123.

ﬁm'spzumol‘pmyo'sopcuuomtotq/ﬁdnq

704

V. Cestarelli et al.

 

Kuehn,H. et al. (2008) Using genepattern for gene expression analysis.
Current Protocols in Bioinformatics, 22, 7—12.

Lehr,T. et al. (2011) Rule based classiﬁer for the analysis of gene—gene
and gene—environment interactions in genetic association studies. BioData
Min., 4, 4.

Li,B. and Dewey,C.N. (2011) Rsem: accurate transcript quantiﬁcation
from rna-seq data with or without a reference genome. BMC
Bioinformatics, 12, 323.

Li,T. et al. (2004) A comparative study of feature selection and multiclass clas-
siﬁcation methods for tissue classiﬁcation based on gene expression.
Bioinformatics, 20, 2429—2437.

McCallum,A. et al. (1998) A comparison of event models for naive bayes text
classiﬁcation. In AAAI—98 Workshop on Learning for Text Categorization,
Vol. 752, pp. 41—48. Citeseer.

Mehta,M. et al. (1996) Sliq: a fast scalable classiﬁer for data mining. In
Advances in Database Technology—EDBT’96, pp. 18—32. Springer.

Miet'tinen,K. (1999) Nonlinear multiobiective optimization, Vol. 12. Springer,
New York, USA.

Mortazavi,A. et al. (2008) Mapping and quantifying mammalian transcrip-
tomes by rna-seq. Nat. Methods, 5, 621—628.

N0gueira,F.T. et al. (2003) RNA expression proﬁles and data mining of sugar-
cane response to low temperature. Plant Physiol., 132, 1811—1824.

Park,C. et al. (2014) Integrative gene network construction to analyze cancer
recurrence using semi-supervised learning. PLoS One, 9, e86309.

Pirooznia,M., et al. (2008) A comparative study of different machine
learning methods on microarray gene expression data. BMC Genomics,
9, $13.

Quinlan,].R. (1993) C4.5: Programs for Machine Learning (Morgan
Kaufmann Series in Machine Learning), 1st edn. Morgan Kaufmann, San
Francisco, California, USA.

Riedmiller,M. (1994) Advanced supervised learning in multi-layer percep-
tronsfrom backpropagation to adaptive learning algorithms. Comput.
Stand. Interfaces, 16, 265—278.

Seber,G.A. and Lee,A.J. (2012) Linear regression analysis, Vol. 936. John
Wiley 86 Sons, Wiley, Hoboken, NJ, USA.

Shaik,R. and Ramakrishna,W. (2014) Machine learning approaches
distinguish multiple stress conditions using stress-responsive genes and
identify candidate genes for broad resistance in rice. Plant physiology, 164,
481—495.

Shipp,M.A. et al. (2002) Diffuse large b-cell lymphoma outcome prediction by
gene-expression proﬁling and supervised machine learning. Nat. Med., 8, 6 8—74.

Storey,].D. and Tibshirani,R. (2003) Statistical signiﬁcance for genomewide
studies. Proc. Natl Acad. Sci. USA, 100, 9440—9445.

Tan,A.C. and Gilbert,D. (2003) Ensemble machine learning on gene expression
data for cancer classiﬁcation. In Proceedings of New Zealand Bioinformatics
Conference, Te Papa, Wellington, New Zealand. University of Glasgow.

Tan,A.C. et al. (2005a) Simple decision rules for classifying human cancers
from gene expression proﬁles. Bioinformatics, 21, 3896—3 904.

Tan,P. et al. (2005b) Introduction to Data Mining. Addison Wesley, Oxford
University Press, Oxford, UK.

Tipping,M.E. (2001) Sparse Bayesian learning and the relevance vector ma-
chine.]. Mach. Learn. Res., 1, 211—244.

Tothill,R.W. et al. (2015) Development and validation of a gene expression tu-
mour classiﬁer for cancer of unknown primary. Pathol.  RCPA, 47, 7—12.
Uhlén,M. et al. (2015) Tissue-based map of the human proteome. Science,

347,1260419.

Vapnik,V.N. (1998) Statistical Learning Theory. Wiley, Hoboken, NJ, USA.

Walz,A.L. et al. (2015) Recurrent dgcr8, drosha, and six homeodomain muta-
tions in favorable histology wilms tumors. Cancer Cell, 27, 286—297.

Wang,Z. et al. (2009) RNA-seq: a revolutionary tool for transcriptomics. Nat.
Rev. Genet., 10, 57—63.

Weinstein,].N. et al. (2013) The cancer genome atlas pan-cancer analysis pro—
ject. Nat. Genet., 45,1113—1120.

Weitschek,E. et al. (2014) Supervised DNA barcodes species classiﬁcation:
analysis, comparisons and results. BioData Min., 7, 4.

Weitschek,E. et al. (2015) Gela: a software tool for the analysis of gene expres-
sion data. In Database and Expert Systems Applications (DEXA),
BIOKDD, pp. 31—35. IEEE.

Zhou,C. et al. (2003) Evolving accurate and compact classiﬁcation rules with
gene expression programming. IEEE Trans. Evol. Comput., 7, 519—531.

ﬁm'spzumol‘pmyo'sopcuuomtotq/ﬁdnq

