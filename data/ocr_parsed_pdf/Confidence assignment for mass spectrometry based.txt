Bioinformatics, 2016, 1—8

doi: 10.1093/bioinformatics/btw225

Advance Access Publication Date: 29 April 2016
Original Paper

 

Structural bioinformatics

Confidence assignment for mass spectrometry
based peptide identifications via the extreme
value distribution

Gelio Alves and Yi-Kuo Yu*

National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health,
Bethesda, MD 20894, USA

*To whom correspondence should be addressed.
Associate Editor: Anna Tramontano

Received on November 5, 2015; revised on March 24,2016; accepted on April 16, 2016

Abstract

Motivation: There is a growing trend for biomedical researchers to extract evidence and draw
conclusions from mass spectrometry based proteomics experiments, the cornerstone of which is
peptide identification. Inaccurate assignments of peptide identification confidence thus may have
far—reaching and adverse consequences. Although some peptide identification methods report accur—
ate statistics, they have been limited to certain types of scoring function. The extreme value statistics
based method, while more general in the scoring functions it allows, demands accurate parameter
estimates and requires, at least in its original design, excessive computational resources. Improving
the parameter estimate accuracy and reducing the computational cost for this method has two ad—
vantages: it provides another feasible route to accurate significance assessment, and it could provide
reliable statistics for scoring functions yet to be developed.

Results: We have formulated and implemented an efficient algorithm for calculating the extreme
value statistics for peptide identification applicable to various scoring functions, bypassing the
need for searching large random databases.

Availability and Implementation: The source code, implemented in C++ on a linux system, is
available for download at ftp://ftp.ncbi.nlm.nih.gov/pub/qmbp/qmbpims/RAld/RAldiLinux764Bit
Contact: yyu@ncbi.nlm.nih.gov

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

1 Introduction

Assigning accurate statistical significance to identified peptides is fun-
damentally important because these peptides form the basis for pro-
tein identifications, whose results are often used to infer biological
processes and functions. Statistical errors at the peptide identification
level inevitably propagate downstream, and may have far reaching
consequences, undermining the biological conclusions drawn from
high level analyses. Therefore, various approaches for bounding the
occurrence of false identifications have been developed. One fre-
quently employed method is to globally control the proportion of
false discoveries (PFD) (Benjamini and Hochberg, 1995) per experi-
mental dataset. The target-decoy approach (Elias and Gygi, 2007) is

often used to estimate the PFD, with its numerator (the number of
false positives in the target database) being approximated by the nun]-
ber of decoy hits and with its denominator being the number of pep-
tides identified in the target database. However, as discussed by
Gupta et a1. (2011), this estimate can be inaccurate when a global
grading standard to prioritize the peptide hits across spectra and
across databases is lacking. Furthermore, as emphasized by Higdon
et a1. (2008), even with a correct grading standard present and under
the same PFD cutoff, two candidate groups from two different experi-
ments do not have identical statistical significances.

These aforementioned problems can be mitigated, however, by
computing per spectrum E-values/P-values. Given a tandem mass

Published by Oxford University Press 2016. This work is written by US Government employees and is in the public domain in the US. l

/310‘srcumo[p10}xo‘soncuHOJIItotq/ﬁdnq

G.Alves and Y.—K. Yu

 

spectrometry (MS/MS) spectrum and a quality score cutoff Sc, the
E—value E(Sc) is defined to be the expected number of random
peptides with scores the same as or better than Sc. (Similarly, the
P—value P(Sc) reflects the probability of finding a random peptide
with quality score S 2 Sc.) In general, the E—value is obtained by
multiplying the P—value by the total number of qualified peptides,
whose mass differences from the precursor ion are within the
specified tolerance. There are multiple advantages to employing
E—values/P—values for controlling false positives (type—I error): it per—
mits peptide/protein prioritization across spectra and experiments
(Alves et al., 2007a); it allows the statistical significances from dif—
ferent analyses to be combined (Alves et al., 2008a). Since the ex—
pected number of random matches per query can be defined without
inferring experimental details, the E—value is an ideal choice for the
universal grading standard for candidate peptides. This greatly as—
sists peptide prioritization in the target—decoy approach.
Furthermore, when candidate peptides are ranked by their E—values
and a threshold E—value is chosen, one may estimate the number of
false positives by multiplying the threshold E—value by the number
of spectra analyzed. This estimated number of false positives divided
by the total number of candidate peptides with E—values smaller
than the threshold E—value is the PFD estimate of Séric. Evidently,
the realization of the statistical benefits described requires accurate
E—values/P—values.

There exist several methods that compute E—values/P—values
using spectrum—dependent information (Eng et al., 2008; Fenyo and
BeaVis, 2003; Geer et al., 2004; Klammer et al., 2009). These meth—
ods use various parametric functions to fit the peptide score histo—
gram per spectrum to estimate the E—values/P—values for the peptides
identified. Even though these assumed parametric functions may fit
the histogram, a per—spectrum goodness-of-ﬁt (GOP) is not pro—
vided. Hence, there is no guarantee that such procedures can consist—
ently yield accurate E—values/P—values (Alves et al., 2007a; Segal,
2008). Nevertheless, there exist a few published methods that do
not assume any parametric form for the score distribution and are
able to compute accurate spectrum—specific significance consistently.
One of these methods extends the central limit theorem (CLT) by
analytically deriving a parametric distribution function, accounting
for finite sample size and skewness, to fit the peptide score histo—
gram per spectrum (Alves et al., 2007b). Another method computes
E—values/P—values by using a dynamic programming algorithm, also
known as all possible peptides statistics (APPS), to generate the score
histogram of all possible peptides whose masses are close enough to
that of the precursor ion (Alves and Yu, 2008; Alves et al., 2010;
Kim et al., 2008). Alternatively, similar to sequence alignment statis—
tics (Yu and Hwa, 2001), one may use the extreme value distribu—
tion (EVD) for significance assignment. Indeed, Spirin et al. (2011)
infer spectrum—specific statistics by employing the EVD with the par—
ameters estimated from searching multiple random databases. More
information about the CLT and the EVD is provided in Section 2.1.

Although all three aforementioned methods can provide accurate
significance estimates (without assuming parametric fitting func—
tions), each admits some limitations. Specifically, the CLT—based
method is applicable only to a single choice of scoring function, the
average of the sum of independent contributions; the APPS—based
method requires each of its scoring functions be a sum of independ—
ent contributions; and the EVD—based method, whose parameter
learning is in general challenging, can be applied only to scoring
functions whose resulting score histograms fall in the domain of at—
traction of the EVD (Gumbel, 1958; Kotz and Nadarajah, 2000).
Among these three methods, however, the EVD—based one offers
perhaps the most flexibility: permitting scoring functions other than

the sum of contributions, it may enable the development of more
discriminative functions that improve the sensitivity and specificity
of peptide identification.

To estimate the EVD parameters, Spirin et al. (2011) propose
searching 100 (or 10) random protein databases and obtaining from
each the best (or the best 10) score(s). Every random protein data—
base of (Spirin et al., 2011) is made of 10000 random protein se—
quences with lengths distributed according to the mouse proteome.
For each MS/MS spectrum, its corresponding set of best scores is
used to find the EVD parameters maximizing the order statistics
probability density function. This procedure, however, faces several
challenges. First, for a given precursor—ion mass, the number of
scored peptides may vary among the 100 (or 10) random protein
databases. Second, even within the same random database, the num—
ber of scored peptides may also vary by precursor—ion masses. The
set of best scoring peptides may thus be sampled from populations
of varying size, affecting the accuracy of the estimated EVD param—
eters. Third, as the mass accuracy of the precursor ion increases, the
small mass—error tolerance yields few database peptides to score,
decreasing the accuracy of estimated EVD parameters because the
large number of scored random peptides (NSRP) needed to accur—
ately fit the high scoring tail of the EVD (Olsen et al., 1999; Yu
et al., 2002) becomes unattainable. Finally, querying 100 or 10 ran—
dom protein databases, as prescribed by Spirin et al. (2011), with a
large set of MS/MS spectra can require a substantial computational
cost, which may deter software developers from rigorously imple—
menting EVD—based algorithms.

In this manuscript, we address the algorithmic challenges faced
by Spirin et al. (2011) by completely eliminating the need for ran—
dom protein databases for EVD parameter estimation. In our EVD
implementation (including XCorr (Eng et al., 1994), Hyperscore
(Fenyo and BeaVis, 2003), Kscore (MacLean et al., 2006) and
Rscore (Alves et al., 2007b)) in RAId_DbS (Alves et al., 2007b),
random peptides used to estimate EVD parameters are generated
on—the—fly during the program execution. This allows us to fix
the NSRP : 100 000 regardless of the mass of the precursor ion, its
mass error tolerance (5), or the size of the protein database.
Under this approach, the computational cost for generating high—
scoring random peptides is much less than the original EVD imple—
mentation (Spirin et al., 2011). However, our goal is not to design
a fast significance assignment method, but a flexible and robust
one that can be pragmatically implemented in most tools without
adding much computational cost. For the convenience of the read—
ers, we have summarized in Table 1 the acronyms used in this

paper.

Table 1. The acronym table

 

APPS All possible peptides statistics DPV Database P-Value

NSRP Number of scored random DG Data group
peptides
PFD Proportion of false discovery MS/MS Tandem mass
spectrometry
c3 Precursor-ion mass error GOF Goodness-of-ﬁt
tolerance
6 Product-ion mass grid spacing EVD Extreme Value

distribution
PTM Post-translational modiﬁcation CLT Central limit
theorem

SAP Single amino acid

polymorphism

 

/310‘srcumo[p10}xo‘sopcuHOJIItotq/ﬁdnq

Peptide identification confidence via E VD

 

2 Methods

2.1 Statistical significance assignment for peptides
Universality emerges when sampling a large number, n, of inde—
pendently identically distributed random variables from some
underlying distribution. The CLT states that if the underlying dis—
tribution has well defined first and second moments, the average of
these 11 random variables follows the Gaussian distribution as
n —> 00. The theory of extreme, on the other hand, indicates that
when the tail of the underlying distribution falls in the domain of
attraction of an EVD, the maximum (or minimum) of these 11 ran—
dom variables, as n —> oo, distributes according to that EVD.
Therefore, when employing the EVD theory, it is important to ver—
ify, analytically or numerically, that the underlying distribution in
question belongs to the domain of attraction of the EVD (Gumbel,
1958; Kotz and Nadarajah, 2000). In this study, all the scoring
functions considered have score distributions bounded by an
exponential tail (theoretically or empirically obtained). One thus
expects them to be in the domain of attraction of Gumbel—type
EVD.
The Gumbel—type EVD can be written as

PIS 2 s;u,l] : 1 — epr—exp{—2(s —  (1)

and its cumulant generating function is given by

g(t) E ln{J 55% d5} : ut+lnIF(1 4/1)], (2)
where F(x) is the gamma function, u is the location parameter, 1 //I
is the scale parameter and the P—value in Equation (1) represents the
probability for the random score S to equal or exceed the sample
maximum score 5.

To estimate the u and /I parameters, we note that the mean (yIsI)
and variance (O'ZISI) correspond to the first two cumulants

HISI =g’(t)lr:o =14— I//(1)//I=u+v//L (3)
71:2
JZISI = g”(t)li:o = IND/12 = my (4)

where y : 0.5 77215 665 . .. is the Euler—Mascheroni constant, Mac)
is the digamma function and W (x) is the polygamma function.

2.2 EVD parameters and database P—value

For each MS/MS spectrum, to estimate the corresponding EVD par—
ameters we use 100 high—scoring random peptides, each obtained
from scoring a set of 1000 random peptides. These 100 000 peptides
are generated in the following manner. For a given precursor—ion
mass associated with an MS/MS spectrum, a set of peptides that are
in the target database and are within 5 of the precursor—ion mass is
identified, and we refer to peptides in this set as qualiﬁed peptides.
We then randomly select N2100 qualified peptides (or N : the
total number of qualified peptides if there are less than 100 of them)
to initiate the procedure described below.

First, for each of the N qualified peptides we generate I1000/Nj
random peptides by replacing parts of the qualified peptide with
substitution tags that are less than 1000 Da and of unique amino
acid composition. Without distinguishing leucine (L) from isoleucine
(I), the use of 19 standard amino acids yields in total 3128 177
unique substitution tags of lengths 2—14. In addition, the mass dif—
ferences between the random peptides and the precursor ion are
required to be smaller than 5. During this step, priority is given to
unique amino acid compositions that yield random peptides

with masses closest to the precursor ion. Along with the original
N highest scoring peptides, this step yields in total M : N(1 + I
1000/NJ) peptides.

Second, for each of these M peptides, we randomly permute its
amino acids, except for the terminal residue(s) targeted by the diges—
tion enzyme(s), I100 000/MI times to generate a total of
M X I100 000/MI 2 100 000 random peptides. Although we aim
for M 2 1000 random peptides with unique compositions prior to
random permutations, sick cases may occur when 5 takes too small
a value. For example, the number of qualified peptides N can be
zero for extremely small 5. For this case, one either declares no pep—
tide match from the database or needs to enlarge 5. We always opt
for the latter. In this case, we will increase 5 until both of the follow—
ing conditions are met: (a) at least one qualified peptide is found; (b)
we obtain a large enough number M of random peptides with
unique compositions such that the permutations of these M peptides
can yield no less than 100 000 different random peptides.

Third, these M X I100 000/MI peptides are scored and ran—
domly assigned to 100 different bins, each viewed as a random data—
base and containing exactly 1000 random peptides. This step
effectively mandates that the NSRP be 100 000 per spectrum.
Fourth, the 100 best scores, one from each bin, are used to estimate
“[5] and 02 These values are then substituted into Equations (3)
and (4) to obtain

TE
1: (/6r;2Is]7 (SI
u=rtlsl -v//i- (6)

To better estimate the EVD parameters, we repeat the third and
fourth steps described above 10 times, without rescoring the pep—
tides and average the resulting EVD parameters.

Lastly, one has to account for the difference between the num—
ber of qualified random peptides, used to estimate the EVD par—
ameters and the number of qualified target peptides. This
difference can be compensated for (Yu and Hwa, 2001) by intro—
ducing an extra parameter k, which for our model is the ratio of
the number of qualified target peptides to the number of qualified
random peptides, i.e. k : (number of qualified target peptides)/
1000. The EVD, needed for computing P—values, in our study is
thus given by

PIS 2 shut/ll = 1 — eXpI-keXM-MS - 14)}I7 (7)

which represents the probability of finding the best scoring peptide
with a score larger than or equal to the threshold 5.

One may view observing a very large score 5 as a rare event and
model it by a Poisson process. Equation (7) then can be written as

PIS 2 s] : 1 — e—Ebi (8)
with the mean number of occurrences given by
E(s) : kexp{—/I(s — .

Here, the E—value E(s) is the expected number of peptides hav—
ing scores 2 s. The P—value in Equation (8) is then the probability
of observing one or more database peptides with scores larger than
or equal to the threshold 5; so it is also referred to as the database
P—value (DPV) (Alves et al., 2008a; Yu et al., 2006). Since both
Equations (7) and (8) represent the same P—value, this establishes
that the EVD P—value is the DPV (Alves and Yu, 2015) for the best
scoring peptide per spectrum. It is also worth mentioning that
when E(s) << 1 the DPV is well approximated by E(s).

ﬁm'spzumol‘pmyo'sopeuuowtotq/ﬁdnq

G.Alves and Y.—K. Yu

 

2.3 EVD model goodness—of—fit (GOF)

For any statistical model proposed, it is important to quantify how
well the model fits the experimental data. For each MS/MS spectrum
analyzed, one thus needs to assess how well the 100 max scores,
used for estimating the EVD parameters, actually agree with the fit—
ted EVD model. Inspired by the work of Kinnison (1989), we use as
the GOF the correlation between the max scores {5,}32? and
—lnI—ln(RP(s,-))I, where RP(s,-) : 1 — R(s,~)/101 is the rank percent—
ile, with R(s,~) being the rank of max score 5,. This correlation coeffi—
cient is computed for each of the 10 iterations used to estimate the
EVD parameters, and its average is our measure for the GOF. Based
on the table provided in (Kinnison, 1989), when 100 data points/
scores are sampled from an EVD, one expects that more than 99%
of the time the scores 5, and —lnI—ln(RP(s,))] have correlation
greater than 0.92. Consequently, we select 0.92 as our correlation
cutoff value: the EVD model is rejected if the GOF is less than 0.92;
in this case, no candidate peptide is reported for the spectrum
considered.

2.4 Scoring functions

In RAId_aPS (Alves et al., 2010), we have implemented several scor—
ing functions (and their associated filtering algorithms), including
Kscore (a plug—in scoring function for XITandem (MacLean et al.,
2006)), Hyperscore (from XITandem (Fenyo and Beavis, 2003)),
XCorr (from SEQUEST (Eng et al., 1994)) and Rscore (from
RAId_DbS (Alves et al., 2007b)). This allows us to reuse them in
RAId_DbS for this study. Note that in RAId programs a grid of
mass points of spacing e is used to speed up the scoring of product
ions. More details about the mass grid and the four scoring func—
tions are provided in the supplementary information. For each of
these four scoring functions, we assess the accuracy of statistical sig—
nificance assignment as well as retrieval efficacy at the peptide level
under the proposed EVD method.

2.5 MS/MS data

High resolution MS/MS spectra, acquired in an LTQ Orbitrap instru—
ment, with mass resolutions approximately 10 ppm for precursor ions
and 100 ppm for product ions, from whole—cell—lysate samples for
three strains of bacteria were downloaded from the Pacific Northwest
National Laboratory website at http://omics.pnl.gov/. Assuming the
mass of the charged fragments to be #1500 Da leads to an estimate of
5 : 0.015 Da for the precursor ion mass error tolerance and e : 0.15
Da for the product—ion mass grid spacing. The downloaded MS/MS
datasets were sorted into three data groups (DGs), each from a separ—
ate bacterial strain. DG—1 contains 12 MS/MS datasets (175 569 spec—
tra) from Escherichia coli K—12; DG—2, 9MS/MS datasets (141 332
spectra) from Mycohacterium tuberculosis H3 7Ru; and DG—3, 8 MS/
MS datasets (121 787 spectra) from Salmonella typhimurium ATCC
14028. Experimental details concerning sample preparations for DGs
1—3 can be found in (Mottaz-Brewer et al., 2008; Schrimpe—Rutledge
et al., 2012). A summary of the datasets downloaded is provided in
Supplementary Table 51.

2.6 Software parameters

To minimize the number of confounding factors, we analyze MS/
MS data with the following fixed software/experimental parameters:
cysteine residues are modified with iodoacetamide, resulting in the
addition of the carbamidomethyl group (57.07Da); trypsin is used
to digest protein mixtures; the maximum number of missed cleavage
sites allowed per peptide is 3; and only b— and y—series are used for
scoring since they form the largest common set of m/z peaks used by

all four scoring functions considered. Dataset—specific parameters
can be found in the figure captions, each of which provides more in—
formation regarding the generation of the figure, such as protein se—
quence database (target/decoy/random), scoring function(s) and
precursor—ion mass error tolerance (6).

2.7 Protein databases

The three target databases contain non—redundant protein sequences
respectively from Escherichia coli (4303 protein sequences),
Mycohacterium tuberculosis H3 7Ru (11 081 protein sequences) and
Salmonella typhimurium ATCC 14028 (5482 protein sequences),
which were downloaded from UniProt http://www.uniprot.org/uni
prot/on July 15, 2013. For each MS/MS data group, the retrieval as—
sessment requires, in addition to the target database, a decoy data—
base that mimics the background of the target database. Although a
different approach (Alves and Yu, 2015 ) was developed, we simply
use the reversed protein sequences as the decoy. This is to facilitate
comparison with other methods, since most of them also use re—
versed protein sequences as the decoy.

In addition to the decoy databases, a random protein database
was employed to test the accuracy of the reported DPVs. With the
Robinson—Robinson frequencies (Robinson and Robinson, 1991) as
the amino acid occurrence probabilities, the random protein data—
base contains 100000 randomly generated proteins, each of 350
amino acids long.

3 Results

Although all four scoring functions mentioned in Section 2.4 are ex—
tensively tested for the accuracy of significance assignments and re—
trieval performance, we describe the results for only XCorr, termed
RAId_DbS EVD(XCorr), in the main text. The results for the other
three scoring functions are similar and are thus relegated to the sup
plementary information.

3.1 DPV accuracy and GOF

To investigate how the NSRP (i.e. the sample size) affects the accur—
acy of the reported DPVs, we test the method described in Section
2.2 with the following NSRP: 1000, 10 000, 100 000 and 1 000 000.
Using these NSRP to estimate the EVD parameters via Equations 5
and 6, we examine how well the reported DPVs agree with the
observed DPVs. Given a score threshold and the EVD parameters,
the reported DPV is computed via Equation (7), while the observed
DPV is the fraction of spectra having matching peptides with re—
ported DPVs smaller than the threshold, i.e. the (reported) DPV
specified. Agreement between the reported DPVs and the observed
DPVs is measured by how well the curve traces the y :x line for the
entire range of DPVs, from 10’6 to 1. The curves in panel A of
Figure 1 show that as the NSRP, used to estimate the EVD param—
eters, increases from 1000 to 100 000, there is a significant improve—
ment in agreement between reported and observed DPVs. However,
not much improvement is gained by raising NSRP from 100 000 to
1 000 000. Similar results are found for other scoring functions, see
panel A’s of Supplementary Figures 51—53. This investigation also
leads us to use NSRP: 100 000 for estimating the EVD parameters
for all four scoring functions.

To assess the statistics” robustness against variation in the num—
ber of qualified database peptides, we compare the reported DPVs
with the observed DPVs when artificially varying 5. Evidently, a
large (small) 6 yields a large (small) number of qualified database
peptides for scoring. The curves in panel B of Figure 1 show that as

[310'sp2umoip105xo'sopeuHOJIItotq/ﬁdnq

Peptide identification confidence via E VD

 

 

Fig. 1. DPV accuracy and assessment of the EVD model. In panels A—C, two
dashes lines, x : 3y and x : y/3, are plotted to show how close/off the
measured curves are from the theoretical yzxcurve. All spectra in DG-1 (E.
coli) were queried against the random database (Section 2.7). With
6:0.01 Da, panel (A) displays the observed DPVs versus the reported DPVs
as NSRP varies from 103, 10“, 105 to 105. With NSRP 2105, panel (B) dis-
plays the accuracy of the reported DPV for different 6s: 0.1 Da, 0.01 Da and
0.001 Da. With NSRP :105 and 6 set to 0.01 Da, panel (C) displays the accur-
acy of the reported database DPVs under different internal mass spacings
(es): 0.1Da,0.01Da and 0.001Da. In panel (D) (with NSRP:105' 6 : 0.01Da,
and e : 0.1Da), the cumulative frequency histogram of the model GOF is
shown

(5 varies, the agreement between reported and observed DPVs re-
mains stable. Similar results are found for other scoring functions;
see panel B’s of Supplementary Figures 51—53.

We also investigate the impact of varying e, RAId’s internal mass
spacing (see Section 2.4). Evidently, varying 6 changes the score ob-
tained for each qualified peptide, influencing the EVD parameters
estimated via Equations (5) and (6), and thus may yield different re-
ported DPVs. However, if the statistics are correct, regardless of the
superficial differences, the reported DPVs should still agree with
observed DPVs. Panel C of Figure 1 as well as panel C’s of
Supplementary Figures 51—53 show that for a fixed precursor-ion
mass tolerance of 0.01 Da, strong agreement between the reported
DPVs and the observed DPVs is found for the three different 6’s: 0.
1 Da, 0.01 Da and 0.001 Da.

An EVD model is useful for computing database P-values only if
it describes well the distribution of the sampled maxima as men-
tioned in Section 2.3. Fortunately, this condition is met by the GOFs
computed for the EVD models. Displayed in panel D of Figure 1
(and in panel D’s of Supplementary Figs 51—53) is the normalized
cumulative frequency histogram for the model GOF. We find that
more than 98% of the EVD models, with parameters obtained using
Equations (5) and (6), have average correlation coefficients greater
than 0.92. The strong agreement between the reported DPVs and
the observed DPVs suggests that the score distributions for all four
scoring functions fall in the domain of attraction of the EVD. It is
possible that peptide properties such as peptide lengths and precur-
sor-ion charges may impact the accuracy of EVD models, which can
be measured by the GOFs. To systematically investigate this effect,
we first group spectra according to their precursor ion charge states;
within each group, we analyze the spectra using four scoring func-
tions via EVD; spectra within the same group are further separated

into subgroups according to the lengths of their best scoring pep-
tides; the statistics of the GOFs and the number of spectra within
each subgroups are documented. As shown in Supplementary Tables
52—55, there is indeed a slight, albeit not significant, deterioration of
the GOFs for short peptides when the charge states of the precursor
ions are low.

3.2 Sorié PFD and the target—decoy PFD

In Figure 2, we examine, using three different DGs, the agreement
between the PFD curves produced using the Soric’ formula and using
the target decoy approach. While these curves are constructed using
RAId_DbS EVD(XCorr), similar results are obtained for the other
scoring functions and the corresponding PFD curves can be found in
the Supplementary Figures 54—56. The Soric’ PFD (Soric’, 1989) is
given by

71,, X DPV,

t(DPV g DPVC) ’ I9)

PFD(DPV g DPVC) z
where DPV, is the DPV cut-off, 71,, is the total number of MS/MS
spectra from a given experiment, t(DPV S DPVC) counts the num-
ber of target database peptides (out of 71,, spectra) identified with
DPV S DPVC, and the total number of false positives with
DPVS DPV, is approximated by na>< DPVC. When the target-
decoy strategy is used to estimate the PFD, the total number of
false positives is estimated by the number of decoy peptides with
DPV S DPVC.

Figure 2 shows that the PFD curves computed using Sorié’s for-
mula and the target-decoy approach trace each other well for PFD
values between 10’3 and 0.3; for PFD values less than 1073, the two
curves slightly disagree. Similar results are obtained for other scor-
ing functions and are shown in Supplementary Figures 54—56. The
deviation between the two curves for small PFD values (less than
1073) is expected. In this region, a small variation in the number of
false positives can influence significantly the computed PFD value.
The observed deviation at large PFD values (greater 0.3) is mainly
due to the disagreement between the overall number of false posi-
tives estimated from the target and decoy databases. In this region,
for a given MS/MS spectrum the best scoring qualified peptides
from the target and decoy database can have very different DPVs,
explaining the possible observed difference in the PFD.

3.3 Peptide retrieval comparison
In the previous section, when using the DPVs as the grading stand-
ard, the agreement between the target-decoy PFD and the Soric’ PFD
is illustrated. However, whether or not these PFD curves coincide
with the ideal PFD curve (reflecting the ground truth) remains an
open question. This issue is partially answered in an earlier publica-
tion (Alves and Yu, 2015), within which an ideal PFD curve is con-
structed by analyzing MS/MS spectra from a known protein mixture
and agreement between the ideal PFD curve and the Soric’ PFD curve
was confirmed. However, given that a sample of known protein
mixture is less complex than true biological samples, a more system-
atic and rigorous study (which is beyond the scope of the current
paper) is needed in order to thoroughly examine the relationship be-
tween the ideal PFD and the target-decoy PFD. Nevertheless, with
the target-decoy approach being well accepted in the community,
we find it appropriate to compare retrieval results based on this
approach.

In panels A—C of Figure 3, corresponding to DGs 1—3, we display
the retrieval PFD curves of XCorr using the original SEQUEST
[v. 28] and our EVD implementation. In Supplementary Figure S7,

[310'sp2umoip105xo'sopeuHOJIItotq/ﬁdnq

G.Alves and Y.—K. Yu

 

 

~o-.

   

 

 

 

 

 
  

         

 

 

 

 

 

'5
3% Z —  garget-Decoy A I,_ j — PFD Target-Decoy B _ I —  garget-Decoy C _
E, 160000 — °"° 1,1. ; -- PFD Sorlc _— —_ orIc __
E : ,’ Z I I : I
_ / _ _ _ _ _
3 120000 — — _ a _ .11
32 — — _ i — r
‘i : : : I’: : 
w l
'5 — _ _ _ _ _
3 40000 — — — — _
E : ... ’T Z ___ 7‘ :
é o ||||||||I IIIIIIIII IIIIIIIII lllllllT _ ||||||||I IIIIIIIII ||||||||I IIIIIIIT 4 I IIIIIIII3 I IIIIIIII2 I IIIIIIII1 I IIIIIITO
10" 10'3 10'2 10'1 10° 10'4 10'3 10'2 10'1 10° 10' 10' 10' 10' 10
PFD PFD PFD

Fig. 2. Agreement between the Soric's PFD and the target-decoy PFD when peptides are ranked by DPVs. The PFD curves through both approaches are displayed
in panels A, B and C, respectively, for DG-1, DG-2 and DG-3; each DG is analyzed using the parameters mentioned in Section 2.6 and with the following additional
parameters: 6 : 0.015 Da, 6 : 0.15 Da, target and decoy databases as described in Section 2.7

 

 

 

70000 - 50000

 

Number of Peptides Identified

 

 

 

* — EVD(XCorr) A [/4 r — EVD(XCorr) B a e — EVD(XCorr) 7
90000 — ——. SEQUEST xcorr ’ — 70000 ‘ --- SEQUEST XCorr ‘ 70000 - --- SEQUEST XCorr ‘

 

50000

 

 

 

 

 

 

 

 

           
    

 

 

 

 

   
   
     
   
     

 
 
 
  
    

 

 

  

 

 

50000 — 30000 I/ 30000
: I IIIIIIII7 I IIIIIIII7 r Illllllh r_  T I IllIlIlIi I IIIIIIII, I IIIIIIII, 1T : I llIlIlIIi I lIIlIlIIi I llIIIlIIi IT
10“ 103 102 1o1 104 103 102 101 10“ 103 102 1o1
PFD PFD PFD
3 120000 90000 I llllllll I llllllll I IIIIIII 80000 I IIIIIIII I llllllll I IIIIIII
g : — EVD(Hyperscore) D r — EVD(Hyperscore) — EVD(Hyperscore)
'g 100000 — ——- EVD(Kscore) : ——' EVD(Kscore) —— EVD(Kscore)
a) _' :1 EVD(XCorr) _ n EVD(XCorr) u EVD(XCorr)
% Z v EVD(Rscore)  70000 _ V EVD(FIscore) _ 60000 V EVD(FIscore)
g 80000 : - : :
'3 gnaw? 50000 — — 40000
a. 60000 g, '  I
.8 — v —
3 40000 — 30000 g —_ 20000
g : _ _
z  ; I IIIIIIIIig I IIIIIIIIZ I IIIIIIII4 I  — I IIIIIIII I IIIIIIII I III|IIII r— 0 I IIIIIIII I llllllII I IIIIIIII I
10 10 10 10 104 1073 1072 1071 1074 1073 1072 1071
PFD PFD PFD

Fig. 3. Peptide retrieval comparison via target-decoy approach. DGs 1-3, analyzed using the same parameters as mentioned in the caption of Figure 2, yield the re-

trieval curves in panels A—C (and in panels D—F) respectively. Panels A—C display the retrieval PFD curves when peptides are ranked by the per spectrum EVD stat-
istics and by the native SEQUEST program, both of which use XCorr as the scoring function. Panels D—F display, for various scoring functions, the retrieval PFD

curves when peptides are ranked by the EVD statistics

we show similar comparison for Hyperscore using the original
XITandem [v. 2013.06.15] and our EVD implementation as well as
for Rscore using the CLT and EVD statistics through RAId_DbS.
For Kscore, however, we are unable to obtain reasonable results
through XITandem [v. 2013.06.15]. Hence we do not include this
retrieval result for comparison. Also, when performing retrieval
comparison between RAId_DbS EVD(XCorr) and SEQUEST XCorr
(panels A—C) it is necessary to turn off in RAId_DbS the parameter
‘isotopic error correction”, which corrects for erroneous monoiso—
topic precursor—ion mass assignment, because SEQUEST does not
have this option.

As shown in panels D—F (corresponding to DGs 1—3) of Figure 3,
comparable retrieval results are observed for different scoring func—
tions under the EVD strategy except for Hyperscore (whose superfi—
cially worse performance might be attributed to X!Tandem”s

aggressive filtering). The retrieval comparison between the EVD
statistics (RAId_DbS) and the APPS strategy (RAId_aPS) is provided
in the Supplementary Figure 58. It is evident that these two strategies
perform comparably under various scoring functions. This is ex—
pected because both strategies have the same spectral filtering and
scoring procedures, and both have accurate statistical significances
assigned to identified peptides. One may notice that the PFD curves
for RAId_DbS EVD(XCorr) in panels A, B and C of Figure 3 are
lower than those in panels D—F. This is because the ‘isotopic error
correction” option mentioned earlier is turned off in order to fairly
compare with the native SEQUEST program. We also observe from
panels A—C of Figure 3 that, with the isotopic error correction
turned off, RAId_DbS EVD(XCorr) still has a better retrieval than
SEQUEST XCorr, albeit under the choice that only b— and y—series
are used for scoring (see Section 2.6).

ﬁm'sreumol‘pquo'sopeuuopttotq/ﬁdnq

Peptide identification confidence via E VD

 

3.4 Perspective on computational speed

To gain the perspective on computational speed, we query a 35 MB
database with 15 000 MS/MS spectra using one quad—core processor
of 2.8 GHz under the same search parameters described in Section
2.6 along with 5 : 0.01 Da, 6 : 0.1 Da and Rscore as the scoring
function. For CLT—based method, it takes 7min; for EVD—based
method, it takes 14 min; for APPS—based method, it takes 5 min. The
EVD implementation, although is slower than both the CLT and the
APPS—based implementations, offers flexibility in terms of scoring
function choices without adding much computational cost.

4 Discussion

By definition, a decoy database contains no true peptide that pro—
duces any of the observed spectra. The primary function of a decoy
database is to mimic the ‘real” background one encounters when
searching the target database. Therefore, if the decoy database is
properly constructed, the distance between score distributions, re—
sulting respectively from searching the target and the decoy data—
bases, should be small. However, to firmly establish that a decoy
database is a good choice requires perhaps more work than the
data analysis itself. Of course, this work can be waived if accurate
statistics can be obtained from the target database alone. For our
EVD implementation, we have tested the effectiveness of error
control using both random databases (for type—I) and retrieval
PFD curves (for type—II). We find that the reported DPVs agree
closely with the observed DPVs (see Fig. 1, Supplementary Figs
51—53) and that the Soric PFDs agree well with the target—decoy
PFDs. The former shows that our assigned statistical significance
coincides with its definition, while the latter indicates that the
common choice of using reverse sequences as the decoy is
reasonable.

In Section 2.3, the correlation between the set of maximum scores
and the rank percentile (after double logarithm transformation) is
introduced as the GOF of the EVD models, and a cutoff value of 0.92
is selected based on the work of Kinnison (1989). Evidently, raising
the threshold to a higher value reduces the number of spectra for ana—
lyses, hence potentially reducing the number of peptides identified.
That is, it increases the number of false negatives (leading to type—II
error). On the other hand, lowering the threshold too much will in—
clude spectra for which the EVD models break down, hence poten—
tially increasing the number of false identifications (leading to type—I
error). Our investigation indicates that the threshold value 0.92 seems
to yield a good balance between type—I and type—II errors.

The search options of RAId_DbS allow for the inclusion of post—
translational modifications (PTMs) and/or single amino acid poly—
morphisms (SAPs). The inclusion of PTMs/SAPs or isotopic labeling
enlarge the search space, hence generally reduces sensitivity as ex—
pected (Alves et al., 2008b). However, the assigned statistical signifi—
cances, when accurate, should naturally reflect this effect. For
example, an identified database peptide with a low P—value will
have a worse E—value when the search space is large as compared to
the case of a smaller search space.

A question arises when one allows more than one candidate pep—
tide per spectrum to accommodate cofragmentation of multiple pre—
cursor ions with proximate masses. The natural extension of the
EVD for considering candidates other than just the best is the order
statistics. However, it makes better sense to use DPVs for lower—
ranking peptides per spectrum; see the discussion in (Alves and Yu,
2015). The DPV for each lower—ranking peptide per spectrum is

simply obtained thorough applying the EVD parameters learned for
the spectrum and that peptide”s score in Equation (7).

Currently, in RAId_DbS”s EVD implementation, for each spec—
trum, 100 000 random peptides are scored and randomly assigned
to 100 bins to estimate the EVD parameters regardless of 6s. In prin—
ciple, there might exist better NSRP/bin combinations that can pro—
duce EVD parameters more rapidly or accurately. It is our plan to
explore other NSRP/bin combinations in the near future.

Another interesting point to mention is the finite size effect asso—
ciated with the EVD, an asymptotic distribution that occurs when
the number of samples drawn from the population approaches infin—
ity. Because we always draw only a finite number of peptides to
score, finite size effects, such as those observed in sequence compari—
son statistics (Yu and Hwa, 2001), are indeed expected. However,
because we are not referring the EVD parameters from a theory but
are fitting them with a finite number of samples, the finite size effect
is automatically taken into account. In addition, the k factor intro—
duced in Equation (7) allows each spectrum”s EVD parameters to be
learned with the same NSRP while at the same time correcting for
uneven sample sizes resulting from searching the target database.

As expected, we find that using the raw score to prioritize pep—
tides yields worse retrieval than using the EVD statistics; see
Supplementary Figure 59. In addition, we also find that when statis—
tics are accurate, almost all scoring functions have highly similar re—
trieval performances, except for Hyperscore (whose superficially
worse performance might be attributed to X!Tandem”s aggressive
filtering). The similar performances found may result from the fact
that all scoring functions considered use the same m/z evidence (b—
and y—series peaks). However, if this were the case, it indicates that
no significant retrieval improvement can be expected from a new
scoring function that simply tweaks or reweighs the contributions of
commonly used evidence peaks; rather, a true advance in scoring is
more likely to come from new scoring schemes that better capture
the physical/chemical mechanism of fragmentations. This type of
new scoring scheme may not be a simple sum of contributions.
Nevertheless, if its score distribution falls in the domain of attraction
of the EVD, the method elaborated in this manuscript can still be
applied to provide accurate statistical significance assignments,
hence bringing out the full strength of the new scheme.

Acknowledgements

We thank the administrative group of the Biowulf Clusters (of the National
Institutes of Health), where all the computational tasks were carried out. We
also thank Stephen Altschul for a critical reading of the manuscript.

Funding

This work was supported by the Intramural Research Program of the
National Library of Medicine at the National Institutes of Health.

Conﬂict of Interest: Home declared.

References

Alves,G. and Yu,Y.K. (2008) Statistical characterization of a 1D random po-
tential problem — with applications in score statistics of MS—based peptide
sequencing. Physica A, 387, 6538—6544.

Alves,G. and Yu,Y.K. (2015) Mass spectrometry-based protein identiﬁcation
with accurate statistical signiﬁcance assignment. Bioinformatics, 31, 6 99—706.

Alves,G. et al. (2007a) Calibrating E-values for M52 database search meth-
ods. Biol. Direct, 2, 26.

Alves,G. et al. (2007b) RAId_DbS: peptide identiﬁcation using database
searches with realistic statistics. Biol. Direct, 2, 25.

ﬁm'sreumol‘piqxo'sopeuuopttotq/ﬁdnq

G.Alves and Y.—K. Yu

 

Alves,G. et al. (2008a) Enhancing peptide identiﬁcation conﬁdence by com-
bining search methods]. Proteome Res., 7, 3102—3113.

Alves,G. et al. (2008b) RAId_DbS: mass-spectrometry based peptide identiﬁ-
cation web server with knowledge integration. BMC Genomics, 9, 505.

Alves,G. et al. (2010) RAId_aPS: MS/MS analysis with multiple scoring func-
tions and spectrum-speciﬁc statistics. PLOS ONE, 5, e15438.

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: a
practical and powerful approach to multiple testing. ]. R. Stat. Soc. Ser. B
(Methodological), 57, 289—300. p

Elias,].E. and Gygi,S.P. (2007) Target-decoy search strategy for increased con-
ﬁdence in large—scale protein identiﬁcations by mass spectrometry. Nat.
Methods, 4, 207—214.

Eng,].K. et al. (1994) An approach to correlate tandem mass spectral data of
peptides with amino acid sequences in a protein database. ]. Am. Soc. Mass
Spectrom., 5, 976—989.

Eng,].K. et al. (2008) A fast SEQUEST cross correlation algorithm.
]. Proteome Res., 7, 4598—4602.

Fenyo,D. and Beavis,R.C. (2003) A method for assessing the statistical signiﬁ-
cance of mass spectrometry-based protein identiﬁcations using general scor-
ing schemes. Anal. Chem., 75, 768—774.

Geer,L.Y. et al. (2004) Open mass spectrometry search algorithm.
]. Proteome Res., 3, 958—964.

Gumbel,E.]. (1958) Statistics of Extremes. Columbia University Press, New
York, USA.

Gupta,N. et al. (2011) Target-decoy approach and false discovery rate: when
things may go wrong. ]. Am. Soc. Mass Spectrom., 22, 1111—1120.

Higdon,R. et al. (2008) A note on the false discovery rate and inconsistent
comparisons between experiments. Bioinformatics, 24, 1225—1228.

Kim,S. et al. (2008) Spectral probabilities and generating functions of tandem
mass spectra: a strike against decoy databases. ]. Proteome Res., 7, 3354—3363.

Kinnison,R. (1989) Correlation coefﬁcient goodness-of—ﬁt test for the ex—
treme-value distribution. Am. Stat., 43, 98—100.

Klammer,A.A. et al. (2009) Statistical calibration of the SEQUEST XCorr
function.]. Proteome Res., 8, 2106—2113.

Kotz,S. and Nadarajah,S. (2000) Extreme Value Distributions. Imperial
College Press, London, UK.

MacLean,B. et al. (2006) General framework for developing and evaluating
database scoring algorithms using the TANDEM search engine.
Bioinformatics, 22, 2830—2832.

Mottaz-Brewer,H.M. et al. (2008) Optimization of proteomic sample prepar-
ation procedures for comprehensive protein characterization of pathogenic
systems.]. Biomol. Tech., 19, 285—295.

Olsen,R. et al. (1999) Rapid assessment of extremal statistics for gapped local
alignment. Proc. Int. Conf. Intell. Syst. Mol. Biol., 211—222.

Robinson,A.B. and Robinson,L.R. (1991) Distribution of glutamine and as-
paragine residues and their near neighbors in peptides and proteins. Proc.
Natl. Acad. Sci. USA, 88, 8880—8884.

Schrimpe-Rutledge,A.C. et al. (2012) Comparative omics-driven genome an-
notation reﬁnement: application across Yersiniae. PLoS ONE, 7,

Segal,M.R. (2008) On E-Values for tandem MS scoring schemes.
Bioinformatics, 24, 1652—1653.

Sorié,B. (1989) Statistical “discoveries” and effect-size estimation. ]. Am. Stat.
Assoc., 84, 608—610.

Spirin,V. et al. (2011) Assigning spectrum-speciﬁc P-Values to protein identiﬁ-
cations by mass spectrometry. Bioinformatics, 27, 1128—1134.

Yu,Y.K. and Hwa,T. (2001) Statistical signiﬁcance of probabilistic sequence align—
ment and related local hidden Markov models. ]. Comput. Biol., 8, 249—282.

Yu,Y.K. et al. (2002). Statistical signiﬁcance and extremal ensemble of gapped
local hybrid alignment. In: Lssig,M. and Valleriani,A. (eds.) Biological
Evolution and Statistical Physics, Volume 585 of Lecture Notes in Physics.
Springer, Berlin, Heidelberg, pp. 3—21.

Yu,Y.K. et al. (2006) Retrieval accuracy, statistical signiﬁcance and compos-
itional similarity in protein sequence database searches. Nucleic Acids Res.,
34, 5966—5973.

ﬁm'sreumol‘piqxo'sopeuuopttotq/ﬁdnq

