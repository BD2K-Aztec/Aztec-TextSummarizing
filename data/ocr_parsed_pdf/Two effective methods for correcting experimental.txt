ORIGINAL PAPER

Vol. 28 no. 13 2012, pages 1775-1782
doi:10. 1 093/bioinformatics/bts262

 

Data and text mining

Advance Access publication May 3, 2012

Two effective methods for correcting experimental

high-throughput screening data

Plamen Dragievlaz, Robert Naolon2’3 and Vladimir Makarenkov”

1D partement d’lnformatique, Universit du Qu bec Montr al, C.P.8888, s. Centre—Ville, Montr al, QC, H3C—3P8,
2Genome Quebec Innovation Centre, 740 Dr. Penfield Ave, Montreal, QC, H3A—1A4 and 3McGill University,
Department of Human Genetics, 1205 Dr. Penfield Ave, N5/13, Montreal, QC, Canada, H3A—1 B1

Associate Editor: Martin Bishop

 

ABSTRACT

Motivation: Rapid advances in biomedical sciences and genetics
have increased the pressure on drug development companies to
promptly translate new knowledge into treatments for disease.
Impelled by the demand and facilitated by technological progress,
the number of compounds evaluated during the initial high-
throughput screening (HTS) step of drug discovery process has
steadily increased. As a highly automated large-scale process,
HTS is prone to systematic error caused by various technological
and environmental factors. A number of error correction methods
have been designed to reduce the effect of systematic error in
experimental HTS (Brideau et al., 2003; Carralot et al., 2012;
Kevorkov and Makarenkov, 2005; Makarenkov et al., 2007; Malo
et al., 2010). Despite their power to correct systematic error when
it is present, the applicability of those methods in practice is limited
by the fact that they can potentially introduce a bias when applied
to unbiased data. We describe two new methods for eliminating
systematic error from HTS data based on a prior knowledge of the
error location. This information can be obtained using a specific
version of the t-test or of the x2 goodness-of-fit test as discussed
in Dragiev et al. (2011). We will show that both new methods
constitute an important improvement over the standard practice of
not correcting for systematic error at all as well as over the B-score
correction procedure (Brideau et al., 2003) which is widely used in the
modern HTS. We will also suggest a more general data preprocessing
framework where the new methods can be applied in combination
with the Well Correction procedure (Makarenkov et al., 2007). Such
a framework will allow for removing systematic biases affecting all
plates of a given screen as well as those relative to some of its
individual plates.

Contact: makarenkov.vladimir@uqam.ca

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on January 26, 2012; revised on April 3, 2012; accepted
on April 30,2012

1 INTRODUCTION

A typical drug development project starts with a candidate
identiﬁcation phase in which a large chemical compound library
is tested against a given biological target (Malo et al., 2006).
Complex high-throughput screening equipment is employed at this

 

*To whom correspondence should be addressed.

stage to obtain precise estimates of compound activity levels. The
collected data are then used to identify the compounds that show
the most promising ‘drug-like’ activity behavior (Brideau et al.,
2003; Malo et al., 2006). The selected compounds, called hits,
typically undergo further testing to conﬁrm their reproducibility
and suitability for drug development. Depending on the nature of
the study, the hits may be compounds with the highest activation
capacity (i.e. activation assays), inhibition capacity (i.e. inhibition
assays) or both. The hit selection process assumes that the
measurements taken by HTS equipment accurately represent the
activity levels of the tested compounds. An important consideration
for this to be true is that experimental conditions are the same
for all compounds of the screen. Biases in the measurements can
nonetheless appear, due to inconsistencies in the environmental
factors, such as electricity, temperature, humidity or lighting changes
(Heyse, 2002; Makarenkov et al., 2007). Organizational factors
can also have a signiﬁcant systematic impact on the results of an
HTS campaign. For example, differences in the incubation time
allow the solvent evaporation to cause unintended variations in
the solution concentrations. Highly sensitive readers in particular
can detect subtle differences among the tested molecules which
misdirect follow-up efforts when they are due to bias rather than
to biology.

As a result of systematic bias causing under— or over-estimation of
biological activity, inactive compounds may be incorrectly selected
as hits (false positives), whereas promising (active) compounds may
remain undetected (false negatives). In HTS, systematic error is
usually column or row dependent (Brideau et al., 2003; Makarenkov
et al., 2007). It is important to note that systematic error can either
affect compounds placed in the same well, column or row location in
all plates of the screen (i.e. screen-speciﬁc error) or affect a column
or row of a speciﬁc single plate of the screen (i.e. plate-speciﬁc
error).

Figure 1 illustrates the presence of positional effects in two
publicly available experimental HTS datasets: McMaster Test
dataset, used as a benchmark for the McMaster Data Mining
and Docking Competition (Elowe et al., 2005; it contained the
compounds intended to inhibit the Escherichia coli Dihydrofolate
reductase, DHFR) and a dataset provided by the Chemistry
Department of Princeton University and consisting of a screen of
compounds meant to inhibit the glycosyltransferase MurG function
of E. coli (Helm et al., 2003). Figures la, c show activity levels
averaged across all plates (i.e. assay background surfaces), whereas
Figures lb, d show the activity levels of two selected single plates
(from the McMaster and Princeton datasets, respectively). These

 

© The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 1775

112 ﬁlo's[Bumo[pJOJXO'soiwuiJOJuroiqﬂ:duq 11101} pepeolumoq

9103 ‘Og anﬁnv uo ::

RDragiev et al.

 

 

(a)12345573910le12345513910

1

3 I!-

(c) 1 a a 4 s a 1 a a 1011121314151ai(d)' 1 2 3 4 n a 1 a s 1011121lll‘ll1a

'IIUILI-hhlﬂ-l
U'Ild'itI-IIUN-l

 

 

 

 

1 1

2 I I _II I

a 3' . II.- . _

' *I In I-.

5 I’EII I I

° I 'l I  II I

‘1' 1r .

I I- I

9 o I

I: II I

II n I I

I: 1: I I

1: 1: _

u 11  I
'5 "I II - I
II In 'I 

IT 1‘. .

 I «'II I I

NI '9 I I I I - I
an;  n I I

III 21 I I. 1.] I
M! .25 .. I _ I. .II

Fig. 1. Hit maps showing the presence of positional effects in the McMaster
1250-plate assay (Elowe at al. 2005)7(a) whole assay background surface,
(b) plate 1036 measurements; and in the Princeton 164-plate assay
(Helm at al. 2003)7(c) whole assay background surface, (d) plate 144
measurements. Color intensity is proportional to the compounds” signal
levels (higher signals, i.e. potential target inhibitors, are shown in red)

examples demonstrate that systematic biases in HTS may have
different screen-speciﬁc and plate-speciﬁc systematic deviations.
For instance, in the McMaster dataset, the measurements in the
column 10 are globally over-estimated (Fig. 1a), but in plate 1036
they are rather under-estimated (Fig. lb). Similarly, Figure 1c reveals
apparent ‘edge effects’ in the Princeton dataset with the values of the
outer rows and columns being below the screen average. This effect
was not observed, however, for all plates of the Princeton screen,
with an evident over-estimation of the ﬁrst column measurements
detected in plate 144 (Fig. 1d). Thus, systematic error correction
methods should be able ﬁrst to recognize the character of systematic
error affecting the data at hand and then remove it either from
the whole assay and/or only from the speciﬁc plates where it
was detected. In this article, we describe two new methods for
eliminating plate-speciﬁc systematic error and show how these
methods can be applied in a more general correction framework
that also includes the Well Correction procedure (Makarenkov et al.,
2007) which allows for removing screen-speciﬁc systematic biases.

2 METHODS
2.1 Data preprocessing in HTS

To analyze experimental HTS assays, a data preprocessing treatment should
be performed before the hit selection. Several data normalization and
correction techniques, including the step of the quality control, have been

proposed to preprocess experimental HTS data (Brideau at al., 2003;
Carralot at al. , 2012; Dragiev at al. , 2011; Kevorkov and Makarenkov, 2005;
Makarenkov at al., 2007; Malo at al., 2006, 2010; Shun at al., 2011; Zhang,
2008; Zhang et al., 1999). The most popular data normalization procedures
used in HTS are as follows: Percent of control that normalizes the given
compound measurements relative to the mean value of the plate’s positive
controls; Normalized percent inhibition in which the normalization is carried
out relative to both positive and negative controls; and Z-score that consists
in a zero mean and unit SD normalization of the plate’s measurements (Malo
at al., 2006). Regarding data correction, mention the B-score (Brideau at al.,
2003) and Well Correction (Makarenkov at al., 2006, 2007) methods which
will be considered in this study. Their main steps of these methods are as
follows:

B-score (Brideau at al., 2003) is a robust normalization procedure
commonly used in experimental HTS. Similarly to the above-mentioned
normalizations, B-score sensibly handles plate-to-plate variability. In
addition, it also corrects the raw plate measurements by removing the existing
row and column positional effects. It assumes the following statistical model
of HTS measurements [Equation (1)]:

xijp = M]; +Rip + ij +8ijpv 

where xii], is the raw measurement of the compound in well (i, j) of a given
plate [7, it], is the plate average, Rip is the systematic error affecting row 1',
Ci], is the systematic error affecting column j and 8,7], is the random noise
affecting well (i, j) of this plate. B-score ﬁrst uses a two-way median polish
(MP) procedure (Tukey, 1977) to obtain the estimated values of xi”, #1,, Rip
and Cf], [Equation (2)]:

iijp 2 ll]; +Rip + ij- 
The residual, rim, for the measurement in well (i, j) is then calculated as
the difference between the raw measurement xii], and its ﬁtted value fry-1,:
rij],=xij],—)?ij],. Finally, the raw compound measurement is replaced with
the corresponding residual adjusted by the plates median absolute deviation
[MAD],, Equation (3)]:

i r1717

xii]J = MAD], , MAD], = median {lrijp — median (rijl,)|}, (3)

 

where x}, is the normalized measurement value.

Well Correction (Makarenkov at al., 2006, 2007) is another combined data
normalization and correction method designed to compensate for positional
effects affecting rows, columns or individual wells, and appearing in all
plates of the screen (i.e. screen-speciﬁc error). Well Correction includes the
two following steps:

(1) For each well location of the screen, a linear or polynomial least-
squares approximation is carried out for the compound measurements
located in that well over all plates of the screen. This approximation
is performed separately for each well location.

(2) The approximated entities within the same well location are then
normalized over all plates of the screen using Z-score. This
normalization is performed separately for each well location.

Once the data normalization and correction steps are completed, a hit
selection procedure, meant to identify the compounds that will be promoted
to leads, is carried out. The most popular strategy for hit selection proceeds by
the identiﬁcation of the compounds whose activity levels exceed a predeﬁned
threshold (Malo at al., 2006). Typically, the hit selection threshold is
expressed in terms of the mean, it, and the SD of the observed measurements.
A commonly used approach selects as hits the compounds whose activity
levels deviate from the mean value p. for >3SD.

Despite their ability to eliminate systematic error, HTS preprocessing
techniques cannot guarantee the recovery of correct hits. In our previous
works (Dragiev at al., 2011; Makarenkov at al., 2007), we showed that a
misapplication of error correction methods on error-free HTS data introduces
a signiﬁcant bias that affects very negatively the accuracy of the hit selection
process. For instance, a simulation study described in Makarenkov at al.

 

1 776

112 ﬁlo's[Bumo[p.IOJXO'soiwuiJOJuroiq/j:duq 11101} pepeolumoq

9103 ‘Og anﬁnv uo ::

Correction of experimental screening data

 

(2007) suggests that the B-score method is unable to cope with screen-
speciﬁc systematic error (Figs 2 and 3 in the latter study) and that the Well
Correction method is not suited for eliminating plate-speciﬁc systematic error
(Fig. 4 in the latter study). Hence, error correction methods should be used
with caution and only when the presence of systematic noise in the data has
been conﬁrmed by statistical tests. In our recent work (Dragiev at al., 2011),
we described how individual HTS plates can be assessed for presence of
systematic error, thus facilitating the decision regarding the application of
data correction techniques.

2.2 Two new data correction methods

Here we present two new methods for HTS systematic error correction,
called Matrix Error Amendment (MEA) and Partial Mean Polish (PMP).
Both methods rely on prior information concerning the location of rows and
columns of individual plates that are systematically over- or under-estimated.
Such information might be available through the analysis of an individual
plate (or entire screen) background (Kevorkov and Makarenkov, 2005) or
can be acquired using a speciﬁc version of the t-test or of the X2 goodness-
of-ﬁt test (Dragiev at al. , 2011; see also the Supplementary Materials section
for the application of these tests in the HTS context). Both MEA and PMP
methods are applied on a plate-by-plate basis.

Let X be a plate of HTS measurements with m rows and n columns. Let
xi]- be the measurement of the compound located in well (i, j) of X and let
p. be the mean value of all measurements of plate X that are not affected by
systematic error.

In the case when plate X is free of systematic error, we can expect that
the mean of the values in a given row 1' (i=1,  m) does not deviate
substantially from it, which in this case is the mean of all measurements on
the plate: Zydxij whit. Similarly, for a given columnj U: 1,  n) of X,
we expect that: 1 xi]- wmii.

Assume that X is affected by systematic error. Let r1, r2,..., r], (p <m)
be the set of rows of X, and cl, 02,...,cS (s <n) be the set of columns of
X, where the presence of systematic error has been conﬁrmed. It is worth
noting that the set r1, r2,  r], can represent any subset of the complete set
of rows 1, 2,  m and the set C] , 02,  c, can represent any subset of the
complete set of columns 1, 2,  n of plate X. The only necessary condition
for the application of the new methods is the presence in X of at least one
row and at least one column not affected by systematic error. Let an. be the
unknown value of systematic error affecting row r,» and ac. be the unknown
value of systematic error affecting column cf. The following 4-fold set of
linear equations can be composed:

Zxrij _ "en- _ :36) = "M v 

m 1)

2xin _mecf _Zer,- :ml’l'v 
i2] i2]
ri x
Ext—DH» (6)
1:1 j:l

m p

inj —Zeri 2mg, (7)
1’21 [’21

where Equation (4) corresponds to rows r1,r2,...,rp affected by row
systematic error, Equation (5) to columns cl , 02,. . ., c, affected by column
systematic error, Equation (6) to rows not affected by row systematic error
and Equation (7) to columns not affected by column systematic error.

MEA method

Systematic error in HTS does not typically affect all the columns and rows
of a plate. The affected columns and rows are often those located on the
plate edges (Brideau at al., 2003; Kevorkov and Makarenkov, 2005). Thus,
typically, [7 is much smaller than m and s is much smaller than n. The presence
of rows and columns not affected by systematic error allows us to estimate

it and leaves an. and ac]. the only unknowns in the linear system of equations
(4)%7), which have m+n equations and fewer than m+n unknowns.
The MEA method consists of the two following steps:

(1) Estimate the values of the row and column systematic errors 2,, and
éc/(i = 1,  p andj: 1,  s), independently for every plate of the
assay, by solving the system of linear equations (4)%7).

(2) Adjust the measurements of all compounds located in rows and
columns of the plates affected by systematic error using the error
estimates a, and a, determined in Step 1.

Two approaches of solving the system of linear equations (4)7(7) were
tested in our study. First, by combining all Equations (4)7(7), we composed
an over-determined system of linear equations Ae=b with m+n equations
and fewer than m+n unknowns, where A was the matrix of the coefﬁcients
for the unknowns an. and ac]. (i: 1,  p andj: 1,  s) combined in the
vector e of size p+s, and b was the vector of free terms. We found that in all
cases the matrix ATA was singular, thus rendering inapplicable the standard
least-square approximation method for solving over-determined systems of
linear equations. We were able, however, to ﬁnd an approximate solution
of this system by using the singular value decomposition (SVD) method.
Second, we also tested a simpler and computationally less intensive approach
consisting of combining only Equations (4) and (5) into the linear system
(8), having exactly m +n equations and m +n unknowns. When In +n > 5, the
system (8) always has a unique solution which can be found using standard
methods for solving linear equations systems (e.g. Gaussian elimination).

n0...0011...11 2,, 17,,

0n...0011...11 Erz brz

00  n01 1 .. 1 1 er,_, 17r,,_l

00..0n11..11 a,” _ I7,” (8)
..11m0..00 ecl _ bcl '
..110m..00 6,, 12,,

11 1 1 0 0  m 0 e,_,_l be“,

11...1100...Om ac, I71-V

where bri 22;:1xm- —np. and b6]. 22;":1xicf —mp..

According to our simulation study, the second approach, which requires
less computer power, generally provided better results in terms of systematic
error identiﬁcation (i.e. it yielded a higher hit detection rate, see Section 3.1).
Thus, its detailed results are presented in Section 3.

The ﬁnal step of the MEA method proceeds by subtracting the obtained
systematic error estimates 2,, and a, from the raw plate measurements
[Equations (9)7(10)]. For all rows ri (i=1,  [7) affected by systematic
error, we have:

xLU- =xrij—éri, for allj: lgjgn, (9)
and for all columns c]- U: 1,  s) we have:
xgcf =xici —écf, for all i: lgigm. (10)

PMP method
Denote by p.) the mean value of all measurements in row i and by [Lj the
mean value of all measurements in column j of plate X :

m

1 ” 1
it): 2 inj and [Lj = a inj.
j:1 i2]
Equations (4) and (5) can be rewritten as Equations (11) and (12):

It S
ne..=Zxr.j—nu—Zec,. (11)
1:1 j:1

m 1)

me., = Ext, —mu — 22.... (12)
i2] i2]

where p. is the mean value of all measurements of X not affected by
systematic error.

 

1 777

112 ﬁlo's[Bumo[p.IOJXO'soiwuiiquioiq/j:duq 11101} papeolumoq

910E ‘OE JSHBHV uo ::

RDragiev et al.

 

Dividing Equations (11) and (12) by n and m, respectively, we obtain:

1 S
2... =11... —u—;Ze.,. (13)
1'21

1 ”
2., =u., —u— $2}... (14)
i2]

Since systematic error usually affects only a few columns and rows of HTS
plates [e.g. row and column measurements on plate edges are often biased; for
more details see Brideau at al. (2003) or Kevorkov and Makarenkov (2005)]
and causes an over- or under-estimation of the affected measurements (i.e.
the error values can be negative or positive), we can assume that the term
consisting of the total column error divided by the number of columns has a
negligible impact compared with the other terms in Equation (13) and thus
that the row systematic error of row ri can be estimated as the difference
between the mean value of the entities in that row and the mean value p. of
the plate measurements that are not affected by systematic error:

grizlltri_pl- 
Similarly, for the column cf, we can expect that:
écleh‘f—M- (16)

Based on the assumptions above, we can formulate the PMP iterative
procedure (only a part of the plate’s rows and columns, i.e. those affected
by systematic bias, will be ‘polished’ by the method). The means in this
procedure can be easily replaced by the medians giving rise to the Partial
Median Polish method which could be Viewed as an extension of a well-
known Median Polish procedure by Tukey (1977) for the case when the
error locations are known.

The main steps of the PMP method are the following:

(1) Compute the mean value p. of all entities of the given plate that are

rag/120W

(m—p)(ri—x) ’
where R: {r1,r2,...,rp|05p<m} is a set of rows ofX affected by
systematic error and C: {cl,cz,...,cxl05s <n} is a set of columns
of X affected by systematic error.

not affected by systematic error: it =

(2) For each i (1 Sifp), compute the mean value, it”, of row ri as
Mn. 2 % lxrij, and then, using Equation (15), the estimate of the
row bias 2,, as: 2,, :11.” —p..

For each j (1 Sj 5s) compute the mean value, 11.6], of column c]- as
[.ch = lxicf, and then, using Equation (16), the estimate of the
column bias a, as: a, 211.6], — it.

(3) For all rows affected by systematic bias, adjust their measurements
using the error estimates determined in Step 2, i.e. for each i (1 5 i 5 p),
and for eachj (1 Sj 5 n): xm- =xm- —é,l..

For all columns affected by systematic error, adjust their
measurements using the error estimates determined in Step 2, i.e.
for eachj (1 Sj 5s), and for each i (1 Sifm): xin =xici —écf.

(4) Compute the value of the convergence parameter 8: 8 =  l | 2,, | +

S A
ijl I 36) 

(5) If 8 <8, where a is a selected convergence threshold, or if a ﬁxed
maximum number of iterations has been already carried out, then
return X, otherwise, repeat Steps 275.

3 RESULTS AND DISCUSSION

To evaluate the performances of the two introduced systematic error
correction methods we ﬁrst carried out simulations with artiﬁcially
generated HTS measurements. We also applied both MEA and
PMP methods to analyse the 1250-plate HTS screen produced at
the HTS Laboratory of McMaster University (i.e. the Test dataset
proposed as a benchmark for the McMaster Data Mining and
Docking Competition, see Fig. 1 and Elowe et al., 2005).

3.1 Simulation study

The simulated data also consisted of 1250-plate assays. Plate sizes
were 96-well plates (8 rows X 12 columns), 384-well plates (16
rows X 24 columns) and 1536-well plates (32 rows X 48 columns).
Inactive compound measurements were generated according to
the standard normal distribution. Active compounds (hits) were
added randomly to the plates to form assays with the following
hit percentages: 0, 0.5, 1, 2, 3, 4 and 5%. Hit locations were
chosen randomly within each plate (i.e. the probability that a given
well contained a hit compound was the same for all wells of the
plate, regardless of the well location within the plate). The hit
measurements were generated according to the normal distribution
with parameters ~N(/,L—SSD, SD), where [,L and SD were the mean
and standard deviation of the original dataset (obtained before the
addition of hits; i.e. [,L = 0 and SD = 1). Systematic row and column
errors were added to randomly selected rows and columns of each
plate. The rows and columns affected by systematic error were
selected separately for each plate, and thus their locations differed
from plate to plate. The values of systematic bias followed a normal
distribution with parameters ~N (0, C). The following values of the
error, C, were considered to generate assays affected by different
degree of systematic error: 0, 0.6, 1.2, 1.8 and 2.4SD. To mimic
empirical HTS data, in our ﬁrst simulations the effect of systematic
error was limited to a few rows and columns only. Thus, at most
2 rows and 2 columns for 96-well plates, at most 4 rows and 4
columns for 384-well plates and at most 8 row and 8 columns for
1536-well plates were affected by systematic bias. A small random
error was also added to both hit and non-hit measurements. The
random error in all datasets followed a normal distribution with
parameters ~N(0,0.6SD).

Equation (17) speciﬁes the model we used to generate an error-
affected measurement of the compound located in well (i, j) of
plate I):

xip=xijp+en.+ec..+randzyp7 07>

where xl’jp is the resulting measurement value, xi”, is the original
error-free measurement, er,” is the systematic error affecting row i
of plate 1), e6”? is the systematic error affecting column j of plate 1)
and randl-jp is the random error in well (i, j) of plate 1).

Six data correction/hit selection methods were tested in our
simulations. All tested methods comprised an identical hit selection
step, but differed in the way the data were processed before the
hit selection. The hits were selected globally for each assay using
the hit selection threshold of It)” —3SDhS (i.e. all compounds with
the measurements lower than It)” — 3SDhS were declared hits, where
[thsand SDhS were, respectively, the mean and SD of the entire assay
after the addition of hits and systematic error). The six methods
evaluated in our simulation study were the following:

0 Original data processing without any data correction;
0 B-score correction method (Brideau et al., 2003);

0 MEA method performed under the assumption that the exact
locations of the error-affected rows and columns on each plate
of the assay are known;

0 MEA method performed for the rows and columns where
systematic error was detected by the t-test (for more details,
see Dragiev et al., 2011);

 

1 778

112 ﬁlo's[Bumo[pJOJXO'soiwuiiquioiq/j:duq 11101} papeolumoq

9103 ‘Og isnﬁnv uo ::

Correction of experimental screening data

 

(a) True positive rate {‘16}. 96-well plates (b) FP+FN tolal, 96-well plates

   

 

L} 5‘1": 1% 2% 3% 4% 5% W 0 5% 3% 2'5’: .351: 4% 5'1“.

Hil percentage Hit percentage
(c) True posilwe rate 11%). 96-well plates (CI) FP+FN latel. QS-WQII plates

100;

90

  

su'

 

60 I 0 I I I I
[JESU El ESL) 1 230 1.350 2131.1 0.0813 0 68D 1 230 ‘ESD 2.4SD
Systematic error $111818ch error

 

Fig. 2. True positive rate and total number of false positive and false negative
hits (i.e. total number of false conclusions) per assay for 96-well plate assays
estimated under the condition that at most two rows and two columns of each
plate were affected by systematic error. Panels (3) and (b) present the results
obtained for datasets with the ﬁxed systematic error SD of 1.2SD. Panels (c)
and ((1) present the results for datasets with the ﬁxed hit percentage rate of
1%. Methods legend: no—correction (O), B-score (A), MEA (El), t-test and
MBA (<>), PMP (+), t-test and PMP (x)

0 PMP method performed under the assumption that the exact
locations of the error-affected rows and columns on each plate
of the assay are known;

0 PMP method performed for the rows and columns where
systematic error was detected by the t-test (for more details,
see Dragiev et al., 2011).

In all experiments, we assessed the performances of the six
data preprocessing methods by measuring the total number of false
positives and false negatives, and by estimating the methods hit
detection rate (i.e. true positive rate).

We conducted two series of experiments to evaluate the methods
performances depending on the hit percentage and the variance
of systematic error. The ﬁrst series of experiments used datasets
with the ﬁxed systematic error of 1.2SD and the hit percentage rate
varying from 0% to 5% (there are no true positives for the case of
0% of hits; see Figs 2—4a).

The second series of experiments considered datasets with the
ﬁxed hit percentage of 1% and the systematic error varying from
0 to 2.4SD. Some 500 datasets were generated for both series
of experiments and for each parameter combination. Figures 2—4
present the average results obtained for the two series of experiments
for the 96-well, 384-well and 1536-well plates, respectively.

Furthermore, we conducted additional simulations to assess the
performances of the MEA and PMP methods in the situation when up
to 50% of the plates’ rows and columns were affected by systematic
bias. The graphics depicting relative performances of the MEA,
PMP, B-score and no-correction strategies in this case are presented
in Supplementary Figures 15—35.

(a) True positive rale {‘11:}. 334-well plates ([3)

FP+FN lotel. 384—1012" plates

14000
1200i]
10000
5000
6000
4000

   

200”
J n .s I
U 5'“) 1% 2% 370 4‘4! 531': 7
llil percentage Hil percentage
(l3) True positive rate [911). 304—0011 pistes (d) FP+FN total, 384-well plates
20150 ' 4
1500

    

 

 

m 4005
55 . . a
0.030 0.650 1 230 1550 2 450 0 030 0 550 1 2:90 t 550 2 450

Systematic strur Systematic error

Fig. 3. True positive rate and total number of false positive and false negative
hits per assay for 384-well plate assays estimated under the condition that at
most four rows and four columns of each plate were affected by systematic
error. Figure 2 panel description applies here

(a) True positive rate (“11]. 1536-well plates ([3)

FP* FN tolal. 1536-well plates

 

 

0.5% 1% 2% 3% 4% 5% 0% D 5% 1% 2% 3% 4% 5%

3500 
3000
2500
2000 I
1500 ‘
05 . . . 1000 if I . I .
0 use 0 see 1 230 1 551: 2.450 0.050 0 680 1.250 1.030 2.430
Syslematic err0I

I14 percentage HII percentage
(c) True positive rate ('10). 1535owell plates (d) FPoFN tutal. 1536-well plates
05 ' 5000 1 o/
90 45.00 1 \/’\—1§—-—g\
4000 '
05  .

EU

75

  

70

 

 

Systematic errpr

Fig. 4. True positive rate and total number of false positive and false negative
hits per assay for 1536-well plate assays estimated under the condition that
at most of eight rows and eight columns of each plate were affected by
systematic error. Figure 2 panel description applies here

The simulation results suggest that both proposed methods
outperformed the B-score and no-correction procedures when the
number of the plate’s rows and columns affected by systematic
error was low (e.g. in case of commonly observed edge effects),
regardless of plate size, hit rate and systematic error variance (see
Figs 2—4). In the situations when the number of affected rows and
columns of each plate affected by systematic bias could attain 50%

 

1 779

112 /3.IO'S[BUmO[p.IOJXO'SOIJBLUJOJIIIOIq/jIdllq morj pepeorumoq

9IOZ ‘OE ISUEHV Ho ::

RDragiev et al.

 

of the plate’s total number of rows and columns (see Supplementary
Figs 1S—3S), the MEA and PMP methods generally yielded better
results than B-score when the hit percentage was under 3% (see
Supplementary Figs 1S—3S, cases a and b) or when the level of
systematic error was under 1.8SD (see Supplementary Figs 1S—3S,
cases c and d). However, in the situations when the hit percentage or
systematic error variance was high, the B-score procedure generally
showed a more stable behavior than the new methods. This was
largely due to the fact that the performance of the t-test, carried out
prior to MEA and PMP, decreases as the amount of data affected by
systematic error grows (Dragiev et al., 2011). In general, the MEA
method turned out to be the best performing method for correcting
systematic error within 96-well plates when the systematic error
variance or the hit percentage was low (see Fig. 2 and Supplementary
Fig. 1S), whereas the PMP method provided better results than MEA
for the 96-well plates when the systematic error variance or the hit
percentage was elevated as well as for the 384- and 1536-well plates
(see Figs 3 and 4; Supplementary Figs 2S and 3S). It is worth noting
that the B-score method was very prone to generating false positives.

3.2 Analysis of the McMaster Test assay

We carried out the MEA and PMP methods to analyse the McMaster
Data Mining and Docking Competition Test assay (see Elowe
et al., 2005 and Fig. 1a and b). We examined their impact on
the hit identities determined during the HTS phase of the project.
This dataset consisted of 625, 96-well plates (with 8 rows and 12
columns) screened in duplicate. Columns 1 and 12 of all plates
contained controls and thus were not considered in our study.
The assay conditions were identical for all plates. They were as
follows: Each 200 Ml reaction mixture contained 40 MM NADPH,
30 MM DHF, 5 nM DHFR, 50 mM Tris (pH 7.5), 0.01% (w/v) Triton
and 10mM ﬂ-mercaptoethanol. The compounds from the screening
library were added to the reaction before initiation by enzyme at a
ﬁnal concentration of 10 MM. All measurements were taken at 25°C.

The threshold of [,L—2.295D was used to identify hits. This
threshold led to the identiﬁcation of 96 average hits which were
reported by the competition organizers (Elowe et al., 2005). Our
previous works showed that the measurements in the McMaster
Test dataset were affected by systematic error (Dragiev et al., 2011;
Makarenkov et al., 2007), especially when some higher hit selection
thresholds were used (e.g. [,L—SD or [,L—ZSD). The hit sets provided
by the six following methods were compared: uncorrected data
processing, B-score, and the introduced MEA and PMP methods
applied as such and in the combination with the Well Correction
procedure (Makarenkov et al., 2007) allowing for removing screen-
speciﬁc systematic error. Both MEA and PMP methods were carried
out on a plate-by-plate basis and were preceded by the t-test, which
was necessary to recover systematic error row and column locations.
The t-test was performed with the or parameter value set to 0.01 (see
Supplementary Materials). As the McMaster Test dataset contained
replicates, the hit selection procedure was adjusted to search for
average hits (i.e. the average of the two measurements of every
compound was calculated and the obtained result was supplied to
the hit selection procedure). The totals of hits retraced by the six
considered methods are presented in Table 1 and Supplementary
Tables S1—S12 (the detailed results).

Both proposed methods identiﬁed more potential hits (100 for
MEA and 115 for PMP) than the organizers of the McMaster

Table 1. Number of hits selected by the six data correction methods for the
McMaster Test dataset

 

Data correction method Number of hits

 

No-correction 96
B-score 186
Matrix Error Amendment (MEA) 100
Partial Mean Polish (PMP) 115
Well Correction + MEA 109
Well Correction + PMP 109

 

The hit selection threshold of “72.29SD was used.

competition (i.e. 96 hits for the uncorrected dataset), while rejecting
a few of the original hits as false positives. The MEA method
found 8 extra hits, while rejecting 4 of the original hits as false
positives. The PMP method extended the set of original hits with
24 new hits, while rejecting only 5 of them. In contrast, the B-score
method rejected 28 original hits, and provided 118 new potential
hits (according to our simulation results, many of those new hits
can be in fact false positives). The total overlap of all the six
considered methods consisted in 55 consensus average hits that
could be recommended for further testing including the structure-
activity relationships (SARs) analysis and various clinical trials. As
shows the example of the consensus hits set of the McMaster Test
assay [see Elowe et al. (2005) or Table 9sm in Makarenkov et al.
(2007)], consensus hits can also contain an important percentage of
false negatives and false positives. The consensus hits list of this
assay, which included 42 hit compounds in total, comprised only
14 of 26 hit compounds conﬁrmed by the SAR analysis conducted
by the McMaster competition organizers (i.e. 12 of 26 conﬁrmed
hits were false negatives and 28 of 42 consensus hits were false
positives). Thus, SAR investigations should be always conducted
in conjunction with data correction and hit selection techniques to
conﬁrm the selected hits.

It is worth also noting that MEA and PMP agreed on most of
the hits they selected (i.e. 92 of the hits identiﬁed by MEA were
also detected by PMP). Furthermore, after the application of Well
Correction, the MEA and PMP methods provided an identical set of
109 hits. Figure 5 and Supplementary Tables 1S—12S present the hit
distribution surfaces (i.e. hit totals obtained for each well location
and computed over all plates of the given assay) of the Master Test
assay obtained for the hit selection thresholds [,L—SD and [,L—2.295D.

The consecutive application of two data correction methods:
Well Correction and MEA (Fig. 5i and j) or Well Correction
and PMP (Fig. 5k and I), allowed us to eliminate screen-speciﬁc
systematic error, ﬁrst, and plate-speciﬁc systematic error, second
(see also Supplementary Tables 9S to 12S). For instance, the
MEA and PMP hit distribution surfaces provide better ﬁts to the
corresponding plain surfaces (which represent a perfect uniform
distribution of the assay hits across all well locations) when Well
Correction is applied beforehand (Fig. 5i and k). After the application
of Well Correction, the hit distribution surface X2 goodness-of-
ﬁt statistic for the hit selection thresholds [,L—SD decreased from
1178.53 (Fig. 5e and Supplementary Table S5) to 203.18 for MEA
(Fig. 5i and Supplementary Table 9S) and from 994.27 (Fig. 5g
and Supplementary Table 7S) to 198.68 for PMP (Fig. 5k and
Supplementary Table 11S).

 

1 780

112 /3.10's[sumo[pJOJXO'sorJBHJJOJurorq/j:duq 11101} papeolumoq

9103 ‘Og isnﬁnv uo ::

Correction of experimental screening data

 

 

(a) (b)
E E
ta E
E a
E E
2 z

(0} (d)
In 3
E E
3 E
.3 3
E E
Z 2

(a) {1'}

m
E s
"6 ‘6
a ‘6
s a
g i

(9} (h)
E E
‘5 a
E E
E E
2 2

(i) (ii
In 3
E E
s "E
E a
E E
Z 2

(It) {I}

g .2
.E .E
‘o E
E E
3 3
Z Z

   

Fig. 5. Hit distribution surfaces of the McMaster Test dataset for the hit
selection thresholds MisD (cases a, c, e, g, i and k) and 11.72.29SD (cases
b, d, f, h, j and 1) obtained for: the raw (i.e. uncorrected) data (a, b), and the
data corrected by B-score (c, (1), MBA (e, f), PMP (g, h), Well Correction +
MEA (i, j) and Well Correction + PMP (k, l)

4 CONCLUSION

We described two new methods, called MEA and PMP, allowing
for elimination of plate-speciﬁc systematic error from experimental
HTS data. Both methods rely on the prior information concerning
the location of the rows and columns of the given plate affected
by systematic bias. Such information can be obtained by using the
methodology described in Dragiev et al. (2011).

We conducted a simulation study with different HTS plate sizes,
hit percentages and systematic error magnitudes. In this study, the
MEA and PMP methods were compared with the B-score (Brideau
et al., 2003) and no-correction strategies. Both new methods always
outperformed the B-score and no-correction procedures when the
number of the plate’s rows and columns affected by systematic
error was low (Figs 2—4). In the simulations where the number of
rows and columns affected by systematic error could reach 50%
of the plate’s total number of rows and columns (Figs 15—35), the
MEA and PMP methods generally yielded better results than B-
score when the hit percentage was under 3% (in a typical HTS
campaign the hit percentage is usually under 1%) or when the
level of systematic error was under 1.SSD. The B-score method
showed a more stable behavior than MEA and PMP only when
the number of rows and columns affected by systematic error, hit
percentage and systematic error variance were high (mainly due
to a mediocre performance of the t-test in this case). MEA was
generally the best method for correcting systematic error within 96-
well plates, whereas PMP performed better for 384 and 1536-well
plates.

The analysis of the McMaster Data Mining and Docking
Competition Test assay (Elowe et al., 2005) showed that the
new methods can be also applied in the combination with the
Well Correction technique (Makarenkov et al., 2007) aiming to
remove screen-speciﬁc systematic error. Hence, a general data
correction phase in HTS, permitting for the elimination of both
screen- and plate-speciﬁc systematic biases, can be conducted in
the following way:

(1) Normalize the raw measurements using Percent of control,
Normalized percent inhibition or Z-score transformation. This
normalization step can be carried out either on a plate-by-
plate basis or for all assay measurements together (i.e. when
all plates have been processed under the same experimental
conditions);

(2) Perform the t-test or X2 goodness-of—ﬁt test on the hit
distribution surface for the selected hit selection threshold; if
systematic error is detected then carry out the Well Correction
method;

(3) Perform the t-test or X2 goodness-of—ﬁt test on each
individual plate of the assay to identify its rows and columns
affected by systematic error as well as the error locations;

(4) For all plates where systematic error is detected: Correct the
plate measurements by carrying out the PMP or MEA method
(or, alternatively, the B-score procedure).

In this study, we addressed the issue of the commonly
considered additive systematic artifact that can be described using
Equation (17). It is worth noting that the multiplicative type of
systematic bias affecting well (i, j) of plate p and deﬁned by

 

1781

112 /3.IO'S[BHmO[p.IOJXO'SOIJBLUJOJIIIOIq/jIdllq morj pepeorumoq

9IOZ ‘OE ISUEHV Ho ::

RDragiev et al.

 

Equation (18):

I — .. ..
xijp ‘le1? X erIp X ecrp “amt/17’ (18)

can be also treated using the proposed methods. Whereas the MEA
method should undergo substantial changes to treat multiplicative
type of systematic error because the linear equations systems
(4)—(7) and (8) will be transformed into the corresponding nonlinear
equations systems, the PMP method can be easily adapted for the
identiﬁcation and correction of multiplicative bias by adding the
following equations: 22,, = [in //,L and 236]. = MC], //,L to Step 2, and then
xrii =xrij/érl. and JCin =xl-Cf ﬂag], to Step 3, of the method instead of
the corresponding equations containing the subtraction sign.

A version of the PMP method, in which a median is used instead
of the mean, could be viewed as a direct extension of the well-known
median polish algorithm (Tukey, 1977), applicable in the situations
when the exact error location is known (the traditional MP assumes
that systematic error is present in all rows and columns of the given
matrix). Another advantage of the PMP method over MP and its
B-score analog is that our method does not reduce the original data
to residuals, keeping the corrected data on the same scale with the
original ones and not modifying the unbiased data at all. Moreover,
both of the proposed methods could be interesting in general, from
the statistical point of view, and applied as data correction methods
in any other ﬁeld.

A new program implementing the two data correction methods
described in this article, and including also the Well Correction,
B-score and Z-score procedures, is freely available at the following
URL: http://www.info2.uqam.ca/~makarenkov_v/HTS_Helper.

Funding: This work was supported by the Natural Sciences and
Engineering Research Council of Canada [NSERC-249644-2011]

and individual stipend to Plamen Dragiev given by the Nature and
Technologies Research Funds of Quebec [FQRNT].

REFERENCES

Brideau,C. et al. (2003) Improved statistical methods for hit selection in HTS. J. Biomol.
Screen, 8, 634$47.

CarralotJP. et al. (2012) A novel speciﬁc edge effect correction method for RNA
interference screenings. Bioinformatics, 28, 2617268.

Dragiev,P. et al. (2011) Systematic error detection in experimental high-throughput
screening. BM C Bioinformatics, 12, 25.

Elowe,N.H. et al. (2005) Experimental screening of dihydrofolate reductase yields a
‘Test Set’ of 50,000 small molecules for a computational data-mining and docking
competition. J. Biomol. Screen, 10, 653$57.

Helm,J.S. et al. (2003) Identiﬁcation of active-site inhibitors of MurG using a
generalizable, high-throughput glycosyltrans-ferase screen. J. Am. Chem. Soc., 125,
11168711169.

Heyse,S. (2002) Comprehensive analysis of high-throughput screening data.
Proceedings of SPIE; 2002; Bellingham, WA. 2002, 4626 pp. 535547.

Kevorkov,D. and Makarenkov,V. (2005) Statistical analysis of systematic errors in HTS.
J. Biomol. Screen, 10, 5577567.

Makarenkov,V. et al. (2006) HTS-Corrector: new application for statistical analysis and
correction of experimental data. Bioinformatics, 22, 140871409.

Makarenkov,V. et al. (2007) Statistical analysis of systematic errors in HTS.
Bioinformatics, 23, 164871657.

Malo,N. et al. (2006) Statistical practice in high-throughput screening data analysis.
Nat. Biotechnol., 24, 1677175.

Malo,N. et al. (2010) Experimental design and statistical methods for improved hit
detection in high-throughput screening. J. Biomol. Screen, 15, 9901000.

Shun,T.Y. et al. (2011) Identifying actives from HTS data sets: practical approaches
for the selection of an appropriate HTS data processing method and quality control
review. J. Biomol. Screen, 16, 1714.

Tukey,J.W. (1977) Exploratory Data Analysis. Addison Wesley, Cambridge, MA.

Zhang,X.D. (2008) Novel analytic criteria and effective plate designs for quality control
in genome-scale RNAi screens. J. Biomol. Screen, 13, 3637377.

Zhang,J. et al. (1999) A simple statistical parameter for use in evaluation and validation
of high-throughput screening assays. J. Biomol. Screen, 4, 67773.

 

1 782

112 jglo'S[1211,1110prOJXO'SOIJBLUJOJIIIOIq/jIdllq 01011 papeo1umoq

9103 ‘0g isnﬁnv uo ::

