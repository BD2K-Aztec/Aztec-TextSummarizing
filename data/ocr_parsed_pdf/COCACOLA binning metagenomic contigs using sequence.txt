Bioinformatics, 2016, 1—8

doi: 10.1093/bioinformatics/btw290

Advance Access Publication Date: 2 June 2016
Original Paper

 

 

Genome analysis

COCACOLA: binning metagenomic contigs
using sequence COmposition, read CoverAge,
CO-alignment and paired-end read LinkAge
Yang Young Lu1, Ting Chen1'2, Jed A. Fuhrman3 and Fengzhu Sun1'4'*

1Molecular and Computational Biology Program, Department of Biological Sciences, University of Southern California,
Los Angeles, CA 90089, USA, 2Centerfor Synthetic and Systems Biology, TNLlST, Beijing 100084, China, 3Department of
Biological Sciences and Wrigley Institute for Environmental Studies, University of Southern California, Los Angeles, CA
90089, USA and 4Centerfor Computational Systems Biology, Fudan University, Shanghai 200433, China

*To whom correspondence should be addressed.
Associate Editor: Cenk Sahinalp

Received on April 11, 2016; revised on April 25,2016; accepted on April 29, 2016

Abstract

Motivation: The advent of next—generation sequencing technologies enables researchers to se—
quence complex microbial communities directly from the environment. Because assembly typic—
ally produces only genome fragments, also known as contigs, instead of an entire genome, it is
crucial to group them into operational taxonomic units (OTUs) for further taxonomic profiling and
down—streaming functional analysis. OTU clustering is also referred to as binning. We present
COCACOLA, a general framework automatically bin contigs into OTUs based on sequence compos—
ition and coverage across multiple samples.

Results: The effectiveness of COCACOLA is demonstrated in both simulated and real datasets in com—
parison with state—of—art binning approaches such as CONCOCT, GroopM, MaxBin and MetaBAT. The
superior performance of COCACOLA relies on two aspects. One is using L1 distance instead of
Euclidean distance for better taxonomic identification during initialization. More importantly,
COCACOLA takes advantage of both hard clustering and soft clustering by sparsity regularization. In
addition, the COCACOLA framework seamlessly embraces customized knowledge to facilitate binning
accuracy. In our study, we have investigated two types of additional knowledge, the co—alignment to
reference genomes and linkage of contigs provided by paired—end reads, as well as the ensemble of
both. We find that both co—alignment and linkage information further improve binning in the majority
of cases. COCACOLA is scalable and fasterthan CONCOCT, GroopM, MaxBin and MetaBAT.
Availability and implementation: The software is available at https://github.com/younglululu/
COCACOLA.

Contact: fsun@usc.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction . . . . . . . . . .
1n51ghts into complex microbial communities even including spec1es

Metagenomic studies aim to understand microbial communities dir- with low abundance (Albertsen et (11., 2013). To further investigate
ectly from environmental samples without cultivating member spe- the taxonomic structure of microbial samples, assembled sequence
cies (Riesenfeld et (11., 2004). The next-generation sequencing fragments, also known as contigs, need be grouped into operational
technologies allow biologists to extract genomic data with unprece- taxonomic units (OTUs) that ultimately represent genomes or
dented high resolution and sufficient sequence depth, offering significant parts of genomes. OTU clustering is also called binning

© The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com l

/310‘sleumo[p10}xo‘sopeuuogutotq/ﬁdnq

Y. Y.Lu et al.

 

(or genomic binning), serving as the key step toward taxonomic
profiling and downstream functional analysis. Therefore, accurate
binning of the contigs is an essential problem in metagenomic
studies.

Despite extensive studies, accurate binning of contigs remains
challenging for several major reasons, including chimeric assemblies
owing to repetitive sequence regions within or across genomes,
sequencing errors or artifacts, strain—level variation within the same
species, etc. (Alneberg et al., 2014; Maude et al., 2012) The cur—
rently available binning methods can be broadly categorized into
classification and clustering approaches. Classification approaches
are ‘taxonomy dependent”, that is, reference databases are needed
for the assignment from contigs or reads to meaningful taxons. The
classification is either based on homology owing to sequence iden—
tity, or genomic signatures such as oligonucleotide composition pat—
terns and taxonomic clades. Homology—based methods include
MEGAN (Huson et al., 2007), which assigns reads to the lowest
common taxonomic ancestor. Examples of genomic signature—based
methods include PhyloPythia (McHardy et al., 2007) and Kraken
(Wood and Salzberg, 2014), which are composition—based classifiers
and naive Bayesian classifier (Rosen et al., 2011), a clade—specific
approach. In addition, hybrid methods are available to take both
alignment and composition—based strategy into consideration, such
as PhymmBL (Brady and Salzberg, 2009) and SPHINX
(Mohammed et al., 2011).

In comparison, clustering approaches are ‘taxonomy independ—
ent’, that is, no additional reference databases or taxonomic infor—
mation is needed. These approaches require similarity
measurements from GC content, tetra—mer composition (Albertsen
et al., 2013; Chatterji et al., 2008; Yang et al., 2010) or Interpolated
Markov Models (Kelley and Salzberg, 2010), to contig coverage
profile (Baran and Halperin, 2012; Wu and Ye, 2011).

Recently, several methods have been developed to bin contigs
using the coverage profiles of the contigs across multiple metage—
nomic samples (Albertsen et al., 2013; Alneberg et al., 2014; Carr
et al., 2013; Imelfort et al., 2014; Kang et al., 2015; Nielsen et al.,
2014; Wu et al., 2015). Here the coverage of a contig is defined as
the fraction of reads mapped to the contig in a sample. The idea is
that if two contigs are from the same genome, their coverage profiles
across multiple samples should be highly correlated. These methods
can be further improved by integrating coverage profiles with the se—
quence tetra—mer composition of the contigs (Alneberg et al., 2014;
Imelfort et al., 2014; Kang et al., 2015). Among these methods,
GroopM (Imelfort et al., 2014) is advantageous in its visualized and
interactive pipeline. On one hand, it is flexible, allowing users to
merge and split bins under expert intervention. On the other hand,
in the absence of expert intervention, the automatic binning results
of GroopM is not as satisfactory as CONCOCT (Alneberg et al.,
2014). CONCOCT (Alneberg et al., 2014) makes use of the
Gaussian mixture model (GMM) to cluster contigs into bins. Also,
CONCOCT provides a mechanism to automatically determine the
optimal OTU number by variational Bayesian model selection
(Corduneanu and Bishop, 2001). MetaBAT (Kang et al., 2015) cal—
culates integrated distance for pairwise contigs and then clusters
contigs iteratively by modified K—medoids algorithm. And MaxBin
(Wu et al., 2015 ) compares the distributions of distances between
and within the same genomes.

In this article we present COCACOLA, a general framework for
contig binning incorporating sequence @mposition, goverAge,
@—alignment and paired—end reads LinkAge across multiple sam—
ples. By default, COCACOLA uses sequence composition and

coverage across multiple samples for binning. Compared with recent
approaches such as CONCOCT, GroopM, MaxBin and MetaBAT,
COCACOLA performs better in three aspects. First, COCACOLA
reveals superiority with respect to precision, recall and Adjusted
Rand Index (ARI). Second, COCACOLA shows better robustness in
the case of varying number of samples. COCACOLA is scalable and
faster than CONCOCT, GroopM, MaxBin and MetaBAT.

In addition, the COCACOLA framework seamlessly embraces
customized knowledge to facilitate binning accuracy. In our study,
we have investigated two types of knowledge, in particular, the co—
alignment to reference genomes and linkage between contigs pro—
vided by paired—end reads. We find that both co—alignment and link—
age information facilitate better binning performance in the
majority of the cases.

2 Materials and methods

2.1 Problem formulation

A microbial community is composed of a set of OTUs at different
abundance levels, and our objective is to put contigs into the gen—
omic OTU bins from which they were originally derived. OTUs are
expected to be disentangled based on contigs comprising either the
discriminative abundance or dissimilarity among sequences in terms
of l—mer composition. The rationale of binning contigs into OTUs
relies on the underlying assumption that contigs originating from
the same OTU share similar relative abundance as well as sequence
composition.

Formally, we encode the abundance and composition of the k—th
OTU by a (M + V) dimensional feature vector, Wk, k : 1,2, - - - ,K,
where M is the number of samples, V is the number of distinct l—mers
and K is the total OTU number. Specifically, ka represents the
abundance of the k—th OTU in the m—th sample, m : 1, 2, - - - ,M, re—
spectively. And WMHA;z stands for the l—mer relative frequency com—
position of the k—th OTU, U : 1, 2, - - - , V. Similarly, the feature
vector of the n—th contig is denoted as X”. Let H)“, be the indicator
function describing whether the n—th contig belongs to the k—th OTU,
i.e. [HIM : 1 means the n—th contig originating from the k—th OTU and
HIM : 0 otherwise. Therefore, X.” can be represented as:

X41: 1HIlrt‘X/»1‘I' HZnW»2‘I'""I'IHIknW»K7 "21727"'7N 

where N is the number of contigs. Equation (1) can be further writ—
ten into the matrix form:

XzWH s.t. W20, He{0,1}KXN,|IH.,,|IO:1 (2)

where W : (W4, W2, - - - , WK) is a (M + V) X K non—negative ma—
trix with each column encoding the feature vector of the correspond—
ing OTU. And [HI : ( H.1,H.2, - - - ,IHIN) is a K X N binary matrix
with each column encoding the indicator function of the corres—
ponding contig. IIHnIIo : 25:1 Him : 1 ensures the n—th contig be—
longs exclusively to only one particular OTU.

The matrices W and [HI are obtained by minimizing a certain ob—
jective function. In this article we use Frobenius norm, commonly
known as the sum of squared error:

. 2 K><N 7
are ngjgo IIX - WHIIF S-t- H 6 {0,1} ,IIlelo — 1 (3)

Note that Equation (3) is NP—hard by formulation as an integer
programming problem with an exponential number of feasible solu—
tions (Jiang et al., 2014). A common procedure to tackle Equation
(3) relaxes binary constraint of [HI with numerical values. Hence

[310‘SIEIIIHOIPJOJXO‘SOQEIIIJOJIIIOIQ/[Idnq

COCACOLA

 

Equation (3) is reformulated as the following minimization
problem:

. 2
_ . , , >
argwiprli IIX WHIIIA st W,H _ 0 (4)

where H serves as a coefficient matrix instead of an indicator matrix.
In the scenario of Equation (4), Wk, the feature vector of the k—th
OTU represents the centroid of the k—th cluster. Meanwhile, each con—
tig X.” is approximated by a weighted mixture of clusters, where the
weights are encoded in H”. In other words, relaxation of binary con—
straint makes the interpretation from hard clustering to soft clustering,
where hard clustering means that a contig can be assigned to one OTU
only, while soft clustering allows a contig to be assigned to multiple
OTUs. It has been observed that by imposing sparsity on each column
of H, the hard clustering behavior can be facilitated (Kim and Park,
2008). Therefore, Equation (4) is further modified through the Sparse
Non—negative Matrix Factorization form (Kim and Park, 2008):

N
. 2 2
argwlfggo IIX — WHIP +  11H"). (5)
where  - H1 indicates L1—norm. Owing to non—negativity of H,

|IH.,,|)1 stands for the column sum of the n—th column vector of H.
The parameter or > 0 controls the trade—off between approximation
accuracy and the sparseness of H. Namely, larger or implies stronger
sparsity while smaller value ensures better approximation accuracy.

2.2 Feature matrix representation of contigs

Similar to CONCOCT (Alneberg et al., 2014), each contig longer
than 1000 bp is represented by a (M + V) dimensional column fea—
ture vector including M dimensional coverage and V dimensional
tetra—mer composition. The coverage denotes the average number of
mapped reads per base pair from each of M different samples. While
the tetra—mer composition denotes the tetra—mer frequency for the
contig itself plus its reverse complement. Owing to palindromic
tetra—mers, V : 136.

Adopting the notation of CONCOCT (Alneberg et al., 2014),
the coverage of all the N contigs is represented by an N X M matrix
Y, where N is the number of contigs of interest and Yum indicates
the coverage of the n—th contig from the m—th sample. Whereas the
tetra—mer composition of the N contigs are represented by an N X V
matrix Z where Z", indicates the count of U-tl’l tetra—mer found in
the n—th contig. Before normalization, a pseudo—count is added to
each entry of the coverage matrix Y and composition matrix Z, re—
spectively. As for the coverage, a small value is added, i.e.
Yim : Yum + 100/Ln, analogous to a single read aligned to each
contig as prior, where Ln is the length of the n—th contig. As for the
composition, a single count is simply added, i.e. Z)“, : Zm/ + 1.

The coverage matrix Y is first column—wise normalized (i.e. nor—
malization within each individual sample), followed by row—wise
normalization (i.e. normalization across M samples) to obtain cover—
age profile p. The row—wise normalization aims to mitigate sequenc—
ing efficiency heterogeneity among contigs.

I ll
Yum p i Y nm
N I m" _ M II
271:1 Yum Zm:1 Y nm

The composition matrix Z is row—wise normalized for each con—

Y’im = (6)

tig (i.e. normalization across M tetra—mer count) to obtain compos—
ition profile q:
I
Z711!

— (7)
21:]:1 Z/m/

qm/ :

The feature matrix of contigs is denoted as X : [p qIT, as the
combination of coverage profile 17 and composition profile q. To be
specific, X is a (M + V) X N non—negative matrix of which each col—
umn represents the feature vector of a particular contig.

2.3 Incorporating additional knowledge into binning

We consider two types of additional knowledge that may enhance
the binning accuracy (Basu et al., 2008). One option is paired—end
reads linkage. Specifically, a high number of links connecting two
contigs imply high possibility that they belong to the same OTU.
Because the linkage may be erroneous owing to the existence of chi—
meric sequences, we keep linkages that are reported through mul—
tiple samples. The other option is co—alignment to reference
genomes. That is, two contigs mapped to the same reference genome
support the evidence that they belong to the same OTU.

We encode additional knowledge by an undirected network in
the form of a non—negative weight matrix A, Where Am: quantifies
the confidence level we believe the n—th contig and the n’—th contig
to be clustered together. Based on the aforementioned matrix A, a
network regularization item is introduced to measure the coherence
of binning (Cai et al., 201 1):

2
Am, : Tr(HLHT) (8)

 

 

N

where Tr(-) indicates the matrix trace, the sum of items along the di—
agonal. D denotes the diagonal matrix whose entries are column
sums (or row sums owing to symmetry) of A, i.e. Dm, : 25:1AW.
The Laplacian matrix (Chung, 1997) is defined as L : D — A. With
convention we use normalized Laplacian matrix instead, that is,
E : D‘l/ZLD_1/2 : I — D‘l/ZAD_1/2 éI — A. By incorporating
the network regularization in Equation (8), the objective function in
Equation (5) changes to the following form:

2
1 + [i Tr(H£HT) (9)

 

 

N
. 2
arg WI/négo |IX —  + or; 

where the parameter I} > 0 controls the trade—off of belief between
unsupervised binning and additional knowledge. Namely, large I} in—
dicates strong confidence on the additional knowledge. Conversely,
small It puts more weight on the data.

To use multiple additional knowledge sources together, a com—
bined Laplacian matrix is constructed as a weighted average of indi—
vidual Laplacian matrices Z : (2d xdﬁd)/(Zd ad) where each
positive weight ad reflects the contribution of the corresponding in—
formation. For simplicity, weights are treated equally in the article.

2.4 Optimization by alternating non—negative least
squares

Among comprehensive algorithms to solve Equation (9), the multi—
plicative updating approach (Lee and Seung, 1999) is most widely
used. Despite its simplicity in implementation, slow convergence is
of high concern. This article adopts a more efficient algorithm with
provable convergence called alternating non—negative least squares
(ANLS) (Kim and Park, 2008). ANLS iteratively handles two non—
negative least square subproblems in Equation (10) until conver—
gence. The ANLS algorithm is summarized in Algorithm 1.

2
1 + p Tr(H£HT) (103)

 

 

N
H ‘ X— z  .
<—argIPrII§)1|I WHIIf—I-OC; H”

[310'sp2umofp105xo'sopeuHOJIItotq/ﬁdnq

Y. Y.Lu et al.

 

(10b)

2
F

 

W <— arg min )XT — HTWTH
W20

We solve Equation (10a) by block coordinate descent, that is, we
divide Equation (10a) into N subproblems and minimize the object—
ive function with respect to each subproblem at a time while keeping
the rest fixed:

arg 131g), Ix.” — Wm): + ullHnllf +rH££Hm n 2 1. - - - .N
2 2 N
: argglngb IIXn _ WHnIIz ‘I'  ‘I'  _ 2: Ann’Hgl/d)
m, n’:1

N

. 2

: argglngb IIXn _  ‘I'  ‘I' I}  _ E Ann/HﬁijIIz
'"’ n/:1

(11)

where the matrix HOId denotes the value of H obtained from the pre—
vious iteration. Following Jacobi updating rule, we combine N sub—
problems in Equation (1 1) into the matrix form:

 

 

 

 

X W 2

argmin OWN — ﬁeixx H (12)
H20 01d .
WH A WIK 1-

where 01XN is a N dimensional row vector of all 0, e1XK is a K di—
mensional row vector of all 1.

2.5 Initialization of Wand H

Note that we need to initialize W and H as the input to Algorithm 1.
A good initialization not only enhances the accuracy of the solution,
but facilitates fast convergence to a better local minima as well
(Langville et al., 2006). We initialize W and H by K—means cluster—
ing, namely, W is set to be the K—means centroid of X with each col—
umn Wk corresponding to the feature vector of the k—th centroid.
Meanwhile, H is set to be the indicator matrix encoding the cluster
assignment.

The distance measurement contributes crucially to the success of
binning. Ideally, a proper distance measurement exhibits more dis—
tinguishable taxonomic difference. The traditional K—means ap—
proach takes Euclidean distance as default measurement to quantify
closeness. However, as for the coverage profile, Su et al. (2012)
shows L1 distance produces more reasonable binning results than
Euclidean and correlation—based distances. As for the composition
profile, L1 distance also reveals superiority over Euclidean and co—
sine distances (Liao et al., 2014). Therefore, our method adopts K—
means clustering with L1 distance. Once preliminary K—means clus—
tering is achieved, we eliminate suspicious clusters with few contigs
using the bottom—up L Method (Salvador and Chan, 2004).
Performance comparisons with respect to L1 and Euclidean distance
are given in the supplementary material.

2.6 Parameter tuning

We have two parameters (01,13) to be tuned in our algorithm.
Traditional cross—validation—like strategy demands searching
through a two dimensional grid of candidate values, which is com—
putationally unaffordable in the case of large datasets. Instead, we
first search a good marginal or value by fixing I} : 0. After that, a
one—dimensional search is performed on a range of candidate I} val—
ues while keeping or fixed.

In our implementation, when I} : 0, or is approximated by the
regression of the corresponding Lagrange Multipliers from N con—
strained problems argmianEoHX —  with constraint
 — 1)2 : 0, where n : 1, - - - ,N. The resulting or is denoted

 

Algorithm 1. Optimization by ANLS

 

Input: feature matrix X E RWHVVN, initial basis matrix
W E RWTWXK and coefﬁcient matrix H E RKXN, tol—
erance threshold 8, maximum iteration threshold T

1: repeat

2 Obtain optimal H of Equation (10a) by ﬁxing W

3: Obtain optimal W of Equation (10b) by ﬁxing H

4: until A particular stopping criterion involving a is satisﬁed

or iteration number exceeds T

Output: W,H

 

 

 

by 51*. Then we run the algorithm with respect to each candidate I}
and fixed or : 51*, resulting in corresponding binning results with
various cluster number. Notice that traditional internal cluster valid—
ity indices are only applicable on the basis of fixed cluster number
scenario (Wiwie et al., 2015), such as Sum of Square Error and
Davies—Bouldin index (Davies and Bouldin, 1979). To be specific,
the indices have the tendency toward monotonically increase or de—
crease as the cluster number increases (Liu et al., 2013). We tackle
the impact of monotonicity by adopting TSS (Tang—Sun—Sun) mini—
mization index (Tang et al., 2005), that is, we choose the candidate
I} with minimum TSS value, recorded as 13*. Then we can solve
Equation (9) by using (01*, 13*) as selected regularization parameters.

2.7 Post—processing

The resulting binning obtained from Algorithm 1 may contain clus—
ters that are closely mixed to each other. Therefore, we define separ-
able conductance as an effective measurement to diagnose the
coupling closeness of pairwise clusters, so as to determine whether
to merge them. Namely, we consider each cluster as having a spher—
ical scope centered at its centroid. To be robust against outliers, the
radius is chosen as the third quartile among the intra—cluster dis—
tances. The separable conductance between the c1—th cluster and the
cz—th cluster, sep(c1,c2), is defined as the number of contigs from
the c1—th cluster also included in the spherical scope of the cz—th clus—
ter, divided by the smaller cluster size of two. Intuitively, the separ-
able conductance exploits the overlap between two clusters. The
procedure of post—processing works as follows: we keep picking the
pair of clusters with maximum separable conductance and merge
them until it fails to exceed a certain threshold. The threshold is set
to be 1 in this study.

2.8 Datasets

Alneberg et al. (2014) simulated a ‘species’ dataset and another
‘strain’ dataset. Both simulated datasets were constructed based on
16S rRNA samples originated from the Human Microbiome Project
(HMP) (Consortium et al., 2012). The relative abundance profiles of
the different species/strains for the simulation were based on the
HMP samples as well.

The simulated ‘species’ dataset consisted of 101 different species
across 96 samples. It aimed to test the ability of CONCOCT to clus—
ter contigs in complex populations (Alneberg et al., 2014). The spe—
cies were approximated by the OTUs from HMP with >3%
sequence differences. Each species was guaranteed to appear in at
least 20 samples. A total of 37 628 contigs remain for binning after
co—assembly and filtering.

The simulated ‘strain’ dataset aimed to test the ability of
CONCOCT to cluster contigs at different levels of taxonomic

[310'sp2umofp105xo'sopeuHOJIItotq/ﬁdnq

Alneberg at al., 2014

Alneberg at al., 2014
Sharon at al.,
2013

Ijaz and Quince, 2013

Qin at al., 2010
Kang at al., 2015

supplementary material

Alneberg at al., 2014 Imelfort at al.,
2014 Kang at al., 2015

Precision Recall

Precision Recall

 

tary material

Precision

Precision

Recall

Recall

 

Nielsen at al., 2014

Figure

1(a)

supplemen

/810's112umo[p10}xo"souBLuJOJutotqﬂ:duq

n with Alignment

Recall with Alignment
ARI with A gnment

Recall wrt Alignment

Recallw h Linkage
ARI with

a)
m
m

x

E

4

.i:
B
c:
o
u
9

D.

Precision witho

n with Alignment + Linkage

Recall with Alignment + Linkage
ARI with A gnment +

 

utAIignment + Linkage ' Alignment + Linkage ' ut Alignment + Linkage

COCACOLA

 

four cases, the ARI is improved noticeably in five cases and
decreased in three cases.

In terms of the ensemble of co—alignment and linkage, as de—
picted in Figure 2(g—i), the precision is improved noticeably in 10
cases and decreased in 3 cases, the recall is improved noticeably in
13 cases and no case suffers decreasing, the ARI is improved notice—
ably in 11 cases and decreased in 1 cases.

We have the following conclusions: (i) When there are sufficient
number of samples, the contributions from additional knowledge di—
minish. (ii) Additional knowledge such as co—alignment and linkage
information facilitate better overall performance in the majority of
cases. (iii) Ensemble of both information performs more stable than
individual information.

3.3 Performance on real datasets

Applying COCACOLA to the ‘Sharon’ dataset (Figure 1(c)), given ini—
tial choice of K : 30, the precision, recall and ARI reach 0.9889,
0.9759 and 0.9670, respectively. In comparison, CONCOCT,
GroopM, MaxBin and MetaBAT achieve 0.9801, 0.9820, 0.7077
and 0.9705 in terms of precision, 0.9606, 0.9147, 0.9767 and 0.8344
in terms of recall, 0.9600, 0.9126, 0.5639 and 0.8634 in terms of
ARI, respectively. COCACOLA identifies six OTUs corresponding to
six reported genomes. In comparison, CONCOCT, GroopM,
MaxBin and MetaBAT identify 14, 24, 5 and 11 OTUs, respectively.

Next, we investigate the performance improvement of
COCACOLA after incorporating additional knowledge. We use
linkage information only because it is circular to use TAXAassign
script (Ijaz and Quince, 2013) on both alignment and labeling.
COCACOLA still identifies six OTUs, with the precision, recall and
ARI reaching 0.9923, 0.9797 and 0.9743, slightly outperforms the
case without additional knowledge.

Applying COCACOLA to the ‘MetaHIT’ dataset (Figure 1(d)),
given initial choice of K : 100, the precision, recall and ARI reach
0.9082, 0.8272 and 0.7717, respectively. In comparison,
CONCOCT, GroopM, MaxBin and MetaBAT achieve 0.8933,
0.5247, 0.6655 and 0.5738 in terms of precision, 0.7901, 0.6843,
0.8228 and 0.7397 in terms of recall, 0.7518, 0.3757, 0.5866 and
0.1088 in terms of ARI, respectively.

Next we investigate the performance improvement of
COCACOLA after incorporating linkage information. The perform—
ance is further slightly improved from 0.9082 to 0.9084 in terms of
precision, from 0.8272 to 0.8350 in terms of recall and from 0.7717
to 0.7844 in terms of ARI, respectively.

3.4 Running time of COCACOLA, CONCOCT, GroopM,
MaxBin and MetaBAT

COCACOLA shares the same data parsing pipeline as CONCOCT
and differs only in the binning step, whereas GroopM uses its own
workflow. It is reasonable to compare running time of binning dir—

ectly between COCACOLA and CONCOCT. To bring GroopM

into context, we take into account the stages related to binning and
therefore exclude the data parse stage. As for MaxBin and
MetaBAT we simply pre—calculate the abundance and depth infor—
mation. MaxBin involves multi—threaded parameter, which is set as
the number of cores. All of five methods run on the 12—cores and
60GB—RAM computing platform provided by the USC High
Performance Computing Cluster. The comparison is conducted on
both the simulated datasets and real datasets (Table 1). We conclude
that COCACOLA runs faster than CONCOCT, GroopM, MaxBin
and MetaBAT.

4 Discussion

In this article, we develop a general framework to bin metagenomic
contigs using sequence composition and coverage across multiple
samples. Our approach, COCACOLA, outperforms state—of—art bin—
ning approaches CONCOCT (Alneberg et al., 2014), GroopM
(Imelfort et al., 2014), MaxBin (Wu et al., 2015) and MetaBAT
(Kang et al., 2015 ) on both simulated and real datasets.

The superior performance of COCACOLA relies on several as—
pects. First, initialization plays an important role in binning accur—
acy. Second, COCACOLA uses L1 distance instead of Euclidean
distance for better taxonomic identification. Third, COCACOLA
takes advantage of both hard clustering and soft clustering.
Specifically, soft clustering (such as the GMM used by CONCOCT)
allows a contig to be assigned probabilistically to multiple OTUs,
hence gains more robust results in general in comparison with hard
clustering (such as the Hough partitioning used by GroopM).
However, in complex environmental samples with strain—level vari—
ations, the corresponding OTUs are closely intertwined. Whereas
soft clustering in turn further mixes the OTUs up and thus deterior—
ates clustering performance. COCACOLA obtains better trade—off
between hard clustering and soft clustering by exploiting sparsity.

However, we notice that binning metagenomic contigs remains
challenging when the number of samples is small, regardless of using
COCACOLA, CONCOCT, GroopM, MaxBin or MetaBAT. With
small number of metagenomic samples, the relationship between the
contigs cannot be accurately inferred based on the relationship be—
tween the abundance profiles. Therefore, future research needs to
study how to re—weight the contributions of abundance profiles and
composition profiles in unsupervised (Cai et al., 2010) or semi—
supervised (Zhao and Liu, 2007) scenario. Moreover, recent studies
suggest that Euclidean or L1 distance between l—mer frequencies do
not perform as well as alternative dissimilarity measurements such
as d; and dye”) (Wan et al., 2010) in comparing genome sequence.
However, the use of such measurements is computationally chal—
lenging, which needs further exploration.

The COCACOLA framework seamlessly embraces customized
knowledge to facilitate binning accuracy. In our study, we have
investigated two types of knowledge, in particular, the co—alignment
to reference genomes and linkage of contigs provided by paired—end

Table 1. Running Time of COCACOLA, CONCOCT, GroopM, MaxBin and MetaBAT

 

 

 

 

Dataset COCACOLA CONCOCT GroopM MaxBin MetaBAT

Time Speedup Time Speedup Time Speedup Time Speedup Time Speedup
‘5pecie5’ 1m41.505 1>< 17m14.715 10.2>< 1h57m285 69.4>< 49m48.525 29.4>< 4m16.145 2.5x
‘5train’ 10.945 1>< 1m10.995 6.5x 17mOO.465 93.3>< 9m54.805 54.4>< 2m31.525 13.9><
‘Sharon’ 13.225 1>< 25.115 1.9x 4m45.855 21.6>< 1m36.095 7.3>< 24.665 1.9><

‘MetaHIT’ 2m39. 125 1 x 20m20.905 7.7><

12m47.685 4.8x

2h20rn525 53.1 x 7m25.075 2.8x

 

ﬁlO'SIBHmOIpJOJXO'SOplZIIJJOJLIIOIQ/ﬂdnq

Y. Y.Lu et al.

 

reads. Even though the contributions from additional knowledge di—
minish when there are sufficient number of samples, they play an
important role in binning results when the number of samples is
small. In future studies, we intend to explore better customized prior
knowledge. one option is exploiting phylogenetic information in
taxonomic annotation (Purdom, 2011). Another option relies on
identifying functional annotation of contigs, including open reading
frames that are likely to encode proteins (Ye and Tang, 2009), or
co—abuudauce gene groups (Nielsen et al., 2014), etc. We have also
investigated the ensemble of both co—alignment and linkage know—
ledge, aud it shows more stable performance than individual infor—
mation. In future studies, we aim to find optimal weights (Tsuda
et al., 2005) instead of equal weights.

Acknowledgements

The authors thank anonymous referees for helpful comments on this work.
The research is partially supported by NSF DMS-1518001 and OCE 1136818.

Conﬂict of Interest: none declared.

References

Albertsen, M. et al. (2013) Genome sequences of rare, uncultured bacteria ob-
tained by differential coverage binning of multiple metagenomes. Nat.
Biotechnol, 31, 533—538.

Alneberg, J. et al. (2014) Binning metagenomic contigs by coverage and com-
position. Nat. Methods, 11, 1144—1146.

Baran, Y. and Halperin, E. (2012) Joint analysis of multiple metagenomic sam-
ples. PLOS Comput. Biol, 8, e1002373.

Basu, S. et al. (2008). Constrained Clustering: Advances in Algorithms,
Theory, and Applications. Data Mining and Knowledge Discovery Series.
Chapman 8C Hall/CRC Press, Boca Raton, Florida, USA.

Brady, A. and Salzberg, S.L. (2009) Phymm and PhymmBL: metagenomic
phylogenetic classiﬁcation with interpolated Markov models. Nat.
Methods, 6, 673—676.

Cai, D. et al. (2010). Unsupervised feature selection for multi-cluster data. In:
Proceedings of the 16th ACM SI GKDD International Conference on
Knowledge Discovery and Data Mining, Washington, DC, USA, pp. 333—342.

Cai, D. et al. (2011) Graph regularized nonnegative matrix factorization for
data representation. IEEE Trans. Pattern Anal. Mach. Intell, 33, 1548—15 60.

Carr, R. et al. (2013) Reconstructing the genomic content of microbiome taxa
through shotgun metagenomic deconvolution. PLoS Comput. Biol, 9, e1003292.

Chatterji, S. et al. (2008) Compostbin: a DNA composition—based algorithm
for binning environmental shotgun reads. Res. Comput. Mol. Biol, 17—28.

Chung, ER. (1997). Spectral Graph Theory, Vol. 92. American Mathematical
Society.

Consortium, H.M.P. et al. (2012) Structure, function and diversity of the
healthy human microbiome. Nature, 486, 207—214.

Corduneanu, A. and Bishop, C.M. (2001) Variational Bayesian model selec-
tion for mixture distributions. In: Artiﬁcial intelligence and Statistics 2001,
Key West, Florida, USA, pp. 27—34.

Davies, D.L. and Bouldin, D.W. (1979) A cluster separation measure. IEEE
Trans. Pattern Anal. Mach. Intell, 1, 224—227.

Huson, D.H. et al. (2007) MEGAN analysis of metagenomic data. Genome
Res., 17, 377—386.

Ijaz, U. and Quince, C. (2013). TAXAassign V0.4. https://github.com/umeri
jaz/taxaassign.

Imelfort, M. et al. (2014) GroopM: an automated tool for the recovery of
population genomes from related metagenomes. Peer], 2, e603.

Jiang, P. et al. (2014) A clustering approach to constrained binary matrix factor—
ization. In: Data Mining and Knowledge Discovery for Big Data, Springer-
Verlag, Berlin Heidelberg, pp. 281—303.

Kang, D.D. et al. (2015) MetaBAT, an efﬁcient tool for accurately reconstruct—
ing single genomes from complex microbial communities. Peer], 3, e1165.

Kelley, D.R. and Salzberg, S.L. (2010) Clustering metagenomic sequences
with interpolated Markov models. BMC Bioinformatics, 11, 544.

Kim, and Park, H. (2008) Sparse nonnegative matrix factorization for clus-
tering. Technical Report GT-CSE-08-01, Georgia Institute of Technology,
Atlanta, Georgia, USA.

Langville, A.N. et al. (2006) Initializations for the nonnegative matrix factor-
ization. In Proceedings of the twelfth ACM International Conference on
Knowledge Discovery and Data Mining (SIGKDD), Philadelphia,
Pennsylvania, USA, pp. 23—26.

Lee, DD. and Seung, H.S. (1999) Learning the parts of objects by non-
negative matrix factorization. Nature, 401, 788—791.

Liao, R. et al. (2014) A new unsupervised binning approach for metagenomic
sequences based on n-grams and automatic feature weighting. IEEE/ACM
Trans. Comput. Biol. Bioinform., 11, 42—54.

Liu, Y. et al. (2013) Understanding and enhancement of internal clustering val-
idation measures. IEEE Trans. Cybern., 43, 982—994.

Maude, S.S. et al. (2012) Classiﬁcation of metagenomic sequences: methods
and challenges. Brief Bioinform., 13, 669—681.

McHardy, A.C. et al. (2007) Accurate phylogenetic classiﬁcation of variable-
length DNA fragments. Nat. Methods, 4, 63—72.

Mohammed, M.H. et al. (2011) SPHINXan algorithm for taxonomic binning
of metagenomic sequences. Bioinformatics, 27, 22—30.

Nielsen, H.B. et al. (2014) Identiﬁcation and assembly of genomes and genetic
elements in complex metagenomic samples without using reference gen-
omes. Nat. Biotechnol, 32, 822—828.

Purdom, E. (2011) Analysis of a data matrix and a graph: metagenomic data
and the phylogenetic tree. Ann. Appl. Stat., 2326—2358.

Qin, J. et al. (2010) A human gut microbial gene catalogue established by
metagenomic sequencing. Nature, 464, 5 9—65 .

Riesenfeld, C.S. et al. (2004) Metagenomics: genomic analysis of microbial
communities. Annu. Rev. Genet., 38, 525—552.

Rosen, G.L. et al. (2011) NBC: the naive bayes classiﬁcation tool webserver
for taxonomic classiﬁcation of metagenomic reads. Bioinformatics, 27,
127—129.

Salvador, S. and Chan, P. (2004). Determining the number of clusters/seg-
ments in hierarchical clustering/segmentation algorithms. In: Proceedings of
the 16th IEEEE International Conference on Tools with AI (ICTAI), Boca
Raton, Florida, USA, pp. 576—584.

Sharon, I. et al. (2013) Time series community genomics analysis reveals rapid
shifts in bacterial species, strains, and phage during infant gut colonization.
Genome Res., 23, 111—120.

Su, C.H. et al. (2012) The impact of normalization and phylogenetic informa-
tion on estimating the distance for metagenomes. I EEE/ACM Trans.
Comput. Biol. Bioinform., 9, 619—628.

Tang, Y. et al. (2005). Improved validation index for fuzzy clustering. In:
American Control Conference, pp. 1120—1125.

Tsuda, K. et al. (2005) Fast protein classiﬁcation with multiple networks.
Bioinformatics, 21, ii59—ii65.

Wan, L. et al. (2010) Alignment—free sequence comparison (ii): theoretical
power of comparison statistics.]. Comput. Biol, 17, 1467—1490.

Wiwie, C. et al. (2015) Comparing the performance of biomedical clustering
methods. Nat. Methods, page (epub ahead of print).

Wood, D.E. and Salzberg, S.L. (2014) Kraken: ultrafast metagenomic se-
quence classiﬁcation using exact alignments. Genome Biol, 15, R46.

Wu, Y.W. and Ye, Y. (2011) A novel abundance-based algorithm for binning
metagenomic sequences using l-tuples.]. Comput. Biol, 18, 523—534.

Wu, Y.W. et al. (2016) MaxBin 2.0: an automated binning algorithm to re-
cover genomes from multiple metagenomic datasets. Bioinformatics, 32,
605—607.

Yang, B. et al. (2010) Unsupervised binning of environmental genomic fragments
based on an error robust selection of l-mers. BMC Bioinformatics, 11, $5.

Ye, Y. and Tang, H. (2009) An ORFome assembly approach to metagenomics
sequences analysis. Bioinforrn. Comput. Biol, 7, 455—471.

Zhao, Z. and Liu, H. (2007) Semi—supervised feature selection via spectral ana-
lysis. In: Proceedings of SIAM International Conference on Data Mining,
pp. 641—646.

ﬁm'spzumot‘pmﬂo'sopeuHOJHtotq/ﬁdnq

