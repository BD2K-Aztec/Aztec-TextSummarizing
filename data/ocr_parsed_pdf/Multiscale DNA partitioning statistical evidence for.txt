BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

A.Futschik et al.

 

that relies on the Gibbs sampler has been proposed by Keith
(2006). An older approach based on information criteria can
be found in Oliver et a]. (1999). Furthermore, recently developed
methods based on entropy criteria have been shown to perform
particularly well; see Elhaik et al. (2010a) and Elhaik et al.
(2010b). A review of segmentation methods can be found in
the article by Braun and Muller (1998), and for a more recent
comparative evaluation of the more popular approaches, see
Elhaik et al. (2010a).

In this paper, we focus on binary segmentation, where the
four—letter alphabet of a DNA sequence is converted into a
two—letter code. For GC content, we set the response to be ‘1’
for G or C at a position and 0 for A/T; we use Y,- to denote the
response at position i and summarize the responses for a se—
quence of length n by

Y=(Y1,Y2,...,Y,,). (1)

We model the responses Y ,- to be independent and Bernoulli
Bin(1,rr,~) distributed, and also assume that there is a partition
0 = 10<rl <  <‘EK = it into an unknown number K of seg—
ments on which the m are piecewise constant, i.e. m = p, for
i e  Here, If 2: (7/,1, 1/] denotes the j’th segment with response
probability p,- for 1 g j f K.

A segmentation algorithm provides estimates K for the
number of segments, for the internal segment boundaries,

0=IO<11<12<~~<11271<112=n, (2)

and for the response probabilities, [3}, on the estimated segments
1/ I: (If/71,13]-

In the following, we will identify a segmentation with (p, I),
wherep 2 (p1, ...,pK) and I: (11, ...,IK).

Our proposed algorithm provides a parsimonious estimate K
for K: K will not exceed the actual number of segments K, except
for a small user—speciﬁed error probability at; as a default value,
we suggest at = 5%, the error probability also chosen in our
simulations and data analyses. Relaxing this significance level
to a larger value, say at = 20%, will typically lead to more iden—
tified segments but at the cost of statistical accuracy.

2 METHOD

Our proposed multiscale segmentation provides estimates for the number
of segments and their boundaries at the same time. We use a certain
multiscale statistic that will ensure that the estimator ﬁts the data well
on all segments simultaneously, i.e. the number of segments is not under-
estimated with high probability. This estimator is based on Frick et a].
(2014) who proposed a general statistical multiscale change-point estima-
tor (SMUCE) for exponential family models. Exponential families in-
clude many classes of well-known distributions, such as the Gaussian
(normal) class, the Poisson class or the Bernoulli class, which is of par-
ticular interest for this article.

In the Gaussian setting, a related estimator has also been suggested in
Davies et a]. (2012). Forerunners of SMUCE are based on a penalized
likelihood with a penality that depends on the number of jumps; see, e.g.
Yao (1988), Braun et al. (2000), Winkler et al. (2002), Boysen et al. (2009)
and the introduction in Frick et a]. (2014) for a brief survey. The under-
lying multiscale statistic is based on the work of Dﬁembgen et a]. (2001);
see also Dﬁembgen et a]. (2008) and Walther (2010). For a general de-
scription of the approach underlying the present work, its statistical in-
terpretation, statistical optimality and theoretical results, we again refer

to Frick et a]. (2014). To ease the understanding, in the following, we
elaborate in greater details on the case of binary Bernoulli observations
with success probabilities given as piecewise constant segments, as this
model underlies the methodology for the segmentation problem at hand.
In contrast to other approaches such as hidden Markov models, we re-
quire neither explicit nor implicit distributional assumptions on the seg-
ments and their lengths.

Let E( Y,», 71,») denote the likelihood of Y,- under the parameter 71,», i.e.
E( Y,»,rr,») = 71,» if Y,» = 1 and E( Y,», 71,») = 1 — 71,» else. We then deﬁne for a
ﬁxed interval (i, j] with 0 5 i < j 5 n the local likelihood ratio statistic
’ a mu)

T(,»ﬂ(p0) = log < max H

3
ﬁoe[0.11[:i+15(Y1,170) ( )

Roughly, this statistic indicates how well the data on the subinterval
(i, j] are described by the constant response probability [)0 e [0, 1] of some
segment under consideration as opposed to choosing some 130 6 [0,1]
freely for that subinterval.

As a goodness-of-ﬁt measure for the segmentation (p,I), we consider
the scale-calibrated multiresolution statistic

T,,(p,I) = max max <./2T(i_ﬂ(pl — 21og(f'T"i)). (4)

1515K (MEI;

(Here ‘e’ denotes Euler’s number.) This statistic may be interpreted
as follows: for all segments 1, in I, the response probability is
assumed to be constant, and for every interval (i, j] within such a segment,
T,,(p,I) measures whether the data are well described by the
constant response probability p, on that interval. It thus checks the
quality of ﬁt on all scales simultaneously, hence the name. Note that the
log-penalty term depends on the length j 7 i of the interval that is currently
checked for deviations from the model. It takes the number of disjoint
intervals of the considered length into account, thereby adjusting for mul-
tiple testing. For our ﬁnal estimate, we determine

(1) the minimal number of segments K, such that there exists a seg-
mentation ((3,1) with K segments satisfying the multiresolution
constraint T,,(f7, i) 5 q for some predetermined signiﬁcance thresh-
old q, and

(2) the segmentation ([3, i) with maximal likelihood among all segmen-
tations having K segments and satisfying the multiresolution
constraint.

To be more precise, let C K denote the set of segmentations with K seg-
ments. Then, our estimate in the second step is

(13,1) = argmax “Y: 17, I), (5)
(p.I)EC,g~ Tn(p~1)§q
where argmax denotes a position ([3,1A) at which the maximum is ob-
tained, and E( Y; 17, 1) denotes the likelihood of all data if the segmentation
(p,I) with K segments were true, i.e.

«mm: H Ham». (6)

151513 l’61!

Following Frick et a]. (2014), the general class of such estimators in ex-
ponential families has been denoted as SMUCE. We adopt this termin-
ology and will denote the estimator in (5) for the Bernoulli and binomial
case as B—SMUCE.

The threshold parameter a determines the parsimony of the estimator;
the larger q, the fewer segments will be included into B-SMUCE. Hence,
the choice of q is crucial. A statistically attractive feature of B-SMUCE is
that a can be chosen as the (1 — oz) quantile of the distribution of T,,(p, I)
under the hypothesis that (p, I) is the true model. In Frick et a]. (2014), it
has been proven that this choice ensures that the number of segments is
not overestimated with probability at least 1 — oz.

 

2256

ﬁm'spzumofpmﬂo'sopeuuopnorq/ﬁdnq

Multiscale DNA partitioning

 

To be more precise, in Frick et a]. (2014), Theorem 2.1 was shown
under some mild technical assumptions that for any ([7, I) the asymptotic
distribution of the multiresolution statistic T,,(p, I) can be bounded by the
asymptotic distribution of the statistic for a signal with only one segment.
Moreover, the latter distribution converges to the limit distribution of (4)
for the case of i.i.d. (independent and identically distributed) zero-mean
Gaussian observations. Therefore, we may (and we do in the following)
simply use Monte Carlo simulations with i.i.d. zero-mean Gaussian data
to determine bounds on the quantiles of the distribution of T,,(p, I). In
simulations, we found the approximate quantiles thus obtained to be
rather conservative (i.e. the preassigned error probability at was not ex-
ceeded) even for small sample sizes. This adds support to the basic
inequality

P<f<>K) : P(T"(p,1)>q> : a (7)

in Section 1.2. of Frick et al., 2014, which renders SMUCE to be a
method that statistically controls the error to overestimate the number
of segments in the binary case, i.e. it provides the statistical validity of B-
SMUCE in the above sense (7). The other way around, Theorem 2.2 in
Frick et a]. (2014) provides an exponential deviation bound for the error
to underestimate the true number of segments, which explicitly depends
on the smallest segment length and signal strength. Under prior informa-
tion on these quantities, these two inequalities together even allow to give
a guarantee for the probability P(K = K) of specifying the number of
segments correctly. Moreover, in the Gaussian case, it can be shown that
SMUCE attains optimal detection rates (and even constants) over a large
range of segment lengths; see Frick et a]. (2014), Theorems 2.6 and 2.7.
Our simulations suggest a similar performance in the binary/binomial
case, although we do not have a rigorous proof of this statement.

2.1 Details of the algorithm

We follow Frick et a]. (2014) and use a pruned version of dynamic
programming to compute our estimated segmentation i and levels 
This is possible because our multiresolution statistic Tn considers only
subintervals of the candidate segments of constant response probability.
For related ideas, where dynamic programming has been used for other
segmentation estimators, see Friedrich et a]. (2008), Boysen et a]. (2009),
Davies et a]. (2012) and, in particular for pruning, Killick et a]. (2012). To
describe the algorithm for computing B-SMUCE, we need the following
notation, identifying a segmentation with (p, I) again: for an interval (i, j],
we deﬁne the local costs of a response probability [)0 e [0, 1] as

J .
 1;“e1“W  <8>
Let call] 2 minpodo~ 1] c(,»,,](p0) denote the minimal costs on (i, j] for a con-
stant response probability under the multiresolution constraint, whereas
pm] 2 argIninp,‘E[0.1]c(,»J](p0) denotes the corresponding optimal estimate.
Let us, for the moment only, consider the observations Y1, . . . , Y,» for
ﬁxed 1 5 i 5 n, and denote by c: K, the optimal overall costs on (0,1]
using K segments, i.e.

at = argmax ear-.121), (9)
K (p~1)ECK.i. 7701.091 112K 
cf. (5), where C K,» denotes the set of segmentations of (0, i] with K seg-
ments; if no segmentation (17,1) 6 C K~ ,» fulﬁlls the multiresolution con-
straint T,»(p,I) 5 q, we let c: K 2 00.

The algorithm for B-SMUCE is then based on the observation that for
K >0

cjk = min, (c7191 + c2311). (10)
‘ 15151 ‘ ‘

In dynamic programming, this is called the Bellman equation; it is
the main ingredient for an efﬁcient implementation; see line 11 in
Algorithm 1.

 

Algorithm 1: dynamic programming algorithm for B-SMUCE

 

1 K<—0,i0<—(A,130<—0,i<—1
2 while i: n do
3 if 1% = 0 then
4 1* <— 0
5: cij <— can]
6' else
7 forl=i—1,...,ldo
8: if ca~ ,] 2 00 then
9: goto 14
10: else
11: c§<—c:k71+cf,l]
12: end if
13: end for
14: 1* <— argnlinZEI-(icf:
15: CL, (- cf
16: end if
17: if c’,‘ A 2 00 then
LK A
18: K <— K+ 1
19: goto 3
20: end if

21: i, (- (i,.,(1*, 1])
225 132' <— (131*,I7(l*.z])
23: end while

24: return K, I,,, 13,,

 

Note that we introduced two rules that permit for early stopping of
loops: if cal] 2 oo, i.e. if the hypothesis of constancy on (I, i] is rejected,
then consequently, this also happens on any larger interval, i.e. for any
smaller I; this justiﬁes lines 879. Similarly, if K segments are insufﬁcient to
fulﬁll the multiresolution constraint on (0, i], then a fortiori so for any
larger i, whence lines 17720. To the best of our knowledge, these shortcuts
that are possible because of the specific structure of the multiscale con-
straint have not been used so far. Additional improvements were used in
our implementation; these, however, are rather technical and thus
omitted from the present article.

3 RESULTS

We evaluated our segmentation approach both on simulated
data and on data taken from the human genome and the long—
known A—phage. In our simulations, we used the benchmark
scenarios proposed in Elhaik et al. (2010a). Because an extensive
comparison of popular DNA segmentation algorithms under
these benchmark scenarios is already available in Elhaik et al.
(2010a), we provide a comparison of our approach with the
method that performed best in Elhaik et al. (2010a), namely,
the one based on the JenseniShannon divergence. This recursive
approach (called D J5) splits one of the current segments in each
step. This is done by adding a new break point such that the
improvement in Jensen7Shannon divergence is maximized. The
algorithm stops when the improvement does not reach a thresh—
old value obtained via simulations. Here, we used the Matlab
implementation Djsegmentationm of the algorithm, which is
publicly available as part of ISOPLOTTER 2.4 (http://code.
google.com/p/isoplotter/). There, 5.8 x 10’5 is taken as a thresh—
old, a value obtained from simulating long (1 Mb) homogeneous
sequences. Although this value seems to work well for the con—
sidered benchmark scenarios and might also be useful to prevent
false—positive findings when searching for long homogeneous se—
quences, it might be less suitable for balancing false—positives and

 

2257

ﬁm'spzumol‘pmjxo'sopeuuqurorq/ﬁdnq

A.Futschik et al.

 

false—negatives under other scenarios. Therefore, a modiﬁed
version (called ISOPLOTTER) of D J5 has been proposed brieﬂy
after (Elhaik et al., 2010b) that uses critical values
dependent both on the segment length and the standard
deviation of the GC content. Therefore, we also report on the
performance of ISOPLOTTER 2.4 (again under the default par—
ameter settings) and provide detailed results in the
Supplementary Material.

To facilitate the comparison and to accelerate the computa—
tions for longer sequences, we binned the data and applied our
algorithm to the resulting binomial frequencies. We choose the
bin size equal to 32, which is the default value with the D J5 and
IsoPlotter software and has also been used in Elhaik et al.
(2010a). Although binning the data clearly improves the speed,
it should be noted that it is not essential for the algorithm to
work.

The first scenario considered there involves sequences consist—
ing of ﬁxed—size homogeneous domains. Although not realistic in
practice, this setup has been proposed by Elhaik et al. (2010a) as
a minimum standard: a criterion that does not perform well on
such data cannot be expected to perform well under more com—
plex settings. The second scenario consists of sequences with
domains of random length generated according to a power—law
distribution. These sequences are reported to mimic mammalian
genomes well; see Clay et al. (2001).

3.1 Performance measures

We measured performance both by a qualitative criterion
proposed by Elhaik et al. (2010a) and by a new quantitative
criterion. For the qualitative criterion, we classify an identiﬁed
segment as true—positive if both segment boundaries are
identiﬁed correctly within an error margin of 5000 bases or
5% of the segment length, whichever is smaller. Thus, an identi—
ﬁed segment is considered to be a false—positive, unless both
detected boundaries were within 5000 bases (or 5%) from the
boundaries of a true segment. Similarly, actual segments were
taken as false—negative findings if they were not detected
correctly within the permitted tolerance. Let now tp, fp and fn
denote the number of true—positives, false—positives and false—
negatives, respectively. Following Elhaik et al. (2010a), we
deﬁne a sensitivity rate as

 

II)
, := —, 11
r. U) +fn ( )
and a precision rate as
IP
r := . (12)
p tr +fp

We investigate the performance of our proposed approach based
on these criteria.

Furthermore, we deﬁned two quantitative criteria that better
reﬂect the accuracy of detecting segment boundaries. We denote
them by false—negative sensitive localization error (FNSLE) and
false—positive sensitive localization error (FPSLE). To introduce
the FNSLE, consider a true segment I} :2 (r,,1, If], and let
m, =  denote the midpoint of the segment. We deﬁne the
best matching estimated segment as the segment I, = (f,,1,f,]

with m, e I) The FNSLE for segment I_,- is then deﬁned as the
mean distance

1 A A
QEFNSL) = 507/71— Tlill + IT} — Til) (13)

between true and estimated boundaries.
The overall FNSLE is then deﬁned as the mean FNSLE taken
over all true segments

1 K
6(FNSL) : E: eEFNSL)- (14)
i=1

Analogously, the FPSLE can be deﬁned by measuring how
closely an estimated segment matches to one of the true seg—
ments. By starting with an estimated segment i, and its midpoint
m,, we look for the true segment satisfying a, e  With analo—

gously defined errors ejFPSL), we call
(FPSL) 1 12 (FPSL)
e 2: 7 e . 15
K2  l ( )

[:1

the overall FPSLE.

These measures for the error may be interpreted as follows:
assume that the estimated segmentation agrees with the true seg—
mentation in the number of segments, and that all boundaries
have been determined with an error smaller than half the length
of each neighboring segment. Then, FPSLE and FNSLE agree:
they essentially give the average distance between true and esti—
mated boundaries. These error measures behave differently,
however, if the numbers of true and detected segments do not
coincide: assume that the estimated segmentation is the true seg—
mentation except that it has incorrectly split one true segment
into two estimated segments. Then, the FNSLE increases by the
length of that true segment minus the length of the longer esti—
mated segment divided by 2K, i.e. a spurious split is treated like
an error in localizing that boundary. The FPSLE, however, will
get rather large, as the length of that true segment divided by 2K
gets added. Similarly, if a true boundary is not detected, the
FNSLE will be larger.

3.2 Simulations

3.2.1 Segments of equal length We first implemented Scenario I
of Elhaik et al. (2010a). Thus, we simulated sequences that con—
sist of 10 segments of equal length. We considered the following
eight different segment lengths: 10kb, 50kb, 100kb, 200kb, 300kb,
500 kb, le and 5Mb. Thus, the longest sequences had total
length 50Mb. For each sequence, we selected a global probability
[30) for the response ‘1’ at a position according to a uniform
distribution on [0.1,0.9]. Then, we randomly modiﬁed this prob—
ability for each sequence segment j by taking

P121730) + OZ}- (16)

Here Z_,- denotes a standard normal random number, and a was
chosen from {0,0.025,0.05,0.075,0.1}. The p,- were conditioned
to lie within [0,1], i.e. if p,- did not turn out to be a proper prob—
ability, a new random number was generated. The individual
observations Y ,- within a given segment I_,- were then chosen as
independent Bernoulli random variables with expected value 1),.

 

2258

ﬁm'spzumol‘pmjxo'sopeuuqurorq/ﬁdnq

 

B—SMUCE - — B-SMUCE - -
6:0.025

B-SMUCE - - 5.3- _
xr?*""

é--e’§ I}
‘44:? ,
,r 4'

I
BisMUCE - -
I
I

I’

 

 

B—SMUCE — - B-SMUCE - -
6:0.025 6:0.05
_-..'. a. - a _-
éé ”'

K: 8- ’
 «r.»

I ’ B*SMUCE - -
y B*SMUCE - -
won

B—SMUCE - - B'SMUCE ' '

 

“qil
,,r’
r
or
, ’T B—SMUCE — — H
a”’ »
‘9 1 "l I l
a -- ’f
I ’0’ .. 4! 7
l' B—SMUCE - - , Q T

 

/3.IO'S[BIIm0[p.IOJXO'SOIJBIIIJOJIIIOIq/ﬂdnq

0‘ : 0.075 G : 0.1

B-SMUCE - - B-SMUCE - - I
I? ' If r ’T
If! ..ﬁ’1
t 9 (if
, ’ ,1
U x
U

G:0025

’ I T B*SMUCE — — ..
r f , ’
’0'! --/r T
/° “‘1’
’Q,
/ B—SMUCE - — I D
‘ I
'

/3.IO'S[BIIm0[p.IOJXO'SOIJBIIIJOJIIIOIq/ﬂdnq

Multiscale DNA partitioning

 

Table 3. Run times (in s) of the B-SMUCE algorithm when applied to
sequences of different length taken from the human chromosome 1

 

 

Sequence length 105 2 X 105 5 X 105 106 5 X 106 107
Run-time bin size 32 0.37 1.0 3.3 9.4 51.9 102.9
Run-time bin size 10 1.7 4.0 12.3 30.7 169.7 384.0

 

Note. The computations were carried out on a single cluster core with 2.6GHz and
8 GB RAM. The results are reported fora = 0.05 and for bins of lengths 32 and 10.
For at = 0.01, similar run times have been obtained.

statistical error control associated with the multiresolution cri—
terion suggests that there are (except for a small error probabil—
ity) at least 640 segments. To check whether this ﬁnding is also
compatible with the D J5 segmentation, we simulated the segmen—
tation with 640 segments obtained with B—SMUCE as our null
model. We simulated 100 datasets from this null model, and for
80% of all datasets, D J5 led to a segmentation with the number
of segments at most 182. With the number of segments taken as
test statistic, this amounts to an estimated p—value of 0.80. Thus,
the segmentation based on the JenseniShannon (D J5) criterion
does not contradict the assumption of 640 segments, whereas the
hypothesis of 182 segments is rejected by the multiscale criterion
underlying B—SMUCE as not being compatible with the data.

We also applied IsoPlotter 2.4 to the data. With its adaptive
detection threshold, 227 segments were identiﬁed. The homogen—
eity test (one—sided F—test) provided with the IsoPlotter software
conﬁrmed for 180 of these 227 segments that they are signiﬁ—
cantly more homogeneous than the entire considered DNA se—
quence. Although this observation does not give us the number
of segments actually present, it seems interesting that the number
of sufﬁciently homogeneous segments found by IsoPlottor is
almost the same as the number of segments identiﬁed with the
D J5 criterion.

Finally, we considered the region between 50 and 60 Mb on
the human chromosome 1. Here, we tried bins both of size 10
and 32. It turned out that with the finer partition slightly more
segments were detected than with the larger bins of size 32, al—
though the difference (1096 versus 1041) was not large. It seems
plausible that ﬁne—scale variation can be detected more easily
with shorter bins.

To illustrate the run—time behavior of the B—SMUCE algo—
rithm with our default signiﬁcance threshold at = 0.05, we con—
sidered several shorter sequences taken from the aforementioned
10 Mb DNA sequence. Table 3 gives the run times of our algo—
rithm (in s) in dependence of the sequence length.

To give an idea about the run times of D J5 and IsoPlotter, we
applied them on the same sequence pieces. With the standard
options (bin size: 32, shortest detectable domain size: 3008), the
run times for the longest sequence (107 bases) were 6.2s (D J5)
and 9.6s (IsoPlotter). However, notice that B—SMUCE is de—
signed to detect segments of any length, and the shortest segment
detected by B—SMUCE in the context of our run time analysis
was 80 bases long. Therefore, we also recorded the run times for
D J5 and IsoPlotter with the minimum segment length changed
from 3008 to 80. For a bin width of 32 and a sequence length of

107, the run time for D J5 remained unchanged, whereas the run
time for IsoPlotter increased to 329.1 s.

For the human genome data considered here, a cross—check
with the genome annotation revealed that several segments have
an interpretation in terms of genes/exons, repetitive elements or
CpG islands. Because the GC content may depend on several
functional and evolutionary factors, we do not expect simple
explanations for many of the identiﬁed segments. Nevertheless,
we explore the overlap of the identiﬁed segments with available
annotation in the Supplementary Material.

4 CONCLUSION

We introduced a new method (B—SMUCE) for the segmentation
of biological sequences. The segmentation is with respect to a
binary response; here, we have considered GC content, but it
might be interesting to apply the method to other applications
involving binary responses (such as ancestral/derived state of al—
leles in population genetic applications). Our approach provides
precise statistical error control and will produce a parsimonious
segmentation that does not contain more segments than there
actually are with a user—speciﬁed preassigned probability of
l—Ol. A comparison under the benchmark scenarios taken
from Elhaik et al. (2010a) suggests that the proposed method
B—SMUCE is more accurate than previously proposed
approaches.

Interestingly, the difference to the popular JenseniShannon
criterion in terms of the number of detected segments has been
particularly large for the human data.

ACKNOWLEDGEMENTS

We are grateful to Dr. Marlies Dolezal for her helpful comments.

Funding: The research of AM. and HS. is supported by
Deutsche Forschungsgemeinschaft (DFG) FOR 916, SFB 803
and the Volkswagen Foundation. The work by AF. is supported
by the Austrian Science Fund (FWF; Vienna Graduate School of
Population Genetics).

Conﬂict of Interest: none declared.

REFERENCES

Amit,M. et al. (2012) Differential GC content between exons and introns establishes
distinct strategies of splice—site recognition. Cell Rep., 1, 5437556.

Benjamini,Y. and Speed,T.P. (2012) Summarizing and correcting the GC content
bias in high—throughput sequencing. Nucleic Acids Res, 40, e72.

Bernardi,G. (2001) Misunderstandings about isochores. Part I. Gene, 276, 3713.

Boysen,L. et al. (2009) Consistencies and rates of convergence of jump—penalized
least squares estimators. Ann. Statis‘t., 37, 1577183.

Braun,J.V. and Muller,H.G. (1998) Statistical methods for DNA segmentation.
Stat. Sci., 13, 1427162.

Braun,J.V. et al. (2000) Multiple change—point ﬁtting via quasi—likelihood, with ap—
plication to DNA sequence segmentation. Biometrika, 87, 3017314.

Cristianini,N. and Hahn,M.W. (2007) Conymtational Genomics. Cambridge
University Press, Cambridge, UK.

Churchill,G.A. (1989) Stochastic models for heterogeneous DNA sequences. Bull.
Mat/i. Biol, 51, 79794.

Churchill,G.A. (1992) Hidden Markov chains and the analysis of genome structure.
Comp. CIZE}’H., 16, 1077115.

Clay,O. et al. (2001) Compositional heterogeneity within and among isochores in
mammalian genomes. I. CsCl and sequence analyses. Gene, 276, 1524.

 

2261

ﬁre'spzumol‘pmyo'sopeuuqurorq/ﬁdnq

A.Futschik et al.

 

Cohen,N. et al. (2005) GC composition of the human genome: in search for iso—
chores. Mol. Biol. Evol., 22, 126(k1272.

Davies,L. et al. (2012) Recursive computation of piecewise constant volatilities.
Comput. Stat. Data Anal., 11, 362373631.

Diimbgen,L. and Spokoiny,V.G. (2001) Multiscale testing of qualitative hypotheses.
Ann. Stat., 29, 124452.

Diimbgen,L. and Walther,G. (2008) Multiscale inference about a density. Ann.
Stat., 36, 175871785.

Elhaik,E. et al. (2010a) Comparative testing of DNA segmentation algorithms using
benchmark simulations. Mol. Biol. Evol., 27, 101571024.

Elhaik,E. et al. (2010b) Identifying compositionally homogeneous and nonhomo—
geneous domains within the human genome using a novel segmentation algo—
rithm. Nucleic Acids Res, 38, e158.

Fickett,J.W. et al. (1992) Base compositional structure of genomes. Genomics, 13,
105G1064.

Frick,K. et al. (2014) Multiscale change—point inference. J. R. Stat. Soc. Ser., 76,
4957580.

Friedrich,F. et al. (2008) Complexity penalized M— estimation: fast computation.
J. Compat. Graph. Stat., 17, 2017224.

Freudenberg,J. et al. (2009) Partial correlation analysis indicates causal relationships
between GC—content, exon density and recombination rate in the human
genome. BMC Bioinformatics, 10, S66.

Fullerton,S.M. et al. (2001) Local rates of recombination are positively
correlated with GC content in the human genome. Mol. Biol. Evol., 18,
113971142.

Galtier,N. et al. (2001) GC—content evolution in mammalian genomes: the biased
gene conversion hypothesis. Genetics, 159, 9077911.

Keith,J.M. (2006) Segmenting eukaryotic genomes with the generalized gibbs sam—
pler. J. Comput. Biol, 13, 136%1383.

Killick,R. et al. (2012) Optimal detection of changepoints with a linear computa—
tional cost. J. Am. Stat. Assoc., 107, 159(%1598.

Oliver,J.L. et al. (1999) SEGMENT: identifying compositional domains in DNA
sequences. Bioinformatics, 15, 9747979.

Risso,D. et al. (2011) GC—Content Normalization for RNA—Seq Data. BMC
Bioinformatics, 12, 480.

Sueoka,N. (1962) On the genetic basis of variation and heterogeneity of DNA base
composition. PNAS, 48, 5827592.

Walther,G. (2010) Optimal and fast detection of spatial clusters with scan statistics.
Ann. Statist., 38, 101(F1033.

Winkler,G. and Liebscher,V. (2002) Smoothers for discontinuous signals.
J. Nonparametr. Stat., 14, 2037222.

Yao,Y.C. (1988) Estimating the number of change—points via Schwarz’ criterion.
Statist. Probab. Lett., 6, 1817189.

 

2262

/810'sleum0fpiqixo'soiieuiJOJuioiq”:duq

