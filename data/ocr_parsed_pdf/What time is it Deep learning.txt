Biainfarmatics, 32, 2016, i8—i17
doi: 10.1093/bioinformatics/btw243
ISMB 2016

 

What time is it? Deep learning approaches for
circadian rhythms

Forest Agostinelli1'*, Nicholas Ceglia1, Babak Shahbabaz,
Paolo Sassone-Corsi3 and Pierre Baldi1'3*

1Department of Computer Science, 2Department of Statistics and 3Department of Biological Chemistry, University
of California-Irvine, Irvine, CA 92697, USA

*To whom correspondence should be addressed.

Abstract

Motivation: Circadian rhythms date back to the origins of life, are found in virtually every species
and every cell, and play fundamental roles in functions ranging from metabolism to cognition.
Modern high—throughput technologies allow the measurement of concentrations of transcripts,
metabolites and other species along the circadian cycle creating novel computational challenges
and opportunities, including the problems of inferring whether a given species oscillate in circadian
fashion or not, and inferring the time at which a set of measurements was taken.

Results: We first curate several large synthetic and biological time series datasets containing labels
for both periodic and aperiodic signals. We then use deep learning methods to develop and train
B|O_CYCLE, a system to robustly estimate which signals are periodic in high—throughput circadian
experiments, producing estimates of amplitudes, periods, phases, as well as several statistical sig—
nificance measures. Using the curated data, B|O_CYCLE is compared to other approaches and
shown to achieve state—of—the—art performance across multiple metrics. We then use deep learning
methods to develop and train B|O_CLOCK to robustly estimate the time at which a particular
single—time—point transcriptomic experiment was carried. In most cases, B|O_CLOCK can reliably
predict time, within approximately 1 h, using the expression levels of only a small number of core
clock genes. B|O_CLOCK is shown to work reasonably well across tissue types, and often with only
small degradation across conditions. B|O_CLOCK is used to annotate most mouse experiments
found in the GEO database with an inferred time stamp.

Availability and Implementation: All data and software are publicly available on the CircadiOmics
web portal: circadiomics.igb.uci.edu/.

Contacts: fagostin@uci.edu or pfbaldi@uci.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

 

The importance of circadian rhythms cannot be overstated: circa—
dian oscillation have been observed in animals, plants, fungi and
cyanobacteria and date back to the very origins of life on Earth.
Indeed, some of the most ancient forms of life, such as cyanobacte—
ria, use photosynthesis as their energy source and thus are highly cir—
cadian almost by definition. These oscillations play a fundamental
role in coordinating the homeostasis and behavior of biological sys—
tems, from the metabolic (Eckel—Mahan and Sassone—Corsi, 2009;
Froy, 2011; Takahashi et (11., 2008; Yoo et (11., 2004) to the cogni—
tive levels (Eckel—Mahan et (11., 2008; Gerstner et (11., 2009).
Disruption of circadian rhythms has been directly linked to health
problems (Knutsson, 2003; Lamia et (11., 2008; Takahashi et (11.,

©The Author 2016. Published by Oxford University Press.

2008) ranging from cancer, to insulin resistance, to diabetes, to
obesity and to premature ageing (Antunes et (11., 2010; Froy, 2010,
2011; Karlsson et (11., 2001; Kohsaka et (11., 2007; Kondratov et (11.,
2006; Sharifian et (11., 2005; Shi et (11., 2013; Turek et (11., 2005). At
their most fundamental level, these oscillations are molecular in na—
ture, whereby the concentrations of specific molecular species such
as transcripts, metabolites and proteins oscillate in the cell with a 24
h periodicity. Modern high—throughput technologies allow large—
scale measurements of these concentrations along the circadian cycle
thus creating new datasets and new computational challenges and
opportunities. To mine these new datasets, here we develop and
apply machine learning methods to address two questions: (i) which
molecular species are periodic? and (ii) what time or phase is

is

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.U/),
which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact

journals.permissions@oup.com

112 /310'srrzu1nofp10}xo"sorwurJOJurorq/ﬁduq r1101} popcorn/nag

9103 ‘Og anﬁnv uo ::

Deep learning approaches for circadian rhythms

i9

 

associated with high—throughput transcriptomic measurements
made at a single timepoint?

At the molecular level, circadian rhythms are in part driven by a
genetically encoded, highly conserved, core clock found in nearly
every cell based on negative transcription/translation feedback
loops, whereby transcription factors drive the expression of their
own negative regulators (Partch et al., 2014; Schibler and Sassone—
Corsi, 2002), and involving only a dozen genes (Partch et al., 2014;
Yan et al., 2008). In the mammalian core clock (Fig. 1), two bHLH
transcription factors, CLOCK and BMAL1 heterodimerize and bind
to conserved E—box sequences in target gene promoters, thus driving
the rhythmic expression of mammalian Period (Perl, PerZ and Per3)
and Cryptochrome (Cryl and CryZ) genes (Stratmann and Schibler,
2006). PER and CRY proteins form a complex that inhibits subse—
quent CLOCKzBMAL1—mediated gene expression (Brown et al.,
2012; Dibner et al., 2010; Partch et al., 2014). The master core
clock located in the suprachiasmatic nucleus (SCN) (Moore and
Eichler, 1972; Ralph et al., 1990) of the hypothalamus interacts
with the peripheral core clocks throughout the body (Takahashi
et al., 2008; Yoo et al., 2004).

In contrast to the small size of the core clock, high—throughput
transcriptomic (DNA microarrays, RNA—seq) or metabolomic (mass
spectrometry) experiments (Andrews et al., 2010; Eckel—Mahan
et al., 2012, 2013; Hughes et al., 2009; Masri et al., 2014b; Miller
et al., 2007; Panda et al., 2002; P.Tognini et al., in preparation),
have revealed that a much larger fraction, typically on the order of
10%, of all transcripts or metabolites in the cell are oscillating in a
circadian manner. Furthermore, the oscillating transcripts and me—
tabolites differ by cell, tissue type, or condition (Panda et al., 2002;
Storch et al., 2002; Yan et al., 2008). Genetic, epigenetic and envir—
onmental perturbations—such as a change in diet—can lead to cellu—
lar reprogramming and profoundly influence which species are
oscillating in a given cell or tissue (Bellet et al., 2013; Dyar et al.,
2014; Eckel—Mahan et al., 2012, 2013; Masri et al., 2013, 20143).
When results are aggregated across tissues and conditions, a very
large fraction, often exceeding 50% and possibly approaching
100%, of all transcripts is capable of circadian oscillations under at
least one set of conditions, as shown in plants (Covington et al.,
2008; Harmer et al., 2000), cyanobacteria and algae (Monnier
et al., 2010; Vijayan et al., 2009) and mouse (Patel et al., 2015;
Zhang et al., 2014).

In a typical circadian experiment, high—throughput omic meas—
urements are taken at multiple timepoints along the circadian cycle
under both control and treated conditions. Thus the first fundamen—
tal problem that arises in the analysis of such data is the problem of
detecting periodicity, in particular circadian periodicity, in these

0
00
3. %
Ph Dim

h @ .. 
‘ Q E

CLO(K BMALI
900 A A N

PER W.MM.M

:4 @ crocx BMALI
A mm: mm:
trimming,

‘. Wilda-u-

\f\

mm. my:

N CLOCK BMALI

man In”

CRV’

Fig. 1. Core clock genes and proteins and the corresponding transcription/
translation negative feedback loop

time series. The problem of detecting periodic patterns in time series
is of course not new. However, in the cases considered here the
problem is particularly challenging for several reasons, including: (i)
the sparsity of the measurements (the experiments are costly and
thus data may be collected for instance only every 4 h); (ii) the noise
in the measurements and the well known biological variability; (iii)
the related issue of small sample sizes (e.g. n : 3); (iv) the issue of
missing data; (v) the issue of uneven sampling in time; and (vi) the
large number of measurements (e.g. 20 000 transcripts) and the
associated multiple—hypothesis testing problem. Here we develop
and apply deep learning methods for robustly assessing periodicity
in high—throughput circadian experiments, and systematically com—
pare the deep learning approach to the previous, non—machine learn—
ing, approaches (Glynn et al., 2006; Hughes et al., 2010; Yang and
Su, 2010). While this is useful for circadian experiments, the vast
majority of all high—throughput expression experiments have been
carried, and continue to be carried, at single timepoints. This can be
problematic for many applications, including applications to preci—
sion medicine, precisely because circadian variations are ignored cre—
ating possible confounding factors. This raises the second problem
of developing methods that can robustly infer the approximate time
at which a single—time high—throughput expression measurement
was taken. Such methods could be used to retrospectively infer a
time stamp for any expression dataset, in particular to improve the
annotations of all the datasets contained in large gene expression
repositories, such as the Gene Expression Omnibus (GEO) (Edgar
et al., 2002), and improve the quality of all the downstream infer—
ences that can be made from this wealth of data. There may be other
applications of such a method, for instance in forensic sciences, to
help infer a time of death. In any case, to address the second prob—
lem we also develop and apply deep learning methods to robustly
infer time or phase for single—time high—throughput gene expression
measurements.

2 Datasets

2.1 Periodicity inference from time series
measurements

To train and evaluate the deep learning methods, we curate
BioCycle, the largest dataset including both synthetic and real—world
biological time series, and both periodic and aperiodic signals.
While the main goal here is to create methods to analyze real—world
biological data, relying only on biological data to determine the ef—
fectiveness of a method is not sufficient because there are not many
biological samples which have been definitively labeled as being
periodic or aperiodic. Even when one can be confident that a signal
is periodic, it can be difficult to determine the true period, phase and
amplitude of that signal. Therefore, we rely also on synthetic data to
provide us with signals that we can say are definitely periodic or
aperiodic, and whose attributes—such as period, amplitude, and
phase—can be controlled and are known. Furthermore, previous
approaches were developed using synthetic data and thus the same
synthetic data must be used to make fair comparisons.

2.1.1 Synthetic data

We first curate a comprehensive synthetic dataset BioCyclesymh,
which includes all previously defined synthetic signals found in
JTK_Cycle (Hughes et al., 2010) and ARSER (Yang and Su, 2010),
but also contains new signals. BioCyclesymll is in turn a collection of
two different types of datasets: a dataset in which signals are con—
structed using mathematical formulas (BioCycleme), and a dataset

112 /310'srcu1noip103xo"sorwurJOJurorq/ﬁduq r1101} popcorn/nag

9103 ‘Og anﬁnv uo ::

i10

F. Agostinelli et aI.

 

in which signals are generated from a Gaussian process (Rasmussen,
2004) (BioCycleGauss). In previous work, synthetic data was gener—
ated with carefully constructed formulas to try to mimic periodic
signals found in real—world data (see below). While this gives one a
lot of control over the data, it can create signals that are too con—
trived and therefore not representative of real—world biological vari—
ations. In addition, the noise added at each timepoint is independent
of the other timepoints, which may not be the case in real—world
data. The BioCycleGauss dataset uses Gaussian processes to generate
the data and address these problems.

The datasets used in JTK_Cycle contain the following types of
formulas or signals: cosine, cosine with outlier timepoints and white
noise. The ARSER dataset contains cosine, damped cosine with an
exponential trend, white noise and an auto—regressive process of
order 1 (AR(1)). In addition to all the aforementioned signals,
BioCycleme contains also 9 additional kinds of signals: combined
cosines (cosine2), cosine peaked, square wave, triangle wave, cosine
with a linear trend, cosine with an exponential trend, cosine multi—
plied by an exponential, ﬂat and linear signals (many of which can
be found in Deckard et al., 2013). Figure 2 shows an example of
each type of signal found in the BioCycleme dataset. For clarity,
the periodic signals are shown without noise. Signals in the
BioCycleme dataset have an additional random offset chosen uni—
formly between —200 and 200, random amplitudes chosen uni—
formly between 1 and 100, signal to noise ratios (SNRs) of 1—5,
random phases chosen uniformly between 0 and 211, and periods be—
tween 20 and 28. [Data for the second (12 h) and third (8h) har—
monics, which are found in biological data, are also generated
(Supplementary Information)]. At each timepoint sample, zero mean
Gaussian noise is added with the proper SNR variance.

The BioCycleGauss dataset is obtained from a Gaussian process.
The value of the covariance matrix corresponding to the timepoints
x and x’ is determined by a kernel function k(x,x’ Equation 1 is
the kernel function used to generate the periodic signals, and
Equation 2 is the kernel function used to generate the aperiodic sig—
nals in BioCycleGauss .

_ - 2 l _ I
8120030: eXI)  + a25(x,x’) + [ixx’ (1)

and». calm put a...

9.. ‘3! D. c!

a a n a

0 2i 0'

ca :1 a: a

'— D 23 £0 '- 0 2D 110 T D 20 4D 0 20 110
mm (“Howl minnow mm'an

i
E
%
é

 

4.0 .

 

 

 

E! D. c!
n—zo so ‘To an do To 20 «in To an 40
Club“ can?! ¢IIB “all ¢nulﬂr Harml- Ill

D. c!

0 CI CI CI
c>._ 0. 0._ 0.
To 20 an Tin—ED 40 To 20 4o Tit—ED 4o
0 lulu Q mm
D D
D\ c!
*D 2b In To '2n‘4n

Fig. 2. Samples of synthetic signals in the BioCycleForm dataset. Signals in
green are periodic; signals in red are aperiodic

2
ka(x7xl) : EXP  + a25(x,x’) 

The parameter 1 controls how strong the covariance is between
two different timepoints, 6 controls how noisy the synthetic data is,
and [3 can add a non—stationary, linear, trend to the signals
(Duvenaud, 2014). The parameter p in equation 1 is the period of the
signal. To generate the data in BioCycleGauss, the values of l, o, [3, p,
as well as the offset and the scale are varied, in a way similar to the
data in BioCycleFom, . Examples of signals from the BioCycleGauss
dataset are given in Figure 3.

JTK_Cycle analyzes synthetic signals sampled over 48 h with a
sampling frequency of 1 and 4 h. ARSER analyzes synthetic signals
sampled over 44 h with a sampling frequency of 4 h. BioCycle ana—
lyzes synthetic signals sampled over 24 and 48 h. Signals sampled
over 24 h have a sampling frequency of 4, 6 and an uneven sampling
at timepoints 0, 5, 9, 14, 19 and 24. Signals sampled over 48 h have
sampling frequencies of 4, 8 and an uneven sampling at timepoints
0, 4, 8, 13, 20, 24, 30, 36, 43. The sampling frequencies in these
datasets are intentionally sparse to mimic the sparse temporal sam—
pling of real—world high—throughput data. The number of synthetic
signals at each sampling frequency is 1024 for JTK_Cycle, 20 000
for ARSER and 40 000 for BioCyclesym}l . Finally, each signal in
BioCyclesym}l has three replicates, obtained by adding random
Gaussian noise to the signal, to mimic typical biological
experiments.

2.1.2 Biological data

The performance of any circadian rhythm detection method requires
extensive validation on biological datasets. In previous work, due to
the aforementioned difficulty of not having ground truth labels, the
biological signals detected as being periodic had to be inspected by
hand, or loosely assessed by comparison to other methods (Straume,
2004). In addition to the scaling problems associated with manual
inspection, this approach did not allow the computation of precise
classification metrics (Baldi et al., 2000), such as the AUC—the
Area Under the Receive Operating Characteristic (ROC) Curve. The
repository of circadian data hosted on CircadiOmics (Patel et al.,
2012) includes over 30 high—throughput circadian transcriptomic
studies, as well as several circadian high—throughput metabolomic

 

Q P...“ Q Wadi: q I was»: 9 Puma:

CI CI El I D

0" Ci Ci ' 0' '

D. c! a? Cl.

'7 0 2D 4'0 '- 0 2D 110 T 0 2D ' «m T D 20 ' ID

o M  Mﬂﬂﬂll 0 WI:  Moll:

0.. O C! . ‘3.

O O 0 O

- .

9. ‘3! :1. c!

'r‘ D—'?O'—d'ﬂ 7‘ O"—EU'_ JO '- lﬁ—_2 "—11: T D—70—nﬂ1
“mail: IDIbI: urinal: "M I:

a c. n_ a

0 CI CI 0

0. 0 Cr. 0.

T 'o—zr—Io— '- m“ ’ u—zti—m" T m

D .pmdm c! upwind: q I npmindi: c! —rudl:

c. c. c. c.

D d' C‘ \‘mv

0 CI Cl : O

F ' ’- n—"arr—"zn 70—" "—40

- I'd—'R’I'"_4'O -' O"'_Zﬂ_""iio

Fig. 3. Samples of synthetic signals in the BioCycleGauss dataset. Signals in
green are periodic; signals in red are aperiodic

112 /310's1rzu.rnofp101xo"sorwurJOJHrorq/ﬁduq r1101} popco1umoq

9103 ‘0g anﬁnv uo ::

Deep learning approaches for circadian rhythms

i11

 

studies, that provide extensive coverage of different tissues and ex—
perimental conditions. From the CircadiOmics data, a high—quality
biological dataset BioCycleRear is created with periodic/aperiodic
labels.

To curate BioCycleReaL we start from 36 circadian microarray or
RNA—seq transcriptome datasets, 32 of which are currently publicly
available from the CircadiOmics web portal (28 of these are also
available from CircaDB (Pizarro et al., 2012)). Five datasets are
from ongoing studies and will be added to CircadiOmics upon com—
pletion. All included datasets correspond to experiments carried out
in mice, with the exception of one dataset corresponding to meas—
urements taken in Arabidopsis Thaliana. BioCycleReal comprises ex—
periments carried over a: 24—h period with a 4 h sampling rate; 48—h
period with a 2 h sampling rate; and 48—h period with a 1 h sampling
rate.

To extract from this set a high—quality subset of periodic time
series, we focus on the time series associated with the core clock
genes (Fig. 1) in the control experiments. These gene include Clock,
Per1, Per2, Per3, Cyr1, Cry2, Nr1d1, Nr1d2, Bhlhe40, Bhlhe41,
Dbp, NpasZ and Tel (Harmer et al., 2001) for mouse, and the cor—
responding orthologs in Arabidopsis (Harmer et al., 2000).
Arabdiposis orthologs were obtained from Affymetrix NetAffx pro—
besets and annotations (Liu et al., 2003). These core gene time series
were further inspected manually to finally yield a set of 739
high—quality periodic signals. To extract a high—quality biological
aperiodic dataset, we start from the same body of data. To identify
transcripts unlikely to be periodic, we select the transcripts classified
as aperiodic consistently by all three programs JTK_Cycle, ARSER
and Lomb—Scargle with an associated P—value of 0.95. After further
manual inspection, this yields a set of 18 094 aperiodic signals.
Examples of signals taken at random from the BioCycleReal are
shown in Figure 4.

2.2 Time inference from single timepoint
measurements

To estimate the time associated with a transcriptomic experiment
conducted at a single timepoint, we curate the BioClock dataset

pumrn p-hn'n par-roar:

g
i
i

10

1D
-1.0
-1.0

Cr

20 40

O

20 40

u
M
o
3

Wriodir: nu'wr‘rlc mribdin Wriur‘l'm

1.0

10 00
3
ll] 00
2
10 0.0 .
i
H] 00
:

.n'——2tr"1ro (cram—1n: .g"2U"Io -cr"‘2::".ro

IpIrlmllI: apnrnnrc Ipcrlmlll: lplllnnk

10
10
1.0

10 00
i
10 00
i
0 0.0
E
-‘i.0 0.0
3%

1.0

l

0..

aperiodic aha-Mi: aperiodic Ihﬁieﬂ'ﬂ

10
IO
10
IO

00
00
00
00
g

 

 

 

IO
ID
IO
ID

 

 

20 d0 - D 40 d0 - 0 2D {0

B

Fig. 4. Samples of biological time series in the BioCycleRea. dataset. Signals in
green are periodic; signals in red are aperiodic. [Note the signals are spline-
smoothed]

starting from the same data in CircadiOmics, focusing on mouse
data only for which we have enough training data. While in prin—
ciple inference of the time can be done using the level of expression
of all the genes, exploratory feature selection and data reduction ex—
periments (not shown) show that in most cases it is sufficient to
focus on the set of core clock genes, or even a subset (see Section 4).
Thus the reduced BioClock dataset contains microarray and RNA—
Seq single time measurements for each gene transcript in the core
clock with the associated timepoint. The BioClock dataset is organ—
ized by tissue and condition. Tissues include liver, kidney, heart,
colon, glands (pituitary, adrenal), skeletal muscle, bone, white fat
and brown fat. Brain specific tissues include SCN (Suprachiasmatic
nucleus), hippocampus, hypothalamus and cerebellum. There are
also several cell—specific datasets including mouse fibroblasts and
macrophages. All the datasets in BioClock contain both control and
treatment conditions. There is great variability among the treatment
conditions (e.g. Eckel—Mahan et al., 2013; Masri et al., 2014a),
varying from gene knock out and knock down (SIRT1 and SIRT6),
to changes in diet (high fat, ketogenic), to diseases (epilepsy). It is
important to be able to assess the ability of a system to predict time
across tissues and conditions.

3 Methods

We experimented with several machine learning approaches for the
two main problems considered here. In general, the best results were
obtained using neural networks. This is perhaps not too surprising
since it is well known that neural networks have universal approxi—
mation properties and deep learning has led to state—of—the art per—
formance, not only in several areas of engineering (e.g. computer
vision, speech recognition, natural language processing, robotics)
(Hannun et al., 2014; Lenz et al., 2015; Szegedy et al., 2014), but
also in the natural sciences (Baldi et al., 2014; Di Lena et al., 2012;
Lusci et al., 2013; Quang et al., 2015). Thus here we focus exclu—
sively on deep learning approaches to build two systems,
BIO_CYCLE and BIO_CLOCK, to address the two main problems.
However, we add comparisons to k—nearest neighbors and Gaussian
processes in the Supplementary Information.

3.1 Periodicity inference from time series
measurements

3. 1. 1 Classifying between periodic and aperiodic signals

To classify signals as periodic or aperiodic, we train deep neural net—
works (DNNs) using standard gradient descent with momentum
(Rumelhart et al., 1988; Sutskever et al., 2013). We train separate
networks for data sampled over 24 and 48 h. The input to these net—
works are the expression time—series levels of the corresponding gene
(or metabolite). The output is computed by a single logistic unit
trained to be 1 when the signal is periodic and 0 otherwise, with
relative entropy error function. We experimented with many hyper—
parameters and learning schedules. In the results reported, the learn—
ing rate starts at 0.01, and decays exponentially according to
W, where t is the iteration number. The training set consists of
1 million examples, a size sufficient to avoid overfitting. The DNN
uses a mini—batch size of 100 and is trained for 50 000 iterations.
Use of dropout (Baldi and Sadowski, 2014; Srivastava et al., 2014),
or other forms of regularization, leads to no tangible improvements.
The best performing DNN found (Fig. 5 (a)) has 3 hidden layers of
size 100. We are able to obtain very good results by training
BIO_CYCLE on synthetic data alone and report test results obtained
on BioCycleme, BioCycleGauss and BioCycleRear .

112 /310'S[Buln0erOJXO'SOIJBLUJOJIIIOICI”Idllq r1101} papeopunoq

9103 ‘0g anﬁnv uo ::

i12

F. Agostinelli et aI.

 

(a) (b) v
m
m

E

BIO_CYCLE. The output is
either the binary periodic/aperiodic

BIO_CLOCK. The outputs are
the cosine and sine of the phase
classiﬁcation, or the regression
estimate of the period of the signal.

angle associated with the expression
measurement of the core clock genes.

Fig. 5. Visualizations of the deep neural networks (DNNs)

3.1.2 Estimating the period

In a way similar to how we train DNNs to classify between periodic
and aperiodic signals, we can also train DNNs to estimate the period
of a signal classified as periodic. During training, only periodic time
series are used as input to train these regression DNNs. The output
of the DNNs are implemented using a linear unit and produce an
estimated value for the period. The error function is the squared
error between the output of the network and the true period of the
signal, which is known in advance with synthetic data. Except for
the difference in the output unit, we use the same DNNs architec—
tures and hyperparameters as for the previous classification
problem.

3.1.3 Estimating the phase and the lag

After the period p, we estimate the phase ()9 of a signal s by finding
the value ()9 that maximizes the following expression:
ZtET co“? + d>)s[t], where T is the set of all timepoints. Given ()9,
the lag (i.e. at what time the periodic pattern starts) is given by g—g.

3. 1.4 Estimating the amplitude

After the phase ()9, we estimate the amplitude at by first removing any
linear trend and then comparing the variance of the signal to the
variance of a cosine signal with parameters ()9, p and amplitude 1.

The formula is shown in Equation 3, where us : fﬁth-slt] and

u. 2 972.3 + r»

 

%Z(sltl — at
or 2 ET— (3)

aZeosﬁ + <l>) — r102
tET

We cannot claim this approach is new, however, we have not
seen it in previous literature. An alternative is to measure the ampli—
tude on the smoothed time series.

3.1.5 Calculating P—Ualnes and q—Ualnes

To calculate P—values, the distribution of the null hypothesis must
first be obtained. To do this, N aperiodic signals are generated from
one of the two BioCyclesym}l datasets. Then we calculate the N out—
put values V(i) (i : 1, . . . ,N) of the DNN on these aperiodic signals.
The Iii—value for a new signal s with output value V is now
§Ziﬂ 1(V > V(i)), where 1 is the indicator function. This equa—
tion provides an empirical frequency estimate for the probability of
obtaining an output of size V or greater, assuming that the signal 5
comes from the null distribution (the distribution of aperiodic sig—
nals). Therefore, the smaller the P—value, the more likely it is that s is

periodic. The q—values are obtained through the Benjamini and
Hochberg procedure (Benjamini and Hochberg, 1995). We also
compute a posterior probability of periodic expression (PPPE) using
the method described in Allison et al. (2002), which models the dis—
tribution of P—values as a mixture of beta distributions.

3.2 Time inference from single timepoint
measurements

For this task, different machine learning methods were investigated,
including simple linear regression, k—nearest neighbors, decision
trees, shallow learning and deep learning, including unsupervised
compressive autoencoders (Baldi, 2012) with two coupled phase
(cosine/sine) units in the bottleneck layer (below and Supplementary
Information). Supervised deep learning methods give the best results
and are used in the final BIO_CLOCK system. The output of the
DNNs is implemented using two coupled output units, representing
the cosine and the sine of the phase angle (Fig. 5(b)). If the total
weighted inputs into these two units are 51 and 52 respectively, then

the values of the two outputs units are given by: 51/ 5% + 5% and

52/ 51+ 5%. These are then automatically converted into a time

(ZT). In order to better assess the effect of having data from differ—
ent tissues, we experiment with both training specialized predictors
trained on data originating from a single tissue, as well as predictors
trained on data from all tissues. The final general—purpose predictor
corresponds to a DNN trained on all the data. In each one of these
experiments, we use 5—fold cross validation on the corresponding
subset of the BioClock dataset, using architectures with 2 to 9
layers, and 100 to 600 units, to select the best network. A learning
rate of 0.1 is typically used, with an exponential decay according to
ﬁt. A visualization of the DNN is provided in Figure 5(b).

3.3 Data normalization

For both the periodicity and time inference problems, training and
testing examples are normalized to have a mean of zero and a stand—
ard deviation of one.

3.4 Software and run time

Downloadable software is currently written in R and Python and is
intended to be easy for biologists to use. While exploring different
models both Pylearn2 (Goodfellow et al., 2013) and Caffe (Jia et al.,
2014) were used. The DNNs typically take hours for training but,
once trained, can process a real—world dataset (~20 000 time series)
in about one minute, both run times corresponding to a single CPU.

4 Results

In all the tables, the best results are shown in bold.

4.1 Periodic/aperiodic classification
For comparison, the methods ARSER (ARS), Lomb—Scargle (LS) and
JTK_Cycle (JTK) are all evaluated along with the DNNs used by
BIO_CYCLE, trained on the BioCycleFom, and BioCycleGauss data—
sets. In addition, we compare to MetaCycle (MC) (Wu et al., 2016).
To identify periodic signals, ARSER uses autoregressive spectral es—
timation, Lomb—Scargle uses a periodogram, and JTK_Cycle uses
the Jonckheere—Terpstra’s and the Kendall’s tau tests. MetaCycle
combines ARSER, Lomb—Scargle and JTK_Cycle into one method.
To determine if the BIO_CYCLE results are significantly differ—
ent from other methods, the testing set is randomly split into 10

112 /310's1rzu.rnofp101xo"soncurJOJHrorq/ﬁduq r1101} papeopunoq

9103 ‘0g anBnV uo ::

Deep learning approaches for circadian rhythms

i13

 

equal—size, non—overlapping, subsets and the results from each subset
are obtained. Then, a Student’s t—test is performed between the re—
sults of the best of the two DNNs and the best of the previously
existing methods. Finally, the P—value from that test is obtained to
assess if the result differences are statistically significant. Small P—
values (such as 0.05 and below) indicate that there is a significant
difference between the methods. The P—values from the t—tests are
shown in the rightmost column in all the tables. The results focus on
periodic signals with periods around 24 h, the most common case,
however periods of 12 and 8h, corresponding to the second and
third harmonics, are analyzed in the Supplementary Information.

In the tables, the datasets BioCycleme, BioCycleGauss and
BioCycleReal are referred to as BCF, BCG and BCR, respectively.

4.1. 1 Synthetic data (BioCyclesyntb)

Results for the area under the receiver operating characteristic curve
(AUC) for the task of classifying signals as periodic or aperiodic are
shown in Table 1, and the ROC curves computed on BioCycleFom,
are shown in Figure 6. The DNNF label corresponds to the DNN
that has been trained on the BioCycleme data, and the DNNG label
corresponds to the DNN that has been trained on the BioCycleGauss
data. The ROC curves computed on BioCycleGauss are similar (not
shown). The results from Table 1 show that the DNN method has
better AUC than all the other published methods on the
BioCycleme and BioCycleGauss datasets. Though the DNN does
better when tested on data from the same distribution as it was
trained on, it still outperforms all the other previous methods, re—
gardless of which data it is trained on. A plot showing how the sig—
nal to noise ratio (SNR) affects performance is shown in Figure 7.
This plot cannot be done for the BioCycleGauss dataset, since in this
case the exact SNR is not known. The DNN outperforms all the
other published methods at all SNRs.

4.1.2 Biological data (BioCyclele)

The performance on the biological dataset is shown in Table 2.
Although the ARSER, LS and JTK_Cycle methods achieve good per—
formance on the aperiodic data, as can be expected since they were
used to label the aperiodic data, the DNN method remains very
competitive, often outperforming at least one of the other published
methods.

Table 1. AUC performance on synthetic data

 

ARS LS JTK MC DNNF DNNG t—test

 

) 0.85 0.86 0.87 0.87 0.92 0.91 0E+00

BCF 24 6) 0.72 0.81 0.76 0.81 0.85 0.84 0E+00
) 0.94 0.95 0.95 0.95 0.97 0.96 3E—06
)

 

BCF 48_8 0.83 0.86 0.78 0.86 0.89 0.89 1E—06
BCF 24_U) 0.80 0.84 0.85 0.84 0.89 0.88 0E+00
BCF 48_U) 0.89 0.92 0.83 0.92 0.94 0.93 0E+00
BCG (24_4) 0.85 0.89 0.89 0.89 0.92 0.94 0E+00
BCG (24_6) 0.73 0.85 0.78 0.85 0.88 0.89 1E—06
BCG (48_4) 0.96 0.95 0.95 0.96 0.97 0.97 5E—04
BCG (48_8) 0.90 0.91 0.80 0.92 0.93 0.93 2E—06
BCG (24_U) 0.84 0.89 0.88 0.89 0.91 0.92 0E+00
BCG (48_U) 0.93 0.94 0.85 0.94 0.95 0.96 2E—06

 

ARS(44_4) 0.99 0.98 0.97 0.99 0.99 0.99 0E+00

 

JTK(48_1) 1.00 1.00 1.00 1.00 1.00 1.00 2E—01
JTK(48_4) 0.96 0.97 0.98 0.98 0.98 0.97 1E+00

 

4.1.3 Evaluation of P—Ualue cutoffs

To investigate if the p—values obtained by BIO_CYCLE are reason—
able, the accuracy of the periodic/aperiodic classification at different
p—value cutoffs is evaluated. In addition to a p—value, BIO_CYCLE
produces a binary classification. If the output of the DNN is greater
than 0.5 the signals is labeled as periodic, otherwise, it is labeled as
aperiodic. The accuracy using this binary classification is also eval—
uated. Results are shown in Figure 8. The vertical dashed line corres—
ponds to a common p—value cutoff of 0.05. However, a proper
p—value does not guarantee that the best accuracy will be at the cut—
off of 0.05. Results show that BIO_CYCLE has the highest potential
accuracy. It also has the best accuracy at 0.05 for 2 out of the 4
plots. In addition, the binary classification of BIO_CYCLE is almost
always better than the accuracy of all the other methods at any
p—value cutoff. Histograms showing the p—values can be found in the
Supplementary Information.

4.2 Period, lag and amplitude estimation
The metric to determine how well each method estimates the period,
lag and amplitude is given by the coefficient of determination R2.

E
E

        
   
 
   

 

 

ARSER

ARSER
LS

JTK
MetaCycle
DNN,
DNNG

LS

JTK
MetaCycle
DN NF "'2
DN NG

True Positive Rate
| | | | | |

True Positive Rate
| | | | | |

 

 

 

 

 

 

 

rm M a» a 5 u 1.0 a n a z u A n s n a r 9
False Positive Rate False Positive Rate

BioCycleFom, (24,4) BioCycleFom, (24,6)

 

 

E
E

 

 

ARSE R

LS

JTK
Metacycle
DN NF “*1
DN NG

ARSER
IS

JTK
MetaCycle
DNNF
DNNG

True Positive Rate

 

 

 

 

 

 

 

 

 

 

 

on as u.» 1.» an n2 u as on In
False Positive Rate False Positive Rate

BioCycle pom, (48,4) BioCycle pom, (4878)

an n.2

Fig. 6. ROC Curves of different methods on the BioCycleForm dataset

I—c ARSER
L5
JTK

DNNF
DNNG DNNG

   

m 0.5 5D

 

.— ARSER
.— LS
.— JTK
-—- DNNF
._. DNNG

LS

JTK
MetaCycle
DN MF

DN NG

 

 

 

 

ID )5 In :5 3r: as u: .s

SNR SNR
BioCycleFom, (48,4) BioCycleFm-m (4878)

Fig. 7. AUC at various signal-to-noise ratios (SNRs) on the BioCycleForm data-
set. The lower the SNR the noisier the signal is

112 /310'S[BIIJnOrPJOJXO'SOIJBLUJOJIIlolq”K1111] r1101} papeopunoq

9103 ‘0g anBnV uo ::

i14

F. Agostinelli et al.

 

Table 2. AUC performance on the biological dataset

Table 3. Coefficients of determinations (R2) for the periods

 

ARS LS JTK MC DNNF DNNG t—test

 

ARS LS JTK MC DNNF DNNG t—test

 

BCR (24_4) 0.97 0.97 0.89 0.97 0.97 0.97 7E—01
BCR (48_1) 0.96 0.94 0.91 0.98 0.98 0.97 5E—01
BCR (48_2) 0.98 0.97 0.95 0.96 0.94 0.95 3E—01

 

 

(b)

m

— ARSER — |5 — JTK
— Metac‘icle — DNN, -- DNN,lhlnaryl
_ on“, .. DMNcmrnaryr -- Walnlllvaluecutoﬂ

— men — LS — m
— MelaCycle — mm, -- Dungarnsryr
— mmc -- DNMGKIalnlry! -- wprcsrmruscumw

 

 

 

 

 

Accuracy
Accuracy

 

 

 

 

 

an 0.2 u 0.5 as 10 on n2 n: as us In
P-Value Cutoff P-Value Cutoff

BioCycreForm (24_4) BioCycreForm (24_6)

 

(c)

w

_ as... _ r5 — m (d)
_ may... _ m, .. s~.,.....m
_ 

-- DNNuthlnary) -- Typical FValue cum

_ ARSER — LS — m
— MeraCycle — mm, -- DNerhlnary)
— mwn -- DNNGKBlnaryl -- WulcalM/aluecutnﬂ

 

 

 

 

Accuracy
Accuracy

 

 

 

 

n n 0.2

u 1 o 0.0 a z a 4 n s 0,3 1.0
P—Value Cutoff

BioCycleme (48_8)

u 0.5
P-Value Cutoff

BioCycleFurm (48_4)

Fig. 8. Accuracy of periodic/aperiodic classification at different p-value cutoffs
on the BioCycleForm dataset

The line y : x corresponds to perfect prediction. In this case, y is the
estimated value given by the method and x is the true value.
R2 measures how well the line y :x fits the points that correspond
to the true value versus the estimated value. Perfect prediction cor—
responds to y :x and corresponds to R2 : 1. The results for
estimating the period, lag and amplitude are shown in Tables 3—5,
respectively. For the BioCycleGauss dataset we cannot control or
know the exact lag or amplitude, so there are no results for
BioCycleGauss in Tables 4 and 5. These tables tell a similar story as
Table 1. The DNN outperforms the other methods in most of the
categories. Even when the DNN is tested on data associated with a
distribution that is different from the distribution of its training set,
in the majority of the cases it gives superior performance compared
to ARSER, LS and JTK_Cycle.

4.3 Missing replicates and missing data

In gene expression experiments, replicate measurements can be miss—
ing. To investigate how missing replicates affect performance, the
BioCycleme dataset which has three replicates for each timepoint
was used to assess performance with zero replicates removed at each
timepoint, one replicate removed at each timepoint and two repli—
cates removed at each timepoint. The results are shown in Figure 9
and show that JTK_Cycle is significantly affected in a negative way
by missing replicates, while the performance of all the other meth—
ods degrades gracefully with the number of missing replicates, and
minimally compared to JTK_Cycle. Missing data (timepoints at
which there are no replicates) is also handled gracefully by
BIO_CYCLE, while it is not handled at all by some of the other
methods (not shown).

 

 

BCG 24_U) 0.06 0.25 0.03 0.25 0.32 0.37 0E+00
BCG 48_U) 0.42 0.63 0.02 0.63 0.73 0.75 0E+00

BCF (24_4) 0.02 0.22 0.17 0.19 0.31 0.27 0E+00
BCF (24_6) 0.04 0.16 0.02 0.16 0.22 0.19 3E—04
BCF (48_4) 0.59 0.64 0.51 0.65 0.74 0.73 5E—05
BCF (48_8) 0.36 0.48 0.00 0.42 0.57 0.55 0E+00
BCF (24_U) 0.05 0.20 0.06 0.20 0.28 0.24 0E+00
BCF (48_U) 0.33 0.52 0.02 0.52 0.62 0.60 0E+00
BCG (24_4) 0.02 0.27 0.20 0.24 0.35 0.40 0E+00
BCG (24_6) 0.07 0.26 0.01 0.26 0.32 0.36 0E+00
BCG (48_4) 0.70 0.68 0.53 0.72 0.80 0.81 0E+00
BCG (48_8) 0.56 0.54 0.00 0.53 0.67 0.69 0E+00

(

(

 

ARS(44_4) 0.74 0.85 0.66 0.83 0.89 0.89 0E+00

JTK(48_1) 0.66 0.94 0.91 0.90 0.93 0.93 3E—03
JTK(48_4) 0.67 0.84 0.62 0.80 0.85 0.83 3E—02

 

 

Table 4. Coefficients of determination (R2) for the lags. The blank
sqaures in LS and MC is due to the programs crashing on this
dataset

 

ARS LS JTK MC DNNF DNNG t—test

 

BCF (24_4) 0.36 0.37 0.27 0.42 0.49 0.49 8E—03
BCF (24_6) 0.30 0.07 0.45 0.43 0E+00
BCF (48_4) 0.50 0.14 0.31 0.50 0.52 0.51 5E—01
BCF (48_8) 0.37 0.12 0.02 0.35 0.42 0.41 6E—03
BCF (24_U) 0.34 0.31 0.10 0.32 0.47 0.47 0E+00
BCF (48_U) 0.36 0.07 0.21 0.38 0.49 0.48 3E—04

 

ARS(44_4) 0.67 0.12 0.41 0.69 0.65 0.65 1E—01

JTK(48_1) 0.60 0.16 0.80 0.70 0.72 0.79 9E—01
JTK(48_4) 0.47 0.12 0.30 0.55 0.49 0.50 5E—01

 

 

Table 5. Coefficients of determination (R2) for the amplitudes. The
blank squares in LS and MC is due to the programs crashing on
this dataset

 

ARS LS JTK MC DNNF DNNG t—test

 

BCF (24_4) 0.81 0.63 0.86 0.87 0.81 0.81 2E—04
BCF (24_6) 0.81 0.76 0.80 0.80 0E+00
BCF (48_4) 0.82 0.55 0.87 0.84 0.75 0.75 0E+00
BCF (48_8) 0.80 0.57 0.48 0.79 0.75 0.75 2E—02
BCF (24_U) 0.68 0.62 0.84 0.85 0.80 0.80 2E—05
BCF (48_U) 0.78 0.56 0.79 0.83 0.77 0.77 1E—03

 

ARS(44_4) 0.97 0.82 0.93 0.99 0.98 0.98 0E+00

 

JTK(48_1) 0.86 0.64 0.90 0.93 0.91 0.92 0E+00
JTK(48_4) 0.72 0.43 0.71 0.74 0.71 0.72 9E—01

 

4.4 Time inference from single timepoint
measurements

4.4.1 Overall performance

BIO_CLOCK is trained using 16 core clock genes: Arntl, Per1, Per2,
Per3, Cyr1, Cry2, Nr1d1, Nr1d2, Bhlhe40, Bhlhe41, Dbp, NpasZ,
Tef, Fm02, Lonrf3 and Tsc22d3. When trained and tested on all the
data, using 70% of the data for training and the remaining 30% for
testing, it accurately predicts the time of the experiment with a mean
absolute error of 1.22 h (less than 75 min) (Table 6). We experi—
mented also with training BIO_CLOCK with an even smaller

112 /310'S[BIIJnOrPJOJXO'SOIJBLUJOJIIlolq”K1111] r1101} papeopunoq

9103 ‘0g anBnV uo ::

Deep learning approaches for circadian rhythms

i15

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

  {1.55
092—\.\ \
\
m -—- ARSER °5° -—- ARSER «
._. LS O—O LS
H JTK U -—- JTK
2' “a H MetaCycle E "'75 >\\ H MataCycle
\—
._. DNNF o—o DNNF
9.35% o—o DNNG on‘\,_ s—s DNNG .
1 055

 

 

1
Replicates Missing per Trmepoint

BioCycle pom, (24_6)

Replicates Missing perTrmepnint

BioCycle Form (24_4)

/\

 

 

 

one,
o—a ARSER 1
o—o L5 ‘
U asst—ﬂ o—c JTK .
3 o—- MetaCycle
“34 '\ o—c DNNF
._. DNNG ,

 

 

 

u 1 2 u 1 z
Replicates Missing per Timepoint Replicates Missing per Timepoint

BioCycle Form (48_4) BioCycle pom, (48_8)

 

 

 

 

Fig. 9. AUC at different levels of missing data

number of genes. For example, using only Arntl, Per1, Per2, Per3, Cry1
and Cry2, produces a mean absolute error of 3.72 h. Adding Nr1d1
and Nr1d2 to this set reduces the mean absolute error to 1.65 h.

4.4.2 Training and testing on different organs/tissues

Table 6 shows the mean absolute errors obtained when training
BIO_CLOCK on data from certain organs/tissues and testing it on
data from a different set of organs/tissues. All the data is from mice
and under WT condition. The only datasets for which we have
enough data for training correspond to liver and brain (when aggre—
gating all the corresponding datasets). We form two additional sets
(Set 1 and Set 2) by combining data from other organs. The first cor—
responds to combined data from the adrenal gland, fat, gut, kidney,
lung and muscle (Set 1). The second corresponds to combined data
from the aorta, colon, fibroblast, heart, macrophages and pituitary
gland (Set 2). Finally, all of the aforementioned data is combined to
form a bigger dataset (All). In all the experiments reported in
Table 6, the data are split using a 70/30 training/test ratio, and tests
sets never overlap with any of the corresponding training sets. The
DNNs perform best when trained and tested on the same organ/tis—
sue or sets of organ/tissues or when trained on all the organs/tissues.
The DNNs perform significantly worse when trained and tested on
data with diverging origins. However, in all cases, the DNN trained
on the combined dataset does almost as well as, or better than, the
corresponding specialized DNN.

4.4.3 Training and testing on different conditions

The collected data also includes data from mice under experimental
conditions. The experimental conditions include high—fat and keto—
genic diets, epilepsy and SIRT1 and SIRT6 knockouts. This dataset
is too small to build a training and testing set. However, one can test
the BIO_CLOCK DNN trained on the combined mice organs under
normal conditions on this dataset. This experiment yields a mean
absolute error of 2.57 h.

4.4.4Annotation of the GEO database

Finally, we extract all the mouse gene expression experiments con—
tained in the GEO repository (Edgar et al., 2002) and run
BIO_CLOCK on them. A file containing all the corresponding
imputed times is available from the CircadiOmics web portal.

Table 6. Cross organ mean absolute error (MAE) comparison of
BIO_CLOCK

 

Testing

Liver Brain Set1 Set2 All

 

Liver 1.21 5.18 3.78 4.77 3.78
Training Brain 3.94 1.50 3.28 5.39 3.84

Set1 4.06 4.25 2.03 4.69 3.58
Set2 2.31 4.10 2.14 0.75 2.00
All 1.28 1.66 1.49 0.70 1.22

 

5 Conclusion

Deep learning methods can be applied to high—throughput circadian
data to address important challenges in circadian biology. In par—
ticular, we have developed BIO_CYCLE to detect molecular species
that oscillate in high—throughput circadian experiments and extract
the characteristics of these oscillations. Remarkably, BIO_CYCLE
can be trained with large quantities of synthetic data preventing any
kind of overfitting. We have also developed BIO_CLOCK to infer
the time at which a transcriptomic sample was collected from the
level of expression of a small number of core clock genes. Both
methods will be improved as more data becomes available and,
more generally, deep learning methods are likely to be useful to ad—
dress several other related circadian problems, such as analyzing
periodicity in high—throughput circadian proteomic data, or infer—
ring sample time in different species. In particular, developing meth—
ods for annotating the time of all the human gene expression
experiments, contained in GEO, and other similar repositories,
would be valuable. Such annotations could be important for im—
proving the interpretation of both old and new data and discovering
circadian driven effects that may be important in precision medicine
and other applications, for instance to help determine the optimal
time for administering certain drugs.

Acknowledgements

We thank Yuzo Kanomata for helping develop and maintain the
CircadiOmics system and web site, and NVDIA for hardware donations.

Funding

This work was supported by grants from the National Science Foundation
(NSF 115—1550705) and the National Institutes of Health (NIH DA 036984).

Conﬂict of Interest: none declared.

References

Allison,D.B. et al. (2002) A mixture model approach for the analysis of micro-
array gene expression data. Comput. Stat. Data Anal., 39, 1—20.

Andrews,J.L. et al. (2010) Clock and bmall regulate myod and are necessary
for maintenance of skeletal muscle phenotype and function. Proc. Natl.
Acad. Sci. USA, 107, 19090—19095.

Antunes,L.C. et al. (2010) Obesity and shift work: chronobiological aspects.
Nutr. Res. Rev., 23,155—168.

Baldi,P. (2012) Autoencoders, Unsupervised Learning, and Deep
Architectures. ]. Mach. Learn. Res., 27, 37—50 (Proceedings of 2011 ICML
Workshop on Unsupervised and Transfer Learning).

Baldi,P. and Sadowski,P. (2014) The dropout learning algorithm. Artif. Intell.,
210C, 78—122.

Baldi,P. et al. (2000) Assessing the accuracy of prediction algorithms for classi—
ﬁcation: an overview. Bioinformatics, 16, 412—424.

112 /310's1rzu.rnofp101xo"soncuiJOJHioiq/ﬁduq r1101} papeopunoq

9103 ‘0g isanV uo ::

i16

F. Agostinelli et al.

 

Baldi,P. et al. (2014) Searching for exotic particles in high-energy physics with
deep learning. Nat. Commun., 5, Article No. 4308.

Bellet,M.M. et al. (2013) Circadian clock regulates the host response to sal-
monella. Proc. Natl. Acad. Sci., 110, 9897—9902.

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: a
practical and powerful approach to multiple testing. I. R. Stat. Soc. Ser. B
(Methodological), 5 7, 289—300.

Brown,S.A. et al. (2012) (re)inventing the circadian feedback loop. Dev. Cell,
22, 477—487.

Covington,M.F. et al. (2008) Global transcriptome analysis reveals circadian
regulation of key pathways in plant growth and development. Genome
Biol., 9, R130.

Deckard,A. et al. (2013) Design and analysis of large—scale biological rhythm
studies: a comparison of algorithms for detecting periodic signals in biolo-
gical data. Bioinformatics, 29, 3174—3180.

Di Lena,P. et al. (2012) Deep architectures for protein contact map prediction.
Bioinformatics, 28, 244 9—245 7.

Dibner,C. et al. (2010) The mammalian circadian timing system: organization
and coordination of central and peripheral clocks. Annu. Rev. Physiol., 72,
5 1 7—5 49.

Duvenaud,D. (2014). Automatic model construction with Gaussian processes.
Ph.D. thesis, University of Cambridge.

Dyar,K.A. et al. (2014) Muscle insulin sensitivity and glucose metabolism are
controlled by the intrinsic muscle clock. Mol. Metab., 3, 29—41.

Eckel-Mahan,K. and Sassone-Corsi,P. (2009) Metabolism control by the circa-
dian clock and vice versa. Nat. Struct. Mol. Biol., 16, 462—467.

Eckel-Mahan,K.L. et al. (2008) Circadian oscillation of hippocampal mapk
activity and camp: implications for memory persistence. Nat. Neurosci., 11,
1074—1082.

Eckel-Mahan,K.L. et al. (2012) Coordination of the transcriptome and
metabolome by the circadian clock. Proc. Natl. Acad. Sci. USA, 109,
5541—55 46.

Eckel-Mahan,K.L. et al. (2013) Reprogramming of the circadian clock by nu—
tritional challenge. Cell, 155, 1464—1478.

Edgar,R. et al. (2002) Gene expression omnibus: NCBI gene expression and
hybridization array data repository. Nucleic Acids Res., 30, 207—210.
PMID: 11752295.

Froy,O. (2010) Metabolism and circadian rhythms — implications for obesity.
Endocr. Rev., 31, 1—24.

Froy,O. (2011) Circadian rhythms, aging, and life span in mammals.
Physiology (Bethesda), 26, 225—235.

Gerstner,I.R. et al. (2009) Cycling behavior and memory formation.
I. Neurosci., 29,12824—12830.

Glynn,E.F. et al. (2006) Detecting periodic patterns in unevenly spaced gene
expression time series using lomb — scargle periodograms. Bioinformatics,
22, 310—316.

Goodfellow,I.I. et al. (2013) Pylearn2: a machine learning research library.
arXiv Preprint arXiv, 13 08.4214.

Hannun,A. et al. (2014) Deepspeech: Scaling up end—to—end speech recogni—
tion. arXiv Preprint arXiv,. 1412.5567.

Harmer,S.L. et al. (2000) Orchestrated transcription of key pathways in arabi-
dopsis by the circadian clock. Science, 290, 2110—2113.

Harmer,S.L. et al. (2001) Molecular bases of circadian rhythms. Annu. Rev.
Cell Devel. Biol., 17, 215—253.

Hughes,M.E. et al. (2009) Harmonics of circadian gene transcription in mam—
mals. PLoS Genet., 5, e1000442.

Hughes,M.E. et al. (2010) Itk_cycle: an efﬁcient nonparametric algorithm for
detecting rhythmic components in genome—scale data sets. I. Biol. Rhythms,
25, 372—380.

Iia,Y. et al. (2014) Caffe: Convolutional architecture for fast feature embed—
ding. arXiv Preprint arXiv, 1408.5 093 .

Karlsson,B. et al. (2001) Is there an association between shift work and having
a metabolic syndrome? Results from a population based study of 27,485
people. Occup. Environ. Med., 58, 747—752.

Knutsson,A. (2003) Health disorders of shift workers. Occup. Med. (Lond),
53, 103—108.

Kohsaka,A. et al. (2007) High-fat diet disrupts behavioral and molecular cir—
cadian rhythms in mice. Cell Metab., 6, 414—421.

Kondratov,R.V. et al. (2006) Early aging and age—related pathologies in mice
deﬁcient in bmall, the core component of the circadian clock. Genes Devel.,
20,1868—1873.

Lamia,K.A. et al. (2008) Physiological signiﬁcance of a peripheral tissue circa-
dian clock. Proc. Natl. Acad. Sci. USA, 105, 15172—15177.

Lenz,I. et al. (2015) Deep learning for detecting robotic grasps. Int. I. Robot.
Res., 34, 705—724.

Liu,G. et al. (2003) Netaffx: affymetrix probesets and annotations. Nucleic
Acids Res., 31, 82—86.

Lusci,A. et al. (2013) Deep architectures and deep learning in chemoinfor—
matics: the prediction of aqueous solubility for drug-like molecules.
I. Chem. Inf. Model., 53,1563—1575.

Masri,S. et al. (2013) Circadian acetylome reveals regulation of mitochondrial
metabolic pathways. Proc. Natl. Acad. Sci., 110, 3339—3344.

Masri,S. et al. (2014a) Partitioning circadian transcription by sirt6 leads to
segregated control of cellular metabolism. Cell, 158, 65 9—672.

Masri,S. et al. (2014b) SIRT6 deﬁnes circadian transcription leading to control
of lipid metabolism. Cell, 15 8, 65 9—672.

Miller,B.H. et al. (2007) Circadian and clock-controlled regulation of the
mouse transcriptome and cell proliferation. Proc. Natl. Acad. Sci. USA,
104, 3342—3347.

Monnier,A. et al. (2010) Orchestrated transcription of biological processes in
the marine picoeukaryote ostreococcus exposed to light/dark cycles. BMC
Genomics, 1 1, 192.

Moore,R.Y. and Eichler,V.B. (1972) Loss of a circadian adrenal corticosterone
rhythm following suprachiasmatic lesions in the rat. Brain Res., 42, 201—206.

Panda,S. et al. (2002) Coordinated transcription of key pathways in the mouse
by the circadian clock. Cell, 109, 307—320.

Partch,C.L. et al. (2014) Molecular architecture of the mammalian circadian
clock. Trends Cell Biol., 24, 90—99.

Patel,V. et al. (2012) Circadiomics: integrating circadian genomics, transcrip—
tomics, proteomics, and metabolomics. Nat. Methods, 9, 772—773.

Patel,V.R. etal. (2015) The pervasiveness and plasticity of circadian oscillations:
the coupled circadian—oscillators framework. Bioinformatics, 31, 3181—3188.

Pizarro,A. et al. (2012) Circadb: a database of mammalian circadian gene ex—
pression proﬁles. Nucleic Acids Res, http://nar.oxfordjournals.org/contentl
early/2012/11/23/nar.gks1161.full.

Quang,D. et al. (2015) Dann: a deep learning approach for annotating the
pathogenicity of genetic variants. Bioinformatics, 31, 761—763.

Ralph,M.R. et al. (1990) Transplanted suprachiasmatic nucleus determines
circadian period. Science, 247, 975—978.

Rasmussen,C.E. (2004) Gaussian Processes for Machine Learning. Advanced
lectures on machine learning. Springer, Berlin Heidelberg, pp. 63—71.

Rumelhart,D.E. et al. (1988) Learning representations by back—propagating
errors. Cognit. Model., 5, 3.

Schibler,U. and Sassone—Corsi,P. (2002) A web of circadian pacemakers. Cell,
111, 919—922.

Shariﬁan,A. et al. (2005) Shift work as an oxidative stressor. I. Circadian
Rhythms, 3, 15.

Shi,S. et al. (2013) Circadian disruption leads to insulin resistance and obesity.
Curr. Biol., 23, 372—381.

Srivastava,N. et al. (2014) Dropout: a simple way to prevent neural networks
from overﬁtting. I. Mach. Learn. Res., 15, 1929—1958.

Storch,K.F. et al. (2002) Extensive and divergent circadian gene expression in
liver and heart. Nature, 417, 78—83.

Stratmann,M. and Schibler,U. (2006) Properties, entrainment, and physio—
logical functions of mammalian peripheral oscillators. I. Biol. Rhythms, 21,
494—506.

Straume,M. (2004) Dna microarray time series analysis: automated statistical
assessment of circadian rhythms in gene expression patterning. Methods
Enzymol., 383,149—166.

Sutskever,I. et al. (2013) On the importance of initialization and momentum
in deep learning. In: Proceedings of the 30th International Conference on
Machine Learning (ICML-13), pp. 1139—1147.

Szegedy,C. et al. (2014) Going deeper with convolutions. arXiv Preprint
arXiv, 1409.4842.

TakahashiJS. et al. (2008) The genetics of mammalian circadian order and dis-
order: implications for physiology and disease. Nat. Rev. Genet., 9, 764—775.

112 /310's1rzu.rnofp101xo"soncuiJOJHioiq/ﬁduq r1101} papeopunoq

9103 ‘0g isanV uo ::

Deep learning approaches for circadian rhythms

i17

 

Turek,F.W. et al. (2005 ) Obesity and metabolic syndrome in circadian clock
mutant mice. Science, 308, 1043—1045.

Vijayan,V. et al. (2009) Oscillations in supercoiling drive circadian gene ex—
pression in cyanobacteria. Proc. Natl. Acad. Sci., 106, 225 64—225 68.

Wu,G. et al. (2016) Metacycle: An Integrated r Package to Evaluate
Periodicity In Large Scale Data, Cold Spring Harbor Labs Iournals.

Yan,I. et al. (2008) Analysis of gene regulatory networks in the mammalian
circadian rhythm. PLoS Comput. Biol., 4, e1000193.

Yang,R. and Su,Z. (2010) Analyzing circadian expression data by harmonic
regression based on autoregressive spectral estimation. Bioinformatics, 26,
i168—i174.

Yoo,S.H. et al. (2004) Period2zzluciferase real—time reporting of circadian dy-
namics reveals persistent circadian oscillations in mouse peripheral tissues.
Proc. Natl. Acad. Sci. USA, 101, 5339—5346.

Zhang,R. et al. (2014) A circadian gene expression atlas in mammals: Implications
for biology and medicine. Proc. Natl. Acad. Sci., 11 1, 16219—16224.

112 /310's1rzu.rnofp101xo"soncuiJOJHioiq/ﬁduq r1101} papeopunoq

9103 ‘0g isanV uo ::

