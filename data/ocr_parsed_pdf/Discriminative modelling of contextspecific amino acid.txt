ORIGINAL PAPER

Vol. 28 no. 24 2012, pages 3240—3247
doi: 10. 1 093/bioinformatics/bt5622

 

Sequence analysis

Advance Access publication October 17, 2012

Discriminative modelling of context-specific amino acid

substitution probabilities

Christof Angermiiller‘, Andreas Biegert2 and Johannes deing”

1Gene Center Munich and Department of Biochemistry, Ludwig-Maximilians-Universtat MUnchen, 81377 Munich,
Germany and 2Genedata, Lena-Christ-Strasse 50, 82152 Martinsried, Germany

Associate Editor: Alfonso Valencia

 

ABSTRACT

Motivation: Protein sequence searching and alignment are fundamen-
tal tools of modern biology. Alignments are assessed using their simi-
larity scores, essentially the sum of substitution matrix scores over all
pairs of aligned amino acids. We previously proposed a generative
probabilistic method that yields scores that take the sequence context
around each aligned residue into account. This method showed dras-
tically improved sensitivity and alignment quality compared with
standard substitution matrix-based alignment.

Results: Here, we develop an alternative discriminative approach to
predict sequence context-specific substitution scores. We applied our
approach to compute context-specific sequence profiles for Basic
Local Alignment Search Tool (BLAST) and compared the new tool
(CS-BLASTdis) to BLAST and the previous context-specific version
(CS-BLASTgen). On a dataset filtered to 20% maximum sequence
identity, CS-BLASTdisis was 51% more sensitive than BLAST and
17% more sensitive than CS-BLASTgenin, detecting remote homo-
logues at 10% false discovery rate. At 30% maximum sequence iden-
tity, its alignments contain 21 and 12% more correct residue pairs than
those of BLAST and CS-BLASTgen, respectively. Clear improvements
are also seen when the approach is combined with PSI-BLAST and
HHblits. We believe the context-specific approach should replace
substitution matrices wherever sensitivity and alignment quality are
critical.

Availability: Source code (GNU General Public License, version 3) and
benchmark data are available at ftp://too|kit.genzentrum.|mu.de/pub/
csblastl.

Contact: soeding@genzentrum.Imu.de

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on August 3, 2012; revised on September 28, 2012;
accepted on October 14, 2012

1 INTRODUCTION

Inferring the functions and the structures of proteins from those
of homologous proteins has proven to be an extremely powerful
approach in biology. To predict a homologous relationship be-
tween two proteins, their sequences are aligned such as to maxi-
mize the sum of scores over all aligned pairs of amino acid
residues minus penalties for gaps. A sufﬁciently high score indi-
cates a homologous relationship. The standard method for

 

*To whom correspondence should be addressed.

calculating scores for pairs of amino acids is the substitution
matrix method (Dayhoff and Schwartz, 1972; Henikoff and
Henikoff, 1992). The substitution score for amino acids a and
b can be written as S(a, b) = const x log(P(a|b)/P(a)), where
P(a|b) is the probability of amino acid b mutating into a, and
P(a) is the background probability of a. The probabilities P(a)
and P(a|b) are derived by counting the numbers of amino acids a
and of aligned pairs (a, b) in a large set of trusted sequence
alignments.

As protein sequences of folded domains are constrained by the
necessity to maintain a stable structure, the substitution prob-
abilities for a given residue are largely determined by the struc-
tural context within which it resides. Substitution matrices have,
therefore, been trained for particular structural contexts, for ex-
ample, depending on the residue’s secondary structure, solvent
accessibility or polarity (Overington et al., 1992; Rice and
Eisenberg, 1997; Shi et al., 2001; Goonesekere and Lee, 2008).
Methods that infer substitution probabilities of amino acids
solely from their local sequence context have the advantage
that they do not require the structure of the query protein to
be known (Jones et al., 1994; Baussand et al., 2007; Huang and
Bystroff, 2006). In Biegert and Soding (2009), we formulated a
general approach to predict substitution probabilities from se-
quence context; for each residue in the query sequence, we com-
pared the 13—residue window centred around it with a pre-
computed library of 13-column sequence proﬁles that represent
all known sequence contexts. The substitution probabilities
are computed as the weighted mixture of the central columns
in these context profiles, with weights proportional to the simi-
larity between the context proﬁle and the 13-residue sequence
context.

The approach was based on a generative model for learning
context-speciﬁc substitution probabilities. The goal of this work
is to further improve the prediction accuracy by developing a
discriminative machine learning method for the prediction of
substitution probabilities. As in our previous work, we apply
the method to enhance Basic Local Alignment Search Tool
(BLAST) by storing the predicted substitution probabilities
for the query sequence in a sequence proﬁle and jump-starting
PSI-BLAST with it. We also apply the new method to gener-
ate context-speciﬁc pseudocounts for PSI-BLAST (Altschul
et al., 1997) and HHblits (Remmert et al., 2011), our highly
sensitive iterative sequence search software based on the pair-
wise comparison of hidden Markov models (HMMs). In all
cases, we observe signiﬁcant improvements over the generative
version.

 

3240 © The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com

112 /310's112u1n0fp10}x0"sotJBurJOJutotq/ﬁduq 11101} papBOIIIAAOG

91oz ‘Og anﬁnV uo ::

Modelling of amino acid substitution probabilities

 

2 METHODS

2.1 Generative versus discriminative models

A generative model explicitly describes the joint distribution
P(x, y) = P(xly)P(y) over the observed variable x and the
target variable y. A generative model allows one to generate
new data points (x, y). Usually, it models the probabilities
P(xly) and P(y) separately (Sutton and McCallum, 2006). To
predict the unobserved target variable y given the observed
data x, the generative model uses Bayes’ theorem,
P(ylx) = P(xly)P(y)/[2y P(xly)P(y)]. A discriminative model
directly models the probability P(ylx) of the target variable con-
ditioned on the observed variable (Rubinstein and Hastie, 1997;
Sutton and McCallum, 2006). It does not model the distribution
of the input variable x, which is not needed to predict y given x.
Generative models are commonly trained by maximizing the
joint probability n” P(x,,,y,,) over the training data (men),
whereas discriminative models are usually trained by maximizing
the conditional probability n” P(ynlxn). Therefore, if the goal is
to predict y given x, discriminative models seem more appropri-
ate (Ng and Jordan, 2001; Caruana and Mizil, 2006).

2.2 Discriminative model for context-speciﬁc substitution
probabilities

Given a query sequence x1, .. . , xL, we want to predict
context-speciﬁc substitution probabilities P(alCi). P(alCi) is the
probability to observe amino acid a given sequence context C).
The context C,- describes the sequence of l:2d+ 1 amino acids
around position i of the input sequence. More precisely, C,- is a
binary profile, C,(j, a) = I(x,-+j = a) for j e {—d, ...,d}, whose
entries are 1 if x,-+j = a and zero otherwise.

Like the generative approach in Biegert and Soding (2009)
(summarized in the Supplementary Material), the discriminative
approach for modelling the substitution probabilities P(alCi) is
again based on K context states, indexed by k e {1, . . . , K}. Each
context state k is characterized by the following real-valued par-
ameters: emission weights vk(a), bias weights 71k and context
weights Ak(j, a). The emission probabilities P(alk) from context
state k are given by the emission weights as follows:

Hulk) : Zoexpuxa» (1)
:1 expuxao)

In the generative model, the probability for context state k
given context C,- was obtained with Bayes’ theorem as
P(ler) = P(Crlk)P(k)/[Zk/ P(Crlk)P(k)], where P(Crlk)P(k)
was modelled with a multinomial distribution, and the previous
cluster probabilities P(k) were model parameters. In the discrim-
inative approach, we model P(lei) directly by the exponential
of an affine function of the context count profile Cl-(j, a),

d 20
P(k|C,-) 2 ﬁrm <7Tk + 2 2M}; a)Ci-(1; m) (2)

j=7d a=l

with a normalization constant Z(C,~) that normalizes P(lei)
to 1.

The bias weights 71k quantify how much cluster k is preferred
over the other clusters and roughly correspond to the P(k) of the

generative model. The context information is encoded by the
context weights; Ak(j, a) is positive if amino acid a is preferred
in column j and negative otherwise. The no, a) corresponds to
the probabilities pk(j, a) of the context profiles of the generative
model [see Equations ($7) in Supplementary Material for
details].

As in the generative model, we assume that the emitted amino
acid a only depends on the context through the context states k:

K K
P(alCr) = Emma) = ZP(aik)P(kic.-) (3)
k=l k=1

In other words, the target distribution P(alCi) is obtained by
mixing the emission probabilities P(alk) of each context state k
weighted by the similarity P(lei) of C,- to k. In essence, our
discriminative model is a logistic regression maximum entropy
classiﬁer (Ng and Jordan, 2001; Rubinstein and Hastie, 1997) for
discriminating between context states k given C). Figure 1 illus-
trates the computation of the context-speciﬁc substitution prob-
abilities P(alCi).

To train the model parameters, abbreviated as (7T,)\.,1)), we
constructed a training set consisting of N: 6 x 106 training
pairs (C1,'El), ...,(CN,'EN), where (Cm'En) was sampled from a
multiple sequence alignment (MSA) with query sequence x and
sequence proﬁle g at position i(n). C” describes the sequence
context of x at position i(n), Cn(j, a) = I(x,-(,,)+j = a). The vector
E, stores how often each amino acid a occurs in alignment
column i(n), 'En(a) = Nq(i(n)) q(i(n), a). Here, Nq(i) is the effective
number of sequences in column 1' of the MSA from which g was
built. It measures the diversity of the profile and is the

Query sequence
with current
context window Ci

  

Context-speciﬁc
profile

Fig. 1. Discriminative model for computing context-speciﬁc substitution
probabilities. For each position i in the query, the context C,- (red
window) is compared with all context states k. The 13-oolumn coloured
histogram blocks show the distribution of amino acids in the context
states [box height ocexp(Ak(j,a))]. Blue bars indicate the ‘weight’ of
each column [mean absolute deviation of the MU, a) from their
median]. The emission probabilities P(alk) of the context states are rep-
resented by separate histogram columns. These emission probabilities are
weighted with P(lei) and summed up to produce the column of substi-
tution probabilities in the context-speciﬁc proﬁle. CS-BLAST then
jump-starts PSI-BLAST with this proﬁle

 

3241

112 /310'S[BIIJHO[pJOJXO'SOIJBLUJOJIIIOIq/ﬂduq 11101} papnolumoq

91oz ‘Og isnﬁnV uo ::

C.Angermiiller et al.

 

exponential of the mean entropy of the amino acid probabilities
over all proﬁle columns (Supplementary Material).

The generative model was trained by maximizing the product
over all probabilities P(Cn) that context C” can be generated by a
mixture of K context proﬁles pk. However, the actual goal should
rather be to predict P(alCn), the frequency of a given context C",
not to learn the distribution of the contexts C", which are
observed anyway. We, therefore, trained our model parameters
71, A, v by maximizing the logarithm of the conditional probabil-
ity of target amino acid distributions E), given the observed se-
quence contexts C” in the training set as follows:

N
f(7t, A, v) = log (P(n, A, v) n P(En|C,,, n, A, 11))  max (4)

n=1

Here, P(EnlCn, n, A, 1)) follows a multinomial distribution,

20 N
log P(En |C,,) = Z P(alCn, 71', A, v)°”(a) + const (5)
a=l
whose parameters P(alCi, n, A, v) are calculated according to
Equations (173). The previous probability P(n, A, v) is modelled
as product of Gaussian distributions with zero means and with
SDs a,” o]- : ocemerym and a, as follows:

K 2 d 20 - 2 20 2
71k MU, a) Vk(a)
P(7T, A, 1)) 0( exp [i=1 <— g — E  — a 203

71 j=7d :1 =1

 

 

We used stochastic gradient descent (Bottou, 2004) with initial
learning rate no for optimizing the log conditional probability f in
Equation (4) (see Supplementary Material).

The approach described so far can easily be generalized to
sequence profiles in a way that all equations (15) remain valid
without change. A sequence proﬁle q is built from a MSA of
sequences that are homologous to the query sequence. The pro-
ﬁle probabilities q(i, a) correspond to the relative frequencies of
residues a e {1, ...,20} in alignment column i. The context C,-
describes the number of effective residue counts C,-(j, a) at pos-
itions (i — d, ..., i + d) of profile q, C,-(j, a) = Nq(i+J) q(i +j, a),
where Nq(i) is the effective number of sequences in column i of
the query MSA.

2.3 CS—BLAST and CSI-BLAST

Our homology search tool CS-BLAST extends BLAST by
context-specific (CS) substitution probabilities that are either
derived with the generative model (CS-BLASTgen) or with the
discriminative model (CS-BLASTdis). Analogously, CSI-BLAST
is our context-speciﬁc iterative (CSI) version of position-speciﬁc
iterative BLAST (PSI-BLAST); given a query proﬁle q,
CSI-BLAST first computes the pseudocount profile with substi-
tution probabilities P(alCi), and then mixes it with the query
proﬁle q(i, a) in a way similar to PSI-BLAST (Altschul et al.,
1997) as follows:

p.50; a) = (1 — 101103 a) + TrP(alCr)- (6)
The pseudocount admixture coefficient I),
II! + 1
Ti 2  
ll] + Nqo)

attains its maximum of (p when the query profile consists of a
single sequence (Nq(i) = 1). When the effective number of se-
quences Nq(i) is large, the relative contribution of the pseudo-
count proﬁle is reduced.

We then jump-start PSI-BLAST with a checkpoint ﬁle con-
taining the proﬁle matrix pCS multiplied by a constant 2". The
proﬁle-to-sequence bit score between proﬁle column i and resi-
due a that PSI-BLAST calculates from this checkpoint file is

‘ (3
some A a) = 1082 (p—“gggz )

(8)
where P(a) is the background probability of a. The factor 2‘S
translates into a constant score offset of 8 bits. This offset con-
trols the trade-off between the alignment sensitivity and the
alignment precision (see Section 3.3).

3 RESULTS

3.1 Datasets and parameter optimization

The structural classiﬁcation of proteins (SCOP) database (Murzin
et al., 1995) provides a hierarchical clustering of protein domains
with known structures and is the defacto standard for evaluating
sequence search tools. We filtered the SCOP database with a max-
imum pairwise sequence similarity of 20% (SCOP20) and also
30% (SCOP30), 40% (SCOP40), 60% (SCOP60) and 80%
(SCOP80). We randomly assigned every fifth fold to the optimiza-
tion set (1329 sequences, 215 folds in SCOP20) and all remaining
folds to the test set (5287 sequences, 862 folds in SCOP20). This
ensures that the optimization set does not share homologous se-
quences with the test set. We performed an all-against-all com-
parison and deﬁned members belonging to the same fold as true
positives (TPs) and those of different folds as false positives (FPs).
Pairs with both proteins within the four- to eight-bladed
ﬂ-propellers (SCOP fold IDs b.6Gb.70) were treated as unknown,
and the same for Rossman-like folds (c.2ic.5, 6.30, 6.66, 6.78, c. 79,
c.111) and a-helical and 4Fe-4S ferredoxins (a.1.2, d.58.1).

The discriminative model has several adjustable parameters. As
shown in (Biegert and Soding, 2009), not only the sensitivity but
also the computation time increase with the number of context
states K and the window length I. We chose K: 4000 and l = 13 as
a trade-off between sensitivity and run time. Further parameters
are the pseudocount admixture parameters (p and 1/1, the score
offset 8, the previous parameters 0,1, ocemer, y and UV, and the ini-
tial learning rate no. The generative model had positional weight
factors wcenter and )3 instead of the previous parameters.

The optimum setting of the parameters for the generative and
discriminative models was determined by maximizing the mean
receiver operating characteristic ﬁve (ROC5) score on the opti-
mization set. The mean ROC5 score is the same as the area under
the ROC5 curve, which is explained in Section 3.2. The mean
ROC5 score is a single numerical value that measures the mean
sensitivity on all query sequences and is robust with respect to
overtraining.

We iteratively optimized each parameter in turn using line
search, several times for each parameter. We found
(<p = 0.88, 1/1 = 14, weemer = 1.6,)3 = 0.85) as the optimum par-
ameter setting for the generative model and
(<p = 1.0,1/1 215,0,r =1.0,acemer = 1.6, y = 0.85,a,, = 1.0,

 

3242

112 /310'S[BIIJHO[pJOJXO'SOTIBLUJOJIITOICI”K1111] 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

Modelling of amino acid substitution probabilities

 

no 2 0.13) for the discriminative model. The score offset 8 was
manually set. Choosing a negative score offset increases the
alignment precision (Fig. 3) and the reliability of the reported
E—Values (Supplementary Fig. S4), but it simultaneously de-
creases the alignment sensitivity. As a compromise, we chose
8 = —0.005 bits for both models.

3.2 Sensitivity

We analysed the sensitivity of NCBI BLAST (blastpgp, version
2.2.26), CS-BLASTgen and CS—BLASTdis by using two comple-
mentary methods, the receiver operating characteristic (ROC)
analysis and the ROC5 analysis.

The ROC plot (Fig. 2A) shows the number of TPs versus FPs
up to a certain E—Value threshold for the SCOP20 test set. It
measures how well the matches are ranked by the E—Value
across all database searches. In Soding and Remmert (2011), it
was argued that it is important to weight down the contribution
of FP and TP pairs from large superfamilies to avoid large super-
families from dominating the ROC plot. Indeed, in Biegert and
Séding (2009), we reported that CS-BLAST is 139% more sen-
sitive than BLAST at a false discovery rate (FDR) of 20% if FPs
and TPs are weighted by 1/(size of the query/s family). This
number drops to 40% if the size of the superfamin is used in-
stead. To be even more conservative, we, therefore, used fold-
weighted FPs/TPs.

CS—BLASTdis detects 20 and 17% more homologues than
CS-BLASTgen at a FDR of 1 and 10%, respectively.
Compared with BLAST, CS-BLASTdis ﬁnds 43 and 51%
more homologues, respectively. The improvement of
CS-BLASTgen over BLAST could be nearly doubled by
CS-BLASTdis. If FPs and TPs are weighted by the reciprocal
size of the query’s family instead of its fold, the improvements
are even stronger (Supplementary Fig. S1).

We tested the sensitivity of the iterative search tool
CSI-BLAST by performing all but the last search iteration
against NCBI’s non-redundant database with 16 million se-
quences to create a MSA (E-Value inclusion threshold 10’3),
which was then used for searching the SCOP20 database. With
two iterations, CSI-BLASTdis is 4.7 and 4.5% more sensitive
than CSI-BLASTgen at an FDR of 1 and 10%, respectively,
and 26.9 and 21.5% more sensitive than BLAST, respectively.
Note that two iterations CSI-BLASTdis yield better results than
ﬁve iterations of PSI-BLAST.

In contrast to the ROC plot, the ROC5 plot (Fig. 2B) reveals
how reliably hits are ranked within each database search. It is
defined as the normalized area under the ROC curve until the
ﬁfth FP. An ROC5 plot shows the fraction of query sequences
whose ROC5 score is above the value on the x-axis. It is more
robust than the ROC plot analysis, which is prone to overtrain-
ing, as a few families of high-scoring FPs can greatly inﬂuence
the ROC plot (Soding and Remmert, 2011).

CS—BLASTdis improves the mean ROC5 score by 9.5% over
CS-BLASTgen and by 39.46% over BLAST. The sensitivity in-
creases most for cases with a mean ROC5 score between 0.1 and
0.5. After two search iterations, the ROC5 score is still 4.2 and
19% higher compared with CSI-BLASTgen and PSI-BLAST,
respectively. Figure 2C and Supplementary Figure S1 show
that the improvements are still appreciable in databases

 

 

A ------ -- 5iter. PSI-BLAST:
2 iter. CSl-BLASTHS
2 iter. CSl-BLASTgm
2 iter. PSI-BLAST
CS-BLASTds ;
U, CS-BLASTgen ;
a) BLAST I
> .
'43
'ﬁ
0
o.
w
3
b
g
.C
as
'a
$
3
o
LL
Fold-weighted false positives
B ' ------ -- 5 iter. LAST
— 2 iter. CSI-BLASTds
— 2 iter. CSl-BLASTgen
— 2 iter. PSI-B LAST
— CS-BLASTds
— CS-BLASTgeI
— BLAST
In
.9
1.
(U
3
U
._
o
C
.9
u
U
E
LL
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Mean ROC5 score
CS-B ds
SCOPSO CS-B LASTgen
SCOPSO BLAST
SCOP40 CS-B LASTds
SCOP40 CS-B LASTgm
------ -- SCOP40 BLAST
— SCOP20 CS-B LASTds
— SCOP20 CS-B LASTgen
a — SCOP20 BLAST
'E
w
3
c-
._
o
C
.9
L.
U
E
LL

 

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Mean ROC5 score

Fig. 2. Sensitivity to detect homologous sequences for BLAST,
PSI-BLAST, the generative and discriminative versions of CS-BLAST
(CS-BLASTgen, CS-BLASTalis), and CSI-BLAST. (A) ROC plot showing
the number of true-positive results found (same fold) versus false-positive
results (different fold), weighted by 1/(size of the query’s fold), on the
SCOP20 test set. Dashed lines indicate FDR of 1, 10 and 20%.
(B) ROC5 plot showing the fraction of queries whose ROC5 score
is above the value on the x-axis (on SCOP20 test set). (C) As in B,
but comparing the performance on test sets SCOP20, SCOP40 and
SCOP80

 

3243

112 /310'S[BIIJHO[pJOJXO'SOTIBLUJOJIITOICI”K1111] 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

C.Angermu'ller et al.

 

 

0.8 . . = .
A — Precision CS-BLASTds
— Precision CS-BLASTgei
07 _ — Precision BLAST ....... ....
' — Sensutuvrty CS-B LASTds
_ Sensitivity CS-B LASTgm
_ S ansitivity BLAST

 

0.6

 

0.5

 

 

 

0.4

 

0.3

 

Alignment quality score

 

0.2

 

0_1   ..

 

 

 

5-10 1015 15-20 2025 25-30 3035 35-40 4045 45-50 5055
Sequence identity

0 d5
0-36 o cs-BLASTgen
o BLAST

0.35

6 =-0.01
0.34
0.33

0.32

Sensitivity

0.31

0.3

0.29

0.28

 

0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48
Precision

Fig. 3. Alignment quality assessment. Structural alignments by TM-align
with TM-score 3 0.6 were used as gold standard. (A) Alignment precision
and sensitivity binned by sequence identity for 7663 sequence pairs
sampled from SCOP80. (B) Average alignment sensitivity versus precision
depending on the score offset 8 for 3700 sequence pairs sampled from
SCOP30 (pairwise sequence identity <30%). The default score offset is
—0.005 bits (dashed lines). CS-BLASTalis alignments have a similar pre-
cision to those of CS-BLASTgen but contain, on average, 12% more
correctly aligned residue pairs

SCOP40, and SCOP80 containing sequence pairs with up to 40
and 80% sequence identity, respectively.

These results demonstrate that the discriminative approach for
predicting context-speciﬁc substitution probabilities improves
the homology detection performance both of sequence and pro-
ﬁle searches.

3.3 Alignment quality

A high quality of pairwise and multiple sequence alignments is
essential for many downstream applications. For example, sec-
ondary structure prediction could be signiﬁcantly improved by
simply generating MSAs using HHblits instead of PSI-BLAST
(Remmert et al., 2011). In homology modelling, target-template
alignment quality is still the bottleneck for more accurate models.
Here, we assessed the quality of CS-BLASTdis alignments by

comparing them to reference alignments obtained from pairwise
structural alignments.

We sampled up to 10 sequence pairs from each family in
SCOP80 (for Fig. 3A) and SCOP30 (for Fig. 3B), yielding
37 663 and 3700 pairs, respectively. We built reference alignments
for them using the structural aligner TM-align (Zhang and
Skolnick, 2005). These alignments were compared with sequence
alignments built by BLAST (blastpgp, version 2.2.26),
CS-BLASTgen and CS-BLASTdis. To make sure that BLAST
produced an alignment for each pair of sequences in the test set,
we decreased the threshold for extending hits (option -f) from 11
to 8. We used blastpgp’s -s option to build alignments with the
SmithiWaterman algorithm. We then evaluated the precision
and sensitivity of each alignment. The alignment precision is the
number of correctly aligned pairs divided by the number of
aligned pairs. The alignment sensitivity is the number of correctly
aligned pairs divided by the number of aligned pairs in the ref-
erence alignment.

Up to a sequence identity of 50%, context-specific substitution
scores improve the alignment sensitivity compared with block
substitution matrix (BLOSUM62) scores used in BLAST (Fig.
3A). For pairs with sequence identities <30%, the alignment
precision improves on average by 5.6% compared with
BLAST (Fig. 3B). The sensitivity of CS-BLASTdis alignments
is 12.3% higher than for CS-BLASTgen and 21% higher than for
BLAST. All in all, the improvement in alignment quality from
CS-BLASTgen to CS—BLASTdis is of similar magnitude as the
improvement from BLAST to CS-BLASTgen. The most striking
improvements are seen in the difﬁcult alignments <25% pairwise
sequence identity (Fig. 3A).

The score offset 8 in Equation (8) allows CS-BLAST users to
control the trade-off between the rate of alignment errors and the
length of the alignment or, in other words, between alignment
precision and sensitivity. A higher score offset allows CS—BLAST
to extend alignments for longer while still accumulating positive
score contributions. This leads to longer, less precise but more
sensitive alignments (Fig. 3B).

3.4 CS-BLAST E—values

E—Values are used to assess the signiﬁcance of sequence search
results. Their correctness is essential for iterative search tools,
which automatically add all hits with E—Values below a speciﬁed
threshold to the MSA for the next search iteration. To estimate
the reliability of E—Values, we plotted the reported E—values of all
hits from an all-against-all comparison on the SCOP test set (see
Section 3.2) against their actual E—value (Supplementary Fig. S3).
The actual E—Value was estimated as the number of observed FPs
with an E—Value below the reported E—Value on the x-axis, aver-
aged over all searches.

We used the score offset 8 for adjusting the reliability of the
reported E—Values. High-scoring alignments between non-
homologous sequences mainly occur between compositionally
biased or repetitive regions. These alignments tend to have
weak similarities over relatively long stretches. Therefore, shift-
ing the substitution scores towards the negative range can shrink
these alignments and reduce their score, effectively suppressing
high-scoring false-positive matches (Supplementary Fig. S2).
As a trade-off between E—Value reliability and alignment

 

3244

112 /310'S[BIIJHO[pJOJXO'SOTIBLUJOJIITOICI”K1111] 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

Modelling of amino acid substitution probabilities

 

 

— cs-BLAs'T dis
— CS—BLAE T gen

 

0.5 
/

00 200 400 800 1 600
Sequence length L

 

Runtime [5]

 

0.25

 

 

 

 

 

 

 

0.125
1

Fig. 4. Run time for generating the context-speciﬁc proﬁle pCS of length L
using K 24000 context-states of length l: 13, measured on an Intel
1.8GHz quad-core processor. CS-BLASTalis is 1.6 times faster than
CS-BLASTgen for a sequence length of L: 350 residues

sensitivity (Fig. 3B), we choose 8 = —0.005 bits. This choice made
CS-BLAST’s E—Values as reliable as BLAST’s (Supplementary
Figs S3 and S4).

3.5 Run time

We compared the run time of CS-BLASTgen and CS-BLASTdis
for generating the context-specific profile pCS for sequences of
length L, which were sampled from the SCOP database
(Fig. 4). The time complexity for both models is O(LKl x 20).
We used K: 4000 context states of length l = 13. CS-BLASTdis
requires ~0.3 s for computing pCS on an Intel quad-core proces-
sor with 1.8GHz given an average sequence length of L=350
residues. CS-BLASTdis is ~1.6 times faster than CS-BLAST be-
cause Equation (2) can be computed more efﬁciently. The con-
text speciﬁc substitution probabilities P(a|c,-) are computed in
parallel for each position i, and the run time scales inversely
with the number of processor cores.

3.6 HHblits sensitivity

HHblits (Remmert et al., 2011) is an iterative homology search
tool based on HMM-to-HMM (HH) comparison that is not only
faster than PSI-BLAST but also much more sensitive and accur-
ate. This is achieved by representing both the query and the
database sequences by HMMs, which are derived from MSAs
of related sequences and, therefore, contain much valuable evo-
lutionary information. HHblits is an extension of HHsearch
(Séding, 2005), and both are used in top ranking structure pre-
diction servers like HHpred (Mariani et al., 2011). HHblits can
be used for fast, iterative searches through clustered versions of
large sequence databases, such as universal protein resource
(UniProt) or NCBI’s non-redundant (NR) database. At the be-
ginning of each search iteration, HHblits uses context-speciﬁc
substitution probabilities to enrich the query HMM, which is
then compared with the database HMMs. Hits with E—Values

 

. I .
2 iter. HHblits dis

2 iter. HHblits gen
1 iter. HHblits dis
1 iter. HH blits ge

 \
 \
\L

0.3 \

0.2

 

 

/

If

 

Fraction of queries

K \

0.1

 

 

/

 

 

 

 

 

 

 

 

 

 

 

 

 

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
ROCS score
Fig. 5. ROC5 plot showing the fraction of queries whose ROC5 score is
below the value on the x-axis. Using HHblits along with context-speciﬁc
pseudocounts predicted by the discriminative model (HHblitsalis) instead
of the generative model (HHblitsgen) increases the mean ROC5 score by
3.0% (one iteration) and 1.5% (two iterations)

below a predeﬁned threshold are added to the query MSA,
from which the HMM for the next iteration is built.

We wanted to test whether the discriminative model for
context-specific substitution probabilities can further improve
the sensitivity of HHblits searches. The present version of
HHblits already uses context-speciﬁc substitution probabilities
computed with the generative model. The same optimization
and test set were used as described in Section 3.1. Models with
K: 4000 context states of length l: 13 were compared for one
and two iterations of HHblits through the uniprot20_02Sep11
database offered together with HHblits. We optimized the ad-
mixture parameters <p and 1/1 as described in Section 3.1. For one
iteration, we found (<p=0.95, 1/1224) and (<p=1.0, 1/1: 14) for
the generative and discriminative model, respectively, and for
two iterations, (<p: 0.58, 1/1: 10) and (q): 0.58, 1/1: 18) were op-
timal. The positional weight factors of the generative model and
previous parameters were left as in Section 3.1.

The mean ROC5 score, after one iteration HHblits on our
SCOP20 test set, could be improved by 3.0% through the dis-
criminative model (Fig. 5). At two iterations, we could gain 1.5%
in sensitivity. In relative terms, this is much less than the im-
provements on single sequences because the HMMs after the
ﬁrst iteration of HHblits already contain detailed position-spe-
ciﬁc substitution probabilities from homologous sequences.
However, the absolute improvement in ROC5 score is retained
after the second iteration.

4 DISCUSSION

4.1 Information in sequence context

What amino acid substitutions are likely to be observed in hom-
ologous proteins is largely determined by the ﬁxation probability
of mutations, which depends mostly on whether the protein can
still fold into its stable structure. The folding requirement exerts
speciﬁc constraints on different positions depending on their
local structural context. The substitution matrix method merely

 

3245

112 /310'S[BHJHOIPJOJXO'SOIJ’BLUJOJIIIOICI”K1111] 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

C.Angermu'ller et al.

 

assesses the similarity of physicochemical properties between the
original and the mutated amino acid. In contrast, the sequence
context-specific method indirectly makes a fine-grained predic-
tion about the probabilities of various structural contexts and,
hence, exquisitely captures the selective constraints at each pos-
ition. For example, a leucine within a membrane helix will have
different substitution probabilities from a leucine on the hydro-
phobic side of an amphipathic ﬂ-strand or from a leucine within
a natively unfolded region. The dramatic improvements in sen-
sitivity and alignment quality bear testimony to the value of se-
quence contexts for predicting substitution probabilities.

4.2 Generative versus discriminative model

Both the discriminative approach and the previously proposed
generative approach for computing context-speciﬁc substitution
probabilities are based on a library of context states that each
represents a speciﬁc typical sequence context. Why does the dis-
criminative model perform considerably better than the genera-
tive model?

First, in contrast to the generative model that describes the
joint distribution P(Ci, k) and then indirectly infers P(k|C,-)
through Bayes’ theorem, in the discriminative approach we dir-
ectly model P(k|C,-). We do not model the probability distribution
of the input contexts C), which is not needed, as the contexts are
observed anyway. Second, the discriminative model learns the
importance of the various positions individually for each se-
quence context, whereas in the generative model, we had to set
the same weights for all sequence contexts explicitly
(Supplementary Material). Third, the discriminative model has
a set of parameters vk(a) to model the emission probabilities in-
dependent of the context information, whereas in the generative
model, the emission distribution is identical to the central context
proﬁle column. This gives the discriminative model more ﬂexibil-
ity to optimize its objective function. As a consequence of these
three points, the generative model with any parameters can be
accurately reproduced by the discriminative model with appro-
priately chosen parameters [Supplementary Material, Equations
($7)], showing that the discriminative model has a higher de-
scriptive potential. Fourth, the discriminative model is trained
by optimizing the conditional probability of the target variable
(the substitution probabilities) given the observed variable (the
sequence context). Hence, in contrast to the generative model, it is
trained to maximize some measure of prediction quality.

4.3 Model training

Although discriminative models typically excel for unlimited
amounts of training data, generative models often perform
better in practice when training data are scarce or training time
is limiting (Ng and Jordan, 2001). The comparison of our dis-
criminative and generative approach is a case in point, as training
the generative model worked well by simple expectation maxi-
mization, whereas training the discriminative model turned out
to be challenging. First, we had to increase the number of train-
ing samples from 1.0 to 6.0 million, in line with the ﬁndings by
Ng and Jordan (2001). Second, the insight that each generative
model can be written exactly as a discriminative model allowed
us to initialize the discriminative model with the equivalent
generative model parameters. Third, we had to try out several

optimization techniques to obtain satisfactory results;
straightforward stochastic gradient descent worked better in
the end than the much more sophisticated Hybrid Monte
Carlo algorithm combined with replica exchange Monte Carlo
sampling (Neal, 1993). Also, using a simple hyperbola function
for controlling the learning rate of stochastic gradient descent
and optimizing the initial learning rate no (Supplementary
Material) proved better than various schemes for dynamic learn-
ing rate adaptation proposed by Almeida et al. (1998).

5 CONCLUSION

The present work shows that a discriminative approach to
context-speciﬁc sequence comparison can further improve the
sensitivity of sequence searches and, in particular, the alignment
quality over a previous generative approach. This was demon-
strated by comparing BLAST and PSI-BLAST with its
context-speciﬁc versions (CS-BLASTgen and CS-BLASTdis).
The new discriminative model also increased the sensitivity of
our iterative sequence search method HHblits and, hence, will
become the default pseudocount model in CS-BLAST and
HHblits. We are convinced that the context-speciﬁc approach
for substitution probabilities presented here is clearly superior
to context-ignorant approaches, such as substitution matrices
and Dirichlet mixtures pseudocounts (Sjolander et al., 1996),
and should supersede those methods wherever maximum per-
f ormance is critical.

ACKNOWLEDGEMENT

The authors thank Stefan Seemayer, Armin Meier and Markus
Meier for discussions.

Funding: Deutsche Forschungsgemeinschaft (SFB646 and
GRK1721); Bavarian Systems Biology Network (BaySysNet)
financed by the Bavarian Ministry for Science, Research and
Arts; LMU through the Excellence Initiative of the BMBF.

Conflict of Interest: none declared.

REFERENCES

Almeida,L. et al. (1998) Parameter adaptation in stochastic optimization. In: Online
Learning in Neural Networks. Cambridge University Press, New York,
pp. 1117134.

Altschul,S.F. et al. (1997) Gapped BLAST and PSI—BLAST: a new generation of
protein database search programs. Nucleic Acids Res., 25, 338%3402.

Baussand,J. et al. (2007) Periodic distributions of hydrophobic amino acids allows
the deﬁnition of fundamental building blocks to align distantly related proteins.
Proteins, 67, 6957708.

Biegert,A. and deingJ. (2009) Sequence context—speciﬁc proﬁles for homology
searching. Proc. Natl Acad. Sci. USA, 106, 37703775.

Bottou,L. (2004) Stochastic learning. Lect. Notes Comput. Sci., 3176, 1467168.

Caruana,R. and Mizil,A.N. (2006) An empirical comparison of supervised learning
algorithms. In: Proceedings of 23rd International Conference Machine Learning,
(ICML 06), ACM, New York, NY. pp. 1617168.

Dayhoff,M.O. et al. (1972) A model of evolutionary change in proteins. In:
Dayhoff,M. (ed.), Atlas of Protein Sequence and Structure, vol. 5. National
Biomedical Research Foundation, Washington, DC, pp. 3457352.

Goonesekere,N.C. and Lee,B. (2008) Context—speciﬁc amino acid substitution matri—
ces and their use in the detection of protein homologs. Proteins, 71, 91(P919.

Henikoff,S. and Henikoff,J.G. (1992) Amino acid substitution matrices from pro—
tein blocks. Proc. Natl Acad. Sci. USA, 8‘), 10915710919.

 

3246

112 /310'S[BHJHOIPJOJXO'SOIJ’BLUJOJIIIOICI”Idllq uteri papeolumoq

9103 ‘Og isnﬁnV uo ::

Modelling of amino acid substitution probabilities

 

Huang,Y.—M. and Bystroff,C. (2006) Improved pairwise alignments of proteins in
the twilight zone using local structure predictions. Bioinformatics, 22, 4134122.

Jones,D.T. et al. (1994) A mutation data matrix for transmembrane proteins. FEBS
Lett., 339, 2697275.

Mariani,V. et al. (2011) Assessment of template based protein structure predictions
in CASP9. Proteins, 79, 37758.

Murzin,A.G. et al. (1995) SCOP: a structural classiﬁcation of proteins database for
the investigation of sequences and structures. J. Mol Biol, 247, 5367540.

Nea1,R. (1993) Probabilistic inference using markov chain monte carlo methods. In:
Technical report CRG—TR—93—I. Department of Computer Science, University of
Toronto.

Ng,A.Y. and Jordan,M.I. (2001) On discriminative vs. generative classiﬁers: a com—
parison of logistic regression and naive bayes. Adv. Neural Inf. Process Syst., 14,
8417848.

Overington,J. et al. (1992) Environment—speciﬁc amino acid substitution tables:
tertiary templates and prediction of protein folds. Protein Sci., 1, 213226.
Remmert,M. et al. (2011) HHblits: lightning—fast iterative protein sequence search—

ing by HMMiHMM alignment. Nat. Methods, 9, 1737175.

Rice,D.W. and Eisenberg,D. (1997) A 3D—1D substitution matrix for protein fold
recognition that includes predicted secondary structure of the sequence. J. Mol
Biol, 267, 10231038.

Rubinstein,Y.D. and Hastie,T. (1997) Discriminative versus informative learning.
In: Proceedings of Third International Conference on Knowledge Discovery and
Data Mining. American Association for Artiﬁcial Intelligence, Newport Beach,
CA, USA, pp. 49753.

Shi,J. et al. (2001) FUGUE: sequence—structure homology recognition using
environment—speciﬁc substitution tables and structure—dependent gap penalties.
J. Mol. Biol, 310, 24%257.

delander,K. et al. (1996) Dirichlet mixtures: a method for improved detection of
weak but signiﬁcant protein sequence homology. Comput. Appl. Biosci., 12,
3277345.

deingJ. (2005) Protein homology detection by HMMiHMM comparison.
Bioinformatics, 21, 9517960.

deingJ. and Remmert,M. (2011) Protein sequence comparison and fold recogni—
tion: progress and good—practice benchmarking. Curr. Opin. Struct. Biol, 21,
404—411.

Sutton,C. and McCallum,A. (2006) Introduction to conditional random ﬁelds for
relational learning. In: Getoor,L. and Taskar,B. (eds), Introduction to Statistical
Relational Learning. MIT Press, Cambridge, USA, pp. 937128.

Zhang,Y. and Skolnick,]. (2005) TM—align: a protein structure alignment algorithm
based on the TM—score. Nucleic Acids Res., 33, 230272309.

 

3247

112 /310'S[BHJHOIPJOJXO'SOIJ’BLUJOJIIIOICI”Idllq uteri papeolumoq

9103 ‘Og isnﬁnV uo ::

