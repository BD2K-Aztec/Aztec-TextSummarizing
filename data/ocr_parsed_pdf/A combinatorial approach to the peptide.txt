BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

A combinatorial approach to the peptide feature matching problem

 

the literature used heuristic algorithms to ﬁnd either an initial set
of matched feature pairs, or an initial time alignment function.
Then they are used to ﬁnd a new time alignment function or a
new set of matched feature pairs, respectively. Naturally, such a
procedure can be repeated iteratively to, hopefully, get more and
more accurate result.

This approach was typified by Li et al. (Li et al., 2005), which
matched features with similar m/z values as the initial feature
matching. Kirchner et al. (2007) used the robust point matching
method to ﬁnd an initial feature matching, and then carried out
smooth monotone regression to ﬁnd time alignment. When there
are significant time shifts and distortions, as well as the present of
noisy false features, the ﬁnding of the initial set of feature match—
ing in the aforementioned approaches can become challenging.
Note that this problem can be solved if the peptides of all the
features are known. Then the features can be matched confl—
dently by checking their peptide identities. Such approaches
have already been proposed in previous research (Fischer
et al., 2006; Tsou et al., 2010). However, this requires additional
MS/MS duty cycles of the instrument, which produce the MS/
MS spectra for the identification of the peptides. This reduces the
number of MS scans at the same time. As a result, many of the
low—abundance peptides from the limited amount of biological
samples may not produce strong enough signal in the LCiMS
data and become undetectable. Therefore, if time alignment can
be achieved without requiring MS/MS, it is advantageous to
perform quantiflcation without MS/MS. The peptides can be
identified in a separate LCiMS/MS run after the quantiﬁcation,
possibly with an inclusion list that targets the quantifled peptide
features, and using a less precious sample. In fact, there are even
proposals in the literature to identify peptides purely based on
the m/z and the aligned retention time of a peptide feature
(LaMarche et al., 2013). This application deflnitely requires
the time alignment without MS/MS. For these reasons, in this
article, we assume the peptide identities are unknown to the
alignment algorithm.

Other researchers focused on ﬁnding an initial time alignment
function. Lange et al. (2007) assumed that the time alignment is a
linear function: f(t) = a x t + b. A pair of coefﬁcients (a,~, b,~) was
calculated from every two pairs of possibly matched features.
The correct coefflcients (a,b) were estimated by ﬁnding a dense
cluster of all the calculated (a,~, b,~). Noticing the time alignment is
usually non—linear, a number of publications (Bellew et al., 2006;
Bylund et al., 2002; Jaitly et al., 2006; Mueller et al., 2007;
Pluskal et al., 2010; Podwojski et al., 2009; Radulovic et al.,
2004; Silva et al., 2005) only assumed local linearity of the time
alignment, and applied linear regression on each local time
window of the data. These works mostly differ at the methods
used for local linear regression, and for connecting the local
linear regression results into a global time alignment function.

Although many of these reviewed methods have been used in
practice, none of them deﬁned a clear optimization goal for the
peptide feature matching problem. There were usually biological
justiﬁcations for each step of these published methods. But the
property of the final output of a method was unclear. The situ—
ation is different from the common practice in traditional algo—
rithmic research, where the optimization goal is usually specifled
mathematically before the algorithm is being developed. This
situation is not uncommon in many emerging bioinformatics

areas (including peptide quantification) because the biologists
often need to have a solution quickly once an experimental
method is invented, in which case an ad hoc solution has its
value. Moreover, given the complexity of biology, the formula—
tion of a tidy mathematical model is often difﬁcult.

But there are certainly disadvantages about this ad hoc type
of research. An immediate one is that the ﬁnal outcome of the
algorithms is unpredictable without running the software on a
speciﬁc input. As such, the performance of the algorithm remains
at the mercy of the implementation details such as the choice of
(many) parameters and sometimes even special considerations
hard—coded in the software by a junior programmer to handle
a special case of the training (and testing) data. Consequently, a
method developed in one laboratory has the tendency to overf1t
the data of the laboratory and may not work as well in another
laboratory or on a future instrument. We advocate that
whenever possible, a combinatorial problem should be clearly
deﬁned. The separation of the problem formulation, the algo—
rithm development and the program implementation can help
reduce the aforementioned overfltting tendency. The ﬁeld know—
ledge of the biologists should be used extensively and (almost)
exclusively during the problem formulation stage to specify the
desired property of the solution. And the algorithm development
should strive to compute a solution that meets the speciﬁed
property, instead of ﬁtting the data that happen to be in the
researcher’s hands.

The ﬁrst purpose of this article is to provide a clearly deﬁned
combinatorial model for the feature matching problem in
Section 2. We will then prove that the feature matching problem
is NP—hard in Section 3. In Section 4, a slightly modiﬁed opti—
mization goal is proposed, under which a polynomial time algo—
rithm is presented. We show that the solution of the modiﬁed
problem helps determine an upper—bound and a lower—bound of
the optimal solution of the feature matching problem. This re—
sults in a practical algorithm for the feature matching problem
with a performance guarantee for each given instance. In Section
5, the optimization goal is amended to control the smoothness of
the time alignment function for feature matching. A polynomial
time algorithm is also presented. Finally, Section 6 examined the
performance of the algorithm on real LCiMS data. Not only
is the proposed model tidy but the algorithm’s performance also
compares favorably with other existing methods.

2 THE MAXIMUM FEATURE MATCHING
PROBLEM

In this section, we formulate peptide feature matching as a com—
binatorial optimization problem. A peptide feature p is a 2—tuple
(m(p), t(p)), where m(p) indicates the mass and the t(p) indicates
the retention time of the feature in an LCiMS experiment.
We assume both m(p) and t(p) are integers, as real numbers
can be discretized by allowing a small rounding error.
A sample consists of a set of features {p1,p2, ...,pn}. Let S
and S / be two samples and their retention time range from
1 to T. A time alignment function that maps the time of S to
the time of S / is a monotonically increasing function
f: [1,TjI—>[1,Tj such thatf(1) = 1 andf(T) = T.

As aforementioned, the retention time of a peptide cannot be
measured accurately. First, the unavoidable variations of LC

 

1 769

ﬁm'spzumofpmﬂo'sopeuuopnorq/ﬁdnq

H.Lin et al.

 

conditions in the two runs can cause systematic drifts of the
retention time for all peptides. This systematic error is modeled
by the time alignment function f Second, the retention time
of an individual peptide may change independently from other
peptides, causing a random error. Suppose two features p e S
and p’ e S / are from the same peptide in the two samples S
and S C Then |t(p/) —f(t(p))| models the random error. After
a proper time alignment, the random error is usually small.
For example, if two LC runs are conducted on the same LC
instrument under the same experimental condition, and each
lasts for 1h, then the random error is often <1 min after the
time alignment.

For every two features, p e S and p’ e S C The matching qual—
ity of p and p/ is a non—negative function w(6m,6,), where
6m 2 |m(p/) — m(p)| and 6, = |t(p/) —f(t(p))|. The function w is
also called a weight function. One example of the weight function
is the unit weight function, denoted by w]. Let Am 3 0 and A, 3 0
be two thresholds on the allowed mass and time errors, respect—
ively. The unit weight function is

_ 1, if am 3 Am and a, 3 At,
“2103"” 6’) _ I 0, otherwise.

The unit weight function essentially treats a pair of features as
a match if and only if their mass and time differences are within
the allowed error tolerances.

A peptide feature matching, or simply, a feature matching, is
a bijective mapping between two subsets P C S and P’ C S C
More speciﬁcally, a feature matching provides a set of fea—
ture pairs, M C {(p,p/) |p e S,p/ e S’}, such that each feature
appears in at most one pair in M. Given a time alignment function
f and a weight function w, the total weight of the matching M,
is defined as

W(M)= Z W(|m(p/)—m(p)|,|t(p/)—f(t(p))|)-

(emeM

For label—free quantiﬁcation, the two studied samples share
most of their peptides, and the biological experiments are
optimized to minimize the noise and the mass and retention
time errors. When the peptide identities for the peptide features are
unknown, the most natural combinatorial goal for peptide feature
matching is to maximize the total weight of the matching.

The maximum feature matching problem (MFM) is, therefore,
deﬁned as follows: given two samples S and S/ and a weight
function w, find a time alignment function f and a feature match—
ing M, such that w(lll) is maximized.

Note that if f is given, MFM can be easily reduced to the max—
imum matching problem in a bipartite graph. In the reduction,
each feature corresponds to a vertex, and the two sets S and S /
are the two vertex sets of the graph. The edge weight between
each pair of features is defined by the weight function w.
In particular, when w is the unit weight function, the reduction
results in the unweighted version of the maximum matching
problem. It is well known that polynomial time algorithms
exist for maximum matching, for both weighted and unweighted
versions (Fredman and Tarjan, 1987; Mucha and Sankowski,
2004). However, for MFM, the time alignment function
f needs to be computed simultaneously with the feature match—
ing. This makes MFM a much harder problem.

3 MAXIMUM FEATURE MATCHING IS NP-HARD

THEOREM 3.1. The maximum feature matching problem is
NP—hard under the unit weight function.

PROOF. The proof can be found in Supplementary Appendix.

4 A PRACTICAL ALGORITHM FOR MAXIMUM
FEATURE MATCHING

In this section, we develop a practical algorithm for MFM. This
is achieved by studying a slightly modiﬁed version of MFM.
Instead of requiring the matching to be a bijective mapping,
the new problem only requires the matching to be a surjective
mapping. More speciﬁcally, a surjective matching M * is a subset
of {(p,p/) |p e S,p/ e S’}, such that a feature p e S appears at
most once in M*. However, it is possible that a feature p/ e S /
appears multiple times. Given a time alignment function f and a
weight function w, the weight of the surjective matching M* can
be deﬁned in the same way as in the MFM problem:

WOW): 2 W(|m(p/)—m(p)|,|t(p/)—f(t(p))|)-

(emeMt‘

Given two samples and a weight function w, the maximum
surjective feature matching problem (SFM) computes a time align—
ment function and a surjective matching M*, such that w(M*) is
maximized. We next present a polynomial time algorithm to the
SFM problem.

For a sample S and a time i, let S,~ = {p e S|t(p) = i} be the
subset of features at time i. Let S5, = {p e S|t(p) g i} be the
subset of features with time at most i.

Let din, be the maximum weight of a surjective matching
between S,- and S/ that can be achieved by a time alignment
function satisfying f(i) = j. As the time of all features in S,- is
equal to i and f(i) equals to j, d,~‘j can be easily computed by
finding the best matching of each p e S,~ separately.

Let Di“, be the maximum weight of a surjective matching
between SE, and S/ that can be achieved by a time alignment
function satisfying f(i) g j. If f(i) < j, then clearly Di“, 2 Din/,1.
If f(i) = j, then the maximum surjective matching includes
the maximum surjective matching from SSH to S /, and the
maximum surjective matching from S,- to S C Therefore,
D,~‘j=D,~,1L/+d,~‘j. Combining the two cases, we know that
Di“, 2 max{D,~“,«,1, DH“, + d,~“,«}. With this recurrence relation,
it is clear that the SFM problem can be computed with dynamic
programming. The algorithm is outlined as follows. The optimal
time alignment function f, as well as the surjective matching,
can be computed by a standard backtracking.

 

Algorithm DP—SFM

1.Forevery15i5Tand15j5T

2. Compute did-

3. Let DLO = 0 and DOJ» = 0 for every 0 5 i 5 T.

4. For ifrom 1 to T

5. Forj from 1 to T

6- LCt Di.j = maXIDijila DHJ + dizj}

7. Output DT~ T as the maximum weight of the surjective matching.

 

 

 

1770

ﬁm'sIeumoI‘pJOJXO'sopeuuopnorq/ﬁdnq

A combinatorial approach to the peptide feature matching problem

 

After tracing back, all (i, j) pairs on the optimal path form the
optimal time alignment function f

THEOREM 4.1. The SFM can be solved in 0(T2 + T>< |S|><
|S /|) time by algorithm DP—SFM.

PROOF. The correctness of the algorithm follows from the dis—
cussion earlier in the text. We only need to prove the time com—
plexity. The computation of each d“, in line 2 takes at most
0(|S,| >< |S/|) time. Therefore, the whole for loop at lines 1

md2mMSmm(KZBWJWAM$0=OUxmhd$U
After d,~“, is computed and stored in memory, each execution of

line 6 takes constant time. Thus, the for loops from line 4 to line
6 take 0(|T|2) time. I

Note that the most expensive part of the time complexity in
Theorem 4.1 is the time 0(T >< |S| >< |S/|) for the computation of
all d,~“,. When the weight function w satisﬁes some properties, it is
possible to speed—up the computation of d,~“,.

COROLLARY 4.2. When the unit weight function W] is used,
SFM can be solved in time

mﬁ+rm$+mxmw

PROOF. We only need to show that d“, can be computed with
time 0(T>< |S|+|S| >< |S/|) for all 1 gig T and 1 gjg T.
For each p e S, let Jp = {jl there is p’ e S/ such that
|m(p/) — m(p)| 3 Am and |t(p/) —j| g A,}. Then Jp can be com—
puted by the following algorithm:

 

Algorithm JP

1. Let JP 2 (A.

2. For each p’ e S’ such that |m(p’) — m(p)| 5 Am
3. JP 2 jp U [t(p’) — A,,t(p’) + A,]

 

 

Note that JI, is the union of many intervals with equal
length. Therefore, there is a simple data structure to store JI,
so that the union operation in line 3 can be done in 0(1) time.
The detail of this data structure is provided in the Supplementary
Appendix. Thus, the complexity of the above algorithm is
0(|S ’|). After JI, is calculated, d“, can be calculated by
d,~“, = |{p e S,~[j e Jp}|. And the calculation for all 1 g i g T
and 1 g j g T can be carried out more efﬁciently with the fol—
lowing algorithm:

 

Algorithm DIJ

1.Foreach15i5 T

2. Calculate JP for each p e S, with algorithm JP.
3 Letd,.j=0foreach15j5 T.

4. For eachp e S,

5

6

 

For eachje JP
Let d” =dU+ 

 

As algorithm JP takes 0(|S/l) time for each [)6 S, the
accumulated time cost for line 2 is 0(|S| >< |S’|). As ljpl g T,
line 6 is repeated at most 0(2;l |S,~| x T) = 0(|S| x T) times.
Therefore, the total time complexity for algorithm DIJ is
0(T>< |S| + |S| >< |S/|). I

Remark: If we sort S / by mass values, then in line 2 of algorithm
JP, we can retrieve all p’ such that |m(p/) — m(p)| 3 Am by a

binary search, without enumerating all p/ e S C Because usually
Am << R, and |S /| > T, this trick provides signiﬁcant speed gain
on real life instances.

In the rest of this section, we examine the relation between the
SFM and the MFM problems.

LEMMA 4.3. Suppose two instances of the SFM and MFM
share the same input. Then the weight of the maximum feature
matching (MFM) is less than or equal to the weight of the
maximum SFM.

PROOF. A bijective mapping is also surjective. Thus, a solution of
MFM is also a solution of SFM. I

On the other hand, let M* C {(p,p/) |p e S,p/ e S/} be a so—
lution for SFM. We can easily modify M* into a suboptimal
solution for MFM by selecting only one pair of features from
M* for every p’ 6 SC In fact, if a better suboptimal solution
is desired, the following algorithm can be used to compute a
suboptimal solution of MFM based on the optimal solution
of SFM.

 

Algorithm SNIFM

1. Compute an optimal solution for SFM using the same input. Let f be
the optimal time alignment function. Let W be the optimal weight.

2. Let W(p,p/) = w(|m(p’) — m(p)|, |t(p’) —f(t(p))|) for every p e S and
p’ 6 SC

3. Treat W(p,p/) as the edge weight in a complete bipartite graph S X S ’,
and compute a maximum bipartite matching.

4. Output the maximum bipartite matching as the suboptimal solution of
MFM, and W as the upper bound of the optimal weight.

 

 

THEOREM 4.4. Algorithm SMFM computes a suboptimal
solution for MFM, and an upper bound for the optimal weight.

PROOF. The theorem is an immediate consequence of
Lemma 4.3.

As algorithm SMFM outputs both a suboptimal solution
and an upper bound for the optimal weight, one can effectively as—
sess the performance of the algorithm for each given instance.

5 VARIATIONS OF THE MAXIMUM FEATURE
MATCHING PROBLEM

5.1 Weight function

The unit weight function w, is conceptually simple, and the mass
and time error thresholds Am and A, can be easily determined by
the technician who operates the instrument according to experi—
ence. However, it is sometimes desirable to use a continuous
weight function to give different weight to different time errors.
It has been shown that in real data, the random retention time
error after the time alignment satisﬁes a normal distribution
(Felinger, 1998). Let 6, = t(pf.) —f(t(p,~)) be the random time
errors of a pair of matched features (p,~,p;.) after the time

alignment. Then Pr(e,~) = ghe’ielz. Assume the random

 

error of different features is independent to each other, then
the probability of all the errors in the matching is

 

UL, m/IEe’ielC By taking the logarithm, it is easy to see that

maximizing the probability aforementioned is equivalent to

 

1771

ﬁm'sIeumoI‘pJOJXO'sopeuuopnorq/ﬁdnq

H.Lin et al.

 

maximizing 2?:1—6’2. As the weight function needs to be

non—negative, we deﬁne the following weight function wZ:

A3 — 3?, if 3,, 3 Am and a, g A,,
0, otherwise.

mom, 6,) = I

5.2 Gap penalty

In the definition of the MFM and SFM problems, not much
restriction is put on the time alignment function f, except that
it has to be monotonically increasing. However, it is sometimes
beneﬁcial to have some smoothness requirement for f This is
mostly for a practical concern: a smooth function needs fewer
data points to ﬁt than an arbitrary function does.

Let [l,~,r,~] (i = 1, ...,k) be the maximal time intervals such
that r, — l,~>1 and f(t) remain constant in each interval. These
are called the type—I gaps. The gap length for [l,~,r,~] is r, — l,~.
Let [ll/,rj] (i = 1, ...,k/) be the maximal time intervals such
that there is no t such that f(t) e [l;,r;.]. These are called
the type—II gaps. The gap length for [lIC r1] is lf—r;+ 1. By
requiring f to be smooth, we essentially want to penalize these
two types of gaps with a gap penalty function g(k)>0 for a
length—k gap.

This is analogous to the gaps in the pairwise sequence align—
ment. But a key difference is that here we prefer many smaller
gaps over a few large gaps, which is the opposite of the sequence
alignment. As a result, although the sequence alignment nor—
mally used a concave gap penalty function, here we choose to
use a convex gap penalty function, such as g(k) 2 k2. And the
total gap penalty of the time alignment function f is deﬁned as

gm = ng — 10+ Zg(r:~— 1.7+ 1).
i=1 i=1

The gapped—MFM problem is to find a bijective feature
matching M and a time alignment f to maximize
score (M, f) = w(lll) — g( f ). Similarly, the gapped—SFM prob—
lem is to ﬁnd a surjective feature matching M* and a time align—
mentfto maximize score (M*,f) = w(M*) — g(f).

We design a dynamic programming algorithm for the gapped—
SFM problem. Let K >0 be the maximum allowed gap length.
Let S,~, SS, and d“, be as deﬁned in Section 4. Let NW be the
maximum score achieved by features in SE, and a time alignment
function satisfying f (i) = j and f (i — 1) < j. Let M ,3, be the max—
imum score achieved by features in SS, and a time alignment
function satisfying f (i) = j.

From the definition ofN,~L,, we know that [f(i — 1) + 1,f(i) — 1]
is a probable type—II gap. Let k =f(i) —f(i — 1) — 1 be the gap
length. Then,f(i — 1) =f(i) — k — 1 =j — k — 1; therefore,

N13} = 0§i§{Mi71,/7k71 + {In} — g(k)} (1)

To compute M ,3), assume that i— k is the least number such that
f (i — k) = j. Then [i — k, i] is a probable type—I gap; therefore,

Mn; = OgiﬁNii/c‘j +l 2+1 (11.; — €00} (2)

From Equations (1) and (2), it is straightforward to develop
a dynamic programming algorithm to compute NR, and MW

simultaneously. The time complexity will be 0(T2K) plus the
time needed by computing d,~“,. Therefore, for a general weight
function w, the time complexity is 0(T2K+ T>< |S| >< |S’|).
Here, the algorithm and proof details are omitted.

As MFM is NP—hard, gapped—MFM with a general gap pen—
alty is also NP—hard. Algorithm SMFM in Section 4 can be
modiﬁed to provide a suboptimal solution for gapped—MFM
and an upper bound to the optimal score. The only required
modiﬁcation is to replace SFM by gapped—SFM in line 1 of
the algorithm.

6 EXPERIMENTAL RESULTS

The performance of our algorithms was compared with three
other state—of—the—art software tools, msInspect (Bellew et al.,
2006), MZmine2 (Pluskal et al., 2010) and MultiAlign
(LaMarche et al., 2013) by using real LCiMS datasets. Our
algorithms include (i) algorithm SMFM with the weight function
wz and (ii) the algorithm with weight function wz and a gap
penalty g(k) = 10k2, as described in Section 5. For the rest of
the section, the ﬁrst algorithm will be denoted by SMFM, and
the second algorithm will be denoted by SMFM—g.

Five LCiMS datasets produced from the yeast proteome by
three different laboratories were chosen for our comparison pur—
pose. These were all public datasets made available by previous
publications (Askenazi et al., 2011; Nagaraj et al., 2012; Swaney
et al., 2008). The names of the datasets and the number of fea—
tures detected by msInspect in each of them are listed in Table 1.
These ﬁve datasets are aligned with one another under different
settings. More speciﬁcally, the alignments C00n1.F3 versus
Coon2.F4 and Mann.1 versus Mann.2 are datasets from the
same laboratory on the same instrument in the same experiment.
These reﬂect the easiest test cases, as the LC conditions do not
vary too much. The alignments iPRG versus Coon2.F4 and
Coon2.F4 versus Mann.1 reﬂect the most challenging test cases,
as the aligned datasets were from different laboratories and the
LC conditions across different laboratories present the largest
possible variations. However, as they were all produced from
the yeast proteome, there should be a signiﬁcant number of pep—
tides shared by the datasets. Therefore, a robust feature matching
algorithm should still be able to match these common peptides’
features, despite the existence of large retention time distortion
and noises. More detailed information about the datasets and the
justiﬁcation of selecting these particular four pairs of datasets for
the alignments can be found in Supplementary Appendix.

For each dataset, the MS/MS spectra were used to identify
peptides with the PEAKS 6 software (Zhang et al., 2012).
Parameters of the database search can be found in
Supplementary Appendix. The peptides identified with false dis—
covery rate 3 1% that matched only one feature in the LCiMS
data were selected as the control set. The purpose of this control

Table 1. The number of features in different samples

 

Dataset iPRG C00n1.F3 Coon2.F4 Mann.1 Mann.2

 

Features 11 430 5879 5320 66 479 68 128

 

 

1772

ﬁm'sIeumoI‘pJOJXO'sopeuuopnorq/ﬁdnq

Mme 2
Malt/Allan
Hill/Wynnzq
R ulun Pmr
Pip/HI, Pit/7'

llN/Yléﬂid
\[mer 2
\Iull/ 17w
1w Inn'rrnmlr-l
n Him-y Pm,-
mommi-

 

/310's112u1n0fp.10}x0"soiwuiJOJuioiq/ﬁduq

H.Lin et al.

 

the peptide identiﬁcation, the Polynomial—4 method ﬁtted a
fourth degree polynomial as the time alignment function (the
second and third degree were also tried, but the results were
not as good as the fourth degree). Note that this was an unfair
comparison because Polynomial—4 used additional information.
Nevertheless, Table 2 showed that our new methods SMFM and
SMFM—g also compared favorably with this polynomial fitting.
This indicated that the time alignment function could not be ﬁt
accurately by a low—degree polynomial, and further justiﬁed the
use of a monotonically increasing function instead of any speciﬁc
simple function in our SMFM model. For the alignment of
Mann.1 versus Mann.2, both msInspect and MZmine2 failed
(msInspect crashed and MZmine2 returned no result). We sus—
pected that it was due to the large data size of Mann’s datasets
(Table 1). Our new algorithms (SMFM and SMFM—g) ﬁnished
successfully in <1 min with 560 MB of memory usage.

Figure 1 illustrates the relative performance of the six com—
pared methods visually. The resulting time alignment from each
software was plotted together with the ‘true’ peptide feature pairs
(represented by blue circles). Retention time of both samples
were scaled to 3600s in the ﬁgure. All the possible feature
pairs that had a mass difference <15ppm were also plotted as
gray crosses. Thus, intuitively, the software tools were using
these gray crosses to compute a time alignment function. The
better software’s result should ﬁt the trend of blue circles. Similar
ﬁgures for the alignments between biological replicates,
Coon1.F3 versus Coon2.F4 and Mann.1 versus Mann.2, were
plotted in Supplementary Figure S5.

7 CONCLUSION AND DISCUSSION

The maximum feature matching problem (MFM) is formulated
to match the peptide features in label—free peptide quantiﬁcation.
To our knowledge, this is the first combinatorial model for the
problem. We show that the problem is NP—hard, and we provide
a practical algorithm that has a performance guarantee for each
instance. Experiments on real data demonstrate that the algo—
rithm has a better performance comparing with other software in
the literature.

Although recognizing the contribution and the need of the ad
hoc software in bioinformatics research, we advocate that, when—
ever possible, the bioinformatics problem should have a clear
combinatorial deﬁnition. This old practice in algorithmic
research can help reduce the risk of overﬁtting the training
data in the process of seeking for a better algorithm. It also
helps predict the performance of an algorithm before running
the software associated with it. As experienced by many, running
a published but undocumented and un—maintained software
package can be challenging. For example, during the preparation
of this manuscript, 10 published software programs have been
tried. However, only 4 of the 10 produced reasonable output.
Among the four, the results of msInspect, MZmine2 and
MultiAlign were included in the experimental result, whereas
another one, OpenMS (Sturm et al., 2008), used a linear model
that clearly could not ﬁt our testing data and, therefore, was not
included. Problems encountered by other six programs included
crashing, out of memory and reporting error in the middle of
the execution. As such, there is a non—negligible risk to compare
algorithms with their software implementations. A buggy

implementation can inadvertently affect the real performance
of an algorithm.

Although a feature p is deﬁned by a 2—tuple (m(p), t(p)) in this
article, more information about a peptide feature retrieved from
the LCiMS data can be added easily. One only needs to replace
m(p) with a vector that includes the other information, and in
w(6,,,,6,) replace am by the difference of the two vectors of the
two compared features. For example, the intensity distribution
over the isotope peaks and over the retention time can be used to
measure the similarity (or matching quality) of two matched fea—
tures. With this adjustment, the NP—hardness and algorithmic
results presented in this article remain the same.

In developing bioinformatics tools, researchers aim to ﬁnd the
‘real’ biological solutions from the input data. However, as the
real solution is unknown when the software is used in practice,
the optimization goal deﬁned in the bioinformatics problem
cannot depend on the real solution, but it is at best an approxi—
mation to the property of the real solution. We have demon—
strated that by clearly deﬁning such optimization goal as a
simple function of the input and the algorithm’s output, not
only does the biological problem become a pure combinatorial
problem that algorithmic researchers can work on, the perform—
ance of the algorithm also compares favorably with the state—of—
the—art ad hoc software packages.

In fact, clearly defining the optimization goal is helpful even
in the ad hoc solutions. For example, many have proposed to
alternatively find a time alignment and a set of matched features
by using each other as the input. But there is no guarantee that
such iteration will converge or can improve the result. However,
if the optimization goal is a simple function of the output, one
can then evaluate the current solution with the optimization goal
at each step of the iteration, and it stops when the score stops
growing.

ACKNOWLEDGEMENT
The authors thank Dr Zefeng Zhang for his useful discussion.

Funding: The authors were supported by an NSERC discovery
(RGPIN 238748—2011) grant and a starter grant (to B.M.) at
University of Waterloo.

Conﬂict of Interest: none declared.

REFERENCES

Askenazi,M. et al. (2011) iPRG 2011: a study on the identiﬁcation of electron
transfer dissociation (ETD) mass spectra. J. Biomol. Tech, 22 (Suppl), 520.
Bellew,M. et al. (2006) A suite of algorithms for the comprehensive analysis of
complex protein mixtures using high—resolution LC—MS. Bioinformaticx‘, 22,

190271909.

Bylund,D. et al. (2002) Chromatographic alignment by warping and dynamic pro—
gramming as a pre—processing tool for parafac modelling of liquid chromatog—
raphyimass spectrometry data. J. Chromatogr. A, 961, 2377244.

Cappadona,S. et al. (2012) Current challenges in software solutions for mass spec—
trometry—based quantitative proteomics. Amino Acidx‘, 43, 108771108.

Felinger,A. (1998) Data Analysix‘ and Signal Processing in Chromatography. Elsevier,
San Diego, CA.

Fischer,B. et al. (2006) Semi—supervised LC/MS alignment for differential prote—
omics. Bioinformaticx‘, 22, e1327e140.

Fredman,M.L. and Tarjan,R.E. (1987) Fibonacci heaps and their uses in improved
network optimization algorithms. J. ACM, 34, 596%15.

 

1 774

ﬁm'spzumol‘pmjxo'sopeuuquioiq/ﬁdnq

A combinatorial approach to the peptide feature matching problem

 

Heck,A.J. and Krijgsveld,J. (2004) Mass spectrometry—based quantitative prote—
omics. Expert Rev. Proteomics, 1, 3177326.

Jaitly,N. et al. (2006) Robust algorithm for alignment of liquid chromatography—
mass spectrometry analyses in an accurate mass and time tag data analysis
pipeline. Anal. Chem., 78, 739777409.

Kirchner,M. et al. (2007) amsrpm: robust point matching for retention time align—
ment of LC/MS data with R. J. Stat. Softw., 18, 1712.

LaMarche,B.L. et al. (2013) Multialign: a multiple LC—MS analysis tool for targeted
omics analysis. BMC bioinformatics, 14, 49.

Lange,E. et al. (2007) A geometric approach for the alignment of liquid chroma—
tographyimass spectrometry data. Bioinformatics, 23, i27¥i281.

Lange,E. et al. (2008) Critical assessment of alignment procedures for LC—MS
proteomics and metabolomics measurements. BMC bioinformatics, 9, 375.
Li,X.J. et al. (2005) A software suite for the generation and comparison of peptide
arrays from sets of data collected by liquid chromatography—mass spectrometry.

Mol. Cell. Proteomics, 4, 132871340.

Mucha,M. and Sankowski,P. (2004) Maximum matchings via gaussian elimination.
In: Proceedings of the 45th Annual IEEE Symposium on Foundations of Computer
Science. FOCS '04, pp. 2487255.

Mueller,L.N. et al. (2007) SuperHirnia novel tool for high resolution LC—MS—based
peptide/protein proﬁling. Proteomics, 7, 347(k3480.

Nagaraj,N. et al. (2012) System—wide perturbation analysis with nearly complete
coverage of the yeast proteome by single—shot ultra HPLC runs on a bench top
orbitrap. Mol. Cell. Proteomics, ll, M111.013722.

Pluskal,T. et al. (2010) MZmine 2: modular framework for processing, visualizing,
and analyzing mass spectrometry—based molecular proﬁle data. BMC bioinfor—
matics, 11, 395.

Podwojski,K. et al. (2009) Retention time alignment algorithms for LC/MS data
must consider non—linear shifts. Bioinformatics, 25, 7587764.

Radulovic,D. et al. (2004) Informatics platform for global proteomic proﬁling and
biomarker discovery using liquid chromatography—tandem mass spectrometry.
Mol. Cell. Proteomics, 3, 9847997.

Silva,J.C. et al. (2005) Quantitative proteomic analysis by accurate mass retention
time pairs. Anal. Chem., 77, 218772200.

Slysz,G.W. et al. (2010) The decontools framework: an application programming
interface enabling flexibility in accurate mass and time tag workflows for
proteomics and metabolomics. In: Proceedings of 58th ASMS Conference on
Mass Spectrometry and Allied Topics. Salt Lake City.

Sturm,M. et al. (2008) OpenM$an open—source software framework for mass spec—
trometry. BMC bioinformatics, 9, 163.

Swaney,D.L. et al. (2008) Decision tree—driven tandem mass spectrometry for shot—
gun proteomics. Nat. Methods, 5, 9597964.

Timms,J.F. and Cutillas,P.R. (2010) Overview of quantitative LC—MS techniques
for proteomics and activitomics. LC—M S/M S in Proteomics: Methods in
Molecular Biology, 658, 19415.

Tsou,C.C. et al. (2010) IDEAL—Q, an automated tool for label—free quantitation
analysis using an efficient peptide alignment approach and spectral data
validation. Mol. Cell. Proteomics, 9, 1317144.

Vandenbogaert,M. et al. (2008) Alignment of LC—MS images, with applica—
tions to biomarker discovery and protein identiﬁcation. Proteomics, 8,
650—672.

Zhang]. et al. (2009) Review of peak detection algorithms in liquid—chromatog—
raphy—mass spectrometry. Curr. Genomics, 10, 388.

Zhang]. et al. (2012) PEAKS DB: de novo sequencing assisted database search
for sensitive and accurate peptide identiﬁcation. Mol. Cell. Proteomics, ll,
M111.01058.

 

1 775

ﬁm'spzumol‘pmjxo'sopeuuquioiq/pdnq

