Bioinformatics, 3217), 2016, 1023—1032

doi: 10.1093/bioinformatics/btv683

Advance Access Publication Date: 20 November 2015
Original Paper

 

 

Sequence analysis

Large-scale machine learning for metagenomics
sequence classification

Kévin Vervier1'2'3'4'1, Pierre Mahé1'*'1, Maud Tournoud1,
Jean-Baptiste Veyrieras1 and Jean-Philippe Vert2'3'4

1Bioinformatics Research Departement, bioMérieux, 69280 Marcy-I'Etoile, 2MINES ParisTech, PSL Research
University, CBIO-Centre for Computational Biology, 77300 Fontainebleau, 3lnstitut Curie, 75248 Paris Cedex and
4INSERM U900, 75248 Paris Cedex, France

*To whom correspondence should be addressed.
TThe authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.
Associate Editor: Inanc Birol

Received on June 4, 2015; revised on October 26, 2015; accepted on November 13, 2015

Abstract

Motivation: Metagenomics characterizes the taxonomic diversity of microbial communities by
sequencing DNA directly from an environmental sample. One of the main challenges in metage—
nomics data analysis is the binning step, where each sequenced read is assigned to a taxonomic
clade. Because of the large volume of metagenomics datasets, binning methods need fast and
accurate algorithms that can operate with reasonable computing requirements. While standard
alignment—based methods provide state—of—the—art performance, compositional approaches that as—
sign a taxonomic class to a DNA read based on the k—mers it contains have the potential to provide
faster solutions.

Results: We propose a new rank—flexible machine learning—based compositional approach for taxo—
nomic assignment of metagenomics reads and show that it benefits from increasing the number of
fragments sampled from reference genome to tune its parameters, up to a coverage of about 10,
and from increasing the k—mer size to about 12. Tuning the method involves training machine learn—
ing models on about 108 samples in 107 dimensions, which is out of reach of standard softwares
but can be done efficiently with modern implementations for large—scale machine learning. The re—
sulting method is competitive in terms of accuracy with well—established alignment and compos—
ition—based tools for problems involving a small to moderate number of candidate species and for
reasonable amounts of sequencing errors. We show, however, that machine learning—based
compositional approaches are still limited in their ability to deal with problems involving a greater
number of species and more sensitive to sequencing errors. We finally show that the new method
outperforms the state—of—the—art in its ability to classify reads from species of lineage absent from
the reference database and confirm that compositional approaches achieve faster prediction times,
with a gain of 2—17 times with respect to the BWA—MEM short read mapper, depending on the num—
ber of candidate species and the level of sequencing noise.

Availability and implementation: Data and codes are available at http://cbio.ensmp.fr/
largescalemetagenomics.

Contact: pierre.mahe@biomerieux.com

Supplementary information: Supplementary data are available at Bioinformatics online.

 

(C7 The Author 2015. Published by Oxford University Press. 1023
This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/Iicenses/by-nc/4.0/),

which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact
journals.permissions@oup.com

/310‘srcumo[p10}xo‘sopcuHOJIItotq/ﬁdnq

1024

K. Vervier et al.

 

1 Introduction

Recent progress in next—generation sequencing technologies allow to
access large amounts of genomic data within a few hours at a rea—
sonable cost (Soon et al., 2013). In metagenomics, next—generation
sequencing is used to analyze the genomic content of microbial com—
munities by sequencing all DNA present in an environmental sample
(Riesenfeld et al., 2004). It gives access to all organisms present in
the sample even if they do not grow on culture media (Hugenholtz
et al., 2002) and allows us to characterize with an unprecedented
level of resolution the diversity of the microbial realm (Peterson
et al., 2009).

The raw output of a metagenomics experiment is a large set of
short DNA sequences (reads) obtained by high—throughput sequenc—
ing of the DNA present in the sample. There exist two main
approaches to analyze these data, corresponding to slightly different
goals. On the one hand, taxonomic proﬁling aims to estimate the
relative abundance of the members of the microbial community,
without necessarily assigning each read to a taxonomic class. Recent
works like WGSQuikr (Koslicki et al., 2014) or GASIC (Lindner
and Renard, 2012) proved to be very efficient for this purpose.
Taxonomic binning methods, on the other hand, explicitly assign
each read to a taxonomic clade. This process can be unsupervised,
relying on clustering methods to assign reads to several bins (i.e.
clusters), or supervised, in which case reads are individually assigned
to nodes of the taxonomy (Mande et al., 2012). While binning is ar—
guably more challenging than profiling, it is a necessary step for
downstream applications which require draft—genome reconstruc—
tion. This may notably be the case in a diagnostics context, where
further analyses could aim to detect pathogen microorganisms
(Miller et al., 2013) or antibiotic resistance mechanisms (Schmieder
and Edwards, 2012).

In this article, we focus on the problem of supervised taxonomic
binning, where we wish to assign each read in a metagenomics sam—
ple to a node of a pre—defined taxonomy. Two main computational
strategies have been proposed for that purpose: (i) alignment—based
approaches, where the read is searched against a reference sequence
database with sequence alignment tools like BLAST (Huson et al.,
2007) or short read mapping tools (e.g. BWA, Li and Durbin, 2009)
and (ii) compositional approaches, where a machine learning model
such as a naive Bayes (NB) classifier (Parks et al., 2011; Wang et al.,
2007) or a support vector machine (SVM, McHardy et al., 2007;
Patil et al., 2012) is trained to label the read based on the set of
k—mers it contains. Recently, a very fast compositional approach
using long k—mers and not based on machine learning models, called
Kraken (Wood and Salzberg, 2014), has also been proposed. Since
the taxonomic classification of a sequence by compositional
approaches is only based on the set of k—mers it contains, they can
offer significant gain in terms of classification time over similarity—
based approaches. Training a machine learning model for taxo—
nomic binning can, however, be computationally challenging.
Indeed, compositional approaches must be trained on a set of se—
quences with known taxonomic labels, typically obtained by sam—
pling error—free fragments from reference genomes. In the case of
NE classifiers, explicit sampling of fragments from reference gen—
omes is not needed to train the model: instead, a global profile of
k—mer abundance from each reference genome is sufficient to esti—
mate the parameters of the NB model, leading to simple and fast im—
plementations (Parks et al., 2011; Rosen et al., 2011; Wang et al.,
2007). On the other hand, in the case of SVM and related discrim—
inative methods, an explicit sampling of fragments from reference
genomes to train the model based on the k—mer content of each

fragment is needed, which can be a limitation for standard SVM im—
plementations. For example, Patil et al. (2012) sampled approxi—
mately 10000 fragments from 1768 genomes to train a structured
SVM (based on a k—mer representation with [6:4, 5, 6) and re—
ported an accuracy competitive with similarity—based approaches.
Increasing the number of fragments sampled to train a SVM may im—
prove its accuracy and allow us to investigate larger values of k.
However, it also raises computational challenges, as it involves ma—
chine learning problems where a model must be trained from poten—
tially millions or billions of training examples, each represented by a
vector in 107 dimensions for, e.g. k : 12.

In this work, we investigate the potential of compositional
approaches for taxonomic label assignment using modern, large—
scale machine learning algorithms. We propose a new, rank—flexible
compositional approach trained with large—scale machine learning
methods and assess its performance in different situations. We show
that it provides an interesting trade—off in speed and accuracy com—
pared to the state—of—the—art, particularly when confronted to species
absent from the reference database, and for a moderate number of
candidate species.

2 Methods

2.1 Linear models for read classification
In most of compositional metagenomics applications, a sequence is
represented by its k—mer profile, namely, a vector counting the num—
ber of occurrences of any possible word of k letters in the sequence.
Only the A.T.C.G nucleotides are usually considered to define
k—mer profiles, that are therefore 4k—dimensional vectors. Although
the size of the k—mer profile of a sequence of length 1 increases expo—
nentially with k, it contains at most I — k + 1 non—zero elements
since a sequence of length k contains 1 — k + 1 different k—mers.
Given a sequence represented by its k—mer profile x 6 R40, we
consider linear models to assign it to one of K chosen taxonomic
classes. A linear model is a set of weight vectors w1. . . . .wK E R40
that assign x to the class

T
ar max w- x 1
g;:1.....1< / ’ ( l

where wT

x is the standard inner product between vectors. To train
the linear model, we start from a training set of sequences x1. . . . .xn
E R“ with known taxonomic labels 61,. . . ,6” E {1, . . . ,K}. An NB
classifier, e.g. is a linear model where the weights are estimated from
the k—mer count distributions on each class. Another class of linear
models popular in machine learning, which include SVM, are the
discriminative approaches that learn the weights by solving an opti—
mization problem which aims to separate the training data of each
class from each other. More precisely, to optimize the weight w, of
the jth class, one typically assigns a binary label 3/, to each training
example (31,21 if c,:/ or y,- : —1 otherwise) and solves an opti—
mization problem of the form

. 1 n
125D;ZZ(yiawai)+/lllwllza (2)
i:1

where [(y. t) is a loss function quantifying how ‘good’ the prediction
t is if the true label is y, and /l 2 0 is a regularization parameter to
tune, helpful to prevent overfitting in high dimension. An SVM sol—
ves (2) with the hinge loss [(31, t) : max(0. 1 — yt), but other losses
such as the logistic loss Z(y,t) : log(1 + exp(—yt)) or the squared
loss [(31, t) : (y — t)2 are also possible and often lead to models with
similar accuracies. These models have met significant success in

[310'sp2umofp105xo'sopeuHOJIItotq/ﬁdnq

Large—scale machine learning for metagenomics sequence classification 1025

 

numerous real—world learning tasks, including compositional meta—
genomics (Patil et al., 2012). In this work, we use the squared loss
function and choose A: 0, a setting that seemed appropriate from
preliminary experiments.

2.2 Large—scale learning of linear models

Although learning linear models by solving (2) is now a mature
technology implemented in numerous softwares, metagenomics ap—
plications raise computational challenges for most standard imple—
mentations, due to the large values that n (number of reads in the
training set), 17 : 4’z (dimension of the models) and K (number of
taxonomic classes) can take.

The training set is typically obtained by sampling fragments
from reference genomes with known taxonomic class. For example,
Patil et al. (2012) sampled approximately n : 10 000 fragments
from 1768 genomes to train SVM models based on k—mer profiles of
size k : 4, 5, 6. However, the number of distinct fragments that may
be drawn from a genome sequence is approximately equal to its
length (by sampling a fragment starting at each position in the gen—
ome), hence can reach several millions for each microbial genome,
leading to potentially billions of training sequences when thousands
of reference genomes are used. While considering every possible
fragment from every possible genome may not be the best choice be—
cause of the possible redundancy between the reads, it may still be
useful to consider a significant number of fragments to properly
account for the intra and inter species genomic variability. Similarly,
exploring models with k larger than 6, say 10 or 15, may be interest—
ing but requires (i) the capacity to manipulate the corresponding
4k—dimensional vectors (415 ~ 109) and (ii) large training sets since
many examples are needed to learn a model in high dimension.
Finally, real—life applications involving actual environmental sam—
ples may contain several hundreds microbial species, casting the
problem into a relatively massive multiclass scenario out of reach of
most standard implementations of SVM.

To solve (2) efficiently when n, k and K take large values, we use
a dedicated implementation of stochastic gradient descent (SGD
Bottou, 1998) available in the Vowpal Wabbit software (VW,
Agarwal et al., 2014; Langford et al., 2007). In short, SGD exploits
the fact that the objective function in (2) is an average of n terms,
one for each training example, to approximate the gradient at each
step using a single, randomly chosen term. Although SGD requires
more steps to converge to the solution than standard gradient des—
cent, each step is n times faster and the method is overall faster and
more scalable. In addition, although the dimension p : 4’2 of the
data is large, VW exploits the fact that each training example is
sparse, leading to efficient memory storage and fast updates at each
SGD step. We refer the interested reader to Bottou (2010) for more
discussion about the relevance of SGD in large—scale learning. In
practice, VW can train a model with virtually no limit on n as long
as the data can be stored on a disk (they are not loaded in memory).
As for k, VW can handle up to 232 distinct features, and the count of
each k—mer is randomly mapped to one feature by a hash table. This
means that we have virtually no limit on k, except that when k
approaches or exceeds the limit (such that 4]2 : 232, i.e. k : 16), col—
lisions will appear in the hash table and different k—mers will be
counted together, which may impact the performance of the model.

2.3 Rank—specific and rank—flexible read classification

The classification approach described in Section 2.1 can be readily
applied by labelling sampled fragments according to a given taxo—
nomic rank and learning read classification models tailored to this

level of resolution, which is sometimes referred to as rank-specific
approaches (Parks et al., 2011). We build such rank—specific classi—
fiers at the species, genus and family levels.

In addition, we implement a rank-flexible classifier to automatic—
ally choose the most adequate level where a read should be classified
in the taxonomy or leave it unclassified if it looks too different from
the reads used to train the model. For that purpose, we assess the re—
liability of a rank—specific prediction at any level by means of two
criteria: the maximum score returned by the linear model (1) and
the difference between the two largest scores. According to the ter—
minology proposed by Gammerman and Vovk (2007), the former
criterion accounts for the credibility of the prediction: if the se—
quence is not granted a sufficient score for any class, it may be con—
sidered unusual with respect to the training dataset. The latter
criterion accounts for the conﬁdence of the prediction: if the scores
of the two top—scoring classes are comparable, both classes may be
considered plausible. By combining both criteria we can reject pre—
dictions that are unlikely or ambiguous. To combine rank—specific
classifiers into a rank—flexible one, we start from the model built at
the lowest rank—species in our case—and iteratively allow a re—
jected read to be classified at the upper rank. If a read is rejected by
all rank—specific models considered, it is left unclassified.

The reject option mechanism underlying this rank—flexible pro—
cedure heavily depends on thresholds on the maximum score of the
linear model and on the difference between the two largest scores,
which can be set globally or on a taxon—by—taxon basis. A strategy
to optimize these thresholds is described in Supplementary Materials
(Section 2), together with an illustration of the trade—offs that can be
achieved in terms of recall and precision.

3 Data

We assemble three databases of genomes, which we refer to below
as the small, the medium and the large databases. Each comprises a
set of reference genomes to train the models and a set of validation
genomes from which reads are generated to evaluate the perform—
ance of the different classification methods.

The small database contains as references 356 complete genome
sequences covering 51 bacterial species, listed in Supplementary
Table 51. For validation, we choose 52 genomes not present in the
reference database but originating from one of the 51 species (two
genomes are indeed available for the Francisella tularensis species,
one of which originating from the nouicida subspecies). This small
database is of limited biological interest but is convenient to exten—
sively test the different methods and vary their parameters.

The medium and large databases are meant to represent more
realistic situations, involving a larger number of candidate bacterial
species and a larger number of reference genomes. We download the
5201 complete bacterial and archeal genomes available in the NCBI
RefSeq database as of July 2014 (Pruitt et al., 2012), by means of a
functionality embedded in the Fragment Classification Package
(Parks et al., 2011). We then filter these sequences according to a
criterion proposed in Parks et al. (2011), only keeping genomes that
belong to genera represented by at least three species. We also re—
move genomes represented by less than 106 nucleotides to filter draft
genome sequences, plasmids, phages, contigs and other short se—
quences. The 2961 remaining genomes originate from 774 species,
among which 193 are represented by at least two strains and 110 by
at least three strains. To build the medium database, we randomly
pick one strain within each of the 110 species with at least three
strains as a validation set and combine all other sequences in the

ﬁm'srcumol‘piqxo'sopeuuowtotq/ﬁdnq

Supplementary Table 52

Patil el al., 2012

Figure 1

l\4artin el al. (2012)

Li, 2013
Rosen el al., 2011

Parks el al., 2011

 

 

 

/3.IO'S[BIImOfp.IOJXO'SOIIBLUJOJIIIOICV/Zduq

\Xlood and Salzberg, 2014

Figure 2

Figure 3

55,2\Ewogmoddmmowoio~&o:~=£¢o~m\

975

5'79 866
823 I
961
891  921 I
j 00 858 am I
i 784 806
751 I

95
886 889

899

8

804

6

3

8O

 

3

7

702

 

Angly at al., 2012

Balzer at al., 2010
Korbel at al. (2009)

2009

Supplementary Materials

2151 97 3

853  878 856 - as
805 793
741

I 
m

 

Korbel at al.,

861

75E1 I 754

 

   

 

Figure 4

Supplementary Materials

E17 3 -

865 858

781

4
u.

m

a

u

 

757 I 764

 

E14 7
88 2

856

E17 4

 

 

/3.IO'S[BIImOfp.IOJXO"SOIJBLUJOJIIIOIqﬂZduq

Figure 5

Supplementary Materials

Supplementary Figure S9

Figure 6

Figure 5

 

Supplementary Figure 87

Figure 6

Lukjancenko et al., 2010

/310'S[BIIm0prOJXO'SOIJEIIIJOJIIIOIq/ﬂdnq

Sonnenburg el al. (2006)

fragments
homo—Balzer

miseq
mutation—2
Kraken

 

 

 

 

Supplementary Table S4

Figure 7

/3.IO'S[BIImOfp.IOJXO'SOIIBLUJOJIIIOICV/Zduq

Large—scale machine learning for metagenomics sequence classification 1031

 

We extensively evaluate its performance when the scale of the problem
increases regarding (i) the length of the k—mers considered to represent
a sequence, (ii) the number of fragments used to learn the model and
(iii) the number of candidate species involved in the reference data—
base. We also investigate in details its robustness to sequencing errors
using simulated reads. We consider three baselines for this evaluation:
a comparative approach based on the BWA—MEM sequence aligner
and two compositional approaches based on the generative NB classi—
fier and based on Kraken. We demonstrate in particular that increas—
ing the number of fragments used to train the model has a significant
impact on the accuracy of the model and allows to estimate models
based on longer k—mers. While this could be expected and was already
highlighted by previous studies, the resulting configurations are out of
reach of standard SVM implementations. We also show that discrimi—
natively trained compositional models usually offer significantly
higher performances than generative NB classifiers. The resulting
models are competitive with well—established alignment tools and with
Kraken for problems involving a small to moderate number of candi—
date species and for realistic amounts of sequencing errors. Our results
suggest, however, that machine learning—based compositional
approaches, both discriminative and generative, are still limited in
their ability to deal with problems involving more than a few hundreds
species. In this case, indeed, compositional approaches exhibit lower
performance than alignment—based approaches and are much more
negatively impacted by sequencing errors. When confronted with spe—
cies absent from the training set, we show that our model is more ac—
curate than Kraken, which has a larger level of rejection due to its use
of longer k—mers, and affects more reads too specifically to species of
the reference dataset. Finally, we confirm that compositional
approaches achieve faster prediction times. This is indeed systematic—
ally the case in the various configurations listed above, with predic—
tions obtained 2—17 times faster by compositional approaches, and,
interestingly, depends on the number of candidate species. We note in
particular, that for problems involving fewer than 100 candidate spe—
cies, which may arise in diagnostic applications involving specific types
of specimens, VW can achieve faster prediction times than Kraken. At
the extreme, for the binary problem aiming to separate bacterial from
human reads, which is commonly used while analyzing a microbiome
sample, VW can offer a 9—fold increase in terms of prediction time
with respect to Kraken. We emphasize, however, that fast predictions
can only be obtained provided that the classification models are
loaded in memory, hence for a memory footprint that scales linearly
with the number of candidate species and exponentially with the size
of the k—mers, which can become important for large reference data—
bases and long k—mers.

At least three simple extensions could be envisioned to make com—
positional approaches more competitive in accuracy with the align—
ment—based approach, faster and to limit their memory footprint. First,
the robustness to sequencing errors may be improved by learning mod—
els from simulated reads instead of fragments. This could indeed allow
to tune the model to the sequencing technology producing the reads to
be analyzed, provided its error model is properly known and character—
ized. Second, introducing a sparsity—inducing penalty while learning the
model would have the effect of reducing the number of features enter—
ing the model, hence to reduce the memory footprint required to load
the model into memory. Finally, alternative strategies, known as error
correcting tournaments (Beygelzimer et al., 2009), could be straightfor—
wardly considered to reduce the number of models to learn, hence to
store into memory during prediction, to address a multiclass problem.
Our results indeed suggest that addressing these issues is critical to
build state—of—the—art compositional classifiers to analyze metagenomics
samples that may involve a broad spectrum of species.

Funding

This work was supported by the European Research Council (SMAC-ERC-
280032 to J-P.V.) and the French National Research Agency (ANR-ll-BINF-
0001 to J—P.V.).

Conﬂict of Interest: none declared.

References

Agarwal,A. et al. (2014) A reliable effective terascale linear learning system.
Mach. Learn. Res., 15,1111—1133.

Angly,F. et al. (2012) Grinder: a versatile amplicon and shotgun sequence
simulator. Nucleic Acids Res., 40, 94—94.

Balzer,S. et al. (2010) Characteristics of 454 pyrosequencing data enabling
realistic simulation with ﬂowsim. Bioinformatics, 26, 420—425.

Beygelzimer,A. et al. (2009) Error-correcting tournaments. Algorithmic
Learn. Theory, 5809, 247—262.

Bottou,L. (1998) Online learning and stochastic approximations. Online
Learn. Neural Netw., 17, 9—42.

Bottou,L. (2010) Large-scale machine learning with stochastic gradient descent.
In: Lechevallier,Y. and Saporta,G. (eds), Proceedings of COMPSTAT’ZOI 0,
Physica-Verlag, pp. 177—186.

Gammerman,A. and Vovk,V. (2007) Eedging predictions in machine learning.
Comput. ]., 50,151—163.

Hugenholtz,P. et al. (2002) Exploring prokaryotic diversity in the genomic
era. Genome Biol, 3, 1—3.

Huson,D. et al. (2007) MEGAN analysis of metagenomic data. Genome Res,
17, 377—386.

Korbel,]. et al. (2009) PEMer: a computational framework with simulation-
based error models for inferring genomic structural variants from massive
paired-end sequencing data. Genome Biol, 10, 23—23.

Koslicki,D. et al. (2014) WGSQuikr: fast whole-genome shotgun metage-
nomic classiﬁcation. PLOS One, 9, e91784.

Langford,]. et al. (2007) Vowpal Wabbit open source project. Technical re-
port. Yahoo.

Li,H. (2013) Aligning sequence reads, clone sequences and assembly contigs
with BWA-MEM. arXiU preprint arXiv:1303.399 7.

Li,H. and Durbin,R. (2009) Fast and accurate short read alignment with
Burrows-Wheeler transform. Bioinformatics, 25, 1754—1760.

Lindner,M.S. and Renard,B.Y. (2012) Metagenomic abundance estimation
and diagnostic testing on species level. Nucleic Acids Res., 41, e10.

Lukjancenko,O. et al. (2010) Comparison of 61 sequenced Escherichia coli
genomes. Microh. Ecol, 60, 708—720.

Mande,S. et al. (2012) Classiﬁcation of metagenomic sequences: methods and
challenges. BriefBioinform., 13, 669—681.

Martin,]. et al. (2012) Optimizing read mapping to reference genomes to de—
termine composition and species prevalence in microbial communities.
PLOS One, 7, e36427.

McHardy,A.C. et al. (2007) Accurate phylogenetic classiﬁcation of variable-
length DNA fragments. Nat. Methods, 4, 63—72.

Miller,R. et al. (2013) Metagenomics for pathogen detection in public health.
Genome Med., 5, 81—95.

Parks,D. et al. (2011) Classifying short genomic fragments from
novel lineages using composition and homology. BMC Bioinformatics, 12,
328—344.

Patil,K. et al. (2012) The PhyloPythiaS web server for taxonomic assignment
of metagenome sequences. PLOS One, 7, e38581.

Peterson,]. et al. (2009) The NIH human microbiome project. Genome Res.,
19, 2317—2323.

Pruitt,K. et al. (2012) NCBI reference sequences (RefSeq): current status,
new features and genome annotation policy. Nucleic Acids Res., 40,
130—135.

Riesenfeld,C. et al. (2004) Metagenomics: genomic analysis of microbial com-
munities. Annu. Rev. Genet, 38, 525—552.

Rosen,G. et al. (2011) NBC: the Naive Bayes classiﬁcation tool webserver
for taxonomic classiﬁcation of metagenomic reads. Bioinformatics, 27,
127—129.

ﬁm'srcumol‘piqxo'sopeuuowtotq/ﬁdnq

1032

K. Vervier et al.

 

Schmieder,R. and Edwards,R. (2012) Insights into antibiotic resistance
through metagenomic approaches. Future Microhiol, 7, 73—89.

Sonnenburg,S. et al. (2006) Large scale learning with string kernels. Mach.
Learn. Res., 7,1531—1565.

Soon,W. et al. (2013) High-throughput sequencing for biology and medicine.
Mol Syst. Biol, 9.

Wang,Q. et al. (2007) Naive Bayesian classiﬁer for rapid assignment of rRNA
sequences into the new bacterial taxonomy. Appl Environ. Microhiol, 73,
5261—5267.

Wood,D.E. and Salzberg,S.L. (2014) Kraken: ultrafast metagenomic sequence
classiﬁcation using exact alignments. Genome Biol, 15, R46.

/810'sleumofp103xo"soueuuogutotqﬂ:duq

