Bioinformatics, 32, 2016, i192—i200
doi: 10.1 093/bioinformatics/btw277
ISM B 2016

 

RapMap: a rapid, sensitive and accurate tool for
mapping RNA-seq reads to transcriptomes

Avi Srivastava, Hirak Sarkar, Nitish Gupta and Rob Patro*

Department of Computer Science, Stony Brook University Stony Brook, New York, NY 11794-2424, USA

*To whom correspondence should be addressed.

Abstract

Motivation: The alignment of sequencing reads to a transcriptome is a common and important
step in many RNA—seq analysis tasks. When aligning RNA—seq reads directly to a transcriptome (as
is common in the de novo setting or when a trusted reference annotation is available), care must
be taken to report the potentially large number of multi—mapping locations per read. This can pose
a substantial computational burden for existing aligners, and can considerably slow downstream
analysis.

Results: We introduce a novel concept, quasi—mapping, and an efficient algorithm implementing
this approach for mapping sequencing reads to a transcriptome. By attempting only to report the
potential loci of origin of a sequencing read, and not the base—to—base alignment by which it derives
from the reference, RapMap—our tool implementing quasi—mapping—is capable of mapping
sequencing reads to a target transcriptome substantially faster than existing alignment tools. The
algorithm we use to implement quasi—mapping uses several efficient data structures and takes ad—
vantage of the special structure of shared sequence prevalent in transcriptomes to rapidly provide
highly—accurate mapping information. We demonstrate how quasi—mapping can be successfully
applied to the problems oftranscript—level quantification from RNA—seq reads and the clustering of
contigs from de novo assembled transcriptomes into biologically meaningful groups.

Availability and implementation: RapMap is implemented in C++11 and is available as open—

 

source software, under GPL v3, at https://github.com/COMBINE— lab/RapMap.

Contact: rob.patro@cs.sto nybrook.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

The bioinformatics community has put tremendous effort into build-
ing a wide array of different tools to solve the read-alignment prob-
lem efficiently. These tools use many different strategies to quickly
find potential alignment locations for reads, for example, Bowtie
(Langmead et (11., 2009), Bowtie 2 (Langmead and Salzberg, 2012),
BWA (Li and Durbin, 2009) and BWA-mem (Li, 2013) use variants
of the FM-index, while tools like the Subread aligner (Liao et (11.,
2013), Maq (Li et (11., 2008) and MrsFast (Hach et (11., 2010) use
k-mer-based indices to help align reads efficiently. Because read
alignment is such a ubiquitous task, the goal of such tools is often to
provide accurate results as quickly as possible. Indeed, recent align-
ment tools like STAR (Dobin et (11., 2013) demonstrate that rapid
alignment of sequenced reads is possible, and tools like HISAT (Kim
et (11., 2015) demonstrate that this speed can be achieved with only
moderate memory usage. When reads are aligned to a collection of
reference sequences that share a substantial amount of sub-sequence
(near or exact repeats), a single read can have many potential

© The Author 2016. Published by Oxford University Press.

alignments, and considering all such alignment can be crucial for
downstream analysis (e.g. considering all alignment locations for a
read within a transcriptome for the purpose of quantification, Li
and Dewey (2011), or when attempting to cluster dc nor/o assembled
contigs by shared multi-mapping reads, Davidson and Oshlack,
2014). However, reporting multiple potential alignments for each
read is a difficult task, and tends to substantially slow down even ef-
ficient alignment tools.

Yet, in many cases, all of the information provided by the align-
ments is not necessary. For example, in the transcript analysis tasks
mentioned above, simply the knowledge of the transcripts and pos-
itions to which a given read maps well is sufficient to answer the
questions being posed. In support of such ‘analysis-efficient’ compu-
tation, we propose a novel concept, called quasi-mapping, and an ef-
ficient algorithm implementing quasi-mapping (exposed in the
software tool RapMap) to solve the problem of mapping sequenced
reads to a target transcriptome. This algorithm is considerably faster
than state-of-the-art aligners, and achieves its impressive speed by

i192

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.U/),
which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact

journals.permissions@oup.com

/310‘srcumo[p10}xo‘sopcuHOJIIrorq/ﬁdnq

RapMap

i193

 

exploiting the structure of the transcriptome (without requiring an
annotation), and eliding the computation of full—alignments (e.g.
CIGAR strings). Further, our algorithm produces mappings that
meet or exceed the accuracy of existing popular aligners under dif—
ferent metrics of accuracy. Finally, we demonstrate how the map—
pings produced by RapMap can be used in the downstream analysis
task of transcript—level quantification from RNA—seq data, by mod—
ifying the Sailfish (Patro et al., 2014) tool to take advantage of
quasi—mappings, as opposed to individual k—mer counts, for tran—
script quantification. We also demonstrate how quasi—mappings can
be used to effectively cluster contigs from de novo assemblies. We
show that the resulting clusterings are of comparable or superior ac—
curacy to those produced by recent methods such as CORSET
(Davidson and Oshlack, 2014), but that they can be computed
much more quickly using quasi—mapping.

2 Methods

The quasi—mapping concept, implemented in the tool RapMap, is a
new mapping technique to allow the rapid and accurate mapping of
sequenced fragments (single or paired—end reads) to a target tran—
scriptome. RapMap exploits a combination of data structures—a
hash table, suffix array (SA) and efficient rank data structure. It
takes into account the special structure present in transcriptomic ref—
erences, as exposed by the SA, to enable ultra—fast and accurate de—
termination of the likely loci of origin of a sequencing read. Rather
than a standard alignment, quasi—mapping produces what we refer
to as fragment mapping information. In particular, it provides, for
each query (fragment), the reference sequences (transcripts), strand
and position from which the query may have likely originated. In
many cases, this mapping information is sufficient for downstream
analysis. For example, tasks like transcript quantification, clustering
of de novo assembled transcripts and filtering of potential target
transcripts can be accomplished with this mapping information.
However, this method does not compute the base—to—base alignment
between the query and reference. Thus, such mappings may not be
appropriate in every situation in which alignments are currently
used (e.g. variant detection).

We note here that the concept of quasi—mapping shares certain
motivations with the notions of lightweight—alignment (Patro et al.,
2015) and pseudoalignment (Bray et al., 2016). Yet, all three
concepts—and the algorithms and data structures used to
implement them—are distinct and, in places, substantially different.
Lightweight—alignment scores potential matches based on approxi—
mately consistent chains of super—maximal exact matches shared be—
tween the query and targets. Therefore, it typically requires some
more computation than the other methods, but allows the reporting
of a score with each returned mapping and a more flexible notion of
matching. Pseudoalignment, as implemented in Kallisto, refers only
to the process of finding compatible targets for reads by determining
approximately matching paths in a colored De Bruijn graph of a
pre—specified order. Among compatible targets, extra information
concerning the mapping (e.g. position and orientation) can be ex—
tracted post boc, but this requires extra processing, and the resulting
mapping is no longer technically a pseudoalignment. Quasi—mapping
seeks to find the best mappings (targets and positions) for each read,
and does so (approximately) by finding minimal collections of dy—
namically sized, right—maximal, matching contexts between target
and query positions. Quasi—mapping is inspired by both lightweight—
alignment (Patro et al. (2015)) and pseudoalignment (Bray et al.,
2016), and while each of these approaches provide some insight into

the problems of alignment and mapping, they represent distinct con—
cepts and exhibit unique characteristics in terms of speed and accur—
acy, as demonstrated below (We do not compare against
lightweight—alignment here, as no stand—alone implementation of
this approach is currently available).

2.1 An algorithm for Quasi—mapping

The algorithm we use for quasi—mapping makes use of two main
data structures, the generalized SA (Manber and Myers, 1993)
SA[T] of the transcriptome T, and a hash table 10 mapping each k—
mer occurring in T to its SA interval (by default k : 31).
Additionally, we must maintain the original text T on which the SA
was constructed, and the name and length of each of the original
transcript sequences. T consists of a string in which all transcript se—
quences are joined together with a special separator character.
Rather than designating a separate terminator $i for each reference
sequence in the transcriptome, we make use of a single separator $,
and maintain an auxiliary rank data structure, which allows us to
map from an arbitrary position in the concatenated text to the index
of the reference transcript in which it appears. We use the rank9b al—
gorithm and data structure of Vigna (2008) to perform the rank op—
eration quickly.

Quasi—mapping determines the mapping locations for a query
read 1’ through repeated application of (i) determining the next hash
table k—mer that starts past the current query position, (ii) comput—
ing the maximum mappable prefix (MMP) of the query beginning
with this k—mer and then (iii) determining the next informative pos—
ition (NIP) by performing a longest common prefix (LCP) query on
two specifically chosen suffixes in the SA.

The algorithm begins by hashing the k—mers of r, from left—to—
right (a symmetric procedure can be used for mapping the reverse—
complement of a read), until some k—mer k,—the k—mer starting at
position 1' within the read—is present in b and maps to a valid SA
interval. We denote this interval as I(ki) : lb. e) . Because of the lex—
icographic order of the suffixes in the SA, we immediately know
that this k—mer is a prefix of all of the suffixes appearing in the given
interval. However, it may be possible to extend this match to some
longer substring of the read beginning with 16,. In fact, the longest
substring of the read that appears in the reference and is prefixed by
k, is exactly the MMP (Dobin et al., 2013) of the suffix of the read
beginning with 13,. We call this MMP,, and note that it can be found
using a slight variant of the standard SA binary search (Manber and
Myers, 1993) algorithm. For speed and simplicity, we implement
the ‘simple accelerant’ binary search variant of Gusfield (1997).
Because we know that any substring that begins with k, must reside
in the interval [b,e), we can restrict the MMP, search to this region
of the SA, which is typically small.

After determining the length of MMP, within the read, one could
begin the search for the next mappable SA interval at the position fol—
lowing this MMP. However, though the current substring of the read
will differ from all of the reference sequence suffixes at the base fol—
lowing MMP,, the suffixes occurring at the lower and upper bounds
of the SA interval corresponding to MMP, may not differ from each
other (see Fig. 1). That is, if I(MMP,~) : [b’, e’) is the SA interval cor—
responding to MMP,, it is possible that lLCP(T[SA[b’] ] .
TlSAle’ — 1] l  > lMMPil . In this case, it is most likely that the
read and the reference sequence bases following MMP, disagree as the
result of a sequencing error, not because the (long) MMP discovered
between the read and reference is a spurious match. Thus, beginning
the search for the next MMP at the subsequent base in the read may
not be productive, as the matches for this substring of the query may

ﬁm'sreumol‘pquo'sopcuuowrorq/ﬁdnq

 

l
I
I
l
I MMPi NIP MMPi
I
I
I

 

 

 

ki ...
ATT
‘ h
\ . h
‘ .
\ . $
\
s
s
‘W
h _ _>
Bray et [1]., 2016
Bray
et [1]., 2016
Ilie
et a]. (2010)
Fig. 1

Liao et a]. (2013)

/810's113umo_fp103x0"SDIJBmJOJurorW/zdnq

Figure 2

Langinead and Salzberg, 2012 Dobin

(7/ LIL, 2013
Bra} (7/ rr/., 2016
Kirster

and Rahniann, 2012
Figure 2

hdargais and Kingsford, 2011

(iriebel (7/ rr/., 2012

Cunningham (7/ rr/., 2015

bowtie- 2

STAR

RapMap

index loading (RapMap)

Su pplenienta 1‘} Appendix 1.2

Suppleinentar)

Appendix 1.1

Su pplenienta 1‘} Append ix 1.1

 

/310'S[BIIJHO[pJOJXO'SOIJBLUJOJIIIOIq/ﬂduq

Table 1

Fig.

Lu

Gilbert el (11., 2004

Supplementary Appendix 1.3

(lho el al. (2014)

Figure 3

Figure 3

 

/810'sreumoprOJxo'sopeuiJOJurorq”:duq

RapMap

i197

 

we see (seemingly) low agreement between Bowtie 2 and other
methods is because the transcript alignment sets reported by Bowtie
2 are generally larger (i.e. contain more transcripts) than those re—
turned by other methods, and thus fail to qualify under our notion
of agreement. This occurs, partially, because RapMap and Kallisto
(and to some extent STAR) do not tend to return sub—optimal multi—
mapping locations. However, unlike Bowtie 1, which provided an
option to return only the best ‘stratum’ of alignments, there is no
way to require that Bowtie 2 return only the best multi—mapping lo—
cations for a read. We observe similar behavior for Bowtie 2 (i.e.
that it returns a larger set of mapping locations) in the synthetic tests
as well, where the average number of hits per read is higher than for
the other methods (see Table 1). In terms of runtime, RapMap,
STAR and Bowtie 2 take 3, 26 and 1020 min, respectively, to align
the reads from this experiment using four threads. We also observed
a similar trend in terms of the average number of hits per read here
as we did in the synthetic dataset. The average number of hits per
read on these data were 4.56, 4.68, 4.21 and 7.97 for RapMap,
Kallisto, STAR and Bowtie 2, respectively.

4 Application of quasi-mapping for transcript
quantification

While mapping cannot act as a stand—in for full alignments in all
contexts, one problem where similar approaches have already pro—
ven useful is transcript abundance estimation. Recent work (Bray
et al., 2016; Patro et al., 2014, 2015; Zhang and Wang, 2014) has
demonstrated that full alignments are not necessary to obtain accur—
ate quantification results. Rather, simply knowing the transcripts
and positions where reads may have reasonably originated is suffi—
cient to produce accurate estimates of transcript abundance. Thus,
we have chosen to apply quasi—mapping to transcript—level quantifi—
cation as an example application, and have implemented our modifi—
cations as an update to the Sailfish (Patro et al., 2014) software,
which we refer to as quasi—Sailfish. These changes are present in the
Sailfish software from version 0.7 forward. Here, we compare this
updated method to the transcript—level quantification tools RSEM
(Li et al., 2010), Tigar2 (Nariai et al., 2014) and Kallisto (Bray
et al., 2016), the last of which is based on the pseudoalignment con—
cept mentioned above.

4.1 Transcript quantification

In an RNA—seq experiment, the underlying transcriptome consists of
M transcripts and their respective counts. The transcriptome can be
represented as a set X : {(t1. . . . . tM). (c1. . . . .cM)}, where t, denotes
the nucleotide sequence of transcript i and c, denotes the number of
copies of t, in the sample. The length of transcript t, is denoted by 1,.
Under ideal, uniform, sampling conditions (i.e. without considering
various types of experimental bias), the probability of drawing a
fragment from a transcript t, is proportional to its nucleotide frac—

tion (Li et al., 2010) denoted by 11,- : 
2;:1 C/I/
If we normalize the 11, for each transcript by its length l,, we ob—
tain a measure of the relative abundance of each transcript called
the transcript fraction (Li et al., 2010), which is given by

l
[I

‘5‘: .
’ 2,:177‘

When performing transcript—level quantification, I] and 1: are gen—

 

erally the quantities we are interested in inferring. Because they are
directly related, knowing one allows us to directly compute the
other. Below, we describe our approach to approximating the

estimated number of reads originating from each transcript, from
which we estimate 1:, and subsequently transcripts per million
(TPM).

4.2 Quasi—mapping—based Sailfish

Using the quasi—mapping procedure provided by RapMap as a li—
brary, we have updated the Sailfish (Patro et al., 2014) software to
make use of quasi—mapping, as opposed to individual k—mer count—
ing, for transcript—level quantification. In the updated version of
Sailfish, the index command builds the quasi—index over the refer—
ence transcriptome as described in Section 2. Given the index and a
set of sequenced reads, the quant command quasi—maps the reads
and uses the resulting mapping information to estimate transcript
abundances.

To reduce the memory usage and computational requirements of
the inference procedure, quasi—Sailfish reduces the mapping informa—
tion to a set of equivalence classes over sequenced fragments. These
equivalence classes are similar to those used in Nicolae et al. (2011),
except that the position of each fragment within a transcript is not
considered when defining the equivalence relation. Specifically, any
fragments that map to exactly the same set of transcripts are placed
into the same equivalence class. Following the notation of Patro
et al. (2015), the equivalence classes are denoted as C : {61.62. . . .},
and the count of fragments associated with equivalence class Cl is
given by d’. Associated with each equivalence class Cl is an ordered
collection of transcript identifiers tl : (til, t/z, . . .), which is simply
the collection of transcripts to which all equivalent fragments in this
class map. We call tl the label of class Cl .

4.2.1 Inferring transcript abundances
The equivalence classes C and their associated counts and labels are
used to estimate the number of fragments originating from each
transcript. The estimated count vector is denoted by or, and or, is the
estimated number of reads originating from transcript t,. In quasi—
Sailfish, we use the variational Bayesian expectation maximization
(VBEM) algorithm to infer the parameters (the estimated number of
reads originating from each transcript) that maximize a variational
objective. Specifically, we maximize a simplified version of the vari—
ational objective of Nariai et al. (2013).

The VBEM update rule can be written as a simple iterative up—
date in terms of the equivalence classes, their counts and the prior
(0(0). The iterative update rule for the VBEM is:

1

el'lx
Ir
51?“ 2104-20,; —M (1)

ad 2 ell ; l

t, 8/ If
where

y? : ‘P(cxo + or?) — w: are + 012) (2)
k

and  is the digamma function. Here,  is the effective length of
transcript t,, computed as in Li et al. (2010). To determine the final
estimated counts—or—Equation (1) is iterated until convergence.
The estimated counts are considered to have converged when no
transcript has estimated counts differing by >1% between succes—
sive iterations.

Given or, we compute the TPM for transcript i as

[310'sp2umofp105xo'sopeuHOJIIrotq/ﬁdnq

i198

A.Srivastava et al.

 

R

l

A“. 3
Zr, r)

I/

)l

 

TPM,- : 1 06

Sailfish outputs, for each transcript, its name, length, effective
length, TPM and the estimated number of reads originating from it.

4.3 Quantification performance comparison

We compared the accuracy of quasi—Sailfish (Sailfish v0.9.0; q—
Sailfish in Table 2) to the transcript—level quantification tools RSEM
(Li et al., 2010) (v1.2.22), Tigar 2 (Nariai et al., 2014) (v2.1) and
Kallisto (Bray et al., 2016) (v0.42.4) using six different accuracy
metrics and data from two different simulation pipelines. One of the
simulated datasets was generated with the Flux Simulator (Griebel
et al., 2012), and is the same dataset used in Section 3 to assess map—
ping accuracy and performance on synthetic data. The other dataset
was generated using the RSEM simulator via the same methodology
adopted by Bray et al. (2016). That is, RSEM was run on sample
NA12716_7 of the Geuvadis RNA—seq data (Lappalainen et al.,
2013) to learn model parameters and estimate true expression. The
learned model was then used to generate the simulated dataset,
which consists of 30 million 75 bp paired—end reads.

We measure the accuracy of each method based on the estimated
versus true number of reads originating from each transcript, and
consider six different metrics of accuracy: proportionality correl—
ation (Lovell et al., 2015 ), Spearman correlation, the true positive
error fraction (TPEF), the true positive median error (TPME), the
mean absolute relative difference (MARD) and the weighted mean
absolute relative difference (wMARD). Detailed definitions for the
last four metrics are provided in Supplementary Appendix 1.5.

Each of these metrics captures a different notion of accuracy,
and all are reported to provide a more comprehensive perspective on
quantifier accuracy. The first two metrics—proportionality and
Spearman correlation—provide a global notion of how well the esti—
mated and true counts agree, but are fairly coarse measures. The
TPEF assesses the fraction of transcripts where the estimate is differ—
ent from the true count by more than some nominal fraction (here
10%). Unlike TPEF, the TPME metric takes into account the direc—
tion of the mis—estimate (i.e. is it an over or under—estimate of the
true value?). However, both metrics are assessed only on truly ex—
pressed transcripts, and so provide no insight into the tendency of a
quantifier to produce false positives.

The absolute relative difference (ARD) metric has the benefit of
being defined on all transcripts as opposed to only those that are
truly expressed and ranges from 0 (lowest) to 2 (highest). Because
the values of this metric are tightly bounded, the aggregate metric,
MARD, is not dominated by high expression transcripts.
Unfortunately, it therefore has limited ability to capture the magni—
tude of mis—estimation. The wMARD metric attempts to account for

the magnitude of mis—estimation, while still trying to ensure that the
measure is not completely dominated by high expression transcripts.
This is done by scaling each ARD, value by the logarithm of the
expression.

Table 2 shows the performance of all four quantifiers, under all
six metrics, on both datasets. While all methods seem to perform
reasonably well, some patterns emerge. RSEM seems to perform
well in terms of the correlation metrics, but less well in terms of the
TPEF, TPME and wMARD metrics (specifically in the Flux
Simulator—generated dataset). This is likely a result of the lower
mapping rate obtained on this data by RSEM’s strict Bowtie 2 par—
ameters. Tigar 2 generally performs well under a broad range of
metrics, and produces highly accurate results. However, it is by far
the slowest method considered here, and requires over a day to com—
plete on the Flux simulator data and almost 7h to complete on the
RSEM—sim data given 16 threads (and not including the time
required for Bowtie 2 alignment of the reads). Finally, both quasi—
Sailfish and Kallisto perform well in general under multiple different
metrics, with quasi—Sailfish tending to produce somewhat more ac—
curate estimates. Both of these methods also completed in a matter
of minutes on both datasets.

One additional pattern that emerges is that the RSEM—Sim data
appears to present a much simpler inference problem compared with
the Flux Simulator data. One reason for this may be that the RSEM—
sim data are ‘clean’—yielding concordant mapping rates well over
99%, even under RSEM’s strict Bowtie 2 mapping parameters. As
such, all methods tend to perform well on these data, and there is
comparatively little deviation between the methods under most
metrics.

For completeness, we also provide (in Supplementary Appendix
1.4) the results, under all of these metrics, where the true and pre—
dicted abundances are considered in terms of TPM rather than num—
ber of reads. We find that the results are generally similar, with the
exception that TIGAR 2 performs considerably worse under the
TPM measure.

5 Application of quasi-mapping for clustering
de novo assemblies

Estimating gene—expression from RNA—seq reads is an especially
challenging task when no reference genome is present. Typically,
this problem is solved by performing de HOUO assembly of the RNA—
seq reads, and subsequently mapping these reads to the resulting
contigs to estimate expression. Owing to sequencing errors and arti—
facts, and genetic variation and repeats, de HOUO assemblers often
fragment individual isoforms into separate assembled contigs.
Davidson and Oshlack (2014) argue that better differential expres—
sion results can be obtained in de novo assemblies if contigs are first

Table 2. Performance evaluation of different tools along with quasi-enabled sailfish (q-Sailfish) with other tools on synthetic data generated

by Flux simulator and RSEM simulator

 

 

 

 

Metric Flux simulation RSEM-Sim simulation
Kallisto RSEM q-Sailfish Tigar 2 Kallisto RSEM q-Sailfish Tigar 2

Proportionality corr. 0.74 0.78 0.75 0.77 0.91 0.93 0.91 0.93
Spearman corr. 0.69 0.73 0.70 0.72 0.91 0.93 0.91 0.93
TPEF 0.77 0.96 0.60 0.59 0.53 0.49 0.53 0.50
TPME —0.24 —0.37 —0.10 —0.09 0.00 —0.01 0.00 0.00
MARD 0.36 0.29 0.31 0.26 0.29 0.25 0.29 0.23
wMARD 4.68 5.23 4.45 4.35 1.00 0.88 1.01 0.94

 

ﬁm'srcumofpquo'sopcuuopuorq/ﬁdnq

RapMap

i199

 

clustered into groups. They present a tool, CORSET, to perform this
clustering, and compare their approach to existing tools such as CD—
HIT (Fu et al., 2012). CD—HIT compares the sequences (contigs) dir—
ectly, and clusters them by sequence similarity. CORSET, alterna—
tively, aligns reads to contigs (allowing multi—mapping) and defines
a distance between each pair of contigs based on the number of
multi—mapping reads shared between them, and the changes in esti—
mated expression inferred for these contigs under different condi—
tions. Hierarchical agglomerative clustering is then performed on
these distances to obtain a clustering of contigs.

Here, we show how RapMap can be used for the same task, by
taking an approach similar to that of CORSET. First, we map the
RNA—seq reads to the target contigs and simultaneously construct
equivalence classes over the mapped fragments as in Section 4. We
construct a weighted, undirected graph from these equivalence
classes as follows. Given a set of contigs c and the equivalence
classes C, we construct G : (V, E) such that V : c, and
E : {{u,v}lEl/' : 14,11 6 ti}. We define the weight of edge {am} as
w(u, U) : W. Here RM is the total number of reads belonging
to all equivalence classes in which contig 14 appears in the label. R, is
defined analogously. Rm, is the total sum of reads in all equivalence
classes for which contigs u and U appear in the label. Given the un—
directed graph G, we use the Markov Cluster Algorithm, as imple—
mented in MCL (Van Dongen, 2000), to cluster the graph.

To benchmark the time and accuracy of our clustering scheme
compared with CD—HIT and CORSET, we used two datasets from
the CORSET paper (Davidson and Oshlaek, 2014). The first dataset
consists of 231 million human reads in total, across two conditions,
each with three replicates (as originally described by Trapnell et al.,
2013). The second dataset, from yeast, was originally published by
Nookaew et al. (2012) and consists 36 million reads, grown in two
different conditions with three replicates each. For both of these
datasets, we consider clustering the contigs of the corresponding de
novo assemblies, which were generated using Trinity (Grabherr
et al., 2011).

To measure accuracy, we consider the precision and recall
induced by a clustering with respect to the true genes from which
each contig originates. Assembled contigs were mapped to anno—
tated transcripts using BLAT (Kent, 2002), and labeled with their
gene of origin. A pair of contigs from the same cluster is regarded as
true positive (tp) if they are from the same gene in the ground truth
set. Similarly, a pair is a false positive (fp) if they are not from same
gene but are clustered together. A pair is a false negative (fn) if they
are from same gene but not predicted to be in the same cluster and
all the remaining pairs are true negatives (tn). With these definitions
of tp, fp, tn and fn we can define precision and recall in standard
manner. As shown in Table 3, when considering both precision and
recall, RapMap (quasi—mapping) enabled clustering performs sub—
stantially better than CD—HIT and similar to CORSET. RapMap
enabled clustering takes 8 min and 2min to cluster the human and
yeast datasets respectively—which is substantially faster than the

Table 3. Performance of CORSET, CD-HIT and RapMap enabled
clustering (R-CL) on yeast and human data

 

Metric Human Yeast

 

CORSET CD-HIT R-CL CORSET CD-HIT R-CL

 

precision 0.96 0.96 0.95 0.36 0.41 0.36
recall 0.56 0.37 0.60 0.63 0.36 0.71
time (min) 957 268 8 23 5 2

 

other tools. To generate the timing results above, CD—HIT was run
with 25 threads. The time recorded for CORSET consists of both
the time required to align the reads using Bowtie 2 (using 25
threads) and the time required to perform the actual clustering,
which is single threaded. The time recorded for RapMap enabled
clustering consists of the time required to quasi—map the reads, build
the equivalence classes and construct the graph (using 25 threads),
plus the time required to cluster the graph with MCL (using a single
thread). Overall, on these datasets, RapMap—enabled clustering ap—
pears to provide comparable or better clusterings than existing
methods, and produces these clusterings much more quickly.

6 Discussion and conclusion

In this article we have argued for the usefulness of our novel ap—
proach, quasi—mapping, for mapping RNA—seq reads. More gener—
ally, we suspect that read mapping, wherein sequencing reads are
assigned to reference locations, but base—to—base alignments are not
computed, is a broadly useful tool. The speed of traditional aligners
like Bowtie 2 and STAR is limited by the fact that they must produce
optimal alignments for each location to which a read is reported to
align.

In addition to showing the speed and accuracy of quasi—mapping
directly, we apply it to two problems in transcriptome analysis.
First, we have updated the Sailfish software to make use of the
quasi—mapping information produced by RapMap, rather than dir—
ect k—mer counts, for purposes of transcript—level abundance estima—
tion. This update improves both the speed and accuracy of Sailfish,
and also reduces the complexity of its codebase. We demonstrate,
on synthetic data generated via two different simulators, that the re—
sulting quantification estimates have accuracy comparable with
state—of—the—art tools. We also demonstrate the application of
RapMap to the problem of clustering a'e HOUO assembled contigs, a
task that has been shown to improve expression quantification and
downstream differential expression analysis (Davidson and
Oshlaek, 2014). RapMap can produce clusterings of comparable or
superior accuracy to those of existing tools, and can do so much
more quickly.

However, RapMap is a stand—alone mapping program, and need
not be used only for the applications we describe here. We expect
that quasi—mapping will prove a useful and rapid alternative to
alignment for tasks ranging from filtering large read sets (e.g. to
check for contaminants or the presence or absence of specific tar—
gets) to more mundane tasks like quality control and, perhaps, even
to related tasks like metagenomic and metatranscriptomic classifica—
tion and abundance estimation.

We hope that the quasi—mapping concept, and the availability of
RapMap and the efficient and accurate mapping algorithms it ex—
poses, will encourage the community to explore replacing alignment
with mapping in the numerous scenarios where traditional align—
ment information is unnecessary for downstream analysis.

Acknowledgements

The authors thank Geet Duggal, Richard Smith-Unna and Owen Dando for
useful discussions regarding various aspects of this work. The authors also
thank the anonymous reviewers whose comments improved the manuscript
and exposition.

Funding

This work was supported by start up funds from Stony Brook University
to RP.

ﬁm'srcumofpquo'sopcuuopnorq/ﬁdnq

i200

A.Srivastava et al.

 

Conﬂict of Interest: Home declared.

References

Bray,N.L. et al. (2016) Near-optimal probabilistic RNA-seq quantiﬁcation.
Nature Biotech., 34(5), 525—527.

Cho,H. et al. (2014) High-resolution transcriptome analysis with long-read
RNA sequencing. PLoS ONE, 9, e108095.

Cunningham,F. et al. (2015) Ensembl 2015. Nucleic Acids Res., 43,
D662—D669.

Davidson,N.M. and Oshlack,A. (2014) Corset: enabling differential gene ex-
pression analysis for de novo assembled transcriptomes. Genome Biol., 15,
410.

Dobin,A. et al. (2013) Star: ultrafast universal RNA-seq aligner.
Bioinformatics, 29, 15—21.

Fu,L. et al. (2012) Cd-hit: accelerated for clustering the next-generation
sequencing data. Bioinformatics, 28, 3150—3152.

Gilbert,C. et al. (2004) Elongator interactions with nascent mrna revealed by
RNA immunoprecipitation. Mol. Cell, 14, 457—464.

Grabherr,M.G. et al. (2011) Full-length transcriptome assembly from rna-seq
data Without a reference genome. Nat. Biotechnol., 29, 644—652.

Griebel,T. et al. (2012) Modelling and simulating generic rna-seq experiments
with the flux simulator. Nucleic Acids Res., 40, 10073—10083.

Gusﬁeld,D. (1997). Algorithms on Strings, Trees, and Sequences: Computer
Science and Computational Biology. Cambridge University Press, New
York, NY, USA.

Hach,F. et al. (2010) mrsfast: a cache-oblivious algorithm for short-read map-
ping. Nat. Methods, 7, 576—577.

Ilie,L. et al. (2010) The longest common extension problem revisited and ap-
plications to approximate string searching.  Discrete Algorithms, 8,
418—428.

Kent,W.]. (2002) Blat—the blast—like alignment tool. Genome Res., 12,
65 6—664.

Kim,D. et al. (2015) Hisat: a fast spliced aligner with low memory require-
ments. Nat. Methods, 12, 357—3 60.

Koster,]. and Rahmann,S. (2012) Building and documenting workﬂows with
python-based snakemake. GCB, 26, 49—56.

Langmead,B. and Salzberg,S.L. (2012) Fast gapped-read alignment with
Bowtie 2. Nat. Methods, 9, 357—359.

Langmead,B. et al. (2009) Ultrafast and memory-efﬁcient alignment of short
DNA sequences to the human genome. Genome Biol., 10, R25.

Lappalainen,T. et al. (2013) Transcriptome and genome sequencing uncovers
functional variation in humans. Nature, 501, 506—51 1.

Li,B. and Dewey,C. N. (2011) RSEM: accurate transcript quantiﬁcation from
RNA-seq data with or without a reference genome. BMC Bioinformatics,
12, 323.

Li,H. and Durbin,R. (2009) Fast and accurate short read alignment with bur—
rows—wheeler transform. Bioinformatics, 25, 1754—1760.

Li,H. et al. (2008) Mapping short dna sequencing reads and calling variants
using mapping quality scores. Genome Res., 18, 1851—1858.

Li,B. et al. (2010) RNA-seq gene expression estimation with read mapping un-
certainty. Bioinformatics, 26, 493—500.

Li,H. (2013). Aligning sequence reads, clone sequences and assembly contigs
with BWA-MEM.

Liao,Y. et al. (2013) The Subread aligner: fast, accurate and scalable read
mapping by seed-and-vote. Nucleic Acids Res., 41, e108.

Lovell,D. et al. (2015) Proportionality: a valid alternative to correlation for
relative data. PLoS Comput. Biol., 11, e1004075.

Manber,U. and Myers,G. (1993) Sufﬁx arrays: a new method for on-line string
searches. SIAM]. Comput., 22, 935—948.

Marcais,G. and Kingsford,C. (2011) A fast, lock-free approach for efﬁcient
parallel counting of occurrences of k-mers. Bioinformatics, 27, 764—770.

Nariai,N. et al. (2013) Tigar: transcript isoform abundance estimation method
with gapped alignment of RNA-Seq data by variational Bayesian inference.
Bioinformatics, 29, 2292—2299.

Nariai,N. et al. (2014) Tigar2: sensitive and accurate estimation of transcript
isoform expression with longer RNA-Seq reads. BMC Genomics, 15, S5.

Nicolae,M. et al. (2011) Estimation of alternative splicing isoform frequencies
from rna-seq data. Algorithms Mol. Biol., 6, 9.

Nookaew,I. et al. (2012) A comprehensive comparison of RNA-Seq-based
transcriptome analysis from reads to differential gene expression and cross-
comparison with microarrays: a case study in saccharomyces cerevisiae.
Nucleic Acids Res., 40, 10084—10097.

Patro,R. et al. (2014) Sailﬁsh enables alignment-free isoform quantiﬁcation
from RNA-Seq reads using lightweight algorithms. Nat. Biotechnol., 32,
462—464.

Patro,R. et al. (2015) Salmon: accurate, versatile and ultrafast quantiﬁcation
from RNA-Seq data using lightweight-alignment. bioinU, 9, 021592.

Trapnell,C. et al. (2013) Differential analysis of gene regulation at transcript
resolution with RNA-Seq. Nat. Biotechnol., 3 1, 46—53.

Van Dongen,S. (2000) A cluster algorithm for graphs. Rep. Inf. Syst., 10,
1—40.

Vigna,S. (2008) Broadword implementation of rank/select queries. In:
Experimental Algorithms. Springer, Berlin Heidelberg, pp. 154—168.

Zhang,Z. and Wang,W. (2014) RNA-skim: a rapid method for RNA-Seq
quantiﬁcation at transcript level. Bioinformatics, 30, i283—i292.

ﬁm'srcumofpquo'sopcuuopuorq/ﬁdnq

