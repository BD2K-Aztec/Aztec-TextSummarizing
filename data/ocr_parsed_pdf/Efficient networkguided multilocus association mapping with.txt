BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

genel

gene2

genel

:39\Ewowsmoaﬁmowoxmoagoﬁsambwﬁ

Network-guided muIti-Iocus mapping

 

SNP is selected and 0 otherwise, the score of the selected SNPs is given by
or» = 22:] carp = H;

We want to ﬁnd the indicator vector f that maximizes Qm while
ensuring that the solution is made of connected components of the
SNP network. However, in general, it is difﬁcult to find a subset of
SNPs that satisfies the above two properties. Given a positive integer k,
the problem of ﬁnding a connected subgraph with k vertices that maxi-
mize the sum of the weights on the vertices, which is equivalent to Qm of
our case, is known to be a strongly NP-complete problem (Lee and
Dooly, 1996). Therefore, this problem is often addressed based on enu-
meration-based algorithms, whose runtime grows exponentially with k.
To cope with this problem, we consider an approach based on a graph-
regularization scheme, which allows us to drastically reduce the runtime.

2.2 Feature selection with graph regularization

Rather than searching through all subgraphs of a given network, we
reward the selection of adjacent features through graph regularization.
As it is also desirable for biological interpretation, and to avoid selecting
large numbers of SNPs in linkage disequilibrium, that the selected sub-
networks are small in size, we reward sparse solutions. The ﬁrst require-
ment can be addressed by means of a smoothness regularizer on the
network (Ando and Zhang, 2007; Smola and Kondor, 2003), whereas
the second one can be enforced with an lo constraint:
T T
afregmnia’x ii — Af Lf — 171 m 10 (1)
association connectivity Sparshy
where L is the Laplacian of the SNP network. L is deﬁned as
L = D — W, where D is the diagonal matrix where DH, is the degree
of node p. Here, we directly minimize the number of nonzero entries in
f and do not require the proxy of an I, constraint to achieve sparsity (of
course in the case of binary indicators, II and lo norms are equivalent).
Positive parameters A and 17 control the importance of the connectedness
of selected features and the sparsity regularizer, respectively.

As WW, 2 1 if q is a neighbor ofp (also written as p ~ q), and 0
otherwise, if we denote by N(p) the neighborhood of p, then the degree
of p can be rewritten DH, 2 Egg/(p) 1. The second term in Equation (1)
can therefore be rewritten as

{TL}: 20; —fq)2, (2)

IV"!

and the problem in Equation (1) is equivalent to

’1
arg min 2M9, — n) — A Z 0;, —f,)2. (3)
fei0.1}” 1):] M
As (fp —f,,)2 is 1 if fp yéfq and 0 otherwise, it can be seen that the
connectivity term in Equation (1) penalizes the selection of SNPs not
connected to one another, as well as the selection of only subnetworks
of connected components of the SNP network. It does not prohibit the
selection of several disconnected subnetworks. In particular, solutions
may include individual SNPs fully disconnected from the other selected
SNPs. Also, as l V110: llfin our case, the sparsity term in Equation (1) is
equivalent to reducing the individual SNP scores c by a constant n>0.

2.3 Min-Cut solution

A cut on a weighted graph over vertices V 2: {1, . . . , n} is a partition of V
in a nonempty set S and its complementary V\ S. The cut-set of the cut is
the set of edges whose end vertices belong to different sets of the partition.
The minimum cut of the graph is the cut such that the sum of the weights
of the edges belonging to its cut-set is minimum. If A is the
adjacency matrix of the graph, ﬁnding the minimum cut is equivalent
to ﬁnding S C V that minimizes the cut-function

ZSZWSAM 2 22:12:21 fp(1 —fq)Ap.q wherefp is 1 ifp e S and 0
[)6

77 _ Cp
(ifli>cp)

    
  
 
 

source (3) sink (t)

  
 
 

/
Cp—T]
mn>m

\

’ /
~ — — — ’ original graph

Fig. 2. Graph for the s/ t-min-cut formulation of the selection of net-
works of genetic markers

otherwise. Given two vertices s and t, an s/t-cut is a cut such that s e S
and t e V\ S. According to the max-ﬂow min-cut theorem
(Papadimitriou and Steiglitz, 1982), a minimum s/t-cut can be efﬁciently
computed with the maximum ﬂow algorithm (Goldberg and Tarjan,
1988).

PROPOSITION 1. Given a graph g of adjacency matrix W, solving
the graph—regularized feature selection problem formalized in
Equation (1) is equivalent to ﬁnding an s/t min—cut on the graph,
depicted in Figure 2, whose vertices are that of g , augmented by two
additional nodes s and t, and whose edges are given by the adjacency
matrix A, where AW] 2 AWp‘q for 13p,q§n and

_ Cp_77 ifcp>77 _ 77—617 ifcp<77
A” _ l 0 otherwise and/1"” _ l 0 otherwise
(p = l, . . . , 
PROOF. The problem in Equation (1) is equivalent to
arg min (1711" — €)Tf+ l»fo (4)

fe(0.1}”

The second term of the objective is a cut—function over g:

n

fTLfZ  (D111) _ Z Wart/:1) =  Wr~vllr(1_fq)-
1):] 41:1 1):] 41:1
The first term can also be encoded as a cut—function by intro—
ducing to artificial nodes s and t:

207 — corp = 2m — c,» + 207 — c,» — 2m — c,»
p=1 peS pei/ MES

tﬂ<n L112” L113”
= ZA.V.,J.(1—f,.)+ Z Ap.n(1—L)+ C
1):] 1):]

where C = Zpemﬂzn (n — cp) is a constant, f, = 1, f, = 0 and A is
deﬁned as aforementioned. As f, = 1 and f, = 0 enforce that s e S and
tgéS, it follows that Equation (1) is an s/t min-cut problem on the trans-
formed graph deﬁned by the adjacency matrix A over the vertices of g
augmented by s and t. The aforementioned still holds if W is a weighted
adjacency matrix, and therefore the min-cut reformulation can also be
applied to a weighted network. I

It is therefore possible to use maximal ﬂow algorithms to ef—
ﬁciently optimize the objective function deﬁned in Equation (1)
and select a small number of connected SNPs maximally asso—
ciated with a phenotype. In our implementation, we use the
BoykoviKolmogorov algorithm (Boykov and Kolmogorov,
2004). Although its worst case complexity is in (9(n2nEnC),
where 115 is the number of edges of the graph and nC the size
of the minimum cut, it performs much better in practice, particu—
larly when the graph is sparse. We refer to this method as
SConES, for Selecting CONnected Explanatory SNPs.

 

i173

ﬁm'spzumol‘pmjxo'soptzuuopuorq/ﬁdnq

C. -A.Azencott et al.

 

3 RESULTS

We evaluate the ability of SConES to detect networks of trait—
associated SNPs on simulated datasets and on datasets from an
association mapping study in A.thaliana.

3.1 Experimental settings

For all of our experiments, we consider the three SNP networks
deﬁned in Section 1: the GS network, the GM network and the
GI network. For SConES, the association term c is derived from
Linear SKAT (Wu et al., 2011), which makes it possible to cor—
rect for covariates (and therefore population structure). SKAT
has been devised to address rare variants association problems
by grouping SNPs to achieve statistical signiﬁcance, but it can
equally be applied to common variants.

Univariate linear regression: As a baseline for comparisons, we
run a linear regression—based single—SNP search for association
and select those SNPs that are signiﬁcantly associated with the
phenotype (Bonferroni—corrected P—value g 0.05).

Linear mixed model: Similarly, we run a linear mixed model
(LMM) single—SNP search for association (Lippert et al., 2011)
and select those SNPs that are signiﬁcantly associated with the
phenotype (Bonferroni—corrected P—value g 0.05).

Lasso: To compare SConES to a method that also considers
all additive effects of SNPs simultaneously with a sparsity con—
straint, but without any network regularization, we also run a
Lasso regression (Tibshirani, 1994), using the SLEP implemen—
tation (http://www.public.asu.edu/~jye02/Software/SLEP) of
the Lasso.

ncLasso: In addition, we compare SConES to the network—
constrained Lasso ncLasso (Li and Li, 2008), a version of the
Lasso with sparsity and graph—smoothing constraints equivalent
to that of SConES. Given a genotype matrix G and a phenotype
r, ncLasso solves the following relaxed problem (f 6 IR"):

argmminélle— r||:+AfTLf+ 17Hle (5)
The solution for ncLasso proposed by Li and Li (2008) re—
quires to compute and store a single value decomposition of L
and is therefore not applicable when its sizes exceeds
100000 >< 100000 by far. However, a similar solution can be
obtained by decomposing L as the product of the network’s in—
cidence matrix with its transpose, an approach that is much
faster (particularly when the network is sparse).
groupLasso and graphLasso: Eventually, we also compare our
method to the nonoverlapping group Lasso (Jacob et al., 2009).
The nonoverlapping group Lasso solves the following relaxed
problem:

. 1 2
argmlnEIIGf— r||2+AZHfg||2 (6)
few geg
where g is a set of (possibly overlapping) predeﬁned groups of
SNPs. We consider the following two versions:

0 graphLasso, for which the groups are directly defined from
the same networks as considered for SConES as all pairs of
vertices connected by an edge;

0 groupLasso, for which the groups are deﬁned sensibly as
follows:

0 GS groups: pairs of adjacent SNPs (this gives raise to the
same groups as for graphLasso with the sequence
network);

0 GM groups: SNPs near the same gene;

0 GI groups: SNPs near either member of two interacting
genes. Here, SNPs near genes that are not in the inter—
action network get grouped by gene.

We use the SLEP implementation of the nonoverlapping
group Lasso, combined with the trick described by Jacob et al.
(2009) to compute the overlapping group Lasso by replicating
features in nonoverlapping groups.

Setting the parameters: All methods considered, except for the
univariate linear regression, have parameters (e. g. A and n in the
case of SConES) that need to be optimized. In our experiments,
we run 10—fold cross—validation grid—search experiments over
ranges of values of the parameters: seven values of A and 17 each
for SConES and ncLasso and seven values of the parameter A for
the Lasso and the nonoverlapping group Lasso (ranging from
10’3 to 103). We then pick as optimal the parameters leading to
the most stable selection and report as ﬁnally selected the features
selected in all folds. More speciﬁcally, we deﬁne stability accord—
ing to a consistency index similar to that of Kuncheva (2007). The
consistency index between two feature sets S and S’ is deﬁned as
[C(S, S/) =  (Details can be found in the
Supplementary Materials). For an experiment with k folds, the
consistency is computed as the average of the k(k — 1)/ 2 pairwise
consistencies between the sets of features selected over each fold.

3.2 Runtime

We ﬁrst compare the CPU runtime of SConES with that of the
linear regression, ncLasso and graphLasso. To assess the perform—
ance of our methods, we simulate from 100 to 200 000 SNPs for
200 individuals and generate exponential random networks with a
density of 2% (chosen as an upper limit on the density of currently
available gene—gene interaction networks) between those SNPs.

We report the real CPU runtime of one cross—validation, for
set parameters, over a single AMD Opteron CPU (2048 KB,
2600 MHz) with 512 GB of memory, running Ubuntu 12.04
(Fig. 3). Across a wide range of numbers of SNPs, SConES is
at least two orders of magnitude faster than graphLasso and one
order of magnitude faster than ncLasso.

3.3 Simulations

To assess the performance of our methods, we simulate pheno—
types for m=500 real A.thaliana genotypes (214051 SNPs),
chosen at random among those made available by Horton
et al. (2012), and the A.thaliana proteiniprotein interaction in—
formation from The Arabidopsis Internet Resource (TAIR,
http: //www.arabidopsis.org/portals/proteome/proteinInteractj sp,
resulting in 55 584646 SNPiSNP connections). We use a
window size of 20 000 bp to deﬁne proximity of a SNP to a
gene, in accordance with the threshold used for the interpret—
ation of GWAS results in Atwell et al. (2010). Restricting our—
selves to 1000 randomly chosen SNPs with minor allele

 

i174

ﬁm'spzumol‘pmjxo'soptzuuopuorq/ﬁdnq

9 re phLasso

ncLassc

ncLassc (accelerated)
SConES

linear regression

graphLasso

ncLasso

ncLasso (accelerated)
SConES

linear regression

 

/3.10's112um0fp10}x0'sopBuiJOJurorq”:duq

Gcncrmcmbcrship network

Genermemhership network

0 SConES

n 11.1] 11,-! im ll..\‘ 1,11
FDR

Generintcraction network

V - O scrum.

3 11.1 m.
FDR

Generinteraction netwn

V gmphLassu O sauna;

ii? 11.1 w} 118‘ 1,1!
FDR

nerinteraction network

 

/3.10's112um0fp10}x0'sopBuiJOJurorq”:duq

an?kgogmomammowoio~&o:3m7.omm\

- ncLasso

05
mm
to
CC
2

:I gicupLasso

 

C. -A.Azencott et al.

 

Table 3. Summary statistics, averaged over the Arabidopsis thaliana
ﬂowering time phenotypes: average total number of selected SNPs (‘No
of SNPs’), average proportion of selected SNPs near candidate genes
(‘near candidate genes’) and average number of different candidate
genes recovered (‘candidate genes hit’)

 

 

Method No of Near Candidate
SNPs candidate genes hit
genes
Univariate 5 0.09 0.35
LMM 2 0.12 0.35
Lasso 86 0.09 3.82
groupLasso GS 153 0.10 4.35
groupLasso GM 611 0.09 1.35
groupLasso GI 546 0.20 2.65
ncLasso GS 684 0.04 4.88
ncLasso GM 608 0.06 4.59
ncLasso GI 608 0.06 4.59
SConES GS 729 0.18 11.53
SConES GM 546 0.08 14.82
SConES G1 496 0.07 12.24

 

In simulations, SConES is better at leveraging the structure of
the biological network to recover causal SNPs.

On real GWAS data from A.thaliana, the predictive ability of
the features selected by SConES is superior to that of
groupLasso on two of the three network types we consider.
When using more biological information (gene membership or
interactions), SConES tends to recover more distinct explanatory
genes than groupLasso, resulting in better phenotypic prediction.

The constraints imposed by groupLasso and SConES are dif—
ferent: although the groups given to groupLasso and the net—
works passed to SConES come from the same information, the
groups force many more SNPs to be selected simultaneously
when they may not bring much more information. This gives
SConES more ﬂexibility and makes it less vulnerable to ill—deﬁned
groups or networks, which is especially desirable in the light of the
current noisiness and incompleteness of biological networks. Our
results on the GS network actually indicate that graphLasso,
using pairs of network edges as groups, may achieve the same
ﬂexibility as SConES; unfortunately, it is too computationally
demanding to be run on the most informative networks.

We currently derive the SNP networks from neighborhood
along the genome sequence, closeness to a same gene or proxim—
ity to interacting proteins. Reﬁning those networks and explor—
ing other types of networks as well as understanding the effects
of their topology and density is one of our next projects.

Although we do not explicitly consider linkage disequilibrium,
the [0 sparsity constraint of SConES should enforce that when
several correlated SNPs are associated with a phenotype, a single
one of them is picked. On the other hand, if SConES is given a
GS network such as the one we describe, the graph smoothness
constraint will encourage nearby SNPs to be selected together,
leading to the selection of subsequences that are likely to be
haplotype blocks. Such a network should therefore only be
used when the goal of the experiment is to detect consecutive
sequences of associated SNPs.

For now, SConES considers an additive model between
genetic loci. Future work includes taking pairwise multiplicative
effects into account. Replacing the association term in Equation
(1) by a sum over pairs of SNPs rather than over individual SNPs
results in a maximum ﬂow problem over a fully connected net—
work of SNPs, which cannot be solved straightforwardly, if only
because the resulting adjacency matrix is too large to ﬁt in
memory on a regular computer. It might be possible, however,
to leverage some of the techniques used for two—locus GWAS
(Achlioptas et al., 2011; Kam—Thong et al., 2012) to help solve
this problem.

Extensions of SConES to other models include the use of
mixed models to account for population structure and other
confounders. This is currently a challenge, as it is unclear how
to derive additive test statistics from such models.

An interesting extension to study would replace the Laplacian
by a random—walk—based matrix, derived from powers of the
adjacency matrix, so as to treat disconnected SNPs that are
close—by in the networks differently from those that are far
apart. Although we already observe that SConES is robust to
edge removal, this would likely make it more resistant to missing
edges.

Another important extension of SConES is to devise a way to
evaluate the statistical signiﬁcance of the set of selected SNPs.
Regularized feature selection approaches such as SConES or its
Lasso comparison partners do not lend themselves well to the
computation of P—values. Permutation tests could be an option,
but the number of permutations to run is difficult to evaluate as
is that of hypotheses tested. Another possibility would be to im—
plement the multiple—sample splitting approach proposed by
Meinshausen et al. (2009). However, the loss of power from per—
forming selection on only subsets of the samples is too large,
given the sizes of current genomic datasets, to make this feasible.
Therefore, evaluating statistical significance and controlling
FDRs of Lasso and SConES approaches alike remain a chal—
lenge for the future.

Finally, further exciting research topics include applying
SConES to larger datasets from human disease consortia (we
estimate it would require less than a day to run on a million of
SNPs) and extending it to the detection of shared networks of
markers between multiple phenotypes.

ACKNOWLEDGEMENTS

The authors thank Recep Colak, Barbara Rakitsch and Nino
Shervashidze for fruitful discussions.

Funding: CA. is funded by an Alexander von Humboldt fellow—
ship. This work was partially funded by the DFG project Kernels
for Large, Labeled Graphs (LaLa).

Conﬂict of Interest: none declared.

REFERENCES

Achlioptas,P. et al. (2011) Two—Locus Association Mapping In Sabqaadratic Time.
KDD '11. ACM, New York, NY, USA, pp. 72(r734.

Ando,R.K. and Zhang,T. (2007) Learning on graph with Laplacian regularization.
In: Scholkopf,B. and Hoffman,T. (eds) Advances in Neural Information
Processing Systems 19.

 

i178

ﬁm'spzumol‘pmjxo'sopeuHOJHrorq/ﬁdnq

Network-guided muIti-Iocus mapping

 

Atwell,S. et al. (2010) Genome—wide association study of 107 phenotypes in
Arabidopsis thaliana inbred lines Nature, 465, 627431.

Boykov,Y. and Kolmogorov,V. (2004) An experimental comparison of min—cut/
max—ﬂow algorithms for energy minimization in vision. IEEE T. Pattern
Anal, 26, 112441137.

Cantor,R.M. et al. (2010) Prioritizing GWAS results: a review of statistical methods
and recommendations for their application. Am. J. Hum. Genet., 86, (#22.
Cho,S. et al. (2010) Joint identiﬁcation of multiple genetic variants via elastic—net
variable selection in a genome—wide association analysis. Ann. Hum. Genet., 74,

41(r428.

Chuang,H.Y. et al. (2007) Network—based classiﬁcation of breast cancer metastasis.
Mol. Syst. Biol., 3, 140.

Fridley,B.L. and Biernacka,J.M. (2011) Gene set analysis of SNP data: beneﬁts,
challenges, and future directions. Eur. J. Hum. Genet., 19, 8377843.

Goldberg,A.V. and Tarjan,R.E. (1988) A new approach to the maximum—ﬂow
problem. J. ACM, 35, 9217940.

Gretton,A. et al. (2005) Measuring statistical dependence with Hilbert—Schmidt
norms. In: Sanjay,J. et al. (eds) Algorithmic Learning Theory, 16th
International Conference, ALT 2005, Singapore, October 8—11, 2005,
Proceedings. Lecture Notes in Computer Science 3734 Springer 2005. ALT.
Springer—Verlag, pp. 63777.

Henderson,C.R. (1975) Best linear unbiased estimation and prediction under a
selection model. Biometrics, 31, 423447.

Horton,M.W. et al. (2012) Genome—wide patterns of genetic variation in worldwide
Arabidopsis thaliana accessions from the RegMap panel. Nat. Genet., 44,
2127216.

Huang,J. et al. (2009) Learning with Structured Sparsity. In: Andrea,P.D. et al. (eds)
Proceedings of the 26th Annual International Conference on Machine Learning,
ICML 2009, Montreal, Quebec, Canada, June 14—18, 2009. ACM, New York,
NY, USA, pp. 417424.

J acob,L. et al. (2009) Group Lasso with Overlap and Graph Lasso. In: Andrea,P.D.
et al. (eds) Proceedings of the 26th Annual International Conference on Machine
Learning, ICML 2009, Montreal, Quebec, Canada, June 14—18, 2009. ACM, New
York, NY, USA, pp. 433440.

J ie,B. et al. (2012) Structural feature selection for connectivity network—based MCI
diagnosis. In: Yap,P.T. et al. (ed.) M ultimodal Brain Image Analysis, Volume 7509
of Lecture Notes in Computer Science. Springer, Berlin/Heidelberg, pp. 1757184.

Kam—Thong,T. et al. (2012) GLIDE: GPU—based linear regression for detection of
epistasis. Hum. Hered., 73, 2207236.

Kuncheva,L.I. (2007) A stability index for feature selection. In: Vladan,D. (ed.)
Proceedings of the 25th IAS TED International M ulti—Conference: artificial intel—
ligence and applications. IASTED/ACTA Press, Innsbruck, Austria.

Le Saux,B. and Bunke,H. (2005) Feature selection for graph—based image classiﬁers.
In: Marques]. et al. (ed.) Pattern Recognition and Image Analysis, Volume 3523
of Lecture Notes in Computer Science. Springer, Berlin/Heidelberg, pp. 1477154.

Lee,H.F. and Dooly,D.R. (1996) Algorithms for the constrained maximum—weight
connected graph problem. Nav. Res. Logist., 43, 98571008.

Li,C. and Li,H. (2008) Network—constrained regularization and variable selection
for analysis of genomic data. Bioinﬁ)rmatics, 24, 117571182.

Lippert,C. et al. (2011) FaST linear mixed models for genome—wide association
studies. Nat. Meth., 8, 8337835.

Liu,J. et al. (2012) Incorporating group correlations in genome—wide association
studies using smoothed group lasso. Biostatistics, 14, 2057219.

Mairal,J. and Yu,B. (2011) Path coding penalties for directed acyclic graphs. In:
Proceedings of the 4th NIPS Workshop on Optimization for Machine Learning
(0PT'II).

Manolio,T.A. et al. (2009) Finding the missing heritability of complex diseases.
Nature, 461, 7477753.

Marchini,J. et al. (2005) Genome—wide strategies for detecting multiple loci that
inﬂuence complex diseases. Nat. Genet., 37, 4137417.

Meinshausen,N. et al. (2009) P—values for high—dimensional regression. J. Am. Stat.
Assoc, 104, 167171681.

Nacu,$. et al. (2007) Gene expression network analysis and applications to immun—
ology. Bioiry’ormatics, 23, 85(F858.

Papadimitriou,C.H. and Steiglitz,K. (1982) Combinatorial Optimization: Algorithms
and Complexity. Prentice—Hall Inc, Englewood Cliffs, NJ, USA.

Price,A.L. et al. (2006) Principal components analysis corrects for stratiﬁcation in
genome—wide association studies. Nat. Genet., 38, 90¢909.

Rakitsch,B. et al. (2012) A lasso multi—marker mixed model for association mapping
with population structure correction. Bioiry’ormatics., 29, 20(r214.

Segura,V. et al. (2012) An efﬁcient multi—locus mixed—model approach for genome—
wide association studies in structured populations. Nat. Genet., 44, 8257830.
Smola,A. and Kondor,R. (2003) Kernels and regularization on graphs. In:
Scholkopf,B. and Warmuth,M. (eds) Learning Theory and Kernel Machines,
Volume 2777 of Lecture Notes in Computer Science. Springer, Berlin/

Heidelberg, pp. 144458.

Tibshirani,R. (1994) Regression shrinkage and selection via the lasso. J. R. Stat.
Soc. Series B, 58, 2677288.

Tsuda,K. (2011) Graph classiﬁcation methods in chemoinformatics. In: Lu,H.H.S.
et al. (ed.) Handbook of Statistical Bioinformatics, Springer Handbooks of
Computational Statistics. Springer, Berlin Heidelberg, pp. 3357351.

Wang,D. et al. (2011) Identifying QTLs and epistasis in structured plant popula—
tions using adaptive mixed lasso. J. Agric. Biol. Environ. Stat., 16, 17(%184.
Wu,M.C. et al. (2011) Rare—variant association testing for sequencing data with the

sequence kernel association test. Am. J. Hum. Genet., 89, 82793.

Zuk,O. et al. (2012) The mystery of missing heritability: Genetic interactions create

phantom heritability. Proc. Natl Acad. Sci. USA, 109, 119%1198.

 

i179

ﬁre'spzumol‘pmjxo'sopeuHOJHrorq/pdnq

