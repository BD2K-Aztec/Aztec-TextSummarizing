BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

CNV-guided multi-read allocation

 

To investigate the impact CNVs might have on multi—read
allocation, we extracted all the reads that align to exactly two
locations of the reference genome in a thf ChIP—seq sample
from GM12878 cells (such two locations are referred to as an
alignment pair from hereon). We found that for 15.2% of reads
that map two locations, the copy numbers of the alignment pairs
differed by at least one (Supplementary Fig. S1 and
Supplementary Table S1); and therefore, we expect the CNVs
to inform the multi—read allocation for such reads. Even for the
alignment pairs with the same copy number, CNVs may still
have an indirect impact by affecting the allocation of other
reads in the neighborhoods of these alignment locations. For
multi—reads with more than two alignments, the copy numbers
are more likely to vary among the alignment locations, and a
larger impact of CNV is expected.

In this article, we develop cnvCSEM (CNV—guided ChIP—Seq
by expectation—maximization algorithm), a ﬂexible framework
that guides multi—read allocation by CNVs. The cnvCSEM
takes advantage of the state—of—the—art multi—read allocation al—
gorithms and incorporates CNV information parsimoniously.
We use the fact that various array— and sequence—based CNV
detection algorithms have been developed (Abyzov et al., 2011;
Komura et al., 2006), and large consortia such as 1000 Genomes
(The 1000 Genomes Project Consortium, 2012) have produced
high—throughput sequencing data for CNV detection. Combining
these efforts, detecting CNV and estimating copy number with a
reasonable accuracy is possible. Our data—driven simulation re—
sults show that (i) cnvCSEM increases multi—read allocation
coverage and signiﬁcantly reduces allocation ambiguity in the
segmental duplication regions (SDR) with only a marginal loss
in accuracy, and (ii) cnvCSEM also improves the accuracy of the
read—depth recovery, especially in the highly repetitive regions
with low copy numbers. Our study of several ENCODE TF
ChIP—seq experiments demonstrate the biological relevance of
the cnvCSEM—allocated reads and the ChIP—seq peaks identiﬁed
in the downstream analysis.

2 METHODS

2.1 Preliminaries

We model the reads with the following generative model, which underlies
the CSEM algorithm (Chung, 2012). Let M be the total number of gen-
omic locations, and N be the total number of reads. For each read R,-,
1': l, . . . , N, we deﬁne Z,» = (Z1, . . . , ZiM) as the indicator of the origin of
R,-, i.e. Z) = 1 if the read R,- originates from location j in the genome, and
Z,-,~ = 0 otherwise. We model Z1, . . . , Z N as independent and identically
distributed samples from a multinomial distribution with parameter
vector 71:011. . . . , JIM). Multi-read allocation can be achieved in two
steps based on this model. The ﬁrst step is to estimate the posterior
distributions of Z1, . . . , Z N, which allocate the multi-reads fractionally.
Then, the most likely originating location of each read can be
determined based on its posterior. A natural way of estimating the pos-
teriors is by an expectation-maximization (EM) algorithm. The expect-
ation and the maximization steps of the CSEM have explicit form
solutions, so numerical optimization is not needed, and the computation
is fast. Specifically, for i=1, ...,N and j= l, . . . , M, we deﬁne
Hg: 1{R,» can be aligned to location j}, and let 71m = (71(1'), - - -, 7153? be
the estimate of 7'! at iteration t. Then, E- and M- steps for iteration
(t+ l) are as follows.

E-step: For a given read R,-, 1': l, . . . , M, the expectation of Z,-,~ is given
by the following equation:
(I)
1 JT- 
2‘.” l: M’ . (1)

’1' (r)
21:1 71* Hi"

M-step:

1 N
+1 2: +1
1(! )_N> 125; )I 

CSEM uses a smoothed EM (EMS) algorithm to enable information
sharing among the neighboring locations on the genome. Speciﬁcally, in
the EMS algorithm, it)” 1) in (2) denotes an initial estimate of 711- and, for
a preselected window size w, 7110”) is determined by smoothing no“)
over the (2w+ 1) bp window around j in a smoothing step (S-step) that

follows the M-step.

S-step:
j + w

1
(1+ 1) _ 2 : (1+ 1)
j 2w+ l k (3)
k=j71r

Although the EMS algorithm enjoys convergence to a local maximum
of the likelihood, its outcome signiﬁcantly depends on the initial esti-
mates, and there is no guarantee that it converges to the maximum like-
lihood estimator. This is especially true in our setting, where the model is
multimodal, and the parameter space is of a high dimension. Although
largely ignored in many applications of the EM algorithm in computa-
tional biology, appropriate initialization of the EM algorithm has been
recognized as an important issue and non-trivial problem in the practice
of ‘Big Data’ (Fayyad et al., 1998; Toutanova and Galley, 2011). CSEM
uses a uniform distribution as its starting conﬁguration, which ignores the
natural variation of ChIP-seq data. Our main contribution in this work is
a CNV-guided initialization scheme for the EMS algorithm. Given the
CNV estimates from the same cell/tissue types as the ChIP sample, this
initialization for the EMS algorithm encodes the natural genomic vari-
ation in ChIP-seq read density, and hence, it is more biologically relevant
than the initial uniform conﬁguration. Consequently, we expect the ﬁnal
estimate of the read density 7'! to be closer to the underlying true read
density.

2.2 cnvCSEM: a general pipeline for CNV-guided
multi-read allocation

We propose the following CNV-aware multi-read allocation framework:

(1) CNV detection and copy-number estimation in the cells that ChIP-
seq experiment is performed.

(2) Initial weight assignment: estimating the initial value, 71(0), so that it
adapts to the CNV of the sample.

(3) EMS algorithm as in (1)43) with the estimated 71(0) as the initial
value.

We estimate the initial value 71(0) non-parametrically as follows. We
ﬁrst run CSEM on the ChIP and the control data to be analyzed, and
also annotate the reference genome with copy numbers estimated either
from sequence- or array-based data. For each value X of the copy-number
estimates, we then calculate the average read-depth of all the genomic
locations with the same copy number. This step essentially aggregates
ChIP or input read counts across locations with the same estimated
copy number. Then, this average read depth is used as the initial
weight at all the locations with copy number X. As copy number is also
an estimated quantity, we truncate high copy numbers to achieve

 

2861

ﬁm'spzumol‘pmjxo'sopeuuopnorq/ﬁdnq

Q.Zhang and S.Kele§

 

robustness. Speciﬁcally, we set the copy numbers 3 4 to 4 for the appli-
cations presented in this article. Further details on the initialization pro-
cedure are provided in the Supplementary Materials, where we also
illustrate with a theoretical analysis and simulation studies that incorpor-
ating CNV information into initialization is sufﬁcient and the gain by
incorporating it into the actual likelihood and the update steps of the
EMS algorithm is expected to be negligible.

In many CNV datasets, only the break point positions of the CNV
regions, instead of the absolute copy numbers, are available. For ex-
ample, for the HepG2 cell line commonly used in the ENCODE project,
the highest resolution CNV information is available from an array-based
experiment, where the genome is segmented into ampliﬁcation regions,
normal regions and heterozygous and homozygous deletion regions. To
accommodate the use of CNV information for these cases, we assign
pseudo copy numbers to these regions. Speciﬁcally, we encode
0 = homozygous deletion, l = heterozygous deletion, 2 = normal and
3 = ampliﬁcation. The genomic regions that are not annotated with one
of these four categories are treated as being normal. We remark that the
numerical valued pseudo copy numbers of 0 and 1 do not necessarily
reﬂect the numerical order of the copy numbers. Although it is natural to
assign 2 to the normal copy-number regions, one may question the choice
of the values assigned to the other three classes. The estimated 71(0) is
invariant to the actual values of the (pseudo) copy numbers. This is be-
cause the elements of 71(0) are estimated from the regions with the same
copy number, and the estimation only depends on the break points of the
CNV regions, but not the actual numerical values of the (pseudo) copy
numbers.

Our strategy of estimating 71(0) is ﬂexible and does not rely on CSEM
or any other speciﬁc models or software. For example, one can use the
read depth of the uni-reads instead of the CSEM output for calculating
the aggregated read depth for initialization.

3 RESULTS

In this section, we compare the following three read allocation
strategies using data—driven simulations and actual ChIP—seq
experiments.

0 Uni: only uni—reads are kept, and all the multi—reads are
discarded.

o CSEM: in addition to the uni—reads, all the alignments of
multi—reads with a CSEM posterior probability 3 0.5 are
kept.

o cnvCSEM: in addition to the uni—reads, all the alignments of
multi—reads with a cnvCSEM posterior probability 3 0.5 are
kept.

Although keeping multi—read allocations with a posterior prob—
ability 30.5 reduces the number of multi—reads used, it facilitates
downstream analysis with commonly adapted ENCODE ChIP—
seq uniform analysis pipeline, which requires each read to map to
a single location on the reference genome (Landt et al., 2012).

Throughout this article, we used Bowtie aligner (Langmead
et (11., 2009). Speciﬁcally, multi—read allocation with CSEM and
cnvCSEM used reads with at most two mismatches and a max—
imum of 99 alignment locations. Reads with only one reported
alignment location are referred to as uni—reads.

3.1 Simulation-based evaluation

We conducted a simulation study to examine the impact of
CNVs on multi—read allocation, especially in the repetitive

regions. We first simulated short reads from a repetitive se—
quence—enriched segment of the human genome with synthetic
binding events and copy numbers, and then compared the three
read allocation methods (Uni, CSEM and cnvCSEM) in terms of
coverage, read allocation accuracy and the read—depth recovery.

We chose the segment chr22:21460001—21920000 of the human
genome for the simulation experiment. There are two pairs of
long repetitive regions that are similar to each other in this inter—
val based on the hg19 (build 37) segmental duplication database
of the human genome (Bailey et al., 2002). These pairs are
[21465673, 21548303], [21613746, 21695794] and [21727109,
21797378], [21846050, 21917116] and have percent sequence
identities of 90%. We artiﬁcially divided this segment into 11
regions and assigned them different copy numbers. We simulated
50 binding events with various binding strengths and the read
density that captured the synthetic binding signals and CNV in—
formation. We used a read length of 36 bp, as this is the typical
read length for the large collection of publicly available ChIP—seq
data. To address both the randomness of read sampling and the
variation in the ChIP read density, we generated 10 read densities
and simulated 10 samples from these densities resulting in 100
simulation replications. Each sample included 2000 simulated
reads. Supplementary Materials provide further details on the
speciﬁcs of this simulation study.

Figure 1 compares the three allocation methods in terms of
their coverage and allocation accuracy. We observe that on aver—
age 21.1% of the simulated reads are uni—reads. The allocation
accuracy of these uni—reads is on average 99.7%; however, the
coverage is low, with an average of only 422 reads of 2000 reads
across the simulation replications. In contrast, CSEM allocates
36.6% of the reads in the sense that each such read has a unique
alignment location with a posterior probability 3 0.5 and has an
average accuracy rate of 90.4%. Therefore, in addition to the
average of 422 uni—reads, it recovers on average 310 multi—reads,
a 73.4% increase at the cost of 9.3% loss in the overall accuracy.
Detailed analysis of the CSEM allocations reveals that, because
of the repetitiveness of the segment used in the simulation,
CSEM allocates on average 30.1% (613 of them) of the multi—
reads ambiguously in the sense that they are distributed to two
alignment locations with a posterior probability of 0.5 for each.
This is a direct consequence of two alignment locations with high
sequence similarity providing a small number of uni—reads to
CSEM to discriminate between them. In comparison,

 

 

 

(b)§ - —

0 ° :
i o _ -
z m

E
Ill
«+

3

n

6
0.95
.

/ of reads allocated uniquely
4U 50
.
o. . .. . [HIM]
Allocauon accuracy
090
.

oo

o

3
"/a nlamhlgunusly allncalad reads

 

 

 

 

 

 

 

 

 

I to .
a _ — a- a a.
—* _'_ o
O
E _ g , . .
HQ _ 0
8 o o o _ _._
O — l l V l l I I
Uni CSEM cnvCSEM Uni CSEM cnvCSEM CSEM cnvCSEM

Fig. 1. Simulation-based evaluations. (21) Percentage of reads that are
uniquely allocated; (b) accuracy rates of the allocations; (c) Percentage
of ambiguously allocated reads. Boxplots display the results over 100
simulation replications with 2000 reads each

 

2862

ﬁm'spzumol‘pmjxo'sopeuuopnorq/ﬁdnq

CNV-guided multi-read allocation

 

 

0.8 0.9
I I
oo 00

l

0.7
o
o

Read—depth recovery loss
0
O a) (X)
0 00¢?

l

 

 

 

 

| I |
Uni CSEM cnvCSEM
Fig. 2. Simulation-based evaluation. Read-depth recovery loss of Uni,

CSEM and cnvCSEM read allocation methods

cnvCSEM allocates 67% of the reads uniquely (on average 918
multi—reads and 422 uni—reads) with an average accuracy rate of
88%. Therefore, by incorporating CNV information in multi—
read allocation, we increase the coverage by another 83.1%
with a small loss of 2.4% in accuracy.

We next compared the read—depth recovery by the three allo—
cation methods. We treated the true and the recovered (esti—
mated) read—depth curves as probability densities and measured
the distance between them by the total variation distance of the
probability measures (see Section 5.7 of the Supplementary
Materials for details). Figure 2 illustrates that both CSEM and
cnvCSEM perform better than Uni, and the distance between the
true and the estimated read densities for cnvCSEM is also smal—
ler than that of CSEM.

Figure 3 displays a typical example of the true and recovered
read—depth curves. We observe that Uni completely misses the
signals in the repetitive regions. Although CSEM successfully
recovers some of the signal patterns in the repetitive regions,
especially in the regions with high copy numbers, it leads to
false—positive results in the repetitive regions with low copy num—
bers. Finally, cnvCSEM shifts the reads from the regions with
low copy numbers to those with high copy numbers, removes
most of the false—positive results in the repetitive regions with low
copy numbers, and also refines the read density estimates in the
regions with high copy numbers.

3.2 Evaluation on multiple ENCODE datasets

In this section, we analyzed several ChIP—seq samples along with
their control samples in GM12878 (thf, Atf3, Gabpa, Pol2),
GM12891 (Pax5, Pou2, Pul, P012) and HepG2 (thf) cells
from the ENCODE project. For GM12878 and GM12891 sam—
ples, high—coverage aligned sequence data measuring CNV were
available from the 1000 Genomes Project (The 1000 Genomes
Project Consortium, 2012). We used CNVNator (Abyzov et al.,
2011) to estimate copy numbers in these samples. For HepG2, we
used the array—based categorical CNV result provided by the
ENCODE project (GEO accession ID: GSM999286). We com—
pared the three read allocation methods in terms of their conse—
quences and biological implications in peak calling, and we

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

O-

Mllll Illlllllll I III I III
e“ 0— [III | || |
(b) °°' _

> _ _

a *- — _—
o_ — _
o
.0

($35“:

395- ||II II

m o" llIII III II III IIIII

(d) :8-

 II I 11
o: JIII III “.1. Id ll|||||

@258"

a- _

ﬁg:
o-—
'0-

We“.

TE

.E§m_ l L

3 o_  .....a.I.J..... I . . L...I.II.IIL....I.....
In

(905% _


o-—
'0-
(h)5%r_l
8% L
>ﬁ-n—
5‘“ o- Armand..." | I I L “1 I

 

 

0e+00 1 e105 2e+05 3e+05 4e+05
Genome coordinate

Fig. 3. Simulation-based evaluation: comparison of read-depth estimates
of Uni, CSEM and cnvCSEM. (21) Simulated binding signal; (b) simulated
CNVs; (c) convolution of the binding signal and CNV information; (d)
true read depth; (e) simulated sample read depth; (f) read-depth estimates
by Uni; (g) read-depth estimates by CSEM; (h) read-depth estimates by
cnvCSEM; (i) segmental duplication annotation, where the two solid lines
and the two dashed lines represent the two pairs of regions with high
sequence similarity

focused most of our attention to the comparison of CSEM
and cnvCSEM. For peak calling, we used ENCODE’s uniform
ChIP—seq processing pipeline (Landt et al., 2012), where SPP
(Kharchenko et al., 2008) is used for calling the peaks, and the
irreducible discovery rate (IDR) (Li et al., 2011) is used for
determining the optimal numbers of peaks for further down—
stream analysis.

3.2.1 cnvCSEM tends to allocate more reads to the regions with
high copy numbers: an essential change that the CN V information
brings to multi—read allocation As discussed in Section 1, CNV
has a direct effect on read densities of sequencing data. Assuming
there is no binding signal and all the reads can be aligned
uniquely to their true origins, the read depth should be roughly
proportional to the copy number in the region, and conse—
quently, it should be 0 in the regions with a copy number of 0.
However, in practice, observed read depths are far from this ideal
scenario because of sequencing errors and sequence repetitive—
ness in ChIP—seq and other high—throughput experiments. This
phenomenon is more prevalent in the SDR, where the sequence
is repetitive, and a much higher portion of reads are multi—reads
compared with other regions (non—SDR). We also remark that
we do not expect CNV and the ChIP—seq read—depths to match
perfectly because of potential associations between the binding
events (i.e. peaks) and CNV (see Section 3 in Supplementary

 

2863

/3.IO'S[BIIm0[p.IOJXO'SOIJBIIIJOJIIIOIq/ﬂdnq

Q.Zhang and S.Kele§

 

Materials for more discussion). Nonetheless, a level of consist—
ency between the ChIP—seq read depth and the copy number is
expected.

We ﬁrst analyzed thf ChIP—seq data from GM12878 cells
with the three allocation methods. Table 1 displays the average
read depth of the regions with the same copy number (0, 1, 2, 3
and 3 4) and the segmental duplication status (SDR/non—SDR).
For the non—SDR, the average read depths of Uni, CSEM and
cnvCSEM are all roughly proportional to the copy numbers, at
least at the lower end. Both CSEM and cnvCSEM have higher
read depths, especially in the regions with high copy numbers,
compared with the uni—reads allocation. In contrast, for SDR,
Uni read depth is much lower and is inconsistent with CNV.
Hence, the uni—read counts in SDR are not sufﬁcient in charac—
terizing the local read density and guiding multi—read allocation.
As a result, CSEM allocates similar amounts of reads to the
regions with copy numbers 0 and 1, which is not consistent
with CNV. In comparison, cnvCSEM allocates much fewer
reads to the regions with copy number 0, thus is more consistent
with the copy numbers in these regions. In general, cnvCSEM
allocates fewer reads to the regions with low copy number and
more reads to regions with high copy numbers. We note that
inferences in SDR are generally much more difﬁcult than those
of non—SDR. Although CSEM and cnvCSEM do not perform as
well in SDR compared with non—SDR, their SDR coverages are
better than uni—read coverage (see Section 3 in Supplementary
Materials for more discussion).

Table 1 displays two results for multi—read allocation with
CSEM: the result with the default number of 200 iterations is
in the column titled CSEM, and the column CSEM1000 has the
output with 1000 iterations. We observe that the final estimates
from these two runs are close to each other, indicating that the
utilization of CNV information in the initialization is essential

Table 1. Average read-depth estimates for segmental duplication and
non-SDR

 

 

 

and can not be achieved by larger number of iterations in the
EMS algorithm.

3.2.2 cnvCSEM improves the consistency between ChIP—seq peaks
and CN V We next evaluated the three allocation strategies in
terms of their downstream effects on the identiﬁed peaks. Table 2
summarizes the deﬁnitions of the peak sets that we compared,
and Supplementary Table S2 tabulates the sizes of all the peak
sets compared in the rest of the article. For the GM12878 thf
dataset, we compared the three read allocation methods by com—
paring the set differences of the three peak lists (Table 3).
ENCODE’s uniform ChIP—seq processing pipeline calls two
lists of peaks: optimal as determined by a specific IDR
(ENCODE default of 0.02 for the presented analysis) threshold
and relaxed, which are super sets of the optimal peaks and in—
clude both high signal peaks and regions that do not show any
ChIP enrichment. We note that 99.5% of the Uni—only peaks are
captured in the extended lists of both CSEM and cnvCSEM;
however, only 38.4% of the Multi—common are identiﬁed in
the extended peak list of uni—reads. We included comparisons
with the relaxed peak sets to ensure that our results hold irre—
spective of the speciﬁc IDR threshold used for peak calling.
Table 3 reveals that Common peaks are rarely in the regions
with CNV. Comparison of the CSEM—only peaks with the
cnvCSEM—only peaks indicates that a much lower percentage
of the cnvCSEM—only peaks are in the regions with lower copy

Table 2. Deﬁnitions of the peak lists for comparison

 

Uni-only In the optimal list of Uni, but not in those of CSEM
and cnvCSEM
In the optimal list of CSEM, but not in those of Uni
and cnvCSEM
cnvCSEM-only In the optimal list of cnvCSEM, but not in those of
Uni and CSEM
Multi-common In the optimal lists of CSEM and cnvCSEM, but not
in that of Uni

CSEM-only

 

 

 

 

 

Common In all the three optimal lists of Uni, CSEM and

Copy number Uni CSEM cnvCSEM CSEM1000 CHVCSEM
SDR

Table 3. Comparison of GM12878 thf peak lists from Uni, CSEM and
0 0061 0'75 0'390 0'723 cnvCSEM allocation strategies
1 0.131 0.868 0.815 0.855
2 0.428 1.252 1.232 1.252
3 0.155 1.500 1.573 1.502 cnvCSEM- CSEM- Multi- Common
3 4 0.387 2.544 2.985 2.558 only only common

non-SDR Number of peaks 249 78 1845 40752

% of copy 41.4 47.4 15.6 0.2
0 0.002 0.006 0.006 0.006 IlutIlber>2
1 0.319 0.409 0.412 0.410 % of copy 3.6 18.0 7.0 0.3
2 0.985 1.050 1.050 1.050 number<2
3 1.528 2.169 2.172 2.169 % of copy 55.0 34.6 77.4 99.5
3 4 3.541 16.342 16.376 16.331 number = 2

Number of copy 1 3 8 5
Notes: The average read depth of the uni—reads (Uni), multi—reads allocated by CSEM number = 0
with 200 iterations (CSEM) and with 1000 iterations (CSEM1000) and multi—reads % in SDR 68.7 100 75.4 2.4

allocated by cnvCSEM (cnvCSEM) for GM12878 thf ChIP—seq dataset.

 

 

2864

ﬁm'spzumol‘pmjxo'sopauuopnorq/pdnq

:39\Ewowsmoaﬁmowoxmoagoﬁsambwﬁ

Q.Zhang and S.Kele§

 

Table 4. Percentage of peaks with the most signiﬁcant de now identiﬁed
motif

Table 5. Average read-depth estimates for segmental duplication and
non-SDR: thf ChIP-seq dataset from HepG2

 

Cell/factor cnvCSEM- CSEM- Multi- Uni-only Common-

 

only only common test
thf (1) 43.4 39.7 61.1 65.9 83.9
Atf3 (1) 12.3 7.1 17.2 37.4 51.2
Gabpa (1) 9.6 13.5 26.8 47.0 71.4
Pax5 (2) 23.6 22.6 27.2 19.9 27.6
Pou2 (2) 7.9 14.0 15.5 13.8 24.4
Pul (2) 63.8 64.6 74.6 67.4 74.6

 

Notes: (1) and (2) in the ﬁrst column denote GM12878 and GM12891 cells,
respectively

peaks. We observed a similar phenomenon for the P012 dataset
in the GM12878 cells. By incorporating the CNV information,
we identified two additional expressed genes with cnvCSEM—
only Pol2 peaks (POLR2J3 and AC006995.3 with transcripts
per million values of 94.53 and 70.39).

3.2.5 cnvCSEM and CSEM lead to similar percentages of peaks
with the binding motif We conducted de novo sequence analysis
to further evaluate the cnvCSEM—only and CSEM—only peaks
using the MEME Suite (Bailey et al., 2009). We identiﬁed the
most signiﬁcant binding motif with a de novo sequence analysis
of the top 500 Common peaks (using the sequences with—
in:|: 50 bp of the peak summits) using MEME. Then, we scanned
both the rest of the Common peaks (Common—test) and the other
peak sets from Table 2 (using the sequences within:|: 150 bp of
the peak summits). Overall, the motif occurrence percentages of
the cnvCSEM—only peaks are comparable with their CSEM—only
counterparts (Table 4).

3.2.6 CN V information with lower resolution is also
useful Although current state—of—the—art for proﬁling CNVs is
based on high—throughput sequencing assays, there are many
datasets for which CNV information is available only from
lower resolution array platforms. Using HepG2 cells, a cancer
cell line for which many ChIP—seq datasets and array—based CNV
information is available from the ENCODE project, we investi—
gated whether lower resolution CNV information can be used in
multi—read allocation. For HepG2 cells, the available CNV in—
formation is not the actual copy—number estimates along the
genome, but a classiﬁcation of the genome into the following
four categories: homozygous deletion (hom.del), heterozygous
deletion (het.del), normal and ampliﬁcation (amp). We assigned
pseudo copy numbers 0, 1, 2 and 3 to these regions, as described
in Section 2, and performed the analysis presented in Sections
3.2.1 and 3.2.2 for the thf ChIP—seq datasets from HepG2 cells.
Although the differences in the performances of CSEM and
cnvCSEM are smaller, the overall patterns are similar to those
we obtained with higher resolution CNV data (Tables 5 and 6).

4 DISCUSSION

In ChIP—seq experiments and other short—read sequencing experi—
ments, a signiﬁcant fraction of the reads map to multiple

SDR non-SDR

 

CNV Uni CSEM cnvCSEM Uni CSEM cnvCSEM

 

hom.del 0.000 0.333 0.038 0.047 0.103 0.099
het.del 0.532 2.546 2.466 1.449 1.689 1.688
normal 1.254 6.677 6.674 3.563 3.899 3.899
amp 1.591 10.063 10.199 5.959 6.388 6.388

 

Notes: The average read depths of the uni—reads (Uni), multi—reads allocated by
CSEM and multi—reads allocated by cnvCSEM.

Table 6. Comparison of HepG2 thf peak lists from uni-read, CSEM
and cnvCSEM allocation strategies

 

 

cnvCSEM- CSEM- Multi- Common
only only common
Number of 51 16 2903 53763
peaks
% of amp 19.6 0.0 12.0 13.2
% of deletion 2.0 25.0 4.1 2.7
% of normal 78.4 75.0 83.8 84.1
% in SDR 45.1 100 65.2 1.8

 

The deletion regions include both heterozygous and homozygous deletions. In all,
96.5% of the Uni—only peaks are captured in both the extended lists of CSEM and
cnvCSEM; however, only 44.1% of the Multi—common are identiﬁed in the ex—
tended peak list of uni—reads.

locations. Processing of multi—reads can impact the downstream
analysis of peak calling significantly. None of the currently avail—
able multi—read allocation methods take into account CNVs in
the sample genomes. We showed in this article that using CNV
provides additional information for discriminating mapping lo—
cations of a multi—read with similar uni—read counts. Our data—
driven simulations revealed significant improvements in multi—
read allocation accuracy and better read—depth recovery when
using CNV information. Analysis of multiple ENCODE datasets
indicated that peaks identiﬁable only when using copy—number
information in multi—read allocation have biologically meaning—
ful characteristics.

In our framework, we incorporated CNV in the initialization
of the EMS algorithm instead of explicitly including it in the
model because of the nature of the CNV information.
Intuitively, copy numbers should inﬂuence the elements of the
read density Jr as multipliers. If the copy numbers are already
encoded in 71(0) during the initialization step, their inﬂuence will
be preserved in the updates of the iterations, except at the loca—
tions around the break points of the CNV regions. However, the
typical numbers of break points are small. For GM12878 and
GM12891 experiments, CNVnator detects <5000 CNV regions,
and consequently <10000 break points. The array—based CNV
annotation of HepG2 includes <600 break points. Compared
with the length of the whole genome, this additional effect of

 

2866

ﬁm'spzumol‘pmjxo'sopauuopnorq/pdnq

CNV-guided multi-read allocation

 

CNV around the break points is rather small, especially if the
EMS algorithm is already appropriately initialized under the
guidance of CNV. In Supplementary Materials, we analytically
investigated our read model and showed how an EMS algorithm
can incorporate CNV in the updating steps. However, our cal—
culations and simulations suggest that the results from this math—
ematically more complicated model will not be notably different
from the cnvCSEM.

One curious question is how any given two regions with high
sequence similarity can have different CNV estimates, while the
uni—read counts in both regions are similarly low. We remark
that this is mainly due to the local uniqueness of the repetitive
regions and the high sequencing depths used for CNV estima—
tion. Repetitive regions such as segmental duplications are usu—
ally composed of alternating short stretches of unmappable
intervals (usually 3 200 bp), sequences of which are almost iden—
tical to some other genomic regions and the mappable intervals
with more sequence uniqueness. The median maximum run
length of unmappable bases across all the segmental duplications
in the hg19 segmental duplication database is 66bp. Overall,
only 14.7% of the segmental duplications have a maximum
unmappable run length >300 bp (data not shown). When the
read coverage is high or the reads are long, there will be sufﬁ—
ciently large numbers of uni—reads overlapping the mappable
intervals and differentiating regions with high sequence similar—
ity. The sequencing—based CNV datasets we used from the 1000
Genomes Project are deeply sequenced (total of 811 and 741
million aligned reads for GM12878 and GM12891, respectively)
and hence able to generate sufﬁciently large numbers of uni—
reads to differentiate regions with high sequence similarity. For
the array—based HepG2 CNV data, the median probe length is
about 1500 bp, much larger than the typical read lengths in
sequencing experiments. In contrast, typical ChIP—seq experi—
ments usually have only 1(L50 million aligned reads, and the
uni—read counts in the repetitive regions are usually too low to
differentiate the regions with similar sequences reliably.

In summary, our work can be viewed as part of the collective
effort in removing background variation in sequencing—based
genomic data analysis. Existing methods for ChIP—seq data ana—
lysis remove potential bias due to CNVs in peak calling (Rashid
et al., 2011) and differential epigenomic analysis (Robinson et al.,
2012). cnvCSEM incorporates CNVs at the level of alignment
and improves the accuracy of multi—read mapping for individual
datasets.

ACKNOWLEDGEMENTS

The authors thank Dr. Peng Liu in Keles’ group for help in
RNA—seq data.

Funding: This work was supported by National Institutes of
Health Grants (HG007019 and HG003747 to S.K.).

Conflict of Interest: none declared.

REFERENCES

Abyzov,A. et a]. (2011) CNVnator: an approach to discover, genotype and charac—
terize typical and atypical CNVs from family and population genome sequen—
cing. Genome Res., 21, 9747984.

Ashoor,H. et a]. (2013) HMCan: a method for detecting chromatin modiﬁcations in
cancer samples using ChIP—seq data. Bioinformatics, 29, 29722986.

Bailey,J.A. et a]. (2002) Recent segmental duplications in the human genome.
Science, 297, 100371007.

Bailey,T.L. et a]. (2009) MEME SUITE: tools for motif discovery and searching.
Nucleic Acids Res., 37 (Suppl. 2), W2027W208.

Chung,D. (2012) Statistical methods and software for ChIP—seq data analysis. Ph.D
Thesis, University of Wisconsin, Madison.

Chung,D. et a]. (2011) Discovering transcription factor binding sites in highly re—
petitive regions of genomes with multi—read analysis of ChIP—Seq data. PLoS
Comput. Biol, 7, e1002lll.

Fayyad,U.M. et a1. (1998) Initialization of iterative reﬁnement clustering algo—
rithms. In Agrawal,R. et al. (eds), KDD—98 Proceedings, pp. 1943198. AAAI
Press.

Hesselberth,J.R. et a]. (2009) Global mapping of protein—DNA interactions in vivo
by digital genomic footprinting. Nat. Methods, 6, 2837289.

Kharchenko,P.V. et a]. (2008) Design and analysis of ChIP—seq experiments for
DNA—binding proteins. Nat. Biotechnol, 26, 135171359.

Komura,D. et a]. (2006) Genome—wide detection of human copy number vari—
ations using high—density DNA oligonucleotide arrays. Genome Res., 16,
157571584.

Landt,S.G. et a]. (2012) ChIP—seq guidelines and practices of the ENCODE and
modENCODE consortia. Genome Res., 22, 181371831.

Langmead,B. et a]. (2009) Ultrafast and memory—efﬁcient alignment of short DNA
sequences to the human genome. Genome Biol, 10, R25.

Li,B. and Dewey,C.N. (2011) RSEM: accurate transcript quantiﬁcation
from RNA—Seq data with or without a reference genome. BMC
Bioiip’ormatics, 12, 323.

Li,H. and Durbin,R. (2009) Fast and accurate short read alignment with Burrows—
Wheeler transform. Bioinformatics, 25, 175431760.

Li,Q. et a]. (2011) Measuring reproducibility of high—throughput experiments. Ann.
Appl. Stat, 5, 175271779.

Newkirk,D. et a]. (2011) AREM: aligning short reads from ChIP—sequencing by
expecmtion maximization. J. Comput. Biol, 18, 149571505.

Pickrell,J.K. et a]. (2011) False positive peaks in chip—seq and other sequencing—
based functional assays caused by unannotated high copy number regions.
Bioiip’ormatics, 27, 214432146.

Rashid,N. et a]. (2011) ZINBA integrates local covariates with DNA—seq data to
identify broad and narrow regions of enrichment, even within ampliﬁed genomic
regions. Genome Biol, 12, R67.

Robinson,M.D. et a]. (2012) Copy—number—aware differential analysis of quantita—
tive DNA sequencing data. Genome Res., 22, 248972496.

Rozowsky,J. et a]. (2011) Alleleseq: analysis of allele—speciﬁc expression and binding
in a network framework. Mol, Syst. Biol, 7, 522.

Song,L. and Crawford,G.E. (2010) DNase—seq: a high—resolution technique for
mapping active gene regulatory elements across the genome from mammalian
cells. Cold Spring Harb. Protoc., 2010, pdb.prot5384.

The 1000 Genomes Project Consortium et a]. (2012) An integrated map of genetic
variation from 1,092 human genomes. Nature, 491, 5&65.

Toutanova,K. and Galley,M. (2011) Why initialization matters for IBM model 1:
multiple optima and non—strict convexity. In: HLT'II Proceedings of the 491/1
Annual Meeting of the Association for Computational Linguistics: Human
Language Technologies: Short Papers. Vol. 2, pp. 461466. Association for
Computational Linguistics: Human Language Technologies.

Wang]. et a]. (2010) A Gibbs sampling strategy applied to the mapping of ambigu—
ous short—sequence tags. Bioinformatics, 26, 250172508.

Wang,R. et a]. (2013) LOcating non—unique matched tags (LONUT) to im—
prove the detection of the enriched regions for ChIP—seq data. PLoS One, 8,
e67788.

 

2867

ﬁre'spzumol‘pmjxo'sopauuowrorq/pdnq

