ORIGINAL PAPER

Vol. 29 no. 24 2013, pages 3158-3166
doi:10. 1 093/bioinformatics/btt5 60

 

Structural bioinformatics

Advance Access publication September 27, 2013

Optimized atomic statistical potentials: assessment of protein

interfaces and loops

Guang Qiang Dong, Hao Fan, Dina Schneidman-Duhovny, Ben Webb and Andrej Sa|i*

Department of Bioengineering and Therapeutic Sciences, Department of Pharmaceutical Chemistry and California
Institute for Quantitative Biosciences (083), University of California, San Francisco, CA 94158, USA

Associate Editor: Anna Tramontano

 

ABSTRACT

Motivation: Statistical potentials have been widely used for modeling
whole proteins and their parts (e.g. sidechains and loops) as well as
interactions between proteins, nucleic acids and small molecules.
Here, we formulate the statistical potentials entirely within a statistical
framework, avoiding questionable statistical mechanical assumptions
and approximations, including a definition of the reference state.
Results: We derive a general Bayesian framework for inferring statis-
tically optimized atomic potentials (SOAP) in which the reference state
is replaced with data-driven ‘recovery’ functions. Moreover, we
restrain the relative orientation between two covalent bonds instead
of a simple distance between two atoms, in an effort to capture orien-
tation-dependent interactions such as hydrogen bonds. To demon-
strate this general approach, we computed statistical potentials for
protein—protein docking (SOAP-PP) and loop modeling (SOAP-Loop).
For docking, a near-native model is within the top 10 scoring models in
40% of the PatchDock benchmark cases, compared with 23 and 27%
for the state-of-the-art ZDOCK and FireDock scoring functions,
respectively. Similarly, for modeling 12-residue loops in the PLOP
benchmark, the average main-chain root mean square deviation of
the best scored conformations by SOAP-Loop is 1.5 A, close to the
average root mean square deviation of the best sampled conform-
ations (1 .2A) and significantly better than that selected by Rosetta
(2.1 A), DFIRE (2.3A), DOPE (2.5 A) and PLOP scoring functions
(3.0A). Our Bayesian framework may also result in more accurate
statistical potentials for additional modeling applications, thus afford-
ing better leverage of the experimentally determined protein
structures.

Availability and implementation: SOAP-PP and SOAP-Loop are
available as part of MODELLER (http://salilab.org/modeller).

Contact: sali@salilab.org

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on June 19, 2013; revised on August 13, 2013; accepted on
September 22, 2013

1 INTRODUCTION

Computational modeling can be used to predict the structures
of whole proteins or their parts (e. g. loops and sidechains) as well
as complexes involving proteins, peptides, nucleic acids and
small molecules (Audie and Swanson, 2012; Baker and Sali,
2001; Dill and MacCallum, 2012; Ding et al., 2010; Skolnick

 

*To whom correspondence should be addressed.

et al., 2013; Wass et al., 2011). A modeling method requires a
conformational sampling scheme for proposing alternative struc-
tures and a scoring function for ranking them. Signiﬁcant pro-
gress has been made on both fronts (Fernandez-Recio and
Sternberg, 2010; Moult et al., 2011). In particular, many phys-
ics-based energy functions and statistical potentials computed
from known protein structures have been described (Andrusier
et al., 2007; Benkert et al., 2008; Betancourt and Skolnick, 2004;
Betancourt and Thirumalai, 1999; Brenke et al., 2012; Chuang
et al., 2008; Colovos and Yeates, 1993; Cossio et al., 2012;
Dehouck et al., 2006; Fan et al., 2011; Ferrada et al., 2007;
Gao and Skolnick, 2008; Gatchell et al., 2000; Hendlich et al.,
1990; Huang and Zou, 2010; Jones, 1999; Keasar and Levitt,
2003; Kocher et al., 1994; Li et al., 2013; Liu and Gong, 2012;
Liu and Vakser, 2011; Lu and Skolnick, 2001; Lu et al., 2008;
McConkey et al., 2003; Melo and Feytmans, 1997; Melo et al.,
2002; Miyazawa and Jernigan, 1996; Park and Levitt, 1996;
Pierce and Weng, 2007; Qiu and Elber, 2005; Rajgaria et al.,
2008; Rata et al., 2010; Reva et al., 1997; Rojnuckarin and
Subramaniam, 1999; Rykunov and Fiser, 2010; Samudrala and
Moult, 1998; Shapovalov and Dunbrack, 2011; Shen and Sali,
2006; Simons et al., 1997; Sippl, 1993; Summa et al., 2005;
Tanaka and Scheraga, 1975; Wang et al., 2004; Xu et al., 2009;
Zhang and Zhang, 2010; Zhao and Xu, 2012; Zhou and
Skolnick, 2011; Zhou and Zhou, 2002; Zhu et al., 2008).
Derivation of a statistical potential has often been guided by
an analogy between a sample of known native structures and the
canonical ensemble in statistical mechanics, suggesting that the
distributions of spatial features in the sample of native structures
follow the Boltzmann distribution (Sippl, 1990). Thus, statistical
potentials are generally calculated in two steps: (i) extracting a
probability distribution of a spatial feature (e.g. a distance
spanned by a speciﬁc pair of atom types) from a sample of
known protein structures and (ii) normalizing this distribution
by a reference distribution (e. g. the distribution of all distances,
regardless of the atom types). Statistical potentials can differ in a
number of aspects, including the sample of known protein struc-
tures, the protein representation (e.g. centroids of amino acid
residues, Ca atoms and all atoms), the restrained spatial feature
(e.g. solvent accessibility, distance, angles and orientation
between two sets of atoms), the sequence features (e.g. amino
acid residue types, atom types, residue separation in sequence
and chain separation), the treatment of sparse samples and the
deﬁnition of the reference state. Here, we optimize the accuracy
of a statistical potential over most of these aspects. This opti-
mization challenge is addressed by formulating a statistical

 

3158 © The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com

112 /310'slcu1nofp103xo"sotJBurJOJutotq/ﬁduq wort popcolumoq

91oz ‘Og anﬁnv uo ::

Optimized atomic statistical potentials

 

potential independently from any assumptions grounded in stat-
istical mechanics; instead, we rely on a Bayesian approach based
on data alone. Although the proposed theory applies to any kind
of a statistical potential, we illustrate it by deriving speciﬁc stat-
istical potentials for proteineprotein docking and loop modeling.

2 METHOD

We begin by deﬁning statistical potentials in terms of distributions
extracted from known protein structures (Section 2.1), followed by a
description of a protocol to actually compute a statistical potential
(Sections 2.2727, Fig. 1).

2.1 Theory

For structure characterization of a given protein sequence by either
experiment or theory, we ideally need a joint probability density function
(pdf) for the structure, given everything we know about it (Shen and Sali,
2006). In general, our knowledge can come from different kinds of
experiments with the protein (e.g. X-ray crystallography), physical the-
ories (e.g. a molecular mechanics force ﬁeld) and/or statistical inference
(e.g. all known structures or only homologous known structures). Here,
we focus on a joint pdf for a given sequence based on the knowledge of all
known protein structures deposited in the Protein Data Bank (PDB)
(Kouranov et al., 2006); thus, our joint pdf is a statistical potential.

To derive the joint pdf for a structure of a sequence, we need to
approximate it by using terms that can actually be computed from the
PDB. The structure X of an amino acid sequence is deﬁned by the set of
its features {fL'(m)},m = 1 . . .n, such as a distance between two speciﬁc

  
 
   
 
 
   

 
    
   
    
  

  
  
   

Select su Use] of known protein structures .k'
Select su user oi lea lure types '1'

Select smoothing prior S [2.7]
Select lecuvery function farm 4;,

initialize recovery function parameters ﬁe

Calcula1e leature distributions [2 3.2)
Calculate smomheﬂ feature distributions {2.4)

Set of known structures 2642.31]
Set oifeature types 11' [2.2)
Selotsmuulhing pnursté [2.4)
Set 0! recovery function forms (7-,- (2.5]

      

i r

 Update recovery function parameters 09:27]
 Calculate recovery lunclion [2.5)

1 Calculate stafslical polenbaf [2.1)

 Calculate the accuracy of lhe smtislical
3 potential on the set of training decoys [2.5)
3 No

Converged?

         
   
    
   
      

 

YES

Seminalan dmysollzs) I      

Calculate Bayestart predictive density [2 T)

”‘55365353510'tiéiéé'iiéimm""‘”'“‘”

 

imitate;Haunting"""""""""""""""'""""""""""""'

 

K.)

 

 

Yes :
, Set of validation decoys D. {2.51 

Optimal {A .1541.) [3.1. 3.2]

 

 

  

I Bayesran inference of 93(2)] I
Optimized statistical potentlal l3 1.3 2)

Fig. 1. Flowchart for optimizing statistical potentials. The corresponding
sections in the text are indicated

atoms. Thus, we can approximate the joint pdf by the product of pdfs
(restraints) for individual features:

pace 1‘1 MW), (1)

15m5n

Without any loss of accuracy, we deﬁne the restraint p(f”(m)) as the ratio
between the feature distribution p(f”|Q;C) from a sample of informative
features in a set of proteins QK with known structures (e.g. for a distance,
all distances spanned by the same atom types in QC) and an unknown
recovery function g(f”|Q;C):

120W) =pth'iQt)/gtf”ict), (2)

In other words, the recovery function is deﬁned such that the product of
restraints approximates the joint pdf as well as possible (cf, Equation 1),
while minimizing the number of parameters that need to be ﬁt to the data.
Construction of the sample of informative features involves a comprom-
ise between including only features of known structures that are most
likely to resemble the predicted feature f "("1) (which minimizes sample
size) and minimizing the statistical noise (which maximizes sample size).
The features used in the sample are termed to be of the same type c as the
inferred feature (Section 2.2). The restraints on all features of X of type c
are calculated from the same set of informative features and thus are the
same. Here, the sample of informative features includes all features of the
same type from representative known protein structures (Section 2.3).

2.2 Feature types

To illustrate the general theory mentioned earlier in the text, we derive
optimized statistical potentials for assessing proteineprotein interfaces
(SOAP-PP) and loop conformations (SOAP-Loop). We restrain the
following feature types:

2.2.] Atomic distance Distance d|a1,a2,bS is considered to depend on
atom types a1 and a2 as well as the ‘covalent separation’ between the two
atoms (by). The atom type depends on the residue type, resulting in the total
of 158 atoms types for the 20 standard residue types (Shen and Sali, 2006).
Covalent separation is measured in three ways. First, by the minimum
number of covalent bonds between the two atoms (bond separation).
Second, by the number of residues separating the two atoms in the poly-
peptide chain (residue separation). Third, by chain separation, which is 0 if
the atoms are in the same chain and 1 otherwise. The distance is mapped in
the range from 0 to a parameterized distance cutoff, such as 15A.

2.2.2 Orientation between a pair of covalent bonds Orientation
d, 051,052, tI/It1,t2,bs is deﬁned by a distance d, two angles 051,052 and a
dihedral angle 11/ (Fig. 2). It is considered to depend on covalent
bond types (t1,t2) deﬁned in turn by their atom types and covalent
separation (by); there are 316 covalent bond types for the 20 standard
residue types.

 

Fig. 2. Distance and angles between two covalent bonds, AeB and C7D.
d, distance between atoms A and C. an, angle between atoms B, A and C.
052, angle between atoms A, C and D. 11/, dihedral angle between atoms B,
A, C and D. b, is deﬁned using atoms A and C

 

3159

112 /310'slcum0fp1q1xo"sotJButJOJutotq/ﬁduq uteri popcolumoq

9103 ‘Og anﬁnv uo ::

G.Q.Dong et al.

 

2.2.3 Relative atomic surface accessibility Accessibility sla is con-
sidered to depend on the atom type (a) (Sali and Blundell, 1993).

2.3 Feature distributions

2.3.] Known protein structures A small fraction of the known pro-
tein structures from the PDB (and their decoy structures) is used only for
assessing the accuracy of statistical potentials (Section 2.5). The remain-
ing structures from the PDB are ﬁltered to construct the known protein
structure set M, including only structures determined by X-ray crystallog-
raphy at the resolution better than 2.2  and Rhee better than 25%. Three
additional subsets of representative structures were obtained by requiring
at most 30, 60 and 95% sequence identity to any other representative
structure, respectively, with preference for structures determined at higher
resolutions and with lower Rhee values. A statistical potential is optimized
by choosing among the entire set [K or its three subsets to estimate the
feature distributions p(f”| QK).

2.3.2 Calculation of feature distributions The sample for comput-
ing this distribution is the set of the individual features of type c in protein
set QK, where each feature is represented by the distribution of this
feature -p(f”(m)|QK). The feature distribution p(f”|Q,C) is the average
of these sample distributions. For a distance and an angle, p(f”(m)|QK)
is approximated by a Gaussian distribution p’(f”(m)|QK) with the mean
equal to the observed value and the standard deviation computed by the
propagation (Neuhauser, 2010) of the uncertainties of individual atomic
positions, which in turn are estimated from the atomic isotropic tempera-
ture factors (Carugo and Argos, 1999; Cruickshank, 1999; Schneider,
2000). For relative atomic surface accessibility, p(f”(m)|QK) is approxi-
mated using a delta function p’(f”(m)|QK) centered at feature ﬁlm) in K.
The approximated feature distribution p’(f”|Q,C) is then computed from
the approximated sample distributions p’(f”(m)|QK).

2.4 Bayesian smoothing and smoothing priors

The feature distributions p’(f”|Q;C) can be noisy when the sample [C is
relatively small, as is often the case for the orientation between a pair of
covalent bonds (Fig. 3A). Thus, we use Bayesian inference to calculate a
smooth feature distribution:

17070“ lQ/dlp’U“ thcD “PU/(1“ 'Ith)|17(f‘ thc)) 17070“ lQ/d) (3)

where p(f”|Q,C) is the ideal distribution without noise from an inﬁnitely
large set of known structures. Both the likelihood p(p’(f”|Q;C)|p(f”| QK))
and the prior 8 E p(p(f”|Q;C)) are multivariate Gaussian distributions
(Rasmussen and Williams, 2005). The smoothness of p(f”|Q;C) is speci-
ﬁed by the prior 8; here, the prior is a multivariate Gaussian distribution
with a zero mean and a squared exponential covariance function
(Mackay, 2003). The characteristic length scale of the covariance function
deﬁnes the range over which the two points are still correlated (the

 
  

o

0
Frequency

 

Fig. 3. Distance and dihedral angle joint distribution between
alanine N-Ca and alanine O-C, when 051 6 [600,900] and 052 6 [600,900].
(A) Original distribution. (B) Smoothed distribution

smoothness of the curve). We set the characteristic length equal to a
scale parameter L multiplied by 0.2A for distance, 10° for angles and
0.1% for atomic surface accessibility. A set of smoothing priors § is
obtained by varying L. Using a scale of 2.0 as an example, the inferred
p(f”|Q,C) is signiﬁcantly smoother than p’(f”|Q,C) (Fig. 3B).

2.5 Decoys and assessment criteria

2.5.] Learning set for SOAP-PP This set consists of 176 native
complex structures in the pairwise protein docking benchmark 4.0
(Hwang et al., 2010) and ~4500 decoys for each of the complexes
generated using PatchDock (Duhovny et al., 2002).

2.5.2 Testing set for SOAP-PP This set consists of 176 native com-
plex structures in the pairwise protein docking benchmark 4.0 (Hwang
et al., 2010) as well as ~212 000 decoys for each of the complexes gener-
ated using PatchDock (Duhovny et al., 2002) and ~54000 decoys for
each of the complexes generated using ZDOCK (Pierce et al., 2011).

2.5.3 Assessment criteria for S OAP-PP Each model is assessed for
accuracy based on root mean square deviation (RMSD) from the native
structure, as used at CAPRI (Lensink et al., 2007). A docking model is
considered acceptable if the ligand CD, RMSD after superposition of the
receptors is <10  or the interface Ca RMSD is <4 A docking model is
of medium accuracy if ligand CD, RMSD is <5A or interface CD, RMSD is
<2 A. The success rate for SOAP-PP is the percentage of benchmark cases
with at least one medium or acceptable accuracy model in the top N
predictions.

2.5.4 Learning set for S OAP-Loop This set consists of 3838 native
loop conformations of #20 residues and ~500 decoys for each loop
generated using MODELLER (Fiser and Sali, 2003; Sali and Blundell,
1993). Loops were extracted from X-ray crystallography structures in the
PDB using DSSP (Kabsch and Sander, 1983; Joosten et al., 2011). We
only considered protein structures determined at a resolution better than
2A, Rhee better than 0.25 and crystallized between pHs 6.5 and 7.5; no
pair of source structures had sequence identity higher than 30%. Each
loop has only standard residues, no missing non-hydrogen atoms, average
atomic surface accessibility between 5 and 60%, no crystal contacts, no
clashes with nearby atoms, no contacts with metal ligands and does not
occur in the PLOP loop modeling decoy set (Jacobson et al., 2004).

2.5.5 Testing set for SOAP-Loop This set consists of 833 native
loop conformations of 442 residues and ~450 decoys for each loop
generated using PLOP (Jacobson et al., 2004).

2.5.6 Assessment criteria for S OAP-Loop Each model is assessed
for accuracy based on its main-chain RMSD to the native conformation,
after superposition of all non-loop atoms (RMSDglobal) (Fiser et al.,
2000); main-chain atoms include amide nitrogen, C“, as well as carbonyl
carbon and oxygen. SOAP-Loop is assessed by the average RMSDglobal
of the top ranked model for each loop.

2.6 Recovery functions and functional forms

We estimate the recovery function g(f”|Q;C) by optimizing the accuracy
of the corresponding statistical potential on a benchmark of interest.
To avoid overﬁtting, we assume either a single recovery function for all
feature types or the same recovery function for a subset of similarly
distributed feature types.

The set of recovery function forms g, is different for distances, angles
and accessibility: The recovery function for the atomic distance is mod-
eled using one of three functional forms: (i) d], where d is distance and q is
a constant (Zhou and Zhou, 2002); (ii) the ideal gas distribution in
spheres with varying radii (Shen and Sali, 2006); and (iii) spliced cubic
splines. For orientation, the recovery function is deﬁned as the product of

 

3160

112 /310'srcum0fp1q1xo"soticuiJOJutotq/ﬁduq uteri popcorn/nag

9103 ‘Og isnﬁnv uo ::

Optimized atomic statistical potentials

 

 

0.016
0.008
a. 0.000

 

 

 

 

3 0.016
a 0.003
a 0.000

 

 

0.015
0.000
0.000

E. _‘ j.
i at L L

0510 0510 0510 0510 0510
Distancem)

 

 

 

 

 

 

 

 

 

Fig. 4. Distance distributions p(f”|Q;C) for different atom pairs are
clustered into 15 different groups. Each line represents a distance distribu-
tion from a pair of atoms of certain types. Each group has 38401 distri-
butions. During k-mean clustering, the number of clusters was set to 20,
resulting in 14 clusters with >5 distributions and 6 clusters with <5 distri-
butions; the latter 6 clusters are grouped together (bottom right panel)

a recovery function for d, a1, a2 and 11/, respectively. The recovery func-
tions for angles (11, a2 and dihedral angle 11/ are modeled using two
different functional forms: (i) the feature distribution calculated using
the ideal gas assumption and (ii) spliced cubic splines. For the relative
atomic surface accessibility, the recovery function form is spliced cubic
splines. Control points of cubic splines are deﬁned by their x and y values.
When searching for the best cubic spline recovery function, the x values
of the control points are either ﬁxed at discrete sampling values or
inferred together with the y values.

To optimize the recovery functions, we need to balance minimizing
noise and maximizing precision. Thus, for atomic distances, we clustered
the distance distributions p(f”|Q;C) for different atom type pairs using
k-mean clustering and assumed that the pairs of atom types with similar
distance distributions have a similar recovery function (Fig. 4).

2.7 Bayesian inference and model selection

A statistical potential is deﬁned by four discrete input variables (the known
protein structure subset IC, the feature type subset .73, the smoothing prior
8 and the recovery function form 9]) and a vector of continuous input
variables (the recovery function parameters g9). We elected to deﬁne the
best values for the four discrete variables are those that result in the most
generalizable statistical potential, as judged by the Bayesian predictive
densities (Vehtari and Lampinen, 2002), whereas the best values for the
recovery function parameters are those that result in the most accurate
statistical potential, as judged by a given benchmark. Because each of the
ﬁve variables can be sampled at many values, enumeration of all combin-
ations is not computationally feasible. Thus, the search for the best values
is carried out in four stages, as follows.

First, irrespective of the ﬁnal restrained feature .73, we begin with the
atomic distance and a single recovery function for all atom type pairs.
The optimal values of the discrete variables (.73, IC, 8, 9]) are found by an
iterative discrete search:

(1) Choose an arbitrary starting value for each variable out of their
possible value sets {[F, K, §, (5)} (Supplementary Table S1 and S2).

(2) For each variable, choose the best value and eliminate the worst
value in the value set using Bayesian model selection based on
Bayesian predictive densities (Vehtari and Lampinen, 2002). The
Bayesian predictive density for each value is calculated with other
variables ﬁxed at their best previous values:

11 /P(Dvlf, 1c, 5, g]. 99) ‘P(Qelf, 1c, .5. g]. Dodge (4)
it, V)

where the learning decoys D are randomly separated multiple times
into a training set D, and a validation set D,, from which the
integrals are estimated using Monte Carlo sampling (Evans and
Swartz, 2000). p(ggl.7-',IC,,S,gf,D,) is calculated following the
Bayes rule:

[7(96 L73, 1C, , 5, 9;, Dr) 0C [7(Dt|.7:. 1C, 5, g], go) ‘I’(% lgf) (5)

here the likelihood p(D,|.7-',IC,S, g), g.) is a half-normal distribu-
tion whose corresponding normal distribution has the mean equal
to the accuracy of an imaginary statistical potential generating
scores that correlate perfectly with the decoy-native RMSD and
the standard deviation computed by dividing the mean by the
number of the cases in the training set D,; the prior p(g9|gf) is
an informative prior deﬁning a reasonable range for g...

(3) Repeat step 2 until the best values do not change.

(4) Repeat ﬁve times steps 173 for different random initial values.

(5) Keep the best performing variable values.

Second, keeping the optimal values from the previous step ﬁxed, we ﬁnd
the optimal values for the feature type, smoothing length scale and the
number of spline anchor points using the same 5-step iterative discrete
search outlined earlier in the text.

Third, if the optimal spatial feature selected in the previous step is not
orientation, we vary the number of recovery functions and the number of
anchor points to optimize their values, again using the 5-step iterative
discrete search.

Fourth, using the selected {.7-',IC,S,gf}, we infer the best recovery
function parameter values g. by maximizing p(ggl.7-', IC, ,8, g), D)
(Equation 5). The optimized statistical potential is then calculated
(Equation 2) and assessed on testing decoy sets.

SOAP-PP and SOAP-Loop are available as part of MODELLER
(http://salilab.org/modeller). All the training, learning, testing, decoys,
benchmark sets and scripts are available at http://salilab.org/SOAP.

3 RESULTS

3.1 Scoring protein—protein interfaces

SOAP-PP is an atomic statistical potential for assessing a binary
protein interface, computed with our Bayesian framework by
optimizing its accuracy on the learning set for SOAP-PP
(Supplementary Table S1).

Using the recovery function parameters optimized for 15 sets
of training decoys (each set is randomly selected 50% of the
learning set), the average top10 success rate (Section 2.5.3) is
44.7:l: 1.2% on the sets of training decoys and 38.4:l: 1.7% on
the sets of validation decoys. The relatively small difference
between the two success rates likely results from overﬁtting. To
investigate overfitting, we increased the size of the training decoy
set from 50 to 67% of the entire learning set of 176 proteins. As a
result, the average top10 success rate on the training decoys
decreased from 44.7 to 44.2%, but the average success rate on
the validation decoys (the remaining 33% of the learning set)
increased from 38.4 to 39.8%. This observation suggested that
increasing the size of the training set may be an effective way of
reducing overﬁtting (Murphy, 2012). Thus, we optimized SOAP-
PP using the entire learning set of 176 proteins as the training set,
even though this forces subsequent testing on the training protein
sequences. To estimate the resulting overfitting, we calculated six
optimized statistical potentials, each one of which was based on a
training set that included a random subset of ~67% of the learn-
ing set. Next, we tested these potentials on two testing sets: the

 

3161

112 /3.10'srcumofpiqrxo"soticuiJOJutotq/ﬁduq uteri popcorn/nag

9103 ‘Og isanV uo ::

G.Q.Dong et al.

 

 

 

     
  

 

 

 

 

 

 

 

 

 

 

 

 

A 0.2 B 0.0 . .
00.8— 7 $0,7en- ZRANK 7
0.7 — “' =04; FireDock 7
*0-5’ ’ “0.5 .2"
30-5’ “ $0 4 ' —
00.4- - a: ’
30.3- - 30'3 '
:02- _ I30.2 J _/_. —
0.14»: — 0.1,." -
0.0 I llllllll . tum-I . “inn 0K0 I .nunl J nut-ml I I ll
10“ 101 102 :to3 10° 101 102 103
Number of predictions Number of predictions
C 0.9 . . . .  D 0.3
0.8— o_1,
430.7— dado-6-
I-O.6- so 5_
“0.5- 'ﬂ '
§0_4_ EDA-
u0.3r I403—
=o.2— =0-2-
tr.- - u: -
0.1- I I 0-1; I I
0.0 0.0
1 ° 101 :to2 103 10° 101 102 103

Number of predictions Number of predictions

Fig. 5. Success rates of SOAP-PP, ZRANK and FireDock on the
PatchDock and ZDOCK decoy sets. (A) Success rates on the
PatchDock decoy set, where a success is deﬁned as having an acceptable
accuracy structure in the top N predictions (x-axis). (B) Success rates on
the PatchDock decoy set for picking structures with medium accuracy.
(C) Success rates on the ZDOCK decoy set for picking structures with
acceptable accuracy. (D) Success rates on the ZDOCK decoy set for
picking structures with medium accuracy

ﬁrst set consisted only of the training proteins; the second set
consisted of the remaining learning proteins. The average top10
success rate for the PatchDock decoys is 41.1% and 38.6% for
the ﬁrst and second test set, respectively; for the ZDOCK decoys,
the average top10 success rate is 40.0 and 38.9% for the ﬁrst and
second test set, respectively. Therefore, given that increasing the
training set size reduces overfitting as shown previously, the
accuracy of SOAP-PP estimated based on a completely different
testing set is expected to be within 2.5% of the current estimate
(later in the text).

SOAP-PP was assessed on the PatchDock (Schneidman—
Duhovny et al., 2012) and ZDOCK decoy sets (Pierce et al.,
2011) (Fig. 5). For PatchDock decoys, the top10 success rate
of SOAP-PP is 40% (Fig. 5A) compared with 23% for
ZRANK and 27% for FireDock. If only models of medium or
better accuracy are considered, the top10 success rate is 33% for
SOAP, 17% for ZRANK and 23% for FireDock (Fig. 5B).
For ZDOCK decoys, the top10 success rate of SOAP-PP is
41% (Fig. 5C) compared with 30% for ZRANK and 22% for
FireDock. If only models of medium or better accuracy are
considered, the success rate is 32% for SOAP-PP, 22% for
ZRANK and 17% for FireDock (Fig. 5D).

High accuracy of SOAP-PP can sometimes be attributed to the
weaker short-distance repulsion (Fig. 6A) compared with
ZRANK (Pierce and Weng, 2007) and FireDock (Andrusier
et al., 2007), both of which use a modiﬁed van der Waals repul-
sion term; thus, the clashes of the best sampled structure with a
receptor are likely less penalized by SOAP than by ZRANK
and FireDock. Although SOAP-PP is more successful than
ZRANK and FireDock overall, picking near-native proteine
protein complex models out of decoys remains a hard problem

 

Fig. 6. Comparison of the top ranked, best sampled and native conﬁg-
urations. (A) 2G77. (B) IOCO. The receptor is shown in gray. The ligand
is shown in the native conﬁguration (yellow), the best sampled conﬁgur-
ation (green for 2G77 and black for IOCO) and the top ranked conﬁg-
uration by SOAP (green), FireDock (blue) and ZRANK (red)

(Fig. 5). For some cases, all three scoring functions perform
badly, especially when the proteineprotein interfaces are small
and have poor shape complementarity (Fig. 6B).

3.2 Scoring loops

SOAP-Loop is an atomic statistical potential for assessing pro-
tein loop conformations, computed with our Bayesian frame-
work by optimizing its accuracy on the learning set for SOAP-
Loop (Supplementary Table S2).

SOAP-Loop was assessed on the PLOP loop modeling decoy
set (Jacobson et al., 2004). We compare SOAP-Loop with DOPE
(Shen and Sali, 2006), DFIRE (Zhang et al., 2004), Rosetta 3.3
(Simons et al., 1999) and PLOP 25.6 scoring functions (Jacobson
et al., 2004) (Fig. 7A). For short loops, SOAP-Loop and Rosetta
perform similarly and better than the other tested scoring func-
tions: the main-chain RMSD of SOAP-Loop’s top ranked struc-
ture is close to that of the best decoy structure. For longer loops,
the accuracy differences become larger. SOAP-Loop is still able
to pick structures close to the best decoy structures: for 12-resi-
due loops, the average main-chain RMSD of the best scored
conformations by SOAP-Loop is 1.5A, close to the average
RMSD of the best decoy conformations (1.2 A) and signiﬁcantly
better than that by DOPE (25A), DFIRE (2.31%), Rosetta
(2.1A) and PLOP scoring functions (3.0A). We note that this
assessment should not be used to rank the PLOP scoring func-
tion because the decoy set used here was generated with PLOP.
Thus, we further compare different scoring functions by their
average all-atom RMSD values of the best scored conformations
using our learning set for SOAP-Loop (Section 2.5.4 and
Supplementary Table S3).

Although no testing protein occurs in the learning set, 11 pairs
of testing-learning loops have the same sequence. Excluding
these 11 loops from the testing set, the average RMSD of the
top ranked loop by SOAP-Loop increases insignificantly from
0.895A to 0.897A; the average RMSD of the best decoy con-
formations also increases insignificantly from 0.566A to 0.567

The relative success of SOAP is attributed to the scoring of the
orientation instead of distance and the use of the recovery func-
tions instead of a reference state (Fig. 8). However, SOAP-Loop

 

3162

112 /3.10'srcumofpiqixo"soticuiJOJutotq/ﬁduq uteri popcorn/nag

9103 ‘Og isanV uo ::

Optimized atomic statistical potentials

 

 

     
   
   
 

 

 

 

3.5 l I I I I I I
Lowest RMSD decoys 
3_0 _ - DOPE 5 "t:
 DFIRE  N
n - - Rosetta 3 ’~., N
m 2 5 — i ’3, I, ~
2  PLOP .~ 1:, 
K ..- I~ . ~
“’20 — SOAP  ~ , t
m I \\I\“‘ ‘ ~
5 1 5 —  "y
BI. 3“ a"l’ .‘
,9 1.0 — “U” ‘r
.“I rhﬁ‘
.mjrv'"
0.5 .6. , _
0.0 | | I I I | |
4 5 6 7 8 9 10 11 12
Loop length

Fig. 7. Accuracy of SOAP-Loop. The average main-chain RMSD of
top ranked structures by DOPE, DFIRE, Rosetta, PLOP and SOAP-
Loop on PLOP loop modeling decoys. The average RMSD of the most
accurate conformations sampled by PLOP is plotted by a dash-dotted
line

 

 

 

 

1.2 I I I I I I I
SOAP-PP
— SOAP-Loop
1'0 ‘ — DFIRE ,-"
DOPE O/
x
0.8 - O/ -
x
s f
— 0.6 - / _
N /
> /
x/
0.4 — K _
K.
0.2 - -
0.0 I I I I
0 8 10 12 14

 

Distance (A)

Fig. 8. Recovery functions for SOAP-PP and SOAP-Loop are compared
with DOPE and DFIRE’s reference states

still fails to identify the best-sampled conformation in some
cases. For a loop in lCYO, for example, the failure can be
attributed to the lack of a sufﬁciently native conformation
among the tested conformations and the absence of significant
interactions between the loop and the rest of the protein
(Fig. 9A). It is also possible that some interactions, such as
long-range interactions, are not treated accurately by any scoring
function, indicating the need for further development of the
theory of statistical potentials.

4 DISCUSSION

We developed a Bayesian approach to optimizing statistical
potentials based on probability theory and without recourse to
questionable statistical mechanical assumptions and approxima-
tions. We also applied this approach to calculate optimized

 

Fig. 9. Comparison of the top ranked, best sampled and native conﬁg-
urations. (A) lCYO. (B) 2AYH. The native structure is shown in light
gray. The loop is shown in the native configuration (yellow), the best
sampled conﬁguration (black for lCYO and green for 2AYH) and the
top ranked conﬁguration by SOAP (green), DOPE (blue), DFIRE (red),
Rosetta (magenta) and PLOP (light blue)

statistical potentials for assessing protein interactions (SOAP-
PP) and loops (SOAP-Loop). These two statistical potentials
perform better than others in their class. For PatchDock
and ZDOCK decoys, the top10 success rate of SOAP-PP is
>10% higher than that of FireDock and ZRANK (Fig. 5).
For 12-residue loops in the PLOP benchmark, the average
main-chain RMSD of the best scored conformations by
SOAP-Loop is 1.5A, close to the average RMSD of the best
sampled conformations (1.2A) and signiﬁcantly better than
that from DOPE (25A), DFIRE (2.3/S), Rosetta (2.11%) and
PLOP scoring functions (3.0 A) (Fig. 7). The relative accuracy of
SOAP-PP and SOAP-Loop results primarily from normalizing
the raw distributions by the recovery functions instead of a
reference state, restraining of orientation instead of only distance
and thoroughly optimizing parameter values while avoiding
overfitting.

Next, we discuss three points in turn. First, we describe our
recovery functions and compare them with the reference states
used for other statistical potentials. Second, we discuss the
importance of restraining orientation and using covalent separ-
ation as an independent variable. Finally, we conclude by
commenting on future improvements of our Bayesian approach
and its applications.

4.1 Cubic splines as a recovery function form

A key difference between statistical potentials is the deﬁnition of
their reference states, which are often derived by assuming that
the PDB provides a Boltzmann ensemble of structural features
(Sippl, 1990). Here, we replace the reference state by data-driven
recovery functions, deﬁned self-consistently without recourse to
these questionable statistical mechanical assumptions
(Finkelstein et al., 1995; Shen and Sali, 2006). In an extreme
case, we use cubic splines to compute optimal recovery functions,
relying on Bayesian inference to obtain parameter values that
result in the most accurate statistical potential given a
benchmark.

The use of splines as recovery functions is motivated by a
qualitative analysis of the recovery function (Supplementary
Equation S2). The distribution p(fc(’”)|QK) of a single feature

 

3163

112 /3.10'srcumofpiqixo"sotJBMJOJutotq//:d11q moi) popcolumoq

91oz ‘Og isanV uo ::

G.Q.Dong et al.

 

fc(’”) is the product of the restraint on fc(’”) and an integral
involving the restraints on QK’s other features (i.e. the environ-
ment restraint). Then, the recovery function g(fc|Q)C) is the
distribution of feature type c in structure set [C resulting from
the environmental restraints alone (Supplementary Equation S2).
We now discuss three implications of this perspective.

First, if we assume that atoms are placed randomly within the
protein shell, a recovery function will be similar to the DFIRE
and DOPE reference states based on the ideal gas assumption
(Shen and Sali, 2006; Zhou and Zhou, 2002).

Second, using the distance d between atoms A and C in
Figure 2 as an example, the environment restraint on d is a con-
sequence of the restraints on distances between AeD, CeB and
BrD as well as the bonds between AeB and C7D. The restraints
on AeD, CeB and BrD distances have short-range repulsion
components. Thus, the environment restraint on the distance
AeC will include an effective short-range repulsion. This quali-
tative analysis is consistent with the observed recovery functions
for SOAP-PP and SOAP-Loop, which all have lower values at
short distances than the DOPE reference state based on the ideal
gas assumption (Fig. 8).

Finally, the recovery functions for different feature types can
vary, because of their different environments, as observed for the
recovery functions for 15 clusters of atom type pairs used in
SOAP-PP (Fig. 8).

Although splines can mimic almost any smooth function given
a sufﬁcient number of anchor points, its ﬂexibility could also
lead to overﬁtting; moreover, a large number of anchor points
could lead to oscillations (Fig. 8). Although our Bayesian model
selection method helps with the generalizability of the optimized
cubic spline (V ehtari and Lampinen, 2002), it is conceivable that
applying Bayesian model selection to a less ﬂexible but appro-
priate functional form will result in a more accurate and general
statistical potential than that based on splines.

4.2 Spatial and sequence features

Our orientation restraints score a spatial relationship between
two sets of atoms in more detail than distance restraints alone,
and should be particularly useful for scoring spatial relationships
between polar atoms, especially for hydrogen bond donors
and acceptors. In fact, the relative accuracy of SOAP-Loop
can be attributed to the use of orientation and recovery func-
tions instead of distance and reference state, respectively
(Supplementary Table S1). However, using orientation did not
result in a better statistical potential for ranking protein inter-
faces (Supplementary Table S2). Although we may not have
found the globally optimal statistical potential for orientation,
a more likely reason is insufﬁcient accuracy of the tested con-
formations produced by rigid docking.

Covalent separation is another important factor affecting the
accuracy of the derived statistical potentials. Surprisingly, for
ranking protein interfaces, statistical potentials derived from
intra—chain non-local atom pairs (bond separation >9) work
better than statistical potentials derived from inter-chain atom
pairs (chain separation: 1) (Supplementary Table S1). A likely
reason is that many protein interfaces in the PDB result from
crystal contacts that do not reﬂect interfaces between proteins
in solution (Carugo and Argos, 1997; Krissinel, 2010). In the

future, a better statistical potential for ranking protein interfaces
might be obtained if only true biological interfaces from PDB
are used.

4.3 Bayesian inference

Statistical potentials can be derived for many different values of
the input variables, with little or no a priori reasons to choose
one set of values over the others. The Bayesian model selection
based on Bayesian predictive densities provides a statistically
rigorous way of choosing the values that result in most general-
izable statistical potentials (V ehtari and Lampinen, 2002).
However, one limitation of this method is that the calculation
of predictive densities is computational intensive, often requiring
more than tens of thousands of evaluations of the statistical
potential on the benchmark. Thus, such calculations are not
always practical. Fortunately, increases in the available computer
power will enable us to ﬁnd more accurate statistical potentials
in an increasingly larger parameter space in the future. Another
approach to improving the search for optimal parameter values
is to use physically motivated feature types, functional forms and
allowed value ranges.

In principle, normalizing the feature distributions by recovery
functions to obtain a statistical potential (Equation 2) is not ne-
cessary. Instead, we could use parametric (e. g. the mathematical
functional forms used in molecular mechanics force fields) or
non-parametric functions to represent the statistical potential
and directly infer the optimal statistical potential by its accuracy
on a benchmark of interest. However, this approach might not
provide an accurate statistical potential in practice because of the
large number of parameters whose values would need to be
optimized.

Our method for smoothing feature distributions is a general-
ization of the two related methods used in calculating statistical
potentials (Sippl, 1990) and homology restraints (Sali and
Blundell, 1993). Both methods are equivalent to our Bayesian
smoothing method with a diagonal covariance matrix as the
smoothing prior. Their prior distribution is equivalent to the
mean of our prior 8, whereas the weights on their prior distri-
butions are defined by the standard deviation in our covariance
matrix.

In conclusion, our Bayesian framework can be applied to
derive an optimized statistical potential for many other kinds
of modeling problems for which sample structures are available,
thus affording better leverage of the experimentally determined
protein structures. Examples include membrane protein topology
and complexes of proteins with small molecules or peptides.

Funding: NIH grants (GM071790 and GM093342; R01
GM054762 to AS).

Conﬂicts of Interest: none declared.

REFERENCES

Andrusier,N. et al. (2007) FireDock: fast interaction reﬁnement in molecular dock—
ing. Proteins, 69, 1397159.

Audie,J. and Swanson,J. (2012) Recent work in the development and application of
protein—peptide docking. Future Med. Chem, 4, 161971644.

Baker,D. and Sali,A. (2001) Protein structure prediction and structural genomics.
Science, 294, 93796.

 

3164

112 /3.10'srcumofpiqixo"sotJBMJOJutotq//:d11q moi) popcolumoq

91oz ‘Og isanV uo ::

Optimized atomic statistical potentials

 

Benkert,P. et al. (2008) QMEAN: a comprehensive scoring function for model
quality assessment. Proteins, 71, 2617277.

Betancourt,M.R. and Thirumalai,D. (1999) Pair potentials for protein folding:
choice of reference states and sensitivity of predicted native states to variations
in the interaction schemes. Protein Sci, 8, 3617369.

Betancourt,M.R. and Skolnick,J. (2004) Local propensities and statistical potentials
of backbone dihedral angles in proteins. J. Mol Biol, 342, 635$49.

Brenke,R. et al. (2012) Application of asymmetric statistical potentials to antibody—
protein docking. Bioinformatics, 28, 260872614.

Carugo,O. and Argos,P. (1997) Protein—protein crystal—packing contacts. Protein
Sci, 6, 226172263.

Carugo,O. and Argos,P. (1999) Reliability of atomic displacement parameters in
protein crystal structures. Acta Crystallogr. D Biol. Cry.stallogr., 55, 4734178.

Chuang,G.—Y. et al. (2008) DARS (Decoys As the Reference State) potentials for
protein—protein docking. Biophys. J., 95, 421741227.

Colovos,C. and Yeates,T.O. (1993) Veriﬁcation of protein structures: patterns of
nonbonded atomic interactions. Protein Sci, 2, 151171519.

Cossio,P. et al. (2012) A simple and efﬁcient statistical potential for scoring ensem—
bles of protein structures. Sci. Rep., 2, 351.

Cruickshank,D.W. (1999) Remarks about protein structure precision. Acta
Crystallogr. D Biol. Cry.stallogr., 55, 583$01.

Dehouck,Y. et al. (2006) A new generation of statistical potentials for proteins.
Biophys. J., 90, 401041017.

Dill,K.A. and MacCallum,].L. (2012) The protein—folding problem, 50 years on.
Science, 338, 104271046.

Ding,X.—M. et al. (2010) Computational prediction of DNA—protein interactions: a
review. Curr. Comput. Aided Drug Des, 6, 1977206.

Duhovny,D. et al. (2002) Efﬁcient Unbound Docking of Rigid Molecules. In:
Second International Workshop, WABI 2002. pp. 1857200.

Evans,M. and Swartz,T. (2000) Approximating Integrals Via Monte Carlo and
Deterministic Methods. Oxford University Press, New York, USA.

Fan,H. et al. (2011) Statistical potential for modeling and ranking of protein—ligand
interactions. J. Chem. Inf. Model, 51, 307873092.

Fernandez—Recio,J. and Sternberg,M.J.E. (2010) The 4th meeting on the Critical
Assessment of Predicted Interaction (CAPRI) held at the Mare Nostrum,
Barcelona. Proteins Struct. Funct. Bioinform., 78, 306573066.

Ferrada,E. et al. (2007) A knowledge—based potential with an accurate description
of local interactions improves discrimination between native and near—native
protein conformations. Cell Biochem. Biophys, 49, 1117124.

Finkelstein,A.V. et al. (1995) Why do protein architectures have Boltzmann—like
statistics? Proteins, 23, 1427150.

Fiser,A. et al. (2000) Modeling of loops in protein structures. Protein Sci, 9,
175371773.

Fiser,A. and Sali,A. (2003) ModLoop: automated modeling of loops in protein
structures. Bioinformatics, 19, 25002501.

Gao,M. and Skolnick,J. (2008) DBD—Hunter: a knowledge—based method for the
prediction of DNA—protein interactions. Nucleic Acids Res, 36, 39703992.
Gatchell,D.W. et al. (2000) Discrimination of near—native protein structures from
misfolded models by empirical free energy functions. Proteins, 41, 5187534.
Hendlich,M. et al. (1990) Identiﬁcation of native protein folds amongst a large
number of incorrect models. The calculation of low energy conformations

from potentials of mean force. J. Mol Biol, 216, 1677180.

Huang,S.—Y. and Zou,X. (2010) Inclusion of solvation and entropy in the know—
ledge—based scoring function for protein—ligand interactions. J. Chem. Inf.
Model, 50, 2627273.

Hwang,H. et al. (2010) Performance of ZDOCK and ZRANK in CAPRI rounds
13—19. Proteins, 78, 31003110.

Jacobson,M.P. et al. (2004) A hierarchical approach to all—atom protein loop
prediction. Proteins, 55, 3517367.

J ones,D.T. (1999) GenTHREADER: an efﬁcient and reliable protein fold recogni—
tion method for genomic sequences. J. Mol Biol, 287, 7977815.

Joosten,R.P. et al. (2011) A series of PDB related databases for everyday needs.
Nucleic Acids Res, 39, D4117D419.

Kabsch,W. and Sander,C. (1983) Dictionary of protein secondary structure: pattern
recognition of hydrogen—bonded and geometrical features. Biopolymers, 22,
257772637.

Keasar,C. and Levitt,M. (2003) A novel approach to decoy set generation: designing
a physical energy function having local minima with native structure character—
istics. J. Mol. Biol, 329, 1597174.

Kocher,J.P. et al. (1994) Factors inﬂuencing the ability of knowledge—based
potentials to identify native sequence—structure matches. J. Mol Biol, 235,
159871613.

Kouranov,A. et al. (2006) The RCSB PDB information portal for structural
genomics. Nucleic Acids Res, 34, D3027D305.

Krissinel,E. (2010) Crystal contacts as nature’s docking solutions. J. Comput.
Chem, 31, 1337143.

Lensink,M.F. et al. (2007) Docking and scoring protein complexes: CAPRI
3rd Edition. Proteins, 69, 700718.

Li,Y. et al. (2013) Building a knowledge—based statistical potential by capturing
high—order inter—residue interactions and its applications in protein secondary
structure assessment. J. Chem. Inf. Model, 53, 500508.

Liu,Y. and Gong,H. (2012) Using the unfolded state as the reference state improves
the performance of statistical potentials. Biophys. J., 103, 19501959.

Liu,S. and Vakser,I.A. (201 1) DECK: distance and environment—dependent, coarse—
grained, knowledge—based potentials for protein—protein docking. BMC
Bioinformatics, 12, 280.

Lu,H. and Skolnick,J. (2001) A distance—dependent atomic knowledge—based poten—
tial for improved protein structure selection. Proteins, 44, 2237232.

Lu,M. et al. (2008) OPUS—PSP: an orientation—dependent statistical all—atom poten—
tial derived from side—chain packing. J. Mol Biol, 376, 2887301.

Mackay,D.J.C. (2003) Information Theory, Inference, and Learning Algorithms.
Cambridge University Press, Cambridge, UK.

McConkey,B.J. et al. (2003) Discrimination of native protein structures using atom—
atom contact scoring. Proc. Natl Acad. Sci. USA, 100, 32153220.

Melo,F. and Feytmans,E. (1997) Novel knowledge—based mean force potential at
atomic level. J. Mol Biol, 267, 2077222.

Melo,F. et al. (2002) Statistical potentials for fold assessment. Protein Sci, 11,
430448.

Miyazawa,S. and J ernigan,R.L. (1996) Residue—residue potentials with a favorable
contact pair term and an unfavorable high packing density term, for simulation
and threading. J. Mol Biol, 256, 623$44.

Moult,J. et al. (2011) Critical assessment of methods of protein structure prediction
(CASPyround IX. Proteins, 79 (SuppL l), 175.

Murphy,K.P. (2012) Machine Learning: A Probabilistic Perspective. The MIT Press,
Cambridge, Massachusetts, USA.

Neuhauser,C. (2010) Calculus For Biology and Medicine ( 3rd Edition ) ( Calculus for
Ly’e Sciences Series). Pearson, London, UK.

Park,B. and Levitt,M. (1996) Energy functions that discriminate X—ray and near
native folds from well—constructed decoys. J. Mol Biol, 258, 3677392.

Pierce,B. and Weng,Z. (2007) ZRANK: reranking protein docking predictions with
an optimized energy function. Bioinformatics, 1086, 107871086.

Pierce,B.G. et al. (2011) Accelerating protein docking in ZDOCK using an
advanced 3D convolution library. PLoS One, 6, e24657.

Qiu,J. and Elber,R. (2005) Atomically detailed potentials to recognize native and
approximate protein structures. Proteins, 61, 4055.

Rajgaria,R. et al. (2008) Distance dependent centroid to centroid force ﬁelds using
high resolution decoys. Proteins, 70, 9507970.

Rasmussen,C.E. and Williams,C.K.I. (2005) Gaussian Processes for Machine
Learning ( Adaptive Computation and Machine Learning series). The MIT
Press, Cambridge, Massachusetts, USA.

Rata,I.A. et al. (2010) Backbone statistical potential from local sequence—structure
interactions in protein loops. J. Phys. Chem. B, 114, 185971869.

Reva,B.A. et al. (1997) Residue—residue mean—force potentials for protein structure
recognition. Protein Eng., 10, 860876.

Rojnuckarin,A. and Subramaniam,S. (1999) Knowledge—based interaction poten—
tials for proteins. Proteins, 36, 5067.

Rykunov,D. and Fiser,A. (2010) New statistical potential for quality assess—
ment of protein models and a survey of energy functions. BMC
Bioinformatics, 11, 128.

Sali,A. and Blundell,T.L. (1993) Comparative protein modelling by satisfaction of
spatial restraints. J. Mol Biol, 234, 7797815.

Samudrala,R. and Moult,J. (1998) An all—atom distance—dependent conditional
probability discriminatory function for protein structure prediction. J. Mol
Biol, 275, 8957916.

Schneider,T.R. (2000) Objective comparison of protein structures: error—scaled
difference distance matrices. Acta Ccrystallogr. D Biol. Crystallogr, 56, 7147721.

Schneidman—Duhovny,D. et al. (2012) A method for integrative structure determin—
ation of protein—protein complexes. Bioinformatics, 28, 328273289.

Shapovalov,M.V. and Dunbrack,R.L. (2011) A smoothed backbone—dependent
rotamer library for proteins derived from adaptive kernel density estimates
and regressions. Structure, 19, 8440858.

Shen,M.Y. and Sali,A. (2006) Statistical potential for assessment and prediction of
protein structures. Proteins Sci, 15, 250772524.

 

3165

112 /310'srcu1nofpioixo"SOIJBMJOJutotq//:d11q moi) popcolumoq

91oz ‘Og isanV uo ::

G.Q.Dong et al.

 

Simons,K.T. et a]. (1997) Assembly of protein tertiary structures from fragments
with similar local sequences using simulated annealing and Bayesian scoring
functions. J. Mol. Biol., 268, 20%225.

Simons,K.T. et al. (1999) Improved recognition of native—like protein structures
using a combination of sequence—dependent and sequence—independent features
of proteins. Proteins, 34, 82795.

Sippl,M.J. (1990) Calculation of conformational ensembles from potentials of mean
force. An approach to the knowledge—based prediction of local structures in
globular proteins. J. Mol. Biol., 213, 8597883.

Sippl,M.J. (1993) Boltzmann’s principle, knowledge—based mean fields and protein
folding. An approach to the computational determination of protein structures.
J. Comput. Aided Mo]. DeS., 7, 4737501.

Skolnick,J. et al. (2013) Are predicted protein structures of any value for binding site
prediction and virtual ligand screening? Curr. Opin. Struct. Biol., 23, 1917197.

Summa,C.M. et al. (2005) An atomic environment potential for use in protein
structure prediction. J. Mol. Biol., 352, 98(r1001.

Tanaka,S. and Scheraga,H.A. (1975) Model of protein folding: inclusion of short—,
medium—, and long—range interactions. Proc. Natl. Acad. Sci. U. S. A., 72,
380273806.

Vehtari,A. and Lampinen,]. (2002) Bayesian model assessment and comparison
using cross—validation predictive densities. Neural Comput., 14, 243972468.
Wang,K. et al. (2004) Improved protein structure selection using decoy—dependent

discriminatory functions. BMC Struct. Biol., 4, 8.

Wass,M.N. et al. (2011) Challenges for the prediction of macromolecular
interactions. Curr. Opin. Struct. Biol., 21, 38273890.

Xu,B. et al. (2009) An all—atom knowledge—based energy function for protein—DNA
threading, docking decoy discrimination, and prediction of transcription—factor
binding profiles. Proteins, 76, 7187730.

Zhang,C.H.I. et a]. (2004) Accurate and efficient loop selections by the
DFIRE—based all—atom statistical potential. Society, 3917399.

Zhang,J. and Zhang,Y. (2010) A novel side—chain orientation dependent potential
derived from random—walk reference state for protein fold selection and
structure prediction. PLoS One, 5, e15386.

Zhao,F. and Xu,]. (2012) A position—specific distance—dependent statistical
potential for protein structure and functional study. Structure, 20,
111871126.

Zhou,H. and Skolnick,J. (2011) GOAP: a generalized orientation—dependent,
all—atom statistical potential for protein structure prediction. Biophys. J., 101,
204372052.

Zhou,H. and Zhou,Y. (2002) Distance—scaled, finite ideal—gas reference state
improves structure—derived potentials of mean force for structure selection and
stability prediction. Protein Sci., 11, 2714w2726.

Zhu,J. et al. (2008) Refining homology models by combining replica—exchange
molecular dynamics and statistical potentials. Proteins, 72, 117171188.

 

3166

112 /310'S[BIIJDO[pJOJXO"SO11BHIJOJII101q/ﬂdnq 11101} papeolumoq

91oz ‘Og anBnV uo ::

