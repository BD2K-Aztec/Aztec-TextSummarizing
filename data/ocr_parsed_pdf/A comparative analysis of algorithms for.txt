BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

N.D.Roberts et al.

 

a particularly signiﬁcant problem in cancer sequencing, as sub—
clonal variation and sample impurity give rise to mutations at the
same low allelic fractions as aggregations of systematic error.

2 SOMATIC SNV DETECTION

Somatic SNV detection is a preliminary step in most cancer
sequencing projects, feeding into various downstream analyses
addressing the broader goals of cancer genome research. How
successfully the motivating research goals are met depends on the
quality of the mutation set used as input for further work.

Early publications, such as the malignant melanoma cell line
analysis by Pleasance et a]. (2010), relied on independent geno—
type calling of the two samples followed by subtraction of the
normal sample calls from the cancer calls to obtain a candidate
somatic mutation set. However, this ‘subtraction’ method using
standard algorithms for SNV calling in single samples did not
optimize the detection of shared germline polymorphisms by
jointly analysing the two samples, nor were standard genotyping
algorithms designed to detect variants at the low allelic fractions
found in cancer samples.

Four SNV calling algorithms specifically designed for joint
analysis of matched cancerinormal samples are VarScan
(Koboldt et al., 2009, 2012), SomaticSniper (Larson et al.,
2012), JointSNVMix (Roth et al., 2012) and Strelka (Saunders
et al., 2012). We also note the availability of MuTect (Cibulskis
et al., 2013); however, this tool was unpublished at the time of
the comparison presented here.

2.1 Variant calling algorithms

A comparison of the underlying models and methods used by
these four SNV calling algorithms is provided in Supplementary
Table S1. It should be noted that these SNV calling algorithms
do not model aneuploidy or copy number variation, and SNV
calls will be confounded with any such events.

2.1.1 VarScan2 VarScan2 flrst independently analyses pileup
ﬁles from the cancer and normal samples to heuristically call a
genotype at positions achieving certain thresholds of coverage
and quality. If there is a variant base constituting at least the
‘minimum variant frequency’ of all reads (0.20 by default), then
the genotype is called as either heterozygous (variant <75%) or
homozygous variant (variant >75%). Otherwise, the site is
deemed homozygous reference. Then, at positions where these
heuristically determined genotypes do not match in cancer and
normal, a one—tailed Fisher’s exact test is performed on the read
counts. A signiﬁcant result is called somatic if the normal sample
was homozygous reference, or as loss—of—heterozygosity (LOH) if
the normal sample was heterozygous, or unknown if the normal
sample was called homozygous variant and the cancer sample
did not match. VarScan2 can take optional purity estimates for
the cancer and/or normal sample, and will adjust its variant
frequency thresholds accordingly.

2.1.2 SomaticSniper SomaticSniper uses a Bayesian probability
calculation to estimate the posterior probability of each possible
joint genotype across the normal and cancer samples given the
data observed and prior genotype likelihoods based on the ref—
erence sequence, sequencing error rate, population mutation rate

and somatic mutation rate. Each site is given a ‘somatic score’
(S), a phred—scaled posterior probability that the cancer and
normal genotypes are the same.

2.1.3 JointSNVMix2 JointSNVMix is based on a different
Bayesian approach using a mixed binomial model. The model
considers each site across the two samples to have one of nine
joint genotypes possible after reducing the bases to ‘A’ for a
reference and ‘B’ for a variant base. The set of joint genotypes
across all sites is considered to have a multinomial distribution
whose parameters have a Dirichlet prior with trained hyper—par—
ameters. At each site, the number of reads supporting the refer—
ence base in cancer and normal is considered to have a binomial
distribution. The binomial probability parameter is modelled
from a beta prior with trained hyper—parameters, conditional
on the joint genotype.

First, the hyper—parameters of the multinomial and binomial
distributions are trained by expectation maximization over a
subset of the data, using set default values as priors. Then, the
posterior probability of each joint genotype is calculated at each
site. The basic model, JointSNVMixl, assumes the data have
perfect base calls and alignment, whereas the extended model,
J ointSNVMix2 (J SM2), weighs each read by base and mapping
quality.

2.1.4 Strelka Strelka performs an initial realignment around
indels in the normal and cancer BAM ﬁles, then uses a complex
set of calculations, again based on a Bayesian probability model,
to report the most likely genotype at candidate sites along with
the phred—scaled joint probability of the most likely normal
sample genotype and the event of any somatic mutation in the
cancer sample. The normal sample allele frequencies are mod—
elled as diploid genotypes with a noise term to factor in sequen—
cing and mapping errors, whereas the cancer sample allele
frequencies are modelled as a mixture of the normal sample
and somatic variation at any frequency. The exact details of
the model, which are too numerous to describe here, take into
account base and mapping qualities, strand bias, the prior prob—
ability of any site being a somatic mutation and the expected rate
of heterozygosity in the normal sample.

2.2 Filtering candidate SNV sites

These somatic SNV calling algorithms use a variety of informa—
tion to calculate a somatic probability score for each candidate
site returned. However, the full complexity of noise present in
any DNA sequencing dataset is not typically considered during
SNV calling, so raw output sets of candidate SNV sites typically
require ﬁltering to remove likely false positives.

Koboldt et a]. (2012) recommended various fllters addressing
the quality of variant bases at candidate sites, including within—
read position, extreme strand bias, ﬂanking homopolymer motifs
and low mapping quality. Larson et a]. (2012) recommended
filtering on the basis of strand bias, mapping quality, proximity
to read ends, proximity to indels, nearby homopolymers, nearby
SNVs and depth. Unlike the other algorithms that solely provide
SNV calling capability, Strelka has its own inbuilt post—calling
filter for sites with extremely high depth indicative of over—map—
ping to repetitive sequences; reads with too many mismatches to
the reference; and the presence of spanning deletions mapped

 

2224

ﬁm'spzumofpmjxo'sopeuuopnorq/ﬁdnq

55,2\Ewogmoddmmowoio~&o:~=£¢o~m\

0.00 0.25 0.50 0.75 1.00

0.8 1.0

0.6

0.4

 

 

Analysis of algorithms for somatic SNV detection in cancer

 

1.0

<>l>

D\D/u——-U_

Proportion of sites in dbSNP
0 0 0 2 0 4 O 6 0 8

—e— VarScan

—A— SomaticSniper 0
—e— JSM2

-EI- Strelka

400 300 200 100 0

Number of top candidate sites

Fig. 5. Proportion of somatic candidates present in dbSNP as the prob-
ability score threshold of each caller is increased to 1.0 and the number of
candidate sites reduces

while of J SM2’s top 124 candidates, 78 were not returned by any
other caller. Strelka’s top 30 candidate sites included 25 returned
by the other three callers with probability 1.00, except for two
sites below a 20% variant frequency missed completely by
VarScan. The five sites given 1.00 somatic probability by
Strelka but not returned at any probability level by the other
three algorithms were low—allelic—fraction candidates with variant
proportion in the normal sample from 0.0 to 1.5% and in the
cancer sample from 2.4 to 5.5%.

Figure 5 illustrates the proportion of somatic sites present in
dbSNP as the output sets are reduced to their top calls.
Candidate somatic mutation sites found in dbSNP are sometimes
interpreted as germline polymorphism false positives (Roth et al.,
2012), or sites of common sequencing error contaminating the
database. This is not always true, as some sites within dbSNP
have validated as true—positive somatic mutations in cancer.
While no particular site should be removed as a false positive
solely on the basis of a dbSNP entry, the overall proportion of
sites in dbSNP should still be a valid indicator of the comparative
number of germline false positives in different output sets. When
considering more than 100 candidates, VarScan appears to be the
worst offender with ~80% constituency of dbSNP compared
with SomaticSniper ~60% and JSM2 ~50%. This vastly im—
proves within the top set of 22 VarScan somatic candidates
and mildly improves within the top set of 49 SomaticSniper can—
didates. As JSM2 considerably overestimates its somatic prob—
ability scores, its top tier of somatic calls can not be reduced to
any <124, and no improvement is seen. In contrast, only ~20%
of Strelka’s candidate sites at any probability cut—off are present
in dbSNP, indicating Strelka is not as prone to returning germ—
line polymorphisms. Rather, Strelka’s false positives may tend to
be the result of sequencing errors.

The characteristics of somatic candidates uniquely returned by
each caller are illustrated by Figure 6. Each set of sites returned
solely by one caller was sorted by variant proportion in the
cancer sample. Then the variant proportion in the cancer

1.0

0.4 0.6 0.8

 

Proportion of most common variant base
0.0 0.2

0.0 0.2 0.4 0.6 0.8 1.0

Scaled index
Fig. 6. The proportion of total depth contributed by the most common
variant base in the cancer (smooth lines) and normal (jagged lines) for
somatic sites uniquely returned by VarScan (red), SomaticSniper (green),
JSM2 (orange) and Strelka (blue). The horizontal axis is the scaled index
of each site after sorting by variant proportion in the cancer (scaled index
chosen for comparisons across different sample sizes)

(smooth lines) and normal sample (jagged lines) were plotted
against the scaled index of each site.

VarScan’s default algorithm design returns somatic candidates
if, for variant bases above 15 in quality, the cancer variant pro—
portion is between 20 and 75% and the normal variant propor—
tion is outside this range. Although obscured to some extent in
Figure 6, which plots the proportion of all variant bases not just
those above 15 in quality, it is apparent that sites uniquely re—
turned by VarScan are those at which the variant proportion in
the normal sample falls slightly below 20% (and above in the
cancer sample). The vast majority of unique VarScan candidates
had a strong variant signal in both samples, again suggesting a
tendency for VarScan to return germline polymorphism false
positives.

SomaticSniper shows a distinctive discretized quality in its
cancer variant proportions, explained by the low depth at most
sites uniquely found by SomaticSniper. Unlike the other callers,
SomaticSniper had no lower bound for the depth of its candidate
sites, and 70% of the candidates unique to SomaticSniper had
depths in the cancer sample below 12. At low depths, variant
allele frequencies can only occur at certain discrete levels, largely
explaining the pattern in Figure 6. While the sites at the discre—
tized variant frequencies and low depths appear to have no cor—
responding variant signal in the normal sample, yielding the
result that 71% of sites unique to SomaticSniper have no variant
signal in the normal, SomaticSniper’s output also contained
unique sites at higher depths with variant signals in evidence
from both samples, constituting likely germline polymorphism
false positives.

JSM2 uniquely returned low—allelic—fraction candidates with
variant proportions in the cancer ~$20%, but variant signals
in the normal sample were also present at 75% of these sites.
Half of the candidates unique to J SM2 had depths in the cancer

 

2227

ﬁm'spzumoipmjxo'sopauuopnorq/ﬁdnq

N.D.Roberts et al.

 

sample above 90. This suggests a possible weakness of JSM2:
that at high depths of sequencing, a statistically signiﬁcant dif—
ference between variant proportions in the two samples is more
likely, regardless of the biological signiﬁcance.

Strelka appears tuned to detect even lower allelic fractions, as
its unique calls have variant proportion in the cancer around 5%.
In contrast to JSM2, 72% of Strelka’s unique output had no
variant base in the normal sample.

3.4 Non-cancer exomes

For each of two exomes sequenced to high depth from non—can—
cerous samples, we twice randomly split the BAM ﬁle in half and
applied the somatic calling algorithms to these matched normali
normal samples to return purely false—positive candidate sets.
After applying the previously described post—calling ﬁlters, the
number of false—positive sites output by all four algorithms in the
four cases were 5, 7, 10 and 11. On inspection, these 33 false
positives were seemingly indistinguishable from some of the som—
atic candidates identified in the cancer samples, with depths ran—
ging from 10 to 73 and most having somatic probability scores
above 0.90.

4 CONCLUSIONS AND FUTURE PERSPECTIVES

Comparing the candidate SNV sets returned by VarScan,
SomaticSniper, JSM2 and Strelka revealed substantial differ—
ences as to the number and character of sites returned; the som—
atic probability scores assigned to the same sites; their
susceptibility to various sources of noise; and in their differing
sensitivities to candidate mutations at a low allelic fraction.

4.1 LOH candidates

All four algorithms return candidate LOH events implying loss
of variation in the cancer sample. The term typically implies a
deletion event, but duplication events also register as LOH can—
didates when a previously 1:1 heterozygous signal shifts to a 2:1
signal in the duplicated region. LOH candidates may also arise
from somatic mutations present in the ‘normal’ cell sample that
were never present as germline polymorphisms in the general cell
population of the individual.

Given these confounding factors, the LOH candidates re—
turned by these tools are not, by themselves, a strong indication
of actual LOH. These SNV calling algorithms have not been
optimized to detect LOH regions, and merely give the output
as a by—product of their main purpose. Regions with a relatively
high frequency of LOH candidates may indicate real copy
number variation, but these should be investigated by alternative
means like aCGH.

After ﬁltering, the proportion of LOH candidates in the
output from each algorithm was ~50% for JSM2, 40% for
VarScan and 10% for SomaticSniper and Strelka. As regions
of interest with relatively high frequency of LOH candidates
are still identifiable in smaller output sets, and as the LOH can—
didates assigned the highest probability scores by VarScan also
tend to be returned by SomaticSniper and, to a slightly lesser
extent, by Strelka as well, no obvious benefit is gained in using
VarScan or JointSNVMix to return greater numbers of LOH
candidates.

4.2 Somatic candidates

The main purpose of the four algorithms analysed here is the
detection of candidate somatic SNV sites purporting gain of
variation in the cancer sample. A core group of sites was identi—
fied by all algorithms at high probabilities, though given the
identiﬁcation of a few similar sites within the non—cancerous
exomes, false positives are likely to be included even in this
common set. Beyond this core group, there were marked differ—
ences in the probability scores assigned to the same sites and in
the characteristics of sites returned by one algorithm only.

VarScan (Koboldt et al., 2009, 2012) has the advantage that its
top set of somatic candidate sites are convincing mutations with
high concordance with other callers. However, aside from these
relatively clearcut candidates identiﬁed by all calling algorithms,
VarScan’s output at lower probability thresholds appear inun—
dated by germline polymorphism false positives, an understand—
able consequence of VarScan’s algorithm design. By
automatically classifying sites with 20775% variant frequency
as heterozygous and sites just outside these thresholds as homo—
zygous, any germline polymorphism that, by chance and the
vagaries of sequencing bias, registers either side of these cut—
offs in the two samples becomes a candidate for Fisher’s test.
At reasonably high depth, even a small difference in variant
proportions can achieve statistical signiﬁcance, regardless of bio—
logical significance. Aside from the high rate of germline false
positives, the other major drawback to VarScan is its inability to
detect low—allelic—fraction candidates below its minimum variant
frequency for heuristic genotyping. We used the default settings
with the lower bound of 20% and thus VarScan failed to return
even the most convincing mutations below this level. Given the
paucity of convincing candidates returned by VarScan that
would not also be returned by SomaticSniper or Strelka at
high probability, we conclude little beneﬁt is gained in running
VarScan as opposed to these other algorithms.

SomaticSniper (Larson et al., 2012) has no minimum depth
requirements and thus is liable to return a unique set of candi—
dates at the low depths that surround target regions in an exome
capture assay. If desired, it would be a simple matter to add an
additional post—calling ﬁlter for minimum depth. Apart from
those sites identiﬁed at low depths in the exome sample, other
sites uniquely found by SomaticSniper tended to be mutations
with a 10730% allelic fraction. As a means of generating a var—
iety of candidate SNV sites without any particular drawbacks,
SomaticSniper is a practical and credible program, though its
results should by no means be interpreted as constituting an
inherently true mutation prof11e.

JSM2 (Roth et al., 2012), in its current implementation, is
extremely inconvenient to use. Unlike the other algorithms,
which only output sites of interest above particular, customizable
thresholds, JSM2 includes a line in the output file for every single
site in the input BAM files regardless of their somatic or LOH
probability scores. This high volume of output is unnecessarily
awkward for exome data and impracticable for whole genome
data. Not only are the training and classifying steps of JSM2
considerably slower than either SomaticSniper or Strelka, but
it is also left up to the user to develop a reasonable method for
extracting the candidate sites. Even after the raw output was
pared back to genuine sites of interest, JSM2’s candidates had

 

2228

ﬁm'spzumoipmjxo'sopauuopnorq/ﬁdnq

Analysis of algorithms for somatic SNV detection in cancer

 

the lowest pass rate through ﬁlters to remove sequencing error
and then after that were found to have 50% constituency in
dbSNP. These results suggest J SM2 candidates are vulnerable
to false positives from both sequencing error and germline
polymorphisms. Furthermore, JSM2 vastly overestimates the
somatic probabilities assigned to each site, such that a small
set of the highest ranking candidates can not be derived. This
problem would be overcome by lowering the prior parameter
for expected rate of somatic mutation, but in this analysis,
only the default settings were considered. The sites uniquely re—
turned by J SM2 have a $20% allelic fraction in the cancer, with
the majority having only slightly lower variant signals in the
normal sample. We suggest that the extra sites identiﬁed by
JSM2 do not, on current evidence, include enough convincing
candidates to outweigh the inconvenience of its unwieldy
implementation.

Strelka (Saunders et al., 2012) is a computationally efficient
program that returns a much smaller output set of candidates
than the other algorithms. Some Strelka calls with probability
scores of 0.0 and 0.2 overlapped with high probability output
from other callers, so all Strelka sites were considered valid
candidates for analysis, regardless of probability score. The
sites uniquely found by Strelka were low—allelic—fraction
mutations ~5% variant frequency in the cancer. Given the clin—
ical importance of subclonal mutations with drug resistant cap—
ability, Strelka is a valuable tool for identifying candidate
mutations below the detection level of other algorithms, without
returning an excessive number of dubious results. Strelka also
identifies the same high—probability clonal—type mutations as the
other algorithms. Of the four algorithms investigated here, we
consider Strelka and SomaticSniper to be the best overall
performers.

Although all designed for the same, conceptually simple, task
of identifying candidate somatic SNV sites in matched canceri
normal sequencing data, the complexity of the systematic noise
permeating sequencing data affects each algorithm in different
ways. In practice, many cancer sequencing projects have relied
on one SNV calling pipeline to generate candidates. The poor
consensus between different algorithms beyond a small group of
clearcut candidates suggests extreme care is needed to prevent
over—interpreting any one output set as being intrinsically repre—
sentative of the true mutation proﬁle. Using two algorithms with
different vulnerabilities to error that appear ‘tuned’ to detect
different types of candidates is likely to provide a signiﬁcant
reduction in false negatives, at the cost of returning more false
positives. However, as post—calling ﬁlters can be designed to
remove as many unconvincing candidates as desired, the beneﬁts
of seeking alternative candidate sites from different algorithms
still hold.

Given the significant differences and contradictions in the
output returned by each SNV calling algorithm, extreme caution
should be applied when interpreting their somatic probability
scores, choosing sites for subsequent analysis, and reporting re—
sults. Over—interpreting the output from any one SNV calling
algorithm as being the closest possible estimation to the real
set of somatic SNVs risks the inclusion of errors that algorithm
is vulnerable to, and the omission of real mutation identiﬁable by
different algorithm designs.

4.3 Filters, ranking and assessment of candidate sites

Candidate SNV sets are typically filtered to remove multiple in—
dicators of sequencing error. Incorporating a knowledge of the
sequencing platform’s error proﬁle after initial SNV calling,
rather than including it as part of the calling algorithm, allows
the basic calling algorithms to remain relevant for various iter—
ations of the sequencing technology. As the error proﬁles of
DNA sequencing platforms rapidly shift with every technical
upgrade, it makes more sense to continually update a set of
best—practice ﬁlters than redesign the calling algorithms every
year. Having said this, there is currently no best—practice filtering
method commonly agreed with.

Aside from the six features we used for ﬁltering (strand bias,
nearby SNVs, spanning deletions, adjacent indels, variant base
and mapping qualities), some other ﬁlters recommended in the
literature include within—read position and the presence of par—
ticular surrounding sequence motifs (Koboldt et al., 2012;
Larson et al., 2012; Meacham et al., 2011; Nakamura et al.,
2011). Errors are known to accumulate in and around homopo—
lymers, inverted repeats and G—rich motifs such as GGT and
GGC, so these would be ideal inclusions in a best—practice ﬁlter—
ing design for Illumina data. The simplest and most accessible
method of ﬁltering is the independent deﬁnition of set cut—offs
for different features dictating the inclusion or exclusion of each
site. However, as more error features are described and included
in ﬁltering, this simple method becomes less appropriate. For
example, while it may be reasonable to require a certain min—
imum mapping quality for every candidate, it would not be rea—
sonable to remove every candidate site following a GG motif,
even though this too has been strongly associated with error. A
more sophisticated method of filtering out likely false positives
would be the joint consideration of multiple error indicators
(including surrounding motifs) in the deﬁnition of a classiﬁcation
or probability recalibration rule reﬂecting the gamut of features
known to correlate with error. Training such a rule requires an
extensive set of validated true— and false—positive SNV candidates
within data from the sequencing platform of interest, so is most
practical at large sequencing centres.

Metrics used to gauge the quality of candidate sites after fil—
tering include the proportion of sites in dbSNP or HapMap to
assess germline polymorphism false positives, and pass rate
through filters to assess sequencing error false positives. In gen—
eral, such metrics are difﬁcult to interpret because a low rate of
one false—positive type may imply either a high true—positive rate
or a high false—positive rate of the other type. Another metric
often used to assess candidate SNV sets is their transitionitrans—
version ratio, under the assumption that departure from the
observed TiiTv ratios of SNPs in normal genomes indicates con—
tamination from sequencing error false positives. However, the
many reports of cancers presenting with transitionitransversion
ratios signiﬁcantly different from the typical levels within non—
cancerous genomes (Liu et al., 2002; Oki et al., 2009; Yang et al.,
2003), coupled with the fact that germline polymorphism false
positives naturally correspond to the standard ratios, suggest the
transitionitransversion ratio is a poor metric for assessing can—
cerous somatic mutations.

Although deletion and duplication events confound the search
for SNV candidates, at present these SNV calling algorithms

 

2229

ﬁm'spzumoipmjxo'sopauuopnorq/ﬁdnq

N.D.Roberts et al.

 

only model diploid variation. Information on copy number vari—
ation from aCGH or other methods should be kept in mind
when interpreting output from SNV calling algorithms.

4.4 Understanding the molecular basis of cancer

Cancer genome projects seek to identify mutations of therapeutic
or biological interest, and to correlate mutation proﬁles with
treatment outcomes for the development of personalized medi—
cine and improved cancer survival rates. Somatic SNVs are an
integral part of the mutational landscape, and, with an under—
standing of their relative strengths and weaknesses, a logical se—
lection of multiple SNV calling algorithms should be used to
offset their individual quirks and reduce the number of false
negatives. As extensive validation experiments are often imprac—
tical, post—calling ﬁlters designed to remove sequencing and ana—
lysis errors can reduce the burden of excessive candidates as
much as required before further investigation.

Although some number of false positives is inevitable in any
candidate mutation set, if the patient cohort is large enough,
relevant and actionable mutations will be ultimately identiﬁed
by their recurrence in multiple patients. This is slightly con—
founded by the presence of systematic sequencing errors accu—
mulating at susceptible genomic positions across different
sequencing samples, but these should balance out between pa—
tients with different clinical outcomes and have little effect on
correlation analysis. However, for rare cancer subtypes for which
large patient cohorts are difﬁcult to recruit, additional validation
steps may be needed to prevent false positives contaminating the
data and obfuscating the associations between mutational pro—
ﬁles and clinical outcomes.

Funding: National Health and Medical Research Council of
Australia (1027531 to S.B., H.S.S. and D.L.A., and fellowship
1023059 to H.S.S.).

Conﬂict of Interest: none declared.

REFERENCES

Cibulskis,K. et ul. (2013) Sensitive detection of somatic point mutations in impure
and heterogeneous cancer samples. Nut. Biotecli., 31, 2137219.

Ding,L. et ul. (2010) Analysis of next—generation genomic data in cancer: accom—
plishments and challenges. Hum. Mol. Genet., 19, R1887R196.

Dohm,J.C. et ul. (2008) Substantial biases in ultra—short read data sets from high—
throughput DNA sequencing. Nucleic Acids Res, 36, e105.

Gundry,M. and Vijg,J. (2012) Direct mutation analysis by high—throughput sequen—
cing: From germline to low—abundant, somatic variants. Mutut. Res, 729, 1715.

Koboldt,D.C. et ul. (2009) VarScan: variant detection in massively parallel sequen—
cing of individual and pooled samples. Bioinformutics, 25, 228372285.

Koboldt,D. et ul. (2012) VarScan 2: Somatic mutation and copy number alteration
discovery in cancer by exome sequencing. Genome Res, 22, 5687576.

Larson,D.E. et ul. (2012) SomaticSniper: identiﬁcation of somatic point mutations
in whole genome sequencing data. Bioiiy’ormutics, 28, 3117317.

Lee,A.J. and Swanton,C. (2012) Tumour heterogeneity and drug resistance:
Personalising cancer medicine through functional genomics. Biocliem.
Plturmucol., 83, 101371020.

Liu,S. et ul. (2002) Genetic instability favoring transversions associated with ErbB2—
induced mammary tumorigenesis. Proc. Nut] Acuil. Sci. USA, 99, 377(k3775.

Loeb,L.A. (2011) Human cancers express mutator phenotypes: origin, consequences
and targeting. Nut. Rev. Cancer, 11, 45(k457.

Meacham,F. et ul. (2011) Identiﬁcation and correction of systematic error in high—
throughput sequence data. BMC Bioinformutics, 12, 451.

Meyerson,M. et ul. (2010) Advances in understanding cancer genomes through
second—generation sequencing. Nut. Rev. Genet., 11, 685%96.

Nakamura,K. et ul. (2011) Sequence—speciﬁc error proﬁle of Illumina sequencers.
Nucle‘w Acids Res, 39, e90.

Oki,E. et ul. (2009) The difference in p53 mutations between cancers of the upper
and lower gastrointestinal tract. Digestion, 79, 33739.

Pleasance,E.D. et ul. (2010) A comprehensive catalogue of somatic mutations from
a human cancer genome. Nature, 463, 1917196.

Roth,A. et ul. (2012) JointSNVMix: a probabilistic model for accurate detection of
somatic mutations in normal/tumour paired next—generation sequencing data.
Bioinfommtics, 28, 9077913.

Salk,J.J. et ul. (2010) Mutational heterogeneity in human cancers: origin and con—
sequences. Annu. Rev. Put/10]., 5, 51775.

Saunders,C.T. et ul. (2012) Strelka: accurate somatic small—variant calling from
sequenced tumorinormal sample pairs. Bioinformutics, 28, 181171817.

Yang,Z. et ul. (2003) Likelihood models of somatic mutation and codon substitu—
tion in cancer genes. Genetics, 165, 6957705.

 

2230

ﬁm'spzumoipmjxo'sopauHOJmorq/ﬁdnq

