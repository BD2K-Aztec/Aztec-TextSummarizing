Bioinformatics, 3117), 2015, 1034—1043

doi: 10.1093/bioinformatics/btu766

Advance Access Publication Date: 18 November 2014
Original Paper

 

Systems biology

HyDRA: gene prioritization via hybrid
distance-score rank aggregation

Minji Kim*, Farzad Farnoud and Olgica Milenkovic

Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana,
IL 61801, USA

*To whom correspondence should be addressed.
Associate Editor: Jonathan Wren

Received on June 2,2014; revised on October 26, 2014; accepted on November 13, 2014

Abstract

Summary: Gene prioritization refers to a family of computational techniques for inferring disease
genes through a set oftraining genes and carefully chosen similarity criteria. Test genes are scored
based on their average similarity to the training set, and the rankings of genes under various simi—
larity criteria are aggregated via statistical methods. The contributions of our work are threefold: (i)
first, based on the realization that there is no unique way to define an optimal aggregate for rank—
ings, we investigate the predictive quality of a number of new aggregation methods and known
fusion techniques from machine learning and social choice theory. Within this context, we quantify
the influence of the number oftraining genes and similarity criteria on the diagnostic quality of the
aggregate and perform in—depth cross—validation studies; (ii) second, we propose a new approach
to genomic data aggregation, termed HyDRA (Hybrid Distance—score Rank Aggregation), which
combines the advantages of score—based and combinatorial aggregation techniques. We also pro—
pose incorporating a new top—versus—bottom (TvB) weighting feature into the hybrid schemes. The
TvB feature ensures that aggregates are more reliable at the top of the list, rather than at the
bottom, since only top candidates are tested experimentally; (iii) third, we propose an iterative pro—
cedure for gene discovery that operates via successful augmentation ofthe set oftraining genes by
genes discovered in previous rounds, checked for consistency.

Motivation: Fundamental results from social choice theory, political and computer sciences, and
statistics have shown that there exists no consistent, fair and unique way to aggregate rankings.
Instead, one has to decide on an aggregation approach using predefined set of desirable properties
for the aggregate. The aggregation methods fall into two categories, score— and distance—based
approaches, each of which has its own drawbacks and advantages. This work is motivated by the
observation that merging these two techniques in a computationally efficient manner, and by
incorporating additional constraints, one can ensure that the predictive quality of the resulting
aggregation algorithm is very high.

Results: We tested HyDRA on a number of gene sets, including autism, breast cancer, colorectal
cancer, endometriosis, ischaemic stroke, leukemia, lymphoma and osteoarthritis. Furthermore, we
performed iterative gene discovery for glioblastoma, meningioma and breast cancer, using a se—
quentially augmented list of training genes related to the Turcot syndrome, Li—Fraumeni condition
and other diseases. The methods outperform state—of—the—art software tools such as ToppGene and
Endeavour. Despite this finding, we recommend as best practice to take the union of top—ranked
items produced by different methods for the final aggregated list.

Availability and implementation: The HyDRA software may be downloaded from: http://web.
engr.illinois.edu/~mkim158/HyDRA.zip

(C7 The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com

 

1034

/310‘sreumo[p10}xo‘sopeuHOJHtotq/ﬁdnq

Gene prioritization via HyDRA

1035

 

Contact: mkim158@i||inois.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

Identification of genes that predispose an individual to a disease is a
problem of great interest in medical sciences and systems biology
(Adie et al., 2006). The most accurate and powerful methods used
for identification are experimental in nature, involving normal and
disease samples (Cardon et al., 2001). Experiments are time con—
suming and costly, complicated by the fact that typically, multiple
genes have to be jointly mutated to trigger the onset of a disease.
Given the large number of human genes (225 000), testing even rela—
tively small subsets of pairs of candidate genes is prohibitively ex—
pensive (Risch and Merikangas, 1996).

To mitigate this issue, a set of predictive analytical and computa—
tional methods have been proposed under the collective name gene
prioritization techniques. Gene prioritization refers to the complex
procedure of ranking genes according to their likelihoods of being
linked to a certain disease. The likelihood function is computed
based on multiple sources of evidence, such as sequence similarity,
linkage analysis, gene annotation, functionality and expression ac—
tivity, gene product attributes—all determined with respect to a set
of training genes.

A wide range of tools has been developed for identifying genes
involved in a disease (Kohler et al., 2008; Kolde et al., 2012; Pihur
et al., 2009), as surveyed (Tiffin et al., 2006). Existing software in—
cludes techniques based on network information, such as GUILDify
(Guney et al., 2014) and GeneMANIA (Warde—Farley et al., 2010),
data mining and machine learning—based approaches as described in
(Perez-Iratxeta et al., 2002), POCUS (Turner et al., 2003) SUSPECTS
(Adie et al., 2006) and (Yu et al., 2008), and methods using statistical
analysis, including Endeavour (Aerts et al., 2006; De Bic et al., 2007),
ToppGene (Chen et al., 2009) and NetworkPrioritizer (Kacprowski
et al., 2013). Here, we focus on statistical approaches coupled with
new combinatorial algorithms for gene prioritization, and emphasize
one aspect of the prioritization procedure: rank aggregation.

The problem of aggregating rankings of distinct objects or enti—
ties provided by a number of experts, voters or search engines has a
rich history (Fishburn, 1970). One of the key findings is that various
voting paradoxes arise when more than three candidates are to be
ranked: it is frequently possible not to have a candidate that wins all
pairwise competitions (the Condorcet paradox) and it is theoretic—
ally impossible to guarantee the existence of an aggregate solution
that meets certain predefined set of criteria [such as those imposed
by Arrow’s impossibility theorem (Fishburn, 1970)]. These issues
carry over to aggregation methods used for gene discovery, and as a
result, the rank—ordered lists of genes heavily depend on the particu—
lar aggregation method used.

Two families of methods have found wide applications in rank
aggregation: combinatorial methods (including score— and distance—
based approaches) (Kemeny, 1959) and statistical methods. In the
bioinformatics literature, the aggregation methods of choice are stat—
istical in nature, relying on pre—specified hypotheses to evaluate the
distribution of the gene rankings. One of the earliest prioritization
softwares, Endeavour, uses the Q—statistics for multiple significance
testing, and measures the minimum false discovery rate at which a
test may be called significant. In particular, rankings based on differ—
ent similarity criteria are combined via order statistics approaches.
For this purpose, one uses the rank ratio (normalized ranking) of a

gene g for m different criteria, r1(g).. . ..rm (g) and recursively com—
putes the Q—value, defined as

r1(3) r2(3) rm(g)
Qi<r1<g>.....rm<g>> : m] j .. dads. . . «it.
0 $1 Smrl

Post—processed Q—values are used to create the resulting ranking
of genes. The drawbacks of the method are that it is based on a null
hypothesis that is difficult to verify in practice, and that it is compu—
tationally expensive, as it involves evaluating an m—fold integral. To
enable efficient scaling of the method, Endeavour resorts to approxi—
mating the Q—integral. The influence of the approximation errors on
the final ranking is hard to assess, as small changes in scores may re—
sult in significant changes of the aggregate orderings.

Likewise, ToppGene uses a well—known statistical approach,
called the Fisher x2 method. It first determines the p—values of
similarity score indexed by /, denoted by p(/), for j : 1.. . ..m. The
p—values are computed through multiple preprocessing stages,
involving estimation of the information contents (i.e. weights) of
annotation terms, setting—up a similarity criteria based on Sugeno
fuzzy measures (i.e. non—additive measures) (Popescu et al., 2006 ),
and performing meta—testing. The use of fuzzy measures ensures that
all similarities are non—negative. Then, under the hypothesis of
independent tests, ToppGene uses Fisher’s inverse x2 result, stating

that —ZZ:1logp(/) —> X2(2m). Here, x2 (2m) stands for the chi—

square distribution with 2 in degrees of freedom. The result is
asymptotic in nature, and based on possibly impractical independ—
ence assumptions.

A number of methods, and additive scoring methods in particu—
lar, have the drawback that they tacitly or implicitly rely on the as—
sumption that (i) only the total score matters, and the balance
between the number of criteria that highly ranked the gene and
those that ranked it very low is irrelevant. For example, outlier rank—
ings may reduce the overall ranking of a gene to the point that it is
not considered a disease gene candidate, while the outlier itself may
be a problematic criterion. To illustrate this observation, consider a
gene that was ranked lst, 2nd, lst, 20th by four criteria. At the
same time, consider another gene that was ranked 6th by all four cri—
teria. It may be unclear which of these two genes is more likely to be
involved in the disease, given that additive score methods would
rank the two genes equally (as one has (1 +2+1 +20)/4:6).
Nevertheless, it appears reasonable to assume that the first candi—
date is a more reliable choice for a disease gene, as it had a very high
ranking for three out of four criteria; and (ii) no distinction is made
about the accuracy of ranking genes in any part of the list; i.e. the
aggregate ranking has to be uniformly accurate at the top, middle
and bottom of the list. Clearly, neither of the two aforementioned
assumptions is justified in the gene prioritization process: there are
many instances where genes similar only under a few criteria (such
as sequence similarity or linkage distance) are involved in the same
disease pathway. Furthermore, as the goal of prioritization is to pro—
duce a list of genes to be experimentally tested, only the highest
ranked candidate genes are important and should have higher accur—
acy than other genes in the list. In addition, most known aggregation
methods are highly sensitive to outliers and ranking errors.

We propose a new approach to gene prioritization by introduc—
ing a number of novel aggregation paradigms, which we collectively

[310'sp2umofp105xo'sopeuHOJIItotq/ﬁdnq

1036

M.Kim et al.

 

refer to as HyDRA (Hybrid Distance—score Rank Aggregation). The
gist of HyDRA is to combine combinatorial approaches that
have universal axiomatic underpinnings with statistical evidence
pertaining to the accuracy of individual rankings. Our preferred
distance measure for combinatorial aggregation is the Kendall
distance (Kendall, 1938), which counts the number of pairwise
disagreement between two rankings, and was axiomatically postu—
lated by Kemeny (1959). The Kendall distance is closely related to
the Kendall rank correlation coefficient (Dwork et al., 2001;
Kendall, 1948). As such, it has many properties useful for gene
prioritization, such as monotonicity, reinforcement and Pareto
efficiency (Thanassoulis, 2001). The Kendall distance can be
generalized to take into account positional relevance of items, as
was done in our companion article (Farnoud et al., 2012, 2014).
There, it was shown that by assigning weights to pairs of positions
in rankings, it is possible to (i) eliminate negative outliers from the
aggregation process, (ii) include quantitative data into the aggregate
and (iii) ensure higher accuracy at the top of the ranking than at the
bottom.

The contributions of this work are threefold. First, we introduce
new weighted distance measures, where we compute the weights
based on statistical evidence of a function of the difference between
p—values of adjacently ranked items. Aggregation weights based on
statistical evidence improve the accuracy of the combinatorial aggre—
gation procedure and make them more robust to estimation errors.
Second, we describe how to scale the weights obtained based on
statistical evidence by a decreasing sequence of TvB (Top versus
Bottom) multipliers that ensure even higher accuracy at the top of
the aggregated list. As aggregation under the Kendall metric is
NP—hard (Non—deterministic Polynomial—time hard) (Bartholdi et al.,
1989), and the same is true of the weighted Kendall metric, we
propose a 2—approximation method that is stable under small per—
turbations. Aggregation is accomplished via weighted bipartite
matching, such as the Hungarian algorithm and derivatives thereof
(Kuhn, 1955). Third, we test HyDRA within two operational scen—
arios: cross—validation and disease gene discovery. In the former
case, we assess the performance of different hybrid methods with re—
spect to the choice of the weighting function and different number
of test and training genes. In the latter case, we adapt aggregation
methods to gene discovery via a new iterative re—ranking procedure.

2 Systems and methods

In our subsequent exposition, we use Greek lower case letters to
denote complete linear orders (permutations), and unless explicitly
mentioned otherwise, our findings also hold for partial (incomplete)
permutations. Latin lower case letters are reserved for score
vectors or scalar scores, and which of these entities we refer to will
be clear from the context. The number of test genes equals n,
while the number of similarity criteria equals m. Throughout the
article, we also use [k] to denote the set {1.. . .. k} and Sn to denote
the set of all permutations on n elements—the symmetric group of
order nl.

For a permutation 0' : (a(1).. . .. a(n)), the rank of element i in
a, rank,,(i), equals a_1(i), where 0‘1 denotes the inverse permuta—
tion of a. For a vector of scores x :  E R“, ax represents a
permutation describing the scores in decreasing order, i.e.
ax(i) : argmaxkET‘xUz), where T, is defined recursively as
T; : Ti_1\0'X(i), with To :  For example, if x:(2.5, 3.8, 1.1,
0.7), then ax : (2.1.3.4). Note that if p is a vector of p—values,

higher scores are associated with smaller p—values, so that argmax
should be replaced by argmin.

The terms gene and element are used interchangeably, and
each permutation is tacitly assumed to be produced by one
similarity criteria. For a set of permutations 2 : {a1.. . .. am}.
an : (ai(1).. . .. ai(n)), an aggregate permutation 0* is a permutation
that optimally represents the rankings in 2. Combinatorial aggre—
gates may be obtained using score- and distance-based methods.
Note that score and distance—based methods do not make use of
quantitative information, such as, e.g., p—values (for the case of gene
prioritization) or ratings (for the case of social choice theory and
recommender systems). In what follows, we briefly describe score
and distance—based methods and introduce their hybrid counter—
parts, which allow to integrate p—values and relevance constraints
into combinatorial aggregation approaches.

2.1 Score—based methods

Score—based methods are the simplest and computationally least
demanding techniques for rank aggregation. As inputs, they take a
set of permutations or partial permutations, 2 : {ah . .. am}.
a, : (ai(1).. . .. ai(n)). For each permutation a,- E 2, the scoring rule
awards s(ai(1), i) points to element 01(1), s(ai(2), i) points to element
01(2), and so on. For a fixed i, the scores are non—increasing func—
tions of their first index. Each element k E [n] is assigned a cumula—

tive score equal to s(k. j). The simplest scoring method is

Borda’s count, for which s(k./) : n — k + 1 independent on f.

The Borda count and related scoring rules exclusively use pos—
itional information in order to provide an aggregate ranking.
Ignoring actual p—values (ratings) may lead to aggregation problems,
as illustrated by the next example.

Example 1: Assume that n : 5 elements were rated according to
x : (7.0. 7.01.0.2.0.45. 7.001). The ranking induced by this rating
equals ax : (2.5.1.4.3), indicating that element 2 received the
highest rating, element 5 received the second highest rating and so
on. According to the Borda rule, element 2 receives 5 points, element
5 receives 4 points, etc. Despite the fact that candidates 2 and 1 are
almost tied with scores of 7.01 and 7.0, and that the difference in
their scores may be attributed to computational imprecision, elem—
ent 2 receives 5 points while element 1 receives only 3 points. As a
result, very small differences in ratings may result in large differ—
ences in Borda scores.

One way to approach the problem is to quantize the score and
work with rankings with ties, instead of full linear orders (i.e. per—
mutations). Elements tied in their rank receive the same number of
points in the generalized Borda scheme. A preferred alternative,
which we introduce in this work, is the Hybrid Borda method.

Let p(i, /) denote the p—value of gene i computed under similarity
criteria j./ : 1.. . .. m. The cumulative score of element i in the hy—
brid Borda setting is computed as

Z, #1. We. i)1 {pr/2.02m»

Si 2 Z pour)

1:1

The overall aggregate is obtained by ordering S in a descending
order. It is straightforward to see that the previous score function
extends Borda method in so far that it scores an element (gene) ac—
cording to the total score of elements ranked lower than the element.
Recall that in Borda’s method, the element ranked i is awarded n — i
+1 points, as n — i + 1 elements are ranked below it, each receiving
the same score 1. In our Hybrid Borda method, each element is

ﬁm'spzumol‘pmﬂo'sopeuuowtotq/ﬁdnq

Gene prioritization via HyDRA

1037

 

awarded a score in accordance with the p-ualues of elements ranked
below it.

Example 2: Let n:4 and m:2, where the two ratings equal
to p1 : (0.2.0.3. 0.01.0.12) and p2 : (01.04.02.035). The
Hybrid Borda scores S, for genes i : 1. 2. 3. 4 are computed as
S1: 0.3/0.2 + (0.4 + 0.2 + 0.35)/0.1 : 11, 32:0, 33 I (0.2 + 0.3
+012)n101+(04-r035y02::6575ands4:(02—r03V012
+ 04/035 : 5.3. By ordering the values Si in a descending manner,
we obtain the overall aggregate 0H3 : (3. 1. 4. 2).

The hybrid Borda method can be extended further by adding a
TvB feature, resulting in the Weighted hybrid Borda method. This is
accomplished by including increasing (multiplier) weights into
the score aggregates, thus stressing the top of the list more than the
bottom. More precisely, the score of gene i is computed as:

S‘ i i: 
l— . . . . .
.:1 wm(z./)P(z./)

where one simple choice for the weight multipliers that provides
good empirical performance equals

1

wm(1~,/) : 

2.2 Distance—based methods

Another common approach to rank aggregation is distance-based
rank aggregation. As before, assume that one is given a set of permu-
tations Z : {a1.. . .. am}. For a given distance function between two
permutations a and TE, d(rr. TE), aggregation reduces to

711
TE : arg min”: d(0'. (7i)

i:1

The aggregate T15 is frequently referred to as the median of the
permutations, and is illustrated in Figure 1.

One of the most important features of distance-based approaches
is the choice of the distance function. Table 1 lists two of the most
frequently used distances, the Kendall tau distance and the
Spearman footrule. As may be seen from the table, the distance
measures are combinatorial in nature, and do not account for scores
or p-values. Furthermore, as already mentioned in the introduction,
it is known that aggregation under the Kendall metric is computa-
tionally hard. Nevertheless, there exists a number of techniques
which provide provable approximation guarantees for the aggre-
gate, including the weighted Bipartite Graph Matching (WBGM)
method (using the fact that the Spearman distance aggregate is a 2-
approximation for the Kendall aggregate), linear programing (LP)
relaxation and Page Rank/Markov chain (PR) methods (Dwork
et al., 2001; Farnoud et al., 2012; Raisali et al., 2013).

The Kendall distance also does not take into account the fact
that the top of a list is more important than the remainder of the list.
To overcome this problem, we introduced the notion of weighted
Kendall distances, where each adjacent swap is assigned a cost, and
where the cost is higher at the top of a list. This ensures that in an
aggregate, strong showings of candidates are emphasized compared
with their weaker showings, accounting for the fact that it is often
sufficient to have strong similarity with respect to only a subset of
criteria. Furthermore, such weights ensure that higher importance is
paid to the top of the aggregate ranking.

The idea behind the weighted Kendall distance dW is to compute
this distance as the shortest path in a graph describing swap relation-
ships between permutations. The key concepts are illustrated in

Fig. 1. Four rankings: (:1. (:2. a3. (74 and their aggregate (median) ranking 7:

Table 1. Two frequently used distance measures for permutations,
accounting for swaps or element-wise differences

 

Distance Measurement Example

 

Spearman’s Sum of differences of dF(abc. cba) = 2 + O + 2 = 4

footrule ranks of elements.

Kendall Minimum number of dK(abc, cba) = 3
adjacent swaps of

entries for transforming

one ranking into another.

 

In the second example, the Kendall tau distance between the permutation
0'1 = (a. h. c) and 0'2 = (c. h.a) equals 3: one ﬁrst swaps elements at positions
1 and 2 to get ([7, a, c), then elements at positions 2 and 3 to get ([7, c, a), and
ﬁnally elements at positions 1 and 2 to get 0'2 = (c. h. a). All swaps contribute
the same weight (one) to the distance.

Figures 2 and 3, where each edge is assigned a length proportional to
its weight W. This weight depends on the swap being made at the top
or at some other position in the ranking. Given that it is computation-
ally demanding to aggregate under the weighted Kendall distance, we
use a specialized approximation function Dw(a. 0) for dw, of the form

W“ 0) 2 2:1 w<0‘1(i> = 04(0). (1)
where
2:, WM + 1). ifk <1.

We ‘1) I :11 W(h.h + 1). ifk >1. (2)
0 ﬁkzL

denotes the sum of the weights of edges  representing adjacent
transpositions (kk + 1). (k + 1 k + 2).. . .. (l — 11). if k <l, the sum
of the weights of edges  representing adjacent transpositions
(ll+1).(l+1l+2).....(k — 1k),ifl<k,and 0,ifk:l.

Example 3: Suppose that one is given four rankings, (1, 2, 3),
(1, 2, 3), (3, 2, 1) and (2, 1, 3). There are two optimal aggregates
according to the Kendall tau distance, namely (1, 2, 3) and (2, 1, 3).
Both have cumulative distance four from the set of given
permutations. If the transposition weights are non-uniform, say such
that W(12)>W(23), the solution becomes unique and equal to
(1, 2, 3). If the last ranking is changed from (2, 1, 3) to (2, 3, 1),
exactly three permutations are optimal from the perspective of
Kendall tau aggregation: (1, 2, 3), (2, 1, 3) and (2, 3, 1). These three
solutions give widely different predictions of what one should
consider the top candidate. Nevertheless, by choosing once
more W(12)>W(23) the solution becomes unique and equal to
(1,2,3).

It can be shown that for any non-negative weight function w,
and for two permutations a and 0, one has

1/2Dw(0'. 0) S dw(rt. 0') S Dw(0'. 0)

/810's113umo_fp103xo"sotJBmJOJutotW/zdnq

Kuhn, 1955 Mclin, 2006

~\_/'

Farnoud at al.. 2012

chr and Bilnics, 2013

/810'sleumofp103xo"sotJBuIJOJutotqﬂ:duq

Gene prioritization via HyDRA

1039

 

ranking induced by the sum of real-valued rating vectors, ordered in
a decreasing manner.

If, as before, p(i, /) denotes the p—value of gene i under criteria /,
we define the normalized Lovasz—Bregman score for gene i as

. Em p(iv‘)
£3 : n—7
(1) /:1% E i:1P(47/)

where the sum of p-values over criteria is normalized by the average
of the p—values for each criterion. The aggregate equals (75, where
ﬂ = (£(i))7:1~

Example 5: Let n : 4 and m : 2, where the two ratings equal to p1
: (0.2. 0.3. 0.01. 0.12) and p2 : (0.1. 0.4. 0.2. 0.35). Note that
will p(i. 1) : 1/4(0.2 + 0.3 + 0.01 + 0.12) : 0.1575, and 1/n
Z; p(i. 2) : 1/4(0.1 + 0.4 + 0.2 + 0.35) : 0.2625. The Lovasz—
Bregman scores £(i). i: 1.2. 3.4, equal £(1): 0.2/0.1575+ 0.1/
0.2625 2 1.65, [3(2) : 0.3/0.1575 + 0.4/0.2625 : 3.43, [3(3) 2 0.01/
0.1575 + 0.2/0.2625 : 0.83, [3(4) : 0.12/0.1575 + 0.35/0.2625 : 2.1.
By ordering £(i) in an ascending manner, one arrives at
013 : (3.1.4.2).

3 Algorithms and implementation

We now turn our attention to testing different aggregation methods
on lists of p—values generated by Endeavour and ToppGene. The
aforementioned methods rely on a set of training genes known to be
involved in a disease. The test genes are compared with all the train—
ing genes according to a set of similarity criteria, and the p—value of
each comparison is computed in the process. For example, if the cri—
terion is sequence similarity, the p—value reflects the z—value, describ—
ing the number of standard deviations above the mean for a given
observation. Given the p—values, the question of interest becomes
how to aggregate them into one ranking. Computing the p—values is
a routine procedure, and the challenge of the prioritization process
is to most meaningfully and efficiently perform the aggregation step.

There are two settings in which one can use the aggregation
algorithms. The first setting is cross-validation, a verification step
that compares the output of an aggregation algorithm with existing,
validated knowledge. This mode of operation is aimed at discover—
ing shortcomings and advantages of different methods. In the
second setting, termed gene discovery, the aim is to identify sets
of genes implicated in a disease which are not included in the data—
base. Clearly, cross—validation studies are necessary first steps in
gene discovery procedures, as they explain best aggregation strat—
egies for different datasets and different similarity and training
conditions.

For both methods, a list of genes involved in a certain disease
(referred to as onset genes) was obtained from the publicly available
databases Online Mendelian inheritance in Man (OMIM) (Hamosh
et al., 2005) and/or the Genetic Association Database (GAD)
(Becker et al., 2004). Both of these sources rely on the literature for
genetic association for vast number of diseases, but OMIM typically
provides a more conservative (i.e. shorter) list than the GAD. Onset
genes were tested along with random genes, obtained by randomly
permuting 19, 231 human genes in the GeneCards database (Safran
et al., 2002), and retaining the top portion of the list according to
the chosen number of test genes.

3.1 Cross—validation
We performed a systematic, comparative performance analysis of
the ToppGene and Endeavour aggregation algorithms and the newly

proposed hybrid methods. Given a list of r onset genes, we first se—
lected t onset genes to serve as target genes (henceforth referred to as
target onset genes) for validation; we used the remaining r—t onset
genes as training genes. Of the n test genes, n—t genes were selected
randomly from GeneCards (Safran et al., 2002). Our cross—valid—
ation procedure closely followed that of Endeavour and ToppGene:
we fixed t: 1, and tested all r individual genes from the pool of
onset genes, and then averaged the results. Averaging was performed
as follows: we took target onset genes one—by—one and averaged their

,,
rankings over < > : r experiments. Note that in principle, one
If
r:1

may also choose t2 2; in this case, the lowest ranking of the t genes
(i.e. the highest positional value that a target onset gene assumed)
should serve as a good measure of performance. One would then

7,
proceed to average the resulting rankings over < > experiments,
t

producing a ‘worst case scenario” for ranking of target onset genes.
For fair comparison with Endeavour and ToppGene, we only used
the first described method with t: 1 and the same set of p—values as
inputs. As will be described in subsequent sections, we used t2 2 for
gene discovery procedures.

3.2 Gene discovery

The ultimate goal of gene prioritization is to discover genes that are
likely to be involved in a disease without having any prior experi—
mental knowledge about their role. We describe next a new, itera—
tive gene discovery method. The method uses aggregation
techniques or combinations of aggregation techniques deemed to be
most effective in the cross—validation study.

Given a certain disease with r onset genes, we first identify 5 sus-
pect genes. Suspect genes are genes that are known to be involved in
diseases related to that under study (as an example, a suspect gene
for glioblastoma may be a gene known to be implicated in another
form of brain cancer, say meningioma), but have not been tested in

 

Algorithm 1: Gene Discovery

 

Input: Set of onset genes, 0 : {01. 02.. . ..o,}, set of sus—
pect genes, 8 : {s1.sz.. . .. s5}, number of test genes,
n6 2+, a cut—off threshold, re 2+, and the number of
allowed iterations, IE Z
Output: Set of potential disease genes, denoted by A
Initialization:
0 Set i:1, A20. R: {r1.r2.....r,,_s} — a set of ran—
domly chosen genes, training set TR:O, test set
TS : S U R
For i g I do
1. Run a gene prioritization suite using the training set TR,
test set TS, and m similarity criteria

I"

Run k aggregation methods on the p—values produced in
Step 1, and denote the resulting rankings by (71.. . .. ck
3. Let B : {01(1).. . ..0'1(r)} U - - - U {Jk(1).. . .. 072(1)}
4. A<—AUB;TR<—TRUB;S<—S\B
5. TS <— S U R’. R’ : set ofn — (S) randomly chosen genes
6. i <— i+ 1
End
Return A

 

 

 

ﬁlO'SleIIIﬂOprOJXO'SOIJIZILLIOJLIIOICV/idnq

Topp Gene

LOY'J szeBregmnn

Table 2

Hybrid
Borda

supplementary data

Hybrid
Kendall

Table 2

Table 2

Supplementary data

 

/3,IO'S[EIIm0[p.IOJXO'SOIJEIIIJOJIIIOIq/ﬂduq

table 2

Sensitivity/Specihuty 90/84

 

Hybrid Hybrid
Kendall

oppGene Lovasz-

 

Bregman Borda

0.951

ROC Endeavour All Criteria

 

1-‘-|I.—- II".- |"\'

table 2

ROC ToppGene All Criteria

 

2009

table 2

Figs. 5 6

K) l‘itSiS er al..

Paridc). 2014

Table 4

1999

i111

Table 2

Buschgcs er al..

SUPPlCIHCIlt‘Jl‘) mater-

/3.10'spzumofp10}xo"sotwuiJOJutotqﬂ:duq

1042

M.Kim et al.

 

Table 4. The union of top three ranked genes from ToppGene, Endeavour and HyDRA methods for the three suspect gene discovery sets,

with the ’suspect’ genes in bold

 

Test disease Iteration 1

Iteration 2

 

Breast cancer
RADS 1 , TP73

VHL, LF, TS, N, TS CCNDl, CD28, CD74, CDK4, CHEKZ, MLHl, MSHZ,

MSH6, NBPF4, PMSZ, PRNT, TSCZ
Meningioma

XRCCS

AKT1, ATM, BRIPl, CDHl, CHEKZ, GSTMZ, KAAG1,

CCNDl, HLA-DQBl, KLF6, KRAS, TGFBl, TGFBRZ,

BARDl, CASP7, ITGA4, KRAS, PALBZ, PHB, SMAD7,
UMOD

ALCAM, APC,MRC1, NCL, NF1,NF2, SNCA, TAF7,
TOPBP1,TSC1,VHL

BAGE,BAP1, CAV1, CD4, CDH1,NF2, PDGFB, PSMCZ,
RFCl, SAMD9L,SERPING1, SMARCBl

 

In all cases, the training genes are genes implicated in glioblastoma. The ‘Disease’ category indicates from which family of diseases the test genes were drawn.

The results of the third iteration may be found in the Supporting ﬁle Section S3.

generated by different methods as best aggregation practice.
Another important observation is that HyDRA methods have sig—
nificantly lower computational complexity than ToppGene and es—
pecially, Endeavour, and hence scale well for large datasets.

Another finding is the fact that the good performance of
ToppGene and all other methods largely depends on including prior
literature on the genes into the aggregation process. We observed situ—
ations where the rank of an element dropped by roughly 90 positions
when this prior was not available. This implies that for gene discov—
ery, it is risky to rely on any single method, and it is again good prac—
tice to merge top—ranked entries generated by different methods.
Finally, it is not clear how to optimally choose the number of training
genes for a given set of test genes, or vice versa. Choosing more
training genes may appear to be beneficial at first glance, but it creates
a more diverse pool of candidates for which some similarity criteria
will inevitably fail to identify the right genes. In this case, we recom—
mend using the Weighted Kendall to eliminate outliers, and in add—
ition, we recommend the use of a fairly large TvB scaling parameter.

Acknowledgements

The work was supported in part by the National Science Foundation (NSF)
under grants CCF 0809895, CCF 1218764, CSoI-CCF 0939370, and IOS
1339388.

Conﬂict of interest: none declared.

References

Adie,E.A. et al. (2006) SUSPECTS: enabling fast and effective prioritization of
positional candidates. Bioinformatics, 22, 773—774.

Aerts,S. et al. (2006) Gene prioritization through genomic data fusion. Nat
Biotechnol, 24, 537—544.

Bartholdi,]. et al. (1989) The computational difﬁculty of manipulating an elec-
tion. Soc. Choice Welfare, 6, 227—241.

Becker,K.G. et al. (2004) The Genetic Association Database. Nat Genet, 36,
431—432.

Buschges,R. et al. (1999). Ampliﬁcation and expression of cyclin D genes
(CCND1 CCND2 and CCND3) in human malignant gliomas. Brain
Pathol, 9, 435—442.

Cardon,L.R. et al. (2001) Association study designs for complex diseases. Nat
Rev Genet, 2, 91—99.

Chen,]. et al. (2009) ToppGene Suite for gene list enrichment analysis and can-
didate gene prioritization. Nucleic Acids Res, 37, W305—W311.

De Bie,T. et al. (2007) Kernel-based data fusion for gene prioritization.
Bioinformatics, 23, i125—i132.

Dwork,C. et al. (2001). Rank aggregation methods for the web. In:
Proceedings of the 10th international conference on World Wide Web
(WWW/10), ACM. Hong Kong, China. pp. 613—622.

Farnoud,F. et al. (2012) Nonuniform vote aggregation algorithms. In: Signal
Processing and Communications (SPCOM), I EEE. Bangalore, India. pp. 1—5.

Farnoud,F. et al. (2014), An axiomatic approach to constructing distances for
rank comparison and aggregation. IEEE Trans Inform Theory, 60,
6417—6439.

Fishburn,P. (1970) Arrow’s Impossibility theorem: concise proof and inﬁnite
voters.]Econ Theory, 2, 103—106.

Freudenberg,]. and Propping,P. (2002) A similarity-based method for genome-
wide prediction of disease-relevant human genes. Bioinformatics, 18,
5110—51 15.

Guney,E. et al. (2014) GUILDify: a web server for phenotypic characterization
of genes through biological data integration and network-based prioritiza-
tion algorithms. Bioinformatics, 30, 178 9—1 790.

Hamosh,A. et al. (2005) Online Mendelian inheritance in Man (OMIM), a
knowledge base of human genes and genetic disorders. Nucleic Acids Res,
33, D514—D517.

Iyer,R. and Bilmes,J.A. (2013) The Lovasz-Bregman divergence and
connections to rank aggregation, clustering, and web ranking. In:
Uncertainty in Artiﬁcial Intelligence (UAI), AUAI, Bellevue, Washington.
pp. 1—10.

Kacprowski,T. et al. (2013) NetworkPrioritizer: a versatile tool for network-
based prioritization of candidate disease genes or other molecules.
Bioinformatics, 29, 1471—1473.

Kemeny,].G. (1959) Mathematics without numbers. Daedalus, 88, 577—591.

Kendall,M.G. (1938) A new measure of rank correlation. Biometrika, 30,
81—93.

Kendall,M. (1948) Rank Correlation Methods. Charles Grifﬁn and Company
Limited, London.

Kohler,S. et al. (2008) Walking the interactome for prioritization of candidate
disease genes. Am] Hum Genet, 82, 949.

Kolde,R. et al. (2012) Robust rank aggregation for gene list integration and
meta-analysis. Bioinformatics, 28, 573—580.

Kuhn,H.W. (1955) The Hungarian method for the assignment problem. Nav
Res Log, 2, 83—97.

Kyritsis,A.P. et al. (2009) Inherited predisposition to glioma. Neuro Oncol,
12, 104—113.

Melin,A. (2006) The Hungarian algorithm. MATLAB Central File Exchange.
http://www.mathworks.com/matlabcentral/ﬁleexchange/l1609-hungarian-
algorithm (8 August 2006, retrieved).

Pandey,].P. (2014) Immunoglobulin GM genes, cytomegalovirus immunoeva-
sion, and the risk of glioma, neuroblastoma, and breast cancer. Front
Oncol, 4., 238.

Perez-Iratxeta,C. et al. (2002) Association of genes to genetically inherited dis-
eases using data mining. Nat Genet, 31, 316—319.

Pihur,V. et al. (2009) RankAggreg, an R package for weighted rank aggrega-
tion. BMC Bioinformatics, 10, 62.

Popescu,M. et al. (2006 ) Fuzzy measures on the Gene Ontology for gene product
similarity. IEEE/ACM Trans Comput Biol Bioinformatics, 3, 263—274.

Raisali,F. et al. (2013) Weighted rank aggregation via relaxed integer pro—
gramming. In: International Symposium on Information Theory (ISIT),
IEEE. Istanbul, Turkey. pp. 2765—2767.

Risch,N. and Merikangas,K. (1996) The future of genetic studies of complex
human diseases. Science, 273, 1516—1517.

Safran,M. et al. (2002) GeneCards 2002: towards a complete, object-oriented,
human gene compendium. Bioinformatics, 18, 1542—1543.

ﬁlO'SIIZLImOprOJXO'SOIJIZILLIOJLIIOICV/idnq

Gene prioritization via HyDRA

1043

 

Thanassoulis,E. (2001) Introduction to the Theory and Application of Data
Envelopment Analysis. Kluwer Academic Publishers, Dordrecht.

Tifﬁn,N. et al. (2006) Computational disease gene identiﬁcation: a concert of
methods prioritizes type 2 diabetes and obesity candidate genes. Nucleic
Acids Res, 34, 3067—3081.

Turner,F.S. et al. (2003) POCUS: mining genomic sequence annotation to pre-
dict disease genes. Genome Biol, 4, R75—R75.

Warde-Farley,D. et al. (2010) The GeneMANIA prediction server: biological
network integration for gene prioritization and predicting gene function.
Nucleic Acids Res, 38, W214—W220.

Yu,S. et al. (2008) Comparison of vocabularies, representations and ranking
algorithms for gene prioritization by text mining. Bioinformatics, 24,
i1 19—i125.

/B.IO'S[BIImOfp.IOJXO"SOIJBHIJOJIIIOIq/ﬂdnq

