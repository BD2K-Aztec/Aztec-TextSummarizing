ORIGINAL PAPER

Vol. 29 no. 15 2013, pages 1879—1887
doi:1 0. 1093/bioinfonnatics/btt309

 

Bioimage informatics

Advance Access publication May 29, 2013

Improved image alignment method in application to X-ray images

and biological images

Ching-Wei Wang” and Hsiang-Chou Chen2

1Graduate Institute of Biomedical Engineering, and 2Graduate Institute of Applied Science and Technology, Honors
College National Taiwan University of Science and Technology, Taipei City, 10607 Taiwan

Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: Alignment of medical images is a vital component of a
large number of applications throughout the clinical track of events;
not only within clinical diagnostic settings, but prominently so in the
area of planning, consummation and evaluation of surgical and radio-
therapeutical procedures. However, image registration of medical
images is challenging because of variations on data appearance, ima-
ging artifacts and complex data deformation problems. Hence, the
aim of this study is to develop a robust image alignment method for
medical images.

Results: An improved image registration method is proposed, and the
method is evaluated with two types of medical data, including biolo-
gical microscopic tissue images and dental X-ray images and com-
pared with five state-of-the-art image registration techniques. The
experimental results show that the presented method consistently per-
forms well on both types of medical images, achieving 88.44 and
88.93% averaged registration accuracies for biological tissue images
and X-ray images, respectively, and outperforms the benchmark
methods. Based on the Tukey’s honestly significant difference test
and Fisher’s least square difference test tests, the presented
method performs significantly better than all existing methods
(P: 0.001) for tissue image alignment, and for the X-ray image regis-
tration, the proposed method performs significantly better than the
two benchmark b-spline approaches (P<0.001).

Availability: The software implementation of the presented method
and the data used in this study are made publicly available for scien-
tific communities to use (http://www—o.ntust.edu.tw/~cweiwang/lmp
rovedlmageRegistrationl).

Contact: cweiwang@mail.ntust.edu.tw

Received on March 8, 2013; revised on May 22, 2013; accepted on
May 24, 2013

1 INTRODUCTION

Image registration is the process of systematically placing separ-
ate images in a common coordinate system so that the informa-
tion they contain can be optimally integrated or compared. This
is becoming the central tool for image analysis, understanding
and Visualization in both medical and scientiﬁc applications
(Matsopoulos et al., 2001). Time series of images are acquired
for various reasons, such as monitoring of bone growth in chil-
dren, monitoring of tumor growth, post-operative monitoring of
healing or observing the passing of an injected bolus trough a

 

*To whom correspondence should be addressed.

vessel tree, and image registration plays an important role for
these medical applications.

However, alignment of medical images is challenging because
of variations on data appearance, imaging artifacts and complex
data deformation problems, making existing registration
approaches unstable and performs poor (Hill et al., 2001);
Section 2 shows the experimental results of four existing regis-
tration methods. Although there has also been substantial pro-
gress in non-rigid registration algorithms that can compensate
for tissue deformation or align images from different subjects,
many registration problems remain unsolved (Hill et al., 2001).
From literature review (Alic et al., 2011; Arganda—Carreras et al,
2006; Chakravarty et al., 2006; Dauguet et al., 2007; Pitiot and
Guimond, 2008; Saalfeld et al., 2010, 2012; Sorzano et al., 2005;
Tan et al., 2007), the raw data tends to be carefully prepared,
showing little morphological distortions or stain variation, to
simplify the registration task. In addition, they tend to work
with low-resolution images without dealing with high-precision
tissue or cell-level registration.

The aim of this work is to investigate a robust and fully auto-
matic image registration method for medical images. Two types
of medical data are included in this study. One is serial micro-
scopic tissue images with conventional histopathological hema-
toxylin and eosin (H&E) staining, and the other is dental X-ray
images acquired using different radiation time from 0.04 to 2.5 s
with slightly different capturing Views. Figure 1 illustrates chal-
lenges with respect to data variations in our experimental data
for image alignment.

There are various types of image registration techniques
(Oliveira and Tavares, 2012; Zitova and Flusser, 2003), which
can be categorized into area-based methods and feature-based
methods. Zitova and Flusser (Zitova and Flusser, 2003) sug-
gested that feature-based methods are recommended if the
images contain enough distinctive and easily detectable objects,
which is usually the case of applications in remote sensing and
computer Vision, and area-based methods are usually used for
medical images, which are not so rich in such details. In this
study, we ﬁrst evaluated five existing image registration tech-
niques on the collected medical images. They are one feature-
based method, i.e. SURF (Bay et a], 2008), which is popularly
adopted for remote sensing and general computer Vision appli-
cations, and four area-based methods demonstrated to be useful
for biological images, including a unidirectional elastic b-spline
model (Unwaer) (Sorzano, et al., 2005), an improved bi—djrec-
tional elastic b-spline model (Bunwaer) (Arganda—Carreras
et al., 2006), a state-of-the-art 3D reconstruction system

 

© The Author 2013. Published by Oxford University Press. All rights resen/ed. For Permissions, please e—mail: journals.permissions@oup.com 1879

112 /310'S[BIIJnO[pJOJXO'SOIJBLUJOJIIIOIq/ﬂduq 11101} pQPBOIHAAOG

91oz ‘Og anﬁnV uo ::

C.-W.Wang and H.-C.Chen

 

      

Stain variation, slain artifacts (arrow),
tissue stretching, translation and rotation

‘°’ I—I-‘t-
. g '

Rotation and translation

0.045 0.15 0.635 2.55

Brightness variation, translation, rotation

Fig. 1. Challenges with respect to data variations for image registration
of medical images. (a) Rotation and translation effects in a pair of serial
tissue slides, (b) signiﬁcant stain variation because of potential discrep-
ancy in thickness of individual tissue sections and stain artifacts in com-
bination with rotation and translation effects in a pair of serial tissue
slides, (c) brightness variations because of changes on radiation time
with different capturing views in dental X-ray images

(TrakEM2) (Cardona et al., 2010, 2012; Saalfeld, et al., 2010,
2012) and mutual information-based image registration ap-
proach (Maes, 1997; Pluim, 2003) using the MATLAB imple-
mentation (MathWorks). The ﬁve benchmark methods (SURF,
Unwaer, Bunwaer, TrakEM2 and mutual information) are
brieﬂy described later in the text.

SURF (speeded-up robust features) (Bay et al., 2008) is a scale
and rotation-nvariant detector and descriptor based on sums of
2D Haar wavelet responses, and the method is a popularly
adopted technique and widely applied to general computer
vision applications such as remote sensing image alignment
(Brook and Ben-Dor, 2011; Teke and Temizel, 2010) and
object recognition task (Dreuw et al., 2009). However, as for
medical images, local image features can appear confusing to
one another; SURF does not perform well on corresponding
feature identiﬁcation. Thus, this method tends to fail in our ex-
periment (see Section 2). Figure 2 shows the results of corres-
ponding landmark detection by SURF in application to general
computer vision images and in biological images. For general
computer vision applications, SURF is able to identify corres-
ponding features (Fig. 2a), but for biological tissue images,
SURF performs poor on corresponding landmark detection
(Fig. 2b).

Unwaer (unidirectional elastic b-spline model) is introduced
by Sorzano et a]. (2005) by combining and extending some of the
best techniques in the context of medical imaging. They use
B-splines to model the deformation field and solve the registra-
tion problem by minimizing a pixelwise mean-square distance
measure between the target image and the transformed source
images with vector-spline regularization constraints. This
method is demonstrated to be effective on the elastic registration
of images of electrophoretic gels and ﬂy embryos. Later, based
on Unwaer, Arganda—Carreras et a]. (2006) developed an im-
proved bi-directional elastic b-spline model (Bunwaer) to per-
form better registration of histopathological tissue images.
However, quantitative evaluations of the method were not

 

I
E
i
x
il

Fig. 2. Corresponding feature detection by SURF. (a) For general
computer vision applications, SURF is able to identify corresponding
features, but (b) for biological tissue images where local features can
be confusing, SURF performs poor on corresponding landmark
detection

provided in (Arganda-Carreras et al., 2006) to show the perform-
ance of Bunwaer on alignment of tissue images. TrakEM2
(Cardona et al., 2010, 2012; Saalfeld et al., 2010, 2012) is a
recent development for 2D medical image registration and/or
3D image reconstruction, but Cardona et a]. (2010) pointed
out that ‘TrakEM2 acknowledges that any automatic procedure
(such as image registration and image segmentation) will even-
tually fail partially or fully and will require manual correction by
a human operator’.

Mutual information techniques (Maes, 1997; Pluim, 2003)
measure the statistical dependence or information redundancy
between image intensities of corresponding voxels in both
images and use mutual information or relative entropy as the
matching criterion. The method has been validated for rigid
body registration of computed tomography, magnetic resonance
and photon emission tomography images. Here, recent
MATLAB R2013a implementation (MathWorks) of the
mutual information-based method is adopted for evaluation.

In our experiments (see Section 2), the five existing techniques
do not deal with either tissue deformations or stain variation
problems and perform poor, obtaining <65% registration
accuracies on average for biological tissue images, and for
X-ray images, the two b-spline models produce poor results
with accuracy <60%. Hence, a robust and fully automatic regis-
tration method is highly desirable.

In this work, an improved image alignment approach that is a
combination of feature-based and area-based elastic registration
method and a tissue pattern extraction technique is introduced
here, and the presented method is fully automatic and performs
consistently well in our experiments for both biological tissue
images and X-ray images. Detailed quantitative evaluations
with statistical analysis were conducted, showing that the pre-
sented method achieves 88.44 and 88.9% averaged registration
accuracies for biological tissue images and X-ray images, respect-
ively, and outperforms the benchmark methods. Based on the
Tukey’s honestly signiﬁcant difference test (HSD) and Fisher’s
least square difference test (LSD) tests, the presented method
performs significantly better than all existing methods
(P50.001) for tissue image alignment, and for the X-ray
image registration, the proposed method performs signiﬁcantly
better than the two benchmark b-spline approaches (P<0.001).

The outline of this article is as follows. The materials and
results are presented in Section 2, and the proposed methods
are described in Section 3. Information regarding the

 

1880

112 /310'S[BIIJHO[pJOJXO'SOIJBLUJOJIIIOICI”K1111] 11101} pQPBOIIIAAOG

9103 ‘Og isnﬁnV uo ::

Improved image alignment method

 

implementation of the presented method is provided in Section 4
and a discussion is given in Section 5.

2 DATA AND RESULTS

2.1 Materials

Serial tissue images. Ninety pairs of serial histopathological slides
were produced as the target and source images to be tested on the
image registration techniques. The serial histological slides were
collected using C57 mice with IgAN [immunoglobulin A (IgA)
nephropathy], which is the most common glomerular disorder
across the world (D’Amico, 1987). IgAN was induced by daily
injection of puriﬁed IgA anti-phosphorylcholine and pneumo-
coccal C-polysaccharide (PnC) as described previously (Chao
et al., 2006). The renal cortical tissue was collected and stored
appropriately until analysis. All animal experiments were per-
formed with the approval (permit number IACUC-11-063) of
the Institutional Animal Care and Use Committee of The
National Defense Medical Center, Taiwan, and were consistent
with the NIH Guide for the Care and Use of Laboratory
Animals. For histopathology, the tissues were ﬁxed in 10% buf-
fered formalin and embedded in parafﬁn. Serial sections (4 am)
were cut using Leica RM2155 and stained with H&E. Slide
images were captured by light microscopy (Olympus, Japan) at
the magniﬁcation of x400.

Dental X-ray Images. Forty-ﬁve pairs of source and target
dental X-ray images were collected for registration, and each
pair was sampled without replacement from 10 dental X-ray
images (45 = Cg) = %), acquired with different radiation time
(0.04, 0.06, 0.1, 0.16, 0.25, 0.4, 0.63, l, 1.6 and 2.5 s) and slightly

different capturing views.

2.2 Experimental results on biological tissue images

Evaluation Method. In conventional computer vision applica-
tions, the performances of image registration algorithms can be
evaluated using sum of squared differences (SSD) between the
target image and the transformed source image to represent the
registration accuracy level. However, for the biological data, this
evaluation result can be misleading, as it is common that the
intensity of the pixel in the target image and the one of the
wrongly registered pixel in the transformed source image can
be similar, and that the intensity of the pixel in the target
image and the one of the accurately registered pixel in the trans-
formed source image can be different because of stain variation.
Hence, to provide a quantitative evaluation, five corresponding
landmarks between target images and the associated transformed
source images by each registration method were first manually
marked, and an automatic matching system is built to compare
the coordinates of the corresponding landmarks. The registration
accuracy for each image pair is computed by the matching suc-
cessful rate over the corresponding landmarks, and the perform-
ance of each registration method is evaluated by the averaged
accuracies over all image pairs. Figure 3 illustrates the evaluation
results of two pairs of tissue images.

Quantitative Results with Statistical Analysis. In the Appendix,
Table 1 presents the quantitative evaluation outcomes of

biological tissue image registration with ANOVA analysis.
Furthermore, using SPSS software (SPSS Inc, 2008), the quan-
titative registration accuracy scores were analyzed with the
Tukey’s HSD and the LSD (Table 2).

The experimental results show that the ﬁve benchmark tech-
niques do not deal with either tissue deformations or stain vari-
ation problems and perform poor, obtaining <65% registration
accuracies on average. In comparison, the presented method
achieves 88.44% averaged registration accuracy for biological
tissue images and significantly outperforms the benchmark meth-
ods based on Tukey’s HSD and LSD tests (P5 0.001).
Moreover, the box plot of the quantitative evaluation results is
provided in Figure 4, showing that the proposed method works
constantly well overall, and the four area-based methods
(Unwaer, Bunwaer, TrakEM2 and mutual information) per-
form better than the feature-based method (SURF) for tissue
image registration. Furthermore, the modern system TrakEM2
and the B-spline model seem to perform better than the other
two benchmark approaches, and thus for the following dental
X-ray image registration experiments, the TrakEM2 and the
B-spline models are selected for comparison.

2.3 Experimental results on dental X-ray images

Evaluation Method. Unlike tissue images, local image features
of dental X-ray scans appear better correlated to each other;
therefore, a general registration performance measurement
method, i.e. the percentage of pixels with similar intensity
levels, is adopted to measure the registration accuracy, and an
automatic evaluation tool is built to conduct quantitative evalu-
ation automatically. The registration accuracy, r, is formulated
as follows.

r 2 #{x3 “1206) — U(11(x))<l}
#9
where 11,12, U(Il) represent the source, target and transformed
source images; £2 = {x 6 (21 ﬂ 22 : d(x) 6 (22 r) 22} deﬁnes a
mask common to the source and target images, and #9 is the
size of the mask in pixels; t: 50 in our experiments.

(1)

Quantitative Results with Statistical Analysis. In the Appendix,
Table 3 presents the quantitative evaluation outcomes of dental
X-ray image registration with ANOVA analysis. Furthermore,
using SPSS software (SPSS Inc, 2008), the quantitative registra-
tion accuracy scores were analyzed with Tukey’s HSD and LSD
(Table 4). Moreover, the box plot of the quantitative evaluation
results is provided in Figure 5. The experimental results show
that the proposed method performs well on registration of dental
X-ray images, obtaining 88.93% averaged registration accuracy
rate, and significantly better than Unwaer and Bunwaer,
which obtain <60% registration accuracy rates on average,
based on Tukey’s HSD and LSD tests (P<0.001). Figure 6
shows registration results of some dental X-ray images.

3 METHODS

In (Zitova and Flusser, 2003), the authors pointed out that feature-based
methods are recommended if the images contain enough distinctive and
easily detectable objects, which is usually the case of applications in
remote sensing and computer vision, and area-based methods are usually

 

1881

112 /310's112u1n0fp10}x0"sorJBurJOJurorq/ﬁduq 11101} pQPBOIIIAAOG

9103 ‘Og isnﬁnV uo ::

c.-W.Wang and H.-C.Chen

 

Target image with
landmarks

Source image

 

a

 

 

 

Registered Source image with iandmark matching results (green box -) match; box -) no match)

“ TrakEMl Prnﬂose‘i "mde
. I . A ,r'.‘ g: - hug.»
. , ' u -. -‘

Registered Source image with iandmark matching results (Erna-n box '3 match: hot: '9' no match)

Target image with
landma rks

Accuracy (%) D 0

Fig. 3. Quantitative evaluation of two pairs of tissue images

Table 1. Registration accuracies (%) of biological tissue image with
ANOVA analysis

 

 

Method N Score SD Standard
Mean error
Unwaer (Sorzano et al., 2005) 90 53.78 45.24 4.77
BUnwaer (Arganda—Carreras 90 49.56 45.98 4.85
et al., 2006)
SURF (Bay et al., 2008) 90 13.78 22.76 2.4
TrakEM2 (Cardona et al., 2010; 90 64.67 43.76 4.61

Saalfeld et al., 2010; Cardona
et al., 2012; Saalfeld et al., 2012)
Proposed method 90 88.44 30.13 3.18
Mutual information 90 45.56 42.4 4.47
(MathWorks: R2013a
imregister; Pluim, 2003)

 

 

ANOVA df Mean square F Sig.
Between groups 5 53961.63 34.816 <0.001
Within groups 534 1549.92

Total 539

 

Note: The proposed method outperforms the benchmark methods on average.

used for medical images, which are not so rich in such details. However,
Shum and Szeliski (2000) indicated that as area-based direct-matching
methods use all available image data, they result in accurate registration if
the initialized disparities at the start of the registration procedure are
already close to the true disparities. This is consistent to our experimental

 

results; when the target images appwr similar to the source images, the
three benchmark area-based methods (Unwaer, Bunwaer and
TrakEM2) perform well, but when the target image and source images
do not appear similar to each other, the three area-based approaches tend
to perform poor.

Sparse methods have achieved grwt success in various biomedical ap-
plications, such as biomarker selection, biological network construction
and magnetic resonance imaging (Ye and Liu, 2012). The underlying
representations of many biomedical data are compressible in the sense
that they have concise representation when expressed in a proper basis.
Feature-based matching methods as sparse models use invariant features
to ensure reliable matching, and widely used framework rely on SURF
descriptors (Bay et al., 2008; Brook and Ben-Dor, 2011; Dreuw et al.,
2009) or SIFT features Gsowe, 2004; Vedaldi, 2006), which offer invari-
ance to afﬁne transformation (i.e. translation, rotation and scaling) in the
image representation. However, Barzigar et al. (2013) pointed out that
feature-based methods are not well suited for estimating large transform-
ations, as the matching accuracy and key point localization degrade for
large transformations. Figure 7 shows the feature-matching results by
SURF, SIFT and the proposed method where SURF produces poor
matching, SIFT generates some incorrect matches and the proposed
method ﬁnds accurate matched key points for fast and higher-level
coarse registration. The associated image registration result is displayed
in Figure 8.

Hence, to investigate a robust alignment method for both medical
and biological images, our goal is to develop a method that integrates
the strengths of both area-based approaches and feature-based meth-
ods. In this article, we develop a fully automatic, robust and fast
registration method for biological and medical data, containing three
major parts: (i) data normalization and feature extraction, (ii) sparse
approximation of images for coarse and fast global registration, and
(iii) optimize and reﬁne local registration by area-based direct-matching
approach.

 

1 882

112 /810's112um0fp10}x0"sorJBuIJOJurorq/ﬁduq 1110.1} papeoIH/noq

9IOZ ‘OE ISUEHV Ho ::

Improved image alignment method

 

Table 2. Multiple comparison for tissue image evaluation: Tukey’s HSD
and LSD

Table 3. Registration accuracy (%) of dental X-ray image registration
with ANOVA analysis

 

 

 

 

 

 

 

Tukey HSD Method N Score SD Standard
(I)Method (J)Method Mean Standard Sig. Mean error
difference error
(H) Unwaer (Sorzano et al., 2005) 45 55.06 35.78 5.39
BUnwaer (Arganda-Carreras 45 55.04 35.21 5.25
Proposed Method Unwaer 34.67a 5.87 <0.001 et al., 2006)
BUnwaer 38.89a 5.87 <0.001 TrakEM2 (Cardona et al., 2010; 45 87.77 5.54 0.83
SURF 74.67a 5.87 <0.001 Saalfeld et al., 2010; Cardona
TrakEM2 23.78a 5.87 0.001 et al., 2012; Saalfeld et al., 2012)
Mutual 42.88a 5.87 <0.001 Proposed method 45 88.93 5.41 0.81
information
ANOVA df Mean square F Sig.
LSD
(DMethod (DMethod Mean Standard Sig. Between groups 3 16547.832 25.807 <0.001
difference error Within groups 175 641.222
(H) Total 178
Proposed Method Unwaer 34.67a 5.87 < 0.00] Note: The proposed method outperforms the benchmark methods on average.
BUnwaer 38.89a 5.87 <0.001
SURF 74.67a 5.87 <0.001
TrakEM2 2378a 5-87 <0-001 Table 4. Multiple comparison for dental X-ray image evaluation:
Mutual 42.89a 5.87 <0.001 Tukey’s HSD and LSD
information

 

“The proposed method is signiﬁcantly better than the benchmark techniques using
both Tukey’s HSD and LSD tests (P50.001).

 

 

 

 

ﬂ
IUDW‘ I —
2" 359 397
I I
g Bnm‘ 1m 25‘
an
3
3 535 453 El!
b ' I 591 r
a anon “a
I-
:I
u
a
C
E 135
2 mm" *
u
a
l
n
a:
It: :30
20.00“ ’
53:21
um‘ 373 823
I I I I I I
Unwamd Bunwaer SURF TrakEM2 Flopuesd Mutual

Melnnﬂ IrlIormallun

Fig. 4. The box plot of quantitative evaluation results of tissue image
registration where outliers >1 .5x interquartile range are marked with a
dot and outliers >3 x interquartile range are marked with an asterisk. The
presented methods work constantly well overall and signiﬁcantly outper-
form the benchmark methods based on Tukey’s HSD and LSD tests
(P 5 0.001) (Table 2)

3.1 Data normalization and feature extraction

A data normalization process is proposed to reduce variations on image
features and enhance tissue patterns, which greatly beneﬁt the following
feature-matching process and area-based directing matching results. For
biological color images, in conventional histopathological staining
(H&E), hematoxylin induces the blue staining of nuclei and eosin induces

 

 

 

 

Tukey HSD
(I)Method (J)Method Mean Standard Sig.
difference error
(14)
Proposed Method Unwaer 33.87a 5.37 <0.001
BUnwaer 33.89a 5.34 <0.001
TrakEM2 1.16a 5. 34 0.996
LSD
(I)Method (J)Method Mean Standard Sig.
difference error
(14)
Proposed Method Unwaer 33.87a 5.37 <0.001
BUnwaer 33.89a 5.34 <0.001
TrakEM2 1.16a 5. 34 0.828

 

“The proposed method is signiﬁcantly better than Unwaer and Bunwaer using
both Tukey’s HSD and LSD tests (P<0.001)

the red/pink staining of cytoplasm. Based on our previous study (Wang
and Yu) showing that applying histogram equalization in RGB color
space performed better in separating the nuclei from the cytoplasm
than in HSL color space, both to enlarge the difference between the
nuclear and cytoplasmic expression in color space and to further produce
more distinctive tissue image features; the normalization is independently
applied to the red I, and blue 1,, channels of each image, producing new
image intensities I”, 1;); see Equations (2 and 3). For dental X-ray images,
the normalization is applied to the single gray-scale channel. The normal-
ization process is formulated as follows.

cfd,(i)

x

00') = M NX (2” - 1) (2)

where r stands for the red channel, h,(i) is the frequency of intensity value
i in the channel r, cfd,(i) =  h,(i), 0 5 i 5 2” — 1, c represents the

 

1883

112 /310's1eu1nofp101x0'sopeurmJurorq/ﬁduq Incl} papeo1umoq

9103 ‘0g1sn8nV uo ::

C.-W.Wang and H.-C.Chen

 

number of bits used to represent each pixel in each channel and M x N is
the size of the image.

CfdbU)
M x N

 

4(1) = X (2” - 1) (3)

where b stands for the blue channel, hb(i) is the frequency of intensity
value i in the channel b, cfdb(i) =  hb(i),0 5 i 5 2” — 1, c represents
the number of bits used to represent each pixel in each channel and
M x N is the size of the image.

100 W
SD M' i
65 20
- 0
4D DO-
2D W‘

DEID-

 

3

Registration Accuracy Score fill)

 

 

 

I I I I
Unwarud ElmwarnJ TrakEIJI'.‘ Frowsed Method

Fig. 5. The box plot of quantitative evaluation results of X-ray image
registration. The presented methods works constantly well overall and
signiﬁcantly outperforms Unwaer and Bunwaer based on Tukey’s
HSD and LSD tests (P<0.001) (Table 4)

Raw Target Raw Source
(0.15) [2.55)

F

If,"
all

    
 
  
  

 
 

2.57

7.26

Raw (Source 1.65)

“’3‘ f

Unwaer

Raw [Target 0.635)

_ 1

For biological images, although the dyes used are visualized as having
different colors, the resulting stains actually have complex overlapping
absorption spectra. In the previous studies, color deconvolution was used
to achieve color separation in forensic image processing (Berger et al.,
2006) and to achieve stain separation (Ruifrok and Johnston, 2001;
Wang, 2012) in biological image processing. Our goal is to extract the
eosinophilic structures, which are generally composed of intracellular or
extracellular protein, as image features for image registration, and the
color decomposition technique is used to extract independent
hematoxylin and eosin stain contributions from individual histopatholo-
gical images using orthonormal transformation of RGB.

In the RGB color-space, every color is deﬁned as
E E (61,62,63) E (r, g, b) where r, g, b represent the red, green and blue
components, and we can see additive color mixing as the vector addition
of RGB components. To model the colors in an image as the vector
addition of a desired (D) and undesired (U) components to a background
color (P), new unit vectors can be deﬁned as follows.

12517] (4)
3535 (5)
nEuxg (6)

- - . —» " —» —» " —>
where n is perpendicular to u and d; n, u, d span the 3D space; PU and
PD are alternative unit vectors based on the undes1red and des1red
colors.

Then, color 3 can be transformed to the new unit vectors.

Z=r>7+grg+beb§=uﬁ+d>g+nn+5 (7)

where [3 E ﬂ; 0 is the origin in the RGB 3D space; ﬂ is a vector.
By setting u = 0, we remove the undesired component and obtain the

—> _.
new color c’ = d > d+ n > ii +  In the case of three channels, the color

   
 
 
      

Transformed Source Images by

' .7 
' .4’

10.57 87.04 88.85

7.26 80.59 81.66

54.08 90.49 90.87

 

Fig. 6. Alignment results of X-ray images. r represents the level of registration accuracy based on the percentage of pixels with similar intensity levels

between the target image and the registered source image

 

1884

112 /810's112um0[p101x0'sopeurJOJHrorq/ﬁduq Incl} papeo1umoq

9103 ‘0g1sn8nV uo ::

Improved image alignment method

 

50hr

 

Fig. 7. Corresponding feature matching by SURF, SIFT and the presented method. SURF produces poor matching; SIFT generates some incorrect
matches; the proposed method ﬁnds accurate matched key points for fast and higher-level coarse registration

 

wince image

Fig. 8. Image registration by the proposed method

system can be described as a matrix of the form with every row repre-
senting a speciﬁc stain and every column representing the optical density
(OD) as detected by the red, green and blue channel for each stain.

Cu 612 613
M = 621 C22 C23 (8)
C31 C32 C33

For normalization, each OD vector is divided by its total length, such
that (EH = c11/,/c§1+c§2 +cj3, c3? = c21/,/c§, +c§2 +c§3 and
537 = C31 / c§1 + c§2 + c§3). In this study, the normalized OD matrix,

M, to describe the color system for orthonormal transformation is
deﬁned as follows:

R G B
A 0 l 1 Red
M = l 0 1 Green (9)
l l 0 Blue

When C is the 3 x 1 vector for amounts of the stains at a particular
pixel, the vector of OD levels detected at that pixel is equal to L = CM.
Therefore, multiplication of the OD image with the inverse of OD matrix
results in orthogonal representation of the stains forming the image
(C = M ‘1L). Then, the image features of the red channel are extracted
as eosinophilic structures for both high-level feature-based coarse regis-
tration and local area-based direct-matching registration. Figure 9
displays the ﬂowchart of the presented approach.

3.2 Sparse approximation for fast and coarse global
registration

Given [1 and I; as two images for alignment, T as a set of all possible
transformations between 11 and 12, and U,(I) as the function that maps an

 
   
 

Input images

Data normalization 82
Feature enhancement

Feature extraction
(eosinophilic structures)

 

.7 -. : Trarmn'rnad gem:

Fig. 9. The ﬂowchart of the presented approach

image I to its transformed image using the transformation t, the goal is to
ﬁnd the optimal transformation t’:

t’ = aligIIIil‘lllUt(1'1)- I2||2 (10)
tET

The transformation invariant distance d(11,12) = ||Uv(11) — 12||2 cor-
responds to the regular Euclidean distance when the images are aligned
optimally in L2 where images are considered as continuous functions in
L2 = {f: R2 —> IR : ff; lf(x)|2dx<oo}, but ﬁnding the optimal trans-
formation t’ and the smallest distance d(11,12) is not easy as the objective
function is non-convex and local minirna trap solution might occur.
Feature-based approaches represent a more efﬁcient class of methods.
Considered images can be well approximated by the sparse expansion
in a series of geometric functions, we deﬁne D = {(00, : or e T d} C L2 as
a set of geometric features constructed by transforming a generating
function Iv 6 L2 where T.) C T represents a ﬁnite discretization of the
transformations T, and do, = “((0) denotes the transformation of the

 

1885

in /810's112um0_fp101x0'so1112u1101u101q/ﬁd1111 mar} papeo1umoq

9103 ‘09 isanV uo ::

C.-W.Wang and H.-C.Chen

 

generating function 11/ by or. Given p and q as the respective K-sparse
approximation of 11 and 12 in D,

K

p = Zuni... (11)
i:1
K

«1 = Zim- (12)
i:1

where of, b,- are non-negative coefﬁcients.

Then, the coarse global image registration problem can be formulated
as ﬁnding the optimal relative transformation t” between the K-sparse
approximations with the smallest approximate transformation invariant
distance d(p,q):

t” = argmin ||U,(p) — QII2 (13)
tET

d(PJt) = “Uri/(P) - Qilz (14)

There are two notable advantages with respect to sparse approxima-
tion and coarse global registration. First, it helps escape from many local
minimum traps, and second, it greatly reduces computational time for
image alignment. Here, the K-sparse approximations p and q are ob-
tained by the following procedures. Obtaining normalized image features
F1, F2 by the method described in Section 3.1, interested points 81, 82 are
detected using the difference of Gaussian detector (Lowe, 2004), and then
the corresponding feature points p,q are selected as geometric consensus
between $1 and 82 using random sample consensus (RANSAC) (Fischler
and Bolles, 1981). The selected paired feature points p, q are then used for
coarse global registration. The registration methodology adapted from
(Arganda-Carreras et al., 2006) is based on the minimization of an energy
function that incorporates three energy terms, (E = arg min E).

E = WiEimg + WmEmark + WL'EL'ons 

where Eimg is the energy of the similarity error between U,(Il) and 12,
Emark is the error of the mapping of paired feature points p, q, Eco,”
expresses the geometrical consistency between the elastic deformation in
both direction (11 —> [2,12 —> 11) and wk are the weights for sub-energy
terms.

3.3 Reﬁne local registration by area-based direct
matching

Obtaining alignment outputs from the coarse registration process
described in the previous section, we then reﬁne registration by an
area-based direct-matching method, adapted from the improved bi-direc-
tional elastic b-spline model (Arganda-Carreras et al., 2006). The regis-
tration methodology is based on the minimization of an energy function
that incorporates four energy terms; the calculation of the elastic deform-
ation ﬁeld, d(x), is through the minimization of an energy function
(If = arg min E).

E = WiEimg + WdEdiv + WrEmt + WL'EL'ons 

where Eimg is the energy of the similarity error between 11 and 12(d(x)),
Ediv, E,,,, are the regularization energy based on the divergence and curl of
the deformation, Em,” expresses the geometrical consistency between the
elastic deformation in both direction (11 —> [2,12 —> 11) and wk are the
weights for sub-energy terms).

1
E,-

mg = #—9 Z (11(X) - I2(d(x)))2 (17)

11:69

where 9 = {x e 91 ﬂ 22 : d(x) 6 92 H 22} deﬁnes a mask common to
the source and target images, and #9 is the size of the mask in pixels.
As suggested by Sorzano et al. (2005), to use Eimg function, 11 and 12 need
to be brought to a common intensity value framework using some

normalization process, and in our experiments, the data normalization
technique presented in the previous section indeed assists the registration
method to produce better alignment outputs.

The smoothness of the deformation ﬁeld is a useful regularization
term, and Amodei and Benbourhim (1991) proposed the two regularizing
terms (Em, E,,,,) that fully exploit the vectorial nature of the data.

Em: / ||Vdivd||2dxdy (18)
R2

where divd = 3de + ayalz represents the divergence of the 2D vector ﬁeld
(I, and the divergence of a vector represents the net ﬂow of the vector of a
unit volume.

E,,,, = / ||Vrotd| |2dxdy (19)
R2

where rotd = —3yd1 + {3de represents the length of the unique compo-
nent of the curl of 2D vector ﬁeld (I, and where Vf: (ax/f 3,1) is the
gradient of the scalar function f; the curl is usually described as a measure
of the circulation of a vector ﬁeld.

EMMY = Ee+ons + Edam 
1
 = W Z) IIX — d’(d+(x))ll2 (21)
XEQT
1
 = #7 Z IIX — d+(d’(x))ll2 (22)
XEQT

where 9*, 9’ deﬁne sets of relevant pixels common to the tar-
get and source images (94r = {x e 92 ﬂ 22 : d+(x) e 91 H 22},
9’ = {x 6 91m 22 : d’(x) e 92 H 22”, where #9+,#9’ are the
number of pixels in the masks, and where alJr is the elastic deformation
in the direction (11 —> 12) and d’ is the elastic deformation in the direc-
thIl(12 —> [1).

4 IMPLEMENTATION

The software implementation of the presented method is de-
veloped in JAVA (with jdk 1.7.0.07 installed) and based on
ImageJ framework (1.45s version) (Schneider et al., 2012). The
software and the data are both made publicly available for
scientiﬁc communities to use (http://www-o.ntust.edu.tw/
~cweiwang/ImprovedImageRegistration/).

5 DISCUSSION

Image registration is the process of overlaying two or more
images of the same scene taken at different times from different
viewpoints or using different capturing modules, and a good
image alignment method has to take a number of issues into
consideration (Barzigar et al., 2013), including imperfect inputs
such as aberrations and artifacts, occlusion issues where many
pixels in one image may not match with any pixel in another
image and uniqueness issues where each pixel in an image has to
uniquely map to a pixel of another image. Alignment of biolo-
gical images is challenging as local image features may appear
confusing to one another, and imperfect inputs are inevitable.
In this article, a robust and fully automatic registration
method has been presented and demonstrated to be promising
for aligning biological tissue images and dental X-ray images.
Moreover, for the tissue image alignment, the presented
method outperforms five popularly adopted existing approaches

 

1886

112 /310's112u1n0fp101x0'sopeurJOJHIOIq/ﬁduq Incl} papeo1umoq

9103 ‘0g1sn8nV uo ::

Improved image alignment method

 

(P 5 0.001) based on Tukey’s HSD and LSD tests and performs
consistently well for both types of data in our experiments (88.44
and 88.93% averaged registration accuracies for biological tissue
images and X-ray images, respectively).

The presented image registration algorithm is not limited to
tissue images or dental X-ray scans but can also be applied to
other anatomically or histologically deﬁned medical data.
Moreover, as complex deformation problems are unavoidable
in real life data, the presented technique will prove to be a sub-
stantial advantage for any application that requires image
registration.

ACKNOWLEDGEMENTS

This study has been supported by the National Science Council
of Taiwan, and the authors thank Prof. Ann Chen and Dr Shuk-
Man Ka from Department of Pathology, Tri-Service General
Hospital, Taipei City, Taiwan, for providing the serial histo-
pathological tissue slides.

Funding: NSC101-2628-E-01l-006—MY3.

Conflict of Interest: none declared.

REFERENCES

Alic,L. et al. (2011) Facilitating tumor functional assessment by spatially relating
3D tumor histology and in vivo MRI: image registration approach. PLoS One,
6, e22835.

Amodei,L. and Benbourhim,M. (1991) A vector spline approximation. J. Approx.
Theory, 67, 51.

Arganda—Carreras,I. et al. (2006) Consistent and Elastic Registration of Histological
Sections using Vector—Spline Regularization. In: Lecture Notes in Computer
Science, Computer Vision Approaches to Medical Image Analysis. Vol. 4241,
pp. 85795.

Barzigar,N. et al. (2013) SCoBeP: dense image registration using sparse coding and
belief propagation. J. Vis. Commun. Image Represent., 24, 1377147.

Bay,H. et al. (2008) Speeded up robust features (SURF). Comput. Vis. Image
Underst., 110, 3467359.

Berger,C. et al. (2006) Color separation in forensic image processing. J. Forensic
Sci., 51, 1007102.

Brook,A. and Ben—Dor,E. (2011) Automatic registration of airborne and space—
borne images by topology map matching with SURF processor algorithm.
Remote Sens, 3, 65782.

Cardona,A. et al. (2010) An integrated micro— and macroarchitectural analysis of
the drosophila brain by computer—assisted serial section electron microscopy.
PLoS Biol, 8, e1000502.

Cardona,A. et al. (2012) TrakEM2 software for neural circuit reconstruction. PLoS
One, 7, e38011.

Chao,T.K. et al. (2006) The endogenous immune response modulates the course of
IgA—immune complex—mediated nephropathy. Kidney Int., 70, 2837297.

Chakravarty,M. et al. (2006) The creation of a brain atlas for image guided neuro—
surgery using serial histological data. NeuroImage, 30, 3597376.

D’Amico,G. (1987) The commonest glomerulonephritis in the world: IgA nephro—
pathy. Q. J. Med, 65 (1987), 702727.

Dauguet,J. et al. (2007) Three—dimensional reconstruction of stained histological
slices and 3D non—linear registration with in—vivo MRI for whole baboon
brain. Kidney Int, 164, 1917204.

Dreuw,P. et al. (2009) SURF—Face: face recognition under viewpoint consistency
constraints. In: Proceedings of the British Machine Vision Conference. BMVA
Press, London, pp. 717711.

Fischler,M. and Bolles,R. (1981) Random sample consensus: a paradigm for model
ﬁtting with applications to image analysis and automated cartography.
Commun. ACM, 24, 3817395.

Hill,D. et al. (2001) Medical image registration. Phys. Med. Biol., 3, 46, R1745.

Lowe,D. (2004) Distinctive image features from scale—invariant keypoints. Int. J.
Comput. Vis., 60, 917110.

Maes,F. (1997) Multimodality image registration by maximization of mutual infor—
mation. IEEE Trans. Med. Imaging, 16, 1877198.

MathWorks. R2013a imregister. http://www.mathworks.com/help/images/ref/imreg
ister.html (15 May 2013, date last accessed).

Matsopoulos,G.K. et al. (2001) Medical image registration and fusion techniques: a
review. In: Stergiopoulos,S. (ed.) Advanced Signal Processing Handbook. CRC
Press, Boca Raton, FL.

Oliveira,F.P. and Tavares,].M. (2012) Medical image registration: a review.
Methods Biomech. Biomed Engin., [Epub ahead of print, March 22, 2012.].
Pluim,].P. (2003) Mutual—information—based registration of medical images: a

survey. IEEE Trans. Med. Imaging, 22, 1(r25.

Pitiot,A. and Guimond,A. (2008) Geometrical regularization of displacement ﬁelds
for histological image registration. Med. Image Anal, 12, 1(r25.

Ruifrok,A.C. and Johnston,D.A. (2001) Quantiﬁcation of histochemical staining by
color deconvolution. Anal. Quant. Cytol. Histol., 23, 2917299.

Saalfeld,S. et al. (2010) As—rigid—as—possible mosaicking and serial section registra—
tion of large ssTEM datasets. Bioinformatics, 26, i577i63.

Saalfeld,S. et al. (2012) Elastic volume reconstruction from series of ultra—thin
microscopy sections. Nat. Methods, 9, 7177720.

Schneider,C.A. et al. (2012) NIH image to Image]: 25 years of image analysis. Nat.
Methods, 9, 671$75.

Shum,H. and Szeliski,R. (2000) Construction of panoramic mosaics with global and
local alignment. Int. J. Comput. Vis., 36, 1017130.

Sorzano,C. et al. (2005) Elastic registration of biological images using vector—spline
regularization. IEEE Trans. Biomed Eng, 52, 652$63.

SPSS Inc. (2008) SPSS for Windows, Rel.17.0.ISPSS Inc, Chicago.

Tan,Y. et al. (2007) 3D reconstruction from 2D images with hierarchical continuous
simplices. Vis. Comput., 23, 9057914.

Teke,M. and Temizel,A. (2010) Multi—spectral satellite image registration using
scale—restricted SURF. In: Proceedings of the 2010 20th International
Conference on Pattern Recognition, Istanbul. IEEE Computer Society,
Washington, DC, USA, pp. 231(k2313.

Vedaldi,A. (2006) An open implementation of the SIFT detector and descriptor.
UCLA CSD Technical Report 070012, UCLA CSD.

Wang,C. and Yu,C. (in press) Automated morphological classiﬁcation of lung
cancer subtypes using H&E tissue images. Mach. Vis. Appl.

Wang,C. (2012) Fast automatic quantitative cell replication with ﬂuorescent live cell
imaging. BMC Bioinformatics, 13, 21.

Ye,J. and Liu,J. (2012) Sparse methods for biomedical data. SIGKDD Explor.
Newsl., 14, 4715.

Zitova,B. and Flusser,]. (2003) Image registration methods: a survey. Image Vis.
Comput., 21, 97771000.

APPENDIX: FULL STATISTICAL RESULTS

A one-way analysis of variance (ANOVA) is a way to test the
equality of three or more means at one time by using variances.
The total variation is comprised the sum of the squares of the
differences of each mean with the grand mean. There is the
between group variation and the within group variation. The
whole idea behind the analysis of variance is to compare the
ratio of between group variance with within group variance. If
the variance caused by the interaction between the samples is
much larger when compared with the variance that appears
within each group, then it is because the means are not the
same. The signiﬁcant ANOVA result suggests rejecting the
global null hypothesis that the means are the same across
the groups being compared. Multiple comparison procedures
are then used to determine which means differ. Here, Tukey’s
HSD and LSD are used as multiple comparison tests.

 

112 /310's112u1n0fp101x0'sopeurJOJHIOIq/ﬁduq won papeo1umoq

9103 ‘0g1sn8nV uo ::

