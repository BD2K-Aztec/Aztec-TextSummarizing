ORIGINAL PAPER

Vol. 27 no. 21 2011, pages 3036-3043
doi:10. 1 093/bioinformatics/btr500

 

Data and text mining

Advance Access publication September 4, 2011

Gaussian interaction profile kernels for predicting drug—target

interaction

Twan van Laarhovenlai‘, Sander B. Nabuurs2 and Elena Marchiorilai‘

1Department of Computer Science, Radboud University Nijmegen and 2Computational Drug Discovery, Center for
Molecular and Biomolecular Informatics, Radboud University Nijmegen Medical Center, Nijmegen, The Netherlands

Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: The in silico prediction of potential interactions between
drugs and target proteins is of core importance for the identification
of new drugs or novel targets for existing drugs. However, only
a tiny portion of all drug—target pairs in current datasets are
experimentally validated interactions. This motivates the need for
developing computational methods that predict true interaction pairs
with high accuracy.

Results: We show that a simple machine learning method that
uses the drug—target network as the only source of information
is capable of predicting true interaction pairs with high accuracy.
Specifically, we introduce interaction profiles of drugs (and of targets)
in a network, which are binary vectors specifying the presence or
absence of interaction with every target (drug) in that network. We
define a kernel on these profiles, called the Gaussian Interaction
Profile (GIP) kernel, and use a simple classifier, (kernel) Regularized
Least Squares (RLS), for prediction drug—target interactions. We
test comparatively the effectiveness of RLS with the GIP kernel on
four drug—target interaction networks used in previous studies. The
proposed algorithm achieves area under the precision—recall curve
(AUPR) up to 92.7, significantly improving over results of state-of-the-
art methods. Moreover, we show that using also kernels based on
chemical and genomic information further increases accuracy, with a
neat improvement on small datasets. These results substantiate the
relevance of the network topology (in the form of interaction profiles)
as source of information for predicting drug—target interactions.
Availability: Software and Supplementary Material are available at
http://cs.ru.nl/~tvanlaarhoven/drugtarget201 1/.

Contact: tvanlaarhoven@cs.ru.nl; elenam@cs.ru.nl
Supplementary Information: Supplementary data are available at
Bioinformatics online.

Received on June 9, 2011; revised on August 12, 2011; accepted on
August 29, 2011

1 INTRODUCTION

The in silico prediction of interaction between drugs and target
proteins is a core step in the drug discovery process for identifying
new drugs or novel targets for existing drugs, in order to guide and
speed up the laborious and costly experimental determination of
drug—target interaction (Haggarty et al., 2003).

 

*To whom correspondence should be addressed.

Drug—target interaction data are available for many classes
of pharmaceutically useful target proteins including Enzymes,
Ion Channels, G-protein-coupled receptors (GPCRs) and Nuclear
Receptors (Hopkins and Groom, 2002). Several publicly available
databases have been built and maintained, such as KEGG
BRITE (Kanehisa et (11., 2006), DrugBank (Wishart et (11., 2008),
GLIDA (Okuno et (11., 2007), SuperTarget and Matador (Gunther
et al., 2008), BRENDA (Schomburg et al., 2004) and ChEMBL
(Overington, 2009) containing drug—target interaction and other
related sources of information, like chemical and genomic data.

A property of the current drug—target interaction databases is that
they contain a rather small number of drug—target pairs which are
experimentally validated interactions. This motivates the need for
developing methods that predict true interacting pairs with high
accuracy.

Recently, machine learning methods have been introduced to
tackle this problem. They can be viewed as instances of the more
general link prediction problem, see Lu and Zhou (2011) for
a recent survey of this topic. These methods are motivated by
the observation that similar drugs tend to target similar proteins
(Klabunde, 2007; Schuffenhauer et al., 2003). This property was
shown, for instance, for chemical (Martin et al., 2002) and side effect
similarity (Campillos et al., 2008), and motivated the development
of an integrated approach for drug—target interaction prediction
(Jaroch and Weinmann, 2006). A desirable property of this approach
is that it does not require the 3D structure information of the target
proteins, which is needed in traditional methods based on docking
simulations (Cheng et al., 2007).

The current state-of-the-art for the in silico prediction of drug—
target interaction is formed by methods that employ similarity
measures for drugs and for targets in the form by kernel functions,
like Bleakley and Yamanishi (2009); Jacob and Vert (2008);
Wassermann et al. (2009); Yamanishi et a1. (2008, 2010). By using
kernels, multiple sources of information can be easily incorporated
for performing prediction (Scholkopf et al., 2004).

In Yamanishi et a1. (2008), different settings of the interaction
prediction problem are explored.

The authors make the distinction between ‘known’ drugs or
targets, for which at least one interaction is in the training set, and
‘new’ drugs or targets, for which there is not. There are then four
possible settings, depending on whether the drugs and/or targets are
known or new. In this article, we focus on the setting where both
the drugs and targets are known. That is, we use known interactions
for predicting novel ones.

 

3036 © The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com

112 /3.Io's[Bumo[pJOJXO'sorwuiJOJurorqﬂ:duq 11101} papeolumoq

91oz ‘Og anﬁnv uo ::

GIP kernel

 

We want to analyze the relevance of the topology of drug—
target interaction networks as source of information for predicting
interactions. We do this by introducing a kernel that captures the
topological information. Using a simple machine learning method,
we then compare this kernel to kernels based on other sources of
information.

Speciﬁcally, we start from the assumption that two drugs that
interact in a similar way with the targets in a known drug—target
interaction network, will also interact in a similar way with new
targets. We formalize this property by describing each drug with
an interaction proﬁle, a binary vector describing the presence
or absence of interaction with every target in that network. The
interaction proﬁle of a target is deﬁned in a similar way. From these
proﬁles, we construct the Gaussian Interaction Proﬁle kernel.

We show that interaction proﬁling can be effectively used for
accurate prediction of drug—target interaction. Speciﬁcally, we
propose a simple regularized least square algorithm incorporating
a product of kernels constructed from drug and target interaction
proﬁles. We test the predictive performance of this method on four
drug—target interaction networks in humans involving Enzymes,
Ion Channels, GPCRs and Nuclear Receptors. These experiments
show that using only information on the topology of the drug—target
interaction, in the form of interaction proﬁles, excellent results are
achieved as measured by the area under the precision—recall curve
(AUPR) (Davis and Goadrich, 2006). In particular, on three of the
four considered datasets the performance is superior to the best
results of current state-of—the-art methods that use multiple sources
of information.

We further show that the proposed method can be easily
extended to also use other sources of information in the form
of suitable kernels. Results of experiments where also chemical
and genomic information on drugs and targets is included show
excellent performance, with AUPR score of 91.5, 94.3, 79.0 and
68.4 on the four datasets, achieving an improvement of 7.4,
13.0, 12.3 and 7.2 over the best results reported in Bleakley
and Yamanishi (2009). A thorough analysis of the results enable
us to detect several new putative drug—target interactions, see
http://cs.ru.nl/~tvanlaarhoven/drugtarget201 1/new-interactions/.

2 MATERIALS

We used four drug—target interaction networks in humans involving
Enzymes, Ion Channels, GPCRs and Nuclear Receptors, ﬁrst
analyzed by Yamanishi et al. (2008). We worked with the datasets
provided by these authors, in order to facilitate benchmark
comparisons with the current state-of-the-art algorithms that do the
same. These datasets are publicly available at http://web.kuicr.kyoto-
u.ac.jp/supp/yoshi/drugtarget/. Table 1 lists some properties of the
datasets.

Drug—target interaction information was retrieved from the
KEGG BRITE (Kanehisa et al., 2006), BRENDA (Schomburg et al.,
2004), SuperTarget (Gunther et al., 2008) and DrugBank (Wishart
et al., 2008) databases. Chemical structures of the compounds was
derived from the DRUG and COMPOUND sections in the KEGG
LIGAND database (Kanehisa et al., 2006). The chemical structure
similarity between compounds was computed using SIMCOMP
(Hattori et al., 2003). This resulted in a similarity matrix denoted
by SC, which represents the chemical space. Amino acid sequences
of the target (human) proteins were obtained from the KEGG

Table 1. The number of drugs and target proteins, their ratio and the number
of interactions in the drugetarget datasets from Yamanishi at al. (2008)

 

 

Dataset Drugs Targets rid /n[ Interactions
Enzyme 445 664 0.67 2926
Ion Channel 210 204 1.03 1476
GPCR 223 95 2.35 635
Nuclear Receptor 54 26 2.08 90

 

 

drug interaction proﬁles
(1, d, d, d, d,

 t. Emu 
t2  

drug—target network

 

 

target interaction proﬁles
t, t, t, t,

2...", all m 
d2 

 

 

 

 

 

 

Fig. 1. An illustration of the construction of interaction proﬁles from a druge
target interaction network. Circles are drugs, and squares are targets. In this
example, the interaction proﬁle of target [1 indicates that it interacts with
drugs [1’1 and d2, but not with d3, d4 or d5.

GENES database (Kanehisa et al., 2006). Sequence similarity
between proteins was computed using a normalized version of
Smith—Waterman score (Smith and Waterman, 1981), resulting in
a similarity matrix denoted S g, which represents the genomic space.

3 METHODS

3.1 Problem formalization

We consider the problem of predicting new interactions in a drugetarget
interaction network. Formally, we are given a set Xd={d1,d2,...,d,,d} of
drugs and a set X[={tl,tz,...,t,,[} of target proteins. There is also a set
of known interactions between drugs and targets. If we consider these
interactions as edges, then they form a bipartite network. We can characterize
this network by the rid X m adjacency matrix Y. That is, yij=1 if drug [111'
interacts with target I]- and y,»ij otherwise. Our task is now to rank all
drugetarget pairs (di, [1) such that highest ranked pairs are the most likely to
interact.

3.2 Gaussian interaction proﬁle kernel

Our method is based on the assumption that drugs exhibiting a similar pattern
of interaction and non-interaction with the targets of a drugetarget interaction
network are likely to show similar interaction behavior with respect to new
targets. We use a similar assumption on targets. We, therefore, introduce the
(target) interaction proﬁle yd,» of a drug [111' to be the binary vector encoding the
presence or absence of interaction with every target in the considered druge
target network. This is nothing more than row i of the adjacency matrix Y.
Similarly, the (drug) interaction proﬁle y; of a target protein t]- is a vector
specifying the presence or absence of interaction with every drug in the
considered drugetarget network. The interaction proﬁles generated from a
drugetarget interaction network can be used as feature vectors for a classiﬁer.
Figure 1 illustrates the construction of interaction proﬁles.

 

3037

112 /3.Io's[BumoIpJOJXO'sorwuiJOJurorq”:duq 11101} papBOIII/lAOG

91oz ‘Og anﬁnv uo ::

T.van Laarhoven et al.

 

Following the current state-of—the-art for the drugetarget interaction
prediction problem, we will use kernel methods, and hence construct a kernel
from the interaction proﬁles. This kernel does not include any information
beyond the topology of the drugetarget network.

One of the most popular choices for constructing a kernel from a feature
vector is the Gaussian kernel, also known as the radial basis function (RBF)
kernel. This kernel is, for drugs (1’) and d-,

Kama/1m,» =exp(—yd My.” —ya,- “2).

A kernel for the similarities between target proteins, KGIRL, can be deﬁned
analogously. We call these kernels Gaussian Interaction Proﬁle (GIP) kernels.
The parameter yd controls the kernel bandwidth. We set

1 rid
t 2
Vd—J/d/( E Id’I 
di:l yl

That is, we normalize the parameter by dividing it by the average
number of interactions per drug. With this choice, the kernel values become
independent of the size of the dataset. In principle, the new bandwidth
parameter J74 could be set with cross-validation, but in this article, we simply
use J74 = 1.

There are other ways to construct a kernel from interaction proﬁles. For
example, Basilico and Hofmann (2004) propose using the correlation of
interaction proﬁles. We have performed brief experiments with these other
kernels, which show that GIP kernels consistently outperform kernels based
on correlation or inner products. The detailed results of these experiments
are included in Supplementary Table $1.

3.3 Integrating chemical and genomic information

We construct kernels containing information about the chemical and genomic
space from the similarity matrices Si and S g. Since these similarity matrices
are neither symmetric nor positive deﬁnite, we apply a simple transformation
to make them symmetric with Ssym=(S +S T)/ 2 and add a small multiple
of the identity matrix to enforce the positive deﬁnite property. We denote
the resulting kernels for drugs and targets by Kchemicalyd and ngnomicyl,
respectively.

To combine the interaction proﬁle kernel with these chemical and genomic
kernels, we use a simple weighted average,

Kd =achhemic-am +(1 —€¥d)KGIP,d
Kt Zatngnomic,t +(1 _ at)KGIRt-

For the reported results of our evaluation, we use simply the unweighted
average, for both drugs and targets, i.e. ad=a[=0.5. In Section 4.2, we
further analyze the effect of these parameters on the predictive performance
of the method.

3.4 RLS-avg classiﬁer

In principle, we could use the GIP kernels with any kernel-based
classiﬁcation or ranking algorithm. We choose to use a very basic classiﬁer,
the (kernel) Regularized Least Squares (RLS) classiﬁer. While Least Squares
is primarily used for regression, when a good kernel is used it has
classiﬁcation accuracy similar to that of Support Vector Machines (Rifkin
and Klautau, 2004). Our own experiments conﬁrm this ﬁnding. In the RLS
classiﬁer, the predicted values 9 with a given kernel K have a simple closed
form solution,
9=K(K+a1>“y.

where a is a regularization parameter. Higher values of a give a smoother
result, while for 0:0 we get 9: y, and hence no generalization at all. The
value 9 is a real-valued score, which we can interpret as a conﬁdence.

The RLS classiﬁer is sensitive to the encoding used for y. Here, we
use 1 for encoding interacting pairs and O for non-interacting ones. Brief
experiments have shown that the classiﬁer is not sensitive to this choice, as
long as the value used for non-interactions is close to 0. Using a value

very different from 0, like —1, would place too much weight on non-
interactions. The classiﬁer would then try to avoid predicting pairs that look
like non-interactions, rather than predicting pairs that look like interactions.

In the previous sections, we deﬁned kernels on drugs and kernels on target
proteins. There are several ways in which we can use kernels in both these
dimensions. Following other works, like Bleakley and Yamanishi (2009);
Zheng Xia and Wong (2010), a simple and effective approach is to apply
the classiﬁer for each drug independently using only the target kernel, and
also for each target independently using only the drug kernel. Then the ﬁnal
score for a drugetarget pair is a combination of the two outputs.

Here we use the average of the output values, and denote the resulting
method by RLS-avg. Observe that in the formulation of the RLS classiﬁer
that we use, performing independent prediction amounts to replacing the
vector y with the matrix Y, and hence the prediction of RLS-avg is

A 1 1
Y: E (Kd(Kd+aI)—‘ Y) + E (K,(K,+a1)—l YT)T.
Note this model is slightly different from using the Kronecker sum kernel
(Kashima at al., 2009a). Since regularization is performed for drugs and
targets separately in the RLS-avg method, rather than jointly.

3.5 RLS-Kron classiﬁer

A better alternative is to combine the kernels into a larger kernel that directly
relates drugetarget pairs. This is done with the Kronecker product kernel
(Basilico and Hofmann, 2004; Ben-Hur and Noble, 2005; Hue and Vert,
2010; Oyama and Manning, 2004). The Kronecker product Kd®Kl of the
drug and target kernels is

K((divU)v(dkvtl))=Kd(divdk)Kt(thl)-
With this kernel, we can make predictions for all pairs at once,
vec(YT)=K(K+UI)_lvec(YT),

where vec(YT) is the a vector of all interaction pairs, created by stacking the
columns of YT. We call this method RLS-Kron.

Using the Kronecker product kernel directly would involve calculating the
inverse of an mm, X nan, matrix, which would take (9((ndnl)3) operations,
and would also require too much memory. We use a more efﬁcient
implementation based on eigen decompositions, previously presented in
Raymond and Kashima (2010).

Let K; 2 WA; VdT and Kl: VLALVLT be the eigen decompositions of the
two kernel matrices. Since the eigenvalues (vectors) of a Kronecker product
are the Kronecker product of eigenvalues (vectors), for our Kronecker
product kernel we have simply K=Kd®KL= VAVT, where A = Ad®Al
and V: Vd® VI. The matrix that we want to invert, K +01 has these same
eigenvectors V, and eigenvalues A+0'I. Hence

K(K+a1)—l =VA(A+aI)—‘VT.

To efﬁciently multiply this matrix with vec(YT), we can use a further
property of the Kronecker product, namely that (A ®B)Vec(X) = vec(BXAT).
Combining these facts, we get that the RLS prediction is

1?: deTV.T.

where
vec(Z)=(Ad®A[)(Ad®Al+al)_lvec(VlTYT Vd).

So, to make a RLS prediction using the Kronecker product kernel we
only need to perform the two eigen decompositions and some matrix
multiplications, bringing the runtime down to (9(nd3 +nl3). The efﬁciency
of this computation could be further improved yielding a quadratic
computational complexity by applying recent techniques for large-scale
kernel methods for computing the two kernel decompositions (Kashima at al. ,
2009b; Wu et al., 2006).

 

3038

112 /3.Io's[BumoIpJOJXO'sorwuiJOJurorq”:dnq moi; papaolumoq

91oz ‘Og isnﬁnv uo ::

GIP kernel

 

3.6 Comparison methods

In order to assess globally the performance of our method, we compare it
against current state-of-the-art algorithms. To the best of our knowledge, the
best results on these datasets obtained so far are those reported by Bleakley
and Yamanishi (2009), where the Bipartite Local Models (BLM) approach
was introduced. These results were achieved by combining the output scores
of the Kernel Regression Method (KRM) (Y amanishi at al., 2008) and BLM
by taking their maximum value. We brieﬂy recall these methods here.

In the KRM method, drugs and targets are embedded into a uniﬁed space
called the ‘pharmacological space”. A regression model is learned between
the chemical structure (respectively, genomic sequence) similarity space and
this pharmacological space. Then new potential drugs and targets are mapped
into the pharmacological space using this regression model. Finally, new
drugetarget interactions are predicted by connecting drugs and target proteins
that are closer than a threshold in the pharmacological space.

The BLM method is similar to our RLS-avg method. In the BLM method,
the presence or absence of a drugetarget interaction is predicted as follows.
First, the target is excluded, and a training set is constructed consisting of
two classes: all other known targets of the drug in question, and the targets
not known to interact with that drug. Second, a Support Vector Machine that
discriminates between the two classes is constructed, using the available
genomic kernel for the targets. This model is then used to predict the label of
the target, and hence the interaction or non-interaction of the considered
drugetarget pair. A similar procedure is applied with the roles of drugs
and targets reversed, using the chemical structure kernel instead. These two
results are combined by taking the maximum value.

4 EVALUATION

In order to compare the performance of the methods, we performed
systematic experiments simulating the process of bipartite network
inference from biological data on four drug—target interaction
networks. These experiments are done by ﬁill leave-one-out cross-
validation (LOOCV) as follows. In each run of the method, one
drug—target pair (interacting or non-interacting) is left out by setting
its entry in the Y matrix to 0. Then we try to recover its true label
using the remaining data.

Note that when leaving out a drug—target pair the Y matrix
changes, and therefore the GIP kernel has to be recomputed.

We also performed a variation of these experiments using ﬁve
trials of 10-fold cross-validation. We recomputed the GIP kernels
for each fold, also for 10-fold cross-validation. So no information
about the removed interactions was leaked in this way.

The results can be found in Supplementary Table S2; we observed
no large differences compared with the results obtained using
LOOCV.

In all experiments, we have chosen the values for the parameters
in an uninformative way. In particular, we set the regularization
parameter 0:1 for both RLS methods; and as stated before, we
set the kernel bandwidths 17d =j7t :1 for both the drug and target
interaction proﬁle kernels.

We assessed the performance of the methods with the following
two quality measures generally used in this type of studies: AUC
and AUPR. Speciﬁcally, we computed the ROC curve of true
positives as a ﬁinction of false positives, and considered the AUC as
quality measure (see for instance Fawcett, 2006). Furthermore, we
considered the the precision—recall curve (Raghavan et al., 1989),
that is, the plot of the ratio of true positives among all positive
predictions for each given recall rate. The area under this curve
(AUPR) provides a quantitative assessment of how well, on average,
predicted scores of true interactions are separated from predicted

Table 2. Results on the drugetarget interaction datasets

 

 

 

 

 

 

 

 

 

 

 

 

 

Dataset Method Kernel AUC AUPR
BYO9 (AUC) chem/gen 97.6 83.3
BYO9 (AUPR) chem/ gen 97.3 84.1
Enzyme RLS-avg GIP 98.2 88.1
RLS -an chem/ gen 96.6 84.5
RLS-avg avg. 97.9 90.5
RLS-Kron GIP 98.3* 88.5
RLS -Kron chem/ gen 96.6 85.6
RLS-Kron avg. 97.8 91.5*
BYO9 (AUC) chem/gen 97.3 78.1
BYO9 (AUPR) chem/gen 93.5 81.3
Ion Channel RLS-avg GIP 98.5 91.8
RLS -an chem/ gen 97.1 80.7
RLS-avg avg. 98.1 93.2
RLS-Kron GIP 98.6* 92.7
RLS -Kron chem/ gen 97.1 77.5
RLS -Kron avg. 98.4 94.3*
BYO9 chem/ gen 95.5 * 66.7
RLS -an GIP 94.5 70.0
GPCR RLS -an chem/ gen 94.7 66.0
RLS-avg avg. 95.0 77.1
RLS -KIOIl GIP 94.7 71.3
RLS -Kron chem/ gen 94.8 63. 8
RLS -Kron avg. 95.4 79.0
BYO9 chem/gen 88.1 61.2
RLS -an GIP 88.7 60.4
NUCIBSI Receptor RLS -an chem/ gen 86.4 54.7
RLS-avg avg. 925* 67.0
RLS -KIOIl GIP 90.6 61.0
RLS -Kron chem/ gen 85.9 51.1
RLS-Kron avg. 92.2 68.4*

 

The AUC and AUPR scores are normalized to 100. For each dataset, *indicates the
highest AUC/AUPR score.

scores of true non-interactions. For this task, because there are few
true drug—target interactions, the AUPR is a more signiﬁcant quality
measure than the AUC, as it punishes much more the existence
of false positive examples found among the best ranked prediction
scores (Davis and Goadrich, 2006).

Table 2 contains the results for the two RLS-based classiﬁers,
RLS-avg and RLS-Kron, each with three different kernel
combinations:

0 GIP: using only the GIP kernels, i.e. Kd=KGIRd and Kt:
KGIPJ, corresponding to Old =at = 1.

 

3039

112 /3.Io's[BumoIpJOJXO'sorwuiJOJurorq”:dnq moi; papaolumoq

91oz ‘Og isnﬁnv uo ::

T.van Laarhoven et al.

 

(a) 1.0-..... (b)1.0-

0.8 0.8

0.6 0.6

Precision
Precision

0.4 0.4

0.2 0.2

 

 

 

0.0 0.0

 

Precision

Precision

 

   

 

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8
Recall Recall

 

I 0.0 0.2 0.4 0.6 0.8 1.0 I 0.
Recall

0.2 0.4 0.6 0.8 1 .0
Recall

Fig. 2. Precisionerecall curves for the RLS-Kron method. The red dotted line corresponds to using only the chemical and genomic kernels. The green dashed
line corresponds to using only the GIP kernels. The blue solid line corresponds to the average of the two types of kernels. On all datasets, the average kernel
shows a small improvement over either kernel type alone. (3) Enzyme; (b) ion channel; (c) GPCR; (d) nuclear receptor.

0 chem/gen: using only the chemical structure and genomic
sequence similarity, so Kd=KChemicaLd and Kt=ngn0miQh
corresponding to aid =at = 0.

0 avg: using the average of the two types of kernels,
corresponding to Old =at :05.

For comparison, we have also included in the table as BY09 (AUC)
and BY09 (AUPR), the best results from the combined BML and
KRM methods from Bleakley and Yamanishi (2009). For the GPCR
and nuclear receptor datasets, the method with the highest AUC is
the same as the one with the highest AUPR, therefore it is included
only once, as BY09.

4.1 Analysis

Using only the GIP kernel, our Kronecker product RLS method
has AUPR scores of 88.5, 92.7, 71.3 and 61.0 on the Enzyme, Ion
Channel, GPCR and nuclear receptor datasets, respectively. These
results are superior to the results from using only the chemical and
genomic kernels.

Overall, the RLS-Kron and RLS-avg methods have comparable
AUC scores. However, the RLS-Kron has a better AUPR when using
the GIP kernel, and a worse AUPR when using the chemical and
genomic kernels. We believe that this problem is due to the poor
quality of the chemical similarity kernel, to which the RLS-Kron
method is more sensitive.

Note also that the RLS-avg method is comparable to Bleakley and
Yamanishi’s bipartite local model (BLM) approach. The differences
are that whereas we use a RLS classiﬁer, they use Support Vector
Machines; and whereas we use the average to combine results, they
use the maximum value. It is therefore not surprising that when
using the chemical and genomic kernels, the results of the RLS-avg
method are very similar to their results.

In all cases, the best results are obtained when the GIP kernels are
combined with the chemical and genomic kernels. With the RLS-
Kron method, we then obtain AUPR scores of 91.5, 94.3, 79.0 and
68.4 on the four datasets, which is an improvement of 7.4, 13.0, 12.3
and 7.2 over the best results reported by Bleakley and Yamanishi
(2009). Figure 2 shows the precision—recall curves for the RLS-
Kron method. Compared with other methods, the RLS-Kron method
with the average kernels achieves a good precision also at higher
recall values, especially on the larger datasets (Enzyme and Ion
Channel).

 

 

 

 

 

 

 

 

 

AUPR AUC
75.2 94.6
3%” 0 s
53.7 92.6
0 |.
0 0.5 I 0 0.5 I

[Yimgei [Yimgei

Fig. 3. AUPR and AUC scores for the GPCR dataset with different
weightings of the kernels. Lighter colors are better. For all datasets Old:
01,205 gives near optimal results.

4.2 Kernels’ relevance

In the previous section, we have shown that using a mix of the
GIP kernels and the chemical and genomic kernels gives results
superior to either type of kernel alone. In order to determine
the relative importance of the network topology compared with
chemical and sequence similarity, we have investigated the change
in prediction performance when varying the parameters Old and
at between 0 (chemical/genomic kernels only) and 1 (interaction
proﬁles kernels only). For computational reasons, we have used
10-fold cross-validation instead of leave-one-out.

In Figure 3, we have plotted the AUPR and AUC scores on the
GPCR dataset for the different parameter values. Lighter colors
correspond to higher values. Because of space limitations, plots for
the other datasets are included in Supplementary Figures S1 and S2.
For all datasets, the optimal AUPR is obtained using a mix of the
drug and target kernels. Using the parameters Old =at :05, as we
did in the previous section, seems to be a good choice across the
datasets. Also note that the choice of Old is more important than the
choice of at. This seems to indicate that the sequence similarity for
targets is more informative than the chemical similarity for drugs.
A similar observation was also made in Bleakley and Yamanishi
(2009). The poor performance of the RLS-Kron method when using
only chemical and genomic kernels that we observed in the previous
section appears to be due entirely to this uninformative chemical
similarity.

On the larger datasets (Enzyme and Ion Channel), the optimal
AUC is obtained with Old: 1, while that choice gives the worst
results on the smaller datasets. This can be explained by noting that
when there are few drugs, there is less information available for each
entry of GIP target kernel, and hence this kernel will be of a lower
quality. We have conﬁrmed this hypothesis by testing different sized

 

3040

112 /3.Io's[BumoIpJOJXO'sorwuiJOJurorq”:duq moi; papaolumoq

9103 ‘Og isnﬁnv uo ::

GIP kernel

 

Table 3. The top 10 new interactions predicted in the GPCR dataset, 4 have
been conﬁrmed (shown in bold)

 

 

 

 

 

 

 

 

 

 

 

Rank Pair Description NN
1 D00283 Clozapine 0.769
[C,D] hsa1814 DRD3: dopamine receptor D3 0.455
2 D02358 Metoprolol 0.750
[C,D] hsa154 ADRBZ: beta-2 adrenergic receptor 0.434
3 D00604 Clonidine hydrochloride 0.933
hsa147 ADRAlB: alpha-1B adrenergic receptor 0.435
4 D03966 Eglumegad 0.036
hsa2914 GRM4: glutamate receptor, metabotropic 4 0.768
5 D00255 Carvedilol 0.380
hsa152 ADRA2C: alpha-2C adrenergic receptor 0.489
6 D04625 Isoetharine 0.737
[K] hsa154 ADRBZ: beta-2 adrenergic receptor 0.434
7 D03966 Eglumegad 0.036
hsa2917 GRM7: glutamate receptor, metabotropic 7 0.758
8 D02340 Loxapine 0.769
[D] hsa1812 DRDl: dopamine receptor D1 0.205
9 D00503 Perphenazine 0.857
hsa1816 DRD5: dopamine receptor D5 0.529
10 D00682 Carboprost tromethamine 0.914
hsa5739 PTGIR: prostaglandin I2 receptor (IP) 0.150

 

Interactions that appear in the ChEMBL database are marked with ‘[C]’, interactions in
Drugbank are marked with ‘[D]’, and interactions in Kegg are marked with ‘[K]’. The
NN column gives the similarity to the nearest drug interacting with the same target, and
to the nearest target interacting with the same drug.

subsets of the Ion Channel dataset, where we observe the same effect
on small subsets. The ﬁill results of that experiment are available in
Supplementary Figure S3.

4.3 New predicted interactions

In order to analyze the practical relevance of the method
for predicting novel drug—target interactions, we conducted an
experiment similar to that described by Bleakley and Yamanishi
(2009). We ranked the non-interacting pairs according to the scores
computed for LOOCV experiments. We estimate the most highly
ranked drug—target pairs as most likely to be putative interactions.
A list of the top 20 new interactions predicted for each of the four
datasets can be found in Supplementary Tables S3—S6.

Table 3 lists the top 10 new interactions predicted for the GPCR
dataset. We have looked up these predicted interactions in ChEMBL
version 9 (Overington, 2009), DrugBank (Wishart et al., 2008)
and the latest online version of KEGG DRUG (Kanehisa et al.,
2006). A signiﬁcant fraction of the predictions (4 out of 10) is
found in one or more of these databases. One should bear in
mind that a large fraction of the interactions in these databases are
already included in the training data, and hence are not counted

Table 4. The number of highly ranked new interactions that are found in at
least one of the three considered databases (ChEMBL, DrugBank or KEGG
DRUG)

 

Dataset Method Top 20 (%) Top 50 (%) Top 80 (%)

 

BY09 6 (30) 15 (30) 17 (21)

Enzyme RLS-Kron-avg 11 (55) 15 (30) 22 (28)

 

BY09 11 (55) 14 (28) 18 (22)

10“ Channel RLS-Kron-avg 8 (40) 12 (24) 22 (28)

 

BY09 13 (65) 22 (44) 30 (38)

GPCR RLS-Kron-avg 9 (45) 28 (56) 40 (50)

 

BY09 5 (25) 15 (30) 22 (28)

Nuﬂw Receptor RLS-Kron-avg 9(45) 20 (40) 22 (28)

 

as new interactions. Moreover, these databases are incomplete,
so if a predicted interaction is not present in one of the used
databases, this does not necessarily mean it does not exist. For this
dataset, we started with only 635 known drug—target interactions
and 20 550 drug—target pairs not known to interact. Of these 20 550
pairs, we selected 10 as putative drug—target interaction, and found
that at least 4 of them are experimentally veriﬁed. These ﬁndings
support the practical relevance of the proposed method.

We compared the newly predicted interactions generated by RLS-
Kron-avg and those generated by Bleakley and Yamanishi (2009),
here referred to as BY09. Speciﬁcally, given a dataset, for each
method we extracted from its top x new predictions those that
have been experimentally validated (that is, that could be found
in ChEMBL, DrugBank or KEGG DRUG). Table 4 contains a
summary of the results for x=20,50, 80. Looking at the top 20
predictions, it seems that the two methods perform best on different
datasets. For the top 50 and top 80 predictions, the results indicate
the capability of RLS-Kron-avg to predict successﬁilly more new
interactions than BY09.

We then compared the resulting two sets of conﬁrmed new
predictions among the top 50, by looking at common predictions and
at interactions uniquely predicted by only one of the two methods.
The results for the four datasets can be found in Supplementary
Tables S7—SlO.

On the Enzyme dataset, BY09 and RLS-Kron-avg successfully
predicted 15 new interactions, with 10 common predictions. On
the Ion Channel dataset, BY09 and RLS-Kron-avg successfully
predicted 14 and 12 new interactions, respectively, of which only 1
interaction was predicted by both methods. Although BY09 found
slightly more conﬁrmed interactions they were less diverse, since
11 of them involve interactions between (different types of) the
voltage-gated sodium channel alpha subunit target and only 2
drugs: prilocaine and tocainide. On the other hand, RLS-Kron-avg
found interactions of 4 different classes of targets and 10 different
drugs. On the GPCR dataset, BY09 and RLS-Kron-avg successfully
predicted 22 and 28 new interactions, respectively, with 14 common
predictions. Finally, on the Nuclear Receptor dataset, BY09 and
RLS-Kron-avg successﬁilly predicted 15 and 20 new interactions,
respectively. Among them, 13 were in common.

 

3041

112 /3.Io's[BumoIpJOJXO'sorwuiJOJurorq”:duq moi; papaolumoq

9103 ‘Og isnﬁnv uo ::

T.van Laarhoven et al.

 

In general, the two methods seem to differ in the type of
new predictions made. While there is always an overlap of new
interactions between the two methods, there is also always a
subset of new interactions which RLS-Kron-avg can successﬁilly
predict but BY09 fails to predict and vice versa. Moreover, there
seems to be a slight tendency of BY09 to generate new successful
predictions that are less diverse than those generated by RLS-
Kron-avg. However, we were not able to identify any differential
biological bias of the methods toward the detection of speciﬁc types
of interactions.

4.4 Surprising interactions

A closer inspection shows that many of the predicted interactions
are not very surprising. For example, the GPCR dataset contains
the interaction between clozapine and dopamine receptor D1. The
drug loxapine is very similar to clozapine, and it is therefore to
be expected that our method also predicts loxapine to interact
with dopamine receptor D1. An analogous thing happens with very
similar target proteins. In order to provide a quantitative measure of
how surprising these predictions are, we computed the similarity
of a the drug and target in an interaction pair to their Nearest
Neighbor (NN), that is, the most similar drug (with respect to
chemical structure similarity) and target (with respect to sequence
similarity) in the training set, respectively. These similarities, which
we call surprise scores, are listed in the NN column of Table 3. An
inspection of the surprise scores shows that the majority of the drug—
target pairs predicted by our method consist of a drug and a target
very similar to a drug and a target already known to interact, and
therefore they are not very surprising. This phenomenon is common
to any computational approach that uses similarity between objects
for inferring interaction.

To assess the ability of our method to also predict more surprising
interactions, we have looked speciﬁcally at the predicted interactions
where there is no similar drug interacting with the same target
or similar target interacting with the same drug in the dataset.
We pick a threshold value and consider drugs (targets) to be
dissimilar if their chemical (genomic) similarity is less than this
threshold. We have used the threshold 0.5 for the chemical similarity
and 0.25 for the genomic similarity.

When only these ‘surprising’ pairs are considered, we ﬁnd, as
expected, that fewer of them are present in the ChEMBL, DrugBank
and KEGG databases. But we still ﬁnd more interactions among the
highly ranked ‘surprising’ pairs compared with those that are ranked
lower. For example, on the GPCR dataset, 89 of the 500 highest
ranked pairs were surprising, and 10 of them (11%) were found in
one of the databases (see Supplementary Material for details).

5 DISCUSSION

We have presented a new kernel that leads to good predictive
performance as measured by AUPR on the task of predicting
interactions between drugs and target proteins. An interesting aspect
of our GPI kernel is that it uses no properties beyond the interactions
themselves. This means that knowing the sequence of proteins and
chemical structure of drugs is perhaps not as important for this task
as previously thought. For example, on the Ion Channel dataset our
method with only the GIP kernel has an AUC score of 98.6 and

an AUPR score of 92.7, which improves upon the state-of-the-art,
while using less prior information.

Besides the GIP kernel, we have also introduced the RLS-Kron
algorithm that combines a kernel on drugs and a kernel on targets
using the Kronecker product. Compared with previous methods that
do prediction with the two kernels independently and then combine
the results, this new method represents a small but consistent
improvement.

By combining the GIP kernel with chemical and genomic
information, we get a method with excellent performance. This
method has AUPR scores of 91.5, 94.3, 79.0 and 68.4 on four
datasets of drug—target interaction networks in humans, representing
an average improvement of 10 points over previous results. The
AUPR is a particularly relevant metric for this problem, because it
is very sensitive to the correctness of the highest ranked predictions.
The large improvement in AUPR suggests that the top ranked
putative drug—target interactions found by our method are more
likely to be correct than those found in previous methods.

A limitation of all machine learning methods for ﬁnding new
drug—target interactions is that they are sensitive to inherent biases
contained in the training data. It would be interesting to try and
analyze the bias of existing datasets of drug—target interaction, but
this is out of the scope of this article. Note also that the datasets
by Yamanishi et al. (2008) used in this article do not include any
singletons: each drug interacts with at least one target, and each
target interacts with at least one drug. This property could affect
the cross-validation results, by allowing a limited form of cheating.
However, the experiments in Section 4.3 show that our method also
works when tested in other ways.

A further limitation of the approach used in this article is that
it can only be applied to detect new interactions for a target or a
drug for which at least one interaction has already been established.
Therefore, biologists can use the method as guidance for extending
their knowledge about the interaction of a drug or of a target, not
for discovering interactions of a new drug or target (that is, one for
which no interaction is known). In particular, our method is useful
for experimentalist to aid in experimental design and interpretation,
especially in solving problems related to drug—target selectivity
and polypharmacology (Merino et al., 2010; Metz and Hajduk,
2010).

There are several ways in which the result might ﬁirther be
improved. So far we have used uninformative choices of the
parameters: )7 = 1, a = 1 and a = 0.5. Of these choices, we have only
investigated the last one. Perhaps with tuning of the other parameters
better predictions are possible, although one has to be careful not to
over-ﬁt them to the data.

Another avenue for improvement is in using more information
about drugs and targets. Since combining the GIP kernel with
chemical and genomic kernels leads to a better predictive
performance, perhaps adding different information in the form of
additional kernels would yield further improvements. These kernels
could be interaction proﬁle kernels based on other types data, such
as protein—protein interaction networks. Similarly, for each pair of
interacting drug and target more information is known beyond the
fact they interact. For example, the type of interaction, the binding
strength, the mechanism of discovery and its uncertainty might all
be known. In this article, we have made no use of this additional
information, nor did we attempt to predict the type or strength of
interactions.

 

3042

112 /3.Io's[BrunoIpJOJXO'sotwuiJOJurorq”:duq 111011 papBo1umoq

9103 ‘0g isnﬁnv uo ::

GIP kernel

 

Funding: Netherlands Organization for Scientiﬁc Research (NWO)
within NWO project (612.066.927, in part).

Conﬂict of Interest: none declared.

REFERENCES

Basilico,J . and Hofmann,T. (2004) Unifying collaborative and content-based ﬁltering. In
I CML '04: Proceedings of the 21 st International Conference on Machine learning.
ACM, New York, NY, pp. 65772.

Ben-Hur,A. and Noble,W. S. (2005) Kernel methods for predicting proteineprotein
interactions. Bioinformatics, 21 (Suppl. 1), i38ei46.

Bleakley,K. and Yamanishi,Y. (2009) Supervised prediction of drug-target interactions
using bipartite local models. Bioinformatics, 25, 239772403.

Campillos,M. et al. (2008) Drug target identiﬁcation using side-effect similarity.
Science, 321, 2637266.

Cheng,A.C. et al. (2007) Structure-based maximal afﬁnity model predicts small-
molecule druggability. Nat. Biotechnol, 25, 7175.

Davis,J. and Goadrich,M. (2006) The relationship between precision-recall and ROC
curves. In ICML '06: Proceedings of the 23rd International Conference on Machine
learning. ACM, New York, NY, pp. 2337240.

Fawcett,T. (2006) An introduction to ROC analysis. Patt. Recognit. Lett., 27, 8617874.

Gﬁnther,S. et al. (2008) SuperTarget and Matador: resources for exploring drug-target
relationships. Nucleic Acids Res, 36, D9197D922.

Haggarty,S.J. et al. (2003) Multidimensional chemical genetic analysis of diversity-
oriented synthesis-derived deacetylase inhibitors using cell-based assays. Chem.
Biol, 10, 3837396.

Hattori,M. et al. (2003) Development of a chemical structure comparison method for
integrated analysis of chemical and genomic information in the metabolic pathways.
J. Am. Chem Soc., 125, 11853711865.

Hopkins,A.L. and Groom,C.R. (2002) The druggable genome. Nat. Rev. Drug Discov.,
1, 7277730.

Hue,M. and Vert,J.-P. (2010) On learning with kernels for unordered pairs. In
Fiirnkraan. and Joachims ,T. (eds) ICML ’10: Proceedings of the 2 7th International
Conference on Machine Learning. Omnipress, Haifa, Israel, pp. 463470.

Jacob,L. and Vert,J.-P. (2008) Protein-ligand interaction prediction: an improved
chemogenomics approach. Bioinformatics, 24, 214972156.

Jaroch,S.E. and Weinmann,H. (eds) (2006) Chemical Genomics: Small Molecule
Probes to Study Cellular Function. Ernst Schering Research Foundation Workshop.
Springer, Berlin.

Kanehisa,M. et al. (2006) From genomics to chemical genomics: new developments in
KEGG. Nucleic Acids Res, 34, D354eD357.

Kashima,H. et al. (2009a) On pairwise kernels: an efﬁcient alternative and
generalization analysis. In PAKDD ’09: Proceedings of the 13th Paciﬁc-
Asia Conference on Knowledge Discovery and Data Mining. Springer,
pp. 103071037.

Kashima,H. et al. (2009b) Recent advances and trends in large-scale kernel methods.
IEICE Trans, 92-D, 133871353.

Klabunde,T. (2007) Chemogenomic approaches to drug discovery: similar receptors
bind similar ligands. Br J. Pharmacol, 152, 577.

Lti,L. and Zhou,T. (2011) Link prediction in complex networks: a survey. Phys. A Stat.
Mech. Appl, 390, 115071170.

Martin,YC. et al. (2002) Do structurally similar molecules have similar biological
activity? J. Med. Chem., 45, 43504358.

Merino,A. et al. (2010) Drug proﬁling: knowing where it hits. Drug Discov. Today, 15,
7497756.

Metz,J.T. and Hajduk,P.J. (2010) Rational approaches to targeted polypharmacology:
creating and navigating protein-ligand interaction networks. Curr Opin. Chem.
Biol, 14, 4987504.

Okuno,Y et al. (2007) GLIDA: GPCR ligand database for chemical genomics drug
discovery database and tools update. Nucleic Acids Res, 36, D9077D912.

Overington,]. (2009) ChEMBL. An interview with John Overington, team leader,
chemogenomics at the European Bioinformatics Institute Outstation of the European
Molecular Biology Laboratory (EMBL-EBI). J. Comput. Aided Mol Des, 23,
1957198.

Oyama,S. and Manning,C.D. (2004) Using feature conjunctions across examples for
learning pairwise classiﬁers. In ECML ’04: Proceedings of the 15th European
Conference on Machine Learning, Vol. 3201. Springer, pp. 322333.

Raghavan,V.V. et al. (1989) A critical investigation of recall and precision as measures
of retrieval system performance. ACM Trans. Informat. Syst., 7, 2057229.

Raymond,R. and Kashima,H. (2010) Fast and scalable algorithms for semi-supervised
link prediction on static and dynamic graphs. In Proceedings of the 2010 European
conference on Machine learning and knowledge discovery in databases: Part III,
ECML PKDD’10. Springer, Berlin, Heidelberg, pp. 1317147.

Rifkin,R. and Klautau,A. (2004) In defense of one-vs-all classiﬁcation. J. Mach. Learn.
Res, 5, 1017141.

Scholkopf,B. et al. (eds) (2004) Kernel Methods in Computational Biology. MIT Press,
Cambridge, MA.

Schomburg,I. et al. (2004) BRENDA, the enzyme database: updates and major new
developments. Nucleic Acids Res, 32 (Suppl. 1), D4317D433.

Schuffenhauer,A. et al. (2003) Similarity metrics for ligands reﬂecting the similarity of
the target proteins. J. Chem. Inf Comput. Sci., 43, 391405.

Smith,T.F. and Waterman,M.S. (1981) Identiﬁcation of common molecular
subsequences. J. Mol Biol, 147, 1957197.

Wassermann,A.M. et al. (2009) Ligand prediction for orphan targets using support
vector machines and various target-ligand kernels is dominated by nearest neighbor
effects. J. Chem. Inf Model, 49, 215572167.

Wishart,D.S. et al. (2008) DrugBank: a knowledgebase for drugs, drug actions and drug
targets. Nucleic Acids Res, 36, D9017D906.

Wu,G et al. (2006) Incremental approximate matrix factorization for speeding up
support vector machines. In KDD ’06: Proceedings of the 12th ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining. ACM, New
York, NY, pp. 76w766.

Yamanishi,Y. et al. (2008) Prediction of drug-target interaction networks from the
integration of chemical and genomic spaces. Bioinformatics, 24, i2327i240.

Yamanishi,Y. et al. (2010) Drug-target interaction prediction from chemical, genomic
and pharmacological data in an integrated framework. Bioinformatics, 26,
i24&i254.

Xia,Z. et al. (2010) Semi-supervised drug-protein interaction prediction from
heterogeneous biological spaces. BMC Syst. Biol, 4 (Suppl. 2), S6.

 

3043

112 /3.Io's[BrunoprOJXO'sorwuiJOJurorq”:duq 111011 pepeo1umoq

9103 ‘0g isnﬁnv uo ::

