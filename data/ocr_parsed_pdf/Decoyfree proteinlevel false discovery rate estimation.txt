BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

peptides proteins
I _ proteins scores
Protein Inference

    

d“.
~
~--—-——---—-——

I
I
Identification scores
on random graphs

Random graph generation
RegreSSion Model FDR estimation
Multiple random graphs
FDR calculation results

/810'SIBum0[pJOJXO'sopELuJOJurorqﬂ:duq

Decoy-free protein-level false discovery rate estimation

 

 

Algorithm 1 Random-graph-generation

Input: Original graph G(L, R, E)

Output: Random graph G’(L, R, E) with the same structure as G
1 E/ <— null
2 Initialize the degree of each protein and each peptide
3 while |E’| < |E| do
4: randomly select one protein 1' with Degree(i) : 1

5: if all j with Degree(j) : 1 make (1', i) e E’ then

6.

7

8

 

select (1'6, ie) E E’ such that (jg, i)¢ E’
remove (1'6, ie) from E’ and add (19,1) to E’
Degree“) + +, Degree(i) — —

9: continue

10: end if

11: randomly select one peptide j with Degree(j) : 1

12: while (1', i) e E’ do

13: re-select one peptide j with Degree(j) : 1

14: end while

15: Degree(i) — —, Degree(j) — —

16: E’ <— E’ U {(1,1)}

17: end while

18: return G’(L, R, E’)

 

The most important advantage of our method for generating the
random graph is that it does not require any parameter. There exist
some other algorithms that can generate random graphs with the same
structure as the original graph. For example, the method in Gionis
et a]. (2007) is more simple and easier to understand than our
method because only local swaps are performed in generating a
random graph. However, this method needs to specify the number of
local swaps and it is difﬁcult to decide which parameter value is the
best.

To make the protein inference results comparable, the graph random-
ization procedure should keep all the features of the original graph un-
changed except the matches between proteins and peptides. The features
of a graph include the number of nodes, the number of edges, the number
of connected components and so on. As our method only ensures that the
individual degree of each node (protein or peptide) is preserved, one may
wonder whether the number of connected components will change sub-
stantially. In the Supplementary Figure S1, we plot the distribution of the
number of connected components in random graphs. It shows that the
difference between the random graph and the real graph with respect to
the number of connected components is small. Therefore, protein infer-
ence is comparable between the original graph and random graphs,
although the numbers of connected components of these graphs are
not exactly the same.

2.2 Predicting the protein scores on random graphs

It is time-consuming and inconvenient to execute some protein infer-
ence algorithms for thousands of times. Therefore, we build a linear
regression model to predict the protein scores reported by these
algorithms.

We use a response variable y,» e R to denote the identiﬁcation score
of protein 1' and a predictor vector X,» e R" to represent the set of asso-
ciated peptide probabilities or scores. The element Xi) in vector
X,» = (xn, X12, . . . , Xi") is constructed by the following way:

probability of peptide j, (j, i) e E
J— 0 (u

_ en¢E
That is, if there is an edge between protein 1' and peptide j in the bipartite
graph, the probability of peptide j will be used as the corresponding
predictor value. As there are m candidate proteins, we have m observation
pairs (Xian)-

Essentially, all existing protein inference algorithms use the bipartite
graph or the equivalent predictor vectors as input to calculate protein
scores/probabilities. If we have executed a protein inference algorithm on
the original bipartite graph, then we have the protein scores generated
from this algorithm. From a machine learning perspective, it is possible to
‘learn’ a similar model that can be used to perform protein inference in
the future. As a result, we can apply our method to simulate the identi-
ﬁcation results of any protein inference algorithm without knowing its
algorithmic details even when its executable program is not available to
us. Based on this motivation, here we build a linear regression model
to realize this goal. In this approach, we search a coefﬁcient vector )3
to minimize the residual sum of squares:

mmmm)=mmu§jor=€mﬁ. (a
[:1

For protein 1', when we have a new peptide contribution vector 2,», with
the estimated coefﬁcient vector )3, we can easily use the linear model to get
the identiﬁcation score )2»:

ﬁi==£fﬁ. (3)

2.3 Calculating the permutation P—value and FDR

After obtaining the protein scores calculated on these random graphs, we
can compute the permutation P-value and FDR.

If our null hypothesis that each protein matches an identiﬁed peptide
by chance is true, then there is no signiﬁcant difference between the score
of each protein in the original graph and those calculated from the
random graphs. Therefore, we can calculate the permutation P-value of
one protein as the percentage of random graphs that produce a larger
score than its score generated on the original graph. More precisely, the
P-value of the ith protein is computed as follows:

#{y,’»>yi}
Pi — T a (4)
where y,- is the original score of the ith protein, yl’. is the score of the ith
protein produced from the tth random graph, #{y§>yi} denotes the
number of random graphs on which protein 1' has a larger score than y,-
and K is the total number of random bipartite graphs.

Based on these P-values, we can calculate the FDR and
the pFDR value using the method described in Storey and Tibshirani

(2003):

A 7101/
FDRW) = W, (5)
pﬁima= “W (o

Pr(P S V){1 -(1- V)m}’

where y denotes the rejection threshold and 710 is the proportion of
false positives. Pr(P 5 y) represents the probability that a P-value P is
no more than y. The pFDR (positive false discovery rate) is a modiﬁed
version of the FDR. As y becomes small, FDR is driven by the fact
that the rejection threshold is small rather than the fact that the ‘rate
that discoveries are false’ is small. In contrast, pFDR can avoid this
disadvantage. Therefore, in this article, we use pFDR as the ﬁnal
estimated value.
We estimate 710 by the following equation:

#{pi > A}

ﬁoO») = (1 _ Mm,

(7)

where p,- is the P-value of each candidate protein, A is a parameter and
#{pi>A} denotes the number of proteins whose P-values are larger than
A. And we use the method in Storey (2002) to pick A.

 

677

ﬁm'spzumol‘pmyo'sopauuopnorq/ﬁdnq

B. Teng et al.

 

A natural estimate of Pr(P 5 y) is:

P;(P§y)=w=¥, (8)

where R(y) 2 #{pi 5 y} represents the number of candidate proteins with
P-value 5 y.

With the estimated ﬁ0(A) and FRP S V), we can easily get the pFDR
value at a given threshold y.

3 EXPERIMENT
3.1 Datasets

In our experiments, we use six publicly available datasets: l8
mixtures (Klimek et al., 2008), Sigma49 (Tabb et al., 2007),
Yeast (Ramakrishnan et al., 2009a), DME (Brunner et al.,
2007), HumanMD (Ramakrishnan et al., 2009b) and
HumanEKC (Ramakrishnan et al., 2009a). The first three
datasets have the ground—truth protein reference sets and
the other three have no such reference sets. The details of
these datasets are described in the Supplementary Table S1
and S2.

We use XlTandem (David and Cottrell, 2004) as the peptide
identiﬁcation method. As we compare our method with
MAYU (Reiter et al., 2009), all MS/MS data are searched
against both target and decoy protein databases. The decoy
database is generated using the Trans—Proteomic Pipeline
(TPP) v4.6 software. In reality, it is not necessary to search
a decoy database when using our method. During the database
search, we use default search parameters and accept the pep—
tides reported by PeptideProphet with probabilities >0.05 as
the input. For any peptide sequence that is matched by mul—
tiple spectra with different scores, we choose the highest iden—
tification score.

3.2 Parameter setting

First, we run the protein inference algorithm on the original
bipartite graph to obtain the original score of each protein and
use these scores to build a linear regression model. Second, we
predict the score of each protein in random graphs with the re—
gression model and calculate the P—value and FDR. The protein
inference algorithms used in our experiment are ProteinProphet
(Nesvizhskii et al., 2003) and ProteinLP (Huang and He, 2012).
We run ProteinProphet included in the Trans—Proteomic Pipeline
(TPP) v4.6 software with the default parameter values and use
ProteinLP by setting 6 = 0. As both ProteinProphet and
ProteinLP output the presence probability of each protein, we
transform the score predicted by the regression model into the
interval [0, 1]. If the score is >1, we set the score to 1; if the score
is <0, we set the score to 0. In addition, the number of random
graphs we choose is 10000.

3.3 Results

For the first three datasets with reference sets, we apply our
method and MAYU to estimate the FDR and check the differ—
ence between the estimated FDR and the ground—truth FDR.
We set {0.05,0.l, ..., 0.95,l} as the threshold, respectively.
For each threshold, the smaller the difference, the better the
performance.

As shown in Figure 2, for the first two datasets, our method is
comparable with MAYU, while our method can provide a more
accurate FDR estimation on the Yeast dataset when the P—value
is larger than 0.2. We can also see that both our method and
MAYU have huge deviations from the real protein FDRs for the
first two synthetic datasets probably because 18 mixtures and
Sigma49 do not have characteristics of those complex proteomics
datasets generated from real samples. Thus, the experimental
result on the more complex Yeast dataset indicates that both
methods can perform relatively well on real data, and the advan—
tage of our method begins to be visible.

For the other three datasets, we compare our method with
MAYU and the naive target—decoy method. For MAYU, we
set {0.05,0.l,...,0.95,l} as the threshold, respectively. When
using the naive target—decoy method, FDR is calculated by
doubling the ratio of the number of decoy proteins and the
total number of protein identiﬁcations in the reported proteins.
As shown in Figure 3, the performance of our method is com—
parable with the naive target—decoy method and MAYU.

One important parameter in our method is the number of
random graphs. We test the inﬂuence of different numbers of
random graphs by comparing absolute difference between the
estimated FDR and the true FDR at each threshold. We
choose {1000, 3000, 5000, 7000, 10000} as the parameter value,
respectively. As shown in Figure 4, we can see that the abso—
lute differences are almost the same when using different num—
bers of random graphs. This means that our method is
insensitive to the number of random graphs when the value
is >1000.

We also list the real no and the estimated fro on six datasets in
Table 1. For the three datasets without reference sets, we calcu—
late the real 710 by doubling the ratio of the number of decoy
proteins in the datasets and the total number of protein identi—
fications in the datasets. As shown in Table l, the estimated fro is
far from its true value on 18 mixtures and Sigma49. This explains
why the absolute FDR differences on these two datasets are
large.

Now we test the running efﬁciency of our method. The run—
ning time of our method and MAYU on six datasets is provided
in Table 2. All the experiments are tested on the DELL Studio
XPS 8100 workstation with 2.80 GHz CPU and 8 G main
memory. It shows that our method is efﬁcient in practice and
faster than MAYU.

4 CONCLUSION

In this article, we propose a novel protein—level FDR estima—
tion method. We assume that each candidate protein matches
an identiﬁed peptide totally at random. Then, we use random
permutation for assessing the statistical signiﬁcance of
each protein in terms of P—value and calculate the ﬁnal
FDR. The main advantage is that our method can calculate
FDR without searching a decoy database. Experimental results
on six proteomics datasets demonstrate the superiority of our
method.

In the future work, we will extend our method to validate
the inference results of the algorithms that do not report pro—
tein probabilities or scores. We plan to train a logistic regres—
sion model, which can assign a corresponding probability to

 

678

ﬁm'spzumol‘pmyo'sopauuopnorq/ﬁdnq

MAYU
Our method

MAYU
Our method

MAYU
Our method

lll|||||||||l|||||| ll ..illl||||H|H|"|HH| llllll

MAYU
Our method

MAYU
Our method

MAYU
Our method

Our method Our method

Naive target-decoy
MAYU

 

Our method
Naive target-decoy

MAYU

Naive target—decoy
MAYU

 

Our method
Naive target—decoy
MAYU

Our method

Naive target-decoy
MAYU

 

Our method
Naive target—decoy
MAYU

 

/3.IO'S[BIIInO[p.IOJXO"SOIJBLUJOJIIIOIqﬂIdllq

55,2kgogmoddmmowoio~&o:~=£¢o~m\

 

Decoy-free protein-level false discovery rate estimation

 

each reported protein. Meanwhile, as no can affect the FDR
estimation results signiﬁcantly, we will ﬁnd more accurate no
estimation method in the future.

Funding: This work was supported by the Natural Science
Foundation of China under Grant No. 61003176.

Conﬂict of Interest: none declared.

REFERENCES

Brunner,E. at n]. (2007) A high—quality catalog of the Droxop/iiln melanognvter
proteome. Nat. Biotechnol., 25, 57(r583.

David,C.M. and Cottrell,].S. (2004) Unimod: protein modiﬁcations for mass
spectrometry. Proteomicx, 4, 15344536.

Gionis,A. at n]. (2007) Assessing data mining results via swap randomization. ACM
Tram. Know]. Dixcov. Data, 1, l4.

Huang,T. and He,Z. (2012) A linear programming model for protein inference
problem in shotgun proteomics. Bioiiy’ormnticx, 28, 295(r2962.

Huang,T. at n]. (2012) Protein inference: a review. Brief. Bioinform., 13, 586—614.

Kim,S. at n]. (2008) Spectral probabilities and generating functions of tandem mass
spectra: a strike against decoy databases. J. Proteome Rm, 7, 3354ﬁ3363.

Klimek,J. at n]. (2008) The Standard Protein Mix Database: a diverse data set to
assist in the production of improved peptide and protein identiﬁcation software
tools. J. Proteome Rain, 7, 967103.

Nesvizhskii,A.I. at n]. (2003) A statistical model for identifying proteins by tandem
mass spectrometry. Anal. Chem, 75, 4646—4658.

Nesvizhskii,A.I. at n]. (2007) Analysis and validation of proteomic data generated
by tandem mass spectrometry. Nut. Methods, 4, 240572417.

Ramakrishnan,S.R. at al. (2009a) Mining gene functional networks to improve
mass—spectrometry based protein identiﬁcation. Bioiiy’ormnticx, 25, 295572961.

Ramakrishnan,S.R. at al. (2009b) Integrating shotgun proteomics and
mRNA expression data to improve protein identiﬁcation. Bioiiy’ormnticx, 25,
139771403.

Reiter,L. at n]. (2009) Protein identiﬁcation false discovery rates for very large
proteomics data sets generated by tandem mass spectrometry. Mol. Cell.
Proteomicx, 8, 7877797.

Spirin,V. at n]. (2011) Assigning spectrum—speciﬁc p—values to protein identiﬁcations
by mass spectrometry. Bioinﬁnmnticx, 27, 112871134.

Storey,J.D. (2002) A direct approach to false discovery rates. J. R. Stat. Soc. Ser.
E Stat. Met/1040]., 64, 4794198.

Storey,J.D. and Tibshirani,R. (2003) Statistical signiﬁcance for genomewide studies.
Proc. Natl Aim! Sci. USA, 100, 944(F9445.

Tabb,D.L. at n]. (2007) Myrimatch: highly accurate tandem mass spectral peptide
identiﬁcation by multivariate hypergeometric analysis. J. Proteome Rec, 6,
654—661.

 

681

ﬁm'spzumot‘piqxo'sopauuopnotq/ﬁdnq

