BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

EFeméndez—Albert et al.

 

with three other methods. Their method performs a normaliza—
tion and an equalization step to give a robust output when
having urine samples with different concentration values.
Among the equalization methods, the one proposed by
Artursson et al., based on component correction (CC), was de—
veloped in the sensor—array field (Artursson et al., 2000). This
method is based on the assumption that, in multivariate data, the
drift direction is the ﬁrst principal component (PC) of a PCA
decomposition for a class consisting of measurements of the
same samples. Such samples are known as technical replicates
(i.e. there is no biological or chemical variation in addition to the
variability of the technical replication of the measure). Once the
drift direction is computed, the drift is removed from the data by
subtracting the data projection on the drift direction from the
original data. However, if some between—class variability is
aligned with the drift direction, it will also be subtracted, and
some non—drift variability will be removed. A natural extension
of the CC method is the one proposed by Ziyatdinov et al., which
is based on a common principal component analysis (CPCA)
decomposition (Ziyatdinov et al., 2010). This method proposes
modelling the drift contribution in the data as the direction cap—
turing maximum variance that simultaneously diagonalizes the
covariance matrices of a set of classes. All the variability of the
samples in that particular direction is considered to be drift—
induced variability, and the projection of the data on that direc—
tion is subtracted from the data as in the CC method.

In this article, to find the drift model, we state the hypothesis
that the intensity drift of the chromatograms is the common
variance direction of all the QC classes that captures the max—
imum variance. In this context, we propose a preprocessing
method based on a two—step approach by first equalizing the
data through a CPCA, and then normalizing the data using a
median fold change step.

2 MATERIALS AND METHODS

2.1 Description of the data

The samples were analysed by liquid chromatography coupled with a
hybrid quadrupole time-of-ﬁight (LC-q-TOF, Hybrid quadrupole TOF
QSTAR Elite, AB/MDS Sciex) in positive mode using the protocol pro-
posed by Tulipani et a]. (2011). LC was performed in High-Performance
Liquid Chromatography (HPLC) Agilent (Agilent 1200 Series Rapid
Resolution HPLC system) using an RP 18 Luna column (50 X 2.0 mm,
5m), with a sample injection volume of 15p,l. A linear gradient elution
was performed consisting of [A] Milli-Q water 0.1 % HCOOH (v/v) and
[B] acetonitrile 0.1% HCOOH (v/v).The gradient elution (v/v) of [B] was
as follows: (time, min; B, %): (0, 1), (4, 20), (6, 95), (7.5, 95),(8, 1), (12, 1).
Q-TOF spray parameters were set as previously described (Llorach et al.,
2009), and full data acquisition was performed scanning from 70 to
700 m/z. The TOF was calibrated with reserpine (lpmol/ul). LCiMS
data were acquired in random order to avoid possible bias and the
batches equilibrated. Throughout all the analysis, data process quality
control (QC) samples were analysed to monitor the stability and func-
tionality of the system. The sample collecting span was of 18 days, and
there was a replacement of the chromatographic column in the process on
day 14. There were 994 study samples and 182 QC samples. Three classes
of QC samples were used for each batch:

0 Water: Milli-Q water samples (n = 96 samples).

0 Spikes: Standard mixture solution (n = 48 samples) consisting of 12
metabolites at the ﬁnal concentration of 5 ppm for all of them except
for indole-3-acetic-2,2-d2 acid whose ﬁnal concentration was of
10 ppm.

0 Reference: Urine sample belonging to the one volunteer (n = 38
samples).

2.2 Preprocessing

All the methods were applied to the chromatograms without any prior
feature detection. The R package XCMS was used to read the chromato-
grams of the szML ﬁles containing the sample data (Smith et al.,
2006). The chromatograms were aligned using an in-house-developed R
package (UB/UPC). The chromatographic data of all the ﬁles read were
merged, creating an n X m chromatogram matrix X. This step required
the binning of the retention time in m bins that were given by the XCMS
package. Therefore, the chromatogram matrix had samples as rows and
retention time as columns (in our case, n = 1176 samples and m = 441
retention time points). Thus, the i-th row of this matrix corresponds to
the chromatogram of the i-th sample. From here on, the variable j refers
to the retention time bins in the chromatogram matrix. A class-wise out-
lier detection and removal procedure was applied to the QC classes. This
procedure was based on computing the score distance (SD) and an or-
thogonal distance (OD) in a PCA model using the pcaPP R package
(Filzmoser et al., 2013; Hubert et al., 2005). QC samples having SD
and OD distances greater than the suggested critical values were con-
sidered to be outliers and were discarded from the dataset (Filzmoser
and Fritz, 2007). The critical values used in the package were (i) a quantile
of the chi-squared distribution for the SD and (ii) a WilsoniHilferty
approximation for the scaled chi-squared distribution for the OD
(Filzmoser and Fritz, 2007; Hubert et al., 2005). Using this approach,
nine outlier samples were detected (four samples in class reference, three
in class water and two in class spikes). As it is known that raw LC/MS
metabolomic data suffer from multiplicative noise, we took the logarithm
of the data to compensate for such error sources and to convert them into
additive noise sources (Veselkov et al., 2011). Once the o outliers were
removed, we could then deﬁne the quantity p=n — o to be the new
sample range. The resulting matrix Y(p X m) was used as an input par-
ameter for all the normalization methods tested. This matrix contains the
data for both the QC classes and the study class, and it can be divided
into matrices corresponding to each class (i.e. YQC(pQC X m) for the cor-
responding dataset for all QC classes, Yr(pr X m) for the corresponding
dataset for the reference class, etc.).

2.3 Methods

The ﬁve methods compared in this article (CPCA, CC, median fold
change, ComBat and our CPCA + median fold change) have different
input parameters. The methods based on a CPCA decomposition or the
CC method involve a class (or classes)-selection step to use them for the
drift modelling. These methods also need as input the number of com-
ponents of the drift decomposition, which are supposed to be captured.
The ComBat method needs the batch relation for each class, whereas the
median fold change method does not need any specific input parameter in
addition to the data to be normalized.

2.3.] Component correction The hypothesis underlying this method
is that the drift direction is found in the ﬁrst PC of a reference class. The
methodology used to normalize these data is described in (Artursson
et al., 2000). As the feature pattern of the QC samples was more complex
than that of the other two QC classes, the reference class was selected to
generate the PCA model. Because of this higher complexity, this class is
better able to capture the drift in the data than would a class with a
simpler feature pattern. Mathematically, the CC method can be expressed

 

2900

ﬁm'spzumofpmjxo'sopnuuopnorq/ﬁdnq

Intensity drift removal in LC/MS metabolomics

 

as in Equation (1).
Yr=S-LT+E (1)

The methodology proposed by Artursson et a]. removes one PC, but the
method can be generalized to remove as many PCs as can be found in the
data. If Ncomps is the number of components to be removed, then S
(pr >< Ncomps) is the scores matrix, L (m X Ncomps) is the loadings
matrix and E (pr X m) is the error matrix.

As only one PC is required to perform the normalization, no further
increase in the dimensions of the matrices S and L is necessary. The drift
direction is the ﬁrst PC, which in this case corresponds to the matrix L.
The next step is to project the dataset Y onto this direction to obtain the
drift component in the data. This projection is mathematically expressed
as the Equation (2).

YZ"=(Y-L)-LT (2)

where the superscript cc refers to CC and the subscript d to drift. Once the
drift component Y3" (pr X m) of the data is computed, the last step in
removing the drift is to subtract it from the data. Equation (3) shows this
last step, and the resulting matrix Z“ (pr X m) is the corrected matrix
using the CC method.

Zoe : Y _ Yin 

2.3.2 Median fold change The median fold change method is not
focused on finding the drift direction. Its objective is to rescale the data
to make the median fold changes of the variables close to zero. The
methodology followed in applying this method is the one of Veselkov
et al., based on a sample-wise approach (V eselkov et al., 2011). The ﬁrst
step of this method, shown in equation (4), is to compute the median for
each variable, thus obtaining a vector )7,»(1 X m). This vector is used to
rescale the original dataset Y into a new one, Y(p X m) IG(IG) [see
Equation (4)].

A _ Yij A _ .

Y~7 A where yii medlan,»( Yij) (4)

21
yi

To obtain the normalized dataset ZM(p X m), the dataset Y is divided
by the sample median of the matrix Y (deﬁned as W‘J-(p X 1)) as shown in
Equation (5).

M _ Yij A _ - A
7 — where wj imedlanj( Yij) (5)

if d.
n]

where the superscript M refers to median fold change method.

2.3.3 ComBat The ComBat method is a function of the R package
sva. This function aims to correct the batch effects, which are known to
be a source of bias, in gene expression experiments; its extension to LC/
MS metabolomic datasets is both natural and straightforward. First, it is
assumed that batch effects have multiplicative and additive contributions
to the data, and that these effects can be variable dependent (gene or
peak, respectively). We state a model following this hypothesis [see
Equation (6)]

Yij], = Olj ‘1‘ 20% ‘1‘ j/jb ‘1‘ 511,611, 

where Y,-,~;, is the intensity value for sample i, variable j and batch b. of is
the intensity value for variable j, X is the design matrix, [31- contains the
regression coefﬁcients of the model, yjb is a matrix containing the additive
batch effects for variable j and batch b, 81-], is a matrix containing the
multiplicative batch effects for variable j and batch b and eff], is the re-
sidual matrix of the model. Using either a parametric or a non-parametric
empirical prior estimation, the distributions for yjb and 812,, are estimated.

The conditional posterior probabilities (y; and 812;“) can then be found,

and the data are corrected for batch effects as shown in Equation (7). In
the following, all the variables having a hat C) on them refer to their
values estimated from the data.
6- A A A
251? = 871(2)» — Vﬂi) '1' “j '1' Xﬁj (7)
if

where the superscript CB refers to the ComBat function, Zi/‘h is the stan-
dardized data and cf]- is the estimated standard deviation.

2.3.4 CPCA CPCA is a generalization of the PCA decomposition for
different classes ﬁrst introduced by Flury et a]. (Flury, 1984). Say we have
k classes and 2;. (pk >< pk) are the set of their covariance matrices, then
CPCA aims at ﬁnding a space such as the one deﬁned by the V (in
general, pk >< pk) matrix shown in Equation (8). In the space spanned
by V, the covariance matrices for all the classes involved 2;. are diagonal.

Ak=VT-2k-V (8)

where AA. (pk >< pk) is the diagonalized covariance matrix for class k. Each
one of the dimensions of this space is called a common principal com-
ponent (CPC). The hypothesis underlying the CPCA method for drift
correction is that the drift direction is contained in the CPC capturing
the largest variance. The CPC will be computed by using the YQC dataset
[i.e. there are three expressions like Equation (8), using the different co-
variance matrices for the QC classes: 2r, EWM, 2mm]. In a similar way
as in a PCA decomposition, given the desired number of CPCs and fol-
lowing a stepwise algorithm, it is possible to compute the number of
CPCs one by one (Trendaﬁlov, 2010). Setting the desired number of
CPCs as Ncomps, the dimensionality of the V matrix is (pk >< Ncomps).
We have tested the values Ncomps = 1, 2, 3 separately for this method.

Once the CPCs are found, the dataset is projected onto this space as
shown in (9)

YEPCA=(Y- V)- VT (9)

Y?“ (n X 17) contains the drift component in the data. To eliminate the
drift from the data, the last step is to subtract this drift from the data
[Equation (10)]

ZCPCA = Y _ ngoi (10)

where ZCPCA (n X p) is the corrected dataset using the CPCA method.

2.3.5 CPCA + median fold change The method we propose con-
sists of a two-step approach. First, the data are equalized by removing the
drift using CPCA and, in the second step, the data are normalized by
applying the median fold change method. As the CPCA method was
applied three times with different number of extracted CPCs (Ncomps
in previous subsection), the proposed method will be computed for the
same number of components (Ncomps = 1, 2, 3).

2.4 Validation

From the class deﬁnition in Section 2.1, it follows that a PCA score plot
of all the classes should have the classes clearly separated in different
clusters. We propose a quality measure for peak intensity drift correction
methods based on the standard clustering internal measures Dunn and
Silhouette for the QC classes in the principal plane (the plane explaining
maximum variability of the data) score plot of all the classes (including
the study class). The clustering technique used was k-means. The R pack-
age clValid was used to compute the quality indices (Brock et al., 2008,
2011). In general, the greater the Dunn and Silhouette indices, the better
the clustering, meaning that the QC classes are more easily separable in
the principal plane and that the intra-class variance is lower.

 

2901

ﬁm'spzumofpmjxo'sopnuuopnorq/ﬁdnq

Water
Reference
Sample

 

/810'SIEumo_fpmjxo'sonnulmjuioiq/ﬁduq

53x\Ewogmoizmnnw.oxmoagoﬁsiwbwﬁ

 

.Cr .Ia.
100.51. 3.. unoccuuoooluoo

 

 
 

:39\Ewowsmoaﬁmowoxmoagoﬁsambwﬁ

s
n
.m
d
e
M
A
C
P
C

 

Intensity drift removal in LC/MS metabolomics

 

QC class separability of the dataset is higher than if just the CPC
method is applied.

Results show that, among all the methods tested to normalize
the LC/ MS metabolomic data, the best approach is to use a two—
step method in which the first step is to remove the drift by
ﬁnding the drift direction in a multivariate space using a
CPCA approach. The second step, based on performing a
median fold change to account for differences in concentration
results, improved between—class separability and hence resulted
in a better—normalized dataset overall. As far we know, this is the
ﬁrst time that this kind of approach has been applied in the
metabolomics context. Applications such as the one proposed
open the possibility of carrying out large epidemiological LC/
MS metabolomics experiments with high guarantee of the con—
trol of the quality of the acquisition data step.

Funding: Spanish national grants (AGL2009—13906-C02—01/ALI,
AGL2010-10084—E, 2014 SGR 1063, 2014 SGR 1566), the
CONSOLIDER INGENIO 2010 Programme, FUN-C—FOOD
(CSD2007—063) from the Spanish Ministry of Economy and
Competitiveness (MINECO), as well as FEDER (Fondo
Europeo de Desarrollo Regional) and Merck Serono 2010
Research Grants (Fundacion Salud 2000). R.LL. thanks the
MICINN and the European Social Funds for their financial
contribution to the R.LL. Ramon y Cajal contract (Ramon y
Cajal Programme, MICINN—RYC RYC—2010—07334). This
work was partially funded by the Spanish Ministerio de
Ciencia y Tecnologia through the (TEC2010—20886—C02—02 and
TEC2010—20886—C02—01) grants, and the Ramon y Cajal pro—
gramme. AP. is part of the (2009SGR—1395) consolidated re—
search group of the Generalitat de Catalunya, Spain. CIBER—
BBN is an initiative of the Spanish ISCIII. F. Fernandez—Albert
thanks EVALXARTA—UB and Agencia de Gestio d’Ajuts
Universitaris I de Recerca, AGAUR (Generalitat de
Catalunya) for their ﬁnancial support. M.G.—A. thanks the
Generalitat de Catalunyas Agency for Management of
University and Research Grants (AGAUR) for the predoctoral
(FI—DGR 2011) fellowship.

Conﬂict of Interest: none declared.

REFERENCES

Aihua,Z. et al. (2012) Modern analytical techniques in metabolomics analysis.
Analyst, 137, 2937300.

Artursson,T. et al. (2000) Drift correction for gas sensors using multivariate meth—
ods. J. Chemom., 14, 7117723.

Brock,G. et al. (2008) clValid: an R package for cluster validation. J. Stat. Softw.,
25, 1722.

Brock,G. et al. (2011) clValid: Validation of Clustering Results. R package version
0.6-4. Comprehensive R Archive Network (CRAN).

Burton,L. et al. (2008) Instrumental and experimental effects in LC—MS—based
metabolomics. J. Chromatogr. B Analyt. Techno]. Biomed. Life Sci, 871,
2277235.

Chen,K. et al. (2013) Gene expression proﬁle analysis of human intervertebral disc
degeneration. Genet. Mol. Biol., 36, 4487454.

Dunn,J.C. (1973) A fuzzy relative of the ISODATA process and its use in detecting
compact well—separated clusters. J. Cybern., 3, 32757.

Dunn,W.B. et al. (2011) Procedures for large—scale metabolic proﬁling of serum and
plasma using gas chromatography and liquid chromatography coupled to mass
spectrometry. Nat. Protoc., 6, 106(k1083.

Fiehn,O. et al. (2006) Establishing reporting standards for metabolomic and meta—
bonomic studies: a call for participation. OMICS, 10, 1587163.

Filzmoser,P. and Fritz,H. (2007) Exploring high—dimensional data with robust prin—
cipal components. In: Aivazian,S. et al. (eds) Proceedings of the eight
International Conference on Computer Data Analysis and Modeling. Vol. 1,
Belarusian Smte University, Minsk, pp. 1&22.

Filzmoser,P. et al. (2013) pcaPP: Robust PCA by Projection Pursuit. R package
version 1.9—49. Comprehensive R Archive Network (CRAN).

Flury,B.N. (1984) Common principal components in K groups. J. Am. Stat. Assoc.,
79, 8924598.

Hubert,M. et al. (2005) ROBPCA: a new approach to robust principal component
analysis. Technometrics, 47, 1734.

Johnson,W.E. et al. (2007) Adjusting batch effects in microarray expression data
using empirical Bayes methods. Biostatistics, 8, 1187127.

Leek,J.T. et al. (2012) The SVA package for removing batch effects and other
unwanted variation in high—throughput experiments. Bioinformatics, 28,
8827883.

Leitch,H.G. et al. (2013) Naive pluripotency is associated with global DNA hypo—
methylation. Nat. Struct. Mol. Biol., 20, 3117316.

Llorach,R. et al. (2009) An LC—MS—based metabolomics approach for exploring
urinary metabolome modiﬁcations after cocoa consumption. J. Proteome Res.,
8, 506075068.

Smith,C.A. et al. (2006) XCMS: processing mass spectrometry data for metabolite
proﬁling using nonlinear peak alignment, matching, and identiﬁcation. Anal.
Chem., 78, 7797787.

Sysi—Aho,M. et al. (2007) Normalization method for metabolomics
data using optimal selection of multiple internal standards. BMC
Bioiry’ormatics, 8, 93.

Tulipani,S. et al. (2011) Metabolomics unveils urinary changes in subjects with
metabolic syndrome following 12—week nut consumption. J. Proteome Res.,
10, 504775058.

Trendaﬁlov,N.T. (2010) Stepwise estimation of common principal components.
Comput. Stat. Data Anal., 54, 344G3457.

Veselkov,K.A. et al. (2011) Optimized preprocessing of ultra—performance liquid
chromatography/mass spectrometry urinary metabolic proﬁles for improved
information recovery. Anal. Chem, 83, 58645872.

Wang,S.Y. et al. (2013) Batch normalizer: a fast total abundance regression cali—
bration method to simultaneously adjust batch and injection order effects in
liquid chromatography/time—of—flight mass spectrometry—based metabolomics
data and comparison with current calibration methods. Anal. Chem, 85,
103771046.

Xin,L. et al. (2008) LC—MS—based metabonomics analysis. J. Chromatogr. B, 866,
64ﬁ76.

Ziyatdinov,A. et al. (2010) Drift compensation of gas sensor array data
by common principal component analysis. Sens. Actuators B Chem., 146,
460—465.

 

2905

ﬁm'spzumofpmjxo'sopnuuqutorq/ﬁdnq

