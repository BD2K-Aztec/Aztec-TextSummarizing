ORIGINAL PAPER

Vol. 28 no. 2 2012, pages 167-175
doi:10. 1 093/bioinformatics/btr629

 

Sequence analysis

Advance Access publication November 13, 2011

Feature-based classifiers for somatic mutation detection in
tumour—normal paired sequencing data

Jiarui DingiaZ, Ali Bashashatil, Andrew Bothl, Arusha Oloumil, Kane Tse3,
Thomas Zeng3, Gholamreza Haffaril, Martin Hirst3, Marco A. Marra3, Anne Condon2,

Samuel Apariciola4 and Sohrab P. Shah1’254a*

1Department of Molecular Oncology, BC Cancer Agency, 2Department of Computer Science, University of British
Columbia, 3Canada’s Michael Smith Genome Science Centre and 4Department of Pathology, University of British

Columbia, Vancouver, BC, Canada
Associate Editor: Alex Bateman

 

ABSTRACT

Motivation: The study of cancer genomes now routinely involves
using next-generation sequencing technology (NGS) to profile
tumours for single nucleotide variant (SNV) somatic mutations.
However, surprisingly few published bioinformatics methods exist for
the specific purpose of identifying somatic mutations from NGS data
and existing tools are often inaccurate, yielding intolerany high false
prediction rates. As such, the computational problem of accurately
inferring somatic mutations from paired tumour/normal NGS data
remains an unsolved challenge.

Results: We present the comparison of four standard supervised
machine learning algorithms for the purpose of somatic SNV
prediction in tumour/normal NGS experiments. To evaluate these
approaches (random forest, Bayesian additive regression tree,
support vector machine and logistic regression), we constructed
106 features representing 3369 candidate somatic SNVs from 48
breast cancer genomes, originally predicted with naive methods
and subsequently revalidated to establish ground truth labels. We
trained the classifiers on this data (consisting of 1015 true somatic
mutations and 2354 non-somatic mutation positions) and conducted
a rigorous evaluation of these methods using a cross-validation
framework and hold-out test NGS data from both exome capture and
whole genome shotgun platforms. All learning algorithms employing
predictive discriminative approaches with feature selection improved
the predictive accuracy over standard approaches by statistically
significant margins. In addition, using unsupervised clustering of the
ground truth ‘false positive’ predictions, we noted several distinct
classes and present evidence suggesting non-overlapping sources of
technical artefacts illuminating important directions for future study.
Availability: Software called MutationSeq and datasets are available
from http://compbio.bccrc.ca.

Contact: sshah@bccrc.ca

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on August 22, 2011; revised on November 1, 2011;
accepted on November 8, 2011

 

*To whom correspondence should be addressed.

1 INTRODUCTION

The genome-wide search for functionally important somatic
mutations in cancer by emergent, cost-effective next-generation
sequencing (NGS) technology has begun to revolutionize our
understanding of tumour biology. The discovery of diagnostic
mutations (Shah et (11., 2009a), new cancer genes (ARIDlA
(Wiegand et (11., 2010), PBRMl (Varela et (11., 2011), PPP2R1A
(McConechy et (11., 2011), IDHl (Yan et (11., 2009), EZH2 (Morin
et (11., 2010)), insights into tumour evolution and progression (Ding
et (11., 2010; Shah et (11., 2009b) and deﬁnitions of mutational
landscapes in tumour types [CLL (Puente et (11., 2011), myeloma
(Chapman et (11., 2011), lymphoma (Morin et (11., 2011)] among
many others, provide important examples of the power and potential
of NGS in furthering our knowledge of cancer biology.

Using NGS to interrogate cancers for somatic mutations usually
involves sequencing tumour DNA and DNA derived from non-
malignant (or normal) tissue (often blood) from the same patient.
Consequently, cancer-focused NGS experiments differ considerably
in experimental design from the study of Mendelian disorders or
normal human variation. In cancer studies, sequence reads from the
two matched samples are aligned to a reference human genome,
and lists of predicted variants using single nucleotide variant (SNV)
callers [e.g. Samtools (Li et (11., 2009a), SOAPsnp (Li et (11., 2009b),
VarScan (Koboldt et (11., 2009), SNVMix (Goya et (11., 2010),
GATK (McKenna et (11., 2010), VipR (Altmann et (11., 2011)] are
compared in the tumour and normal data. Using naive approaches,
those variants appearing in the tumour, but not the normal sample
would be considered putative somatic mutations and provide the
investigator with a list of candidates to follow up for functional
impact and clinical relevance. Unfortunately, such naive approaches
often result in false predictions and we suggest herein that the
problem of computational identiﬁcation of somatic mutations from
NGS data derived from tumour and matched normal DNA remains
an unsolved challenge. As a result, labour intensive and often costly
validation experiments are still required to conﬁrm the presence of
predicted somatic mutations for both research purposes and clinical
interpretation.

Although some false predictions may be due to under-sampled
alleles, most can be attributed to detectable artefacts that we
argue can be leveraged in principled inference techniques to
improve computational predictions. Many different approaches to

 

© The Author(s) 2011. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0), which permits unrestricted non—commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.

112 ﬁlo's[Bruno[pJOJXO'sorJBurJOJurorqﬂ:duq uror} papeorumoq

9103 ‘Og anﬁnv uo ::

J.Ding et al.

 

the problem of SNV discovery from NGS have been implemented.
Model-based methods such as SNVMix and SOAPsnp aim to
probabilistically model the allelic distributions present in the data
and infer the most likely genotype from allelic counts. These
methods avoid imposing ad hoc depth-based thresholds on allelic
distributions, but their accompanying software packages do not
explicitly handle known sources of technical artefacts and they
must rely on pre- or post-processing of the data to produce reliable
predictions. Examples of features that can indicate artefacts include
strand bias induced by polymerase chain reaction (PCR) duplicates
from the sequencer whereby all variant reads are sequenced in the
same orientation (Chapman et (11., 2011), mapping quality (how well
each read aligns to its stated position), base quality (the signal to
noise ratio of the base call) and average distance of mismatched
bases to the end of the read, among many others (Section 2). Many
of these features are readily available from aligned data in packages
such as GATK and Samtools and it is generally accepted that
applying ﬁlters on these quality metrics is necessary to remove false
signals. Some software tools such as VarScan, Samtools and GATK
aim to leverage these features in their SNV prediction routines;
however, they are often guided by heuristics, whereby somewhat
arbitrary decision boundaries are implemented.

We propose that training feature-based classiﬁers using robust
classiﬁcation methods from the machine learning literature will
better optimize the contribution of each feature to the discrimination
of true and false positive somatic mutation predictions. Fitting such
classiﬁers to large sets of ground truth data should allow us to
discriminate classes of false positives that may be predicted for
different reasons, enabling a more thorough understanding of NGS
machine, alignment and biology-related artefacts that are informed
by data. We suggest that features that best identify somatic mutations
will differ in importance in the normal data compared with the
tumour data, and so integrated analysis of the tumour and normal
data will yield better results than independent treatment of the two
datasets. To our knowledge, this notion is currently not considered in
any published somatic mutation detection method. Finally, ﬂexible
feature-based classiﬁers that can use any number of features can
combine features from different software packages and therefore
leverage newly discovered discriminative features to continually
improve somatic mutation prediction accuracy as the bioinformatics
literature and methodology matures.

In this article, we study the use of discriminative, feature-
based classiﬁers and investigate computational features from aligned
tumour and normal data that can best separate somatic SNVs
from non-somatic SNVs. We implemented four standard machine
learning algorithms: random forest, Bayesian additive regression
tree, support vector machine and logistic regression, and compared
their performance to each other and to standard methods for somatic
mutation prediction. We trained the classiﬁers on a set of 106
features computed from tumour and normal data on a set of ~ 3400
ground truth positions from 48 primary breast cancer genomes
sequenced with exome capture technology, while simultaneously
estimating the importance of features. Classiﬁers were evaluated
in a cross-validation scheme using robust quantitative accuracy
measurements of sensitivity and speciﬁcity on labelled training
data, and on independent held-out test data derived from four
additional cases sequenced with a different technology. We show
that principled, feature-based classiﬁers signiﬁcantly improve
somatic mutation prediction in both sensitivity and speciﬁcity over

standard approaches such as Samtools and GATK. Finally, using
discriminative features, we show how false positive (wild-type)
positions can be segregated into several distinct types of systematic
artefacts that contribute to false positive predictions.

2 METHODS

Supplementary Figure Sl shows the workﬂow of the feature-based classiﬁer
for somatic mutation prediction. We used supervised machine learning
methods ﬁt to validated, ground truth training data originally predicted using
naive methods (see below for details). Using deep sequencing to validate
predictions, we deﬁne positions as somatic mutations where the variant
was found in the tumour but not the normal, germline variants where the
variant was found in the tumour and the normal or wild-types (no variants
found in either the tumour or the normal, i.e. false positive predictions). The
germline and wild-type positions are classed as non-somatic positions so
that binary classiﬁers can be used. Features are constructed for each SNV
in the training data using the exome capture barnfiles from the tumour
and normal alignments. As explained below, we use features available in
Samtools, GATK and a set of features we have deﬁned ourselves. These
features along with their somatic/non-somatic labels are the inputs to train
classiﬁers. Given test bamﬁles, we construct features for each candidate site,
and apply the trained classiﬁer to predict the probability of somatic mutation
for each site.

2.1 Feature construction

We formalize the somatic mutation prediction problem as a classiﬁcation
problem. Each candidate mutation site of the genome is represented by a
feature vector x with 106 feature components {x1,...,x105}. The problem is
to predict the label y of the feature represented site. y is deﬁned as ‘1’ if
the site is a somatic mutation, and ‘0’ otherwise. Below we ﬁrst deﬁne each
component of the feature vector in detail, and then compare different models
to predict y given x.

Features X] to x20 are constructed from the normal data and their
deﬁnitions are given in Table 1. This table is based on the table in
http://sarntools.sourceforge.net/mpileup.shtml. Features x21 to X40 have the
same deﬁnitions but are constructed from the tumour. Features X41 to X50
are constructed from the normal data and their deﬁnitions are given in
Table 2. These features are constructed based on GATK. Features X51 to
X30 have the same deﬁnitions but are constructed from the tumour. We
show in Section 3.3 how simultaneous treatment of the tumour and normal
data allow the classiﬁers to differentially weight corresponding features
so as to emphasize tumour-speciﬁc and normal-speciﬁc features that best
discriminate between real and false predictions.

To account for variance in depth across the data, features that scale
with depth (e.g. feature x; to x17) are ﬁrst normalized by dividing by the
depth. In addition to Samtools and GATK, we added several features that
we noticed may contribute to systematic errors. For example, in Meacham
et al. (2011a,b), the authors found that GGT sequences are often erroneously
sequenced as GGG. To capture this artefact, we computed the difference
between the sum of the base qualities of the current site and the next site, the
sum of the square of the base qualities of the current site and the next site,
for both normal and tumour. These features are deﬁned as features X3 1_g4.
In addition, the reference base, the alternative base of the normal as well the
alternative base of the tumour are included as features X35_95 (by dummy
representation of categorical variables). In addition, to combine strand bias
effects from the tumour and normal data, we deﬁne feature X95 and feature
X97 to estimate the strand bias from the pooled normal and tumour data.

To boost weak signals such as rare somatic mutations that may be under-
sampled or represent a mutation occurring in a small proportion of cells in
the tumour, and to decrease the inﬂuence of germline polymorphism, another
nine features are introduced. The deﬁnitions of these features are given in
Table 3. Note in the table, F i means the normalized version of the i-th feature

 

168

112 ﬁlo's[Bruno[p.IOJXO'sonBurJOJurorq”:duq uron papeorumoq

9103 ‘Og anBnV uo ::

Feature-based classifiers for somatic mutation prediction

 

Table 1. The deﬁnitions of features )0 to x20

 

(1) Number of reads covering or bridging the site

(2) Number of reference Q13 bases on the forward strand

(3) Number of reference Q13 bases on the reverse strand

(4) Number of non-reference Q13 bases on the forward strand
(5) Number of non-reference Q13 bases on the reverse strand
(6) Sum of reference base qualities

(7) Sum of squares of reference base qualities

(8) Sum of non-reference base qualities

(9) Sum of squares of non-reference base qualities

(10) Sum of reference mapping qualities

(11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
(19)
(20)

Sum of squares of reference mapping qualities

Sum of non-reference mapping qualities

Sum of squares of non-reference mapping qualities

Sum of tail distances for reference bases

Sum of squares of tail distance for reference bases

Sum of tail distances for non-reference bases

Sum of squares of tail distance for non-reference bases

P(D | G,» =aa), phred-scaled, i.e. x is transformed to —1010g(x)
maxGi¢m(P(D| G,»)), phred-scaled

ZGi¢M(P(D | G,»)), phred-scaled

 

Q13 means base quality bigger or equal to Phred score 13; D represents the three dimensional vector (depth, number of reference bases and number of non-reference bases) at the
current site; G,» e [aa,ab,bb} means the genotype at site i, where (1,}; e [A, C ,T,G} and a is the reference allele and b is the non-reference allele. These features are constructed from

Samtools.

Table 2. The deﬁnitions of features X41 to X50

 

 

 

(41) QUAL: phred-scaled probability of the call given data (51) QD: variant conﬁdence/unﬁltered depth
(42) Allele count for non-ref allele in genotypes (52) SB: strand bias (the variation being seen on only the forward or only
(43) AF: allele frequency for each non-ref allele the reverse Strand)
(44) Total number of alleles in called genotypes (53) sumGLbyD
(45) Total (unﬁltered) depth over all samples (54) Allehc depths for the ref-allele
(46) Fraction of reads containing spanning deletions (55) Allehc depths for the non-ref allele
(47) HRun: largest contiguous homopolymer run of variant allele in (56) DP: read depth (only ﬁltered reads used for callmg)
either direction (57) GQ: genotype quality computed based on the genotype likelihood
(48) HaplotypeScore: estimate the probability that the reads at this (58) P(D | Gizaa), phred-scaled
locus are coming from no more than 2 local haplotypes (59) P(D I G Zab)’ phred_scaled
(49) MQ: root mean square mapping quality (60) P(D I G = bb)’ phred_scaled
(50) MQO: total number of reads with mapping quality zero
These features are constructed from GATK.
Table 3. The deﬁnitions of X93 to x105
(98) Forward strand non-reference base ratio F 24 / F4 (103) Sum of squares of non-reference mapping quality ratio F33 /F13
(99) Reverse strand non-reference base ratio F 25 / F 5 (104) Sum of non-reference tail distance ratio F 35 / F 15
(100) Sum of non-reference base quality ratio F 23 /F g (105) Sum of squares of non-reference tail distance ratio F37 /F17
(101) Sum of squares of non-reference base quality ratio F 29 / F 9 (106) Non-reference allele depth ratio F 75 / F 55

(102) Sum of non-reference mapping quality ratio F 32 / F 12

 

These features are used to boost weak mutation signals in the tumour and decrease the inﬂuence of germline polymorphism. In this table, F 1 means the normalized version of the i-th

feature.

(dividing by the depth feature). All features are standardized to have zero

mean and unit variance prior to training and testing.

2.2 Models

After constructing the feature value vector x for each candidate somatic
position, the problem is to ﬁnd a discriminative function f(x), which
optimally separates the true somatic positions from false somatic positions.

In so doing, we wished to simultaneously learn the features that best
discriminate the two classes. Numerous tools have been developed to
solve this problem in the statistics and machine learning community.

Here

we compare four methods: random forests (Hastie at 111., 2009),

Bayesian additive regression tree (Chipman at 111., 2010), support vector
machines and logistic regression. These methods (described below) differ
in their underlying methodology and generally represent broad classes of
classiﬁers present in the machine learning literature. We set out to compare

 

169

112 ﬁlo's[Bruno[p.IOJXO'sonBurJOJurorq”:duq moi; pap201umoq

9103 ‘0g15n8nv uo ::

J.Ding et al.

 

performance of the different approaches in the speciﬁc context of predicting
somatic mutations from NGS data. (Note that additional material on all
methods, including approaches for hyperpararneter settings, is presented in
the Supplementary Material.)

2.2.] Random forests Random forests (RF) are tree-based methods
for classiﬁcation and regression analysis. Given a training dataset, a
classiﬁcation tree g is grown by repeatedly splitting the feature vector
into disjoint pieces {Rm}g’ll:l. The splitting rules are typically based on a
single component of the whole feature vector and are of the form {xfs}
versus {x> s}, where s is a real number determined in training. After the
classiﬁcation tree is grown (a series of s are determined), given a test feature
vector x, if it is in piece R,,,, the probability of its label y can be estimated as

1
p(y=klo.x>= — Z I(y,-=k>
Nm xveR
1 m
where k e {0, 1} in our case, 9 is all the parameters of the splitting rules, N", is
the number of training sites in piece Rm, xj is a training site, yj is its label and
I (.) is the indicator function. RF makes a prediction based on an ensemble
of B trees {gb}g:l, i.e. the mode ofB trees
8
L I = k
p0=k|9,x)=—Z”“ If” )
where g), =k means that tree gb’s prediction is k. Speciﬁcally, B bootstrap
samples (random sampling with replacement) are drawn from the training
data, and a tree is grown on each bootstrap sample. To reduce the dependence
of the B trees, p features out of all the features (106 for our case) are chosen
at each node when a tree is grown.

2.2.2 Bayesian additive regression tree The Bayesian additive regression
tree (BART) model is based on regression trees. The regression tree is grown
by repeatedly splitting the feature vector into disjoint pieces {Rm “21:1. The
problem is to predict a continuous output z given an input feature vector x.
Given a test feature vector x, if it is in piece R,,,, the distribution of z can be

modelled by
[7(Z l9vx)=N(Z “1011702)

where N(z |11,,,,r72) is a Gaussian distribution with mean )1", and standard
deviation (7. )1", is the mean of dependent variables of the training sites in
region R,,,,

As for RFs, BART models the output z using the sum of B trees, so

8
p(z|9.x>=N<zIZgr.a2)

17:1
where g), is the output of the b-th tree. For binary classiﬁcation, e. g. to classify
a site i as somatic (y): 1) or non-somatic (y,»=0), the class probability is
deﬁned as:

B
170i |9~Xi)= <1) (2812)
12:1
where <I>(.) is the standard Gaussian cumulative distribution function, as
opposed to the majority vote used by RFs.
The BART model differentiates from RF because BART is a fully
Bayesian model. All the parameters are given priors and use Markov-Chain
Monte-Carlo sampling for inference.

2.2.3 Support vector machine The support vector machine (SVM)

classiﬁer ﬁnds a linear discriminative function of the the form
f(X)=WT<1>(X)+W0

where (D is a basis function which maps x from 106 dimension to a higher

dimension. Note f(x) is a linear function of <I>(x) but may be a non-linear

function of x.

The SVM assumes that the optimal discriminative function is the one
which leaves the largest possible margin on both sides of the feature
space. For SVM, the importance of each feature is estimated by backward
elimination.

2.2.4 L1 regularized logistic regression The logistic regression (Logit)
method models the probability of y given the feature vector x, representing
candidate mutation site, as

p(y19.x>=g(wix+wo>

where w=(w1,...,wD) is the weight for each feature, D=106 is the
dimensionality of each feature vector and the function g(r])= W is
the logistic link function. The parameter vector w and wo can be found by
maximum likelihood estimation.

Here we put a prior p(w) on the weight of the logit model, and do
maximum a posterior estimation (MAP) of the parameter w. We focus on
the factorized Laplace prior

p(w)= ﬁmw-lp): 121 iexp <— 
H J 1:1 2p p

Given N i.i.d. validated mutation sites (xi,y,»)§v:l,

minimizing the following negative log posterior

we can estimate w by

N
w =argm‘jn — 201101507wa xi»

[:1 D

+(1—yz’)10g(1—I7(yi|W~Xi))]+DlOg(2p)+iZIWjI}
j:l

%Zj:1 |wj| to the negative
log-likelihood function. Since the L1 norm is deﬁned as ||w||1 :2 21:1 |wj|,
the above logistic regression model with Laplace prior on the weights
is called L1 regularized (penalized) logistic regression model. The L1
regularized logistic regression model has the property of shrinking the
weights of irrelevant features to zero.

The Laplace prior introduces a penalty term

2.3 Datasets

We used two independent datasets to train and test the performance of the
models for somatic mutation prediction. The ﬁrst dataset (exome capture
data) consists of 48 triple negative breast cancer Agilent SureSelect V1
exome capture tumour/normal pairs sequenced using the Illumina genome
analyzer as 76 bp pair-end reads. These data were generated as part of a large-
scale sequencing project (Shah et al., manuscript in preparation) whereby
3369 variants were predicted using only allelic counts and liberal thresholds.
Follow-up re-sequencing experiments achieving ~6000>< coverage for the
targeted positions revalidated 1015 somatic mutations, 471 germline and
1883 wild-type (false positive) positions. The exome capture data are
subdivided into two groups consisting of non-overlapping positions:

0 Squall (somatic:775 germline:101 wild-type: 487, total: 1363)
0 Squal2 (somatic:269, germline:428, wild-type: 1410, total: 2107)

Squall positions were obtained by aligning the reads to the whole human
genome, while Squal2 positions were obtained by aligning the reads to a
reference limited to the targeted human exons. Squal2 was considerably
noisier due to misalignments. (Note that 101 positions overlapped in the two
datasets therefore we removed redundant sites from the combined dataset.)

The second dataset (whole genome shotgun data) is from four whole
human genome tumour/normal pairs sequenced using the Life Technologies
SOLiD system as 25750 bp pair-end reads. These data were aligned to
the human genome by using the BioScope aligner. Ground truth for these
samples was obtained from orthogonal exome capture experiments followed
by targeted resequencing on the same DNA samples resulting in 113 somatic
mutations, 57 germline mutations and 337 wild-types. We deliberately held
these positions out of the training data so as to have a completely independent
test set for evaluation.

2.4 Experimental design

For each of the four classiﬁers, we used the exome capture data for classiﬁer
training, and tested on the whole genome shotgun data. For training, we used

 

170

112 /3.IO'S[BIIJI’IOprOJXO'SOIJBLUJOJIItth”Idllq urorj papeo1umoq

9103 ‘0g15n8nv uo ::

Feature-based classifiers for somatic mutation prediction

 

the following procedure. Since each of the models accepts hyper-parameters,
we applied a 10-fold cross-validation analysis on arange of hyper-parameters
(Supplementary Materials) to approximate the optimal settings. We applied
the resulting settings on all of the exome capture data in the ﬁnal training step.
We obtained a set of discriminative features using ensemble feature selection
(Abeel et al., 2010) after training using 40 bootstrap samples and ﬁnally
computed a feature set aggregated from these 40 samples for each classiﬁer.
To test the robustness of each classiﬁer to the input set of features, we trained
each classiﬁer using each of the other classiﬁers” feature sets, producing
4 X 4: 16 results, which were then assessed using sensitivity, speciﬁcity and
accuracy metrics.

To compare our classiﬁcation methods to standard approaches for SNV
detection, we used two popular methods: Samtools V1.16 and GATK
V1.0.5543M. Samtools mpileup and bcftools were run independently
on the tumour and normal barnﬁles to produce SNV calls at the 3369 positions
in the exome capture data. Those SNVs present in the tumour list, but
not the normal were considered somatic mutations, otherwise they were
considered non-somatic. For GATK, we used the UnifiedGenotyper
tool in a similar fashion to classify the positions in the exome capture data.
We also compared the results after removing small indel-induced artefacts
using GATKs local realignment and base quality recalibration tool. We then
compared all methods using accuracy and receiver operator characteristic
curves (ROCs).

3 RESULTS

3.1 Classiﬁers outperform standard approaches

To visually investigate the discriminative ability of the features,
we used principal component analysis (PCA) to project the 106
dimensional space to a 3D space. Supplementary Figure S2
shows that somatic mutations were reasonably separated from
non-somatic mutations, suggesting that accurate classiﬁers could
potentially be learned from the set of features we chose to examine.
Comparison of accuracy on the combined dataset Squall+2
of the different classiﬁers, Samtools bcftools and GATK’s
Uni f iedGenotyper (Fig. 1a, Supplementary Table S1) showed
that BART was most accurate (0.9679) followed by RF (0.9567),
SVM (0.9555) and Logit (0.9065). All classiﬁers were better than
Samtools (0.8103) and GATK (0.7551). We next evaluated the
contribution of speciﬁcity to the accuracy results using a high ﬁxed
sensitivity of 0.99 to establish a probability threshold for each of
the classiﬁers. Speciﬁcity at this threshold was 0.9584, 0.9422,
0.9405 and 0.8704 for BART, RF, SVM and Logit, respectively,
suggesting that Logit had less discriminative power than the other
classiﬁers. The comparative sensitivity and speciﬁcity breakdown
for Samtools was 0.8631 and 0.7876, and for GATK it was 0.9842
and 0.6563. Thus, Samtools had more balanced misclassiﬁcations,
whereas GATK was very sensitive but with a lower speciﬁcity than
the other methods.

Similar patterns were observed for independent analysis of
Squall (Fig. 1b, Supplementary Table S2), although results
for GATK (sensitivity: 0.9819, speciﬁcity: 0.9031) and Samtools
(sensitivity: 0.8245, speciﬁcity: 0.9218) were better than for the
Squall+2 results. We also tested whether local realignment reads
around insertions and deletions and base quality re-calibration
(post-alignment processing tools in the GATK package) improved
results. The classiﬁer results were nearly identical to those
shown in Figure 1b for Squall (Fig. lc). However, while
results for Samtools and GATK both showed an improvement in
speciﬁcity, there was a substantial reduction in sensitivity (Fig. lc,

Supplementary Tables S2 and S3). We also assessed results on
Squal2 independently (Fig. 1d, Supplementary Table S4) and
found that accuracy was highest for BART (0.9312) followed by
RF (0.9282), SVM (0.9160), Logit (0.8677), Samtools (0.7651)
and GATK (0.6208). All methods were worse on this dataset
than on Squall, although the difference for the classiﬁers was
more moderate than the other methods. The markedly worse
performance of Samtools and GATK for this dataset was mainly
due to considerably decreased speciﬁcity; this dataset was generated
from constrained alignments to exons that likely induce many false
alignments, thus the classiﬁer methods may be more robust to
artefacts introduced by misalignments.

Finally, we assessed the statistical signiﬁcance of the observed
differences between methods using the best performing results
for Samtools and GATK (Squall). For each cross-validation
fold, we ﬁxed sensitivity according to the Samtools results and
computed the speciﬁcity of the other methods. We then compared
the speciﬁcity distributions of the methods over all folds using a one-
way ANOVA test. Similarly, we evaluated sensitivity distributions
by ﬁxing speciﬁcity. A similar procedure was then applied to
the GATK results. The classiﬁers were not statistically different
from each other in any comparison. However, all classiﬁers
were statistically signiﬁcantly higher in speciﬁcity and sensitivity
(ANOVA, P <0.00001) than Samtools and GATK (Supplementary
Table SS).

To test the generalization performance of the trained classiﬁers,
we applied them to the test data: four cases with whole genome
shotgun sequencing from tumour and normal DNA on the SOLiD
platform. Despite being trained on exome data, the classiﬁers
performed extremely well and recapitulated the results seen in
the cross-validation experiments (Fig. 2). The accuracy for the
classiﬁers was 0.9487, 0.9487, 0.9369 and 0.9191 for BART,
SVM, RF and Logit, respectively. Samtools accuracy was 0.9053
followed by GATK at 0.8738. These results indicate that, on a
limited dataset, the trained parameters should generalize well to
other platforms and are likely robust to overﬁtting. Moreover, the
trends of higher accuracy of the classiﬁers compared with GATK
and Samtools carried over to the independent test data. Importantly,
at speciﬁcity levels obtained by GATK (0.8883, Supplementary
Table S6), the classiﬁers obtained sensitivity of 0.9381, 0.9027,
0.9027 and 0.8938 for RF, BART, SVM and Logit, respectively
(Supplementary Table S7). At sensitivity levels obtained by
GATK (0.8230, Supplementary Table S6), the speciﬁcity of the
classiﬁers was 0.9772,0.9772,0.9747, and 0.9721 for RF, SVM,
BART and Logit, respectively (Supplementary Table S7), whereas
GATK speciﬁcity was 0.8883. At sensitivity levels obtained by
Samtools, the speciﬁcity of classiﬁers reached 10101.0 and
0.9797 for RF, BART, SVM and Logit, respectively (Supplementary
Table S7), whereas Samtools speciﬁcity was 0.9467. Similarly, at
speciﬁcity levels given by Samtools, the sensitivity of classiﬁers was
0.8938,0.8761,0.8761 and 0.8319 for RF, BART, SVM and Logit,
whereas Samtools sensitivity was 0.7611. Thus, on the orthogonal
test data, all classiﬁers outperformed GATK and Samtools in both
sensitivity and speciﬁcity with BART exhibiting the best overall
performance.

We next investigated whether the use of classiﬁers or the expanded
set of features contributed to increased performance of our methods.
Using the Squall dataset, we restricted the analysis to only
Samtools-derived features (x1_40) and compared the results of

 

171

112 /3.IO'S[BIIJI’IOprOJXO'SOIJBLUJOJIItth”Idllq urorj papeo1umoq

9103 ‘0g15n8nv uo ::

J.Ding et al.

 

(a) 1

0.95

.‘3
(D

 

 

 

 

 

 

 

 

 

 

A
8

P
(D
u-

.0
(0

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

   

— RF (0.9567) — RF (0.9699) — RF (0.9735)
_ b — , — .
 “5 —§CET(§‘.’§ZZ§’  “5 I —§CET13%323?  “5 —§CiiT(S$ZZ§?’
g — Logit (0.9065) g — Logit (0.964) g — Logit (0.9620)
:0 0-8 I Samtools(0.8103) u: 0-5 I Samtools (0.9665) «n 0-8 I Samtools(0.8048)
Q GATK(0.7551) O GATK(0.9479) Q GATK(0.9304)
075 0.75 0.75
0.7 0.7 0.7 I
.05 o. ...5
o 0 0.1 0.2 0.9 0.4 0.5 0 0.1 0.2 0.3 0.4 0.5 o 0 0.1 0.2 0.9 0.4 0.5
1 —Sneciticity 1—Specilicity 1—Speciticity
(d), (e) 1___ 1 + (f) 1___ _ 1
+ + + Cl E |;| I: E] + + E] El 7
 . r . . , 0 a
0.95 0.95 . 0.95 0.95 L T
0.9 * '
—RF 0.9292 7
3085 _BN;T(0'93)12)  0.9 ANOVAp—value: . E 0.9 ANOVAp—value:  0.9 ANOVAp—value: E 0.9 ANOVAp—value=ﬁ
:5 ' —SVM (0.916) 1% 4.1as4e—26 : a 5.2109e—09 l i 9.8084e—09 a 5.3159e—09
2 —L0 it (0.8677) 5 r a E. a
a) 05 9 w w
m - I Samtools (0.7651) 0-55 0-55 o
9 GATK (0.6209)
0.75
0.9 0.9
r
0.7 i
o E 0”“ RF BARTva Lagit ST 0-75 RF BARTva Logit 5T
“‘"0 0.1 0.2 0.3 0.4 0.5
1—Specificity

Fig. 1. (a) Accuracy results from cross-validation experiments on all the exome capture data (Squall+2). All classiﬁers showed better results than Samtools
and GATK’s prediction results in terms of ROC comparison. The numbers in parentheses are the prediction accuracy by ﬁxing the sensitivity at 0.99, except for
Samtools and GATK’s prediction results because their outputs are deterministic. (b) Accuracy results from cross-validation experiments on the exome capture
data of Squall. (c) Accuracy results from cross-validation experiments on the exome capture data of Squall after GATK’s local realignment around indels
and base quality recalibration. (d) Accuracy results from cross-validation experiments on the exome capture data of Squal2. (e) Comparison of classiﬁers
and Samtools’s (ST) performance at the speciﬁcity and sensitivity level given by Samtools. (f) Comparison of classiﬁers and GATK’s performance at the

speciﬁcity and sensitivity level given by GATK.

 
 
   
   
 

.0
(D
tn

 

0-9 — RF (0.9369)

g - - - BART (0.9497)

9: 1-1- SVM (0.9497)

g 0 85 Logit (0.9191)

(0 I, O I Samtools (0.9053)
0.9 . 6 GATK (0.9739)

 

 

 

0.75

0.7

 

0 0.1 0.2 0.3 0.4
1—Specificity

Fig. 2. ROC curves derived from the held-out whole genome shotgun
independent test data from four cases show different classiﬁers” prediction
results as well as Samtools and GATK’s prediction results. The numbers
in the parentheses are the prediction accuracy by using the same threshold
as for the exome capture data (except for Samtools and GATK’s prediction
results).

classiﬁers with those of the Samtools caller. All classiﬁers performed
statistically better than the Samtools caller (Supplementary Fig. S3a
and S3b). For the second experiment, we restricted the analysis to
only the GATK features (x41_30). As for Samtools, the classiﬁers
showed statistically signiﬁcantly better results than those of the
GATK caller (Supplementary Fig. S3c and S3d). These results
suggest that the classiﬁers on the same set of features for both
Samtools and GATK better approximated the ‘optimal’ decision

boundary without the use of heuristic thresholds employed by the
naive methods and demonstrate the clear advantages of the machine
learning approaches we used.

Finally, we studied the effect of the additional 26 features
we introduced (Table 3, x31_106) to the Samtools and GATK
features in order to boost weak mutation signals in the tumour and
decrease the inﬂuence of germline polymorphisms. We compared
the performance of RF and BART on different feature sets:
Samtools alone (x1_40), GATK alone (x41_30) our 26 features
alone (x31_106) and all features combined (x1_106). As shown in
Supplementary Figure S4, by using all the features, RF and BART
showed the best performance in terms of accuracy. However, the
improvement attributed to the 26 novel features was incremental
and may only apply in rare circumstances. We therefore suggest
that while the use of the machine learning classiﬁers accounts for the
majority of improvement over naive methods, further improvement
is achievable with the introduction of novel features thus illustrating
the power of the ﬂexible framework we used in this study (see also
Section 3.3).

3.2 Robustness of classiﬁers to different feature sets

We used ensemble feature selection to output a set of the most salient,
discriminative features for each classiﬁer, leading to four feature
sets overall. We then ﬁt each classiﬁer to the exome capture data
using only the four selected feature sets output from the ensemble
feature selection method. We noted (Table 4) that overall, BART
and RF were most robust to the initial set of features and performed
similarly for each of the four sets, showing stable performance in

 

172

112 /3.10's112111110prOJXO'soneurJOJurorq”:duq urorj papeo1umoq

9103 ‘0g15n8nv uo ::

Feature-based classifiers for somatic mutation prediction

 

Table 4. The classiﬁcation accuracy of classiﬁers by using different
feature sets

 

 

 

Model/Feature RF_F (18) BART_F SVM_F Logit_F
(23) (17) (17)

RF 0.9369 0.9487 0.9448 0.9329

BART 0.9369 0.9428 0.9369 0.9310

SVM 0.9034 0.9408 0.9369 0.9408

Logit 0.8856 0.9487 0.9250 0.9310

Mean 0.9157 0.9453 0.9359 0.9339

 

Here RF_F means the feature selected by RF Classiﬁer. BART_F, SVM_F and Logit_F
are similarly deﬁned. The numbers in parentheses are the number of feature selected.

the presence of variable initial feature sets. Interestingly, all four
methods performed equally well on the features chosen by ensemble
feature selection applied to BART (Table 4) with a mean accuracy
of 0.9453 compared to 0.9359,0.9339 and 0.9157 for SVM, Logit
and RF chosen features, respectively. The detailed test results of
each classiﬁer on different feature sets are given in Supplementary
Table S8—Sll.

In summary, all classiﬁers performed better than the naive
methods for somatic SNV prediction, with RF and BART showing
the best performance. RF classiﬁer is slightly more sensitive
(Fig. 2), while BART has slightly higher speciﬁcity (Fig. 1d). The
performance of SVM and Logit is relatively poor, especially in the
presence of outliers as can be seen from Figure 1d. Importantly, both
RF and BART are less sensitive to different feature sets compared
to SVM and Logit (Table 4). Overall, the data support using RF and
BART over SVM and Logit and suggest that RF may achieve better
sensitivity while BART will achieve higher speciﬁcity, though both
methods are extremely comparable.

3.3 Discriminative features are different for tumour
and normal data

The description of the set of features selected by BART is given
in Supplementary Table S12. The features fell into ﬁve broad
categories: (i) allelic count distribution likelihoods: provided by both
Samtools and GATK; (ii) base qualities such as the sum of reference
base qualities, sum of non-reference base qualities, sum of squares
of non-reference base quality ratio; (iii) strand bias such as sum of
the pooled estimation of strand bias on both strands; (iv) mapping
qualities such as the mean square mapping quality; and (v) tail
distance such as sum of squares of tail distance for non-reference
bases and sum of squares of non-reference tail distance (minimum
distance of variant base to the ends of the read) ratio. Notably, the
features are often different in the tumour and normal. For example,
the reference base qualities (x6) are selected in the normal, but
for tumour both reference (x26) and non-reference base qualities
(x23) are selected. Other tumour-speciﬁc features included sum of
tail distance of the non-reference bases (x37), allele frequency for
each non-reference allele (x63) and variant conﬁdence normalized
by depth (x71). Therefore, BART assigned unequal weights to the
features in the normal and tumour, suggesting that the improved
accuracy is due to treating the tumour and normal data differentially
to optimize the contribution of the discriminant features. We note
in Supplementary Table S12 that BART selected several of the

new features we designed (x33, x96, x97, x99, x101, x102, x105).
These were not in Samtools or GATK, and some were a combined
calculation from the tumour and normal data. This illustrates the
advantage of the classiﬁers’ ability to add arbitrary features and
the importance of simultaneous (not independent) treatment of the
tumour and normal data.

3.4 Sources of errors and subclassiﬁcation of wild-types

We subgrouped the wild-type positions (false positives from the
original predictions) by their feature vectors in order to characterize
false positives due to distinct sources of error. Using the wild-type
positions from Seqvall, we identiﬁed the features which were not
unimodal with the dip statistic (Hartigan, 1985) and selected 28
features with P < 0.1. We then used PCA to project the features to
the ﬁrst seven principal components, and modelled the wild-types
in the 7D space (the ﬁrst seven principal components account for
about 95% of the variance) using a mixture of Gaussian distributions
clustering algorithm ﬁt with EM. We used the Bayesian information
criteria (BIC) score (Supplementary Material) to select six clusters
(Supplementary Fig. S5a and S5e). The number of wild-types in
Group 1 to Group 6 was 37, 189, 43, 181, 6 and 31, respectively.
We attributed the six events in Group 5 to outliers and excluded
this group from further analysis. We then identiﬁed discriminant
features of the different groups, using an analysis of variance
(ANOVA) test followed by a multiple comparison test on each
feature (Supplementary Table S13).

Broadly the groups had the following characteristics. Group 1
(black) featured high values for x102 and x103 indicating
disproportionate mapping qualities in the tumour compared with
the normal. Thus, the tumour reads harbouring variants mapped
with higher qualities than the normal reads harbouring variants at the
same genomic location. In addition, Group 1 exhibited strand bias as
shown by high values of (x96 and x97). The events in this group had
low values for x57 and x77 which indicated low genotype qualities
(conﬁdence in the genotype call). Taken together, these data suggest
that the combination of poor mapping quality of the normal reads
and the strand bias may be affecting the callers’ ability to accurately
call these variants.

Group 2 (red) is characterized by high values of x96 suggesting
strand bias (Supplementary Fig. S6). We examined the surrounding
sequence content around these variants and found the majority of the
variants in this group had a common tri-nucleotide sequence GGT,
changing to GGG (Supplementary Fig. S7), a pattern which has been
discovered in whole genome methyl-Seq experiments Meacham
et al. (2011a,b). Thus, we expect the false positive events in this
group to be induced by systematic artefacts owing to sequencing
errors at speciﬁc tri-nucleotide sequences as well as PCR artefacts
inducing strand bias.

The discriminative features for Group 3 (green) events
were characterized by mapping quality-related features (x10,
x11, x50, x70, x49, x69). Thus, these wild-types may be the
result of misaligned reads, or simply repetitive regions that
are difﬁcult to unambiguously sequence. To investigate this,
we computed the UCSC mapability (http://genome.ucsc.edu/cgi-
bin/hgTrackUi?db=hg18&g=ngncodeMapability) of each site as
shown in Supplementary Figure S8. The mappability of a site depicts
the uniqueness of the reference genome in a window size of 35.
Overall, Group 3 wild-types have considerably lower mappability

 

173

112 /3.10's112111110prOJXO'soneurJOJurorq”:duq urorj papeo1umoq

9103 ‘0g15n8nv uo ::

J.Ding et al.

 

scores than the other groups and therefore can be best explained by
characteristics of the genome at these positions that make variant
calling error prone.

For the wild-types in Group 4 (blue), the pooled estimated strand
biases are zero (x96 and x97). This is because these two features
were computed after Samtools internal base quality ﬁlter threshold
of 13, and the variant alleles had small base qualities so they did
not pass this ﬁlter. The Samtools caller utilizes this base quality
ﬁlter and therefore did not call these positions as variants (large x39
and x40). Group 4 wild-types were also characterized by the GGT
to GGG systematic sequencing artefact (Supplementary Fig. S9)
we observed for Group 2 and therefore is fundamentally similar to
Group 2, but may be easier to detect owing to poor base qualities at
the site of the sequencing error.

Interestingly, Group 6 (magenta) exhibited very similar patterns to
the true somatic mutations (yellow) and thus made them challenging
to interpret. Upon inspection, many of these positions had weak
signals for a variant in the normal data, but perhaps not enough to
induce a variant call. The tumour data, conversely [as shown by
(x62, x63, x71, x73)] exhibited strong signals for a variant. Thus,
the weak signals in the normal data were likely being prematurely
thresholded out by the naive methods. Indeed, the Samtools caller
called 13 of the 31 Group 6 events as somatic while GATK called
29 of the 31 events as somatic. The characteristics of the positions
in Group 6 underscore the strength of simultaneously considering
the tumour and normal features that we suspect enhances the ability
of the classiﬁer to choose better decision boundaries.

4 DISCUSSION

We studied the use of feature-based classiﬁers for the purpose
of somatic mutation detection in tumour/normal pair NGS data.
Using an extensive set of ground truth positions, we trained
four different machine learning classiﬁers using features extracted
from existing software tools and novel features we computed
ourselves. All four classiﬁers statistically signiﬁcantly outperformed
popular software packages used in a naive way to detect somatic
mutations, treating the tumour and normal data independently.
Results were consistent between a cross-validation analysis of the
training data and a completely independent test dataset derived from
an orthogonal sequencing platform. Our results encapsulate three
key results: (i) machine learning classiﬁers can be trained using
principled machine learning techniques to signiﬁcantly improve
somatic mutation detection; (ii) feature selection analysis revealed
that our classiﬁcation method selects different features in the tumour
and normal datasets to optimize classiﬁcation ability, underscoring
that simultaneous rather than independent analysis of the paired
data is important; and (iii) we identiﬁed ﬁve distinct groups of false
positive results. This last result indicates that feature-based analysis
of ‘negative’ or wild-type positions can be helpful to guide future
developments in software pipelines that operate upstream of variant
calling.

Limitations and future work: the results presented herein rely on
third-party software tools for which there is some feature overlap.
Future implementations of our framework will make use of the
bamtools API (Barnett et a1., 2011) to compute features and
remove any redundancy and dependence on third-party software
packages. In addition, the majority of our conclusions in this study

were based on application to exome capture data. Although test
data were derived from a limited set of whole genome shotgun
data, and results suggested reasonable generalization, it will be of
considerable interest to train our classiﬁers on a sufﬁciently large
training set derived from whole genome shotgun studies as this is
likely to be the standard approach for cancer genome interrogation
in the coming years. Finally, we focused our work to support somatic
SNV mutation detection from tumour/normal paired data; we expect
that the framework could easily be adapted to somatic indel detection
and to single sample analyses of NGS genomes for studying human
or other organism variation, given sufﬁcient training data.

5 CONCLUSION

Our results underscore the advantages of developing cancer-speciﬁc
tools for NGS data that can capitalize on the unique experimental
design of tumour/normal paired data. Our conclusions support the
notion that principled feature-based machine learning classiﬁcation
frameworks will be well placed to leverage evolving trends in
the cancer NGS ﬁeld, thereby reducing the burden of downstream
validation efforts with more accurate predictions.

ACKNOWLEDGEMENTS

We thank Daniel Lai for the help computing the mappability of
each site.

Funding: The study was funded by a Canadian Institutes for Health
Research (CIHR) Catalyst Grant: Bioinformatics Approaches to
Cancer Research, application #202452 awarded to S.P.S. and SA.
S.P.S. is supported by the Canadian Breast Cancer Foundation and
the Michael Smith Foundation for Health Research. J .D. is supported
by the OvCaRe - Clear Cell Project.

Conﬂict of interest: none declared.

REFERENCES

Abeel,T. et al. (2010) Robust biomarker identiﬁcation for cancer diagnosis with
ensemble feature selection methods. Bioinformatics, 26, 3927398.

Altmann,A. et al. (2011) VipR: variant identiﬁcation in pooled DNA using R.
Bioinformatics, 27, i777i84.

Bamett,D. et al. (2011) Bamtools: a C++ API and toolkit for analyzing and managing
BAM ﬁles. Bioinformatics, 27, 169171692.

Chapman,M. et al. (2011) Initial genome sequencing and analysis of multiple myeloma.
Nature, 471, 467472.

Chipman,H. et al. (2010) BART: Bayesian additive regression trees. Ann. Appl. Stat.,
4, 26&298.

Ding,L. et al. (2010) Genome remodelling in a basal-like breast cancer metastasis and
xenograft. Nature, 464, 99971005.

Goya,R. et al. (2010) SNVMix: predicting single nucleotide variants from next-
generation sequencing of tumors. Bioinformatics, 26, 7307736.

Hartigan,P. (1985) Algorithm as 217: computation of the dip statistic to test for
unimodality. J. R. Stat. Soc. Ser C, 34, 3207325.

Hastie,T. et al. (2009) The Elements of Statistical Learning: Data Mining, Inference,
and Prediction. Springer, New York.

Koboldt,D. et al. (2009) VarScan: variant detection in massively parallel sequencing of
individual and pooled samples. Bioinformatics, 25, 228372285.

Li,H. etal. (2009a) The sequence alignment/map format and SAMtools. Bioinformatics,
25, 207872079.

Li,R. et al. (2009b) SNP detection for massively parallel whole-genome resequencing.
Genome Res, 19, 112471132.

McConechy,M. et al. (2011) Subtype-speciﬁc mutation of PPP2R1A in endometrial and
ovarian carcinomas. J. Pat/101., 223, 5677573.

 

174

112 /3.10's112111110prOJXO'soneurJOJurorq”:duq urorj papeo1umoq

9103 ‘0g15n8nv uo ::

Feature-based classifiers for somatic mutation prediction

 

McKenna,A. et al. (2010) The Genome Analysis Toolkit: a MapReduce framework for
analyzing next-generation DNA sequencing data. Genome Res., 20, 129771303.

Meacham,F. et al. (2011a) Identiﬁcation and correction of systematic error in high-
throughput sequence data. BMC Bioinformatics, 12, 451.

Meacham,F. et al. (2011b) Identiﬁcation and correction of systematic error in high-
throughput sequence data. Nature Precedings, June 2011.

Morin,R. et al. (2010) Somatic mutations altering EZH2 (Tyr641) in follicular and
diffuse large B-cell lymphomas of germinal-center origin. Nat. Genet, 42, 1817185.

Morin,R.D. et al. (2011) Frequent mutation of histone-modifying genes in non-hodgkin
lymphoma. Nature, 476, 2987303.

Puente,X. et al. (2011) Whole-genome sequencing identiﬁes recurrent mutations in
chronic lymphocytic leukaemia. Nature, 475, 1017105.

Shah,S. et al. (2009a) Mutation of FOXL2 in granulosa—cell tumors of the ovary.
N. Engl. J. Med., 360, 271972729.

Shah,S. et al. (2009b) Mutational evolution in a lobular breast tumour proﬁled at single
nucleotide resolution. Nature, 461, 8097813.

Varela,I. et al. (2011) Exome sequencing identiﬁes frequent mutation of the SWI/SNF
complex gene PBRMl in renal carcinoma. Nature, 469, 5397542.

Wiegand,K. et al. (2010) ARIDlA mutations in endometriosis-associated ovarian
carcinomas. N. Engl. J. Med., 363, 153271543.

Yan,H. et al. (2009) IDHl and IDH2 mutations in gliomas. N. Engl. J. Med., 360,
7657773.

 

175

112 /3.10's112111110prOJXO'soneurJOJurorq”:duq urorj papeo1umoq

9103 ‘0g15n8nv uo ::

