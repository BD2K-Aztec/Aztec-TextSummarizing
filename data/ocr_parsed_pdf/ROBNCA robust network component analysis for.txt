ORIGINAL PAPER

Vol. 29 no. 19 2013, pages 2410—2418
doi:10. 1 093/bioinformatics/btt433

 

Gene expression

Advance Access publication August 11, 2013

ROBNCA: robust network component analysis for recovering

transcription factor activities

Amina Noor‘, Aitzaz Ahmad2, Erohin Serpedin”, Mohamed Nounou3 and Hazem Nounou4
1Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX 77843, USA,
2Corporate Research and Development, Qualcomm Technologies Inc., San Diego, CA 92121, USA, 3Department of
Chemical Engineering and 4Department of Electrical Engineering, Texas A&M University at Qatar, Doha Qatar

Associate Editor: Ziv Bar—Joseph

 

ABSTRACT

Motivation: Network component analysis (NCA) is an efficient method
of reconstructing the transcription factor activity (T FA), which makes
use of the gene expression data and prior information available about
transcription factor (T F)—gene regulations. Most of the contemporary
algorithms either exhibit the drawback of inconsistency and poor
reliability, or suffer from prohibitive computational complexity. In add-
ition, the existing algorithms do not possess the ability to counteract
the presence of outliers in the microarray data. Hence, robust and
computationally efficient algorithms are needed to enable practical
applications.

Results: We propose ROBust Network Component Analysis
(ROBNCA), a novel iterative algorithm that explicitly models the pos-
sible outliers in the microarray data. An attractive feature of the
ROBNCA algorithm is the derivation of a closed form solution for
estimating the connectivity matrix, which was not available in prior
contributions. The ROBNCA algorithm is compared with FastNCA
and the non-iterative NCA (NI-NCA). ROBNCA estimates the TF ac-
tivity profiles as well as the TF—gene control strength matrix with a
much higher degree of accuracy than FastNCA and Nl-NCA, irrespect-
ive of varying noise, correlation and/or amount of outliers in case of
synthetic data. The ROBNCA algorithm is also tested on Saccharo-
myces cerevisiae data and Escherichia coli data, and it is observed to
outperform the existing algorithms. The run time of the ROBNCA al-
gorithm is comparable with that of FastNCA, and is hundreds of times
faster than Nl-NCA.

Availability: The ROBNCA software is available at http://people.tamu.
edu/~amina/ROBNCA

Contact: serpedin@ece.tamu.edu

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on March 26, 2013; revised on June 28, 2013; accepted on
July 24, 2013

1 INTRODUCTION

Recent advances in technology have enabled monitoring of cel-
lular activities using more sophisticated techniques, and have
provided a deluge of biological data. Using these data to unravel
the underlying phenomena that regulate various activities in a
living organism offers the potential to reap numerous benefits.

 

*To whom correspondence should be addressed.

One of the key biological processes is transcriptional regulation,
which controls the gene expression and amount of RNA pro-
duced. This process is regulated by transcription factors (TFs),
which are specialized proteins causing the genes to express by
binding onto the gene promoters. A thorough understanding of
this complex transcriptional regulation and TFigene interaction
will potentially aid in predicting the biological processes and
designing control strategies to cure and/or avoid the diseased
conditions (Lahdesmaki et al., 2008). Microarray technologies
are able to measure the level of gene expressions and quantify
them in the form of gene expression data. Such data are widely
used in the inference of geneigene interactions. Transcription
factor activity (TFA), which is deﬁned as the concentration of
its subpopulation with DNA binding ability, controls the tran-
scriptional regulation (Jajamovich et al., 2011). The correlation
between TFAs and TF expression level is modiﬁed at the post-
transcriptional and post-translational stage. It is, therefore, much
harder to measure TFA proﬁles experimentally, and scientists
have resorted to computational methods for their estimation
Wang et al., 2005).

Several statistical techniques including principal component
analysis (PCA) (J olliffe, 1986) and independent component ana-
lysis (ICA) (Comon, 1992) have been used to deduce useful in-
formation from sets of biological data. However, the successful
application of these algorithms hinges on the assumptions of
orthogonality and independence between the signals, which do
not hold for biological signals in practice (Chang et al., 2008). In
fact, some prior information is usually available for many sys-
tems, and it should be incorporated in the system model, e.g.
ChIPwhip data indicates which TFs and genes are known to
interact. The gene regulatory network can be modelled linearly
as follows (Liao et al., 2003)

Y=As+r, (1)

where Y is the N x K gene expression data matrix, A is the
N x M control strength or connectivity matrix and S is the
M x K matrix denoting the TFAs. The uncertainties in the ob-
servation data are assumed to be Gaussian (Chang et al., 2008;
Jacklin et al., 2012), and are represented by the entries of the
noise matrix F. Genes and TFs are known to interact in a dy-
namic and non-linear manner; however, a log-linear relationship
provides a good approximation. Because a particular TF regu-
lates only a few other genes, the connectivity matrix A is expected
to be sparse. The problem then boils down to estimating S and

 

2410 © The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com

112 /310'S[BIIJHO[pJOJXO'SOTJBLUJOJIITOTCI”Zduq 11101} popcolumoq

9103 ‘Og anﬁnv uo ::

ROBNCA

 

A, where Y is available and some a-priori information about the
matrix A is known.

Network component analysis (NCA), proposed by Liao et a].
(2003), provides a more accurate model for TFigene regulation
and makes use of the related prior information available. It was
shown that provided certain conditions are met, the NCA algo-
rithm produces a unique solution of the aforementioned estima-
tion problem in the absence of noise. The NCA criteria require
that: (i) the matrix A is full column-rank; (ii) if a row is removed
from S as well as the output elements connected to it, the
updated control strength matrix should still be of full column-
rank; (iii) the TFA matrix S should have a full row-rank. These
criteria guarantee that the solution obtained is unique up to a
scale ambiguity (Jacklin et al., 2012; Liao et al., 2003). When
the NCA criteria are satisﬁed, the optimization problem
reduces to:

11131§IIIY — ASH; s.t. A(I) = 0, (2)
where ||.||F denotes the Frobenius norm and I is the set of all
indices where the entries of matrix A are known to be zero. The
algorithm in (Galbraith et al., 2006) allows the recovery of source
signals when the microarray data consist of fewer data points
and (Tran et al., 2005) formulates the incorporation of regula-
tory knockout constraints as well.

The NCA problem in (2) was ﬁrst solved by using alternate
least squares (ALS) for both A and S (Liao et al., 2003).
However, because the ALS solution requires solving a high
dimensional matrix optimization problem at each iteration, it
entails prohibitive computational complexity for large datasets,
which often need to be handled in gene networks. FastNCA
provides a closed form solution for A, which uses singular
value decomposition (SVD) (Chang et al., 2008), and is several
tens of times faster than the ALS algorithm. The authors in
(Jacklin et al., 2012) propose a non-iterative version of NCA,
herein referred to as NI-NCA, which offers greater consistency in
terms of TFA estimation at the cost of much higher computa-
tional complexity than FastNCA. However, because the decom-
position techniques used to derive these algorithms are
susceptible even to the presence of small amount of outliers
(Mateos and Giannakis, 2012), their performance is expected
to deteriorate signiﬁcantly when data points are corrupted by
outliers. It is commonly known that the microarray data are
noisy and are corrupted with outliers because of erroneous meas-
urements and/or abnormal response of genes, and robust algo-
rithms are required for gene network inference (Finegold and
Drton, 2011). Therefore, it is imperative to develop an NCA
algorithm that has an inherent ability to mitigate the effect of
outliers, and also entails low computational costs and provides
good consistency and accuracy. It is precisely this avenue which
is the focus of our current work. The main contributions of this
article can be summarized as follows:

(1) A novel algorithm, ROBust Network Component
Analysis (ROBNCA), is proposed which has the inherent
ability to counteract the presence of outliers in the data Y
by explicitly modelling the outliers as an additional
sparse matrix. The iterative algorithm estimates each of
the parameters efﬁciently at each iteration, and delivers

superior consistency and greater accuracy for TFA
estimation.

(2) A particularly attractive feature of the ROBNCA algo-
rithm is the derivation of a closed form solution for the
estimation of the connectivity matrix A, a major source of
high computational complexity in contemporary algo-
rithms. To further lower the computational burden, a
still faster closed form solution is derived that requires
matrix inversion of much smaller size. The resulting algo-
rithm is comparable with FastNCA in terms of computa-
tional complexity, and is hundreds of times faster than
NI-NCA.

(3) The performance of ROBNCA is tested on Haemoglobin
test data from (Jacklin et al., 2012) for both low and highly
correlated source signals.

ROBNCA is seen to outperform the state-of-the-art algo-
rithms for estimating both A and S in terms of mean square
error (MSE). In addition, ROBNCA is applied to yeast cell
cycle data (Lee et al., 2002) and Escherichia coli data (Kao
et al., 2004), and by plotting the standard deviation of estimates,
it is observed that ROBNCA offers better consistency than
FastNCA and NI-NCA.

2 METHODS
2.1 NCA with outliers

Most of the contemporary algorithms have studied the gene network
construction problem using NCA with Gaussian noise models.
However, inaccuracies in measurement procedures and abnormal gene
responses often render heavier tails to the gene expression data, and
Gaussian noise models may no longer be a natural ﬁt in these cases.
The decomposition techniques used in the available algorithms are
highly sensitive to the presence of outliers i.e. the samples that do not
conform to the Gaussian noise model, and their estimation capabilities
are extremely susceptible to outliers. As a consequence, the gene network
inference becomes unreliable for practical purposes. Therefore, we focus
on deriving computationally efficient NCA algorithms that are robust to
the presence of outliers.

Towards that end, we take the approach of explicitly modelling the
outliers as an additional matrix that corrupts the data points. From (1), it
follows that the complete system model that accounts for the presence of
outliers as well as noise can be expressed as

Y=AS+0+F, (3)

where the matrix 0 denotes the outliers. The outlier matrix 0 is a column
sparse matrix, as there are typically a few outliers. The joint optimization
problem for the estimation of the three parameters, which also allows for
controlling outlier sparsity, can be formulated as

AAA _ - _ _ 2
{A.s.0}—arggpollr As 0||p+ko||0||o (4)

such that AU) 2 0,

where the non-convex [0 norm “0",, denotes the number of non-zero
columns in 0, and the extent of sparsity in the columns of 0 is controlled
by the tuning parameter A0. The optimization problem in (4) is reminis-
cent of compressive sampling techniques based on the [0 norm, and are
known to be NP-hard (Tropp, 2006). Therefore, some relaxation is
needed to solve the joint optimization problem without incurring expo-
nentially increasing computational complexity. A viable alternative is the
column-wise [2 sum i.e. ||0||2,L, 2 25:1 H01, “2, which is the closest convex

 

2411

112 /310's112u1n0fp10}x0"sorwurJOJurorq/ﬁduq 11101} pQPBOIIIAAOG

9103 ‘Og isanV uo ::

A.Noor et al.

 

approximation of “0",, (Tropp, 2006). With this relaxation, the resulting
joint optimization problem can be expressed as

A A A _ - _ _ 2
{A, S, 0} _ arg inqan H Y AS 0“; + A2||0||2,c (5)

such that AU) 2 0.

Our goal is to estimate the three parameters A, S and 0 by solving the
optimization problem (5). However, it can be noticed that the optimiza-
tion problem is not jointly convex with respect to (w.r.t) {A, S, 0}.
Therefore, we resort to an iterative algorithm that alternately optimizes
(3) w.r.t one parameter at a time.

2.2 The ROBNCA algorithm

The update of each of the parameters, S(j), A(j) and 0(1), at an iteration j
is discussed as follows.

2.2.] Update of the TFA matrix At iteration j, the value of the
parameter S(j) is updated by minimizing the objective function (3) w.r.t
S, while ﬁxing the parameters A and 0 to their respective values at iter-
ation (j — 1). By defining the matrix X(j) = Y— 0(j — 1), the optimiza-
tion problem can be written as

S(I) = argmsin IIXU) - AU - US“;- (6)

Because the connectivity matrix A(j — 1) has full column rank (by
virtue of NCA criterion 1), the matrix AT(j — 1)A(j — 1) is invertible.
Therefore, an estimate of the TFA matrix S at the jth iteration can be
readily obtained as

. . . *1 . .
S(1) = (ATU — 1)A(1 — 1)) ATU -1)X(I)- (7)
The estimate S(j), so obtained, is used in the upcoming steps to deter-

mine A and 0.

2.2.2 Update of the connectivity matrix The next step in the itera-
tive algorithm is to solve the optimization problem (3) w.r.t the matrix A,
while ﬁxing the values of the parameters S and 0 to S(j) and 0(j — 1),
respectively. The resulting optimization problem can be written as

A0) = argrnAin IIXU) — 145(1)“;
such that AU) 2 0

(8)

REMARK 1. The optimization problem (8 ) was also considered in the ori-
ginal work on N CA by Liao et al. (2003). However, a closed form solution
was not provided and the proposed algorithm relied on costly optimization
techniques to update the matrix A. Because this minimization needs to be
performed at each iteration until convergence, the ALS algorithm is known
to be extremely slow for large networks, and computational resources
required may be prohibitive (Jacklin et al., 2012 ). Hence, it is imperative
that a closed form solution is obtained for the optimization problem in (8 ),
so that the algorithm is faster and efficient.

Without loss of generality, we can consider the transposed system

2? = §Z + f". (9)

where (T, S, A and IN" denote the transpose of the original matrices,

respectively. The resulting equivalent optimization problem can now be
stated as

2(1) = argmNin H270) — Emil;
A (10)
such that A(T) = 0,
where T is the set of all indices where the entries of the matrix A are

known to be zero. The following theorem presents a closed form solution
of the optimization problem (10), herein referred to as ROBNCA 1.

THEOREM 1. The solution of (10) at the jth iteration is given by

17,10") = QTIU)[Wn(1') — Cf‘I'TIUWnQ’lUWAD], (11)
where  f C" QT1(j)C;-, W41") 2 STU)fn(j), the symmetric matrix
Q(j) f STU)S(j) and 5,, and 3,, represent the nth columns of matrices A
and X, respectively. The Ln x M matrix C" is a matrix of zeroes except

CAT") 2 1, where in is the set of indices where the entries of 27,, are zero,
and L” denotes the number of zero entries in in.

PROOF. The n’h column of (9) can be written as
a, = E47,, + 17,. (12)

The objective function in (10) can be equivalently expressed as
~ ~ N N ~
llX(1') - SUM”; = Z HEU) - SU)47nll2- (13)
n:1

The constraint Ad) :0 can be written as a set of n constraints
0,47,, = 0 for n = 1, .. . ,N. The Ln x M matrix C" is constructed such
that it consists of all zeroes except CAT") 2 1. For instance, if M = 6, and
47,, = [an,,a,,2,0,a,,4,0,a,,6]T, the 2 x 6 matrix C" consists of all zeroes
except Cn(1, 3) = Cn(2, 5) = 1. It can be easily veriﬁed that the matrix
C" so constructed has full row rank.

The optimization problem in (10) can now be written as

N
2(1) = arguing lino) — §(I')«~nll2 (14)

suchthat Cna~n=0, Vn=1,...,N.

The optimization problem is, therefore, separable in terms of columns
of A, and can be equivalently solved by considering one column at a time.
This also reduces the computational complexity of estimating the con-
nectivity matrix A. Henceforth, we will use convex optimization tech-
niques to derive a closed form solution of the separable optimization
problem. For the n’h column, we have

«3(1) = argQUﬁn — r: (1);.
an (15)
such that 0,47,, = 0,

where the objective function is re-scaled and terms independent of 47,, are
neglected. The Lagrangian dual function can be expressed as

N IN .N N .~ ~
ﬂan, M) = EanWln - WIUM + MTCnan.

The KarushiKuhniTucker (KKT) conditions can be written as (Boyd
and Vandenberghe, 2004)

9(1):?" — M) + Cir = 0 (16)

0,47,, = 0. (17)

LEMMA 1. The KKT conditions are necessary and sufﬁcient for the opti-
mization problem (15).

PROOF. Since the optimization problem (15) contains linear equality con-
straints, the KKT conditions are necessary for optimality (Boyd and
Vandenberghe, 2004). Let any 47: be a local minimum. Then, since the
KKT conditions are necessary, there exists a Lagrange multiplier u* such
that (47:41,") is the solution to the system of equations in (16) and (17).
Now since the objective function is convex, it follows that E: is also a
global minimum (Boyd and Vandenberghe, 2004). This implies that the
KKT conditions are also sufﬁcient for optimality.

Hence, a solution to (15) can be obtained by solving the KKT system
of equations. Using (16), it follows that

«3 = Q’IU)(W(1')- Cir), (18)

 

2412

112 /310's112u1n0fp10}x0"soiwuiJOJuioiq/ﬁduq 11101} papeolumoq

9103 ‘Og isnﬁnv uo ::

ROBNCA

 

where the matrix Q(j) is indeed invertible by virtue of the linear inde-
pendence of the rows of S (NCA criterion 3). Substituting (18) in (17),
we have

CnQTIU)CfM = CnQTIU)W(j)-
Since the matrix C,, has full row rank, the matrix ‘I’(j) g C,, Q’1(j)Cf is
invertible. The Lagrange multiplier can, therefore, be expressed as

M = ‘1”1(1')CnQ’1(1')W(1')- (19)

Upon substituting (19) in (18), the solution 47,, in THEOREM 1 readily
follows. N

Therefore, using THEOREM 1, an estimate of A(j) can be efﬁciently
obtained and this approach results in substantial reduction in computa-
tion complexity compared with the ALS algorithm.

REMARK 2. While the aforementioned closed form solution provides a sig-
niﬁcant advantage in terms of computational complexity over the ALS
algorithm, we note that the solution requires inverting the matrix Q. For
large networks, this can potentially be a large matrix, whose inverse incurs
computational load, and may lead to inaccuracies as well. In the following
discussion, we derive a still faster algorithm, ROBNCA 2, that takes ad-
vantage of the special structure of the column vector 5,, and provides added
savings over the closed form solution derived in THEOREM 1.

We begin by noting that the rows of Y and A can always be
reordered in (9). Hence, without loss of generality, the vector 47,, can be
partitioned as

~ 3,,
11,, = [0Lnx1], 

where 6,, e RWTWXI is a vector consisting of the non-zero entries in (7,.
Construct an L,, x M matrix U,, such that

Un = [0L,X(M7L,) IL,  (21)

With the above deﬁnition, the optimization problem (15) can be equiva-
lently represented as

N . , 1 N . N N . ~
an(1) = arg H1111 -an(1)an - Wiman
11,, 2 (22)
such that U,,a~,, = 0.
Deﬁne a substitution
in = Vnﬁna 
where the M x L,, matrix V,, is constructed such that it lies in the null

space of the matrix U,,, i.e. U,, V,, = 0. The matrix V,, is, therefore, given
by

V,,=[ I‘M’L")  (24)

0L,,><(M7L,,)

By substituting 47,, from (23) into (22), and noting that the constraint is
always satisﬁed due to the construction of V,,, we have an unconstrained
optimization problem in the variable 6,, given by

in") = argrginéﬁi View rm — WI (1') rm. (25)

The solution of the aforementioned unconstrained quadratic optimiza-
tion problem can be easily obtained as

M) = (V,,TQ(/)V,)’1 Vim). (26)

where the matrix V;Q(1’)V,, is invertible, as V,, has full column rank.
The symmetric invertible matrix Q(j) can be partitioned as

._ QnU) 912(1)
90) {921(1) 9201’

where the invertible matrix Q11(j) is the upper (M — L,,) x (M — L,,)
submatrix of Q(j). From the structure of V,,, the matrix V;Q(1’)V,, can
be reduced as

Via/"W,
Q1103 Q120)][ 1min) ]
= I , 0 , X , , , 27
[ (M L") (M L” L 119210) 922(1) 02min) ( )
2 Q1101
Similarly, by partitioning 1%,(1') as
2.0) = 
it follows that
VIM) = WI), (28)

where Wn(j) is the upper (M — L,,) x 1 vector of 1%,(1'). Collecting all the
terms, the solution in can now be compactly represented as

in) = 9,1102%"). (29)

Once all columns 47,, (j) are determined, the connectivity matrix A(j) can be
easily updated.

REMARK 3. By comparing the closed form solution derived in (11) with
( 29 ), it is clear that the latter only requires inverting a submatrix Q11(j) of
Q(j). Since the connectivity matrix is usually sparse and the number of non-
zero entries (M — L,,) in the nth column is usually very small, inverting the
(M — L,,) x (M — L,,) matrix Q11(j) results in a considerable reduction in
computational complexity and ensures a much faster implementation of the
iterative algorithm.

The respective computational times incurred in calculating (11)
and (29) will be quantiﬁed in Section 3 to emphasize the usefulness of
deriving (29).

2.2.3 Update of the outlier matrix The last step in the iterative
algorithm pertains to the estimation of the outlier matrix 0 by using
the values S(j) and A(j) obtained in the preceding steps. It is straightfor-
ward to notice that the optimization problem (3) w.r.t 0 decouples across
the columns and results in K subproblems, each of which being expressed
as follows:

02(1) = argrrgn 1|ka) — 01,113+ Aznoknz. (30)

where mm = yk — A(j)sk(j). The solution to (30) is given by (Kekatos
and Giannakis, 2011)

“kale ’

where (g) + 3 max(0, g). The solution (31) is intuitively satisfying, as it
sets the outlier 0;,(1') to zero whenever “bk (j)||2 fails to exceed the threshold
A2 /2, where A2 is the sparsity-controlling parameter. Several approaches
have been identified in the literature for selecting A2, which depend on
any a-priori information available about the extent of sparsity (Giannakis
et al., 2011). If the concentration of outliers is unknown, a typical rule of
thumb is to take A2 = 0.7 where this value has been determined to pro-
vide 95% asymptotic efﬁciency of the estimator (Kekatos and Giannakis,
2011). If a rough estimate of the concentration of outliers is available, (30)
can be solved for a grid of values and selecting the A2 giving the expected
number of outliers, which can be performed efficiently using the Group-
LARS algorithm (Yuan and Lin, 2005). It is noted that the performance
of the algorithm is insensitive to minor variations in the value of the
parameter. Since the subproblems at each iteration have unique minim-
izers, and the non-differentiable regularization affects only the outlier
matrix 0, the convergence of the ROBNCA algorithm is established
using the results in (Tseng, 2001).

0,0): k=1,...,K (31)

 

2413

112 /310's112u1n0[p101x0"soiwuiJOJHioiq/ﬁduq 111011 pap201umoq

9103 ‘0g isanV uo ::

A.Noor et al.

 

PROPOSITION 2. As j—> co, the iterates generated by the ROBNCA
algorithm converge to a stationary point of (3).

It is important to point out that ROBNCA is signiﬁcantly different
from NI-NCA algorithm. NI-NCA, as the name suggests, is a non-itera-
tive algorithm that uses a subspace-based method for the estimation of
the connectivity matrix A using eigen-decomposition and relies on solving
a constrained quadratic optimization problem, which has high computa-
tional cost. On the other hand, in ROBNCA, we propose two closed form
solutions for the estimation of the connectivity matrix A, which result in
considerable reduction in computational complexity.

3 RESULTS AND DISCUSSION

This section investigates the observed performance of ROBNCA,
in comparison with the state-of—the-art algorithms including
FastNCA, NI-NCA and ALS in terms of MSE using both syn-
thetic and real data. The efﬁciency and consistency of ROBNCA
in estimating the TFAs under various scenarios is also illustrated.
The datasets for all of the experiments as well as the MATLAB
implementation of FastNCA and NI-NCA are downloaded
from http://www.seas.ucla.edu/liaoj/download.htm and http://
www.ece.ucdavis.edu/jacklin/NCA, respectively.

3.1 Synthetic and haemoglobin test data

First, to evaluate the performance of various algorithms, test
data from (Liao et al., 2003) is used. The spectroscopy data
consist of M :7 haemoglobin solutions formed by mixing up
N :3 pure haemoglobin components. The connectivity matrix
in this case represents the concentration and presence or absence
of each component in the mixture. In addition, the structure of
this matrix is validated to comply with the NCA criteria. The
absorbance spectra are taken for wavelengths in the range of
38(L700 nm, with lnm increments to get K: 7 observation
points, which is deﬁned as Abs 2 Ce (Liao et al., 2003), where
the rows of Abs give the absorbance spectra for the range of
wavelengths, C denotes the connectivity matrix and 6 gives the
spectra of the pure components. The importance of using these
data is that this experiment mimics the gene regulatory network
very closely and contains all of its key properties. The knowledge
of the pure spectra helps us to effectively evaluate the perform-
ance of various NCA algorithms. In addition, using the data
from (Liao et al., 2003) and (Jacklin et al., 2012) ensures a fair
comparison.

The proposed algorithm is tested against varying noise for two
important scenarios: (i) when the source signals are correlated,
and (ii) the observed data are corrupted with outliers. Using the
same connectivity matrix, source signals were generated which
had low, moderate and high correlation (Jacklin et al., 2012).
The outliers are artiﬁcially added to the data by modelling
them as a Bernoulli process. The success probability indicates
the concentration of outliers present and is assumed to be the
same for all the genes. Since only a few points are expected to be
corrupted in the real data, the outliers are assumed to be sparse
and therefore the success probability of presence of outliers is
kept small. The performance of ROBNCA, FastNCA and NI-
NCA is evaluated in the aforementioned scenarios. ROBNCA
algorithm is implemented in MATLAB. Since the observed data
matrix Y is expected to contain outlying points, the algorithms

are assessed by computing the MSE incurred in estimating the
matrices A and S, instead of ﬁtting error for Y. The comparison
with ALS is omitted here because it takes much longer to run as
will be shown in the next subsection.

3.1.] Impact of correlation The algorithms are ﬁrst tested for
low and highly correlated source signals by varying the signal-to-
noise ratio (SNR). The noise is modelled as Gaussian in all the
experiments. The results are averaged over 100 iterations and are
depicted in Figure 1. It is observed that the presence of a small
amount of outliers makes the estimation using FastNCA unreli-
able and inconsistent for both low and highly correlated signals.
On the other hand, NI-NCA is able to estimate S better than
FastNCA, and the estimation of A is quite accurate and consist-
ent as well. It can be observed that the overall estimation per-
formance for A is much better and more consistent than that of
S. The reason for this could be attributed to the availability of
some prior information for the former. Since ROBNCA takes
into account the presence of outliers in the observed data, it
outperforms the other two algorithms for estimating both A
and S and its consistent performance should be contrasted
with the unboundedness and unpredictability exhibited by the
other two algorithms. In general, the performance of all the
algorithms improves with the increase in SNR and degrades
with the increase in correlation of the source signals.

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

(a) FastNCA NI-NCA ROBNCA
20 _ —5 _ V —5
-10 .  .  . . -10
h -15 Q -  -15
g e : . .
< _20..:~°_.¢_.e< _20. :. .  
—25--: -  - —25'-'H-9-+—v
_30 I i _30 I I
0 20 40 0 20 40
NI-NCA ROBNCA
—5 7 —5
I 40919“
\
\ . - .
“,3 o \ -15 . . \. i0. .
g x\ ' \ I ,\
. ‘ _ ._ . \
(I: -10 \ .. .. ..l 20 b . 01)
1x, I . .
x I\ -25 . . . . . .
-20 -30 I -30
0 20 40 0 20 40 0 20 40
 FastNCA NI-NCA ROBNCA
20 —5 7 —5
\‘   -10 . . . . . . -10
qu 10 {(01 _
E . \.
Z . .. _
I
2 o . ..).\. 
. v I
. 3e
-10 I
0 20 40 0 20 40 0 20 40
NI-NCA ROBNCA
' \ . . '5
\. .
-10 . a . [q

S NMSE

 

 

 

 

 

 

 

 

 

o 20 40 o 20 40
Fig. 1. Impact of correlation: Normalized mean square error (NMSE)
(dB) for different algorithms and different datasets with (a) low correlated
TFAs and (b) highly correlated TFAs against varying SNR (dB), with the
level of outliers = 0.05

 

2414

112 /310's112u1n0[p101x0"soiwuiJOJHioiq/ﬁduq 111011 pap201umoq

9103 ‘0g isanV uo ::

ROBNCA

 

3.1.2 Impact of outliers As noted earlier, the presence of out-
liers can severely affect the performance of algorithms. It is there-
fore, important to investigate the impact of the presence of
outlying points in the observation matrix Y. Comparison per-
formed for low and high concentration of outliers is depicted in
Figure 2. It is observed from Figure 2a that in the case of low
concentration of outliers, NI-NCA provides good accuracy for A
and estimates it quite consistently. The estimation of S gives a
small MSE as well and generally performs consistently.
FastNCA, however, is not able to estimate both the matrices
even for high SNRs. This indicates its high vulnerability to the
presence of even a small number of outliers. In case of a higher
concentration of outliers, the performance of NI-NCA degrades
a little bit as depicted in Figure 2b. It is observed that ROBNCA
is able to estimate the two matrices for both low and high out-
liers, and outperforms the other two algorithms.

The estimation of 0 matrix is shown in the Supplementary
Material where Figure 1 depicts the outliers present in the syn-
thetic data and their estimates using ROBNCA algorithm. It is
noted that ROBNCA is able to identify the outliers very well.
Figure 2 shows the recovered signal AS after subtracting the
outlier matrix 0 from the data matrix X. It can be observed
that the recovered signal is a good match with the original signal.

 

 

(a) 30 FastNCA _5 Nl-NCA _ ROBNCA
—1o~w§ ((((  —1o tttttttttttttt ~

g -15  -  - -15

: —2oI°99-9°‘ —2o

   

 

 

-10 0 10 20 -10 0 10 20

FastN CA ROBNCA

 

 

S NMSE

 

 

 

 

-10 0 10 20

 

 

 

 

 

 

 

 

SNR(dB)
Nl—NCA ROBNCA
—1o~~£ r I r I  —1o I r I r r I r I - I r I r r ~
Hg -15 .. . ._ . _,5
L . .
i —20 6999‘” —2o --
' ' A AAA
-25 . . . . . . . . -25 .V. .V.". Y.
o ' —3o —30
-1o 0 10 20 -1o 0 1o 20 -1o 0 1o 20
FastNCA Nl-NCA ROBNCA
, 5

S NMSE

 

 

 

 

 

 

 

_20 . I _30 . . . .
—1o 0 1o 20 —10 o 10 20 —1o 0 1o 20
SNR (dB)

 

 

Fig. 2. Impact of outliers: Normalized mean square error (NMSE) (dB)
for different algorithms and different datasets with (a) level of out-
liers=0.01 and (b) level of outliers=0.1 against varying SNR (dB) for
a highly correlated dataset

These experiments indicate that ROBNCA solves the estima-
tion problem with much more accuracy than NI-NCA and
FastNCA. It is important to emphasize here that the MSE for
NI-NCA is always higher than ROBNCA and its computational
complexity is many times greater than the latter, which can prove
to be a bottle-neck in case of large datasets.

3.2 Results for real data

We now turn our attention to the comparison of these algorithms
on real data. Two datasets are considered for this purpose, which
are the Saccharomyces cerevisiae cell cycle data (Lee et al., 2002)
and E.coli data (Kao et al., 2004). The transcription factor activ-
ities are estimated for the TFs of interest in each experiment, and
the results are compared for different algorithms. In addition, the
variability of the estimates is evaluated using the subnetwork
analysis Wang et al., 2005) which will be explained in the fol-
lowing subsections.

3.2.I S.cerevisiae cell cycle data The algorithms discussed in
this article are applied to the yeast cell cycle data from (Lee
et al., 2002) and (Spellman et al., 1998). To assess the perform-
ance and variability of the various NCA algorithms, subnetwork
analysis is performed, which has also been used previously in
(Chang et al., 2008), Wang et al., 2005) and (Jacklin et al.,
2012). The core idea behind this analysis is to divide the set of
transcription factors into a number of smaller subsets, which are
not mutually disjoint, where the intersection of these subsets
contains the TFs of interest. The subnetworks were constructed
to satisfy the gNCA criteria (Tran et al., 2005), which requires
that the number of TFAs M should be less than the number of
sample points K. These sub-networks are used to estimate the
transcription factor activities independent of each other. These
TFA estimates are then compared and a smaller disagreement
between these estimates is a measure of consistency of the
algorithm. This indicates that the results obtained are reliable
despite of the presence or absence of certain genes or TFs
from the experiment. The disagreement can be quantiﬁed

as: disagreement(i) =  [max sm-(k) — min sn,,-(k)] where s

indicates the rows of matrix S, i is the TF index and n is the
subnetwork index. The Yeast cell cycle dataset consists of results
from three different synchronization experiments. The first
experiment is the synchronization by elutriation, which is com-
posed of one cell cycle from 0 to 390 min. The data consist of 14
points sampled at 30-min intervals. The second experiment per-
forms the synchronization by a— factor arrest and contains two
cell cycles from 0 to 119min. A total of 18 samples are taken
every 7min. The synchronization in the third set is the result of
cdcl5 temperature sensitive mutant with samples taken every
20 min from 0 to 300 min. The data from the three experiments
are concatenated to form one large dataset. The Yeast cell cycle
study has 11 TFs of interest (Chang et al., 2008), which are Ace2,
Fkhl, Fkh2, Mbpl, Mcml, Nddl, Skn7, Stbl, Swi4, Swi5 and
Swi6. This section compares the performance of the NCA algo-
rithms for these TFs and the related genes.

The subnetwork analysis is carried out by dividing the original
network into four subnetworks each consisting of 40 TFs and the
number of genes varies from 921 to 1247. The aforementioned 11
TFs are included in each of the subsets. The structure of A is

 

2415

112 /310's112u1n0[p101x0"soiwuiJOJHioiq/ﬁduq 111011 pap201umoq

9103 ‘0g isanV uo ::

A.Noor et al.

 

veriﬁed to satisfy the NCA criterion (2) for all of the subnet-
works. The reconstruction of the 11 TFAs, which is the average
of the four subnetworks, using ROBNCA, FastNCA and NI-
NCA is depicted in Figure 3. The TFA estimation using ALS
algorithm is skipped here because the algorithm takes very long
to run for this large dataset. The results for the three experiments
are shown separately in the three columns. The TFAs for these
experiments are expected to have a periodic behavior with one,
two and three cycles in elutriation, a— factor and ode-15, respect-
ively, which can easily be corroborated from the ﬁgure. The
results from ROBNCA differ from FastNCA in some of the
instances. On the other hand, NI-NCA provides very similar
estimates to that of ROBNCA. It can be inferred that the results
of these two algorithms are more reliable as compared with
FastNCA because the former reveal the periodic behavior in
almost all of the TFs.

We now look to investigate the consistency of the algorithms.
The disagreement between the TFA estimates of the four subnet-
works is calculated and the results are shown in Figure 4a. Out of
the three algorithms considered, ROBNCA incurs the smallest
disagreement. The performance of NI-NCA is somewhat com-
parable; however, FastNCA shows a high degree of
inconsistency.

The simulations for standard deviation for TFAs are presented
in the Supplementary Material for ROBNCA, NI-NCA and
FastNCA. It is noted from Supplementary Figures S57S7 in
the Supplementary section that ROBNCA yields the lowest vari-
ation whereas FastNCA shows much higher variation in the
TFA estimates than both the other algorithms. It can therefore
be concluded that ROBNCA outperforms NI-NCA both in
terms of estimating the TFAs as well as in terms of consistency
for Yeast cell cycle data.

3.2.2 E.coli data The performance of NCA algorithms is now
tested for E.coli data. This dataset contains the gene expression
proﬁles obtained during transition of the sole carbon source
from glucose to acetate (Kao et al., 2004). Out of 296 genes
found to be of relevance during the carbon source transition,
100 genes were separated so that the resulting network satisﬁes
the NCA criteria. A total of 16 TFs were identiﬁed to be related
to this experiment, which are ArcA, CRP, CysB, FadR, FruR,
GatR, IcIR, LeuO, Lrp, Narl, PhoB, PurR, RpoE, RpoS, TrpR
and TyrR. We perform subnetwork analysis to this data to esti-
mate the transcription factor activities for the 16 TFs of interest.
The downloaded network is divided into four subnetworks con-
taining 81, 82, 85 and 88 genes, respectively. The number of TFs

m2 ka Fkhz mm
0.05 0.2 0.5

~05 -u.os -o 2 . -u.

in each subnetwork is fixed to 20, where the aforementioned 16
TFs are included in all of them. The samples are taken at 5, 15,
30 and 60 min and then every hour until 6h. Multiple samples
are taken at these instances, which make a total of 25 time points.
The advantage of using this data is that the ALS algorithm can
be added to the performance evaluation because of its smaller
subnetworks. ALS is known to have prohibitive computational
complexity (Jacklin et al., 2012) and is included here only for the
comparison of estimation accuracy. The reconstruction of TFAs
is performed using the four algorithms, and the average of the
TFA estimates from four subnetworks is depicted in Figure 5.
The results from ROBNCA, NI-NCA and ALS are in agreement
for almost all of the TFAs. In addition, these estimates are also
similar to those found in (Kao et al., 2004) except for a few
TFAs. The reason for this small dissimilarity could be that, in
this article, the estimates are obtained using the subnetworks
whereas (Kao et al., 2004) use the complete network of 100
genes. For 5 out of the 16 TFs, namely GatR, Lrp, NarL,
TrpR and TyrR, FastNCA is not able to recover the TFAs.
Moreover, the TFAs predicted by ROBNCA are similar to
those predicted by ALS, which is the original solution as
shown in Figure 5. It can therefore be inferred that ROBNCA
estimates the TFAs more accurately than FastNCA.

The consistency of the algorithms is assessed for this experi-
ment as well and the respective disagreement for each of the four
algorithms is shown in Figure 4b. FastNCA is again seen to
incur the maximum disagreement. NI-NCA and ALS perform
better than FastNCA; however, ROBNCA gives the least dis-
agreement for the four estimates of TFAs and performs the most
consistently out of all the algorithms.

3.2.3 Computational complexity comparison An important fea-
ture of all gene network reconstruction algorithms is the compu-
tational complexity incurred in their implementation. The
computational complexity of estimating A in (29) at a particular
iteration is approximately 0(22‘;l (M — L,,)3 + (M — L,,)Z),

a.

O

. ’1 V

o o .

,,.=: “9“. A [Q r

11.1 .1 .t .

n . .. . I . o In“; n It. I‘
1 . 5 i 12 1,

n 2 4 5 a m 12 u m 14

0

mme unost ‘Nmu "mum 0mm mum ms

Fig. 4. Average disagreement for different algorithms across the subsets
for TFAs. X-axis indicates the TFA index. Consistency comparison for
(a) S .cerevisiae data and (b) E.coli data

Ndd1 Sim? 5m SwiA

 

'0 2m Am a 2m) Am a

05 or 02 05 05

alarm
c
o
o
o
o
o
0

~05 -u.1 — -u

 

.2 . .
0 501m) in so 100 u

0.5 0.1 0.5 0.5 0.5

 

 

 

%

705

am M, W low

1 0.2 0.2 n 5

 

701— 705
U 100 200 300 D 100 200 300 D 100 200 300

71
0100 zoo :00 um zoo son u too we son

70 a) 05

2 2 7
a 100 zoo zoo u we 21m 300 0 run 200 sun

Fig. 3. TFAs reconstruction: Estimation of 11 TFAs (9 shown) of cell cycle-regulated yeast TFs. Average values of the TFs are shown for the four
subnetworks. The results of ROBNCA (black), FastNCA (red) and NI-NCA (blue) are given

 

2416

112 /310's112u.m0[p.101x0"soiwuiJOJHioiq/ﬁduq 111011 pap201umoq

9103 ‘0g isanV uo ::

ROBNCA

 

 

 

 

 

ArcA CRP CysB FadR
1 0.5 0.5 0.2
o w o g 0 K: 0 W
-1 -0.5 -0.5 -0.2
FruR GatR lclR LeuO
0.5 2 1 1
o R o g” o r E o t:
-0.5 -2 -1 -1
Lrp NarL PhoB PurR
1 0 5 .5 1
0 L7 0 & o o
-1 -0.5 -0.5 -1
RpoE RpoS TrpR TyrR
0.2 0.5 0 5 0.5
0% ° °W 0&3:
—0.2 -0 5 0 5

 

 

 

. — . -0.5
0 200 400 0 200 400 0 200 400 0 200 400

Fig. 5. TFAs reconstruction: Estimation of 16 TFAs of E.coli. Average
values of TFs are shown. The results of ROBNCA (black), FastNCA
(red), NI-NCA (blue) and ALS (green) are given

Table 1. Average computational time for various methods in seconds

 

Subset S.cerevisiae E.coli

 

_
N
m
4;
_
N
m
4;

 

FastNCA 0.2 0.2 0.24 0.2 0.014 0.007 0.007 0.008
ROBNCA 2 0.2 0.2 0.25 0.2 0.016 0.010 0.008 0.008
ROBNCA 1 1.0 0.8 0.99 0.8 0.020 0.018 0.016 0.023
NI-NCA LP 67 36 56.2 33 0.93 0.76 0.73 0.83
NI-NCA QP 71 30 125 97 0.59 0.13 0.13 0.13
ALS Exceeds memory limit 5.3 6.0 7.1 3.5

 

where (M — L,,) is the number of non-zero unknowns in the nth
column, which is usually small. We now compare the computa-
tional complexity of the four algorithms using the subnetwork
data from Yeast and E.coli. Average runtime calculated in
seconds is summarized for four subnetworks of each data in
Table 1. These experiments were performed on a Windows 7
system with a 1.90GHz Intel Core i7 processor on a Matlab
7.10.0. It is noted that the run time of ROBNCA is comparable
with that of FastNCA and is hundreds of times faster than NI-
NCA algorithms for both of its implementations, i.e. involving
linear programming and quadratic programming. Moreover, the
run time for ROBNCA is far superior to that of the ALS, a
direct consequence of the closed form solution derived for esti-
mating the connectivity matrix. It can also be observed that the
faster closed form solution for estimating A (29) provides add-
itional savings over its predecessor (11).

Therefore, it can be inferred from these experiments on syn-
thetic and real datasets that ROBNCA renders superior perform-
ance than the contemporary algorithms not only on the
yardsticks of accuracy and reliability, but also in terms of com-
putational complexity. The high computational complexity of
NI-NCA far outweighs the beneﬁts it offers in terms of consist-
ency. FastNCA has the smallest run time out of all the algo-
rithms but has poor reliability and is the least robust to the
presence of outliers in the data.

4 CONCLU$ON

In this work, we present ROBNCA, an algorithm for robust
network component analysis for estimating the TFAs. The
ROBNCA algorithm accounts for the presence of outliers by
modelling them as an additional sparse matrix. A closed form
solution available at each step of the iterative ROBNCA algo-
rithm ensures faster and reliable performance. The performance
of the proposed ROBNCA algorithm is compared with NI-NCA
and FastNCA for synthetic as well real datasets by varying SNR,
degrees of correlation and outlier concentration. It is observed
that while FastNCA is computationally simpler, yet the TFA
recovery is inaccurate and unreliable, a direct consequence of
the sensitivity of its decomposition approach to the presence of
outliers. The NI-NCA algorithm offers performance somewhat
comparable with the ROBNCA algorithm; however, the
ROBNCA algorithm is much more computationally efficient
and does not require solving costly optimization problems.
Therefore, the cumulative beneﬁts of robustness to the presence
of outliers, higher consistency and accuracy compared with the
existing state-of—the-art algorithms, and much lower computa-
tional complexity make ROBNCA well-suited to the analysis
of gene regulatory networks, which invariably requires working
with large datasets.

Funding: US National Science Foundation (NSF) grant
[0915444] and QNRF-NPRP grant [09-874-3-235].

Conﬂict of Interest: none declared.

REFERENCES

Boyd,S. and Vandenberghe,L. (2004) Convex Optimization. Cambridge University
Press, New York.

Chang,C. et al. (2008) Fast network component analysis (FastNCA) for gene regu—
latory network reconstruction from microarray data. Bioinformatics, 24,
134971358.

Comon,P. (1992) Independent component analysis. Higher—Order Statistics, 2%38.

Finegold,M. and Drton,M. (2011) Robust graphical modeling of gene networks
using classical and alternative t—distributions. Ann. Appl.Stat., 5, 105771080.

Galbraith,S.J. et a]. (2006) Transcriptome network component analysis with limited
microarray data. Bioinformatics, 22, 188(r1894.

Giannakis,G. et al. (2011) USPACOR: Universal sparsity—controlling outlier rejec—
tion. In: Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE
International Conference. pp. 195271955.

Jacklin,N. et al. (2012) Noniterative convex optimization methods for network
component analysis. IEEE/ACM Trans. Comput. Biol. Bioinform., 9,
147271481.

Jajamovich,G.H. et a]. (2011) Bayesian multiple—instance motif discovery with
bambi: inference of recombinase and transcription factor binding sites.
Nucleic Acids Res., 39, e146.

Jolliffe,I. (1986) Principal Component Analysis. Springer—Verlag, New York, p. 487.

Kao,K.C. et al. (2004) Transcriptome—based determination of multiple transcription
regulator activities in escherichia coli by using network component analysis.
Proc. Natl. Acad. Sci. USA, 101, 641$46.

Kekatos,V. and Giannakis,G.B. (2011) From sparse signals to sparse residuals for
robust sensing. IEEE Trans. Signal. Process, 59, 335573368.

Lahdesmaki,H. et a]. (2008) Probabilistic inference of transcription factor binding
from multiple data sources. PLoS One, 3, e1820.

Lee,T.I. et a]. (2002) Transcriptional regulatory networks in saccharomyces cerevi—
siae. Sci. Signal, 298, 799.

Liao,J. et a]. (2003) Network component analysis: reconstruction of regulatory sig—
nals in biological systems. Proc. Natl. Acad Sci. USA, 100, 15522715527.

Mateos,G. and Giannakis,G.B. (2012) Robust PCA as bilinear decomposition with
outlier—sparsity regularization. IEEE Trans. Signal Process., 60, 517(r5190.

 

2417

112 /310's112u1n0[p101x0"soiwuiJOJHioiq/ﬁduq 111011 papeo1umoq

9103 ‘0g1sn8nv uo ::

A.Noor et al.

 

Spellman,P.T. et a]. (1998) Comprehensive identiﬁcation of cell cycleLregulated
genes of the yeast Saccharomyces cerevisiae by microarray hybridization. Mol.
Biol. Cell, 9, 327373297.

Tran,L. et a]. (2005) gNCA: a framework for determining transcription factor ac—
tivity based on transcriptome: identiﬁability and numerical implementation.
Metab. Eng., 7, 1287141.

Tropp,J.A. (2006) Just relax: convex programming methods for identifying sparse
signals in noise. IEEE Trans. Inf. Theory, 52, 103071051.

Tseng,P. (2001) Convergence of a block coordinate descent method for nondiffer—
entiable minimization. J. Optim. Theory Appl., 109, 4754194.

Yang,Y.—L. et al. (2005) Inferring yeast cell cycle regulators and interactions using
transcription factor activities. BMC Genomics, 6, 90.

Yuan,M. and Lin,Y. (2005) Model selection and estimation in regression with
grouped variables. J. R. Stat. Soc. Series B Stat. Methodol, 68, 49$7.

 

2418

112 /310's112u1n0[p101x0"soiwuiJOJHioiq/ﬁduq 111011 papeo1umoq

9103 ‘0g1sn8nv uo ::

