BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

Més-o-menos

 

and ‘so—so’, describing its theoretically non—optimal but still prac—
tically useful discrimination ability.

2 METHODS

2.1 Mas-o-menos

Let each component X ,7 of the p X 1 covariate vector X,» = (X [1, . . . , X ip)T
be a quantitative measurement of the 1'” gene from the i’h subject. The Xi)
could represent various types of genomic information, such as expression
levels from microarrays or next-generation sequencing experiments, or
non-genomic data. Mas-o-menos uses a patient’s X,» to calculate a
signed sum of that patient’s covariate values. The procedure is as follows:

(1) Standardize the covariates such that
(n— 1)*IZ(Xij—)7j)2=1,j=1,...,p, where )7,- = r142:qu

(2) Perform univariate regressions of the outcome on each igene to
obtain marginal estimates of the regression coefﬁcient 69-.

(3) Let ﬁj = sgn(&j)/p1/2, where sgn(c) = 2I(c>0) — 1 for c 75 0 and
sgn(c)=0 for c = 0.

(4) The risk score for the I'm patient is calculated as X179, where
v* = (ﬁ1,...,ﬁ,,)T.

The factor of 171/2 in the deﬁnition of the ff merely serves to ensure the
arbitrary scaling ||v||2 = 1. By changing the regression model used in step
(3), mas-o-menos can be used with clinical outcomes of any type, such as
continuous, binary or censored data. The discrimination performance of
XiTv can be quantiﬁed using correlation for continuous outcomes, the
area under the receiver operating characteristic curve for binary outcomes
(Bamber, 1975) or the C-statistic for censored outcomes (Uno et al.,
2011).

Mas-o-menos, and procedures similar to it, is already in use for ana-
lyzing genomic data. For example, Donoho and Jin (2008) introduced a
family of classiﬁers, one of which, called HCT-clip, is equivalent to mas-
o-menos. They found that HCT-clip performed surprisingly well in
cross-validation experiments using standard datasets with uncensored
outcomes. Some also use marginal regression to identify good and bad
prognosis covariates, which are then used to rank patients by risk.
Ranking methods include the t-statistic for difference in expression of
good versus bad prognosis genes (Bell et al., 2011; Verhaak et al.,
2013) and signed averaging of discretized or continuous expression
values (Colman et al., 2010; Dave at al., 2004; Hallett et al., 2010;
Kang et al., 2012; Réme et al., 2013). Replacing lasso coefﬁcients by
their signs has been proposed for summarizing gene pathway activity
(Eng 8! al., 2013).

It may sometimes be helpful to perform an initial feature selection
step before implementing mas-o-menos, as we argue in Section 2.3.
Feature selection has been the subject of a great deal of research, and a
detailed discussion is beyond the scope of this article. In our data analysis
in Section 3.3, we found that selection had little effect on the discrimin-
ation ability of mas-o-menos. However, selection can provide more
interpretable models by dramatically reducing the number of genes
required for prediction.

2.2 Discrimination for survival outcomes

We focus on survival outcomes because they are typically the most
difﬁcult to deal with and the most clinically relevant and are the outcomes
collected in our real data. Let T,- be the survival time of the i’h
subject. To measure discrimination in the survival setting, we use
the C-statistic over the follow-up period (01'), deﬁned by Uno et a].
(2011) as

CAB) = P{g(Xi) > g(Xj)| Ti < ij Ti < I}, (1)

where g(X) is the risk score for a subject with covariate vector X. We
consider linear risk scores of the form g(X) = XTB forB = ([31, . . . , ﬁp)T.
We deﬁne the optimal weight vector to be

30 = argmaxP(Xl.TB > XijTi < Tj, Ti < r),
llillllollg *1
where we have arbitrarily scaled BO to have norm 1 because C,(B) is
invariant to scaling of B.

To implement mas-o-menos in this setting, we will obtain the 6;]- by
ﬁtting univariate Cox models. We choose the Cox model because it is a
well-established and well-understood procedure in clinical research.
In addition, the estimators 6;]- converge to well-deﬁned 0101- even when
the Cox model is not correctly speciﬁed (Lin and Wei, 1989; Struthers
and Kalbﬂeisch, 1986), as is likely to be the case in our marginal regres-
sions. Finally, if the data truly come from a Cox model, the true
parameter vector should maximize CI and should be a scalar multiple
of the optimal BO.

2.3 Statistical properties

We show that under certain conditions, the mas-o-menos weights
can have good discrimination power along with low variability. Hand
(2006) provided similar arguments to justify equalization of regression
coefficients when all covariates have the same directions of effect
on the outcome, and this direction is known a priori. Hand describes
this in terms of the ‘ﬂat maximum effect’: that in the context of classiﬁers,
often little advantage can be gained in prediction accuracy over simple
models. Here, we do not assume that the directions of effect are known.

Let v* =(v’f, . . . , v*)T be the probability limit of 9, such that v —> v*.
Because ﬁj = sgn(&j), if 6;]- —> 0101- in probability, then by the continuous
mapping theorem vj’.‘ = sgn(oz0j). We will analyze the performance of the
mas-o-menos estimator v in terms of the discrimination ability of v*
relative to that of BO, and the variability of v around v*. For now, we
assume vj’.‘ 7A 0 for all genes j. At the end of the section we discuss the
implications if this is not true.

By the deﬁnition of CT, the discrimination performance
of v*=(v’f, . . . , v*)T depends only on the degree of linear association
between X1730 and XiTv". In addition,

cov(XiTBO, X17 v*) = Z sojcowxij, X). v;)
M

= Z ﬁojvj’fz cov(X,»J-vj’.‘, Xikvzf) 2 E: ﬁojvj‘.
j k j

where ﬁ=minj1flzk cov(X,»-vj’.‘,X,»kv,’:). The second equality follows
-vj’.‘ always equals 1. Thus, XiTv" will be highly correlated

with X1730, and will have similar discriminative ability, under the condi-

because vj’.‘

tion that Z [30ij and 5 have the same sign.
1'
It is not unreasonable to expect these terms to be positive. First,

each [301- quantiﬁes the association between X ,7 and T,- conditional on all
genes in X,», while each v’.‘ reﬂects its univariate association. If a gene has
the same direction of effect in both the conditional and marginal
models, then ﬁojvi>0 This is plausible for at least some genes, and
even if it does not hold for all genes 2]. ﬁojvj’.‘ can still be positive.
Second, the E term is the minimum average covariance between X l»ij
and Xikvzf. This will be positive if genes with the same marginal
directions of effect tend to be positively correlated, while genes with dif-
ferent marginal directions of effect tend to be negatively correlated.
Indeed, the encoded proteins of conserved co-expressed gene pairs are
likely to be part of the same biological pathway (van Noort et al., 2003).
Again, 5 can be positive even if this covariance condition holds only for
some pairs of genes, as we merely need the average covariance to be
positive.

 

3063

ﬁm'spzumofpmjxo'sopeuuopnorq/ﬁdnq

l++<es<1>g+i+®+I

+++®+Hl+®+

A

ale

Eiil®¢ H-

h

>
o

.y,



+694“

+694“

O'SOIJEIIIJOJIIIOIq/ﬂduq

/810'SIEumo_fp10jx

Més-o-menos

 

Van Houwelingen, 1994) and marginal regression (Emura et al.,
2012), which gives risk scores of the form 2; X [/67 i. For all meth—
ods we first standardized all covariates to have unit variance. We
also included two negative controls: (i) the single gene with the
largest (it) estimated from the training set and (ii) randomly gen—
erated risk scores 2; X [/Z/, where the Z,- were drawn independ—

ently from a standard normal.

We implemented lasso and ridge regression for the Cox model
using the package glmnet (Friedman et al., 2010), selecting the
penalty parameter using 3—fold cross—validation using the built—in
function. Marginal Cox regressions and mas—o—menos are imple—
mented in the package survHD (Bernau et al., 2012).

3.2 Simulations

To simulate training data, we generated p x 1 covariate vectors
X,~ and survival times from a Cox model with a p x 1 true par—
ameter vector BO. We let the true Cox regression coefﬁcient
vector BO have s non—zero components all with magnitude
5"”, such that llﬂollz = 1. The first 5/2 non—zero components
were positive and the rest were negative. We generated censoring
times from an independent exponential distribution to give
~50% censoring. In each testing dataset, we replaced the positive
entries of BO by random uniform draws from (0, 4/51/2), and the
negative entries by random draws from (—4/sl/2, 0). Each train—
ing and testing dataset contained 11 = 200 observations.

We considered the low—dimensional case of P = 100 and the
high—dimensional one of P = 10000. To generate sparse BO, we
let s = 10, and for non—sparse BO we let s = P. We drew X,~ from
a multivariate normal with mean zero and unit marginal
variance. From Section 2.3, the discrimination ability of mas—
o—menos depends on the covariance structure of the X,~. In an
‘easy’ setting, the covariates were divided into two blocks, with
X i,- positively correlated within blocks and negatively correlated
between blocks. Those  with ﬂoj>0 were assigned to one
block, those with ﬂoj<0 were assigned to the other and those
with 60/ = 0 were assigned equally between the blocks. In a ‘hard’
setting, we let cov(X[/, Xik) > 0 for j and k both even or both
odd, and cov(X[,«, Xik) < 0 otherwise. We let |cov(X,:,«, Xik)| =0,
0.3 or 0.5 for all j and k and ran 200 simulations.

The computations in this article were run on the Odyssey
cluster supported by the Faculty of Arts and Sciences (FAS)
Science Division Research Computing Group at Harvard
University. Table 1 illustrates the speed advantage enjoyed by
mas—o—menos.

In general, mas—o—menos kept pace with lasso, ridge and mar—
ginal regression. Each of these performed better than the single
best gene and the randomly generated negative control. Figure 1
reports the average out—of—sample C—statistics obtained by the
different methods. The C—statistics were calculated at r=2,
where ‘L' is defined in (1). Conﬁdence intervals represent the em—
pirical 2.5 and 97.5% quantiles. The results clearly illustrate the
importance of the covariance structure. All of the methods
except for the negative control performed better under the easy
covariance setting than under the hard one. The easy covariance
satisﬁes the assumptions of the theoretical discussion in Section
2.3: cov(Xl~/v;‘,T,~) > 0 and cov(X[/v;f,X,~kvj:) > 0 for all j, k.
The difﬁculty of the hard covariance structure arises from
the fact that it is impossible to meet this condition. For example,

by construction, cov(X,~1, T ,~) > 0 and cov(X,~2, T ,~) > 0, but
cov(X,~1,X,~2)<0. In other words, the signs of the 60/ and the
covariances are incoherent in the hard covariance case.

When the covariates were independent, higher dimensionality
made discrimination harder regardless of sparsity, perhaps
because there was no way to borrow information across the
covariates. Under the easy covariance structure with a dense
BO, however, high dimensionality was actually beneﬁcial, per—
haps because if the effects of some covariates were by chance
incorrectly estimated, there were many other correlated ones that
could be used as surrogates. On the other hand, with a hard
covariance matrix, dimensionality added difﬁculty even in the
non—sparse case because of the incoherence between the ﬁg; and
the covariate correlations.

With no correlation, sparsity allowed for easier discrimination.
When correlation was introduced in the easy covariance setting,
sparsity was detrimental to prediction. This might have been
owing to the screening step because univariate screening is
liable to retain unimportant covariates simply because they are
correlated with important ones. These incorrectly retained
covariates can degrade performance. In the hard covariance set—
ting, however, sparsity was helpful regardless of the level of
correlation. This may be because in the sparse case, there were

Table 2. Cancer gene expression datasets

 

 

Reference Sample size Events
Bladder, 2463 common probesets
Als et a]. (2007) 30 25
Blaveri et a]. (2005) 80 44
Kim et a]. (2010) 165 69
Lindgren et a]. (2010) 87 26
Riester et a]. (2012) 93 65
Sjodahl et a]. (2012) 224 25
Breast, 9768 common probesets
Desmedt et a]. (2007) 134 35
Foekens et a]. (2006) 710 191
Minn et a]. (2005) 245 76
Minn et a]. (2007); Wang et a]. (2005) 209 80
Schmidt et a]. (2008) 162 33
Sotiriou et a]. (2006) 85 19
Symmans et a]. (2010) 164 38
Ovarian, 6138 common probesets
Bentink et a]. (2012) 128 73
Crijns et a]. (2009) 98 72
Bonome et a]. (2008) 185 129
Denkert et a]. (2009) 41 13
Dressman et a]. (2007) 59 36
Ferriss et a]. (2012) 30 22
Konstantinopoulos et a]. (2010) 28 17
Konstantinopoulos et a]. (2010) 42 23
Mok et a]. (2009) 53 41
Bell et a]. (2011) 452 239
Tothill et a]. (2008) 140 72
Yoshihara et a]. (2010) 43 22
Yoshihara et a]. (2012) 129 60
Yoshihara et a]. (2012) 17 10

 

 

3065

ﬁm'spzumofpmjxo'sopeuuopnorq/ﬁdnq

S.D.Zhao et al.

 

 

Bladder, no screening

Lasso 
L—I—l

. '

. .—.—.'—'—’

Q - 0.63 [ 0.56 , 0.61 ]
Ridge 

|——I—|
: I—I
f - 0.69 [ 0.65 , 0.12]
Marginal 

I—l

Mas—o—menos . I—I—I.
I—I
_ - 0.11[0.61,0.74]
Single Gene 13—I—1
D—I—‘—t
I—-——I
P—I—I
.3- 0.54[0.49,0.58]

Random 

 0.45 [ 0.40 , 0.50 ]

 

I I Q I I I
0.25 0.39 0.54 0.68 0.83

C—statistics

Breast, no screening

- 0.11 [0.61 , 0.14]

Bladder, HC screening

Lasso :I—u—I
f .—.:.H
' - 0.64[0.60,0.68]
Ridge 
I—v—I—I
._;_.—' I—I—>
i - 0.64[0.60,0.68]
Marginal f l—I—l
I—‘l—I
I:—.—I H
j - 0.69[0.65,0.73]
Mas—o—menos : I—I—l
I—I—I
_ - 0.11[0.61,0.74]
Single Gene I3—I—I
D—F—t
I—-——I
P—I—t
.3 0.54[0.49,0.58]
Random I—i—n—I
:l—I—i
O—I—I
D—IE—t
5 - 0.51[0.53,0.62]

 

| I ; I | |
0.25 0.40 0.54 0.69 0.83

C—statistics

Breast, HC screening

 

: .—._.
Lasso ; I—I—c

- 0.73 [ 0.69 , 0.76]

Ridge  w

‘38 [ 0.75 , 0.81]

Marginal E ’—‘—’I—.—.

E

- 0.14 [ 0.10 , 0.11]

Mas—o—menos i ._._.I—I—'

 

 

l—I—l

“55° 2 %

- 0.10 [ 0.61 , 0.14]

Ridge  E
i +
.015 [ 0.12 , 0.18]

Marginal E ’—'—’.—.—I

.'——.E!

-014 [ 0.11 ,0.18]

I—l—b

Mas—o—menos i r—I—I
: n—l—IZE!

-015 [ 0.72 , 0.78]

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

   

Single Gene ~—-.—« Single Gene 
.—.— ‘——'.—.—
‘—'_.—.‘—. ﬂ
 0.49 [ 0.45 , 0.53]  0.49 [ 0.45 , 0.53]
Random  Random ,_._. '—I— 
._’+-_7—‘ ’—',_.-_.—‘
‘3. 0.49 [ 0.45 , 0.53] .3 0.41[0.44,0.51]
I I E I I I I I E I I I
0.25 0.39 0.53 0.67 0.81 0.25 0.39 0.54 0.68 0.82
C—statistics C—statistics
Ovarian, no screening Ovarian, HC screening
Lasso 3 _._ Lasso
.— 0.51[0.54,0.59] 0.56 [ 0.55 , 0.60]
Ridge  Ridge
g —. 0.60 [ 0.56 , 0.63] 0.56 [ 0.56 , 0.60]
Marginal # Marginal

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Mas—o—menos . H;—
5‘ .' —‘ 0.59[0.56,0.61]
L
Single Gene ._._=
9
Random _.:—
9 — 0.51[0.48,0.53]

I
0.25 0.39 0.53 0.66 0.80

C—statistics

. 0.59 [ 0.57 , 0.61 ]

0.51 [0.49 , 0.54]

0.59 [ 0.51 , 0.61 ]

Mas—o—menos
0.59 [ 0.51 , 0.62]

Single Gene
0.51 [0.49 , 0.54]

Random

 

3 0.55 [ 0.52 , 0.51]
l—l—'l—|—I
0.25 0.39 0.53 0.66 0.80

C—statistics

Fig. 2. Validation C-statistics at r: 5 years using different discrimination methods

 

3066

ﬁm'spzumol‘pmjxo'sopeuuowrorq/ﬁdnq

Mas-o-menos

 

 

 

 

 

 

 

 

 

 

 

 

 

Bladder Breast Ovarian
o _,_ _'_
o 0 — T -I-
g — T I? _ _'_ E to : : -.—
I d _3_ O _ + "' I I —r— I
2 '5 - I .9 - -I— .9 I ' ' '
E I   _ I -1- T  In — E
g to _ S o 3 I l S O -‘- I
a: O —'— "- é: _ 3 E I a: V o : 3 3 3
m_. EBB 8.. 4 . e- ++4+
o + .1. . : ° _ + I 333 o
I
g — _._ .L 9. _ _._ o‘ — o o
I 6| \I I 6| 6: o‘ I I I I I I I \l I I I
o . ’0 o9 c o o e o o o 3 Q, 9 o
\x’bee 4.3g 1&9 6&0 69% (‘60 09% qbg . 00° 960 06° V099 Qi-‘bq ‘99 00° 960 0606‘
s ,o’ 9.9 60 V 6’0 806% 43’ 6’" 58.06“ 43’
I . (5‘ .e’ ‘9‘
8% 9’0 9’0

Fig. 3. Average 3-fold cross-validation C-statistics at r=5 years, calculated within each dataset of each disease type; no feature screening was

implemented

fewer important covariates with which the hard covariance struc—
ture could cause difficultly.

3.3 Application to bladder, breast and ovarian cancer

We applied mas—o—menos, lasso, ridge, marginal regression and
the two negative control methods to an extensive compendium of
real cancer gene expression data (Table 2). We obtained six blad—
der cancer datasets totaling 679 patients from Riester et a].
(2012), seven breast cancer datasets totaling 1709 patients from
Haibe—Kains et a]. (2012) and 14 ovarian cancer datasets totaling
1445 patients from Ganzfried et a]. (2013). We processed
the breast cancer data as in Bernau et a]. (2014). The bladder
and ovarian cancer data have been manually curated to have
standardized clinical annotations, probeset identiﬁers and micro—
array preprocessing, and are available in the Bioconductor pack—
ages curatedBladderData and curatedOvarianData,
respectively.

For each disease, we limited our analyses to the probesets
common to all studies. We trained each algorithm on the largest
available study and evaluated its performance on each of the
remaining datasets using the C—statistic calculated at 1= 5
years, where ‘L' is deﬁned in (1). Roughly 60% of all study
participants, combined across all diseases, were still alive after
5 years. The C—statistic is robust to the choice of 1' unless few
deaths or censoring events occur at times greater than T (Uno
et al., 2011).

We generated 100 bootstrap samples of each validation dataset
to obtain 95% conﬁdence intervals. In addition to applying the
methods without feature selection, we also implemented higher
criticism thresholding (Donoho and Jin, 2008), which screens out
covariates with high marginal Cox regression P—values but is
entirely data—driven and automatically chooses the number of
covariates to retain. Summary statistics were calculated by
ﬁxed effects meta—analysis with the metafor package
(Viechtbauer, 2010).

Figure 2 reports the results. Selecting only a single gene or
using random weights gave the lowest performance, confirming
the appropriateness of our negative controls. Mas—o—menos was
consistently on par with lasso, and even outperformed lasso in
several cases. Its performance was much more similar to those of

ridge and marginal regression. Screening did not dramatically
affect the performances of any of the methods.

A referee noted that it is unclear how well mas—o—menos
performs within a single dataset, as opposed to across datasets.
To answer this question, we evaluated the performance of each
risk prediction algorithm within each dataset of each disease type
by calculating the average 3—fold cross—validated C—statistic at
1= 5 years. No feature screening was implemented. Figure 3 re—
ports the results and shows that mas—o—menos was again on par
or better than the other methods. It appears that in addition to
being robust across studies, mas—o—menos is also simply a good
predictor.

4 DISCUSSION

We have studied mas—o—menos, a simple algorithm for classiﬁca—
tion and discrimination that has seen popular adoption but has
not been formally investigated. We gave a precise deﬁnition of
the algorithm, showed theoretically and in simulations that it can
perform well and demonstrated in an extensive analysis of real
cancer gene expression studies that it can achieve good discrim—
ination performance in realistic settings, even compared with
lasso and ridge regression. Our results provide some justiﬁcation
to support its widespread use in practice. We hope our work will
help shift the emphasis of ongoing prediction modeling efforts in
genomics from the development of complex models to the more
important issues of study design, model interpretation and inde—
pendent validation.

One reason why mas—o—menos is comparable with more
sophisticated methods such as penalized regression may be that
we often use a prediction model trained on one set of patients to
discriminate between subgroups in an independent sample,
usually collected from a slightly different population and pro—
cessed in a different laboratory. This cross—study variation is not
captured by standard theoretical analyses, so theoretically
optimal methods may not perform well in real applications
(Hand, 2006). Bernau et a]. (2014) proposed a method for
giving a realistic measure of the practical utility of algorithms
in the presence of cross—study variation. At the same time, we
found using cross—validation experiments that even within the

 

3067

ﬁm'spzumol‘pmjxo'sopeuuopnorq/ﬁdnq

S.D.Zhao et al.

 

same dataset, mas—o—menos remained competitive with more
sophisticated methods.

Batch effects create study—speciﬁc measurement bias, and are
widespread and often unidentified in genomic data (Leek et al.,
2010). They may be responsible for the cross—study variation that
degrades the performance of algorithms such as lasso or ridge
regression. Although certain batch—correction techniques have
gained widespread use (Leek and Storey, 2007; Li and
Rabinovic, 2007), these have been motivated primarily by class
comparison rather than class prediction. In a genomic prediction
competition, batch correction was seen to provide no overall
beneﬁt for validation accuracy (MAQC Consortium, 2010).
Rather, we propose that the impact of unknown batch effects
may be best mitigated by using methods less prone to over—
ﬁtting. Mas—o—menos risk scores have lower variability, and
may be less associated with batch, than those of the other
methods, which might explain its robust performance in both
cross—validation and cross—study validation in 27 datasets from
three cancer types.

While we focused on microarray data and survival endpoints,
mas—o—menos can be applied to any type of outcome variable,
using any regression model, and has precedents for application in
diverse settings outside of genomics (Davis—Stober et al., 2010;
Wainer, 1976; Laughlin, 1978; Lovie and Lovie, 1986). It is fast
to implement, simple to interpret, comparable in performance
with more complex methods and appears robust to cross—study
variation. Mas—o—menos should be useful for developing predic—
tion models from high—dimensional data in any situation where
the covariates are sufﬁciently correlated and the true effect is
roughly linear.

ACKNOWLEDGEMENT

The authors thank the anonymous referees for comments, which
substantially improved this article.

Funding: This work was funded by the National Cancer Institute
at the National Institutes of Health (1RC4CA156551—01 and
5P30 CA006516—46 to GP.) and by the National Science
Foundation (CAREER DBI-1053486 to C.H.).

Conﬂict of Interest: none declared.

REFERENCES

Als,A.B. et a]. (2007) Emmprin and survivin predict response and survival following
cisplatin—containing chemotherapy in patients with advanced bladder cancer.
Clin. Cancer Res., 13, 440774414.

Bamber,D. (1975) The area above the ordinal dominance graph and the area below
the receiver operating characteristic graph. J. Math. Psychol., 12, 3874115.
Bell,D. et a]. (2011) Integrated genomic analyses of ovarian carcinoma. Nature, 474,

609%15.

Bentink,S. et a]. (2012) Angiogenic mRNA and microRNA gene expression
signature predicts a novel subtype of serous ovarian cancer. PloS One, 7, e30269.

Bernau,C. et al. (2012) survHD: Synthesis of M icroarrav—based Survival Analysis. R
package version 0.5.0. https://bitbucket.org/lwaldron/survhd.

Bernau,C. et a]. (2014) Cross—study validation for assessment of prediction models
and algorithms. Bioinformatics, 30, i1057i112.

Blaveri,E. et a]. (2005) Bladder cancer outcome and subtype classiﬁcation by gene
expression. Clin. Cancer Res., 11, 4044—4055.

Bonome,T. et a]. (2008) A gene signature predicting for survival in suboptimally
debulked patients with ovarian cancer. Cancer Res., 68, 547875486.

Biihlmann,P. and Van De Geer,S. (2011) Statistics for High—dimensional Data:
Methods, Theory and Applications. Springer, Heidelberg.

Colman,H. et a]. (2010) A multigene predictor of outcome in glioblastoma.
Neuro—oncology, 12, 49757.

Crijns,A. et a]. (2009) Survival—related proﬁle, pathways, and transcription factors in
ovarian cancer. PLoS Meat, 6, e1000024.

Dave,S.S. et a]. (2004) Prediction of survival in follicular lymphoma based on mo—
lecular features of tumor—inﬁltrating immune cells. N. Engl. J. Med., 351,
215972169.

Davis—Stober,C. et a]. (2010) A constrained linear estimator for multiple regression.
Psyc/wmetrika, 75, 5217541.

Denkert,C. et a]. (2009) A prognostic gene expression index in ovarian cancer—
validation across different independent data sets. J. Pathol., 218, 2737280.
Desmedt,C. et a]. (2007) Strong time dependence of the 76—gene prognostic
signature for node—negative breast cancer patients in the transbig multicenter

independent validation series. Clin. Cancer Res., 13, 320773214.

Donoho,D. and Jin,J. (2008) Higher criticism thresholding: Optimal feature selec—
tion when useful features are rare and weak. Proc. Nat Acad. Sci. USA, 105,
1479314795.

Dressman,H. et a]. (2007) An integrated genomic—based approach to individualized
treatment of patients with advanced—smge ovarian cancer. J. Clin. Oncol., 25,
5177525.

Emura,T. et a]. (2012) Survival prediction based on compound covariate under cox
proportional hazard models. PLoS One, 7, e47627.

Eng,K.H. et a]. (2013) Pathway index models for construction of patient—speciﬁc
risk proﬁles. Stat. Med., 32, 152471535.

Ferriss,J.S. et a]. (2012) Multi—gene expression predictors of single drug responses to
adjuvant chemotherapy in ovarian carcinoma: predicting platinum resistance.
PloS One, 7, e30550.

Foekens,J.A. et a]. (2006) Multicenter validation of a gene expressionibased
prognostic signature in lymph nodeLnegative primary breast cancer. J. Clin.
Oncol., 24, l66yl67l.

Friedman,J.H. (1997) On bias, variance, 0/lloss, and the curse—of—dimensionality.
Data Min. Know]. Discov., 1, 55777.

Friedman,J.H. et a]. (2010) Regularization paths for generalized linear models via
coordinate descent. J. Stat. Softw., 33, 1722.

Ganzfried,B.F. et a]. (2013) curatedOvarianData: clinically annotated data for the
ovarian cancer transcriptome. Database, 2013, bat013.

Haibe—Kains,B. et a]. (2012) A three—gene model to robustly identify breast cancer
molecular subtypes. J. Nat Cancer Inst., 104, 3117325.

Hallett,R.M. et a]. (2010) An algorithm to discover gene signatures with predictive
potential. J. Exp. Clin. Cancer Res., 29, 120.

Hand,D.J. (2006) Classiﬁer technology and the illusion of progress. Stat. Sci., 21,
1714.

Hastie,T. et a]. (2005) The elements of statistical learning: data mining, inference
and prediction. Math. Intel]., 27, 8%85.

Hoerl,A. and Kennard,R. (1970) Ridge regression: biased estimation for nonortho—
gonal problems. Technometrics, 12, 55%7.

Kang,J. et a]. (2012) A dna repair pathway—focused score for prediction of outcomes
in ovarian cancer treated with platinum—based chemotherapy. J. Nat Cancer
Inst., 104, 673681.

Kim,W.J. et a]. (2010) Predictive value of progression—related gene classiﬁer in
primary non—muscle invasive bladder cancer. Mol. Cancer, 9, 3.

Konstantinopoulos,P. et a]. (2010) Gene expression proﬁle of BRCAness that cor—
relates with responsiveness to chemotherapy and with outcome in patients with
epithelial ovarian cancer. J. Clin. Oncol., 28, 355573561.

Laughlin,].E. (1978) Comment on Estimating coefﬁcients in linear models: it don’t
make no nevermind. Psyclwl. Bull., 85, 2477253.

Leek,J.T. and Storey,J.D. (2007) Capturing heterogeneity in gene expression studies
by surrogate variable analysis. PLoS Genet., 3, el6liel6l.

Leek,J.T. et a]. (2010) Tackling the widespread and critical impact of batch effects in
high—throughput data. Nat. Rev. Genet., 11, 7337739.

Li,C. and Rabinovic,A. (2007) Adjusting batch effects in microarray expression data
using empirical Bayes methods. Biostatistics, 8, 1187127.

Lin,D. and Wei,L. (1989) The robust inference for the Cox proportional hazards
model. J. Am. Stat. Assoc., 84, 10744078.

Lindgren,D. et a]. (2010) Combined gene expression and genomic proﬁling
deﬁne two intrinsic molecular subtypes of urothelial carcinoma and gene
signatures for molecular grading and outcome. Cancer Res., 70, 346373472.

Lovie,A. and Lovie,P. (1986) The flat maximum effect and linear scoring models for
prediction. J. Forecast., 5, 1597168.

 

3068

ﬁre'spzumol‘pmjxo'sopeuuowrorq/pdnq

Mas-o-menos

 

MAQC Consortium (2010) The microarray quality control (maqc)—ii study of
common practices for the development and validation of microarray—based pre—
dictive models. Nat. Biotechnol, 28, 8274565.

Minn,A.J. et al. (2005) Genes that mediate breast cancer metastasis to lung. Nature,
436, 5187524.

Minn,A.J. et al. (2007) Lung metastasis genes couple breast tumor size and meta—
static spread. Proc. Nat Acaal. Sci. USA, 104, 6740—6745.

Mok,S. et al. (2009) A gene signature predictive for outcome in advanced ovarian
cancer identiﬁes a survival factor: microﬁbril—associated glycoprotein 2. Cancer
Cell, 16, 5217532.

Reme,T. et al. (2013) Modeling risk stratiﬁcation in human cancer. Bioinformatics,
29, 114971157.

Riester,M. et al. (2012) Combination of a novel gene expression signature with
a clinical nomogram improves the prediction of survival in high—risk bladder
cancer. Clin. Cancer Res., 18, 132371333.

Schmidt,M. et al. (2008) The humoral immune system has a key prognostic impact
in node—negative breast cancer. Cancer Res., 68, 540575413.

Scholkopf,B. and Smola,A.J. (2002) Learning with Kernels: Support Vector
Machines, Regularization, Optimization, anal Beyonal. MIT press.

Shaughnessy,J. et al. (2007) A validated gene expression model of high—risk
multiple myeloma is deﬁned by deregulated expression of genes mapping to
chromosome 1. Blooal, 109, 227(r22S4.

Sjodahl,G. et al. (2012) A molecular taxonomy for urothelial carcinoma.
Clin. Cancer Res., 18, 337773386.

Sotiriou,C. et al. (2006) Gene expression proﬁling in breast cancer: understanding
the molecular basis of histologic grade to improve prognosis. J. Nat Cancer
Inst., 98, 2627272.

Struthers,C. and Kalbfleisch,J. (1986) Misspeciﬁed proportional hazard models.
Biometrika, 73, 3637369.

Symmans,W.F. et al. (2010) Genomic index of sensitivity to endocrine therapy for
breast cancer. J. Clin. Oncol., 28, 411141119.

Tibshirani,R.J. (1996) Regression shrinkage and selection via the lasso. J. R. Stat.
Soc. Ser. B, 58, 2677288.

Tibshirani,R.J. (1997) The lasso method for variable selection in the Cox model.
Stat. Meal., 16, 3857395.

Tothill,R. et al. (2008) Novel molecular subtypes of serous and endometrioid ovar—
ian cancer linked to clinical outcome. Clin. Cancer Res., 14, 519875208.

Uno,H. et al. (2011) On the c—statistics for evaluating overall adequacy of risk
prediction procedures with censored survival data. Stat. Meal., 30, 110571117.

van Noort,V. et al. (2003) Predicting gene function by conserved co—expression.
Trenals Genet., 19, 2387242.

Verhaak,R.G. et al. (2013) Prognostically relevant gene signatures of high—grade
serous ovarian carcinoma. J. Clin. Invest., 123, 517.

Verweij,P. and Van Houwelingen,H. (1994) Penalized likelihood in cox regression.
Stat. Meal., 13, 242772436.

Viechtbauer,W. (2010) Conducting meta—analyses in R with the metafor package.
J. Stat. Softnt, 36, 1418.

Wainer,H. (1976) Estimating coefﬁcients in linear models: it don’t make no never—
mind. Psyclwl. Bull., 83, 2137217.

Waldron,L. et al. (2014) Comparative meta—analysis of prognostic gene signatures
for Late—Stage ovarian cancer. J. Nat Cancer Inst., 106, pii: dju049.

Wang,Y. et al. (2005) Gene—expression proﬁles to predict distant metastasis of
lymph—node—negative primary breast cancer. Lancet, 365, 671%79.

Yoshihara,K. et al. (2010) Gene expression proﬁle for predicting survival in advanced—
stage serous ovarian cancer across two independent datasets. PloS One, 5, e9615.

Yoshihara,K. et al. (2012) High—risk ovarian cancer based on l26—gene expression
signature Is uniquely characterized by downregulation of antigen presentation
pathway. Clin. Cancer Res., 18, 137¢1385.

 

3069

ﬁre'spzumol‘pmjxo'sopeuuowrorq/pdnq

