ORIGINAL PAPER

Vol. 26 no. 7 2010, pages 912-918
doi: 1 0. 1093/bioinformatics/btq053

 

Systems biology

Advance Access publication February 12, 2010

Gene function prediction from synthetic lethality networks via

ranking on demand

Christoph Lippert1’*, Zoubin Ghahramani2 and Karsten M. Borgwardt1

1Machine Learning & Computational Biology Research Group, Max Planck Institutes, T bingen, Germany and
2Department of Engineering, University of Cambridge, Cambridge, UK

Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: Synthetic lethal interactions represent pairs of genes
whose individual mutations are not lethal, while the double mutation
of both genes does incur lethality. Several studies have shown a
correlation between functional similarity of genes and their distances
in networks based on synthetic lethal interactions. However, there is a
lack of algorithms for predicting gene function from synthetic lethality
interaction networks.

Results: In this article, we present a novel technique called
kernelROD for gene function prediction from synthetic lethal
interaction networks based on kernel machines. We apply our novel
algorithm to Gene Ontology functional annotation prediction in yeast.
Our experiments show that our method leads to improved gene
function prediction compared with state-of-the-art competitors and
that combining genetic and congruence networks leads to a further
improvement in prediction accuracy.

Contact: Christoph.lippert@tuebingen.mpg.de

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on October 30, 2009; revised on January 29, 2010;
accepted on February 3, 2010

1 INTRODUCTION

Synthetic lethality—concept and mechanisms: synthetic lethal
interactions have received much attention in the genetics community
over recent years. A synthetic lethal interaction refers to a pair of
genes which ‘interact’ in the following sense: while mutating each
of the two genes individually does not cause lethality, a double
mutation of both genes does show a lethal effect on the organism.
Hence, synthetic lethality seems to indicate a compensatory effect
of two genes, with one gene compensating for the deletion of the
other and with lethal consequences only if both genes are deleted
jointly.

The two main hypotheses to explain synthetic lethality between
two genes A and B are the within- and between-pathway models
(Boone et (11., 2007; Ye et (11., 2005b). The within-pathway
hypothesis assumes that both genes A and B are part of the same
pathway, and that the function of this pathway is diminished by
the single mutations, but rendered below the viability threshold by

 

*To whom correspondence should be addressed

their double mutation. The between-pathway hypothesis assumes
that A and B act in parallel pathways that can compensate for defects
in the other. These two main hypotheses can be extended in more
complex models of synthetic lethality (e.g. see Ma et (11., 2008),
and algorithms for detecting pathways within genetic networks have
been deﬁned based on these hypotheses (Kelley and Ideker, 2005;
Ma et (11., 2008; Ulitsky and Shamir, 2007).

Synthetic lethality and gene function: the compensatory effect of
genes in synthetic lethal interactions and the two main hypotheses
to explain this phenomenon already hint at a strong link between
gene function and synthetic lethal interaction. This link could be
conﬁrmed in several studies. Tong et (11. (2004) report that 12
and 27% of synthetic lethal interaction pairs have identical or
similar Gene Ontology (GO; Ashburner et (11., 2000) annotations,
respectively. Ye et (11. (2005a) report correlations between GO
annotations of genes and their distances in so-called congruence
networks which are derived from the genetic network. These
congruence networks quantify similarity between two genes by
means of a score that depends on their number of common neighbors
in the genetic interaction graph. In a second study, Ye et (11. (2005b)
report correlations between GO annotations of gene pairs and
this congruence score. This correlation is strongest for the GO
annotations that refer to the biological process and the cellular
component that these genes are part of, and weaker for their
molecular function. Qi et (11. (2008) deﬁned difﬁision kernels on
genetic interaction networks whose scores were shown to correlate
with semantic similarity of gene functions according to all three GO
categories.

Goals and scope of this article: while previous studies focused on
examining whether there is a correlation between genetic network
structure and functional associations (Qi et (11., 2008; Tong et (11.,
2004; Ye et (11., 2005a, b) or in discovering pathways (Kelley and
Ideker, 2005; Ma et (11., 2008; Ulitsky and Shamir, 2007), our goal in
this article is to deﬁne algorithmic machinery to rank all the genes
in a genetic network based on their likelihood of belonging to a
particular functional class, given a set of examples from this class.
This ranking provides guidance in choosing promising targets for
experimental ﬁinction determination.

First, we study this problem of gene ﬁinction prediction in yeast
and for all three deﬁnitions of gene ﬁinction provided by the GO
(Ashburner et (11., 2000): biological process, molecular ﬁinction and
cellular component. Second, we assess the prediction accuracy of
our method in comparison with that of state-of—the-art methods.
Third, we study whether combining predictions based on genetic

 

912 © The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org

112 /3.Io's[Bumo[pJOJXO'sotwuiJOJutotqﬂ:duq mot} pepeolumoq

9103 ‘{g anﬁnv 110::

Function prediction from synthetic lethality networks

 

and congruence networks improves accuracy, or whether both types
of networks provide redundant information.

Related work: the approaches closest to the one presented here are
those which unify several different data sources, including genetic
networks, into a joint prediction of gene ﬁinction or co-complex
membership (Deng et al., 2004; Lee et al., 2006; Letovsky and
Kasif, 2003; Qiu and Noble, 2008; Tian et al., 2008). The approach
presented here, however, differs conceptually from these earlier
studies (Sharan et al., 2007), as we describe in the following.
Ranking on demand ranks all genes in a given network based on
their likelihood of belonging to a set of example genes from the
same ﬁinctional class.

Related work on methods on ranking on demand is scarce. The
family of techniques for transductive semi-supervised learning does
not apply here, as we are dealing with one class, while these
are designed for discriminative learning on two or more classes
(Chapelle et al., 2006; Tsuda et al., 2005). A noteworthy exception
are Bayesian sets (BS; Ghahramani and Heller, 2006) that use a
model-based concept of a cluster (i.e. ﬁinctional class of genes) to
rank items (i.e. genes) using a score that evaluates the marginal
probability that each item belongs to a cluster containing the query
items. Another ranking on demand approach is RankProp (Weston
et al., 2004), which is designed for detecting remote homologs
in a network of protein sequence similarities by propagating this
sequence similarity through the graph. For a special choice of kernel,
the random walk kernel, our kernel-based ranking procedure can
imitate this information propagation idea from RankProp. Ranking
on demand has been performed before for loss-of—function RNAi
phenotype prediction on biological networks (Lee et al., 2008). This
approach is based upon the guilt by association (GBA) principle:
the more edges between a node and the labeled examples, the
higher its position in the ranking and the larger its probability
of belonging to the same ﬁinctional class. However, there are
justiﬁed doubts that this successful technique will work on synthetic
lethal interaction networks as well, because it only considers direct
neighbors in a graph (nodes connected by an edge), and does
not take the number of common neighbors into account, which
has been shown to be correlated with ﬁinctional similarity of two
genes in genetic networks (Ye et al., 2005b). A central point in our
experiments is to ﬁnd out how this GBA approach compares with
our novel approaches to ﬁinction prediction. In our experiments,
we compare our kernel-based technique with BS and GBA, and
explore the use of difﬁision and random walk kernels within our
framework.

2 ALGORITHM

Our algorithm for ﬁinction prediction on synthetic lethality networks
focuses on the following scenario: given a network Q of synthetic
lethal interactions, one has experimentally determined a subset DC
of genes that exhibit a particular function. The goal is then to
rank all remaining genes in the genetic network based on their
likelihood of having the same biological ﬁinction (see Fig. l for a
schematic illustration). In algorithmic terms, the problem of ‘ranking
of demand’ can be deﬁned as follows.

PROBLEM STATEMENT l (Ranking on demand). Given a graph
Q with N nodes V: {v1,...,vN} and a symmetric, undirected and
unweighted adjacency matrix A, and a subset of nodes DC belonging

O/O\./O
\./ \.

/\\<

|
0—0 0

Fig. 1. Schematic illustration of ‘Ranking on demand”: given is a network
of synthetic lethal interactions and a query set of genes with known common
function (black nodes). The task is to rank all other genes (white nodes)
based on their likelihood of exerting the same function.

to the same functional class C. The problem of ranking on demand is
to ﬁnd a permutation 7T : N —> N on the vertices in V\DC such that
for xi,xj EV\DC

770)277(1):P(Clxi)2P(CIXj)y (1)

i.e. 7T ranks the nodes in V\DC based on their likelihood of
belonging to C themselves.

A kernel approach to ranking on demand: it seems attractive to
deﬁne a kemel-based approach for ranking on demand due to the
efﬁciency of kernel machines in dealing with graph-structured data
(Smola and Kondor, 2003) and in combining several different data
sources (Scholkopf et al., 2004).

The key observation that led to our novel algorithm was that BS,
the Bayesian inference approach to ranking on demand (Ghahramani
and Heller, 2006), computes a two-sample test statistic to score the
likelihood of a gene (an item) to belong to a particular functional
class (a cluster). A two-sample test tries to decide whether two
samples, in our case x and DC, have been generated by the same
distribution or not. In more detail, BS compute a Bayes factor that
compares two hypotheses: the hypothesis 7-11 that x and DC were
generated by the same distribution versus the hypothesis 7-12 that
they were generated by two different distributions.

The key idea in designing a kernel algorithm for ranking on
demand is to compute a score that is based on a kemel-based two-
sample test statistic rather than a Bayes factor. Such a kernel-based
test statistic for the two-sample problem is the Maximum Mean
Discrepancy (MMD) by Gretton et a1. (2007).

Ranking criterion: the MMD is a criterion for measuring similarity
between two distributions (population MMD) or between samples
from two distributions (empirical MMD). The empirical MMD was
shown to be equivalent to the distance between the means of two
samples in a universal reproducing kernel Hilbert Space (Gretton
et al., 2007).

THEOREM 1. Let p and (1 be distributions and X = {x1,...,xml } and
Y ={y1,...,ym2} be samples from p and (1, respectively. Let <1): X —>
7-1 be a mapping from input space to feature space, and let k: X X
X —> R be the associated kernel function. Then the empirical MMD
can be computed as

1 m1 1 m2
MMD<H.X.Y>:= “In—12m»— m—ZZnynn
i=1

i=1

 

913

112 /3.Io's[Bumo[pJOJXO'sotwuiJOJutotqp:duq mot} papeolumoq

9103 ‘{g anﬁnv 110::

C.Lippert et al.

 

 

Algorithm 1 Kernel-based ranking on demand (kemelROD)
background: A graph Q with nodes V and adjacency matrix A,
a kernel ﬁinction k(., .) between nodes in Q
input: a query DC = {xi} C V
for all er\DC d0
1

score(x>=—||¢(x>— tam)“2

 

end for
output: return elements of V\DC sorted by descending score

 

 

1 m1 2 m1sm2
= [g  k(x,-.x1~>— mm  k(x,-.yj>
11,]:1 l,]=l
1 m2 1
+—2 2 mm] . (2)
m2 . ._
l,]—l

The kemel-based estimator (2) follows from the fact that a kernel
is an inner product between objects in feature space, i.e. k(xi,yj)=
¢(xi)T ¢(yj). The intuitive deﬁnition of a kernel is that it represents
a similarity measure between objects x,- and yj.

Using this test statistic, Gretton et al. (2007) deﬁned two-sample
tests whose key concept can be summarized as follows: the larger
the empirical MMD between X and Y, the larger the probability
that p and q are not the same. Hence —MMD (negative MMD), and
equivalently —MMD2, shows exactly the same behavior as the score
in BS: the larger —MMD, the more likely it is that the two samples
were generated by the same distribution.

Computation: to determine the ranking score of a gene x, we
compute the squared distance between x and the set of examples
{xi} in feature space,

1
||¢(x)— W 2 (man? (3)
C xieDc
We then multiply this score by —l, as we want scores to be the
largest for x that are likely to ﬁt into the set of examples DC. In
terms of kernels, this score(x) can be rewritten as

2 IDCI 1 IDCI
_ [14”) _ w  k(x,xj)+ Wiglkghxpj. (4)

We can drop the third term from (4) as it does not depend on x
and hence does not affect the ranking. Hence, we have to compute
IDCI +1 kernel values for each of the N objects in our dataset to
perform kernel-based ranking on demand. The entire procedure is
summarized in Algorithm 1.

Kernel design for function prediction on genetic networks: the choice
of kernel k(.,.), which can be thought of as a similarity measure
between two genes, is crucial for applying kemel-based ranking
on demand to function prediction on genetic networks. We used
different kernel functions in our experiments and provide here
biological interpretations of how they measure similarity between
two nodes in a genetic network.

Random walk kernels: as synthetic lethal interactions have been
shown to occur directly between functionally related genes (Tong
et al., 2004), we designed a kernel that captures direct neighborship
between genes. The p-step random walk kernel exhibits this property
(Smola and Kondor, 2003). It is deﬁned as Krw = (a1 — 1:)17, where a

is a scalar, I is the identity matrix and I: =D‘1/2(D —A)D_1/2 with
D(i,i)=ZjA(i,j) is the normalized graph Laplacian. This kernel
measures similarity between two nodes x,- and xj in a graph in terms
of the number of random walks from i to j in p steps. The term a]
allows the random walk to remain in the same node in the next step
with some probability (we will refer to a as the restart parameter).
The larger a, the larger this probability.

For p=l the random walk only takes one step, which means it
reaches only the direct neighbors of a node and hence the associated
kernel deems direct neighbors in the graph similar, which ﬁts the
observation by Tong et al. (2004). For p=2 one may visit nodes
that are direct or indirect neighbors of a given node, which means
that the corresponding kernel deems direct neighbors and nodes
with similar neighborhoods similar, combining both the observations
by Tong et al. (2004) and Ye et al. (2005b). For p> 2, the kernel
leads to a diffusion-like exploration of the graph and resembles the
graph difﬁision kernel by Qi et al. (2008), whose kernel values have
been shown to correlate with similarity in gene function, and the
information propagation approach RankProp (Weston et al., 2004).

Diﬁ‘usion kernels: for comparison, we also considered the
diffusion kernel as deﬁned by Kondor and Lafferty (2002) and used
by Qi et al. (2008), which is deﬁned as Kdiffusi0n=exp(— 131:),
where 13 is a scalar, Z the normalized graph Laplacian as deﬁned
above and exp is the matrix exponentiation. This difﬁision kernel
deems nodes similar if they are in close proximity in the graph and
connected by several paths. Qi et al. (2008) summed even- and
odd-length path separately in their approach.

3 METHODS AND MATERIALS

Dataset: the BioGRID repository (Stark et al., 2006), version 2.0.51,
was parsed for a total of 11998 directed synthetic lethal interaction pairs
between N = 2579 Saccharomyces cerevisiae genes. By correcting for double
counting bait-hit pairs, this results in a network of 10 791 undirected synthetic
lethal interactions. Functional annotations for these genes were obtained
from the Saccharomyces Genome Database (Cherry at al., 1998) and follow
the GO nomenclature (Ashburner at al., 2000). Functional categories in the
GO follow a general-to-speciﬁc ordering between terms of different depths
in the GO graph. The annotations are transitive, meaning that if a gene is
annotated with a term, this includes all terms that are more general. We make
this explicit by annotating each gene by its GO terms and all GO terms that
are more general than the annotated ones. We repeat this procedure for each
of the three main GO branches: molecular function, biological process and
cellular component.

Congruence network: in addition to the network of direct synthetic lethal
interactions, we also computed a genetic congruence network based on the
undirected synthetic lethal interactions as described by Ye et al. (2005a, b).
They deﬁne a genetic congruence score of two nodes xi 75 xj as the negative
logarithm of the probability that the number of shared true neighbors,
IN; ON; |, in the graph is equal to or higher than the observed number
of shared neighbors, lNobsl =|N§1i {lin |, of x, and xj, that is

congruence(xi,xJ-) = —log10P  ON; I Z INobs I)
where P is hypergeometrically distributed:

POM: 0N,Z;|2 INobsI)=

' . , Wil N-lN,-l

lawn-l (my 1)
xi

 

914

112 /3.IO'S[1211anprOJXO'SOIJBLUJOJIIIOIq”Idllq 111011 papeo1umoq

9103 ‘1g15n8nv 110::

Function prediction from synthetic lethality networks

 

In order to retain only signiﬁcant edges, all edges (xi,xj) with
P(xi,xj) >  were deleted, where the denominator equals the total
number of possible edges in the congruence graph and corrects for multiple
testing.

Experimental setting: gene function prediction experiments were
performed on each of the three main GO branches for GO terms of GO
depth (or G0 level) 1, 2, 3 and 4, where depth is measured as the shortest
distance to the root of the GO hierarchy. Depth 1 comprises the most general
terms. For each of these terms, i.e. for each node on this level of the GO, we
performed 5 -fola1 stratiﬁed cross-validation (5CV). The genes were randomly
divided into ﬁve sets of equal size and equal proportions of members and
non-members of a functional class. Then in each of ﬁve iterations, four sets
were used for training and the remaining set was used as the query database.
This ensures that each gene was used for testing exactly once.

Ascertainment bias correction: our experiment might suffer from an
ascertainment bias (Supplementary Section 2.1), as bait genes from the same
functional classes have a higher probability of being connected by an edge,
and might artiﬁcially boost prediction accuracy if they appear in both training
and test set. To avoid this effect, we make sure that bait genes with same
function are either all in the training dataset or all in the test set.

Comparison methods and parameter optimization: we run kernelROD
using a random kernel on the synthetic interaction network (synth), the
congruence network (cong) and using the sum of both kernels (sum). We
conduct the same three experiments for the diffusion kernel. We compare
kernelROD with two ranking on demand approaches, GBA and BS, and to a
two-class support vector machine (SVM) and a one-class SVM (SVMl) (for a
full descriptioniincluding the choice of negative examples for the SVM7
see Supplementary Section 1). We set the parameters for all methods by
3CV on the training set. Parameters include the number of steps in the p-step
random walk kernel (p e {1, . . . ,4}), the restart parameter a which controls the
inﬂuence of shorter random walks (a e {21, . . . , 2ll }), the diffusion parameter
of the diffusion kernel (13 6 {2‘5, . . . , 22}), weights for the convex combination
of two kernels (M e {0.1,...,0.9} and 1221—1”). In the case of the SVM
there is also the parameter C e{10_6,...,106} and in the SVMl a parameter
deﬁning the size of outlier quantile (v e {IO—6, . . ., 100}).

Evaluation criteria: in order to assess the quality of the rankings, we
computed the area under the receiver operator characteristic curve (AUC) and
the area under the receiver operator characteristic for up to 50 false positives
(AUC50) for each ranking. The AUC score reﬂects the probability that a
randomly drawn positive example is ranked higher than a randomly drawn
negative example. AUC50 reﬂects the probability that a randomly chosen
positive example is ranked higher than one random example out of the 50
highest ranked negative examples. The latter criterion is more appropriate
in a setting in which one is only interested in a small set of high conﬁdence
predictions that can be further evaluated experimentally. We report the AUC
results in the main paper and the AUC50 results in Supplementary Material.

To quantify the performance of a method across tasks, we compute the
Lz-distance between the results of this method and the best method on each
task. A low Lz-distance indicates that a method is always close to the best
performing one on each task.

4 RESULTS

We perform gene ﬁinction prediction via cross-validation on a
synthetic lethality network from yeast using kemelROD and several
comparison methods: BS, GBA and SVMl and two-class SVM
(see Table 1 and Fig. 2, and Supplementary Tables 2 and 3 and
Supplementary Figs 6 and 7 for all results).

All methods are signiﬁcantly better than random: as a ﬁrst check,
we examined whether the results we had obtained with kernelROD,
GBA and BS were better than random. For this purpose, we
generated 1000 random rankings on each task and computed
the AUC values for these random rankings. We then used this

approximated null distribution of AUC values from random rankings
to compute a P-value of the results of our methods. If the methods
worked only as good as a random ranker, one would expect to obtain
a distribution over P-values that is close to uniform. As can be
seen from Figure 3 and Supplementary Figure 8, the distribution
of P-values of all methods is skewed toward small P-values,
and highly signiﬁcantly different from that of a random ranker
[Kolmogorov-Smirnov test (KS-test), P = 0].

kernelROD improves GO term prediction by ranking on demand:
kernelROD based on the combination of a random walk kernel on
both the synthetic and the congruence network gives the best results
across all GO branches and GO levels, that is, the lowest L2 distance
to the best method on each task in terms of AUC.

The improvement achieved by kernelROD is largest when looking
at AUC50 scores (Supplementary Fig. 7): here kemelROD with
a random walk kernel achieves the lowest L2 distance on all
three networks, that is the synthetic lethal interaction network,
the congruence graph and on both. In terms of AUC, BS perform
similarly well as kemelROD on the synthetic interaction network.
This indicates that the top-ranked predictions of kemelROD tend to
be more accurate than those of BS.

Indirect interactions improve rankings: to further understand why
kernelROD leads to improved AUC scores, we examine the impact
of the number of steps taken in its random walk kernel on its AUC
scores. We compare kernelROD with a one-step random walk kernel
and kernel with a two-step random walk kernel on the synthetic
interaction network, for all GO branches and GO depths from 1 to 4
(Table 1). The two-step random walk kernel gives signiﬁcantly better
results than the one-step random walk kernel, reaching a higher AUC
value in 10 out of 12 settings (P = 0.0032; Binomial distribution with
n = 12, P = 0.5). This indicates that it is useﬁil to consider more than
just direct interactions for gene ranking.

Combination of networks improves prediction of G0 terms: in 8 out
of 12 experiments, the best AUC result is achieved using kemelROD
with a sum of kernels on both the synthetic and the congruence
network. In three out of the other four experiments, a random walk
kernel on the synthetic network or the congruence network yields the
highest AUC score. These results indicate that both data integration
is beneﬁcial for function prediction and that direct synthetic lethal
interactions and shared neighbors in the synthetic lethal interaction
network are both indicative of joint function.

Performance varies for diﬁ’erent G0 levels and branches: next we
examine whether our prediction results differ signiﬁcantly between
different GO branches and for different levels in the GO hierarchy
(see Table 1 and the plots of AUC versus GO level in Fig. 2). In
Figure 2, we compare kernelROD to GBA and BS.

The AUC results across GO branches do not differ signiﬁcantly,
they are all clustered in the range from 0.55 to 0.65. On GO
molecular ﬁinction (Fig. 2a), results on the congruence graph
improve with G0 depth, whereas the methods on the synthetic
interaction graph show no uniform trend. On GO molecular function
(Fig. 2b), results of all methods on the synthetic network deteriorate
from GO level 1 to 3, whereas the methods on the congruence graph
improve simultaneously. On GO biological process (Fig. 20), we
observe an increase in AUC for deeper levels of the GO hierarchy
for all methods expect for GBA on the synthetic interaction network.
This indicates that across all GO branches, the gene function classes
tend to be the more clustered in the congruence network, the deeper

 

915

112 /3.IO'S[1211anprOJXO'SOIJBLUJOJIIIOIq”Idllq 111011 pepeo1umoq

9103 ‘1g15n8nv 110::

C.Lippert et al.

 

Table 1. Results for GO term prediction using genetic interaction networks: Average AUC and standard deviations for GO term prediction on three GO
branches

 

Five times 5-fold : ross-validation with correction for ascertainment bia_s
AUC GO cellular component

 

 

GO molecular function GO biological process

 

60 level 1 2 a 4 1 2 3 4 1 2 3 4
Method Kernel Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD Avg. SD L2
Synthetc lethal interaction network
kROD RW 0.619 0.131 0.614 0.171 0.611 0.197 0.626 0.201 0.621 0.169 0.590 0.176 0.575 0.219 0.590 0.216 0.600 0.125 0.615 0.154 0.604 0.190 0.611 0.194 0.040
kROD Diff 0.549 0.149 0.585 0.165 0.599 0.202 0.611 0.205 0.592 0.172 0.568 0.173 0.569 0.219 0.588 0.212 0.546 0.132 0.576 0.161 0.583 0.186 0.600 0.197 0.065
kROD 1step 0.617 0.126 0.561 0.202 0.568 0.214 0.578 0.207 0.569 0.176 0.605 0.176 0.572 0.221 0.578 0.242 0.614 0.117 0.594 0.176 0.592 0.189 0.602 0.201 0.065
kROD 261ep 0.630 0.137 0.628 0.162 0.612 0.199 0.618 0.202 0.627 0.159 0.591 0.170 0.584 0.219 0.602 0.212 0.605 0.121 0.608 0.156 0.601 0.189 0.615 0.194 0.038
GBA — 0.584 0.133 0.596 0.162 0.558 0.203 0.586 0.166 0.576 0.191 0.563 0.161 0.553 0.224 0.561 0.232 0.578 0.106 0.597 0.161 0.573 0.179 0.597 0.196 0.010

BS — 0.581 0.137 0.637 0.154 0.595 0.214 0.609 0.206 0.625 0.176 0.611 0.167 0.601 0.216 0.596 0.225 0.573 0.103 0.597 0.151 0.598 0.182 0.618 0.166 0.045
SVM1 RW 0.548 0.121 0.583 0.123 0.563 0.173 0.613 0.165 0.524 0.113 0.555 0.155 0.550 0.162 0.574 0.137 0.543 0.087 0.558 0.120 0.546 0.141 0.573 0.157 0.085
SVM1 Diff 0.547 0.147 0.605 0.105 0.583 0.146 0.625 0.157 0.532 0.104 0.547 0.156 0.544 0.166 0.565 0.159 0.536 0.095 0.557 0.122 0.559 0.135 0.580 0.170 0.081
SVM RW 0.588 0.091 0.622 0.116 0.607 0.149 0.631 0.157 0.600 0.095 0.589 0.149 0.605 0.165 0.584 0.161 0.585 0.090 0.612 0.130 0.594 0.134 0.625 0.150 0.043
SVM Diff 0.584 0.096 0.631 0.110 0.600 0.166 0.634 0.169 0.604 0.111 0.609 0.141 0.602 0.161 0.597 0.156 0.599 0.101 0.606 0.131 0.592 0.132 0.626 0.153 0.040

 

 

 

SVMsim RW _ _ 0.578 0.151 0.610 0.160 _ _ 0.541 0.160 0.557 0.162 _ _ 0.552 0.126 0.574 0.156 0.083
SVM sim Diff _ _ 0.590 0.164 0.599 0.164 _ _ 0.541 0.155 0.583 0.151 _ _ 0.555 0.135 0.584 0.157 0.017
SVM dis RW _ _ 0.580 0.150 0.609 0.156 _ _ 0.542 0.159 0.568 0.166 _ _ 0.544 0.149 0.568 0.153 0.084
SVM dis Diff _ _ 0.582 0.180 0.612 0.166 _ _ 0.553 0.156 0.582 0.170 _ _ 0.555 0.140 0.575 0.157 0.016

 

Congruence network
kROD RW 0.576 0.126 0.642 0.172 0.655 0.219 0.679 0.206 0.582 0.183 0.602 0.166 0.604 0.227 0.621 0.235 0.608 0.116 0.632 0.167 0.638 0.189 0.655 0.204 0.021
kROD RW-f 0.579 0.121 0.643 0.166 0.659 0.217 0.680 0.206 0.594 0.164 0.598 0.194 0.602 0.226 0.621 0.233 0.607 0.116 0.634 0.162 0.636 0.193 0.651 0.200 0.025
kROD Diff 0.545 0.129 0.629 0.169 0.653 0.216 0.675 0.205 0.600 0.165 0.595 0.192 0.597 0.225 0.606 0.234 0.592 0.121 0.625 0.164 0.628 0.194 0.648 0.205 0.035
kROD Diff-f 0.559 0.119 0.629 0.166 0.655 0.214 0.674 0.204 0.602 0.166 0.597 0.192 0.597 0.227 0.605 0.234 0.595 0.122 0.625 0.164 0.627 0.193 0.648 0.204 0.032
GBA — 0.521 0.117 0.578 0.173 0.620 0.216 0.636 0.207 0.517 0.187 0.565 0.170 0.573 0.214 0.589 0.236 0.551 0.123 0.570 0.166 0.589 0.186 0.608 0.203 0.013
SVM1 RW 0.539 0.100 0.579 0.144 0.573 0.155 0.609 0.146 0.525 0.136 0.551 0.152 0.536 0.167 0.567 0.162 0.541 0.086 0.559 0.107 0.557 0.135 0.585 0.149 0.086
SVM1 Diff 0.560 0.115 0.601 0.107 0.573 0.155 0.606 0.167 0.523 0.141 0.565 0.159 0.550 0.150 0.575 0.145 0.539 0.086 0.562 0.120 0.564 0.136 0.588 0.150 0.080
SVM RW 0.578 0.115 0.634 0.112 0.602 0.161 0.644 0.154 0.590 0.101 0.598 0.155 0.619 0.156 0.582 0.160 0.593 0.101 0.611 0.132 0.593 0.137 0.628 0.146 0.042
SVM Diff 0.572 0.105 0.636 0.112 0.588 0.165 0.650 0.160 0.593 0.100 0.599 0.154 0.607 0.166 0.597 0.151 0.587 0.095 0.604 0.136 0.596 0.130 0.626 0.146 0.043

 

SVM sim RW _ _ 0.578 0.172 0.614 0.167 _ _ 0.565 0.146 0.569 0.156 _ _ 0.555 0.129 0.590 0.150 0.014
SVMsim Diff _ _ 0.596 0.161 0.614 0.159 _ _ 0.551 0.150 0.563 0.152 _ _ 0.548 0.127 0.577 0.153 0.011
SVM dis RW _ _ 0.577 0.165 0.610 0.160 _ _ 0.561 0.155 0.583 0.160 _ _ 0.538 0.124 0.568 0.150 0.081
SVM dis Diff _ _ 0.592 0.159 0.619 0.154 _ _ 0.554 0.159 0.586 0.147 _ _ 0.544 0.126 0.573 0.156 0.015

 

Combination of kernels
kROD RW 0.608 0.135 0.660 0.169 0.665 0.215 0.669 0.214 0.643 0.172 0.619 0.176 0.608 0.227 0.636 0.222 0.621 0.122 0.641 0.161 0.641 0.192 0.655 0.204 0.009
kROD Diff 0.562 0.127 0.639 0.171 0.663 0.220 0.671 0.215 0.641 0.167 0.610 0.192 0.603 0.229 0.624 0.222 0.603 0.134 0.635 0.165 0.639 0.195 0.651 0.205 0.024
SVM1 RW 0.525 0.143 0.591 0.136 0.590 0.149 0.608 0.163 0.538 0.126 0.555 0.156 0.547 0.154 0.577 0.162 0.525 0.084 0.551 0.122 0.553 0.136 0.578 0.156 0.084
SVM1 Diff 0.553 0.116 0.599 0.119 0.581 0.171 0.630 0.154 0.541 0.111 0.573 0.159 0.549 0.154 0.573 0.165 0.536 0.093 0.560 0.131 0.561 0.134 0.590 0.155 0.016
SVM RW 0.585 0.110 0.635 0.111 0.607 0.163 0.655 0.152 0.608 0.103 0.599 0.146 0.624 0.155 0.598 0.156 0.595 0.096 0.617 0.125 0.604 0.125 0.639 0.145 0.034
SVM Diff 0.594 0.106 0.637 0.110 0.615 0.163 0.651 0.163 0.601 0.140 0.610 0.149 0.611 0.166 0.601 0.172 0.603 0.097 0.618 0.126 0.606 0.125 0.639 0.150 0.032

 

SVM sim RW _ _ 0.585 0.160 0.616 0.165 _ _ 0.543 0.166 0.564 0.156 _ _ 0.550 0.131 0.578 0.149 0.080
SVM sim Diff _ _ 0.580 0.160 0.624 0.165 _ _ 0.540 0.156 0.574 0.155 _ _ 0.555 0.129 0.592 0.155 0.015
SVM dis RW _ _ 0.560 0.173 0.611 0.163 _ _ 0.554 0.156 0.589 0.146 _ _ 0.547 0.133 0.572 0.156 0.082
SVM dis Diff 0.565 0.161 0.611 0.170 0.543 0.155 0.576 0.156 0.552 0.130 0.573 0.156 0.083

 

random — 0.500 0.114 0.500 0.150 0.500 0.186 0.500 0.177 0.500 0.150 0.500 0.154 0.500 0.199 0.500 0.206 0.500 0.105 0.500 0.139 0.500 0.166 0.500 0.175 0.146

 

 

 

 

 

 

 

Depth of the GO tree is denoted by integers 14. Best AUC values and AUC values not signiﬁcantly worse (a: 5%) are marked in bold. ‘L2’ Euclidean distance to the best methods
in individual experiments. (Methods: GBA; BS; kROD, kernelROD; SVM1; SVM, discriminative support vector machines; kernels: RW, random walk kernel; Dif, diffusion kernel;
1step and 2step, random walk kernels with steps restricted to p=1 and p=2; Dif, diffusion kernel; RW—f and Diff-f, kernels on the congruence graph without thresholding.) For
complete results see supplementary Tables 172.

the GO level we look at. On the synthetic interaction network, we
could not detect a similar trend.

kemel-based approach kernelROD outperforms state-of—the-art
methods and that a combined random walk kernel on genetic

112 /3.Io's[BrunoprOJXO'soneuiJOJHtotq”:duq 111011 pepeo1umoq

9103 ‘1g15n8nv 110::

Choice of kernel: ﬁnally, we assess to which degree the choice of
kernel affects our gene prediction performance (Table 1). In terms
of L2-distance to the best performing method, the random walk
kernel is better than the difﬁision kernel on the synthetic network,
the congruence network and their combination.

5 DISCUSSION

In this article, we have presented kernelROD, a novel ranking
approach for gene ﬁinction prediction from synthetic lethality
networks. In function prediction in yeast, we observe that our

networks and on congruence networks (Ye et al., 2005a) often
improves, and never harms prediction accuracy. Considering indirect
interactions (walks of length 2) in the synthetic interaction network
results in improved rankings compared with considering only direct
interactions.

We could conﬁrm that congruence networks are useﬁil for
function prediction from genetic networks, as reported by
Ye et al. (2005a, b). We could also conﬁrm that difﬁision or random
walk-based kernels are a promising approach to ﬁinction prediction
on genetic networks, as reported by Qi et al. (2008). Furthermore,
we also established that random walk kernels achieve even better

 

916

Function prediction from synthetic lethality networks

 

(a) G0 Component (b)

0.7 

AUC
AUC

 

 

 

GO Function

 

2 3
GO depth

(c) GO Process
   

    

 

‘ - 1 - - random

-6— kROD FlW sum
— El - kROD RW Cong
+ kROD FlW

-*- Bayesian Sets
—A— GBA

-V- GBA cong

AUC

 

 

 

 

2 3
GO depth

Fig. 2. AUC versus GO level. (aw): average AUC values and standard errors on GO levels 1, 2, 3 and 4. kROD, kernelROD; RW, random walk kernel; cong,

congruence network; sum, both networks.

5 times 5 CV ascertainment bias corrected

 

1,— ---- "r ---- -- . . I l 5 5 5

    
  

- — kROD FIW sum
— kROD RW Cong
kFlOD FlW '

Bayesian Sets

' — GBA '
_ — GBA Cong
._ ... random {H

 

Cummulative distribulion function

 

I
. . O
0  i

0 0.1 0.2 0.3 0.4 "-0.5 0.6 0.? 0.8 0.6 1
p-value

1...

Fig. 3. Cumulative P-Value distribution. Cumulative distribution functions
of P-Values estimated from an empirical null distribution of 1000 random
rankings per AUC experiment. For all methods the distributions are
signiﬁcantly biased toward small values. (kROD, kernelROD; RW, random
walk kernel; Cong, congruence network; sum, both networks) Best Viewed
in color.

results on congruence networks. Our best performing kernel, both
on genetic and on congruence networks, is the random walk kernel,
and it achieves its best results when integrating information both
from the synthetic and the congruence network.

We make the following interesting observations which will
motivate ﬁiture research efforts: our ranking on demand approach
outperforms discriminative SVMs in ﬁinction prediction, reaching
better results in terms of L; on the congruence graph and the
combined graph, and similar ones on the synthetic graph. This
indicates that within-class similarity seems to be more important
than between-class dissimilarity for our task: genes with the same
ﬁinction seem to be in close proximity in the network (within-
class similarity), but there are also connected genes with different
functions (lack of between-class dissimilarity). The within-class
similarity allows our ranking method to obtain good results, because
genes with similar ﬁinction will appear high in the ranking. The
lack of between-class dissimilarity is likely to be the cause for the
worse performance of discriminative methods, because ﬁinctional

classes cannot be distinguished based on proximity in the network.
At the same time, this lack of between-class dissimilarity also keeps
our method from reaching higher accuracy levels, as it leads to
genes from other ﬁinctional classes being ranked high. A topic of
future research will be to add further data sources to our prediction
system that increase the between-class dissimilarity in our feature
representation of genes. Due to the closure properties of kernels, our
kernel-based ranking algorithm will be a convenient framework for
this task of data integration.

Conﬂict of Interest: none declared.

REFERENCES

Ashburner,M. et al. (2000) Gene ontology: tool for the uniﬁcation of biology. the gene
ontology consortium. Nat. Genet, 25, 25729.

Boone,C. et al. (2007) Exploring genetic interactions and networks with yeast.
Nat. Rev. Genet, 8, 437449.

Chapelle,O. et al. (eds) (2006) Semi-Supervised Learning. MIT Press, Cambridge, MA.

Cherry,J.M. et al. (1998) SGD: Saccharomyces genome database. Nucleic Acids Res,
26, 73779.

Deng,M. et al. (2004) An integrated probabilistic model for functional prediction of
proteins. J. Comput. Biol., 11, 463475.

Ghahramani,Z. and Heller,K.A. (2006) Bayesian sets. In Weiss,Y. et al. (eds) Advances
in Neural Information Processing Systems I 8. MIT Press, Cambridge, MA.

Gretton,A. et al. (2007) A kernel method for the two-sample-problem. In Advances in
Neural Information Processing Systems I9. MIT Press, Cambridge, MA.

Kelley,R. and Ideker,T. (2005) Systematic interpretation of genetic interactions using
protein networks. Nat. Biotechnol, 23, 5617566.

Kondor,I.R. and Lafferty,J.D. (2002) Diffusion kernels on graphs and other discrete
structures. In Proceedings of the International Conference on Machine Learning.
Morgan Kaufmann, San Francisco, CA, pp. 315732.

Lee,H. et al. (2006). Diffusion kernel-based logistic regression models for protein
function prediction. Omics J. Integrative Biol, 10, 40755.

Lee,I. et al. (2008) A single gene network accurately predicts phenotypic effects of
gene perturbation in Caenorhabditis elegans. Nat. Genet, 40, 1817188.

Letovsky,S. and Kasif,S. (2003) Predicting protein function from protein/protein
interaction data: a probabilistic approach. Bioinformatics, 19 (Suppl. 1), i1977i204.

Ma,X. et al. (2008) Mapping genetically compensatory pathways from synthetic lethal
interactions in yeast. PLoS ONE, 3, e1922.

Qi,Y. et al. (2008) Finding friends and enemies in an enemies-only network: a
graph diffusion kernel for predicting novel genetic interactions and co-complex
membership from yeast genetic interactions. Genome Res, 18, 199172004.

Qiu,J. and Noble,W.S. (2008) Predicting co-complexed protein pairs from
heterogeneous data. PLoS Comput. Biol, 4, e1000054.

Schblkopf,B. et al. (2004) Kernel Methods in Computational Biology. MIT Press,
Cambridge, MA.

 

917

112 /3.Io's[BumoprOJXO'soneuiJOJHtotq”:duq 111011 pepeo1umoq

9103 ‘1g15n8nv 110::

C.Lippert et al.

 

Sharan,R. et al. (2007) Network-based prediction of protein function. Mol. Syst. Biol.,
3, 88.

Smola,A.J. and Kondor,I.R. (2003) Kernels and regularization on graphs. In
Schblkopf,B. and Warmuth,M.K. (eds) Proceedings of the Annual Conference on
Computational Learning Theory. Lecture Notes in Computer Science. Springer,
Heidelberg, pp. 1444158.

Stark,C. et al. (2006) BioGRID: a general repository for interaction datasets.
Nucleic Acids Res, 34, D5357D539.

Tian,W. et al. (2008) Combining guilt-by-association and guilt-by-proﬁling to predict
saccharomyces cerevisiae gene function. Genome Biol., 9 (Suppl. 1), S7.

Tong,A. et al. (2004) Global mapping of the yeast genetic interaction network. Science,
303, 8087813.

Tsuda,K. et al. (2005) Fast protein classiﬁcation with multiple networks. Bioinformatics,
21 (Suppl. 2), ii597ii65.
U1itsky,I. and Shamir,R. (2007) Pathway redundancy and protein essentiality revealed
in the Saccharomyces cerevisiae interaction networks. Mol. Syst. Biol., 3, 104.
Weston,J. et al. (2004) Protein ranking: from local to global structure in the protein
similarity network. Proc. Natl Acad. Sci. USA, 101, 655976563.

Ye,P. et al. (2005a) Commensurate distances and similar motifs in genetic congruence
and protein interaction networks in yeast. BMC Bioinformatics, 6, 270.

Ye,P. et al. (2005b) Gene function prediction from congruent synthetic lethal interactions
in yeast. Mol. Syst. Biol., 1, 20050026.

 

918

112 /3.Io's[BrunoprOJXO'soneuiJOJHtotq”:duq 111011 pepeo1umoq

9103 ‘1g15n8nv 110::

