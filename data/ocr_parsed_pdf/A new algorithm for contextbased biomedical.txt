ORIGINAL PAPER

Vol. 29 no. 6 2013, pages 780—789
doi:10. 1 093/bioinformatics/btto30

 

Bioimage informatics

Advance Access publication February 7, 2018

A new algorithm for context-based biomedical diagram similarity

estimation

Songhua Xu‘”, Jianqiang Sheng2M and Xiaonan Luo2

1Information Systems Department, College of Computing Sciences, New Jersey Institute of Technology, University
Heights, Newark, NJ 07102, USA and 2National Engineering Research Center of Digital Life, State-Province Joint
Laboratory of Digital Home Interactive Applications, School of Information Science and Technology, Sun Yat-sen

University, Guangzhou 510006, PR. China
Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: Diagrams embedded in the biomedical literature convey
rich contents, which often concisely and intuitively highlight key thesis
of a research article. Despite their vital importance and informative
clues for biomedical literature navigation and retrieval; currently, we
miss an effective computational method for automatically understand-
ing and accessing these valuable resources.

Proposed Method: To address the aforementioned gap, we propose a
novel context-based algorithm for estimating the similarity between a
pair of biomedical diagrams. The main difference of the proposed al-
gorithm with respect to the existing methods lies in the new algorithm’s
incorporation of the semantic context associated with diagrams in their
source documents into the diagram similarity estimation process. In
addition, the new approach also performs a series of advanced
image processing and text mining operations to comprehensively ex-
tract the semantic content graphically encoded inside diagram images.
Results: The new algorithm can be deployed as a reusable compo-
nent providing a fundamental function for building many advanced,
semantic-aware applications on biomedical diagram processing. As
a case study, in our experiments, we demonstrate the advantage of
the new algorithm for diagram retrieval. A set of biomedical diagram
search and ranking experiments were conducted, where the perform-
ance of the new method was compared with that of five peer methods.
The comparison results demonstrate the performance superiority of
the new algorithm with all peer methods with statistical significance.
Contact: songhua.xu@njit.edu, shengjianqiang@163.com or Inslxn@
mail.sysu.edu.cn.

Received on May 27, 2012; revised on January 11, 2013; accepted on
January 17, 2013

1 INTRODUCTION

Diagrams are widely used graphical vehicles for illustrating ideas,
explaining hypotheses and reporting findings. They provide a
powerful communication device for Visually sharing key infor-
mation supplied in a document. These Visual elements are well
received by readersipeople often like to overview key contents
of a document through browsing its embedded diagrams, if any.
Such a diagram browsing-based practice for document

 

*To whom correspondence should be addressed.
7‘The authors wish it to be known that, in their opinion, the ﬁrst two
authors should be regarded as joint First Authors.

navigation has been popularly adopted in reality by many
biomedical researchers to cope with the exploding amount of
biomedical literature in existence today. In this article, we pro-
pose a new diagram similarity estimation method, which exploits
the context information of a diagram latent in its source docu-
ment for deriving a high-level understanding over the diagram’s
intended semantic messages. As image similarity is of fundamen-
tal importance for many biomedical diagram image processing,
understanding and retrieval tasks, our new similarity estimation
method can be used for many advanced semantic computing
applications relating to diagram images, such as searching, rank-
ing, clustering and categorizing diagrams, to name a few. One
important extended application of our algorithm is to apply the
algorithm to empower search engines and digital library systems,
so that they can more capably return diagrams and the corres-
ponding source documents to meet users’ needs and interests in
diagram searching and diagram browsing-based Visual literature
navigation. Because of space limit, we will only report the results
of our experiments that demonstrate the advantage of our
method for diagram retrieval and ranking.

In this article, we introduce a new method for context-based
diagram similarity estimation Via a probabilistic reasoning ap-
proach. Based on the new method, we build an algorithmic
framework for deriving context-based diagram similarity, includ-
ing procedures to detect nodes and edges from an input diagram
image using off-the-shelf computer Vision tools, a method to
represent the extracted nodes and edges from the input diagram
image as a graph and the procedure to apply the new method for
deriving pairwise diagram similarity through cross-referencing
the diagrams’ graph representations and their source documents
(see Fig. l for an example). In the end, we also present extensive
experimental results for validating the effectiveness of our new
method in the application context of diagram retrieval and
ranking.

2 RELATED WORK

We will now brieﬂy look at two aspects of work closely related to
our study here, including (i) diagram similarity estimation and
(ii) context-based image retrieval.

Diagram similarity estimation. Signiﬁcant efforts have been
dedicated to designing algorithms and methods for estimating
pairwise diagram similarity, most of which focus on processing

 

780 © The Author 2013. Published by Oxford University Press. All rights resen/ed. For Permissions, please e—mail: journals.permissions@oup.com

112 /310's112u1n0fp10}x0"sotJBuiJOJutotq/ﬁduq 11101} papaolumoq

91oz ‘Og anﬁnV uo ::

Biomedical diagram similarity estimation

 

(a) (b)

(c) (d)

 

 

 

 

 

 

   

 

 

   

 

  
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

I" 21"“ “T 2'7"” V Tln- Italuham ur mum. ]imlmi- unll _ 02
l'KKI Mrrr Ml'iHNl. :Ind 12-! monk “(In
a 1 idmliﬁﬂl illlm-Irdx urn- l'\|'||l||td.lillr I--: 7
’ ..  n I   - ||.|.-\..u|'---u:||--.u. ~' 
b1 ' iii"    i . -?- \:.-.-I'H:'\ -.....-... |‘-.-..--.|\ al
.3233? " 82 '  .. .., 046 0.33
1111- alumni-ix and full lull. M H n-mrd. “I r'!‘ , 32
- . e2 1" L]
d1 . :r" km.“ 7 Marat Mm- ru'lullnl.dur Iu: [EMU U “'25 O 57 U 44
 run «I .16 mm... "n- L .. |,_|_.\ .m _‘r._'....
— [)2 d2 dl Ll -l I 1.2 u:
I :..I -- - _
Q1 ‘ ,,,,,  ,.__.. 0.31 5-55 0.21 0'29
I II I _ I I I I A In Mal. mun «Mics M'roim'ludtd in |hi~ I. Tllllllml. Fl.”- II M KIN-I'm.” I   . I
0......“ 1.. m. .._...wi.+  mﬂgqﬂulh ‘5 n W- | l' I - g I (‘12 02
(e) (f (9)
31 b1 “1 d1 91 £1 £1 32 b2 c2 d2 e2 a1 b1 c1 (11 e1 f1 gl
:1 02,5 0'35 0'33 030 025 g 3 a2 0 0.57 0.44 0 0 a2 0.09 0 0 0 0 0 0
c1 Q33 0 0 0 0 0 0 b2 0.57 0 0 0.21 0.29 b2 0 0 0 0.44 0 0 0
d1 0 0.40 0 0 o 0.31 0.45 Cl 0.44 0 0 0 0 c2 0 0 0 0 0.11 0 0
e1 0 0.25 O O O O 0
ﬂ 0 O O 031 O O 0 d2 0 0.21 0 0 0 d2 0 0 0 0 0 0.31
"'gl "' 0 " 0 " 0 "Q55" 0 " 0 " 0 ' e2 0 0.29 0 0 0 e2 0 0 0 0 0 0.05 0

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Fig. 1. (a and b) are two diagrams commonly related to the query theme of gastric cancer, where (a) is Figure 1 in the article of Liu et a]. (2010), and (b) is
Figure 1 in the article of Qiao and Feng (2012); (c and d) are the two diagrams’ respective attributed graph representations extracted by the method
introduced in this article; (e and i) are the two diagrams’ respective weighted adjacency matrices Ws constructed by our method according to their
respective source documents; (g) is the optimal matching matrix IVI computed for the two diagrams

a speciﬁc type of diagram. For example, within the software
engineering community, statecharts are a specialized type of dia-
grams widely used for illustrating calling logics in a software
architecture design. Nejati et a]. (2007) studied the problem
of optimally matching statecharts, where they offered a special-
purpose image similarity metric for measuring statechart similar-
ity. Wombacher (2006) validated a number of metrics for
measuring the similarity between a pair of workﬁow diagrams,
where each workﬁow is represented as finite state automata. All
the metrics he evaluated can be broadly categorized into lan-
guage and structure-based approaches. His study suggested
that the relatively simple n-gram sets-based approach achieves
the best performance among all peer methods. Li et a]. (2008)
proposed a structural approach using high-level change oper-
ations for measuring similarity between two process model dia-
grams. Their idea is to find a minimum set of addition, deletion
and moving operations to transform one diagram into another
diagram, where the minimum number of transformation steps
needed is used as the pairwise diagram distance. Dijkman et a].
(2011) experimentally compared three classes of similarity meas-
urement methods for business process model diagramsilabel
similarity, structural similarity and behavioural similarity (elem-
ent labels and causal relations captured in a process model).
Their result shows that structural similarity attains the best per-
formance. Ehrig et a]. (2007) introduced a method for measuring
the similarity between a pair of business process model diagrams.
Their method derives diagram similarity from three aspects: syn-
tactic, linguistic and structural measures. Minor et a]. (2007)
studied the problem of workﬁow diagram similarity estimation
and retrieval by introducing a structure-based approach using a
weighted graph edit distance. Melnik et a]. (2002) proposed a
versatile graph matching algorithm, called ‘similarity flooding’,

for matching data schema diagrams. Their algorithm first derives
a similarity propagation graph to denote pairwise node simila-
rities between two diagrams and then performs a similarity
spreading process in the graph for deriving an optimal matching
between the two diagrams. Madhusudan et a]. (2004) introduced
a structural method using Artificial Intelligence (AI) planning
techniques for comparing diagrams illustrating workﬁow
models. Their method ﬁrst uses a domain-independent AI
planning-based approach to represent diagrams of business
workﬁow models as cases and then adopts a case-based reason-
ing framework for deriving pairwise diagram similarity.

Context-based information retrieval. A decade ago, Lawrence
(2000) pointed out the importance of context in web search.
Recently, Belkin (2008) discussed the challenges associated with
characterizing context for building information retrieval applica-
tions. Within the image retrieval ﬁeld, people have explored con-
textual information for image processing, annotation and
retrieval, e.g. Sinha and Jain (2008); Luo et a]. (2009); O’Hare
and Smeaton (2009); Lopes (2009); Segev and Toch (2009); Yang
et a]. (2010); Fisher and Hanrahan (2010); Choi et a]. (2010);
Yang et a]. (2011). For the diagram retrieval problem, textual
information carried inside a diagram only intends to shed high-
lights rather than to provide detailed explanation over the dia-
gram’s content; in addition, the caption of a diagram does not
always cover every message illustrated in the diagram. Both fac-
tors incur computational difﬁculties for automatic diagram
understanding and retrieval.

In the bioinformatics literature, Meekers and Rahaim (2005)
observed the importance of socioeconomic context when de-
veloping social marketing models for improving reproductive
health. Moskovitch et a]. (2007) designed a context-sensitive
search method for retrieving medical text with better accuracy.

 

781

112 /310's112u1n0fp10}x0"sotivurJOJutotq/ﬁduq 11101} papnolumoq

9103 ‘Og anﬁnV uo ::

S.Xu et al.

 

Sinha and Jain (2008) described an unsupervised context analysis
method for inferring context-speciﬁc gene regulatory networks
from publicly available gene expression data. Rodriguez-Esteban
and Iossifov (2009) introduced a ﬁgure mining method that
jointly leverages image understanding, text mining and optical
character recognition (OCR) techniques to retrieve tables and
ﬁgures embedded in the biomedical literature that match a cer-
tain user-prescribed image type.

Among all the methods surveyed earlier in the text, none has
looked into the contextual information of diagrams as a clue for
estimating diagram similarities. To develop more comprehensive
and accurate understanding over a diagram’s semantic contents,
we propose to acquire supplementary contextual information of
a diagram from its source document for estimating diagram simi-
larity in a semantically meaningful way. Our proposed approach
is also applicable for processing other generic types of figures,
such as statecharts and workﬁow diagrams, even though our
method works particularly effectively with biomedical contents
because of the prevalence of diagrams in biomedical publica-
tions. To the best of our knowledge, no published efforts have
previously pursued this idea in the biomedical informatics field.

3 REPRESENTING A DIAGRAM WITH ITS
DOCUMENT CONTEXT AS A GRAPH

Given a diagram G embedded in its source document D, in our
method, we represent it as an attributed undirected graph.
Each entity in G is represented as a node in the graph; each
visually illustrated relationship between entities in G is
represented as an edge in the graph. When no ambiguity
arises, we will not differentiate the diagram from its graph
representation. We can formally characterize G as
(N(G),E(G),W(G)), where N(G)= {NilNie G} is the set of
nodes in G; E(G) = {EleNhM e N(G),E[,j e G} is the set of
edges in G; W(G) is a weighted adjacency matrix, which describes
whether two nodes in the diagram are connected, and if so, how
intensively the source document D discusses the semantic rela-
tionship represented by the edge, or how saliently the semantic
relationship is embodied in D. We will look at how to derive
W(G) later. As from the matrix W(G), we can readily understand
the node connectivity information, we can more compactly char-
acterize a diagram as (N (G), W(G)), without losing any informa-
tion. Figure 1 gives an example of two sample diagrams’ graph
representations constructed by our method.

3.1 Detecting nodes from a diagram

Given an input diagram G in the form of a static image, we detect
its nodes and edges through a set of image processing steps as
follows. We first apply the Gaussian ﬁlter function offered by the
OpenCV 2.2.0 package (http://sourceforge.net/projects/opencvli-
brary) to remove local image noise from G. We then detect from
G a collection of basic shape elements, including quadrilaterals,
circles and ellipses. In our current implementation, we adopt the
method proposed in the study by Qin et a]. (2010) to detect these
elements.

For each detected shape element, we further attempt to recog-
nize any text that may be carried inside the interior image region of
the shape. This text recognition task is accomplished by parsing

the image region to the OCR tool provided in the Microsoft Ofﬁce
2007 Document Imaging package. In our OCR process, currently,
we only process English contents. For each recognized word from
the OCR process, we match the word against the full text of the
diagram’s source document D. Only words that occur in D will be
retained; the rest of the words will be considered OCR errors and,
hence, discarded. For all remaining OCR result words, we further
remove stop words. Finally, we perform a stemming process to
restore each word to its basic root form.

Each shape element detected previously will be represented
as a node N,. In this way, we establish our node set
N(G) = {N1,N2, ---}, where each N,- is a shape element. After
this step, we remove from the image G all the detected shape
elements, including their interior image regions, to make the
downstream image processing steps more reliable.

3.2 Detecting edges from a diagram

To construct the edge set E(G) for representing the node con-
nectivity information in the diagram, we first detect arrows and
line pieces, the latter of which are composed of one or multiple
line segments in the image G (see Fig. 1 for an example). To
detect line pieces in G, we applied the application programming
interface (API) named ‘choughLines2’ in the OpenCV 2.2.0
package; to detect arrows in G, we adopted the algorithm pro-
posed in the study by Wendling and Tabbone (2003), which is
relatively easy to implement and is capable of producing satisfy-
ing performance in our experiments. Occasionally, line pieces
and arrows in a diagram may be accompanied by annotation
text. To capture such text, we ﬁrst remove from G all recognized
line pieces and arrows. For the remaining image region, we then
perform a text detection procedure using the method suggested
in the study by Xu and Krauthammer (2010). For each recog-
nized text region, we will anchor the text region onto its nearest
line piece or arrow according to the Euclidean distance. Finally,
we will call another OCR procedure to recognize these annota-
tion text strings.

For each line piece or arrow detected previously, we need to
associate both its end points to their respective closest shape
elements according to the Euclidean distance. In our work, we
deﬁne the distance between a line piece or an arrow to a shape
element as the minimum distance between one end point of the
line piece or arrow and a pixel on the contour of the shape
element. As each shape element has been represented as a node
N,, any pair of nodes commonly pointed to by a line piece or an
arrow are considered linked, in which case, we will introduce an
edge to connect the two nodes in G. Through the aforementioned
process, we construct our edge set E(G) for G. The aforemen-
tioned procedure of transforming an input diagram image into
its corresponding structural graph representation is implemented
as a fully automatic module in our prototype system.

3.3 Identify counterpart text for diagram nodes

For each node N,- detected from G, we need to identify text frag-
ments in the source document D that embody the semantics rep-
resented by N,-’s corresponding visual symbol on the diagram. To
locate a text position in a document, we use a sentence’s sequence
number in the document as the location index. For text appear-
ing in the main body of an article, we separate it into sentences

 

782

112 /310'S[BHJHOIPJOJXO'SOIJBLUJOJIIIOICI”Zduq 11101} pQPBOIII/IAOG

9103 ‘Og isnﬁnV uo ::

Biomedical diagram similarity estimation

 

according to the presence of punctuation marks in the text; in
particular, for text occurring in the title of an article, an article
section or sub-section, as long as the source document allows
automatic detection of these title regions, we treat all text
displayed in one title region as a single sentence. Let the set of
sentences semantically related to the node N,- be
S, = {$31, $32, - - -}, where each SM- is a sentence in D that explains
or discusses the meanings of Ni. Each SM- is associated with a
significance score ,0“- e [0, 1] that indicates the semantic related-
ness between SM- and N,. For an arbitrary sentence 3,, e D, to
measure its semantic relatedness with N,, we compare the align-
ment of the semantics represented by 3,, and Ni, respectively,
according to their text. Recall that the text of the node N,- has
been previously recovered through the OCR process. To estimate
the aforementioned semantic alignment, we use the algorithm
proposed in the study by Li et a]. (2006), which is specifically
designed for measuring semantic similarity between two pieces of
short text. To determine the sentence set S,- for a given node N,,
we start with an empty set and scan all sentences in D. We re-
spectively derive each sentence’s semantic relatedness with N,-
following the aforementioned procedure. If the detected semantic
relatedness exceeds an empirically chosen threshold (0.05 in all
our experiments), we consider the sentence noticeably related to
the node and collect the sentence into the set S,. In this document
sentence scanning procedure, we consider all sentences in the full
text of the document, including those in the document’s title,
abstract, footnotes and ﬁgure captions.

3.4 Identify counterpart text for diagram edges

Once we have identiﬁed the counterpart text in D for every node
in G, we can further identify the corresponding text in D that
reflects the semantic meanings denoted by each edge in the dia-
gram. Our edge counterpart text detection procedure is based on
the node counterpart text detection result. Recall that E(i, j) is
the edge that connects the nodes N,- and N]- in G; N,, and Nj’s
counterpart text in D is organized as two sentence sets S,- and S],
respectively. To locate counterpart text for the edge E(i,}), we
essentially pair sentences from S,- and Sj, one from each set. Let
|SX| be the number of sentences in the sentence set SX. Our
aforementioned edge counterpart text identiﬁcation procedure
leads to |S,~| x ISjl instances of the counterpart text for E(i,}).
For the sentence pair Si," 6 S,- and SM e S], we estimate its sig-
niﬁcance in representing the semantic meanings of E(i,}) as
p,,upj,v6(s,-,u,sj,,). Recall that pi,“ and pm are the signiﬁcance
of the sentences S1," and SN in embodying meanings of the
nodes N,- and N], respectively; 6(S[,u,Sj,v) is a newly introduced
measure that quantiﬁes how likely the two sentences S1," and SL1;
embody the semantic meanings intended by the edge E(i,}). We
assume the farther apart the two sentences are, the less likely the
pair of sentence describes the relationship represented by the
edge. Note that Si," and sj, ,, may both refer to the same sentence,
in which case, it is most likely the meanings of the edge E(i,}) are

reﬂected by the sentence. In our current design, 6(S[,u,Sj,v) is

estimated as follows: 6(s,,u,sj,,)=exp(—% , where

diS(S[,u,Sj,v) is the number of non-stop words separating the
two sentences S1," and SM; ave_dis(D) is the average number of
non-stop words in a sentence in the document D.

We further introduce a function Q(s,-,u,sj,,, t“) e [0, l] to
measure the degree of relevance (the larger, the more relevant)
between text of the two sentences S1," and SL1; and the annotation
text of the edge 1“. Recall that we mentioned earlier that occa-
sionally a line piece or an arrow in a diagram may be accompa-
nied by some annotation text. We empirically deﬁne
Q(s,-,u, sj, v, t“) as follows:

Q(Si,ussj,w 7:i,j) : maXIE(WaIwuet,-Js Winvbe.v,-‘,,Usj‘,.)}s 

where 5(wa, w) e [0, 1] computes the semantic relatedness
between a pair of words, w“ and wh, according to
WordNet: :Similarity (http: / / search.cpan.org/ dist /W ordNet-
Similarity/doc/intro.pod). If the edge does not have any anchor-
ing text, i.e. tw- = 0, Q(s,-,u,sj,,, t“) = 1. The reason why we made
such a value assignment is due to the following logic: if an edge
does not carry any anchoring text, no particular semantic rela-
tionship is speciﬁed to govern the edge’s two end nodes. Hence,
we give the beneﬁt of doubt by assuming any text can be relevant
in some way to the relationship represented by the edge. If there
is indeed some anchoring text associated with the edge, then only
those counterpart text instances that embody the same semantic
relationship speciﬁed by the anchoring text shall be considered
well matched and relevant to the edge.

Based on the signiﬁcance of each sentence pair, we can further
estimate the signiﬁcance of the edge E(i, j) embodied in the entire
document D by aggregating the signiﬁcance of all its counterpart
sentence pairs across the document as follows:

2 pi,upj,v6(si,usSj,v)Q(Si,usSj,Vs lij): 

1
Wt. . = _
,1 Z
s,‘,es,-,sj‘,esj

where z is a scaling factor to ensure the signiﬁcance value for the
most signiﬁcant edge in G is 1. Based on the estimated
signiﬁcance for each edge in G, we can construct a weighted
adjacency matrix W(G), for characterizing whether two nodes
in the graph are connected, and if so, how saliently this connec-
tion is embodied in the source document D. Let W,, j(G) be the
element on the i-th row and j—th column of the matrix W(G); we
deﬁne W(G) as follows: WLJ-(G) 2 WM- if EM 6 E(G) and 0
otherwise.

4 MEASURING DIAGRAM SIMILARITY BY
LEVERAGING DOCUMENT CONTEXT

Given two diagrams G1 and G2, to measure their similarity, we
need to compute an optimal matching between these two dia-
grams. Let |N(G1)| and |N(G2)|, respectively, be the number of
nodes in the two diagrams. We can then represent any matching
relationship between G1 and G2 using a |N(G1)| x |N(G2)| dimen-
sional matching matrix M(G1, G2). The element on the i-th row
and j-th column of M(G1, G2), denoted as MLJ-(Gl, G2) 6 [0, 1],
represents the matching degree between the i-th node in G1 and
the j-th node in G2. Note that MAJ-(G1, G2) can be any number
between 0 and 1, which implies one node from a diagram can
match to one, multiple or no node in the other diagram. Such a
fuzzy matching mechanism allows our method to deal with
a wide range of diagram matching scenarios without enforcing
a strict one-to-one matching between two diagrams’ nodes, the
situation of which does not always exist in reality. For simplicity,

 

783

112 /310's112u1n0fp101x0"sotwuuqutotq/ﬁduq 111011 pap1201um0q

9103 ‘0g isnﬁnV uo ::

S.Xu et al.

 

we will abbreviate M(G1,G2) for M from now on when no
ambiguity arises. Also, we will abbreviate W(Gl) and W(G2) as
W1 and W2, respectively, for easy notation. In the following, we
will introduce a method for deriving an optimal matching
relationship matrix M for an arbitrary pair of diagrams G1
and G2. The optimality in the matching relationship
matrix refers to the estimation of the optimal matching degree
between two matrices using our heuristic-based estimation
framework.

We first introduce a heuristic function H(G1, G2, M) to repre-
sent the semantic relatedness between two diagrams G1 and G2,
assuming that nodes in the two diagrams are matched according
to the correspondence relationship M. Intuitively, the more
semantically related the two diagrams are, the larger the value
of H(G1, G2, M) becomes. This modelling perspective is inspired
by the work of Li and Hsu (2008), who studied a related problem
of content-based natural image retrieval with relevance feedback
using a graph-theoretic region correspondence estimation
method. Given the aforementioned function H(G1,G2,M), we
can search for the optimal matching relationship matrix IVI as
follows:

A

M = argmaxH(G1,G2,M). (3)
M

As mentioned earlier, a diagram G can be characterized using
its node set N (G) and its weighted adjacency matrix W(G).
Working with this premise, we empirically assume that:

H(G1, G2,  O(
IN(G )I IN(G )I . .
‘ 11:, 2 PWNiGI), NAG», whwz, M),

i=1
where H(N,-(G1), NJ-(G2), W1, W2, M) estimates the pairwise node
matching score between N,-(G1) and NJ-(G2). Recall that N,-(GX) is
the i-th node in the node set N (G), and M i, j is the element on the
i-th row and j-th column of the matching matrix M.

It shall be noted that the above property is heuristically
assumed. Intuitively, the pairwise graph similarity can be
estimated according to the pairwise similarities between corres-
ponding nodes in the two graphs. The higher such node
similarities collectively are, the more semantically related the
two graphs may be perceived as assumed by our heuristic.
Note that if MM 730, it means that the node N,(G1) from
N(Gl) matches the node NJ-(G2) from N(G2) according to the
matching relationship M. The reason why we raise the pairwise
node matching score function H(N,-(G1),Nj(G2),W1, W2,M) to
the power of M i, j is because the matching degree M i, j can be any
number between 0 and 1 to emulate the fuzzy nature of
such non-binary matching decision. Again, this power factor is
empirically introduced, whose effectiveness will be proved
through our experimental results to be presented later in this
article.

Next, to estimate H(N,-(G1), NJ-(G2), W1, W2, M), we take into
account two clues: (i) self similarity, i.e. how closely the two
nodes’ carrying text are; (ii) context similarity, i.e. how similar
the two nodes’ surrounding nodes are in terms of their text simi-
larity. To measure the self similarity ¢(N,-(G1), NJ-(G2)) between a
pair of nodes N,-(G1) and NJ-(G2), we ﬁrst implement a method
for estimating content similarity between a pair of sentences. Let
1//(s,-, Sj) e [0, 1] be the semantic similarity for an arbitrary pair of

(4)

sentences s,- and sj. 1//(s,-, sj) = 1 indicates the two sentences deliver
the same semantics, whereas 1//(s,-,sj) = 0 shows the two sen-
tences share no semantic overlap. To derive the value of
1//(s,-,sj), in our current implementation, we adopt the sentence
similarity estimation algorithm proposed in the study by Li et al.
(2006) because of the algorithm’s leading performance among
the peer methods. Based on the function of 1//(s,-,sj), we can
now estimate ¢(N,-(G1),Nj(G2)). Assume N,-(G1) and NJ-(G2)’s
counterpart sentence sets detected from diagrams G1 and G2’s
source documents D1 and D2, are S,(G1) and Sj(G2), respectively.
Also recall that the signiﬁcance for a sentence s,” (va) in
S,(G1) (SJ-(G2)) to embody the meanings intended by the
node N,(G1) (NJ-(G2)) is ,0“ (p13,). We can now estimate
¢(N,~(G1),Nj(G2)) as follows:

¢(Nt(Gl ), Nj(Gz))
1 (5)
= — Z pi,upj, VII/(51,14: Sj, v)
Z(G1’ G2)s,~\,,eS,-(G1)ﬁves/(G2)
where Z(G1, G2) is a normalization term to ensure the maximum
pairwise node similarity across the two graphs G1 and G2 is 1.
To estimate the context similarity of the pair of nodes N,-(G1)
and NJ-(G2), we ﬁrst consider the similarity of the two nodes’
immediately adjacent neighbours, which is denoted as
191,1(N,(G1), NJ-(G2)), as follows:

191,1(N1(G1)JVj(G2))
= Z Z w1,.-,.w2,,-,V¢(N..(Gl),N162», (6)

Nu(G1)EN(G1) Nv(G2)EN(G2)

where WU,“ and W2,” are the short notations for W,,u(G1) and
W!" V(G2), respectively.

Similarly, we can estimate the similarity between one
node’s immediate neighbour node and the other node’s
second-level neighbour node. In analogy to the deﬁnition of
191,1(N,(G1), NJ-(G2)), we can further deﬁne 191,2(N,(G1), NJ-(G2))
and 192, 1(N,-(G1), M(G2)) as follows:

191,2(Nt(Gl), Nj(GZ)) =

ZNxGoeMGI) ZNV(Gz)eN(Gz) ZM<Gz>eN<Gn<WLWWZJ’ V (7)
W2, v, X¢(NM(GI )9 NX(G2)))9

192, 1(N1(G1): Nj(G2)) =

ZN.(Gl)eN(GI) ZNv(G1)EN(G1) ZNV(Gz)eN(Gz)(W‘"3"WI’N
W2,j,v¢(Nx(Gl)s

(8)
Similarly, we can further deﬁne 192,2(N,(G1), M(G2)), whose ex-
plicit form is omitted because of space limit. By aggregating all
the aforementioned sub-estimates, we can derive the context
similarity for the pair of nodes N,-(G1) and NJ-(G2), denoted as
19(N,-(G1), M(G2)), as follows:

29(NI(G1)JVJ-(Gz))= Z Z 29.,.(M(GI),N.-(Gz)). (9)

u=l,2v=l,2

In our method, we do not calculate 29",,(N,(G1), NJ-(G2)) for u>2
or v>2 because their values are almost always 0.

 

784

112 /310's112u1n0fp101x0"sotwuuqutotq/ﬁduq 111011 pap1201um0q

9103 ‘0g isnﬁnV uo ::

Biomedical diagram similarity estimation

 

Finally, by combining aim-(GI), M62» and tam-(GI), M62»,
we can estimate H(N,-(G1), NJ-(G2), W1, W2, M) as follows:

  W19 W29 

10
=Kexp{¢(M(G1)J\G(Gz))+19(N1(G1)J\G(Gz))}, ( )

where K is a fixed constant. Substituting Equation (10) into
Equation (4), we further have:

argmax H(N(G1), N(G2), W1, W2, M)
M

|N(G1)||N(G2)|
= arg max: EMU log(H(N,-(G1), Nj(G2),W1,W2,M))
i=1 j=l
|N(G1)| |N(G2)|
= arg max 2 Z MAJ-(logic
i=1 j=l
+ ¢(N1(G1)a Nj(G2)) + 19(N1(G1)a Nj(G2)))-
(11)

To calculate the optimal matching matrix M, we first create
a |N(G1)| x |N(G2)| dimensional matrix 1%, whose element on
the i-th row and j-th column, is“, takes the value of
log K + ¢(N,-(G1), NJ-(G2)) + 29(Nl-(G1), NJ-(G2)). We thus have:

|N(G1)| |N(G2)|

Mzargmax Z Z Mi,er,j- (12)
i=1 j=l

As M is a matching matrix, it has the property that
2]. ML]- 5 1 and 21M,”- 5 1 for all i and j. The inequality in
the constraints is introduced for handling the situation that an
element from a diagram shall not be matched to any element in
the other diagram to yield an optimal matching between the two
diagrams. To solve the aforementioned optimization problem,
we can use linear programming to find the optimal matching
matrix, M, that maximizes Z]:(1G‘)IZI.:(IG2)IMMNU. Once we
derive M, we can further derive the value of H(G1,G2,IVI) as

the similarity between the two diagrams G1 and G2. For infor-
mation retrieval tasks that only care about rankings where the
absolute similarity value is not important, it sufﬁces to use the
optimized target function value yielded in the linear program-

ming procedure, i.e. 21.2fm ZIEEGZN [IAIN-th, as the estimated

similarity for the two diagrams G1 and G2. Figure 1 gives an

example of the optimized matching matrix constructed by our
method for a pair of sample input diagrams.

5 EXPERIMENTATION

5.1 Experiment set-up

To explore the effectiveness of our new diagram similarity esti-
mation method for diagram retrieval, we conducted a set of
evaluation experiments using a PC equipped with a Core i3
2.93GHz CPU and 4GB main memory, which ran the
Windows XP operating system. To carry out our experiments,
we first constructed a diagram image corpus where each diagram
is accompanied by its corresponding source document. We
acquired these images and their source documents through
both downloading from PubMed Central (PMC) and using
Google Image Search as follows: (i) we ﬁrst downloaded all

the publicly accessible images from PMC where each image is
always accompanied by its source document. We then applied
the diagram image recognition algorithm proposed in the study
by Qin et al. (2010) to identify diagrams from all downloaded
images. This procedure lets us acquire 12500 diagrams. (ii) We
then randomly selected 50 diagrams downloaded from PMC in
the first step and fed the captions of these images, respectively, as
queries into Google Image Search. For each search result image,
Google always provides a back link to its source webpage.
Following the back link, we can check whether the search
result image is associated with a meaningful source document.
In this operation, we ﬁrst removed all the advertisement and
navigation content from an image’s source webpage using the
algorithm proposed in the study by Ntoulas et al. (2006). If the
ﬁltered webpage contains >500 words, we then consider the web-
page as a meaningful document. Otherwise, we discard the
search result image. For all the images that passed the preceding
test, we ran the algorithm of Qin et al. (2010) to detect and select
all images of the diagram type and added them into our diagram
corpus. Using the second approach, we acquired ~3000 add-
itional diagrams through Google Image Search.

To experimentally explore the performance of a diagram re-
trieval method, we conducted a collection of diagram image
search sessions, which were organized into 16 groups of queries,
where each query group consists of multiple query sessions on a
common theme. The 16 querying themes are, respectively, as
follows, for which we also specify the number of query sessions
performed for each theme group using a number in the bracket
following the theme’s topic phraseia: breast cancer (9), b: gas-
tric cancer (9), c: non-Hodgkin’s lymphoma (9), d: multiple mye-
loma (9), e: HIV (8), f: detection of chronic kidney (9), g: heart
block (9), h: malaria (8), i: thrombosis (8), j: angiogenesis (8), k:
tumour angiogenesis (8), l: ochrobactrum (8), m: gene expression
(8), n: cardiomyopathy (8), o: respiratory syndrome (9) and p:
bone metastase (9). Query theme groups a4: primarily consist of
images acquired through Google Image Searches; query theme
groups dim mostly consist of images downloaded from PubMed;
the remaining query theme groups, i.e. groups n, o and p, contain
images acquired through both means more evenly. For each
query session, we randomly selected an image from our diagram
corpus whose caption matches the session’s theme phrase as the
query input image. We then performed diagram retrieval against
the whole diagram corpus (excluding the selected query input
image) using a retrieval method whose performance is to be
evaluated.

5.2 Experimental results

After the aforementioned procedure, we then applied the new
diagram similarity estimation method introduced in this article
for diagram retrieval and ranking. In each query session, we rank
all the retrieved diagram search results according to each result
diagram’s estimated relatedness to the query diagram. We then
recruited five subjects and asked each of them to independently
label the relatedness of each search result diagram to the input
query diagram according to each subject’s personal judgment
regarding the two diagrams’ semantic similarity. The numeric
label ranges from 0 (entirely irrelevant) to 1 (extremely related).
We then took an average of the ﬁve user labels as the image’s

 

785

112 /310's112u1n0fp101x0"sotwuuqutotq/ﬁduq 111011 pap1201um0q

9103 ‘0g isnﬁnV uo ::

S.Xu et al.

 

overall user-rated query relevance score. Based on this score, we
further calculated the normalized discounted cumulative gain
(NDCG) to measure the quality of diagram retrieval and ranking
for the query session. To understand the deﬁnition of NDCG, we
ﬁrst need to introduce the notation of discounted cumulative
gain (DCG), which measures the information retrieval quality
of a ranked search result set. DCG takes into consideration the
query-relevance of each search result document along with its
ranking position in the result list. The DCG score at a particular
rank position 1) can be computed as:
P 2m],- _ 1

DCGP _  Og2(i+ 1), (13)
where rel,- is the average user-rated query relevance of the search
result item ranked at the position i in the list. Based on the no-
tation of DCGP, we can further calculate the NDCG score for a
ranked search result set at a particular rank position 1) as follows:

DCG
ND 2 P
CGP IDCGp ’

 

(14)

where IDCGp is the ideal (maximum) DCG score at the rank
position 1) reachable by the current search result set. For more
thorough discussions on the NDCG metric, readers are referred
to Jarvelin and Kekalainen (2002). In this article, we adopted
NDCG as our retrieval performance metric following the pre-
dominant practice in the information retrieval research ﬁeld be-
cause such metric gives weighted considerations to search result
items at different ranking positions, prioritizing those displayed
at the top positions of the list. Plenty of information retrieval
research, e.g. Jarvelin and Kekalainen (2002), has pointed out
that the NDCG metric can better reﬂect the search quality per-
ceived by end users than the traditional precision-based evalu-
ation, which ignores rank positions. For all our experiments
reported in this article, we use NDCG20 as the metric, as we
empirically find it behaves most representatively among all ver-
sions of the NDCG scores for our application.

For comparison purposes, we also applied the following peer
image search methods to repeat the image search experiments
described earlier in the textiPeer Method (PM) 1: each image
is represented using its caption text. We then used the text search
engine Lucene to retrieve and rank images, whose ranking mech-
anism is described with details in the study by Hatcher and
Gospodnetic (2004). PM 2: the method is to use the text present
in title, description and tags of the images for improving the
results obtained with a standard content-based search (Barrios
et al., 2009). PM 3: each image is represented using its caption
text and its visually embedded text, as well as the image’s an-
choring text, i.e. the sentence(s) in the source document that
directly quotes the image. This is the image search method pro-
posed in Xu et al. (2008). The weighting for mixing the three
types of text in the ranking process is also manually tuned to
maximize the total NDCG score of the method for all our tested
queries. PM 4: the biomedical image metadata manager system
proposed by Korenblum et al. (2011) that retrieves similar bio-
medical images using semantic metadata features. PM 5: a
state-of-the-art process model diagram search method proposed
by Li and Hsu (2008). When conducting all sessions of our com-
parative experimental studies, we used the same target diagram

corpus when executing the ﬁve peer methods and our algorithm
to ensure fair comparison among all methods.

To explore the diagram retrieval performance of the new
method with respect to the ﬁve peer methods, we conducted a
series of diagram search experiments using the aforementioned
16 theme groups of diagram query sessions. Figure 2 reports
NDCG scores of both our method and that of the ﬁve peer
methods in all these experiments, where the NDCG score of
each method for every query is individually reported. We also
congregated these individual NDCG scores to derive the distri-
butions of all NDCG scores attained by our method and the five
peer methods in all our querying experiments, whose distribu-
tions are reported in Figure 3 using boxplots. All the aforemen-
tioned experiment results clearly show that our new diagram
similarity estimation method performs significantly superior to
all peer methods for searching and ranking diagram images.

To further verify our method’s performance superiority to the
peer methods, we calculated P-values for the paired t-test follow-
ing the well-established procedure in statistic hypothesis testing.
We tested a series of null hypotheses that the performance of our
method and that of a speciﬁc peer method is statistically equal. In
Table 1, we report the P-values as results of two-tailed paired t-
tests for diagram querying experiments of 16 theme groups. More
concretely, for each query theme group, we executed all its con-
stituent query sessions using our method and the ﬁve peer retrieval
methods, respectively. Without loss of generality, let’s focus on the
first peer method PM1 initially. For every query session, we paired
the NDCG scores for the top 20 diagram retrieval results obtained
by our method with those returned by PM1 according to their
respective rank positions. That is, every query session will produce
20 pairs of NDCG scores. For each query session in the ﬁrst query
theme group, we repeated the same process and collected all the
resultant NDCG score pairs. This gave us 180 pairs of NDCG
scores because there are nine query sessions in the ﬁrst query
theme group. Given these NDCG score pairs, we can then
derive the P-values for the two-tailed paired t-test comparing
the retrieval quality of our method and that of PM1 for the
whole query theme group. The aim is to test the statistical signiﬁ-
cance of the superiority of our method with respect to PM1. The
result is reported in the tabular cell under the column ‘Ours-PMl’
and on the row for the ﬁrst query theme group in Table 1. To fill
the entire table, we repeated the aforementioned procedure for
comparisons against all the peer methods and query theme
groups. In Table 2, we further report P-values for both one-
tailed and two-tailed t-tests for all 16 theme groups of query ex-
periments. To calculate the P-values, this time we collected all
paired NDCG scores comparing our method and one of the
peer methods across all query sessions in all query themes.
Overall, among all P-values reported in Table 1, almost all of
them are <0.05, except for a few ones that are marked in bold.
In Table 2, all calculated P-values both for the one-tailed and two-
tailed t-tests are <0.05. These small P-values consistently indicate
a statistically significant superiority of our method with respect to
the peer methods in retrieving diagrams semantically relevant to
the input query diagram.

To explore the diversity in the search result diagrams, we fur-
ther calculate the distributions of co-author distances among top
ranked diagram retrieval results returned by our method. The
purpose is to verify that the new algorithm is capable of

 

786

112 /310's112u1n0[p101x0'so1112111101u101q//:d1111 111011 pap1201um0q

9103 ‘0g JSanV 110 ::

Biomedical diagram similarity estimation

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

It
1 1 1 ,1, 1 1 1 1 1
0.9 7 1 0.9 0.9 1.. . 0.9 0.9 0.9 0.9 0.9
0.0 g 110.0 1. i 0.0: . 0.0 . 0.0 0-0 0.0 0-0
0 0.7 at :0: . 30.7 .¢ “0.7 - t 0.7 .4 0.7 . H 0.7 0.7 _
:5 0.0 :0. 0.0% ;:-xo.0 i _g.- 0.0% I ><0.0 3- 0.0 . . x 0.0 '3 0-0 _
3 0.5 04:00.5 . . 0.51:... 0.5 $03 30.5 $0.: 0.5 _‘lx 0.5 _x0.5 f3 h
1, 0.4 "gt-30.41; :o'§0.4* _ -><0-4+-__" gong '9 0-4 *.><0.4 tg-x0-4 __l =§
g 0.3 30.3 ..:0:>< 0.3 igﬂxosgih 0.3 $18. 0.3 |">< 0.3 $3.503 1E -
z 0.2 0.2 $0.2 “50-2 70.2 - 0-2 i .g 0.2 030.2 I g
0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
0123450 0123450 0123450 123455 0123450 123455 0123450 01234510
__,_. ._.,# ._.,_, __,_. ._.,_, ._,_, EM
0 b c d e f g h
IL
1 1 1 1 1 1 1 1
0.9 0.9 0.9 0.9 0.9 0.0 0.9 0.9
o 0.0 0.0 0.0 0.0 0.0 - 0.31 0.5 0.3
:5 0.7 0.7 __ 0.7 0.7 0.7 0.7 0.7 0.7 .
:3 0.0 io‘ 00 J: ' 00*. " 0.0% I 0.01,+ 0.0K  0.0; 3 0.0 . .1
3 0.5 -§ x05 ' _ 05 'E- 0.5 $-: 0.5 i-g 0.5 “t I 0.5 i {Masaié8 _
o 0.4 41 IgUA $ ‘ $0.4 - I$0.4 $30 0.4 :1: l§0.4*$33 04:41! x04 2 ﬁg
2 0.3 i 35x03 $o has 33- 0.3 E 0.3 L037: 0 E00 ivﬁas +3.”
0.2 I § 0.2 o - w 0.2 ' I x 0.2 0.2 0.2 0.2 ¢ Ix 0.2 “ - x
0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
1ﬁgﬁ_ 123450 1234i, 0123115 amuse c'123450 l31.23450, u123450
i j k I m n 0 p
1 Ours I  Peer men-1001 ‘ |. Peer method: ‘ [9 Peer meth003 ] ]. Peer method-I I ] X Peer methods

 

 

Fig. 2. NDCG scores for all querying experiments of 16 theme groups performed using our method and the peer methods, respectively

 

 

 

 

T
0.7- I
T
0.6- I +
I
e
8 05. I T
8 I I — | _l_ ‘I'
o ' I
D | _
2 0.4- | ' I
_I_ |
+ _I_ _|_
_I_
0.3- _I—
+ _I_
0.2- +
Ours PM1 PM2 PM3 PM4 PMS

Fig. 3. Distributions of NDCG scores of our method (Ours) and the ﬁve
peer methods (PMlePMS) in all our diagram querying experiments

retrieving diagrams composed by people sharing weak or no
collaboration relationships. That is, the algorithm will indeed
retrieve diagrams according to their semantic similarity rather
than common diagram composition styles or practice shared
by people who are academically closely related. Let
Damhor(AX,Ay) be the co-author distance between a pair of au-
thors AX and Ay. In this work, we derive the co-author distance
between a pair of authors by checking all the publication records
in the open access portion of the PubMed corpus.
Damhor(AX,Ay) = 0 if and only if AX is the same person as Ay;
Damhor(AX, Ay) = 1 if AX and Ay at least co-author one article as
captured in the corpus; for the general case, we used the classic
Dijkstra’s shortest distance algorithm to compute
Damhor(AX,Ay). Based on the notation of Damhor(AX,Ay), we

Table 1. P-values for two-tailed, paired t-tests for search results of 16
query themes using our method and the ﬁve peer methods

 

 

Theme Ours-PM1 Ours-PM2 Ours-PM3 Ours-PM4 Ours-PMS
number

1 6.72E-6 9.77E-6 0.00418 9.84E-8 4.02E-7
2 4.69E-6 8.54E-8 0.42255 9.62E-8 0.00025
3 2.03E-5 7.47E-7 1.33E-6 1.52E-6 1.96E-7
4 0.02707 0.0502 0.96529 0.00092 3.14E-5
5 0.52284 0.09693 0.06315 0.53414 0.00039
6 7.35E-6 1.53E-9 2.42E-10 4.60E-8 3.03E-9
7 7.26E-10 0.27657 0.21753 0.0039 0.0074

8 6.69E-10 1.42E-9 1.97E-8 1.88E-8 6.28E-12
9 3.17E-7 2.68E-9 9.58E-8 3.48E-11 1.46E-12
10 0.00074 0.00174 4.15E-5 1.26E-5 6.17E-7
11 1.19E-6 8.51E-9 4.88E-7 2.04E-7 1.42E-8
12 1.46E-11 3.20E-11 4.16E-6 6.03E-8 5.82E-10
13 3.59E-8 3.83E-8 6.36E-7 3.28E-8 1.08E-8
14 2.08E-5 0.00708 0.00651 0.45278 2.98E-5
15 8.76E-8 1.14E-6 0.0017 6.16E-7 5.29E-7
16 5.05E-6 8.63E-8 4.20E-6 4.88E-7 8.42E-8

 

The ﬁrst column lists the query theme number.

Table 2. P-values of paired t-tests with both one-tailed and two-tailed
settings

 

 

Type Ours-P1 Our-P2 Ours-P3 Ours-P4 Ours-P5
One-tailed 0.00475 0.00631 0.02423 0.00239 0.00117
Two-tailed 0.00949 0.01263 0.04845 0.00478 0.00234

 

 

787

112 /310's112u1n0[p101x0'so1112111101u101q//:d1111 111011 p3p1201um0q

9103 ‘0g JSanV 110 ::

S.Xu et al.

 

 

 

 

 

 

  
     

. w 7 2‘ /' ‘
0—2 3—5 6—8 9—1 1 12—20 20—inI
image co—author distance

 

 

 

 

 

 

 

 

   

 

0—2 3—5 6—8 9 1 12—20 20—inf

image co—author distance

Fig. 4. Distributions of image co-author distances among top diagram
search results by our method. We derive the image co-author distances
between an input diagram and its top 20 search results returned by our
method. For all query sessions in a query theme group, we compute the
percentage distribution of these distances. The upper sub-ﬁgure shows
such distributions for the query theme groups 178 (labelled as ‘51’7‘58’,
respectively), and the bottom sub-ﬁgure shows results for the query theme
groups $16 (labelled as ‘s9’7‘sl6’, respectively). The horizontal axis
indicates a speciﬁc image co-author distance range, where the last
(rightmost) one corresponds to the distance value range of (20, 00)

can further deﬁne the co-author distance between a pair of bio-
medical images DimageUX, 1y). Two images’ co-author distance is
deﬁned as the minimum co-author distance between one of the
authors of one image’s source document with one author of the
other image’s source document. Formally, let the source docu-
ments to which the two images IX and [y are embedded be Docx
and Docy, respectively. Let the lists of authors of Docx and Docy be
AX = {AX1,AX2, ---,Axn} and A = {Ay1,Ay2, ---,Aym}, respect-
ively. We then deﬁne Dmge (IX, I y) to be
DimageUX, 1y) =minAxeAx, AyeAy Damhor(AX, Ay). For each of the 16
theme groups of query sessions conducted in our experiments, we
collected all images that were ranked among the top 20 search re-
sults by our method in at least one of the query sessions. We then
computed the distribution of image co—author distances between the
input diagrams and their corresponding search result diagrams for
all executed query sessions. In Figure 4, we report the percentage
distribution of image co-author distances for each query theme
group, respectively. From the reported results, we can clearly see
that the new algorithm is able to retrieve semantically related dia-
grams regardless of whether these diagrams are composed by people
that are closely related academically.

6 CONCLUSION AND DISCUSSIONS

We propose a novel context-based method for estimating dia-
gram similarity. The method augments concepts and their

relationships illustrated in a diagram by leveraging the contextual
information provided by the full text of the diagram’s source
document. As a diagram usually highlights rather than explains
its intended message, expanding the concisely encoded message
by cross-referring to the diagram’s source document can supply
rich supplementary context for more accurately and comprehen-
sively understanding the diagram’s intended semantic meanings.

The comparative experiments demonstrate the superiority of
our new method for semantically oriented diagram similarity
estimation with respect to traditional image similarity metrics,
which do not explore such context information. Our enhanced
diagram similarity estimation can beneﬁt many information re-
trieval tasks dealing with diagrams, e.g. improving user experi-
ences with digital library systems for diagram searching and
diagram browsing-based visual literature navigation.

The main challenge of estimating the similarity of diagrams
embedded in the biomedical literature lies in the following two
aspects: (i) unlike diagrams used in the software engineering and
many other engineering disciplines that are typically composed
of parametric objects using the Uniﬁed Modelling Language
(UML) or other specialized languages or software packages
and, hence, amenable to automatic computer processing, dia-
grams in the biomedical literature are typically released as
bitmap images with no high-level descriptive representation.
Therefore, detecting, extracting and automatically understanding
entities and their mutual relationships graphically encoded in
these bitmap images present a non-trivial technical challenge.
To address this issue, we introduce a series of advanced image
processing procedures in Section 3.2. For diagrams embedded in
the biomedical literature, we witness the novel opportunity of
observing and borrowing the context in a diagram’s source docu-
ment to acquire informative semantic clues for enhancing auto-
matic diagram understanding and similarity estimation. Such an
opportunity is unique for diagrams carried inside a peer-reviewed
research publication because the document usually contains
high-quality text that explains its embedded diagrams (such
property does not always exist for diagrams from other sources,
e.g. those included on casual webpages, as they usually do not
have rich and quality explanation text). To leverage the afore-
mentioned opportunity for enhancing automatic biomedical dia-
gram understanding and similarity estimation, we thus
introduced a novel and advanced diagram similarity estimation
method by incorporating the rich semantic context information
supplied in a diagram’s source document (see Section 4).

Finally, in terms of the applicability of our method, even
though the new method aims to process diagrams embedded in
the biomedical literature, it can be applied for dealing with dia-
grams in the literature of other science or technology fields.
Nevertheless, we notice that many science and technology
fields do not use diagrams as intensively as by the broad biomed-
ical discipline, which affects the potential of our method in pro-
cessing diagrams in these ﬁelds. One fundamental limitation of
our method is that it does not work with stand-alone diagrams
that do not have accompanying source documents.

Funding: National Natural Science Foundation of China
(NSFC) (60903132); National Key Basic Research and
Development Program of China (973) (2013CB329505); NSFC-
Guangdong Joint Fund (U1201252, Ull35003 and U0935004);

 

788

112 /310's112u1n0[p101x0'so1112111101u101q//:d1111 111011 p3p1201um0q

9103 ‘0g JSanV 110 ::

Biomedical diagram similarity estimation

 

National Natural Science Foundation of China (61232011);
National Key Technology R&D Program (2011BAH27B01).

Conﬂict of Interest: none declared

REFERENCES

Barrios,J. et al. (2009) Text—based and content—based image retrieval on ﬂickr:
Demo. In: Proceedings of the 2009 Second International
Workshop on Similarity Search and Applications. IEEE Computer Society,
pp. 15(r157.

Belkin,N. (2008) Some (what) grand challenges for information retrieval. ACM
SIGIR Forum, 42, 47754.

Choi,J. et al. (2010) Automatic face annotation in personal photo collections using
context—based unsupervised clustering and face information fusion. IEEE Trans.
Circuits Syst. Video T echnol., 20, 129271309.

Dijkman,R. et al. (2011) Similarity of business process models: metrics and evalu—
ation. Inf. Syst., 36, 4987516.

Ehrig,M. et al. (2007) Measuring similarity between semantic business process
models. In: Proceedings of the Fourth Asia—Pach Conference on Comceptual
Modelling—Volume 67. Australian Computer Society, Inc, pp. 71780.

Fisher,M. and Hanrahan,P. (2010) Context—based search for 3d models.
ACM Trans. Graph., 29, 182.

Hatcher,E. and Gospodnetic,O. (2004) Lucene in Action. Manning Publications,
Greenwich, CT.

Jirvelin,K. and KekiliinenJ. (2002) Cumulated gain—based evaluation of IR tech—
niques. ACM Trans. Inf. Syst., 20, 4224146.

Korenblum,D. et al. (2011) Managing biomedical image metadata for search and
retrieval of similar images. J. Digit. Imaging, 24, 7397748.

Lawrence,S. (2000) Context in web search. IEEE Data Eng. Bull, 23, 25732.

Li,C. and Hsu,C. (2008) Image retrieval with relevance feedback based on
graph—theoretic region correspondence estimation. IEEE Trans. Multimed, 10,
4477456.

Li,C. et al. (2008) On measuring process model similarity based on high—level change
operations. In: Proceedings of the 27th International Conference on Conceptual
Modeling ( ER ’08). Springer—Verlag, Berlin, Heidelberg, pp. 2487264.

Li,Y. et al. (2006) Sentence similarity based on semantic nets and corpus statistics.
IEEE Trans. Knowledge Data Eng., 18, ll38r1150.

Liu,L. et al. (2010) Interleukin—8— 251 a/t gene polymorphism and gastric
cancer susceptibility: a meta—analysis of epidemiological studies. Cytokine, 50,
3287334.

Lopes,C. (2009) Context—based health information retrieval. In: Proceedings of the
32nd international ACM SIGIR conference on Research and development in
information retrieval, ACM, pp. 8457845.

Luo,J. et al. (2009) Integration of context and content for multimedia management:
an introduction to the special issue. IEEE Trans. Multimed, 11, 1937195.

Madhusudan,T. et al. (2004) A case—based reasoning framework for workﬂow
model management. Data Knowledge Eng., 50, 877115.

Meekers,D. and Rahaim,S. (2005) The importance of socio-economic context for
social marketing models for improving reproductive health: evidence from 555
years of program experience. BMC Public Health, 5, 10.

Melnik,S. et al. (2002) Similarity ﬂooding: a versatile graph matching algorithm and
its application to schema matching. In: Proceedings. 18th International
Conference on Data Engineering, 2002. IEEE, pp. 1177128.

Minor,M. et al. (2007) Representation and structure—based similarity assessment for
agile workﬂows. In: Case—Based Reasoning Research and Development Lecture
Notes in Computer Science Volume 4626. Springer—Verlag, Berhn Heidelberg,
pp. 224238.

Moskovitch,R. et al. (2007) A comparative evaluation of full—text, concept—based,
and context—sensitive search. J. Am. Med. Inform. Assoc., 14, 164474.

Nejati,S. et al. (2007) Matching and merging of statecharts speciﬁcations. In:
Proceedings of the 29th International Conference on Software Engineering.
IEEE Computer Society, pp. 54—64.

Ntoulas,A. et al. (2006) Detecting spam web pages through content analysis. In:
Proceedings of the 15th International Conference on World Wide Web, ACM,
pp. 83792.

O’Hare,N. and Smeaton,A. (2009) Context—aware person identiﬁcation in personal
photo collections. IEEE Trans. Multimed, 11, 2207228.

Qiao,L. and Feng,Y. (2012) Genetic variations of prostate stem cell antigen (PSCA)
contribute to the risk of gastric cancer for eastern Asians: a meta—analysis based
on 16792 individuals. Gene, 493, 83791.

Qin,K. et al. (2010) A uniﬁed approach based on hough transform for quick de—
tection of circles and rectangles. J. Image Graph, 15, 1097115.

Rodriguez—Esteban,R. and Iossifov,I. (2009) Figure mining for biomedical research.
Bioinformatics, 25, 208272084.

Segev,A. and Toch,E. (2009) Context—based matching and ranking of web services
for composition. IEEE Trans. Serv. Comput., 2, 21(P222.

Sinha,P. and Jain,R. (2008) Semantics in digital photos: a contextual analysis. In:
2008 IEEE International Conference on Semantic Computing. IEEE, pp. 5&65.

Wendling,L. and Tabbone,S. (2003) Recognition of arrows in line drawings based
on the aggregation of geometric criteria using the choquet integral. In: 2003.
Proceedings. Seventh International Conference on Document Analysis and
Recognition, IEEE, pp. 2997303.

Wombacher,A. (2006) Evaluation of technical measures for workﬂow similarity
based on a pilot study. In: Proceedings of the 2006 Confederated International
Conference On the Move to Meaningful Internet Systems: C00pIS, DOA, GADA,
and ODBASE ( 0DBASE’06/0T M ’06 ) — Vol. I. Springer—Verlag, Berlin,
Heidelberg, pp. 2557272.

Xu,S. and Krauthammer,M. (2010) A new pivoting and iterative text detection
algorithm for biomedical images. J. Biomed. Inform., 43, 924e931.

Xu,S. et al. (2008) Yale image ﬁnder (YIF): a new search engine for retrieving
biomedical images. Bioinformatics, 24, 196871970.

Yang,L. et al. (2011) Object retrieval using visual query context. IEEE Trans.
Multimed, 13, 129571307.

Yang,X. et al. (2010) Mobile image search with multimodal context—aware queries.
In: 2010 IEEE Computer Society Conference on Computer Vision and Pattern
Recognition Workshops ( C VPR W), IEEE, pp. 25732.

 

789

12 /310's12u1n0fp101x0'so112111101u101q//:d1111 111011 p3p201um0q

9103 ‘0g1sn8nv 110 ::

