BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

C. C.Berry et al.

 

We also present a limited comparison with a machine learning
technique that recursively splits data from a chromosome to
form genomic intervals (Olshen et al., 2004).

2 METHODS
2.1 FDRs for vector clumps

Figure 1 provides an example of the ISs, their locations on the chromo-
some and the windows that overlie them for one clump. Referring to it
ﬁrst may ease reading the details here. Clumps are formally deﬁned in
Supplementary S2 (Section 3). The datum representing one IS in a com-
parative study has three components: (i) the chromosome on which it is
located (e.g. ‘chr1’), (ii) the position on the chromosome as the count of
bases from the short end or pter (e.g. 147 251 235) and (iii) an indicator
of which vector was used (e.g. 0 for vector A, 1 for vector B). Typically,
thousands of ISs are collected using each vector (lest the experiment be
uninformative), and the basic data form a table with one row for every

Final Clump

 

Depth 1

 

 

 

 

 

 

 

 

 

24 l 26

Mse 0
Avr A

 

 

 

 

 

 

 

 

32800000 33000000 33200000 33400000 33600000

Chr17 : 32720845 - 33728995

Fig. 1. Clustering of ISs by recovery method. A region of chromosome 17
is shown and marked by locations of HIV vector ISs recovered by each of
two methods (see Section 3.3 for details). Sites recovered after cleavage of
genomic DNA with Mse are marked with circles; those recovered after
cleavage with the Avr cocktail are shown by the triangles. The circles and
triangles are shown evenly spaced along the x-axis (lower middle) for ease
of visualization, then connected by lines to the chromosome scaffold
(bottom) to show their distribution on the chromosome. A clump, or
genomic interval enriched for a recovery method, is discovered as follows:
Windows containing between 15 and 75 sites were tested for enrichment
of Avr or Mse, but only those passing the enrichment test are shown.
Each horizontal bar (upper section of ﬁgure) represents a window that
spans the x-values for a group of sites that show enrichment for Mse. (In
this region, no such group shows enrichment for Avr.) The bars are
grouped together according to the number of sites spanned and the
number of Mse sites required to declare enrichment (see text for details
of how the cutpoints were chosen). Those numbers are given just above
the right edge of each group as a fraction (required/spanned). The depth,
i.e. number of different window size groups over a site, is indicated at the
top. Sites with greatest depth are always included in the ﬁnal clump, but
sites at the edges are screened using a likelihood criterion; in this case
several sites on each side are excluded. Dashed vertical lines enclose the
sites that were ultimately assigned to the clump

IS and three columns for the components just listed. Genomic intervals
that host relatively more IS from either vector (chrl :154 268 327
154272351, say) are of interest, and such intervals would be subjected
to further study using informatic tools, wet bench experiments or moni-
toring in clinical trials. It is natural to describe the intervals in terms of
that sort of molecular address (as long used, e.g. by Abel et al., 2007;
Karlin et al., 1991). However, statistical testing in that coordinate
system can be complicated by nuisance parameters for spatial inhomo-
geneities shared by the two vectors. Treating the spatial order of the
integrations as the coordinate reduces the problem to a Bernoulli pro-
cess (or its generalization when ties are present) that is homogeneous
under the null hypothesis, and a scan using a binomial test can identify
regions in which one vector is overrepresented. For example, if there are
n IS on one chromosome that are ordered by position and the vector
indicators collected into windows for the positions indexed by intervals
{1, ...,w}, {2, ...,w+1}, ..., {n—w+1, ...,n}, the sum of the
indicators in each interval would be compared with cutpoints for the
binomial distribution with w trials and intervals with suitably high or
low counts marked. The process is repeated for the other chromosomes,
and then all is repeated using another choice of w. Marked intervals that
overlap or adjoin are connected to form a single interval or clump. The
number of clumps discovered is R. The value of A is the average number
of clumps discovered under the null hypothesis. Here it is estimated by
the average number of clumps discovered over replications in which the
indicators in the third column of the table described above are permuted
and the procedure just outlined is applied. The FDR is then estimated
by substituting R and that estimate of A into (1).

Many details have been ignored here. These include what values of w
to use, how to choose cutpoints for low and high counts and how to
handle contradictions when a window is overlapped by other windows
favoring each of the vectors. These are discussed in the following sections
and in Supplementary S2 (Sections 3, 4 and 5). Also, the ends of a clump
may contain ISs that do not favor either vector, in which case removing
them from the clump is sensible. Finally, the introduction of a non-
speciﬁc ﬁlter based on the number of bases covered by a window can
improve power (Bourgon et al., 2010) and allows control over the scan
using distance in bases as the coordinate. The ﬁlter is described at the end
of Section 2.2.

2.2 Algorithm for ﬁnding clumps

Two different sets of ISs generated by integration of two retroviral vec-
tors form a N by three table describing locations (chromosome and pos-
ition) and vector indicators. There are N sites, indexed by i = 1, ...,N,
whose locations L = {(1,172) : i = 1, . . . , N} are ordered by chromosome
(1“) and by position (1,2) on each chromosome. The vector that contrib-
utes site i is indicated by m,» = {0, 1}, and local regions will be compared
with the genome-wide background odds of 1m,» : 1 (1 — ml»),
which are determined by experimental design or happenstance but are
not of direct interest. Those background odds are used to establish cut-
points (see Section 2.3) for the counts described in the next paragraph. A
collection of sliding windows of J different widths, {Wj,j: 1, ..., J}
covers the locations. Typically, every one of a range of widths is used,
i.e. wj =wj,1 +1.

Some notation is needed to refer to those windows, the sites they cover,
the counts in the window and all the windows covering a given site. For
each width, the set of overlapping windows has the element Sij that is the

set of consecutive integers {i — wj +1, ..., i}, so SW1 2 {1, ..., W1} is the
ﬁrst window on the ﬁrst chromosome for the narrowest width. For nota-
tional convenience, sets 811 through Swlzm are deﬁned as the empty set

and so is every other 81] whose index 1' appears in the ﬁrst wj — 1 positions
of a chromosome. This convention allows the index i run from 1 to I and
for summation over elements of any Sij (whose sum is 0 for the empty
set). As a notational convenience, let Bj(L) refer to the set of all values of i
for which Sij is a set of w) consecutive integers. Also, some indexes may be

 

1494

ﬁm'spzumofpmjxo'sopeuuopnorq/ﬁdnq

DNA integration clusters

 

removed from Bj(L) and the corresponding Sij converted to the empty set
to filter out collections of sites that sparsely cover a genomic region and
to ensure that sites sharing a common location are not split between
different windows of the same width. The set of sites covered by a

window of width w), also covering site i is Ti]- :  Si/j. Also, Ti]-
indexes width w) windows that overlap Sij. The set of windows that
cover site iis T;- = {1" : ie 8”}.

An initial screening marks each window if the count of one vector is in
a critical region deﬁned by cutpoints (discussed below). If i e Bj(L), the
count m; = Elves” m; is compared with cutpoints to yield
nij = 8(m; : yﬂ) — 8(m; < yﬂ) taking 8(-) as the indicator function and
yﬂ 5 yﬂ as lower and upper critical region cutpoints. Otherwise, nil- : 0,
indicating that the count was neither so high nor so low that the window
is seen to depart from the background odds or that Si]- is the empty set. A
window is considered marked if it has a non-zero value of nif.

All marked overlapping or adjacent windows are gathered to form a
clump unless there are marks that conﬂict according to the vector they
favor. Such conﬂicts are resolved site-by-site in favor of the smallest value
of j for which there is a mark, thereby making the region of conﬂict as
small as possible.

Taking cm 2 1,1': 1, ...,N, then

1'
Cij = H H 8(nijni’j’ Z (DEM/71

i=1 yer.)

that is, 6,) indicates if the windows of width w) overlapping site i are free of
such conﬂicts. ﬁg- : nil-cl]- is corrected for overlap conﬂicts.

The classiﬁcation of sites as being marked by windows of width j is
given by

V1728 0< —8 0>Zﬁfj

v »« », *
zeTf/ zeTf/

which yields values of—l, 0 or 1 according to whether vector 1, neither
vector, or vector 2 is favored, and the overall classiﬁcation of each site is

J J
j:1 j:1

and the covering depth is deﬁned as d,» =  |vij|.

The clumps are non-zero runs in u,-, i.e. clumps are identiﬁed as
Ak = {01.1, ---,ak2}, Where uuklur =1, 01.1 S I‘ S 01.2, (tuba/.2) =
argmaxukl.uk,(ak2 — a“) and 1“li 21%.]. It is sensible to prune these
clumps, as the edges sometimes include sites whose vector proportions
do not differ from the background. Each edge of a run is pruned back
until highest depth is reached and then added back depth-by—depth using
a likelihood criterion to determine the boundary. To do this, the region of
greatest depth is identiﬁed as a“ = min(r) and ﬁkz = max(r), where
a“ 5 (r,s) 5 am and dr 2 supx(dx). The tail regions are added according
to a log likelihood criterion, treating vector identities in the provisional
clump as independent Bernoulli events whose probability is the observed
relative frequency and the vector identities outside the clump as Bernoulli
events whose probability is the background frequency: a“ = arg mianRk
(h(a;‘.1 , r) + g(l‘, ﬁkz» and (Al/{2 = arg maxxesk (h(S, a“) + g(§k1, S», where
Rk = {r I HA1 5 I‘ S 5A1,urdr 7E urildril} and SA = {3151.2 5 S S akz,

uxdxyéuxirldxirl} and h(i,j)=10gp<2£1imk;j—i,rt0) if j>i and 0

gm) = logp(Z{:,mk;j — i+ 1, Zilzimk/(j — i+ 1)),
p(k; n,rt) = 71" (1 — n)"”" is the Bernoulli mass function and the back-

otherwise,

ground value of its parameter often is taken as 710 =  mi/N.

2.3 Choosing cutpoints and setting filters

There are a number of seemingly natural ways to choose the cutpoints for
discovery that would reﬂect departure of vector odds in a window from

genome-wide background odds. A small ﬁxed at level could be used for all
window widths and cutpoints given by the binomial distribution with the
proportion given by the overall frequencies of the two vectors.
Alternatively, a target for expected false discoveries might be set and
the largest at level satisfying it for each window size determined. There
are many other possibilities, and some are discussed in Supplementary S2
(Section 5). Likewise, the fraction of windows to be pre-ﬁltered must
depend to some degree on the experimental content. Section 3.2 illustrates
these considerations using two datasets.

2.4 Software implementation

The geneRxCluster R package implements the algorithm for ﬁnding
clumps and estimating FDRs. The principal function returns a GRanges
object (Lawrence et al., 2013) representing the genomic locations of the
clumps discovered with metadata annotations indicating the number of
sites from each vector and the smallest target for false discoveriesitaken
as the smallest at level times number of windows (lBJ-l) attained by any
window in each clump. This object can interface to the BioConductor
software suite (Gentleman et al., 2004) containing tools for genomic data
analysis, browsing and data display.

The evaluation of ﬁltering rules, counting vectors in windows and
application of cutpoints to obtain the window marks, n,-,~, is straightfor-
ward. The computation of conﬂict indicators, 6,], is implemented as a
ﬁnite-state automaton that traverses the sets of windows covering each
site, Tij, with 1' moving fastest and j in order 1, ...,J. By updating and
downdating counts of nil->0 and nij< 0 (i.e. windows satisfying the crit-
ical region for each vector), counts of favored vector for each Si/j window
in Ti]- and counts of conﬂicts based on lesser values of j, only one refer-
ence to each nif is needed. The order of the computation of all the cf], vi]-
(window class) and u,- (site class) is NJ. Finally, the order of computation
in pruning the clumps depends on the number of points at which pruning
cuts can be made.

2.5 Illustrative datasets

The data used to illustrate the method come from two experiments. In
one (here called ‘Jurkat’, see Wang et a]. (2007) for more details), the ISs
were generated by HIV infection of 50 independent cultures of Jurkat
cells using an HIV-based vector, the DNA of each divided into two ali-
quots, one cleaved by the restriction enzyme MseI (here called Mse, rec-
ognition site: TTAA) and one by a cocktail of three enzymes (here called
Avr, recognition sites: ACTAGT, CCTAGG and GCTAGC). DNA lin-
kers were then ligated onto the free DNA ends, and DNAs were PCR-
ampliﬁed using primers complementary to the linker and the vector DNA
long terminal repeat (LTR). DNA libraries were subsequently pooled,
sequenced and mapped to the hg18 freeze of the human genome
(Lander et al., 2001; Meyer et al., 2013). It is known that the recovery
of ISs after cleavage with a restriction enzyme depends on their j uxtapos-
ition with restriction sites (Alonso et al., 2003; Gabriel et al., 2009; Wang
et al., 2008), so the use of two different sets of enzymes fueled our
expectation that the sites recovered might differ. The other dataset
(named ‘CD4+’) is newly described here and comprises one of the largest
datasets determined for an HIV primary isolate (designated HIV89.6)
infecting primary human T-cells. An analysis of its association with gen-
omic features is presented in Supplementary S1 where it is described in
detail. Brieﬂy, the dataset was generated using three replicate infections
(referred to as Infection I, Infection II and Infection III) of CD4+ T cells
infected with HIV89.6. The DNA from each infection was cleaved with
NLAIII (recognition site: CATG), sequenced and mapped. It was
expected that these replicates would not differ from each other but
would differ from those of the Jurkat experiment.

These datasets usefully illustrate the kinds of variations that might be
anticipated in an actual experiment comparing two gene therapy vectors.
It is important to know if replicates show extra-Bernoulli variation

 

1 495

ﬁm'spzumofpmjxo'sopeuHOJmorq/ﬁdnq

C. C.Berry et al.

 

because this would invalidate the permutation estimate of A. The Avr
versus Mse comparison is expected to illustrate subtle differences that
might mirror a challenging comparison of vectors. The datasets are
large enough (with more than 185 000 distinct ISs) to characterize the
genome-wide variation in integration targeting accurately.

3 RESULTS

3.1 Spatial association versus data source

The 147294 CD4+ and 40 974 Jurkat ISs were ordered by the
genomic locations of the sites of integration (Craigie and
Bushman, 2012) of the viral DNA. Table 1 gives the identity
of the members of each successive pair of integrations under
that ordering. Under the null hypothesis of equal target prefer—
ences and equal recovery of integrations regardless of restriction
enzyme, all rows would be equal. The three ‘Infection’ rows are
equal or nearly so (and X2 = 6.06, 4df, P201948). Jurkat
(Avr and Mse rows and columns combined) differs from
CD4+ (all Infections combined) (X2 = 4894.12,
1df, P<0.0001). Avr and Mse differ from one another
(x2: 183.58, 1df, P<0.0001) to a lesser degree; that they
differ is unsurprising given the bias in the recovery of an IS
that depends on its distance from the relevant restriction site.
The apparent homogeneity of the three infections is expected,
given the use of identical materials and procedures in each rep—
licate. The use of permutation methods to estimate the FDR
would be invalidated by inhomogeneous replicates. So, this ﬁnd—
ing provides support for using permutation methods to compare
ISs from experiments in which all samples of a kind are prepared
from the same starting materials and processed identically. The
difference between the CD4+ data and the J urkat data might be
expected considering that the sources of host cells, the HIV
vector or virus and the restriction enzymes used all differ.

3.2 Tuning the clump discovery parameters

The algorithm requires a collection of window widths and upper
and lower critical regions for each width. Optionally, the analyst
may filter out some windows to improve power or to avoid
regions of low integration density that will usually be of low
interest for assessing risk.

Table 1. Successive pairs of ISs

 

 

IS source Infection Infection Infection Avr Mse Total
I II III

Infection I 0.31 0.27 0.24 0.08 0.10 55 835

Infection II 0.32 0.27 0.23 0.08 0.10 47 553

Infection III 0.32 0.27 0.24 0.09 0.10 42 051

Avr 0.24 0.21 0.18 0.21 0.16 19424

Mse 0.26 0.22 0.20 0.15 0.18 21202

 

Note: Rows identify the source of the site at the lesser chromosomal position and
columns that of the site at the higher position. The cell values are the proportions of
the total given in the last column rounded to two digits (each row adds to 1.0).
Locations occupied by multiple integrations are omitted, as ﬁltering to remove PCR
duplications undercounts independent integrations at the same site in the same
replicate.

What values of these parameters should be chosen? A sensitive
region that is much more attractive to a candidate retroviral
vector may precipitate an adverse event. Current understanding
suggests that sensitive regions are of limited size (e.g. the pro—
moter region and ﬁrst intron of the LMO2 proto—oncogene) and
usually do not cover many megabases. Discovering that a broad
region is modestly more attractive to ISs is not likely to be useful
because it may include subregions of varying sensitivity, and a
modest increment in integrations only modestly increases the
chance that an integration would trigger an adverse event.
However, a narrow region with a high rate of integration can
be inspected (e.g. using a genome browser) for hints that inte—
grations there would heighten risk. So, ﬁnding relatively small
regions with high rates of integration is most useful. Further,
having a few false—positive discoveries will not seriously impede
investigating the risk potential of all discoveries or monitoring
patients for adverse events, such as expansion of clones hosting
sites in discovered regions.

A window covering many more bases than usual for a fixed
number of ISs would not represent a region of high integration
even if only one of the vectors accounted for all sites (unless one
of the two vectors contributed almost all of the ISs). When rates
of integration vary widely across the genome (as typical of many
vectorihost combinations), ﬁltering out such windows can
improve power (Bourgon et al., 2010) and avoid focusing on
regions of low interest. Supplementary S2 and Figures 1 and 2
show that most sites are in regions with lower integration rates,
and the distribution is highly skewed. So, filtering out many of
the sites would seem in order. For now, windows spanning more
than the median number of bases for windows with the same
number of sites are ﬁltered out. For the J urkat data, this means
that windows of 15 sites will span no more than 486 735 bases,
and windows of 75 sites will span no more than 4407 247 bases.
For the combined Jurkat and CD4+ data, the corresponding
limits are 43 519 and 443 665 bases.

Critical regions ought to be chosen to balance true discoveries
with false discoveries. With a given dataset, ﬁltering rule and set
of critical regions, the expected number of false discovered
clumps can be estimated [e.g. by using permutation or subsam—
pling (Bickel et al., 2010) methods]. However, insights useful in
setting critical regions can be had by studying the behavior of
windows of ﬁxed width. Figure 2 shows the critical regions for
two comparisons at selected window widths when the ﬁltering
removes windows exceeding the median number of bases for
each width. The critical regions are chosen so that the expected
number of false discoveries in each tail of each window width is
at most five. Figure 3 shows the relationship between the ex—
pected number for each window width (called target false
discoveries) and the expected false discoveries based on 200 per—
mutations of the data. It seems that choosing the critical regions
to s tisf at < #

a y J—IUi:ls’/|
target, r/2, for the number of falsely discovered clumps divided
by the number of windows after ﬁltering) leads to an expected
number of false discoveries on the order of r. This is not too
surprising: for a single window width, one expects the number of
windows falsely identiﬁed to be r if the mass in the critical
regions sums to exactly 204,, but usually their sum will be some—
what less. The overlap of discovered windows results in the

for each tail (i.e. to have a) smaller than a

 

1496

ﬁre'spzumofpmJXO'sopeuHOJHrorq/ﬁdnq

 

_E_

55,2kgogmoddmmowoxwoagoﬁsambmﬁ

C. C.Berry et al.

 

 

 

 

 

 

 

 

 

 

 

 

 

CD4+ vs Jurkat Avr vs Mse
O
‘_._ #5.... 3— A¢.AAA
A 8 D
g_ :5 gq_  I
A O
‘ E DDS
._ ‘°-— I ._ <o_§ 9 "
a: 0 A IA 0 a: o'
5 - 5 ° u
[L <r__ . A D. . I:-
o o g-
0 o I
N_o A o I H
Al o N._
'00 n o H
g—Senuu an i
LSDLSDLSD LSDLSDLSD
20 40 60 20 40 60
u M

Fig. 4. Power for discovery. Alternatives depend on relative odds
(squares=3-fold, circles=7-fold, triangles=15-fold) and on expected
number of ISs, n and whether odds are increased (solid) or decreased
(hollow) versus background. A lower bound (L) for power is computed
(see text), and power is simulated when the interval is embedded in a
sparsely (S) or densely (D) targeted region. Critical regions are as shown
in Figure 2

The power to detect a difference in the region must be higher
when there are densely populated ﬂanking regions, and the effect
is usually to increase power by ~0. 10 when the power is between
0.1 and 0.9. The lower bound is closer to the simulated values
when u is higher. The bound achieved some very high values, and
when it is <0.60, neither simulated value surpassed 0.80. These
results do not directly depend on the number of bases in the
region of interest, but it should be noted that typically regions
covered by w_,- sites will contain many fewer bases in datasets with
more ISs. The windows for the Jurkat data alone covered 10
times as many bases at their median widths as the combined
CD4+ and Jurkat sites, but the latter set had only 5 times as
many sites. So, power comparisons of different datasets ought to
select u for each set according to the number of integrations in
each set.

Supplementary S2 (Section 5) explores other choices and
methods of finding cutpoints and criteria for ﬁltering that may
be preferred depending on study objectives. One interesting
choice is to set the power required for each w_,- and an odds
ratio; the number of windows passing the filter is adjusted for
each w_,- to meet the target for false discoveries. For small values
of w_,-, only a handful of windows can pass the ﬁlter, showing how
challenging it can be to detect local variations in integration rates
in very small regions.

In summary, there are many options for establishing cutpoints
and ﬁltering criteria. The toolkit provided here allows explor—
ation of different criteria for filtering and establishing cutpoints
and the effects those criteria have on false discovery and power.

3.3 Clump example

Figure 1 shows a clump of ISs comparing Mse with Avr sites in
the Jurkat dataset. Values of w_,- (of 15, 16, . . . , 74, 75) were used.
The target for false discoveries was 0.5 for each tail, and again
windows spanning more than the median number of base pairs
were filtered out. Most of the sites in that clump were recovered
with the Mse method compared with about half in the full data—
set. Seventeen different values of w,- (between 25 and 46) marked
a region containing most of the sites. The likelihood ratio

Table 2. Avr versus Mse FDRs

 

 

Target Clumps discovered FDR
Observed Expected

0.2 4 0.30 0.06

1.0 7 1.24 0.13

2.0 15 2.10 0.13

10 34 8.93 0.26

 

Note: Cumulative number of discoveries (Observed) and false discoveries (Expected)
and the FDR, according to the target for false discoveries.

criterion rejected the six sites at the left (3 Avr, 3 Mse), seven
on the right (3 Avr, 4 Mse) and retained the remainder.

3.4 FDRS

Tables of the discoveries were prepared using targets for expected
false discoveries of 0.2, 1, 2 and 10. Table 2 shows that 34 clumps
were discovered for Avr versus Mse at an FDR of 0.26. In a
comparison of actual gene therapy vectors, this would be a small
enough number of clumps to inspect them one by one using a
genome browser and design wet—bench follow on studies. This
FDR would probably be acceptable in that context. The CD4+
versus J urkat comparison yielded 350 discoveries at an FDR of
0.0176, which if seen in a comparison of candidate gene therapy
vectors would rule out clump—by—clump inspection but allow for
comparisons via statistical analysis and data mining. For the
comparison of each of the CD4+ replicate infections to the
others, there were 6, 6 and 8 clumps discovered with expectations
of 9.84, 8.58 and 8.27, respectively. The results for the CD4+
replicates are thus consistent with all of the clumps being false
discoveries.

The clumps discovered in the Avr versus Mse comparison
at target false discovery 310.0 are shown in Figure 5. The
odds ratio for restriction sites are odds of Mse to Avr for
restriction sites in the region occupied by a clump divided
by its genomic average. Log odds ratios for ISs are calculated

as log(0.5 +  mi) — log(0.5 +  (1 — m0) — log
(no/(1 — 710)) for each clump. The Spearman correlation is
0.697 (P<0.0001). Thus, the availability of restriction sites
strongly affects the vector composition of individual clumps, as
was expected.

With the clumps discovered in hand, there are various options
for the biomedical scientist to develop an understanding of the
mechanisms that caused them or their implications for patient
care. There are 350 clumps discovered when comparing Jurkat
cells with the CD4+ cells. Figure 6 shows the histogram of the
log odds ratios (compared with background) for the two cell
types. There are 117 clumps that favor Jurkat and 233 sites
that favor CD4+. If one were faced with this many clumps in
a comparison of actual gene therapy vectors, it would be possible
to explore the differences between them using data mining tools.
In addition, browsing the regions occupied by the clumps with
extreme log odds ratios might also be productive, as those
regions will be targeted more intensely by one of the vectors.

 

1 498

ﬁre'spzumofpmJXO'sopeuHOJHrorq/ﬁdnq

DNA integration clusters

 

 

log odds ratio - insertion sites

 

 

 

I I I I
—3 —2 —1 0

log odds ratio - restriction sites

Fig. 5. Integration versus restriction sites. Log odds ratios for Mse versus
Avr ISs and log odds ratios for Mse versus Avr restriction sites. See text
for details. Positive values on each axis indicate that Mse sites are
favored. Solid (hollow) dots indicate target for false discoveries
<10 (2 1.0)

The Jurkat clumps range from 1567 to 889570 bases with a
median of 90 254 bases, whereas the CD4+ clumps range from
4299 to 1 108 435 bases with a median of 134158 bases. These
regions are small enough to allow productive use of a genome
browser to inspect them.

4 DISCUSSION

The clumping method provides a ﬂexible toolkit for exploring
local differences in collections of retroviral ISs and for planning
experiments. The comparison of the Avr with Mse recovery
methods may mirror future studies of gene therapy vectorsi
only subtle differences exist but they may have profound impli—
cations for the risk profile of a newly engineered vector.

In clinical trial reporting, the CONSORT criteria (Schulz
et al., 2010) require reporting of the power of the trial for the
pre—speciﬁed endpoint. This report steps in the direction of allow—
ing a deliberative approach to study planning. Supplementary S2
(Section 5) illustrates some of the possibilities of using this toolkit
for planning with an eye toward choosing sensible rules for fil—
tering and sensible cutpoints for discovery.

There are various parameters that affect the discovery of
clumps and the FDRs associated with them. Ideally, these
would be set using prior knowledge and without dependence
on statistics that correlate with the ultimate test statistic
(Bourgon et al., 2010). Optimizing the FDR reported by search—
ing over the parameter space has the potential to introduce
resubstitution bias. When such optimization is desired, strategies
should be implemented, such as training on one set of data and
using an independent test set to validate the clumps discovered.
Further work may explore how sensitive resubstitution bias is to
different parameters.

 

 

 

 

 

 

 

O—
<l'
O—
W)
3
C
a:
3
e 3-
LL
3.
o— l'l'll'il'n'l I'I
I I I I I I I
-6 -4 -2 o 2 4 6

log odds ratio

Fig. 6. Odds ratios for J urkat versus CD4+ sites in each clump. Log odds
ratios are calculated as for Figure 5 (see text). Positive values indicate that
Jurkat sites are favored in the region occupied by the clump

One issue that arises in clinical trials in humans is patient—to—
patient variability in the genome and other host factors that may
yield patient—speciﬁc clumps of integrations. On the one hand,
this challenges clumping methods that depend on assuming
homogeneity among patients, and methods that resample
patients or subsample genomic segments (Bickel et al., 2010)
will be required for estimation of FDRs. Furthermore, planning
for human studies will need to take heterogeneity into account.

Funding: National Institutes of Health (2R01 AIOS2845 and
5R01 AIO82020).

Conﬂict of Interest: none declared.

REFERENCES

Abel,U. et al. (2007) Real—time deﬁnition of non—randomness in the distribution of
genomic events. PLoS One, 2, e570.

Aldous,D. (1988) Probability Approximations via the Poisson Clamping Heuristic.
Springer, New York.

Alonso,J. et al. (2003) Genome—wide insertional mutagenesis of Arabidopsis thaliana.
Science, 301, 653$57.

Bickel,P.J. et al. (2010) Subsampling methods for genomic inference. Ann. Appl.
Star, 4, 166(F1697.

Bourgon,R. et al. (2010) Independent ﬁltering increases detection power for high—
throughput experiments. In: Proceedings of the National Academy of Sciences.
9546.

Craigie,R. and Bushman,F. (2012) HIV DNA integration. Cold Spring Harb.
Perspect. Med., 2, a006890.

Deichmann,A. et al. (2007) Vector integration is nonrandom and clustered and
inﬂuences the fate of lymphopoiesis in SCID—Xl gene therapy. J. Clin. Invest,
117, 222572232.

Gabriel,R. et al. (2009) Comprehensive genomic access to vector integration in
clinical gene therapy. Nat. Med., 15, 143171436.

Gentleman,R.C. et al. (2004) Bioconductor: open software development for com—
putational biology and bioinformatics. Genome Biol, 5, R80.

Hacein—Bey—Abina,S. et al. (2003) A serious adverse event after successful gene
therapy for X—linked severe combined immunodeﬁciency. N. Engl. J. Med.,
348, 25y256.

 

1 499

ﬁlO'SIBHmOprOJXO'SOplZIIJJOJLIIOIQ/ﬂdnq

C. C.Berry et al.

 

Hacein—Bey—Abina,S. et a]. (2010) Efﬁcacy of gene therapy for X—linked severe
combined immunodeﬁciency. N. Eng]. J. Med., 363, 3557364.

Karlin,S. et a]. (1991) Statistical methods and insights for protein and DNA se—
quences. Anna. Rev. Biophys. Biophys. Chem., 20, 1757203.

Lander,E.S. et a]. (2001) Initial sequencing and analysis of the human genome.
Nature, 409, 8607921.

Lawrence,M. et a]. (2013) Software for computing and annotating genomic ranges.
PLoS Comput. Biol, 9, e1003118.

Meyer,L.R. et a]. (2013) The UCSC Genome Browser database: extensions and
updates 2013. Nucleic Acids Res., 41, D64eD69.

Mitchell,R.S. et a]. (2004) Retroviral DNA integration: ASLV, HIV, and MLV
show distinct target site preferences. PLoS Biol, 2, e234.

Olshen,A.B. et a]. (2004) Circular binary segmentation for the analysis of array—
based DNA copy number data. Biostatistics, 5, 5577572.

Schroder,A.R.W. et a]. (2002) HIV—l integration in the human genome favors active
genes and local hotspots. Cell, 110, 5217529.

Schulz,K.F. et a]. (2010) Consort 2010 statement: updated guidelines for reporting
parallel group randomised trials. BMC Med., 8, 18.

Siegmund,D. et a]. (201 1) False discovery rate for scanning statistics. Biometrika, 98,
9797985.

US. Food and Drug Administration, CBER. (2006) Gene Therapy Clinical Trials
Observing Subjects for Delayed Adverse Events. FDA: Maryland.

Wang,G.P. et a]. (2007) HIV integration site selection: analysis by massively parallel
pyrosequencing reveals association with epigenetic modiﬁcations. Genome Res.,
17, 118G1194.

Wang,G.P. et a]. (2008) DNA bar coding and pyrosequencing to analyze adverse
events in therapeutic gene transfer. Nucleic Acids Res., 36, e49.

Wu,X. et a]. (2003) Transcription start regions in the human genome are favored
targets for MLV integration. Science, 300, 174971751.

Zhang,Y. (2008) Poisson approximation for signiﬁcance in genome—wide ChIP—chip
tiling arrays. Bioinﬁ)rmatics, 24, 282572831.

 

1500

/3.IO'S[BIIInOfp.IOJXO'SOIJBLUJOJIIIOICI”Idllq

