Vol. 3018MB 2014, pages i157—i164
doi:1 0. 1093/bioinfonnatics/btu2 75

 

Metabolite identification through multiple kernel learning on

fragmentation trees

Huibin Shen1'2'*, Kai DUhrkopB, Sebastian Booker3 and Juho Rousul'2

1Department of Information and Computer Science, Aalto University, Espoo, Finland, 2Helsinki Institute for Information
Technology, Espoo, Finland and 3Chair for Bioinformatics, Friedrich Schiller University Jena, Jena, Germany

 

ABSTRACT

Motivation: Metabolite identification from tandem mass spectrometric
data is a key task in metabolomics. Various computational methods
have been proposed for the identification of metabolites from tandem
mass spectra. Fragmentation tree methods explore the space of pos-
sible ways in which the metabolite can fragment, and base the me-
tabolite identiﬁcation on scoring of these fragmentation trees. Machine
learning methods have been used to map mass spectra to molecular
fingerprints; predicted fingerprints, in turn, can be used to score can-
didate molecular structures.

Results: Here, we combine fragmentation tree computations with
kernel-based machine learning to predict molecular fingerprints and
identify molecular structures. We introduce a family of kernels capturing
the similarity of fragmentation trees, and combine these kernels using
recently proposed multiple kernel learning approaches. Experiments on
two large reference datasets show that the new methods significantly
improve molecular fingerprint prediction accuracy. These improve-
ments result in better metabolite identiﬁcation, doubling the number
of metabolites ranked at the top position of the candidates list.
Contact: huibin.shen@aalto.fi

Supplementary information: Supplementary data are available at
Bioinformatics online.

1 INTRODUCTION

Metabolomics deals with the analysis of small molecules and
their interactions in living cells. A central task in metabolomics
experiments is the identiﬁcation and quantification of the metab-
olites present in a sample. This is mandatory for subsequent
analysis steps such as metabolic pathway analysis and flux ana-
lysis (Pitkanen et al., 2010). Mass spectrometry (MS) is one of
the two predominant analytical technologies for metabolite iden-
tiﬁcation. Identiﬁcation is done by fragmenting the metabolite,
for example, by tandem MS (MS/MS), and measuring the mass-
to-charge ratios of the resulting fragment ions. The measured
mass spectra contain information about the metabolite, but ex-
tracting the relevant information is a highly non-trivial task.
Several computational methods have been suggested to iden-
tify the metabolites from MS/MS spectra. Mass spectral data-
bases (spectral libraries) have been created (e.g. Hisayuki et al.,
2010; Oberacher et al., 2009; Smith et al., 2005; Tautenhahn
et al., 2012), which allow us to search measured mass spectra.
Unfortunately, this approach can only identify ‘known un-
knowns’ where a reference measurement is available.
Fragmentation trees are combinatorial models of the MS/MS
fragmentation process. Bocker and Rasche (2008) suggested

 

*To whom correspondence should be addressed.

fragmentation trees for identifying the molecular formula of an
unknown compound. Later, fragmentation trees were shown to
contain valuable structural information about the compound
(Rasche et al., 2011, 2012).

The relation between spectral and structural similarities has
been studied by Demuth et a]. (2004). A kernel-based machine
learning approach for metabolite identification was recently
introduced by Heinonen et a]. (2012), relying on predicting the
molecular ﬁngerprints as an intermediate step. Molecular ﬁnger-
prints are given as bit vectors with each bit describing the exist-
ence of certain molecular property such as substructures in the
molecule. After the prediction, imposing some scoring strategy,
the predicted molecular ﬁngerprints are used for searching some
chemical database and finally the ranked list of candidates are
generated (Heinonen et al., 2012; Shen et al., 2013).

Besides these two approaches, methods have been suggested
for predicting MS/MS spectra from molecular structures (Allen
et al., 2013; Kangas et al., 2012); commercial software packages
also exist for this task. Such simulated spectra can be used to
replace the notoriously incomplete spectral libraries by molecular
structure databases (Hill et al., 2008). Combinatorial fragmenta-
tion of molecular structure serves the same purpose (Gerlich and
Neumann, 2013; Wolf et al., 2010). Finally, we can search spec-
tral libraries for similar compounds, by comparing either MS/
MS spectra (Demuth et al., 2004; Gerlich and Neumann, 2013)
or fragmentation trees (Rasche et al., 2012). See Scheubert et a].
(2013) and Hufsky et a]. (2014) for recent reviews.

We propose a joint strategy that combines fragmentation trees
and multiple kernel learning (MKL) to improve molecular ﬁn-
gerprint prediction and, subsequently, the metabolite identiﬁca-
tion. We ﬁrst outline the metabolite identiﬁcation framework
and introduce fragmentation trees and their computation.
Next, we introduce a family of kernels for fragmentation trees,
consisting of simple node and edge statistics kernels as well as
path and subtree kernels that use dynamic programming (DP)
for efﬁcient computation. We then describe state-of-the-art
methods for MKL. In these experiments, we evaluate different
MKL algorithms with regards to the ﬁngerprint prediction and
the metabolite identiﬁcation.

2 METHODS

Figure 1 gives an overview for our metabolite identiﬁcation framework
through MKL. Fragmentation trees are computed ﬁrst, followed by the
computation of kernels. MKL approaches are used to integrate different
kernels for molecular ﬁngerprint prediction. The ﬁnal step of the frame-
work is to query molecular structure databases with the predicted mo-
lecular ﬁngerprint using a probabilistic scoring function.

 

© The Author 2014. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/by/
3.0/), which permits non—commercial re—use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re—use,

please contact journals.permissions@oup.com.

112 /310'S[BIIJHO[pJOJXO'SOTIBLUJOJIIlOlq/ﬂduq uIOJJ papaolumoq

9103 ‘Og isanV uo ::

H.Shen et al.

 

' [twain

 

 

1: ° CD
 c>
- D Build Tree
= W m u.» '2” 
nu; 
J} MS Keme| ® & Fragmentation Tree Kernel

Multiple Kernel Learning based
Molecular Fingerprint Prediction

   

.I .‘3. w In

'1 | : I : : :'I ! I

.r' i

 b 
_ k/ __ ,

3 Molecular Database Retrieval

- - -
PUB- CHEMs

Fig. 1. The metabolite identiﬁcation framework through MKL. First, we
construct the fragmentation tree from the MS/MS spectrum. Second, we
compute kernels for both MS/MS data and fragmentation trees. Third,
MKL is used to combine kernels and predict molecular ﬁngerprints.
Finally, ﬁngerprints are used for molecular structure database retrieval

The advantages of the kernel-based machine learning framework are:
that it easily allows incorporating the combinatorial fragmentation trees
by kernelizing the model; that it can query molecular structure databases
which are much larger than MS/MS spectral libraries; and that molecular
ﬁngerprints can help to characterize the unknown metabolite and may
shed light for de novo identiﬁcation.

2.1 Fragmentation trees

Booker and Rasche (2008) introduced fragmentation trees to predict the
molecular formula of an unknown compound using its MS/MS spectra.
A fragmentation tree annotates the MS/MS spectra of a compound via
assumed fragmentation processes. Nodes are molecular formulas, repre-
senting the unfragrnented molecule and its fragments. Edges represent
fragmentation reactions between fragments, or the unfragrnented mol-
ecule and a fragment. Details on the computation can be found in
Booker and Rasche (2008) and Rasche et a]. (2011); here, we quickly
recapitulate the method. We assume that MS/MS spectra recorded at
different collision energies have been amalgamated into a single spectrum,
as described in Section 3. We decompose all peaks in the amalgamated
spectrum, ﬁnding all molecular formulas that are within the mass accur-
acy of the measurement. For each decomposition of the parent peak, we
build a fragmentation graph which contains all possible explanations for
each peak, where nodes are colored by the peaks they originate from. We
insert all edges between nodes that are not ruled out by the molecular
formulas: that is, a product fragment can never gain atoms of any element
through the fragmentation. Edges of this graph are then weighted, taking
into account the intensity and mass accuracy of the product fragment, the
mass of the loss and prior knowledge about the occurrence of certain
losses.

Under the parsimony assumption, we then compute a colorful subtree
of this graph with maximum weight. Unfortunately, ﬁnding this tree is an
NP-hard problem (Rauf et al., 2012). Nevertheless, we can compute op-
timal trees in a matter of seconds using Integer Linear Programming
(Rauf et al., 2012). For each peak, this tree implicitly decides whether
it is noise or signal and, in the later case, assigns the molecular formula of
the corresponding fragments and the fragmentation reaction it resulted
from. The score of the tree is the sum of its edge weights. Candidate
molecular formulas of the parent peak are ranked by this score, which
is the maximum score of any tree that has this molecular formula as its
root.

Different from Booker and Rasche (2008) and Rasche et a]. (2011), we
used a modified weighting function for the edges of the fragmentation
graph. With these new weights, the above optimization can be interpreted
as a maximum a posteriori estimator of the observed data. We weight
edges by the logarithmic likelihood that a certain fragmentation reaction
occurs: for this, we consider the intensity and mass deviation of the prod-
uct fragment peak, the loss mass and chemical properties of the molecular
formula as proposed in Kind and Fiehn (2007): namely, the ring double
bond equivalent and the hetero atoms and carbon atoms ratio.
Furthermore, we favor a few common losses that were learned from
the data, and penalize implausible losses and radicals. Such weights
have already been used in Booker and Rasche (2008) and Rasche et a].
(2011); different from there, we did not choose parameters ad hoc but
rather learned them from the data. Details about these new weights will
be published elsewhere.

2.2 Kernels for fragmentation trees and MS/MS spectra

2.2.] Probability product kernel Heinonen et a]. (2012) compared
several kernels that can be computed directly from the MS/MS spectra
without the knowledge of the fragmentation trees. In their studies, simple
peak and loss matching kernels were found inferior to the probability
product kernel (PPK). Thus, we use the PPK as the baseline comparison
with the fragmentation tree kernels. The idea of the PPK is the following:
each peak in a spectrum is modeled by a 2D Gaussian distribution with
the mass-to-charge ratio as one dimension, and the intensity as the other.
All-against-all matching between the Gaussians is performed to avoid
problems arising from alignment errors.

Formally, a spectrum is deﬁned as x={x(1), . . . , X(Zx)}, a set of (X
peaks x(k) = (p,(k), [(k)) e R2, (k= 1, . . . ,Zx) consisting of the peak mass
p,(k) and the normalized peak intensity [(k). The k-th peak of the mass
spectrum X is represented by [7an =N(x(k), 2) centered around the peak
measurement and with covariance shared with all peaks

2:01 0
0 a?

where the variances oi for the mass is estimated from data and a? is

tuned by cross-validation. No covariance is assumed between peak dis-
tributions. The spectrum X is ﬁnally represented as a mixture of its peak

_ ' , 4:
d1str1but10ns px = lizkxﬂpxm

x

The PPK eraks (Jebara et al., 2004) between the peaks of two spectra
x, x’ is given by:

Kpcaks(X, XI) : K(px , [7%)

= f 2px(x)pxi(x)dx
IR

_ 1 (Xxxi 1
ZXZX/k’k/:

(X(k) — X’(k’))TYl(X(k) — X’(k’)))-

1
1 4:10,, a, exP(— 2

 

i158

112 /310'S[BHJHOIPJOJXO'SOIJBLUJOJIIIOICI”Zduq 11101} papaorumoq

9103 ‘Og isanV uo ::

Metabolite identification through MKL

 

The precursor ion is the compound selected in the ﬁrst round of MS/
MS and further fragmented in the second round. As a result, the differ-
ence (loss) between the peak x(k) and the precursor ion prec(x) = (a(p),0)
is also important, where Mp) is the mass of the precursor ion. We can
model the difference with distribution [7%) =N(§((k), 2), where
5((k) = |prec(x) — x(k)|. This feature is denoted as loss and corresponding
kernel matrix as K1055. Experiments in Heinonen et al. (2012) and Shen
et al. (2013) showed that the combined kernel eraks -I- K10SS achieved best
accuracy and computational efﬁciency among the spectral kernels.

2.2.2 Fragmentation tree kernels Fragmentation trees can be con-
sidered as an annotated representation of the original MS/MS spectra.
Recent advancement (Rasche et al., 2012; Rojas-Cherté et al., 2012) in
comparing and aligning the fragmentation trees enables similarity metrics
to be deﬁned between fragmentation patterns for small molecules. Rasche
et al. (2012) introduced fragmentation tree alignments, and showed align-
ment scores to be correlated with chemical similarity. However, alignment
scores of this type do not, in general, yield positive semideﬁnite kernels.
In the following, we deﬁne a set of kernels for fragmentation trees that
will allow us to transfer the power of the fragmentation tree approach to
the kernel-based learning algorithms for molecular ﬁngerprint prediction
and metabolite identiﬁcation.

A fragmentation tree T = (V, E) consists of a nodes set V of molecular
formulas (corresponding to the fragments) and an edges set E g Vx V
(corresponding to the losses). Let r denote the root of T. For an edge
e = (u, v) e E let Me) = Mu, v) := u — v be the molecular formula of the
corresponding loss. Clearly, different edges may have identical losses; let
ME) be the multiset of all losses. For some loss molecular formula I, let
N(l) be the number of edges e e E with Me) = 1. Each path from the root
rtoanode vimpliesarootlossr— v; leté': ={r — v: v e V} be the setof
all root losses. For a MS/MS spectrum x, let T), = (VX,EX) be the corres-
ponding fragmentation tree, with root losses 5,, and loss multiplicities
Nx(>). For any node v e Vx let 1,,(v) be the corresponding peak intensity;
for an edge e = (u, v) 6 Ex let 1,,(e) be the intensity of the terminal node v.

For the loss- and node-based kernels, feature vectors d) are constructed
and the kernel function is just a simple dot product between two feature
vectors. Path-based kernels are more complicated, and details on their
computation will be given below.

Loss-based kernels: edges in the fragmentation trees represent the losses
from the parent node to the child node. The following feature vectors are
devised based on the losses in a fragmentation tree TX:

0 LB: Loss binary, indicates the presence of a loss I in a fragmentation
tree TX, that is, ¢%B(x)= 1,61%).

0 LC: Loss count, counts the number of occurrences of a loss I in a
fragmentation tree TX, that is, ¢%C(x) = Nx(l).

0 LI: Loss intensity, uses the average intensity of the terminal
nodes with loss I in a fragmentation tree TX, that is,

_ 1
#100 ’ m ZeEExMe) =1 ‘x(€)-

o RLB: Root loss binary, indicates the presence of a root loss I in a
fragmentation tree TX, that is, ¢?LB(x) = llegx.

o RLI: Root loss intensity uses the intensity of the terminal node of a
root loss if it is present in a fragmentation tree TX. For root r we set
¢?L1(x) =ix(r — I) if r — l e Vx, and ¢?L1(x)=0 otherwise.

Node-based kernels: the nodes in the fragmentation tree explain peaks in
the MS/MS by some chemical formula of the hypothetical fragment. The
nodes are unique in a fragmentation tree T, and so are the root losses. To
this end, we can omit root losses from the feature vectors.

a NB: Nodes binary, indicates the presence of a node v in a fragmen-
tation tree TX, that is, ¢§B(x) = 1VE yx.

o NI: Nodes intensity, uses the intensity of the node if it is presented
in a fragmentation tree TX; that is, ¢§I(x)=ix(v) for v e Vx, and
d)?II (x) = 0 otherwise.

Path-based kernels: these kernels are count common path between two
fragmentation treesihere, ‘common path’ refers to an identical sequence
of losses in the two trees. We use DP to efﬁciently count the number of
common paths, that is, the dot product of two feature vectors which are
not explicitly constructed. For two fragmentation trees T1 = (V1,E1) and
T2 = (V2,E2) we compute a DP table D[u,v] for all u 6 V1 and v 6 V2. In
all cases, the number of common paths is D[r1,r2] where r,- is the root of
Ti. We initialize

D[u, V]: 0, Va E £(T1), v E T2

D[u, v]=0,Vu 6 T1, v e £(T2)

where £(T) denotes the leaves of a tree T. Let C(v) be the children of a
node v.

a Common path counting (CPC). The DP table entry D[u,v] records the
count of common path for the subtrees rooted in u and v, respect-
ively. This leads to the following recurrence:

D[u,v]= Z (1+D[a,b]).
HEC(II).]7€C(V)
M14.a)r Mink)

Common paths of length 2 (CPZ). In this case, only common losses
for paths of length two are considered:

D[u, v] = Z

xecru). aEC(.\‘). yeC( v). be ex y)
M14..\‘)r Mr.y).M.\‘.a) 41an

(1+ D[a, b]).

a Common path with eraks (CPK). Instead of simply counting the
common paths, we use the PPK eraks to score the terminal peaks.
We omit the straightforward but somewhat tedious details.

a Common subtree counting (CSC). In this case, we count the number
of ‘common subtrees’ between T1 and T2, which can be deﬁned
analogously to the common paths above. Entry D[u,v] now counts
the number of common subtrees for the two subtrees rooted in u of
T1, and v of T2. We have to consider three cases: for each pair of
children a 6 C(14) and b e C(v) with Mu,a) = A (v,b) we can either
attach the subtrees rooted in a and b; we can use solely the edges
(u, a) and (v, b) as a common subtree; or, we can attach no common
subtree for this pair of children. But if we choose no subtree for all
matching pairs of children, the result would be a tree without edges
and, hence, not a valid common subtree. Thus, we have to correct for
this case by subtracting one. Hence, the recurrence is:

D[u,v]= H (2+D[a,b])— 1.
aEC(u).bEC(\1)
Mxi.a)er.b)

2.3 MKL

In many applications, multiple kernels from different kernel functions or
multiple sources of information are available. MKL becomes a natural
way to combine information contained in the kernels. Instead of choosing
the best kernel via cross-validation as in Heinonen et al. (2012) and Shen
et al. (2013), MKL seeks a linear, convex or even non-linear combination
of the kernels. An overview of MKL algorithms can be found in a survey
by Gonen and Alpaydin (2011).

In practice, it is often difﬁcult for MKL algorithms to outperform the
uniform combination of the kernels (UNIMKL) where the weights for ker-
nels are equal. However, in some cases, some methods have seen improve-
ments over the uniform combinations. Three algorithms coupled with
SVM are considered in the following: centered alignment-based algorithms

 

i159

112 /310'S[BIIJHOIPJOJXO'SOIJBLUJOJIIIOICI”Zdllq won pap1201umoq

9103 ‘0g isanV uo ::

H.Shen et al.

 

(Cortes et al., 2012), quadratic combination of the kernels (Li and Sun,
2010) and Zp-norm P> 1 for the kernel weights (Kloft et al., 2011).

For all the three algorithms, the input will be a set of kernels
K={Kk|Kk e R"X",k= 1, ...,q} computed from n data points. The
output is a set ofm ﬁngerprint properties Y e {—1, +1}"Xm which is a
multi-label prediction task and each label is trained independently in the
experiments.

2.3.] Centered alignment-based MKL The centered alignment-
based MKL algorithms are based on the observation that the centered
alignment score with the target kernel Ky = ny correlates very well with
the performance of the kernel, where y is a single label. Experiments by
Cortes et al. (2012) show consistent improvements over the uniform com-
bination. In the molecular ﬁngerprint prediction setting, the target kernel
is deﬁned as Ky = YYT.

Two-stage model are considered in which the kernel weights are
learned ﬁrst and then can be applied to all kernel-based learning algo-
rithms (SVM in this work). The centered kernel matrices are deﬁned by

Equation (1):
C [I eer] [I eer] (1)
n n

where I is the identity matrix and e is the vector with all ones.
VA, B 6 RM", let (>, >)F denotes the Frobenius product and H > “F denotes
the Frobenius norm which are deﬁned by

(A, B)F=Tr[ATb] and ||A||F=,/(A,A)F.

Let now K e [R'm’ and K’ e [R'm’ be two kernel matrices such that
||KLV||F¢ 0 and ||K:,||F;é 0. Then the centered alignment between K
and K’ is deﬁned by

(Kc, K’LIF

bK,K’=—.
( ) IIKcIIFIIKQIIF

(2)

The simple independent centered alignment-based algorithm (ALIGN)
(Cortes et al., 2012) computes the alignment score between each kernel
matrix K,- and the target kernel matrix Ky and combine the kernels as

1]
Kt o< 22m, KnKk
k=1

 

1 q (Kk,Ky>F
= —K
“Kym; iiKkiiF "

The alignment maximization algorithm (ALIGNF) (Cortes et al., 2012)
jointly seeks the weight a,- to maximize the alignment score deﬁned by
Equation (2) between the convex combination of the kernel in K and the
target kernel Ky = ny, that is, the following optimization problem:

m (Kt, Km
ueM IIKuIIF

where M=M = IIMII2=LM : 0.

2.3.2 Quadratic combination MKL In this setting, the quadratic
combination of kernels (QCMKL) is included in the formulation and the
MKL problem is solved by semideﬁnite programming (Lanckriet et al.,
2002; Li and Sun, 2010). The kernels in K are enriched to a new set
K = {K,|t= 1, ...,q(q-I-1)/2} by the following transformation:

~ Kion igéj
K2021): K_ i=1.

where i,j = 1, . . . ,q and 0 denotes the Hadamard product.

. . . . ~ +1 2
The convex comblnatlons of the kernels 1s g1ven by K, = 1 V ,

K, with a 3 0 and eTa= 1. Adapting the soft margin SVM formula-
tion reveals the following dual problem (in epigraph form) (Li and
Sun, 2010):

max u
11,14

r 1 r K
St. 14305 e—Ea G( 1,)05,

0 5a: Ce,otTy=0,

a30,eTa=1.

The derived Lagrangian for the problem is (Li and Sun, 2010):
1 s
L(or, ,8, 8, y) =orTe — EaTG(K1,)or-I- ,BTor
-I- yorTy-I- 8(Ce — or)

with 05,15 3 0,8 3 0, y as dual variables, and G(K)=diag(y)Kdiag(y).
Applying Schur’s lemma to convert the ﬁrst inequality constraint to
Linear Matrix Inequality (LMI) unveils the following semideﬁnite pro-
gram (SDP) (Li and Sun, 2010):

min u

11,14

G(K1,) e+,8+yy—8
S.t.
(e+,8+yy—8)T u—2C8Te

a30,eTa=1,,B30,830.

>0

/

Many standard SDP solvers can be used to ﬁnd the optimal solutions
such as cvx (http://cvxr.com/).

2.3.3 Zp-norm MKL While (1 norm on the kernel weights
a produces sparse solutions, higher norms p>1 produces non-
sparse solutions which may be beneﬁcial. A general framework
for Zp-norm MKL (KP-MKL) was proposed by Kloft et al. (2011).
The (1 kernels correspond to q feature mappings
\Ilk : X —> 7-0,, k= 1, . . . , q and l is some convex loss function and the
primal problem is then:

It

min C Kim (x-)> +by-)+1§qI—Hwklll“
Mb,” 1 k:1 kyk r 'Hk , r 2k:1 Mk

i.
81- M 2 0, llu ll; 5 1.

when the optimization is coupled with hinge loss, the problem has a
simple dual form (Kloft et al., 2011):

1 _
max aTe — E 11(aTG(K,-)a);j: 1111,,

where all the variables are all as deﬁned before but [7* = 

The optimization problem can be solved by alternating the dual vari-
ables or and the kernel weights a via the squared norm on w by the
following equations:

iIWkiiz=uiaTKka,Vk=1,...,q. (3)
IIWkIIz
Mk7 ,, 2 l,Vk=1,.--,q- (4)
_L_
(X) “Wk/HM»
14:1

Based on the above equations, a simple alternating algorithm has been
proposed by Kloft et al. (2011) as Algorithm 1.

 

i160

112 /310'S[BIIJHOIPJOJXO'SOIJBLUJOJIIIOICI”Zdllq won pap1201umoq

9103 ‘0g isanV uo ::

Metabolite identification through MKL

 

 

Algorithm 1 Wrapper algorithm for Zp-norm MKL

Input feasible or and a

while optimization conditions are not satisﬁed do
Solve or with current a using standard SVM.
Compute ||wk||2 with equation (3).
Update a by equation (4).

end while

 

 

The optimization conditions can be the difference of objective function
or the duality gap between two subsequent iterations. More detailed,
theoretical results and a faster chunking-based algorithm are also pre-
sented in Kloft et al. (2011).

2.4 Probabilistic scoring of candidate metabolites

Given a predicted ﬁngerprint associated with a mass spectrum, for me-
tabolite identiﬁcation, we need to retrieve metabolites with similar ﬁnger-
prints from a molecular database. Assume y e {—1, -I- 1}"‘ is a predicted
ﬁngerprint and an arbitrary ﬁngerprint y e {—1, -I- 1}"‘ for some molecule
in some molecular database, one can score the y by the following equa-
tion as used in FingerID (Heinonen et al., 2012; Shen et al., 2013):

m
, 1d. 
PPB(yIJ/, y)= H r,” ”(1 — V01” ’/
j=1
that is, the Poisson binomial probability for the ﬁngerprint vector y where
the cross-validation accuracies (10);”:1 e [0.5, 1]'” of the ﬁngerprints pre-
diction are taken as the reliability scores.

3 RESULTS

Two MS/MS datasets, 978 compounds downloaded from
METLIN (Tautenhahn et al., 2012) and 402 compounds from
MassBank (Hisayuki et al., 2010), both measured by QTOF
MS/MS instruments are tested. For each compound, mass spec-
tra recorded at different collision energies were amalgamated
before further processing: we normalize MS/MS spectra such
that intensities sum up to 100%. We merge peaks from different
collision energies with m/z difference at most 0. 1, using the m/z of
the highest peak and summing up intensities. We discard all but
the 30 highest peaks, as well as peaks with relative intensity
<0.5%.

Next, we compute the fragmentation tree. We assume that we
can identify the correct molecular formula from the data: limit-
ing candidate molecular formulas to those present in KEGG
(Kanehisa and Goto, 2000), which is used for searching molecu-
lar structures below, the best scoring fragmentation tree identi-
ﬁed the correct molecular formula of the compound in 97.1%
(96.0%) of the cases for the METLIN (MassBank) dataset.
Integrating other sources of information such as MS1 isotope
patterns (Bocker et al., 2009) or retention times would reach
even better identiﬁcation rates. To allow for a meaningful com-
parison of the power of the different kernels, we therefore use the
best scoring fragmentation tree of the correct compound molecu-
lar formula.

All 11 fragmentation tree kernels proposed in the previous
section were computed, along with PPK used in Heinonen
et al. (2012) and Shen et al. (2013) computed directly from
MS/MS, resulting in 12 kernels to be evaluated.

Molecular fingerprints were generated using OpenBabel
(O’Boyle et al., 2011) which contains four types of fingerprints
(http://openbabel.org/wiki/Tutorial:Fingerprints). FP3, FP4 and

Table 1. Micro-average performance of individual kernels

 

 

 

METLIN Mas sBank

Acc (%) F1 (%) Acc (%) F1 (%)
LB 79.5:I:0.S 69.9:I:0.9 78.9:I: 1.0 69.0:I:2.2
LC 79.4:I:0.3 69.6:I:0.4 78.5:I: 1.2 68.4:I:2.7
LI 77.8:I:0.S 66.8:I:0.7 77.4:I:1.0 66.7:I:2.0
RLB 81.6:I:0.8 73.2:I:1.1 78.6:I:1.0 68.4:I:1.2
RLI 78.4:I:0.6 68.5:I:0.8 76.7:I:0.9 65.4:I: 1.6
NB 81.9 :I: 0.4 73.9 :I: 0.3 81.4 :I: 0.7 73.2 :I: 1.2
NI 80.3:I:0.7 71.1:I:0.8 79.8:I:1.0 70.5:I:0.9
CPC 80.6:I:0.5 71.6:I:0.7 78.7:I: 1.4 68.9:I:2.4
CP2 78.7:I:0.7 68.4:I:1.2 76.4:I:1.0 6S.S:I:1.1
CPK 72.9:I:0.3 58.8:I:0.5 72.2:I:0.6 S7.9:I:0.5
CSC 74.9:I:0.4 61.9:I:0.8 77.8:I:0.8 67.2:I:2.0
PPK 76.7:I:0.6 64.0:I:0.7 72.9:I:1.1 58.6:I:1.2

 

PPK is the method from Heinonen et al. (2012), which we compare against.

MACCS fingerprints (528 bits in total) were generated based on
the software predeﬁned SMARTS patterns. In our dataset, more
than half of the fingerprint properties have high-class bias rate,
with a large majority of the dataset belonging to the positive class
(most compounds match the property) or respectively the nega-
tive class (most compounds do not match the property). For
such ﬁngerprints, the default classiﬁer, one that always predicts
the majority class, has high accuracy, although the model is not
meaningful. For our performance comparisons, we opted to only
include ﬁngerprints with class bias rate <0.9.

For each ﬁngerprint property, we separately trained a SVM;
for all properties, we used identical training and testing com-
pounds. Five-fold cross-validation was performed and the
SVM margin softness parameter (C 6 {2’3, 2’2, . . . , 26, 27})
was tuned based on the training accuracy.

3.1 Fingerprint prediction performance

The micro-average (simultaneous average over ﬁngerprint prop-
erties and compounds) accuracy and F1 of the individual kernels
on the predictions of ﬁngerprint properties with bias rate <0.9
are shown in Table 1 with the SDs computed from different
cross-validation folds. The kernel NB achieves the best accuracy
and F1 on both METLIN and MassBank. Compared with the
PPK, the fragmentation tree kernels are markedly more accurate
on average.

The improvement of MKL approaches over single kernel
SVMs are clear. The t-test between NB and ALIGNF shows the
differences of mean accuracy and F1 are indeed very signiﬁcant
with P—Values of 4 x 10‘6 and 1.7 x 10‘3, respectively. The kernel
weights learned by different MKL algorithms are shown in the
supplementary file.

The micro-average accuracy and F1 of the MKL algorithms
on the fingerprint properties predictions are shown in Table 2,
where it can be concluded that averaged overall ﬁngerprints of
the MKL methods are quite close. We conducted further pair-
wise difference testing, where the performance difference of each
method on each individual fingerprint property is evaluated.
Table 3 shows the signiﬁcance level of the sign test on the

 

i161

112 /310'S[BIIJDOIPJOJXO'SOIJBLUJOJIIIOIq/ﬂduq uion pap1201umoq

9103 ‘0g isanV uo ::

H.Shen et al.

 

accuracy and F1 on the METLIN and MASSBANK datasets using
the different MKL methods. The sign test describes whether one
of the methods has higher probability of success (better than the
other on a fingerprint) than the other (alternative hypothesis) or

Table 2. Micro-average performance of MKL algorithms

 

 

 

METLIN MassBank

Acc (%) F1 (%) Acc (%) F1 (%)
UNIMKL 85.0:I:0.6 78.3:I:0.7 82.2:I:0.6 73.9:I: 1.5
ALIGN 85.2:I:0.6 78.6:I:0.7 82.4:I:0.7 74.4:I:1.4
ALIGNF 85.0 :I: 0.5 78.6 :I: 0.4 82.8 :I: 0.4 75.2 :I: 1.2
QCMKL 84.9:I:0.5 77.8:I:0.5 82.1 :I:0.6 74.0:I:0.7
Zz-MKL 84.7:I:0.5 77.5:I:0.5 82.2:I:0.5 74.0:I:0.9
£3-MKL 85.2 :I: 0.6 78.5 :I: 0.7 82.4 :I: 0.6 74.4 :I: 1.3
£4-MKL 85.2:I:0.6 78.5:I:0.8 82.3:I:0.6 74.2:I:1.0
(s-MKL 85.1 :I:0.6 78.5:I:0.7 82.3:I:0.6 74.1 :I: 1.3

 

not (null hypothesis). From the table, we can deduce that ALIGN
and ALIGNF rise slightly above the competition whereas 32-MKL
and QCMKL are slightly inferior to the rest. The performance of
UNIMKL is also respectable. The scatter plots of accuracy and F1
between every pair of the MKL algorithms are shown in the
supplementary ﬁle.

3.2 Metabolite identiﬁcation performance

The molecular ﬁngerprint prediction can serve as an intermediate
step for metabolites identiﬁcation, and can be used to search a
molecular structure database (Heinonen et al., 2012; Shen et al.,
2013). We want to evaluate whether improvements in ﬁngerprint
prediction propagate to better metabolites identiﬁcations. We will
search for molecular structures from the KEGG database. As we
assume to know the correct molecular formula, we may ﬁlter
based on this information to generate our candidate lists. But it
turns out that this ﬁlter is too strict for a meaningful evaluation,
as the number of candidates for each MS/MS spectrum becomes
very small and, hence, all kernels show good performance. For a

Table 3. Sign test for the performance of MKL algorithms on the METLIN and Mas sBank datasets

 

 

ACC UNIMKL ALIGN ALIGNF QCMKL Zz-MKL Z3-MKL Z4-MKL ZS-MKL
METLIN UNIMKL —— — + + + + __ __
ALIGN -I- -I- —I— —I— —I— —I— —I— —I— —I—
ALIGNF + + + + + +
QCMKL —— —— —— + + __ __ __
(32-MKL —— —— —_ __ __ __ __
£3-MKL — —I— —I— —I— —I—
£4-MKL -I- -I- —I— —I— —I— —I—
Zs-MKL -I- -I- —— — —I— —I— —I— —I—
MassBank UNIMKL — —— -I- —I— +
ALIGN -I- —— —I— —I— —I— —I— —I— —I— —I—
ALIGNF +—I— +—I— +—I— +—I— +—I— +—I— +—I—
QCMKL — — —— _ __ _
(32-MKL — —— —— _ _
(33-MKL —— + +
£4-MKL —— —— —I— —I— —I— —
ZS-MKL — —— —— -I- -I-
F l UNI MKL AL I GN AL I GNF QCMKL Zz-MKL Z3-MKL Z4-MKL Z 5-MKL
METLIN UNIMKL — + __ __ __
ALIGN -I- —I— —I— —I— —I—
ALIGNF -I- -I- -I-
QCMKL —— — + __ __
Zz-MKL 7 —— —— _ __ __ __
£3-MKL -I- -I- —I— —I— —I— —I—
£4-MKL -I- -I- —I— —I— —I— —I—
(ZS-MKL + + + +
Mas sBank UNIMKL — +
ALIGN -I- —I— —I— —I— —I—
ALIGNF -I- -I- -I- -I-
QCMKL —— —— __ __ I
Zz-MKL —— ——
(33-MKL + +
Z4-MKL -I- -I-
(ZS-MKL e +

 

‘+’ indicates the method in the row is better than the method in the column (‘—’ otherwise) with signiﬁcance P—valuc between 0.01 and 0.05; blank indicates no signiﬁcance.
Similarly, ‘-I- +’ and ‘——’ indicate signiﬁcance with P—valuc<0.01. Upper table is for accuracy and lower table is for F1.

 

i162

112 /310'S[BIIJDOIPJOJXO'SOIJBLUJOJIIIOIq/ﬂduq uion pap1201umoq

9103 ‘0g isanV uo ::

Metabolite identification through MKL

 

 

 

   

 

 

 

 

 

 

 

 

 

 

 

    

 

 

 

 

 

 

(a) 100 —
c}: 80 —
‘65
(I)
to
1'6 60 -
'O
I...
O
C
2 40 — — L3MKL
g — NB
9 20 _ — UNIMKL
,1 — ALIGNF
— PPK
0 _ . . . . .. NUM
| | | | | | |
1 2 5 10 20 50 100
Rank (log scale)
ME IL IN trained ﬁngerprints
(0) — L3MKL
g\°, — UNIMKL
Aé — ALIGNF
g 60 _ — PPK
._ NUM
Q.
B
“6 4o —
C
.9
t’
8 20 —
2
n.
0 _
| | I | I
20ppm 50ppm 100ppm 200ppm 300ppm

Mass window

METL IN top 1 rank against mass windows

 

   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

(b) 100 —
c}: 80 —
“65
U)
(5
1'6 60 -
'O
u—
0
C
3 40 — — L3MKL
5 — NB
8 20 _ — UNIMKL
at — ALIGNF
— PPK
0 _ . . . . .. NUM
| | | | | | l
1 2 5 10 20 50 100
Rank (log scale)
Ma s sBank trained fingerprints
(d) — L3MKL
g\°, — UNIMKL
é — ALIGNF
g 60 _ — PPK
._ NUM
Q.
2
"6 4o —
C
.9
t'
8 20 — ._
9 ' - - . . . . . . .,
n- . I 7 ‘ u.
0 _ ' - . . . . . . . . . . ..
I | I | I
20ppm 50ppm 100ppm 200ppm 300ppm

Mass window

MassBank top 1 rank against mass windows

Fig. 2. (a and b) show the performance for identiﬁcation when searching KEGG using 300-ppm mass window with predicted molecular ﬁngerprints,
with ﬁngerprints trained with METLIN and Mas sBank datasets, respectively. NUM denotes the number of candidate molecules returned per query.
(c and (1) show the proportion of data that were correctly identiﬁed in the top 1 rank against a series of mass windows

more discriminative evaluation of the kernels, we artiﬁcially
enlarge the set of candidates: we use all molecular structures in
KEGG with mass accuracy window [MM—A, aM+A] as
candidates, where MM is the true mass of the unknown
molecule. For sufﬁciently large mass accuracy A, this results
in candidate lists that allow a meaningful comparison of the
kernels.

For identiﬁcation, we want the true molecular structure to be
ranked as high as possible in the candidates list. Figure 2a and b
shows the fraction of compounds that were ranked higher than
certain rank for the two datasets, when searching KEGG with
300 ppm mass inaccuracy to generate the candidates for the two
datasets.

We notice that the NB kernel is consistently more accurate than
PPK. In addition, MKL clearly improves the identiﬁcation
performance, especially the number of top-ranked identiﬁcations

increases signiﬁcantly. T—test between the ranks of the ALIGNF
and PPK shows a P—Value of 0.06 which veriﬁes the
improvements in identiﬁcation by ALIGNF over the PPK is
indeed signiﬁcant. ALIGNF comes on top of the MKL
approaches, which is in line with its good ﬁngerprint prediction
accuracy and F1 score.

The effect of mass accuracy windows during the database re-
trieval are shown in Figure 2c and d. A narrower 20-ppm mass
search window ﬁlters out many false candidates, and thus sig-
niﬁcantly elevates the identiﬁcation accuracies to 60% on
METLIN dataset and 40% on MassBank dataset. However,
the effect of improved molecular fingerprint prediction is sof-
tened due to the fewer but possibly more similar candidates.
An extreme case is observed in Figure 2d in which all the meth-
ods shrink to the same result when searching with 20-ppm mass
accuracy window.

 

i163

112 /310'S[BIIJDOIPJOJXO'SOIJBLUJOJIIIOIq/ﬂduq uion pap1201umoq

9103 ‘0g isanV uo ::

H.Shen et al.

 

4 DBCUSﬁON

The present work combines the combinatorial fragmentation tree
approach with machine learning through a kemel—based ap-
proach. We suggest several kernels for fragmentation trees, and
show how to fuse their information through MKL. The result
signiﬁcantly enhances molecular ﬁngerprint prediction and me-
tabolite identiﬁcation.

The closest analogs to our fragmentation tree kernels in litera-
ture are those deﬁned for parse trees in natural language pro-
cessing (Collins and Duffy, 2001); our fragmentation trees can be
seen as parses of the MS/MS spectra. DP techniques similar to
ours are used there for computing kernels between trees (Collins
and Duffy, 2001; Kuboyama, 2007). However, fragmentation
trees have important differences to the trees deﬁned between
parses of natural language and to kernels comparing molecular
structures (Mahé and Vert, 2009). Differently from natural lan-
guage parses, the node labels have partial order (via their mo-
lecular weights) and also the edges have labels. Differently from
kernels for molecular graphs, the label spaces of both nodes and
edges are vast (subsets of molecular formulae).

The comparison with the PPK employed by the FingerID
(Heinonen et al., 2012) software shows that the fragmentation
tree kernels are able to extract more information out of the MS/
MS spectra. Improvements are seen in both the prediction ac-
curacy and the F1 score. Comparing with FingerID (PPK), the
uniform combination of the kernels (UNIMKL) improves the
molecular fingerprint prediction significantly in accuracy and
F1. As witnessed by many MKL applications, the UNIMKL al-
gorithm is hard to beat. In our result, several MKL algorithms
such as ALIGNF and l3-norm can give slightly better result than
UNIMKL. The improvements in the molecular ﬁngerprint predic-
tion translate to improved metabolite identiﬁcation.

There are several possible routes forward with the current me-
tabolite identiﬁcation framework. First, post-processing on the
candidates list, such as the one proposed by Allen et al. (2013), is
necessary when searching a large compound database such as
PubChem, because the returned candidates (hundreds to thou-
sands) may share the same ﬁngerprints and there is no way to
differ them based only on molecular fingerprints. Second, train-
ing a separate SVM for each ﬁngerprint property is clearly an
aspect that can be improved upon, for example, by a multi-label
classiﬁcation approach. A still more tempting yet challenging
direction would be to replace the two-step identiﬁcation by an
integrated prediction approach. Such an approach would poten-
tially learn to predict the fingerprint properties that are import-
ant for discriminating metabolites from each other.

Funding: Academy of Finland grant 268874 (MIDAS); Deutsche
Forschungsgemeinschaft grant (B0 1910/ 16-1) (IDUN).

Conflict of Interest: none declared.

REFERENCES

Allen,F. et al. (2013) Competitive fragmentation modeling of ESI—MS/MS spectra
for metabolite identiﬁcation. Pre—print. arXiv:1312.0264.

B6cker,S. and Rasche,F. (2008) Towards de novo identiﬁcation of metabolites by
analyzing tandem mass spectra. Bioinformatics, 24, i497i55.

B6cker,S. et al. (2009) Sirius: decomposing isotope patterns for metabolite identiﬁ—
cation. Bioinformatics, 25, 2187224.

Collins,M. and Duffy,N. (2001) Convolution kernels for natural language. In
Dietterich,T.G. et al. (ed.) Advances in Neural Information Processing Systems
14. MIT Press, Cambridge, MA, pp. 625$32.

Cortes,C. et al. (2012) Algorithms for learning kernels based on centered alignment.
J. Mach. Learn. Res., 13, 7957828.

Dcmuth,W. et al. (2004) Spectral similarity versus structural similarity: mass spec—
trometry. Anal. Chim. Acta, 516, 75785.

Gerlich,M. and Neumann,S. (2013) MctFusion: integration of compound identiﬁ—
cation strategies. J. Mass Spectrom., 48, 2917298.

G6nen,M. and Alpaydin,E. (2011) Multiple kernel learning algorithms. J. Mach.
Learn. Res., 12, 221172268.

Heinonen,M. et al. (2012) Metabolite identiﬁcation and molecular ﬁngerprint pre—
diction through machine learning. Bioinformatics, 28, 233372341.

Hill,D.W. et al. (2008) Mass spectral metabonomics beyond elemental formula:
chemical database querying by matching experimental with computational frag—
mentation spectra. Anal. Chem, 80, 557435582.

Hisayuki,H. et al. (2010) Massbank: a public repository for sharing mass spectral
data for life sciences. J. Mass Spectrom., 45, 7037714.

Hufsky,F. et al. (2014) Computational mass spectrometry for small molecule frag—
mentation. Trends Anal. Chem, 53, 41418.

Jebara,T. et al. (2004) Probability product kernels. J. Mach. Learn. Res., 5, 81%844.

Kanehisa,M. and Goto,S. (2000) KEGG: Kyoto encyclopedia of genes and gen—
omes. Nucleic Acids Res., 28, 27730.

Kangas,L.J. et al. (2012) In silico identiﬁcation software (ISIS): a machine learning
approach to tandem mass spectral identiﬁcation of lipids. Bioinformatics, 28,
170571713.

Kind,T. and Fiehn,O. (2007) Seven golden rules for heuristic ﬁltering of
molecular formulas obtained by accurate mass spectrometry. BMC
Bioinformatics, 8, 105.

Kloft,M. et al. (2011) lp—norm multiple kernel learning. J. Mach. Learn. Res., 12,
9537997.

Kuboyama,T. (2007) Matching and learning in trees. PhD Thesis, University of
Tokyo.

Lanckriet,G. et al. (2002) Learning the kernel matrix with semi—deﬁnite program—
ming. J. Mach. Learn. Res., 5, 2004.

Li,J. and Sun,S. (2010) Nonlinear combination of multiple kernels for support
vector machines. In International Conference on Pattern Recognition, Istanbul.
IEEE, pp. 288972892.

Mahé,P. and Vert,J.—P. (2009) Graph kernels based on tree patterns for molecules.
Mach. Learn., 75, 3735.

Oberacher,H. et al. (2009) On the inter—instrument and the inter—laboratory trans—
ferability of a tandem mass spectral reference library: 2. optimization and char—
acterization of the search algorithm. J. Mass Spectrom., 44, 4943502.

O’Boyle,N. et al. (2011) Open babel: an open chemical toolbox. J. Cheminform,
3, 33.

Pitkanen,E. et al. (2010) Computational methods for metabolic reconstruction.
Curr. Opin. Biotechnol., 21, 7&77.

Rasche,F. et al. (201 1) Computing fragmentation trees from tandem mass spectrom—
etry data. Anal. Chem., 83, 124%1251.

Rasche,F. et al. (2012) Identifying the unknowns by aligning fragmentation trees.
Anal. Chem, 84, 341773426.

Rauf,I. et al. (2012) Finding maximum colorful subtrees in practice. In Benny,C.
(ed.) Research in Computational Molecular Biology. Volume 7262 of Lecture
Notes in Computer Science. Springer, Berlin Heidelberg, pp. 2137223.

Rojas—Cherto,M. et al. (2012) Metabolite identiﬁcation using automated compari—
son of high—resolution multistage mass spectral trees. Anal. Chem, 84,
552475534.

Scheubert,K. et al. (2013) Computational mass spectrometry for small molecules.
J. Cheminform., 5, 12.

Shen,H. et al. (2013) Metabolite identiﬁcation through machine learningitackling
casmi challenge using FingerID. Metabolites, 3, 4843505.

Smith,C.A. et al. (2005) Metlin: a metabolite mass spectral database. Drug Monit.,
27, 7477751.

Tautenhahn,R. et al. (2012) An accelerated workflow for untargeted metabolomics
using the METLIN database. Nat. Biotechnol., 30, 823828.

Wolf,S. et al. (2010) In silico fragmentation for computer assisted identiﬁcation of
metabolite mass spectra. BMC Bioinformatics, 11, 148.

 

i164

112 /310'S[BHJHOIPJOJXO'SOIJBLUJOJIIIOICI”Idllq uror} popao1umoq

9103 ‘0g isanV uo ::

