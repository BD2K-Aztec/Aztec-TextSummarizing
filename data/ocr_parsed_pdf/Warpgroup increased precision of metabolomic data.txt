Bioinformatics, 32(2), 2016, 268—275

doi: 10.1093/bioinformatics/btv564

Advance Access Publication Date: 30 September 2015
Original Paper

 

Data and text mining

Warpgroup: increased precision of metabolomic
data processing by consensus integration
bound analysis

Nathaniel G. Mahieu1'2'*, Jonathan L. Spalding1'3 and Gary J. Patti1'2'*

1Department of Chemistry, Washington University, St Louis, MO 63130, USA, 2Department of Medicine and
3Department of Genetics, Washington University School of Medicine, St Louis, MO 63110, USA

*To whom correspondence should be addressed.
Associate Editor: Jonathan Wren

Received on June 17, 2015; revised on September 4, 2015; accepted on September 22, 2015

Abstract

Motivation: Current informatic techniques for processing raw chromatography/mass spectrometry
data break down under several common, non—ideal conditions. lmportantly, hydrophilic liquid
interaction chromatography (a key separation technology for metabolomics) produces data which
are especially challenging to process. We identify three critical points of failure in current infor—
matic workflows: compound specific drift, integration region variance, and naive missing value im—
putation. We implement the Warpgroup algorithm to address these challenges.

Results: Warpgroup adds peak subregion detection, consensus integration bound detection, and
intelligent missing value imputation steps to the conventional informatic workflow. When com—
pared with the conventional workflow, Warpgroup made major improvements to the processed
data. The coefficient of variation for peaks detected in replicate injections of a complex Escherichia
Coli extract were halved (a reduction of 19%). Integration regions across samples were much more
robust. Additionally, many signals lost by the conventional workflow were ’rescued’ by the
Warpgroup refinement, thereby resulting in greater analyte coverage in the processed data.
Availability and implementation: Warpgroup is an open source R package available on GitHub at
github.com/nathaniel—mahieu/warpgroup. The package includes example data and XCMS compati—
bility wrappers for ease of use.

Supplementary information: Supplementary data are available at Bioinformatics online.

Contact: nathaniel.mahieu@wustl.edu 0r gjpattij@wustl.edu

 

 

1 Introduction

Omics-scale separation/mass spectrometry approaches (e.g. LC/MS,
GC/MS, (IE/MS, etc.) generate large, 3D data sets consisting of elu-
tion time (rt), mass-to-charge ratio (m/z), and signal intensity infor-
mation (Crutchfield et (11., 2010). Analytes are separated by their
chemical characteristics prior to being introduced into the mass
spectrometer (yielding rt). The mass spectrometer acts as a second
dimension of separation and a detector, providing information on
the accurate mass (m/z) and amount of each analyte (signal inten-
sity). Each sample run can generate gigabytes of data representing
tens of thousands of distinct analytes (Kéill and Vitek, 2011).

The processing of raw data is a significant challenge and the conven-
tional workflow consists of several steps. These steps include mass
trace detection, chromatographic feature detection, inter-sample re-
tention time drift correction, inter-sample grouping of common fea-
tures (correspondence determination), and statistical analysis of
feature groups (Patti et (11., 2012). A feature in this context refers to
signal which displays a peak shape in both m/z and rt domains. The
result of this data processing is quantification of all unique analytes
detected across multiple sample runs.

Historically, most chromatography/mass spectrometry experi-
ments have been performed with reversed-phase chromatography.

(6) The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 268

/310‘srcumo[p10}xo‘sopcuuoiutotq/ﬁdnq

Kele and Abate-Fella at 211., 2015
Guiochon, 2000

Prince and Marcotte, 2006 Supplementary

 

 

 

 

 

 

Figure S2
Buszewski and
Noga, 2012
Fuhrer and Zamboni, 2015 Supplementary Fig. S3
Tautenhahn at £11., 2008 Fig. 1 Smith at £11., 2006
Cappadona
at £11., 2012
Nikolskiy at £11., 2013
Fig. 1
Rabiner, 1978
Vandenbogaert at £11., 2008
Quarry at 211., 1984
Csardi and Nepusz, 2006
Podwojski
at £11., 2009
Supplementary
Figs S2 S3 Smith at £11., 2015
AA  “L “L L 4% JWAEJUUJCJEUMC
re re 1L
0% UK UEUGE MMMM
Jk Jk A A ft ft ft 1‘):
_J\A Jlk _lbt

 

/3.IO'S[EIIm0fp.IOJXO'SOIJEIIIJOJIIIOIq”Zduq

270

N. G.Mahieu et al.

 

2 Methods

2.1 Overview of the Warpgroup algorithm

The Warpgroup algorithm is applied after feature detection has been
performed. It augments the conventional retention time correction
and feature grouping steps with the addition of group splitting and
consensus bound determination. The benefits of Warpgroup are
derived from the combination of several peak finding rounds by using
the independently determined alignment between chromatograms.

The Warpgroup algorithm utilizes two pieces of information.
The first piece of information is one EIC trace per sample which in—
cludes all of the masses contributing to the peak group. This trace
could contain a single detected peak, or multiple peaks per sample
depending on the experimental retention time drift and mass drift.
These traces are used to determine the pairwise alignment between
each sample’s time domain for this putative group of compounds.
The second piece of information is a list of peak bounds detected in
the EIC traces. These must have been determined previously by a
peak detection step for at least one sample. The Warpgroup algo—
rithm will use these bounds and the aligned sample traces to split the
detected peak list into groups, each of which represent a distinct
chromatographic region.

The key assumption made by the Warpgroup approach is that
the sample EIC traces exhibit similar topography. Though not
strictly true, this is the common assumption made in current reten—
tion time alignment techniques (Smith et al., 2015) and has been
shown here to be a robust basis for Warpgroup analysis. Under this
assumption, we use established methods to warp (shift, expand, and
contract) the time domain of the sample EIC trace such that the dif—
ference between two sample traces is minimized. In this way we es—
tablish a relationship between the two time domains, equating the
scans in one sample to the scans in a second for a specific group of
compounds (i.e. ﬁn," (scan in sample m):scan in sample n). This
warping function is taken as the true correspondence between scans
in each sample trace and is used to establish relationships between
the detected peaks as well as to determine the proper integration re—
gion in samples where a peak was not detected.

To this end, the alignment between each sample scan is used to
evaluate whether the supplied peak bounds delineate similar or dis—
tinct chromatographic regions of their EIC traces. Peak bounds
which describe similar chromatographic regions should overlap
upon transformation into a second sample’s time domain. We ask,
for each peak, if the transformed bounds agree. These yes/no an—
swers are expressed as linkages between detected peaks (nodes) cre—
ating a graph structure. This graph is split using the walktrap
community detection method (Pons and Latapy, 2005) and the re—
sulting communities are taken as peak groups (i.e. groups of peaks
which describe similar chromatographic regions).

For each resulting peak group, the full set of transformed peak
bounds is then filtered for outliers that do not describe a chromato—
graphic region similar to that of the majority of detected peaks. The
mean of the transformed peak bounds within one standard deviation
of the mean is taken, defining the ‘group—consensus peak bound” for
each sample.

Finally, integration bounds must be determined for samples
which have no detected peak remaining in the group. It is common
for features to be detected in some but not all samples, especially in
cases where compounds are of low abundance. Each group’s consen—
sus peak bounds are transformed into the missing sample’s time do—
main and the median of these transformed consensus peak bounds is
taken as the integration region for the missing sample.

In this way, Warpgroup assures that each peak group contains a
region from every sample, each peak group describes a unique chro—
matographic region, and all peaks in that group describe similar
chromatographic regions (Fig. 1).

2.2 Description of the Warpgroup algorithm

2.2.1 Input

The algorithm takes two pieces of information. A sample >< scan sam—
ple—trace—matrix (Fig. 1, traces) and a matrix of peak bounds includ—
ing the peak start, peak end, and sample index (Fig. 1, dots).

2.2.2 Sample trace pre-processing

Optionally, each sample trace is smoothed, padded with 0’s equal to
10% of the length of the trace, and normalized to a maximum inten—
sity of 1.0.

2.2.3 Pairwise sample warping matrix generation

Each pair of sample traces is used to generate a sample >< sample
warping—matrix (W). Each matrix entry is a step function
Wm," :fm,n(x) such that fmm (scan in sample m) :scan in sample n
(Supplementary Fig. S4) The notation WC), represents the step func—
tion converting scans from the sample in which peak / was detected
into the sample in which peak 1' was detected.

The warp matrices for this work are generated using DTW to de—
termine the optimal warp path. Other techniques such as parametric
time warping (PTW) have recently been applied to the correction of
retention time drift (Wehrens et al., 2015) and in general any tech—
nique which establishes alignment between the scans in each sample
can be used.

2.2.4 Establishing relationships between the supplied peaks
The supplied peak bounds are transformed from the originating sam—
ple’s elution space into each of the other sample’s elution space via
the previously determined warping—matrix. Peaks which delineate the
same chromatographic regions will share bounds when transformed
from their time domain into the other sample’s time domain.

Each pair of peak bounds is compared to populate a peak >< peak
match—matrix (P). Pairs which differ by less than the settable cut—off
sc.aligned.lim are filled as true.

PL; : (boundspeaki — IVA/(boundspeakyﬂ < sc.aligned.lim

2.2.5 Splitting the supplied peaks into groups which describe
distinct chromatographic regions
Matrix P is represented as a graph structure where matrix indices
are the nodes and matrix elements containing a true value are the
edges (Supplementary Fig. SS). The nodes of this graph are split into
communities using the walktrap community detection method (Pons
and Latapy, 2005 ).

Each of the resulting communities contains one or more detected
features. Within each community (i.e. group), all detected features
are taken to represent the same analyte.

2.2.6 Determination of consensus peak bounds for each group

All detected peaks within each group contribute to the consensus
peak bounds such that each peak represents the same chromato—
graphic region. Grouped peak pairs are transformed into each sam—
ple’s time domain to create a peak >< peak transformed matrix (C).

CL]. : Wi.j(b0und5peaki)

ﬁm'sreumol‘piqxo'sopeuuowtotq/ﬁdnq

Increased precision of metabolomic data processing

271

 

The mean of the bounds within one standard deviation of the mean
is taken along each column, defining the consensus peak bounds for
the jth peak.

2.2.7 Determination of integration region for samples without a
detected peak

For samples in which there was no detected peak remaining in a group,
the consensus peak bounds are projected into that sample’s time domain.

CL; : IVA/(consensus boundspeaki)

The median of these transformed bounds are taken as the miss—
ing sample’s peak bounds.

2.2.8 Output

The output of the algorithm is a list, each entry representing one
peak group. A group entry is a matrix with a set of consensus peak
bounds for each sample as well as descriptors of the alignment and
grouping process. This output can be used for peak integration, fil—
tering, and statistics.

2.3 XCMS implementation

Warpgroup was developed as a standalone algorithm and as such it
can be applied to any suitable chromatographic data. For convenience,
the Warpgroup package includes integration with XCMS type objects.
These functions allow application of the Warpgroup algorithm in the
conventional XCMS manner by calling group.warpgroup(). The re—
turned object is an xcmsSet object with peak bounds and groups gen—
erated by the Warpgroup algorithm. This resulting xcmsSet does not
need any further fillPeaks() and is ready for statistical analysis, either
manually or with XCMS’s diffreport() function. Further information
can be found in Supplementary Information page S6.

2.4 Datasets

2.4.1 Raw data

We experimentally generated two datasets on which to benchmark
Warpgrouping. To evaluate performance under a relevant set of condi—
tions, we chose to generate one dataset with reversed—phase C18 chro—
matography and the second with amino propyl HILIC (Ivanisevic
et al., 2013). Each dataset contained 11 LC/MS runs of Escherichia
coli (E. coli) strain K12, MG1655 metabolic extract. This design
allowed us to inspect the standard error of quantitation on both ideal
(C18) and non—ideal (HILIC) datasets while also observing the algo—
rithm’s performance as dataset quality degrades at longer times.

Metabolic extract was generated as described previously
(Mahieu et al., 2014). Briefly, two cultures of E. coli were grown,
one on natural—abundance glucose and a second on uniformly
labeled 13C—glucose as the sole carbon source. E. coli was harvested
by pelleting 10 ml of culture at OD600: 1.0. Pellets were extracted
using 1 ml of 2:2:1 methanol:acetonitrile:water, and reconstituted in
100 pl of 1:1 acetonitrile:water.

Datasets were generated on the Thermo Q—Exactive Plus mass
spectrometer interfaced with an Agilent 1260 capillary liquid chro—
matography system. Spectra were collected with the following HESI
II source settings: aux. gas, 15 ; sheath gas, 30; counter gas, 0; capil—
lary temperature, 310 °C; sheath gas temperature, 200 °C; spray
voltage, 3.2 kV; needle diameter, 34 ga; s—lens, 65 V; mass range,
85—1165 Da; resolution 140 000; microscans, 1; max injection
time; 200 ms; automatic gain control target: 3e6.

HILIC was performed as described previously (Ivanisevic et al.,
2013) by using the Phenomenex Luna NH2 (1.0 mm X 150 mm X 3 pm)
column and a ﬂow rate of 50 ul/min. Spectra were collected in negative

ion mode. Solvents were: A, 95% water+ 20 mM ammonium
hydroxide+20 mM ammonium acetate; B, 100% acetonitrile. An in—
jection volume of 1 pl was used with a linear gradient of (minutes,
%A): 0, 5; 40, 100; 50, 100; 50.5, 40; 54.5, 15; 55, 5; 65, 5.

Reversed—phase chromatography was performed as described
previously (Ivanisevic et al., 2013) by using the Agilent Zorbax C18
(0.5 mm X 150mm X 3 pm) column and a flow rate of 30 ul/min.
Spectra were collected in positive ion mode. Solvents were: A,
water+ 0.1% (v/v) formic acid; B, acetonitrile + 0.1% (v/v) formic
acid. An injection volume of 1 ul was used with a linear gradient of
(minutes, %A): 0, 95; 45, 0; 55, 0; 56, 95; 65, 95.

2.4.2 Pre-processing

The Warpgroup algorithm implements peak subregion detection,
consensus/missing peak integration bound determination, and group
filtering. These steps come after peak detection has been performed
and putative correspondence has been determined. To generate data
for comparisons, peak detection for each of the C18 and HILIC
datasets was performed by the centWave algorithm as implemented
in the XCMS R package (R Core Team, 2014; Smith et al., 2006;
Tautenhahn et al., 2008). Parameters were: C18, ppm : 2.5,
peakwidth : c(8 120), HILIC: ppm : 2.5, peakwidth : c(8 120).
This set of detected peaks was used as the basis for both the conven—
tional and Warpgroup workflows as described below.

2.4.3 Conventional workflow

The conventional workflow as referred to here consists of the fol—
lowing listed analysis steps and parameters taken from XCMS
Online recommendations for the Q—Exactive Plus (Tautenhahn
et al., 2012). Global retention time correction is performed with the
OBI—warp algorithm (profStep:1, center:1). Features are then
grouped between samples with the density method (mzwid : 0.015 ).
Finally, missing peaks are filled by integrating the range of m/z and
retention times in the group using fillPeaks(). The resulting filled
peak groups contain at minimum one intensity value per sample, but
in many instances include multiple intensity values per sample.
When performing statistics, the groupval() function applies a filter
to select a value which will represent each sample. By default, this
naively selects the peak which is closest to the median retention time
of the group. All calculations are based on this groupval() output to
make results representative of diffreport() output as used in the con—
ventional workflow and by XCMS Online.

2.4.4 Warpgroup workﬂow

The Warpgroup workflow consists of the following steps. Global re—
tention time correction is performed with the OBI—warp algorithm
(profStep:1, center:1). A rough grouping of features is estab—
lished by grouping all features within 3ppm and 25 scans. In our
data sets this rough grouping ensured that all peaks which could
possibly be the same analyte across samples remained in the same
group—this also caused some groups to contain multiple peaks.
Here, these rough groups were refined with the Warpgroup
algorithm by a call to group.warpgroup (rt.max.drift:20,
ppm.max.drift:3, rt.aligned.lim:7). The resulting dataset con—
tained one peak per sample in every group, all of which described
the same region. This output xcmsSet was used for all further statis—
tics and assessment of the Warpgroup algorithm.

2.4.5 Selecting peak groups for comparison
The Warpgroup analysis assumes each detected peak represents a le—
gitimate peak region. Upon Warpgroup analysis of these regions, a

ﬁm'sreumol‘piqxo'sopeuuowtotq/ﬁdnq

Table 2

Fig. 1

Fig. 2
Table 1

Supplementary Fig. S7

Supplementary Figures S2 S3

Fig. 1

Figure 3

Fig. 3

1.00

 

0.75

 

 

 

 

/3.IO'S[EIIm0fp.IOJXO'SOIJEIIIJOJIIIOIq/ﬂduq

200

100

Traditional

Warpgroup

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Figure 1

 

 

Table 2

2009

Fig. 1

Smith ct al., 2015

Fig. 1

Figure 1
Aberg ct al.,

/3.IO'S[BIIm0[p.IOJXO'SOIJBIIIJOJIIIOIq/ﬂdnq

274

N. G.Mahieu et al.

 

The peak bounds for each missing sample are then returned
(Fig. 1B).

5.1.4 Grouping of peaks which deviate from the global retention
time drift

Warpgroup’s ‘grouping’ of peaks is a result of the subregion detec—
tion and splitting. In this mode, the EIC region supplied to
Warpgroup will envelop multiple peak groups and thus take longer
than the above modes (Fig. 1C). A small value for sc.aligned.lim
should be supplied if peak subregion detection is desired, or a larger
value if the goal is to distinguish two well—separated peaks. The re—
sult will contain a group for each detected peak group.

5.2 Output considerations
One major advantage of the Warpgroup workflow is the ability to
detect noise groups. The Warpgroup algorithm includes several
peak descriptors for each group after analysis. It is important to
note that Warpgroup output is dependent on the input and contains
all resulting groups, including noise. Due to the splitting approach,
this can result in a large increase in group number—many of which
may be redundant. Further, as noise regions have an under—deter—
mined warp path, these regions are often split into distinct regions.
Two descriptors generated by the algorithm can be used to detect
and filter these cases. These descriptors provide a type of quality
measurement of the group. The first descriptor is ‘n’—the number of
peaks originally detected which contribute to this group. This param—
eter is featured in the conventional workflow, but Warpgroup pro—
vides a more refined metric. Rather than n representing all features
eluting near each other, here 11 represents the detected features which
describe similar subregions of the chromatogram; thus, the metric is
much more reliable. In cases of high 11, feature detection agreed upon
the region of the chromatogram to call a peak. In cases of low 11, the
peak detection did not robustly detect the region and it is likely noise.
The second descriptor is ‘warp.consistency’. This metric meas—
ures how much the bounds shift when projected into each time—
domain and back. Chromatograms with a well—defined and con—
served topography will generate highly reproducible warp paths.
When bounds are projected through these warp paths, any intro—
duced shift will be small and this metric will be low. When bounds
are shifted through a poorly defined region, shifts will be greater
and this metric will be high. It is recommended to monitor and filter
peak groups based on these parameters prior to further analysis.

5.3 Challenges
A drawback of the Warpgroup approach is speed. As described in
Prince et al., ‘warping function . . . [scaling] . . . is bounded by com—
putational complexity (the more segmented the warp function the
more computation required)” (Smith et al., 2015). Warpgroup seg—
ments every distinct mass trace and, as such, the computational de—
mand is high. The DTW algorithm employed scales with the length
of the input as O(n2). Thus, as correspondence confidence decreases,
the length of the EIC supplied to Warpgroup increases and process—
ing time lengthens rapidly. Conversely, in cases where correspond—
ence confidence is high or the goal is simply consensus peak bound
and subregion detection for well—grouped peaks, the algorithm
remains very fast. Accordingly, the incorporation of mass and reten—
tion time drift correction as well as the establishment of correspond—
ence prior to Warpgroup is recommended.

Prince et al. raise several limitations of current correspondence
methods (Smith et al., 2015). Though not intended as a correspond—
ence algorithm, Warpgroup does address some of the challenges

these methods face. Most importantly, Warpgroup makes more real—
istic assumptions about the component—specific drift expected in
these datasets. Further, as a single reference sample is not used for
alignment, Warpgroup remains symmetric and robust. The algo—
rithm is easily implemented in most workflows as it relies on only
one required user—settable parameter.

5.4 Future directions

Improving the scaling with sample number is an important goal.
Although the current implementation is sufficient for many pub—
lished metabolomic studies, the analysis of larger datasets remains a
priority. Computation can be minimized by several strategies. For
many peak groups, refinement with Warpgroup will be unnecessary,
making minor or no modification to the predetermined group. In
these cases, Warpgroup can be omitted for all but the most complex
groups. The major computational step is the establishment of a
warp path between each sample. To reduce computation, the DTW
algorithm can be replaced with faster warping algorithms such as
PTW if the data allow. Finally, this implementation calculates the
full sample >< sample warping matrix. However, implementation of
a sparse matrix approach could be explored.

Although Warpgroup was presented here in the context of LC/
MS data, the input and output of the algorithm are of a general
form (multiple time series and regions within those time series.) As
such, the method is generalizable and can find consensus regions
within any time—series data. An example of Warpgrouping on echo—
cardiogram data (Goldberger et al., 2000;Penze1et al., 2000) can be
found in Supplementary Figure S9.

The Warpgroup algorithm as presented addresses several major
drawbacks of the current informatic workflow. Still, current pro—
cessing techniques leave significant room for improvement. The de—
velopment of more effective correspondence algorithms is a critical
step for the advancement of the field (Smith et al., 2015).
Additionally, we see promise in leveraging the information
embedded in the component—specific drift observed in these datasets.
For example, the drift data may be used to cluster ions into compos—
ite spectra and to inform further identification.

6 Conclusion

In summary, we have found Warpgroup to be an important refine—
ment step for current integration and correspondence methods. With
Warpgroup refinement in place, data processing results remain robust
across a wide range of experimental conditions. Major advantages
have been noted in coverage as well as quantitation, especially in low—
abundance signals. Further, Warpgroup output includes additional
descriptors which can be used to filter noise and unreliable groups
from the final datasets. Overall, we expect the addition of a
Warpgrouping step to the informatic workflow to improve the quality
and reliability of untargeted metabolomic analyses.

Supporting data

The LC/MS datasets used in benchmarking of the Warpgroup algo—
rithm can be found on our laboratory website at http://pattilab.
wustl.edu/software/warpgroup/.

Acknowledgements

We would like to thank Dr. Robert Pless for his valuable guidance in helping
develop this work.

ﬁm'sreumol‘prqxo'sopeuuowtotq/ﬁdnq

Increased precision of metabolomic data processing

275

 

Funding

G.J.P. received ﬁnancial support for this work from the National Institutes of
Health Grants R01 ES022181 and L30 AGO 038036, as well as the Alfred P.
Sloan Foundation, the Camille and Henry Dreyfus Foundation, and the Pew
Scholars Program in the Biomedical Sciences.

Conﬂict of Interest: none declared.

References

Abate-Pella,D. et al. (2015) Retention projection enables accurate calculation
of liquid chromatographic retention times across labs and methods.
]. Chromatogr. A, 1412, 43—51.

Aberg,K.M. et al. (2009) The correspondence problem for metabonomics
datasets. Anal. Bioanal. Chem, 394, 151—162.

Buszewski,B. and Noga,S. (2012) Hydrophilic interaction liquid chromatog-
raphy (HILIC)—a powerful separation technique. Anal. Bioanal. Chem,
402, 231—247.

Cappadona,S. et al. (2012) Current challenges in software solutions for mass
spectrometry-based quantitative proteomics. Amino Acids, 43, 1087—1108.

Crutchﬁeld,C.A. et al. (2010) Mass spectrometry-based metabolomics of
yeast. Methods Enzymol., 470, 393—426.

Csardi,G. and Nepusz,T. (2006) The igraph software package for complex
network research. Interjonrnal Complex Sy, 1695.

Fuhrer,T. and Zamboni,N. (2015) High-throughput discovery metabolomics.
Curr. Opin. Biotechnol., 31, 73—78.

Giorgino,T. (2009) Computing and visualizing dynamic time warping align-
ments in R: the dtw package. ]. Stat. Softw, 31, 1—24.

Goldberger,A.L. et al. (2000) PhysioBank, PhysioToolkit, and PhysioNet:
components of a new research resource for complex physiologic signals.
Circulation, 101, e215—e220.

Ivanisevic,]. et al. (2013) Toward ‘omic scale metabolite proﬁling: a dual sep-
aration—mass spectrometry approach for coverage of lipid and central car-
bon metabolism. Anal. Chem, 85, 6876—6884.

Kall,L. and Vitek,O. (2011) Computational mass spectrometry-based prote-
omics. PLoS Compnt. Biol., 7, e1002277.

Kele,M. and Guiochon,G. (2000) Repeatability and reproducibility of reten-
tion data and band proﬁles on reversed-phase liquid chromatography col-
umns]. Chromatogr. A, 869, 181—209.

Mahieu,N.G. et al. (2014) Credentialing features: a platform to benchmark and
optimize untargeted metabolomic methods. Anal. Chem, 86, 95 83—95 89.

Nikolskiy,I. et al. (2013) An untargeted metabolomic workﬂow to improve
structural characterization of metabolites. Anal. Chem, 85, 7713—7719.

Patti,G.]. et al. (2012) Innovation: Metabolomics: the apogee of the omics tril-
ogy. Nat. Rev. Mol. Cell Biol., 13, 263—269.

Penzel,T. et al. (2000) The apnea-ECG database. In: Computers in Cardiology
2000. Vol.27 (Cat. 00CH37163). IEEE, pp. 255—258.

Podwojski,K. et al. (2009) Retention time alignment algorithms for LC/MS
data must consider non-linear shifts. Bioinformatics, 25, 758—764.

Pons,P. and Latapy,M. (2005) Computing communities in large networks using
random walks (long version). Lect. Notes Comput. Sci., 3733, 284—293.

Prince,].T. and Marcotte,E.M. (2006) Chromatographic alignment of ESI-LC-
MS proteomics data sets by ordered bijective interpolated warping. Anal.
Chem, 78, 6140—6152.

Quarry,M.A. et al. (1984) Measurement and use of retention data from high-
performance gradient elution. ]. Chromatogr. A, 285, 19—51.

R Core Team (2014) R: A Language and Environment for Statistical
Computing.

Rabiner,L.R. (1978) Considerations in dynamic time warping algorithms for
discrete word recognition. ]. Aconst. Soc. Am, 63, S79.

Smith,C.A. et al. (2006) XCMS: processing mass spectrometry data for metab-
olite proﬁling using nonlinear peak alignment, matching, and identiﬁcation.
Anal. Chem, 78, 779—787.

Smith,R. et al. (2015) LC-MS alignment in theory and practice: a comprehen-
sive algorithmic review. Brief. Bioinform., 16, 104—117.

Tautenhahn,R. et al. (2008) Highly sensitive feature detection for high reso-
lution LC/MS. BMC Bioinformatics, 9, 504.

Tautenhahn,R. et al. (2012) XCMS Online: a web-based platform to process
untargeted metabolomic data. Anal. Chem, 84, 5035—5039.

Vandenbogaert,M. et al. (2008) Alignment of LC-MS images, with applications
to biomarker discovery and protein identiﬁcation. Proteomics, 8, 65 0—672.

Wehrens,R. et al. (2015) Fast parametric time warping of peak lists.
Bioinformatics, 31, 3063—3065.

ﬁm'sreumol‘prqxo'sopeuuowtotq/ﬁdnq

