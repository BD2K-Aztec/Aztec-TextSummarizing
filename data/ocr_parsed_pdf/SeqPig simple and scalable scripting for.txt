BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

A.Schumacher et al.

 

reads = LOAD 'ir1.qseq' USING QseqLoader();
STORE reads INTO 'out.fq' USING Fasthtorer();

Fig. 1. Converting Qseq into Fastq; the dataset is simply read and then
written using the appropriate load/store functions

reads = LOAD 'in.fq' USING Fasthoader();
read_bases = FOREACH reads GENERATE
UnalignedReadSplit(sequence, quality);
read_gc = FOREACH read_bases {
only_gc = FILTER $0 BY readbase == 'G'
OR readbase == 'C';
GENERATE COUNT(only_gc) AS count;
}
gc_counts = FOREACH (GROUP read_gc BY count)
GENERATE group AS gc_cnt, COUNT($I) AS cnt;
DUMP gc_counts;

Fig. 2. Script that generates a histogram for GC content of reads. The
script loads a Fastq ﬁle, splits each read into separate bases and for each
read coordinate ﬁlters only bases that are either G or C. The ﬁltered bases
are then counted and counts are grouped. Finally, the script prints
records which contain the GC count and the count of reads that have
the given GC count

mapping (for pileups, extracting SNP positions) and more. It comes
packaged with scripts that calculate various statistics and manipulations
on read data, which also serve as examples. The growing library of func-
tions and scripts is documented in the SeqPig manual. Contributions
from the community are welcome and encouraged. Figures 1 and 2
show script examples. For a more detailed list of features and more
examples please see the project Web site: http://seqpig.sourceforge.net/.

To evaluate SeqPig, we implemented a script that calculates most of the
read quality statistics that are collected by the popular FastQC tool
(Andrews, 2010). The script is included with the examples (fast_fastqc.
pig). We ran a set of experiments, which measured the speed-up gained
by using SeqPig on Hadoop clusters of different sizes compared with using
a single-node FastQC run. We used a set of Illumina reads as input (read
length: 101 bases; ﬁle size: 61.4 GB; format: Fastq). Software versions were
as follows: FastQC 0.10.1; Hadoop 1.0.4; Pig 0.11.1. All tests were run on
nodes equipped with dual quad-core Intel Xeon CPUs  2.83 GHz, 16 GB
of RAM and one 250 GB SATA disk available to Hadoop. Nodes are
connected via Gigabit Ethernet. FastQC read its data from a high-per-
formance shared parallel file system by DDN. SeqPig used the Hadoop ﬁle
system, which uses each node’s local disk drive.

We ﬁrst ran ﬁve different SeqPig read statistics for a different number
of computing nodes: the sample distribution of (i) the average base qual-
ity of the reads; (ii) the length of reads; (iii) bases by position inside the
reads; and (iv) the GC contents of reads. Finally, we combined them into
a single script. Each of the executions results in a single MapReduce job
and thus a single scan through the data. All runs were repeated three
times and averaged (deviation from average <7%). From Figure 3 one
can see that it is possible to achieve a significant speed-up by exploiting
the parallelism in read and base statistics computation using Hadoop.
Further, the total runtime of the script that computes all statistics is
mostly determined by the slowest of the individual ones, as the complete
script is compiled into a single map-only job. A different observation is
that for most of the statistics computed, we are able to achieve a close to
linear speed-up compared with FastQC until 48 nodes. We assume that
the leveling off is due to the Hadoop job overhead eventually dominating
over speed-up due to parallelization, depending on input ﬁle size.

SeqPig enables simple and scalable manipulation and analysis of
sequencing data on the Hadoop platform. At CRS4 SeqPig is already
used routinely for several steps in the production workﬂow; in addition,
it has been successfully used for ad hoc investigations into data quality

 

  

 

 

 

 

60 . . .
avg readqual —~—
read length 
50 _ basequalstats --
0 GO contents  E-v-
g all at once --+--
a 40 -
u.
(I)
a
33 30 -
>
D.
3
B 20 -
(D
Q.
(I)
10 -
0 . . . . .
0 10 20 30 40 50 60 70

Worker nodes

Fig. 3. Results of an experiment with an input file of 61.4GB and a
different number of Hadoop worker nodes. The script does not currently
implement all FastQC statistics (we expect the missing ones to scale
similarly in SeqPig), whereas the per-cycle quality distribution is not
computed by FastQC

issues, comparison of alignment tools and reformatting and packaging
data. We have also tested SeqPig on Amazon’s Elastic MapReduce service,
where users may rent computing time on the cloud to run their SeqPig
scripts and even share their S3 storage buckets with other cloud-enabled
software. Instructions are provided in the Supplementary Material.

Funding: This work was supported by the Cloud Software and
D21 Programs of the Finnish Strategic Centre for Science,
Technology and Innovation DIGILE; Academy of Finland
[139402]; the Sardinian (Italy) Regional Grant [L7—2010/
COBIK]; COST Action BM1006 “Next Generation Sequencing
Data Analysis Network”, Squhead. Computational resources
were provided by CRS4 and ELIXIR node hosted at CSCiIT
Center for Science.

Conﬂict of Interest: none declared.

REFERENCES

Andrews,S. (2010) Fastqc. a quality control tool for high throughput sequence data.
http://www.bioinformatics.babraham.ac.uk/projects/fastqc (8 November 2013,
date last accessed).

Chen,Y. et a]. (2012) Interactive analytical processing in big data systems: a cross—
industry study of MapReduce workloads. In: Proceedings of the VLDB
Endowment. Vol. 5, VLDB Endowment, pp. 180271813.

Langmead,B. et a]. (2009) Searching for SNPs with cloud computing. Genome Biol.,
10, R134.

Marx,V. (2013) Biology: the big challenges of big data. Nature, 498, 2557260.

Niemenmaa,M. et a]. (2012) Hadoop—BAM: directly manipulating next generation
sequencing data in the cloud. Bioiiy’ormuticx, 28, 8767877.

Nordberg,H. et a]. (2013) BioPig: a Hadoop—based analytic toolkit for large—scale se—
quence data. Bioiiy’ormuticx, [Epub ahead of print, doi: 10.1093/bi0informatics/
btt528, September 10, 2013].

O’Connor,B. et a]. (2010) Square query engine: storing and searching sequence
data in the cloud. BMC Bioiiy’ormuticx, 11 (Suppl. 12), S2.

Pireddu,L. et a]. (2011) SEAL: a distributed short read mapping and duplicate
removal tool. Bioinformuticx, 27, 215972160.

Robinson,T. et a]. (2011) SAMQA: error classiﬁcation and validation of high—
throughput sequenced read data. BMC Genomics, 12, 419.

Schonherr,S. et a]. (2012) Cloudgene: a graphical execution platform for MapReduce
programs on private and public clouds. BMC Bioiiy’ormuticx, 13, 200.

Stein,L. (2010) The case for cloud computing in genome informatics. Genome Biol.,
11, 207.

Taylor,R. (2010) An overview of the Hadoop/MapReduce/HBase framework and its
current applications in bioinformatics. BMC Bioinfommtim‘, 11 (Suppl. 12), SI.

Whelan,C.W. et a]. (2013) Cloudbreak: accurate and scalable genomic structural
variation detection in the cloud with MapReduce. arXiv:1307.2331.

 

120

ﬁm'spzumol‘pmﬂo'sopeuuopuotq/ﬁdnq

