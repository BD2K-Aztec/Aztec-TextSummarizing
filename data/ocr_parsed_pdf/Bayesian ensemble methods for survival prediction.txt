ORIGINAL PAPER

Vol. 27 no. 3 2011, pages 359-367
doi: 1 0. 1 093/bioinformatics/btq660

 

Gene expression

Advance Access publication December 8, 2010

Bayesian ensemble methods for survival prediction in gene

expression data

Vinicius Bonatol, Veerabhadran Baladandayuthapanizaik, Bradley M. Broom3,
Erik P. Sulman4, Kenneth D. Aldape5 and Kim-Anh D02

1Pfizer Inc., Groton, CT 06340, 2Department of Biostatistios, 3Department of Bioinformatics and Computational
Biology, 4Department of Radiation Oncology and 5Department of Pathology, The University of Texas, M. D. Anderson

Cancer Center, Houston, TX 77030, USA
Associate Editor: Trey Ideker

 

ABSTRACT

Motivation: We propose a Bayesian ensemble method for survival
prediction in high-dimensional gene expression data. We specify
a fully Bayesian hierarchical approach based on an ensemble
‘sum-of-trees’ model and illustrate our method using three popular
survival models. Our non-parametric method incorporates both
additive and interaction effects between genes, which results in
high predictive accuracy compared with other methods. In addition,
our method provides model-free variable selection of important
prognostic markers based on controlling the false discovery rates;
thus providing a unified procedure to select relevant genes and
predict survivor functions.

Results: We assess the performance of our method several
simulated and real microarray datasets. We show that our method
selects genes potentially related to the development of the disease
as well as yields predictive performance that is very competitive to
many other existing methods.

Availability: http://works.bepress.com/veera/1/.

Contact: veera@mdanderson.org

Supplementary Information: Supplementary data are available at
Bioinformatics online.

Received on May 6, 2010; revised on October 19, 2010; accepted
on November 27, 2010

1 INTRODUCTION

Gene expression proﬁling using DNA microarray technology has
successfully identiﬁed molecular Classes of cancer and revealed
gene expression patterns that are associated with disease recurrence
or prognosis of patient survival (Berchuck et al., 2005). Survival
prediction is often formulated in terms of categorical outcomes
(e.g. ‘poor’ versus ‘good’ prognosis), which may be useful
for guiding decisions about cancer management and treatment
(Ross, 2009). However, due to a large degree of heterogeneity
observed within prognostic Classes, prediction of time to a Clinical
event/occurrence may not be successful. Improved accuracy of
survival prediction can be attained by relating time-to-event
measures directly with gene expression proﬁles, which requires
speciﬁc survival analysis methods that account for the presence
of right censored outcomes, such as the (multivariable) Cox

 

*To whom correspondence should be addressed.

proportional hazards (CPH) model (Cox, 1972) and the accelerated
failure time model (AFT; Klein and Moeschberger, 1997). In our
context, we deﬁne the (uncensored) survival time as the dependent
variable of interest representing the time to an event (such as death
or recurrence), and a right censored observation is an observation
that is lost to follow-up after the period of study.

In spite of their widespread use in other settings, these standard
multivariable survival methods cannot be directly applied to Clinical
outcome prediction using gene expression data because the number
of covariates (genes) under investigation is considerably larger than
the number of samples (patients)—the ‘large 1), small 11 problem’
(West, 2003). Many different strategies have been employed to
solve this high dimensionality problem. For example, Clustering
techniques have been applied to group-correlated sets of genes,
(D’haeseleer, 2005), linear combinations of covariates obtained by
the partial least squares method (Nguyen and Rocke, 2002; Park
et al., 2002) or the principal components of the design matrix
(Li and Gui, 2004) have been used as explanatory variables in
survival regression models. In addition, some authors have proposed
the use of penalized versions of the CPH model, L1-penalized
(Lasso regression) and L2-penalized (ridge regression) versions,
for estimating parameters while simultaneously performing variable
selection (Gui and Li, 2005; Park et al., 2002; Tibshirani, 1997).
Similarly, Datta et al. (2007) developed penalized variants of
the AFT model for ﬁtting high-dimensional datasets. Bayesian
techniques for variable selection have also been developed for
Weibull and CPH models (Lee and Mallick, 2004) as well as for
the AFT model (Sha et al., 2006).

Although these strategies address the high-dimensionality
problem with some degree of success, they fail to incorporate
complex interactions between genes because they model genes
in an additive and linear manner. Ensemble methods such as
bagging (Breiman, 1996), boosting (Friedman, 2001) and random
forests (Breiman, 2001) are ﬂexible alternatives for accommodating
variable interactions that are more stable in high-dimensional
settings (Breiman, 2001). Because ensemble methods use a linear
combination of trees to ﬁt data variations such that each tree ﬁts
part of the data, these methods have been shown to have high
predictive accuracy (Lee et al., 2005). The ensemble methods
were originally developed for modeling binary or continuous
responses. Extensions for modeling survival data, often called
survival ensembles (Hothorn et al., 2006), address the censoring
problem by growing relative risk forests (Ishwaran et al., 2004), by

 

© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 359

112 /3.Io's[BumoIpJOJXO'sonBurJOJurorq”:duq 11101} papBOIH/lAOG

91oz ‘Og anﬁnv uo ::

V.Bonato et al.

 

imputing censored observations (Ishwaran et al., 2008) or by using
a Kaplan—Meier curve aggregation procedure to predict the survival
of a new observation (Hothorn et al., 2004). In general, survival
ensemble methods estimate a survival ﬁinction for each terminal
node of the tree, weighing censored observations differently, and
then perform predictions by dropping down the tree to a new
observation (Hothorn et al., 2006). A different approach proposed
by Schmid and Hothorn (2008) estimates the predictor ﬁinction
of the AFT model simultaneously with the estimation of the scale
parameter, so that the boosting algorithm can be applied to minimize
a predeﬁned loss function. Bayesian estimation has been shown to
improve the predictive performance of tree models with nominal
or continuous responses (Chipman et al., 1998; Denison et al.,
1998; Pittman et al., 2004). The application of Bayesian survival
ensembles, however, has been limited to a study by Clarke and West
(2008), in which they proposed using a tree-based Weibull model to
predict the outcome of advanced stage ovarian cancer.

In this article, we propose a Bayesian ensemble method for
survival prediction that is appropriate for high-dimensional data
such as gene expression data (Section 2). Our approach is based
on the ensemble ‘sum-of—trees’ model (Chipman et al., 2010)
and is deﬁned by a likelihood and a prior. We specify a fully
Bayesian hierarchical approach with uncertainty in estimation being
propagated at each stage of the hierarchy to make predictions. We
illustrate our methodology using three popular survival models: the
CPH (Section 2.1), Weibull (Section 2.2) and AFT models (Section
2.3). Our approach is unique as we overcome the lack of conjugacy
by using a latent variable formulation to model the covariate effects,
which not only allows stochastic deviations from the parameteric
model but also results in efﬁcient and computationally less expensive
model ﬁtting. Our approach is non-parametric and incorporates
additive and interaction effects between genes, which results in high
predictive accuracy as compared with other methods. In addition,
our method provides model-free variable selection of important
predictive prognostic markers that is based on controlling the false
discovery rates (Section 2.5). We compare the predictive accuracy
of our method with baseline reference survival methods that were
reviewed by van Wieringen et al. (2009) using a benchmark breast
cancer dataset (Section 3.1). We also apply our methodology to a
brain tumor dataset (Section 4) and conclude with a brief discussion
(Section 5). Additional technical and computational details as well
as simulation results are available via Supplementary Materials.

2 METHODS

We denote the observed data for the i-th patient (i=1,...,n) as 1,». the
survival time. along with 8,». the event indicator function. where 8,20 if
the data are right censored and (3,21 if they are not. In addition to the
survival response. the p-dimensional vector of the covariates (genes/probes)
potentially associated with the i-th patient survival time. X». is also available.
Let t: ([1 , . . . , tn) denote the vector of the survival times and let anp denote
the matrix of the gene expression data. In the following sections. we develop
the survival distribution. which aids to predict the survival time of a new
patient with covariates Xnew.

Modeling the survival data usually proceeds in two steps: (i) speciﬁcation
of a sampling distribution p(tU”(X)). conditional on a function of the
covariates f(X). such as modeling either the hazard function (as in CPH
models) or directly modeling the survival time (as in Weibull and AFT
models) and (ii) speciﬁcation of the regression function f (X). which models
the covariate effects. For computational convenience. the covariates are

usually assumed to be linear and independently related to survival. such that
f(X)=X’/3 where [3 is a vector of [7 unknown regression coefﬁcients that
captures the covariate effects on the survival time or hazard. There are two
drawbacks to this approach. First. the linear and independent assumption
is a restrictive one. Second. and more importantly. in high-throughput
studies such as those based on gene expression data. the problem becomes
much more complex when p. the dimension of X. is very large. possibly
larger than the sample size n. This makes the estimation of [3 unstable
and exacerbates the high dimensionality problem if interactions between
covariates are considered. Dimension reduction approaches such as feature
selection or partial least squares methods alleviate this problem to a certain
degree. However. these methods are based on a linear relationship between
the response and the covariate. which may not be very realistic. If the actual
f is non-linear. these models may fail to produce a reasonable prediction due
to a lack of ﬂexibility. We propose to model f (X) in a ﬂexible manner using
ensemble methods that not only accommodate non-linear effects but which
also incorporate the interactions of the covariates to estimate the effects on
survival time. The non-parametric representation of f (X) is introduced in the
context of three alternative established survival time models in the following.

2.1 Ensemble-based proportional hazards regression

The Cox proportional hazards model (CPH; Cox. 1972). one of the most
popular survival models in the statistical literature. does not model the time-
to-event measures directly; rather. it models the hazard function h(t). at any
time t as

W IX) = ha(l)exp(w) ,

where h0(t) is the baseline hazard function and a) is an unknown function
modeling the associated latent covariate effect. The joint conditional survival
function of t in the CPH model can then be written as

S<tlw.A>=exp(—Z;;l A<zi>exp(wi>) .

where A represents the cumulative hazard function. The associated
complicated form of the likelihood makes it impossible to express conditional
distributions of the parameters (a), A) in closed forms (Ibrahim et al.. 2001).
As a result. the drawing of posterior distributions requires the sampling of
all model parameters using complex Markov chain Monte Carlo (MCMC)
procedures at each iteration. which makes the process computationally
intensive and potentially leads to poor mixing. especially in high-dimensional
settings.

We simplify the joint likelihood in two ways. First. for the cumulative
hazard function. we follow the approach of Kalbﬂeisch (1978) by specifying
a Gamma process prior for A. such that

A ~g73(aA*,a) .

where A* is the mean process and a is a weight parameter about the mean
with A(t)~G aA*(t),a . The use of the Gamma process prior allows us

to analytically integrate out the A vector. such that the marginal likelihood.
conditional on a). can be written as

Law) 2 exp(— ZaWiA*(ti)) H (a),*(ti)Wi)3i »

where 8,» is the indicator for the event. V, = ZleR<ti)exp(wl). i: 1, . . . , n. R(t,»)
is the set ofindividuals at risk at time 1,». and W, = — log{1 — exp(wi)/(a + Vi)}.

Second. we modify the model by treating the refs as random latent
variables. conditional on the [[5 being independent of the X55 by the
following factorization: p(ti|wi)p(wi |X,»). This latent variable construction has
the following advantages: (i) allows deviations from the ﬁxed parameteric
survival models by including a latent error term (6) and (ii) preserves the
conjugacy of the ensemble structure which enables us to employ efﬁcient
MCMC algorithms such as Gibbs sampler that greatly aids computations
for such large datasets. Speciﬁcally. we assume a Gaussian process on
p(w|X,). such that wi=f(Xi)+ei. where f(X,») is the regression function
and 6,» are residual random effects assumed to be distributed Normal(0,r72).

 

360

112 /3.Io's[BrunoIpJOJXO'sorwurJOJurorq”:duq 11101} papaolumoq

91oz ‘Og anﬁnv uo ::

Ensemble methods for survival prediction

 

The residual random effects. 6,». account for the unexplained sources of
variation in the data. most probably due to explanatory variables (genes)
not included in the study (Lee and Mallick. 2004).

We approximate f(o) using a tree-based ensemble method in order to
model the non-linearity effects of the genes and also to account for the
high dimensionality of the data. We use the ‘sum-of—trees’ approach of
Chipman. George and McCulloch (2010; hereafter referred to as CGM).
which they called the Bayesian additive regression trees (BARTS) model.
as our candidate choice due to its excellent predictive performance on
a variety of datasets. Compared with other ensemble methods. BART is
preferable because it is explicitly deﬁned in terms of a full probability model.
i.e. with likelihoods and priors. and. therefore. can be used to implement
a full Bayesian hierarchical approach for the estimation of all relevant
uncertainties. BART as developed by CGM only considered continuous and
categorical outcome variables. and in the following we extend it to survival
models in the presence of censoring in high-dimensional settings using a
fully Bayesian hierarchical framework. We present a brief review of BART;
see CGM for more details.

Let T represent a single decision tree containing both internal and terminal
nodes. Internal nodes of the tree are grown through recursive partitions of
the data using splitting rules. Splitting rules produce binary splits of the data
and are deﬁned in terms of splitting variables and cutoff values. Dropping
an individual with covariates xi down the tree assigns it to a terminal node
according to the tree splitting rules. Let each tree be indexed by B terminal
nodes and deﬁne p. =(u1 , . . . , [1.3) as the vector of averages m, of individuals
assigned to the same node i). where b = 1, . . . ,B. Thus. each observation can
be mapped by a functionf such that f(x,»)=g(x,»,T,p.). Since BART is a
‘sum-of—trees’ model. f can be approximated by

 = (zit/11:1  Tm; Mm)) 9

where M is the total number of trees. Compared to single tree models.
BART is more ﬂexible since several trees incorporate the additive effects
and. consequently. improve estimation. However. a large number of trees
can increase the computation time. We discuss the computational trade-offs
related to the size of M in later sections.

To complete the full Bayesian hierarchical formulation of our ensemble-
based proportional hazards regression model. we need to specify
the following priors: [7(a) U”(X),c72),p(c72|<l>) and p(f|<I>) where (D 2
(T1, p. 1 , . . . , Tm , um) represents the tree-speciﬁc parameters. Our prior for p(f )
is of the form

M

M
 1117011141411) = H  ) 7701'»: le)}»

111:] 111:]

where the second equality is obtained by recursively conditioning on the
terminal nodes.

We follow CGM and deﬁne p(T,,,) by three factors: (i) the distribution
on the splitting variable assignments at each interior node is a uniform
prior over all available variables; (ii) the distribution on the splitting rule
assignment in each interior node. conditional on the splitting variable. is a
uniform distribution over the set of available splitting values; and (iii) the
probability that a node at depth d is non-terminal is given by c(1+d) _e.
where c e (O, 1) and e e [0, 00) are ﬁxed parameters controlling the size of the
tree. Following CGM. we set 020.95 and 2:2 to give prior probabilities
Of (0.05. 0.55. 0.28. 0.09 and 0.03) for trees to have (1. 2. 3. 4. 35) terminal
nodes. respectively. As in CGM. we assume i.i.d conjugate normal priors
for p(p.,,|T,,). Assigning prior distributions for the set of tree parameters
T and p. constrains the size of the trees. which avoids having the model
populated by noninformative covariates. This imposed variation in the tree
size grants BART the ﬂexibility to accommodate the main effects as well as
the interactions of different orders (more than one splitting rule). This results
in a better predictive performance from BART compared with competing
methods such as random forest and boosting algorithms. To complete the
prior formulations. we assume a conjugate inverse chi-squared distribution

on :72 as [:72] ~ vn/XE. where v is a data-determined ﬁxed hyperparameter.
The full conditional posterior distributions for sampling can be accessed Via
the Supplementary Material.

The complete hierarchical Bayesian model for the ensemble-based CPH
model can be concisely written as

[tlw] ~ L(t|w).
[w,y(x,),a2] ~ Normal (f(X,),a2),
f (Xi) ~ Tree(<1>).
(:2 ~ xﬁ.

where Tree(o) encompasses all the priors and distributional assumptions
detailed in the above paragraph.

2.2 Ensemble-based Weibull regression

The Weibull model is parametric and used extensively to describe lifetimes.
and can be reparameterized as both a CPH and an AFT model (Klein
and Moeschberger. 1997). The Weibull distribution is indexed by a shape
parameter r and scale parameter tlfi, and models the probability of survival
at time t, for patient 1' as

fUiIE Elf) = TllfiSKEW—1W})I(t,>0;r>0;z//,>0)-

Reparametrizing the scale parameters as cu,» =log(1lt,»). the Weibull
likelihood can be written as
f(tilr. w.) = n,“ expo). —exp(w.z;>)1(.,>o;.>m.
and the survival function as S (tilt, mi) 2 exp ( — exp(w,»)tir  Letting A = 28,
represent the number of censored observations. the joint likelihood function
for the parameter r and the vector of parameters a) 2(a)] , . . . , can) becomes

" 5 1—5
L(r.m|X.t.8) :Hf(z,|r.m,)’s(zi|r.m,) ’
1:1
1

:rAexp(Z(8,-mi+8i(ril)1og(t;))7Zexp(m;)tf).
1:1 [:1

As in the previous section. we model the covariate effects using a latent
variable formulation. as wi~Normal(f(Xi),02). and use BART to model
f. We complete our hierarchical model by assigning a conjugate gamma
prior on r as Gamma(r0,k0). with ﬁxed but vague hyperparameters. Thus.
our ensemble-based Weibull regression model can be concisely written
(following the above notations) as.

[ti | 1'. mi] N Weibull(r, mi),
[1'] ~ Gamma(r,, , k0),
[wi1f(X)v‘72] ~ Normal(f(X,»),az),
f (X) N Tree(<I>).
(:2 ~ XE,

2.3 Ensemble-based accelerated failure time model

The AFT model is a parametric survival model that assumes that the
individual survival time t, depends on the multiplicative effect of an unknown
function of covariates f (X,) over a baseline survival time oz. The AFT model
(on log scale) can be written as.

log(t,)=cx+f(Xi)+ei. i=1,...,n

where f captures the covariate effects affecting the (log) survival time
directly.

We assume that the random errors. 6’s. are normally distributed; however.
we can easily adopt other distributions such as an extreme value or 1
distribution (Klein and Moeschberger. 1997). Note that under an extreme
value distribution. the AFT model is equivalent to the Weibull model
described previously.

As before. let a) be a latent variable such that cu,» =f(X,»)+e,». where the
655 are i.i.d Normal (0,02). The AFT model can then be expressed using

 

361

112 /3.Io's[BrunoIpJOJXO'sorwuiJOJurorq”:duq 11101} papaolumoq

91oz ‘Og anﬁnv uo ::

V.Bonato et al.

 

the data augmentation approach of Tanner and Wong (1987) to impute the
censored values as.

log(t;‘)=oi+wi if 8,21,
log(t;‘)>oi+wi if 8,20,

where at is assigned a conjugate normal prior distribution as Normal(oi0,oic).
where an and etc are ﬁxed hyperpararneters.
Thus. our ensemble-based AFT model can be succinctly written as

[lila’whf] Normal(oi+wi.f72),

[04010.6] ~ Normal(oi0 , ac).
[in(X),02] ~ Normal(f(X,»),r72),
f(Xi) N 1336(4))»
:72 ~ XE.

2.4 Model ﬁtting via MCMC

We use MCMC (Gilks et al.. 1996) algorithms to generate samples from
the posterior distributions. The full conditionals for all three models.
CPH. Weibull and AFT. as well as some examples of MCMC chains and
computation times can be accessed Via the Supplementary Materials. In
addition. the algorithm for the proposed models is made available in R
language at http://works.bepress.com/Veera/1/. The speciﬁc drawing scheme
for the CPH model uses a Gibbs sampler to estimate the set of parameters
(a), (Roz). Gibbs sampling iterates k: 1, . . . ,K times through the following
steps:

(i) update <I> using the Bayesian backﬁtting MCMC algorithm described
in CGM;
(ii) update 02|<I> using a Gibbs sampler;

(iii) update [wi|<1>,02]. where i: 1, . . .,n. using for each cu,» a Metropolisi
Hastings procedure with a proposal density q(wi,w;“) that generates
moves from the current state co,» to a new state (of. The probability of
accepting the change is given by

. P(w§‘|wi¢i.X~1)II(w§‘wwi)
71ml. 2 mm , —*
[7(wi 1wl¢i~Xv 011(0):: mi)

The posterior distributions of the Weibull model parameters (a), <1), 1102)
are obtained in a similar manner:

(i) update <I> using the Bayesian backﬁtting MCMC algorithm described
in CGM;
(ii) update 02|<I> using a Gibbs sampler;

(iii) update [wi|<1>, 1:02] componentwise. where i = 1, . . . , n. using for each
cu,» a similar MetropolisiHastings procedure with the probability of
accepting the change given by

. P(w§‘lwi¢i.X.lw5wT)4(w?~wi)
71ml. 2 mm , 7.,
p(wilwi¢i.X.t.6. r)q(wi.w,»)

(iv) update [r|w, <1), :72] using the MetropolisiHastings procedure with the
acceptance probability given by

, p(r*|w,<l>,t,8)q(r*,r)
it, 2 mm 1, — .
p(r|w, <1), I, 8)q(r, r*)

The drawing scheme for the AFT model parameters @0402 follows ﬁve
steps:

(i) update <I> using the Bayesian backﬁtting MCMC algorithm described
in CGM;
(ii) update 02|<I> using a Gibbs sampler;
(iii) obtain [a|<1>, :72 , 1];
(iv) update cu,» if 8,» = 1;

(V) sample from a Normal(oi+wi,r72) truncated at t, if 8,» = 0.

2.5 FDR-based variable selection for Ensemble-based
models

One of the key goals of gene expression data analysis is selection of
important predictive genes. As stated previously. BART offers a model-free
mechanism for variable/gene selection. Once we apply the MCMC methods
described in Section 2.4. we are left with posterior samples of the model
parameters that we can use to perform Bayesian inference. The MCMC
samples explore the distribution of possible tree conﬁgurations suggested by
the data. with each conﬁguration leading to a different sets of genes. Some
gene conﬁgurations that are strongly supported by the data may appear in
most of the MCMC samples. while others with less evidence may appear
less often. There are different ways to summarize this information in the
samples. One could choose the most likely (posterior mode) conﬁguration
and conduct conditional inference on this particular gene set. The beneﬁt of
this approach would be the yielding of a single set of deﬁned genes. but the
drawback is that the most likely conﬁguration might still only appear in a
very small proportion of MCMC samples. Alternatively. one could use all of
the MCMC samples and. using Bayesian model averaging. mix the inference
over the various conﬁgurations Visited by the sampler. This approach better
accounts for the uncertainty in the data. leads to estimators with the smallest
prediction error and should lead to better predictive performance. We will
use this Bayesian model averaging approach.

Suppose from our MCMC. we have K posterior samples of the
corresponding parameter set. Let [7]- denote the posterior probability of the
inclusion of the j-th gene. represented by yj. in the model withj=1,...,p.
We approximate 17]- based on the relative frequency of occurrence. (3,7,. of the
i-th gene across the k MCMC samples as

K
_ 1
Pj=EZ¢ﬂh
k:1

where oik is the indicator function 100- 6 X0”). and X“) is the set of covariates
used to the build the tree model in the k-th MCMC iteration. Note that
(1 —pj) can be interpreted as Bayesian q-Values. or estimates of the local
false discovery rate (FDR; Newton et al. 2004; Storey 2003) as they measure
the probability of a false positive if the j-th gene is called a discovery or is
signiﬁcant. Given a desired global FDR bound at 6(0, 1). we can determine
a threshold $0, to ﬂag a set of genes X45“ ={j :pj > $0,} as signiﬁcant. The
signiﬁcance threshold $0, can be determined based on classical Bayesian
utility considerations. such as in Muller et al. (2004). based on the elicited
relative costs of false positive and false negative errors or can be set to control
the average Bayesian FDR as in Morris et al. (2008). which we follow here.
For example. suppose we are interested in ﬁnding the value $0, that controls
the overall average FDR at some level oz. meaning that we expect only 100a%
of the genes to be declared as signiﬁcant are in fact false positives. For all
genes yj,j=1,...,p. we sort [7]- in descending order to yield pg),j=1,...,p.
Next. $0, 217(5). where E = max[j* :(j*)_l  {1 — 2pm} 50;]. Then we can
claim the set of genes X45“ to be signiﬁcant corresponding to an expected
Bayesian FDR of oz.

3 PERFORMANCE ASSESSMENT

We assess the performance of our method using cross-validation,
i.e. we randomly split the data into mutually exclusive training and
test sets in a ﬁxed proportion, build the predictor using the training
set, and then predict survival for the test set and compare it with the
observed survival. In the absence of a single standard measure of
prediction performance in survival models, we use three measures
that assess multiple Characteristics of the goodness of ﬁt and provide
our Clinical collaborators meaningful outcome interpretations: the
Brier score (BS), the coefﬁcient of determination (R2) and the
concordance index (CI). Several studies have shown that that
these metrics are very good descriptors of predictive performance.

 

362

112 /3.Io's[BumoIpJOJXO'sorwurJOJurorq”:duq wort papaolumoq

91oz ‘Og anﬁnv uo ::

Ensemble methods for survival prediction

 

(Harrell, 2001 ; Schumacher et al., 2007; van Wieringen et al., 2009).
We discuss each of these measures in detail. The BS is a specialized
measure of goodness-of—ﬁt for survival models (Graf et al., 1999)
that compares the observed and estimated survival functions. The
BS is given by

 

" Six, 2Itift/v3i:1 1:3zxi21z,>z
BSUbjgr (I >> gm) >+( (lag ( >],

where i2(o) is the Kaplan—Meier estimate of the survival distribution
for the observations ([1, ...,t,,) and I denotes an indicator function.
For the BS, we utilize the training data t and X to ﬁt a model p(t|X),
and employ it to obtain the survival distribution S(t*|t,X*) for a
ﬁiture patient with covariate X*. The BS ranges from 0 to 1; the
smaller the score, the better the ﬁt.

The R2 measure is the usual coefﬁcient of determination of the
ﬁtted model and quantiﬁes the proportion of variability observed in
the test set that can be explained by the predictor. R2 is estimated as

R2 :17 exp (7 %(L(3>):L(0))>a

where L(o) denotes the log-likelihood ﬁinction evaluated at a
particular value. In order to obtain the R2, we use the median of
the posterior distribution to estimate d), the vector of the latent
covariate effects and then we use it as a predictor in the univariable
version of the speciﬁc underlying model. For example, the vector c?)
estimated from the ensemble version of the AFT model is used as
the predictor vector in a univariable AFT. R2 also ranges from 0 to
1 and a predictor that explains a high proportion of variability in the
survival data will have R2 values Close to 1.
The CI can be expressed in the form

Cl [(116),

_ Ewen

’ M
where 1(fi,fj)=1 if  >1} or 0 if otherwise, is based on pairwise
comparisons between the prognostic scores  and  for patients 1'
and j, respectively, and S2 consists of all the pairs of patients {i, j}.
The Close the CI is to 1, the better is the ﬁt.

3.1 Breast cancer data

We compared the performance of our method with other survival
prediction methods tailored for gene expression data as recently
reviewed by van Wieringen et al. (2009) and other popular survival
methods. We used the breast cancer dataset of Van’t Veer et al.
(2002; http://www.rii.Com/publiCations/2002/vantveer.html), which
contains gene expression proﬁles for 295 breast cancer patients and
5057 gene expression values, along with patient survival outcomes.
Around 73% of these observations are right censored. Patient age
ranges from 26 to 53 years and the percentage of patients with tumor
grade I is 34%, grade II is 40% and grade III is 26%. We reapplied the
‘best’ methods found by van Wieringen et al. (2009): multivariable
linear CPH model (CPH), L1-penalized Cox regression (CPH-L1)
of Tibshirani (1997) and the L2-penalized Cox regression (CPH-
L2) of Gui and Li (2005). We replicate the same setup used by
van Wieringen et al. (2009) to allow comparisons across studies,
i.e. we use the multivariable linear CPH model, in which the top 10
genes were obtained using a univariable Cox regression. In addition,
we ran a multivariable linear Weibull model, in which the top 10
most signiﬁcant genes were obtained by univariable Weibull models.
We also used a multivariable linear AFT model, in which the top
10 genes were pre-selected by using a univariable AFT analysis.

We also included conditional inference tree ensemble methods
as Bagging, Random Forest (Hothorn et al., 2006) and Random
Survival Forests (ntree=2000; Ishwaran et al., 2008) as well as
CoxBoost (Binder & Schumacher, 2009). Bagging and Random
Forest models were also studied by van Wieringen et al. (2009).
Similarly to van Wieringen et al. (2009), we used the top 200 most
signiﬁcant genes obtained by the underlying univariable model to
run our ensemble versions of the accelerated failure time model
(AFT-TREE), the Weibull model (WEI-TREE) and the CPH model
(CPH-TREE). We used a long single Chain of K = 10000 iterations
for each survival model with a bum-in of the ﬁrst 5000 samples. In
addition, we ran several Chains with different initial values and found
that our results are robust to these convergence Checks. We repeated
the cross-validation procedure 50 times with the data randomly split
into training and test sets in a 2:1 ratio and with the number of
censored observations kept balanced between training and test sets.
We used the training set to build the predictor and then used the test
set to assess the performance of the competing methods.

Based on the BS, our proposed ensemble-based methods
outperformed most of the competing methods. The median BS
for the ensemble method is roughly 10% smaller than those for
the CPH-L1 and CPH-L2 methods, which were reported to be the
best performing methods by van Wieringen et al. (2009). The best
median BS is for the AFT-TREE model (0.158), followed by WEI-
TREE (0.160). The median BS for CPH-TREE (0.164) model is also
small and Close to the medians of CoxBoost (0.162) and Bagging
(0.165) methods. In terms of R2, the AFT-TREE (0.141) model
seems to have performance equivalent to CoxBoost (0.145) and RSF
(0.146) methods while CPH- and Weibull-TREE methods did not
perform as well. For the CI, all methods seem to have equivalent
performance leaded by AFT (0.603) and CoxBoost (0.600) methods.
The performance of some or all proposed tree-based models
(0582—0598) is better than the performance of RSF (0.571), CPH-
L1 (0.582) and RF (0.583) (see Supplementary Material for
detailed information). Based on these three evaluation measures,
our proposed method improves survival prediction accuracy in some
cases or is, at least, equivalent in performance to competing methods.
We believe that this improvement may be attributable to added
ﬂexibility when accounting for additive and non-linear effects.

We use a Bayesian FDR cutoff of 0.1 to select signiﬁcant
covariates for survival prediction (explained in Section 2.5) and,
as a result, we found that a total of 9 variables were signiﬁcant in
the CPH-TREE, 7 in the WEI-TREE and 12 in the AFT-TREE. One
gene (BCL2) was simultaneously listed for the AFT-TREE and the
WEI-TREE. Genes identiﬁed by the models represent promising
targets for further biological investigation as, for example, BCL2
gene which is one of the strongest predictors of shorter survival
among breast cancer patients and was also reported by Van’t Veer
et al. (2002) or STK12 gene which is located in a region frequently
deleted in tumors, which contains tumor-related genes such as p53
(Tatsuka et al., 1998). More details and results are presented in the
Supplementary Material.

4 APPLICATION TO BRAIN TUMOR DATA

We applied the proposed method to a dataset containing gene
expression proﬁles of brain tumors in order to identify molecular
and genetic signatures that could be of prognostic value. The dataset
contains gene expression measurements and survival information for

 

363

112 /3.Io's[BumoIpJOJXO'sorwurJOJurorq”:duq wort papaolumoq

91oz ‘Og anﬁnv uo ::

V.Bonato et al.

 

734 patients that were obtained from nine different cancer treatment
centers (Broom et al., 2010). The post-diagnosis survival time of
the patients with brain tumors ranges from 1 to 698 weeks, with
15% of the observations censored. Patient age ranges from 14 to
86 years and the percentage of patients with tumor grade II is 6%,
grade III is 16% and grade IV is 78%. The gene expression data
were obtained using three different Affymetrix microarray Chips
(HT-U133A, U133A and U133Plus2) and was pre-processed using
a customized CDF ﬁle (Brain Array Lab, University of Michigan,
see brainarray.mbni .med.umich.edu), which combines
in a single expression measure the signal intensities of probesets
targeting a particular gene. A total of 11911 genes common to
these three platforms was then selected and batch normalized (JMP
Genomics SAS®) to remove batch effects.

In practice, we are often interested in Clusters containing
correlated genes with very similar measurements in all samples.
One use of these Clusters is to infer the relatedness of individual
genes from their membership in a common Cluster. A second use is
to suggest possible ﬁinctions for individual genes of interest, based
on the functions of other variables in the Cluster, and to suggest
additional related genes that might also be of interest. A third use
is to calculate a Cluster metagene for each sample by averaging
the individual genes in the Cluster. The Cluster metagenes might
yield more robust measurements and tests of sample Characteristics
than the individual variables. Converting the individual genes
into metagenes also reduces the number of variables, and makes
searching high dimensional spaces for interaction effects more
tractable. Since our main interest is in ﬁnding prognostic groups
of correlated genes, we focus our analysis on a set of metagenes that
we obtained by applying an unsupervised Clustering algorithm, gene
shaving (Hastie et al., 2000). Gene shaving is an established method
for generating such Clusters. Gene shaving identiﬁes the largest
principal component, Clusters the genes highly correlated with it
and shaves out the less correlated genes. After ﬁnding the largest
principal component, the procedure repeats until it has obtained a
maximum number of Clusters Chosen a priori. The metagenes are
then constructed from the Clusters, which are assigned according
to the (signed) average gene expression of their members. Using
this procedure, we found 142 metagenes for downstream analysis
via our ensemble-based method. In addition to the metagenes, we
added Clinical covariates to the survival model that included patient
age and histopathological tumor grade (coded as II, III or IV). All
our inferences are based on one long run of 10 000 MCMC samples,
discarding the ﬁrst 5000 as bum-in.

The median BS calculated for the proposed tree-based models are
similar to the median BS for other models, all of them around 0.11,
which indicates a good model ﬁt. In terms of medians of R2, the tree-
based method CPH-TREE (0.218) and CoxBoost (0.218) ﬁgure as
the best models followed by RF (0.214) and AFT-TREE and SRF
(both with median 0.212). For the CI, all methods seem to have
equivalent performance leaded by AFT-TREE (0.618). In general,
the performance of the proposed tree-based models (0608—0618)
is better than the performance of other tree-based methods as SRF
(0.609), RF (0.614) and Bagging (0.601) (see Supplementary
Material for detailed information).

The posterior probabilities of the covariates used by our models
are shown in Figure 1 along with the BFDR cut-off at Oi=0.l.
The signiﬁcant covariates for what are above this cut-off are
shown in Table 1. There is a signiﬁcant overlap in the metagenes

 

 

 

 

 

 

 

0.10

0.08

0.06

0.04

 A n, 11111.11th manila. 1m uu
Covariates

0.04

0.03

0.02

0.01 "ll L n

0.00
Covariates

0.04

0.03

002 {II II

0.01 in ,JI IL” 11 J1. "

 

 

0.00
Covariates

Fig. 1. Posterior probability of a variable appearing in the CPH-TREE (top).
WEI-TREE (center) and AFT-TREE (bottom) survival ensemble methods as
applied to the brain tumor data. Variables with posterior probability above
the horizontal gray line are considered to be signiﬁcantly used; controlled
by 10% FDR. High-resolution version of this ﬁgure can be Viewed in the
supplementary materials.

Table 1. Covariates signiﬁcantly used in the ensemble-tree models
controlling the BFDR at 10% sorted by their posterior probabilities of
inclusion in the model

 

 

AFT Weibull CPH
metagene99a Tumor grade Tumor grade
Tumor grade metagene99" metagene52”
Patient age metagene82” metagene99"
metagene82b metagene52”

metagene52b Patient age

 

aContains cancer-related genes.
bContains glioma-related genes.

and Clinical covariates found by all three methods. In addition,
the top ﬁve covariates mostly used by the AFT-TREE and WEI-
TREE models are the same (although in different order). Tumor
grade, one of the most important Clinical factors for predicting
survival of patients with brain tumors (The Cancer Genome Atlas
Network, 2008), was conﬁrmed in our results as one of the
covariates more frequently used by all the models. Patient age,
another important Clinical covariate (The Cancer Genome Atlas
Network, 2008), is also among the top covariates for the AFT-TREE
and WEI-TREE models. In all the models, we found metagenes
52 and 99 had the highest posterior probabilities of inclusion. A
search of the OMIM database (http://www.ncbi.nlm.nih.gov/omim/)
revealed that these metagenes include genes known to be associated
with the development and progression of tumors, including many
associated with brain tissue. For example, metagene 52 includes
four genes that are associated with glioma phenotypes: PHLPP,
GRIPE, PIK3R1 and BAI3. PHLPP is known for its capacity to
dephosphorylate Akt, triggering apoptosis and suppressing tumor
growth via the p53 and RTK mitogenic pathways. PHLPP appears
downregulated in several colon cancer and glioblastoma cell lines
(Gao et al., 2005). Upregulation of GRIPE induces neuronal
differentiation (Heng and Tan, 2002) and, therefore, prevents cells
going through migration or invasion processes, resulting in good
prognosis gliomas. Further, alterations of the PIK3R1 signaling
pathway are present in Close to 90% of glioblastomas (Cancer
and Genome Atlas Network, 2008). Likewise, BAI3 is an inhibitor

 

364

112 /3.Io's[BumoIpJOJXO'sorwurJOJurorq”:duq wort papeolumoq

910E ‘OE JSHBHV uo ::

Ensemble methods for survival prediction

 

 

 

 

 

nlnalalumwwwwm
IMF. Wee—-
301]-
M:
w 1.. m an I. u to .1. IU
150'
B .
mm
E w u
E1011-
3- HrIwuﬁ! .—.—.—.—.—.—.—.—.—.—.—.——v
i 4 r r a r t 1 4 \ s u
“SHU-
a. MI.ch
la la n 1» :5
100'
umwuqa
anJoa ollIl'flllo
50‘
I I I I I I l'oIaleMI

 

|.Illml|’lledlmx v-v—I—v-I—v—I—v—v-v—v—v-v—v—ﬁ-I—v—I—v-I
Mm. :ruasgggaggu

Fig. 2. Marginal effects of signiﬁcant covariates. Left panel: partial
dependence function plots for metagene 82 with y-axis in weeks. Right
panel: nomogram of the most important variables in the AFT-TREE model.
High-resolution version of this ﬁgure can be Viewed in the supplementary
materials.

of angiogeneses and its downregulation is linked to an increasing
of tumor vascularization, a marked Characteristic of high-grade
gliomas as Glioblastoma Multiforme (Shiratsuchi et al., 1997). In
addition, metagene 82 includes the gene MXIl, which negatively
regulates the MYC oncoprotein, an important glioblastoma tumor
inductor (Albarosa et al., 1995). The downregulation of MXIl
causes the overexpression of MYC that activates cell proliferation,
deactivates apoptosis (controls the death receptor BCl-2) and triggers
the mesenchymal phenotype in high-grade gliomas (Albarosa et al.,
1995). In addition, metagene 70 includes the EGFR gene, which
is one of the most important genes related to the development
of gliomas (The Cancer Genome Atlas Network, 2008) and its
upregulation triggers cell proliferation and migration processes,
noticeable Characteristics of poor prognosis gliomas (Wang et al.,
2004).

In addition to selecting relevant covariates, one of the by-products
of BART are partial dependence ﬁinctions (Friedman, 2001), which
summarize the marginal effect of the relevant covariate s on the
response. One can partition f (x) into f (x) = f (xs,xc) where x.
represents the predictor of interest and xc its complement. The
marginalization is obtained as f(xs)= %Z;’=1f(xs,xic), where xic
is the i-th observation of xc in the data. The posterior distribution
(post bum-in) of f(xs) can then be used to estimate the marginal
effect of s as well as its conﬁdence intervals. Partial dependence plots
are particularly useful to illustrate the marginal effect of a relevant
covariate directly on survival outcome, especially in the AFT-TREE
model. A plot of the partial dependence ﬁinctions (Fig. 2) shows
that relative upregulation of metagene 82 (variation in the x-axis)
increases the survival of patients with brain tumors to roughly 170
weeks or 3.3 years (variation in the y-axis). Nomograms are another
important tool fairly used by Clinicians to identify the individual
contributions of the covariates on patient survival. Nomograms
are two-dimensional plots designed to show marginal effects of
a relevant unﬁxed covariate while the other 1—p non-relevant
covariates remain ﬁxed. In Figure 2, we show a nomogram of the
most important variables in the AFT-TREE model. The nomogram
is interpreted as follows: (i) identify the patient’s age and draw a
vertical line to the ‘Points’ scale at the top of the nomogram. Repeat
this process for the remaining variables; (ii) sum the points for each
individual variable and locate the sum on the ‘Total Points’ scale at
the bottom of the nomogram. The width of a variable scale represents
how much it affects the overall survival time; (iii) to calculate the

 

 

 

 

 

 

 

 

CPH WEI AFT
n! l I I u I I I u I I I
u“ I. {I 1% 14 I! 1 l n. I+ II  I  ‘1 1:“ I+ II  I  1 1
3... I II 3.1 all ‘m . ‘l
.. ii i .. ll ,. ll ’

Fig. 3. Time-dependent AUC analysis. The plots compare the performance
of the proposed tree-ensemble methods with their multivariable linear
versions. as applied to the brain tumor data. Dots represent the medians across
splits of training/test sets; lines depict the interquartile limits. Left plot: CPH
(dashed lines) and CPH-TREE (solid lines); center plot: Weibull (dashed)
and WEI-TREE (solid); right plot: AFT (dashed) and AFT-TREE (solid).
High-resolution version of this ﬁgure can be Viewed in the supplementary
materials.

survival time in weeks, draw a vertical line from the ‘Total Points’
spot on the linear predictor scale.

To evaluate the predictive accuracy of our methods, we used the
same setup designed for the breast cancer data, i.e. we performed a
cross-validation procedure with the data randomly split 50 times into
training and test sets at a 2: 1 ratio. First, we built the predictor using
the training set. Then, we assessed and compared the performance of
different methods using evaluation measures calculated for the test
set. To evaluate the predictive ability of the proposed models, we
conducted a time-dependent area under the curve (AUC) analysis
(Fig. 3) that compares the prognostic capacity of the survival
models across different binary splits of the survival response. The
Clinical literature reports frequent use of the time-dependent AUC
analysis (Cerhan et al., 2007) to help physicians better categorize
patients in terms of survival Classes. In our study, the proposed
ensemble methods performed better than the competing methods
and demonstrated higher sensitivity.

In conclusion, our results show that the Clinical covariates and the
expression values of few (meta)genes impact the overall survival
of patients with brain tumors. We believe that these genes might
be worthy of ﬁirther scientiﬁc investigation, especially as potential
therapeutic targets.

5 DISCUSSION

We propose Bayesian ensemble methods for survival prediction for
high-throughput data such as gene expression data. Using a powerful
predictive tool, BART, we model the covariate effects via a latent
variable scheme, that not only allows stochastic deviations from
the parameteric model but also greatly reduces the computational
complexity. We Chose BART because it has the ﬂexibility to
accommodate a high number of covariates and their interactions. In
addition, our primary reason of working under a Bayesian paradigm
is that the uncertainty in estimation is propagated at each stage of
the hierarchy, thus the credible intervals on all our model parameters
are in some sense exact by conditioning on all sources of variation.
Thus, using the selected gene expression proﬁle one can estimate
the median survival time and credibility intervals for a given patient
using the posterior distributions of the process parameters obtained
with the AFT-TREE model or, alternatively, survival curves along
with conﬁdence bounds for the population using the WEI-TREE and
CPH-TREE methods. Although our method is based on the BART

 

365

112 /3.Io's[BumoIpJOJXO'sorwurJOJurorq”:duq wort papeolumoq

91oz ‘Og anﬁnv uo ::

V.Bonato et al.

 

formulation, our framework can be extended to allow for the use of
any other ensemble method.

Our primary motivation of using gene sets for the brain tumor
dataset was that we were more interested in groups of common genes
that predict survival rather than individual genes. These genesets can
be derived in various ways either using prior pathway knowledge
[e.g. gene ontololgy (GO) or Kyoto Encyclopedia of Genes and
Genomes (KEGG) databases] or using data-driven methods for
ﬁnding clusters of correlated genes with very similar measurements
in all samples, such as gene shaving. Although our methods can
accommodate both scenarios, we choose the latter since it allows
to infer the relatedness of individual genes from their membership
in a common cluster as well as to suggest possible functions for
individual genes of interest, based on the functions of other variables
in the cluster, and to suggest additional related genes that might also
be of interest.

The screening ability of the BART identiﬁes important predictors
across trees and training test splits of data, which allowed the
model to reveal the impact of many important genes and clinical
covariates on the survival of cancer patients. The application of
our method to two different datasets showed that the prediction
accuracy of our model outperforms that of many available models.
In addition, the variable selection procedure, partial dependence
ﬁinctions and nomogram techniques imbue the ﬁnal model with a
high level of interpretability. We have a highly efﬁcient R package
available at http://works.bepress.com/veera/1/. A limitation of our
proposed method is the lack of interpretability as compared to
simpler regression models which is, at least, counterbalanced by
gains in prediction accuracy and the ability to incorporate complex
interaction effects among the covariates.

We note that the number of regression trees M set for the tree-
ensemble methods dictates how often a covariate will be selected
to be part of the model. Chipman et al. (2010) showed that setting
a relatively small number of trees beneﬁts the variable selection
procedure since variables compete with each other to improve ﬁt
and therefore, relevant predictors should appear more frequently
in the tree model. Because we were interested in exploring the
BART variable selection feature, we set the number of trees M :40,
which also reduces computation time without losing predictive
performance. A more detailed study of the adequate number of trees
can be found in the Supplementary Material.

Although motivated by a gene expression dataset, our
methodology can be applied to other genomic data as well such
as array-based comparative genomic hybridization and SNP data.
This is so, since we do not assume any structure on the covariate
space—via a ensemble formulation that accommodates complex
combination of continuous and categorical predictors. We leave this
task for future consideration.

ACKNOWLEDGEMENTS

We want to thank the Associate Editor and three anonymous referees
for their very insightful comments that substantially improved this
article.

Funding: This reasearch is supported in part by National Science
Foundation grant IIS-0914861 (VB) and the National Institutes of
Health/National Cancer Institute SPORE in Brain Cancer (PP- 3A)
1P50CA127001 01A1. Additional support was received from a

Neurooncology Grant from the Center for Targeted Therapy at the
University of Texas MD Anderson Cancer Center.

Conﬂict of Interest: none declared.

REFERENCES

Albarosa,R. et al. (1995) Redeﬁnition of the coding sequence of the MXIl gene and
identiﬁcation of a polymorphic repeat in the 3-prime non-coding region that allows
the detection of loss of heterozygosity of chromosome 10q25 in glioblastomas.
Hum. Genet, 95, 7097711.

Berchuck,A. et al. (2005) Patterns of gene expression that characterize long-term
survival in advanced stage serous ovarian cancers. Clin. Cancer Res., 11,
368C3696.

Binder,H. and Schumacher,M. (2009) Incorporating pathway information into boosting
estimation of high-dimensional risk prediction models. BMC Bioinformatics, 10,
18.

Breiman,L. (1996) Bagging predictors. Mac/i. Learn., 24, 1237140.

Breiman,L. (2001) Random forests. Mac/i. Learn., 4S, 5732.

Broom,B.M. et al. (2010) Bagged gene shaving for the robust clustering of high-
throughput data. Int. J. Bioinformatics Res. Appl, 6, 32&343.

The Cancer Genome Atlas Research Network. (2008) Comprehensive genomic
characterization deﬁnes human glioblastoma genes and core pathways. Nature, 455,
106171068.

Cerhan,J.R. et al. (2007) Prognostic signiﬁcance of host immune gene polymorphisms
in follicular lymphoma survival. Blood, 109, 54395446.

Chipman,H.A. et al. (1998) Bayesian CART model search (with discussion). J. Am.
Stat. Assoc., 93, 9357960.

Chipman,H.A. et al. (2010) BART: Bayesian Additive Regression Trees. Ann. Appl.
Stat., 4, 266298.

Clarke,J. and West,M. (2008) Bayesian Weibull tree models for survival analysis of
clinico-genomic data. Stat. Methodol, 5, 2387262.

Cox,D. (1972) Regression models and life tables. J. R. Stat. Soc. B, 34, 1877220.

Datta,S. et al. (2007) Predicting patient survival from microarray data by accelerated
failure time modeling using partial least squares and LASSO. Biometrics, 63,
2594271.

Denison,D. et al. (1998) A Bayesian CART algorithm. Biometrika, 85, 3637377.

D’haeseleer,P. (2005) How does gene expression clustering work? Nat. Biotechnol, 23,
149941501.

Friedman,J.H. (2001) Greedy function approximation: a gradient boosting machine.
Ann. Stat, 29, 118941232.

Gao,T. et al. (2005) PHLPP: a phosphatase that directly dephosphorylates Akt, promotes
apoptosis, and suppresses tumor growth. Mol. Cell, 18, 13724.

Gilks,W.R. et al. (1996) Markov Chain Monte Carlo in Practice: Interdisciplinary
Statistics. Chapman & Hall, New York.

Graf,E. et al. (1999) Assessment and comparison of prognostic classiﬁcation schemes
for survival data. Stat. Med., 18, 252942545.

Gui,J. and Li,H. (2005) Penalized Cox regression analysis in the high-dimensional and
low-sample size settings, with applications to microarray gene expression data.
Bioinformatics, 21, 300173008.

Harrell RE. (2001) Regression modeling strategies, with applications to linear models,
survival analysis and logistic regression. Springer, New York, 2001.

Hastie,T. et al. (2000). ‘Gene shaving’ as a method for identifying distinct sets of genes
with similar expression patterns. Genome Biol., 1, RESEARCH0003.

Heng,J.I. and Tan,S.-S. (2002) Cloning and characterization of GRIPE, a novel
interacting partner of the transcription factor E12 in developing mouse forebrain.
J. Biol. Chem, 277, 4315243159.

Hothorn,T. et al. (2004) Bagging survival trees. Stat. Med., 23, 77791.

Hothorn,T. et al. (2006) Survival ensembles. Biostatistics, 7, 3557373.

Ibrahim,J.G. et al. (2001) Bayesian Survival Analysis. Springer, New York.

Ishwaran,H. et al. (2004) Relative risk forests for exercise heart rate recovery as a
predictor of mortality. J. Am. Stat. Assoc., 99, 5917600.

Ishwaran,H. et al. (2008) Random survival forests. Ann. Appl. Stat., 2, 8417860.

Kalbﬂeisch,J.D. (1978) Non-parametric Bayesian analysis of survival time data. J. R.
Stat. Soc. B, 40, 2144221.

Klein,J.P. and Moeschberger,M.L. (1997) Survival Analysis - Techniques for Censored
and Truncated Data. Springer, New York.

Lee,K.E. and Mallick,B.K. (2004) Bayesian methods for variable selection in survival
models with application to DNA microarray data. Sankiiya, 66, 75&778.

 

366

112 /3.Io's[BumoIpJOJXO'sorwurJOJurorq”:duq wort papeolumoq

9103 ‘Og isnﬁnv uo ::

Ensemble methods for survival prediction

 

Lee,J.W. et al. (2005) An extensive comparison of recent classiﬁcation tools applied to
microarray data. Comput. Stat. Data Anal, 48, 8697885.

Li,H. and Gui,J. (2004) Partial Cox regression analysis for high-dimensional microarray
gene expression data. Bioinformatics, 20, i2087i215.

Morris,J.S. et al. (2008) Bayesian analysis of mass spectrometry data using wavelet-
based functional mixed models. Biometrics, 64, 479489.

Mueller, P., Parrnigiani, 6., Robert, C., and Rousseau, J. (2004) Optimal sample size
for multiple testing: the case of gene expression microarrays. J. Am. Stat. Assoc.,
99, 99o1001.

Newton,M.A. etal. (2004) Detecting differential gene expression with a semiparametric
hierarchical mixture method. Biostatistics, 5, 1557176.

Nguyen,D.V. and Rocke,D.M. (2002) Partial least squares proportional hazard
regression for application to DNA microarray survival data. Bioinformatics, 18,
162541632.

Park,P.J. et al. (2002) Linking gene expression data with patient survival times using
partial least squares. Bioinformatics, 18, S12WS127.

Pittman,J. et al. (2004) Bayesian analysis of binary prediction tree models for
retrospectively sampled outcomes. Biostatistics, 5, 5877601.

Ross,J.S. (2009) Multigene classiﬁers, prognostic factors, and predictors of breast
cancer clinical outcome. Adv. Anat. Pathol, 16, 2044215.

Schmid,M. and Hothorn,T. (2008) Flexible boosting of accelerated failure time models.
BMC Bioinformatics, 9, 269.

Schumacher,M. et al. (2007) Assessment of survival prediction models based on
microarray data. Bioinformatics, 23, 176871774.

Sha,N. et al. (2006) Bayesian variable selection for the analysis of microarray data with
censored outcomes. Bioinformatics, 22, 226272268.

Shiratsuchi,T. et al. (1997) Cloning and characterization of BAIZ and BAI3, novel
genes homologous to brain-speciﬁc angiogenesis inhibitor 1 (BAIl). Cytogenet.
Cell Genet, 79, 1034108.

Storey,J.D. (2003) The positive false discovery rate: a Bayesian interpretation and the
q-value. Ann. Stat., 31, 201372035.

Tanner,T. and Wong, W. (1987) The calculation of posterior distributions by data
augmentation. J. Am. Stat. Assoc., 82, 5287549.

Tatsuka,M. et al. (1998) Multinuclearity and increased ploidy caused by overexpression
of the aurora- and Ipll-like midbody-associated protein mitotic kinase in human
cancer cells. Cancer Res., 58, 48114816.

Tibshirani,R. (1997) The Lasso method for variable selection in the Cox model. Stat.
Med., 16, 3857395.

Van’t Veer,L.J. et al. (2002) Gene expression proﬁling predicts clinical outcome of
breast cancer. Nature, 415, 53W536.

van Wieringen,W.N. et al. (2009) Survival prediction using gene expression data: a
review and comparison. Comput. Stat. Data Anal, 53, 159071603.

Wang,K. et al. (2004) Epidermal growth factor receptor-deﬁcient mice have delayed
primary endochondral ossiﬁcation because of defective osteoclast recruitment.
J. Biol. Chem, 279, 53848753856.

West,M. (2003) Bayesian factor regression models in the “large p, small n” paradigm. In
Bernardo,J.M. et al. (eds) Bayesian Statistics 7. Oxford University Press, New York,
pp. 7334742.

 

367

112 /3.Io's[BumoIpJOJXO'sorwurJOJurorq”:duq wort papeolumoq

9103 ‘Og isnﬁnv uo ::

