Bioinformatics, 31 (20), 2015, 3282—3289

doi: 10.1093/bioinformatics/btv378

Advance Access Publication Date: 20 June 2015
Original Paper

 

Phylogenetics

An efficient Bayesian inference framework for
coalescent-based nonparametric phylodynamics

Shiwei Lan1'*'T, Julia A. Palaciosz'3'4'1, Michael Karcher5,
Vladimir N. Minin5'5 and Babak Shahbaba7'*

1Department of Statistics, University of Warwick, Coventry CV4 7AL, UK, 2Department of Organismic and
Evolutionary Biology, Harvard University, MA 02138, US, 3Department of Ecology and Evolutionary Biology, Brown
University, RI 02912, US, 4Center for Computational Molecular Biology, Brown University, 5Department of Statistics,
University of Washington, WA 98195, US, 6Department of Biology, University of Washington and 7Department of
Statistics, University of California, Irvine, CA 92697, US

*To whom correspondence should be addressed.
TThe authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.
Associate Editor: David Posada

Received on December 1, 2014; revised on May 25,2015; accepted on June 16, 2015

Abstract

Motivation: The field of phylodynamics focuses on the problem of reconstructing population size
dynamics over time using current genetic samples taken from the population of interest. This tech—
nique has been extensively used in many areas of biology but is particularly useful for studying the
spread of quickly evolving infectious diseases agents, e.g. influenza virus. Phylodynamic inference
uses a coalescent model that defines a probability density for the genealogy of randomly sampled
individuals from the population. When we assume that such a genealogy is known, the coalescent
model, equipped with a Gaussian process prior on population size trajectory, allows for nonpara—
metric Bayesian estimation of population size dynamics. Although this approach is quite powerful,
large datasets collected during infectious disease surveillance challenge the state—of—the—art of
Bayesian phylodynamics and demand inferential methods with relatively low computational cost.
Results: To satisfy this demand, we provide a computationally efficient Bayesian inference frame—
work based on Hamiltonian Monte Carlo for coalescent process models. Moreover, we show that
by splitting the Hamiltonian function, we can further improve the efficiency 0fthis approach. Using
several simulated and real datasets, we show that our method provides accurate estimates of
population size dynamics and is substantially faster than alternative methods based on elliptical
slice sampler and Metropolis—adjusted Langevin algorithm.

Availability and implementation: The R code for all simulation studies and real data analysis con—
ducted in this article are publicly available at http://www.ics.uci.edu/Nslan/lanzi/CODES.html and in
the R package phylodyn available at https://github.com/mdkarcher/phylodyn.

Contact: S.Lan@warwick.ac.uk 0r babaks@uci.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction past population size dynamics from current genetic data. In recent

years, phylodynamic inference has become an essential tool in areas like
Poplllation g€n€tics d1er Stat“ that Chang“ in Poplllation Si“ 3&6“ ecology and epidemiology. For example, a study of human inﬂuenza A
genetic diversity, leaving a trﬂC€ 0f th€S€ changes in indiVidualSs gen- virus from sequences sampled in both hemispheres pointed to a source-
omes. The field of phylodynamics relies on this theory to reconstruct sink dynamics of the inﬂuenza evolution (Rambaut et (11., 2008).

© The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com

 

/310‘sreumo[p10}xo‘sopeuHOJIIrorq/ﬁdnq

Efficient Bayesian ph y/odynamics

3283

 

Phylodynamic models connect population dynamics and genetic
data using coalescent—based methods (Griffiths and Tavare, 1994;
Kuhner et al., 1998; Strimmer and Pybus, 2001; Drummond et al.,
2002; Drummond et al., 2005; Opgen—Rhein et al., 2005; Heled and
Drummond, 2008; Minin et al., 2008; Palacios and Minin, 2013).
Typically, such methods rely on Kingman’s coalescent model, which
is a probability model that describes formation of genealogical rela—
tionships of a random sample of molecular sequences. The coales—
cent model is parameterized in terms of the effective population size,
an indicator of genetic diversity (Kingman, 1982).

While recent studies have shown promising results in alleviating
computational difficulties of phylodynamic inference (Palacios and
Minin, 2012, 2013), existing methods still lack the level of computa—
tional efficiency required to realize the potential of phylodynamics:
developing surveillance programs that can operate similarly to wea—
ther monitoring stations allowing public health workers to predict
disease dynamics to optimally allocate limited resources in time and
space. To achieve this goal, we present an accurate and computa—
tionally efficient inference method for modeling population dy—
namics given a genealogy. More specifically, we concentrate on a
class of Bayesian nonparametric methods based on Gaussian proc—
esses (Minin et al., 2008; Gill et al., 2013; Palacios and Minin,
2013). Following Palacios and Minin (2012) and Gill et al. (2013),
we assume a log—Gaussian process prior on the effective population
size. As a result, the estimation of effective population size trajectory
becomes similar to the estimation of intensity of a log—Gaussian Cox
process (LGCP; Meller et al., 1998), which is extremely challenging
since the likelihood evaluation becomes intractable: it involves inte—
gration over an infinite—dimensional random function. We resolve
the intractability in likelihood evaluation by discretizing the integra—
tion interval with a regular grid to approximate the likelihood and
the corresponding score function.

For phylodynamic inference, we propose a computationally effi—
cient Markov chain Monte Carlo (MCMC) algorithm using
Hamiltonian Monte Carlo (HMC; Duane et al., 1987; Neal, 2010)
and one of its variants, called Split HMC (Leimkuhler and Reich,
2004; Neal, 2010; Shahbaba et al., 2013), which speeds up standard
HMC’s convergence. Our proposed algorithm has several advan—
tages. First, it updates all model parameters jointly to avoid poor
MCMC convergence and slow mixing rates when there are strong
dependencies among model parameters (Knorr—Held and Rue,
2002). Second, unlike a recently proposed Integrated Nested
Laplace Approximation method (INLA, Rue et al., 2009; Palacios
and Minin, 2012), which approximates the posterior distribution
of model parameters given a fixed genealogy, our approach can be
extended to more general settings where we observe genetic data
(as opposed to the genealogy of sampled individuals) that provide
information on genealogical relationships. Third, we show that our
method is up to an order of magnitude more efficient than alterna—
tive MCMC algorithms, such as Metropolis—adjusted Langevin algo—
rithm (MALA; Roberts and Tweedie, 1996), adaptive MALA
(aMALA; Knorr—Held and Rue, 2002) and Elliptical Slice Sampler
(ESZ; Murray et al., 2010) that are commonly used in the field of
phylodynamics. Finally, although in this article we focus on phylo—
dynamic studies, our proposed methodology can be easily applied to
more general point process models.

The remainder of the article is organized as follows. In Section 2,
we provide a brief overview of coalescent models and HMC algo—
rithms. Section 3 presents the details of our proposed sampling
methods. Experimental results based on simulated and real data are
provided in Section 4. Section 5 is devoted to discussion and future
directions.

2 Preliminaries

2.1 Coalescent
Assume that a genealogy with time measured in units of generations is
available. The coalescent model allows us to trace the ancestry of a
random sample of n genomic sequences: two sequences or lineages
merge into a common ancestor as we go back in time until the com—
mon ancestor of all samples is reached. Those ‘merging’ times are
called coalescent times. The coalescent with variable population size
is an inhomogeneous Markov death process that starts with n lineages
at present time, t,, : 0, and decreases by one at each of the consequent
coalescent times, tn_1 <  < t1, until reaching their most recent
common ancestor (Kingman, 1982; Griffiths and Tavare, 1994).
Suppose we observe a genealogy of n individuals sampled at time
0. Under the standard (isochronous) coalescent model, given the ef-
fective population size trajectory, Ne(t), the joint density of coales—
cent times tn : 0 < tn_1 <  < t1 is

Plti.  .tnlNe(t)l : maritime»
[2:2

Nfébdtl

where Ah :  and Ik : (tk. tk_1]. Note that the larger the popula—
tion size, the longer it takes for two lineages to coalesce. Further, the

 

larger the number of lineages, the faster two of them meet their com—
mon ancestor.

For rapidly evolving organisms, we may have different sampling
times. When this is the case, the standard coalescent model can be
generalized to account for such heterochronous sampling (Rodrigo
and Felsenstein, 1999). Under the heterochronous coalescent, the
number of lineages changes at both coalescent times and sampling
times. Let {t;z }Z:1 denote the coalescent times as before, but now let
sm : 0 < sm_1 <  < 51 denote sampling times of nm,  ,n1 se—
quences respectively, where  n; : n. Further, let s and n denote

the vectors of sampling times {5/}"7 and numbers of sequences

;:1
{71/}:1 sampled at these times, respectively. Then we can modify

density (1) as

Plt177tnlsin7N€(t)l:

 

 

 

A012 J Aug
A — ‘ d — d 2
ﬁ o.kexp{ JIMNeOf) t  “New t} ( )
[2:2 Ne(tk—1) 7

where the coalescent factor AL;z : (’3) depends on the number of
lineages [ME in the interval IL;z defined by coalescent times and sam—
pling times. For k : 2,  ,n, we denote half—open intervals that
end with a coalescent event by

10.12 I (maX{tk75/}itk—1li (3)

for s,- < tk_1 and half—open intervals that end with a sampling event
by (i > 0)

111k : (maX{tkiS;+i}rS;+i—1li (4)

for tk < 5,1,;135,‘ < tk_1. In density (2), there are n — 1 intervals
{I,.k}i:0 and m — 1 intervals {Ii.k}i>0 for all (i, k). Note that only
those intervals satisfying I M C (tk. tk_1] are non—empty. See Figure 1
for more details.

We can think of isochronous coalescence as a special case of het—
erochronous coalescence when m : LAWz : AkJOk : 1,2,1”z : Q)
for i> 0. Therefore, in what follows, we refer to density (2) as the
general case.

/310‘spzumo[p10}xo‘sopeuHOJIIrorq/ﬁdnq

3284

S.Lan et al.

 

Time (Present to Past)

 

 

 

 

 

 

 

Number of lineages
Observed data
Grid of Points

 

Fig. 1. A genealogy with coalescent times and sampling times. Blue dashed
lines indicate the observed times: coalescent times {117444715} and sampling
times {51752753}. The intervals where the number of lineages change are
denoted by I,-_k. The superimposed grid {X17 « « « 7 X5} is marked by gray dashed
lines. We count the number of lineages in each interval defined by grid
points, coalescent times and sampling times

We assume the following log—Gaussian Process prior on the ef—
fective population size, Ne(t):

Ne(t) = eXPlf(t)li W) N 97)(07C(9))7 (5)

where 973(0, C(0)) denotes a Gaussian process with mean function 0
and covariance function C(B). A priori, Ne(t) is a log—Gaussian
process.

For computational convenience, we use a Gaussian process with
inverse covariance function €5,106) : K Ci—nl, where Cir: corres—
ponds to a modified inverse covariance matrix of Brownian motion
(Cg/I) that starts with an initial Gaussian distribution with mean 0
and large variance. This corresponds to an intrinsic autoregression
model (Besag and Kooperberg, 1995; Knorr—Held and Rue, 2002).
The computational complexity of computing the density of this
prior is 0(D) since the inverse covariance matrix is tri—diagonal
(Kalman, 1960; Rue and Held, 2005; Palacios and Minin, 2013).
The precision parameter K is assumed to have a Gamma(or, [3) prior.

2.2 HMC

Bayesian inference typically involves intractable models that rely on
MCMC algorithms for sampling from the corresponding posterior
distribution, 71(0). HMC (Duane et al., 1987; Neal, 2010) is a state—
of—the—art MCMC algorithm that suppresses the random walk
behavior of standard Metropolis—based sampling methods by pro—
posing states that are distant from the current state but nevertheless
have a high probability of being accepted. These distant proposals
are found by numerically simulating Hamilton dynamics, whose
state space consists of position, denoted by the vector 0, and mo-
mentum, denoted by the vector p. It is common to assume
p N N(0,M), where M is a symmetric, positive—definite matrix
known as the mass matrix, often set to the identity matrix I for
convenience.

For Hamiltonian dynamics, the potential energy, U(0), is defined
as the negative log density of 0 (plus any constant); the kinetic energy,
K(p) for momentum variable p, is set to be the negative log density of
p (plus any constant). Then the total energy of the system, the
Hamiltonian function, is defined as their sum: H (0, p) : U(()) + K(p).

The system of (0,p) evolves according to the following set of
Hamilton’s equations:

9:  M_1Pi
p : —V9H(0,p) : —V9U(0).

(6)

In practice, we use a numerical method called leapfrog to approxi—
mate the Hamilton’s equations (Neal, 2010) when the analytical so—
lution is not available. We numerically solve the system for L steps,
with some step size, 8, to propose a new state in the Metropolis algo—
rithm and accept or reject it according to the Metropolis acceptance
probability (see Neal, 2010, for more discussions).

3 Method

3.1 Discretization

As discussed above, the likelihood function (2) is intractable in general.
We can, however, approximate it using discretization. To this end, we
use a fine regular grid, x : {xd}g:1, over the observation window and
approximate Ne(t) by a piecewise constant function as follows:

D—1
>l< * xd + xd
Nee) z Zexpvrxaibetiw.» xi 2  <7)
d:1

Note that the regular grid x does not coincide with the sampling
coalescent times, except for the first sampling time sm : x1 and the
last coalescent time t1 : am. To rewrite (2) using the approximation
(7), we sort all the time points {t, s,x} to create new D + m + n — 4
half—open intervals  with either coalescent time points, sampling
time points or grid time points as the end points (Fig. 1).

For each or E {1, - - - ,D + m + n — 4}, there exists some i, k and
a' such that I; : IL;z ﬂ (xd,xd+1]. Each integral in density (2) can be
approximated as a sum:

 

Ark
‘ dtz A,- ex — x* A,7
jaw)  .t pr f( or

where AI}, is the length of the interval 1;. This way, the joint density
of coalescent times (2) can be rewritten as a product of the following

 n

where y6C is an auxiliary variable set to 1 if I; ends with a coalescent

terms:

time and to 0 otherwise. Then, density (2) can be approximated as
follows:

D+m+n—4
Pit177tnlsin7N€(t)lz H PlyalsiniN€(t)l
«:1

Dﬂl H { Ark Fl { Ai.lea }
I — ex —— ,
,:,,,C(,,,M, expvrxni 1’ expvrxni

where the coalescent factor Aik on each interval 1,: is determined by
the number of lineages [,12 in 1;. We denote the expression on the right—

hand side of Equation (9) by Coalescent(f), where f 2: {f :11.

3.2 Sampling methods

Our model can be summarized as

{y6C }D+m+n—4

«:1 157 Ilif ~ Coalescent(f),

flic ~N<0,%Cm>. (10)

K N Gamma(or, 

/810's12um0_fp10}x0'sauEuIJogurorq/ﬁduq

Efficient Bayesian ph y/odynamics

3285

 

After transforming the coalescent times, sampling times and
grid points into {ym AME, A0,}, we condition on these data to generate
posterior samples for f : logNg(x*) and K, where x" :  is the
set of the middle points in (7). We use these posterior samples to
make inference about Ne(t).

For sampling f using HMC, we first compute the discretized log—
likelihood

D—1
1?: Z {may+A..tAiexpl—f(x:;)l}

11:1 I§C(xir~xir+1l
and the corresponding gradient (score function)

5d I - Z {M - Ai.kAanPl-f(x2)l}-
I;C(Xd~xd+1l
based on (9).
Because the prior on K is conditionally conjugate, we could dir—
ectly sample from its full conditional posterior distribution,

K )y,s,n,f ~ Gamma(or + (D — 1)/2,/} + fTClTnlf/2). (11)

However, updating f and K separately is not recommended in gen—
eral because of their strong interdependency (Knorr-Held and Rue,
2002): large value of precision K strictly confines the variation of f,
rendering slow movement in the space occupied by f. Therefore, we
update (f, K) jointly in our sampling method. In practice, of course,
it is better to sample 0 2: (f, ‘5), where ‘E : log(K) is in the same scale
as f : logNg(x*). Note that the log—likelihood of 0 is the same as
that of f because density (2) does not involve ‘E. The log—density prior
on 0 is defined as follows:

logP(0) (X ((D — 1)/2 + or): —(ch,;1£/2 + met. (12)

3.3 Speed up by splitting Hamiltonian
The speed of HMC could be increased by splitting the Hamiltonian
into several terms such that the dynamics associated with some of
these terms can be solved analytically (Leimkuhler and Reich, 2004;
Neal, 2010; Shahbaba et al., 2013). For these analytically solvable
parts (typically in quadratic forms), simulation of the dynamics does
not introduce a discretization error, allowing for faster movements
in the parameter space.

For our model, we split the Hamiltonian H((), p) : U(()) + K(p)
as follows:

—l — [(D — 1)/2 + or]: + lieT
fTCi—nlfeT + pr —1 — [(1) — 1)/2 + or]: + per
2 + 2 .

H0979)
(13)

 

We further split the middle part into two dynamics involving fl‘r and
rlf, respectively,

f : 7
{ ‘1 “3 (14a)
p_D : —Ci;1fer.
 I [7D7
_ T _1 (14b)
pD : _f Cin fer/2'7

where the subindex ‘— D’ means all but the Dth element. Using the
spectral decomposition Ci—nl : UAU_1 and denoting f" :: \/Xer/2
U_1f and p"_D :: U_1p_D, we can analytically solve the dynamics
(14a) as follows (Lan, 2013) (more details are provided in the
Supplementary Material):

[ 1*(1) ] i [ cosrfAei/Zt) sinrfAei/Zt)H f*(0) ] (15)
p"_D(t) — —sin(\/XeT/2t) cos(\/XeT/2t) P:D(0)

 

Algorithm 1. splitHMC for the coalescent model

 

Initialize 0(1) at current 0 = (L17)

Sample a new momentum value pm ~ N(0, I)

Calculate H(0(1),p(1)) = U(0(1)) + K(p(1)) according to (13)
for K = 1 to L do

p68) 2pm +8/2

 

SW
((D - 1)/2+6<) —ﬁexp(r“))i

1
pg 2) :pg) _8/2f*<r)1f*<rv2

16%) : I“) + (91/ng8)

1 a; 1 a;
farm COS (VXCZU  a) sin (@624  5) fan

(—

«a 1  1  «a
PTD —sin (ﬁeix -> 5) cos (ﬁeix -> a) PTD
1
NH) 2 16%) + (cl/217(7)

D

1
pg“) 2 pg?) _ 8/2f*((+1)Tf*(l+1)/2

paid) : p<h%) +8/2

 

S(H1)
((D — 1)/2 + or) — ﬁexp(r(f+1)):|

end for

Calculate H(0(T1),p(LT1)) = U(0(L+1)) + K(p(L+1)) according to (13)

Calculate the acceptance probability or = min{1, exp)—H(0(+1),p(LT1))+
HWUAPUUU

Accept or reject the proposal according to or for the next state 0'

 

where diagonal matrix \/X scales different dimensions. We then use
the standard leapfrog method to solve the dynamics (14b) and the
residual dynamics in (13). Note that we only need to diagonalize
Cf“1 once prior to sampling and then calculate fTCi—nlfeT : f*Tf*;
therefore, the overall computational complexity of the integrator is
0(D2). Algorithm 1 shows the steps for this approach, which we

refer to as splitHM C.

4 Experiments

We illustrate the advantages of our HMC—based methods using four
simulation studies. We also apply our methods to analysis of a real
dataset. We evaluate our methods by comparing them to INLA in
terms of accuracy and to several sampling algorithms, MALA,
aMALA and ESZ, in terms of sampling efficiency. We measure sam—
pling efficiency with time—normalized effective sample size (ESS).
Given B MCMC samples for each parameter, we define the corres—
ponding ESS : B[1 + 225:1 y(/€)]_1 and calculate it using the
‘effectiveSize’ function in R Coda. Here, 25:11/06) is the sum of K
monotone sample autocorrelations (Geyer, 1992). We use the min—
imum ESS over all parameters normalized by the CPU time, s (in se—
conds), as the overall measure of efficiency: min (ESS) / s.

We tune the stepsize and number of leapfrog steps for our HMC—
based algorithm, such that their overall acceptance probabilities are
in a reasonable range (close to 0.70). In all experiments, we use
Gamma hyper prior parameters or : I} : 0.1.

ﬁm'spzumol‘pmyo'sopeuHOJLIrotq/ﬁdnq

Roberts and Tweedie, 1996 Knorr-
Held and Rue, 2002

Roberts and Stramer, 2002
Girolami and Calderhead, 2011 Supplementary Material

Minin at al., 2008 Gill at al., 2013
Murray at al., 2010
Palacios
and Minin (2013)

Palacios and Minin (2013)
Supplementary File

Figure 2

 

 

 

/810's113um0_fp103x0"sorJBmJOJurorW/zdnq

Figure 3

Figure 4

 

Table l

Drummond (#111,, 2005 Minin at al., 2

Drummond at al., 2012

Supplementary Figure S2 Supplementary File

Figure 4

Palacios and Minin, 2012 2013

 

008

 

 

1
ll

 

/3.IO'S[BIImOfp.IOJXO'SOTJBLUJOJIITOiqﬂIdllq

 

Figure 5

Table 2

Supplementary Document

Supplementary Material

Kuhner at al., 1998

Palacios and Minin, 2013

2014

13

Pakman and Paninski,

Supplementary File

/810's113um0_fp103x0"sorJBmJOJurorW/zdnq

Efficient Bayesian ph y/odynamics

3289

 

Girolami,M. and Calderhead,B. (2011) Riemann manifold Langevin and
Hamiltonian Monte Carlo methods]. R. Stat. Soc. B 73, 123—214.

Grifﬁths,R.C. and Tavare,S. (1994) Sampling theory for neutral alleles in a
varying environment. Philos. Trans. R. Soc. Lond. B Biol. Sci., 344,
403—410.

Heled,]. and Drummond,A. (2008) Bayesian inference of population size his-
tory from multiple loci. BMC Evol. Biol., 8, 289.

Kalman,R.E. (1960) A new approach to linear ﬁltering and prediction prob-
lems. Trans. ASME ]. Basic Eng., 82(Series D), 35—45.

Kingman,]. (1982) The coalescent. Stochastic Processes Appl., 13, 235—248.

Knorr-Held,L. and Rue,H. (2002) On block updating in Markov random ﬁeld
models for disease mapping. Scand. ]. Stat., 29, 597—614.

Kuhner,M.K. et al. (1998) Maximum likelihood estimation of population
growth rates based on the coalescent. Genetics, 149, 429—434.

Lan,S. (2013) Advanced Bayesian computational methods through geometric
techniques. Ph.D. dissertation, Copyright ProQuest, UMI Dissertations
Publishing 2013, M3.

Leimkuhler,B. and Reich,S. (2004) Simulating Hamiltonian Dynamics.
Cambridge University Press, New York.

Minin,V.N. et al. (2008) Smooth skyride through a rough skyline: Bayesian
coalescent-based inference of population dynamics. Mol. Biol. Evol., 25,
1459—1471.

Mullen]. et al. (1998) Log Gaussian Cox processes. Scand.  Stat., 25:
451—482.

Murray,I. et al. (2010) Elliptical slice sampling. ]. Machine Learn. Res.
Workshop Conf. Proc., 9, 541—548.

Neal,R.M. (2010) MCMC using Hamiltonian dynamics. In: Brooks, S. et al.
(eds.) Handbook of Markov Chain Monte Carlo. Chapman and Hall/CRC,
Boca Raton, pp. 113—162.

Opgen-Rhein,R. et al. (2005) Inference of demographic history from genealogical
trees using reversible jump Markov chain Monte Carlo. BMC Evol. Biol. 5, 6.
Pakman,A. and Paninski,L. (2014) Exact Hamiltonian Monte Carlo for trun-

cated multivariate Gaussians.]. Comput. Graphical Stat., 23, 518—542.

Palacios,].A. and Minin,V.N. (2012) Integrated nested Laplace approximation
for Bayesian nonparametric phylodynamics. In: de Freitas,N. and
Murphy,K.P. (eds.) UAI. Catalina Island AUAI Press, pp. 726—735.

Palacios,].A. and Minin,V.N. (2013) Gaussian process-based Bayesian non-
parametric inference of population size trajectories from gene genealogies.
Biometrics, 69, 8—18.

Rambaut,A. et al. (2008) The genomic and epidemiological dynamics of
human inﬂuenza A Virus. Nature, 453, 615—619.

R0berts,G.O. and Stramer,O. (2002) Langevin diffusions and Metropolis-
Hastings algorithms. Methodol. Comput. Appl. Probability 4, 337—357.

R0berts,G.O. and Tweedie,R.L. (1996) Exponential convergence of Langevin
distributions and their discrete approximations. Bernoulli, 2: 341—363.

Rodrigo,A.G. and Felsenstein,]. (1999) Coalescent approaches to HIV popula-
tion genetics In: Crandall,K. (ed.) The Evolution of HIV, Johns Hopkins
Univ. Press, Baltimore, pp. 233—272.

Rue,H. and Held,L. (2005) Gaussian Markov Random Fields: Theory and
Applications, volume 104 of Monographs on Statistics and Applied
Probability. Chapman 8c Hall, London.

Rue,H. et al. (2009) Approximate Bayesian inference for latent Gaussian mod—
els by using integrated nested Laplace approximations. ]. R. Stat. Soc. B 71,
319—392.

Shahbaba,B. et al. (2013) Split Hamiltonian Monte Carlo. In: Statistics and
Computing, 24, 339—349.

Strimmer,K. and Pybus,O.G. (2001) Exploring the demographic history of DNA
sequences using the generalized skyline plot. Mol. Biol. Evol., 18, 2298—2305.

ﬁm'spzumol‘pmyo'sopeuuoptrorq/ﬁdnq

