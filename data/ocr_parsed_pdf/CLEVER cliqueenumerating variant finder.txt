BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

T.Marschall et al.

 

It is common to many library protocols that internal segment
size follows a normal distribution with machine— and protocol—
specif1c mean It and standard deviation (7. On a side remark, we
would like to point out that our approach does not depend on this
assumption and that we also accommodate arbitrary internal seg—
ment size distributions (which may result from preparing libraries
without a size selection step, as one example) to the user. One
commonly deﬁnes concordant and discordant alignments: an align—
ment with interval length [(A) (see Fig. l) is concordant iff
|I(A) — MI 5 K0 and discordant otherwise. The constant K can
vary among the different approaches. A concordant read is deﬁned
to concordantly align with the reference genome, that is, it should
give rise to at least one concordant alignment.

With only one exception (Lee et al., 2009, MoDIL), all prior
approaches discard concordant reads. In this article, we present
clique—enumerating variant finder (CLEVER), a novel insert size
based approach that takes all, including concordant, reads into
consideration. Although a single discordant read is signiﬁcantly
likely to testify the existence of a structural variant, a single con—
cordant read only conveys a weak variant signals if any.
Ensembles of consistent concordant alignments, however, can pro—
vide significant evidence of usually smaller variants. The major
motivation of this study is to systematically take advantage of
such groups of alignments to not miss any significant variant
signal among concordant reads.

We employ a statistical framework, which addresses deviations
in insert size, alignment quality, multiply mapped reads and
coverage fluctuations in a principled manner. As a result, our
approach outperforms all prior insert size approaches on both
simulated and biological data and also compares favorably with
two state—of—the—art split—read aligners. Beyond its favorable re—
sults, our tool predicts a substantial amount of correct indels as
the only tool (e. g. more than 20% of true deletions of 2049 bp in
the simulated data). Overall, CLEVER’s correct calls benef1cially
complement those of the split—read aligner considered (Ye et al.,
2009, PINDEL).

Moreover, we need ~8 h on a single CPU for a 30>< coverage
whole—genome dataset with ~l billion reads, which compares
favorably with the estimated 7000 CPU hours needed by
MoDIL, the only method that also takes all reads into
consideration.

I(B)=yB—xB—1

 

 

 

Reference genome :13 B . .yB
,' ,' “ “ Alignment B
Paired-end read | '

I(A)=yA—mA—1
Reference genome :13,“ .yA

 

 

 

l l
l
l

,'  Alignment A
Paired-end read ' |

I I
I I
I I
I I
I I

02 = (145,146,147)

1.1 Approach and related work

1.1.] Graph—based framework Our approach is based on orga—
nizing all read alignments into a read alignment graph, whose
nodes are the alignments and edges reflect that the reads behind
two overlapping alignments are, in rigorous statistical terms,
likely to stem from the same allele. Accordingly, maximal
cliques (max—cliques) reflect maximal consistent groups of align—
ments that are likely to stem from the same location in a donor
allele. Because we do not discard alignments, the number of nodes
in our read alignment graph is large. We solve instances with
more than 109 nodes. We determine all max—cliques in this
graph by means of a specifically engineered, fast algorithmic
procedure.

The idea to group alignments into location—specif1c, consistent
ensembles, such as max—cliques here, is not new. In fact, it has
been employed in the vast majority of previous insert size based
approaches. We briefly discuss related concepts of the three most
closely related approaches by Hormozdiari et al. (2009,
VariationHunter [VH]), Sindi et al. (2009, GASV) and Quinlan
et al. (2010, HYDRA). Although not framing it in rigorous stat—
istical terms, HYDRA is precisely based on the same concept of
max—clique as our approach. After constructing the read align—
ment graph from discordant reads alone, they employ a heuristic
algorithm to find max—cliques. Because no theoretical guarantee
is given, it remains unclear whether HYDRA enumerates them
all. The deﬁnition of a ‘valid cluster’ in VH (Hormozdiari et al.,
2009) relaxes our deﬁnition of a clique in a subtle, but decisive
aspect. As a consequence, each of our max—cliques forms a valid
cluster, but the opposite is not necessarily true. The reduction in
assumptions, however, allows VH to compute valid clusters as
max—cliques in interval graphs in a nested fashion, which yields a
polynomial run—time algorithm. Sindi et al. (2009, GASV) use a
geometrically motivated definition that allows application of an
efﬁcient plane—sweep style algorithm. A closer look reveals that
each geometric arrangement of alignments inferred by GASV
constitutes a max—clique in our sense, but not necessarily vice
versa, even if a max—clique is formed by only discordant read
alignments. We recall that GASV, HYDRA and VH do not
consider concordant read data and hence consider read align—
ment graphs of much reduced sizes.

Reference genome

 

 

 

 

 

 

   

 

 

 

Read alignment graph Alignments

Fig. 1. Left panel: two read alignments. Assuming I(A)>p,>I(B), where p, is the mean of the true insert size distribution, alignment A is likely to
indicate a deletion while alignment B may indicate an insertion. Right panel: Read alignment graph for seven closely located read alignments. Note that
l/3(I(A5) + I(A(,) + I(A7))> l/3(I(A1) + 1(A2) + 1(A3). Assuming that all alignments have equal weight, C2 is more likely to indicate a deletion than C1
through a hypothesis test as in Equations (3) and (2). Note that we have not marked cliques (A3, A4) and (A4, A5). See Figure 2 for deﬁnition of edges

 

2876

ﬁm'spzumofpmﬂo'sopeuuopuorq/ﬁdnq

CLEVER

 

Finding max—cliques is NP—hard in general graphs. On the
basis of the idea that the read alignment graph we consider
still largely resembles an interval graph, we provide a speciﬁcally
engineered routine that computes and tests all max—cliques in a
reasonable timeiabout 1 h on a current eight—core machine for a
whole human genome sequenced to 30x coverageﬁlespite that
we do not discard any reads.

1.1.2 Significance evaluation

Commonly concordant and discordant reads: Testing whether
|I(A) — MI 3 K - o, to determine whether a single alignment is
concordant, is equivalent to performing a Z—test at signiﬁcance
level pK :2 1 — <I>(K), where CD is the standard normal distribu—
tion function. However, when determining whether m consistent
alignments (such as a clique of size m) with mean interval length i
are commonly concordant, a Z—test for a sample of size m is
required, which translates to

1—¢(M-¥)2pK¢>M-Ii—MIEKU. (1)

Due to the factor ﬂ, already smaller deviations |I— — Ml turn out
to render the alignments commonly discordant. In our approach,
we rigorously expand on this idea. Roughly speaking, each
max—clique undergoes a Inequality—(1)—like hypothesis test.

Multiply mapped reads: Although we approach the idea of not
‘overusing’ multiply mapped reads in an essentially different
fashion, our routine serves analogous purposes as the set—cover
routines of VH and HYDRA. The difference is that we statis—
tically control read—mapping ambiguity but do not aim at resol—
ving it.

Following Li et al. (2008), we compute each alignment’s prob—
ability of being correctly placed. In case of a max—clique consist—
ing of alignments A1, ...,An (all from different reads) with
probabilities p1, ...,pn, let A1,] C {1, ...,n} be the event that
precisely the alignments A), j 6 J are correct. We compute
P(AJ) = n/er/n/¢J(l —p,«). Let H0 be the null hypothesis
that the allele in question thatiwe recall that max—cliques just
represent groups of alignments likely to be from the same allelei
coincides with the reference genome. In correspondence to
Inequality (1), we compute

Par/11> := 1 — ¢<¢m¥> (2)

with I} = $2146 J p/I(A/), which is the probability of obser—

ving A], j 6 J when assuming the null hypothesis, given A J. We
further compute

PH0(A1, ...,An) = Z P(AJ)PH0(AJ) (3)

JC{1, ...,n}

as the probability that max—clique A1, ..., Am does not support
an indel variant. We further correct PH0(A1, . . . , A") with a local
Bonferroni factor to adjust for coverage—mediated ﬂuctuations in
the number of implicitly performed tests. If the corrected
PH0(A1, ..., A") is signiﬁcantly small, it is likely that (at least)
one allele in the donor is affected by an indel at that location. See
Section 2 for details. In a last step, we apply the Benjaminii
Hochberg procedure to correct for multiple hypothesis testing
overall. Note that, among the prior approaches, only MoDIL

(Lee et al., 2009) addresses to correct for multiple hypothesis
testing (also using Benjamini—Hochberg), although many others
either explicitly (e.g. Chen et al., 2009) or implicitly
(e.g. Hormozdiari et al., 2009; Korbel et al., 2009; Quinlan
et al., 2010) perform multiple hypothesis tests.

Among the statistically motivated approaches, Lee et al.
(2009), after clustering, use KolmogoroviSmirnov tests in com—
bination with bimodality assumptions, whereas Chen et al.
(2009) measure both deviations from Poisson—distribution
based assumptions (BreakdancerMax) and use Kolmogorovi
Smirnov (BreakdancerMin) tests to discover copy number
changes.

2 METHODS
2.1 Notations, deﬁnitions and background

2.1.] Reads and read alignments Let R be a set of paired-end
reads, stemming from a donor (genome) that has been aligned against
a reference (genome). We write A for a paired-end alignment, that is a
pair of alignments of the two ends of a read (Fig. 1) and A(R) for the set
of correctly oriented alignments that belong to read R. We neglect incor-
rectly oriented alignments and write A = U RA(R) for the set of all align-
ments we consider. We assume that |A(R)| Z 1; that is, each read we
consider give rise to at least one well-oriented alignment. We do not
discard any reads.

We write XA for the rightmost position of the left end and y A for the
leftmost position of the right end. We write [XA + 1, y A — 1] and call this
the interval of alignment A (in slight abuse of notation: intervals here only
contains integers) and I(A) := y A — XA — 1 for the (alignment) interval
length. When referring to alignment intervals, we sometimes call X A, y A
the left and right endpoint. See Figure 1 for illustrations.

2.1.2 Internal segment size statistics We write I(R) for the in-
ternal segment (or insert) size of paired-end read R, i.e. the distance be-
tween the 3’ endsithe inner ends of the sequenced reads. Note that the
distance between the 5’ outer ends is an equally common deﬁnition for
insert size in the literature. In the datasets treated here, I(R) can be
assumed normally distributed with a given mean a and standard
deviation :7 (Hormozdiari et al., 2009; Lee et al., 2009; Li and Durbin,
2009; Li et al., 2008), i.e. I(R) ~N(#.0). Estimation of mean a and
standard deviation :7 from the alignments A of reads R poses the chal-
lenge that statistics on alignment insert size I(A) (further denoted as PEmp)
do not immediately reﬂect statistics on I(R) because alignment insert size
I(A) statistics already reﬂect the structural variants in the dataset. As a
result, statistics on I(A) are fat-tailed and multimodal, even if library
protocols determine statistics on I(R) as normal. Here, we rely on
robust estimation routines, as implemented by BWA (Li and Durbin,
2009). Note that, in general, we allow to deal with arbitrary internal
segment size statistics.

2.1.3 Alignment scores and probabilities As described by Li et al.
(2008), we determine loglo Pph(A) := — Z]. Qj/IO, wherej runs over all
mismatches in both read ends and QJ- is the Phred score for position j, i.e.
1049/10) is the probability that the nucleotide at position j reﬂects a
sequencing error. Hence, Pph(A) is the probability that the substitutions
in alignment A are due to sequencing errors. The greater Pph(A) the more
likely that A is correct, so Pph(A) serves as a statistical quality assessment
of A. Note that to neglect single-nucleotide polymorphism (SNP) rates
and indels reﬂects common practice (Li and Durbin, 2009; Li et al., 2008),
which is justiﬁed as in Illumina reads substitution error rates are higher
than SNP rates, indel sequencing error rates and deletion/insertion

 

2877

ﬁm'spzumofpmjxo'sopeuuopnorq/ﬁdnq

T.Marschall et al.

 

polymorphism (DIP) rates by orders of magnitude (Bravo and Irizarry,
2010; Albers et al., 2011).

Following Li et al. (2008) and Li and Durbin (2009), we integrate the
empirical interval length distribution PEmp(I(A)) into an overall score
SO(A) := Pph(A) - PEmp(I(A)) and obtain as the probability that A is
the correct alignment for its read, by application of Bayes’ formula

P0(A) = L)“ (4)
Z 50(A)

AEA(R)

2.1.4 The read alignment graph We arrange all scored read align-
ments A in the form of an undirected, weighted graph G = (A, E, w).
Because we identify nodes with read alignments from A, we use these
terms interchangeably. We draw an edge between alignments A, B e A if
we cannot reject the hypothesis that, in case they are both correct, their
reads can stem from the same allele. See the subsequent paragraph for
details. The weight function w : A —> [0, 1] is deﬁned by w(A) := P0(A).
We further label nodes by r : A —> {1, ...,N}, where r(A) = n iff
A e A(R,,) that is alignment A is due to read R,,.

As usual, we write 8(A) := |{B e A|(A, B) e E}| for the degree of node
A. A clique C C A is deﬁned as a subset of mutually connected nodes, i.e.,
(A, B) e E for all A, B e C. A max-clique C is a clique, such that for every
node A e A \ C there is B e C : (A, B) g! E. Note that by our deﬁnition of
edges, a clique is a group of alignments that can be jointly assumed to be
associated with the same allele, or, in other words, to jointly support the
same local phenomenon in the donor genome. Max-cliques are obviously
particularly interesting: although all alignments in the clique are likely to
support the same local phenomenon, joining any other overlapping align-
ment may lead to conﬂicts.

2.1.5 Edge computation See Figure 2 for illustrations of the fol-
lowing. Let A, B be two alignments. We deﬁne:

7 A(A, B) := |I(A) — I(B)| is the absolute difference of interval length.

7 0(A,B) := min(yA,yB) — max(xA,xB) — 1, where in case of
0(A,B) : 0 we refer to all positions between max(xA, X3) and
min(yA, yB) as their common interval.

7 1(A, B) :2 (I(A) + I(B))/2 is the mean interval lengths.

7 U(A, B) := 1(A, B) — 0(A, B) is the difference of mean interval
length and overlap. To motivate this quantity, note that, in case A
and B overlap [hence, the length of common interval 0(A,B)>0]
and are from the same allele, a deletion at that location can only
happen to take place in their common interval. If U(A, B) is large,
then 1(A, B) signiﬁcantly deviates from p, and the common interval is
not large enough to explain this by a large-enough deletion. Hence, it
is unlikely that A,B are from the same allele.

Let X be ./\/(0~ 1)-distributed and, as above, it, a be the mean and variance
of the insert size distribution. We draw an edge between alignments A, B
in the read alignment graph iff the reads of A and B are different,
0(A, B) 2 0 and

P(le Z éw) 5 0.05 and (5)
P(X Z (2%) 5 0.05 (6)

Inequality (5) is a two-sided two sample Z—test to measure statistically
compatible insert size. Inequality (6) reﬂects a one-sided one-sample Z—test
for statistically consistent overlap (W asserman, 2004). If two alignments
A, B with 0(A, B) 2 0 pass these tests, we have no reason to reject the
hypothesis that the alignments are from the same allele, so we draw an
edge.

2.2 CLEVER: algorithmic workﬂow

(1) Enumerating max-cliques: We compute all max-cliques in the read
alignment graph.

(2) We assign two P-values, pD(C),p1(C) to each max-clique C, which
are the probabilities that the alignments participating in C do not
commonly support a deletion or insertion. So the lower pD(C) or
p1(C), the more likely it is that C supports a deletion or insertion,
respectively.

(3

V

For the thus-computed P-value, we control the false discovery rate
at 10% by applying the standard Benjamini7Hochberg procedure
separately for insertions and deletions. All cliques remaining after
this step are deemed significant and processed further.

(4) Determining parameters: We parameterize deletions D by their left
breakpoint DB and their length DL, which denotes that reference
nucleotides of positions D B, . . . , D3 + DL — 1 are missing in the
donor. We parameterize insertions I by their breakpoint IB and
their length IL, such that before position 13 in the reference there
has been a sequence of length I L inserted in the donor. Depending
on whether C represents a deletion or insertion, we determine,
defining w(C) := 2,166 w(A),

Z w(A)(I(A) — pt) respectively
AEC

1 1

— — ‘ A — I A 7
W W; M )(u ( )) ( )
as the length DL of the deletion, respectively, IL of the insertion. We
determine breakpoints D3 or [B such that the predicted deletion or in-
sertion sits right in the middle of the intersection of all internal segments

of alignments in C.

2.2.1 Enumerating max—cliques We identify nodes of the read
alignment graph with the intervals of the corresponding alignments.
We ﬁrst sort the 2m endpoints of these intervals, m :2 |A|, in ascending
order of their positions. We then scan this list from left to right. We
maintain a set of active cliques that could potentially be extended by a
subsequent interval, which initially is empty. If the current element (3 of
the list is a left endpoint, we extend the set of active cliques according to
the following rules. For the sake of simplicity, let us assume that a unique
interval starts at 6, corresponding to a vertex A in the read alignment
graph G. Let N(A) be the open neighborhood of A. IfC ﬂ N(A) = (A for
all active cliques C, add a singleton clique {A} to the set of active cliques.
Otherwise, for each active clique C,

(i) if C F) N(A) = C, then C := C U {A}, otherwise
(ii) ifC ﬂ N(A) 7A (A, add (C F) N(A)) U {A} to the set of active cliques.

Finally, duplicates and cliques that are subsets of others are removed.

If the current element (3 of the list is a right endpoint, we output all
cliques that contain at least one interval ending at 6. These cliques go out
of scope and are thus maximal. We remove intervals ending at (3 from
active cliques. Cliques that become empty are removed from the set of
active cliques.

2.2.2 Run—time analysis Let k be an upper bound on local align-
ment coverage, c be the maximum number of active cliques and s be the
size of the output. The detailed run-time analysis of Section A in the Sup-
plementary Material gives a total running time of O(m(log m + kcz) + s).
Despite these rather moderate worst-case guarantees, our algorithm is
very fast in practice. See the Supplementary Material, Section A, for an
analysis of the corresponding reasons.

2.2.3 P—values for cliques We proceed as outlined in the Section
1.1.2. Let C be a max-clique in the read alignment graph and let
w(C) :2 2,166 w(A) = 2,166 P0(A) be the weight of the clique. Let
I(C) :2  - ZAEc w(A) - I(A) be the weighted mean of alignment interval

 

2878

ﬁm'spzumofpmjxo'sopeuuopnorq/ﬁdnq

CLEVER

 

(1) N0 edge: length
difference too large

_I<A> W—

(2) No edge: long insert
lengths but small overlap
A —I I (A) > It — A

—I(B)>H—B —I(B)>:M,— B

02/453) I—(A, B) > it
U(A, B) > ,u

(3) Edge: average insert
lengths, small overlap

(4) Edge: long insert lengths,
sufﬁcient overlap

1A)?“— A —:I(A)>/t—A
#93:)ng —§I(B)>M:— B

'O(A,B)5 f(A,B) >,u

0(3753) 1(A,B)z ,t
U(AB) < H

U(A, B) < M

Fig. 2. Four scenarios of two overlapping alignment pairs A and B. In the read alignment graph, two alignments are connected by an edge if they are
compatible, i.e. they support the same phenomenon. (1) Alignment A has an insert length about the expected insert length it, suggesting that there is no
variation present but alignment B has an insert length much larger than )1, suggesting a deletion. Hence, A and B are not compatible. (2) Both alignments
have similar insert lengths larger than [1,, both suggesting a deletion of size I(A) — p, % I(B) — [1,, but the overlap 0(A, B) is too small to harbor a deletion
of this size. Thus, they are incompatible. (3) Both alignments do not suggest any variation and are therefore compatible. (4) Similar to Case (2), but now

the overlap is large enough to contain the putative deletion

length of the clique. Let (D be the standard normal distribution function.
Let p(C) be the number of alignments that are at the genomic location of
the clique. For example, in Figure 1, p(C1) = p(C2) = 7 is just the
number of alignments that overlap with one another at this position of
the reference. We compute

moi, := W Z PH..(A.,>[1 — MM [(61%)] (8)

.ICC

i C —
12(6), := W ZPH.,(AJ>[<I>(M%)1 (9)
.ICC
just as in Equations (3) and (2) with the difference that we distinguish

between cliques, which give rise to deletions and insertions. 2’“) is the
number of subsets of alignments one can test at this location, that is the
virtual number of tests which we perform, so multiplying by 2’“) is a
Bonferroni-like correction. This correction accounts for coverage
ﬂuctuations.

If p(C)D is signiﬁcantly small then 1(C) is signiﬁcantly large; hence, the
alignments in C are deemed to commonly support a deletion.
Analogously, if p(C), is signiﬁcantly small, then C is supposed to support
an insertion. Refer to Supplementary Material, Section B, for details on
how the exponential sums in Equations (8) and (9) can be computed
efﬁciently.

3 RESULTS AND DISCUSSION

3.1 Simulation: Craig Venter reads

We downloaded the comprehensive set of annotations of both
homozygous and heterozygous structural variants (also including
inversions and all other balanced rearrangements) for Craig
Venter’s genome, as documented by Levy et al. (2007) and intro—
duced them into the reference genome, thereby generating two
different alleles. If nested effects lead to ambiguous interpret—
ations, we opted for an order that respects the overall predicted
change in copy number. We used UCSC’s SimSeq (https://
github.com/jstjohn/SimSeq) as a read simulator to simulate
Illumina paired—end reads with read end length 100, insert size
mean u = 112 (we recall: distance between the inner ends of the
sequenced reads) and standard deviation 0 = 15, which reﬂects
many biological datasets (see below). See Section J in the Sup—
plementary Material for performance rates on u 2 500,0 2 50
that highlights the limitations of insert size based approaches.
Coverage 15>< for each of the two alleles yields 30>< sequence
coverage overall.

3.2 Biological data: NA18507

We were further provided with reads of the genome of an indi—
vidual from the Yoruba in Ibadan, Nigeria, by Illumina. Reads
were sequenced on a GAIIx and are now publicly available (ftp: / /
ftp.sra.ebi.ac.uk/vol1/ERA015/ERA015743/srf/). Read ends are
of length 101. Read coverage is 30 x , furthermore
It 8 112, o B 15 (see the following paragraph). For benchmark—
ing purposes, we used annotations from Mills et al. (2011,
Gen.Res.) merged with NA18507 ‘DIP’ annotations from the
HGSV Project (http://hgsv.washington.edu/general/download/
SNPs_DIPs) database, lifted to hg18.

3.3 Reference genome and alignments

As a reference genome, we used version hg 18, as downloaded
from the UCSC Genome Browser. All reads considered were
aligned using BWA (Li and Durbin, 2009) with the option to
allow 25 alignments per read end, which amounts to a maximum
of 252 alignments per paired—end read. BWA determined mean
insert size It 8 112 and standard deviation 0 B 15 for both simu—
lated and NA18507 reads. Note that we are aware that realign—
ment of discordant reads with a more precise (but time
consuming!) alignment tool, such as Novoalign (http://www
.novocraft.com/main/index.php) (as suggested by Quinlan
et al., 2010), can lead to subsequent resolution of much mis—
aligned sequence and hence to improved results for all tools
considered.

3.4 Experiments

For benchmarking, we considered five different state—of—the—art
insert size based approaches, four of which are applicable for a
whole—genome study: GASV (Sindi et al., 2009), VH (Hormoz—
diari et al., 2009, v3.0), Breakdancer (Chen et al., 2009) and
HYDRA (Quinlan et al., 2010). We ran MoDIL (Lee et al.,
2009) only on Chromosome 1 of the simulated data which, on
our machines, required several hundred CPU hours. In contrast,
we process Chromosome 1 in less than 1 h. We also consider the
split—read aligners PINDEL (Ye et al., 2009) and SV—seq2 (Zhang
et al., 2012). Details on program versions and on how we ran
each method are given in Supplementary Material, Section C. In
case of deletions, we define a hit as a pair of a true deletion and a
predicted deletion that overlap and whose lengths do not differ
by more than 100 bp, which roughly is the mean of internal

 

2879

ﬁm'spzumol‘pmjxo'sopeuHOJmorq/ﬁdnq

T.Marschall et al.

 

segment size. We say that a true insertion (BO,L0) and a pre—
dicted insertion (Bl,L1), where B is for breakpoint, L is for
length, hit each other if the intervals [Bo + 1, ...,Bo + L0] and
[Bl + 1, ...,Bl + L1] overlap. This ‘overlap criterion’ precisely
parallels the one for deletions: if one views deletions in the ref—
erence as insertions in the donor, then the deletions in the refer—
ence (relative to reference coordinates) hit if and only if the
insertions in the donor hit (relative to donor coordinates).
Again, we also require |L0 — L1| g 100. We also offer results
on alternative hit criteria which, instead of overlap, depend on
ﬁxed thresholds on breakpoint distance and differences of indel
length in Supplementary Material, Section F. As usual, re—
call =TP/(TP+FN), where TP (=true positives) is the
number of true deletions being hit and FN (=false negatives)
is the number of true deletions not being hit. For Preci—
sion=TP/(TP+FP), TP is the number of predicted indels
being hit and FP is the number of predicted indels not
being hit. We relate recall and precision to one another and
also display the F—measure, F =2*Recall*Precision/(Recall+
Precision), as a common overall statistic for performance
evaluation. We refer to Exc. (=exclusive) as the percentage
of true annotations, which were exclusively (and correctly)
predicted by the method in question. Because the annotations

for the biological dataset are obviously still far from complete,
a false positive may in fact be due to a missing annotation.
We therefore call the ratio TP/(TP+FP) relative precision
(RPr.). For recall on the biological data, note that a good
amount of existing annotations may be of limited reliability.
Therefore, the F—measure is meaningless for these data and we
refrain from displaying it. Last but not least, we present aver—
age deviation of breakpoint placement and differences in
length for all tools in the Supplementary Material, Section
G. In Supplementary Material, Section H, we present CLE—
VER’s results on simulated data when including true align—
ments in the BAM ﬁles, or even using only true alignments
so as to analyze its behavior relative to removal of external
sources of errors.

3.5 Results

See Table 1 for performance ﬁgures. See also Section E in
the Supplementary Material for a further subdivision of the
10(750 000 bp part. Boldface numbers designate the best ap—
proach, and italic numbers the best insert size based approach
(if not the best approach overall). Comparing absolute numbers
of true indels in the biological data with the simulated data
points out immediately that the vast majority of annotations is

Table 1. Benchmarking results for simulated (Venter) and biological data (NA18507)

 

Dataset Venter insertions Venter deletions

NA18507 insertions NA18507 deletions

 

Prec. Rec. Exc. F Prec. Rec.

Exc. F RPr. Rec. Exc. RPr. Rec. Exc.

 

Length range 20—49 (8786 true ins., 8502 true del.)

CLEVER 62.5 53.0 20.4 57.4 60.4 66.8
BreakDancer 7 5.1 0.1 7 75.5 7.5
GASV NA NA NA NA 5.4 25.8
HYDRA 0.0 0.0 0.0 7 7 0.1
VH 32.4 8.4 0.2 13.4 66.3 8.0
PINDELa 66.1 44.9 18.7 53.5 49.5 55.8
SV-seq2“ NA NA NA NA 96.0 1 .2
Length range 5(799 (2024 true ins., 1822 true del.)
CLEVER 60.4 86.6 7.3 71.2 72.7 80.7
BreakDancer 86.5 56.5 0.2 68.3 87.3 48.1
GASV NA NA NA NA 46 .1 35.0
HYDRA 0.0 0.0 0.0 7 7 5.2
VH 55.8 76.6 1.4 64.5 66.5 65.8
PINDELa 77.5 20.5 0.3 32.5 72.5 37.5
SV-seq2a NA NA NA NA 83 .6 19.8
Length range 10(750 000 (3101 true ins., 2996 true del.)
CLEVER 66.2 23.8 2.0 35.1 87.6 69.9
BreakDancer 61.0 17.6 3.0 27.4 65.8 57.7
GASV NA NA NA NA 0.9 49.2
HYDRA 0.0 0.0 0.0 7 72.8 56.8
VH 60.4 25.5 3.5 35.8 58.8 65.1
PINDELa 7 1.9 0.0 7 84.7 39.5
SV-seq2a NA NA NA NA 81 .6 37.5

(2295 true ins., 2192 true del.)

15.9 63.4 7.7 24.1 8.4 8.9 44.7 6.6
0.0 13.6 7 0.3 0.0 8.2 5.8 0.0
1.8 8.9 NA NA NA 1.0 20.1 2.0
0.0 7 0.0 0.0 0.0 7 0.0 0.0
0.3 14.3 0.8 3.8 0.4 4.6 4.6 0.3

12.1 52.5 13.1 40.0 25.3 9.3 64.9 26.3
0.0 2.3 NA NA NA 15.2 1.6 0.2

(303 true ins., 294 true del.)
6.8 76.5 1.6 70.3 6.9 5.5 79.6 12.2
0.3 62.0 6.4 15.5 0.0 9.8 44.2 0.7
1.5 39.8 NA NA NA 2.3 34.7 1.0
0.0 7 0.0 0.0 0.0 7 2.4 0.0
1.5 66.1 1.4 62.7 2.3 4.3 57.1 1.4
0.4 49.4 10.8 29.7 1.3 8.3 43.9 0.3
0.2 32.0 NA NA NA 9.9 28.6 0.3

(165 true ins., 414 true del.)
4.1 77.7 0.5 31.5 1.8 4.8 70.3 2.7
0.0 61.5 0.9 23.0 1.8 5.2 62.1 0.5
1.0 1.7 NA NA NA 0.1 57.7 2.4
0.4 63.8 0.0 0.0 0.0 2.0 65.5 0.5
1.5 61.8 1.8 44.9 10.9 3.0 70.0 1.4
0.1 53.9 7 0.6 0.0 5.9 51.9 0.2
0.3 51.3 NA NA NA 3.9 34.5 0.0

 

Performance rates as recall, precision, exclusive predictions (Exc. which are true predictions, uniquely predicted by that tool) and F—measure are grouped by different indel size
ranges. Dash and NA stands for ‘no prediction” and ‘not applicable”, respectively. Insertions signiﬁcantly exceeding the internal segment size (~ 112 here) cannot be detected

by insert size based approaches. PINDEL does not detect such insertions either.
"Split—read approach.

 

2880

ﬁm'spzumol‘pmjxo'sopeuHOJmorq/ﬁdnq

CLEVER

 

still missing seemingly. Therefore, all results on the biological
data, in particular those on precision, can only reﬂect certain
trends. For the simulated data, all values reﬂect the ground
truth. As expected, performance rates greatly depend on the
size of the indels. For prediction of indels shorter than 20 bp,
split—read based approaches and/or read alignment tools them—
selves are the option of choice.

2H9bp: CLEVER outperforms all other approaches on the
simulated data and is the best insert size based approach also
on the biological data. PINDEL achieves best rates on the bio—
logical data. Also, CLEVER makes a substantial amount of ex—
clusive calls in all categories. Tables in the Supplementary
Material, subsection F.2, points out that 8(790% of
CLEVER’s indel calls come significantly close to a real indel.
Further analyses (Supplementary Material, Section H) demon—
strate that 30% of CLEVER’s false positives are due to misalign—
ments and mapping ambiguities (see External sources of errors
below). Obviously many of those extremely close but not truly
hitting calls are due to external errors. Breakdancer makes little
and highly precise calls at the expense of reduced accuracy in
terms of indel breakpoint placement and length (see
Supplementary Material, Section G).

5799 bp: Here, CLEVER achieves substantially better recall and
more exclusive calls than PINDEL on the biological data. On the
simulated data, CLEVER again achieves best overall perform—
ance. In contrast to 20719 bp, however, Breakdancer and VH
already make signiﬁcant contributions. Although VH achieves
good overall performance, Breakdancer mostly excels in preci—
sion. As before, when allowing a certain offset of breakpoints
(Supplementary Material, subsection F2) or when integrating
correct alignments (Supplementary Material, Section H),
CLEVER’s precision substantially rises from 6(772% to
72796% across the categories.

10750 000 bp: Also, CLEVER is best while other tools
(Breakdancer, HYDRA, VH) also make decisive contributions.
This documents that the current challenges for indel discovery
are rather in the size range of 2(7100 bp. Note that none of the
tools makes predictions for insertions longer than 250 bp, see
Section E in the Supplementary Material.

MoDIL: We compared MoDIL with all other tools on
Chromosome 1 alone because of the excessive run—time require—
ments of MoDIL (CLEVER is faster by a factor of ~1000). See
Supplementary Material, Section I. Overall, MoDIL incurs cer—
tain losses in performance with respect to CLEVER across all
categories, but outperforms the other insert size based
approaches apart from larger indels (3100 bp). It is noteworthy
that MoDIL makes a substantial amount of exclusive calls for
insertions of 5(799 bp.

Accuracy of breakpoint and length predictions: See Section G for
related numbers. The split—read based approaches outperform
the insert size based approaches. Among the latter, CLEVER
and GASV are most precise for 2(749 and 10(750 000 bp. For
5(799 bp calls, Breakdancer achieves favorable values.

External sources of errors: See Supplementary Material, Section
H, for related results and a detailed discussion on to what degree

misalignments and multiply mapped reads/alignment hamper
computational SV discovery.

Conclusion: We have presented a novel internal segment size
based approach for discovering indel variation from paired—end
read data. In contrast to all previous, whole—genome—applicable
approaches, our tool takes all concordant read data into ac—
count. We outperform all prior insert size based approaches on
indels of sizes 2(799 bp and also achieve favorable values for
long indels. We outperform the split—read based approaches con—
sidered on medium—sized (50799 bp) and larger (3100 bp) indels.
In addition, our approach detects a substantial amount of vari—
ants missed by all other approaches, in particular, in the smallest
size range considered (20719 bp). In conclusion, CLEVER makes
substantial contributions to SV discovery, in particular, in the
size range of 2(799 bp.

Our approach builds on two key elements: first, an algorithm
that enumerates maximal, statistically contradiction—free ensem—
bles as max—cliques in read alignment graphs in short time and,
second, a sound statistical procedure that reliably calls max—
cliques that indicate variants. Our approach is generic with re—
spect to choices of variants; max cliques in the read alignment
graphs can also reﬂect other variants such as inversions or trans—
locations. For future work, we are planning to predict inversions
and to incorporate split read information as a unifying approach.

Conﬂict of Interest: none declared.

REFERENCES

Abyzov,A. et al. (2011) CNVnator: an approach to discover, genotype, and char—
acterize typical and atypical CNVs from family and population genome sequen—
cing. Genome Res., 21, 9747984.

Albers,C.A. et al. (2011) Dindel: accurate indel calls from short—read data. Genome
Res., 21, 9617973.

Alkan,C. et al. (2009) Personalized copy number and segmental duplication maps
using next—generation sequencing. Nat Genet, 41, 106171067.

Alkan,C. et al. (2011) Genome structural variation discovery and genotyping. Nat
Rev. Genet, 12, 3637376.

Bentley,D.R. et al. (2008) Accurate whole human genome sequencing using revers—
ible terminator chemistry. Nature, 456, 53759.

Bravo,H.C. and Irizarry,R.A. (2010) Model—based quality assessment and
base—calling for second—generation sequencing data. Biometrics, 66, 665%74.
Campbell,P.J. et al. (2008) Identiﬁcation of somatically acquired rearrangements in
cancer using genome—wide massively parallel paired—end sequencing. Nat

Genet, 40, 7227729.

Chen,K. et al. (2009) Breakdancer: an algorithm for high—resolution mapping of
genomic structural variation. Nat Methods, 6, 677%81.

Chiang,D.Y. et al. (2009) High—resolution mapping of copy—number alterations with
massively parallel sequencing. Nat Methods, 6, 997103.

Eid,J. et al. (2009) Real—time DNA sequencing from single polymerase molecules.
Science, 323, 1337138.

Hach,F. et al. (2010) mrsFAST: a cache—oblivious algorithm for short—read map—
ping. Nat Methods, 7, 5767577.

Hormozdiari,F. et al. (2009) Combinatorial algorithms for structural variation de—
tection in high—throughput sequenced genomes. Genome Res., 19, 127(71278.

Itsara,A. et al. (2009) Population analysis of large copy number variants and hot—
spots of human genetic disease. Am. J. Hum. Genet, 84, 1487161.

Korbel,J.O. et al. (2009) PEMer: a computational framework with simulation—based
error models for inferring genomic structural variants from massive paired—end
sequencing data. Genome Biol, 10, R23.

Langmead,B. et al. (2009) Ultrafast and memory—efﬁcient alignment of short DNA
sequences to the human genome. Genome Biol, 10, R25.

Lee,S. et al. (2009) MoDIL: detecting small indels from clone—end sequencing with
mixtures of distributions. Nat Methods, 6, 4737474.

 

2881

ﬁm'spzumol‘pmjxo'sopeuHOJmorq/ﬁdnq

T.Marschall et al.

 

Levy,S. et al. (2007) The diploid genome sequence of an individual human. PLoS
Biol, 5, e254.

Li,H. and Durbin,R. (2009) Fast and accurate short read alignment with
Burrows—Wheeler transform. Bioinformatics, 25, 175471760.

Li,H. et al. (2008) Mapping short DNA sequencing reads and calling variants using
mapping quality scores. Genome Res., 18, 185171858.

Medvedev,P. et al. (2009) Computational methods for discovering structural vari—
ation with next—generation sequencing. Nat Methods, 6 (11 Suppl.), $137820.

Mills,R. et al. (2011) Natural genetic variation caused by small insertions and de-
letions in the human genome. Genome Res., 21, 83(7839.

Mills,R.E. et al. (2006) An initial map of insertion and deletion (indel) variation in
the human genome. Genome Res., 16, 118271190.

Quinlan,A.R. et al. (2010) Genome—wide mapping and assembly of structural vari—
ant breakpoints in the mouse genome. Genome Res., 20, 623$35.

Sindi,S. et al. (2009) A geometric approach for classiﬁcation and comparison of
structural variants. Bioinformatics, 25, i2227i230.

Sudmant,P.H. et al. (2010) Diversity of human copy number variation and multi—
copy genes. Science, 330, 641%46.

The 1000 Genomes Project Consortium. (2010) A map of human genome variation
from population—scale sequencing. Nature, 467, 106171073.

The International HapMap Consortium. (2005) A haplotype map of the human
genome. Nature, 437, 129971320.

Wasserman,L. (2004) All of Statistics. Springer, New York.

Ye,K. et al. (2009) Pindel: a pattern growth approach to detect break points of large
deletions and medium sized insertions from paired—end short reads.
Bioiiﬁ’ornmtics, 25, 286572871.

Yoon,S. et al. (2009) Sensitive and accurate detection of copy number variants using
read depth of coverage. Genome Res., 19, 158(71592.

Zhang,J. et al. (2012) An improved approach for accurate and efﬁcient calling
of structural variations with low—coverage sequence data. BM C Bioinformatics,
13, S6.

 

2882

/810's112um0fp10}x0"sonBuiJOJuioiqﬂ:duq

