ORIGINAL PAPER

Vol. 27 no. 2 2011, pages 225-231
doi: 1 0. 1 093/bioinformatics/btq650

 

Gene expression

Advance Access publication November 18, 2010

SLIM: a sliding linear model for estimating the proportion of true
null hypotheses in datasets with dependence structures
Hong-Qiang Wangl, Lindsey K. Tuominen1 and Chung-Jui Tsai1’2’*

1Warnell School of Forestry and Natural Resources and 2Department of Genetics, University of Georgia, Athens,

GA 30602, USA

Associate Editor: Trey Ideker

 

ABSTRACT

Motivation: The pre-estimate of the proportion of null hypotheses
(no) plays a critical role in controlling false discovery rate (FDR) in
multiple hypothesis testing. However, hidden complex dependence
structures of many genomics datasets distort the distribution of
p-values, rendering existing no estimators less effective.

Results: From the basic non-linear model of the q-value method,
we developed a simple linear algorithm to probe local dependence
blocks. We uncovered a non-static relationship between tests’
p-values and their corresponding q-values that is influenced by data
structure and no. Using an optimization framework, these findings
were exploited to devise a Sliding Linear Model (SLIM) to more
reliably estimate no under dependence. When tested on a number
of simulation datasets with varying data dependence structures and
on microarray data, SLIM was found to be robust in estimating no
against dependence. The accuracy of its no estimation suggests that
SLIM can be used as a stand-alone tool for prediction of significant
tests.

Availability: The R code of the proposed method is available at
http://aspendb.uga.edu/downloads for academic use.

Contact: cjtsai@warnell.edu.edu

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received and revised on September 28, 2010; accepted on
November 5, 2010

1 INTRODUCTION

Experiments in the ‘omics’ ﬁelds often involve hundreds to
thousands of dependent variables, such as those encountered in
genetic linkage (Lander and Kruglyak, 1995), gene expression
(Stafford and Yidong, 2007) and metabolic proﬁling (Clarke and
Haselden, 2008). Multiple testing correction is necessary in order to
identify statistically signiﬁcant variables for subsequent analyses,
without a ﬂood of false positives called by chance. The false
discovery rate (FDR) approach (Benjamini and Hochberg, 1995) and
its many variants, including the positive FDR (pFDR)-based q-value
statistic (Storey, 2002), have been widely used for false discovery
control in multiple hypothesis testing. The q-value represents the
minimum pFDR that can occur for any possible 6 greater than
or equal to a p-value point. Given a set of p-values ranked in an
increasing order, pi,i=1,2,...,m (m is the total number of tests),

 

*To whom correspondence should be addressed.

the q-value is calculated as:

q(pi)= “3mm (1)

 

This formula indicates that no is the only unknown parameter to be
pre-estimated. The accuracy of the no estimate directly affects the
q-value calculation and the optimal control of FDR. A reliable no
estimate also provides a simple prediction of the number of genes
that are differentially expressed under the experimental conditions
in gene expression analysis.

A widely used method is the A-estimator (Storey, 2002), i.e.

A #{Pi > A}

nom— (1 _ m (2)
where A e (0, 1) is a pre-chosen cutoff and #{pi > A} is the number
of p-values greater than A. Considering the non-linear relationship
between 710(A) and A, we refer to this estimator as the non-linear
model. The underlying assumption is that the largest p-values are
most likely to come from a uniform distribution of null features
in the range (0,1). In practice, there is a bias versus variance
tradeoff for choosing an optimal A for the estimation of 710 (Storey,
2002). To balance this trade-off, Storey and Tibshirani (2003) used
a natural cubic spline smoothing (CSS) method to ﬁt the non-
linear relationship across a range of A, as implemented in the
QVALUE software. Jiang and Doerge (2008) proposed an average
estimate (AE) method, which takes advantage of multiple non-linear
estimators to reduce the 710 estimation variance. Markitsis and Laj
(2010) recently proposed a censored beta mixture model (CBMM),
based upon the beta-uniform mixture (BUM) method of Pounds and
Morris (2003), to approximate the p-value distribution.

Both the original and the q-value-based FDR procedures were
developed for independent test statistics. Although these methods
can be applied to weakly dependent data (Benj amini and Hochberg,
1995; Storey and Tibshirani, 2003), they are unreliable for datasets
with inherent multiplicity and complex dependence (Clarke and
Hall, 2009). The BUM-based methods also cannot effectively
handle irregular p-value distribution (Markitsis and Lai, 2010).
To speciﬁcally handle multiple testing under dependence, Efron
(2007a) developed an empirical Bayesian framework, called Locfdr,
to remedy the effects of data correlation. However, Locfdr is only
applicable to data with a large (30.9) 710 (Efron, 2007a).

We have developed a linear n0 estimator from the non-linear
method of Storey (2002) to explore local properties of p-value
distributions as a means to better capture data dependence. When
applied to data with a uniform null p-value distribution, the slope
and intercept of the linear model reﬂect the proportions of null

 

© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 225

112 /3.Io's[Bruno[p.IOJXO'sorwurJOJurorq”:duq won papBOIII/lAOG

9103 ‘{g isnﬁnv 110::

H. -Q. Wang et al.

 

(710) and alternative hypotheses (711), respectively. Based on this
framework, we devised a sliding linear model (SLIM) for estimating
no that can be applied over a broader range of p-value distributions.
An interrelationship between p-values and q-values was observed
and exploited to optimize SLIM. We compared the performance of
SLIM with that of four other methods on three types of simulated
datasets mimicking various p-value distribution scenarios and data
dependence structures, as well as on one Populus microarray
experiment. The results show that SLIM performs better than the
previous methods under the conditions examined.

2 GENERATION OF SIMULATION DATASETS

Considering that dependence often leads to a distorted p-value
distribution, we generated two simulated datasets with uniform and
non-uniform null p-values, referred to as uniform and non-uniform
datasets, respectively, to investigate the effect of various p-value
distributions on 710 estimation. The third simulated dataset mimics
microarray gene expression data by explicitly adding dependence
structures.

2.1 Uniform and non-uniform datasets

The uniform and non-uniform datasets were produced using a
procedure modiﬁed from Storey (2002). For the former, we set
m: 10000, and generated mno null hypotheses from a normal
distribution with mean [20:0 and SD 0: 1, as well as m(1—7'r0)
alternative hypotheses from a normal distribution with M1 :5 and
a = 1. We varied 710 among 0.1—0.9 to track estimation performance.
The non-uniform datasets were similarly generated except that the
null hypotheses comprised a mixture of two normal distributions:
one with M0=—1 and 0:1 and the other, [20:1 and 0:1. The
mixture coefﬁcient was set to 11:05. The p-values for each dataset
were calculated assuming a normal null distribution N (0, 1).

2.2 Gene expression simulation datasets

We followed the procedure of Qin et al. (2008) to produce the
microarray gene expression simulation data, consisting of two
experimental conditions with sample sizes of 111 and 112, and
G=10 000 gene probes. To add hidden dependence structures,
a correlation background X [G ><n(n=n1+n2)] was generated by
(i) randomly selecting clump size m from {1,2,...,100} and
clump-wise correlation ,0 from U (051). For a given (m, ,0) pair,
we (ii) generated noise vectors ej of dimension m><1 from
N(0m,(1—,0)Im+p1m1;n), and (iii) set xj=lr+diag(w)e.j as the
background expression values of the m genes in the clump at sample
j=1,2,...,n=n1+n2, where [L is an m ><1 vector of elements

Mg ~1000xg and a) is an m X 1 vector ofelements cog =eﬁ0/2M51 /2,
and 50 and 51 are two constants for all G genes. In this exercise,
we set ﬂO=—5, 51 :2 and n1=n2=6.

Differential expression data were generated by setting an
as the number of genes differentially expressed between the
two conditions, with one half upregulated and the other half
downregulated. Steps (i) through (iii) were repeated to form a
correlation background for the 711G regulated genes in the 11
samples. We then added (or subtracted) a term 2_1/26gwg to (from)
the samples of one of the two conditions, where the coefﬁcient
68 was sampled from a uniform distribution U(5, 10) such that
the true expression ratio is 1+2_1/2eﬁ°/268~ U(1.2901, 1.5804).

Finally, we randomly replaced 711G rows of the background
X with the 711G differentially expressed genes, and varied 710
between 0.1 and 0.9 to simulate various data conﬁgurations, with
1000 iterations each. For each ‘gene’, we calculated the p-value
for differential expression between the two conditions using the
moderated t-statistic (Smyth, 2004).

3 THE LINEAR MODEL-BASED FRAMEWORK
FOR no ESTIMATION

Let #{pi f A} be the number of hypotheses with p-values less than a
cutoff A, we transform the Storey’s non-linear model to:

_ #{pi >A}
Wm
=>1—n0(1—),)=1_m:>1_ﬂ0(1_k)=#{17i£l}
m m
=>#{pi£)»}=m(l—JT0(1—A))=m(1_T[0+n-0)L) (3)

=>#{Pi S A} =(mA)770+m (1 -770)

Next, let y and x substitute #{pifA} and mA, respectively, and
Equation (3) can simply be rewritten as:

y=7r0x+m(1—Tr0)=rr0x+mrr1 (4)

where 711:1—710 is just the proportion of the alternative
hypotheses. Equation (4) clearly reveals that the total number of
hypotheses called signiﬁcant with a p-value cutoff A comprises
two portions: one associated with null hypotheses (false positive),
710x [or (mA)7'r0], and the other with alternative hypotheses (true
positive), mm. Let y: y / m be the proportion of hypotheses called
signiﬁcant by A, Equation (4) then becomes:

y=n0A+n1 (5)

The associated (A,y) plot actually represents the cumulative
probability distribution (CPD) of p-values (Fig. 1A). Intuitively,
from Equation (5) one may linearly ﬁt the CPD of p-values over
a proper range, and calculate the slope of this ﬁtting line as the
estimated 710. Without loss of generality, given a range of A,
A = [A5,Ae],0.05 3A5 <Ae f 1, the 710 estimation can be written as:

Ve — Vs

 

 

     

 
   
 

 

 

 

 

 

 

 

770(A57A6): (6)
Ae—AS
A C!— B G.— n
2' g- a $U=mo{1}=n_4219
g— mapl)=0.5895z(1—iio) A 3- now-4
- if.
' a
g" : 90(5kewrate}=0.409 g-
? no=0.-1
N- 3 N-
C) a
—9— Observed —9— Observed
EL — Linear ﬁtting curve q_ — Spline ﬁtting curve
C D

 

 

 

0.0 0:2 0:4 0:5 aia 1:0 0:0 0:2 0:4 Dis 018 1'.o
l A

Fig. 1. Estimation of no using (A) linear and (B) non-linear models. For
illustration. the proportion of true null hypotheses is no 2 0.4.

 

226

112 /3.io's[Bumo[p.IOJxosorwuiJOJurorq”:duq won papBOIIIAAOG

9103 ‘{g isanV 110::

Sliding linear model estimation of no

 

where ys and ye represent the cumulative probabilities at AS and Ae,
respectively, and 0.05 is set according to the conventional p-value
cutoff for statistical signiﬁcance.

For data with a uniform p-value distribution, Equation (6) may
be applied directly for no estimation. This is shown in Figure 1,
using the uniform simulation dataset. We obtained a linear ﬁtting
curve via Equation (6) over a range A e [0.7, 1] (Fig. 1A), and a non-
linear ﬁtting curve using the CSS algorithm (Storey and Tibshirani,
2003) with default parameters (Fig. 1B). Given a true no of 0.4,
Equation (6) takes advantage of the data linearity on the right side
of the (A,y) plot to yield a n0=0.4089, which is more accurate
than n0=0.4219 generated by CSS. Large variation of n0(A) at
A e [0.8, 1] makes ﬁtting the non-linear model more error prone.

Equation (6) only uses the partial information in A=[AS,Ae],
e.g. [0.7, 1] in Figure 1A, for the no estimation, and will
be inadequate to handle datasets with non-uniform p-value
distributions. In order to retain as much information as possible
about the null hypotheses’ p-value distribution, we devised the
following strategy for the estimation of no. We ﬁrst divide the
(A,y) plot into a series of A-segments (S). Thus, 11 segments can
be formed as:

S={Siisi=[)~i.)~i+1l}'f. 0.053% EMS-EM“ =1 (7)

We then linearly regress y by A using Equation (6) for each segment
and obtain 11 local estimates of n6=n0(Al-,Ai+1),i=1,2,...,n, in
accordance with Equation (7). In View of the overall null p-value
distribution being a mixture of local distributions, we estimate no as:

no =D_1(a) (8)

where D represents the cumulative distribution ﬁinction of ﬁg, D—1
represents its inverse (i.e. quantile) function, and 0 f or f 1 represents
a given quantile point. The selection of an appropriate value of or
will be addressed in Section 4.2. This n0 estimator, which we termed
the sliding linear model (SLIM), considers the collective effect of
null p-values over the majority of their distribution range. Therefore,
SLIM should be able to deal effectively with null p-values having a
complex distribution pattern.

4 PARAMETERS OF THE SLIM ESTIMATOR

In this section, we ﬁrst consider some properties of the q-value and
their implications for the development of SLIM. We then discuss
the optimization of SLIM parameters for no estimation.

4.1 Properties of q-values

Based on Equation (1), the CPD curves of p-values and q-values in
the (A, y) plot intersect at A =pz, where z: nom. This is illustrated
in Figure 2A and B (gray solid arrows) using the uniform simulation
datasets with various n0 scenarios. We observe that the q-value of a
given test is larger than p-value (i.e. 61,- > 1),) when p,- < pz and smaller
than p-value (ql- <pi) when p,- > pz. This non-static relationship
suggests that the common use of an arbitrary q-value cutoff, often
at the same level as the p-value or FDR cutoff, is not universally
appropriate.

Given n0, let pmax be the maximum p-value among the truly
signiﬁcant (as opposed to called signiﬁcant) tests; we infer that there
exists a corresponding, hidden maximum FDR, denoted by FDRmax.
That is, no false negatives are encountered at pmax, and all errors

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

... “.04 l
4. sin—as :
_ —l— x.._oa :
.
.
.
.

 

 

 

0-94

 

0.02

 

 

 

 

 

 

 

 

 

 

I
: P

   

Fig. 2. Non-static relationships between the p- and q-Values. (A and B)
Uniform simulation datasets (B gives a close-up View of A); (CiF) non-
uniform data. Gray solid arrows (A and B) indicate the intersection points
of the two corresponding CPD curves. and green dashed arrows (A4: and
E) depict the change of FDRmax across different no scenarios. (D) and (F)
illustrate the change of L (difference between the fractions of tests called
signiﬁcant by q-Values and p-Values) under a range of hypothetical no
values (true no:I:O.1) for three no scenarios. A ﬁxed pmax 20.05 was used
in A through D. while apmax =0.03. 0.02 and 0.01 was used for the three no
scenarios in E and F. Data presented in D are also shown in Table 2.

are due to false positives, estimated pmaxno. The FDRmax thus can
be written as:

FDRmax _ Pmale'O Pmax 770

— = — (9)
771+I7max770 1—(1—Pmax)”0

Taking pmax = 0.05 as an example, we can calculate the FDRmax by
Equation (9) for different n0 scenarios (Supplementary Table S1).
Since the rank of pmax is n1m+pmaxn0m, the q-value at pmax
becomes q=FDRmax according to Equation (1). Therefore, the
FDRmax can be taken as the maximum q-value among all alternative
tests. This means that the two hypothesis testing criteria, p-value and
q-value, will call the same set of tests signiﬁcant at their respective
cutoffs, pmax and FDRmax, because the q-value procedure does not
change the order of hypotheses ranked by p-values.

Let L be the absolute difference between the fractions of tests
called signiﬁcant by the two (p-value and q-value) methods; we
have L: 0 at the true value of no. Supplementary Figure S1
gives a geometric interpretation of the relationship in the (y,A)

 

227

112 /3.ro's[Bumo[pJOJxosorwuiJOJurorqﬂ:duq won papBOIII/lAOG

9103 ‘{g isanV 110::

H. -Q. Wang et al.

 

plot. Figure 2A and B illustrates the relationship for uniform
data: at A =FDRmax, the CPD of q-values has a y intercept same
as that of the CPD of p-values at A =pmax (green horizontal dashed
lines). For non-uniform data, the irregular distribution of null p-
values can skew this relationship, as shown for three n0 scenarios
at pmax=0.05, where no at the minimum L deviated from the
true values (Fig. 2C and D). However, given a proper pmax (e.g.
0.03, 0.02 and 0.01 for the three n0 scenarios, respectively), the
relationship held again, and the minimum L=0 gave accurate
n0 estimates (Fig. 2E and F). Extensive testing showed that L
always reached a minimum around the true n0 over a range of
pmax (Supplementary Fig. S2). Together, the data suggest that the
observed relationship between q- and p-values holds irrespective of
data structure, and can be exploited to guide the parameter tuning
of SLIM.

4.2 Parameter tuning of the SLIM estimator

The SLIM depends on three parameters: A 1, n and or. A1 speciﬁes the
lower boundary of the ﬁrst sliding segment used for no estimation
across the A axis of the (A,y) plot. Considering that the smaller
p-values are most likely to come from alternative hypotheses, a
small A1 is preferred to maximize the range of data coverage while
minimizing the inﬂuence of true positives on no estimation. Analysis
with various simulation datasets and n0 scenarios showed that the
mean relative errors (MREs) of no estimates reached a minimum
at A1 < 0.2 (Supplementary Fig. S3). We therefore set A1 :01 as
default. The parameter n speciﬁes the number of A-segments, and
inﬂuences how the distribution of null p-values is estimated. For data
encompassing a complex p-value distribution, a sufﬁciently large n
is necessary to capture clusters of similar p-values. However, an
overly large 11 may lead to smaller segments with abrupt changes in
slope and increase n0 estimation errors. We have found 11 = 10 to be
generally robust against a range of data scenarios.

The quantile parameter or captures the collective effect of the 11
local n0 estimates from the sliding segments, thus playing a crucial
role in the global no estimate by SLIM. Following the relationship
between p- and q- values, the selection of a proper or can be solved
as an optimization problem, i.e.

Minimize L =

 

Jig—ﬁg, s1. Ofafl (10)

 

where {:3 =#{qi < FDRmax} / m and fr]? = #{pi < pmax } / m represent
the fraction of tests called signiﬁcant by q-values and p-values,
respectively, under n3 =D_1(or). Equation (10) aims to choose the
optimal or by minimizing the difference L between fr“ and fr“ at
a given pmax to approximate the global n0. We devised an or-
searching procedure to solve the optimization problem. We ﬁrst
form a candidate set of or, A={orl- = ﬁti: 1,2, ...,B}, from which
a proper or will be selected. To gain sufﬁcient granularity, we set B
to be no less than 100. For each ori, we then calculate n3 =D_1(or)
and the difference L between fraand fr]? using no =ng and a given
pmax (see below). Finally, the (it with the minimum L is chosen as
the ﬁnal value of or.

We examined the effect of varying pmax on no estimation using
simulated uniform, non-uniform and gene expression data. Although
the results varied depending on data structure and n0 scenario, too
large (>06) and too small (<0.01) a pmaxtended to give rise to
large MREs of no, based on 1000 random iterations (Supplementary
Fig. S4). In most cases, the MRE was less than 0.1 for a pmax

between 0.01 and 0.1, suggesting that SLIM is relatively insensitive
to pmax (i.e. a true pmax is not necessary in practice, since it is an
unknown property). We recommend setting pmax at 0.05 as default.
For further optimization, users may wish to test multiple pmax and
examine the CPD curves of p-values and q-values in the resultant
(A,y) plots, as illustrated in Figure 2, in order to select an optimal
pmax’

Overall, we transform the or optimization problem into two
user-deﬁnable and insensitive parameters B and pmax, thereby
simplifying the implementation of SLIM. A procedural framework
for SLIM is depicted in Supplementary Figure S5.

5 SIMULATION EXPERIMENTS

We applied SLIM to the three types of simulation datasets from
Section 2 in comparison with four other methods: CSS (Storey and
Tibshirani, 2003), AE (Jiang and Doerge, 2008), CBMM (Markitsis
and Lai, 2010) and Locfdr (Efron, 2007a).

5.1 Uniform and non-uniform simulation data

Table 1 summarizes the mean errors and SD of no estimates for each
of the ﬁve methods across nine n0 scenarios on the uniform and non-
uniform data. The results show that SLIM achieved overall lower
mean errors for no estimation than the other four methods, especially
for the non-uniform data. CBMM also worked well, but exhibited
a decreasing accuracy as no increases. As reported by Efron
(2007a), Locfdr is applicable only to datasets with a large no, and
it was indeed most accurate for the non-uniform data with no :09
(Table 1). CSS and AE worked reasonably well with uniform data,

Table 1. Comparison of SLIM with four previous methods on uniform and
non-uniform simulation datasets

 

no 61 CSS AE CBMM Locfdr SLIM

 

Uniform data

0.1 03570.89 7.5/9.4 20.4/33.4 1.1/1.4 NA 3.8/1.6
0.2 0.26k0.78 110/137 194/306 1.8/1.8 NA 3.9/1.8
0.3 02170.69 138/182 124/165 1.9/2.0 NA 3.4/4.3
0.4 02570.65 158/184 107/124 1.8/2.2 NA 1.7/1.2
0.5 03370.78 16.8/19.8 11.1/12.3 2.3/3.1 NA 24/25
0.6 0.317071 176/203 116/98 2.4/3.1 NA 1.9/1.9
0.7 02970.82 18.6/21.1 8.4/8.3 2.5/3.2 NA 1.4/1.4

0.8 0.297080 19.5/23.0 9.0/9.6 2.6/3.1 43.5/36.1 1.9/1.6
0.9 0.327083 19.2/240 7.4/8.7 3.6/4.0 8.8/11.9 1.6/2.4

Non-uniform data

0.1 07440.90 781/72 297/38 125/13 NA 11.7/1.6
0.2 0.76k0.90 147.5/9.8 615/64 234/22 NA 17.7/1.7
0.3 0.76k0.89 231.6/14.5 917/68 368/25 NA 28.2/4.5
0.4 07570.89 299.3/14.5 117.2/5.1 48.6/3.2 NA 35.5/2.7
0.5 07440.90 379.0/12.3 130.5/13.6 60.1/4.0 NA 42.8/3.9
0.6 0.7(L0. 89 NA 138.2/7.4 71.2/3.1 NA 39.9/2.4
0.7 06870.88 NA 163.2/6.3 83.3/2.8 NA>1< 60.6/3.7
0.8 07170.89 NA 183.9/7.6 934/26 764/204 68.2/4.7
0.9 07770.90 NA NA 102.7/3.7 30.7/30.6 77.1/4.6

 

The smallest value for each no scenario is highlighted in boldface. NA, the method did
not work (in the cases of CSS and AE, no: 1 in all random iterations); *, mean error
and SD could not be determined because Locfdr did not work for some of the 1000
random datasets. Data are presented as mean error/SD (><10_3) of no estimates from
1000 random iterations.

 

228

112 /3.ro's[Bruno[pJOJxosorwuiJOJurorqﬂ:duq won papBOIII/lAOG

9103 ‘{g isanV 110::

Sliding linear model estimation of no

 

but lost their accuracy for non-uniform data, suggesting their general
deﬁciency in dealing with complex p-value distributions. Table 1
also reports the range of or determined by the optimization scheme
of Equation (10): (it was around the mid-range (~03 to 0.8) for the
uniform data, and trended toward larger values (~07 to 0.9) for the
non-uniform data.

Based on one of the non-uniform datasets (no :08), we
compared the computation cost of SLIM and three other previous
methods (CSS did not work for this dataset). The CPU time (in
second) was 1.1 (SLIM), 13.00 (AE), 0.17 (Locfdr) and 0.50
(CBMM) using an intel®Core2 Duo 3 GHz processor with 3 GB of
RAM and the Microsoft Windows XP operating system. The result
suggests that SLIM is not computationally demanding.

5.2 Gene expression simulation data with hidden
dependence structures

The simulated gene expression analysis showed that SLIM
outperformed the other four methods based on the mean errors
and SDs of no (Fig. 3). We calculated the number of alternative
hypotheses predicted by each method, i.e. (1 —fr0)>< 10000, as a
proxy of the number of differentially expressed (DE) genes for each
no scenario. Because the true null and alternative hypotheses are
known, the false positive rate (FPR), false negative rate (FNR), FDR
and accuracy of each method can be evaluated. SLIM achieved an

 

 

 

 

 

 

 

 

 

 

Q G
A 5' -- 055 B 3‘ v
+ AE , i.
g_ -+ CBMM 1, m g_ o._
‘3 ‘9' Locfdr "-I 8 Cl In," 
E ---- SLIM o—°'- =' v -._,,
2 § .1“ ‘to  E- o =-
II} : 15 Z ln-o-o—Ajp
I: °,a—.a-—n—A,_' ,4— a :
8 3- Ana/5 9 g 3- a x“ 1,
E o a ’ 1: :3 °
0 E / +
g- c/ ..+ 0’) g— +..+--+--+"+"
O _+_.+--+ +"+ + CI __+.. "
l. t:_.__‘__' ...g. I I i--I...__._..—-n--I--""
8.— 8.—
CI I r I I I | 0 I I I I I I
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
7T0 TKO

Fig. 3. Comparison of mean errors (A) and SDs (B) of no estimated by the
ﬁve methods in simulated gene expression analysis.

overall low FPR, FNR and FDR (Table 2). The ability of SLIM to
balance between false positive and false negative errors led to an
overall high accuracy (~0.99). The previous methods suffered from
various trade-offs. For instance, CBMM generated the lowest FNR
in most scenarios at the expense of higher FPR and FDR, leading
to reduced accuracy compared with SLIM. Locfdr was effective
for large no scenarios, producing a low level of FPR and FDR in
these cases, but at the expense of higher FNR and an overall low
accuracy. These results demonstrate the power and robustness of
SLIM in coping with data dependence structures. We also observed
that the n1 (=1—n0) estimate of SLIM may be used as a cutoff
for DE gene selection with sufﬁcient FDR control and a high level
of accuracy (Table 2). In practice, the FDRmax of the maximum
p-value among the (1 —fr0) X m DE genes may be taken as the FDR
for these DE genes. For the simulation data, the FDRmax values of
SLIM-called DE genes were found to be very close to the actual
FDR (most of the differences were around 0.001).

To illustrate the inﬂuence of hidden dependence structures on
the no estimation, representative p-value distributions of the three
types of simulation data were shown in histograms and (A,y) plots.
Compared with the uniform data (Fig. 4A), the non-uniform data
have a skewed distribution of null hypotheses (Fig. 4B), which
complicates no estimation. The addition of dependence structures
(Fig. 4C—G) led to various irregular p-value distribution patterns.
These differences in histograms are reﬂected in the CPD curves
of p-values in the (A,y) plot (Fig. 4H). The non-uniform data show
sinusoidal deviations from the straight line generated by the uniform
data, while the gene expression simulation datasets are intermediate
in shape between those for the uniform and non-uniform data. These
comparisons help explain why no estimation methods developed on
the assumptions of data independence and uniformity do not work
as effectively for datasets containing dependence structures.

6 APPLICATION TO REAL-WORLD GENE
EXPRESSION DATASETS
To test SLIM in practice, we examined two Affymetrix microarray

datasets from a Populus stress response experiment (GEO no.
GSE14515, Yuan et al., 2009). The experiment monitored gene

Table 2. FPR. FNR. FDR and accuracy of the ﬁve methods for the gene expression simulation data

 

no DE FPR
gene

FNR

FDR Accuracy

 

110‘ CSS AE CBMM Locfdr SLIM CSS AE CBMM Locfdr SLIM CSS AE CBMM Locfdr SLIM CSS AE CBMM Locfdr SLIM

 

0.1 9000 0.101 0.066 0.082 NA 0.119 0.013 0.034 0.004 NA
0.2 8000 0.071 0.048 0.053 NA 0.047 0.022 0.039 0.005 NA
0.3 7000 0.055 0.035 0.040 NA 0.024 0.029 0.040 0.006 NA
0.4 6000 0.051 0.032 0.034 NA 0.018 0.048 0.051 0.007 NA
0.5 5000 0.040 0.027 0.029 NA 0.013 0.075 0.068 0.009 NA
0.6 4000 0.029 0.021 0.024 NA 0.010 0.110 0.086 0.012 NA
0.7 3000 0.025 0.017 0.021 NA>1< 0.008 0.164 0.117 0.017 NA>l<
0.8 2000 NA 0.014 0.019 0.011 0.007 NA 0.174 0.024 0.404
0.9 1000 NA NA 0.019 0.008 0.007 NA NA 0.045 0.354

0.002 0.011 0.007 0.009 NA 0.013 0.978 0.962 0.989 NA 0.986
0.004 0.017 0.012 0.013 NA 0.011 0.968 0.959 0.986 NA 0.988
0.006 0.022 0.014 0.017 NA 0.010 0.964 0.961 0.984 NA 0.989
0.007 0.031 0.020 0.022 NA 0.012 0.951 0.957 0.982 NA 0.989
0.010 0.036 0.024 0.027 NA 0.013 0.942 0.953 0.981 NA 0.989
0.013 0.037 0.028 0.034 NA 0.015 0.938 0.953 0.981 NA 0.989
0.018 0.047 0.034 0.043 NA>1< 0.019 0.933 0.953 0.980 NA>1< 0.989
0.026 NA 0.047 0.064 0.011 0.028 NA 0.954 0.980 0.911 0.989
0.046 NA NA 0.121 0.054 0.053 NA NA 0.979 0.957 0.989

 

The best performer (lowest error rate or highest accuracy) from each no scenario is shown in boldface. FPR is calculated as the number of false positives over the number of false
positives plus true negatives; FNR is the number of false negatives over the number of false negatives plus true positives; FDR is the number of false positives over the number of
false positives plus true positives; and the accuracy is the number of true positives plus true negatives over the total number of tests. NA: the method did not work; *: Locfdr did
not work for some of the 1000 random datasets.

 

229

112 /3.IO'S[1211anprOJXO'SOIJBLUJOJIIIOIq”Idllq won papBo1umoq

9103 ‘1gisn8nv 110::

H. -Q. Wang et al.

 

 

 

 

 

 

 

A § 5% ‘3 §
‘— Unifonn ‘— Non-unifurm ‘— Dependence 1
E
3 a o c:
3 8 8 3
LI.
0 D D
l_I_I_I_!_l I—I_I_I_t_l I_I_I_I_I_I
0.0 0.4 0.8 0.0 0.4 0.3 0.0 0.4 0.3
p-value p-value p-value
D E 8 F 8
0
Dependence 2 ‘— Dependence 3 Dependence 4
E
3 o c: a
3 3 9r 8
LL
6 D O
I—I_I_I_I—l
0.0 0.4 0.8 0.0 0.4 0.8 0.0 0.4 0.3
p-value p-VEIUB p-value
G g ,
‘— Dependence 5
g A
:I >- B
E 8 G
LL ‘1' D
E
0 F
0.0 0.4 0.8 G
|
p-value 1'0

 

Fig. 4. Histograms and (A,y) plots of p-Values in different simulation
datasets. (A7G) Histograms for uniform (A) and non-uniform (B) data.
as well as data with ﬁve different dependence structures (C7G). (H) The
corresponding CPD curves of p-Values in the (A, y) plot.

Table 3. Estimates of no and the corresponding DE gene numbers by
different methods for the two Populus nitrogen stress datasets

 

CSS AE CBMM Locfdr SLIM r],=0.01 r],=0.05 r],=0.1

 

YL no 0.45 0.47 0.41 0.96 0.73 7 7 7
DE no. 7333 7099 7916 594 3649 1913 4134 5475

ML no 0.46 0.49 0.43 0.97 0.75 7 7 7
DE no. 7075 6751 7542 398 3285 1648 3787 5109

 

expression changes in young (YL) and mature (ML) leaves in
response to 4 week nitrogen depletion (normal versus low N),
each with two biological replicates. Raw hybridization signals
were processed using the R package affyPLM, and m=13335
probes that passed quality control ﬁltering (raw intensities 3100
in both replicates of at least one condition) were obtained for
ﬁirther analysis. We used the moderated t-statistics (Smyth, 2004)
to summarize the expression differences between treatments and to
calculate the corresponding p-values for each gene.

As shown in Table 3, SLIM obtained a no of 0.73 and 0.75 for
the YL and ML datasets, respectively, with a corresponding (ii of
0.7 and 0.72. In comparison, the estimates by CSS, AE and CBMM
were much lower (<0.5), while those by Locfdr were very high
(>0.95). Because the true no is unknown, the reproducibility of
the ﬁve methods for no estimation was evaluated. We followed
the bootstrap procedure of Markitsis and Lai (2010) to re-sample
the p-values 500 times with replacement and equal probabilities,
and to determine the 95% conﬁdence interval (CI) of the resultant
no estimates from the 500 resampling datasets. SLIM and CBMM

 

 

 

 

 

 

 

 

 

 

 

A ‘3._ __ B o_
 "
UL _:_ .'"
‘3 cu --'-
a :2 d_ .""
I: w_ I: ' -
.5 c __ *5 _--.. .
E ...._ T g m_ . _'-: - _
3° §° ----..---.-._
3% ra_ ‘ﬁ 
DJ 0 Lu ‘L - ‘ . v.-
o -.
w— ——
a _L El + CSS __v__ mm,
+ ‘T . N_ + ma
:— T a --+-- CBMM ' 8””
SLIM CSS AE Iocidr CBMM 0 0 0 2 0 4 0.6 0 8 1 0

Fig. 5. Comparison of the ﬁve methods on the Populus YL dataset. (A)
Boxplots of bootstrapped no estimates. (B) The relationship between local
no estimates across various segments A e[0.2.1] (short black bars) and the
global no estimates (horizontal lines).

both exhibited excellent stability as shown in the boxplot (Fig. 5A
for the YL dataset), with a tight 95% CI (SLIM: 0723—0731 and
CBMM: 0.404—0.413). In contrast, no estimates by the Locfdr had
the widest 95% CI. Similar results were obtained for the ML dataset
(Supplementary Fig. S6A).

Several lines of evidence suggest that the higher estimates of
SLIM and Locfdr are more reasonable than those of CSS, AE or
CBMM. First, Locfdr was designed for datasets having a large
no (Efron, 2007a), and our simulation analysis conﬁrmed that
it is indeed not applicable to no scenarios <0.7, regardless of
the dependence structure (Tables 1 and 2). The mere fact that
Locfdr worked suggests that the two datasets are more likely
to have a no greater than 0.7. Second, we estimated the proxy
number of DE genes (alternative hypotheses) by each method using
(1 —no) X 13 335, and compared the results with DE genes selected
by p-value cutoffs (Table 3). The underestimate of no by the CSS,
AE and CBMM methods is evident, judging from the large numbers
of corresponding DE gene proxies—greater than those obtained
by p30.1—in both datasets. Third, based on the local estimates
across various segments of Ae[0.2,1], the no of CSS, AE and
CBMM appeared to be biased toward A e[0.6,1], as shown for the
YL data in Figure 5B. The local estimates were obtained using the
linear estimator of Equation (6) and with segments sl- = [0.2+0.01 ><
(i—l),0.2+0.01Xi],i=1,2,...,80. Similar results were obtained
for the ML dataset (Supplementary Fig. S6B). These ﬁndings
suggest that the CSS, AE and CBMM methods largely disregard
the contribution of null p-values from [0,06], leading to their
underestimation of the no. The Locfdr has a tendency to
overestimate no (Fig. 5B) and incur a higher FNR based on our
simulation analysis (Table 2). Accordingly, it predicted fewer DE
genes for the two datasets, compared with those called by a stringent
p cutoff 1'], =0.01. The numbers of SLIM-predicted DE genes
for the YL and ML datasets (3649 and 3285, respectively) were
less than those (4134 and 3787) called by rp=0.05, consistent
with the default setting of pmax=0.05 in SLIM. The calculated
FDRmax was 0.12 and 0.13 for YL and ML, respectively, based on
Equation (9). Examination of the CPD curves of p- and q-values
showed that their respective y intercepts at pmaxand FDRmax are
in close proximity, with a negligible L (~10_4) in both datasets
(Supplementary Fig. S7). This suggests that the SLIM-estimated no
should be near their theoretical values. On these bases, we argue that
SLIM provides the most reasonable no estimate in practice. Users

 

230

112 /3.IO'S[1211anprOJXO'SOIJBLUJOJIIIOIq”Idllq won popBo1umoq

9103 ‘1gisn8nv 110::

Sliding linear model estimation of no

 

can further reduce the list of DE genes, if deemed necessary, by
other criteria, such as q-value, FDR or fold-change cutoffs.

7 DSCUSSON

An important issue in multiple hypothesis testing is how to deal with
the dependencies hidden among thousands of tests. Efron (2007b)
has shown that correlation among variables considerably changes
the theoretical null distribution patterns. We also observed that
dependence structures lead to distorted distributions of null p-values,
and this likely underlies the relatively large no estimation errors by
methods developed under the assumption of data independence. The
Locfdr approach (Efron, 2007a) was speciﬁcally designed to handle
data containing dependence structures, but it is only applicable
when no is large. CBMM uses a censored beta-uniform mixture
model to ﬁt the distorted p-value distribution, alleviating to some
degree the difﬁculty caused by dependence. SLIM is based on a
linear model transformed from the non-linear A estimator (Storey,
2002). The superior performance of SLIM can be ascribed to its data
partitioning and optimization schemes. SLIM uses a sliding linear
model to partition data into local dependence blocks. This reduces
data complexity, while enabling SLIM to utilize information from
a broader range of p-value distribution for no estimation. Using
simulated data, we uncovered a non-static relationship between
p-values and q-values of a given set of tests that is inﬂuenced by data
structure and no scenarios. SLIM employs an optimization scheme
to explicitly exploit this relationship by minimizing the difference
(L) between the fractions of tests called signiﬁcant by the p-value and
q-value methods. The optimization scheme is particularly important
to balance between positive and negative errors, thereby achieving
FDR control. Thus, SLIM effectively handles hidden dependence
without the need to empirically adjust the null p-value distributions.

The selection of a proper q-value cutoff in multiple hypothesis
testing is not trivial, especially given the dependence of the q-value
calculation on the no estimation. Recalling that the number of
signiﬁcant tests in a given experiment is simply nlm, we argue
that an accurate estimation of no can serve as an alternative to
q-value-based signiﬁcance testing. Using simulated data, SLIM
was shown to outperform the other methods, achieving the lowest
FDR overall, accompanied by the highest degree of accuracy in
declaring signiﬁcant tests. This suggests that SLIM can be used as a
stand-alone tool in multiple testing for determination of signiﬁcant
tests.

In summary, SLIM is a robust estimator especially suited for
datasets with non-uniform p-value distribution patterns due to

data dependence. SLIM is computationally efﬁcient and easy to
implement. It requires four user-selected parameters, n, A1, pmax
and B (the latter two are proxies of the quantile parameter at).
We recommend n= 10, A1=0.1, B: 100 and pmax=0.05 as the
default settings. Users may wish to test a higherB to ensure sufﬁcient
granularity, and a range of pmax for optimal or selection and no
estimate. In addition to microarray analysis, SLIM has been applied
to metabolite proﬁling analysis in our laboratory, and should be
applicable to a wide range of experiments

Funding: US National Science Foundation Plant Genome (grant
DBI-0836433 to C.-J.T.); National Science Funding of China (No.
30900321 to H.-Q.W.).

Conﬂict oflnterest: none declared.

REFERENCES

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: a practical
and powerful approach to multiple testing. J. R. Stat. Soc. B, 57, 2897300.

C1arke,S. and Hall,P. (2009) Robustness of multiple testing procedures against
dependence. Ann. Stat, 37, 3327358.

C1arke,C.J. and Haselden,J.N. (2008) Metabolic proﬁling as a tool for understanding
mechanisms of toxicity. Taxieal. Pat/10L, 36, 1407147.

Efron,B. (2007a) Size, power and false discovery rates. Ann. Stat, 35, 135171377.

Efron,B. (2007b) Correlation and large-scale simultaneous signiﬁcance testing, J. Am.
Stat. Assoc, 102, 937103.

Jiang,H. and Doerge,R.W. (2008) Estimating the proportion of true null hypotheses for
multiple comparisons. Caneer Inform, 6, 25732.

Lander,E. and Kruglyak,L. (1995) Genetic dissection of complex traits: guidelines for
interpreting and reporting linkage results. Nat Genet, 11, 2417247.

Markitsis,A. and Lai,Y. (2010) A censored beta mixture model for the estimation of the
proportion of non-differentially expressed genes. Biainfarmaties, 26, 64m646.
Pounds,S. and Morris,S.W. (2003) Estimating the occurrence of false positives and false
negatives in microarray studies by approximating and partitioning the empirical

distribution of p-values. Bioinformaties, 19, 123671242.

Qin,H. et al. (2008) An efﬁcient method to identify differentially expressed genes in
microarray experiments. Biainfarmaties, 24, 158371589.

Smyth,G.K. (2004) Linear models and empirical bayes methods for assessing
differential expression in microarray experiments. Stat. Appl. Genet. Mal. Biol, 3,
Article 3.

Stafford,P. and Yidong,C. (2007) Expression technology - a review of the performance
and interpretation of expression microarrays. IEEE Signal Prae. Mag., 24,
18726.

Storey,J.D. (2002) A direct approach to false discovery rates. J. R. Stat. Soc. B, 64,
479498.

Storey,J.D. and Tibshirani,R. (2003) Statistical signiﬁcance for genomewide studies,
Proc. Natl Acad. Sci. USA, 100, 944e9445.

Yuan,Y. et al. (2009) Alternative splicing and gene duplication differentially shaped the
regulation of isochorismate synthase in Papa/as and Arabidopsis. Pme. Natl Aead.
Sci. USA, 106, 22020722025.

 

231

112 /3.Io's172an0prOJxosoneuIJOJurorq”:duq won popeo1umoq

9103 ‘1gisn8nv 110::

