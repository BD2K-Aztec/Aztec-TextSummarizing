Vol. 29 ISMB/ECCB 2013, pages i117—i125
doi:1 0. 1093/bioinfonnatics/btt221

 

Stability selection for regression-based models of transcription

factor—DNA binding specificity

Fantine Mordelet‘, John Horton‘, Alexander J. Hartemink1'2‘3, Barbara E. Engelhardtl'e"4

and Raluca Gordan1'2'4‘5'*

1Institute for Genome Sciences and Policy, 2Department of Computer Science, 3Department of Statistical Science,
4Department of Biostatistics and Bioinformatics and 5Department of Molecular Genetics and Microbiology, Duke

University, Durham, NC 27708, USA

 

ABSTRACT

Motivation: The DNA binding specificity of a transcription factor (T F) is
typically represented using a position weight matrix model, which im-
plicitly assumes that individual bases in a TF binding site contribute
independently to the binding affinity, an assumption that does not
always hold. For this reason, more complex models of binding speci-
ficity have been developed. However, these models have their own
caveats: they typically have a large number of parameters, which
makes them hard to learn and interpret.

Results: We propose novel regression-based models of TF—DNA
binding specificity, trained using high resolution in vitro data from
custom protein-binding microarray (PBM) experiments. Our PBMs
are specifically designed to cover a large number of putative DNA
binding sites for the TFs of interest (yeast TFs be1 and Tye7, and
human TFs c-Myc, Max and Mad2) in their native genomic context.
These high-throughput quantitative data are well suited for training
complex models that take into account not only independent contri-
butions from individual bases, but also contributions from di- and
trinucleotides at various positions within or near the binding sites.
To ensure that our models remain interpretable, we use feature selec-
tion to identify a small number of sequence features that accurately
predict TF—DNA binding specificity. To further illustrate the accuracy of
our regression models, we show that even in the case of paralogous
TF with highly similar position weight matrices, our new models can
distinguish the specificities of individual factors. Thus, our work rep-
resents an important step toward better sequence-based models of
individual TF—DNA binding specificity.

Availability: Our code is available at http://genome.duke.edu/labs/
gordan/ISMB2013. The PBM data used in this article are available in
the Gene Expression Omnibus under accession number GSE47026.
Contact: raluca.gordan@duke.edu

1 INTRODUCTION

At the level of transcription, gene expression is regulated mainly
Via the binding of transcription factors (TFs) to speciﬁc short
DNA sites in the promoters or enhancers of genes they regulate.
Accurate characterization of the DNA binding speciﬁcity of TFs
is critical to understand how these proteins achieve their regula-
tory purpose in the cell. Currently, the most widely used model
for representing the DNA binding speciﬁcity of a TF is the pos-
ition weight matrix (PWM, or DNA motif) (Staden, 1984;
Stormo, 2000), a matrix containing scores (or weights) for each
nucleotide at every position in the TF binding site. PWMs can

 

*To whom correspondence should be addressed.

perform well in practice: these models have been combined with
chromatin accessibility data to successfully predict where speciﬁc
TFs bind across the genome in a cell-specific way (Kaplan et al.,
2011; Pique-Regi et al., 2011). However, PWM models make the
assumption that individual bases in a TF binding site contribute
independently and additively to the afﬁnity of that site, which
is not always true in practice.

Dependencies among positions within TF binding sites have
been observed in small-scale experimental studies (Bulyk et al.,
2002; Jauch et al., 2012; Man and Stormo, 2001), in statistical
analyses of known TF binding sites (Tomovic and Oakeley,
2007; Zhou and Liu, 2004), and in computational analyses of
high-throughput in vitro and in vivo TF binding data (Badis
et al., 2009; Berger et al., 2006; Jolma et al., 2013; Zhao et al.,
2012). This suggests that extending the classic definition of a
PWM may lead to speciﬁcity models that better ﬁt the TF binding
data. Indeed, several studies have explored more complex models
of TFiDNA binding speciﬁcity and found that they outperform
PWMs (Barash et al., 2003; Siddharthan, 2010). However, com-
plex models are typically characterized by a large number of par-
ameters, which makes them hard to interpret (Agius et al., 2010;
Annala et al., 201 1) and prone to overfitting (Zhou and Liu, 2004).

Here, we present regression-based models of TFiDNA
binding speciﬁcity, which take into account both the contribu-
tions from individual bases in a TF binding site and the contri-
butions from higher-order k-mers. Our approach differs from
previous work in three aspects: (i) our models are trained on
high-throughput quantitative data generated speciﬁcally for
this task; (ii) we use a new feature selection method based on
LASSO regression (Bach, 2008; Meinshausen and Biihlmann,
2010; Tibshirani, 1996) to restrict the number of features,
which makes our models easier to Visualize and interpret; and
(iii) we include dependencies by using 2-mers and 3-mers as fea-
tures and by using a non-linear support vector regression (SVR)
method. The first aspect is important because many previous
models were trained either on a small number of high-resolution
binding regions (Barash et al., 2003; Zhou and Liu, 2004) or on
high-throughput in vivo data (Sharon et al., 2008; Siddharthan,
2010), both of which are noisy, have low resolution and may
reﬂect both direct and indirect DNA binding of the tested TFs
(Gordan et al., 2009). In vitro data from high-throughput
assaySﬂuch as protein binding microarrays (PBMs) (Berger
et al., 2006), MITOMI (Maerkl and Quake, 2007) or high-
throughput SELEX (Jolma et al., 2010; Zhao et al., 2009Fare
more appropriate for learning complex models of TFiDNA
binding speciﬁcity (Agius et al., 2010; Annala et al., 2011;

 

© The Author 2013. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0/), which permits non—commercial re—use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial

re—use, please contact journals.permissions@oup.com

112 /310'slvu1nofp103xo"sorJBurJOJurorq/ﬁduq 11101} popcorn/hog

9103 ‘Og isnﬁnv uo ::

F.Mordelet et al.

 

B Myc 129119919;
Max 1 
Mad 

Fig. 1. PWMs for yeast TFs Cbﬂ and Tye7 (A) and human TFs Myc,
Max and Mad (B). PWMs were derived from universal PBM data
[Munteanu and Gordan, 2013 (B); Zhu et al., 2009 (A)], and PWM
logos were generated using enoLOGOS (Workman et al., 2005). As
Myc and Mad do not bind DNA efﬁciently on their own, the Myc and
Mad PBM experiments were performed using each TF in combination
with Max (see Section 3.1)

A  Lama-
Tye7 

Weirauch et al., 2013; Zhao et al., 2009). Here, we use the PBM
technology to generate custom data on the binding speciﬁcities of
the TFs of interest. Our microarray designs contain hundreds or
thousands of genomic DNA regions centered at putative DNA
binding sites for the TFs of interest (see Section 2 for details).

The features used in our regression models are based on the oc-
currences of 1-mers, 2-mers and 3-mers at various positions in the
TF binding sites or their ﬂanking regions. Regression models that
take into account all k-mers have hundreds or thousands of par-
ameters, depending on the value of k and on the size of the ﬂanking
regions. Such a large number of parameters can lead to overfitting
the training data and also make the models hard to Visualize and
interpret. To overcome this problem, we use a feature selection
approach based on LASSO regression (Bach, 2008; Haury et al.,
2012; Meinshausen and Buhlmann, 2010; Tibshirani, 1996). This
allows us to drastically reduce the number of parameters to
estimate while maintaining high prediction accuracy.

To illustrate the accuracy of our regression models, we train and
test them on custom PBM data for five TFs from the bHLH protein
family: yeast TFs be 1 and Tye7, and human TFs c—Myc (‘Myc’),
Max and Mad2 (‘Mad’). We show that for both yeast and human
bHLH TFs, our regression models can distinguish the binding
speciﬁcities of individual family members, although their PWMs
(Fig. 1) are highly similar. This illustrates that our approach may be
used to better understand the importance of intrinsic sequence
preferences for achieving speciﬁcity within TF families.

2 APPROACH

Our approach for learning TFiDNA binding specificity models is
summarized in Figure 2. We design custom microarrays that con-
tain genomic regions centered at putative TF binding sites. Next,
we measure TF binding to the selected genomic regions, using the
PBM technology (Berger and Bulyk, 2009). Brieﬂy, in a PBM
experiment, we express each TF of interest with an epitope tag
(typically a GST or 6xHis tag), purify it and apply it to a double-
stranded DNA microarray. After the TF binds its preferred se-
quences on the microarray, we label the microarray with a ﬂuor-
ophore-conj ugated antibody speciﬁc for the protein tag. Next, the
microarray is scanned to generate a ﬂuorescence intensity value
for each DNA sequence present on the array. Higher intensities
correspond to DNA sequences with higher afﬁnities for the TF.

The vast majority of PBM data available in the literature have
been generated using ‘universal’ array designs, which contain arti-
ﬁcial DNA sequences designed to collectively cover all possible
10-mers (Berger et al., 2006). Thus, universal PBM data provide a

 

 

 

 

 

 

Genome
Custom PBM data
>9“ 1 CACGTG PBM
11. 64 AGTAATAGCGATCACGTGATTATCCGTGGA
ATGCGGTT... scanning
>Chr 2 _>

11 . 55 AATAGATATTAGCACGTGI‘CTCGGAGAGAA
1 1 . 2 B TTTTTTTAACTGCACGTGCATCAAGGGGAT
12 . 03 TGATAAGCATATCACGTGACTGTGGTTCTA

 

 

 

ACCC [‘GGC...

>Chr n

WWW I mommosmuvmsmw

I

1199.133 Immvamsvammmvmv

 

 

swam msvsmmsmmvs

 

 

 

mouse); Valmvsmmmmm

d
a
a
d
E
Eexpe'imem 11.90 CATGTCCGGCATCACGMTTATGATGTAG
8
E

   

 

 

 

 

 

 

 

 

 

 

GTTCTTGA... Feature
derivation
11.64 0 1 1 Fauna 11.64 0 0 1 1 1 005 1
  11:2: 2::  11:: g   $3.1m
pred'ct'onfunct'on 11.2905 0.5 1 11.23 0.5 1 0.5 1 0 0 1 0
ISUChthat 12.03 1 1 1 12.03 1 0 1 1 1 1 0 0
Y=I(X') .. .  .
Y X’ Y X

Fig. 2. Workﬂow of the proposed method for learning the DNA binding
speciﬁcity of TFs using custom PBMs

broad, unbiased View of the DNA binding preferences of TFs.
However, universal PBM data are not suitable to predict binding
of a TF to longer genomic sequences. To overcome this problem,
we designed custom ‘genomic’ arrays to directly measure TF bind-
ing of putative DNA binding sites in native genomic context.
The DNA sequences on our custom microarrays were
designed to include a large number of potential DNA binding
sites for the TFs of interest. To learn the DNA binding speciﬁ-
cities of be 1 and Tye7, we used custom PBM data from Gordan
et a]. (2013). For Myc, Max and Mad, we designed a new array
containing potential Myc/Max/Mad binding sites extracted from
the human genome. As all bHLH TFs used in this study are
known to have a strong preference for the E-box CACGTG,
both the be 1 /Tye7 and the Myc/Max/Mad array designs
focus on the genomic sites centered at this E-box (Fig. 2).
From the raw PBM data, we compute the natural logarithm of
the normalized signal intensity for each DNA sequence contain-
ing the E-box CACGTG ﬂanked by genomic sequences of 12 or
15 bases on each side for be 1 /Tye7 and Myc/Max/ Mad, respect-
ively. Next, we derive quantitative features from the sequence
content of the genomic regions ﬂanking the CACGTG E-box
core, and we use them to train regression models that can predict
the PBM signal intensity (i.e. the in vitro TFiDNA binding spe-
ciﬁcity). Our custom PBM data allow us to investigate whether
the genomic ﬂanks of the E-box sites inﬂuence binding afﬁnity
differently for distinct members of the same TF family.
Regression-based approaches are a natural ﬁt for the continu-
ous intensity data from PBM experiments. The purpose of a
regression model is to estimate a function f to ﬁt the output y
to the input features X as y = f(X). In our case, y is the binding
intensity as measured on the microarray and X are DNA se-
quence features. In particular, to introduce dependency effects,
we take X to be all individual nucleotides, and all pairs, triplets
and quadruplets of sequential nucleotides (2-mers, 3-mers and
4-mers) in the DNA sequences in our training set. A good can-
didate function is expected to fit the training set well (i.e. y close
to f(X)) and to produce accurate predictions on new test ex-
amples (i.e. low generalization error). The latter is usually as-
sessed by cross-validation experiments, where part of the
dataset is used to learn the regression function, which is used
to predict the output y on the held out part.
When X is of high dimension, regularization is a standard
practice, which consists in smoothing function f to ensure low

 

i118

112 /310'slvu1nofp103xo'sopBHJJOJurorq/ﬁduq 11101} popcorn/hog

9103 ‘Og isnﬁnv uo ::

Stability selection for regression models of TF-DNA binding

 

generalization error and to prevent overﬁtting. One method of
regularization, known as ‘feature selection’, is to select a small
subset of features that are sufﬁcient to model the data. We note
that our DNA sequence features result in high-dimensional fea-
tures, which support the use of feature selection. Feature selec-
tion lends a model interpretability, by basing predictions on a
small number of features that may have biological meaning,
which is a desirable property when one wants to study further
which features contribute to model accuracy.

Two popular regression methods are SVR (Smola and
Schélkopf, 2004) and LASSO regression (Tibshirani, 1996). SVR
often has good generalization error properties and, when used with
a non-linear kernel, can capture non-linear functions f. LASSO
regression includes an L1 constraint that selects a small subset of
features in X to explain the y variable and is preferred for inter-
pretability purposes. However, the feature set selected by LASSO
is not robust, even to slight perturbations of the data. This lack of
stability casts doubt on the relevance of the subset of variables it
selects. Following previous work (Bach, 2008; Haury et al., 2012;
Meinshausen and Biihlmann, 2010) on ‘stability selection’, we pro-
pose a regression scheme that combines SVR and a stable feature
selection procedure based on LASSO. We describe our method-
ology in detail in Section 3 and show the performance of our
models on human and yeast TF binding data in Section 4.

3 METHODS

3.1 PBM data

Custom PBM data for bel and Tye7, in the form of normalized log signal
intensity values, were obtained from Gordan et a]. (2013). For Myc, Max
and Mad, we performed PBM experiments (Berger and Bulyk, 2009) using
6xHis-tagged proteins expressed and puriﬁed in bacteria (as described in
Lin et al., 2012). As Myc requires heterodimerization with Max to bind
DNA efﬁciently, the Myc PBM experiments were performed using both
Myc and Max 011 the same microarray. As in previous work (Munteanu
and Gordan, 2013), we used a 10 times higher concentration of Myc
compared with Max to ensure that mostly Myc:Max heterodimers, instead
of Max:Max homodimers, are formed. Similarly, Mad PBM experiments
were performed using both Mad and Max 011 the same microarray, with a
10 times higher concentration of Mad.

The Myc/Max/Mad custom array contains, in addition to positive and
negative control sequences, 36-bp long human genomic regions centered
at CACGTG sites. After scanning the microarray and normalizing the
raw PBM data (as described in Berger and Bulyk, 2009), we compute, for
each genomic sequence, the median log signal intensity over the six
replicate spots that contain that particular sequence. These median log
intensity values are used by the regression algorithms. In addition, to test
the reproducibility of our PBM data, we performed replicate PBM
experiments for TF Myc. We obtained a Pearson correlation coefficient
(R) of 0.98 between replicate experiments.

Before training regression models using the custom PBM data, we
ﬁltered out any sequence that contained potential TF binding sites in
the regions ﬂanking the CACGTG core, to ensure that each sequence
contains one and only one TF binding site. We required that the ﬂanks
do not contain any 8-mer with a PBM enrichment score (E-score) greater
than 0.3. PBM E-scores range from —0.5 to +0.5, with higher values
corresponding to higher sequence preferences; typically, E-scores > 0.35
correspond to speciﬁc TFiDNA binding (Berger et al., 2006; Gordan
et al., 2011). After the ﬁltering step, we obtained 280 sequences for
bel, 312 for Tye7, 4917 for Myc, 4430 for Max and 4292 for Mad.

As expected, the number of sequences for each TF is much higher for
the human TFs as compared with yeast TFs.

For each TF, we use N to denote the number of DNA sequences
selected from the custom PBM data. The averaged DNA binding inten-
sities (as measured on the PBMs) are the output y = (yl , . . . , yN) that we
aim to predict using regression models.

3.2 Feature derivation

It is commonly accepted that much of the binding speciﬁcity of a protein-
DNA complex is encoded in the base content of the DNA sequence.
Therefore, our regression methods use sequence-based features.
Numeric features are derived from sequences as follows. bHLH TFs
typically bind DNA as dimers, i.e. two copies of the same protein or
related proteins interact to bind two symmetric half-sites. Thus, as
there is no way to deﬁne a ‘left’ versus a ‘right’ ﬂank, we describe the
base content of the two ﬂanks simultaneously. To do so, we deﬁne
the ﬂanks as a single sequence using the palindromic symmetry of the
E-box as shown in Figure 3. For each position ﬂanking CACGTG, from
1 to 12 for bel/Tye7 or 1 to 15 for Myc/Max/Mad, we count the
occurrences of each k-mer, where k 6 {1,2, 3,4}. We obtain n vectors
describing the sequences {(x’i, . . . , xi)}iE(1,___,N) where:

_ 0.5 if the k-mer is present at that position in one ﬂank
xj’. = 1 if the k-mer is present at that position in both ﬂanks
0 otherwise

The index j refers to one k-mer at a particular position. [7 is therefore the
product between the length of the ﬂanking sequence and the number of
k-mers used (see Table 1 for values of p). More precisely, a feature value
of 1 means the corresponding k-mer is present in one ﬂank at the cor-
responding position, and its complementary k-mer is present in the other
ﬂank at the same position. We eliminate those k-mer features that are
completely absent from all sequences.

We note that bel, Tye7 and Max bind DNA efﬁciently as homodi-
mers, i.e. using two copies of the same protein, whereas Myc and Mad

 
   
 
 
  
 

7“ position 7-ATC = 1

TAG

 

7th position 7-ATC = 0.5
TCG

Fig. 3. DNA regions ﬂanking the CACGTG E-box are used to derive
sequence-based features that take into account the dimer mode of DNA
binding by bHLH proteins

Table 1. Total number of features for different feature sets

 

 

Values ofk 1 2 3 4 172 173 141
bel 48 176 623 1596 224 847 2440

Tye7 48 176 624 1672 224 848 2520
Myc/Max/Mad 6o 7 7 284 1116 7

 

 

i119

112 /310's112u1nofp101x0'sopBHJJOJurorq/ﬁduq 111011 pap1201umoq

9103 ‘0g isanV uo ::

F.Mordelet et al.

 

need to heterodimerize with Max. Thus, in the case of Myc and Mad,
only one of the half-sites is bound by the TF of interest, whereas the other
is bound by the TF partner (Max). Ideally, one would treat the two
half-sites differently and learn one model for each half-site; however,
we do not know a priori, for each binding region, which half-site is
bound by which TF. For this reason, for Myc and Mad, we use the
same approach as for homodimers, recognizing that the speciﬁcity
signal will be diluted because of the heterodimerization with Max.

3.3 Feature selection with ‘Stable LASSO’

LASSO regression enables feature selection through the use of an L1
penalty. In particular, the output y is modeled as a linear function of
the input features X by estimating the coefﬁcient vector w 6 [RP that
minimizes the squared residual error plus the (scaled) absolute value of
the coefﬁcient weights, inducing many of the weights to go to zero, and
effectively eliminating the use of that feature in prediction. We can write
LASSO regression as the following optimization problem:

. A N ,-2
H3115 llw “1+;(yi—wa)

Parameter A reﬂects the trade-off between fit and sparsity, or the propor-
tion of features removed. The penalty term means that a solution w be-
comes sparser as A increases. Thus, a smaller set of features are used to
model y.

The least angle regression (LARS) algorithm (Efron et al., 2004) allows
us to compute the solution path for all values of A. This iterative algo-
rithm adds features to the linear model one by one and exploits the fact
that the w coefﬁcients vary continuously as A increases. A good value for
A is often chosen by cross-validation; instead, we keep the whole solution
path, in a stability selection procedure described later in the text.

LASSO regression is sensitive to perturbations of the training set and
often does not result in a robust set of selected features. This is especially
true when the features are correlated, as is the case here because of re-
dundancy between k-mers of different lengths. As the coefﬁcient values
estimated for each feature are unstable, they cannot be used directly as
importance scores for features. To overcome those limitations, Bach
(2008); Haury et a]. (2012) and Meinshausen and Bﬁhlrnann (2010)
have proposed the use of a stability selection procedure. This consists
in randomly perturbing the dataset many times, running LASSO on those
perturbed datasets and combining the successive regressions to obtain
importance scores for each feature, based on the frequency with which
they are selected in the successive LASSO runs. Such a score is akin to a
probability that the feature should participate in the model.

 

Algorithm 1 Stable LASSO

INPUT: X 6 ROM), y 6 ER", or=perturbation level, T: number of
iterations
OUTPUT: An area score for all features
for [:1 to T do
Randomly perturb the data:
Draw a subsample (y,, X ,) of size n/2 from (y, X)
Draw a vector w ~ LI([or, 1]1’)
Re-weight the features: X , <— X ,w
Compute the LASSO path of length n/2 using LARS
Keep the selection matrix F, 6 {0,1}”"’/2 where

 

1 if i-th feature selected at j-th LARS step
0 otherwise

FtUaj) = {
end for

Compute the area score for feature 1' as

n/2 T

2 . .
ﬁ = Wiggljm»

 

As described in Algorithm 1, at each iteration t: 1 . . . T, we perturb
the original training set (y, X): we randomly subsample one half of the
training set (y,, X ,) and reweight all features in X , using randomly gener-
ated weights w drawn uniformly on [05, 1]. Parameter or controls the level
of perturbation: a smaller or implies more variable weights, whereas at = 1
means no reweighting.

In practice, instead of a loop of length Tas shown in Algorithm 1, we
run a single loop of length T/2 and compute the LARS path on the two
random halves of the dataset at each iteration. This still allows us to
compute the ‘area score’ (i.e. the feature importance score) as the average
of T selection frequency matrices, as shown in Figure 4. The area score
can be interpreted as the area under the average selection frequency curve
over Titerations (see Fig. 5).

In the classic version of LASSO regression, one needs to select a value
for parameter A. Instead, the area score uses the whole regularization
path and therefore has the great advantage of avoiding any arbitrary
cutoff on the number of features and any additional computation time
owing to parameter selection.

We observed that the area scores were distributed according to a multi-
modal distribution, each model corresponding to a given k-mer length.
This suggests we cannot apply a single uniform threshold on the import-
ance score across all features with different values of k. Instead, we derive
one threshold value for each group of features of the same length. To do
so, we computed a background score distribution for each k-mer length
by randomly permuting the intensity values and running Stable LASSO
on the permuted values. We then select features with an area score higher
than the mean plus two standard deviations of their corresponding back-
ground distribution. Finally, we use this feature subset as input to an

      
    
 
   
   

GOOD-11111111111
000111111111111
111111111111111

000000000000111 ' _ 
000000000111111  1 'n/Z
011111111111111 001111111111111
' ' 000000011111111
- . 001111111111111

Feature

    
 
 
  
  
 

' .I LARS step

000000001111111
000000000111111
' “x? 000000000001111_

Fig. 4. Output of Algorithm 1: T binary matrices describing which
features are selected along the LARS path

Average frequency
of selection

Area=score f, t

1 LARS step n/2

Fig. 5. Computation of the ‘area score’ for each variable. An average
selection frequency curve over the T iterations is computed for each
feature (ﬁve features are shown in this ﬁgure). The area under each
curve represents the area score for the corresponding feature

 

i120

112 /310's112u1nofp101x0'sopBHJJOJurorq/ﬁduq 111011 pap1201umoq

9103 ‘0g isanV uo ::

Stability selection for regression models of TF-DNA binding

 

SVR to learn binding speciﬁcity models. In Section 4, we show that this
Stable LASSO selection procedure performs better than simply choosing
a small number of features (random selection) or choosing features based
on their SVR weights (SVR selection) (see Fig. 7).

3.4 Regression with SVR

SVR (Smola and Schélkopf, 2004) uses the concept of maximum margin
(Vapnik, 1998) for regression. SVR is formulated as an optimization
problem as follows:

N
min; ||f|l2+C;(S.-+S§‘)

yi —f(Xi) S 5 + 51'
Subject to ﬁx) — y,- S 8 + ‘5?
Si, 5? 5 0

The only difference between the SVR and the SVM lies in the loss
function, which is devised for a continuous output in the case of the
SVR. This loss function, called the a-insensitive function, enforces the
support vectors, or informative examples, to lie within a tube of width
8 around function f. Parameter C orchestrates the trade-off between the
loss term, which enforces a good ﬁt to the training data, and the margin
term, which regularizes the f function and often produces better general-
ization error. Parameter 8 plays a similar role to C, with small values of
a leading to a better ﬁt on the training set, and larger values preventing
overﬁtting.

An essential ingredient to any SV method is the kernel function K,
which can be thought of as a similarity function between any two example
points. Function f can be written as f(x) = 106,-K(Xi, x) The simplest
kernel is the linear kernel, which is the dot product between the feature
vectors for two samples:

Klm(xi, x1) 2 (xi, xj),

implying f is linear in the input features x. Other kernels, however, yield a
non-linear function f, via the ‘kernel trick’. This consists in deﬁning an
implicit mapping of the original features into a higher dimension space
and looking for a linear function f in that transformed space. A common
non-linear kernel is the radial basis function (RBF) kernel, deﬁned by

i _ j 2
Krbf(x’, x1) = exp (— %).
The linear SVR allows us to associate coefﬁcients to the features
by rewriting f(x) so that coefﬁcient for variable j is Wj = laix;
However, the relationship between the features and the output is often
better modeled by a non-linear (but not interpretable) kernel such as
the RBF kernel.
Each model was evaluated by computing by computing the squared
Pearson correlation coefﬁcient (R2) between predicted DNA binding spe-
ciﬁcity/intensity and the actual PBM log signal intensity values.

4 RESULTS

4.1 Regression models trained on custom PBM
data give accurate predictions of DNA binding
speciﬁcity
We first evaluate the performance of full SVR regression models
(i.e. without any feature selection) learned from yeast and human
custom PBM data. To describe the DNA sequences, we used
k-mers of different lengths and generated several features sets
that included, successively, {1, 2, 3, 4, 172, 173, 174}-mers.
Table 1 shows the resulting number of features ([2) for different

0.8
2.
R 0.4
0.2 I I
0
('9 «9 s k {'1
° <° 6* 6‘ «006‘

O
G)

(béeo‘e (ode o‘e o‘a é(0‘5 o @0‘96‘21‘9 6‘0 6‘09 e é‘o‘a
N"); '5' v3: 31,»: N'q: r2; w;1:;5',ix
N N N N N N

 

 

1 lMyci iMaxl iMadl
0.8
R2 0.6 I I I I I I I I l LinearSVR
0-4 I RBF SVR
0.2
0
(005% @059 (our? 6,65% @657 £059 66" ’85, 6‘"

N, N’q; N'rb' NI \ﬂ: N’()3 V N’q" N’rb

Fig. 6. Performance (R2) of linear and RBF SVR regression methods
(without feature selection) for learning binding specificity from sequence
content. We used several feature sets to investigate the use of including

longer k-mers in the models

feature sets. Next, for each feature set, we ran a linear and an
RBF SVR. We used 10-fold cross-validation for parameter selec-
tion over a large grid of possible parameter values. Each model
was evaluated by computing the Pearson squared correlation
coefﬁcient (R2) between the predicted and the actual signal in-
tensity of held out test data. For each method, a 10-fold cross
validation was carried out to assess the performance in predicting
binding speciﬁcity for test DNA sequences.

Figure 6 shows that the linear and RBF SVR model predic-
tions are well correlated with the actual intensity. Among the
regression models tested here, linear SVR models based on
1-mer features are technically equivalent to PWM models,
including the assumption of independence and additivity.
These models ﬁt the data well and result in R2 values of 0.6 or
higher in the 10-fold cross-validation test. This is in agreement
with previous studies suggesting that even when the additivity
assumption does not fit the data perfectly, in many cases, it gives
a good approximation of the data (Benos et al., 2002; Zhao and
Stormo, 2011). However, taking into account non-independent
contributions, by either using the RBF kernel or by incorporat-
ing 2-mer and 3-mer features, slightly improves the accuracy of
our regression models trained on custom PBM data.

Using 1-mers and 2-mers is enough to reach a good perform-
ance on be 1 and including 3-mers improves performance only
slightly on Tye7. Taking into account 4-mer features in addition
to 1-mers, 2-mers and 3-mers did not improve our models any
further for TFs be 1 and Tye7 (Fig. 6). Based on this observa-
tion, we limited all experiments on the larger human datasets to
feature sets containing 1-mers, 172-mers or 173-mers. Overall,
from Figure 6, we see that the best regression-based specificity
models were obtained using the RBF kernel and either 172-mer
or 173-mer features.

4.2 Feature selection using Stable LASSO maintains 01'
improves the accuracy of DNA binding models

Although the regression models trained on 172-mer and 173-mer
features are highly accurate, they are hard to interpret because of

 

i121

112 /310's112u1nofp101x0'sopBHJJOJurorq/ﬁduq 111011 pap1201umoq

9103 ‘0g isanV uo ::

F.Mordelet et al.

 

the large number of features (Table 1). To address this problem,
we used the Stable LASSO feature selection procedure described
in Section 3.3 and re-ran the linear and RBF SVRs using only the
subset of selected features. The performance on the regression
models remained almost the same or even improved slightly after
the feature selection step (Fig. 7).

We also compared the performance of Stable LASSO against
a feature selection procedure based on the feature weights
learned by the linear SVR model. More precisely, for each data-
set, we ran a linear SVR using the full set of features, computed
the feature coefﬁcients, ranked the features in decreasing order
of their absolute value and then selected the same number of
features as were previously selected by Stable LASSO. We also
implemented a ‘random selection’ procedure that selects ran-
domly, the same number of features as Stable LASSO.

We tested these two alternative procedures on the smaller of
our two datasets (i.e. the yeast data). Figure 7 shows that both
SVR selection and random selection perform worse than Stable
LASSO, demonstrating the power of the bootstrap and random-
ization scheme to select relevant features for this problem, which
maintain or even improve the accuracy of the model.

In addition, we note that running feature selection before
training the regression model greatly reduces the computation
time, which is important, especially for the human TF data.
As an example, for be 1 data, an RBF SVR without feature
selection and with parameters optimized on a grid of size 1620
ran in an hour on a laptop with a 2.3 GHz Intel Core i5 and
4 GB RAM, when the method with Stable LASSO feature se-
lection took only 7 min, and the parameters were optimized on
the same grid. We believe this huge difference comes mostly from
kernel computation, as it increases linearly with the size of the
feature set. Moreover, we hypothesize that reducing the feature
set might also make the problem easier to solve and therefore
help the SVR algorithm to converge faster.

1

0.8
2 No feature selection
R 0-6 ‘ lStable LASSO selection
04 1 l SVR selection
02 Random selection
0

Linear RBF Linear RBF
SVR SVR SVR SVR
1-2-mers 1-2-mers 1-2-mers 1-2-mers

1
0.8
R2 0.6 - 1
0.4 - 1
0.2 - 1
0

Linear RBF Linear RBF Linear RBF
sva sva sva sva sva sva
1-3—mers 1-3-mers 1-3—mers 1-3—mers 1-3—mers 1-3—mers

Fig. 7. Predicting binding intensity for bel, Tye7, Myc, Max and Mad
using a regression-based model trained on selected features. The squared
correlation coefﬁcient between predicted intensity and actual intensity (y-
axis) is computed for different feature selection strategies followed by a
linear and an RBF SVR. Feature selection on 172-mers performed best
for bel and Tye7. Feature selection on 173-mers performed best for
Myc, Max and Mad TFs. A Wilcoxon paired signed rank test shows a
signiﬁcant difference between 172-mers and 173-mers, with P-values
{0.002, 0.002, 0.0059}, respectively

4.3 Interpretability

Table 2 reports the numbers of features that were selected for
each feature set and TF. These numbers are small such that our
models become interpretable, a desirable property for under-
standing how binding is enacted. This algorithm also provides
a short list of features and their importance scores that reﬂect
how often each feature was selected. To determine whether a
particular sequence feature has a positive or negative inﬂuence
on TF binding, we can look at the sign of the feature weight
calculated from the linear SVR model (Section 3.4). As an ex-
ample, Figure 8 shows the selected features for be 1 and Tye7,
ordered by position on the ﬂank from the core to the extremity
(see Fig. 3), and then by k-mer size (i.e. first 1-mers and then 2-
mers). The second-to-last column gives the importance score as-
signed to each feature by our algorithm, and the last column is

Table 2. Size of feature set selected by the Stable LASSO algorithm

 

 

 

 

Feature set be1 Tye7 Mad Max Myc
172-mers 20 20 35 25 22
173 -mers 56 46 130 98 95
1 2 3 4 5 6 7 8 9 10 11 12 areascore SVRcoeff
A - - - - - - - - - - - 0.9573 0.5950
c — 0.3733 0.4743
A 0 0.7934 1.1023
A T 0.5374 0.3252
A A 0.5301 70.3330
c A 0.5057 0.2092
— T — — — — — — — — — — 0.3935 0.6150
T G - - - - - - - - - 0.4331 0.0311
- c A - - - - - - - - 0.6016 0.5573
- - T A - - 0.4206 0.2199
c c - - 0.3121 0.0005
A A . 0.4422 0.3123
- c c 04423 0.1114
T T 0.3412 0.3242
G A - - - - 0.3334 0.0362
- c c - - - 0.3001 0.0373

0.3790 0.3432
0.4040 0.2711
T 0.4574 0.2252
A 0.3723 0.0391

area score SVR coeff
0.9735 2.2677

 

N
w
.5
01
a:
‘1
' m
to
3
R;

0.7524 1.2248
0.6917 -2.2058
0.6598 1.2116

0.6266 1.8290
0.4424 0.1261
0.4221 412489
0.9327 0.9442
0.8997 0.9587
0.5252 0.4979
0.8603 0.6516
0.5715 0.3483
0.3865 0.1675
0.4474 0.3003
. . . - - - - 0.4117 0.6380
1' T . . - - - 0.3755 0.1579
_ . 0.8552 0.2393

'0-lo>>>>-‘
'—lO-l>>—l-l>0'
.0400..1....1.

100))1111111111.
.>_11111111....1.

'-l—l

_ . - 0.4547 0.4428
T . . 0.4375 0.4106

A A 04559 0.2720
Fig. 8. Selected features for be1 (top) and Tye7 (bottom) ordered by
position on the ﬂank and length. Positions are speciﬁed relative to the
core of the binding site (position 1 is the closest to the core). The second-
to-last column is the area importance score of the feature, and the last
column reports the weight coefﬁcient attributed to the feature by a linear
SVR. In red, we show the features with the six top coefﬁcients; the blue
features are those that contribute negatively to binding

1.10.

 

i122

112 /810's112u1n01p101x0'so1112111101u101q//:d1111 111011 pap1201umoq

9103 ‘0g15n8nv 110 ::

Stability selection for regression models of TF-DNA binding

 

the coefﬁcient assigned to it when a linear SVR is trained on the
selected set to predict binding intensity. We observe that the
order on positions correlates well with the importance score
order, suggesting that, as expected, positions right next to the
E-box are more important than positions further away. Our se-
lection procedure does identify features in the distal ﬂanks that
appear to be important for model accuracy (e. g. feature AA at
position 11 in the Tye7 model, Fig. 8). Interestingly, the selected
distal features are mostly 2-mers that exhibit speciﬁc DNA shape
characteristics. For example, AA/AT dimers are typically bent
toward the minor groove, and AA/TT shows the largest roll
among all dimers (Zhurkin et al., 1991). Both minor groove
width and roll are important for DNA binding by TFs
(Gordan et al., 2013; Rohs et al., 2010).

4.4 Model speciﬁcity

When trying to predict TFiDNA interactions using models of
DNA binding speciﬁcity, a difﬁcult problem arises in the case of
paralogous TFs (i.e. TFs that belong to the same protein family).
Such TFs often have highly similar DNA binding speciﬁcities
(Badis et al., 2009; Jolma et al., 2013), despite the fact that
they are observed to interact with different sets of genomic
sites in vivo (ENCODE Project Consortium, 2012). For some
paralogous TFs, simple models such as PWMs are sufﬁcient to
capture differences in sequence preferences (Fong et al., 2012;
Zhou and O’Shea, 2011). In many cases, however, the PWMs
of paralogous TFs are Virtually identical. Two such examples are
studied in this article: Saccharomyces cerevisiae TFs bel and
Tye7, and Homo sapiens TFs Myc, Max and Mad.

be 1 and Tye7 bind distinct sets of targets sites in yeast cells
and have different regulatory functions (Harbison et al., 2004;
Kent et al., 2004; Nishi et al., 1995). However, their PWMs are
similar (MacIsaac et al., 2006; Zhu et al., 2009) (Fig. 1A) and
cannot be used to distinguish the genomic regions bound in vivo
by the two TFs with any speciﬁcity (Gordan et al., 2013). Myc,
Max and Mad are members of a network of TFs that controls cell
proliferation, differentiation and death. Despite playing different
roles in the cell and having different sets of targets sites in vivo
(ENCODE Project Consortium, 2012), Myc, Max and Mad have
almost identical PWMs (Fig. 1B). Myc, Max and Mad PWMs
cannot be used to differentiate between the genomic regions
bound in vivo by these factors (Munteanu and Gordan, 2013).

To illustrate that our regression-based approach can generate
TFiDNA binding models speciﬁc enough to distinguish between
paralogous TFs, we performed a comparison among three dif-
ferent types of models: (i) available PWMs of size 10 for the TFs
of interest (Munteanu and Gordan, 2013; Zhu et al., 2009); (ii)
linear SVR models trained on custom PBM data using 1-mer
features from the core 10 positions (these models are technically
equivalent to PWMs of size 10, but learned from our quantitative
PBM data); and (iii) RBF SVR models trained on custom PBM
data following feature selection. We trained each model on data
for one TF and used it to predict the binding speciﬁcity of related
TFs. All the PWMs used in this analysis have been derived from
universal PBM data and are in good agreement with previously
reported motifs for the same TFs (Munteanu and Gordan, 2013;
Zhu et al., 2009). We chose PWMs of size 10 because they ob-
tained the best correlation coefﬁcients between the PWM log

ratio scores (for the putative binding site in each PBM probe)
and the PBM log signal intensity.

Figures 9 and 10 present the results of our speciﬁcity analysis,
reporting the squared correlation coefﬁcients between predicted
and true binding intensities. In general, we notice that a model
learned on TF A is less accurate at predict intensity for TF B
than the model actually trained on data for TF B. For instance,
our best SVR models after stability selection for yeast TFs were
obtained on 172-mer features. In a 10-fold cross-validation test,
the model trained on be 1 data proved highly accurate at pre-
dicting be 1 binding speciﬁcity (R2 = 0.737) and not so accurate

be1 predicted from be1

co

be1 predicted from Tye7
o

    

> >
1512 °°° 33 1512
i’: 9 : o
:‘1’: .o ‘ :‘1’:
a ,° ° 3
0 35
g)“ .1: o a g)“
a o 5' .m a
‘15: ° «We ‘15:
“,10 $3.33" 2 “,10’35”
3 ° °o R=0.737 a
1— 1—

 

12

1 0 1 1 12
Predicted binding specificity

10 1 1
Predicted binding specificity

Tye7 predicted from be1 Tye7 predicted from Tye7

<9

 

True binding specificity
True binding specificity

   

6 8 10
Predicted binding specificity

Fig. 9. Scatter plots of predicted versus true DNA binding speciﬁcity for
regression-based models learned on the yeast data, using prior stability
selection on 172-mer features. The ‘predicted binding speciﬁcity’ values
represent predicted PBM log intensities. The ‘true binding speciﬁcity
values’ represent actual PBM log intensities. Top panels: predicting
DNA binding speciﬁcity for be1 from a model learned 011 be1 data
(left) and Tye7 data (right). Bottom panels: predicting DNA binding
speciﬁcity for Tye7 from a model learned 011 be1 data (left) and Tye7
data (right). All tests were done using 10-fold cross-validation

3 Linear SVR model c PWM model of size 10
(sues of Size 10) (as in Figure 1)

Predictions from model Predictions from model Predicﬁons from PWM
trained on data for TF: trained on data for TF: mode| for TF:
c511 Tye7 c511 Tye7 c511 Tye7

M

A RBF SVR model

0.415

9
i."
4:.

Binding signal
for TF
Tye7 be1
Tye7 be1

 

 

 

 

 

   

E Myc Max Mad
*5 g g g 0 353 0 374
E E E E . .

E

 g g 0.239 0.192
13 E E E 0.325 0.409
E E E E

 

 

 

 

 

 

I For each row: - Highest R2 D Median R2 n Lowest R2 I

 

Fig. 10. The speciﬁcity of RBF regression models with feature selection
(using 172-mers for bel/Tye7 and 173-mers for Myc/Max/Mad) (A),
linear SVR l-mers models trained on sites of size 10 (B) and PWM
models of size 10 (C) was tested by comparing performance when pre-
dicting the binding intensity of test sequences from a model trained on the
same TF versus a different TF. Numbers represent R2 values

 

i123

112 /810's112u1n01p101x0'so1112111101u101q//:d1111 111011 pap1201umoq

9103 ‘0g JSanV 110 ::

F.Mordelet et al.

 

at predicting Tye7 speciﬁcity (R2=O.461); similarly for Tye7
(Figs 9 and 10A).

The two PWM models in our comparison (Fig. 10B and C)
exhibit smaller and more similar correlation coefﬁcients, and
are therefore less accurate and less specific. For instance, we
see that predicting binding signal for be 1 from the be 1
versus the Tye7 PWMs gives similar results (Fig. 10C)
(R2=O.147 and 0.130, respectively). Learning PWM-like
models from the custom PBM data improves both the accuracy
and the specificity of the models (Fig. 10B), but the best models
are the ones that include non-independent contributions and are
trained on custom PBM data (Fig. 10A). These results suggest
that highly quantitative data (such as the custom PBM data in
our study) allow us to gain both in specificity and accuracy.
In addition, departing from the standard PWM model (by
adding dependencies between adjacent positions and non-linear
contributions to binding) helps improve the models even further
on both levels.

5 DISCUSSION

We have presented a new approach for learning regression-based
models of proteiniDNA binding speciﬁcity from quantitative TF
binding data, using SVR with feature selection. When tested on
yeast and human TF binding data, our models are able to predict
the speciﬁcity of each TF of interest. In addition, we show that
the regression models trained on custom PBM data are able to
distinguish binding behaviors of paralogous TFs, even when
their PWM models are similar. Several factors contribute to
the accuracy and speciﬁcity of our TFiDNA binding models.
First, we train our regression models on quantitative high-
resolution data obtained using a high-throughput in vitro tech-
nology (PBM). This allows us to train complex models of speci-
ﬁcity without the risk of overﬁtting the training data. High-
throughput, in vitro data, including data generated using the
PBM technology, has been previously used to train complex
models of TFiDNA binding specificity (Agius et al., 2010;
Annala et al., 2011; Weirauch et al., 2013). Our approach is
somewhat similar to the work of Agius et al. (2010) and
Annala et al. (2011), who also learn regression models from
PBM data. However, both these studies use PBM data generated
using universal array designs, which contain artiﬁcial DNA se-
quences designed to collectively cover all possible 10-mers
(Berger et al., 2006). When using such an array design, each
probe on the array may contain 0, 1 or more binding sites for
the TF of interest, and these binding sites may be located at any
position along the probe (i.e. any position relative to the free
DNA end). Given the well-characterized positional bias in the
universal PBM data (Berger et al., 2006), models trained on these
data either try to learn the bias (Zhao and Stormo, 2011) or
implicitly assume that the bias will average out when multiple
probes are considered (Annala et al., 2011; Weirauch et al.,
2013). In contrast, our custom microarray is designed so that
each probe contains a single putative binding site located at
the same location related to the free DNA end. This allows us
to learn regression models that take into account k—mer occur-
rences at speciﬁc positions relative to the core of the binding site,
as opposed to k—mers occurrences along the probes as done pre-
viously in Annala et al. (2011). The use of positional information

makes our models easier to interpret than simple k—mer based
models.

Second, by using a feature selection procedure, we restrict our
regression models to a small number of parameters while main-
taining a high prediction accuracy. This makes our models easier
to Visualize and interpret than other complex models of DNA
binding speciﬁcity. For example, Agius et al. (2010) have also
developed SVR-based models trained on PBM data. Their
models fit the universal PBM data very well; however, the
models are based on a special string kernel that makes is difﬁcult
to identify speciﬁc features that are important for model accur-
acy. In contrast, our feature selection procedure identiﬁes rele-
vant sequence features and also reports how frequently each
feature is selected and how it contributes to the binding afﬁnity
(see Fig. 8).

Third, unlike the widely used PWM models, our regression
models take into account non-independent contribution from
individual bases in a TF binding site, by using the RBF kernel
in the SVR algorithm and by incorporating 2-mer and 3-mer
features. Importantly, our algorithm selects sequence features
not only in the regions next to the CACGTG core but also in
distal ﬂanking regions, where the TF might not make speciﬁc
DNA contacts. This suggests that the ﬂanking regions may have
an indirect inﬂuence on the binding afﬁnity, possibly exerted
through DNA shape, a hypothesis that we have tested previously
for yeast TFs be1 and Tye7 (Gordan et al., 2013). We note,
however, that the current study is different from our previous
work in several respects: previously, we neither performed any
feature selection nor tried to interpret the specificity models; in-
stead, we focused on the importance of intrinsic sequence pref-
erences of paralogous TFs be 1 and Tye7 for achieving in vivo
speciﬁcity, and on the potential role of DNA shape in providing
a mechanistic explanation for the inﬂuence of ﬂanking regions
on DNA binding afﬁnity. In the current study, we generate
custom data for human TFs in addition to using the yeast data
from Gordan et al. (2013), and we focus on using feature selec-
tion to get more accurate and interpretable models of binding
speciﬁcity.

Future work will include developing similar models for TFs
from other structural classes and organisms, as well as refining
the feature selection procedure and testing other feature selection
methods (Maldonado and Weber, 2010; Nguyen and de la Torre,
2010; Yang and Ong, 2010) that might help us identify sequence
features relevant for model accuracy.

In conclusion, our regression-based approach for learning
complex models of TFiDNA binding speciﬁcity from custom
PBM data can be easily extended and improved, and we antici-
pate that the proposed regression models will help explain, at
least in part, how paralogous TFs with highly similar PWMs
are able to interact with distinct genomic targets.

ACKNOWLEDGEMENTS

The authors thank Peter Rahl and Richard Young (Whitehead
Institute and MIT) for providing puriﬁed c—Myc, Max and Mad2
proteins.

Conﬂict of Interest: none declared.

 

i124

112 /810's112u1n01p101x0'so1112111101u101q//:d1111 111011 pap1201umoq

9103 ‘0g JSanV 110 ::

Stability selection for regression models of TF-DNA binding

 

REFERENCES

Agius,P. et al. (2010) High resolution models of transcription factor—DNA
afﬁnities improve in vitro and in vivo binding predictions. PLoS Comput.
Biol, 6, e1000916.

Annala,M. et al. (2011) A linear model for transcription factor binding afﬁnity
prediction in protein binding microarrays. PLoS One, 6, e20059.

Bach,F.R. (2008) Bolasso: Model consistent LASSO estimation through the boot—
strap. In: Cohen,W.W., McCallum,A. and Roweis,S.T. (eds.) Proceedings of the
25th International Conference on Machine Learning, New York, NY, USA.

Badis,G. et al. (2009) Diversity and complexity in DNA recognition by transcription
factors. Science, 324, 172(kl723.

Barash,Y. et al. (2003) Modeling dependencies in protein—DNA binding sites. In:
Proceedings of RECOMB 2003. New York, NY, USA, pp. 28737.

Benos,P. et al. (2002) Additivity in protein—DNA interactions: how good an
approximation is it? Nucleic Acids Res., 30, 44424451.

Berger,M. et al. (2006) Compact, universal DNA microarrays to comprehensively
determine transcription—factor binding site speciﬁcities. Nat. Biotechnol, 24,
142971435.

Berger,M.F. and Bulyk,M.L. (2009) Universal protein—binding microarrays for
the comprehensive characterization of the DNA binding speciﬁcities of tran—
scription factors. Nat. Protoc., 4, 393411.

Bulyk,M.L. et al. (2002) Nucleotides of transcription factor binding sites exert inter—
dependent effects on the binding afﬁnities of transcription factors. Nucleic Acids
Res., 30, 125$1261.

Efron,B. et al. (2004) Least angle regression. Ann. Stat., 32, 407499.

ENCODE Project Consortium. (2012) An integrated encyclopedia of DNA
elements in the human genome. Nature, 489, 57774.

Fong,A.P. et al. (2012) Genetic and epigenetic determinants of neurogenesis and
myogenesis. Dev. Cell, 22, 7217735.

Gordﬁn,R. et al. (2009) Distinguishing direct versus indirect transcription factor—
DNA interactions. Genome Res., 19, 20932100.

Gordﬁn,R. et al. (2011) Curated collection of yeast transcription factor DNA bind—
ing speciﬁcity data reveals novel structural and gene regulatory insights. Genome
Biol, 12, R125.

Gordﬁn,R. et al. (2013) Genomic regions ﬂanking E—box binding sites inﬂuence
DNA binding speciﬁcity of bHLH transcription factors through DNA shape.
Cell Rep., 3, 109371104.

Harbison,C. et al. (2004) Transcriptional regulatory code of a eukaryotic genome.
Nature, 431, 997104.

Haury,A.C. et al. (2012) TIGRESS: Trustful inference of gene regulation using
stability selection. BMC Syst. Biol, 6, 145.

Jauch,R. et al. (2012) The crystal structure of the Sox4 HMG domain—DNA com—
plex suggests a mechanism for positional interdependence in DNA recognition.
Biochem. J., 443, 3947.

Jolma,A. et al. (2010) Multiplexed massively parallel SELEX for characterization
of human transcription factor binding speciﬁcities. Genome Res., 20, 8617873.

Jolma,A. et al. (2013) DNA binding speciﬁcities of human transcription factors.
Cell, 152, 3277339.

Kaplan,T. et al. (2011) Quantitative models of the mechanisms that control genome—
wide patterns of transcription factor binding during early Drosophila develop—
ment. PLoS Genet., 7, e1001290.

Kent,N.A. et al. (2004) belp is required for chromatin remodeling at promoter—
proximal CACGTG motifs in yeast. J. Biol. Chem., 279, 2711927123.

Lin,C.Y. et al. (2012) Transcriptional ampliﬁcation in tumor cells with elevated c—
Mye. Cell, 151, 56—67.

MacIsaac,K.D. et al. (2006) An improved map of conserved regulatory sites for
Saccharomyces cerevisiae. BM C Bioinformatics, 7, 113.

Maerkl,S.J. and Quake,S.R. (2007) A systems approach to measuring the binding
energy landscapes of transcription factors. Science, 315, 2337237.

Maldonado,S. and Weber,R. (2010) Feature selection for support vector regression
via kernel penalization. In: IJCNN 2010. Barcelona, Spain, pp. 177.

Man,T.K. and Stormo,G.D. (2001) Non—independence of Mnt repressor—operator
interaction determined by a new quantitative multiple ﬂuorescence relative
afﬁnity (QuMFRA) assay. Nucleic Acids Res., 29, 247172478.

Meinshausen,N. and Bi'1hlmann,P. (2010) Stability selection. J. R. Stat. Soc. Ser. B,
72, 417473.

Munteanu,A. and Gordﬁn,R. (2013) Distinguishing between genomic regions
bound by paralogous transcription factors. Recomb2013. Lect. Notes Comp.
Sci., 7821, 145.

Nguyen,M.H. and de la Torre,F. (2010) Optimal feature selection for support vector
machines. Pattern Recogn., 43, 5847591.

Nishi,K. et al. (1995) The GCRl requirement for yeast glycolytic gene expression is
suppressed by dominant mutations in the SGCl gene, which encodes a novel
basic—helix—loop—helix protein. Mol. Cell. Biol, 15, 26492653.

Pique—Regi,R. et al. (2011) Accurate inference of transcription factor binding
from DNA sequence and chromatin accessibility data. Genome Res., 21,
447455.

Rohs,R. et al. (2010) Origins of speciﬁcity in protein—DNA recognition. Annu. Rev.
Biochem., 79, 2337269.

Sharon,E. et al. (2008) A feature—based approach to modeling protein—DNA
interactions. PLoS Comput. Biol, 4, e1000154.

Siddharthan,R. (2010) Dinucleotide weight matrices for predicting transcrip—
tion factor binding sites: generalizing the position weight matrix. PLoS One, 5,
e9722.

Smola,A.J. and Sch01kopf,B. (2004) A tutorial on support vector regression. Stat.
C0mput., 14, 1997222.

Staden,R. (1984) Computer methods to locate signals in nucleic acid sequences.
Nucleic Acids Res., 12 (1 Pt 2), 5057519.

Stormo,G.D. (2000) DNA binding sites: representation and discovery.
Bioinformatics, l6, 1&23.

Tibshirani,R. (1996) Regression shrinkage and selection via the lasso. J. R. Stat.
Soc. Ser. B, 58, 2677288.

Tomovic,A. and Oakeley,E.J. (2007) Position dependencies in transcription factor
binding sites. Bioinformatics, 23, 9337941.

Vapnik,V.N. (1998) Statistical Learning Theory. Wiley, New—York, NY.

Weirauch,M.T. et al. (2013) Evaluation of methods for modeling transcription—
factor sequence speciﬁcity. Nat. Biotechnol, 31, 1267134.

Workman,C.T. et al. (2005) enoLOGOS: a versatile web tool for energy normalized
sequence logos. Nucleic Acids Res., 33, W3897W392.

Yang,J.B. and Ong,C.J. (2010) Feature selection for support vector regression using
probabilistic prediction. In: ACM SIGKDD. ACM, New York, NY, USA,
pp. 3437352.

Zhao,Y. and Stormo,G.D. (2011) Quantitative analysis demonstrates most tran—
scription factors require only simple models of speciﬁcity. Nat. Biotechnol,
29, 480483.

Zhao,Y. et al. (2009) Inferring binding energies from selected binding sites. PLoS
Comput. Biol, 5, e1000590.

Zhao,Y. et al. (2012) Improved models for transcription factor binding site identi—
ﬁcation using nonindependent interactions. Genetics, 191, 7817790.

Zhou,Q. and Liu,J.S. (2004) Modeling within—motif dependence for transcription
factor binding site predictions. Bioinformatics, 20, 9097916.

Zhou,X. and O’Shea,E.K. (2011) Integrated approaches reveal determinants of
genome—wide binding and function of the transcription factor Pho4. Mol.
Cell, 42, 8264836.

Zhu,C. et al. (2009) High—resolution DNA binding speciﬁcity analysis of yeast tran—
scription factors. Genome Res., 19, 559566.

Zhurkin,V.B. et al. (1991) Static and statistical bending of DNA evaluated by
Monte Carlo simulations. Proc. Natl Acad. Sci. USA, 88, 70437050.

 

i125

112 /810's112u1n01p101x0'so1112111101u101q//:d1111 111011 pap1201umoq

9103 ‘0g1sn8nv uo ::

