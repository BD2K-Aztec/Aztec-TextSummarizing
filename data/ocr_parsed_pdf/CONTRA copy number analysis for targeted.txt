ORIGINAL PAPER

Vol. 28 no. 10 2012, pages 1307-1313
doi:10. 1093/bioinformatics/bts146

 

Genome analysis

Advance Access publication April 2, 2012

CONTRA: copy number analysis for targeted resequencing

Jason Lil’*, Richard Lupatlaz, Kaushalya C. Amarasinghe3, Ella R. Thompsonz,
Maria A. Doylel, Georgina L. Ryland2, Richard W. Tothill4, Saman K. Halgamuge3,

Ian G. Campbell12’5’6 and Kylie L. Gorringe2’5s6

1Bioinformatics Core Facility, 2Victorian Breast Cancer Research Consortium Cancer Genetics Laboratory, Peter
MacCallum Cancer Centre, VIC 3002, 3Department of Mechanical Engineering, University of Melbourne, Parkville,
VIC 3010, 4Molecular Genomics Core Facility, Peter MacCallum Cancer Centre, VIC 3002, 5Sir Peter MacCallum
Department of Oncology and 6Department of Pathology, University of Melbourne, Parkville, VIC 3010, Australia

Associate Editor: Alex Bateman

 

ABSTRACT

Motivation: In light of the increasing adoption of targeted
resequencing (TR) as a cost-effective strategy to identify disease-
causing variants, a robust method for copy number variation
(CNV) analysis is needed to maximize the value of this promising
technology.

Results: We present a method for CNV detection for TR data,
including whole-exome capture data. Our method calls copy number
gains and losses for each target region based on normalized depth of
coverage. Our key strategies include the use of base-level log-ratios
to remove GC-content bias, correction for an imbalanced library
size effect on log-ratios, and the estimation of log-ratio variations
via binning and interpolation. Our methods are made available
via CONTRA (COpy Number Targeted Resequencing Analysis), a
software package that takes standard alignment formats (BAM/SAM)
and outputs in variant call format (VCF4.0), for easy integration with
other next-generation sequencing analysis packages. We assessed
our methods using samples from seven different target enrichment
assays, and evaluated our results using simulated data and real
germline data with known CNV genotypes.

Availability and implementation: Source code and sample data
are freely available under GNU license (GPLv3) at http://contra-
cnv.sourceforge.net/

Contact: Jason.Li@petermac.org

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on April 5, 2011; revised on February 27, 2012; accepted
on March 23, 2012

1 INTRODUCTION

Targeted resequencing (TR), including whole-exome sequencing,
is becoming widely adopted as a cost-effective way to interrogate
speciﬁc genomic regions across a large number of samples, a
technique particularly useful for the study of genetic causes of
cancer and other diseases. A number of studies have demonstrated
success in the application of TR to the identiﬁcation of disease-
causing variants, including variants associated with arare Mendelian
disorder. Freeman—Sheldon syndrome (Ng et (11., 2009), inherited
mutations for breast and ovarian cancer (Walsh et (11., 2010) and

 

*To whom correspondence should be addressed.

a single non-sense mutation that causes a syndromic form of cleft
palate (Johnston et (11., 2010). The primary objective of TR, as in
above studies, is the detection of single-nucleotide variants (SNVs)
and short (<50 bp) insertions and deletions (indels) within the
targeted regions. Inherent limitations on sequence alignment of
short reads prohibit the detection of larger indels and, therefore,
many potential disease-causing copy number variations (CNVs) are
not accessible from TR data. While whole-genome sequencing and
single-nucleotide polymorphism (SNP) genotyping microarrays are
more appropriate tools for genome-wide CNV interrogations, it is
imperative that robust CNV analysis methods be developed for TR
data, in order to maximize the utility of the rapidly increasing amount
of TR data that are being generated globally.

CNV detection methods have been developed for whole-genome
sequencing and incorporate three main aspects: the estimation of
copy number breakpoint locations by segmentation using depth
of coverage (DOC) (Campbell et (11., 2008; Ivakhno et (11., 2010;
Medvedev et (11., 2009), the incorporation of paired-end or mate
pair information to enhance detection accuracies (A.Abyzov et (11.,
submitted for publication; Medvedev et (11., 2010; Miller et (11 ., 2011)
and the reduction of representation biases due to GC-content and
other physio-chemical characteristics (Aird et (11., 2011; Boeva et (11.,
2011; Chiang et (11., 2009). Segmentation and bias reduction have
been applied to TR data on large target regions (~40 kb) (Walsh
et (11., 2010). However, the size of a target region in most TR projects
is typically small, ranging from 100 to 200 bp as in exon or whole-
exome capture. In addition, genomic distribution of target regions
is often sparse and uneven due to the size of intronic segments
and the arbitrary locations of the genes of interest. The small
size, sparseness and non-contiguous nature of target regions pose
challenges to the application of existing CNV methods on TR data.
Even if the DOC is high in the target regions, data resolution would
be too low to make reasonable segmentation and bias reduction on
a whole-genome scale. It has also been reported that the underlying
assumptions made for CNV estimation in whole-genome sequencing
fail to hold in the exome sequencing setting (Sathirapongsasuti et (11.,
2011). More speciﬁcally, the assumptions that genome-wide read
depth is normally distributed, and that segmentation search space is
continuous, fail to apply for exon capture data.

To date, a limited number of methods have been published for
the CNV analysis of TR data. Exome CNV (Sathirapongsasuti
et (11., 2011) was designed speciﬁcally for whole-exome capture.

 

© The Author(s) 2012. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0), which permits unrestricted non—commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.

112 /3.Io's[Bumo[pJOJXO'sorwuiJOJurorqﬂ:duq 11101} pepeolumoq

91oz ‘Og anﬁnv uo ::

J.Li et al.

 

This method is based on data observed from six human samples
captured using a single-exome capture platform, and involved the
modeling of log-ratios using the Geary—Hinkley transformation for
which a normally distributed exon-level DOC is assumed. The
method, however, did not address a number of factors biasing the
log-ratios, including the discrepancy in total sequence read count
between the case and the control samples and the percentage of on-
target reads. Other limitations include the lack of assessment of other
capture platforms and the lack of a strategy to create a pseudo-control
in the absence of a matched control sample.

We have developed a CNV detection tool called CONTRA
(COpy Number Targeted Resequencing Analysis) for small-region
TR, including data derived from exome capture. Using base-level
log-ratios, copy number gain and loss of each region is inferred,
with signiﬁcance estimated based on the null distribution of log-
ratios (Fig. 1). Our method was tested on human and mouse
samples derived from seven different capture platforms, and it
was evaluated using both simulated TR data and real exome data
derived from well-studied HapMap individuals. CONTRA includes

Erulmmplrun. Tn-u-nmplnun.
Mat: hing control samme 0R MultiDle normal samD‘es

 

Same capture platform

Target enrichment

 

N65 and base calling

 

Alignment es- BWA

 

Remove duplicates v.5. Picard

 

CONTRA input format: an MXSAM

 

Breakdown large Create
Regions Baseline

Base-level log-ratio
LibraryI size bias removal
Estimate log-ratio SD
Signiﬁcance call

 

Exon-level CNV calls

CONTRA

 

Segmentation on log-ratios
Heuristics based prediction l

. Y ‘,

CONTRA output format: utﬂ‘tnbdeﬁmited

Large-region CNV calls

 

 

 

 

 

 

Fig. 1. CONTRA workﬂow. Either a matched control sample (left arrow) or
a pool of normal samples for creating a baseline control (right arrow) must
be present.

a module to efﬁciently create a pseudo-control from multiple
samples. The software package interfaces with standard next-
generation sequencing (NGS) formats for easy integration into
analysis pipelines, taking BAM ﬁles as input and generating variant
call format (VCF) ﬁles as output. CONTRA runs on Unix/Linux
and Mac OS and is publicly available under GNU General Public
License (GPLV3).

2 METHODS

2.1 Exome and custom exon capture data

As summarized in Table l. Illumina GAHx and HiSeq short-read data derived
from various target enrichment platforms were assessed to develop our
method of analysis. These include 56 captures across 7 enrichment platforms
and include both human and mouse.

2.2 Sequence analysis

Sequence reads were aligned to the reference genome assemblies (HG19
and MM9) using BWA (Li and Durbin. 2009). Local realignment around
indels and base quality score recalibration were performed using the Genome
Analysis Tool Kit (GATK) software (McKenna et (11.. 2010). with duplicate
reads removed using Picard (http://picard.sourceforgenet).

2.3 Creating a robust baseline from multiple samples
as the control

Creating a baseline from multiple samples is essential for population and
family studies where a matched control is not available. The baseline should
capture the technical variation of a platform. but not variations due to
CNVs or copy number polymorphisms (CNPs) in the samples. Therefore.
the selection of samples should target subjects from a different background
(e.g. not genetically related). so that speciﬁc CNPs can be diluted out. For
baseline creation. we ﬁrst deﬁne library size as:

L, =NS >< read length >< percentage on target (1)

where L, is the library size of sample s and N, is the total number of short
reads for sample s. Base-level coverage is then computed for each targeted
base:

(1;, = C), XZ/LS (2)

where d), and C), are the adjusted and raw coverage of sample s at targeted
base b respectively. and L the geometric mean of all LS and the control set.

Our deﬁnition of library size takes read length into account so that
samples sequenced with different read lengths can be pooled together in the
control set. We also observed that although the percentage of on-target reads
is mostly stable across samples. it can vary quite signiﬁcantly in some cases

Table 1. A summary of the samples that have been assessed against our characterization of depth-of-coverage and log-ratios in TR data

 

 

Species Manufacturer Target enrichment Platform Technology No. of Sequencing SE/PE Type
platform alias used samples
Human Roche Sequence Capture 2.1 M SeqCap Array Array based 10 GAHx SE and PE Normal
NimbleGen Exome Array blood DNA
EZ Exome Library V2.0 EZ Exome V2 Solution based 10 HiSeq or GAHx PE
EZ Exome Library V1.0 EZ Exome V1 10 GAHx
Agilent SureSelect All Exon 50 Mb SureSelect V1 10
SureSelect All Exon v.2 SureSelect V2 5
SureSelect Custom Custom 10 SE Tumor versus
Exon Capture Capture normal
Mouse SureSelect Mouse All SureSelect 6 PE
Exon Mouse

 

 

1 308

112 /3.Io's[Bumo[pJOJXO'sorwuiJOJurorqﬂ:duq 11101} papeolumoq

9103 ‘Org anﬁnv uo ::

CONTRA

 

due to experimental conditions and reduced capture efﬁciency. Such technical
variation is removed by incorporating percentage on target in Equation (1).

A robust average across the samples in the control set is then calculated
as a trimmed mean of d), at each targeted base (denoted as Eb). The removal
of outliers (10% both ends) aims to take out CNPs that are speciﬁc to a small
number of individuals. If L, is consistent across samples. the variance of?
is inversely proportional to the size of the control set. greatly improving the
stability of downstream log-ratio analysis when the size is large.

2.4 Algorithm for exon/small-region CNV detection

2.4.1 Base-level log-ratios Using either a matched control or a robust
baseline. the ﬁrst step of our method is to compute base-level log-ratios.
This is internally achieved by the following steps: (i) coverage proﬁles of
the samples. or bedgraphs. are created using BEDTools (Quinlan and Hall.
2010); (ii) regions with raw coverage lower than a predeﬁned threshold are
excluded from analysis (our default requires at least 10 bp with c), > 10);
(iii) coverage is scaled by Equation (2). with I being the geometric mean of
library size between the case and the control; and (iV) log-ratios are computed
for each base using the adjusted coverage. Region-level log-ratios (RLRS)
are then computed by taking the mean of base-level log-ratios in the region.
The use of geometric mean for scaling has been discussed in the context
of RNA-seq analysis (Robinson et al.. 2010). The reason for using base-
level log-ratios. as opposed to RLRs. is to maximally remove GC-content
effect on coverage. a bias that has been observed in many second-generation
sequencing data. in particular Illumina (Aird et al.. 2011).

2.4.2 Library-size bias correction Log-ratios are linearly dependent on
log-coverage when the library sizes (Equation 1) between case and control
are unequal (Fig. 2C). To remove the bias. a straight line is ﬁtted between log-
ratio and log-coverage using all RLRs. The ﬁtted line corresponds to copy
number neutrality. and is subtracted from each RLR in the correction step.

2.4.3 Modeling log-ratio variation against log-coverage We observed
that the corrected RLRs are normally distributed for regions with similar
coverage. This observation has been validated across different platforms and
across a spectrum of coverage (Supplementary Fig. Sl). We. therefore. model
the RLRs using a normal distribution:

RLR~N(;1,,,a,,) (3)
where subscript (11 corresponds to the adjusted coverage of the region of

interest. signifying that the distribution is dependent on coverage. The

A GCContenlBias C Libregﬁsizebias
.m wanna

 

“AI-DATA
D _ . - . case:a ool'ltnol
ex. .  .
2 - . . '- _ _ I u ..
a I .
a.
3
c
m .
g ' “m”: .°°."‘"."
B Log-ratio Profile '
2
E. . .
g - . .
. . 'caae c control
loo-coverage II log-WWW?

Fig. 2. Characteristics of base-level log-ratios. (A) Log-ratio versus GC-
content; (B) log-ratio versus logz-coverage derived from two normal
samples; and (C) effect of imbalanced library-size on log-ratios. for both
simulated negative binomial data (left) and real data (right). The data points
represent copy number neutrality. Top: library size of case sample is two
times that of control; middle: equal size; bottom: case is half of control.

distribution mean. 11,) is estimated by the mean of RLRs. which is close to
zero after library size bias correction. The SD. (7,) decreases with increasing
coverage (Fig. 3). and is estimated using the following procedure: (i) regions
are binned based on their similarity in log-coverage; (ii) an empirical SD of
RLRs. c? is obtained for each bin; (iii) linear interpolation is used between
adjacent bins to make 8 function of a1 ; and (iv) (7,) is then estimated by 6(a).
We discuss other ways of estimating ad in Supplementary Material.

2.4.4 Computing signiﬁcance Based on Equation (3). a two-tailed P-Value
is computed for each region and is adjusted to reduce false discovery rates by
applying the BenjaminieHochberg multiple test correction (Benjamini and
Hochberg. 1995). We also allow the user to set some arbitrary thresholds on
raw read counts on case and/or control under which signiﬁcance is not called
due to the fact that sequencing data are extremely noisy and unpredictable
at low read counts. This is useful when the normal control is expected to be
diploid but has regions with very few or no reads. probably due to capture or
sequencing artifacts. Excluding these regions is a recommended ﬁltering step.

2.5 A heuristic approach for predicting large CNV

For detecting large CNVs spanning multiple target regions. we ﬁrst perform
circular binary segmentation (Olshen et al.. 2004) on RLRs. using different
parameters to achieve different resolutions of segmentation. Starting from
the coarsest resolution (largest regions). we apply three criteria for calling
a segment signiﬁcant: (i) the segment has a log-ratio >0.3 (gain) or < —0.3
(loss); (ii) at least half of the regions covered by the segment must have
been called signiﬁcant in region-level CNV predictions; and (iii) the CNV
direction (i.e. gain or loss) must be consistent between A and B. After all. the
segments at a given resolution are processed. the same criteria are re-applied
to the segments at a higher resolution (shorter segments). If a segment at
the higher resolution overlaps with one that has been called signiﬁcant at a
lower resolution. the segment at the higher resolution is ignored; i.e. larger
segments take higher precedence.

2.6 Simulated TR data

We simulated Illumina paired-end short reads using Chromosome 20 of the
human reference assembly (hgl9). The data incorporate a degrading quality
score proﬁle toward the end of the reads and substitution errors that are
present in actual llumina Genome Analyzer 11x data. Our simulated data had
a read length of 100 bp and a median insert size of 200 bp. We generated a
control dataset and case datasets at different median coverage levels. The data
cover the 4743 exons in Chromosome 20. as used by the Agilent SureSelect

Malcllad Comml n Pooled Control

 

— mantnen woman

— Dam noma I6 Games:

\ mun Mam! |1)s:mna:!
_ x We“ puma nu SaIME‘SII

 

0.4 0.6 0.8
I

Standard deviation of lag-ratios

0.2

 

 

 

5
Log Courage

Fig. 3. Comparison of log-ratio variations between matched control and
pooled controls of varying number of samples. plotting log-ratio SD against
log; coverage. The same case sample has been used throughout. Control
sample(s) are subset/superset of others.

 

1 309

112 /3.Io's[Bumo[pJOJXO'sorwuiJOJurorqﬂ:duq wort papeolumoq

9103 ‘Org anﬁnv uo ::

J.Li et al.

 

All Exon V2 capture platform. The case sample contained 311 deletions and
duplications ranging from 20 bp to 10 kb. including full and partial exon
deletions and duplications. as well as variations spanning multiple exons
(Supplementary Table S3). Our scripts for generating the simulated data are
available Via the CONTRA website.

2.7 Samples from HapMap/1000 genomes project

Five human individuals that have been studied in both the HapMap
(www.hapmap.org) and the 1000 Genomes project (www.1000genomes.org)
were selected for evaluating the performance of CONTRA. The selection was
made such that: (i) they are members of the CEU population. which is the
more studied group in HapMap; (ii) exome sequencing was performed in the
same Genome Centre (Beijing Genome Institute); (iii) exome capture was
performed using the same assay (NimbleGen V2); and (iV) they are all the
same gender (male). The HapMap sample IDs of the selected individuals are
NA11893. NA12347. NA12413. NA12775 and NA12827. One individual
(NA12546) was initially selected but was later excluded due to having too
few CNV regions with a coverage > 10x. The exome sequencing data (.bam
ﬁles) were obtained from the 1000 genomes project website. The CNV
genotype proﬁles were obtained from the HapMap website.

3 RESULTS

3.1 Characteristics of depth-of-coverage and log-ratios
in target enrichment platforms

3.1.1 Depth-of-coverage We observed a large degree of variation
of DOC in all the target enrichment platforms that we interrogated
(Table l). DOC variation across exons within a sample is highlighted
in Figures 4A and 4B. The instability of DOC along a chromosome
differentiates TR data from whole-genome sequence data, justifying
the need for new developments of specialized CNV methods. A
previous study (Nord et (11., 2011) was successful in explaining and
correcting the variation by using two factors, GC-content and bait-
distance biases. However, their data were derived from a custom
capture design targeting a few but very large regions (~40 kb). For
the off-the-shelf exome capture platforms that target much smaller
regions (~200 bp), we failed to observe sufﬁcient correlations
between DOC and GC-content or bait distance (Fig. 4C and D)
that would allow similar corrections. While there is a trend of GC-
content correlation, as suggested by the lowest line in Figure 4C, the
correlation is weak, with DOC spreading a wide range of values at
any given GC-content. Similar observations apply to the ﬁrst 300 bp
of the bait-distance plot (Fig. 4D), after which no correlation is
observed at all (ﬂat line).

Despite the huge variation of DOC, we observed a consistency of
coverage proﬁles between samples captured by the same platform,
a key characteristic of DOC that enables us to carry out CNV
analysis for TR data. This observation has been reported for one
capture platform in an independent study (Sathirapongsasuti et (11.,
2011). Here, we present similar observations on other platforms,
and contrast them against the poor correlations between samples
captured by different platforms (Fig. 5A). Although all capture
platforms exhibit consistency in DOC proﬁles, the array-based
platform (SeqCap Array) clearly exhibits a much larger variation
of coverage, whereas SureSelect v1 and EZ Exome v2 are shown
to have least variation, making them the most stable platforms for
CNV analysis (Fig. 5B).

3.1.2 Log-ratios The characteristics of DOC as discussed above
suggest that having a control derived from the same platform would

b

.Dlsmhutlor- arerans'coverase B [>99xeriatlertalwsstimtneaom

i5 'a'lll‘ll.

.l 'i t .  _
|I Illllllllxli Illlxl'll- ||._I|

covelage nut; scalar

=requenny tnu. memos:

 

501mm I "

com-Eran! '-
6 EC comentblaeueverage) D Baltcapture Dias

 

legato-arm:

 

Fig. 4. Variation of DOC in TR. (A) Histogram of exon-level coverages in
a single sample; (B) coverage proﬁle along a chromosome (showing ﬁrst 20
k targeted bp of Chromosome 1); (C) coverage versus GC-content; and (D)
coverage versus distance from the ﬁrst targeted base.

largely reduce technical variation. We show that the base-level log-
ratios between case and control are independent of GC-content
(Fig. 2A), but have variations dependent on coverage (Figs 2B
and 3). Also, we observed that log-ratios are linearly dependent on
log-coverage when the library sizes (Equation 1) between case and
control are unequal (Fig. 2C). This bias exists when the coverage
data follow a Poisson (over-dispersed) or a negative binomial
distribution (Fig. 5B suggests our data are negative binomial).

3.2 CONTRA—a novel method for CNV detection

Based on our observed characteristics of DOC and log-ratios, we
have developed a novel method for CNV detection. Our method
uses base-level log-ratios to remove GC-content bias, corrects for
imbalanced library size effect by estimating a linear dependency
between log-ratios and log-coverage, and uses a robust baseline
creation strategy to reduce variations when a control set is available.
The relationship between log-ratio variation and DOC is estimated
empirically from the data through binning and linear interpolation.
Our methods have been implemented as a software tool called
CONTRA, a publicly available package that can interface with
most other NGS analysis packages via stande formats, BAM/SAM
and VCF. CONTRA was implemented in Python and R, and has
been tested on 32/64-bit Linux (Redhat/Ubuntu) and Mac OS X.
We have also made publicly available pre-calibrated baseline ﬁles
for the various exome capture platforms, which can be used as a
pseudo-control for samples that do not have a matched control.

3.3 Performance assessment based on simulated data

We carried out a comparison between CONTRA and a previously
published R package, Exome CNV (Sathirapongsasuti et (11., 2011),
using a simulated dataset. The data contain Illumina paired-end short
reads, with a mean coverage of 50x. We simulated 311 deletions and
duplications ranging from 20 bp to 10 kb in the case sample and no
CNP in the control sample. For a large CNV spanning multiple target
regions, we consider it as a true positive if an algorithm calls more

 

1310

112 /3.Io's[Buino[pJOJXO'sorwuiJOJurorqﬂ:duq moi; papeolumoq

9103 ‘Org anﬁnv uo ::

CONTRA

 

A u Inna-v! sum-an

 

Lug-min

 

human .1 n. s..th u!

 

Lost-Gm

 

 

 

Base Poslmn Base Pnsatbn

Susan Mn Burl-Inn v5. urn-m1 B

.'. iii-gaitiii'i'an‘tIt}! 2

i
r
.
q
1
g .
r
i

 

Mom cannon

Agth Smlltl M Ewan r1

ﬁgihn SunSulncl RI Emnﬁ /
ltgiinnk SweSclncl “nun ﬂl Ewan /’
Nil-hieGaII E2 EIqu v1 /
Nlmam E2 From a:

Human Susan Exome Aim.

Variance (I092)

 

5
Coverage “1592]

Fig. 5. Coverage correlation between samples. (A) Log-ratio versus targeted base position along Chromosome 20. derived from pairs of random samples as
indicated in the plot titles. E.g. top-left: log-ratios between two EZ Exome V2 samples; bottom-right: an E2 Exome V1 sample matched against a SureSelect
V2 sample. See also Supplementary Figure S4. (B) Base-level coverage variance against coverage mean. using six random samples for each platform.

Table 2. CNV detection performance over a 50x coverage simulated dataset.
using default algorithmic parameters

 

 

 

No. of CONTRA (%) ExomeCNV (%)
Size of instances . . . H . . . . .. .
variants Simulated Sen51t1V1ty Spec1ﬁc1ty Sen51t1V1ty Speclﬁc1ty
2050 bp 100 57.0 99.7 8.0 100.0
507200 bp 100 68.0 100.0 25.0 100.0
Full exons 111 96.4 100.0 62.2 100.0

 

than half of the regions positive. Both algorithms were run with
default parameters.

Both CONTRA and Exome CNV are able to predict large CNVs
better than the smaller ones (Table 2), as they were both designed to
detect exon- or region-level CNVs. Exome CNV is very conservative
in calling a region signiﬁcant, resulting in low sensitivity and
high speciﬁcity. Although the algorithm provides an option to
relax speciﬁcity, no remarkable improvement has been observed in
sensitivity, and many regions remain uncalled (neither positive nor
negative) due to insufﬁcient coverage.

We evaluated the performance of CONTRA at a lower coverage
level (35x) across different numbers of bins. With the reduction in
coverage, sensitivity for the smaller CNVs drops by ~5%, while
that for large CNVs remains unchanged. When the number of bins
is relatively small (<10 bins), sensitivity is dependent on the bin size
(Supplementary Table S1). This dependency, however, diminishes
as the number of bins approaches optimum (between 10 and 40;
Supplementary Fig. S2).

3.4 Performance on samples with known CNV

We applied CONTRA on the exome data of 5 healthy human
individuals that have been studied in both the International
HapMap Project (www.hapmap.org) and the 1000 Genomes Project
(www.1000genomes.org). The CNV genotypes of these individuals,
thoroughly proﬁled in the HapMap project, were used as the ‘known
truth’ in our performance evaluation. Arobust baseline is constructed
from all ﬁve samples, plus an additional HapMap sample (see

CUNW’! km: for the ﬁve HapMap Individuals (averaged)

 

1.0

 

 

H lb
'3
i
E Atp=0.01
PC: 3 — _ Sensitivity Speciﬁan accuracy
muss: 0.889 0.995 0.953
mm.” 0.9;; 0.907 0.009
luau-r13 I] 3‘” D 930 0.993
n! _ M1211: 0.qu 0.939 0.9?)
o “1202'! 039:. 0354 0.090
imam: mass mesa 0.549
O. _
c.
I | I I I
0.0 0.2 0.4 EI.E 0.8 1.0

FPR I I—5 pec Incny:

Fig. 6. Receiver operating characteristics (ROC) curve for the HapMap
samples. generated by varying CONTRA’S P-Value threshold. The middle
table shows sensitivities and speciﬁcities for each individual sample at a
P-Value of 0.01.

Section 2), to serve as the control. For each sample, a region is
considered a real CNV if its HapMap copy number is not 2 and at
least four of the remaining ﬁve samples have copy number equal
to 2 for that region. Existing methods such as Exome CNV cannot
be applied to this HapMap dataset due to the lack of a function to
create a pseudo-control from multiple germline samples.
CONTRA achieved an average sensitivity of 86.8% and
speciﬁcity of 95.4% with P=0.01. The trade-off between true
positive rates (sensitivity) and false positive rates (1 — speciﬁcity)
is summarized in Figure 6. The performance of CONTRA is
comparable to the reported performance of Exome CNV on a
melanoma sample with matched control (sensitivity 87%; speciﬁcity
95%; Sathirapongsasuti et (11., 201 1). Given that the number of exons
is high in a whole-exome capture, a higher speciﬁcity (e.g. 99%) is
often preferred. In this case, a more stringent P-value is to be used in
exchange for lower sensitivity rates. As will be further discussed, this

 

1311

112 /3.Io's[BuinoprOJXO'sorwuiJOJurorq”:duq moi; papeolumoq

910E ‘OE JSHBHV uo ::

J.Li et al.

 

limitation is rooted in the coverage variation of target enrichment
assays.

4 DISCUSSION

The technical variation of coverage across ﬁve human and one
mouse exome capture platforms were compared. The one platform
that exhibits a distinct coverage distribution is the older, array-
based capture platform (SeqCap Array), with a slope larger than
all other platforms in the (log) mean-variance plot (Fig. 5B). Its
association with larger DOC variations is also apparent from the
chromosome-wide log-ratio plots (Fig. 5A), making it unsuitable for
CNV and other DOC-based analyses. Other solution-based capture
platforms are comparable, with EZ Exome v2 being the most stable
in our sample cohort. Our comparison of log-ratio plots between
single-end and paired-end SeqCap Array data shows no remarkable
differences. However, we have no access to further single-end data to
make similar comparisons for other platforms. Given the reduction
in sequencing cost, it is expected that sequencing data will be
predominantly paired-end.

The use of a matched control versus that of a control set was
also compared in terms of log-ratio variation (Fig. 3). As expected,
using multiple samples to create a baseline coverage helps to reduce
DOC variations, and in turn log-ratio variations, improving CNV
detection sensitivity. As shown in Figure 3, increasing the number
of samples in the control set would reduce the SD of log-ratios at any
given coverage, until a minimum level of SD is reached. Therefore,
even when a matched control is available, a secondary analysis using
multiple unmatched normal samples as the control can be performed
(in additional to a paired analysis) to improve the detection of true
positives.

The main difference between CONTRA and Exome CNV is their
approach to calling a region signiﬁcant. Exome CNV models the
log-ratios using a Geary—Hinkley transformation (Sathirapongsasuti
et (11., 2011), based on an approximation that DOC has a normal
distribution of equal mean and variance. This model makes
the assumption that DOC follows a Poisson distribution, which
converges to normal with sufﬁcient DOC. There are two limitations
of this approach: (i) low DOC regions are not properly addressed
and (ii) a Poisson model fails to capture the increasing variance at
high DOC, a characteristic that is evident from the mean-variance
plot of our data (Fig. 5B) and that has been discussed in the context
of RNA-seq and a negative binomial model (Robinson et (11 ., 2010).
CONTRA, on the other hand, was developed based on empirical
relationships between log-ratios and DOC that have been observed
to be consistent across multiple target enrichment platforms. It relies
on the case sample being largely copy number neutral, through
which a null distribution of log-ratios is estimated and outlying
events (CNVs) detected. This assumption has been demonstrated to
hold sufﬁciently well for normal individuals in our evaluation using
HapMap data. For non-diploid samples, the limitation of CONTRA
is a reduced sensitivity in CNV detection when a large proportion
of the target regions are associated with a copy number change,
such as in a small custom capture of tumor material (Supplementary
Materials). However, this limitation is eased in the case of whole-
exome capture, where a large proportion of copy number neutral
regions can be achieved. Furthermore, this limitation does not apply
to family and population studies, where CNV events are expected
to be rare.

The inherent limitation of TR data, regardless of analysis methods,
lies in the high variation of DOC. Such a high variation makes
the detection of a single copy number gain a very difﬁcult task,
as apparent from Figure 2B, where the cloud of null data spreads
across the log-ratio = 0.58 line (1.5 fold-change). The detection of
hemizygous deletions would perform better as it corresponds to a —2
fold-change (log-ratio = — l), but would be challenging for regions
with coverage less than ~30x.

In addition to CNV calls at the region (exon) level, CONTRA
offers a ﬁinction to predict large CNVs spanning multiple regions.
However, care must be given to the interpretation of these large
predictions. A large CNV segment often consists of a percentage
of regions that have inconclusive CNV status (high P-values).
They may correspond to either copy number neutral regions or low
coverage regions. The strategy employed by CONTRA is to set a
threshold on this percentage, above which no CNV call is made.
On the other hand, the strategy used by Exome CNV is to add
up DOC across the regions and then assess the overall log-ratio
(Sathirapongsasuti et (11., 201 l), heavily biasing toward those regions
with high coverage. Neither of these methods adequately addresses
the sparseness and non-contiguous nature of target regions, an
inherent limitation of TR data that restricts practical prediction
to be made at the region level. For this reason, while TR (or
exome sequencing) is appropriate for predicting novel single-exon
CNVs and screening for known CNVs, other technologies such as
genotyping microarrays must be used for the accurate predictions of
larger CNVs.

For the upstream processing of sequence data, CONTRA imposes
no requirements on the methods used, but it is recommended that
multi-mapped reads and PCR duplicates be removed to reduce
signal noise in DOC. Downstream analysis after CNV detection
includes the removal of known CNPs from candidate CNV regions
using public resources, such as the Copy Number Variation Project
(http://www.sanger.ac.uk/humgen/cnv). This is particularly useful
when a pooled control strategy is used.

5 CONCLUSION

Targeted resequencing data across seven capture platforms have
been assessed in terms of coverage and log-ratio variations. We
have developed a method for the detection of CNV based on
empirical relationships between log-ratio and coverage. CONTRA
outperforms an existing algorithm based on a simulated dataset,
and is particularly suitable for population and family studies.
Our methods are available as a software package, CONTRA, via
http://contra-cnv.sourceforge.net

Funding: Peter MacCallum Cancer Foundation Endowment Fund,
the Victorian Breast Cancer Research Consortium and Australian
Research Council (grant DP1096296).

Conﬂict of Interest: none declared.

REFERENCES

Abyzov,A. et a1. (2011) CNVnator: an approach to discover, genotype and characterize
typical and atypical CNVs from family and population genome sequencing. Genome
Res., v01. 21, pp. 974984.

Aird,D. et a1. (2011) Analyzing and minimizing PCR ampliﬁcation bias in Illumina
sequencing libraries. Genome 3101., 12, R18.

 

1312

112 /3.Io's[BrunoprOJxosorwurJOJurorq”:duq moi; pepeo1umoq

9103 ‘0g isanV uo ::

CONTRA

 

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: a practical
and powerful approach to multiple testing. J. R. Stat. Soc., 57, 2897300.

Boeva,V. et a1. (2011) Control-free calling of copy number alterations in deep-
sequencing data using GC-content normalization. Bioinformatics, 27, 2687269.
Campbell,P.J. et a1. (2008) Identiﬁcation of somatically acquired rearrangements in
cancer using genome-wide massively parallel paired-end sequencing. Nat. Genet,

40, 7227729.

Chiang,D.Y. et a1. (2009) High-resolution mapping of copy-number alterations with
massively parallel sequencing. Nat. Methods, 6, 997103.

Ivakhno,S. et a1. (2010) CNAscgia novel framework for identiﬁcation of copy number
changes in cancer from second-generation sequencing data. Bioinformatics, 26,
305173058.

Johnston,J.J. et a1. (2010) Massively parallel sequencing of exons on the X chromosome
identiﬁes RBM10 as the gene that causes a syndromic form of cleft palate. Am. J.
Hum. Genet., 86, 7437748.

Li,l-I. and Durbin,R. (2009) Fast and accurate short read alignment with Burrows-
Wheeler transform. Bioinformatics, 25, 175471760.

McKenna,A. et a1. (2010) The genome analysis toolkit: a MapReduce framework for
analyzing next-generation DNA sequencing data. Genome Res., 20, 129771303.
Medvedev,P. et a1. (2009) Computational methods for discovering structural variation

with next-generation sequencing, Nat. Methods, 6, $137520.

Medvedev,P. et a1. (2010) Detecting copy number variation with mated short reads.
Genome Res., 20, 161371622.

Miller,C.A. et a1. (2011) ReadDepth: a parallel R package for detecting copy number
alterations from short sequencing reads, PLoS One, 6, 616327.

Ng,S.B. et a1. (2009) Targeted capture and massively parallel sequencing of 12 human
exomes. Nature, 461, 2727276.

Nord,A. et a1. (2011) Accurate and exact CNV identiﬁcation from targeted high-
throughput sequence data. BMC Genomics, 12, 184.01shen,A.B. et a1. (2004)
Circular binary segmentation for the analysis of array-based DNA copy number
data. Biostatistics, 5, 5577572.

Quinlan,A.R. and Hall,I.M. (2010) BEDTools: a ﬂexible suite of utilities for comparing
genomic features. Bioinformatics, 26, 8417842.

Robinson,M.D. et a1. (2010) edgeR: a Bioconductor package for differential
expression analysis of digital gene expression data. Bioinformatics, 26,
1397140.

Sathirapongsasuti,J.F et a1. (2011) Exome sequencing-based copy-number variation
and loss of heterozygosity detection: exomeCNV. Bioinformatics, 27, 264872654.

Walsh,T. et a1. (2010) Detection of inherited mutations for breast and ovarian cancer
using genomic capture and massively parallel sequencing. In Proceedings of the
National Academy of Sciences, Vol. 107, pp. 12629712633.

 

1313

112 /3.Io's[BrunoprOJxosorwurJOJurorq”:duq moi; pepeo1umoq

9103 ‘0g isanV uo ::

