Vol. 28 E005 2012, pages i562—i568
doi:1 0. 1 093/bioinformatics/bt3372

 

An approach to describing and analysing bulk biological
annotation quality: a case study using UniProtKB
Michael J. Belli, Colin 8. Gillespiez, Daniel Swans” and Phillip Lord1’*

1School of Computing Science, 2School of Mathematics & Statistics and 3Bioinformatics Support Unit, ICAMB,
Medical School, Newcastle University, Newcastle—Upon—Tyne, NEt 7RU, UK

 

ABSTRACT

Motivation: Annotations are a key feature of many biological
databases, used to convey our knowledge of a sequence to the
reader. Ideally, annotations are curated manually, however manual
curation is costly, time consuming and requires expert knowledge
and training. Given these issues and the exponential increase of data,
many databases implement automated annotation pipelines in an
attempt to avoid un-annotated entries. Both manual and automated
annotations vary in quality between databases and annotators,
making assessment of annotation reliability problematic for users.
The community lacks a generic measure for determining annotation
quality and correctness, which we look at addressing within this
article. Specifically we investigate word reuse within bulk textual
annotations and relate this to Zipf’s Principle of Least Effort. We
use the UniProt Knowledgebase (UniProtKB) as a case study to
demonstrate this approach since it allows us to compare annotation
change, both over time and between automated and manually
curated annotations.

Results: By applying power-law distributions to word reuse in
annotation, we show clear trends in UniProtKB over time, which
are consistent with existing studies of quality on free text English.
Further, we show a clear distinction between manual and automated
analysis and investigate cohorts of protein records as they mature.
These results suggest that this approach holds distinct promise as a
mechanism for judging annotation quality.

Availability: Source code is available at the authors website:
http://homepages.cs.ncl.ac.uk/m.j.be||1/annotation.

Contact: phil|ip.|ord@newcastle.ac.uk

1 INTRODUCTION

Akey descriptive feature of biological data is its annotation: a textual
representation of the biology associated with the data. Biologists use
these annotations to understand and contextualize data in biological
sequence databases. Annotations play an essential role in describing
and developing the users’ knowledge of a given sequence and can
form the foundation for further research (Jones et (11., 2007). Some
annotation is structured, for example, using an ontology (Stevens
and Lord, 2009) or keyword list. However, free text annotation often
contains the richest biological knowledge (Camon et (11., 2005), but
while free text is appropriate for human comprehension it is difﬁcult
to interpret computationally.

 

*To whom correspondence should be addressed.
1Present address: Oxford Gene Technology, Yarnton, Oxfordshire, OX5
lQU, UK.

The current ‘gold standard’ for annotation is a set of reviewed and
manually curated entries (Curwen et (11., 2004). However, manually-
curated annotation is labour-intensive, time consuming and costly.
To cope with the amount of data, which is typically increasing
exponentially, many resources and projects generate annotations
computationally (Boeckmann et (11., 2003). Automated annotations
are more prone to errors than their manual counterparts (Gilks et (11.,
2002), with several studies suggesting high levels of misannotation
in automated annotation (Andorf et (11., 2007; Jones et (11., 2007;
Schnoes et (11., 2009). It can be hard, even impossible, to determine
the source from which an error has propagated (Buza et (11., 2008)
causing signiﬁcant problems for biologists. Annotation quality is not
consistent across all databases and annotators (Dolan et (11., 2005),
whether curated manually or automatically. It can, therefore, be
difﬁcult to determine the level of quality, maturity or correctness of
a given textual annotation. However users often incorrectly assume
that annotations are of consistent quality and correctness (Ussery
and Hallin, 2004).

Currently there are few stande metrics for assessing annotation
quality. Annotations are frequently assigned a score, using a variety
of methods. These approaches include assigning conﬁdence scores to
annotations based on their stability (Gross et (11., 2009) or combining
the breadth (coverage of gene product) and the depth (level of
detail) for the terms in the Gene Ontology (GO) (Buza et (11. 2008).
However, while deeper nodes within an ontology are generally more
specialized, these measures are problematic; ﬁrst G0 has three root
domains and second an ontology, such as G0, is a graph not a tree,
therefore depth is not necessarily meaningful. Other methods (Buza
et (11., 2008; Pal and Eisenberg, 2005; Rogers and Ben-Hur, 2009)
use evidence codes as a basis for an annotations reliability, although
ironically, the GO annotation manual explicitly states that evidence
codes should NOT be used in this way (GO Consortium, 2011),
describing rather the type of evidence not its strength.

All of these approaches rely upon additional information
to determine annotation quality. Resources, such as sequence
databases, vary in their structures and in the additional information
stored. For example, not all resources use evidence codes and these
codes are not comparable between resources (Lord et (11., 2003);
likewise, it is not generally possible to use methods based on an
ontological hierarchy for non-ontological resources.

Most resources carry some annotations which are unstructured,
free text. Therefore, a quality metric that can be derived purely
from textual annotation would potentially allow any resource to
be analysed and scored. There are various measures for analysing
the quality of text, such as the Flesch—Kincajd Readability Test
(Flesch, 1948) and SMOG Grading (Laughlin, 1969). These metrics
are generally based around readability, or reading-age; that is the

 

© The Author(s) 2012. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0), which
permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.

112 /3.Io's[Bruno[pJOJXO'sorwurJOJurorqﬂ:duq 11101} papeolumoq

91oz ‘Og anﬁnv uo ::

An approach to describe and analyse bulk annotation quality

 

literary quality of the text, rather than correctness and quality of the
subject matter.

In this article, we report on a bulk analysis of textual annotation in
the UniProt Knowledgebase (UniProtKB), attempting to understand
whether we can exploit our knowledge of changes in the annotation
over time as a mechanism for developing a quality measure of
biological correctness. We investigate word occurrences, and their
changes over time, as reﬂected in their distribution; we show that
using these relationships we are able to detect large-scale changes
in the annotation process; and we demonstrate that the parameters
of these relationships also change. Speciﬁcally, we ﬁt a power-law
distribution to the extracted word occurrences and extract a value,
called a. We relate this a value to Zipf’s principle of least effort,
which states it is human nature to take the path of least effort to
achieve a goal. Broadly, higher values of (1 indicate a resource
which is easier for the reader, whereas lower values are easier for
the annotator.

Although manually curated annotation is generally accepted as
the most accurate (Curwen et (11., 2004), a signiﬁcant problem
is the lack of more explicit gold stande datasets (James et (11.,
2011; Roberts et (11., 2011). This makes deﬁning a quality measure
somewhat troublesome. Our investigation into whether changes in
word distribution are representative of quality and maturity in the
annotation show that these forms of measures can detect large-scale
features of annotation, and that clear trends appear as UniProtKB
matures and grows over time. These trends are often reﬂective of
our a priori judgements of quality within UniProtKB, for example,
a distinction between manual and automated annotation. In the
absence of a gold standard, we believe that this represents reasonable
evidence that this form of analysis may be used as the basis for a
quality metric for textual annotation.

2 METHODS
2.1 Data extraction from UniProtKB

UniProtKB (UniProt Consortium, 2010) consists of two sections:
UniProtKB/Swiss-Prot, which is reviewed and manually annotated, and
UniProtKB/TrEMBL which is unreViewed and automatically annotated. The
ﬁrst version of Swiss-Prot was released in 1986, with TrEMBL appearing
in 1996. Releases of TrEMBL were initially more frequent than Swiss-Prot,
meaning the databases were released independently. In Table 1, we map
between each Swiss-Prot release and the nearest version of TrEMBL. This
allows us to compare the quality of manually and automatically curated
annotation at similar points in time.

Following the formation of the UniProt Consortium in 2002, the releases
of the two databases were synchronized (from 2004). The correct names are
now technically UniProtKB/Swiss-Prot and UniProtKB/TrEMBL. We will
use the following naming approach for clarity:

0 UniProtiRefers to the UniProt Consortium.

0 Swiss-ProtiRefers to Swiss-Prot entries prior to the formation of
the UniProt Consortium.

0 TrEMBLiRefers to TrEMBL entries prior to the formation of the
UniProt Consortium.

UniProtKBiRefers to the combination of both Swiss-Prot and
TrEMBL datasets.

Where necessary we will explicitly write UniProtKB/Swiss-Prot or
UniProtKB/TrEMBL. This naming scheme allows us to refer to post-
UniProtKB versions of UniProtKB/Swiss-Prot and UniProtKB/TrEMBL

Table 1. Mapping between TrEMBL and Swiss-Prot release dates

 

 

Date Swiss-Prot version Date TrEMBL version
Oct-96 34 Nov-96 1
Nov-97 35 J an-98 5
J ul-98 36 Aug-98 7
Dec-98 37 J an-99 9
Jul-99 38 Aug-99 11
May-00 39 May-00 l3
Oct-01 4O Oct-01 18
Feb-03 41 Mar-O3 23
Oct-O3 42 Oct-O3 25
Mar-04 43 Mar-04 26

 

For each version of Swiss-Prot, we have associated the nearest version of TrEMBL
based on release date.

with the same number, starting from version two of UniProtKB.l We can
investigate annotation change over time, as complete datasets for historical
versions of UniProtKB and Swiss-Prot are made available by UniProt on
their FTP server, with the exception of Swiss-Prot versions 1-8 and 10 which
were never archived. Pre-UniProtKB/TrEMBL releases were kindly made
available to us by UniProt.

Our extraction approach, also summarized in Figure 1, involves four key
steps:

(1) The UniProt FTP server (ftp.uniprot.org/pub/databases/uniprot/)
provides complete datasets for past versions of Swiss-Prot and
UniProtKB in ﬂat ﬁle format.

(2) UniProtKB ﬂat ﬁles adhere to a strict structure, as detailed in
the UniProtKB user manual (UniProt Consortium, 2011). A Java
framework was created that allowed UniProtKB comment lines to
be correctly extracted.

(3) Over time annotations in UniProtKB have become more structured
with the addition of topic headings (e.g. ‘subcellular location” and
‘function’). These headings are ignored by our analysis. We also
remove punctuation, the ‘CC’ identiﬁer, brackets and whitespace.

(4) The ﬁnal step in this process is to output a list of all words and their
frequency for all annotations in a given database version.

In order to ensure accurate data extraction, we checked that the number
of entries parsed (Figure 1, step 2) matched the number expected from
the release notes. Additionally the list of headings (comment blocks and
properties) removed (Figure 1, step 3) were noted, along with their frequency,
to ensure only headings described in the UniProtKB manual were removed.
Finally, a random selection of records were manually checked against parsed
outputs (Figure 1, all steps).

2.2 Model ﬁtting

When developing a framework to model the occurrence of words, a variety
of competing models were considered. These ranged from relatively simple
distributions, such as the exponential and log-normal, to more complex
mixture models. However, the power-law distribution achieved a good
balance between model parsimony and ﬁt.

In this article, we only deal with the discrete power-law distribution [see
(Clauset et (11., 2009) for a discussion on power-laws]. The discrete power-
law distribution has probability mass function

—a

170‘) : {(avxmin)

 

1Version 2 was the ﬁrst major release containing Swiss-Prot version 44 and
TrEMBL version 27.

 

i563

112 /3.Io's[Bumo[pJOJXO'sorwurJOJurorqﬂ:duq moi; papeolumoq

9103 ‘Og isnﬁnv uo ::

M.J.Bell et al.

 

    
 
 
 

‘ '. STn-ﬂiE Ex::.-nr.<nn .r.H-l'

 

 

ianéi'  "1'2"

— and brain

by 9 I J uuiuuiiinazmi- and
In T aiilg
amassed :le _

alrnilarill.I 3  "  I 1.4?

degradation 3 I

ubicuilination 1 

 

Fig. 1. Outline view of the data extraction process. (1) Initially we download
a complete dataset for a given database version in ﬂat ﬁle format. (2) We
then extract the comment lines (lines beginning with ‘CC’, the comment
indicator). (3) We remove comment blocks and properties [as deﬁned in
the UniProtKB manual (UniProt Consortium, 2011)], punctuation, ‘CC’,
brackets and make words lower case, so as to treat them as case insensitive.
(4) Finally, we count the individual words and update the occurrence of each
word total count

where

00
{(avxmin) = :01 +xmin)—a
r120
is the generalized or Hurwitz zeta function.

To ﬁt the power-law distribution, we followed the Bayesian paradigm. We
assumed a proper uniform U (1 , 5) prior for 01. Since the posterior distribution
for the parameters is analytically intractable, we integrate out the uncertainty
using a Markov chain Monte Carlo (MCMC) algorithm. The parameter space
was explored using a Gaussian random walk. The Markov chain reached
equilibrium very quickly and only a small amount of thinning was necessary.

We modelled multiple datasets simultaneously using a ‘ﬁxed-effects’
approach. Let 1' denote the dataset of interest, then we aim to infer the
parameter

Oli’=0l+ll«i

where 01 is the coefﬁcient for a baseline dataset and 11, is difference from this
baseline. For example in Figure 3, the baseline dataset is UniProtKB/Swiss-
Prot version 16 and 11,» represents the change in the 01 coefﬁcient from
UniProtKB/Swiss-Prot version 16.

Throughout this article, we set xmin = 50, which we determined using the
Bayesian information criterion (BIC) criteria when ﬁtting all the datasets in
Figure 3. However, the conclusions are not sensitive to changes of xmin. For
smaller values of xmin, the credible region is reduced since there is more
data, conversely increasing xmin to around 200 increases the credible regions
slightly.

The ﬁtting of a power-law corresponds to the exponent of the regression
line represented by 01. Given that the graph and 01 value is based on the
underlying text, it is plausible that the 01 value could provide a measurement
to assess the underlying textual quality. Indeed, it has been previously
suggested (Ferrer, 2005) that the 01 value is related to Zipf’s principle of
least effort (Zipf, 1949).2 This principle states that it is human nature to take
the path of least effort when achieving a goal. For example, an annotator can
create an annotation with generic terms (least effort for the annotator, more
work for the reader) or with precise and specialist terms (least effort for the
reader, more work for the annotator). Table 2 shows 01 values that have been
extracted from a variety of texts, that give conﬁdence to this claim. We can

 

2Additionally, Zipf has shown that a words occurrence is inversely
proportional to its rank (Zipf’s Law). Zipf’s law, Pareto’s law and power-law
distributions are all types of power-law that are, essentially, different ways
of looking at the same thing (Adarnic and Huberman, 2002).

use this information as a basis for quality; texts which require minimal effort
for the reader, due to expertly curated annotation, are deemed to be of high
quality.

3 RESULTS
3.1 Does annotation in UniProtKB obey a power-law
distribution?

Power-laws have been shown to exist in numerous man-made and
natural phenomena (Clauset et (11., 2009). The link between Zipf’s
principle of least effort and a was originally based on natural
language. If a power-law distribution is a measure of quality,
we would expect that a power-law distribution is more likely to
occur in human-curated annotation rather than annotations produced
automatically. Therefore, for our initial analysis, we selected Swiss-
Prot as a gold stande resource. Results are shown in Figure 2a, for
two versions of Swiss-Prot. We can see that annotation does broadly
obey a power-law, although with a distinct ‘kink’ in Swiss-Prot
version 37, between x: 104 and x: 105.

Inspection of the words in this region showed that this structure is
artefactual, resulting not from annotation per se but from copyright
and license information, which are included in the CC lines, along
with biological information. These copyright statements were ﬁrst
introduced into Swiss-Prot at version 37, with wording changes at
UniProtKB versions 4 and 7. From this analysis, we show that we
can detect the introduction of a large amount of material with no
biological signiﬁcance into the annotation. This demonstrates that
the power-law can be used as a partial measure of quality, albeit for
detecting artefacts.

For subsequent analysis we removed the copyright statements.
Updated graphs, with copyright statements removed, are also shown
in Figure 2a. Inspection of these graphs show that the slope
for the head and tail increase at different rates with Swiss-Prot
versions. This is a result of a marked two-slope behaviour which is
commonly seen for mature resources, such as large complex natural
languages (Cancho and S016, 2001; Ha et (11., 2006). These graphs
follow a power-law distribution reasonably well. However Figure
2b shows some versions of TrEMBL where a power-law does not
ﬁt that well. As discussed in Section 2.2, various competing models
were considered, with a power-law being chosen partly due to the
simplicity of its output, a. It is clear that this change over time
requires further analysis.

3.2 How do the distributions change over time?

Although it is useﬁil for demonstrating the two-slope behaviour,
this View makes it difﬁcult to see change over time. Given that the
main analytical value comes from the extracted a values, subsequent
graphs show just these values for different database versions. This
approach allows us to investigate the change over time by looking
at all historical data simultaneously. The resulting graphs from this
analysis is shown in the top half of Figure 3.

As Figure 3 shows, the annotation in Swiss-Prot is changing in its
nature over time. (1 decreases over time for Swiss-Prot, suggesting
that Swiss-Prot is becoming optimized towards least effort for the
annotator, rather than the reader. This ﬁts with previous research
from Baumgartner et (11. (2007) suggesting that the enormous
increase in proteins requiring annotation is outstripping the provision
of this annotation. This issue has been acknowledged by UniProt,

 

i564

112 /3.Io's[Bumo[pJOJXO'sorwurJOJurorqﬂ:duq moi; papeolumoq

9103 ‘Og isnﬁnv uo ::

An approach to describe and analyse bulk annotation quality

 

Table 2. Relationship between at value and Zipf’s principle of least effort

 

 

 

 

 

   
 
    

 

 

 

at value Examples in literature Least effort for
01 < 1.6 Advanced schizophrenia (Piotrowska and Piotrowska, 2004; Zipf, 1949), young children (Brillouin, 2004; 7
Piotrowska and Piotrowska, 2004)
1.6 5 01 < 2 Military combat texts (Piotrowska and Piotrowska, 2004), Wikipedia (Serrano at al., 2009), Web pages listed Annotator
on the open directory project (Serrano at al., 2009)
oz :2 Single author texts (Balasubrahmanyan and Naranan, 1996) Equal effort levels
2 < 01 5 2.4 Multi author texts (Ferrericancho, 2005) Audience
01 > 2.4 Fragmented discourse schizophrenia (Piotrowska and Piotrowska, 2004) 7
For a values < 1.6 or > 2.4, we have no corresponding effortelevel as the text is treated as incomprehensible.
(a) 0mm! mt Comm mmred  | TrEMBL i s Swiss—Flu s4 TIEMBL la a Swiss—Plot as
we _ I "In _ Wmlun
—-— Swiss-43ml
‘0 ‘ — ‘DI‘ — —- TI‘EMBL
‘0 ? _ g I ‘D.2 _
3
“r3 - : g a m a _
T“ w‘ - ,1 in ‘ -
g “(h  [ uaniuILEZ Llani-mKBlE
0- n. la" —
1D" - ‘
“3'
“TL  in"
.' "‘.
_,_ «- . ‘51. I‘
w l 10'“ “‘3
t 'i. "
10‘ v ' ' 4
1D ‘

 

| | | | | .1
:02 in“ :o‘ 10’

I I l
in“ m' lit2 103

.' l l
m‘1 in“ no“ 10‘
K

 

 

 

 

.- l | I
ma ll?!1 10‘ :05 lo“ I02 Io” m‘ :05 10“

Fig. 2. Cumulative distributions of words for various Swiss-Prot and TrEMBL versions, shown with logarithmic scales. The size (number of words) is shown
along the X -axis whereas the probability is shown on the Y-axis. A point on the graph represents the probability that a word will occur x or more times. For
example, the upper left most point represents the probability of 1 (i.e. 100) that a given word will occur once (i.e. 100) or more times. A word must occur
at least once to be included. Words occurring very frequently are presented in the bottom right of the graph. (3) Shows the resulting graphs for Swiss-Prot
version 9 (November 1988) and Swiss-Prot version 37 (December 1998), with and without copyright. The distinct structure visible between x2104 and
x: 105 in Swiss-Prot version 37 (bottom left panel) is caused by the copyright statement declaration. Swiss-Prot version 9 operates as a control to show that
the attempted removal of copyright has no effect where no copyright information is present. (b) Shows the data with ﬁtted power-law distributions for an
even subset of historical versions of Swiss-Prot and the co-ordinate release of TrEMBL

with their introduction of automated annotation; therefore, we next
investigate this form of annotation.

3.3 How does manual annotation compare to
automated annotation?

Within UniProtKB proteins are initially annotated automatically and
placed into TrEMBL. Eventually they are manually annotated and
placed into Swiss-Prot. Therefore, TrEMBL and Swiss-Prot are ideal
resources to compare equivalent human and automated annotations.
Here, we compare these two resources, investigating their behaviour
over time, at equivalent points in time. As previously described, prior
to UniProtKB version two, TrEMBL and Swiss-Prot releases were
not synchronized, so we use the version of TrEMBL released closest
in time to each version of Swiss-Prot, as show in Table 1. An evenly
spaced subset of these analyses are shown in Figure 2b, with Figure
3 showing the a values for all versions of TrEMBL and Swiss-Prot.

In Figure 2b, TrEMBL and Swiss-Prot appear to diverge over
time with Swiss-Prot demonstrating the behaviour typical of a more
mature resource. TrEMBL shows less maturity, with many words
occurring with a high frequency. In short, Swiss-Prot appears to
show a richer use of vocabulary. We cannot, however, rule out
the possibility that this difference occurs as they are annotating
different proteins. Unfortunately, it is not possible to check a proteins
annotation in both Swiss-Prot and TrEMBL at the same point in
time; once a record is migrated to Swiss-Prot, it is removed from
subsequent versions of TrEMBL. This is necessary as Swiss-Prot is
used as a basis for annotation in TrEMBL, so proteins not removed
from TrEMBL would have their automated annotation based on their
manual annotation in Swiss-Prot. However, the rapid increase in size
of both resources, argues against this explanation.

Whereas Swiss-Prot shows a relatively regular progression,
TrEMBL does not. There are two signiﬁcant disjuncts in the
relationship where large jumps occur between releases, as

 

i565

112 /3.Io's[Bumo[pJOJXO'sorquJOJurorqﬂ:duq urorJ papeo1umoq

9103 ‘0g isnﬁnv uo ::

M.J.Bell et al.

 

i “not _ mnm.w
ol

 l llllllll'llllillllllll

"I 'HHHHlH
i

a

 

Dﬂulanca m m "cm Unowusmu-om W50! 10

ll 

llllll-i-lll

a: - dh’imlb
i .

llllillllﬁ 1' ill.

«-

Fig. 3. 01 values over time, for each version of Swiss-Prot and TrEMBL.
The graph shows the difference in 01 value (with 95% credible region)
from UniProtKB/Swiss-Prot version 16, for which the 01 value was 1.62.
So, for example, Swiss-Prot version 9 has a difference of, approximately,
0.45. Therefore the resulting oz for Swiss-Prot version 9 is around 2.07

highlighted in Figure 3. We also note a signiﬁcant rise of total words
between these versions, compared to those for nearby releases (data
not shown).

We have identiﬁed two plausible explanations for these disjuncts,
based on historical events. Firstly in 1998 (highlighted by disjunct
(1) a number of new procedures appear to have been introduced
(Bairoch and preiler, 1998). These approaches include making
use of the ENZYME database, specialized genomic databases
and scanning for PROSITE patterns compatible with an entries
taxonomic range. PROSITE patterns are used to enhance the content
of the comment lines by adding information such as protein ﬁlnction
and subcellular location. Interestingly, prior to this disjunct, the
ﬁrst four versions of TrEMBL have an a value higher than their
Swiss-Prot counterpart.

Secondly in 2000, the introduction and development of annotation
rules was planned in TrEMBL which could explain the second jump
(highlighted by disjunct b) (Bairoch and preiler, 2000). Both of
these disjuncts would be expected to produce an increase in the total
amount of annotation, as well as introducing new words and phrases
which would affect the measures described here. Given the lack of
detailed statistics and the age of the database at this time, UniProt
could not conﬁrm these explanations. They did acknowledge that
extensive work in 2001 and early 2002 was carried out to improve
the data, although they believe the scanning of PROSITE was in
effect from TrEMBL version 1.

The increase of total words noted earlier correlates with the
increase of entries into UniProtKB; the rate of data being added
is exponential. Given this increase, we ﬁnd ourselves analysing
entries and annotations of mixed age. Here we have seen the apparent
decreasing of quality for complete datasets, of both Swiss-Prot and
TrEMBL, over time. Following on from this, we wish to explore the
quality of annotations within a set of mature entries.

3.4 Analysing maturity of entries over time and the
impact of new annotations

Our prior analysis has investigated annotation quality in bulk,
without analysing how individual records are maturing. If we
consider ‘maturity’ as a simple ﬁlnction of age, then we would
expect, given the rapid increase in the size of Swiss-Prot, while
new records appear, the older entries should mature. Figure 4a
illustrates the exponential rate at which Swiss-Prot and TrEMBL
are growing, showing the number of entries in each database
version.

Each entry contains a date stamp, indicating when it was ﬁrst
introduced into the database. We use this information to show that
the average creation date of a record has increased only slowly
over the life span of Swiss-Prot as a whole—illustrated in Figure
4b. Swiss-Prot is currently around 20 years old, yet the average
record age is around 5 years old and decreasing. This is illustrated
in Figure 4c, where we show the difference between the average
creation date and release date. As an example, Swiss-Prot version
9 was released in November 1988 and the average entry release
date is July 1987, so the ﬁgure reﬂects this difference of 1 year
and 4 months. Given this, we wished to abstract from increasing
size of Swiss-Prot and ask whether individual records appear to be
maturing.

This analysis is not straightforward; we need, essentially, a set
of records which relate to a deﬁned set of proteins. To achieve
this we extracted the annotations from all of the entries that were
common in both Swiss-Prot version 9 and UniProtKB/Swiss-Prot
version 15 (the ﬁrst and last version available to us). The resulting a
values are shown in Figure 5b, with the addition of the a value for
those entries in UniProtKB version 15 but not Swiss-Prot version 9.
These results show that the a value for the mature set of entries has
decreased over time, correlating with the Swiss-Prot database as a
whole.

Given that the a value for mature entries has decreased over time,
it is of interest to investigate the a values of entries that are new
to each version of Swiss-Prot. For this, we extracted annotations
from entries that appeared for the ﬁrst time in a given database
version. Results of this analysis are shown in Figure 5a. It again
would appear that the a value is decreasing over time, similar to
that of other Swiss-Prot graphs.

4 DISCUSSION

The biological community lacks a generic quality metric that allows
biological annotation to be quantitatively assessed and compared.
In this article we applied power-law distributions to the UniProtKB
database and linked the extracted a values to Zipf’s principle of
least effort in an attempt to derive such a generic quality metric. The
results within this article give conﬁdence to our initial hypothesis
that this approach holds promise as a quality metric for textual
annotation.

Initially, our analysis focused on the manually curated Swiss-
Prot. As shown in Figure 3, early versions of Swiss-Prot give a
values that suggest annotations were of high quality; that is, they
were of least effort for the reader. However, over time we see a
steady reduction in the a value, which does suggest that the average
annotation is now harder for readers to interpret, requiring more
expertize to consume the data than was previously required. This

 

i566

112 /3.IO'S[1211,1110prOJXO'SOIJBLUJOJIIIOIq”Idllq urorJ papeo1umoq

9103 ‘0g isnﬁnv uo ::

An approach to describe and analyse bulk annotation quality

 

o is mm M
I .
mu .
_ an; -
_.-

lil‘ »
.. A“
9 .5 §m -
a _- g
a it» . ,1,
a . .e" "
s 1'  §.,,, _
z x

 A 3

.a
p {_t’ M“ ' _
.’ ,
io‘ ' I“,
m mu m g'm m in

ma mo
Ram Dal:

mu m
Flakes! Dal:

r- lcl

i
l
Dilemma-u wears)

 

Fig. 4. Swiss-Prot (red circles) and TrEMBL (blue triangles). (a) Growth (number of entries) in Swiss-Prot and TrEMBL over time. (b) Average creation date
over time for Swiss-Prot and TrEMBL. (c) Difference between release date and average creation date (i.e. age) over time

2.6 — {a} _ _
9m-le Unmet sum—Pm:

9% lllllll 

1 I

1.6—

I'i'l |'1'."I"|'.' |'I"'|"I ' I'I'i'i | I'i I'I ' |'|"|'| 'I I I"T'i I'I '1'|'"|'1"‘|"|"i'
i2la2o2n2aazaeanma 8|2IB
Database version

2.5 — {tn}
2.4 —'

2.2 —

6
2.0 — i

|

| | '
SPIJB ALL UF'SP‘-5 ALL UPSF'15 Other

Database verslun

Fig. 5. (3) Analysis of those entries that are new to a particular version of
Swiss-Prot. (b) 01 value (with 95% credible region) for all entries in Swiss-
Prot version 9 that are in UniProtKB version 15, all entries in UniProtKB
version 15 that are in Swiss-Prot version 9, and all those in UniProtKB
version 15, but not in Swiss-Prot version 9

result is perhaps best explained by the exponential increase of data
that is added to Swiss-Prot. Manual annotations are regarded as
the highest quality annotation available and it is inevitable that the

acknowledged pressure on manual annotation is going to increase.
This conclusion appears to ﬁt with previous research (Baumgartner
et (11., 2007) that shows manual curation techniques cannot keep up
with the increasing rate of data.

Many of the patterns exhibited by Swiss-Prot are also shown in our
analysis of TrEMBL. From Figure 3, we conclude that annotation in
Swiss-Prot and TrEMBL show similar characteristics in that, for both
cases, annotation appears to be increasingly optimized to minimize
efforts for the annotator rather than the reader; unsurprisingly, this
appears to be more pronounced for TrEMBL than for Swiss-Prot.
We are currently unclear whether this form of direct numerical
comparison over the two different resources is highly meaningful,
although this distinction between the two resources appears to
be more pronounced over time rather than less. Therefore, these
results are consistent with the conclusion that manual annotation
behaves as a signiﬁcantly more mature language than automated
annotation. This ﬁts with our a priori assumptions which again is
suggestive that this form of analysis is operating as a measure of
quality.

In addition to analysing whole UniProtKB datasets, we also
investigated how sets of entries mature over time (Fig. 5b) and
the quality of annotations within new entries (Fig. 5a). Within
the mature entries we interestingly see a decrease in quality over
time, rather than increasing or maintaining a similar quality level.
However this decrease is much slower than the Swiss-Prot database
as a whole over time, and is still of much higher quality than
the remainder of entries in UniProtKB version 15. For the new
annotations we also see a general decrease in quality over time. It
is plausible that these results stem from the manner of management
and curation of annotations; the UniProt annotation protocol consists
of six key steps (Magrane and Uniprot Consortium, 2011), one
of which is identifying similar entries (from the same gene and
homologues by using BLAST against UniProtKB, UniRefs and
phylogenomic resources). If two entries from the same gene and
species are identiﬁed then they are merged; annotations between
the remaining entries are then standardized. It would appear that
attempts to standardize growing sets of similar entries is having a
detrimental effect on the quality of both individual entries and the
overall database.

In addition to being used as a quality measure, the approach
described here could be used for artefactual error detection. Our
early analysis identiﬁed information with no biological signiﬁcance
(copyright statements) included within the comment lines.

 

i567

112 /3.IO'S[1211,1110prOJXO'SOIJBLUJOJIIIOIq”Idllq urorJ papeo1umoq

9103 ‘0g isnﬁnv uo ::

M.J.Bell et al.

 

Our focus in this article was on UniProtKB, and we have not
tested across other databases. One database of immediate interest
would be InterPro. The work in this article focuses on protein
annotation; extending this to InterPro would allow us to analyse
protein family annotation which would normalize for the many near
duplicate records of the large protein families found in UniProtKB.
This would require further bulk analysis—however, once data are
correctly extracted, this form of analysis is straightforward and
does not require specialist resources. Analysis of other forms of
annotation would also be interesting; Kalankesh et (11. (2012) has
recently reported on similar results in GO annotation.

Further work analysing additional databases would allow us
to draw more conclusive conclusions regarding the ﬁtting of the
power-law, and consequently the usability of at as a quality metric.
However, our analysis of UniProtKB suggests that this approach
holds promise of being a useﬁil tool for database curators and users
alike.

ACKNOWLEDGEMENTS

The authors thank Allyson Lister for her helpful discussions. We also
thank the UniProt helpdesk for answering our various queries and
Daniel Barrell at EBI for making available the historical versions of
TrEMBL.

Funding: We thank the EPSRC for supporting M. J. Bell

Conﬂict of Interest: none declared.

REFERENCES

Adamic,L.A. and Huberman,B.A. (2002) Zipf’s law and the intemet. Glottometrics, 3,
1437150.

Andorf,C. et al. (2007) Exploring inconsistencies in genome-wide protein function
annotations: a machine learning approach. BMC Bioinformatics, 8, 284+.

Bairoch,A. and preiler,R. (1998) The SWISS-PROT protein sequence data bank and
its supplement TrEMBL in 1998. Nucleic Acids Res., 26, 3842.

Bairoch,A. and preiler,R. (2000) The SWISS-PROT protein sequence database and
its supplement TrEMBL in 2000. Nucleic Acids Res., 28, 4548.

Balasubrahmanyan,V.K. and Naranan, S. (1996) Quantitative linguistics and complex
system studies. J. Quant. Linguisti, 3, 177+228.

Baumgartner,W.A. et al. (2007) Manual curation is not sufﬁcient for annotation of
genomic databases. Bioinformatics, 23, i41+148.

Boeckmann,B. et al. (2003) The SWISS-PROT protein knowledgebase and its
supplement TrEMBL in 2003. Nucleic Acids Res., 31, 365+370.

Brillouin,L. et al. (2004) Science and Information Theory. 2nd Edition (Dover Phoenix
Editions). Dover Publications.

Buza,T.J. et al. (2008) Gene ontology annotation quality analysis in model eukaryotes.
Nucleic Acids Research, 36, 612.

Camon,E.B. et al. (2005) An evaluation of GO annotation retrieval for BioCreAtIvE
and GOA. BMC Bioinformatics, 6 (Suppl. 1), 517+.

Cancho,R.F. and Solé,R.V. (2001) Two regimes in the frequency of words and the
origins of complex lexicons: Zipf’s law revisited. J. Quant. Linguist, 8, 1657173.

Clauset,A. et al. (2009) Power-law distributions in empirical data. SIAM Rev., 51, 661+.

Curwen,V. et al. (2004) The Ensembl automatic gene annotation system. Genome Res.,
14, 942950.

Dolan,M.E. et al. (2005) A procedure for assessing GO annotation consistency.
Bioinformatics, 21 (Suppl. 1), i136+il43.

Ferrer,R. (2005) The variation of Zipf’s law in human language. Eur Phys. J. B, 44,
2497257.

Ferrericancho,R. (2005) Decoding least effort and scaling in signal frequency
distributions. Physica A, Stat. Mech. Appl., 345, 275+284.

Flesch,R. (1948) A new readability yardstick. J. Appl. Psychol., 32, 2217233.

Gilks,W.R. et al. (2002) Modeling the percolation of annotation errors in a database of
protein sequences. Bioinformatics, 18, 164171649.

GO Consortium (2011) Guide to GO evidence codes.

Gross,A. et al. (2009) Estimating the quality of ontology-based annotations by
considering evolutionary changes. In DILS ’09: Proceedings of the 6th International
Workshop on Data Integration in the Life Sciences. Springer-Verlag, Berlin,
Heidelberg, pp. 71787.

Ha,L.Q. et al. (2006) Zipf and type-token rules for the English, Spanish, Irish and latin
languages. Web J. Formal Comput. Congni. Linguist, 8, 142.

James,K. et al. (2011) Multiple gold standards address bias in functional network
integration. Technical Report I 302. University of Newcastle Upon Tyne.

Jones,C. et al. (2007) Estimating the annotation error rate of curated GO database
sequence annotations. BM C Bioinformatics, 8, 170+.

Kalankesh,L. et al. (2012) The language of gene ontology: a zipf’s law analysis. BM C
Bioinformatics, 13, 127+.

Laughlin,H.M. (1969) SMOG grading-a new readability formula. J. Reading, 12,
63946.

Lord,P.W. et al. (2003) Investigating semantic similarity measures across the Gene
Ontology: the relationship between sequence and annotation. Bioinformatics, 19,
127571283.

Magrane,M. and Uniprot Consortium (2011) UniProt knowledgebase: a hub of
integrated protein data. Database, 2011, bar009.

Pal,D. and Eisenberg,D. (2005) Inference of protein function from protein structure.
Structure, 13, 121430.

Piotrowska,W. and Piotrowska,X. (2004) Statistical parameters in pathological text.
J. Quant. Linguist, 11, 133440.

Roberts,R.J. et al. (2011) COMBREX: a project to accelerate the functional annotation
of prokaryotic genomes. Nucleic Acids Res., 39 (Suppl. 1), D11+D14.

Rogers,M.F. and Ben-Hur,A. (2009) The use of Gene Ontology evidence codes in
preventing Classiﬁer assessment bias. Bioinformatics, 25, 117371177.

Schnoes,A.M. et al. (2009) Annotation error in public databases: misannotation of
molecular function in enzyme superfamilies. PLoS Comput. Biol., 5, e1000605+.

Serrano,M.A. et al. (2009) Modeling statistical properties of written text. PLoS ONE,
4, e5372+.

Stevens,R. and Lord,P. (2009) Application of ontologies in bioinforrnatics. In Staab,S.
and Studer,R. (eds) Handbook on Ontologies, International Handbooks Information
System, Springer, Berlin, Heidelberg, pp. 7357756.

UniProt Consortium (2010) The universal protein resource (uniprot) in 2010. Nucleic
Acids Res., 38 (Suppl. 1), D142+D148.

UniProt Consortium (201 1) UniProt knowledgebase user manual.
http://www.geneontologyorgGO.evidenceshtml

Ussery,D.W. and Hallin,P.F. (2004) Genome update: annotation quality in sequenced
microbial genomes. Microbiology, 150 (Pt 7), 201572017.

Zipf,GlK. (1949) Human Behaviour and the Principle of Least Eﬂort. Hafner Publishing
Co Ltd, new issue of 1949 edn.

 

i568

112 /3.IO'S[1211,1110prOJXO'SOIJBLUJOJIIIOIq”Idllq urort papeo1umoq

9103 ‘0g isnﬁnv uo ::

