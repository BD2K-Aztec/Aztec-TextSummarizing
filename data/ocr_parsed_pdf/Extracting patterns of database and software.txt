BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

G.Duck et al.

 

Each unique resource name is categorized as either a database
(including datasets, ontologies, etc.) or software (including web services,
packages, etc.) at the corpus level (for a full deﬁnition, see Duck et al.,
2012). Categorization is done automatically and is based on several pieces
of information. Firstly, the bioNerDS dictionary entries have already
been categorized as either databases or software wherever possible, and
secondly, we score names by counting the indicative keywords found
around all the name mentions within text during extraction, ﬁnally
taking the majority decision (e.g. more database indicative terms than
software ones). In the cases when there is insufﬁcient evidence to assign
a speciﬁc category, we assigned the ‘unknown’ class to that name.
Overall, we identiﬁed 201 113 mentions of software, and 233920 men-
tions of databases in the corpus, and thus removing 8160 ‘unknown’
mentions (leaving 3872 unique software names and 2143 unique database
names).

(iii) Methods section ﬁltering. To identify only resource mentions that
were used as part of the method presented in an article, we focus on
identiﬁcation of method sections. Previous work in this area has focused
on sentence-level classiﬁcation (‘zoning’), often using a machine learning
approach (Kovacevic et al., 2012). We instead make use of regular ex-
pressions to identify an entire section, rather than individual sentences,
assuming that relevant sentences are placed within the correct section (in
particular for method sections). We use section headings to classify the
text into one of two possible sections: method or non-method.

To engineer regular expressions for section identiﬁcation, we ﬁrst ex-
tracted section heading titles from a random sample of 100 full-text PMC
articles (using the associated XML tags for section headings). These were
grouped and associated manually to form the heading texts with which to
search. Additional variants were generated using simple transformations
(e.g. case, plural, numbered sections, etc.). Once a method heading is
detected at the start of a sentence or paragraph, the associated section
classiﬁcation continues until an alternative (non-method) section heading
is detected. To further evaluate the approach, we selected another set of
100 full-text PMC articles and manually veriﬁed the recognized method
sections. The proposed approach showed a precision of 97.2% with a
recall of 79.2%. All resource mentions that were outside the recognized
method sections where then discarded, leaving 65 451 software mentions
(3289 unique), and 69 466 database mentions (1711 unique).

(iv) Frequent resource pair mining. We next extract common pairs of
resources co-occurring within the same method section, hypothesizing
thatiwith enough dataithey may reveal the main individual experimen-
tal steps in bioinformatics. In particular, for each resource, we pair it with
the resource that immediately follows it in text (based on mention offsets,
ignoring non-resource mentions), aiming also to infer the directionality
within each pair. We assume that given sufﬁcient source material, the
more common ordering in-text will be the ‘correct’ (applicable) one.

We consider two cases: co-occurrence of software mentions, and co-
occurrence of database and software mentions (any combination thereof).
Our dataset generated 22 880 total resource pairs (13 965 unique) for our
software-only set, and 54 562 pairs (29 066 unique) for our databases and
software names set. In the interest of exploring common practice, we
removed pairs that were only extracted from a single document. This
removed 12101 pairs from our software set and 25111 pairs from our
databases and software set.

(v) Statistical ﬁltering and network generation. With the two possible
orders of a given pair, and the occurrence count of each, we use a bino-
mial test to assign a conﬁdence to each pair order, thus providing the
probability of a particular order occurring a given number of times by
chance. From this, we ﬁlter the ordered resource pairs down to only those
that are above a certain conﬁdence threshold using cut-offs at 95 and
99%. Using a conﬁdence threshold of 95% provides 2518 software pairs
(145 unique) and 7001 software and database pairs (297 unique), whereas
using a threshold of 99% results in 1450 software pairs (55 unique)
and 3383 database and software pairs (95 unique). Using these ﬁnal

resource pairs, we generate a network using Cytoscape (Smoot et al.,
2011), where nodes are the resources appearing in those pairs, and a
directed edge between two nodes reﬂects the extracted ordering of the
given resource pair.

3 RESULTS AND DISCUSSION

We present the resulting networks with software—only and soft—
ware and/ or database pairs built using the 95 and 99% conﬁdence
levels, respectively, which have been extracted from 22 376 full—
text articles.

To evaluate the accuracy of the automatic categorization of
resources as databases and software, we manually classiﬁed three
separate lists of 50 resource names:

0 The ﬁrst group had 50 names randomly selected from the set
of all unique names.

0 The second set was selected in proportion to resource men—
tion level counts, enabling repeats of frequent names.

0 The last group of 50 names were selected from the final set
of all names, which occur within the networks presented in
this article.

Table 1 has the resulting accuracies for each of these groups.
Note that the accuracy increases as we test a more speciﬁc
subset of resource name classiﬁcations, showing that the ﬁltering
steps we used during network generation removed the majority
of the incorrectly categorized instances.

3.1 Most common resource pairs

Table 2 shows the most common software pairs extracted with a
minimum of a 99% conﬁdence level. The pairs focus primarily
on sequence search and alignment (generally in that order%a
task central to various bioinformatics analyses. In addition, there
are a couple of sequence assembly pairs (containing Phred,
Phrap, Consed), which are all part of the same package.

To assess the quality of extracted pairs, we separately evalu—
ated all the extracted resource pairs remaining at both the 95 and
99% conﬁdence boundaries. This was done by taking a given
ordered pair, linking it back to the full—text articles whence it was
extracted, and manually assessing whether the pair order agreed

Table 1. Resource classiﬁer evaluation scores

 

 

Total Correct (%) Incorrect Unknown
Group 1 50 28 (56) 5 17
Group 2 50 33 (66) 3 14
Group 3 50 43 (86) 3 4

 

Note: The accuracy of the classiﬁer increases as we test more speciﬁc subsets of
resource names (more ﬁltered groups). An instance is marked as unknown if the class
was inconclusively categorized during manual evaluation, often because of insufﬁ—
cient evidence—this does not necessarily imply that the automatically assigned class
is incorrect (e.g. it is correct in cases where the resource mention is not a false—
positive hit).

 

i602

ﬁm'spzumol‘pmﬂo'sopeuuopuorq/ﬁdnq

Bioinformatics resource usage patterns

 

Table 2. Most common 99% ordered software pairs

 

 

Software-directed pair Total count Contribution
BLAST —> ClustalW 205 14.1
BLAST —> PSI-BLAST 103 7.1
Phred —> Phrap 89 6.1
ClustalW —> MEGA 77 5.3
Cluster —> Tree View 75 5.2
Phrap —> Consed 51 3.5
ClustalW —> PHYLIP 41 2.8
BLAST —> ClustalX 43 3.0
BLAST —> MUSCLE 40 2.8
BLASTN —> ClustalW 39 2.7

 

Note: The contribution is calculated as the total count (after applying all our data
ﬁlters), divided by the 1450 total pairs extracted.

Table 3. Manual evaluation scores for the resource name pairs we
extracted at various conﬁdence levels

 

 

 

Software-only Software/databases

95% 99% 95% 99%
Total pairs 141 53 288 90
Correct (%) 66.7 77.4 45.1 54.4
Partial (%) 13.5 7.5 14.9 12.2
Incorrect (%) 5.7 7.5 12.5 10.0
Same (%) 14.2 7.5 27.4 23.3

 

Note: We ignore pairs resulting from a bioNerDS false—positive match during
manual evaluationithis excluded four and two pairs from the 95 and 99% soft—
ware-only evaluation, and nine and ﬁve pairs from the 95 and 99% databases and
software pairs evaluation.

with the usage of the resources in the associated articles. Each
ordered pair received one of the following classiﬁcations:

0 Correct: Extracted order agreed with the order of resource
use in text.

0 Partial: Extracted order either mostly agrees, or agrees but
there is an important resource step missing. This can also be
the case where there is an indirect link between the
resources.

0 Incorrect: The order extracted contrasts with the order of
usage in the text, or where there is no clear (even indirect)
link between the resources.

0 Same: The two resources are generally used to do equivalent
tasks (e. g. ClustalW and MUSCLE are both sequence align—
ment tools).

Our automated pair extraction approach appears to provide a
good indicator of resource pairing (Table 3). A higher conﬁdence
level resulted in a higher proportion of ‘correct’ name pairs, and
a lower proportion of pairs categorized as ‘same’. We note that
there is an increase in the proportion of ‘incorrect’ pairs for our
software—only set despite a higher conﬁdence boundary (perhaps

because of the small sample size), but the absolute number of
errors decreased by 50%.

3.2 Resource networks

Figure 1 provides a usage network generated by analysing soft—
ware name mentions within the methods section with a 95%
conﬁdence threshold (the edges are weighted according to their
conﬁdence). There is a large central cluster of sequence alignment
tools within this network, which could correlate to the broad
applicability of these resources. This centre is split into homo—
logue detectionisearch (BLAST, PSI—BLAST%and then fol—
lowed by (pair—wise) alignment (ClustalW, ClustalX,
MUSCLE). Leading into this central series of connected compo—
nents are several more domain—speciﬁc resourcesia series of
sequence assembly tools (e.g. Phred, Phrap, Consed), a gene
locator (GLIMMER) and mass—spectroscopy software
(MASCOT). There are two major routes out of the sequence
alignment cluster, with links to the fields of proteomics
(Modeller, PROCHECK, etc.) and phylogenetics (PhyML,
PHYLIP, PAML, etc.). There is also a third route towards
manual alignment editors (Tree View and BioEdit). This pro—
vides an overview of common stages within a bioinformatics
pipeline: sequence assembly, homologue search, pair—wise align—
ment, protein modelling and protein visualization/evaluation.
Importantly, this core route consists of edges with conﬁdence
above 99%. There is also a link between (Mozilla) Firefox and
(Apple) Safari, which remains pervasive throughout many of the
networks we present here. This link seems to originate from fre—
quent comments on supported browsers (e.g. ‘Our web applica—
tion can be accessed through all major web browsers, including
Firefox, Safari . . 

Figure 2 was generated by using both database and software
names to form pairs. This addition of databases helps highlight
where some of the data entry/annotation points are within the
usage graph, assuming that databases are generally used for an—
notation, search and retrieval or deposition. This trend can be
seen within the network. For example, UniProt (Swiss—Prot and
TrEMBL) and the Gene Expression Omnibus (GEO) all directly
link into BLAST; GenBank links into several multiple sequence
alignment tools, while the Protein Data Bank (PDB) links into
various protein prediction and evaluation programs. In addition,
the Gene Ontology (G0) is a data ‘sink’, as it covers a wide
variety of annotation tasks, and there is a linked group of path—
way databases (e.g. KEGG, BioCyc, Reactome).

Interestingly, the extracted order of mentions of databases ap—
pears to be less reliable than that of software. A likely reason is
thatiin a written articleian author is more likely to use a tool
on a database, rather than speciﬁcally getting data from a data—
base before using these with a tool. Additionally, some database
pairs were incorrect because of the structure of a paperiin par—
ticular, a paper may describe the in silico methods used, before
listing all data resource locations at the end of the methods sec—
tion (rather than at their point of use). Figure 2 helps highlight
this as all the edges annotated as incorrect (in red) involve data—
bases, and there are few correct (green) direct database to data—
base links.

If we perform an additional statistical analysis of our results,
using the method of directionality previously published by

 

i603

ﬁm'spzumol‘pmjxo'sopeuuopuorq/ﬁdnq

G.Duck et aI.

 

 

Pe ophet

\ST
Fro.ophet

    

Fig. 1. Usage network for software name resource pairs. mentioned within the methods section only The thickest edges surpass the 99.9% confidence

level. medium 99“,»11 and the thinnest edges have a minimum confidence of 95%. Edges are colour coded according to their evaluated accuracy Green

edges are ((Il’l’t’t 1. orange are partial. red are inwrrctl: blue edges link resources that are categorized as same. for presentation purposes. we only include

pairs (edges) that had at least 10 mentions

Hidalgo e/ ul. (2009). we can draw similar conclusions from our
networks. We see that annotation and statistical resources such
as CO. SPSS. Cytoscape and WebLogo are significant network
sin/rs. whereas common databases like TrEMBL. CEO and PDB
are significant network sources: In general. databases are net—
work sources. and software is a data sink. This conforms to
the common assumption that bioinformatics access data within
databases to perform various in silico analyses with software
resources.

We further evaluated how the resource usage has changed over
time. To do this. we split our dataset into three separate sets:
200472006. 200772009 and 201072012 (inclusive). These were
chosen as a trade—off between the number of ranges (at least
three) and ensuring there was enough data contained within
each range to generate a meaningful network (note that there
is insuflicient data between 2000 and 2003. and incomplete data
for 2013). We then ran our automatic resource pair extractor as
before using a conlidence threshold cut—off of 95%;.

From 2004 to 2006 (Fig. 3a). there is a clear usage bias to—
wards sequence alignment software (BLAST. ClustalW.
ClustalX). Separately there is a triple of sequence asseinbly—
based software (Phred. Phrap. Polyl’hred). and a pair of clus—

tering software and visualization tools (Cluster. Tree View).

There is also a hint of phylogenetics with alignment links to
PAML and PHYLIP.

The 200772009 period features an expansion of resource pairs.
in particular. those using sequence alignment software (e.g. the
addition of MUSCLE and PSI—BLAST: Fig. 3b). In addition.
these now directly link back to the assembly programs. although
the ordering is not well established. Protein modelling also now
features with a pair from Modeller (which predicts protein struc—
tures) to PROCHECK (which evaluates potential protein struc—
tures). as well as a link between TMHMM and HMMTOP
(which are both protein structure predictors). There appears to
be a general theme of visualization with mentions of BioEdit and
Tree View. which are now tied to the main network. The phylo—
genetics field has also grown slightly. with PhyML and MrBayes.
although PAML is no longer directly linked to the main
network.

Finally. from 2010 to 2012 (Fig. 3c). the size of the network
expands once again (in part because of the fact that there is the
most literature published during this time frame). Phylogenetics
has more links than before to sequence alignment (PhyM L.
PAM L. PHYLIP) and has expanded with MAFFT and
RAxML in a disjoint pairing. The protein—based chains have
been expanded with protein visualization software (VM D).

 

i604

[310'sp2umofpmjxo'sopeuuopnotq/ﬁdnq

G.Duck et aI.

 

 

(a) 2004 to 2006 (b) 2007 to 2009

 

ophet

I Pm. M AST
I

c.pe .

(0)2010to 2012

Fig. 3. Usage networks for software names within the given time frames (inclusive). All resource name pairs pass the 95“,»11 confidence level. (a) 2004 to
2006. (b) 2007 to 2009 and (c) 2010 to 2012

 

i606

[310'sp2umofpmjxo'sopeuuopnotq/ﬁdnq

Bioinformatics resource usage patterns

 

Step 1 - Sequence
Alignment

\ Step 2 - Tree
Inference

 

 

 

Zoo LSIDs
.'1 (Li nce \
Id

ers)

 

/ \
\
\\ Step 4 - Tree
\ visualisation
\
M.test \
\
L \
s \
\
\
.‘e y? w
\\
Step 3 - Statistical Testing \
(including Bayesian and \\

Maximum-Likelihood methods) \

Fig. 4. Usage network for software names within phylogenetics papers. The network is annotated into four steps, which correlate to those identiﬁed
previously by Eales et al. (2008). Note that several ambiguous resources can be used to perform multiple steps

bioinformatics articles. The networks formed from these patterns
show a general overview of core bioinformatics tasks and steps.
Although our technique used for network extraction focuses on
only the most used resources, it successfully captures what may
be termed ‘bioinformatics 101’7that is, the core bioinformatics
tasks of selection and alignment of sequences, along with a
common pattern of biological analysis: that DNA sequences
lead to proteins, which then form more complex 3D structures.
Our results are an important ﬁrst step in validating the long—held
assumption that this forms the basis of all bioinformatics re—
search and usage. Our networks also highlight some of the
ways that bioinformatics has changed over time, with the
recent emergence of the fields of next—generation sequencing
and proteomics. Sequence alignment has maintained an import—
ant central role within the ﬁeld and is often used as a link be—
tween other analyses and/or domains.

The results help provide an overview of the resource patterns
used within bioinformatics, which can be considered an approxi—
mation of domain method. Comparing our usage patterns for
phylogenetics with the model previously published by Eales et al.
(2008) shows that our method extraction enables exploration of
common practice within particular fields. For example, if a re—
searcher has some particular data, tool or task in mind, our
results could be used to generate suggestions on what has and
can been done with the data, or what programs could be used for
further research. Speciﬁcally, given any name pair, we can link
back to where in the literature this pair was mentioned, offering
the opportunity to discover what types of research could be per—
formed with those resources.

Future work could involve refining the pattern extraction pro—
cess, perhaps to enable sentence—level pairing using more sophis—
ticated association techniques (e. g. dependency parsing or
syntactic structure). Though our method can provide a
generalized overview of the resources used (and their order of
use), such a refinement could enable more ﬁne—grained workflow
extractionian important step towards method validation and

reproduction, as well as having implications for the spreading
of knowledge and the monitoring of trends within methods.
This could have implications in establishing or suggesting scien—
tiﬁc ‘best practice’, using a variety of criteria, for example time
(the more recent tools/databases, the better), author (focusing on
‘domain experts’), journal (preference for higher impact or spe—
cialist journals) or popularity (common practice). As such, if we
restrict our network links to just those that adhere to a given
‘best’ criteria, this will limit the suggestions we would provide to
just those within a network of best practice.

ACKNOWLEDGEMENT

The authors would like to acknowledge the assistance given by
IT Services and the use of the Computational Shared Facility at
The University of Manchester for our full—text literature analysis.

Funding: This work was supported by a studentship to G.D.
from the Biotechnology and Biological Sciences Research
Council (BBSRC) to G.N., D.L.R. and RS.

Conﬂict of interest: none declared.

REFERENCES

Altschul,S.F. et al. (1990) Basic local alignment search tool. J. Mol. Biol, 215,
4034110.

Bhagat,J. et al. (2010) BioCamlogue: a universal catalogue of web services for the
life sciences. Nucleic Acids Res., 38, W6897W694.

Brazas,M.D. et al. (2011) The 2011 bioinformatics links directory update: more
resources, tools and databases and features to empower the bioinformatics com—
munity. Nucleic Acids Res., 39 (Suppl. 2), W37W37.

Cannata,N. et al. (2005) Time to organize the bioinformatics resourceome. PLoS
Comput. Biol, 1, e76.

Duck,G. et al. (2012) Ambiguity and variability of database and software names in
bioinformatics. In: Ananiadou,S. et al. (ed.) Proceedings of the 5th International
Symposium on Semantic Mining in Biomedicine ( SM BM ). pp. 279.

Duck,G. et al. (2013) bioNerDS: exploring bioinformatics” database and software
use through literature mining. BMC Bioinformatics, 14, 194.

 

i607

ﬁm'spzumot‘pmjxo'sopeuuopuorq/pdnq

G.Duck et al.

 

Eales,J.M. et al. (2008) Methodology capture: discriminating between the “best”
and the rest of community practice. BMC Bioiiy’ormatics, 9, 359.

Hidalgo,C.A. et al. (2009) A dynamic network approach for the study of human
phenotypes. PLoS Comput. Biol, 5, e1000353.

Kovacevic',A. et al. (2012) Mining methodologies from NLP publications: a case
study in automatic terminology recognition. Comput. Speech Lang., 26,
1057126.

Roberts,R.J. (2001) PubMed Central: the GenBank of the published literature.
Proc. Natl Acad. Sci. USA, 98, 3817382.

Smoot,M.E. et al. (2011) Cytoscape 2.8: new features for data integration and net—
work visualization. Bioinﬁ)rmatics, 27, 4314132.

Stevens,R. et al. (2003) Performing in silico experiments on the grid: a users per—
spective. In: Proceedings of the UK e—Science Programme All Hands Meeting.
pp. 43750.

 

i608

/3.IO'S[BIIInOfp.IOJXO'SOIJBLUJOJIIIOIq/ﬂduq

