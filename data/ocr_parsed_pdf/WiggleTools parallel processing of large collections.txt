BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

WiggleTools

 

Table 1. Benchmarking CPU and memory requirements to compute the
sum of 126 BigWig ﬁles (121 GB of data in total)

 

 

Pipeline Stage CPUs Time/CPU (s) RAM/CPU (GB)
1 wiggletools 116 351 mean 0.22 mean
739 maximum 0.32 maximum
bigWigCat 1 378 5.23
Overall 1 16 1090 5.23
2 wiggletools 116 351 mean 0.22 mean
739 maximum 0.32 maximum
bigWigMerge l 3441 6.93
wigToBigWig 1 8887 68.85
Overall 116 13067 68.85
3 bigWigMerge l l l 036 43.73
wigToBigWig 1 9423 75.12
Overall 1 20 459 75.12

 

Note: Several pipelines are compared; hence some components appear multiple
times.

composed to create more complex operators. Iterators can either
traverse the entire genome or a slice of the genome.

2.2 Functionalities

The primary intent of the library is to compute statistics across a
large number of datasets, so that the users need only display one
curve on their genome browser instead of a multitude. For ex—
ample, they can compress a collection of datasets into a median,
as well as compare datasets (e. g. cases versus controls) and gen—
erate a track that denotes the differences between the two sets.

In addition, the WiggleTools library can compute statistics
across genomic positions for a single iterator (area under the
curve, variance) or a pair of iterators (Pearson correlation).
These statistics can be computed across the entire genome or
on regions of interest. For example, it can compute the read
coverage at known promoter regions. Similarly, WiggleTools
can be used to compute a scaled summary proﬁle of the data
on a set of regions.

The WiggleTools library can be used as a C library but also as
a standalone command—line tool. The user has complete access to
the richness of the framework using a simple Polish Notation
language. For example, to generate the sum of a collection of
BigWig ﬁles and write the result into a new Wiggle file, the com—
mand would look like:

wiggletools write sum.wig sum data/* .bw

2.3 Performance

The WiggleTools library has been specifically designed to handle
many ﬁles simultaneously, allowing complex statistics to be com—
puted as directly as possible, with low memory requirements. The
limiting factor of this approach is the I/O access to the files,
meaning that it requires the input ﬁles to be in the local network
of the computation CPUs. However, because of the efﬁcient

indexing of BigWig files, the output can be directly displayed
on a remote server, such as a genome browser.

It is trivial to accelerate computations by slicing the genome
into regions and assigning each region to a different CPU.
A wrapper script is available to do this automatically.
However, one obstacle to this approach is merging the ﬁnal
ﬁles, as the tools provided in the original Kent library quickly
become a performance bottleneck. Therefore, we developed
modiﬁed functions that parallelize the computation of summary
tables (which are crucial to accelerate display at large scales),
which we contributed to the Kent library.

To evaluate the performance of our tool, we downloaded all
the DNAseI hypersensitivity wiggle tracks contained on the
ENCODE January 2011 data freeze (The ENCODE Project
Consortium, 2012) and computed the sum of all these signals
through three pipelines. We first ran the WiggleTools library in
parallel on 116 sections of the genome (up to 30—Mbp long),
producing as many output BigWig ﬁles that were merged with
our new bigWigCat utility. Second, we ran WiggleTools but
merged the output files with the default bigWigMerge utility
(Kent et al., 2010). Finally, we used bigWigMerge to directly
sum the 126 BigWig files. The bigWigMerge tool only creates
ﬂat ﬁles; therefore, a compression and indexing stage, performed
by the wigToBigWig tool, must also be done. The results in
Table 1 clearly show that the ﬁrst pipeline, which took 1090s
to run, is ~12 and 19 times faster than the other approaches,
while requiring a fraction of the memory.

ACKNOWLEDGEMENTS

The authors thank Jim Kent, Petr Danecek and John Marshall
for their advice on using their respective libraries.

Funding: The Wellcome Trust (WTO95908) and EMBL. The re—
search leading to these results has received funding from the
European Union’s Seventh Framework Programme (FP7/2007—
2013) under grant agreement nO 282510—BLUEPRINT.

Conﬂict of Interest: none declared.

REFERENCES

Adams,D. et a]. (2012) BLUEPRINT to decode the epigenetic signature written in
blood. Nat. Biotec/t., 30, 2247226.

Bernstein,B.E. et a]. (2010) The NIH roadmap epigenomics mapping consortium.
Nat. Biotec/t., 28, 104&1048.

Flicek,P. et al. (2013) Ensembl 2013. Nucleic Acids Re.\'., 41, D487D55.

Kent,W.J. et a]. (2010) BigWig and BigBed: enabling browsing of large distributed
datasets. Bioiiy’ormaticx, 26, 22042207.

Li,H. et a]. (2009) The sequence alignment/map format and SAMtools.
Bioinformaticx, 25, 207872079.

Meyer,L.R. et a]. (2013) The UCSC genome browser database: extensions and
updates 2013. Nucleic Acids Re.\'., 41, D6¢D69.

Quinlan,A. and Hall,I. (2010) BEDTools: a flexible suite of utilities for comparing
genomic features. Bioinﬁnmaticx, 26, 8417842.

R Core Team. (2013) R: A Language and Environment for Statistical Computing.
R Foundation for Statistical Computing, Vienna, Austria.

The ENCODE Project Consortium. (2012) An integrated encyclopedia of DNA
elements in the human genome. Nature, 489, 5474.

 

1 009

ﬁre'spzumol‘pmﬂo'sopeuuowrorq/ﬁdnq

