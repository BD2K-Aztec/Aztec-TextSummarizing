ORIGINAL PAPER

Vol. 27 no. 5 2011, pages 655-661
doi:10. 1 093/bioinformatics/btr002

 

Gene expression

Advance Access publication January 21, 2011

Recovering key biological constituents through sparse
representation of gene expression

Yosef Pratl, Menachem Fromerl, Nathan Linial1’2’* and Michal Linial3’*

1School of Computer Science and Engineering, 2Sudarsky Center for Computational Biology and 3Department of
Biological Chemistry, Institute of Life Sciences, The Hebrew University of Jerusalem, Jerusalem, Israel

Associate Editor: David Rocke

 

ABSTRACT

Motivation: Large-scale RNA expression measurements are
generating enormous quantities of data. During the last two decades,
many methods were developed for extracting insights regarding the
interrelationships between genes from such data. The mathematical
and computational perspectives that underlie these methods are
usually algebraic or probabilistic.

Results: Here, we introduce an unexplored geometric view point
where expression levels of genes in multiple experiments are
interpreted as vectors in a high-dimensional space. Specifically,
we find, for the expression profile of each particular gene, its
approximation as a linear combination of profiles of a few other
genes. This method is inspired by recent developments in the
realm of compressed sensing in the machine learning domain.
To demonstrate the power of our approach in extracting valuable
information from the expression data, we independently applied it
to large-scale experiments carried out on the yeast and malaria
parasite whole transcriptomes. The parameters extracted from the
sparse reconstruction of the expression profiles, when fed to a
supervised learning platform, were used to successfully predict
the relationships between genes throughout the Gene Ontology
hierarchy and protein—protein interaction map. Extensive assessment
of the biological results shows high accuracy in both recovering
known predictions and in yielding accurate predictions missing from
the current databases. We suggest that the geometrical approach
presented here is suitable for a broad range of high-dimensional
experimental data.

Contact: michall@cc.huji.ac.il

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on August 18, 2010; revised on December 27, 2010;
accepted on January 1, 2011

1 INTRODUCTION

High-throughput technologies have come to play a central role in
biological and biomedical research in the last decade. Advances in
large-scale technologies on a genome-wide scale produce enormous
amounts of data (Bader et (11., 2004; Barrell et (11., 2009; Beyer et (11.,
2007; Desiere et (11., 2005). Yet, a major goal of functional genomics
is the quest for a comprehensive description of the functions and
interactions of all genes and proteins in a genome.

 

*To whom correspondence should be addressed.

Data such as large-scale gene expression are usually represented
by a matrix, where 11 genes are examined in (1 experimental
conditions. Here, we view such data as a set of n points (vectors)
in d-dimensional space, each of which represents the proﬁle of
a given gene over (1 different experimental conditions. Many
known methods that have yielded meaningful biological insights
in fact seek geometric or algebraic features of these vectors.
For example, analyzing the angles between vectors amounts to
a correlation-based analysis. Similarly, the direction in space
along which these points are most ‘spread out’ correspond to
singular value decomposition (SVD) (Alter et (11., 2000) and its
principal component analysis implementation (Raychaudhuri et (11.,
2000; Yeung and Ruzzo, 2001). These are powerful tools in
providing biological inference (Misra et (11., 2002). In general,
methods and disciplines developed toward extracting information
from expression data include pairwise properties (e.g. correlation,
variance, entropy-based distance) (Amato et (11., 2006; Jeffery et (11.,
2006), clustering (Alon et (11., 1999; Eisen et (11., 1998), Bayesian
networks (Friedman et (11., 2000), information theory, ordinary
differential equations and other sophisticated distance measures
[reviewed in Quackenbush (2006) and Slonim (2002)].

In this study, we applied a different approach to gene expression
data analysis. The geometric principle that underlies it is very natural
and different from existing methods, though it is close in spirit,
and inspired by recent advances in compressive sensing and sparse
signal recovery (Candes, 2008; Candes and Tao, 2005; Donoho,
2006). A simple probabilistic consideration implies the following
geometric claim: given a set of 11 randomly chosen points in the
d-dimensional space, it is ‘very unlikely’ that a linear subspace Y
exists where more than dim(Y) points of the chosen points reside
‘very close’ to Y (see Section 3).

In this study, we present a natural, yet unexplored, approach for the
seemingly exhausted problem of gene expression analysis. Adopting
a sparse signals reconstruction mindset, we recover a support set
of genes for each gene in a genome. Geometrically, we uncovered
linear subspaces that are overpopulated with expression proﬁles
in the multidimensional space of the experiments set. We could
verify the robustness and signiﬁcance of the sparse reconstructions
using measures intrinsic to the method and data. Formally, we are
interested in subsets S of our n-point set that (nearly) resides on a
subspace of dimension strictly smaller than |S|. Having found such
sets, several immediate questions suggest themselves: (i) are these
ﬁndings robust? (ii) If they are robust, can we directly interpret
their biological meaning? (iii) Can such representation uncover
meaningful structures? (iv) Does the method generalize? In this

 

© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 655

112 /3.Io's[Bruno[pJOJXO'sorwurJOJurorqﬂ:duq 11101} pepeolumoq

91oz ‘Og anﬁnv uo ::

{Prat et al.

 

article, we answer these questions by considering gene expression
alone and testing datasets coming from the transcriptomes of the
budding yeast Saccharomyces cerevisiae and the malaria parasite
Plasmodiumfalciparum.

A conceptually new method that we call SPARCLE (SPArse
ReCovery of Linear combinations of Expression) is introduced.
It is inspired by the plausible assumption that expression data,
when considered over a broad range of experimental conditions,
encodes profound layers of systematic (yet hidden) behaviors. We
further conﬁrmed the stability and robustness of SPARCLE results
for entire transcriptomes under perturbations to the data. Extracting
features from the geometric parameters of SPARCLE’s results, and
training AdaBoost, a machine learning platform, to exhaustively
reveal pairwise associations between gene ﬁinction [represented
by Gene Ontology (GO) annotations and by the protein—protein
interaction (PPI) map] conﬁrmed the principal information encoded
by the geometric-based representation. The generality of the method
is conﬁrmed by applying it to both the knowledge-rich yeast model
and the poorly annotated malaria parasite proteome.

2 SPARSE REPRESENTATION OF EXPRESSION

We wish to discover linear dependencies within groups of expression
proﬁles, using ﬁill transcriptome mRNA expression measured under
a wide range of environmental conditions. Given an objective gene
expression proﬁle, one would seek, then, the smallest number of
proﬁles, whose linear span contains the expression proﬁle of the
objective gene. Formally, this is expressed as the following problem:

minllxllo

(P0) s.I.Ax = b

HereA e RdX" is a matrix of RNA expression levels of 11 genes (the
entire genome excluding the objective gene) measured in (1 different
experiments, b 6 Rd is the vector of expression levels of the objective
gene in the (1 experiments, and x e R" are the n optimization
variables, which are n coefﬁcients corresponding to the 11 genes in the
genome. The ||x| |0 notation stands for the L0 ‘norm’ of x, which is
the number of non-zero entries in x (See example in Fig. 1A and B).
We should note here that we consider the common situation where
n is much larger than (1, hence Ax = b is an underdetermined system
of linear equations. In its general form, this optimization problem
is NP-hard (Natarajan, 1995). Fortunately, theoretical developments
in recent years imply that this problem can be efﬁciently solved
in practice, or at least approximated well, in many practical cases.
The theory developed around this problem (Candes and Tao, 2005;
Donoho, 2006; Rudelson and Vershynin, 2008) shows that for
generic instances of this problem, the solution of P0 coincides, at
least nearly, with the solution of the following problem:

minllxlli
(P1) s.t.Ax=b

The advantage is that P1, where the L0 ‘norm’ has been replaced
by the L1 norm, can be stated as a linear programming problem
and is hence efﬁciently solvable. In order to apply this method to
noisy biological data, we use a relaxed form ofP1:

minllxlli

(P8) s.t.||Ax—b||1§8

 

Frequency
m
o
O

 

E;
o

 

.. .n. . 5. .

B .i' :1
5:05 I
300
+
I! — '
20 60 BO

 

oo 40 ‘
Support SIZe

VKRUMW
o
vDLzle

VPRUSIIW

VFLmnw

      

Fig. 1. Sparse reconstruction of yeast genes expression proﬁles by
SPARCLE. (A) Support sizes of the solutions to the SPARCLE optimization
problem (the number of genes used to reconstruct each particular gene), for
all 6254 yeast genes analyzed. (B) The expression proﬁle reconstruction for
MEPl (ammonium transporter) as recovered by SPARCLE. The expression
proﬁle of the gene (bottom) is displayed as a linear combination of the
proﬁles of its supporting genes, with their corresponding coefﬁcients (left).
For comprehensibility. only the 15 genes with the largest absolute value
coefﬁcients are shown, as well as a third of the 85 conditions. (Asterisk)
transmembrane transporters; (dagger) oxidationireduction proteins; (double
dagger) ammonia-related processes. (C) Genes in the support of MEPl. The
objective gene (MEPl) is indicated by a red square. Note that the majority
of the genes are part of a PPI network. (D) Sample of four objective genes
(marked by red squares) whose supports are indicated by poor connectivity
and a fragmented PPI network. PPI connectivity is retrieved from the BioGrid
(http://thebiogrid.org/) repository. Graphics are based on Pathway Palette
(Askenazi at (11., 2010).

where 8 is a sufﬁciently small noise parameter. We use a linear
programming solver to solve this optimization problem, for each
gene in the dataset as an objective gene in its turn. This is followed
by an intrinsic assessment of robustness. We refer to this combined
procedure as SPARCLE.

3 METHODS
3.1 Datasets

Gene expression measurements were extracted from the GEO database
GSE11452 (Knijnenburg at (11., 2009) and consist of a microarray
compendium of 170 steady-state chemostat cultures of S.cerevisiae, which
encompass 55 unique environmental conditions. The full data consists of
9335 Affymetrix probes, representing the full S.cerevisiae transcriptome. We
used a set of 6254 genes, after elimination of most non-coding transcripts
including transposons, tRNAs and rRNAs, and selecting one probe for each
coding gene. The same ﬁlters were applied to GEO database GSE19468 of the
malaria parasite P. falciparum. We used a set of 208 microarray experiments
that cover 4365 genes from Pfalciparum (Hu et (11., 2009).

3.2 Solving the SPARCLE optimization problem

The expression dataset was divided into two sets of experiments, where
one was used for the unsupervised learning of sparse representations, and
the other was left aside for a cross-validation test of robustness. The

 

656

112 /3.Io's[Bruno[pJOJXO'sorwurJOJurorqﬂ:duq 11101} papeolumoq

91oz ‘Og anﬁnv uo ::

Geometrical analysis of gene expression data

 

problem was solved using the matrix A of 85 (experiments) X6254 (genes),
for Scarevisiae, and 104 (experiments) X4365 (genes), for Pfalciparum.
Repeatedly, each column (85, or 104, coordinate gene expression proﬁle) is
chosen as b in (PS) and is removed (for this single iteration) from the matrix
A. The optimization problem was solved as a linear programming problem
using Matlab’s linprog solver. The noise parameter 8 in (P5) was set to
0.5 (Supplementary Fig. S1). The noise was evaluated using the L1 norm,
permitting an efﬁcient linear programming description. Random partitions
of the data into learning and test sets (ﬁve repetitions) resulted in almost
identical outcome, verifying the independence of the results on the speciﬁc
partitions chosen.

3.3 Robustness of expression proﬁle representations

Biological robustness and validity of the solutions were measured by their
degree of approximation in the unseen data of experiments. Speciﬁcally, we
denote by A’ the unobserved matrix excluding the objective gene, and b’
as the objective gene’s d-dimensional expression proﬁle in the unseen data.
The solution of the minimization problem using the ﬁrst matrix (A) is x*.
We then take 8’ = ||A’x* —b’ | | 1 as the degree of approximation on the unseen
data. When 8’ is small, the solution may be considered as biologically robust,
since the linear combination it describes holds true for a set of biological
experiments not utilized by SPARCLE. In order to assess the quality of 8’ ,
we performed two different tests. In the ﬁrst one, we chose a random support
set for each gene, of the same size as the support chosen by SPARCLE and
calculated coefﬁcients for each support member by solving: minx ||Ax —b| | 1
where b is the objective gene’s proﬁle, and x is a vector of all zeroes but
at the support’s coordinates. Then, using the solution x, we evaluated 8’ as
before; repeating 10 000 times, we estimated the background distribution of
the 8’ value, resulting in a P-Value for each 8’ value.

In the second test, we randomly select (1 genes, reducing the matrix A to
contain only these (1 genes, which produced A 6 Rd W and solve:

(PA) mAinllxlli
s.t.||Ax—b||1<0.5

For each gene, we obtained x and calculated 8’ = ||A’x— b’ | | 1. The choice of
(1 genes was done in order to ensure the existence of a feasible solution in
the optimization problem (as the biological data is noisy, we assume both
matrices A and A have rank (1); repeating this process 1000 times allows
estimation of the corresponding P-Value.

3.4 Normalization and setting the noise measure

The raw expression data were normalized in two ways: (i) the expression
proﬁle for each gene was divided by its maximal value and (ii) for each
experiment/condition, the mean expression value across the entire set of
genes was subtracted from each gene. We further added a column (i.e. a
new ‘gene’) with a constant expression value of 1, and gave it a zero weight
in the minimization problem; this step permitted the free use of a constant
factor in the linear combinations found. We tested several values for the noise
factor 8. Clearly, a larger 8 yields sparser solutions (as the constraints of the
optimization problem are relaxed) but with a less accurate reconstruction of
the objective gene. On the other hand, tighter constraints of smaller 8 values
result in overﬁtting to the noise in the train data. In this article, we describe
results obtained using 8:05. The 8 value was selected to be <5% of the
mean L1 norm of the normalized proﬁles, and such that it will never exceed
20% of any proﬁle’s L1 norm. The assessments and inﬂuence on support sizes
of using different values of 8:025, 8:075 are shown in Supplementary
Figure S 1.

3.5 High-dimensional geometric analysis

We enhanced the mathematical ﬁndings of SPARCLE by direct geometric
analysis of the raw input data. As mentioned above, we View each expression
vector as a point in d-dimensional space. We analyzed the geometric
properties of the data by investigating the convex hull of this set of vectors.

This information was used to quantify the deviation of the expression vectors
of genes from those of others. These quantities were included as features
in leveraging the follow-up supervised learning of biological associations
between genes.

3.6 Measuring GO enrichment

For a given set of support genes found by SPARCLE to reconstruct an
objective gene, GO enrichment was calculated using a hypergeometric test,
with the entire set as a background (Barrell 21111., 2009). Sets were considered
enriched with an annotation if the annotation received a P < 0.05, corrected
for a false detection rate (FDR) of 5%. Hypergeometric probabilities and
FDR were computed directly using Matlab.

3.7 Extraction of feature vectors

The sparse representations found by SPARCLE were condensed into feature
vectors for each pair of genes. These vectors contained both individual
features of each member of the pair and pairwise features. Importantly,
all the features were extracted from the input data (e.g. correlations,
high-dimensional geometric analysis), the output solutions of SPARCLE
(e.g. support sizes, mutual coefﬁcient values) and their intrinsic assessment
values (e.g. 8’); no external features were used. These feature vectors were
used in a supervised learning platform in order to assess the signiﬁcance of
our results.

The following features were extracted from SPARCLE results and the
raw data. They comprise a vector with 40 parameters for each pair of genes,
which was used for the supervised learning. The features (for a pair of genes
1 and j) are as follows: (i) coefﬁcient of each gene in the expression proﬁle
of the other, as reconstructed by SPARCLE (non-zero if gene 1 is in the
selected support for gene j and Vice versa). (ii) The number of genes in the
intersection of the two supports as recovered by SPARCLE. (iii) The number
of supports containing both of the two genes. (iv) The L1 distance of each
gene’s expression proﬁle from the convex hull of the other genes” vectors, as
recovered by the high-dimensional geometric analysis (Section 3.5). (V) The
Euclidean distance of the expression proﬁle of gene 1 from the subspace
spanned by gene j’s supporting proﬁles and Vice-versa. (Vi) Support size
for each gene. (Vii) Number of appearances in other supports for each
gene. (viii) Average and SD for features (i)%vii) over 20 perturbation runs
of SPARCLE on the same data (where 25% of the genes were randomly
removed each time). (ix) Pearson’s correlation between is and j ’5 expression
proﬁles, for both the normalized and unnormalized expression data. (x) For
each gene, the mean, median and SD of feature (ix) over the entire set.

All listed features (i)%x) were used in the supervised learning of shared
GO annotations and PPI by the AdaBoost algorithm. To test the principal
information from SPARCLE, we separated features (ix), (x) for a direct
evaluation of the contribution of features that can be extracted directly from
the raw data. We denoted the analysis based on AdaBoost using features (ix),
(x) collectively as Correlations+AB (Fig. 4, Figs S37S7).

3.8 Prediction of gene associations

The G0 is structured as three directed acyclic graphs (DAG): the cellular
component (CC), the biological process (BP) and the molecular function
(MF) ontology. Each term, used to annotate genes, resides at a different
depth with respect to its root (CC, BP or MP). The deeper the term resides
in the graph, the higher its annotation resolution, i.e. it is more speciﬁc
(as illustrated in Supplementary Fig. S2). In order to label two genes as
associated by similar GO terms, one should ﬁrst choose the resolution of
interest. We choose to measure the depth of the term as the length of the
shortest path from the root to the term in the DAG. We tested our predictions
both at low resolution (close to the root) and at high resolution (deep in
the GO structure, i.e. speciﬁc annotations). The low-resolution depth was
chosen as the lowest level of description where <50% of the gene pairs
would be considered as associated with a GO term (depths 5, 2 and 1 for
CC, BP and MF, respectively, for the yeast data and depths 3, 1 and 1 for the

 

657

112 /3.Io's[Bruno[pJOJXO'sorwuiJOJurorqﬂ:duq moi; papeolumoq

91oz ‘Og isnﬁnv uo ::

{Prat et al.

 

malaria parasite data). The high-resolution depth was chosen as the highest
level of description where at least 1% of the gene pairs would be assigned
the same annotation (depths 11, 8 and 7 for the yeast and depths 7, 5 and
5 for CC, BP and MF, respectively for the malaria parasite). In addition to
using the depth measure for resolution, we also applied the GO-Slim (Barrell
at al., 2009) set of manually selected GO terms, constructed to eliminate the
hierarchical structure of G0.

3.9 Interpreting the results of supervised learning

We trained the AdaBoost method (Freund and Schapire, 1997) to classify
the feature vectors as positive (i.e. same GO annotation) or negative for
biological association. The training set included 15 000 randomly selected
pairs, half positively and half negatively labeled. The test set contained
200 000 randomly selected pairs that were not used in the training set, again
half positively and half negatively labeled. We applied a simple threshold on
the AdaBoost raw classiﬁcation values in order to assign conﬁdence values to
its classiﬁcations. The conﬁdence level granted a tradeoff between coverage
and accuracy. In essence, this requires higher conﬁdence in making any
classiﬁcation at all, hence refusing to classify some of the examples. In order
to obtain x% coverage, we ignore all but the x% highest positive classiﬁcation
values and x% lowest negative values.

3.10 Comparing predictions

We compared SPARCLE-based learning by AdaBoost to three other methods
of predicting associations among genes. First, we used AdaBoost to learn
associations using only correlation-related features. Second, we used the
correlation-based transitive shortest path (SPath) evaluation method (Zhou
21111., 2002). Brieﬂy, an undirected graph is constructed, with genes as nodes
and edge weights 1 — P, where P = the Pearson’s correlation between the pair
(for P 30.6). A shortest path was then constructed between each pair, and
its weight was used as an estimator for a distance between the genes. Lastly,
we used the absolute value of the Pearson’s correlation between genes as a
measure of their association, applying a conﬁdence level.

3.11 Inspection SPARCLE-based predictions

We chose to manually test the possibility that the false predictions are due
to incomplete labeling of gene products by GO annotations. To this end,
we sampled a set of 10 predicted associations (gene pairs) from the yeast
data, which were not annotated as being associated (false positives), and
compared them with a random sample of 10 pairs predicted as not associated,
conforming to GO annotation [true negatives (TNs)]. This process was
done for all three GO subontologies (CC, BP and MF); hence, 60 pairs
were manually investigated (Supplementary Table S3). For each pair, a
shared annotation (if found) was retrieved from a literature-based association
protocol (Jenssen at al., 2001). Further analysis included the use of PPI
networks based on the BioGrid (Stark et al., 2006) and STRING (von
Mering at al., 2003) experimental data servers. When the servers found an
association, they also returned a P-Value for the connection. The minimal
number of intermediate nodes connecting a pair of genes in the network was
retrieved using Pathway Palette (Askenazi at al., 2010).

4 RESULTS

To demonstrate the utility of SPARCLE on gene expression data,
we analyzed two very large experimental datasets: from the yeast
S.cerevisi(1e and from the malaria parasite Pfalciparum composed
of 170 and 208 experiments and covering 6254 and 4365 genes,
respectively. While the SPARCLE methodology is not restricted by
the type or source of data, we used mRNA expression measurements
from Knijnenburg et (11. (2009), which constitute a microarray
compendium of chemostat cultures of Scerevisiae that cover 55
unique growth conditions, including nutrient-limiting substrates,

>
u:
S

 

m
o

   

Randomized CV—soore
8
Randomized CV—score
N
O

0

Support optimized from

Random suppon ofsame size g5 mndum genes

 

 

 

 

o
on

40 40

1(SPARCLEOCV-scoriieo 1 (SPARCLEOCV-scorgo
Fig. 2. Cross-validation tests for SPARCLE robustness. (A) Comparison
of the cross-validation (CV) scores for each reconstructed support for an
expression proﬁle with the score obtained for a random support of the same
size; note that lower scores correspond to a more robust predictive power.
(B) Comparison of the CV scores for each reconstructed support for an
expression proﬁle with the score obtained by a restricted SPARCLE run over
85 random proﬁles (see Section 3). The SPARCLE results are consistently
better than random. For the ﬁrst test (A) all 6254 results received P < 10‘6,
for the second test (B) 4633 results received P<10_6, and another 445
received P < 0.05.

growth rate, aeration, pH and temperature. This dataset was divided
randomly into two equal-sized sets of d = 85 experiments covering
n=6254 yeast genes. Our matrix has ﬁill row rank (1:85 and
linear algebra implies that the smallest support (of a solution to P0)
will never exceed (1. Indeed, the coefﬁcient vectors obtained were
considerably sparser with an average support size of 67 (Fig. 1A).
Thus, our goal of achieving a ‘short’ compact linear representation is
achieved. To ensure robustness, half of the experiments (85) were not
used for such representation, and were reserved for the purpose of
cross-validation and evaluation. Random partitions of the data into
two parts were performed ﬁve times with essentially identical results
(see Section 3). Following this new geometrical representation of
the data and conﬁrming its stability to perturbations (Fig. 2), we
turned to extracting valuable biological information for the entire
proteomes.

The ﬁrst ﬁinctional test was based on searching enrichment in GO
(Barrell et (11., 2009) annotations. For 10% of the genes, signiﬁcant
enrichment of ﬁinctional annotation could be found among their
set of supporting genes retrieved by SPARCLE. An example is the
gene MEPl (Fig. 1B) for which many of the support members share
annotations (Supplementary Table S1). The statistical enrichments
of GO annotations for a sample of gene supports are shown
(Supplementary Table S2). Furthermore, MEPl is interconnected
with several of the support gene products, as reﬂected by the
connected graph of the PPI network (Fig. 1C). However, for most
genes (90%), an immediate biological interpretation could not be
retrieved from the support set. Typically, the objective gene and its
support gene products are isolated in a PPI network graph (examples
are shown in Fig. 1D).

As SPARCLE results proved meaningful and robust by the
cross-validation test (Fig. 2; Supplementary Fig. S1), we expect
the method to capture hidden information. To this end, we used
SPARCLE results as input for a machine learning procedure
(Fig. 3A). Speciﬁcally, we trained the AdaBoost framework (Freund
and Schapire, 1997) to classify whether each pair of genes has a
reported PPI or not, using information that is only extracted from
the input data itself (i.e. the expression matrix) and the SPARCLE
analysis (see Section 3). Together, the results of SPARCLE, with the

 

658

112 /3.Io's[Bruno[pJOJXO'sorwuiJOJurorqﬂ:duq moi; papBOIII/lAOG

9103 ‘Og isnﬁnv uo ::

Geometrical analysis of gene expression data

 

SPARCLE output: J ’

Feature vaclnr for
support for each gene

each pair o‘igenes

ﬁbre Clive Support
g 9n e for g en 9

Gene pairs l [.I._.}i

@ (Hill. .. iii—E11

 

Features

   

nt— Gun.

Label

 

El I liﬂﬁﬁ'.

 

1— Coefﬁcient

   

 

Correlations ‘
~ G0 Slirn

   

1 00% 20% 100%

50% 50%
Coverage Coverage

Fig. 3. Prediction of PPI and GO annotations. (A) Illustration of feature
extraction for pairs of genes from SPARCLE. Each sparse representation
includes a set of genes and their assigned coefﬁcient. For each pair of genes,
a feature vector was constructed from the properties of their representing
sets. The feature vector also included another high-dimensional analysis,
i.e. distances of each proﬁle from the convex hull of the others. Other
features were obtained directly from the input data (see Section 3). Features
in the illustration: 1, co-occurrence in supports; 11, gene i’s coefﬁcient in
gene j’s support; 111, gene j’s coefﬁcient in gene i’s support; IV, Pearson’s
correlation of the expression proﬁles. (B) Prediction of PPI, as represented
by the STRING database, by supervised learning from SPARCLE results
(SPARCLE+AB). Accuracy is traded off with coverage by applying certainty
thresholds on the classiﬁer output. Other methods for predicting genes
interrelationships are as follows: Pearson’s correlation of the expression
proﬁles (Correlations), and a transitive correlations method (SPath, see
Section 2). (C) Prediction of associations for the GO Slim annotations,
covering CC ontology. For detailed analyses of accuracy coverage tradeoff,
see Supplementary Figure S5 (GO slim) and Figure S5 (PPI).

input expression data, were condensed into feature vectors for each
pair of genes (Fig. 3A).

We tested whether ﬁinctional information that is encoded in the
yeast PPI map can be successfully recovered. Using a conﬁdence
threshold for the classiﬁcation, accurate performance can be traded
off in exchange for providing lower coverage of the data. The results
of the supervised learning were exceptionally good (Fig. 3B). For
50% coverage of the high-conﬁdence predictions, an accuracy of
78% was reached. Even for 100% coverage, the accuracy reaches
70% (Fig. 3B). Recall that the yeast unﬁltered PPI map still exhibits
a high false positive (FP) rate (Wu et (11., 2006). The combined
protocol of the unsupervised SPARCLE method and supervised
learning platform (based on SPARCLE feature vector, Fig. 3A) was
then tested for the task of recovering the GO associations between
genes, with the three ﬁinctional branches covering MF, CC and BP
(Fig. 3C). Speciﬁcally, gene pairs were classiﬁed as sharing, or not
sharing, similar GO annotations.

For comparison, we compare the prediction results to other
correlation-based methods (Fig. 3B and C). While the GO
hierarchical database covers different descriptive resolutions
(Supplementary Fig. S2), our protocol exhibited accurate predictions
at all resolution levels (Supplementary Figs S3—S5). For example,
with 20% coverage at high GO resolution, the accuracy reached
97.6, 91 and 99% for CC, BP and MF, respectively (SPARCLE+AB;
Fig. 4A—C and Supplementary Figs S3—S5). For 100% coverage,
we still achieved 65—72% accuracy for all ontology branches
at low resolution (SPARCLE+AB, Fig. 4A—C), and 73—89%
for the more speciﬁc terms of the high resolution of GO
annotations (SPARCLE+AB; Supplementary Figs S3—S5). An
additional perspective on the SPARCLE+AB method is retrieved
from the tradeoff of sensitivity and 1—speciﬁcity as presented by
the receiver operating characteristic curves. In all tests (for PPI,
GO low and high levels and GO Slim), when SPARCLE+AB and
Correlation+AB are compared a higher sensitivity is measured for
the same speciﬁcity (data not shown).

Next, we tested whether our inference method ‘happens’ to do
well on the yeast as a model system. Indeed, the yeast genome is
extremely rich in annotations and currently 88% of its genes are
associated with some informative GO annotation. Similarly, the
quality and density of the yeast interactome exceed those of any
other model system. We thus repeated the entire protocol for a set
of 208 experiments (Hu et (11., 2009) measuring 4365 Pfalciparum
genes expression levels, from cells exposed to ~30 anti-malaria
drugs. Note that only 5% of the malaria genes are reviewed by
SwissProt, 65% of the proteins are annotated as ‘putative’ and only
46% of the genes are associated with some GO annotations (often
at a low resolution, Supplementary Fig. S7). The SPARCLE-based
protocol again demonstrated high predictive power (Fig. 4D—F;
Supplementary Fig. S7).Finally, we systematically tested the novel
knowledge gained from the above-described protocols (Figs 3 and 4;
Supplementary Figs S3—S5). To this end, we randomly sampled
pairs of yeast genes which were annotated as unrelated and yet
which we predicted to be related (FF) and, for comparison, pairs
of genes which were annotated as unrelated and predicted to be
unrelated (TNs). We manually examined each such pair of genes
for ﬁinctional connections. Remarkably, we veriﬁed our predictions
for interrelations in ~80% of all FP samples, yet could only
detect relations in about a third of the TN set (Supplementary
Table S3). While this manual inspection cannot be considered
to stand on solid statistical ground, it provides support for the
relevance of SPARCLE-based properties, when they are fed into
a machine-leaming platform to empower functional inference.

5 DISCUSSION

The value of the information retrieved by the SPARCLE approach
was demonstrated by using its results as a basis for machine learning
classiﬁcation of gene associations. A systematic and comprehensive
evaluation, ranging from PPI networks and going through all
resolution levels of the GO annotation database, covering the
immensely explored yeast transcriptome and the poorly annotated
malaria-parasite genome, revealed the large potential of using such a
poorly studied geometric approach to extract principal insights from
gene expression data.

Many approaches aim to develop a systematic way to unravel
hidden structure in data. Most studies that looked for biological

 

659

112 /3.Io's[Bruno[pJOJXO'sorwuiJOJurorqﬂ:duq moi; papeolumoq

9103 ‘Og isnﬁnv uo ::

{Prat et al.

 

A Cellular Component B Biological Process C Molecular Function
‘ . . _ ‘ . . : : ‘ _ . . .
"SPARCLE-AB
‘ CorrelalionquB .
0.9 - 09 ' [LB t
'1... . I swam
-.__ .
. "1.." ‘ --. _ " Correlelione I ‘-._
me o . " n.‘ as . "1.1  ' '  ' tie : " o._
)- 0 . . --._‘ a o ‘ ...___- ,- . _I‘.
a -.. -.. ‘11 i -. -1- g - it.
a D? I. ‘. o ' I ' . "'o_‘__ = a? . ‘ n "'-u._._ : r” ' o . "' p .
2. I+H_._._._F::_:-“:::..t§ sot... 'o,".1 ‘_‘ ‘8 '.."-1"
I-F I- . '¢ ¢ ' a
DB .ﬂ11;;; as . F.—.+'_‘ "9 §4H.-.  EIE . . ' ' ' 
‘414 l O 0 H WH*
0.5 05 0.5 '
0 oz 0.4 on as l 0.2 an as us I o 02 a: as as
coverage Coverage Coverage
Saccharomyces cerevisiae
D Cellular Component E Biological Prooeee F Molecular Function
,. . . . ‘. _._..  _ _ _ ‘. 1.... _.__ _ _ _
o . IF‘ f". H—I-I-o_‘._._ _'+' F‘*-O—o+o-._._._
L. ._ «_.__. g
‘ 1 . "'-o..
0.0 ' '1..‘ 0.0 ' i.._ 00 '
'1...
II.".... D
0.5 i ' De - ' . ea ' .
3 E ' o 8 ' .
E ‘ . E . n E ' o -
ﬁn! ' go: "I. Em '0.
d: ' ' o d: ' ° - 4. ' o
O . . O . ' I i .
. ' o . ' ' u .
. . ‘ . T .
as :- - . as -  as - _ -
"e. 0m o—H—Q—c- - I' l It.
as —- iot— Qty. 05. boo-O—O—WO—H—WO—O—WHj 05 H—H‘HH"“""""""
0 DZ I'M 0.6 no i 02 0.4 0.6 0.5 I 0 0.2 0.4 0.6 0.5
Coverage Coverage Coverage

 

 

Plasmodium falciparum

Fig. 4. Prediction of genes’ associations according to GO, where accuracy is deﬁned as in Figure 3. A comparison of SPARCLE-based AdaBoost
learning (SPARCLE+AB), correlation-based AdaBoost learning (Correlations+AB), correlations-based shortest path (SPath) (Zhou et al., 2002) and pairwise
correlations for the raw data (Correlations) for S.cerevisiae (AeC) and Pfalciparum (DeF) transcriptomes. The ontology branches CC (AeD), BP (BeE)
and MF (CeF) were examined. A detailed analysis for all GO resolution levels is shown for Scarevisiae (Supplementary Figs S37S5) and Pfalciparum in

Supplementary Figure S7.

coherence in gene expression data applied clustering (at different
levels of sophistication), revealing the existence of some hidden
‘structure’ in the data. In the current research, comparisons to
clustering results were not carried out, as our goal here is quite
different. The high performance of SPARCLE-based AdaBoost
learning should be considered as evidence for the principal
information that is embedded in the geometric properties of the
data. Therefore, a critical comparison was performed to evaluate
the information that is embedded in correlation (a form of geometric
representation, see below). We show that the correlation performed
very poorly on the malaria data and somewhat better on the yeast
data. In addition, by combining the AdaBoost learning protocol with
the correlation (Correlation+AB), we isolated the contribution of the
AdaBoost learning itself. SPARCLE+AB outperformed these other
approaches for the entire range of accuracy and coverage (Figs 3
and 4; Supplementary Figs S3—S7).

Several aspects of our approach differ from common practices,
and should be elaborated. Most of the activity in the machine-
learning area can be viewed as a modem-day approach to the
classical questions of statistics. The data at hand is considered as
being sampled from some distribution and the question is to get as
accurate as possible a description of that distribution. Our approach
is different.

When data items are (or can be naturally viewed as) points in
space, it is possible to utilize any ‘unexpected’ geometric properties
that this set of points (corresponding to data items) has. In fact, many

successful existing methods in machine learning can be viewed
from this perspective. Thus, if S is a generic set of N points in
d-dimensional space and if N is subexponential in (1, then we do not
expect to see any pairs of points (even nearly) in the same direction
from the origin. If the set of points that is your dataset violates
this statement, you can conclude that it has a geometrically non-
trivial structure. This structural property is very likely a reﬂection
of an interesting (albeit not necessarily interpretable) property in
the domain from which the dataset came. This is our interpretation
of correlation analysis, one of the most reliable workhorses of
bioinformatics. Likewise, a generic point set in Euclidean space
is not expected to be stretched in any special directions in space.
Therefore, if your dataset, viewed geometrically, is stretched in
certain directions it tells you something that can often be used to
discover interesting phenomena. This is our interpretation of SVD
analysis.

Correlations and stretch are only two of the numerous properties
that one may consider in a point set in Euclidean space. Our
work considers another very basic property that we know not to
exist in generic sets: (nearly) linearly dependent sets of points
of cardinality that is substantially smaller than the dimension
of the host space. When such an unexpected property of the
dataset is discovered, two questions suggest themselves: (i) is this
phenomenon only coincidental? and (ii) how can this geometric
property of the data help us learn something about the system
which it represents? In this study, we conﬁrm the robustness of this

 

660

112 /3.Io's[Bruno[pJOJXO'sorwurJOJHrorqﬂ:duq uror} popBo1umoq

9103 ‘0g15n8nv uo ::

Geometrical analysis of gene expression data

 

property under multiple perturbations (Figs 1 and 2; Supplementary
Fig. S1) and the generality for multiple model organisms (Figs 3
and 4; Supplementary Figs S3—S7). The SPARCLE-based machine
learning analysis is a ﬁrst step toward a deeper understanding of the
underlying complexity of the biological gene associations.

In this study, we present a natural, yet unexplored, approach for the
seemingly exhausted problem of gene expression analysis. Adopting
a sparse signals reconstruction mindset, we recover a support set
of genes for each gene in a genome. Geometrically, we uncovered
linear subspaces that are overpopulated with expression proﬁles in
the multidimensional space of the experiments set. We could verify
the robustness and signiﬁcance of the sparse reconstructions using
measures intrinsic to the method and data.

A notable byproduct of the process is the observation that a
biological interpretation of the support sets was mostly indirect. This
is to be expected, since we only consider the smallest support size for
each given vector while often many other representations of the same
vector can be found with subdimensional supports. Another offshoot
is the partial ability to identify unannotated genes, which somewhat
contributed to the high precision in the case of the Pfalciparum
study. Such genes are mostly evolutionary branch-speciﬁc genes,
and identifying them from expression data is stimulating in and of
itself.

Funding: This work was supported by EU Framework VII Prospects
consortium and a grant (ISF 592/07). Y.P. and M.F. are supported
by the Sudarsky Center for Computational Biology.

Conﬂict of Interest: none declared.

REFERENCES

Alon,U. et al. (1999) Broad patterns of gene expression revealed by clustering analysis
of tumor and normal colon tissues probed by oligonucleotide arrays. Proc. Natl
Acad. Sci. USA, 96, 6745£750

Alter,O. et al. (2000) Singular value decomposition for genome-wide expression data
processing and modeling. Proc. Natl Acad. Sci. USA, 97, 10101710106.

Amato,R. etal. (2006) Amulti-step approach to time series analysis and gene expression
clustering. Bioinformatics, 22, 5897596.

Askenazi,M. et al. (2010) Pathway Palette: a rich internet application for peptide,
protein- and network-oriented analysis of MS data. Proteomics, 10, 188071885.
Bader,J.S. et al. (2004) Gaining conﬁdence in high-throughput protein interaction

networks. Nat. Biotechnol, 22, 78785.

Barrell,D. et al. (2009) The GOA database in 2009ean integrated Gene Ontology

Annotation resource. Nucleic Acids Res, 37, D39GD403.

Beyer,A. et al. (2007) Integrating physical and genetic maps: from genomes to
interaction networks. Nat. Rev. Genet., 8, 6997710.

Candes,E. (2008) The restricted isometry property and its implications for compressed
sensing. Compt. Rend. Mat/1., 346, 5897592.

Candes,E.]. and Tao,T. (2005) Decoding by linear programming. IEEE Trans. Inf
Theory, 51, 42034215.

Desiere,F. et al. (2005) Integration with the human genome of peptide sequences
obtained by high-throughput mass spectrometry. Genome Biol., 6, R9.

Donoho,D.L. (2006) For most large underdetermined systems of linear equations the
minimal l(1)-norm solution is also the sparsest solution. Commun. PureAppl. Mat/1.,
59, 7977829.

Eisen,M.B. et al. (1998) Cluster analysis and display of genome-wide expression
patterns. Proc. NatlAcad. Sci. USA, 95, 14863714868.

Freund,Y. and Schapire,R. (1997) Adecision-theoretic generalization of on-line learning
and an application to boosting. J. Comput. Syst. Sci., 55, 1197139.

Friedman,N. et al. (2000) Using Bayesian networks to analyze expression data.
J. Comput. Biol., 7, 601$20.

Hu,G et al. (2009) Transcriptional proﬁling of growth perturbations of the human
malaria parasite Plasmodium falciparum. Nat. Biotechnol, 28, 91798.

Jeffery,I.B. et al. (2006) Comparison and evaluation of methods for generating
differentially expressed gene lists from microarray data. BMC Bioinformatics, 7,
359.

Jenssen,T.K. et al. (2001) A literature network of human genes for high-throughput
analysis of gene expression. Nat. Genet., 28, 21728.

Knijnenburg,T.A. et al. (2009) Combinatorial effects of environmental parameters on
transcriptional regulation in Saccharomyces cerevisiae: a quantitative analysis of a
compendium of chemostat-based transcriptome data. BMC Genomics, 10, 53.

Misra,J. et al. (2002) Interactive exploration of microarray gene expression patterns in
a reduced dimensional space. Genome Res, 12, 111271120.

Natarajan,B.K. (1995) Sparse Approximate Solutions to Linear-Systems. SIAM J.
Comput., 24, 2277234.

Quackenbush,J. (2006) Weighing our measures of gene expression. Mol. Syst. Biol., 2,
63.

Raychaudhuri,S. et al. (2000) Principal components analysis to summarize microarray
experiments: application to sporulation time series. Pac. Symp. Biocomput.,
455466.

Rudelson,M. and Vershynin,R. (2008) On sparse reconstruction from Fourier and
Gaussian measurements. Commun. Pure Appl. Mat/1., 61, 102571045.

Slonim,D.K. (2002) From patterns to pathways: gene expression data analysis comes
of age. Nat. Genet., 32, 5027508.

Stark,C. et al. (2006) BioGRID: a general repository for interaction datasets. Nucleic
Acids Res, 34, D5357D539.

von Mering,C. et al. (2003) STRING: a database of predicted functional associations
between proteins. Nucleic Acids Res, 31, 2587261.

Wu,X. et al. (2006) Prediction of yeast protein-protein interaction network: insights
from the Gene Ontology and annotations. Nucleic Acids Res, 34, 213772150.
Yeung,K.Y. and Ruzzo,W.L. (2001) Principal component analysis for clustering gene

expression data. Bioinformatics, 17, 7637774.

Zhou,X. et al. (2002) Transitive functional annotation by shortest-path analysis of gene

expression data. Proc. Natl Acad. Sci. USA, 99, 12783712788.

 

661

112 /3.Io's[BumoprOJXO'sorwurJOJHrorq”:duq mot} popeo1umoq

9103 ‘0g15n8nv uo ::

