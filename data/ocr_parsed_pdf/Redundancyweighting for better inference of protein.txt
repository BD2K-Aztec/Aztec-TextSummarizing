ORIGINAL PAPER

Vol. 30 no. 16 2014, pages 2295-2301
doi:1 0. 1093/bioinfonnatics/btu242

 

Structural bioinformatics

Advance Access publication April 25, 2014

Redundancy-weighting for better inference of protein structural

features

Chen Yanover1 '*, Natalia Vanetikz, Michael Levitts, Rachel Kolodny4 and Chen Keasar5'*

1Machine Learning for Healthcare and Life-Sciences, Analytics Department, IBM Research Laboratory, Haifa, 3490002,
2Department of Software Engineering, Shamoon College of Engineering, Beer-Sheva 84100, Israel, 3Department of
Structural Biology, Stanford University School of Medicine, Stanford, CA 94305, USA, 4Department of Computer
Science, University of Haifa, Mount Carmel, Haifa, 3498838 and 5Departments of Life Sciences and Computer Science,
Ben-Gurion University of the Negev, Beer-Sheva, 84105, Israel

Associate Editor: Anna Tramontano

 

ABSTRACT

Motivation: Structural knowledge, extracted from the Protein Data
Bank (PDB), underlies numerous potential functions and prediction
methods. The PDB, however, is highly biased: many proteins have
more than one entry, while entire protein families are represented by
a single structure, or even not at all. The standard solution to this
problem is to limit the studies to non-redundant subsets of the PDB.
While alleviating biases, this solution hides the many-to-many relations
between sequences and structures. That is, non-redundant datasets
conceal the diversity of sequences that share the same fold and the
existence of multiple conformations for the same protein. A particularly
disturbing aspect of non-redundant subsets is that they hardly benefit
from the rapid pace of protein structure determination, as most newly
solved structures fall within existing families.

Results: In this study we explore the concept of redundancy-weighted
datasets, originally suggested by Miyazawa and Jernigan.
Redundancy-weighted datasets include all available structures and
associate them (or features thereof) with weights that are inversely
proportional to the number of their homologs. Here, we provide the
first systematic comparison of redundancy-weighted datasets with
non-redundant ones. We test three weighting schemes and show
that the distributions of structural features that they produce are
smoother (having higher entropy) compared with the distributions
inferred from non-redundant datasets. We further show that these
smoothed distributions are both more robust and more correct than
their non-redundant counterparts.

We suggest that the better distributions, inferred using redundancy-
weighting, may improve the accuracy of knowledge-based potentials
and increase the power of protein structure prediction methods.
Consequently, they may enhance model-driven molecular biology.
Contact: cheny@il.ibm.com or chen.keasar@gmail.com

Received on February 18, 2014; revised on April 4, 2014; accepted on
April 19, 2014

1 INTRODUCTION

Mining the riches of experimentally determined data in the
Protein Data Bank (PDB) (Berman et al., 2013a, b; Bernstein
et al., 1977) has been a major source of structural knowledge

 

*To whom correspondence should be addressed.

over the past four decades. In a reverse engineering-like fashion
it allows the derivation of rules and methods for the prediction of
secondary structure (Chou and Fasman, 1974; Garnier et al.,
1978; McGufﬁn et al., 2000; Rost, 1996), solvent accessibility
(Karplus, 2009; Rost, 1996) and trans-membrane regions
(McGufﬁn et al., 2000; Rost, 1996), as well as knowledge-
based potentials (Eisenberg et al., 1997; Liithy et al., 1992;
Samudrala and Moult, 1998; Sippl, 1993; Summa and Levitt,
2007; Tanaka and Scheraga, 1976). These methods and poten-
tials have had a considerable impact on our understanding of the
protein universe and accelerated progress in biology, chemistry
and medicine. This study aims to enhance these data mining
efforts by attacking their major obstacle, data redundancy.

The underlying premise behind data mining of protein struc-
tures is that recurring patterns may result from physical aspects
of protein folding and stability (e.g. the hydrophobic effect)
(Miyazawa and Jernigan, 1985). However, the data, which are
available for mining, are not uniform samples of sequence and
structure spaces. Certain folds (e. g. TIM barrels and G-protein—
coupled receptors) are far more abundant than others in gen-
omes [see Goldstein (2008) for some suggestions of why it is
so]. The PDB content is further skewed by research interests of
the contributing experimentalists and by methodological con-
straints. This bias, often referred to as the ‘PDB redundancy’,
may amplify or diminish the signal of recurring patterns. For
example, the stabilizing effect of the beta-alpha-beta superse-
condary structure may be overestimated because of the abun-
dance of folds that include it (e. g. TIM barrels).

The common solution to data redundancy is to use a non-
redundant subset of the PDB, composed of family representa-
tives. Kabsch and Sander (1983) pioneered this solution using a
62-membered subset of the 75 high-quality entries of the PDB,
leaving out homologs with sequence identity of 50% or higher (a
rather promiscuous threshold by current standards). This ap-
proach has been adopted by numerous studies, and became the
ﬁeld’s norm, with publicly-available and standardized tools for
data culling (Hobohm and Sander, 1994; Wang and Dunbrack,
2003, 2005). Yet, notwithstanding the evident utility of non-
redundant PDB subsets, they have inherent limitations in scal-
ability and descriptive power. First and foremost, they do not
benefit from the rapid growth of the PDB because almost all new
entries are mapped to already known folds [Fig 1; and see also

 

© The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com 2295

112 /310'slvu1nofp103x0"sotJBurJOJutotq/ﬁduq wort papeolumoq

91oz ‘Og isnﬁnV uo ::

C.Yanover et al.

 

 

I—o—New SCOP Superfamilies - e-New Releases]

 

 

.e—o€»‘?’
,a—v"
a

_e-o-o’
.00

 

 

 

1990 1995 2000 2005 2010
Year

Fig. 1. The rapid pace of protein structure determination hardly af-
fects the size of non-redundant databases. The PDB growth rate (gray)
has accelerated in recent years but the rate of new Structural
Classiﬁcation of Proteins (SCOP) superfamily reports (black) dwindled
in the last three releases of the database (versions 1.717175)

Levitt (2009)]. More importantly, non-redundant datasets con-
ceal much of the complexity of protein universe. Speciﬁcally,
they hide the compatibility of diverse sequences with the same
fold and the ﬂexibility of protein structures (Kosloff and
Kolodny, 2008). Our working hypothesis is that this oversimpliﬁed
perspective manifests itself in artiﬁcially ‘bumpy’ distributions of
the measurable features.

An important alternative was presented more than a decade
ago by Miyazawa and Jernigan (1996, 1999), who weighted
structures in their knowledge-based potentials. In those studies,
they considered all the PDB structures (of sufﬁcient quality and
length), yet assigned non-uniform weights to protein chains, so
that the weights of chains with many homologs are scaled down.
Thus, all the data are considered, yet biases are alleviated.
Somewhat surprisingly, we are unaware of any recent studies
that use this approach. Further, to the best of our knowledge,
no study has yet compared its performance with the standard,
representative subset, approach.

Interestingly, the redundancy, which is removed from structural
datasets, is valuable when investigating families of homologous
sequences. There, evolutionary conserved patterns characterize a
family and deviations from these patterns shed light on the
uniqueness of speciﬁc members. The distribution of sequence
similarities across a family is typically uneven; that is, there may
be subsets of sequences that are more closely related. This might
bias the analysis toward patterns that appear in such highly simi-
lar subsets. In this context, however, a non-redundant subset (i.e.
one without recognizable similarities) would consist of a single
sequence, and be devoid of any information. Instead, scholars
have successfully used various weighting schemes that downscale
contributions from large subsets of sequences [see Altschul et a].
(1997), and references therein], most notably for multiple sequence
alignment (Thompson et al., 1994) and sequence search (Altschul
et al., 1997). Structural data mining is a different computational
task: most importantly, it does not focus on a single protein family
but rather must deal with multiple families and account for their
varying sizes. Nonetheless, the success of including more, and
even all, available proteins in the context of search and alignment
tasks, suggests that similar approaches may be valuable in struc-
tural data mining as well.

Our study revisits the redundancy-weighting approach and
provides the ﬁrst systematic assessment of its correctness and

robustness. To this end, we compare interatomic distance distri-
butions, a central component in knowledge-based potentials,
sampled from either non-redundant or redundancy-weighted
datasets; for the sake of completeness, we also consider distribu-
tions that were sampled from an unweighted, redundant dataset.
We estimate the complexity of these distributions by their en-
tropy and observe that the redundancy-weighted datasets have
higher entropy than their non-redundant counterparts. We fur-
ther demonstrate that the higher entropy distributions are more
correct and robust. Our observations suggest that structure pre-
diction methods could beneﬁt considerably from training on re-
dundancy-weighted datasets rather than on non-redundant ones.
This in turn, can improve our understanding of the forces that
shape the protein structure universe.

2 METHODS

2.1 Structure dataset

Our dataset includes 7307 structures of polypeptide chains (in 6956 PDB
ﬁles), at least 40 residues long, solved at 1.510% resolution or better. To
allow a straightforward deﬁnition of local structural features, we broke
each chain into (non-overlapping) segments of peptide-bonded amino
acids, where two consecutive residues are considered ‘bonded’ if the dis-
tance between their Cor atoms is within 10% of the canonical peptide
bond distance (2.95 or 3.810% for cis and trans peptide bond, respectively)
and none is listed as ‘missing’ (in PDB Remark 465, missing residues, or
Remark 470, missing atoms). The resulting set consists of 8876 segments
longer than 20 residues.

These data are split into training and test subsets. The training subset
consists of 6299 structures (7635 segments) released by the end of 2011,
whereas the remaining 1008 chain structures (1241 segments), released
from January 2012 to April 2013, constitute the test set. We compare
the feature distributions obtained from the larger training set with those
inferred using the smaller test set.

This study focuses on Car distance distributions of the 441 possible type
pairs (all combinations over 20 amino acids -l- the wild-card amino acid
X) of residues separated by predeﬁned distances along the sequence (e.g.
20 residues apart). We compare distributions that were inferred using
various weighting schemes and over different sets of protein structures.
In general, the reliability of distributions improves as the number of in-
stances from which they were derived, grows. Figure 4D depicts the
number of residue pairs (20 residues apart) in the training set. Note the
two orders of magnitude difference between the rarest pair (two
Tryptophan residues, 304 instances) and the most common pair (two
Leucine residues, 10 163).

2.2 Weighting schemes

For each chain, we maintain a list of homologs and their aligned regions,
as found by the FASTA (Pearson and Lipman, 1988) sequence alignment
tool (with e-value 5 104). The sets of chains and homology assignments
constitute the vertices and edges, respectively, of a neighbors graph
(Fig. 3). We consider connected components of this graph as homology
subsets; the size distributions of these subsets in the training and test sets
are shown in Figure 2. We follow a common practice [see, for example,
Bull et a]. (2013); Li and Godzik (2006)] and generate a non-redundant
dataset by picking a random representative from each homology subset.
In contrast, redundant and redundancy-weighting datasets use all avail-
able structures.

In this study, we consider ﬁve schemes (Fig. 3): non-redundant,
redundant and three ways for redundancy-weighting. The standard,
non-redundant scheme effectively assigns a weight of l to each feature

 

2296

112 /310'slcu1nofp103x0"sotJBurJOJutotq/ﬁduq wort papaolumoq

91oz ‘Og isnﬁnV uo ::

Redundancy-weighting of protein structural features

 

instance (here, a distance between two Cor atoms separated by a certain
number of residues) from a representative subset of structures. The
redundant scheme, too, effectively associates a weight of l to each fea-
ture, but includes all structures in the set.

The redundancy-weighting schemes use all structures available in
the dataset, while balancing the contributions of protein families with
many PDB entries and ones that have fewer. To this end, these schemes
deﬁne the weight of a feature instance to be inversely proportional to the
number of its homologs.

We implement three redundancy-weighting schemes. The ﬁrst, per-
sequence weighting scheme (R Ws) associates each structure s with a set
of close neighbors, ones with sequence similarity 340% and coverage
350%. The structure’s weight, which is assigned to all its features, is
l/(N(s) -l- l), where N(s) is the number of these neighbors. The se-
cond, per-feature weighting scheme (RWf) assigns the weights individu-
ally to each feature instance. The weight of a structural feature, in this
scheme, is inversely proportional to the number of homologous chains
that align with all of its positions, without gaps. The last scheme, MJ,
follows Miyazawa and Jernigan (1996, 1999) sample weighting. Brieﬂy,
sequence identity between each pair of structures is computed as the
fraction of identical residues in their alignment (Needleman and
Wunsch, 1970); eigenvalue decomposition of the sequence identity
matrix deﬁnes per-sequence weights, which are approximately equal to
the inverse of the number of similar sequences. This weight is assigned to
all the features of the structure.

Homology set size

 

80 -Training set
|:ITest set

w A
O o

% Homology sets

N
o

 

 

« TA 5,9 Noah 15,158 50,99 2,00

Fig. 2. Homology subset sizes for the polypeptide structures in the train-
ing (black) and test (white) sets

NR R

 

3 as 

 8 

2.3 Performance assessment

We quantify the similarity between two distance distributions, P and Q,
by their Jensenishannon divergence (JSD) deﬁned as:

JSD(P; Q) = %(dKL(P, M) + dKL(Q, M» (1)

where M = %(P-l- Q) and dKL is the KullbackiLeibler divergence (Lin,
1991, Equation (4.1) and setting P and Q’s weighs to 0.5). For each
feature distribution (e.g. Euclidean distances between Tryptophan
Car at position i and Histidine Ca at position i -l- 20; see Fig. 4A£),
we deﬁne the robustness of a weighting scheme, W, as the complement
of the JSD between W-induced feature distributions in the training
(P W(Train)) and teSt (P W(Tcst)) sets:

Robustness(W) = l — J SD (Pquain); PW(TC5t)) (2)

Similarly, the correctness of a weighting scheme, for a given feature
distribution, is the complement of the divergence between the scheme’s
test distribution and the standard, non-redundant feature distribution,
inferred over the training set:

Correctness(W) = l — JSD (P Margin); Pvt/(T950) (3)

We also compute the Shannon entropy of W-induced feature
distribution, PW:

Entropy(Pw)= — 212,- I Iogzcnj) (4)
j

where j ranges over all distribution bins.

Finally, we deﬁne the gain in either correctness, robustness or entropy,
as the increase in that measure obtained using weighting scheme W1
compared with W2; for example:

Correctness gain(W1, W2) = Correctness(W1) — Correctness(W2) (5)

3 RESULTS

Distributions of interatomic distances lie at the heart of knowledge-
based potentials and as such are among the most studied features in
PDB data mining. Here, we compare data-mining of such distances
from three types of datasets: redundant, non-redundant and redun-
dancy-weighted. The redundant training and test datasets include
all proteins that were solved before and after the end of 2011,

RWs RWf

t t + 20
Query sequence

Hit 2—C]—
_{:_
Hit4 —L]— £—

Fig. 3. Weighting schemes. A homology graph represents the similarity relations (edges) between chain sequences (nodes); each homology set, i.e. a
connected component in this graph, is depicted in a different shade. The non-redundant and redundant schemes use uniform weights (shown inside the
circles), assigned to a set of representatives and to all available structures, respectively. The two redundancy-weighting schemes, RWs and RWf, associate
each feature (e.g. a speciﬁc pair of Ca atoms, 20 residues apart), with a weight, which is inversely proportional to its redundancy. RWs considers
redundancy at the chain level, that is, all the features of a given chain have the same weight, which is inversely proportional to the number of chains with
which it has considerable sequence similarity and coverage (schematically illustrated as thicker lines). In contrast, RWf considers redundancy at the
feature level. Two features are considered redundant if they are part of an alignment of high identity level and are both complete and continuous. For
example, the query feature instance shown in the illustration is given a weight of 0.5 as its only counterpart is Hit 1

 

2297

112 /310'sleu1nofp103x0"sotwurJOJutotq/ﬁduq 11101} pcpnolumoq

91oz ‘Og isnﬁnV uo ::

C.Yanover et al.

 

A Wga — Hicfm B
NLraining = 550, Ntest = 85

WE“ — YErm
Ntraining = 931, Ntest = 154

C W?“ — $320
Ntraining = 1645, Ntest = 292

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

        

      

0.25 _ 1; x
Q! ‘|
0.2 ,1" 
., ‘1
I. I ‘
0.15 ’ 
E ‘. .
0.1 ’ 
—NR Train
005 —RWf Train
- - -NR Test
0 _ c ---RWftest ‘ ~ ---- -~
10 15 20 25 30 35 4O 10 15 20 25 30 35 b 10 20 30 40
Distance [A] Distance [A] Distance [A]
D Feature sample size E Correctness(NR) F Correctness(RWf) G Correctness gain(RWf,NR)
Pivalus <10'lg

w s w w ‘ 0'02

E S g o 9 u 015

M 5.5 M M ' 5 '

‘F’ ‘F’ l; 03 0.01

a 5 e c

'13 g [3 I! 0.35 0.005
5. g 4'58 a. 5 § [T] as 0
5 R , ‘2 5 R 5 R '

KI 3 KI Kl Q75 »o.oos

S 3.5 S S _

s s 5  

2 3 i g 0.65 -o.o15

L L L

X 2.5 X X .15 -o.02

  

WCHMYFQNFTDRKISEVGALX

M

WCHMYFONPTADAIRKISEVGALX WCHMYFQNFTAIi‘RKISEVGALX WCHMYFQNFTAa‘RKISEVGALX

Fig. 4. Upper panel: Comparing feature distributions. Cot£ot distance distributions between Tryptophan (WI—C“) and Histidine (Hf—31120, A), Tryptophan
and Tyrosine (Yicfzo, B) or Tryptophan and Leucine (LI—Cf”, C) 20 positions apart calculated using non-redundant (red) and redundancy-weighted (R Wf,
blue) schemes over the training (solid) and test (dashed) sets; amino acid pairs are ordered, from left-to-right, by the number of their instances in these
sets (as indicated above each plot). The insets show the similarity of the speciﬁed distributions, where hotter colors indicate greater divergences.
Weighting scheme performance is described in terms of correctness and robustness. Correctness here is the similarity of a weighting scheme-induced
test distributions (dashed) to the one inferred using the non-redundant training dataset (solid, red); these values are shown in the top row of each inset.
Robustness indicates the similarity of weighting scheme-induced distributions over the training and test sets (plots with the same color); these values are
shown along the inset diagonals. Note the improvement (higher similarity) in both measures as the number of instances increases. Lower panel: (D) The
number of Cat pairs with 20 residues separation in the training set (note that the color scheme is exponential). The amino acid types are ordered by
prevalence in the Swiss-Prot data bank (from left to right and top to bottom); X denotes all residue types. (E—G) Correctness of NR (E) and RWf (F)
weighting schemes for all pairs of amino acids is shown as a heat-map; entries corresponding to distributions shown in the upper panel are highlighted
(black boxes). Correctness gain, the difference between the correctness of RWf and NR, is positive (G, blue shades) for the vast majority of amino acid
pairs, indicating an improvement obtained using the former scheme; the one-tailed, paired-sample Wilcoxon signed rank test P-value is shown on the top

respectively, at 1.5Aresolution or better. The training and test non- performance of a weighting scheme W by two quantities: cor-
redundant datasets are subsets of the redundant ones, containing a rectness, which measures how similar is W’s test distribution to
single representative from each set of homologous structures. the non-redundant distribution over the training set (inset’s top
Finally, the three pairs (training and test) of redundancy-weighted row); and robustness, which measures how similar are W’s train-
datasets include the same structures as their redundant counterparts ing and test distributions (inset’s diagonal; see Section 2 for
but the contributions of these structures, or features thereof, are formal deﬁnitions).

weighted. The three redundancy-weighting schemes (see Section 2 Figures 4E and F shows the correctness of CaiCot distance
and Fig. 3) are: (i) a scheme that assigns a single weight to each distributions over all pairs of amino acids when using a non-
polypeptide chainiand all the feature instances computed from its redundant dataset and a redundancy-weighted one.
structureibased on the number of its homologs (RWs); (ii) a Predictably, correctness for both schemes is lower for amino
scheme that computes a per-feature weight based only on homo- acid pairs with a relatively small number (i.e. hundreds) of sam-
1ogs that cover all the positions in a feature (R Wf); and (iii) the ples (top left corner of both heat-maps) compared with pairs with
algebraic sample weighting scheme of Miyazawa and Jernigan many more (i.e. tens and hundreds of thousands) samples (see
(1996; 1999). Fig. 4D for sample counts of each amino acid pair); the

We focus on distributions of CaiCot distances, as a proof of Spearman’s rank correlation between the number of samples
concept. Figure 4, upper panel, shows training and test distribu- and the correctness of NR and RWf is 0.96, P<107100.
tions of Ca distances between three types of amino acid pairs Evidently, the distance distributions derived using the redun-
1ocated 20 positions apart along the sequence: Tryptophan (W) dancy-weighted scheme are, for the most part, more correct
and Histidine (H, left), Tryptophan and Tyrosine W, center) and than those inferred using the non-redundant scheme (Fig. 4G);
Tryptophan and Leucine (L, right). We compute the distribu- Of 441 distributions, one for each amino acid pair, 422 (95.7%)

tions using the standard, non-redundant scheme (NR) or a re- redundancy-weighted distributions are more correct. Moreover,
dundancy-weighting scheme, RWf. The insets in Figure 4A7C the improvement in correctness, or the correctness gain, is greater
depict the similarity of these distributions. We assess the for amino acid pairs with lower number of samples (Spearman’s

 

2298

112 /310'sleu1nofp103x0'sopeurJOJutotq/ﬁduq 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

Redundancy-weighting of protein structural features

 

Correctness gain(R,NR)
P-value = 1.0000

Correctness gain(MJ,NR)

P-value < 10’“

 

Correctness gain(RWs,NR)

P-value < 10’“3

Correctness gain(RWf,NR)

P-value < 10’65

 

 

 

 

 

 

 

0.015
0.01
0.005
0
—o.005
-0.01
—o.o15
WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX '°'°2
AAI AAI AAl AAl
Entropy gain(R,NR) Entropy gain(MJ,NR) Entropy gain(RWs,NR) Entropy gain(RWf,NR)
P—VEIUB = 1.0000 P-value < 10"“5 P-value < 10'55 P-value < 10'58
w 0.2
g 3
lie [I] 0.15
F E 0.1
Q Q
E g 0.05
e T a T a
.+_ D 1 D 1 D
i I; 5 R i
I K. —0.05
E E
v v "0'1
G G
A A —0.15
L L
X X —0 2
WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX '
AA AA AA, AA,
1 i . .
Robustness gain(R,NR) Robustness gain(MJ,NR) Robustness gain(RWs,NR) Robustness gain(RWf,NR)
P-value < 10’24 P-value < 10’73 P-value < 10’72 P-value < 10’73
W w w 0.02
c c c
H H H 0.015
“I “i “t
F F F 0.01
It - B B
P P F, 0.005
E T T T
'1 D D D 0
E R R R
K. K. K. —0.005
E E E
v v v '0'01
G G G
A A A —o.o15
L L L
x x x

 

 

WCHMYFQNPTDRKISEVGALX WCHMYFQNPTDRKISEVGALX
AA AA

WCHMYFQNPTDRKISEVGALX
AA

WCHMYFQNPTDRKISEVGALX _o'02
AA

Fig. 5. Weighting scheme performance. Correctness (top row), entropy (middle) and robustness (bottom) gain of various weighting schemes compared
with the standard, non-redundant scheme. One-tailed, paired-sample Wilcoxon signed rank test P-values are shown above each heat-map; see Figure 2

for more details

rank correlation = 417, P<10%5) for which, as we indicated
above, the correctness is poorer.

A more complete picture is presented in Figure 5, which
compares the standard non-redundant scheme with the four
non-standard ones, over three performance criteria: correctness,
entropy and robustness. As expected, the non-redundant Cat,- 7
Cog-+20 distributions are signiﬁcantly more correct (one-tailed,
paired-sample Wilcoxon signed rank test P<10’6) and asso-
ciated with greater entropy (P<10’16) than the corresponding
redundant distributions. This agrees with the common practice
of preferring non-redundant datasets to redundant ones. Yet,
importantly, all three redundancy-weighting schemes perform
significantly better than the non-redundant scheme in terms of
correctness and robustness, and obtain higher entropy scores; for
example: the median improvement in correctness using RWs
compared with NR is 0.89%, P<10’68.

Finally, Figure 6 compares the performance of all weighting
schemes over Ca distance distributions of residues 5, 10, 20, 50
and 100 amino acids apart. In all these cases, and consistent with
the results for the Ca,- 701,420 distributions (Fig. 5), all three
redundancy-weighting schemes perform better in terms of their
correctness, entropy and robustness, than the standard

non-redundant and redundant alternatives. Among the redun-
dancy-weighting schemes, RWf is the most correct in 4 out of
5 amino acid distances and MJ signiﬁcantly more correct than
RWs for Cat atoms 50 and 100 amino acids apart; RWf’s entropy
values are the greatest for the longer amino acid ranges and M J’ s
for the shorter ones; and, consistently, MJ is the most robust,
followed by RWf. Comparing the non-redundant and redundant
distributions reveals that the latter is always more robust, where-
as the former is more correct in all but the longest range (where
redundant is more correct, P = 0.0002); and obtains greater en-
tropy values in all but the shortest range. These results show that
the redundancy-weighting performs better than the widely-used
non-redundant datasets, in all these measures.

4 DISCUSSION

The dominant approach for data mining of the PDB is to extract
the knowledge from a relatively small subset of non-homologous
structures and consider their homologs (all other structures) as
redundant and, thus, non-informative. Although this approach
circumvents much of the inherent biases in the PDB, it also ar-
tiﬁcially reduces the variability of the structural landscape. An

 

2299

112 /310'sleu1nofp103xo'sopeurJOJutotq/ﬁduq 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

C.Yanover et al.

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Cat - Cat+5 Cat - (3061410 Cat - Cat+20 Cat - Cat+50 Cat - (30614100
Correctness
NR _ NR _ NR _ NR _5
R R R R 5
- - - 40%
MJ MJ MJ MJ 5
- - - —15"g
RWs RWs RWs RWs 5’
- - » -2o
RWf RWf RWf RWf
NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ‘25
Entropy
NR _ NR _ NR _ NR _ NR _5
R A
R _ R _ R _ R _ _10 g
>
MJ MJ MJ MJ MJ _15=LV
RWs RWs Rw RWs RWs 5’
_ . — - -20
RWf RWf Rw RW RW
NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf '25
Robustness
NR _ NR _ NR _ NR _ NR _5
R R R R R a
- - - - 40%
MJ MJ MJ MJ MJ 5
- - - - —15"g
RWs RWs Rw RWs RWs 5’
- - - » -2o
Rw Rw Rw Rw RW
NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ' NR R MJ RWs RWf ‘25

 

 

 

 

 

Fig. 6. Performance summary. Signiﬁcance of correctness (top), entropy (middle) and robustness (bottom) gain of various weighting schemes, all-
against-all (x-axis scheme over y-axis one), for distance distributions of Cat atoms 5 (left column) to 100 (right column) amino acids apart. The base-10
logarithm of one-tailed, paired-sample Wilcoxon signed rank test P-value is shown, with stronger colors indicating more signiﬁcance gains. NR: non-
redundant; R: redundant; MJ: Miyazawa and Jernigan (1996, 1999) sample weighting; RWs: per-sequence redundancy-weighting; RWf: per-feature

redundancy-weighting

alternative approach, which we term here redundancy-weighting,
considers all available structures but assigns them (or features
thereof) lower weights proportionally to the number of homologs
they have in the dataset.

Redundancy-weighting, originally proposed by Miyazawa and
Jernigan almost two decades ago (Miyazawa and Jernigan,
1996), has been rarely used since and, to the best of our know-
ledge, never been systematically benchmarked against the stand-
ard approach. Here, we compare the correctness, complexity and
robustness of feature distributions, which were inferred using
non-redundant and redundant datasets, and three redundancy-
weighting schemes: the algebraic sample weighting of Miyazawa
and Jernigan (MJ) (Miyazawa and Jernigan, 1996), as well as our
novel RWs and RWf weightings. To this end, we quantify and
compare the correctness, complexity and robustness of distance
distributions, which were derived from training and test datasets
according to these schemes.

Our most signiﬁcant contribution is demonstrating that the
three redundancy-weighting schemes outperform the ‘standard’
non-redundant approach in all tested metrics. The MJ scheme,
which is the most robust, is probably not scalable enough for
practical use. This scheme requires an eigenvalue decomposition
of an all-against-all similarity matrix. As the PDB is quickly
approaching the 100 000 structures milestone, such decompos-
ition becomes challenging both in terms of the computational
requirements (space and time) and the numerical stability
(Heath, 2002). RWf, which is the most correct scheme, has a

milder limitation: it requires recomputing of weights for each
structural feature. The RWs scheme is less accurate and robust
than the other two, but does not suffer from these limitations.
Thus, it may serve as a simple, off-the-shelf, general weighting
scheme, which performs better than non-redundant datasets.

Here, we focused on a relatively small set (only a few thou-
sands) of the PDB’s most accurately solved structures (with reso-
lution better than 1.5 A). Focusing on this set had several
advantages: most importantly, the computational cost of explor-
ing alternative weighting schemes is tractable and, in particular,
we could easily calculate the eigenvalue decomposition
needed for the MJ weighting scheme. Notice that homology
is not too common within this set, which includes >50% single-
tons (see Fig. 2). Thus, one could expect that reﬁning the weight-
ing scheme will not have any impact on the accuracy and
robustness when inferring structural features from the set.
However, it does. Thus, we believe that such weighting schemes
can similarly beneﬁt others, even more so when considering
larger subsets of the PDB, culled using more lax experimental
quality thresholds.

While most residueiresidue contact potentials [e. g. Miyazawa
and Jernigan (1996)] consider ‘un-directional’ residue pairs (thus
combining pairs of two same residues with different orders to a
single unique pair), we chose to focus on directional pairs to
increase the dynamic range of the explored features (Fig. 4D).
Notably, the trends shown in Figure 6 are preserved when un-
directional pairs are considered (data not shown).

 

2300

112 /310'sleu1nofp103xo'sopeurJOJutotq/ﬁduq 11101} papeolumoq

91oz ‘Og isnﬁnV uo ::

Redundancy-weighting of protein structural features

 

Importantly, our study shows that the gain in accuracy and
robustness is proportional to the rarity of the studied feature
(Figs. 4 and 5). Current applications of PDB data mining (e.g.
derivation of pairwise potentials and secondary structure predic-
tion) are dominated by highly prevalent features (e.g. contacts
between speciﬁc residues and the three major secondary structure
elements). However, in more subtle applications [e. g. multi-body
potentials (Gniewek et al., 2011) and fragment prediction (Gront
et al., 2011; Kalev and Habeck, 2011; Shen et al., 2013)] the
number of relevant features grows while their prevalence in the
non-redundant dataset drops. We speculate that shifting to the
redundancy-weighting paradigm may be essential for the ad-
vancement of computational structural biology beyond pairwise
potentials and prediction of simple features.

Although two of the redundancy-weighting schemes presented
here are already useful, this study is mostly a proof-of-concept. A
promising route for improvement is to take advantage of rapid
structural search methods (Budowski-Tal et al., 2010) and re-
place the currently used sequence alignments by more reliable
and sensitive structural alignments. Another possible direction
is to focus on domains rather than peptide chains, which often
harbor several, repeating domains (e. g. Zn fingers) and are, thus
redundant by nature. Finally, the weighting scheme may apply
some evolutionary model to gain better estimate of the in-
terdependencies of homologous proteins (Thompson et al.,
1994).

In a wider context, redundant datasets are abundant in other
domains of knowledge, e.g. genomics, natural language process-
ing and computer Vision. While the current work focuses on
protein structure datasets, we hope insights obtained in this
domain can have impact on data mining in other, unrelated ones.

ACKNOWLEDGEMENT

CY. and CK. are grateful to Eitan Bachmat for generous
support. R.K. and CY. would like to thank Yaron Rothman
and Udi Feldman for introducing them to one another.

Funding: C.K. and ML. are supported by BSF (grant number
2009432).

Conﬂicts of Interest: none declared.

REFERENCES

Altschul,S.F. et al. (1997) Gapped BLAST and PSI—BLAST: a new generation
of protein database search programs. Nucleic Acids Res., 25, 338973402.

Berman,H.M. et al. (2013a) The future of the protein data bank. Biopolymers, 99,
2187222.

Berman,H.M. et al. (2013b) Trendspotting in the protein data bank. FEBS Lett.,
587, 103(r1045.

Bernstein,F.C. et al. (1977) The protein data bank: a computer—based archival ﬁle
for macromolecular structures. J. Mol. Biol., 112, 5357542.

Budowski—Tal,I. et al. (2010) FragBag, an accurate representation of protein
structure, retrieves structural neighbors from the entire PDB quickly and accur—
ately. Proc. Natl Acad. Sci. USA, 107, 348173486.

Bull,S.C. et al. (2013) Maximising the size of non—redundant protein datasets using
graph theory. PLoS One, 8, e55484.

Chou,P.Y. and Fasman,G.D. (1974) Prediction of protein conformation.
Biochemistry, 13, 2227245.

Eisenberg,D. et al. (1997) VERIFY3D: assessment of protein models with three—
dimensional proﬁles. In: Carter,C.W. Jr and Sweet,R.M. (eds) Macromolecular

Crystallography Part B, Volume 277 of Methods in Enzymology. Academic
Press, pp 396—404.

Garnier,J. et al. (1978) Analysis of the accuracy and implications of simple
methods for predicting the secondary structure of globular proteins. J. Mol.
Biol., 120, 977120.

Gniewek,P. et al. (2011) Multibody coarse—grained potentials for native structure
recognition and quality assessment of protein models. Proteins, 79, 192371929.

Goldstein,R.A. (2008) The structure of protein evolution and the evolution of pro—
tein structure. Curr. Opin. Struct. Biol., 18, 17(P177.

Gront,D. et al. (2011) Generalized fragment picking in Rosetta: design, protocols
and applications. PLoS One, 6, e23294.

Heath,M.T. (2002) Scienti ic Computing: An Introductory Survey. 2nd edn. The
McGraw—Hill Companies Inc, New York, NY.

Hobohm,U. and Sander,C. (1994) Enlarged representative set of protein structures.
Protein Sci., 3, 5227524.

Kabsch,W. and Sander,C. (1983) Dictionary of protein secondary structure: pattern
recognition of hydrogen—bonded and geometrical features. Biopolymers, 22,
257772637.

Kalev,I. and Habeck,M. (2011) HHfrag: HMM—based fragment detection using
HHpred. Bioinformatics, 27, 31 1&3116.

Karplus,K. (2009) SAM—T08, HMM—based protein structure prediction. Nucleic
Acids Res., 37 (SuppL 2), W4927W497.

Kosloff,M. and Kolodny,R. (2008) Sequence—similar, structure—dissimilar protein
pairs in the PDB. Proteins, 71, 8917902.

Levitt,M. (2009) Nature of the protein universe. Proc. Natl Acad Sci. USA, 106,
11079711084.

Li,W. and Godzik,A. (2006) Cd—hit: a fast program for clustering and comparing
large sets of protein or nucleotide sequences. Bioinformatics, 22, 165871659.
Lin,J. (1991) Divergence measures based on the Shannon entropy. IEEE Trans. Inf.

Theory, 37, 1457151.

Luthy,R. et al. (1992) Assessment of protein models with three—dimensional proﬁles.
Nature, 356, 83785.

McGufﬁn,L.J. et al. (2000) The PSIPRED protein structure prediction server.
Bioinformatics, 16, 404—405.

Miyazawa,S. and Jernigan,R.L. (1985) Estimation of effective interresidue contact
energies from protein crystal structures: quasi—chemical approximation.
Macromolecules, 18, 5347552.

Miyazawa,S. and Jernigan,R.L. (1996) ResidueLresidue potentials with a favorable
contact pair term and an unfavorable high packing density term, for simulation
and threading. J. Mol. Biol., 256, 623$44.

Miyazawa,S. and Jernigan,R.L. (1999) Self—consistent estimation of inter—residue
protein contact energies based on an equilibrium mixture approximation of
residues. Proteins, 34, 49768.

Needleman,S.B. and Wunsch,C.D. (1970) A general method applicable to the
search for similarities in the amino acid sequence of two proteins. J. Mol.
Biol., 48, 4434153.

Pearson,W.R. and Lipman,D.J. (1988) Improved tools for biological sequence com—
parison. Proc. Natl Acad. Sci. USA, 85, 2444w2448.

Rost,B. (1996) PHD: predicting one—dimensional protein structure by proﬁle—based
neural networks. In: Doolittle,R.F. (ed.) Computer Methods for Macromolecular
Sequence Analysis, Volume 266 of Methods in Enzymology. Academic Press, pp.
525539.

Samudrala,R. and Moult,J. (1998) An all—atom distance—dependent conditional
probability discriminatory function for protein structure prediction. J. Mol.
Biol., 275, 8957916.

Shen,Y. et al. (2013) Detecting protein candidate fragments using a structural al—
phabet proﬁle comparison approach. PLoS One, 8, e80493.

Sippl,M.J. (1993) Recognition of errors in three-dimensional structures of proteins.
Proteins, 17, 3557362.

Summa,C.M. and Levitt,M. (2007) Near—native structure reﬁnement using in vacuo
energy minimization. Proc. Natl Acad Sci. USA, 104, 317773182.

Tanaka,S. and Scheraga,H.A. (1976) Medium— and long—range interaction param—
eters between amino acids for predicting three—dimensional structures of pro—
teins. Macromolecules, 9, 9457950.

Thompson,J.D. et al. (1994) CLUSTAL W: improving the sensitivity of progressive
multiple sequence alignment through sequence weighting, position—speciﬁc gap
penalties and weight matrix choice. Nucleic Acids Res., 22, 467374680.

Wang,G. and Dunbrack,R.L. (2003) PISCES: a protein sequence culling server.
Bioinformatics, 19, 158971591.

Wang,G. and Dunbrack,R.L. (2005) PISCES: recent improvements to a PDB se-
quence culling server. Nucleic Acids Res., 33, W947W98.

 

2301

112 /310'S[BHJHO[pJOJXO'SOIJ’BLUJOJIIIOICI”Zduq uteri papeolumoq

9103 ‘Og isnﬁnV uo ::

