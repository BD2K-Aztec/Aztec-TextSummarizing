Bioinformatics, 32(16), 2016, 2457—2463

doi: 10.1093/bioinformatics/btw207

Advance Access Publication Date: 19 April 2016
Original paper

 

Genetics and population analysis

Sparse group factor analysis for biclustering of

multiple data sources

Kerstin Bunte*"’, Eemeli Leppaaho, lnka Saarinen and

Samuel Kaski*

Helsinki Institute for Information Technology HllT, Department of Computer Science, Aalto University, Finland

*To whom correspondence should be addressed.

TPresent address: School of Computer Science, University of Birmingham, Edgbaston B15 2Tl', UK

Associate Editor: Oliver Stegle

 

Received on December 28, 2015; revised on March 14, 2016; accepted on April 10, 2016

Abstract

Motivation: Modelling methods that find structure in data are necessary with the current large vol—
umes of genomic data, and there have been various efforts to find subsets of genes exhibiting con—
sistent patterns over subsets of treatments. These biclustering techniques have focused on one
data source, often gene expression data. We present a Bayesian approach for joint biclustering of
multiple data sources, extending a recent method Group Factor Analysis to have a biclustering
interpretation with additional sparsity assumptions. The resulting method enables data—driven
detection of linear structure present in parts of the data sources.

Results: Our simulation studies show that the proposed method reliably infers biclusters from
heterogeneous data sources. We tested the method on data from the NCl—DREAM drug sensitivity
prediction challenge, resulting in an excellent prediction accuracy. Moreover, the predictions are
based on several biclusters which provide insight into the data sources, in this case on gene
expression, DNA methylation, protein abundance, exome sequence, functional connectivity

fingerprints and drug sensitivity.

Availability and Implementation: http://research.cs.aalto.fi/pml/software/GFAsparse/
Contacts: kerstin.bunte@googlemail.com or samuel.kaski@aalto.fi

 

1 Introduction

Numerous clustering approaches have advanced to extract know—
ledge from sets of e.g. gene expression experiments, when conditions
of the samples are either not known or researchers are interested in
dependencies within or across experiments. Conditions or treat—
ments can affect the expression levels of certain genes only, and
similarly, many genes are likely to be co—regulated under certain
conditions only. For this purpose, biclustering techniques have been
developed (Cheng and Church, 2000; Hartigan, 1972; Lazzeroni
et (11., 2002; Morgan and Sonquist, 1963). Biclustering is tradition—
ally defined as simultaneously clustering both rows and columns in
a data matrix. Depending on the metric and the data, different
approaches have emerged, aiming to cluster genes based on their ex—
pression levels being the same, differing by a constant, or being lin—
early dependent, with respect to different conditions (Madeira and

Oliveira, 2004). Hochreiter et al. (2010) introduced a generative ap—
proach called Factor Analysis for Bicluster Acquisition (FABIA), ac—
counting for linear dependencies between gene expression and
conditions. The biclusters are factors of the measurement matrix,
and hence can be overlapping in both genes and conditions, whereas
many approaches are limited to distinct clusters. Each bicluster can
also include oppositely regulated genes (up— and down—regulated)
across conditions. Similar approaches have been proposed by
Carvalho et al. (2008) and Gao et al. (2014), with the latter one add—
itionally focusing on the inference of gene co—expression networks.
FABIA has also been extended to better suit genotype data
(Hochreiter, 2013).

Waltman et al. (2010) proposed an algorithm for simultaneous
biclustering of heterogeneous multiple species data collections. They
investigate the identification of conserved co—regulated gene groups

©The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2457

9103 ‘Og JSanV 110 salaﬁuv soc] ‘BtHJOJtIBQ 30 AJtSJQAtuf] 112 /310'S[B111n0fp10}x0'SOlJBLUJOJIItth/ﬂduq 11101} popcolumoq

2458

K.Bunte et al.

 

(modules) by comparing genome—wide datasets for closely related
organisms and the evolution of gene regulatory networks. Most
genes are unlikely to be co—regulated under every possible condition,
and exclusive gene clusters cannot capture the complexity of tran—
scriptional regulatory networks. Their proposed approach aims to
identify meaningful condition—dependent conserved modules, inte—
grating data across the same genes present in multiple species.

Inferring bicluster structure jointly from multiple data sources is
potentially more accurate than analysis of a single set, and the dis—
covered relationships between the sources may offer new insights. In
this paper, we extend a recent generative Bayesian modelling ap—
proach, group factor analysis (GFA) (Klami et al., 2015; Suvitaival
et al., 2014; Virtanen et al., 2012). GFA was developed for explora—
tory analysis of multiple data sources (views), resulting in an inter—
pretable group—sparse factorization of the data collection. When the
factors are additionally variable—wise sparse, as a result of introduc—
ing suitable priors, they are interpretable as biclusters of multiple
co—occurring data sources that need not share the same features
(genes; as opposed to Waltman et al., 2010). As a factor model GFA
further shares the favourable properties of FABIA. We demonstrate
its use in a multi—view drug sensitivity prediction task that the previ—
ous bicluster methods could not handle naturally: the approach
shows superior prediction performance, and is able to infer mean—
ingful structure present in subsets of the data.

2 Methods

2.1 Factor analysis

Factor Analysis for Bicluster Acquisition (Hochreiter et al., 2010)
assumes preprocessed and filtered gene expression data Y E IRNXD .
Every row represents a sample and every column a gene. Therefore
the value y,,,- corresponds to the expression level of the jth gene in
the ith sample. A bicluster is defined as a set of rows that are similar
for a set of columns, and vice versa. The model for K biclusters is

K
Y : Zxrtwf. + e, (1)
k:1

where each factor k is defined by an outer product of the lath col—
umns of the factor matrix X E IRNXK and the loading matrix
W E IRDXK, and e E IRNXD is normally distributed noise:
Enid ~ N(0, (73). The factors are the biclusters, with lwdﬁk
ing the (soft) membership of gene d in bicluster k, and )xnya

indicat—

 

likewise

 

for sample 71. Both the W and X are given sparse priors, more specif—
ically component—wise independent Laplace distributions:

1 DKK D _\/i‘w ‘
p(W):(ﬁ) Hﬂe  (2)

1 NKK N _\/i‘ ‘
p(X):(ﬁ) ﬁne *1“. (3)

The parameters are inferred with variational expectation maxi—
mization, see Hochreiter et al. (2010) for details.

2.2 Sparse group factor analysis for biclustering

Group factor analysis has been proposed as an extension to factor
analysis for finding factors capturing joint variability between data—
sets instead of individual variables (Klami et al., 2015; Suvitaival
et al., 2014; Virtanen et al., 2012). It is designed to deal with several
data sources Y“) E RNXD1,...,Y(M) E IRNXDM (called views) of

dimensionality Dm with N co—occurring observations. GFA models
the nth sample of the mth data view as

ylt") ~ N (Vt/("1km of 1D,), (4)

where rm is the noise precision of view m. The loading matrix W‘m)
is given a sparse prior that allows omitting any component [2 from
affecting drug data view YW). This enables a group—sparse factoriza—
tion, where components may be (i) specific to a single data view, (ii)
shared between all the data views or (iii) shared between any subset
of the data views. As we are interested in finding biclusters, we
introduce a prior that is additionally variable—wise sparse, that is,
across the elements of the matrices WW) and X. This is done simi—
larly to how Khan et al. (2014) produced variable—wise sparsity, but
now for both variables and samples to produce biclusters. Namely
we use the following spike and slab priors (Suvitaival et al. (2014)
included sparsity for samples and mentioned the connection to
biclustering, but the interpretation was not explored further.):

ana ~ hng(0, (mfg—1) + (1 —  50 (5)
WE}? ~ 1751'1)N(07 (“if”)? + (1 — 1731))50 (6)

19);}, N Bernoulli(7t,:)) n53 N Beta(a", b") a)? N Gamma(a”, b”) (7)

where the binary 1751",? determines whether the component (bicluster)
Sign at")
determines the scale of the component [2 in view m and nkm) the

k is active in the dth feature of Y“) (for all non—zero n in 17

probability of 173:) : 1. The prior is analogous for samples (i.e. the
rows of the data matrices) through 175:2. Effectively, the spike and
slab prior will set weights that affect the data (likelihood) only little
to 0, which allows direct biclustering interpretations without a need
for arbitrary thresholding afterwards. The model is completed with
a gamma prior for the noise precision parameters rm and uninforma—
tive hyperpriors ([a”, b”,a°‘, bani, bi] : 1).

In this formulation, the data source information (feature group—
ing) is used in three ways: (i) the noise precision (rm) is the same for
all the features in a view, (ii) the binary vector 17):) has a common
probability (Trim) of being active and (iii) the scale of a component
(aim) is shared within a view. With an uninformative Gamma prior,
often called Automatic Relevance Determination prior, this third
property implements the group sparsity. The second property implies
that a specific feature d (in view m) is more likely to be active in a
bicluster, if many of the features in view m belong to the said biclus—
ter, and vice versa. This allows explaining variance that is not present
in all the data sources, but dense in some of them, more robustly.
Given data with significant (source specific) structured variation re—
spective components can help to detect biclusters more accurately.

The formulation above assumes that all the data views have co—
occurring samples. We also extend GFA for joint modelling of datasets
that are paired in two modes (see Fig. 1), i.e. {Y(1’1),. . . ,Y(M1’1),
YO”, . . .Y(M2’2)}, where YWZ) 6 RD1 ’N2 is paired with the features of
Y(1’1). Both the modes will have a set of components identical to the
ones presented above with one exception, and hence we will not repeat
the details of the priors here. The exception is that the View paired in
both the modes is generated from the components of both the modes, as

36.311) N N(WI(-1’1)x,(-1) + ng’2)xl(.2),rﬂ). (8)

As the priors remain conjugate, the model can be inferred using
Gibbs sampling, resulting in linear complexity in both N and D, but

9103 ‘Og JSanV 110 salaﬁuv soc] ‘BtHJOJtIBQ 30 AJtSJQAtuf] 112 /310'S[B111n0fp10}x0'SOIJBLUJOJIIIOIq/ﬂduq 11101} pQPBOIII/lAOG

Sparse group factor analysis for biclustering

2459

 

N2—

N1 y(171)

   

      
 

Y,Yy y(1,1)Y:Y

D1 D2 D3

Fig. 1. Left: four non-overlapping biclusters (coloured blocks) used in the
multi-view data (gray area). Right: The biclusters inferred by GFA

cubic w.r.t. the number of components K. The parameters shown in
this paper, and used in predictive tasks, will be the posterior means.
In the following sections we will test FABIA and GFA in several
simulation studies and a drug sensitivity analysis, incorporating gen—
etic data available from the DREAM project.

3 Simulation study

We show an illustrative example of bicluster inference, generating a
collection of datasets, {Y(1’1),Y(2’1),Y(3’1),Y(1’2)}, with 200 samples
and dimensions (100, 50, 60) for YM), and 100 samples and dimen—
sion (70) for Y(1’2). The data collection was generated with four
biclusters and additional noise with variance 1. The non—zero parts
of x and W for the biclusters were drawn from N(0,1), but trun—
cated between absolute values 1 and 2 for illustrative purposes. The
data structure is shown in Figure 1 (left); for clarity the biclusters
are non—overlapping blocks. We inferred the component structure of
these data using GFA; the posterior mean of the biclusters is visual—
ized in Figure 1 (right). GFA can clearly infer this kind of component
structure very accurately.

GFA has been designed for joint modelling of multiple datasets.
However, when the data consist of one set only, FABIA and GFA
are essentially the same model; in the current implementations there
is the technical difference that FABIA has a continuous valued spars—
ity prior for X and W, whereas GFA implements a discrete choice
with the spike—and—slap. We first investigate the effect of this tech—
nical difference by comparing GFA with FABIA on single—view data
(FABIA1), and then investigate how much multi—view data helps, by
comparing GFA against FABIA for which data are concatenated
into a single matrix (FABIA2).

For the simulation studies, we construct data from the genera—
tive model Eq. (4), with matrices X and W generated such that
each element is either zero or sampled randomly from the normal
distribution N(0,1) to build the bicluster(s). The resulting data
matrices Y are given to the methods, which then return the biclus—
ter estimates xfﬁkwfl. They are compared to the true biclusters to
analyze the models’ performance. FABIA is run with the correct
number of biclusters K, and the results are reported for a range of
thresholds. GFA learns the cluster number by driving unnecessary
ones to zero, and we used a component number 5 above the correct
K. The final biclustering is based on 101 posterior samples (2000
burn—in samples, 20 thinning): if the majority of (qukwfﬁ'zﬁhi are
non—zero in the posterior samples, then ) is assigned to the lath
bicluster, otherwise not. All the simulation studies are repeated

(a) Homogeneous data views
0.05

(b) Heterogeneous data views

 

. ,->(--“X 0.05

   
   

0.00 0.00

1‘: :g‘§§%;:gii:gz:g m
G

,.o" V "
010 ‘1’: '¢ '? $¢$WW ‘ 1? ‘.' ﬁat. 010 ‘1’; "g 'Q $$W ‘ 1? ‘.' ($.17.
1 100 1 100

 

F1
F1

 

 

 

10 10
Number of views M Number of views M

(c) Group-sparse biclusters
0.02

(d) Structured source-specific noise

 

E 0.74

  
 
 

    

5. 6 6m = =6: = = =6 = =6
.1" ¢'?¢§>W‘?Tr?nr. '

1 100 0 1 2 a 4 5 a
Number of structured noise components

 

 

10
Number ofviews M

(e) Multiple partly overlapping biclusters (f) Varying bicluster strength
0.05

 

0.04

 

@Lg-II-e—-<>—o-—e—-o—o-—e

_ ’

 

 

 

 

 

 

use .0, . ..r....l ...|....I ...r....| . ..r....|
100

a 0.1 .
Bicluster strength in supporting views

a 4 5
Number of biclusters

Model: — GFA ---- FA --- FABIA1 - - FABIA2 Threshold X auto 0 0.01 A 0.05 I 0.1

Fig.2. Simulated experiments comparing the abilities of GFA, FA and FABIA
to detect data-generating biclustering. (a) and (b) report the F1 scores over a
varying number of data views (M) present, for homogeneous and heteroge-
neous data collections, respectively. The biclusters are further assumed
group-sparse in (c). In (d), the problem is made more challenging by adding
structured noise on top of the signal, whereas the number of biclusters is var-
ied in (e). In (f), the strength of the bicluster is varied in the supporting views.
FABIA1 uses only the data matrix of interest, whereas FABIA2 and FA have
side information concatenated with it; both FABIAs are reported for thresh-
olds (0.01, 0.05, 0.10) determining the biclusters

10 times and we report the average F1 score for detecting the true
bicluster structure:

2TP

:2TP+FN+FP I9I

F1
where TP, FN and PP denote the number true positives, false nega-
tives and false positives, respectively, summed over all the elements
of the data matrix. To be able to evaluate the effects of different
sparsity priors and inference techniques, we also compare to FA
with similar priors as GFA, using the full concatenated data, and
inferred with Gibbs sampling. This is done be changing Eq. (5) to
Eq. (7) to allow only single 01):) and n21) across the data features, and
by giving each feature independent noise precision 17,).

By default we use M : 5 data views, N: 50 samples, Dm : 100
features per data view and one bicluster active in 70% of the sam—
ples and the features. Bicluster and noise variance in the view of
interest are set to 1. To make the data views heterogeneous, the
other 4 data views are given bicluster and noise variances of
((0.2, 0.2), (5, 5), (0.2, 5), (5, 0.2)). We report the mean performance
of the methods in Figure 2, in six different experimental settings:

(a) All data views are set to be homogeneous having variance of 1 in
the bicluster and the noise residual, and the number of data
views is varied. Due to the homogeneity of the data views, GFA
has no advantage over FA. FA outperforms FABIA on high—di—
mensional large number of views.

9103 ‘Org JSanV uo salaﬁuv 50’] 0211110ther JO AJtSJQAtuf] 112 /310'S[Buln0prOJXO'SOIJBLUJOJIIIOIq/ﬂduq 11101} papeolumoq

2460

K.Bunte et al.

 

(b) Similar to (a), but with heterogeneous data with respect to the
bicluster and noise residual strength. The multi—view approach
of GFA is superior, while FA and FABIA have similar
performance.

(c) Similar to (b), but with sparse biclusters w.r.t. the samples and
group sparse w.r.t. the features (present in all but every 3rd
view). This matches GFA’s assumptions leading to superior
results.

(d) Additional view—speciﬁc noise components (0—6) were added on
top of the bicluster signal (as xmisewloise, each vector element
sampled from N(0,1)). The GFA—type of priors and inference
are clearly more robust against the structured noise.

(e) We evaluated the accuracy of detecting 1—7 partly overlapping
biclusters. GFA outperforms FA, whereas FABIA does not seem
very robust when the number of biclusters increases; using the
additional data can even decrease its performance.

3

The strength of the biclusters is varied for the additional views
(precision or ranging from 10’2 to 102). GFA is more accurate
when the additional views have strong biclusters, and has a simi—
lar performance with FABIA when weaker. FA suffers compared
to FABIA when the additional views get less relevant.

Across all the studies discussed above, GFA was able to detect
the correct number of biclusters (and additional noise components)
exactly in 90.4% of the runs, and overestimated it by 1, 2 or 3 in
9%, 0.4% and 0.1% of the runs, respectively. The extra compo—
nents were modelling artificial structure detected in the residual
noise and did not resemble the bicluster structure. To confirm that
they did not give an advantage in the comparison, we also ran
FABIA with five extra components, resulting in consistently worse
performance compared to the reported runs, where FABIA was
given the true component amount. The standard deviations of the
mean F1 scores, averaged over the 10 independent repetitions,
ranged from 0.003 to 0.01. Inferring a single model took on average
22 s, 45 s, 0.04 s and 0.5 s for GFA, FA, FABIA1 and FABIA2, re—
spectively, demonstrating the efficiency of the EM—algorithm in
FABIA.

Our FA implementation is generally, but not consistently, more
robust than FABIA in bicluster detection with additional data sour—
ces. The advantages of the multi—view setup of GFA (vs concaten—
ation in FA and FABIA2) are most significant when (i) there are
plenty of heterogeneous data views, (ii) the biclusters are group—
sparse or (iii) the data views are highly heterogeneous. These condi—
tions are realistic in real—life applications.

4 Drug response study

The NCI—DREAM drug sensitivity prediction challenge (Costello
et al., 2014) provided publicly available data consisting of gene ex—
pression (GE), RNA, DNA methylation (MET), copy number vari—
ation (CNV), protein abundance (RPPA) and exome sequence (EX)
measurements for 53 human breast cancer cell lines. In the chal—
lenge, expression data were based on Affymetrix Genome—Wide
Human SNP6.0 Array and Affymetrix GeneChip Human Gene
1.0 ST microarrays. RNA sequencing libraries were prepared using
the TruSeq RNA Sample Preparation Kit and whole transcriptome
shotgun sequencing was performed. The Mutation status was ob—
tained from exome—capture sequencing and GenomeStudio
Methylation Module v1.0 was used to express the methylation for
each genome—wide detected CpG locus resulting in values between 0
(completely unmethylated) and 1 (completely methylated) propor—
tional to the degree of methylation at any particular locus. More

details on the preparation of the genomic data for the challenge are
provided by Costello et al. (2014). Each cell line was exposed to 31
therapeutic compounds and the dose—response values of growth in—
hibition were collected. The drug response data was revealed only
for 35 of the cell lines, and the challenge was to predict the response
of the remaining 18 cell lines, ranking them from the most sensitive
to the most resistant.

As the drug response prediction problem is extremely challeng—
ing, we performed the following steps, learning from Costello et al.
(2014), to increase the signal—to—noise ratio: We reduced the dimen—
sionality to the 500 genes with the highest average variance over the
data views, including the overlapping set of 14 genes appearing in
the RPPA dataset. Furthermore, the most predictive data sources for
further analysis were chosen by 7—fold cross validation on the 35
training samples with known drug response values. To compare the
sources the root mean squared error (RMSE), as well as Pearson and
Spearman correlations of the predicted drug responses, were com—
puted averaged over 10 repetitions of the experiments, each with dif—
ferent random splits. We inferred the GFA model for this multi—view
data by ignoring the missing drug response data in the likelihood,
after which the missing values can be predicted from XWW), where
X for the missing cell lines is inferred based on the other data sour—
ces only. The performance of GFA trained with different combin—
ations of data views is shown in Table 1.

The most promising views finally chosen for the bicluster ana—
lysis were gene expression, methylation, exome sequence and RPPA
measurements, leaving out the copy number variation and RNA.
Finally, we ran GFA for the full data (handling the test drug re—
sponses as missing values) and reconstructed the missing data aver—
aged over the posterior samples of 50 sampling chains. We gave the
model a mildly informative prior assuming signal—to—noise ratio of
0.5. All the sampler chains were initialized with K260, allowing
data—driven inference of model complexity (resulting in 48—5 6 com—
ponents). A total of 100 sampled parameters were stored for each
chain (every 20th sample stored after 10 000 burn—in iterations), re—
sulting in an average runtime of 84 min per chain. The performance
was quantified using the same score as in the challenge, that is, the
weighted averaged probabilistic concordance index. We achieved a
score of 0.592, which would have been placed the first in the

Table 1. Averaged 7-fold cross validation results for GFA on the
training set of the DREAM7 drug sensitivity prediction challenge to
identify the views showing best prediction performance (bolded)
forfurther analysis

 

 

Views used RMSE Pearson Spearman
All 1.9 0.031 0.079
GE, MET, CNV, RNA, RPPA 2.3 0.016 0.088
GE, CNV, RNA, RPPA, EX 2.0 0.031 0.078
GE, MET, CNV, RPPA, EX 1.5 0.040 0.085
GE, MET, CNV, RNA, EX 1.8 0.012 0.078
MET, CNV, RNA, RPPA, EX 1.6 0.018 0.058
GE, MET, RNA, RPPA, EX 1.9 0.040 0.089
GE, MET, CNV, RPPA 1.8 0.028 0.071
GE, CNV, RPPA, EX 1.8 0.018 0.074
GE, MET, CNV, EX 1.5 0.024 0.090
MET, CNV, RPPA, EX 2.1 0.020 0.061
GE, MET, RPPA, EX 1.4 0.046 0.087
GE, MET, RPPA 1.9 0.024 0.072
GE, RPPA, EX 1.6 0.016 0.059
GE, MET, EX 1.5 0.042 0.084
MET, RPPA, EX 1.8 0.011 0.075

 

9103 05 JSanV uo sopﬁuv 50'] 0211110111123 10 AJtSJQAtun 112 /310'S[BHJnOprOJXO"SOIJBHIJOJIIIOIq/ﬂdnq 111011 pap1201umoq

Sparse group factor analysis for biclustering

2461

 

challenge (winner model reaching 0.583), indicating excellent pre—
diction performance of GFA on this data, possibly stemming from
the biclustering nature of the model. Furthermore, we ran GFA uti—
lizing data sources paired in two modes in a similar way with add—
itional functional connectivity fingerprints describing the drugs
(FCFP; calculated with PaDEL—Descriptor, Yap, 2011), allowing
joint modelling of biological and chemical effects in the measured
data. The additional chemical view resulted in a slight increase in
the target score, to 0.599. The structure of the latter model is inter—
preted in the following sections, motivated by the excellent predict—
ive performance.

4.1 Robust components

For interpretation purposes we next sought representative point so—
lutions to describe the posterior distributions. Due to the extremely
challenging nature of the problem the total variance explained by in—
dividual components is small. To minimize the risk of analyzing pat—
terns occurred by chance, we searched for components that occur
consistently across the different sampling chains, making the as—
sumption (which was checked manually) that component indices are
reasonably stable within a chain, but can naturally be arbitrarily
permuted between chains. To find the matches between chains we
averaged the components over the posterior samples within their
chain, and compared using cosine similarity. If the similarity of the
best match exceeded the threshold 0.80, we considered the compo—
nents to be the same. Furthermore, we chose to further study com—
ponents found in at least half of all chains, deemed robust in this
procedure. Out of the average 52.6 components inferred by the sam—
pling chains, 25 were on average chosen to the set of robust compo—
nents. Ideally we would infer the model parameters with a single
well—mixing sampling chain, but as the posterior is multimodal (and
we do not want to constrain it artificially) the inference problem is
extremely challenging, and we resort to the described computational
simplification.

We observed that some of the components are very sparse, only
containing one or two cell lines and hence most probably explaining
outliers in the data. Therefore, we will focus the interpretations on
the more dense biclusters only; 3 out of the total 27 biclusters found
predicted 1.26%, 0.06% and 0.11% of the total variance in the test
data (2.89%, 0.3% and 0.98% in the set of active drugs). There was
1 additional bicluster shared with the drug descriptors, but it had no
significant effect to the test data. With the drug sensitivity prediction
of these four components only, we received a target score of 0.591.

4.2 Interpretations of the biclusters

For interpretation purposes, we collected the descriptions of the
drugs and cell lines used in the challenge (Costello et al., 2014).
Some groups of drugs can be identified, which we will abbreviate as:
autophagy (au), cell cycle (cc), metabolism (me), regulation (re) and
signalling growth (gr) drugs, as well as nuclear factor (nf), protease
(pr) and receptor tyrosine kinase (rtk) inhibitors. Furthermore, most
of the cell lines represent a subtype of cancer which can be catego—
rized as basal or luminal.

The bicluster structure of the activity patterns for the first com—
ponent in the drug sensitivity (DS) view, consisting of measurements
of sensitivity of cell lines to drugs, is depicted in Figure 3a.
Component one distinguishes basal and luminal cell types, without
that information being used in the training. The response for all five
cell cycle and all four metabolism drugs is positive or above average
for most of the basal cell lines, whereas luminal cells show negative
activation. Luminal cells respond strongly to regulation drugs,

where the response of basal cells is negative. Component 2 shows
high activity patterns for proteasome and cell cycle drugs as depicted
in Figure 3b. The other components have relatively small biclusters
with only a few active cells and drugs. Component 3, for example,
shows cells that are (un)responsive to rtk inhibitors and otherwise
mixed groups of cells and drugs (see Fig. 3c). The remaining robust
component, in the second mode, was associated with most of the
drugs and drug descriptors, and weakly with approximately half of
the cell lines (strongly with T47DKBLUC).

Due to the large number of genes in the other views, we show
summaries of enrichment of known cancer genes in the components.
We performed hypergeometric tests comparing a varying number of
the most active genes (i.e. genes with the highest mean absolute val—
ues in W corresponding to RPPA and GE views) and random sets of
equal size, for the occurrence of known cancer genes (extracted
from Stephens et al., 2012) in the most predictive components and
all views. Low P—values indicate that the approach is able to detect a
significant amount of known (breast) cancer genes in the top active
genes of the components when compared to random subsets of genes
in the views. Figure 4 shows the results of the hypergeometric test
for two robust components. For component 1 (Fig. 4a) we observe
highly significant cancer activity already in the 10 most active genes
in every view, except in the RPPA data. In the Exome sequence data
we observe significant cancer gene activity independently of the size
of the subset. For component 2 (Fig. 4b) we observe less significant
activity of cancer genes in the gene expression and exome data than
in component 1. However, we find high cancer gene activity in the
methylation view and very high activity of breast cancer genes in
exome sequencing data.

Besides the statistical tests we report the results on the level of in—
dividual genes. We condensed the analysis showing the 50 most ac—
tive genes (in terms of their absolute values) in component 1 in the
gene expression (Fig. 3d) and the RPPA view in Figure 3e.
Component 1 contains proportional and anti—proportional co—regu—
lated genes as indicated by the intensity of the biclusters depicted.
The genes which are known as cancer or breast cancer genes are
marked by a black and gray squares, respectively. Figure 3f summar—
izes the mean participation in biclusters of the cells in seven different
components on the top 10 active genes in each of the views. The left
side contains the list of all cells sorted by their mean absolute values
in the seven most active components, which are depicted in the mid—
dle row. The right side contains the list of top genes clustered by
their mean activity in these components, accompanied by a shortcut
for the view they were taken from and [C] in case they are known
as cancer gene in the literature. Component one (coloured red) con—
tains the biggest biclusters with comparably high mean absolute val—
ues depicted by thicker connecting lines in lots of cells and
genes throughout the different views except the exome se—
quence data. Even only selecting 10 most active genes from each
view delivers at least one known cancer gene. Although components
overlap they also depict relationships of different cells in different
views.

Furthermore, we performed a Gene Ontology (GO) enrichment
analysis on the most active gene sets in the components and gene
related views. In G0 the genes or gene products are hierarchically
classified and grouped into three categories: molecular function (mf)
describing the molecular activity of a gene, biological process (bp)
denoting the larger cellular role and cellular component (cc) depict—
ing where the function is executed in the cell. The enrichment ana—
lysis was performed directly in the GO website (http://geneontology.
org/), which connects the PANTHER (Mi et al., 2013) classification
system with G0 annotations. From each of the gene—related views

9103 05 rsnﬁnv uo sopﬁuv 50'] 0211110111123 10 AJtSJQAtun 112 /310's112u1n0[p101x0'sopeurJOJHtotq/ﬁduq 111011 pap1201umoq

2462

K.Bunte et al.

 

(a) DS: Robust Component 1

Color Key Color Key

Activity in component 1

70,5 02
Value

 

«memes -_ I - - _

wcmrz
111751
)4me
WWW
Hoczm
M
zmsm
MCFY
Home:
mo
vwmmu
sumrssri
Hocura
mm
av...
mums
5
I zmsa
v

 

 

 

at:
in
g

EE8E§§§§§§§§§§§§§§§§§§§§AE  a?
“ ggisagsmgstr tam ‘5  E m 5‘
. §. . S . Z.
subtypes -— II __—
I

thrnavrr
NZ
Farm
Ewmlrmus
Valnrnarn

 

(d) Top 50 Genes in GE View

(b) DS: Robust Component 2

Activity in component 2

70,3 02
Value

«may... - — _
- '-

 

(c) DS: Robust Component 5

Color Key
Activity in component 5

7015 0.1
Value

I _ drugwnes — - -_ —

skam
500mm
>6an
M1566
vwm
mm
sumsan
um
500151.052
5.10 m
m an
new

   

I I I I-—_
i: ..
ta: 2

m 1
— sumrssri
2mm

——-——
2%
SE

vwmmu
vmvmw
1:12

 

comm (f) Summary 7 robust components: Cell lines and top 10 genes in all Views

M GE: top 50 Genes in component 1

71,5 1
Value

“W” PM 52%? u u -

H0050;
My.
21m
sumri
W.
15455
2. w.
"mam
15441

- m. 151
skew:
A1565
man
woman:
Hoczrss
50mm
zmsa
cAer
Momma
3117:
mm
5mm:er
Hocura
Mmmawsvu
um
zmsm
W.
Home:
M
H0912
WWW
WWW
111751
mm

, 9 :22

ii

1;

(e) Top 50 Genes in RPPA View HCC1806

Color Key ZR751
RP: top 50 Genes in component 1

 

 

 

 

II—
i.
t itsttgsigaﬁg“

9

9%

<3 9

y 0

9’98

)

an
JUN (RPPA) [c]
PDKI (RPPA

  
     

      
   
     
   

\   6 e
 I r2010 (GE)
& C150er (GE)
V \\ \ TLRZ (MET)
SIGLECS (MET)

(X3) ELHING .

Fig. 3. Bicluster activity patterns of robust components. (a)—(c) The intensity values of cells (in rows) and drugs (in columns) in the drug sensitivity (DS) view of three
different components. Component one mainly distinguishes basal and luminal cell lines, while (d) and (e) show the corresponding bicluster activity pattern of the 50
genes with highest mean absolute values in the RPPA and GE views, marking known (breast) cancer genes by a (gray) black square. (f) Bicluster participation of all
cells (left) in 7 selected robust components (middle) with respect to their mean absolute intensity values (represented in the thickness of the lines) for the top 10
genes in each of the views (GE, MET, RPPA and EX). Known cancer genes are marked by [C] (Color version of this figure is available at Bioinformatics online.)

GE, MET, RPPA and EX we selected a list of the 50 most active
genes from the dense robust components. For each of such gene
sets we calculated the enrichment for all categories. The result
table contains a list of shared GO terms for each gene set together
with information about the background and sample frequency,
fold enrichment and the P—value determined by a binomial statistic.

A P—value close to zero indicates the significance of the GO term
associated with the provided group of genes.

More than one thousand shared GO terms are returned for the
most active gene sets. We condensed the results showing only the
most repeating and most significant ones by using a threshold for
the p—value and showing only GO terms below 107 6, which appear

9103 ‘09 1sn8nv no so1o§uv s01 0211110111123 JO [mus/1111f} 112 /310's112u1n0[p101x0"sotJBurJOJHtotq/ﬁduq 111011 popao1umoq

Sparse group factor analysis for biclustering

2463

 

(a) Cancer gene activity in component 1

 

 

 

 

 

 

 

type

‘1’ 1.0000 g
3 0 ac
lg 0.3000 3 s g A Q 9 g g . C
a, V W O 0 0
.g 0.0500 0 g X g g g V O <> 0 _
‘5 (ss X 0 O vrew
E 0.0100 <> 0 v GE
té’,0.0030 O Q X MET
£00010 0 O A RPPA
4: “9°03 . . <.> . . . . . . . . . 0 Ex

10 20 30 40 50 c0 70 50 90 100 150 200

number of genes

(b) Cancer gene activity in component 2 type
‘1’ 1.000 xx
2 V Z V V V
g vv avgevogoowc
110.300 3 g 0 o X X g ‘8 . C
'E 5 E § X X 0 X view
*‘ 0.050
g 0 e >X< at O O <> X X W GE
530.010 0 . <> o x X x MET
(.1)
§0003 O X A RPPA
.: <> 0 EX

10 20 30 40 50 60 70 50 90 100150 200
number of genes

Fig. 4. Hypergeometric test of the activity of known breast cancer (BC) and all
cancer (C) genes in the two most predictive components and all views. Low
P—values indicate a high number of cancer genes in the top n active genes in
comparison with randomly picked sets. See the text for details

Significant GO terms

growth tactor cinding
synapse part $
synapse &
proteinaceous extracellular matrix

postsynapse ﬁr
plasma membrane region $
extracellular matrix $
anchoring junction 3 view
adherens junction

regulation of cellular component movement ﬁ 0 Ex
regulation of cell motility $ >< GE
regulation of cell migration $ + Me

positive regulation of locomotion
positive regulation of cellular component movement g El RP
positive regulation of cell motility $
positive regulation of cell migration $

neuron projection morphogenesis
neuron projection guidance

neuron projection development
gland development $
extracellular structure organization g

I'll—II'II'II'II'II'I

GO
0 bp
0 cc
0 mf
extracellular matrix organization
epithelium development
cell morphogenesis involved in neuron differentiation $
cell morphogenesis involved in differentiation
axonogenesis
axon guidance

axon development

EIEIEI EIEI

 

 

3 3.5 4 4.5 >5
fold enrichment

Fig. 5. Enrichment of the most significant GO terms, which occur more than 3
times in all the gene related views and the three dense robust components
(Color version of this figure is available at Bioinformatics online.)

throughout the views and components more than 3 times. Figure 5
shows the reduced list of significant GO terms with fold enrichment
value bigger than 3. This value indicates the magnitude of fold en—
richment for the observed set of genes over the expected, thus with
values bigger than one the category implying over—representation.
For biological process we found most of the repeating significant
GO terms in all of the views in nearly all cases. These GO terms are
related to cell motility and its regulations.

5 Discussion

We presented sparse group factor analysis as a way of inferring
biclusters from heterogeneous multi—source data. The method is able
to detect predictive and interpretable structure present in any subset
of the data sources, and sparse within the sources. It proved to be ro—
bust in this task, as witnessed by the simulation studies and the out—
standing performance in the NCI—DREAM drug sensitivity
prediction challenge. The biclusters of the joint data identified can—
cer cell subtypes, grouped drugs by their functional mechanisms,
and associated known cancer genes with the drug sensitivity data,
all in a data—driven fashion. The shown approach is suitable for ex—
ploratory analysis of multiple data sources, giving condensed and in—
terpretable information with respect to the data collection.

In this paper we focused on formulating a model that implements
the novel multi—data—source biclustering, and on evaluating the accuracy
of the results. Two important questions we did not yet fully address are:
(i) could some of the alternative ways of implementing sparsity, substi—
tuting the spike—and—slabs of this paper, result in computationally more
efficient and still as accurate solutions. (ii) Computational speed. The
EM point estimates the single—data—source FABIA algorithm uses would
naturally be faster for multiple data sources as well, but the ability to
handle uncertainty due to highly noisy and high—dimensional small sam—
ple—size data would suffer. Variational approximations would be at—
tractive as they would also help avoid the matchings between the
different sampling chains, but deriving variants of the algorithm would
be more difficult and variational approximations are known to produce
a biased estimate of the uncertainty of the solutions. For large data
parallelized sampling solutions would be particularly attractive ways of
speeding up computation.

Funding

We thank the Academy of Finland (Finnish Centre of Excellence in
Computational Inference Research COIN) for funding.

Conﬂict of Interest: none declared.

References

Carvalho,C.M. et al. (2008) High—dimensional sparse factor modeling: appli—
cations in gene expression genomics. I. Am. Stat. Assoc., 103, 1438—145 6.
Cheng,Y. and Church,G.M. (2000). Biclustering of expression data. In: Proc.
of the 8th International Conference on Intelligent Systems for Molecular

Biology, pp. 93—103. AAAI Press.

Costello,I.C. et al. (2014) A community effort to assess and improve drug sen—
sitivity prediction algorithms. Nat. Biotechnol, 32, 1202—1212.

Gao,C. et al. (2014). Differential gene co-expression networks via Bayesian
biclustering models. arXiv preprint arXiv:1411.1997.

Hartigan,I.A. (1972) Direct clustering of a data matrix. I. Am. Stat. Assoc.,
67,123—129.

Hochreiter,S. (2013) HapFABIA: identiﬁcation of very short segments of iden—
tity by descent characterized by rare variants in large sequencing data.
Nucleic Acids Res., 41, e202.

Hochreiter,S. et al. (2010) FABIA: factor analysis for bicluster acquisition.
Bioinformatics, 26, 1520—1527.

Khan,S.A. et al. (2014) Identiﬁcation of structural features in chemicals associ—
ated with cancer drug response: a systematic data-driven analysis.
Bioinformatics, 30, i497—i504.

Klami,A. et al. (2015) Group factor analysis. IEEE Trans. Neural Netw.
Learn. Syst., 26, 2136—2147.

Lazzeroni,L. et al. (2002) Plaid models for gene expression data. Stat. Sin., 12,
61—86.

Madeira,S.C. and Oliveira,A.L. (2004) Biclustering algorithms for biological
data analysis: A survey. IEEE/ACM Trans. Comput. Biol. Bioinf., 1, 24—45.

Mi,H. et al. (2013) Large—scale gene function analysis with the PANTHER
classiﬁcation system. Nat. Protoc., 8, 155 1—15 66.

Morgan,I.N. and Sonquist,I.A. (1963) Problems in the analysis of survey data,
and a proposal. I. Am. Stat. Assoc., 58, 415—434.

Stephens,P.I. et al. (2012) The landscape of cancer genes and mutational proc-
esses in breast cancer. Nature, 486, 400—404.

Suvitaival,T. et al. (2014) Cross—organism toxicogenomics with group factor
analysis. Syst. Biomed., 2, 71—80.

Virtanen,S. et al. (2012). Bayesian group factor analysis. In: Lawrence,N. and
Girolami,M. (eds), Proc. of the 15th International Conference on Artiﬁcial
Intelligence and Statistics, pp. 1269—1277.

Waltman,P. et al. (2010) Multi—species integrative biclustering. Genome Biol.,
11, R96.

Yap,C.W. (2011) PaDEL-descriptor: an open source software to calculate mo—
lecular descriptors and ﬁngerprints. I. Comput. Chem, 32, 1466—1474.

9103 05 isnﬁnv uo so1o§uv 50'] 0211110111123 10 AitsmAtuf} 112 /310'S[Buln0prOJXO'SOIJ’BLUJOJIIIOICI”Idllq 111011 pap1201umoq

