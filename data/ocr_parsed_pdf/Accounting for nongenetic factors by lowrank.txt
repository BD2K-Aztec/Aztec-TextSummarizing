ORIGINAL PAPER

Vol. 29 no. 8 2013, pages 1026—1034
doi:10. 1 093/bioinformatics/btto 75

 

Gene expression

Advance Access publication February 17, 2018

Accounting for non-genetic factors by low-rank representation
and sparse regression for eQTL mapping

Can Yang‘, Lin Wangl'z, Shuqin Zhangl'3 and Hongyu Zhao1 '*

1Department of Biostatistics, Yale School of Public Health, New Haven, CT 06520, USA, 2Center for Theoretical Biology,
Peking University, Beijing 100871 and 3Center for Computational Systems Biology, School of Mathematical Sciences,

Fudan University, Shanghai 200433, China
Associate Editor: Trey ldeker

 

ABSTRACT

Motivation: Expression quantitative trait loci (eQTL) studies investigate
how gene expression levels are affected by DNA variants. A major chal-
lenge in inferring eQTL is that a number of factors, such as unobserved
covariates, experimental artifacts and unknown environmental perturb-
ations, may confound the observed expression levels. This may both
mask real associations and lead to spurious association findings.
Results: In this article, we introduce a LOW-Rank representation to
account for confounding factors and make use of Sparse regression
for eQTL mapping (LORS). We integrate the low-rank representation
and sparse regression into a unified framework, in which single-
nucleotide polymorphisms and gene probes can be jointly analyzed.
Given the two model parameters, our formulation is a convex optimiza-
tion problem. We have developed an efficient algorithm to solve this
problem and its convergence is guaranteed. We demonstrate its ability
to account for non-genetic effects using simulation, and then apply it to
two independent real datasets. Our results indicate that LORS is an
effective tool to account for non-genetic effects. First, our detected
associations show higher consistency between studies than recently
proposed methods. Second, we have identified some new hotspots
that can not be identified without accounting for non-genetic effects.
Availability: The software is available at: http://bioinformaticsmed.
yale.edu/softwareaspx.

Contact: hongyu.zhao@yale.edu

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on May 1, 2012; revised on January 11, 2013; accepted on
February 7, 2013

1 INTRODUCTION

Nowadays both gene expression levels and hundreds of thou-
sands of single-nucleotide polymorphisms (SNPs) can be mea-
sured by high-throughput technologies. This allows us to
systematically explore the relationship between gene expression
levels and genotypes: whether a gene is differentially expressed
with different genotypes (or alleles) at a specific locus. The loci
that are associated with gene expression levels are known as
‘expression quantitative trait loci’ (eQTL) (Li et al., 2012).
Recently, a large number of eQTLs have been found in eQTL
studies (Cookson et al., 2009). These ﬁndings provide insights on
how gene expression levels are affected by speciﬁc genetic

 

*To whom correspondence should be addressed.

variants (Cheung and Spielman, 2009). They may further help
to prioritize disease-associated loci and contribute to disease
understanding (Nica and Dermitzakis, 2008).

An important issue in eQTL mapping is that a fairly large
proportion of the measured gene expression variations may not
be caused by genetic variants, but by some other factors, includ-
ing cellular state (Alter et al., 2000), environmental factors
(Gibson, 2008) and experimental conditions (Leek et al., 2010).
A typical example is the batch effect, which may arise when
sub-groups of samples were processed by different laboratories,
different technicians or on different days. Because these factors
are unrelated to genetic variants, we call them non-genetic fac-
tors in the rest of the article.

Some of the non-genetic effects can be directly measured. For
example, when the batch information is available, the batch effects
may be adjusted, e. g an empirical Bayes method named ‘Combat’
(Li and Rabinovic, 2007). However, in practice, non-genetic fac-
tors may not be directly and completely observable and thus
remain hidden. For example, Pastinen et a]. (2006) showed that
cell culture conditions have an unnegligible inﬂuence on a large
number of genes. Gagnon—Bartsch and Speed (2012) reported that
a substantial within-batch effect exists in the Microarray Quality
Control study (Shi et al., 2006). ‘Expression heterogeneity’ (EH)
arises when these hidden factors are not taken into account in
statistical analysis. Leek and Storey (2007) showed that EH not
only leads to the reduction of statistical power but also spurious
association signals in eQTL mapping.

Recently, capturing EH in gene expression studies has drawn
the attention of researchers. Many methods have been proposed
to infer the hidden factors by some forms of factor analysis, and
adjust the inferred factors as if they were observed (Alter et al.,
2000; Nielsen et al., 2002).

One well-known method that attempts to address these issues
is the Surrogate Variable Analysis (SVA; Leek and Storey, 2007).
It performs principal component analysis while taking genotypes
into consideration and uses permutation to choose the number of
principal components. Kang et a]. (2008) proposed the intersam-
ple correlation emended (ICE) eQTL mapping method, in which
a linear mixed model was introduced to model the hidden
factors. When modeling EH, Kang et a]. (2008) used the
covariance matrix of the gene expression data as the EH covari-
ance matrix in their ICE model. However, this estimate is incon-
sistent and thus reduces the power of eQTL mapping. Listgarten
et a]. (2010) introduced another linear mixed model, named

 

1026 © The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com

112 /310's112u1n0fp10}x0"sotJBuiJOJutotq/ﬁduq 11101} papeolumoq

9103 ‘Og anﬁnV 110 ::

LORS

 

‘LMM-EH’, which corrected the inconsistency of the estimated
EH covariance matrix. Once the latent covariance matrix has
been estimated, LMM-EH can scan every gene-SNP pair.
Alternatively, Stegle et al. (2010) jointly modeled SNPs, gene
probes and hidden confounders into a Bayesian framework.
Despite its greatly increased power in eQTL mapping, its
heavy computational burden might limit its usage. Fusi et al.
(2012) proposed another model named ‘PANAMA’ and bor-
rowed some computational techniques from Gaussian process
(Rasmussen and Williams, 2006) and further improved the per-
formance of eQTL mapping. However, during the model opti-
mization, PANAMA may be trapped in a local optimum because
the optimization problem is not convex.

In this article, we introduce an alternative formulation to ad-
dress this issue. We propose a LOw—Rank representation to ac-
count for non-genetic factors and make use of Sparse regression
for eQTL mapping (LORS). We integrate the low-rank represen-
tation and sparse regression into a uniﬁed framework, in which
SNPs and gene probes can be jointly analyzed. Given the two
regularization parameters, the optimization of the model struc-
ture is a convex problem. We have developed an efﬁcient algo-
rithm to solve this convex problem and its convergence is
guaranteed. We demonstrate its usefulness through its applica-
tions to both synthetic data and real data.

2 MODEL

Before introducing our formulation, we summarize the notations
used in this article. We consider the following norms of a vector
v 6 IR": the £1 norm deﬁned as ||v||1 = Zilvjl; the £2 and the
squared £2 norms deﬁned as ||v||2 = «El-v? and ||v||§ = 2,- v?,
respectively. We use the following three norms of a matrix

W e IR’M”: the Frobenius norm ||W||F = izij W2 the nuclear

j],
norm ||W||* = 21.90;, where 01, ...,a,. are the singular values
of W and r is the rank of W and the ‘elementwise’ £1 norm
llWll1= Zngi-jl.

Let Y be an n x q matrix corresponding to a gene expression
dataset, where n is the number of samples and q is the number of
genes. Let X be an n x p matrix corresponding to a SNP dataset,
where p is the number of SNPs. To model the relationship
between Y and X, we propose to decompose Y as:

Y=1u+XB+L+e (1)

where B 6 RPM is the coefﬁcient matrix, 1 6 Wm is a vector
whose entries are all 1, a is a 1 x q matrix with uj,j = 1, ...,q
being the j-th intercept and e e IR’WI is a Gaussian random noise
term with zero mean and variance 02, i.e. ejj ~ N(0, 02). Here we
introduce L e IR’WI in our model to account for the variations
caused by a few hidden factors. This model implies that gene
expression levels are inﬂuenced by genetic factors, non-genetic
factors and random noises.

To make the decomposition (1) possible, we make the follow-
ing assumptions:

0 There are only a few hidden factors that may inﬂuence gene
expression levels. Thus, L is a low-rank matrix. Here, we
also implicitly assume that the hidden factors have global
effects rather than local effects.

0 The gene expression level may only be affected by a small
fraction of SNPs. This implies that the coefﬁcient matrix B
should be sparse.

Based on these assumptions, we propose to solve the following
optimization problem:

min ij — XB — 1p — ijfv

B, u, L 

s.t. rank(L) 5 r0, IIBII1 5 to

where ||B||1 is the elementwise £1 norm deﬁned before, r0 and to
are some ﬁxed constants. To make the minimization problem
tractable, we relax the rank operator on L with the nuclear
norm, which has been proven to be an effective convex surrogate
of the rank operator (Recht et al., 2010). Now we rewrite (2) in a
Lagrange form

. I
611111 ‘IIY—XB— 1H_LII§7+pIIBIIl +AIILII* (3)
ML 2

where ||L||* is the nuclear norm of L, p and A are regularization
parameters that control the sparsity of B and the rank of L,
respectively. Now it is a convex optimization problem and can
be solved efﬁciently.

Missing data are commonly encountered when analyzing gene
expression data. Here we extend our basic model (3) in the fol-
lowing to handle missing data naturally.

Suppose we only observed a subset of entries in Y, indexed by
Q. The unobserved entries are indexed by Qi. Mathematically,
we can deﬁne an orthogonal projection operator 73 that projects
a matrix W onto the linear space of matrices supported by Q:

Pawn) =   :2 (4)

and 7391 (W) is its complementary projection, i.e. 739(W) + 7391
(W) = W.

Because we want to find a sparse coefﬁcient matrix B and a
low-rank matrix L based on the observed data, we propose to
solve the following optimization problem:

. 1
mm -||7’n(Y—XB— lu—L)II%+DIIBII1 +M|Lll* (5)
B,M.L 2

where the ﬁrst term ||Pg(Y—XB— 1a —L)||§, is the sum of
squared errors on the observed entries indexed by Q.

3 ALGORITHM

To solve the optimization problem (3) efﬁciently, we need the
following lemma [the proof can be found in (Mazumder et al.,
2010)]:

LEMMA 1. Suppose matrix men has rank r. The solution to the
optimization problem

. 1 2
HIZIHEIIW—ZIIF+AIIZII* (6)
is given by 2 = S),(W) where

SA(W) = UDAVT with DA 2 diag[(d1 — 1),, ...,(d,. — 1),] (7)

UDVT is the Singular Value Decomposition ( S VD ) of W,
D = diag[d1, . . . , dr], and t+ = max(t, 0).

 

1 027

112 /310'S[BHJDO[pJOJXO"SOIJBHIJOJIIIOICI/ﬂdnq 11101} papeolumoq

9103 ‘Og isnﬁnV 110 ::

C. Yang et al.

 

We adopt an alternating strategy to solve problem (3). For
ﬁxed B and a, the optimization problem becomes

. 1
mLmEIIY—XB—lu—Lll%+?~llLll* (8)

By Lemma 1, we have a closed-form solution for L:
LZSAW—XB—IM) (9)

For fixed L, the optimization problem becomes
. 1
gunEIIY—XB—lu—Liiéwiimil (10)
,M

It can be further decomposed into q independent Lasso prob-
lems (Tibshirani, 1996):

pingiin — Lj — XBj — mil; +plllel1J =1....,q (11)
13M]

where Yj, Lj and Bj are the j-th column of Y,L and B, respect-
ively. The Lasso problem can be solved efﬁciently by the coord-
inate descent algorithm (Friedman et al., 2007, 2010). Now we
have Algorithm 1:

 

Algorithm 1 A fast algorithm to solve problem (3)
0 Input: Y e IR’WI,X e Rnxp,p,A. Initialize B <— 0, a <— 0.

 

o Iterate until convergence:

0 L-step: L = S),(Y — XB — la).
0 (B, u)-step: Solve q independent Lasso problems (11) by
the coordinate descent algorithm.

0 Output: B, L, a.

 

So far we have developed the algorithm for solving problem
(3). To derive an algorithm to solve optimization problem (5), we
need the following lemma [its proof was given by (Mazumder
et al., 2010)]:

LEMMA 2. Soft-impute algorithm
mZiné ||199(W — z)“; + A||Z||*
= mziné mm) — [z — maul; + Allle* (12)
= mZiné “[mm + 199i(z)]— lefv+ A||Z||*

By Lemma 1, the optimal value Z* of the optimization problem
(12) can be obtained via updating Z using
2 e simxw) + 7w» (13)
with an arbitrary initialization.

We also adopt the alternating strategy to solve (5). For ﬁxed B
and a, optimization problem (5) becomes

. 1
mLIHEIIPoW—XB— lu—L)ii%+AIILII. (14)

By Lemma 2 we have

L <— sioagor — XB) + P§(L)) (15)

For ﬁxed L, optimization problem (5) becomes
. 1
(Ba/1’): arg 3,1155 lan(Y — L — XB — 1mm p||B||1 (16)

Again, this problem can be decomposed into q independent
Lasso problems as follows:

. 1 .
glln)§lan,(Yj-Lj —XBj -Mj)ll§+plllel1,J=1,...,q (17)

( All]

Now we have Algorithm 2:

 

Algorithm 2 A fast algorithm to solve problem (5)
0 Input: Y e R”Xq,X e R"X”,p,A. Initialize B <— 0, a <— 0.

 

o Iterate until convergence:

0 L-step: iteratively update L using (15).

o (B, u)-step: Solve q independent Lasso problems (17)
using the coordinate descent algorithm.

0 Output: B, L, a.

 

The convergence analysis of our algorithms and the CPU tim-
ings are provided in the Supplementary Document.

4 PARAMETER TUNING

We have two parameters that need to be tuned in our models.
Here we propose a cross-validation—like strategy to select these
two parameters. The idea is as follows: Let Q be the index of the
observed entries of Y. We randomly divide 9 into training entries
91 and testing entries 92: S21 U92 2 Q and £21 {—192 = 0. The
sizes of S21 and 92 are roughly the same. We may solve problem
(5) on a grid of (p, A) values on the training data:

. 1
191,31 EIIPQH—XB—lu—L)iI%+piiBiil+AIILII* (18)

Then we evaluate the prediction error (19) on the testing data

Erma, 1) = $1119an — XBo, A) — mm A) — Lo, 1))“; (19)

where we write B, a and L as B(p, A), u(p, A) and L(p, A) to
emphasize that B, a and L depend on the parameters ,0 and A.
We can then choose the parameter setting (0*, A*), which min-
imizes the prediction error (19).

However, searching for two parameters on a grid of values
may be too computationally expensive when dealing with large
datasets. Instead, we search a good A value with fixing p 2 co
and then perform a one dimensional search on a sequence of p
values. In our implementation, we ﬁrst set the maximum rank of
L, denoted as rankmax(L), equal to min(n,q)/2. Then, we start
from a large Amax, which equals to the second largest singular
value of matrix 739(Y). After solving

. l
mﬁn EIIPnlw—L)II%+MILII* (20)

if rank(L)<rankmax(L), we reduce A by a factor n = 0.9 and
repeatedly solve (20) until rank(L) 3 rankmax(L). Using

 

1 028

112 /310's112u1n0[p101x0"sotJBuiJOJHtotq/ﬁduq 111011 pap1201um0q

9103 ‘0g isnﬁnV 110 ::

LORS

 

warm-start, this sequential optimization is efﬁcient (Mazumder
et al., 2010).
Then we choose a A value, which minimizes the prediction error

Ewe) = $1119an — MM)“; (21)

Let A be the value corresponding to the minimal prediction
error (21). Now we can perform a one dimensional search for a
good value for ,0. We generate a sequence of p values with length
np equally decreasing from pmx to epmax on the log scale, where
pmx is the smallest p value such that all entries of B(p, A) are zero.
Typically, we set np = 20 and e = 0.05. For each ,0 value, we solve

. 1 A
191ng 51179an — 1M — XB — L)“; + pllBll1+ AllLlh (22)

and evaluate the prediction error:

Erma, X) = % ll7’92(Y — Imp, X) — XBo, 1) — Lo, A3)“; (23)

Then we choose the p value corresponding to the minimal
prediction error (23). Now we can solve model (5) using (AA)
as regularization parameters, and obtain a sparse matrix B(,5, A)
and a low rank matrix L(,6, A).

5 DISCUSSION

5.1 Relationship between our method and other methods

To our knowledge, LMM-EH (Listgarten et al., 2010) proposed
the ﬁrst framework, where multiple gene expression levels and
confounder effects can be jointly analyzed in eQTL studies. For
the j-th gene expression level in the LMM-EH model, it assumes
the following structure:

Yj=XBj+uj+ej,j=1,...,q 

where Y e R”Xq,X 6 RM” are the expression and SNP data
matrices, respectively. Here ej denotes Gaussian noise, i.e.
ej ~ N (0, 0821), and uj denotes a random effect, i.e.
“j ~ N(0, ‘52), where ‘L' is a scalar and 2 e IR’W'. Assuming the
independence among Y], j = 1, . . . , q, and integrate out uj and ej,
we arrive at the following form:

q
Pr(Y|X, {B, r, of}, )3) = n Pr(XBj,122 + 051) (25)
j=l

LMM-EH adopts the following strategy to estimate the co-
variance matrix 2 and other model parameters ® 2 {B, ‘L', 03}:

0 First, it estimates 2 from the null model, which does not
include any SNPs, denoted as Z (Kang et al., 2008, 2010;
Lippert et al., 2011).

0 Second, using E in model (24) as a known covariance and
estimate ® 2 {B, ‘L', 08} for all gene-SNP pairs (one gene ver-
sus one SNPs at a time).

PANAMA extends LMM-EH and allows joint analysis of all
SNPs (Fusi et al., 2012). Specifically, PANAMA models the re-
lationship between gene expression levels and SNPs as follows:

Y=u+XB+HW+e (26)

here a is the intercept, B and W are the corresponding coeffi-
cients representing the effects of SNPs and hidden factors H.
PANAMA assigns independent Gaussian priors for B and W:

K
Pr(B)=ﬁ/\/(0, 01,21), Pr(W)= I'M/(0, 5,2,1) (27)
1:1 k=1

where K is the number of hidden factors. Assuming Yj, j = 1,
. . , q are independent and integrating out B and W, the model
becomes

‘1 P K
Pr(Y|H, e) = TIA/(0, Z a§X,X,T + Z ﬁﬁHkH; + 031), (28)
' l ' k=1

1: [:1

where the intercept term a is dropped for notation convenience
and ® 2 {{alz}, {0i},a§}. In principle, parameter estimation in
(28) can be done by borrowing some computational tricks
from Gaussian process model optimization (Rasmussen and
Williams, 2006). Computation becomes prohibitive when all
genome-wide SNPs are included. In this case, PANAMA
adopts a heuristic strategy: PANAMA begins with the null
model (i.e. the model does not include SNPs). It ﬁrst uses prin-
cipal components to initialize H and gradually adds signiﬁcantly
associated SNPs into model (28), and re-estimate model param-
eter ® and H. This process iterates until no signiﬁcantly asso-
ciated SNPs are added into the model. In summary, H and ® are
jointly optimized during the iterations.

Our model (1) can be regarded as an equivalent form of (26)
because a low rank matrix can always be written as L = HW
with H e IR’W,W e IRWI, where r is the rank of L. Unlike
PANAMA, both our formulations (3) and (5) are joint convex
w.r.t (B, a, L). When the tuning parameters (A and p) are given,
our algorithms are guaranteed to converge to the optimal solu-
tion without any heuristic. Furthermore, we do not assume that
Y,-, i = 1, . . . , q are independent. This can be seen from Lemma 1
and Lemma 2: information among multiple gene expression is
used jointly by singular value decomposition.

Compared with PANAMA, the proposed method LORS has
its disadvantages. Using PANAMA’s formulation, statistical sig-
niﬁcance of the associations can be evaluated. Currently, we can
not provide a rigorous statistical signiﬁcance test of the estimated
coefﬁcient matrix B. The difﬁculty comes from the unknown
statistical property of the nuclear norm. How to do statistical
tests with the nuclear norm regularization needs to be investi-
gated in the future. In this article, we use permutation to obtain a
rough estimate of false discovery rate (FDR) for our method.

5.2 A screening method based on LORS

Although optimization of our LORS model (3) is a convex prob-
lem, it is still too computationally intensive to directly use it for
analyzing human-size datasets (e. g. the number of genes
(1 B 20 000, the number of SNPs p B 500 000). One can see the
computational bottleneck in the (B, a) step of Algorithm 1 and 2.
In this step, q Lasso problems need to be solved, each of which
involves p variables. To overcome this computational difficulty,
we propose to solve the following optimization problem:

1
i — Y—X. ,_ 1 _L 2 A L 29
$3111 2“ 15/ M IIF+ ii i. ( )

 

1 029

112 /310's112u1n0[p101x0'sopBHJJOJmth/ﬁduq 111011 pop1201um0q

9103 ‘0g isnﬁnV 110 ::

C. Yang et al.

 

where Y e IR’WI is the entire data matrix of gene expression,
Xj 6 Wm is the j-th SNP, 13,- e IRIX‘I is the coefﬁcient of the
j-th SNP corresponding to its effect size on g genes. Here we
consider one SNP at a time, and thus, we do not add L1 regu-
larization. Clearly, it can be considered as the single-variable
version of LORS. Thus, we call this screening method as
‘LORS-Screening’. The algorithm to solve (29) is given in the
Supplementary Documents. The computational time of
LORS-Screening is given in the Supplementary Material.

For large datasets (e. g. human datasets), we recommend to use
LORS-Screening to reduce the number of SNPs. After the
screening process, we may select top d SNPs for each gene
(based on the absolute value of the coefﬁcients). Then we can
ﬁt the LORS model using the selected SNPs. This strategy is
similar to the single-variable screening step followed by joint
analysis in linear regression (Fan and LV, 2008). According to
the property of L1 regularization, LORS can identify at most n
non-zero coefﬁcients for each gene. Here we may set d: n.

6 RESULTS
6.1 Synthetic data

To avoid the simulation setup favoring our own model, we use
LMM-EH model (24). Speciﬁcally, we generate genetic effects,
non-genetic effects and noises as follows:

0 Genetic effects: each SNP is generated independently and
the minor allele frequencies of these SNPs are uniformly
distributed in the interval (0.1, 0.4). The coefﬁcient matrix
B is a sparse matrix with 1% non-zero entries. These non-
zero coefﬁcients are generated using standard Gaussian dis-
tribution. Let G denote the genetic effect G = XB.

o Non-genetic effects: The covariance matrix 2 is generated
by HHT, where H e IRWK and HM ~ N(0, 1). Here Kis the
number of hidden factors. The random effect “j is drawn
from N(0, 12). Let u 2 [ul, ...,u,,].

o e ~N(0, 0821).
Nowwehave
Y=XB+u+e=G+u+e (30)

In the following simulation studies (Sections 6.2 and 6.3), we set
n = 100, p = 100 and q = 200. To evaluate the performance under
different signal-to-noise ratios, we deﬁne SNRl and SNR2 as:

_ Var(G) _ Var(G)
SNRI _  Var(e)’ SNR2 _  Var(u) (31)

Parameters ‘L' and 03 can be used to control SNRl and SNR2.
An example of synthesized datasets is given in the Supplementary
Document.

 

 

6.2 Inﬂuence of parameter tuning

Before we compare LORS with some other methods, we would
like to empirically evaluate our parameter tuning procedure.
Given a dataset, we need to randomly partition the observed
entries into two parts: 91 and S22. Basically, we train our
model based on £21 for different parameters and choose a good

parameter conﬁguration such that the trained model has an ac-
curate prediction on 92. There may be two concerns: (i) Because
the random partition may introduce randomness in our model-
ing process, does this strategy provide a stable parameter selec-
tion? (ii) Can this strategy adapt to different noise level? To
answer these questions, we do 100 random partitions of a syn-
thetic dataset, and run our method based on each partition sep-
arately. The distribution of the selected parameters is shown in
Figure 1. First, one can see that the selected parameters (A, ,0) do
not change a lot during 100 random partitions. The stability of
our method should be attributed to the continuity property of
the £1 norm (Fan and Li, 2001), that is, a small change of dataset
will not cause a big change of the optimization solution. Second,
when the signal becomes weaker, i.e. SNR1 = 1 (the left panel of
Fig. 1) reduces to SNRl = 1/2 (the right panel of Fig. 1), a larger
,0 will be selected to prevent the noise from entering the model.
This shows that our parameter tuning strategy can adapt to dif-
ferent noise levels. In Section 3.2 of the Supplementary
Document, we provide more evidence to show that the random
partition in our parameter tuning has little effects on eQTL map-
ping (i.e. the estimation of matrix B).

6.3 Performance evaluation

We will mainly compare our method LORS with PANAMA.
The reasons are: (i) PANAMA can be regarded as an extension
of LMM-EH as we discussed above. (ii) Fusi et al. (2012) showed
that PANAMA signiﬁcantly outperforms other related methods,
including SVA, PEER and ICE. Here we include the results from
standard linear regression as reference, and compare LORS,
LORS-Screening and PANAMA with the standard linear
regression.

To compare our method with PANAMA under different
settings, we vary SNRl, SNR2 and K. For each setting, we
report the averaged result from 50 realizations. Figure 2 shows
the comparison results for different combinations of SNRl,

SNR1=1,SNR2=1I3

SNR1=1/2,SNR2=1I3

0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

5 10 15 20 5 10 15 20
Index ofp Index ofp

Index of}.
Index ofA

   

Fig. 1. The distribution of selected parameters (100 random partitions of
training and testing data) for synthetic datasets. Left panel: the synthetic
dataset is generated with n = 100, p: 100, (1:200, SNR1 = 1 and
SNR2 = 1/3. For the parameter A, A27 and A28 are selected in the se-
quence of A values in most cases; for parameter p, p13 is selected in most
cases. Right panel: the synthetic dataset is generated with n: 100,
p: 100, (1:200, SNR1 = 1/2 and SNR2 = 1/3. For A, A20 and A21 are
often selected; for p, p12 is selected in most cases

 

1030

112 /310's112u1n0[p101x0'sopBHJJOJmth/ﬁduq 111011 pop1201um0q

9103 ‘0g isnﬁnV 110 ::

LORS

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

    

 

 

 

 

 

 

 

 

 

(A)
SNR1=1/2, SNR2=1 SNR1=1/2, SNR2=1/2 SNR1=1/2, SNR2=1I3
1 1 1
l T ‘ ‘ ‘ l l . , . H
0.8 ,r’ 0.8 .~:;"’ 0.8
I
I ’ ’ a
m 0.6 r’ 0.6 0.6
E
0.4 0.4 0.4
0.2 0.2 0.2
0 0 o
SNR1=1, SNR2=1 SNR1=1, SNR2=1IZ SNR1=1, SNR2=1I3
1 1 H 1
0.8 — ’ 7 0.8 g" 7 0.8 f
a: 0.6 0.6 0.6
E
0.4 0.4 0.4
0.2 0.2 0.2
0 0 0
SNR1=2. SNR2=1 SNR1=2, SNR2=1l2 SNR1=2, SNR2=1I3
1 1 1
0.8 0.8 ‘ 0.8
m 0.6 0.6 0.6
E
0.4 0.4 0.4
0.2 0.2 0.2
0.2 0.4 0.6 0.8 1.0 0.2 0.4 0.6 0.8 1.0 0.2 0.4 0.6 0.8 1.0
FPR FPR FPR

(B)
SNR1=1/2, SNR2=1 SNR1=1/2, SNR2=1/2 SNR1=1/2’ SNR2=1I3
1 1 1

 

 

0.8 I ’ 0.8

0.8
I
’ f
0.6 0.6 x 0.6
0.4 0.4 0.4
0.2 0.2 0.2

 

 

0 0
SNR1=1, SNR2=1 SNR1=1, SNR2=1l2 SNR1=1, SNR2=1I3
1 1 1

v ‘ , . I ~ ' " _,—‘
u —
 ,1

 

 

0.8 /.r' 0.8" 0.81

0.6 0.6 0.6

0.4 0.4 0.4

0,2 0.2 0.2
o 0

 

 

0
SNR1=2, SNR2=1 SNR1=2, SNR2=1l2 SNR1=2, SNR2=1I3
1 1 1

 

0,8 6 ’ 7 7 0.8 ‘p 0.8 i)
0.6 0.6 0.6
0.4 0.4 0.4
0.2 0.2 0.2

 

 

 

 

 

 

 

 

0.2 0.4 0.6 03 m 0.2 0.4 0.6 0.8 1.0 0.2 0.4 0.6 0.8 1.0
FPR FPR FPR

 

| — LORS 11111 ~ LORS—Screening - - - PANAMA

 

Linear regression I

 

Fig. 2. The ROC curves for performance comparison. (A) The number of hidden factors K: 10. (B) The number of hidden factors K: 30. In each panel,
we vary SNR1 = {1 /2, 1, 2}, SNR2 = {1, 1/2, 1/3} to compare the performance of LORS, PANAMA and standard linear regression

SNR2 and K (more simulation results can be found in the
Supplementary Document). From these simulation results, we
can see the following:

c When the number of hidden factors increases, the perform-
ance of both LORS and PANAMA degrades slightly.

0 When the genetic effects and non-genetic effects are small
(compared with noises), e.g. SNR1 = 1/2, SNR2 = 1),
LORS is only comparable with standard linear regression
and PANAMA is even worse. This is because the noise plays
a dominant role here, it is difﬁcult to account for
non-genetic effects under this situation.

0 As the genetic effects and non-genetic effects become
more apparent, both LORS and PANAMA perform
better than standard linear regression. As we mentioned in
Section 5.1, LORS and PANAMA share the same
model structure, and they differ in how the model struc-
ture is inferred. We suspect that PANAMA may be
trapped at a local optimum during its model optimization.
As a result, LORS may have better performance than
PANAMA.

0 Regarding to LORS-Screening, it turns out that LORS-
Screening is slightly worse than LORS but comparable
with PANAMA. Because the computational cost is largely
reduced, it is preferred in large data analysis.

6.4 Estimate of false discovery rate

Owing to lack of statistical tests, it is necessary to provide a way
to estimate the FDR of our method. Because correlation exists
among the rows and columns of Y, exactly estimating FDR be-
comes difﬁcult. Here we follow the strategy of (Tibshirani and
Wang, 2008; Nowak et al., 2011) to obtain a rough estimator of
the true FDR, which may serve as a guideline when applying our
method. We use

F/D\R,=N’

 

(32)

as a rough estimator for FDR, where N, is the number of asso-
ciations identiﬁed at threshold I under the null distribution, A, is
the number of associations identiﬁed at threshold I in the original
dataset. We use permutation to obtain the number of associations
identiﬁed under the null distribution. Speciﬁcally, for a given
threshold I, we do T permutations. At the t-th permutation, we
permute the rows of the expression dataset Y to generate a null
dataset, denoted as Y“). Then, we run LORS on the permuted

dataset (Y(’), X) and obtain the number of associations by apply-

ing the threshold I to the estimated matrix B, denoted as :43).
After T permutations, the ﬁnal estimation of FDR, is given by

N i 11;»
F’D\RT : _T = L
Ar Ar (33)

 

1031

112 /310's112u1n0[p101x0"sothJJOJmth/ﬁduq 111011 pop1201um0q

9103 ‘0g isnﬁnV 110 ::

C. Yang et al.

 

 

xvi

xiv

XIII

  

 

(A) (B)
u 0 .l. 0' I
- L n a ,f
_- i . . . .  . . . u/
" : _ '. '. . ' ..'. .-  .._.._' .. ' fr 2'
u : I I. 1.- 2 18:. 0 . II a .I. 0..
_- , X 'o ' o “o , o ' so i" o o
_ . i . ' '... :. .._ :'{~._.- : ".3. .'?.'/-.:-.I--- "
g : - g _ & ' - - o . .. Ign ' .
‘E _ - l - ‘c’i ' I’ .
Q - I - 9 n .\ . o u -
‘5) x ' _ -;  x . . / : ‘
8x a  8X_,:.:._._/,.. ..
E; --- ',~ =-.-- a; 2' -.-- - » '  .-
2 > , ~ u 3’ _§- - 2 > 1 ' . - - .-
0 = -. - o = .
8. =. a : o> up... .. =.-- =  H n - H:
S I '- . . . . 5 . - ' I. ' '
> I ‘ / : _ > . . I . .
-~- . _ .. , _ . :. :
2 ' I 2 . 5"» . ~
 _ - - .. ’7‘.  . ..... - . .
_ _. - . - : _ './ . . .

 

 

 

 

 

 

| II III IV V VI VII VIII IX X XI XII XIII XIV XV XVI
Genomic position(SNP)

 

| II III IV V VI VII VIII IX X XI XII XIII XIV XV XVI
Genomic position(SNP)

Fig. 3. (A) A plot of significant linkage peaks given by standard linear regression (P< 0.01 after Bonferroni correction) for expression QTL in the study
(Smith and Kruglyak, 2008) by marker location (x-axis) and expression trait location (y-axis). (B) The plot of linkage peaks in the study (Smith and
Kruglyak, 2008) given by LORS (Top 1000 associations based on abs (B) are shown here. The plot of All associations are given in the supplementary

document)

We report estimated FDR based on the simulated data as
described in Section 6.1 in Figure 9 of the Supplementary
Document. The permutation strategy provides a reasonably
good estimate for the true FDR. The estimated FDR often over-
estimates the true FDR (due to the correlation), and thus, it may
serve as a conservative guideline.

6.5 Application to eQTL data from yeast

We applied our method to two yeast datasets for eQTL mapping.
The first dataset is from Brem et al. (2002) (GEO accession
number GSE 1990), which consists of 7084 probes and 2956
genotyped loci in 112 segregates. The second one comes from
Smith and Kruglyak (2008), which includes 5493 probes mea-
sured in 109 segregates. Analysis of these two datasets provides
us an opportunity to demonstrate the benefit of our method
because the two expression data share the same genetic effect
but different confounding effects.

The significant linkage peaks given by standard linear regres-
sion are shown in Figure 3 (A). We can clearly see the confound-
ing effects that lead to spurious associations. We also show the
result given by LORS in Figure 3 (B). In total, LORS has de-
tected about 10000 associations according to non-zero B values.
Because LORS does not perform statistical significance tests, we
are not able to report our result based on statistical signiﬁcance.
In practice, people may be more interested in the top signals that
will be followed up for replications. Thus, we only show the top
1000 associations based on the absolute value of B. The plots of
all associations are also given in the Supplementary Document
for completeness. It can be seen that the confounding effects are
successfully accounted by LORS, and thus spurious associations
are greatly reduced. To quantitatively evaluate the ability of ac-
counting for confounding effects, we compare the reproducibility

 

0.5

 

— LORS
- - - PANAMA

 

 

 

0.4

Fraction Consistent

0.2

0.1

 

0.0

 

 

 

I I
0 1000 2000 3000 4000

it of detected associations

Fig. 4. Consistency of detected associations between two independent
yeast eQTL datasets

of the results given by LORS and PANAMA. We examine the
reproducibility based on the following two criteria:

0 The consistency of detected SNP-gene associations. Let 81
and 82 be the sets of SNP-gene associations detected in the
two yeast datasets, respectively. The most T significant as-
sociations from the two datasets are denoted as SIT and 8;.
The consistency is deﬁned as £53”, where |81Tﬂ 8le de-
notes the size of 81TH 8;. For LORS, the ranking is based
on the absolute value of B. For PANAMA, the ranking is
based on the q-Value.

 

1032

112 /310's112u1n0[p101x0"sothJJOJmth/ﬁduq 111011 pop1201um0q

9103 ‘0g isnﬁnV 110 ::

LORS

 

o The consistency of detected hotspots. For a SNP, we can
count the number of associated genes from the detected
SNP-gene associations (for LORs, all SNP7Gene pairs
with a non-zero B are defined as associations. For
PANAMA, SNP7Gene pairs with a q—Value <0.001 are
defined as associations, we tried different cutoffs from 0.01
to 0.001, the results are similar), i.e. the regulatory degree of
the SNP. SNPs with large degrees are often referred to as
hotspots. According to SNPs’ regulatory degrees, we sort
them in a descending order and denote the sorted SNPs
lists as [11 and £2 for the two yeast datasets. Let [IIT and

 

 

 

 

 

 

 

 

 

‘3. L
— LORS _
>-- PANAMA
'9. L
o a
E «a L
.E o
(D
1':
O
O
1:
.2
‘13 v
I‘.’ c5 T
LL
N. _ 
O l
O. _ 
O
I I I l I I
0.0 0.2 0.4 0.6 0.8 1.0
Fraction of Hotspots

Fig. 5. Consistency of detected eQTL hotspots between two independent
yeast eQTL datasets

Table 1. Summary of the detected hotspots

(I; be the top T SNPs in the sorted SNP lists, respeptivlely.
The consistency of detected hotspots is deﬁned as 

For Brem’s dataset (Brem et al., 2002), the estimated sparse
matrix B given by LORS has about 6000 non-zero entries in
total. Among them, there are 4500 entries with abs (B)>0.01
and 2500 entries with abs (B)>0.05, respectively. For Simth’s
dataset (Smith and Kruglyak, 2008), the estimated B has about
10000 non-zero entries in total. There are about 4500 entries
with abs (B)>0.05. (To provide a meaningful guideline of the
thresholds, we estimate FDR using 50 permutations. The esti-
mated FDR corresponding to different thresholds are provided
in the Supplementary Document. It tells us that FDR 5 0.01
when threshold I 3 0.01). In Figure 4, we show the consistency
of the top 4500 associations. The consistencies of hotspots are
shown in Figure 5. It seems to be counter-intuitive that the frac-
tion of consistency of PANAMA increases as the number of
detected association increases. In fact, the consistency of
PANAMA increases to 0.12 and then drops. We provide the
detailed information in the Supplementary Document. From
Figures 4 and 5, it can be seen that LORS achieves better con-
sistency than PANAMA.

So far we have shown that spurious associations can be
reduced by successfully accounting for non-genetic effects.
Now we are going to show whether it could help to detect
more biologically relevant associations. We take a closer inspec-
tion of the top 15 hotspots, as listed in Table 1. In most cases
(12/15), associated genes are enriched with at least one GO cat-
egory, which implies that they are biologically relevant ﬁndings.
In particular, we detect two novel hotspots (NO. 9 and NO. 13),
which can not be detected by standard linear regression (adjusted
P >0.1). For these two hotspots, the associated genes are

 

 

Hotspot index Sizea Locib GO categoryc Hitsd t-test (all)e t-test (hits)r
NO. 1 32 Chr XII:1056103 Telomere maintenance via recombination*** 5 20 5
NO. 2 27 Chr IV:1525327 Telomere maintenance via recombination*** 4 5 3
NO. 3 26 Chr XII:662627 Sterol metabolic process*** 7 25 7
NO. 4 24 Chr 1:52859 Fatty acid metabolic process*** 10 12 6
NO. 5 24 Chr XV:202370 Response to abiotic stimulus** 10 11 6
NO. 6 23 Chr III:201166 Response to pheromone** 7 16 6
NO. 7 21 Chr VII:402833 Protein folding** 8 4 3
NO. 8 19 Chr 1:7298 Fatty acid beta-oxidation*** 5 13 4
NO. 9 18 Chr IV:33214 Response to toxin* 5 0 0
NO. 10 16 Chr 11:562415 Cytokinesis*** 8 15 8
NO. 11 16 Chr X:698149 7 7 3 7
NO. 12 16 Chr XV:132423 7 7 13 7
NO. 13 15 Chr XIH:843356 Organic acid transport* 5 0 0
NO. 14 15 Chr V:395442 7 7 3 7
NO. 15 15 Chr XVI:486637 Sexual reproduction* 6 8 4

 

“Number of genes associated with the hotspot. bThe chromosome position of hotspot. CThe most signiﬁcant GO category enriched in the associated gene set. The enrichment
test was performed using DAVID (Huang da and Lempicki, 2008). The gene function is deﬁned by GO Fat category. DAVID outputs the Benjamini7Hochberg adjusted
P—value. Adjusted P—values are indicated by *, where "10‘2 ~ 104; *"10‘3 ~ 10‘5; *"*10‘5 ~ 10‘“). dNumber of associated genes that are functional in the enriched GO
category. 6Number of associated genes that can also be identiﬁed using t—test. fNumber of associated genes that are functional in the enriched GO category and can also be

identiﬁed using t—test. Two novel hotspots (NO. 9 and NO. 13) which cannot be detected by standard linear regression are in bold.

 

1033

112 /310's112u1n0[p101x0"sotwutJOJHtotq/ﬁduq 111011 pap1201um0q

9103 ‘0g1sn8nv 110 ::

C. Yang et al.

 

enriched in GO categories. In detail, for hotspot NO. 9, ﬁve of
the 18 associated genes are functional in response to toxin, they
are AAD4, YDL2]8 W, YLL056C, AAD6 and SPS]00. The hot-
spot eQTL is cis-linked to one of them, AAD4, which apparently
explains the detected association. Hotspot NO. 13 locates at
transcription factor (TF) CAT8. Based on the transcriptional
regulation information in yeast from both direct (Chip-chip) or
indirect (Microarrays7wild type versus TF mutant) evidence
(Teixeira et al., 2006), 9 (they are ADY2, PUT4, GAP], AT03,
ALP], YDR222w, C WP], ADHZ and LPXI) of the 15
associated genes can be potentially regulated by CAT8 (adjusted
P <10’10, the details of the p-Value calculation is given in the
Supplementary Document). Interestingly, ﬁve genes (i.e. ADY2,
PUT4, GAP], AT03, ALP]) are functional in organic acid
transport and CA T8 is known to regulate acid transport pathway
Woung et al., 2003). Identiﬁcation of this hotspot provides a
positive example and indicates that, when non-genetic effect
has been successfully accounted for, we may be able to detect
more biologically relevant trans eQTL.

7 CONCLUSIONS

In this article, we have introduced a method named ‘LORS’ to
account for non-genetic effects in eQTL mapping. LORS pro-
vided a unified framework in which all SNPs and all gene probes
can be jointly analyzed. The formulation of LORS is a convex
optimization problem and thus its global optimum can be
achieved. We also developed an efﬁcient algorithm to solve this
problem and guaranteed its convergence. We demonstrated its
performance using synthetic datasets and real datasets.

A limitation of LORS is that we do not provide a rigorous
statistical signiﬁcance test of the estimated coefﬁcient matrix B.
Here we simply rank associations based on the estimated sparse
matrix abs(B) and estimate FDR.

Funding: This work was supported in part by NSF (DMS
1106738), NIH (R01 GM59507) and NSFC (10901042,
10971075 and 91130032).

Conflict of Interest: none declared.

REFERENCES

Alter,O. et al. (2000) Singular value decomposition for genome—wide expression data
processing and modeling. Proc. Natl Acad. Sci. USA, 97, 10101710106.

Brem,R.B. et al. (2002) Genetic dissection of transcriptional regulation in budding
yeast. Science, 296, 7527755.

Cheung,V. and Spielman,R. (2009) Genetics of human gene expression: mapping
dna variants that inﬂuence gene expression. Nat. Rev. Genet., 10, 595$04.
Cookson,W. et al. (2009) Mapping complex disease traits with global gene expres—

sion. Nat. Rev. Genet., 10, 1847194.
Huang da,W. et al. (2008) Systematic and integrative analysis of large gene lists
using david bioinformatics resources. Nat. Protoc., 4, 44757.

Fan,J. and Li,R. (2001) Variable selection via nonconcave penalized likelihood and
its oracle properties. J. Am. Stat. Assoc., 96, 134871360.

Fan,J. and LV,J. (2008) Sure independence screening for ultrahigh dimensional fea—
ture space. J. R. Stat. Soc. Series B Stat. Methodol, 70, 8497911.

Friedman,J. et al. (2007) Pathwise coordinate optimization. Ann. App]. Stat., l, 3027
332.

Friedman,J. et al. (2010) Regularization paths for generalized linear models via
coordinate descent. J. Stat. Softw., 33, 1722.

Fusi,N. et al. (2012) Joint modelling of confounding factors and prominent genetic
regulators provides increased accuracy in genetical genomics studies. PLoS
Comput. Biol, 8, 61002330.

Gagnon—Bartsch,J. and Speed,T. (2012) Using control genes to correct for unwanted
variation in microarray data. Biostatistics, 13, 5397552.

Gibson,G. (2008) The environmental contribution to gene expression proﬁles. Nat.
Rev. Genet., 9, 5757 581.

Kang,H. et al. (2008) Accurate discovery of expression quantitative trait loci under
confounding from spurious and genuine regulatory hotspots. Genetics, 180,
190971925.

Kang,H. et al. (2010) Variance component model to account for sample structure in
genome—wide association studies. Nat. Genet., 42, 3487354.

Leek,J. and Storey,J. (2007) Capturing heterogeneity in gene expression studies by
surrogate variable analysis. PLoS Genet., 3, e161.

Leek,J. et al. (2010) Tackling the widespread and critical impact of batch effects in
high—throughput data. Nat. Rev. Genet., 11, 7337 739.

Li,C. and Rabinovic,A. (2007) Adjusting batch effects in microarray expression data
using empirical Bayes methods. Biostatistics, 8, 1187127.

Li,L. et al. (2012) eQTL. Methods Mol Biol, 871, 2657279.

Lippert,C. et al. (2011) Fast linear mixed models for genome—wide association
studies. Nat. Methods, 8, 8337835.

Listgarten,J. et al. (2010) Correction for hidden confounders in the genetic analysis
of gene expression. Proc. Natl Acad Sci. USA, 107, 16465716470.

Mazumder,R. et al. (2010) Spectral regularization algorithms for learning large
incomplete matrices. J. Mach. Learn. Res., 11, 228772322.

Nica,A. and Dermitzakis,E. (2008) Using gene expression to investigate the genetic
basis of complex disorders. Hum. Mol Genet., 17 (R2), R1297R134.

Nielsen,T. et al. (2002) Molecular characterisation of soft tissue tumours: a gene
expression study. Lancet, 359, 130171307.

Nowak,G. et al. (2011) A fused lasso latent feature model for analyzing
multi—sample aCGH data. Biostatistics, 12, 77(r791.

Pastinen,T. et al. (2006) Inﬂuence of human genome polymorphism on gene expres—
sion. Hum. Mol Genet., 15 (SuppL 1), R9.

Rasmussen,C. and Williams,C. (2006) Gaussian Processes in Machine Learning. The
MIT Press, Cambridge, MA, USA.

Recht,B. et al. (2010) Guaranteed minimum—rank solutions of linear matrix equa—
tions via nuclear norm minimization. SIAM Rev., 52, 4717501.

Shi,L. et al. (2006) The microarray quality control (MAQC) project shows inter—and
intraplatform reproducibility of gene expression measurements. Nat.
Biotechnol, 24, 115171161.

Smith,E.N. and Kruglyak,L. (2008) Gene—environment interaction in yeast gene
expression. PLoS Biol, 6, e83.

Stegle,O. et al. (2010) A Bayesian framework to account for complex non—genetic
factors in gene expression levels greatly increases power in eQTL studies. PLoS
Comput. Biol, 6, 61000770.

Teixeira,M. et al. (2006) The yeastract database: a tool for the analysis of transcrip—
tion regulatory associations in Saccharomyces cerevisiae. Nucleic Acids Res., 34
(SuppL l), D44(rD451.

Tibshirani,R. (1996) Regression shrinkage and selection via the lasso. J. R. Stat.
Soc. Series B., 58, 2677288.

Tibshirani,R. and Wang,P. (2008) Spatial smoothing and hot spot detection for
CGH data using the fused lasso. Biostatistics, 9, 18729.

Young,E. et al. (2003) Multiple pathways are co—regulated by the protein kinase
Snf1 and the TFs Adrl and Cat8. J. Biol. Chem., 278, 2614(r 26158.

 

1 034

112 /310's112u1n0[p101x0"sotwutJOJHtotq/ﬁduq 111011 pap1201um0q

9103 ‘0g1sn8nV 110 ::

