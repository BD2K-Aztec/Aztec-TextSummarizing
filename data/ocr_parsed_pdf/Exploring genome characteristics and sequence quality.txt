BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

Exploring genome characteristics

 

Fig. 1. Schematic representation of a portion of a de Bruijn graph. Red
vertices are k-mers-containing sequence errors. Green vertices are k-mers
with sequence variation. Blue vertices are repeats

To quantify the structure of the de Bruijn graph, we sample
k—mers and explore the local structure of the graph around the
sampled vertex. Consider the schematic diagram of part of a de
Bruijn graph in Figure 1.

A typical de Bruijn graph—based assembler will try to ﬁnd and
remove branches that are caused by sequencing errors (red ver—
tices), ﬁnd and collapse ‘bubbles’ caused by sequence variation
(green vertices) and attempt to resolve branches caused by
repeats (blue vertices). The rate at which the graph branches
due to repeats and variation are key determinants of assembly
difficulty. In Section 3, we design an algorithm to estimate how
often such branches occur.

3 METHODS

3.1 Framework

The basic building block of the following methods is simply counting the
number of times a particular string occurs in the read collection. For this
task, we use the FM-index (Ferragina and Manzini, 2000) which allows
the number of occurrences of a pattern P in the read collection to be
counted in time proportional to the length of P. We will use the notation
count(P) to refer to this procedure. As our dataset consists of DNA and
we will often want to know the count of P and its reverse-complement, we
deﬁne the function

countDNA(P) = count(P) + count(rc(P))

where the rc(P) function returns the reverse-complement of P.

A second building block of our algorithms is sampling a read at
random from the FM-index of the read collection S. We adapted the
well-known functions to efficiently extract arbitrary substrings of the
text from the FM-index (Ferragina et 01., 2004) to the restricted case of
extracting an entire read from S. We will call the procedure to extract
read i from the index extract(i). For a read collection with n reads, our
sampling procedure simply draws a random number i from 0 to n 7 1 then
runs extract(i).

We can also use the FM-index to implicitly represent the structure of a
de Bruijn graph. In Pevzner’s original definition of a de Bruijn graph
k-mer subsequences of the reads are vertices in the graph (Pevzner
et 01., 2001). Two vertices X and Y are connected by an edge if some
read contains a (k+ 1)-mer that contains X as a preﬁx and Y as a sufﬁx,
or vice-versa. This condition allows one to formulate the assembly as a
tour of the graph that visits each edge at least once. As we do not require
this condition for this work, we adopt the slightly simpler definition of the
graph where the vertex set is the set of k-mer subsequences and the edges
are defined by k 7 1 overlaps between k-mers (Pell et 01., 2012; Simpson
et 01., 2009). For our purposes, we consider a k-mer and its reverse
complement to be the same vertex.

This deﬁnition of the graph allows us to determine the structure of the
graph by simply performing k-mer count queries on the FM-index. Given
a vertex sequence X, we can use the following procedure to find the
neighbors of X. Write X as X=aZ where Z is the k 7 1 suffix of X.
We can then run countDNA(Zb) for b e {A, C,G,T}. The k-mers with
non-zero count represent the ‘suffix neighbors’ of X. The ‘prefix neigh-
bors’ of X can be found similarly.

If a vertex has multiple sufﬁx neighbors, we call it a ‘sufﬁx branch’
(respectively, ‘prefix branch’).

3.2 The k—mer count distribution

The number of times a given k-mer occurs in the sequence reads depends
on the k-mer’s genomic copy number, whether it contains a sequencing
error, and the total number of k-mers drawn from the genome. To model
k-mer counts, we assume a diploid genome and consider different types of
k-mers. First, k-mers containing sequencing errors will occur at some rate
A0 that depends on sequence quality and the total number of k-mers.
Second, k-mers that are present on one of two parental chromosomes
will occur at some rate A1 which is half the rate of k-mers that are present
on both parental chromosomes, A2. We will refer to these k-mers as het-
erozygous and homozygous, respectively. The k-mers that are repeated in
the genome occur at rate A, for r>2. A natural generative model for the
probability of observing a k-mer 6, times for one component is a Poisson
distribution (Lander and Waterman, 1988). In our case as we do not
observe k-mers with count 0, we use a zero-truncated Poisson
distribution:

L7 7A/
A]. e

P(cilz; =11,» = 

(1)
The latent variables 2, indicate the type of the k-mer. For example 2,- = 0
indicates k-mers that contain a sequencing error, 2,- = 1 indicate hetero-
zygous k-mers and so on. The probability of observing 6, reads for k-mer i
can be found by marginalizing out 2,:

P(c. | A, w) = 2m,- | 2,- =1; M)P(Zi =.i|w) (2)
/:0

where P(z,- =_]' | w) = w,- are the mixture proportions.

To fit the parameters of this model, we first construct an empirical
distribution of k-mer counts by sampling 50000 reads from the
FM-index. Let NC = |{K in sample | countDNA(K) = c}|. Intuitively,
NC is the number of sampled k-mers with count 6 across all reads.

We initialize the model by calculating the mean count of homozygous
k-mers A as described in the supplement, fixing the number of compo-
nents n to 10, setting w = [0.1, ...,0.1] and A = [A/50,A/2,A,2A, ...]. The
vector w and A are iteratively updated using the Expectation-
Maximization algorithm (Dempster et 01., 1977) until convergence or
30 iterations to obtain posterior estimates w and A. When updating A
only A0 is changed. The parameters A,- for i >0 are fixed to constrain
the model based on the assumption that the k-mer counts for each gen-
omic copy-number state are directly determined by overall sequence
coverage.

In principle, it is preferable to model the counts as a mixture of nega-
tive binomial distributions to model over dispersion of the count data.
Chikhi and Medvedev (2013) recently modeled the count distribution
using a mixture of Gaussians for this purpose. We found the Poisson
mixture was sufﬁcient for the following applications so opted for the
simpler model.

3.3 Estimating genome size

It is useful to know the expected genome size to evaluate the completeness
of the final assembly. Previously, genome size has been estimated from
the distribution of k-mer counts (Li et 01., 2009). Here we adapt this
method by explicitly correcting for sequencing errors.

 

1 229

/3.IO'S[BIII[10[p.IOJXO'SOIJBIIIJOJIIIOIq/ﬂdnq

J. T.Simpson

 

Assuming all reads are length l and the reads do not contain sequen-
cing errors, there is a simple relationship between k, the number of reads,
n, and genome size, G. There are n(l — k + 1) k-mers in the reads and
G — k + 1 a G (as G >> k) k-mers in the genome. The mean number of
times a homozygous k-mer appears in the reads is therefore:

_n(l—k+l)
_—G .

If we know A, which we approximate from the count distribution as
described in the previous section, G can easily be calculated. If the reads
contain sequencing errors, this calculation requires modiﬁcation. In this
case, the quantity n(l — k + 1), the total number of k-mers in the reads, is
a mixture of genomic k-mers and artiﬁcial k-mers containing errors.
However, A indicates the mean count of homozygous k-mers only, and
does not include k-mers containing errors. Therefore the calculation
G = n(l—k+1)/A will overestimate G as n(l 7k+ 1) is inﬂated by
k-mers with errors. We correct for this effect using wo, the proportion
of k-mers that contain errors from our mixture model. Our genome size
calculation therefore becomes:

A (3)

n(l—k+l)

G=(1—%) (4)

We use k = 31 when estimating genome size.

3.4 Branch classiﬁcation

Sequencing errors, sequence variants and repeats cause branches in the de
Bruijn graph contributing to assembly difﬁculty (Fig. 1). We can estimate
the rate of branching in the graph that can be attributed to each of these
branch types by coupling a graph traversal with a probabilistic classiﬁer.
For this analysis, we assume that the sequenced genome is diploid. We start
by sampling a read from the FM-index then iterating over all k—mers in the
read. We check each k-mer that satisﬁes P(z,» = 2 | 6,», A, w) > 0.90 (the pos-
terior probability of the k-mer being homozygous) for a sufﬁx branch. To
minimize the impact of systematic errors (Guo et al., 2012), we require that
a neighboring k-mer is seen on both sequencing strands to be a valid edge
in the graph. If k,- has more than one sufﬁx neighbor, we attempt to classify
the branch. Let km and k], be the two highest coverage neighbors of k,- with
counts cu and c,,. We set km to be the higher coverage neighbor (ca z 6],).

We classify each such branch using a modiﬁed version of the probabilistic
model designed by Iqbal et a]. (2012). Initially we modeled the total coverage
of the branch, I 2 cu + 6],, using a Poisson distribution with mean A under
the variant and error models and IA in the repeat model (for r z 2, repre-
senting the repeat copy number). This model tended to misclassify repeats as
variants in the case when k,- is from a low-coverage region of the genome, as t
is correlated to c,- and therefore undersampling k,- -biased t to be smaller than
expected. To account for this, we deﬁne a new variable without the depend-
ency on c,-. Let cm (respectively, c,,,) be the number of reads that contain both
k,- and kn (k,- and k1,). We deﬁne d 2 cu + c], — cm — 6,1,. Intuitively, d is the
number of reads that contains km or k], but not ki. Under the variant and
error model this is only possible when km or k], is the ﬁrst k-mer of a read or if
there is a sequencing error in the ﬁrst base of ki. Both of these cases are
relatively rare so d is expected to be very small under the variant and error
model. Under the repeat model km and k], appear in more genomic locations
than k,. This gives more opportunities to sample k-mers covering km and k], so
we expect d to be relatively large.

We use the following distributions for d, conditional on the branch
classiﬁcation:

P(dl error, A, w) = Pois(d; or + woAO) (5a)
P(dl variant, A, w) = Pois(d; or + woAO) (5b)

P(dl repeat, A, w) =
Zr23 Wr

(56)

where or = n/ G is the density of read-starting positions along the
genome. In the repeat model, we sum over repeat states of the mixture
model, where each state represents an integral number of extra genomic
copies of km and k],.

The second source of information is the coverage balance between km
and 10,. If km and k], represent a variant, we expect each k-mer to be
equally well represented. If the branch is due to an error we expect
most reads to support the higher coverage neighbor, kn. We model cover-
age balance with the following distributions:

P(cu, c], |error) = BetaBinom(cu, cu + C7,; 50, 1) (6a)
P(cu, c], | variant) 2 Binom(cu, cu + 61,; 0.5) (672)
P(cu, c], |repeat) = BetaBinom(cu, cu + C7,; 5, 1) (66)

Here BetaBinom(k, n,oz, )3) is the probability mass function of the
Beta-Binomial distribution parameterized by at and )3 and
Binom(k, n,p) is the probability mass function of the Binomial distribu-
tion parameterized by p. The parameters at and )3 of the Beta-Binomial
under the repeat model are chosen to reflect our uncertainty of the gen-
omic copy-number conﬁguration of km and k], (Iqbal et al., 2012).

We calculate the posterior probability of each classiﬁcation using
Bayes’ rule assuming independence of d and C“, c], and a uniform prior
on the classiﬁcations. We then estimate branch rates from the classiﬁca-
tions. We count the number of branches classified as each type
(Ne, N..,Nr) and the number of homozygous k-mers that were checked
for a branch (Nh). Rather than classifying each branch to the type with
the largest posterior probability, we use soft classiﬁcations and update the
branch counts with the expectation from the posterior of the model:

NI = 2 Hz.» = 2 I a». A, w) (M)
ieH

N. = 2 Hz.» = 2 I CI, 2, w)P(error I cu, ch, d, A, w) (7b)
ieB

N. = 2 Hz,» = 2 I cl, A, w)P(variant I cu, c,,, d, A, w) (76)
[GB

N. = 2 Hz.» = 2 I ci, 1, w)P(repeat I c... ch, d, A, w) (M)
ieB

Here H is the set of sampled k-mers that were checked for a branch and B
is the subset of H consisting of k-mers that have a sufﬁx branch.

We perform this classiﬁcation on every k-mer in 1000 000 randomly
sampled reads for k 21771 in increments of 5. For the output plots in the
PDF report the branch rates are calculated as Nr/N,7 and N../N,7. If the
number of branches for a classiﬁcation is <2, no point is plotted for that
value of k.

This model has limited power to distinguish between sequence errors
and variants when A is small. Additionally, if A is too small we will simply
not observe variant branches in the graph due to both alleles not being
represented in the sequence data. Therefore, we do not output classiﬁca-
tions when A< 15.

3.5 Estimating position-speciﬁc error rates

Sequencing errors complicate de Bruijn graph assembly by lowering
effective k-mer coverage and adding false branches to the graph. In over-
lap-based assembly sequencing errors must be accounted for by either
allowing the overlaps to have mismatches or gaps, which leads to false-
positive edges in the graph, or by error correcting the reads prior to graph
construction (Simpson and Durbin, 2012).

To estimate the sequencing-error rate as a function of base position
within the read, we compute read7read overlaps that are seeded by short
exact matches. We begin by sampling a read R from the FM-index and

 

1230

ﬁm'spzumol‘pmﬂo'sopeuuopuorq/ﬁdnq

Exploring genome characteristics

 

computing the set of reads that share a 31-mer with R. For each read in
this candidate set we compute an overlap between the read and R. To
avoid spurious matches between repetitive sequences, we require the over-
lap is at least 50 bp in length and the percent identity is at least 95%. We
construct a multiple alignment using R and the pair-wise overlaps for
reads meeting this threshold. We then compute a consensus sequence
for each column of the multiple alignment. A base call R[]] = b is con-
sidered to be incorrect if I; does not match the consensus base, at least
three reads support the consensus base and fewer than four reads support
base call I). We calculate the error rate at position j as:

 I[base j incorrect in read i]

sf 2 ﬁ. (8)
We use M 2100 000 for the ﬁgures in this manuscript. To avoid
excessively long computation time for repetitive reads, we skip 31-mers
that are seen >200 times in the reads when computing the candidate

overlap set.

3.6 Estimating the fragment-size distribution

To help resolve long genomic repeats, read pairs are typically obtained
by sequencing both ends of a DNA fragment. The fragment size range is
determined during preparation of the DNA prior to sequencing. To
ensure that the sequenced fragment size distribution matches the expected
distribution, we developed a method to estimate the fragment size distri-
bution. We begin by sampling a read pair, X and Y, from the FM-index.
Starting from the ﬁrst 51-mer of X, we perform a greedy search of the
51-mer de Bruijn graph by choosing the highest coverage branch as the
next vertex in the search. The search stops when the ﬁrst 51-mer of Y is
found, there are no possible extensions or 1500 iterations have passed. If
a complete walk from X to Y is found, the length of the walk in nucleo-
tides is emitted as the fragment size. If sequence coverage is low, this
method of estimating the fragment size distribution may be biased to-
wards shorter fragments, as it is more likely that a walk representing a
long fragment is broken by lack of coverage. For Section 4.7, 100 000
read pairs were sampled.

3.7 Simulating de Bruijn assembly

We designed a method to simulate the output of a de Bruijn assembler to
allow the dependency between k-mer size and contig size to be explored.
For small k the graph will branch more often due to repeats than for large
k but for large k we are less likely to sample the complete set of genomic
k-mers leading to coverage breaks. Our simulation allows the balance
between these factors to be explored by performing walks through a de
Bruijn graph mimicking the performance of an assembler that is able to
identify and resolve false branches that are caused by errors and bubbles
that are caused by variants. As opposed to most assemblers which classify
branches as errors, variants or repeats based the topology of the graph we
use the probabilistic model developed in Section 3.4 to guide the graph
traversal.

We begin by sampling a read at random and calculating the probabil-
ity that the ﬁrst k-mer of the read is a homozygous k-mer as in the branch
classiﬁcation method. If the probability is <0.50, we discard this read and
start again. Otherwise we begin a new contig starting from the ﬁrst k-mer
of the read.

Let X be the current k-mer of the contig. We check X for a branch as in
our branch classiﬁcation method. If X does not have a branch, or has a
branch that is classiﬁed as an error or variant, we iterate from the highest-
coverage neighbor. If X does not have a neighbor or has a repeat branch
we terminate extension of the contig. This procedure occurs for both the
sufﬁx neighbors of the initial k-mer and the preﬁx neighbors. Once the
extension has terminated in both directions the number of k-mers visited
is written to the output ﬁle.

To avoid excessively long computation time we cap the maximum walk
length at 50 000 and stop extension if a particular k-mer is visited twice.
We also do not allow a given walk to be used multiple times by recording
all visited k-mers in a bloom ﬁlter. Starting k-mers that are present in the
bloom ﬁlter are skipped. We perform 20 000 walks for each k from 21 to
91 in increments of 5.

3.8 Computations

The program to calculate the genome characteristics and qc metrics is
implemented as a module of the SGA assembler in C++. This program
writes the results to a JSON ﬁle, which is read by a Python script
to generate the PDF report. The computations performed in this article
are fully reproducible by downloading and running the following
Makeﬁle:

https: //github.com/jt s/preqc-paper/tree/master/bin/generate_data.make

The Makeﬁle will download the input data from public repositories,
run SGA, and then generate the ﬁnal reports. Version 0.10.12 of SGA
was used to generate the data and ﬁgures for this article. The JSON-
formatted results are available online (ftp://ftp.sanger.ac.uk/pub/js18/
preqc-paper).

The computation time for the human data, the largest set used in the
article, was 13h (elapsed time) to download the data, 18h to build the
FM-index and 6 h to calculate the metrics. The memory high-water mark
was 56 GB during construction of the FM-index. For the other genomes
the index construction time ranged from 1 h for the yeast data to 14h for
the snake data. The metrics calculation runtimes ranged from 2h (yeast)
to 9 h (bird).

4 RESULTS
4.1 Input data

In the following sections, we demonstrate the output of our pro—
gram using freely available data from genomes of varying com—
plexity. The selected datasets and their accessions are:

c Saccharomyces cerevisiae (ERR049929),

o Melopsittacus undulatus, a budgerigar from Assemblathon2
(ERR244146),

o Maylandia zebra, a Lake
Assemblathon2 (SRX033046),

o Boa constrictor constrictor, a snake from Assemblathon2
(ERR234359-ERR234374),

o Crassostrea gigas, a
SRR322877),

o Homo sapiens, a human genome (ERR09157l—ERR091574).

Malawi Cichlid from

Paciﬁc oyster (SRR3228 74—

For simplicity and consistency with the Assemblathon2 paper,
we will refer to these datasets as ‘yeast’, ‘bird’, ‘ﬁsh’ ‘snake’,
‘oyster’ and ‘human’. The yeast genome was selected to provide
an example of an uncomplicated genome that is typically
straightforward to assemble. In contrast, the oyster genome is
highly heterozygous and repeat—rich. This genome was recently
sequenced using a fosmid—pooling strategy after whole genome
assembly failed to produce satisfactory results (Zhang et al.,
2012). The human and Assemblathon2 datasets represent a
range of large eukaryotic genomes of varying heterozygosity
and repeat content. Multiple high—coverage sequencing libraries
are available for the human and Assemblathon2 samples. For
each genome a single library was selected for analysis. For the

 

1231

ﬁm'spzumol‘pmﬂo'sopeuuopuoiq/ﬁdnq

 

/310'S[BIIJHO[pJOJXO'SOIJBLUJOJIIIOIq/ﬂduq

 

/310'S[BIIJHO[pJOJXO'SOIJBLUJOJIIIOIq/ﬂduq

an?kgogmomammowoio~&o:3m7.omm\

 

Exploring genome characteristics

 

Dempster,A.P. et al. (1977) Maximum likelihood from incomplete data via the EM
algorithm. Journal of the Royal Statistical Society. Series B (Methodological),
39, 1738.

Dohm,J.C. et al. (2008) Substantial biases in ultra—short read data sets from high—
throughput DNA sequencing. Nucleic Acids Res., 36, e105.

D0nmez,N. and Brudno,M. (2001) Hapsembler: an assembler for highly poly—
morphic genomes. In: Proceedings of the 15th Annual International Conference
on Research in Computational Molecular Biology, RECOMB’ll, pp. 38752.
Springer—Verlag, Berlin, Heidelberg.

Ferragina,P. and Manzini,G. (2000) Opportunistic data structures with applica—
tions. In: Proceedings 41st Annual Symposium on Foundations of Computer
Science. IEEE Comput. Soc, Los Alamitos, CA, USA, pp. 3907398.

Ferragina,P. et al. (2004) An alphabet—friendly FM—index. In: Apostolico,A. and
Melucci,M. (eds) String Processing and Information Retrieval, Vol. 3246 of
Lecture Notes in Computer Science, pp. 1507160. Springer, Berlin Heidelberg.

Genome 10K Community of Scientists. (2009) Genome 10K: A proposal to obtain
Whole—Genome sequence for 10000 vertebrate species. J. Heredity, 100,
6597674.

Goffeau,A. et al. (1996) Life with 6000 genes. Science (New York, N.Y.), 274,
54G567.

Guo,Y. et al. (2012) The effect of strand bias in illumina short—read sequencing data.
BM C Genomics, 13, 666.

Iqbal,Z. et al. (2012) De novo assembly and genotyping of variants using colored de
bruijn graphs. Nat. Genet., 44, 22(r232.

Keegan,K.P. et al. (2012) A platform—Independent method for detecting
errors in metagenomic sequencing data: DRISEE. PLoS Comput. Biol, 8,
e1002541.

Kelley,D. et al. (2010) Quake: quality—aware detection and correction of sequencing
errors. Genome Biol, 11 (11), R116.

Kingsford,C. et al. (2010) Assembly complexity of prokaryotic genomes using short
reads. BMC Bioinform., ll, 21.

Kozarewa,I. et al. (2009) Ampliﬁcation—free illumina sequencing—library preparation
facilitates improved mapping and assembly of (G+C)—biased genomes. Nat.
Methods, 6, 2917295.

Lander,E.S. and Waterman,M.S. (1988) Genomic mapping by ﬁngerprinting
random clones: a mathematical analysis. Genomics, 2, 2317239.

Li,R. et al. (2009) The sequence and de novo assembly of the giant panda genome.
Nature, 463, 3117317.

Nakamura,K. et al. (2011) Sequence—speciﬁc error proﬁle of illumina sequencers.
Nucleic Acids Res., 39, e90.

Pell,J. et al. (2012) Scaling metagenome sequence assembly with probabilistic de
bruijn graphs. Proc. Natl Acad. Sci. USA, 109, 13272713277.

Pevzner,P.A. et al. (2001) An eulerian path approach to DNA fragment assembly.
Proc. Natl Acad. Sci. USA, 98, 974879753.

Ross,M. et al. (2013) Characterizing and measuring bias in sequence data. Genome
Biol, 14, R51.

Schroder,J. et al. (2010) Reference—Free validation of short read data. PLoS ONE,
5, e12681.

Simpson,J.T. and Durbin,R. (2012) Efﬁcient de novo assembly of large genomes
using compressed data structures. Genome Res., 22, 5497556.

Simpson,J.T. et al. (2009) ABySS: a parallel assembler for short read sequence data.
Genome Res., 19, 111771123.

The Potato Genome Sequencing Consortium. (2011) Genome sequence and analysis
of the tuber crop potato. Nature, 475, 1897195.

Wang,X.V. et al. (2012) Estimation of sequencing error rates in short reads. BMC
Bioinform., 13, 185.

Weber,J.L. and Myers,E.W. (1997) Human Whole—Genome shotgunsequencing.
Genome Res., 7, 4014109.

Zerbino,D.R. and Birney,E. (2008) Velvet: Algorithms for de novo short read as—
sembly using de bruijn graphs. Genome Res., 18, 8217829.

Zhang,G. et al. (2012) The oyster genome reveals stress adaptation and complexity
of shell formation. Nature, 490, 49754.

 

1 235

ﬁm'spzumol‘pmyo'sopeuuopuorq/pdnq

