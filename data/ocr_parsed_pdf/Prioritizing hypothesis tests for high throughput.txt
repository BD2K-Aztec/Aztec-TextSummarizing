Bioinformatics, 3216), 2016, 850—858

doi: 10.1093/bioinformatics/btv608

Advance Access Publication Date: 16 November 2015
Original Paper

 

Genetic and population analysis

Prioritizing hypothesis tests for high
throughput data

Sangjin Kim and Paul Schliekelman*

Department of Statistics, University of Georgia, Athens, GA 30602, USA

*To whom correspondence should be addressed.
Associate Editor: Alfonso Valencia

Received on December22, 2014; revised on September 11, 2015; accepted on October 16, 2015

Abstract

Motivation: The advent of high throughput data has led to a massive increase in the number of
hypothesis tests conducted in many types of biological studies and a concomitant increase in stringency
of significance thresholds. Filtering methods, which use independent information to eliminate less prom—
ising tests and thus reduce multiple testing, have been widely and successfully applied. However, key
questions remain about how to best apply them: When is filtering beneficial and when is it detrimental?
How good does the independent information need to be in order for filtering to be effective? How should
one choose the filter cutoff that separates tests that pass the filter from those that don’t?

Result: We quantify the effect of the quality ofthe filter information, the filter cutoff and other factors
on the effectiveness of the filter and show a number of results: If the filter has a high probability (e.g.
70%) of ranking true positive features highly (e.g. top 10%), then filtering can lead to dramatic increase
(e.g. 10—fold) in discovery probability when there is high redundancy in information between hypoth—
esis tests. Filtering is less effective when there is low redundancy between hypothesis tests and its
benefit decreases rapidly as the quality of the filter information decreases. Furthermore, the outcome
is highly dependent on the choice of filter cutoff. Choosing the cutoff without reference to the data will
often lead to a large loss in discovery probability. However, na'ive optimization of the cutoff using the
data will lead to inflated type I error. We introduce a data—based method for choosing the cutoff that
maintains control of the family—wise error rate via a correction factor to the significance threshold.
Application ofthis approach offers as much as a several—fold advantage in discovery probability rela—
tive to no filtering, while maintaining type I error control. We also introduce a closely related method
of P—value weighting that further improves performance.

Availability and implementation: R code for calculating the correction factor is available at http://
www.stat.uga.edu/people/faculty/paul—schliekelman.

Contact: pdschlie@stat.uga.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

1 Introduction

A dominant trend in biology in recent years has been the develop-
ment of high throughput techniques and the dramatic increase in the
resolution of available data. However, most of the information
gained is not relevant for any particular question at hand and comes
at the cost of more hypothesis tests and thus more stringent statis-
tical thresholds. There is often high redundancy between tests and
the gain in information may be slower than the increase in

resolution. Thus, higher resolution will not always lead to higher
probability of discovery.

Given the realities of multiple testing, it is unlikely that a mere
increase in throughput and resolution will greatly increase discov-
eries. Rather, it will be necessary to combine high throughput data
with other sources of information in order to better target investiga-
tions. The problems of multiple testing are well understood and
many methods have been proposed for using external information

(63 The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 850

/310‘srcumo[p10}xo‘sopcuHOJIItotq/ﬁdnq

Prioritizing hypothesis tests for high—throughput data

851

 

to filter for the most promising features of the data. Such methods
typically have two stages: first, some filtering criterion is used to se—
lect the most promising features. Then, only those features are tested
for the effect of interest. These include methods for microarrays
(Bourgon, et al., 2010; Clevert, et (11., 2013; Hackstadt and Hess,
2009; Jiang and Doerge, 2006; Lu, et al., 2011; McClintick and
Edenberg, 2006; Talloen, et al., 2007; Talloen, et al., 2010), RNA—
Seq (Bottomly, et (11., 2011; Ramskold, et al., 2009; Rau, et al.,
2013a, b; Sultan, et al., 2008), genome—wide association studies
(Calle, et al., 2008; Dai, et al., 2012; Degnan, et al., 2008; Li, et al.,
2013; Patvvardhan, et al., 2014; Roeder and Wasserman, 2009; Van
Steen, et (11., 2005) and epistasis (Emily, et (11., 2009; Evans, et al.,
2006; Pattin and Moore, 2008; Yang, et (11., 2009).

Despite the popularity of filtering methods, key questions remain
about their general statistical properties. Bourgon et al. (2010) dis—
cussed the conditions sufficient for maintaining Type I error control
and showed that the key requirement is that the null hypothesis dis—
tribution of the test statistics after filtering should be the same as the
null hypothesis distribution before filtering. They showed that some
filtering techniques in use can violate this requirement. Their focus
was on the conditions for filtering to be valid. Little is known about
the conditions required for filtering to be successful in significantly
increasing discovery probabilities, and our focus is on this question.

In this paper, we address two major issues. First, we evaluate the
usefulness of filtering and determine major factors affecting its be—
havior. We quantify the effect of the filtering statistic in terms of its
probability of ranking true effects highly. We show that a strong fil—
ter that has a high probability of ranking true positives in e.g. the
top 10% can greatly increase discovery probability (as much as
20—fold) when there is high redundancy between features and when
a good cutoff is known in advance. Even a random filter can in—
crease power when the cutoff point is well chosen. On the other
hand, filtering is less effective when there is low redundancy be—
tween features and if the filter statistic is not able to reliably rank
true positive features highly.

Second, most applications of filtering methods have used ad—hoc
approaches to choosing the filter cutoff point. The filter cutoff point
refers to the value of the filtering criterion which separates features
that will be included in the second stage and those which will not.
We show that the filter cutoff has a large effect on the performance
of filtering methods. A good choice can make a several—fold differ—
ence in discovery probability relative to a poor choice. Furthermore,
inappropriate ad—hoc methods can greatly inflate false positive rates.
We introduce a general and rigorous method for choosing the filter
cutoff and show that this approach can increase discovery probabil—
ities by several—fold relative to no filtering. We also introduce a sim—
ple and intuitive method for weighting p—values that is closely
related to our filtering method and improves the performance
further.

2 Methods

2.1 Optimized filtering

Consider a generic high throughput study. There are L true effects in
the data and m potential hypothesis tests that could be performed in
order to find those effects. In a QTL mapping study, the true effects
would be genetic polymorphisms that affect the trait of interest and
the hypothesis tests would be genetic markers. In an RNA—seq study,
the true effects would be genes that are differentially expressed be—
tween treatment conditions and the hypothesis tests would be the
genes that are tested.

Now, suppose that the hypothesis tests are ordered by a filtering
criterion that attempts to identify the tests most likely to be able to
identify true effects with the best candidate test being ranked #1, se—
cond best #2 and so on. The filtering criterion will be based on some
biological knowledge of the hypothesis tests derived from independ—
ent data. The top U tests on this filter—ordered list will be conducted
and the remaining tests will be discarded. Discarding tests will re—
duce multiple testing and potentially increase power. Our goal is
determining what U should be in order to maximize power.

We choose a vector 5 : (111....nR) of proposed values for U,
where n,- is the number of filter—ordered tests, R is the total number
of subsets of tests, 111 < 112 <. . . . . < 11R 3 m and each subset is
included in the larger ones. Thus, we test 1 to 111, 1 to 112, etc. Take
71 . 1’2. . . . . .rm to be the P—values for the filter—ordered hypothesis
tests. The test set nk refers to the filter—ordered set of hypothesis tests
1 to k. A hypothesis test 1' in test set nk is significant if

(1)

ri < A. X 11k
where or is the desired family—wise error rate (FWER). That is, a
Bonferroni correction for the number of tests 11;, is applied with a
correction factor 2 that will correct the multiple testing adjustment
for the fact that we will optimize v overﬁ. We then take whichever
test set maximizes the number of rejected null hypotheses. We show
in the SI that

{x 711 R—1 {x "Al—"r
FWERg 1 — (1 ——> (1 — —> (2)
A. X 1’11 [:1 A. X 11,41

This has a simple interpretation: in order for no tests to be signifi—
cant, then no p—value can be lower than the least—stringent threshold
at which it is tested. The least—stringent threshold to which the first
111 tests are compared is oc/(l X 111). The least stringent threshold to
which the next 112—111 tests are compared is oc/(l >< n2),etc. We obtain
the correction factor 2 required to control FWER by equating (2) to
or and solving for /l.The resulting equation does not have a closed
form solution, but can easily be solved numerically. We conducted
simulations to verify that this expression correctly controls FWER
(Supplementary Fig. S1). Supplementary Figures S1 and S2 show a
plot of calculated correction factors as a function of the number of
elements of Z. The Supplementary Material also shows approximate
closed—form solutions for the correction factor.

We focus on the control of FWER in this paper, which is import—
ant for applications such as QTL and genetic association mapping.
A future paper will address control of FDR.

Some filtering schemes will result in tied ranks. Provided that
tied tests lie in the same block between consecutive elements of the
vector 5, then they will be tested at the same significance threshold.

Our approach assumes independence between tests in calculating
the correction factor. However, there will usually be substantial cor—
relation between tests. An alternative is to estimate an effective num—
ber of independent tests. Such approaches can be implemented in
our method by calculating an effective number of tests within each
subset. Simulation results in the SI show that this approach can im—
prove power while maintaining Type I error.

We illustrate the above method with a simple example in
Table 1. There are m : 9 total hypothesis tests and we take 5 : [3,
6, 9]. The filter—ranked P—values are shown in the table. Note that
the filter—ranking will not correspond exactly to the p—value order
and thus the p—values are not ordered. First consider the case with
no correction to the significance threshold. In the first test set, the
P—values are tested against a threshold of 0.05/3 : 0.0167 and two

/3.IO‘SI€III[10[p.IO}X0‘SDDEIIIJOJIIIOIQ/[Zdllq

852

S.Kim and P.Schliekelman

 

Table 1. Toy example with m = 9 P-values and test sets of B = [3, 6, 9]

 

 

 

 

 

 

P-value Without correction factor (2 = 1) With correction factor (2 = 1.793)

Test set Test set

141:3 142:6 143:9 141:3 142:6 143:9
Signiﬁcance Threshold .0167 .0083 .0056 .0093 .0046 .0031
P1 .0011 .0011 .0011 .0011 .0011 .0011
P2 .0092 .0092 .0092 .0092 .0092 .0092
P3 .0201 .0201 .0201 .0201 .0201 .0201
P4 .0089 .0089 .0089 .0089
P5 .0091 .0091 .0091 .0091
P6 .0064 .0064 .0064 .0064
P7 .0022 .0022
Pg .0861 .0861
P9 .0045 .0045

 

The Signiﬁcance thresholds are calculated as 0.05/n) without the correction factor and 0.05/(n; >< 1.793) with the correction factor. The P-values in bold are less

than the signiﬁcance threshold for that test set.

are significant (shown in bold). In the second test set, the threshold
becomes 0.05/6 : 0.0083. One of the previously significant P—values
0.0092 becomes non—significant, but a newly added P—value 0.0064
is significant. In the third test set, the P—values are tested against a
threshold of 0.05/9 : 0.0056. Now the 0.0064 P—value drops out of
significance, but two new P—values 0.002 and 0.0045 are significant.
The third test set has the highest number (three) significant P—values
and thus we would take U : 9 as the optimal cutoff.

However, we have not accounted for the effect of this optimiza—
tion on the FWER. We are maximizing rejections over three sets and
the expected number of false positives will be increased by this
maximization. The probability of type I error is the probability that
there is at least one false positive across the three sets. The first set
in which a P—value appears has the least stringent threshold that
p—values will be tested against. If it is not rejected in that test set,
then it will not be rejected in any (see SI for more details). Thus, the
probability of type I error is

0.05 2 P(S 2 1)
= 1 — P(S = 0)
= 1 — (1 — o.o5/31)3(1 — 0.05/6i)(6’3)(1 — 0.05/9M“)

where 0.05 is a target FWER, S is the number of type I errors and /l
is the correction factor based on 3 candidate subsets. We numeric—
ally solve this equation for 2, yielding A : 1.793. After applying the
correction factor, the significance thresholds decrease to the values
shown in the table and the number of significant tests decreases as
well. Now, test sets 1 and 3 both have two significant tests and thus
we can take either U : 3 or U : 9 as the optimal cutoff.

2.2 Power gains from filtering
Our first goal is to explore the potential gain in statistical power
from filtering. Consider again the generic high—throughput experi—
ment discussed earlier. We will focus on one specific true effect that
we label as effect ‘5 . There are m potential hypothesis tests that
could be performed in order to find this effect and r of these tests
can actually detect the effect ‘5 . ‘ ‘5 -tests’ refers to these tests. We
will make the approximation that all of these 1’ tests have the same
power to detect ‘5 .

Suppose that all of the tests are ordered by a filtering criterion
and the first U such tests are conducted and the remainder discarded.
For the moment, we will assume that U is fixed in advance so that a

simple Bonferroni correction will suffice and no adjustment to the
significance criterion needs to be made. The probability that at least
one of the r ‘5 -tests successfully detects ‘E is

r

WV) 2 Z v.(s)%(5)

5:1

where v is the number of filter—ordered hypothesis tests conducted,
y,,(s) : probability that 5 out of the r ‘5 —tests are included in the top
U tests, and ([9,,(5) : probability that at least one of the s ‘5 —tests de—
tects ‘E . We refer to [ML/)as the discovery probability. We use this
terminology to distinguish it from the power for a single test. We as—
sume that the test statistics for the r ‘5 —tests follow a multi—normal
distribution with mean 0 when the null hypothesis is true and with
the mean determined by the effect size when the null hypothesis is
false. The correlation coefficients will be varied and reflect the
amount of correlation between tests.

The function yv(s)quantifies the effectiveness of the filter. An ef—
fective filter will rank hypothesis tests highly that are able to detect
true effects. We assume that the top U filter—ordered tests are inde—
pendently sampled without replacement from the m total tests, of
which 1’ are ‘5 —tests. Take q(u)as the probability that a given ‘5 —test
is included in the top proportion 14 of all hypothesis tests. q(u) is
modeled with a beta CDF, giving great flexibility for determining
the properties and effectiveness of the filter function. If sampling
was with replacement, then the function 10(5) would follow the bi—
nomial distribution with U trials and q(U/m) as the probability of suc—
cess. However it instead follows Wallenius’ noncentral
hypergeometric distribution (Fog, 2008a, b) because sampling is
without replacement. If the filtering is effective, then the ‘5 —tests
will have a higher probability of being selected, which distinguishes
the distribution from a standard hypergeometric. Wallenius’ non—
central hypergeometric accounts for this. See SI for further details.

The assumption of independence in filter rank may be violated in
some data sets and the benefits of filtering will be lower (see SI). The
discovery probability formula is implemented in an R program that
is included in the SI.

Example Scenarios. In our calculations below, we will consider
two basic scenarios. The first scenario has a single test capable of de—
tecting each true effect. This is characteristic of, for example, micro—
array and RNA—seq studies. In these studies, we are interested in
determining which genes are differentially expressed between

ﬁlO'SIIZLImOprOJXO'SOplZIIJJOJLIIOIQ/[idnq

Ionita-Laza (Ii LIL (2007)

Benjamini and IIoehberg, 1997 Firms and
Salmaso, 2007 (ienm ese, (Ii LIL, 2006 IIolm, 1979 Kropf, (Ii LIL,
2004 Roeder and \Wasserman, 2009 Roquain and van de \Wiel,
2009 Rubin, (Ii LIL, 2006 \Wasserman, (Ii LIL, 2006 \X’estfall, (Ii LIL,
2004

Figure 1

' F'rT “ I
Equatlon (I) lhulc

Figure 1

Eq. (2)
r=1,n=50, m=10.000

Table 1

Figure 1

Figure 1

r=20.n=‘10.cor=0.2. m=1000

1m

r=2l1|.n=200,cor=0.9. m=1000

 

/310's112u1no[p10}xo'sopeuiJOJutotq”:dnq

Figure 1

Figure 1

Figures 1

Figure 2

Figure 1

Figures 1

Figure 1

Figure 1

ﬁlter

Fig. 2

Figs2

4

 

/310's112u1no[p10}xo'sopeuiJOJutotq”:dnq

Figure .3

Figure 4

number f t

Figure 2

Figure 2

(ihazalpour e! LIL (2006)

Smith, 0! LIL, 2014

r=2 0, co r=0.2

._____.__‘_

 

/310's112u1no[p10}xo'sopeuiJOJutotq”:dnq

856

S.Kim and P.Schliekelman

 

candidates for being body weight QTLs. Because we did not use the
body weight data in calculating the filter ranks, then the filter ranks
will be independent of the LOD scores with respect to body weight
under the null hypothesis that the SNP is not a body weight QTL.
We consider both the optimal filtering approach (Eq. (1)) and the
P—value weighting approach (Eq. (3)).

There were four chromosomal regions with some evidence for
body weight QTLs, although no SNP is significant under the stand—
ard Bonferroni correction with 1065 tests. For the SNP with the best
chance of being detected in each of the four QTL regions, Table 2
shows the filter rank and the maximum number of tests for which it
would be significant under a Bonferroni correction. The maximum
number of tests gives a measure of how significant the test is. If the
maximum tests equals or exceeds m : 1065, then the SNP would be
significant under a standard Bonferroni correction. The lower this
quantity is below m, then the better the filter will have to perform in
order for the SNP to be significant.

The SNP shown in the table for each QTL region is the SNP with
the highest value of (max tests to be significant)/(filter rank). The
most significant SNPs are on chromosome 19. The strongest would
be significant if tested among 591 or fewer SNPS. These SNPS have
filter ranks of about 400 (among 1065). Three other SNPs in the
same region are moderately weaker, but are filter—ranked at about
the 17th percentile. The most significant SNP of these is shown in
the Table 2. It would be significant if tested among 444 or fewer
markers. The next most significant region is on chromosome 15.
The most significant markers would be significant if tested among
190 or fewer markers. These markers are filter—ranked very highly at
about the 1% point. The third most significant region is on chromo—
some 5. The strongest SNP would be significant if tested among 124
or fewer markers. The filtering ranking is ineffective with this SNP,
placing it about the 33rd percentile. The fourth strongest region is
on chromosome 1. Although several markers are filter—ranked at
about the 10th percentile, the most significant SNPs would have to
be filter—ranked in the top 5% to be significant. No other regions
show any evidence of QTLs. The most significant SNP outside of
these four regions would only be significant if tested among six or
fewer markers and most of the remaining P—values are greater than
0.05. Supplementary Table 51 in the SI shows the top 20 most sig—
nificant SNPS.

Table 2 shows the results of using three different schemes for
optimizing the filter: 5: 100—500 in increments of 100, 5:25—
1050 in increments of 25 and 5 :50—200 in increments of 50. For
each combination of SNP and search scheme, we show the lowest
value (labeled ‘Next highest inc.’) of E that is higher than the filter
rank (i.e. the value at which the SNP will be tested), and that value
multiplied by the correction factor (i.e. the effective number of hy—
pothesis tests in the Bonferroni correction for that SNP, labeled
‘Corrected’). The SNP will be significant if this corrected value is

less than or equal to the maximum Bonferroni—corrected number of
tests for that SNP (column 3 in the Table). The corrected values are
bold in cases where this occurs.

Under the first scheme, the QTL on chromosome 19 is signifi—
cant. It has filter rank 182 and thus the next highest increment is
200. After multiplying by the correction factor of 222.22, the ef—
fective number of tests is 444 and the marker is significant. No other
markers are significant. Although the marker on chromosome 15 is
very highly ranked (12th), the next highest increment is 100 under
this relatively coarse search scheme. This marker is too weak to be
significant under the resulting 222 effective number of tests. These
results are the same whether we use the optimal filtering approach
or the weighted P—value approach.

The second search scheme uses increments of 25. This causes the
correction factor to increase from 2.22 to 4.17. However, this re—
sults in a decrease from 100 to 25 in the next highest increment for
the 12th—ranked chromosome 15 marker. Even after applying the
higher correction factor, the marker is still significant. On the other
hand, the chromosome 19 marker is no longer significant. The finer
search grid makes no difference in the next highest increment (200
in both cases) and the higher correction factor causes the marker to
lose significance.

The third search scheme uses increments of 50, but only for the
top 200 filter—ordered tests. The 12th—ranked chromosome 15
marker has a next highest increment of 50. After applying the cor—
rection factor of 2.03 the effective number of tests is 104 and it is
significant. The 180th—ranked chromosome 19 marker again has a
next highest increment of 200. With the lower correction factor of
2.03, the effective number of tests is 406 and it is also significant.
Under the optimal filtering approach, we would have a choice of
taking the filter cutoff at either 50 or 200 and get one QTL either
way. Under the weighted p—value approach, both QTLs are
significant.

These examples show the tradeoffs in choosing different search
schemes. Smaller search increments will tend to favor highly
ranked features, because they can make a large proportional differ—
ence in the minimum number of tests including that feature. The
chromosome 15 marker benefits greatly from being tested among
25 features rather than 100, even after correction factor. On the
other hand, a lower ranked feature gets less proportional benefit
and may decrease in discovery probability because of an increase
in 2.

We have shown the results of several different search schemes in
order to demonstrate important aspects of our method. However, it
should be noted that the search scheme must be chosen in advance
of seeing the data, or the Type I error rate will be inflated. Naive ad—
justment of the search scheme to get the largest number of positive
results will inflate false positives just as naive adjustment of the filter
cutoff does.

Table 2. The SNPs with the highest value of (max tests)/ (filter rank) for each of the four putative QTL regions

 

Search scheme

 

100—500 by 100 2 = 2.22

25—1050 by25 2 =4.17 50—200 by50 2 =2.03

 

 

ID CHR. Max tests Filter rank Next Highest Inc. Corrected Next Highest Inc. Corrected Next HighestInc. Corrected
1345915 19 444 182 200 444 200 834 200 406
1344593 15 190 12 100 222 25 104 50 102
p45558 5 124 353 400 888 375 1564 — —
p46339 1 53 101 200 444 125 521 150 305

 

ﬁm'srcumol‘pquo'sopcuuopttotq/ﬁdnq

Prioritizing hypothesis tests for high—throughput data

857

 

4 Discussion

Although filtering methods have been in common use throughout
the genomic era, their general statistical properties are not well
understood. In this study, we have introduced a framework that
quantifies filter effectiveness in terms of the probability of a feature
associated with a true effect being ranked at or above a specified
quantile. Using this approach, we have examined the conditions for
filtering to be successful.

First, we have shown that filters can be very effective at increas—
ing discovery probabilities for weak effects. However, the filter must
have a substantial probability of ranking true positive features
highly (e.g. the top 10%). Furthermore, the benefit of filtering is
greater when there is high redundancy in information between hy—
pothesis tests. In this case, a filter with a high probability of ranking
true positive features in the upper 10% can increase discovery prob—
abilities by 10—fold or more. The gain is less with lower redundancy
between tests, but there is a several—fold (and higher) benefit over a
wide range of conditions of filter effectiveness and redundancy in
tests. In applications such as QTL mapping and GWAS, there are
commonly many tests capable of detecting each true effect. In this
case, filtering can be highly effective. In applications such as stand—
ard transcriptomics or proteomics where there is a single test per
true effect, then redundancy is minimal and filtering less effective
but can still be beneficial.

A major caveat is that the increased benefit in the case of high re—
dundancy is contingent on the correlation in filtering ranks being
low after conditioning on shared causative mechanism. If there is
additional correlation (as in our QTL example where the ranks are
all derived from the same data), this benefit is reduced (SI).

Second, the gain from filtering is highly dependent on the choice
of filter cutoff. The choice of cutoff can easily make a 2— to 3—fold
difference in discovery probability in the lower redundancy situation
and a bigger difference in the high redundancy case. Most applica—
tions of filtering choose the cutoff in an arbitrary fashion, poten—
tially leading to large loss in discovery probabilities relative to what
is possible. Even worse, however, is choosing the cutoff based on the
outcome without properly accounting for type I error. FWER can be
greatly inflated when the cutoff is naively chosen based on the data.

Third, we have introduced a method for choosing the filter cutoff
that finds the best value and properly accounts for the effect on
FWER. Even after adjusting for the search procedure, there can still
be a gain of several—fold in discovery probability relative to an arbi—
trary choice of cutoff. This data—dependent filtering procedure leads
naturally to a closely related data—independent p—value weighting
technique. In this approach, tests are filter—ordered in blocks and
weighted by the inverse of the filter percentile rank for the lowest
ranked member of the block, adjusted by a correction factor that en—
sures the target FWER is maintained. This method will always per—
form at least as well as optimal filtering and will sometimes result in
more rejected null hypotheses while maintaining the same FWER.

The benefit of filtering depends strongly on effectiveness that the
filter statistic is at ranking true effects highly. According to our re—
sults, a filter statistic with a high probability (say 70%) of ranking
true effects in the top 10% can substantially improve discovery
probabilities. Filters that are substantially less effective than this will
not be likely to improve discovery probabilities and may make them
worse. Determining whether filtering statistics can be expected to
routinely perform this well is a crucial question that should be ad—
dressed in future research.

It is important to emphasize that P—value weighting/optimal fil—
tering does come at a cost relative to the case where we know the

correct filter cutoff in advance. A comparison of Figures 2 and 4
shows that discovery probabilities can be reduced by a factor of two
or more between the case where we know the optimal filter cutoff
and the case where we have to search for it. Furthermore, there is a
tradeoff in deciding how finely we should search for the peak.
Searching more finely makes it more likely to find the peak, but
comes at a cost of a bigger FWER correction. When there is high
correlation between hypothesis tests, then peaks tend to be sharper
and searches with a finer grid may be beneficial. Future research
should investigate the shape of filter functions for different types of
data and filtering information. This would provide insight into the
best choice of the vector 5. Ideally, we would determine where good
cutoff points tend to be for particular types of data. Then, optimiza—
tion of the filter would not be required and the full benefits of filter—
ing could be realized.

Another finding from this work (Figure 1d and SI) is that filter—
ing can greatly increase the relative discovery probability for weak
effects, but it is constrained in terms of the absolute gains in power
that are possible. Whether such gains for weak effects are of much
value depends on the distribution of effect sizes. For example, accu—
mulating evidence suggests that complex traits in humans are often
driven by very large numbers of very low effect genetic variants (e.g.
Gibson, 2011). In such a scenario, a boost in discovery probability
from, for example, 0.1 to 1% for many such variants would be very
significant. On the other hand, filters will be less effective at, for ex—
ample, boosting power from 20% to 80% unless the filter is very ef—
fective at ranking true positive features highly.

A number of previous studies (Benjamini and Hoehberg, 1997;
Finos and Salmaso, 2007; Genovese, et al., 2006; Holm, 1979; Ionita—
Laza, et al., 2007; Kropf, et al., 2004; Roeder and Wasserman, 2009;
Roquain and van de Wiel, 2009; Rubin, et al., 2006; Wasserman,
et al., 2006; Westfall, et al., 2004) have proposed alternative methods
for P—value weighting and several studies (Roeder and Wasserman,
2009; Rubin, et al., 2006; Wasserman, et al., 2006) have derived opti—
mal weights based on the true effect size. However, true effect size is
never known and optimality is unclear under schemes for estimating
it. Our correction factor approach is based solely on the filter—ranks.
It will tend to perform better for sufficiently good filter—ranks, but the
relative merits in practical circumstances are unclear. A future manu—
script will explore these issues more thoroughly.

Funding

This study was supported in part by the University of Georgia Research
Computing Center, a partnership between the Ofﬁce of the Vice President for
Research and the Ofﬁce of the Chief Information Ofﬁcer of the University of
Georgia.

Conﬂict of Interest: none declared.

References

Benjamini,Y. and Hochberg,Y. (1997) Multiple hypotheses testing with
weights. Scand.  Stat., 24, 407—418.

Bourgon,R. (2010) Independent ﬁltering increases detection power for high-
throughput experiments. Proc. Natl Acad. Sci., 107, 9546—9551.

Bourgon,R. et aL (2010) Reply to Talloen et al.: independent ﬁltering is a gen-
eric approach that needs domain speciﬁc adaptation. Proc. Natl Acad. Sci.,
107, E175—E175.

Calle,M.L. et al. (2008) Improving strategies for detecting genetic patterns of
disease susceptibility in association studies. Stat. Med., 27, 6532—6546.

Dai,].Y. et aL (2012) Two-stage testing procedures with independent ﬁltering
for genome-Wide gene-environment interaction. Biometrilza, 99, 929—944.

[310'sp2umoip105xo'sopeuHOJIItotq/ﬁdnq

858

S.Kim and P.Schliekelman

 

Degnan,].I—I. et al. (2008) Genomics and genome-wide association studies: an
integrative approach to expression QTL mapping. Genomics, 92, 129—133.

Evans,D.M. et al. (2006 ) Two-stage two-locus models in genome-Wide associ-
ation. PLoS Genet, 2, e157.

Finos,L. and Salmaso,L. (2007) FDR- and FWE-controlling methods using
data-driven weights]. Stat. Plan. Inference, 137, 3859—3870.

Fog,A. (2008a) Calculation methods for Wallenius’ noncentral hypergeome-
tric distribution. Commnn. Stat. Simnl. C, 37, 258—273.

Fog,A. (2008b) Sampling methods for Wallenius’ and Fisher’s noncentral
hypergeometric distributions. Commnn. Stat. Simnl. C, 37, 241—25 7.

Genovese,C.R. et al. (2006) False discovery control with p-value weighting.
Biometrilza, 93, 509—524.

Ghazalpour,A. et al. (2006) Integrating genetic and network analysis to char-
acterize genes related to mouse weight. Plos Genet. 2, 1182—1192.

Gibson,G. (2011) Rare and common variants: twenty arguments. Nat. Rev.
Genet., 13,135—145.

Hackstadt,A.]. and Hess,A.M. (2009) Filtering for increased power for micro-
array data analysis. BMC Bioinf, 10, 11.

Holm,S. (1979) A simple sequentially rejective multiple test procedure. Scand.
]. Stat., 6, 65—70.

Ionita-Laza,I. et al. (2007) Genomewide weighted hypothesis testing in fam-
ily-based association studies, with an application to a 100K scan. Am. ].
Hum. Genet., 81, 607—614.

Jiang,I—I. and Doerge,R.W. (2006 ) A two-step multiple comparison procedure
for a large number of tests and multiple treatments. Stat. Appl. Genet. Mol.
Biol, 5, Article28.

Kropf,S. et al. (2004) Nonparametric multiple test procedures with data-
driven order of hypotheses and with weighted hypotheses. ]. Stat. Plan.
Inference, 125, 31—47.

Li,L. et al. (2013) Using eQTL weights to improve power for genome-Wide
association studies: a genetic study of childhood asthma. Front. Genet., 4, 103.

Lu,]. et al. (2011 ) Principal component analysis—based ﬁltering improves detec-
tion for Affymetrix gene expression arrays. Nucleic Acids Res., 39, e86.

McClintick,].N. and Edenberg,H.]. (2006) Effects of ﬁltering by Present call
on analysis of microarray experiments. BMC Bioinf., 7, 49.

Pattin,K.A. and Moore,].I—I. (2008) Exploiting the proteome to improve the
genome-Wide genetic analysis of epistasis in common human diseases. Hum.
Genet., 124, 19—29.

Patwardhan,A. et al. (2014) Variant priorization and analysis incorporati-ng
problematic regions of the genome. Pac. Symp. Biocompnt., 277—287.

Ramskold,D. et al. (2009) An abundance of ubiquitously expressed genes revealed
by tissue transcriptome sequence data. PLoS Compnt. Biol, 5, e1000598.

Rau,A. et al. (2013a) HTSFilter : independent data-based ﬁltering for repli-
cated transcriptome sequencing experiments. 1—14, web document found at
https://WWW.bioconductor.org/packages/release/bioc/vigriettes/HTSFilter/inst/
doc/HTSFilter.pdf.

Rau,A. et al. (2013b) Data-based ﬁltering for replicated high-throughput tran-
scriptome sequencing experiments. Bioinformatics, 29, 2146—2152.

Roeder,K. and Wasserman,L. (2009) Genome-wide signiﬁcance levels and
weighted hypothesis testing. Stat. Sci. Rev. ]. Inst. Math. Stat., 24, 398—413.

Roquain,E. and van de Wiel,M.A. (2009) Optimal weighting for false discov-
ery rate control. Electron. ]. Stat., 3, 678—711.

Rubin,D. et al. (2006) A method to increase the power of multiple testing pro—
cedures through sample splitting. Stat. Appl. Genet. Mol. Biol., 5, 19.

Smith,C.M. et al. (2014) The mouse Gene Expression Database (GXD): 2014
update. Nucleic Acids Res., 42, D818—D824.

Sultan,M. et al. (2008) A global View of gene activity and alternative splicing
by deep sequencing of the human transcriptome. Science (New York, N. Y),
321, 956—960.

Talloen,W. et al. (2007) I/NI-calls for the exclusion of non-informative genes:
a highly effective ﬁltering tool for microarray data. Bioinformatics (Oxford,
England), 23, 2897—2902.

Talloen,W. et al. (2010) Filtering data from high-throughput experiments
based on measurement reliability. Proc. Natl Acad. Sci. USA, 107, E173—
E174.

Wasserman,L. et al. (2006) Genome-wide signiﬁcance levels and weighted hy-
pothesis testing. Stat. Sci. 2009, 24, 398—411.

Westfall,P.H. et al. (2004) Weighted FWE-controlling methods in high-dimen-
sional situations. Lect. Notes Monogr. Ser. Recent Dev. Multiple
Comparison Proced., 47, 143—154.

ﬁm'srcumol‘pquo'sopeuuopttotq/ﬁdnq

