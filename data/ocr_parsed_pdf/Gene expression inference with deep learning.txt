Bioinformatics, 32112), 2016, 1832—1839

doi: 10.1093/bioinformatics/btw074

Advance Access Publication Date: 11 February 2016
Original Paper

 

 

Gene expression

Gene expression inference with deep learning

Yifei Chen1'4'1, Yi Li”, Rajiv Narayanz, Aravind Subramanianz and
Xiaohui Xie1'3'*

1Department of Computer Science, University of California, Irvine, CA 92697, USA, 2Broad Institute of MIT And
Harvard, Cambridge, MA 02142, USA, 3Center for Complex Biological Systems, University of California, Irvine, CA
92697, USA and 4Baidu Research-Big Data Lab, Beijing, 100085, China

*To whom correspondence should be addressed.
TThe authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors.
Associate Editor: Inanc Birol

Received on August 5, 2015; revised on December 14, 2015; accepted on February 3, 2016

Abstract

Motivation: Large—scale gene expression profiling has been widely used to characterize cellular
states in response to various disease conditions, genetic perturbations, etc. Although the cost of
whole—genome expression profiles has been dropping steadily, generating a compendium of ex—
pression profiling over thousands of samples is still very expensive. Recognizing that gene expres—
sions are often highly correlated, researchers from the NIH LINCS program have developed a cost—
effective strategy of profiling only ~1000 carefully selected landmark genes and relying on compu—
tational methods to infer the expression of remaining target genes. However, the computational
approach adopted by the LINCS program is currently based on linear regression (LR), limiting its
accuracy since it does not capture complex nonlinear relationship between expressions of genes.
Results: We present a deep learning method (abbreviated as D—GEX) to infer the expression of tar—
get genes from the expression of landmark genes. We used the microarray—based Gene Expression
Omnibus dataset, consisting of 111K expression profiles, to train our model and compare its per—
formance to those from other methods. In terms of mean absolute error averaged across all genes,
deep learning significantly outperforms LR with 15.33% relative improvement. A gene—wise com—
parative analysis shows that deep learning achieves lower error than LR in 99.97% of the target
genes. We also tested the performance of our learned model on an independent RNA—Seq—based
GTEx dataset, which consists of 2921 expression profiles. Deep learning still outperforms LR with
6.57% relative improvement, and achieves lower error in 81.31% ofthe target genes.

Availability and implementation: D—GEX is available at https://github.com/uci—cbcl/D—GEX.

Contact: xhx@ics.uci.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 lntrOducuon connected using expression pattern-matching (e.g. HDAC inhibitors

A fundamental problem in molecular biology is to characterize and 65312296“ receptor modUIaml‘SI (Lamb 91:111., 2006)-

the gene expression patterns of cells under various biological states.
Gene expression profiling has been historically adopted as the tool to
capture the gene expression patterns in cellular responses to diseases,
genetic perturbations and drug treatments. The Connectivity Map
(CMap) project was launched to create a large reference collection of
such patterns and has discovered small molecules that are functionally

Although recent technological advances, whole-genome gene ex-
pression profiling is still too expensive to be used by typical aca-
demic labs to generate a compendium of gene expression over
a large number of conditions, such as large chemical libraries, gen-
ome-wide RNAi screening and genetic perturbations. The initial
phase of the CMap project produced only 564 genome-wide gene

(63 The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 1832

/310‘srcumo[p10}xo‘sopcuHOJIItotq/ﬁdnq

Gene expression inference with deep learning

1833

 

expression profiles using Affymetrix GeneChip microarrays (Lamb
et al., 2006).

Despite the large number of genes (~22 000) across the whole
human genome, most of their expression profiles are known to be
highly correlated. Systems biologists have leveraged this idea to con—
struct gene regulatory networks and to identify regulator and target
genes (Bansal et al., 2007). Researchers from the LINCS program
(http://www.lincsproject.org/) analyzed the gene expression profiles
from the CMap data using principal component analysis. They found
that a set of ~1000 carefully chosen genes can capture ~80% of the
information in the CMap data (http://support.lincscloud.org/hc/en—us/
articles/202092616—The—Landmark—Genes). Motivated by this obser—
vation, researchers have developed the L1000 Luminex bead technol—
ogy to measure the expression profiles of these ~1000 genes, called
the landmark genes (http://support.lincscloud.org/hc/en—us/articles/
202092616—The—Landmark—Genes), with a much lower cost (~$5 per
profile) (Peck et al., 2006). Therefore, researchers can use the expres—
sion signatures of landmark genes to characterize the cellular states of
samples under various experimental conditions. If researchers are
interested in the expression of a specific gene other than landmark
genes, the expression profiles of the remaining ~21 000 genes, called
the target genes, can be then computationally inferred based on land—
mark genes and existing expression profiles. With the L1000 technol—
ogy, the LINCS program has generated ~1.3 million gene expression
profiles under a variety of experimental conditions.

However, computationally inferring the expression profiles of
target genes based on landmark genes is challenging. It is essentially
a large—scale multi—task machine learning problem, with the target
dimension (~21 000) significantly greater than the feature dimen—
sion (~1000). The LINCS program currently adopts linear regres—
sion (LR) as the inference method, which trains regression models
independently for each target gene based on the Gene Expression
Omnibus (GEO) (Edgar et al., 2002) data. While LR is highly scal—
able, it inevitably ignores the nonlinearity within gene expression
profiles that has been observed (Hasty et al., 2001). Kernel machines
can represent dexterous nonlinear patterns and have been applied to
similar problems (Ye et al., 2013). Unfortunately, they suffer from
poor scalability to growing data size. Thus, a machine learning
method enjoying both scalability and rich representability is ideal
for large—scale multi—task gene expression inference.

Recent successes in deep learning on many machine learning
tasks have demonstrated its power in learning hierarchical nonlinear
patterns on large—scale datasets (Bengio et al., 2013). Deep learning
in general refers to methods that learn a hierarchical representation
of the data through multiple layers of abstraction (e.g. multi—layer
feedforward neural networks). A number of new techniques have
been developed recently in deep learning, including the deployment
of General—Purpose Computing on Graphics Processing Units
(Ciresan et al., 2012; Coates et al., 2013), new training methodolo—
gies, such as dropout training (Baldi and Sadowski, 2013; Hinton
et al., 2012b) and momentum method (Sutskever et al., 2013). With
these advances, deep learning has achieved state—of—the—art perform—
ances on a wide range of applications, both in traditional machine
learning tasks such as computer vision (Krizhevsky et al., 2012), nat—
ural language processing (Socher et al., 2011), speech recognition
(Hinton et al., 2012a) and in natural science applications such
as exotic particles detection (Baldi et al., 2014), protein structure
prediction (Di Lena et al., 2012), RNA splicing prediction (Leung
et al., 2014) and pathogenic variants identification (Quang et al.,
2014).

Here, we present a deep learning method for gene expression in—
ference (D—GEX). D—GEX is a multi—task multi—layer feedforward

neural network. We evaluated the performances of D—GEX, LR
(with and without different regularizations) and k—nearest neighbor
(KNN) regression on two types of expression data, the microarray
expression data from the GEO and the RNA—Seq expression data
from the Genotype—Tissue Expression (GTEx) project (Ardlie et al.,
2015; Lonsdale et al., 2013). GPU computing was used to accelerate
neural network training so that we were able to evaluate a series of
neural networks with different architectures. Results on the GEO
data show that D—GEX consistently outperforms other methods in
terms of prediction accuracy. Results on the GTEx data further dem—
onstrate D—GEX, combined with the dropout regularization tech—
nique, achieves the best performance even where training and
prediction were performed on datasets obtained from different plat—
forms (microarray versus RNA—Seq). Such cross platforms generaliz—
ability implies the great potential of D—GEX to be applied to
the LINCS program where training and prediction were also done
separately on the microarray data and the L1000 data. Finally, we
attempted to explore the internal structures of the learned neural
networks with two different strategies and tried to interpret the ad—
vantages of deep learning compared with LR.

2 Methods

In this section, we first introduce three expression datasets we used
in this study and formulate gene expression inference as a supervised
learning problem. We then present D—GEX for this problem and ex—
plain a few key deep learning techniques to train D—GEX. Finally,
we introduce several common machine learning methods that we
used to compare with D—GEX.

2.1 Datasets

The GEO expression data were curated by the Broad Institute from
the publicly available GEO database. It consists of 129 158 gene ex—
pression profiles from the Affymetrix microarray platform. Each pro—
file comprises of 22 268 probes, corresponding to the 978 landmark
genes and the 21 290 target genes. The original GEO data were ac—
cessed from the LINCS Cloud (http://www.lincscloud.org/), which
has been quantile normalized into a numerical range between 4 and
15. Some of the expression profiles in the GEO dataset are biological
or technical replicates. To avoid complications in the learning proced—
ure, we removed duplicated samples (see Supplementary material),
leaving 111 009 profiles in the end.

The GTEx expression data consist of 2921 gene expression pro—
files of various tissue samples obtained from the Illumina RNA—Seq
platform (Ardlie et al., 2015). The expression level of each gene was
measured based on Gencode V12 annotations (Ardlie et al., 2015)
in the format of Reads Per Kilobase per Million (RPKM).

The 1000 Genomes expression data consist of 462 gene expres—
sion profiles of lymphoblastoid cell line samples from the Illumina
RNA—Seq platform (Lappalainen et al., 2013). The expression level
of each gene was also measured based on Gencode V12 annotations
(Lappalainen et al., 2013) in the format of RPKM.

Since the gene expression values of the microarray platform and
the RNA—Seq platform were measured in different units (probes ver—
sus Gencode annotations) and different numerical scales, we quantile
normalized the three expression datasets jointly to retain the max—
imum information cross platforms. Because one Gencode annotation
may include multiple microarray probes, 943 landmark genes and
9520 target genes in terms of Gencode annotations were left after
joint quantile normalization. Details of joint quantile normalization
are given in Supplementary materials. Finally, all the datasets were

[310‘SIBIIIHOLPJOJXO‘SQDEIIIJOJIIEOIQ/[Idllq

1834

Y. Chen et al.

 

standardized by subtracting the mean and dividing by the standard
deviation of each gene.

2.2 Gene expression inference as multi—task regression
Assume there are L landmark genes, T target genes and N training
samples (i.e. profiles); the training dataset is expressed as {xi7 yi},z:1,
where X, 6 RL denotes the expression values of landmark genes and
y,- 6 RT denotes the expression values of target genes in the ith sam—
ple. Our goal is to infer the functional mapping 7: : RL —> RT that
fits {x,~7 yi}E:1, which can be viewed as a multi—task regression
problem.

We use mean absolute error (MAE) to evaluate the predictive
performance at each target gene t,

1 N’ A
MAEU) : V: I)’i(t) — yank (1)
i:1

where N’ is the number of testing samples and 51,-”) is the pre—
dicted expression value for target gene t in sample i. We define the
overall error as the average MAE over all target genes, and use it to
evaluate the general predictive performance.

For the microarray platform, we used the GEO data for training,
validation and testing. Specifically, we randomly partitioned the
GEO data into ~80% for training (88 807 samples denoted as
GEO—tr), ~10% for validation (11 101 samples denoted as GEO—va)
and ~10% for testing (11 101 samples denoted as GEO—te). The val—
idation data GEO—va were used to do model selection and parameter
tuning for all the methods.

For the RNA—Seq platform, we used GEO—tr for training, the
1000 Genomes data for validation (denoted as 1000G—va), and the
GTEx data for testing (denoted as GTEx—te). The validation data
1000G—va was used to do model selection and parameter tuning for
all the methods.

2.3 D—G EX

D—GEX is a multi—task multi—layer feedforward neural network. It
consists of one input layer, one or multiple hidden layers and one
output layer. All the hidden layers have the same number of hidden
units. Units between layers are all fully connected. A hidden unit /' in
layer 1 takes the sum of weighted outputs plus the bias from the pre—
vious layer 1 — 1 as the input, and produces a single output 01’- using
a nonlinear activation function f.

H
ojzf<ZwI;10I_1 + #71), (2)
i:1

where H is the number of hidden units, {wI;1.h/I_1}:1 are the
weights and the bias associated with unit / that need to be learned.
We adopt the hyperbolic tangent activation function to hidden units,
which naturally captures the nonlinear patterns within the data.
Linear activation function is applied to output units for the regres—
sion purpose. The loss function for training is the sum of mean

squared error at each output unit, namely,

T 1 N A 2
4 : 2(3’1‘0)‘ Mm) ]- (3)

D—GEX contains 943 units in the input layer corresponding to
the 943 landmark genes. Ideally, we should also configure D—GEX
with 9520 units in the output layer corresponding to the 9520 target
genes. However, each of our GPUs has only 6 GB of memory, thus
we cannot configure hidden layers with sufficient number of hidden
units if all the target genes are included in one output layer.

Therefore, we randomly partitioned the 9520 target genes into two
sets that each contains 4760 target genes. We then built two separ—
ate neural networks with each output layer corresponding to one
half of the target genes. With this constraint, we were able to build
a series of different architectures containing 1—3 hidden layers
each and each hidden layer contains 3000, 6000 or 9000 hidden
units. Supplementary Figure 51 shows an example of architecture of
D—GEX with three hidden layers.

Training D—GEX follows the standard back—propagation algorithm
(Rumelhart et al., 1988) and mini—batch gradient descent, supple—
mented with advanced deep learning techniques. Detailed parameter
configurations are given in Supplementary Table 51. For more descrip—
tions about neural networks and their background please see Chen
(2014). We discuss a few key training techniques as follows:

1. Dropout is a technique to perform model averaging and regu—
larization (Hinton et al., 2012b) for neural networks. At the training
time, each unit along with its edges is temporarily dropped out
with probability p for each training sample. Then the forward— and
back—propagation are performed on a particularly ‘thinned’ net—
work. For an architecture with n units performing dropout, there

are  such thinned networks. At the testing time, all the

units are retained with weights multiplied by 1 — p. Therefore, drop—
out can be seen as model averaging of exponentially many different
neural networks in an approximate but efficient framework.
Dropout has been shown to suppress co—adaptation among units
and force each unit to learn patterns that are more generalizable
(Srivastava et al., 2014). The dropout rate p serves as a tuning par—
ameter that controls the intense of regularization. We applied drop—
out to all the hidden layers of D—GEX except for the outgoing edges
from the input layer. The dropout rate was set to [0%, 10%, 25%]
to compare the effect of different degrees of regularization.

2. Momentum method is a technique to accelerate gradient—based
optimization. It accumulates a velocity in directions of gradients
of the loss function across iterations and uses the velocity instead of
the gradient to update parameters (Sutskever et al., 2013). Given
a loss function £ with respect to the parameters 6) of the neural net—
work, the momentum is given by

VUZH) : HVU?) _ "(k)v£(®(k))7

®(k+1) : 802) + V(lz+1)7 (4)

where H E [0.1] is the momentum coefficient, 1’] is the learning
rate, V is the velocity and V£(®) is the gradient of the loss function.
Momentum method has been shown to improve the convergence
rate particularly for training deep neural networks (Sutskever et al.,
2013).

3. Normalized initialization is a technique to initialize the
weights of deep neural networks (Glorot and Bengio, 2010). The
weights of a unit is sampled from a uniform distribution defined by,

\/€ \/€

WNU _4747
Vni‘I'no Vni‘I'no

(5)

where n,, n,, denote the number of fan—ins and fan—outs of the
unit. It is designed to stabilize the variances of activation and back—
propagated gradients during training (Glorot and Bengio, 2010).
The uniform distribution of the output layer of D—GEX was set to be
within a smaller range of [—1 X 104. 1 X 104] as it was adopted
with the linear activation function.

4. Learning rate was initialized to 5 X 10_4 or 3 X 10_4 depend—
ing on different architectures, and was decreased according to the

ﬁm'sreumol‘pquo'sopeuuowtotq/ﬁdnq

Bergstra (7/ al., 2010

(7/ al., 2011

Bentle) , 197

5

(ioodfellmv (7/ al., 2013

Figure 1

Table 1

Supplementar) Tables 52 5.)

Figure 1

Pedregosa Bengio, 2009

Figure 2

w or hidden layers
1

2
I3

 

/310'S[Buln0prOJXO'SOIIBLUJOJIIIOICI”Idllq

 

Figure 3

Table 1

Lonsdale (7/ al.,
2013

\Xlang (7/ al., 2014

Table 2

Supplementar) Tables 54 55

Figure 4

Fig. 4b

Figure 5

/310'S[Buln0prOJXO'SOIIBLUJOJIIIOICI”Idllq

9517 dots (99.97%) above diagonal

9520 dots (100%) above diagonal

 

Supplementar} Figure 53

/310'S[Buln0prOJXO'SOIIBLUJOJIIIOICI”Idllq

7741 dots (81.31%) above diagonal 9095 dots (95.54%) above diagonal

 

Gene expression inference with deep learning

1839

 

better model than LR for gene expression inference. We believe that
it achieves more accurate predictions for target gene expressions of
the LINCS dataset generated from the L1000 platform.

Interpreting the internal representation of deep architectures is
notoriously difficult. Unlike other machine learning tasks such as
computer vision, where we can visualize the learned weights of hid—
den units as meaningful image patches, interpreting the deep archi—
tectures learned by biological data requires novel thinking. We
attempted to interpret the internal structures of the neural networks
learned from gene expression data using strategies that were inspired
by linear model. Yet, more systematic studies may require advanced
computational frameworks that are specifically designed for deep
learning. Unsupervised feature learning methods, such as autoen—
coder (Vincent et al., 2008) and restricted Boltzmann machine
(Hinton, 2010) may provide some insights on this problem.

In the current setting, target genes were randomly partitioned
into multiple sets, and each set was trained separately using different
GPUs due to hardware limitations. Alternatively, we could first clus—
ter target genes based on their expression profiles, and then partition
them accordingly rather than randomly. The rationale is that target
genes sharing similar expression profiles share weights in the context
of multi—task neural networks. Ultimately, the solution is to jointly
train all target genes, either by using GPUs with larger memory such
as the more recent Nvidia Tesla K80, or by exploiting multi—GPU
techniques (Coates et al., 2013).

Acknowledgements

The authors greatly acknowledge Peter Sadowski, Daniel Quang, Mengfan
Tang, Ian Goodfellow, Frédéric Bastien, Kyle Kastner and Olivier Delalleau
for helpful discussions.

Funding

This work was partly supported by National Institutes of Health
P50GM76516 and National Science Foundation DBI-0846218.

Conﬂict of Interest: none declared.

References

Ardlie,K.G. et al. (2015) The genotype-tissue expression (gtex) pilot analysis:
multitissue gene regulation in humans. Science, 348, 648—660.

Baldi,P. and Sadowski,P.]. (2013) Understanding dropout. In Advances in
Neural Information Processing Systems, pp. 2814—2822.

Baldi,P. et al. (2014) Searching for exotic particles in high-energy physics with
deep learning. Nat. Commun., 5, 4308.

Bansal,M. et al. (2007) How to infer gene networks from expression proﬁles.
Mol. Syst. Biol., 3, 1.

Bengio,Y. (2009) Learning deep architectures for AI. Found. Trends Mach.
Learn., 2, 1—127.

Bengio,Y. et al. (2013) Representation learning: a review and new perspec-
tives. IEEE Trans. Pattern Anal. Mach. Intell. 35, 1798—1828.

Bentley,].L. (1975) Multidimensional binary search trees used for associative
searching. Commun. ACM, 18, 509—517.

Bergstra,]. et al. (2010) Theano: a CPU and GPU math expression compiler.
In: Proceedings of the Python for Scientiﬁc Computing Conference (SciPy),
Austin, US.

Chen,Y. (2014) Machine learning for large-scale genomics: algorithms, mod-
els and applications. PhD Thesis, University of California, Irvine, ProQuest,
UMI Dissertations Publishing.

Ciresan,D. et al. (2012) Multi-column deep neural networks for image classiﬁ-
cation. In: IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), Providence, US, pp. 3642—3649.

Coates,A. et al. (2013) Deep learning with cots hpc systems. In: Proceedings of
the 30th International Conference on Machine Learning, Atlanta, US, pp.
1337—1345.

Di Lena,P. et al. (2012) Deep architectures for protein contact map prediction.
Bioinformatics, 28, 2449—2457.

Edgar,R. et al. (2002) Gene expression omnibus: NCBI gene expression and
hybridization array data repository. Nucleic Acids Res., 30, 207—210.

Glorot,X. and Bengio,Y. (2010) Understanding the difﬁculty of training deep
feedforward neural networks. In: International Conference on Artiﬁcial
Intelligence and Statistics, Sardinia, Italy, pp. 249—256.

Goodfellow,I.]. et al. (2013) Pylearn2: a machine learning research library.
arXiv Preprint arXiv:1308.4214.

Hasty,]. et al. (2001) Computational studies of gene regulatory networks: in
numero molecular biology. Nat. Rev. Genet., 2, 268—279.

Hinton,G. (2010) A practical guide to training restricted Boltzmann machines.
Momentum, 9, 926.

Hinton,G. et al. (2012a) Deep neural networks for acoustic modeling in speech
recognition: the shared views of four research groups. IEEE Signal Process.
Mag., 29, 82—97.

Hinton,G.E. et al. (2012b) Improving neural networks by preventing co—adap-
tation of feature detectors. arXiv Preprint arXiv:1 207.0580.

Krizhevsky,A. et al. (2012) Imagenet classiﬁcation with deep convolutional
neural networks. In: Advances in Neural Information Processing Systems,
Lake Tahoe, US, pp. 1097—1105.

Lamb,]. et al. (2006) The connectivity map: using gene-expression signatures
to connect small molecules, genes, and disease. Science, 313, 1929—1935.
Lappalainen,T. et al. (2013) Transcriptome and genome sequencing uncovers

functional variation in humans. Nature, 501, 506—51 1.

Leung,M.K. et al. (2014) Deep learning of the tissue-regulated splicing code.
Bioinformatics, 30, i121—i129.

Lonsdale,]. et al. (2013) The genotype-tissue expression (GTEX) project. Nat.
Genet., 45, 580—585.

Peck,D. et al. (2006) A method for high-throughput gene expression signature
analysis. Genome Biol., 7, R61.

Pedregosa,F. et al. (2011) Scikit-learn: machine learning in Python.  Mach.
Learn. Res., 12, 2825—2830.

Quang,D. et al. (2014) DANN: a deep learning approach for annotating the
pathogenicity of genetic variants. Bioinformatics,

Rumelhart,D.E. et al. (1988) Learning representations by back-propagating
errors. Cogn. Model, 5, 1.

Socher,R. et al. (2011) Parsing natural scenes and natural language with recur-
sive neural networks. In: Proceedings of the 28th International Conference
on Machine Learning (ICML-11), pp. 129—136.

Srivastava,N. et al. (2014) Dropout: a simple way to prevent neural networks
from overﬁtting.]. Mach. Learn. Res., 15, 1929—1958.

Sutskever,I. et al. (2013) On the importance of initialization and momentum
in deep learning. In: Proceedings of the 30th International Conference on
Machine Learning (ICML-13), Atlanta, US, pp. 1139—1147.

Theil,H. (1958) Economic Forecasts and Policy. North-Holland, Amsterdam.

Vincent,P. et al. (2008) Extracting and composing robust features with denois-
ing autoencoders. In: Proceedings of the 25th International Conference on
Machine Learning, ACM, Helsinki, Finland, pp. 1096—1103. ACM.

Wang,C. et al. (2014) The concordance between RNA-Seq and microarray
data depends on chemical treatment and transcript abundance. Nat.
Biotechnol., 32, 926—932.

Ye,G. et al. (2013) Low-rank regularization for learning gene expression pro-
grams. PloS One, 8, e82146.

ﬁm'sreumol‘piqxo'sopeuuowtotq/ﬁdnq

