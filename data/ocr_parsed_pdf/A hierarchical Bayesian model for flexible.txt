Biainfarmatics, 31, 2015, i17—i26
doi: 10.1093/bioinformatics/btv228
lSMB/ECCB 2015

 

A hierarchical Bayesian model for flexible
module discovery in three-way time-series data

David Amar1'*, Daniel Yekutieliz, Adi Maron-Katz1'3'4, Talma Hendler3'4
and Ron Shamir1'*

1The Blavatnik School of Computer Science, Tel Aviv University, Tel Aviv 69978, Israel, 2Department of Statistics
and OR, School of Mathematical Sciences, Tel Aviv University, Tel Aviv 69978, Israel, 3Functional Brain Center,
Wohl Institute for Advanced Imaging, Tel Aviv Sourasky Medical Center, Tel Aviv 64239, Israel and 4Sackler
Faculty of Medicine, Tel Aviv University, Tel Aviv 69978, Israel

*To whom correspondence should be addressed.

Abstract

Motivation: Detecting modules of co—ordinated activity is fundamental in the analysis of large bio—
logical studies. For tvvo—dimensional data (e.g. genes >< patients), this is often done via clustering or
biclustering. More recently, studies monitoring patients over time have added another dimension.
Analysis is much more challenging in this case, especially when time measurements are not
synchronized. New methods that can analyze three—way data are thus needed.

Results: We present a new algorithm for finding coherent and flexible modules in three—way data.
Our method can identify both core modules that appear in multiple patients and patient—specific
augmentations of these core modules that contain additional genes. Our algorithm is based on a
hierarchical Bayesian data model and Gibbs sampling. The algorithm outperforms extant methods
on simulated and on real data. The method successfully dissected key components of septic shock
response from time series measurements of gene expression. Detected patient—specific module
augmentations were informative for disease outcome. In analyzing brain functional magnetic res—

 

onance imaging time series of subjects at rest, it detected the pertinent brain regions involved.
Availability and implementation: R code and data are available at http://acgt.cs.tau.ac.il/twigs/.

Contact: rshamir@tau.ac.il

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

Identifying modules of elements acting in concert is a fundamental
paradigm in interpreting, visualizing and dissecting complex
biomedical data. For two—dimensional data (e.g. genes versus condi—
tions), clustering is the simplest way to group the elements of one di—
mension (Hartigan, 1972). Biclustering seeks row and column
subsets that manifest similarity (Cheng and Church, 2000;
Hartigan, 1972; Madeira and Oliveira, 2004). Such analysis has
become standard in computational biology (Mitra et (11., 2013;
Oghabian et (11., 2014). Algorithms for finding biclusters differ in
how they define (and identify) biclusters (Madeira and Oliveira,
2004). For example, biclusters were defined as sub—matrices with
constant values (Hartigan, 1972), row or column additive or multi—
plicative values (Lazzeroni and Owen, 2002) and submatrices with
order preserving values (Ben—Dor et (11., 2003).

Recent studies have extended the idea of biclustering to more
complex input structures beyond the standard row—column data

©The Author 2015. Published by Oxford University Press.

(Mitra et (11., 2013). Meng et al. (2009) extended the classic Iterative
Signature Algorithm (ISA) (Bergmann et (11., 2003) to analyze a sin—
gle matrix of time series data together with prior knowledge on gene
function to detect temporal transcription modules that are biologic—
ally meaningful. Li and Tuck (2009) introduced an algorithm for
joint analysis of ChIP—chip and gene expression data to find biclus—
ters that are likely to be regulated by similar transcription factors.
Waltman et al. (2010) and Dede and Ogul (2013) proposed three—
way clustering of gene—condition—organism data. The algorithm of
Waltman et al. (2010) uses sequence information to integrate data
across species, and a post—processing step allows detection of
species—specific information. Gerber et al. (2007) cluster tissues
hierarchically and then find the representative gene set of each tissue
cluster in the hierarchy.

A common data source that calls for three—way analysis is a col—
lection of gene expression profiles measured for a set of subjects
over a series of time points. Hence, the data are represented by a

“7

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/Iicenses/by-nc/4.U/),
which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact

journaIs.permissions@oup.com

112 /310'slcum0fp1q1x0"sorwurJOJurorq/ﬁduq 11101} popcolumoq

91oz ‘Og isanV uo ::

i18

D.Amar et aI.

 

A

 

 

 

 

.

.
11, 12, t3, ...,tT : t1, t2, ta,  , t,

:> :

a.

3

:‘3‘

A

5 The observed data I

 

Fig. 1. Overview of the model. (A) A toy example of a core module (A) and its
private modules (B, C). (B) An overview of the dependencies in the hierarch-
ical model. P is the vector of subject-specific probabilities PS

gene >< subject >< time 3D matrix (i.e. a tensor of order 3) (Mankad
and Michailidis, 2014; Zhao and Zaki, 2005). For such matrices,
Supper et al. (2007) presented EDISA, an extension of ISA that han—
dles a time—course vector for each gene—subject pair instead of a sin—
gle scalar. Extant models are limited in their ability to detect a signal
that is specific to a particular subject. For example, the set of genes
active under one subject in a module may only partially overlap
with the gene set of other subjects. Another limitation is the assump—
tion of synchronicity of time points across subjects. Although this
assumption is valid for technical repeats or well—tailored experi—
ments, it is less plausible in other situations, e.g. samples taken from
patients over time, due to possible heterogeneity in the response of
different patients.

Here, we introduce a new, ﬂexible definition of a module suit—
able for three—way data where subjects have entities (e.g. genes)
measured over time, but time courses are unsynchronized among
the subjects. A core module is defined by a subset of the subjects
and a subset of the entities, along with subject—specific subset of
the time points. In addition, subjects may have private modules
that only partially coincide with the core set of entities. The as—
sumption is that the resulting submatrices will show values mark—
edly different from the whole matrix. A toy example is shown in
Figure 1A.

We developed a statistical framework and algorithm for ana—
lyzing such data. Our framework can detect core modules and for
each subject in a core module, a private module with relevant time
points. We developed a hierarchical Bayesian generative model for
the data and a procedure that aims to fit model parameters for a
given dataset. Our algorithm uses a regular biclustering solution as
a starting point and then performs iterative improvement using a
Gibbs sampling procedure. The algorithm is called TWIGS (three—
way module inference via Gibbs sampling). In simulations, we
show that TWIGS outperforms standard algorithms even when the
core modules have no additional subject—specific signal. When sub—
ject—specific signals exist, the ability of extant algorithms to detect
the core modules declines markedly, whereas the performance of
TWIGS remains high.

We demonstrate the advantage of our framework on experimen—
tal data from two different domains: gene expression and brain
functional magnetic resonance imaging (fMRI) signals. We first ana—
lyzed whole blood expression profiles, taken daily for 5 days from
14 patients after septic shock (Parnell et (11., 2013). TWIGS detected
two core modules of up—regulated genes, showing enrichment for
different immune system processes. The first was related to response
to bacteria, whereas the second was related to regulation of T—cells.
Analysis of the subject—specific private modules revealed multiple en—
richments that illustrate patient—specific—activated biological proc—
esses. Hence, our analysis produced both shared and subject—specific
insights, highlighting biological pathways that repeatedly emerge as

 

up—regulated after septic shock, together with additional biological
functions particular to each patient. We also analyzed fMRI read—
ings for 20 subjects at rest (Vaisvaser et (11., 2013). The data for each
subject are a matrix of 464 brain regions (parcels) measured over 94
time points at 3 s intervals. Each value in the matrix is the parcel’s
average blood—oxygen—level—dependent (BOLD) contrast. These lev—
els are indicators of the activity at that region. TWIGS revealed sev—
eral core modules of highly activated bi—lateral brain regions.
Reassuringly, the detected modules were enriched with regions that
are known to be active during rest. This analysis shows that our
framework is able to detect large functional networks that reappear
as activated across subjects and also highlight subject—specific activa—
tion patterns.

2 Methods
2.1 The probabilistic model

The input for our problem is summarized as a 3D matrix Z where
st is the activity level of the measured object 11 E 1, . . . , V, at time
t E 1,. . . ,T, for subject 5 E 1,. . . ,S. We will say that v and t repre—
sent the rows and columns of the matrix and 5 represents layers. In
gene expression data, 11 represents genes, whereas in fMRI, data 11
represents brain regions (parcels or voxels). For uniformity, from
now on we use for v the term row or voxel. Here, we describe a hier—
archical probability model for generating a single module from the
distribution of Z.

We assume that there is a set of voxels V{1, . . . , V} that tend to
have high values jointly in a subset of the subjects. V is specified by
the indicator vector H : (H1, . . . ,H V), through the relation
V : {v : Hy : 1}. We assume that H,, N Bernoulli(rIVC). Although
H marks the rows of the core module, the signal in each specific sub—
ject might change. The subject—specific voxel sets are specified by the
matrix HS : {HSLL - - - ,HSVis}, where HS“ : 1 specifies that
voxel v participates in the module of subject 5. The relation between
H and H5 is as follows: if H,, : 1 then HS“ ~ Bernoulli(p5), other—
wise HSM ~ Bernoulli(po).

We next model the time—series relations. C : Cm 6 {0,1} indi—
cates whether the voxel set of subject 5 is active at time t. We assume
Pr(C1,S : 1) : ’l'El’l. The activity at time t : 2,. . . ,T, depends on
the time window of size to Z 1 before t. In times t : 2, . . . ,w, the
time window is 1 - - - t — 1. Let C275 : 1, if the time window of sub—
ject 5 right before time point t contains at least one active time point
and set C275 : 0 otherwise. We assume that Pr(Ct,S : 1IC275 : 0)
: n1I0 and Pr(CtiS : 1IC;,S : 1): nlIl.

Finally, we assume that for v, t, s for which Cm : 1 and
HS“ : 1, st ~ F1, otherwise st ~ F0. An overview of the
model hierarchy is shown in Figure 1B. We assume that
all hyper—parameters above have Beta prior distributions:
itVC ~ Beta(a1, b1), 17, ~ Beta(a2, b2), 170 ~ Beta(a3,b3), 111:1 ~ Beta
(a4, I74), 111“ ~ Beta(a5, b5), n1I° ~ Beta(a6,b6).

2.2 The Gibbs sampling algorithm

Our algorithm starts from a solution produced using a standard
biclustering algorithm and then applies iterative improvement
steps. In each step, all parameters are fixed except a single one
that is sampled according to its conditional probability. The order
of parameters matches the subsections below. This order is re—
peated cyclically [2 times. The output of the process is the set of
sampled values for each parameter in all iterations. We then ex—
tract the core modules and the subject—specific modules from this
output.

112 /3.10'spzu.rn0fp.rqix0"soiwurJOJuioiq/ﬁduq r1101} papeolumoq

9103 ‘Og isnﬁnv uo ::

Three—Way module Inference using Gibbs Sampling

i19

 

(1) As H,, are Bernoulli realizations with success probability nVC:
’l'EVC) - - - ~ Beta(a1+){v:H,, : 1}),b1+){v:H,, : 
Similarly:
p5) - -- ~ Beta(a2 + ){v : HS“ : 1,H,, : 1}),
b2 + ){v : HS“ : 0,H,, : 
p0) - -- ~ Beta(a3 + ){v,s : HS“ : LHv : 0})7
b3 + ){v,s : HS“ 2 0,H,, : 0})),
--~ Beta(a4 +){s:C1,s : 1}),
b4 + I{$= C15 2 0}))7
n1I1)--- ~ Beta(a5 + ){t,s : C275 : 1, Ct), : 1}),
b5 + ){t,s : ngs : 1,Ct,5 : 0})),
n1I°)--- ~ Beta(a6 + ){t,s : C275 : 0,Ct,5 : 1}),
b6 + ){t,s : cg), : 0,Ct,5 : 

“1,1 ,

 

(2) H,, is affected by nVC, and it affects the values of HS“ for each s:

“(Hz 2 1,HS,,), : 1) . . .) : “V91757
Pr(Hv : 1,HS,,S : 0) . . .) : nvc , (1 _ps)7
“(Hy : 0,HS,,,S : 1)...) Z (1 _ nvc) .1707
Pr(H1/ : 0,HS,,,S : 0)...) Z (1 _ nvc) ' (1 _p0)

Thus,

Pr(H,, : 1,Hs,,.  _

 

.(1 _ ps)Zs(1 _ H5145)7
)2 <1 — n“) - poms“
.(1 _ po)zs(1 _ HSV,5)_

Pr(H,, : 0,HS,,. ~-

 

Therefore, the conditional posterior of H,, is:

i Pr(H,, : 1, HS,,. --
_ Pr(H,, : 1,HS,,. --

 

')

PI'(H1/ :  ' '   + Pr(Hv : 07HSI/ﬁ H

 

 

 

')

(3) Given Cm, only the value of HS“ affects the distribution of
2%,. Assume for now, that we condition on H,, : 1, then:

Pr(Zi/,t,57HSI/,5 : 0)Ct,5 : 07 ' '  I (1 — P5)f0(zr/,t,5)7
Pr(Zi/,t,57HSI/,5 : 1)Ct,5 : 07 ' '  2 P5 'fO(Zi/,t,5)7
Pr(Zi/,t,57HSI/,5 : 0)Ct,5 : 17 ' '  (1 — P5) ' fO(ZI/,t,5)7
Pr(Zi/,t,57HSI/,5 : 1)Ct,5 : 17 ' '  P5 'f1(Zr/,t,5)'

From the above, it is clear that when Ct), : 0:

Pr(HS,,,S : 1)C,,S : 0,H,, : 1,2,“, . . .) : p5,

Pr(HS,,,S : 0)C,,S : 0,H,, : 1,2,“, . . .) : 1 — 175.
Therefore, a time point t in which Ct), : 0 will not affect the
marginal distribution of HS“. Let T; : {t : Ct), : 1}, then:

Pr(HS,,qS : 1,2,“), Hy : 1, - - 

I P5 ' Ht6T2f1(Zr/,t,5)7
Pr(HS,,,S : 0,2W H,, : 1, . . .)

2 <1 — p.) - magnate.

 

 

On the basis of the equations above, we can calculate the condi—
tional posterior of HS“, given that H,, : 1, through:

Pr(HS,,,S : 1)H,, : 1, . . .)
i Pr(HS,,,S : 1,
_ Pr(HS,,,S : 0 v HS“ : 1,2W

 

Hv:17"')
Hv:17"')

 

 

Similarly, the conditional posterior of HS“ given that H,, : 0 can be
calculated by replacing every p, with 170 in the formulas above.

(4) As the value of C1,, affects the value of the time window C25, . . . ,
Can“ and the values of 2,4), with HS“ : 1:

 

Pr(C1,5 : 17C2,57"'7Cw+1,57zx<,1,5 
w+1 w+1
2C)“ (1 Ck,5)
7 “1,1 n1)1k:2 (1 _ n1)1)k72 H f1 (21/7175)
1/2HS,,_5:1

Unlike the equation above, calculating the probability of C1,, : 0
requires breaking the window into two parts. Assume that the time
window contains at least one active cell. Let I be the first time point
of C25, . . . , Can“ that changes from 0 to 1. Thus:

 

Pr(C1,S I 0,C2,S,---,C,,,+1,S,Z,,1,S "
w+1
[—1 2C)“
2 (1 _ 111,1), )H(1 _ 1110)) .n1)o,n1)1k:z
k:2
w+1
2(1 — ca)
(1 - “my?2 H fo(Zv,1,s)
1/2HS,,_5:1
If there are no active cells in C25, - - - , Can“, then the calculation re—
duces to:
Pr(C1,S I 0,C2,5,~ -,C,,,+1,S,Z.,1,S "

 

:(1—n1~1).(1—n1l0)w- H fo(Zv,1,s)

1/2HS,,_5:1
Finally, the conditional of C1,, can be calculated by:

Pr(C1,5 : 1)C2,57 ' ' ' 7 Cw+1,57z*,1,57 ' ' 

7 Pr(C1,5 : 17 C2,57 ' ' ' 7 Cw+1,57z*,1,5 "
Pr(C2,57 ' ' ' 7 Cw+1,57 Zx<,1,5 "

The conditional probability of the event C1,, : 0 is computed in the

 

')

 

 

same way.

(5) For t E 2,. . . ,T — 1, the value of Ct), is affected by the value of
C25, and it affects the value of Cm, . . . , CminWHg-jﬁs, and the val—
ues of st with HS“ : 1. Thus:

 

Pr(Ct,S : 1, C*,S,Z*ﬁt75 --
min(w+t,T)
Ck,5
: “n10” mnol-CLS «n1 rpm
min(w+t,T)
(1 _ Ck,5)

.(1 _ n1l1) k:t+1

H f1(Zi/,t,5)

1/2HS,,_5:1

112 /3.10'spzu.rn0ip.rqix0"soiwurJOJuioiq/ﬁduq r1101} papeolumoq

9103 ‘Og isnﬁnv uo ::

i20

D.Amar et aI.

 

 

Pr(Ct,5 : 07 C*,57Z*,t,5 "
min(t+w,T)
C ,-c’ c ,— 1—c'
: H “H1 7:. 11.5 who i. ( 11.5)
k:t
min(t+w,T)
(1 _ “1(1)(1—Cl..)-C;_,
k:t
min(t+w,T)
(1 _ 1t1)o)(1—Cl..)-(1-C’,_,)
k:t
H f0(ZI/.t.s)
1/2HS,,_5:1

Thus, Pr(Ct,S : 1) - -  can be calculated similarly to the calculations
in the previous section.

2.3 Setting f0 and f1

Here, we discuss two options for setting f0 and f1 and their hyper—
parameters: (i) a Bernulli-Beta model for binary data and (ii) a
Normal-Gamma model for normal distributions. Let A be the cells
within the module (including the core and private parts):
A : {st : Ct), : 1 /\ HS“ : 1}. Let B be the cells outside the
module: B : {st : Ct), : 0 V HS“ : 0}

For binary data, we assume that me 6 {0,1}, f0 : Bernoulli(
TECO) and f1 : Bernoulli(nCl). Thus, our model learns the back—
ground probability rICO of observing a value of 1 and the probability
it“ of observing 1 within the module. In this model, TECO and itC1 fol—
low Beta posterior distributions:

nCO) - -- ~ Beta(a7 +  : B,- : 1}),b7 +  : B,- : 

TIC1) - -- ~ Beta(a7 +  : A,- : 1}),b7 +  : A,- : 
In the continuous case, we assume that f0 is N (no, (so) and f1 is
N(u1, 61). Under the Normal-Gamma model, the prior distribution

for the mean u and the standard deviation 6 of a normal distribution
N ( u, (S) is:

110 SS0
1 ~ — —
/cs Gamma( 2 , 2 )
1
N N m ,—
II ( 0 P0)
The conditional posteriors for Y : (y1,...,y,,) where for each i,

y,- N N(p, cs) are:

1/6)Y ~ Gamma(1/2- (120 +71),

1/2. (550 + iXyi — 7f +5121? — mo)2)>
i:1

 

 

 C )

"+170 7170+"

Thus, we apply the model above for A and B, thereby modeling f0
and f1 as normal distributions.

2.4 Finding multiple modules

To find a single module, we use a standard biclustering algorithm to
produce an initial solution and then use the Gibbs sampler to im—
prove it. The biclustering algorithm is applied on a 2D matrix M ob—
tained by concatenating the layers in Z, i.e. MW- : st, where
i : (s — 1)S + t. In this study, we tested Bimax (Prelic et (11., 2006)
and ISA (Bergmann et (11., 2003) as the base algorithms. To binarize
real—valued data Z to run Bimax, we use a threshold 1: we set every
value st > r (< r) to 1 (0). By default, we set I to be the 0.9

quantile of the values in Z. After running the Gibbs sampler, we
take the mode of H, HS and C as the solution. By default, all hyper—
parameters of the Gibbs sampler are set to non—informative priors.
This means that the algorithm infers these parameters and thus no
tunning is required.

To find multiple modules, we tested two previously used heuris—
tics (Serin and Vingron, 2011; Shabalin et (11., 2009). In the first
(Cheng and Church, 2000), which we call masker, we run the algo—
rithm iteratively on the residual matrix of Z. The residual matrix is
calculated by going over all cells in the module and updating their
values in Z. In the binary model, the update rule is to change all
module cells to zero. In the normal model, we subtract the mean of
f1 from the value of each cell.

The second heuristic, called filter, takes a set of biclusters U as
input and produces a reduced set. It first uses the overlap reduction
method of Serin and Vingron (2011): initially U’ : Q), then the larg—
est module in U is added to U’ and all remaining modules with a
large overlap with it (we used Jaccard index 2 0.5) are removed
from U. The process is repeated until U is empty. Next, we run the
Gibbs sampler on the original matrix Z starting with each module in
U’. The result is a set of new modules U”. Finally, as different mod—
ules in U’ might converge into similar modules in U”, the overlap re—
moval process is used again, taking U” as input.

For both heuristics, we define when to add a module to the final
output. When using masker, we add modules until the first time a
module is rejected. A module is accepted if it is large enough and the
difference )f1 — ﬂy) for it is large enough. In the binary case, we set
it“ > 0.5 and in the normal case we set u > 0.3. Setting the minimal
module size depends on the application and on the size of the input
data. By default, we set the minimal size of a core module to 5 rows
and 5 time points (combining all subjects).

2.5 Performance measures

In the results below, we compare algorithms on simulated data. In
each case, we compare the known H, HS, C to the algorithm output
H’,HS’, C’ using the Jaccard coefficient. For example, the Jaccard
score of H and H’ is:

, , (rm-mm
’(H’H) ‘ l{i;Hz- VHz-il

When the data contain more than one module we use the running
max average of all pairwise Jaccard scores. Given the known
solution H : (H1, . . . ,Hkl) and the algorithm output

 

HI 2 (Hi7 - - - 7H),) the running max average score is:
Z ( max l(Hi,H’.)) + Z ( max ](H,-,H’.))
iel,...,k1 (Elwkz I islmkz iel,...,k1 7
k1 + [22

The same method is used for HS and C.

3 Results

3.1 Simulations

Our simulations setup was as follows. We set V2500, T250,
S: 10 and create an initial matrix Z in which all values are zero.
We then add modules to Z in which all values are 1 and later add
noise according to the tested model (binary or normal). To define a
new module, we first need to randomly select the rows and columns
of each subject 5. Time points are selected randomly with w: 1,
111:1 : 0.05, 11m : 0.6 and 11m : 0.1. Rows are selected randomly
as follows. We first select randomly 20 rows i1 . . .izo for the

112 /310's1rzu.rn0[p.rq1x0"soiwurJOJHroiq/ﬁduq r1101} pap1201um0q

9103 ‘0g15n8nv uo ::

Three—Way module Inference using Gibbs Sampling

i21

 

 

 

A Case 1, Binary, p0: 0.25,;1w = 0.25 B Case 1, Normal, 00: 1, o w = 1
a. 0.
in. m.
D CI
2 ‘0. E no.
0 D
U
E z E s
a! N.
O D
D :1 -
° H H5 0 D H HS C
El Bimax El Bimavaibbs I ISA I ISA-Gibbs
C Case 2, Binary, pa= 0.25, p“, = 0.25 D Case 2, Normal, o°= 1, a w = 1
0. a.
a; on
D a
E w E {D
8 cl 3 d
U 1- ” w
2 cs 2 6
cs c
a - U. -
° H HS 0 ° H H8 C

Fig. 2. Simulation results for data with a single module. Each bar represents the average over 10 repeats. (A) Case 1: no subject-specific signal. (B) Case 2: with
subject-specific signals. The Bimax-Gibbs variant was later chosen as the default TWIGS algorithm

core module. Then, we add row r to the private module of subject 5
with probability p; if r 6 {i1 . . .izo}, otherwise r is added with prob—
ability 17),.

Adding random noise to the data depends on the tested model.
In the binary case, we randomly replace st with 1 — st, with
probability pm if (v, t, 5) belongs to the private module of s and with
probability p0 otherwise. In the normal model for each (u, t, 5)
within the private module of s we select ems N N (0, CW), otherwise
we select ems N N (0, on). We then add the noise by updating
st : Z335 +e,,,t,5. We tested scenarios of a single module with
and without subject—specific signals and of multiple modules.

3.2 Case 1: a single core module

In this test, we set p; : 1 and p), : 0. This case represents the stand—
ard biclustering task because there is no subject—specific signal.
Thus, biclustering algorithms are expected to achieve high
performance.

The results are shown in Figure 2A and B. Each algorithm was
tested on 10 instances and the average Jaccard score, which quanti—
fies the agreement between the known solution and the algorithm
output, is shown. We set high noise levels both in the binary data
(Fig. 2A)—p;, : p), : 0.25 and in the normal data (Fig. 2B)—
GL, : 6:) : 1. The Bimax algorithm had a low Jaccard score in most
cases, since its output covered only a small part of the true bicluster.
Although the false—positive rate was very low (<0.01 both for the
bicluster rows and columns), the true—positive rate was low as well
(<0.25). ISA performed much better, especially in terms of identify—
ing H and HS. Using TWIGS to improve the solution was beneficial:
it was able to keep the high performance of ISA for H and HS and to
considerably improve the score of C. It greatly improved the Bimax
solution in all criteria. For example, in the normal data, the score of
C went up from 0.053 to 0.93. The ISA solution improved from
0.63 to 0.95 using TWIGS. Notably, this improvement was achieved
with only 50 sampling iterations, which took less than 7s on average
(over simulation repeats). Thus, this boost in performance was
achieved at a low cost of running time. We kept this number of iter—
ations also in subsequent analyses. Note, however, that when the
data are much larger (e.g. )T) > 1000), the running time could in—
crease to several minutes.

We also tested a binary case in which the noise levels were not
symmetric: we set 17;, : 0.5 and p2, : 0.1. The results are shown in
Supplementary Figure 1. In this case, the Bimax—Gibbs combination
reached the top performance in all measurements, with very high
scores: 0.92 (H), 0.86 (HS) and 0.93 (C). The performance of both
ISA and Bimax was low (all scores were <0.7), indicating that
standard algorithms have difficulty in such noise levels.

3.3 Case 2: a core module with subject—specific signal

In this test, we set p; : 0.9 and p), : 0.01. Thus, this scenario is dif—
ferent from standard biclustering and triclustering tasks in two
ways: (i) not all shared rows are necessarily part of each private
module and (ii) each private module is likely to contain additional
rows that are not shared among all subjects.

The results (averaged over 10 instances) are shown in Figure 2C
and D. The noise levels were 17),, : p), : 0.25 in the binary data
Fig. 2C) and 6;, : 6:) : 1 in the normal data (Fig. 2D). Similar to
Case 1, Bimax had low scores because it typically covered only a
small perfect fraction of the module, whereas ISA reached higher
performance. However, the performance of ISA was much lower
than in Case 1. For example, in the normal data the score of H,
which represents the core module rows, dropped from 0.87 in Case
1 to 0.57. This result demonstrates a weakness of standard bicluster—
ing algorithms when the data contain subject—specific signal: the al—
gorithms might fail to discover even the shared information. In
contrast to ISA and Bimax, TWIGS improved the solution consider—
ably in all measures. For example, the score of H and C was >0.89
when starting with the Bimax solution.

3.4 Case 3: multiple modules
Here, we tested the performance of TWIGS with filter and masker
on data with five core modules, each with it own subject—specific sig—
nals, using as before p; : 0.9 and p), : 0.01. The results are shown
in Figure 3. As expected, the results were lower than in the single
core module tests. Nonetheless, the results were still high in spite of
the high noise levels.

Unlike the previous cases, using masker with Bimax as the base
algorithm was much better than all other algorithms. For example,
in the binary case (Fig. 3A), it reached scores of 0.86 and 0.8 for H

112 /310's1cu1nolp.rq1x0"soiwurJOJHroiq/ﬁduq r1101} pap1201um0q

9103 ‘0g15n8nv uo ::

i22

D.Amar et al.

 

 

A Binary, p0: 0.25, pw = 0.25 D Bimax
III ISA
I ISA-Gibbs-masker
- Bimax-Gibbs—filter
I ISA—Gibbs—ﬁlter

 

E Bim ax-Gibbs—masker

B Normal, 00: 0.75, o w = 0.75

1.0

 

 

l

HS C

Jaccard

 

0.4 0.6

Jaccard

0.2

:0

limit

Fig. 3. Simulation results for data with five core modules. Each bar represents the average over 10 repeats. (A) Binary data. (B) Normal data. The Bimax-Gibbs-

masker variant was later chosen as the default TWIGS algorithm

and C respectively, where all other algorithms had scores below 0.6.
In the normal data, we observed a sharp decrease in performance
when setting the noise levels to (so : 1 as in the previous sections,
see Supplementary Figure 2. With a bit lower noise levels of 0.75,
the results were similar to the binary case (Fig. 3B). Interestingly,
forcing high mean value in f1 (i.e. by setting mo 2 1 and high 170 con—
stant in the Normal—Gamma model, see Section 2) achieved higher
performance scores. For example, setting the mean value to 1.5 im—
proved the score of H from 0.8 to 0.9 and the score of C from 0.71
to 0.77. We discovered that the non—informative variant had some
detrimental instances in which some core modules were grouped to—
gether (average number of detected modules was 4.2), whereas
enforcing high mean for f1 detected the correct number of core
modules.

On the basis of the above results, from this point on, we used the
Bimax—Gibbs—masker as the default variant of the TWIGS
algorithm.

3.5 Gene expression data

We tested the performance of TWIGS by analyzing transcriptional
response of patients to sepsis. Parnell et al. (2013) monitored pa—
tients after septic shock. For up to 5 days after sepsis, blood samples
were taken daily, and whole blood gene expression was measured
using Illumina microarrays. The dataset contained 14 patients for
which five profiles, one for each day after sepsis, were available.
Our goal was to detect up—regulated biological functions after septic
shock. Therefore, for each subject we calculated the log fold change
between time points 2, 3, 4, 5 and the first time point. We binarized
the data by setting a threshold of 2 for the fold change (i.e. 1 for the
log fold change) and ran masker with Bimax as the base algorithm.
See the Supplementary Text for additional analyses using the non—
binarized data and for sensitivity analysis of the binarization thresh—
old. We set the minimal size of the detected core module to 10 rows
and 10 columns (number of time points from all patients) and f1 to
have it“ > 0.5. Using these stop criteria in masker, a single small
module of 5 genes was detected over 20 repeats in which we inde—
pendently and randomly shufﬂed the values of each row in the input
matrix.

Two core modules were detected on the real expression matrix.
The first covered 11 patients and 53 genes. The second covered
seven patients and 62 genes. Four patients were represented in both.
Distinct private modules were assigned to each subject in each mod—
ule. Thus, a total of 20 modules (core or private) were detected in
the analysis. GO enrichment analysis [using EXPANDER (Ulitsky

et al., 2010)] detected significant enrichment (0.05 FDR) in 19 of
the modules. The two detected core modules differed in their en—
riched biological functions. The first was highly enriched with genes
related to killing of cells of other organisms (P : 2.7E — 11) and re—
sponse to bacterium (P : 2.2E — 9).The second core module was
enriched with functions that were more specific to T—cell activity
(e.g. regulation of T cell activation P : 4.5E — 10). Thus, TWIGS
identified a fuzzy partition of the subjects into two main branches of
the immune system and also pointed out the relevant up—regulated
genes.

The private modules in the solution were often much larger than
the core modules. For example, in the first core module, the private
modules of subjects 19 and 24 contained more than 450 genes each.
The first core module and the enrichment analysis results of its pri—
vate modules are shown in Figure 4. See Supplementary Figure 3 for
the results of the second core module. Only biological functions that
were not significant in the core modules are shown. The figure illus—
trates how our analysis provides a complementary view to the core
modules. That is, although the core modules indicate which biolo—
gical functions tend to reappear across subjects, the private modules
reveal additional enrichments that are sometimes much more spe—
cific biologically. For example, the private module of subject 24 was
highly enriched with genes related to viral infectious cycle
(P : 1.7E — 9). The network also highlights patients without sub—
ject—specific unique enrichments (subjects 30, 46, 49 and 50) and
two hubs: subjects 24 and 19. Strikingly, out of the 11 patients cov—
ered by this core module, these two patients had much larger private
modules and they were the only patients that did not survive the sep—
tic shock.

3.6 fMRI data

Vaisvaser et al. (2013) collected brain fMRI data from 20 male sub—
jects at rest over 94 time points. In this technique blood ﬂow
(BOLD) intensity is measured at every voxel of the brain along time,
providing levels of some 100 000 voxels every 2—3 s. The level re—
ﬂects the activation intensity of the brain voxel. Standard fMRI pre—
processing was applied on the raw data as reported in (Vaisvaser
et al., 2013). We used a whole brain functional parcellation to trans—
form the data into 517 brain parcels (Craddock et al., 2012). Parcels
were masked to include gray matter voxels only using the WFU Pick
Atlas Tool (Maldjian et al., 2003; Stamatakis et al., 2010) and 54
parcels that had 3 5 gray matter voxels were excluded. For each
subject, average BOLD value across all gray matter voxels was cal—
culated within each parcel at each time point. As is standard practice

112 /310's1cu1nofp.rq1x0"soiwurJOJHroiq/ﬁduq r1101} pap1201um0q

9103 ‘0g15n8nv uo ::

Three—Way module Inference using Gibbs Sampling

i23

 

 

 

¥¥§2%°2% 333523aeaaeseggs§22=9geg§sgga
ea 390° Eogzgzaa—gaaimaaegégaa awe
a; g a “we; II‘II 53*; W n ,1:
On 1‘

magnum :0 biotin:

a 
rnnnle immune ’
leﬁﬂimhﬁ- ‘ rp. Angeli}

i:-:rrtarna lill'Iqu‘E
protern targeting

- . . l
 2 regulairun r_rl
to membrane  
pmrlive response to
regulation ulcel‘ organ“:
$:_:lwatii'_iri substance

reguiaiion at
hiiriugical quality

i:.-,-1i:rl-:rne- marinated
Signaling palm-ray-

 

   

iTIIIII'Fl I‘FifFlI I['|I'I FII

'iriral inla Elna-.1 
cycle __
..‘
cellular response
to chemical
:SlllTIUIUS

cellular reasons-r:
Ir:i mini-uni:

protein mmplax Stimulus
subuiiri
rri ' arr-zaliirn ri'nrr'ruiu'i reliant-1r

DI'DC BSS

rr'ruiir -o anis in
process

 

   
   
  
  
 
    
   
  

chemical U 
humanism 51‘: I fﬂSDﬁnSl-ﬁ 1r:
__-

      
      
   
 

modification 01
morphology -:H
ahys. 11:11,- at
other organism

 

 

 

 

 

 

 

 

 

 

 

GO
NO
YES
Log fold change

2.0 T

J. .0

I10

11.0

—1.0 l

Eaésa
gmgge %§
mrnirl'rcalrorr111,- SU  54
_ Ii:_i:il LII 5 minor“
SU  45 hi sin-3y rir
physxcdogy
sub :42 5UI3I= 30
so bj: 46
I'EEfiDi'i-Eie [Er
fungus regulation of
pint-2m Sent-Elli)".  J: 

sleririi! I1I.irl'ni'_|l'II-.'
Slir'iliilus

cell migration 7 l
regulation of
. i;- iki .,

locomotion

  

EEII cI'iei'i'ii'ilaaii'R

SU 

 

blood coagulation

Fig. 4. A module summarizing patient response to sepsis. Top: the first core module heatmap. Bottom: the subject-specific enrichments. The red stripes in each
patient's node represent the time points that were covered by its private module. An edge between a subject and a category (blue node) indicates that the sub-

ject-specific module was enriched for that category

in fMRI analysis (Birn, 2012), to reduce the effect of physiological
artifacts and nuisance variables, the whole—brain mean signal, six
motion parameters, cerebrospinal ﬂuid and white matter signals
were regressed out of the parcel signals. The result is a matrix M, for
each subject 5, in which rows are parcels and columns are time
points. We standardized the signal of each row in M5 by subtracting
the mean and dividing by the standard deviation. This normalization
allows us to find relative changes in the activity of brain regions to
highlight temporally activated regions (Rana et al., 2013).

We ran TWIGS with the normal model, Bimax as the initial solu—
tion finder and masker. With non—informative priors, the algorithm
converged to large modules with relatively low mean value (<0.5).
As we were interested in highly activated brain regions, we reset the
mean of f1 to a high value: we tested pl : 1.5 and pl : 2. As in the
simulations, using such prior improved the results considerably since
the non—informative variant tended to merge core modules with high
mean value. No module was detected when running the algorithm
after randomly and independently shufﬂing each row of the data
matrix (20 repeats).

Unlike in the gene expression analysis, each subject participated
in each core module. For pl : 2 (Fig. 5A), four core modules were
detected (labeled 1A—4A), with an average of 48.5 parcels. For pl
: 1.5 (Fig. 5B), five core modules were detected (labeled 1B—5B),
with an average of 66.4 parcels. Out of the five core modules de—
tected using pl : 1.5, four had a parallel core module detected using
ul : 2. In addition, modules 1A and 1B maintained similar spatial
structure and size and so did 3A and 3B. Modules 2A and 4A were
larger than their counterparts.

We evaluated the parcel sets of the identified core modules by
comparing them to known functional annotations of the brain (Yeo
et al., 2011). The results show that our analysis detected well—known
functional modules that are expected to share common activation
patterns both during task and at rest. In both solutions, core module
1 was enriched with regions that are involved in visual processing in
the occipital lobe of both hemispheres (q S E — 11) (Belliveau et al.,
1991). Core module 2B was enriched with parcels located within
the ventral attention network, which is involved in bottom—up ori—
enting of attention (q S 0.02) (Fox et al., 2006). In both solutions,

11; /810's1cumofp101x0"soiJBHIJOJuroiq/ﬁduq 11101} papeo1umoq

9IOZ ‘OE ISUEHV 110 ::

i24

D.Amar et al.

 

 

DDODD—n
UNI-Lama

Number of time points U 9‘:- Covered shared parcels o
sub1‘
sub2'
suba'
subd‘
subﬁ"
Subﬁ'
sub?“
subs"
subQ’

I- N F) '3' in w h- l‘) G)
.9 .CI D D .1: D .9 .CI a
:I :l :l 3 :I 3 3 :I 3
W 0'! If! 0 in 0'! 09 I11 W

.13
.23
I33
I43
I53

 

 

sub10‘
sub11'
sub12‘
sub13“
sub‘M'
sub15‘
sub16'
911017”

501313
sub‘IQ'

sub20

 

sub10
sub11
sub12
sub13
subt4
sub15
sub16
$0017
sub18
subts
sub20

Fig. 5. Results of the fMRI analysis. (A) The core module rows of the solution with 11.1 = 2. (B) The core module rows of the solution with 11.1 = 1.5. (C, D) Examples
of subject-specific statistics. This example shows the results for core module 4B. (C) The percent of core module parcels covered by the private modules.
Asterisks indicate subjects whose private module had a significant overlap (hyper-geometric P 3 0.001) with the core module. (D) The number of time points in

each private module

core module 3 was enriched with parcels located in regions that are
involved in sensori—motor processing (q 3 1E — 11) and in parcels
located within regions of the dorsal attention network, which is
involved in top—down orienting of attention (q S 003) (Fox et al.,
2006). Modules 4A and 4B were enriched with parcels located in
the default mode network (q 3 1E — 4), which is composed mainly
of midline structures and is involved in self referential functions that
include remembering the past as well as planning the future, and the
frontoparietal control network, which is responsible for adaptive be—
havior (q 3 1E — 7) (Dosenbach et al., 2007). Finally, core module
5B contained 29 parcels and was enriched with regions that are
involved in visual processing (q 3 5E — 9) and with parcels that are
located within the dorsal attention network (q 3 0.001).

Inspecting the private modules, we observed large heterogeneity
in their tendency to overlap with their core module parcels and in
the number of time points. Figure 5C and D shows the results for
core module 4B. This module is of particular interest as it was en—
riched with both the default mode network and the frontoparietal
control networks. Patterns of co—activation between these two
networks have been reported before and suggested to support goal—
directed thought processes (Spreng et al., 2010). On average, each
private module covered 44.4% of the core module parcels (Fig. 5C)
and contained 15.5 time points. In addition, in 18 out of 20 subjects,
the overlap between the subject—specific parcels and the core module
parcels was significant (hyper—geometric P < 0.001). Other modules

had much higher coverage. For example, core module 1B had mean
coverage of 64.4% and a larger number of time points (mean 23),
see Supplementary Figure 4.

When including the private modules in the enrichment analysis,
15 out of 20 private modules of core module 4B were also enriched
with the default mode network. The frontoparietal control network
was identified in 12 of the 20 subjects. Although to a much lower
extent than in the gene expression analysis, we also detected subject—
specific signal. For example, ventral attention enrichment was iden—
tified in 4 out of 20 subjects but not in the core module. This sug—
gests a tendency of these four subjects to engage in bottom—up
processing (e.g. be more attentive to sensory stimuli) during goal—
directed thought processes. These results demonstrate the advantage
of our multi—subject analysis: it was able to detect large functional
networks that reappear as activated across subjects and even high—
light subject—specific activation patterns.

3.7 Comparison to related algorithms

Extant algorithms for three—way data analysis were mainly de—
veloped for gene expression data. Triclustering (Zhao and Zaki,
2005) assumes that a module is a subcube created by one subset in
each of the three dimensions. This setting is too rigid for simultan—
eous analysis of responses in many patients. Figures 4 and 5 show
that our modules are not triclusters since the time points and gene

11; /810's1cumofp101x0"soiJBHIJOJuroiq/ﬁduq 11101} papeo1umoq

9IOZ ‘OE ISUEHV 110 ::

Three—Way module Inference using Gibbs Sampling

i25

 

set of each private module differ under the same core module.
Another type of three—way analysis seeks biclusters < G’, S’ > where
G’ is a set of genes and S’ is a set of subjects, such that all genes in
G’ manifest a similar time response across all subjects in S’. Two
such algorithms are EDISA (Supper et al., 2007), which seeks high
correlation between subjects across time points, and the plaid model
of Mankad and Michailidis (2014), which extends (Lazzeroni and
Owen, 2002) and seeks up— or down—regulated time responses.
Finally, Gerber et al. (2007) simultaneously cluster tissues and genes
to produce biclusters, while accounting for three possible time re—
sponses for each tissue when introduced to a drug. However, this
analysis answers very different questions than TWIGS as it assumes
a hierarchical structure of tissue clusters without overlap, whereas
we analyze a single tissue over many time points at rest and allow
overlapping core modules.

We compared TWIGS to seven methods: ISA (Bergmann et al.,
2003), Bimax (Prelic et al., 2006), SAMBA (Tanay et al., 2004),
EDISA (Supper et al., 2007), the plaid model (Mankad and
Michailidis, 2014), sliding window analysis of fMRI data (Allen et al.,
2014) and modularity analysis of ﬂVIRI data (Rubinov and Spoms,
2010, 2011). For each method, we tested a wide range of its internal
parameters to fine tune it for the tested dataset. The Supplementary
Text provides all details; here we give a brief overview.

Our comparison shows that except for modularity analysis
(which enforces using all subjects by the method’s definition), extant
methods have difficulties in finding modules that cover many sub—
jects. TWIGS provides an almost 2—fold improvement in the ability
to find modules that cover many patients. For example, on average,
modules identified by EDISA on the sepsis data covered less than
five patients compared with nine by TWIGS. The sliding window
analysis, which estimates the covariance matrix of each time win—
dow and then clusters all windows from all subjects, had an average
coverage of less than 10 on the fMRI data, whereas TWIGS covered
all 20 subjects. TWIGS was comparable to other methods in enrich—
ment analysis for known biological functions in terms of: (i) the
total number of covered functions, (ii) the strength of the detected
enrichments and (iii) the fraction of modules with enriched terms.
When consolidating scores 1—3 using non—parametric ranking,
TWIGS ranked first.

When applying the plaid model to the sepsis data, it tended to
find much larger gene sets. However, these modules manifested a
very mild up—regulation response compared with the TWIGS mod—
ules. The fMRI modularity analysis method of Rubinov and Sporns
(2010, 201 1) partitioned the brain into clusters, each containing one
of our core modules. TWIGS’s subject—specific module augmenta—
tions provided additional biological results.

4 Discussion

We presented a novel problem formulation and algorithm for ﬂex—
ible three—way clustering of multi—matrix time course data. We
defined a core module as (i) a set of rows that are likely to be active
together across a set of subjects and (ii) a set of active time points in
each covered subject. In addition, each core module has subject—spe—
cific private modules that can contain additional genes and have
high overlap with the core module. The set of active time points of a
module can vary in size and times among subjects.

Our model is much more ﬂexible than existing models. First, it
allows different active time points for each subject, thereby accom—
modating heterogeneity and asynchrony in the response of different
subjects. Second, different subjects can differ in their underlying fea—
tures (rows) and time points (columns). The row set of a particular

subject in a module does not necessarily cover all core module rows.
This property was crucial in the analysis of fMRI data, where it
allowed discovering core modules that better covered active brain
regions. In addition, the row set of a private module can contain
additional rows that represent subject—specific signal. This property
was crucial in the gene expression case as it allowed discovering pa—
tient—specific up—regulated immune processes.

We compared TWIGS to seven other methods and showed that
extant methods have difficulties in finding modules that cover many
subjects, whereas TWIGS easily finds modules that represent a bio—
logical function shared by many subjects. In addition, our method
outperformed other methods in terms of enrichment analysis. We
employed additional metrics for evaluation in each domain. Other
comparison criteria can be used in the future, e.g. test—likelihood or
perplexity.

Our current analysis has some limitations that can be addressed
by future studies. First, we assume that the data originated from two
distributions f0 and f1. Other approaches could be considered, such
as row—based or column—based additive models (Lazzeroni and
Owen, 2002). Second, our basic model deals with only a single mod—
ule at a time. More complex models and algorithms could be pro—
posed to directly model multiple modules. Finally, additional tests
are needed to fully exploit the abilities of the model. For example,
we focused only on testing a time window of size 1 to find homogen—
ous highly activated private modules.

Funding

This study was supported in part by the Israel Science Foundation (grant 317/
13, to R.S.), the Azrieli Foundation Fellowship and the Edmond J. Safra
Center for Bioinformatics at Tel Aviv University (to D.A.). Additional support
was provided by the Israeli Centers of Research Excellence (I-COREs) Gene
Regulation in Complex Human Disease, Center No. 41/11 (R.S.) and
Program in the Cognitive Sciences (to T.H.).

Conﬂict of Interest: none declared.

References

Allen,E.A. et al. (2014) Tracking whole-brain connectivity dynamics in the
resting state. Cereb. Cortex, 24, 663—676.

Belliveau,J.W. et al. (1991) Functional mapping of the human visual cortex by
magnetic resonance imaging. Science, 254, 716—719.
Ben-Dor,A. et al. (2003) Discovering local structure in gene expression data:
The order—preserving submatrix problem. ]. Comput. Biol., 10, 373—384.
Bergmann,S. et al. (2003) Iterative signature algorithm for the analysis of
large—scale gene expression data. Phys. Rev. E Stat. Nonlin. Soft Matter
Phys, 67, 031902.

Birn,R.M. (2012) The role of physiological noise in resting-state functional
connectivity. Neuroimage, 62, 864—870.

Cheng,Y. and Church,G.M. (2000) Biclustering of expression data. Proc. Int.
Conf. Intell. Syst. Mol. Biol., 8, 93—103.

Craddock,R.C. et al. (2012) A whole brain fMRI atlas generated via spatially
constrained spectral clustering. Hum. Brain Mapp., 33, 1914—1928.

Dede,D. and Ogul,H. (2013) A three-way clustering approach to cross—
species gene regulation analysis. In: 2013 IEEE International Symposium
on Innovations in Intelligent Systems and Applications (INISTA), IEEE,
pp. 1—5.

Dosenbach,N.U.F. et al. (2007) Distinct brain networks for adaptive and stable
task control in humans. Proc. Natl Acad. Sci. USA, 104, 11073—11078.

Fox,M.D. et al. (2006) Spontaneous neuronal activity distinguishes human
dorsal and ventral attention systems. Proc. Natl Acad. Sci. USA, 103,
10046—10051.

Gerber,G.K. et al. (2007) Automated discovery of functional generality of
human gene expression programs. PLoS Comput. Biol., 3, 1426—1440.

112 /310's1cu.inofp.iq1x0'soiicurJOJHioiq/ﬁduq r1101} pap1201um0q

9103 ‘0g isnﬁnv uo ::

i26

D.Amar et al.

 

Hartigan,I.A. (1972) Direct clustering of a data matrix. I. Am. Stat. Assoc.,
67,123—129.

Lazzeroni,L. and Owen,A. (2002) Plaid models for gene expression data. Stat.
Sin., 12, 61—86.

Li,A. and Tuck,D. (2009) An effective tri—clustering algorithm combining expres-
sion data with gene regulation information. Gene Regul. Syst. Biol., 3, 49—64.
Madeira,S.C. and Oliveira,A.L. (2004) Biclustering algorithms for biological data

analysis: a survey. IEEE—ACM Trans. Comput. Biol. Bioinform., 1, 24—45.

Maldjian,I.A. et al. (2003) An automated method for neuroanatomic and
cytoarchitectonic atlas—based interrogation of fMRI data sets. Neuroimage,
19,1233—1239.

Mankad,S. and Michailidis,G. (2014) Biclustering three—dimensional data
arrays with plaid models. I. Comput. Graph. Stat., 23, 943—965.

Meng,I. et al. (2009) Enrichment constrained time-dependent clustering
analysis for ﬁnding meaningful temporal transcription modules.
Bioinformatics, 25, 1521—7.

Mitra,K. et al. (2013) Integrative approaches for ﬁnding modular structure in
biological networks. Nat. Rev. Genet., 14, 719—32.

Oghabian,A. et al. (2014) Biclustering methods: biological relevance and ap-
plication in gene expression analysis. PLoS One, 9, e90801.

Parnell,G.P. et al. (2013) Identifying key regulatory genes in the whole blood
of septic patients to monitor underlying immune dysfunctions. Shock, 40,
166—74.

Prelic,A. et al. (2006) A systematic comparison and evaluation of biclustering
methods for gene expression data. Bioinformatics, 22, 1122—1129.

Rana,M. et al. (2013) A toolbox for real—time subject—independent and sub-
ject-dependent classiﬁcation of brain states from fMRI signals. Front.
Neurosci., 7, 170.

Rubinov,M. and Sporns,O. (2010) Complex network measures of brain con—
nectivity: uses and interpretations. NeuroImage, 52, 105 9—1069.

Rubinov,M. and Sporns,O. (2011) Weight—conserving characterization of
complex functional brain networks. NeuroImage, 56, 2068—2079.

Serin,A. and Vingron,M. (2011) Debi: discovering differentially expressed
biclusters using a frequent itemset approach. Algorithms Mol. Biol., 6, 18.
Shabalin,A.A. et al. (2009) Finding large average submatrices in high dimen-

sional data. Ann. Appl. Stat., 3, 985—1012.

Spreng,R.N. et al. (2010) Default network activity, coupled with the fronto—
parietal control network, supports goal-directed cognition. NeuroImage,
53, 303—317.

Stamatakis,E.A. et al. (2010) Changes in resting neural connectivity during
propofol sedation. PLoS One, 5, e14224.

Supper,I. et al. (2007) EDISA: extracting biclusters from multiple time-series
of gene expression proﬁles. BMC Bioinformatics, 8, 334.

Tanay,A. et al. (2004) Revealing modularity and organization in the yeast mo—
lecular network by integrated analysis of highly heterogeneous genomewide
data. Proc. NatlAcad. Sci. USA, 101, 2981—2986.

Ulitsky,I. et al. (2010) Expander: from expression microarrays to networks
and functions. Nat. Protoc., 5, 303—322.

Vaisvaser,S. et al. (2013) Neural traces of stress: cortisol related sustained en—
hancement of amygdala—hippocampal functional connectivity. Front. Hum.
Neurosci., 7, 313.

Waltman,P. et al. (2010) Multi—species integrative biclustering. Genome Biol.,
11, R96.

Yeo,B.T.T. et al. (2011) The organization of the human cerebral cortex
estimated by intrinsic functional connectivity. I. Neurophysiol, 106,
1 125 —1 1 65.

Zhao,L. and Zaki,M.I. (2005) TriCluster: an effective algorithm for mining
coherent clusters in 3d microarray data. In: Ozcan,F. (ed.), Proceedings of
the 2005 ACM SIGMOD International Conference on Management of
Data. ACM Press, Baltimore, MD, USA, pp. 6 94—705 .

112 /310's1cu.inofp.iq1x0'soiicurJOJHioiq/ﬁduq r1101} pap1201um0q

9103 ‘0g isanV uo ::

