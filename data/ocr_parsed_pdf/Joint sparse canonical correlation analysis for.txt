Bioinformatics Advance Access published August 21, 2016

Bioinformatics, 2016, 1—9

doi: 10.1093/bioinformatics/btw485

Advance Access Publication Date: 27 July 2016
Original Paper

 

 

Bioimage informatics

Joint sparse canonical correlation analysis for
detecting differential imaging genetics modules

Jian Fang1'2, Dongdong Lin3, S. Charles Schulz4, Zongben Xuz,
Vince D. Calhoun3 and Yu-Ping Wang1'*

1Biomedical Engineering Department, Tulane University, New Orleans, LA 70118, USA, 2School of Mathematics
and Statistics, Xi'an Jiaotong University, Xi'an, ShaanXi 710049, China, 3The Mind Research Network, Department
of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM 87131, USA and 4Department
of Psychiatry, University of Minnesota, Minneapolis, MN 55455, USA

*To whom correspondence should be addressed.
Associate Editor: Robert Murphy

Received on March 24, 2016; revised on June 17, 2016; accepted on July 12, 2016

Abstract

Motivation: Imaging genetics combines brain imaging and genetic information to identify the rela—
tionships between genetic variants and brain activities. When the data samples belong to different
classes (e.g. disease status), the relationships may exhibit class—specific patterns that can be used
to facilitate the understanding of a disease. Conventional approaches often perform separate ana—
lysis on each class and report the differences, but ignore important shared patterns.

Results: In this paper, we develop a multivariate method to analyze the differential dependency
across multiple classes. We propose a joint sparse canonical correlation analysis method, which
uses a generalized fused lasso penalty to jointly estimate multiple pairs of canonical vectors with
both shared and class—specific patterns. Using a data fusion approach, the method is able to detect
differentially correlated modules effectively and efficiently. The results from simulation studies
demonstrate its higher accuracy in discovering both common and differential canonical correl—
ations compared to conventional sparse CCA. Using a schizophrenia dataset with 92 cases and
116 controls including a single nucleotide polymorphism (SNP) array and functional magnetic
resonance imaging data, the proposed method reveals a set of distinct SNP—voxel interaction mod—
ules for the schizophrenia patients, which are verified to be both statistically and biologically
significant.

Availability and Implementation: The Matlab code is available at https://sites.googIe.com/site/jian
fan986/JSCCA.

Contact: wyp@tulane.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 IntrOducuon number of variables. However, how to combine the large amount of

Imaging genetics is an emerging field of study in brain research multi—modal data remainsa challenging problem.

9103 ‘Og JSanV 110 seleﬁuv soc] ‘BtHJOJtIBQ 30 AJtSJQAtuf] 112 ﬁle'smumofqutxo"sotJBurJOJutotq/ﬁduq 11101} pepeolumoq

(Hariri et (11., 2006; Meyer—Lindenberg, 2012). It aims to discover
genetic variants that explain brain activities, providing more com—
prehensive information that can hopefully inform the diagnosis and
treatment of mental disorders (e.g. schizophrenia). To date, imaging
and genomic data are collected and both modalities include a large

Canonical correlation analysis (CCA) (Hotelling, 1936 ) and par—
tial least squares (PLS) (Wold, 1985) are common multivariate
approaches to integrate two or more data types. The basic idea is to
maximize the correlation (or covariances in PLS) between linear
combinations of variables from different data types to find the

©The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com l

J.Fang et aI.

 

components that are associated with each other. Kernel CCA (Lai
and Fyfe, 2000; Larson et (11., 2014) and deep CCA (Andrew et (11.,
2013) are extensions to extract nonlinear correlation between two
datasets. However, in genomic and brain imaging studies, the di—
mension of the data is usually much higher than the sample size. As
a result, severe overfitting can occur when conventional CCA meth—
ods are applied. To address this problem, penalized CCA and related
methods were introduced by employing sparse penalties to select a
small number of features. Examples include sparse CCA
(Parkhomenko et (11., 2009; Witten and Tibshirani, 2009), sparse
PLS (Chun and Keles, 2010) and sparse reduced rank regression
(Vounou et (11., 2010), which have been demonstrated to be effective
in detecting multivariate genomic and brain imaging associations
(Grellmann et (11., 2015; Liu and Calhoun, 2014). To incorporate
biological prior knowledge and data structures to guide the search
of associations, group SCCA (Lin et (11., 2014) and network—guided
sparse reduced rank regression (Wang et (11., 2014) were proposed,
which can further improve variable selection.

In all the above methods, a common assumption is that the data
are collected from the same distributions. However, in real imaging
genetic studies, the data are collected from subjects corresponding
to different disease statuses (e.g. the schizophrenia patients and
healthy controls). A separate estimation will suffer a lack of power
due to the limited size of each individual class, but a simple combin—
ation of the data may miss the identification of the heterogeneity of
the interactions. Therefore, it is desirable to discover both the com—
mon and class—specific interactions simultaneously by joint analysis
of multi—class data. In (Chen et (11., 2013), a statistical method was
proposed to jointly study miRNA—gene interactions from multiple
cancers. However, this method is restricted to univariate inference
that is not able to detect complex multivariate correlations. A chal—
lenge was also recognized in (Chen et (11., 2013) that the direct appli—
cation of sparse multivariate methods may choose different sets of
interaction pairs for each class. Especially for sparse CCA, similar
patterns may appear in different orders, leading to the problem of
mismatch during joint analysis across classes.

In this paper, we propose a novel sparse CCA method to jointly
estimate multiple CCA models corresponding to different classes. As
illustrated in Figure 1 with two types of data from K classes, the
main idea is to find a common sparse linear combination of the vari—
ables from one type of data (for example the imaging data) and K
joint sparse linear combinations from the other type (e.g. the gen—
omic data) to maximize the summed correlation. In this way, the
method can obtain the brain regions that are important for all
classes and discover their differential interactions with the genetic
variants. Specifically, by restricting the imaging canonical variables
to be common across classes, the method overcomes the problem of
mismatch that can make full combination of the data from multiple
classes (see Fig. 1). We also apply a fused lasso penalty on the K ca—
nonical vectors for genetic data to encourage them to share a similar
(but not the same) structure. The fused lasso penalty is chosen be—
cause it has been successfully applied to jointly estimate multiple
graphical models to find differential dependency networks (Danaher
et (11., 2014; Tian et (11., 2014; Yang et (11., 2015). Inspired by the op—
timization framework for penalized CCA in (Witten et (11., 2009),
we design an efficient algorithm based on block coordinate descent
for solving JSCCA. The JSCCA is featured as a multivariate method
for joint interactions analysis, promising to detect complicated ab—
normal interaction modules between genomic variants and brain
activities. We first apply the proposed method to the simulation
data containing three classes. Through a comprehensive compari—
son, we demonstrate the effectiveness of JSCCA in discovering both

Genomic Data Joint Sparse CCA Brain Imaging

 

 

  

IC‘ommon
' ‘asrr [1ch It
Y; 1111mm mm:c1 1 s 'r X.
m V] C 55—2 SDL‘CIITL‘
I Class-K Spccilit:
JJJDJJJJJIUI
Y2 JJIﬂIIllEDI—- X:
1111111111111:
Y, IIJIEIIIJEEI—- X,

 

 

 

 

Fig. 1. An illustration of the JSCCA method for detecting differential imaging
genetics modules. The method finds a common sparse set of voxels and K
joint sparse set of SNPs to maximize the summed correlation. The SNP is se-
lected in the kth class only if it is highly correlated with the voxels. Therefore,
the class specific SNPs have potentially higher interactions with the detected
voxels

shared and class—specific correlations. Next, we apply the JSCCA
method to a schizophrenia dataset with 92 cases and 116 controls.
The data include functional magnetic resonance imaging (fMRI) and
single—nucleotide polymorphism (SNP) data, collected by The Mind
Clinical Imaging Consortium (Gollub et (11., 2013). We found a
number of SNP—voxel modules with significantly increased correl—
ation for schizophrenia patients.

The rest of the paper is organized as follows. Section 2 intro—
duces the joint sparse CCA method. The performance of the pro—
posed method is evaluated through both simulations and real data
analysis in Section 3, followed by some discussions and concluding
remarks in the last section.

2 Methods

2.1 Sparse CCA
The CCA is a method that determines the associations between two
datasets. More specifically, given datasets X E 72”” , Y E 72”" with
71 samples, where X has 17 features and Y has q features, the CCA
method aims to find linear combinations of variables in X and Y to
maximize the correlation:

max wTXTYv s.t. wTXTXw : vTYTYv : 1, (1)
where we assume that the columns of X and Y are standardized to
have zero mean and unit variance, and w, v are the corresponding
canonical vectors.

However, in genomic and bio—imaging applications, the dimen—
sion of the data is much higher than the sample size. The (1) model
tends to overfit and does not yield desirable results. To circumvent
this problem, sparse CCA has been proposed in recent years. By
imposing sparse regularization on the canonical vectors, sparse CCA
can achieve better model fitting with variable selection. In this
paper, we adopt the formulation in (Witten and Tibshirani, 2009)
with L1 regularization as follows:

rrwliVn—wTXTYvaIIwIIl HVIIvIIl st. Hwa :11sz 2 1. <2>
where A“, and 1,, are the regularization parameters. In (2), the vari—
ance matrix of X and Y is treated as diagonal matrix, which has

shown to be effective and efficient for high—dimensional data
(Grellmann et (11., 2015; Witten and Tibshirani, 2009).

2.2 Joint sparse CCA (JSCCA)

In this paper, we consider how to perform multivariate association ana—
lysis of K classes of normalized data, X;a 6 RM” , Y;a 6 RM”,
[2 : 1, . . . ,K, where me is the number of observations in the kth class.

9103 ‘Og JSanV uo seleﬁuv 50'] ‘BtulomBQ JO AJtSJQAtuf] 112 /310'slcu1nofp103xo"sotJBurJOJutotq/ﬁduq 11101} pQPBOIII/IAOG

Joint sparse CCA

 

As described in the introduction and Figure 1, the main idea is to jointly
estimate CCA models belonging to multiple classes with one common
canonical vector for X and K related sparse canonical vectors for Y.
More formally, the joint sparse CCA model is given by:

14/.1/

K
, 1
mln — inXZkak + 
13:1'“a

K (3)
1 1
+ZMIUUI1+ Z THU}: - vle1
13:1 k<k’
2 2
S-t- Hsz I UVUF I 1
where w and V : [111, . . . ,UK] are the canonical vectors of X12 and Y12

respectively,  : Z}, III/kl); 1w,1,,,r are regularization param—
eters. In (3), we apply the general fused lasso penalty (Danaher
et (11., 2014; Hoefling, 2010) on V. The L1—penalty on each 1112, con—
trolled by 1,,, encourages the sparsity over each individual canonical
vector. The L1—penalty on the differences between every two canon—
ical vectors from different classes encourages them to share a similar
structure. In this way, all of the components 111, from Y are correlated
with the common component to from X; hence their shared and
class—specific interactions can be determined. The parameter 17 plays
an important role to adjust the degree of fusion. Specifically, when
17: 0, there is no fusion across the canonical vectors. When 17: oo,
(3) is obtained only when all canonical vectors are identical to each
other. Moreover, if we add the constraint  : 1 as a whole in—
stead of constraining each canonical vector, we realize a joint esti—
mation. When K : 1, this reduces to regular sparse CCA.

2.3 Numerical algorithm

In this section, we introduce the algorithm to obtain w and V that can
minimize (3). To begin with, we outline the key steps of the optimiza—
tion. In JSCCA, the object function is convex with respect to to when
V is fixed and vice versa. So the block coordinate descent, which is
widely used in SCCA method, can be applied to solve this problem.
Roughly speaking, the iteration procedures mainly contain two steps:

K

. 1
mln _ _(x[Y,u,)Tw+/1,,ijjjj,
11w112:1 b1"
K 1 1 1
mm — Z—wzxzm +1.11v1111 + Z r1111 4/1111
ill/1117:] k:1 "k k<kI

According to (Witten et (11., 2009), the solution of the first prob—

lem is given by w : xi, where
ijjz
K 1
13 : H (2 —X,TY,,u,,, 1,),
13:1 "’3
and H is the soft—thresholding operator defined by H (x, 1) :
sgn(x)max(jx) — 1, 0).
To obtain V when w is fixed, we follow the results from Section
2.3 in (Witten et (11., 2009) and can easily get (the proof is omitted):

Proposition 1: The solution of
K 1 1
min E —Z1Tvk+1vHI/1H1+ E TIM-1111M,
HVHF:1 k:1 R},
where z}, : i YTka;a T, is given by V V v, where V is the 0 ti—
ny, k F p

mum of

K
. 2 1 1
frganij-zkjjz‘i'ivjjvkjb‘ferjvk—Vkljb (4)
13:1 k<k’

The problem of (4) is a special case of the fused lasso signal ap—
proximation (Hoefling, 2010). A very efficient algorithm for the so—
lution is available (Danaher et (11., 2014; Hocking et (11., 2011).
Specifically, (4) can be solved in successively three steps: a fusion
step, a sparsification step and a normalization step. In the fusion
step, a V is obtained by setting 1,, : 0, which fuses the variables that
do not have significant difference (dependent on 17). Here, we say
that the variable i in Y is fused between the kth and k’th classes if
17),,- : 17;,:,-. In the sparsification step, V is derived through soft—
thresholding on V, that is, 5;, : H(17;,,1,,). Finally, in the normaliza—
tion step, : m leads to the solution.

Since 71 < < q, a very sparse solution is required to ensure the
reliability. This highly increases the sensitivity of the selection of 1M,
and 1,, (Parkhomenko et (11., 2009), hence increasing the difficulty in
parameter selection. To mitigate this problem, we adopt the sparsity
level of the solution to guide the selection of the tuning parameters
(Duan et (11., 2014; Zongben et (11., 2012). Then the selection can be
searched around the sample size n, yielding a much less sensitive
searching process. In particular, we set the 1“, based on Kw, which is
the number of non—zeros in to. There is a correspondence between
1“, and K“, by setting 1“, in each iteration to satisfy

AW 6 [)W)Kw+17 )W)Kw:|7

where jwjkw is the Kwtl'l largest absolute magnitude of w.
Meanwhile, it was found in both simulations and real applications
that using the same 1,, for different classes will result in unstable so—
lutions (see Fig. S1 in supplementary data). To overcome this prob—
lem, we instead keep the sparsity 16,, the same for each class. We set
the 1,,1z based on the same sparsity K,,, where the corresponding rela—
tionship can be obtained accordingly. This procedure will result in
different thresholds, which makes it overestimate the number of
changes among 1112. Nevertheless, the difference of the thresholds
was found to be small in practice and we can still detect the changes
by comparing 17;a after the fusion step.

Finally, we describe how to obtain multiple canonical vectors.
Suppose we have derived the first K pairs of canonical vectors using
the iterations described above, we calculate the remaining matrix

Y 1/ VT . .
X;a : X;a — kawT, Y;a : Y;a — W, from wh1ch we can obtaln
k 2

the second K pairs of canonical vectors. The subsequent canonical
vectors can be obtained by repeating the above procedures.
We summarize the JSCCA algorithm in Algorithm 1.

2.4 Parameter selection
There are mainly three tuning parameters Kw, K,,, 17 in the JSCCA
model. The first two control the number of selected features and the
third one determines how similar the derived genomic features are.
However, conventional parameter selection methods, such as the
cross validation, is not well suited. On one hand, limited by the sam—
ples size, the optimized parameters selected from cross validation
could still yield many irrelevant features (Wang et (11., 2014). On the
other hand, since the imaging and genetic correlation is quite low
(Grellmann et (11., 2015) the selected parameters vary a lot during re—
peated trials. As an alternative, we apply a hybrid of Monte Carlo
validation and stability selection (Meinshausen and Buhlmann,
2010) to select the parameter 17 and correlated features.

Specifically, we perform random sampling from the original
dataset without replacement for B times with the same portion of
observations, leading to training samples ka, Yb)“ b : 1 . . .,B and

9103 ‘01; JSanV uo seleﬁuv 50'] ‘BtulomBQ JO 11151911111 {1 112 /310'slcu1nofp103xo"sotJBurJOJutotq/ﬁduq 11101} pQPBOIII/IAOG

J.Fang et aI.

 

 

Algorithm 1 Algorithm for joint sparse CCA

 

Require: Normalized data X;a 6 RM”, Y;a 6 RM”, param—
eters Kuhn/,1.

Ensure: Canonical vectors to and V.

1: Initialize w as the ﬁrst left—singular vector of Z}, iXZYk,

2: repeat

, K

3: V : argminV];1 HUI, 2,}:YZXku/II + Zkk, tllvk 2ka“;
4: fork:1toKdo
5= 11k 2 Iﬁijm;
6: 51 = Mink/in);
7: end for
8: VZV/UVUF;

K
9: Lil : Z anZkak;

13:1 “
10: 4w : jwjxw+13
11: L?! : H(LT.I,1W);
12: W I W/Hﬁ’jjz;

13: until Convergence T
Y
14: Calculate X;a : X;a — kawT, Y;a : Y;a — %; return to
k 2

Step 2 to get the next L pairs of canonical vectors.

 

testing samples XEk, chk. For each subsample, the JSCCA is fitted
with fixed Kw, 16,, and a candidate set of 17, and the canonical vectors
wit/2T are obtained. First, the 17" that maximizes the averaged test
correlation on the test subsamples 2,, Z}, corr(X,§kw;,r, Ybth/ZT) is
selected, where corr(x, y) calculates the Pearson correlation between
vectors x and y. Second, the canonical vectors 1017,11,}: corresponding
to the selected 17" are collected. For the imaging canonical vectors,
we measure the importance of a voxel by the empirical selection

probability
.7 12 b
pun — B b  > 0): 

where I is the indicator function. Based on which a set of important
voxels is selected with a cut—off as S“, : {i : pm,- > 1%}.

For the genomic canonical vectors, we focus on the differences in
the selected SNPs across multiple classes. We compare the canonical
weights in a pairwise way. In particular, for every two class [2, k’, we
measure the degree of specificity from k to k’ by the following

probability
1 _ _
125:2 ,21011 > 11.111211 2 11.1). (61
b

where the first condition requires that there exists difference. Since
stability selection needs multiple runs on the resampled data and
each run will result in either weaker or stronger jvkij than jvklij, we
only count the cases that 11121.1 > 1112,11 in pf?” to make subsequent

analysis more informative (the case of stronger Up,- is considered in

k/k
pvi

enough, determined by whether the canonical weights are fused dur—
ing the fusion step in Algorithm 1. The high—rank SNPs, determined
by a cut—off TE,,, are then picked as the candidate set of differential
SNPs Sf,” : {i : p5,!” > 11,}. In this way, we expect to find class—k
specific (as compared to class k’) SNPs, that frequently have stronger

). The second condition requires the difference to be large

correlations with the imaging features than in class—k’.

2.5 Differential correlated modules detection

The high—ranked voxels and differential SNPs are more likely to be
differentially correlated, and we propose to detect the differential
correlated modules by selecting cut—offs that properly control the
module FDR (mFDR) of pairwise differential correlation between
elements in S“, and 55’”. Specifically, the difference of the Pearson
correlation of each pair of selected voxel and SNP in S“, and SE,” is
calculated

1: I:
Am,“ ’ : ICOfr(sz-7 1(a)) — icon-(X1377 Yla’i)

. (7)

and the corresponding significance 17,-,- is estimated by the permuta—
tion test. More specifically, to get 17,-i, the null hypothesis of no dif—
ferent correlation between a SNP i and voxel / in class [2 and k’ can
be formulated as Ho : Apg’k’ : 0 versus the alternative hypothesis,
H1 : Apg’k’ 94 0. To test the hypothesis, we first calculate Apg’k’. By
comparing the observed statistic with the null statistics
Apgf’, b : 1, . . . , T, i.e. with T times permutation of the class label

of the samples, we can evaluate the significance of the correlation by

T
13,}: 13,}:
1717' : 21(Apijb/ Z Apij (VT
[7:1

Then the mFDR is calculated by

Z Z 1(Pii > 0-05)

iesw jesgkl

Iswjjssk'j ‘8)

Finally, the 1:“, and 11,, are selected by maximizing the module
size (for example ijj 15W, 1) that satisfies mFDR g 11f. In this paper,
we set 11f : 0.1 by considering the weak voxel—SNP correlation and
some possible missing edges in the modules.

3 Results and discussions

3.1 Simulations

In a series of simulations, we aim at evaluating the potential power
of JSCCA in detecting imaging genetics associations. We first com—
pared SCCA and JSCCA with varied tuning parameters. Then we
investigated the influence of noise level on the performance of
detection.

3.1.1 Simulation setup
In all simulations, we consider the data belonging to three classes.
Each class consists of 71 samples of fMRI data and SNP data.

To simulate the correlation between fMRI and SNPs, a latent
variable model similar to (Lin et (11., 2014; Parkhomenko et (11.,
2009) was used. We first generated one imaging canonical vector or
with l non—zero entries and three genomic canonical vectors [312 with
m non—zero entries. Among the m canonical variables, m5 of them
had the same value while m5 of them were only present in one class
(e.g. having zero entries in the other two, see Fig. 1). Each non—zero
variable in or and [i], was drawn independently from a uniform distri—
bution with support on [—1,—0.5] U [05,1].

Given a pair of canonical vectors or and [31,02 : 1, 2, 3), we gener—
ated a latent variable 17 with normal distribution N (0, 01,) for each
sample, where a), is the signal to noise level (e.g. a noise variance of
1). For the imaging data, the voxels were simulated using a
Gaussian distribution N (01/7, I[) for correlated voxels and N (0, 11,4)
for uncorrelated ones. For the genomic data, the SNP was coded by
0 (no minor allele), 1 (one minor allele) and 2 (two minor allele) and
the minor allele frequency 11 was uniformly drawn from U [0.2, 0.4].

9103 ‘01; JSanV uo so1e§uv soc] ‘BIIIJOJIIBD JO 1115191111111 112 /310's112u1n0fp101x0"sotJBurJOJutotq/ﬁduq 111011 pepBo1u/noq

Joint sparse CCA

 

The 1th SNP was simulated from a binomial distribution B(2,logit_1

(—/)’,,,-h + logit(11,-))) if it is a correlated variable and B(2,11,-) other—
wise. Here logit(p) : log(ﬁ) is the logit function.

We used the true positive rate (TPR), false positive rate (FPR)
and precision to evaluate the performance of the model. Specifically,
we applied stability selection to JSCCA and SCCA and compared
their ability in identifying the canonical voxels and the differential
canonical SNPs. For JSCCA, we calculated the selection probability
as in (5) and (6), and determined the positives according to a given
cut—off threshold. When applied to multi—group problems, the TPR
and FPR for differential canonical SNPs were calculated based on
the summation of the number of FPs and TPs between every two
groups. For SCCA, we estimate the canonical vectors individually
on each class, and calculated the selection probability on the voxels
using (5 ) separately but on the differential SNPs using (6) jointly.
Two methods were compared to identify voxels for SCCA. One
used the selection probability from a single class, which is denoted
as SCCA (single). The other refers to SCCA (combined), which iden—
tified voxels when the selection probabilities for all the three classes
exceeded the cut—off threshold. For the SNPs, we followed the same
procedures for JSCCA. In each simulation, the statistics were aver—
aged over 100 replications.

3.1.2 Simulation results

First, we evaluated the JSCCA with varied parameter 1:. We gener—
ated 100 samples for each class (totally 300 samples) with 1000 vox—
els and 1000 SNPs. We set I: 100, m, : 100, mg: 50, a), : 0.2. The
receiver operating characteristics (ROC) curve was adopted for the
comparisons in identifying the canonical voxels and the differential
canonical SNPs with different 17. Specifically, for each 17, we set
K“, : 200, 16,, : 200 and draw the curves by varying the cut—off prob—
abilities. The SCCA was also included in the comparisons.

Figure 2(a), (b) displays the TPR against FPR on the selected
voxels. We can see that the SCCA with single class data and com—
bined threshold performs much worse than the JSCCA. The com—
bined threshold performs even worse than single class case.

 

    

 

   
    

 

 

 

 

 

 

 

(a) 1 (b) 1
2 n
:2 0.8 a 0.3
2 8
Z1 0.6 ,3 0.6
S 5
§ 0.4 —JSCCA(1=0) Em T—Tlsccmwlof T
,5 —JSCCA(1=0.1) .5 JSCCAfr:01)
D: —JSCCA(7=0.2) II —JSCCﬁ{v-=0.2)
n_ 02 —JSCCA(120.4) E 02 —JSCCA{1_=D.4)
|— —SCCA(SIngle) —SCCA(SIIIgIe)
—SCCA(Combined) —SGCA(COmnneu1
0
00 0.2 0.4 0.6 0.8 1 0 0.02 0.04 0.06 0.05 0.1
FPR of canonical voxels FPFI of canonical voxels
(c) (d)
a 1- a 1-
% 5
‘5: 0.8 “mi 0.3
.2 .2
S E
I:
g 0.6 E 0 G
.9 n!
E’ 0.4 E 0.4-
a a —JSDCA[1=0]
E :5 ammo-0.1]
.3 0.2 - ‘5 0.2 —.Jsocm.=o.2:
O —JSDCA[)=D.4] '5 —JSCCA[1=0.4J
c: —SCCA(CurriJimd) II —scm(Cuurbinau1
In: 0_ _ _.   E 0 _ ..  ..
0 0.2 0.4 0.6 0.8 1 0 0.02 0.04 0.06 0.08 0.1

FPR of clifferntial canonical SNPs

FPR ol clitlemtial canonical SN PS

Fig. 2. A comparison of SCCA and JSCCA in identifying the differential inter-
actions. (a) TPR versus FPR on the detection of canonical voxels. (b) The de-
tailed comparison on the detection of canonical voxels. (c) TPR versus FPR on
the detection of differential canonical SNPs. (d) The detailed comparison on
the detection of differential canonical SNPs

Moreover, as the parameter 17 increases, the area under curve does
not change too much. Figure 2(c), (d) evaluates the success in detect—
ing differential canonical SNPs. The figure implies that JSCCA in all
setting performs no worse than the SCCA. In addition, for JSCCA,
as the parameter 17 increases from 0 to 0.2, the TPR increases con—
stantly, especially given a low FPR. But when 17: 0.4, the perform—
ance decreases. All these results indicate that the parameter 17 plays
an important role in combining the power of each individual class to
reduce the false detections in both SNPs and the related voxels. But
excessive fusion will hinder the power in the detection for the differ—
ential canonical SNPs. Hence, a proper balance is required to yield a
desirable solution. To study the proposed method in different scen—
arios, a set of simulations were conducted to evaluate the effect of 1,
m5, mg on the performance, which are available in supplementary
data.

We then varied the noise level 0e from 0.05 to 0.5 to see its ef—
fects on the performance. Figure 3 draws the precision for the detec—
tion of the canonical voxels and differential canonical SNPs. In
particular, we selected the top ranked 100 voxels and 100 differen—
tial SNPs for each method to calculate the precision. Obviously, as
the signal to noise level 0;, increases, the precision increases for all
methods in the two cases. The JSCCA performs better than SCCA
for both the canonical voxels and differential canonical SNPs. In
addition, as the tuning parameter 17 increases, the precision increases
for JSCCA, but the improvement is quite small for the detection of
canonical voxels. We also studied the performance with top ranked
50 and 200 features (see Figs S8 and S9 in supplementary data),
which show that less selected features provide more reliable results.
All these results indicate that the JSCCA with proper fusion could
yield the best combination of multi—class data to increase the detec—
tion accuracy.

3.2 Application to a schizophrenia dataset

Schizophrenia is a complex mental disorder often characterized by
abnormal thinking, speech and behavior of a patient. It is considered
to be related to a number of genetic factors and the study of the as—
sociations between genetic factors and brain activities will facilitate
our understanding of the biological mechanisms underlying the dis—
ease. Comparing the difference in the association of imaging and
genetics between cases and controls could yield disease—specific
features.

We applied the method to SNP and fMRI data collected by The
Mind Clinical Imaging Consortium (MCIC). The data were from
208 subjects, among them 92 are schizophrenia patients (age:
34 :11, 22 females) and 116 healthy controls (age: 32 :11, 44 fe—
males). We follow the same preprocessing procedures as in Lin et al.

 

 

   

 

   
 

   

 

 

 

 

 

 

 

a b

1n ) 1 (w) 1

_ D.

ﬂ 2

g 0.8 U_) 0.8

— m

.S "E

g 0.6 g 0.6

5 .3;

° —JSCCA(1=0) '0

E 0'4 iJSCCA(r=0.1) "5 0'4 —JSCCA(1=0)

2 —JSCCA(r=0.2) S —JSCCA(r=0.1)

g 0.2 —JSCCA(1=0.4) 3% 0.2 —JSCCA(1=0.2)

9 —SCCA(SingIe) 93 —JSCCA(1=0.4)

n- c —SCCA(Combined) 0. c —SCCA(Single)
0.1 0.2 0.3 0.4 0.5 0.1 0.2 0.3 0.4 0.5

Signal to noise level Signal to noise level

Fig. 3. A comparison of the precision under different signal to noise levels. (a)
precision for the detection of canonical voxels. (b) precision for the detection
of differential canonical SNPs

9103 ‘01; JSanV uo so1e§uv 50’] 0211110111123 10 1115191111111 112 /310's1cu1nofp101xo"$011Bu1101u101q/ﬁduq 111011 pepBo1u/noq

J.Fang et aI.

 

(2014), resulting in 41, 236 voxels and 777, 635 SNPs. Then, the
voxels with the mean response less than 0.3 were removed while the
SNPs included by the Kyoto Encyclopedia of Genes and Genomes
(KEGG) pathway were selected (Kanehisa and Goto, 2000), result—
ing in finally a dataset with 8, 891 voxels and 129, 145 SNPs.

3.2. 1 Experimental results

We applied the algorithm in Section 2 to the data provided. The
data were normalized according to samples from each class. The Km
and 16,, were set to be 200. We found that K“, and 16,, did not affect
too much on the results if they were small enough, e.g. at the same
order as the sample size. We randomly sampled 120 subjects with—
out replacement for 1000 times, and performed JSCCA on each sub
dataset to find the optimum parameter 17. Given the selected 17, we
then applied stability selection and picked important voxels by the
probability p“, and the degree of specificity of SNPs for cases and
controls by the probability 1711,0(0 for control and 1 for case) as
described in Section 2. The differential correlated modules were se—
lected as described in Section 2.5. The analysis of the first two mod—
ules were presented.

We first show the module components. The selected voxels were
plotted in Figure 4. As shown in the figure, for the first group, 95
voxels were selected, which are mainly from the bilateral putamen.
For the second group, 159 voxels were selected, which are mainly
from the right inferior frontal gyrus and right insula. The selected
SNPs were summarized in Table 1. There were 7 SNPs from 6 genes
and 10 SNPs from 8 genes selected by the first and second module,
respectively.

 

Right inferior frontal gyrus: 2.24cm3 & Right insula: 1.81cm3

.1 11 d

Fig. 4. Maps showing the brain regions related to the SNPs. The magnitudes
are the corresponding selection probability. (a) The first module, (b) the se-
cond module

    

Table 1. The susceptibility schizophrenia-specific canonical SNPs
related to the brain region

 

 

SNP ID Gene Chr SNP ID Gene Chr
The ﬁrst module

15163907 AGXTZ 5 156121460 CDH4 20
1516955972 CES7 16 157186424 CES7 16
15105961 1 LPLa 1512512830 SLIT2 4
15132946 PLA2G6a 22

The second module

1510183370 B3GNT2a 2 1512211663 EPHA7 6
1510251347 CNTNAPZa 7 157691506 HADH 4
1512427675 CSNK1A1L 13 153796992 HADH 4
151555639 CSNK1A1L 13 1510513805 MASP1 3
157033245 NOTCH1 9 1517160670 PDE1C 7

 

aGenes reported to have potential relationship with schizophrenia.

Moreover, we plotted the detailed SNP—voxel correlations be—
tween the selected SNPs and voxels in Figure 5. For both the first
and second module, the correlations are high in case group but are
constantly low in control group. Specifically, the mean difference of
the SNP—Voxel correlation between cases and controls is 0.2917
(P < 1e—6) for the first module and 0.2872 (P < 1e—6) for the second
module (the p value was estimated by permutation test), which fur—
ther proves that these case—specific SNPs have significantly increased
correlations with the detected brain regions.

We tested the selected SNPs for gene set over—representation ana—
lysis using ConsensusPathDB (Kamburov et (11., 2013). The Gene
ontology (GO) terms related to neural activity enriched with p—value
less than 0.01 are summarized in Table 2. There are mainly three
GO terms enriched for the first module, by genes CDH4 and SLIT2.
There are mainly eight GO terms enriched for the second module,
primarily by genes EPHA7, NOTCH1, B3GNT2 and CNTNAP2.

3.3 Discussions

In the realm of imaging genetics, CCA is regarded as an efficient al—
gorithm for multivariate analysis of correlations with low computa—
tional complexity, which has been used in our previous studies (Lin
et (11., 2014). Our main results in this paper presented an extension
of sparse CCA to discover differential association modules from dif—
ferent disease statuses. Inspired by the idea of a joint sparse model
(Baron et (11., 2005) and fused graphical lasso (Danaher et (11., 2014;
Yang et (11., 2015), we proposed an JSCCA method and verified its
performance in a schizophrenia dataset. The dataset consists of
fMRI data and SNP data with 116 healthy controls and 92 schizo—
phrenia patients. We designed to explore abnormal brain—genomic
associations in schizophrenia patients. We first applied JSCCA to
find a common brain component and two genetic components (for
cases and controls respectively) to maximize their summed correl—
ations. Then the stability selection method was used to pick up a
candidate set of SNPs that are differentially associated with the tar—
get brain components. Finally, modules are detected by controlling
the mFDR of the pair—wise differential correlation. Overall, the dif—
ferences of group—size associations can infer specific genomic func—
tions in brain activities for schizophrenia patients.

3.3.1 Comparison with sparse CCA

In simulation studies, we have shown the advantages of JSCCA over
SCCA in identifying the differential correlated components when
there is only one pair of canonical vectors. The problem would be

     
 

         

(a) AGXTE 0.5
con-1 1,,
CES7
0.3
CES7
LF'L 0.2
PLA2Ga u,
ELIT2 0
Fuiamen; Putamenj FutarnenJ Pulamenj
(b) 1531111112 0.5
CNTNAPZ
GSNKIM L 0.4
CSNKIM L
EFHA? 0.3
HADH
HADH ‘12
MASP1
NOTCH1 “'1
PDE1C u

Flunlalilnljl lnsulaj anlalilnLFI lnsulajt

Fig. 5. Heatmaps showing the pair-wise absolute Pearson correlation be-
tween the selected voxels and SNPs given the common colormap on the
right, where the left is for cases while the right is for controls. (a) The first
module, (b) the second module

9103 ‘01; JSanV 110 so1e§uv 50’] ‘1211110111123 10 1115191111111 112 /310's112u1n0[p101x0'so1112111101u101q//:d1111 111011 pep1201um0q

Joint sparse CCA

 

Table 2. The enriched gene ontology terms that are related to the neural activity

 

 

GO term Gene P—value
Neuron projection extension 3.5e—4
Neuron projection guidance CDH4, SLIT2 4.5e—3
Positive regulation of nervous system Development 4.7e—3
Neuron projection development 3.2e—4
Neuron development 5 .6e—4
Neuron differentiation EPHA7, NOTCH1, B3GNT2, CNTNAP2 1.2e—3
Neurogenesis 2.1e—3
Nervous system development 8.9e—3
Brain development 2.2e—3
Head development EPHA7, NOTCH1, CNTNAP2 2.6e—3
Central nervous system development 5 .1e—3

 

more complicated in real applications. For example, when applying
SCCA separately to cases and controls, we found the voxels selected
by SCCA in the 3rd and 4th component in cases, in the 1st and 10th
component in controls, are most relevant to the voxels in the two
modules detected by JSCCA. Therefore, a matching procedure is
usually required before the comparison among the results given by
SCCA. However, unlike the case in the simulation, the components
cannot always be ideally matched, which may further degrade the
performance. In contrast, as shown in Figure 1, the JSCCA provides
a joint model which naturally pairs the components so that the joint
analysis becomes more reliable. An alternative approach for match—
ing high dimensional imaging genetics data has been proposed
within an independent component analysis framework (Liu et (11.,
2008; Pearlson et (11., 2015). It would be interesting to do a direct
comparison of these different approaches, which we plan to do in fu—
ture work.

3.3.2 Biological implications

Two brain components were recognized by JSCCA. In particular,
the first brain component includes the region of bilateral putamen.
The putamen is one of the basal ganglia nuclei and part of the stri—
atum, and is associated with the motor skills. Dopamine is concen—
trated within the putamen (Meador—Woodruff et (11., 1996) and
dopamine synthesis capacity has been found related to schizophrenia
and symptom severity (Howes et (11., 2013). In addition, decreased
volume and total neuron number were found in putamen in schizo—
phrenia patients (Kreczmanski et (11., 2007). The second brain com—
ponent includes the region of right inferior frontal gyrus and right
insula. The right inferior frontal gyrus is a component of the pre—
frontal lobe, which is involved in inhibition and attention control
(Hampshire et (11., 2010). Decreased neural activation was found in
the right inferior frontal gyrus for schizophrenia patients (Zandbelt
et (11., 2011; Zhang et (11., 2016). The insula is related to emotional
processing and motor function, and plays an important role in
schizophrenia. The pathological function of the insula in schizophre—
nia was summarized in (Wylie and Tregellas, 2010), which primarily
includes the emotional facial processing, auditory affect processing,
self versus non—self, etc. Moreover, a network connectivity study has
shown aberrant functional connectivity between the right insula and
inferior frontal gyrus (Voegler et (11., 2016).

There were two groups (modules) of SNPs identified in this
paper. In the first module, we have discovered seven SNPs from six
genes. Among them, the LPL, PLA2G6 were reported to have poten—
tial relationship with the risk of schizophrenia. The LPL gene is ex—
pressed in the brain regions with functionally relevant cognitive

functions, and was found to be related to schizophrenia (Le—
Niculescu et (11., 2007; Xie et (11., 2011 ). PLA2G6 (Phospholipase A2
group 6) gene is important for normal brain development and syn—
aptic functioning. The role of PLA2G6 in schizophrenia was re—
viewed in (Law et (11., 2006), which indicated their potential
relationship. In the second module, we have discovered 10 SNPs
from 8 genes. The B3GNT2 and CNTNAP2 were reported to have
potential relationship with the risk of schizophrenia. The B3GNT2
is an immune—related gene and was implicated to be tied to schizo—
phrenia (Sanders et (11., 2013). The CNTNAP2 gene is among the
top schizophrenia genes and has been reported with increased sus—
ceptibility (Friedman et (11., 2008; O’Dushlaine et (11., 2011; Wang
et (11., 2010). In addition, several GO terms related to the neuron
projection, neuron and brain development were enriched by CDH4,
SLIT2, EHHA7, NOTCH1, B3GNT2 and CNTNAP2. All these
findings further demonstrate the biological significance or implica—
tions of the selected modules.

Finally, we are interested in how their interactions affect and dis—
tinguish schizophrenia. One study in (Ross et (11., 1999) suggested
decreased PLA2 activity in putamen for schizophrenia patients. It
was also shown in (Whalley et (11., 2011) that the association be—
tween CNTNAP2 gene and brain activity exists in the right inferior
frontal gyrus in healthy individuals during a language task, which
may indicate the potential risk to mental illness.

3.3.3 Potential limitations

In JSCCA, the assumption on a completely common imaging feature
is too strict in practice, although this assumption provides a fair way
for comparison between classes. To overcome this problem, we are
working on some postprocessing methods (e.g. partial correlation
network) to further eliminate unrelated and indirectly related
connections.

The parameter selection method for penalized CCA is still an
open problem. Especially when the correlation is weak between
genetic variant and brain activity, it is more important to detect re—
liable associations while reducing the FDR (Grellmann et (11.,
2015 ). Stability selection is a recently proposed strategy that can
better control Type—1 error rate (Meinshausen and Biihlmann,
2010; Wang et (11., 2014), hence it is adopted in our proposed
method. The simulations in the supplementary data also demon—
strate that the stability selection can yield better results than cross
validation. However, the selection of the cut—off probability for sta—
bility selection remains a challenging issue, especially for high di—
mensional data. Although the proposed module detection method

9103 ‘01; JSanV 110 so1e§uv s01 ‘1211110111123 10 1115191111111 112 /310's112u1n0[p101x0'so1112111101u101q//:d1111 111011 pep1201um0q

J.Fang et al.

 

worked effectively, it is still far from optimal. We will continue to
work on this problem.

In this paper, the method was evaluated on a case—control study.
We proposed a method to detect the differential correlated modules.
However, the method introduced in Section 2.5 cannot be directly
applied to detect common modules. This is because the calculation
of mFDR is based on the permutation test, where the null hypothesis
is built for detecting differences but not for detecting similarities.
More robust and appropriate statistical methods will be studied in
the future to enable the detection of both common and differential
correlations simultaneously. Moreover, the proposed model could
be more powerful for analyzing data from more than two classes or
from multiple conditions. For example, we can easily extend the
study to imaging genomic data collected from a combination of dif—
ferent research groups and different mental disorders. This would be
a very interesting topic.

4 Conclusion

The main contributions of the present paper can be summarized as
follows. First, we propose a ISCCA method, which can discover re—
lationship among data from observations corresponding to distinct
classes to infer their common and different association patterns.
Second, we present an efficient algorithm to solve the model.
Third, we study the numerical performance of ISCCA via a series
of simulations. Our results show that an appropriate fusion of mul—
tiple data can improve the detection accuracy of both common and
differential associations. Finally, we applied the proposed
method to the analysis of schizophrenia data. We discovered some
novel abnormal interactions between a group of SNPs with
some interesting brain regions. The differential interaction can
infer some important information on how the dysfunction of genes—
brain interactions can imply the risk of schizophrenia. The inter—
pretation of these interactions should be further confirmed via
replications and additional biological evidences, which needs fur—
ther research.

Funding

The authors wish to thank the National Institutes of Health (ROlGM109068,
ROlMH104680, ROlMH107354, P20GM103472) and National Science
Foundation (#1539067) for their partial support.

Conﬂict of Interest: none declared.

References

Andrew,G. et al. (2013). Deep canonical correlation analysis. In: Proceedings
of the 30th International Conference on Machine Learning, pp. 1247—1255.

Baron,D. et al. (2005 ) Distributed compressed sensing, Technical Report
[Online]. Available at http://dsp.rice.edu/sites/dsp.rice.edu/ﬁles/publications/
report/2006/distributed-ece—2006.pdf.

Chen,X. et al. (2013) Joint analysis of expression proﬁles from multiple can—
cers improves the identiﬁcation of microrna—gene interactions.
Bioinformatics, 29, 2137—2145.

Chun,H. and Keles,S. (2010) Sparse partial least squares regression for simul-
taneous dimension reduction and variable selection. I. R. Stat. Soc. Ser. B
(Stat. Methodol.), 72, 3—25.

Danaher,P. et al. (2014) The joint graphical lasso for inverse covariance esti-
mation across multiple classes. I. R. Stat. Soc. Ser. B (Stat. Methodol.), 76,
373—397.

Duan,I. et al. (2014) Common copy number variation detection from multiple
sequenced samples. IEEE Trans. Biomed. Eng., 61, 928—937.

Friedman,I. et al. (2008) CNTNAP2 gene dosage variation is associated with
schizophrenia and epilepsy. Mol. Psychiatry, 13, 26 1—26 6.

Gollub,R.L. et al. (2013) The MCIC collection: a shared repository of multi—
modal, multi—site brain image data from a clinical investigation of schizo—
phrenia. Neuroinforrnatics, 11, 367—388.

Grellmann,C. et al. (2015 ) Comparison of variants of canonical correlation
analysis and partial least squares for combined analysis of MRI and genetic
data. NeuroIrnage, 107, 289—310.

Hampshire,A. et al. (2010) The role of the right inferior frontal gyrus: inhib-
ition and attentional control. NeuroIrnage, 50, 1313—1319.

Hariri,A.R. et al. (2006) Imaging genetics: perspectives from studies of genet—
ically driven variation in serotonin function and corticolimbic affective pro—
cessing. Biol. Psychiatry, 59, 888—897.

Hocking,T. et al. (2011). Clusterpath: an algorithm for clustering using con—
vex fusion penalties. In: Proceedings of the 28th International Conference
on Machine Learning (ICML-11), pp. 745—752.

Hoeﬂing,H. (2010) A path algorithm for the fused lasso signal approximator.
I. Comput. Graph. Stat., 19, 984—1006.

Hotelling,H. (1936) Relations between two sets of variates. Biometrika, 28,
321—377.

Howes,O.D. et al. (2013) Midbrain dopamine function in schizophrenia and
depression: a post—mortem and positron emission tomographic imaging
study. Brain, 136, 3242—3251.

Kamburov,A. et al. (2013) The consensusPathDB interaction database: 2013
update. Nucleic Acids Res., 41, D793—D800.

Kanehisa,M. and Goto,S. (2000) KEGG: kyoto encyclopedia of genes and gen—
omes. Nucleic Acids Res., 28, 27—30.

Kreczmanski,P. et al. (2007) Volume, neuron density and total neuron number
in ﬁve subcortical regions in schizophrenia. Brain, 130, 678—692.

Lai,P.L. and Fyfe,C. (2000) Kernel and nonlinear canonical correlation ana—
lysis. Int. I. Neural Syst., 10, 365—377.

Larson,N.B. et al. (2014) Kernel canonical correlation analysis for assessing
gene—gene interactions and application to ovarian cancer. Eur. I. Hum.
Genet., 22, 126—131.

Law,M. et al. (2006) The role of phospholipases A2 in schizophrenia. Mol.
Psychiatry, 1 1, 5 47—5 5 6.

Le—Niculescu,H. et al. (2007) Towards understanding the schizophrenia code:
an expanded convergent functional genomics approach. Am. I. Med. Genet.
B, 144, 129—158.

Lin,D. et al. (2014) Correspondence between fMRI and SNP data by
group sparse canonical correlation analysis. Med. Image Anal., 18,
891—902.

Liu,I. and Calhoun,V.D. (2014) A review of multivariate analyses in imaging
genetics. Front. Neuroinﬁ, 8, 262—272.

Liu,I. et al. (2008) A parallel independent component analysis approach to in—
vestigate genomic inﬂuence on brain function. IEEE Signal Process. Lett.,
15, 413—416.

Meador—Woodruff,I.H. et al. (1996) Dopamine receptor mRNA expression in
human striatum and neocortex. Neuropsychopharmacology, 15, 17—29.

Meinshausen,N. and Biihlmann,P. (2010) Stability selection. I. R. Stat. Soc.
Ser. B (Stat. Methodol.), 72, 417—473.

Meyer—Lindenberg,A. (2012) The future of fMRI and genetics research.
NeuroIrnage, 62, 1286—1292.

O’Dushlaine,C. et al. (2011) Molecular pathways involved in neuronal cell ad-
hesion and membrane scaffolding contribute to schizophrenia and bipolar
disorder susceptibility. Mol. Psychiatry, 16, 286—292.

Parkhomenko,E. et al. (2009) Sparse canonical correlation analysis with
application to genomic data integration. Stat. Appl. Genet. Mol. Biol., 8, 1—34.

Pearlson,G.D. et al. (2015) An introductory review of parallel independent
component analysis (p—ICA) and a guide to applying p-ICA to genetic data
and imaging phenotypes to identify disease-associated biological pathways
and systems in common complex disorders. Front. Genet., 6, 276.

Ross,B.M. et al. (1999) Differential alteration of phospholipase A2 activities
in brain of patients with schizophrenia. Brain Res., 821, 407—413.

Sanders,A. R. et al. (2013) Transcriptome study of differential expression in
schizophrenia. Hum. Mol. Genet., 22, 5001—5014.

Tian,Y. et al. (2014) Knowledge-fused differential dependency network models for
detecting signiﬁcant rewiring in biological networks. BMC Syst. Biol., 8, 87.

9103 ‘01; JSanV 110 so1e§uv s01 ‘1211110111123 10 1115191111111 112 /310's112u1n0[p101x0'so1112111101u101q//:d1111 111011 pep201um0q

Joint sparse CCA

 

Voegler,R. et al. (2016) Aberrant network connectivity during error processing
in patients with schizophrenia. I. Psychiatry Neurosci. IPN, 41, E3—E12.

Vounou,M. et al. (2010) Discovering genetic associations with high—
dimensional neuroimaging phenotypes: a sparse reduced—rank regression ap-
proach. NeuroImage, 53, 1147—1159.

Wang,K.S. et al. (2010) A genome—wide meta—analysis identiﬁes novel loci
associated with schizophrenia and bipolar disorder. Schizophrenia Res.,
124, 192—199.

Wang,Z. et al. (2014) Network-guided regression for detecting associations be—
tween DNA methylation and gene expression. Bioinformatics, 30, 2693—2701.

Whalley,H. C. et al. (2011) Genetic variation in CNTNAP2 alters brain func—
tion during linguistic processing in healthy individuals. Am. I. Med. Genet.
B Neuropsychiatric Genet., 156, 941—948.

Witten,D. M. and Tibshirani,R. I. (2009) Extensions of sparse canonical cor—
relation analysis with applications to genomic data. Stat. Appl. Genet. Mol.
Biol., 8, 1—27.

Witten,D.M. et al. (2009) A penalized matrix decomposition, with applica-
tions to sparse principal components and canonical correlation analysis.
Biostatistics, 10, 515—534.

Wold,H. (1985) Partial least squares. Encyclopedia Stat. Sci, 6, 5 81—5 91.

Wylie,K. P. and Tregellas,I. R. (2010) The role of the insula in schizophrenia.
Schizophrenia Res., 123, 93—104.

Xie,C. et al. (2011) Association between schizophrenia and single nucleotide
polymorphisms in lipoprotein lipase gene in a Han Chinese population.
Psychiatric Genet., 21, 307—314.

Yang,S. etal. (2015 ) Fused multiple graphical lasso. SIAM I. Optim., 25, 916—943.

Zandbelt,B. B. et al. (2011) Reduced proactive inhibition in schizophrenia is
related to corticostriatal dysfunction and poor working memory. Biol.
Psychiatry, 70, 1151—1158.

Zhang,R. et al. (2016) Working memory in unaffected relatives of patients
with schizophrenia: A meta—analysis of functional magnetic resonance imag—
ing studies. Schizophrenia Bull., 42, 1068—1077.

Zongben,X. et al. (2012) ll); regularization: a thresholding representation the—
ory and a fast solver. IEEE Trans. Neural Netw. Learn. Syst., 23,
1013—1027.

9103 ‘01; 1sn8nV 110 so1e§uv s01 ‘21111011123 10 1115191111111 12 /310's12u1n0[p101x0'so112111101u101q//:d1111 111011 pep201um0q

