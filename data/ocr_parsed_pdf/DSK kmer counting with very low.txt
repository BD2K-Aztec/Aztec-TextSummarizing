BIOINFORMA TICS

0'so;112u110}u101q//2duq

SIBumoprOJX

£10"

DSK: k-mer counting

 

Table 1. Wall-clock time and memory usage for counting 27-mers in
whole-genome human data

 

 

Program Time (h) Memory (GB) Disk (GB)
DSK 17.9 4 160
DSK-SSDa 3.5 4 240
BFCounter 41.2 56 0
Jellyﬁsh 3 .5 70 211

 

The dataset used is the NA18507 human genome (SRX016231), unﬁltered, consist—
ing of 1.4 billion reads of average length 100 bp (160 GB ﬁle size). Jellyﬁsh used
eight threads, DSK—SSD used four threads and DSK and BFCounter are
single—threaded. The disk column indicates the temporary amount of disk space
used by each method.

“Executed on a desktop computer equipped with two hard drives, including an SSD.

less than M /(b+ 32) distinct k-mers are inserted in T. At each iteration
(v/nims), k-mers are split into np partitions. Each partition contains at
most v/(nimsnp) 5 [0.7M/(b + 32)] k-mers. In the worst case, all these k-
mers are distinct; thus, the load factor is upper-bounded by 0.7 (a classical
threshold above which hash table performance degrades).

The time complexity of Steps 7711 (including the iteration loop) is
0(v2b/D). The algorithm creates (nimnp) 5 Mb + 32)/(0.7M)] tempor-
ary hash tables, inserting at most [(0.7M/(b+ 32)] elements in each.
Hash tables accesses and insertions (Step 15) are done in constant ex-
pected time with open-addressing, as long as the load factor is strictly <1
(which was proved earlier in the text). Hence, the expected time complex-
ity of Steps 12717 (including the iteration loop) is 0(v). Thus, Algorithm
1 runs in expected time 0(v2b/D). The algorithm runs in expected linear
time with respect to v when D = @(v), e.g. setting D equal to the sum of
input bases. In practice, the simplifying assumption on the uniform re-
partition of the hash function h does not hold exactly. Some partitions
contain a slightly larger number of distinct k-mers than [v/H]. Hence,
the actual disk usage of the algorithm is slightly above D, and the load
factor of Tcould, in theory, be >0.7 (because of high k-mer redundancy,
this is not the case in practice).

3 RESULTS

In Table 1, we compared the execution time and memory usage
of DSK with Jellyﬁsh (version 1.1.5) and BFCounter (version
0.2) on a human genome Illumina dataset. The target disk
usage of DSK was set to 160 GB, equal to the size of the
reads ﬁle. As the algorithm relies heavily on I/O to the disk,
we also tested DSK with a solid—state drive (DSK—SSD). The
reads ﬁle was placed on a standard hard disk drive, and parti—
tions of redundant k—mers were written on a 256 GB SSD. In this
conﬁguration, we noticed the algorithm is no longer limited by
disk I/O and could benefit from multi—threading. The two for
loops lines 7 and 12 were parallelized using openMP (four
threads). DSK—SSD ran for 3.5h using 4 x 1 GB of memory.
Although this experiment required speciﬁc hardware, it is
worth noting that the running time of DSK can be greatly
reduced with an SSD and multi—core parallelism.

To further assess the trade—off between time, memory and disk
usage, we executed DSK (using a standard hard drive) on two
smaller Escherichia coli and Drosophila ananassae datasets, with
various target memory and disk usage parameters (Figure 1). For
the executions with 100 MB and 1 GB memory usage, the run—
ning time of DSK on both datasets decreases as the target disk

 

 

 

 

 

 

 

 

E. coli DNA Drosophila RNA
_’ _(I
8 _‘ x
A <1- \‘ A 8 _ \‘
L0, _ \ L”, 5-2 1‘
GE) 8 — \ GE) 0 \‘x
i: N \\ i: 8 — ‘\.‘..\.._.._ _
_ “w. ;-;-;';~
0 o _
| | | | | | | | | | | |
115 1150 4600 148 743 2975

Disk space (MB) Disk space (MB)
Memory (MB)

10 - - 100 1000

Fig. 1. Execution time of DSK (k = 21) as a function of memory and disk
usage, on the Ecoli (Illumina DNA SRR001665, 20.8 - 106 reads of aver-
age length 36 bp) and D.ananassae datasets (Illumina RNA-Seq
SRR332538, 9.1 - 106 reads of average length 150 bp)

space increases. This is a consequence of the decreasing number
of iterations nnm. The running times reach a plateau at roughly
the reads ﬁle size (where num = 1). The execution time generally
seems to be unaffected by the target memory usage. However, at
the smallest tested memory usage (10 MB), the execution time on
both datasets is slightly higher, possibly because of consecutive
disk writes to a large number of partitions. Note that in practice,
the memory usage of DSK cannot be arbitrarily low: it is limited
by the number of files that can be simultaneously opened on the
system (partitions {(10, ...,dnp} are all opened simultaneously).

4 DISCUSSION

Contrary to other methods, DSK does not provide random
access to k—mer counts. However, it beneﬁts from three strong
points:

0 Low-memory usage: Only an arbitrarily small subset of k—
mers is loaded in memory at any time. In contrast,
BFCounter stores all the k—mers with count 3 2 in a hash
table. In principle, Jellyﬁsh can use arbitrarily small hash
tables; however, storing the intermediate results requires a
prohibitive amount of disk (3 1 TB for human genome
reads using a hash table of size 5 GB).

0 Parameters are automatically inferred: The only mandatory
argument is the k—mer length. Optionally, target memory
and disk usages can be speciﬁed. Jellyﬁsh and BFCounter
require the user to specify a hash table size and an
upper—bound on the number of distinct k—mers, respectively.

0 Supports arbitrarily large values of k: As opposed to up to 32
for Jellyﬁsh (unbounded for BFCounter).

Funding: ANR MAPPI, ANR—10—COSI—0004.

Conﬂict of Interest: none declared.

REFERENCES

Mar;ais,G. and Kingsford,C. (2011) A fast, lock—free approach for efﬁcient parallel
counting of occurrences of k—mers. Bioiiy’ormuticx, 27, 764e770.

Melsted,P. and Pritchard,J. (2011) Efﬁcient counting of k—mers in DNA sequences
using a bloom ﬁlter. BMC Bioiiy’ormuticx, 12, 333.

 

653

ﬁm'spzumol‘pmﬂo'sopeuuopuotq/ﬁdnq

