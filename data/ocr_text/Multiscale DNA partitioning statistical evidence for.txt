ORIGINAL PAPER

Vol. 30 no. 16 2014, pages 2255—2262
doi: 10. 1 093/bioinformatics/btu 1 80

 

Sequence analysis

Advance Access publication April 21, 2014

Multiscale DNA partitioning: statistical evidence for segments

Andreas Futschik1 ’*, Thomas Hot22’*, Axel Munk3’4 and Hannes Sieling3

1Department of Applied Statistics, JK University Linz, A—404O Linz, Austria, 2Institute of Mathematics, Technische
Universitat llmenau, D—98693 llmenau, Germany, 3Institute for Mathematical Stochastics and Felix Bernstein Institute for
Mathematical Statistics in Biosciences, Georgia Augusta University of Goettingen and 4Max Planck Institute for

Biophysical Chemistry, D—37077 Goettingen, Germany

Associate Editor: John Hancock

 

ABSTRACT

Motivation: DNA segmentation, i.e. the partitioning of DNA in com-
positionally homogeneous segments, is a basic task in bioinformatics.
Different algorithms have been proposed for various partitioning cri-
teria such as Guanine/Cytosine (GC) content, local ancestry in popu-
lation genetics or copy number variation. A critical component of any
such method is the choice of an appropriate number of segments.
Some methods use model selection criteria and do not provide a
suitable error control. Other methods that are based on simulating a
statistic under a null model provide suitable error control only if the
correct null model is chosen.

Results: Here, we focus on partitioning with respect to GC content
and propose a new approach that provides statistical error control: as
in statistical hypothesis testing, it guarantees with a user-speciﬁed
probability l—a that the number of identified segments does not
exceed the number of actually present segments. The method is
based on a statistical multiscale criterion, rendering this as a segmen-
tation method that searches segments of any length (on all scales)
simultaneously. It is also accurate in localizing segments: under
benchmark scenarios, our approach leads to a segmentation that is
more accurate than the approaches discussed in the comparative
review of Elhaik et al. In our real data examples, we find segments
that often correspond well to features taken from standard University
of California at Santa Cruz (UCSC) genome annotation tracks.
Availability and implementation: Our method is implemented in
function smuceR of the R-package stepR available at http://www.sto
chastik.math.uni-goettingen.de/smuce.

Contact: andreas.futschik@jku.at or thomas.hotz@tu-ilmenau.de
Supplementary information: Supplementary Data are available at
Bioinformatics online.

Received on August 6, 2013; revised on March 28, 2014; accepted on
April 1, 2014

1 INTRODUCTION

It has been observed a long time ago (Sueoka, 1962) that DNA
sequences are not composed homogeneously and that bases ﬂuc-
tuate in their frequency. These inhomogeneities often have an
evolutionary or a functional interpretation, and can be relevant
for the subsequent analysis of sequence data. Because it correl-
ates with many features of interest, the GC content, i.e. the

 

*To whom correspondence should be addressed.

relative frequency of the bases G and C, is one of the most
commonly studied sequence properties.

Large-scale regions, typically 300 kb (Bemardi, 2001), of ap-
proximately homogeneous GC content have been called iso-
chores. In View of the somewhat vague notion of ‘approximate
homogeneity’ and conceptual criticism in studies such as Cohen
et al. (2005) or Elhaik et al. (2010a), there is less interest in iso-
chores nowadays. However, there is no doubt about variation in
GC content along genomes, and search is done instead for do-
mains of any length exhibiting distinct local GC content; see, for
instance, Elhaik et al. (2010b). Several factors can inﬂuence the
GC content of a region. At larger scales, it correlates with the
density of genes, with gene-rich regions typically exhibiting an
elevated GC content compared with regions of low gene density.
At smaller scales, there is ﬂuctuation in the GC content, for in-
stance, because of repetitive elements and GpC islands. The GC
content is also known to vary between exons and introns.
Especially for long introns, their lower GC content seems to
play a role in splice site recognition (Amit et al., 2012). There is
also a correlation between the GC content and the local recom-
bination rate (Fullerton et al., 2001; Galtier 2001). For a further
discussion of features correlated to the GC content, see
F reudenberg et al. (2009).

In gene expression studies, regions of homogeneous GC con-
tent are of interest because the GC content of a region affects the
number of reads mapped to this region. For DNA and RNA-seq
experiments with the Illumina Genome Analyzer platform, this
has been, for instance, investigated in Benjamini and Speed
(2012) and Risso et al. (2011).

Segmentation algorithms aim to partition a given DNA se-
quence into stretches that are homogeneous in their composition
but differ from neighboring segments. The classical approach of
using moving windows is simple and available, for instance, as an
option with the UCSC and Ensembl genome browsers. However,
it has some disadvantages. For instance, the choice of the
window size is difﬁcult because it deﬁnes implicitly a ﬁxed
scale at which segments primarily will be detected. Further, the
involved smoothing blurs abrupt changes. Without additional
statistical criteria, the method also does not tell us whether dif-
ferences between neighboring windows are statistically signiﬁ-
cant. Therefore, several more sophisticated approaches have
been proposed. These methods include hidden Markov models
(Churchill, 1989, 1992) and walking Markov models (Fickett
et al., 1992). There are also change-point methods available;
see, for instance, Braun et al. (2000). A Bayesian approach

 

© The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2255

112 ﬁle'slcumo[pJOJXO'sopchoguioiq/ﬁdnq IIIOJJ pepcolumoq

910K ‘09 lsnﬁnV no :2

A.Futschik et al.

 

that relies on the Gibbs sampler has been proposed by Keith
(2006). An older approach based on information criteria can
be found in Oliver et al. (1999). Furthermore, recently developed
methods based on entropy criteria have been shown to perform
particularly well; see Elhaik et al. (2010a) and Elhaik et al.
(2010b). A review of segmentation methods can be found in
the article by Braun and Muller (1998), and for a more recent
comparative evaluation of the more popular approaches, see
Elhaik et al. (2010a).

In this paper, we focus on binary segmentation, where the
four-letter alphabet of a DNA sequence is converted into a
two-letter code. For GC content, we set the response to be ‘1’
for G or C at a position and 0 for A/T; we use Y,- to denote the
response at position i and summarize the responses for a se-
quence of length n by

Y: (Y1, Y2,  Y”). (1)

We model the responses Y,- to be independent and Bernoulli
Bin(1,7r,-) distributed, and also assume that there is a partition
0 = T0<T1<  <‘L'K = 11 into an unknown number K of seg-
ments on which the at,- are piecewise constant, i.e. at,- = pj for
i e Ij. Here, I]- : (‘EJ-_1,‘Ej] denotes the j ’th segment with response
probability pj for 1 5 j 5 K.

A segmentation algorithm provides estimates K for the
number of segments, for the internal segment boundaries,

0=to<tl<tz<---<tk_1<tk=n, (2)

and for the response probabilities, 13,-, on the estimated segments
Ij i: (ff—19 

In the following, we will identify a segmentation with (p, I),
wherep 2 (p1, ...,pK) and I: (11, ...,IK).

Our proposed algorithm provides a parsimonious estimate K
for K: K will not exceed the actual number of segments K, except
for a small user-speciﬁed error probability a; as a default value,
we suggest a = 5%, the error probability also chosen in our
simulations and data analyses. Relaxing this signiﬁcance level
to a larger value, say a = 20%, will typically lead to more iden-
tiﬁed segments but at the cost of statistical accuracy.

2 METHOD

Our proposed multiscale segmentation provides estimates for the number
of segments and their boundaries at the same time. We use a certain
multiscale statistic that will ensure that the estimator ﬁts the data well
on all segments simultaneously, i.e. the number of segments is not under-
estimated with high probability. This estimator is based on Frick et al.
(2014) who proposed a general statistical multiscale change-point estima-
tor (SMUCE) for exponential family models. Exponential families in-
clude many classes of well-known distributions, such as the Gaussian
(normal) class, the Poisson class or the Bernoulli class, which is of par-
ticular interest for this article.

In the Gaussian setting, a related estimator has also been suggested in
Davies et al. (2012). Forerunners of SMUCE are based on a penalized
likelihood with a penality that depends on the number of jumps; see, e.g.
Yao (1988), Braun et al. (2000), Winkler et al. (2002), Boysen et al. (2009)
and the introduction in Frick et al. (2014) for a brief survey. The under-
lying multiscale statistic is based on the work of Duembgen et al. (2001);
see also Duembgen et al. (2008) and Walther (2010). For a general de-
scription of the approach underlying the present work, its statistical in-
terpretation, statistical optimality and theoretical results, we again refer

to Frick et al. (2014). To ease the understanding, in the following, we
elaborate in greater details on the case of binary Bernoulli observations
with success probabilities given as piecewise constant segments, as this
model underlies the methodology for the segmentation problem at hand.
In contrast to other approaches such as hidden Markov models, we re-
quire neither explicit nor implicit distributional assumptions on the seg-
ments and their lengths.

Let K( Y,,7t,-) denote the likelihood of Y, under the parameter m, i.e.
£(Y,-,7t,-) = 7r,- if Y,- = 1 and £(Y,-,7t,-) = 1 — 7t,- else. We then deﬁne for a
ﬁxed interval (i, j] with 0 5 i< j 5 n the local likelihood ratio statistic
1 £09,130)

T . = 10 max
(1.11070) g (mew, 1] [111 a 171,170)

 

(3)

Roughly, this statistic indicates how well the data on the subinterval
(i, j] are described by the constant response probability po 6 [0, 1] of some
segment under consideration as opposed to choosing some 130 6 [0,1]
freely for that subinterval.

As a goodness-of—ﬁt measure for the segmentation (p, I), we consider
the scale-calibrated multiresolution statistic

Tn(p,I) = max max <‘/2T(,-,f_l(pl — 210g(/%)). (4)

1515K (i,j] Ell

(Here ‘e’ denotes Euler’s number.) This statistic may be interpreted
as follows: for all segments I, in I, the response probability is
assumed to be constant, and for every interval (i, ]] within such a segment,
T n(p, 1) measures whether the data are well described by the
constant response probability p, on that interval. It thus checks the
quality of ﬁt on all scales simultaneously, hence the name. Note that the
log-penalty term depends on the length j — i of the interval that is currently
checked for deviations from the model. It takes the number of disjoint
intervals of the considered length into account, thereby adjusting for mul-
tiple testing. For our ﬁnal estimate, we determine

(1) the minimal number of segments K, such that there exists a seg-
mentation (p, f) with K segments satisfying the multiresolution
constraint ms, 2) 5 q for some predetermined signiﬁcance thresh-
old q, and

(2) the segmentation (p, f) with maximal likelihood among all segmen-
tations having K segments and satisfying the multiresolution
constraint.

To be more precise, let CK denote the set of segrnentations with K seg-
ments. Then, our estimate in the second step is

(13.1”) = argmax amp. I). (5)
(pa DECK; Tn(Ps 
where argmax denotes a position ([3, i) at which the maximum is ob-
tained, and £(Y; p, 1) denotes the likelihood of all data if the segmentation
(p, I) with K segments were true, i.e.

may): H Ham-.121). (6)

1515K i611

Following Frick et al. (2014), the general class of such estimators in ex-
ponential families has been denoted as SMUCE. We adopt this termin-
ology and will denote the estimator in (5) for the Bernoulli and binomial
case as B-SMUCE.

The threshold parameter q determines the parsimony of the estimator;
the larger q, the fewer segments will be included into B-SMUCE. Hence,
the choice of q is crucial. A statistically attractive feature of B—SMUCE is
that q can be chosen as the (1 — a) quantile of the distribution of Tn(p, I)
under the hypothesis that (p, I) is the true model. In Frick et al. (2014), it
has been proven that this choice ensures that the number of segments is
not overestimated with probability at least 1 — a.

 

2256

112 /810'S112umofpleXO'sottemJOJHtotw/zdnq uroxj pepeolumoq

910K ‘09 lsnﬁnV no :2

Multiscale DNA partitioning

 

To be more precise, in Frick et al. (2014), Theorem 2.1 was shown
under some mild technical assumptions that for any (p, I) the asymptotic
distribution of the multiresolution statistic T n(p, I) can be bounded by the
asymptotic distribution of the statistic for a signal with only one segment.
Moreover, the latter distribution converges to the limit distribution of (4)
for the case of i.i.d. (independent and identically distributed) zero-mean
Gaussian observations. Therefore, we may (and we do in the following)
simply use Monte Carlo simulations with i.i.d. zero-mean Gaussian data
to determine bounds on the quantiles of the distribution of T n(p, I). In
simulations, we found the approximate quantiles thus obtained to be
rather conservative (i.e. the preassigned error probability a was not ex-
ceeded) even for small sample sizes. This adds support to the basic
inequality

P(I‘<>K) s P(T.<p.1)>q) s a (7)

in Section 1.2. of Frick et al., 2014, which renders SMUCE to be a
method that statistically controls the error to overestimate the number
of segments in the binary case, i.e. it provides the statistical validity of B-
SMUCE in the above sense (7). The other way around, Theorem 2.2 in
Frick et al. (2014) provides an exponential deviation bound for the error
to underestimate the true number of segments, which explicitly depends
on the smallest segment length and signal strength. Under prior informa-
tion on these quantities, these two inequalities together even allow to give
a guarantee for the probability P(K = K) of Specifying the number of
segments correctly. Moreover, in the Gaussian case, it can be shown that
SMUCE attains optimal detection rates (and even constants) over a large
range of segment lengths; see Frick et al. (2014), Theorems 2.6 and 2.7.
Our simulations suggest a similar performance in the binary/binomial
case, although we do not have a rigorous proof of this statement.

2.1 Details of the algorithm

We follow Frick et al. (2014) and use a pruned version of dynamic
programming to compute our estimated segmentation i and levels 13.
This is possible because our multiresolution statistic Tn considers only
subintervals of the candidate segments of constant response probability.
For related ideas, where dynamic programming has been used for other
segmentation estimators, see Friedrich et al. (2008), Boysen et al. (2009),
Davies et al. (2012) and, in particular for pruning, Killick et al. (2012). To
describe the algorithm for computing B-SMUCE, we need the following
notation, identifying a segmentation with (p, I) again: for an interval (i, j],
we deﬁne the local costs of a response probability po 6 [0, 1] as

. — — njizi+l  YbPO) ifT(isJ] (p0) S q:
CWKPO) _ { oo otherwise. (8)

Let cal] = minpodo, 1] cm] (p0) denote the minimal costs on (i, j] for a con-
stant response probability under the multiresolution constraint, whereas
p031] = argrninpoe[0,1]c(,-,ﬂ(po) denotes the corresponding optimal estimate.

Let us, for the moment only, consider the observations Y1, .. . , Y,- for
ﬁxed 1 5 i 5 n, and denote by c: K, the optimal overall costs on (0, i]

using K segments, i.e.
czK = argmax H Han-.121). (9)
(P,I)ECK,i,Ti(p,I)Sq 1515Kj61,

cf. (5), where CK,- denotes the set of segmentations of (0, z] with K seg-
ments; if no segmentation (p, I) 6 CK,- fulﬁlls the multiresolution con-
straint Ti(p,I) 5 q, we let cZK = 00.

The algorithm for B-SMUCE is then based on the observation that for
K > 0

cZK = 12211; ((;;fK_1 + ch). (10)

In dynamic programming, this is called the Bellman equation; it is
the main ingredient for an efﬁcient implementation; see line 11 in
Algorithm 1.

 

Algorithm 1: dynamic programming algorithm for B-SMUCE

 

1 K<—0,i0<—0,po<—0,i<—l
2 while i 5 n do
3 Hk=omm
4 1* <— 0
5: czo <— cfm
6' else
7 forl=i—1,...,1do
8. if 6(1le 2 00 then
9: goto 14
10: else
11: c§<—cZ§_1+caﬂ
12: end if
13: end for
14: 1* <— argminIEKZ-c;
15: c;_‘:I2 <— cl.
16: end if
17: if c’f‘ A = 00 then
K A
1& KeK+l
19: gate 3
20: end if

2h Zeqath
223 131' <— (1315190211)
23: end while

24: return K, In, 13,,

 

Note that we introduced two rules that permit for early stopping of
loops: if cal] = 00, i.e. if the hypothesis of constancy on (l, i] is rejected,
then consequently, this also happens on any larger interval, i.e. for any
smaller I; this justiﬁes lines 8—9. Similarly, if K segments are insufﬁcient to
fulﬁll the multiresolution constraint on (0, i], then a fortiori so for any
larger i, whence lines 17—20. To the best of our knowledge, these shortcuts
that are possible because of the speciﬁc structure of the multiscale con-
straint have not been used so far. Additional improvements were used in
our implementation; these, however, are rather technical and thus
omitted from the present article.

3 RESULTS

We evaluated our segmentation approach both on simulated
data and on data taken from the human genome and the long-
known A-phage. In our simulations, we used the benchmark
scenarios proposed in Elhaik et al. (2010a). Because an extensive
comparison of popular DNA segmentation algorithms under
these benchmark scenarios is already available in Elhaik et al.
(2010a), we provide a comparison of our approach with the
method that performed best in Elhaik et al. (2010a), namely,
the one based on the Jensen—Shannon divergence. This recursive
approach (called D 15) splits one of the current segments in each
step. This is done by adding a new break point such that the
improvement in J ensen—Shannon divergence is maximized. The
algorithm stops when the improvement does not reach a thresh-
old value obtained via simulations. Here, we used the Matlab
implementation Djsegmentationm of the algorithm, which is
publicly available as part of ISOPLOTTER 2.4 (http://code.
google.com/p/isoplotter/). There, 5.8 x 10—5 is taken as a thresh-
old, a value obtained from simulating long (1 Mb) homogeneous
sequences. Although this value seems to work well for the con-
sidered benchmark scenarios and might also be useful to prevent
false-positive ﬁndings when searching for long homogeneous se-
quences, it might be less suitable for balancing false-positives and

 

2257

112 /810'S112umofpleXO'sot112u1101utotq//2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

A.Futschik et al.

 

false-negatives under other scenarios. Therefore, a modiﬁed
version (called ISOPLOTTER) of D 15 has been proposed brieﬂy
after (Elhaik et al., 2010b) that uses critical values
dependent both on the segment length and the standard
deviation of the GC content. Therefore, we also report on the
performance of ISOPLOTTER 2.4 (again under the default par-
ameter settings) and provide detailed results in the
Supplementary Material.

To facilitate the comparison and to accelerate the computa-
tions for longer sequences, we binned the data and applied our
algorithm to the resulting binomial frequencies. We choose the
bin size equal to 32, which is the default value with the D 15 and
IsoPlotter software and has also been used in Elhaik et al.
(2010a). Although binning the data clearly improves the speed,
it should be noted that it is not essential for the algorithm to
work.

The ﬁrst scenario considered there involves sequences consist-
ing of ﬁxed-size homogeneous domains. Although not realistic in
practice, this setup has been proposed by Elhaik et al. (2010a) as
a minimum standard: a criterion that does not perform well on
such data cannot be expected to perform well under more com-
plex settings. The second scenario consists of sequences with
domains of random length generated according to a power-law
distribution. These sequences are reported to mimic mammalian
genomes well; see Clay et al. (2001).

3.1 Performance measures

We measured performance both by a qualitative criterion
proposed by Elhaik et al. (2010a) and by a new quantitative
criterion. For the qualitative criterion, we classify an identiﬁed
segment as true-positive if both segment boundaries are
identiﬁed correctly within an error margin of 5000 bases or
5% of the segment length, whichever is smaller. Thus, an identi-
ﬁed segment is considered to be a false-positive, unless both
detected boundaries were within 5000 bases (or 5%) from the
boundaries of a true segment. Similarly, actual segments were
taken as false-negative ﬁndings if they were not detected
correctly within the permitted tolerance. Let now tp, fp and fn
denote the number of true-positives, false-positives and false-
negatives, respectively. Following Elhaik et al. (2010a), we
deﬁne a sensitivity rate as

 

1P
:= —, 11
and a precision rate as
1P
r := . (12)
p tp +fp

We investigate the performance of our proposed approach based
on these criteria.

Furthermore, we deﬁned two quantitative criteria that better
reﬂect the accuracy of detecting segment boundaries. We denote
them by false-negative sensitive localization error (FNSLE) and
false-positive sensitive localization error (FPSLE). To introduce
the FNSLE, consider a true segment I]- : (‘EJ-_1,‘Ej], and let
mJ- =  denote the midpoint of the segment. We deﬁne the
best matching estimated segment as the segment I; = (1?;_1, f;]

with mJ- e f]. The FNSLE for segment I]- is then deﬁned as the
mean distance
1 A A
eJQFNSL) = 5(lTj—1 — T1—1|+|Tj — Til) (13)
between true and estimated boundaries.

The overall F NSLE is then deﬁned as the mean F NSLE taken
over all true segments

1 K FNSL
emu ;= Egg; >. (14)
j=1
Analogously, the FPSLE can be deﬁned by measuring how
closely an estimated segment matches to one of the true seg-
ments. By starting with an estimated segment I; and its midpoint
m], we look for the true segment satisfying m; e Ij. With analo-
(FPSL)
gously deﬁned errors e] , we call

1 12
e(FPSL) :2 7: egFPSL)' (15)
[:1

the overall FPSLE.

These measures for the error may be interpreted as follows:
assume that the estimated segmentation agrees with the true seg-
mentation in the number of segments, and that all boundaries
have been determined with an error smaller than half the length
of each neighboring segment. Then, FPSLE and FNSLE agree:
they essentially give the average distance between true and esti-
mated boundaries. These error measures behave differently,
however, if the numbers of true and detected segments do not
coincide: assume that the estimated segmentation is the true seg-
mentation except that it has incorrectly split one true segment
into two estimated segments. Then, the F NSLE increases by the
length of that true segment minus the length of the longer esti-
mated segment divided by 2K, i.e. a spurious split is treated like
an error in localizing that boundary. The FPSLE, however, will
get rather large, as the length of that true segment divided by 2K
gets added. Similarly, if a true boundary is not detected, the
F NSLE will be larger.

3.2 Simulations

3.2.1 Segments of equal length We ﬁrst implemented Scenario I
of Elhaik et al. (2010a). Thus, we simulated sequences that con-
sist of 10 segments of equal length. We considered the following
eight different segment lengths: 10kb, 50kb, 100kb, 200kb, 300kb,
500 kb, le and 5Mb. Thus, the longest sequences had total
length 50Mb. For each sequence, we selected a global probability
[3“) for the response ‘1’ at a position according to a uniform
distribution on [0.1,0.9]. Then, we randomly modiﬁed this prob-
ability for each sequence segment j by taking

Pj = 130) + 021- (16)

Here Z]- denotes a standard normal random number, and a was
chosen from {0, 0.025, 0.05, 0.075, 0.1}. The p, were conditioned
to lie within [0,1], i.e. if p, did not turn out to be a proper prob-
ability, a new random number was generated. The individual
observations Y,- within a given segment I]- were then chosen as
independent Bernoulli random variables with expected value pj.

 

2258

112 /810'S112umofpleXO'sot112u1101utotq//2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

Multiscale DNA partitioning

 

 

 

I - 0.8

    

- 0.6
_ _ _ B-SMUCE - -
BJgMUCE _ DJS 

 

6 = 0.025 0' = 0.05

 

sensitivity rate

0.8 -

B-SMUCE - -
DJS —

     

B-SMUCE - -
DJS —

 

 

 

 

 

1:14 1:15 1i)6 5xl106 I I I I
segment length (logarithmic scale)
Fig. 1. Average sensitivity rate as deﬁned in (11) for D JS (0) and
B-SMUCE (x). Results are based on simulations under Scenario I (seg-
ments of equal length) for several values of a. The sensitivity obtained
with the multiresolution criterion tends to be higher. At the simulated
segment lengths, 95% conﬁdence intervals are given as error bars

We simulated 100 sequences for each combination of segment
length and heterogeneity a of the segment-speciﬁc response
probabilities.

In Elhaik et al. (2010a), a detection threshold was introduced,
and neighboring true segments for which the value of p, differed
by less than this threshold have been merged and considered as a
single segment in the subsequent performance analysis. We did
not use such a threshold, however, as we did not want to penalize
high sensitivity. A correct detection of two neighboring segments
with unequal but too similar levels of pj would be counted as an
error if such a detection threshold was used.

The average sensitivity and precision rates of B-SMUCE and
the method based on the Jensen—Shannon entropy (D 15) are dis-
played in Figures 1 and 2, respectively. Especially for shorter
segments, B-SMUCE performs better than D JS, with higher sen-
sitivity and precision. IsoPlotter performed worse than D 15
under the considered scenarios and gave up to 40 segments on
average for the long sequences. B-SMUCE is able to detect also
short segments, while controlling the number of spuriously
detected segments. However, notice that in the case of a homo-
geneous sequence without partitioning into segments (a = 0),
D 15 always obtained the correct answer, whereas B-SMUCE
sometimes introduced spurious segment boundaries. This is to
be expected, as the error of introducing spurious boundaries has
been set to or = 5% under such a model. Furthermore, under all
scenarios, too many boundaries were estimated by B-SMUCE in
<5 % of the simulations, as predicted. We consider the ability to
control this error to be a particular strength of our approach.

Figures 3 and 4 show the average FNSLE (14) and FPSLEs
(15) that measure the accuracy of the segment detection. For
these quantitative criteria, we only consider sequences that are
non-homogeneous (o>0). Again, B-SMUCE shows better per-
formance, leading to smaller errors on average. With increasing
heterogeneity a, there will be typically larger differences between

 

 

’ I
- I ’ 1r - 08
it
_ — 0.6
_ _ _ B—SMUCE - -
BJSMUCE DJS
— — 0.4
- - 0.2
6 = 0.025 6 = 0.05

 

 

precision rate

0.8 -

 

0.6 -

   
 

B-SMUCE - -
DJS —

04- B—SMUCE - -
DJS —

0.2 -

 

 

 

 

104 1115 1:13 5xl1o° I I I I
segment length (logarithmic scale)
Fig. 2. Average precision rate, as deﬁned in (12) for D JS (0) and
B-SMUCE (x). Results are based on simulations under Scenario I (seg-
ments of equal length) for several values of a. The precision rate obtained
with the multiresolution criterion tends to be higher. At the simulated
segment lengths, 95% conﬁdence intervals are given as error bars

104 105 106 5x106
I I | |

 

 

 

 

0' = 0.025 0' = 0.05

 

B-SMUCE - -
DJS —

FNS localisation error (Iog10)

      

Ir B—SMUCE - -
DJS —

4.0 - ..

 

 

 

 

104 105 11)6 5x|106 I I I I
segment length (log10)

Fig. 3. Logarithm (base 10) of average FNSLE, as deﬁned in (14) for
D JS (0) and B-SMUCE (x). Results are based on simulations under
Scenario I (segments of equal length) for several values of a. The errors
encountered with the multiresolution criterion tend to be smaller. At the
simulated segment lengths, 95% conﬁdence intervals are given as error
bars

neighboring segments and thus smaller errors. The graphs also
seem to indicate that both F PSLE and F NSLE tend to get larger
with increasing sequence lengths. A closer inspection reveals that
this is mostly caused by outliers, as the median accuracy of de-
tection stays nearly the same for all segment lengths. These out-
liers occur when a segment is either missed or detected
incorrectly, and such events lead to larger errors when the seg-
ments are longer.

3.2.2 Segments according to power law In our second simula-
tion setup, we generated 100 sequences consisting of segments

 

2259

112 /810'S112umofpleXO'sot112u1101utotq//2d11q 111011 pepeolumoq

910K ‘09 tsnﬁnV no 22

A.Futschik et al.

 

 

I I
5:0.075 0'= 0.1

 

      

 

 

      

— — 5.5
_ B—SMUCE - -
DJS —
8 _
‘6:
2
§ _
a 0'
.5 0' = 0.025 0- : o_05
 5-5- -
S
2 B—SMUCE - -
w 5.0 — DJS — —
D.
LI.
4.5 — —
4. — —
0 I B—SMUCE - -
U DJS —
3.5 — 1 —

 

 

 

 

104 105 106 5xl106 I I I I
segment length (Iog10)
Fig. 4. Logarithm (base 10) of average FPSLE, as deﬁned in (15) for D JS
(0) and B-SMUCE (x). Results are based on simulations under Scenario
I (segments of equal length) for several values of a. The errors encoun-
tered with the multiresolution criterion tend to be smaller. At the simu-
lated segment lengths, 95% conﬁdence intervals are given as error bars

with different lengths. As in Elhaik et al. (2010a), we chose the
segment lengths according to a power-law distribution:

p(x) = Car—“1] [x > x0], (17)

with a = 1.55 and x0 = 10 000. The parameter a was chosen to
mimic segment lengths for mammalian, in particular, human
DNA sequences; see Elhaik et al. (2010a), Clay et al. (2001)
and Cohen et al. (2005). Notice that the minimal segment
length x0 = 10 000 was introduced to avoid short segments
that are difﬁcult to detect. The total sequence length was taken
to be n = 106. For even numbered segments, we selected the
response probability p, according to a uniform distribution on
[0.6,1], whereas for odd segments, we took pj uniformly from
pj e [0, 0.4].

Qualitatively, it turns out that B-SMUCE performs better
than the Jensen—Shannon entropy criterion D 15 both in terms
of sensitivity and precision rate; see Table 1. B-SMUCE detected
90% of all true segments within the desired margin of error.
Furthermore, 94% of all detected segments were correct, again,
within the desired level of accuracy. Because we used B-SMUCE
with a type I error probability of 5% for including too many
segments, this implies that almost all of the detected jumps were
detected within the required level of accuracy. Furthermore,
when incorrect, our method usually detected not more than
one spurious segment boundary. We also tried IsoPlotter on
the simulated sequences and got 85.23 detected segments on
average. Given an mean number of 27.51 true segments (see
Table 1), more than three times the true number of segments
has been detected on average. More detailed results on
ISOPLOTTER can be found in the Supplementary Material.

B-SMUCE also leads to good results in terms of the FPSLE
and F NSLE; see Table 2. Thus, on average, detected segments
and true segments match more closely with B-SMUCE than with
the D 15 criterion.

Table 1. Sensitivity rate and precision rate under Scenario II for the
Jensen—Shannon divergence method (D J5) and B-SMUCE

 

 

Performance criterion D J5 B-SMUCE
Average true number 27.51 (1.90) 27.51 (1.90)
Average number of true-positives 23.26 (1.69) 24.68 (1.80)
Average number of false-positives 2.51 (0.20) 1.60 (0.14)
Average number of false-negatives 4.25 (0.37) 2.83 (0.24)
Average sensitivity 0.83 (0.016) 0.87 (0.015)
Average precision 0.88 (0.013) 0.92 (0.013)

 

Note. Long and short segments were generated from a power-law distribution, and
the total sequence length was n = 106. We provide averages (and in parentheses
standard errors) over 100 simulation runs.

Table 2. FNSLEs and FPSLEs under Scenario II for the Jensen—
Shannon divergence method (D J5) and B-SMUCE

 

 

FNSLE FPSLE
1),, 0.27 (0.436) 0.06 (0.103)
B-SMUCE 0.11 (0.164) 0.01 (0.014)

 

Note. Long and short segments were generated under a power-law distribution, and
the total sequence length was n = 106. The results are averages (and standard
errors) over 100 simulation runs. The error rates were standardized according to
the average segment length.

3.3 Real data

We applied our segmentation algorithm to three data sets. The
ﬁrst two examples, A phage and human major histocompatibility
(MHC) complex, have previously been studied in the context of
segmentation algorithms. As a further example, a 10 Mb se-
quence chunk (hg19, chr1:50000002—60000000) has been arbitrar-
ily chosen from human chromosome 1.

The genome of bacteriophage A consists of 48 502 bases and
was one of the ﬁrst completely sequenced genomes. Our segmen-
tation led to six segments with boundaries 1, 22501, 27829,
33186, 39172, 46367 and 48502. Notice that the same number
of segments, although with a bit different boundaries, has been
reported as the outcome of a segmentation using hidden Markov
models in Chapter 4 of Cristianini and Hahn (2007).

We next investigate human genome data from chromosome
6p21.3 and 6p22.1 (hg19, chr6:29 677 952—33 289 874). This seg-
ment harbors the much studied human MHC complex. We found
a number of segments even larger than that in Elhaik et al.
(2010b), contradicting once again the concept of homogeneous
isochores (from the UCSC browser for this example.) We recoded
G,C as ‘1’ and A,T as 0 and applied B-SMUCE and both D 15 and
IsoPlotter to these data. With D 15, we found 182 segments. With
B-SMUCE and a type I error probability of or = 0.05, we identi-
ﬁed 640 segments. (With or = 0.01, 528 segments were obtained,
and choosing or = 0.1 led to 716 segments.)

A natural question is whether the number of 640 or 182 seg-
ments is more appropriate. To address this issue, notice that the

 

2260

112 /810'S112umofpleXO'sot112u1101utotq//2d11q 111011 pepeolumoq

910K ‘09 tsnﬁnV uo 22

Multiscale DNA partitioning

 

Table 3. Run times (in s) of the B-SMUCE algorithm when applied to
sequences of different length taken from the human chromosome 1

 

 

Sequence length 105 2 x 105 5 x 105 106 5 x 106 107
Run-time bin size 32 0.37 1.0 3.3 9.4 51.9 102.9
Run-time bin size 10 1.7 4.0 12.3 30.7 169.7 384.0

 

Note. The computations were carried out on a single cluster core with 2.6 GHz and
8 GB RAM. The results are reported for or = 0.05 and for bins of lengths 32 and 10.
For a = 0.01, similar run times have been obtained.

statistical error control associated with the multiresolution cri-
terion suggests that there are (except for a small error probabil-
ity) at least 640 segments. To check whether this ﬁnding is also
compatible with the D 15 segmentation, we simulated the segmen-
tation with 640 segments obtained with B-SMUCE as our null
model. We simulated 100 datasets from this null model, and for
80% of all datasets, D 15 led to a segmentation with the number
of segments at most 182. With the number of segments taken as
test statistic, this amounts to an estimated p-value of 0.80. Thus,
the segmentation based on the J ensen—Shannon (D 15) criterion
does not contradict the assumption of 640 segments, whereas the
hypothesis of 182 segments is rejected by the multiscale criterion
underlying B-SMUCE as not being compatible with the data.

We also applied IsoPlotter 2.4 to the data. With its adaptive
detection threshold, 227 segments were identiﬁed. The homogen-
eity test (one-sided F-test) provided with the IsoPlotter software
conﬁrmed for 180 of these 227 segments that they are signiﬁ-
cantly more homogeneous than the entire considered DNA se-
quence. Although this observation does not give us the number
of segments actually present, it seems interesting that the number
of sufﬁciently homogeneous segments found by IsoPlottor is
almost the same as the number of segments identiﬁed with the
D JS criterion.

Finally, we considered the region between 50 and 60 Mb on
the human chromosome 1. Here, we tried bins both of size 10
and 32. It turned out that with the ﬁner partition slightly more
segments were detected than with the larger bins of size 32, al-
though the difference (1096 versus 1041) was not large. It seems
plausible that ﬁne-scale variation can be detected more easily
with shorter bins.

To illustrate the run-time behavior of the B-SMUCE algo-
rithm with our default signiﬁcance threshold or = 0.05, we con-
sidered several shorter sequences taken from the aforementioned
10 Mb DNA sequence. Table 3 gives the run times of our algo-
rithm (in s) in dependence of the sequence length.

To give an idea about the run times of D 15 and IsoPlotter, we
applied them on the same sequence pieces. With the standard
options (bin size: 32, shortest detectable domain size: 3008), the
run times for the longest sequence (107 bases) were 6.2s (D 15)
and 9.6s (IsoPlotter). However, notice that B-SMUCE is de-
signed to detect segments of any length, and the shortest segment
detected by B-SMUCE in the context of our run time analysis
was 80 bases long. Therefore, we also recorded the run times for
D 15 and IsoPlotter with the minimum segment length changed
from 3008 to 80. For a bin width of 32 and a sequence length of

107, the run time for D 15 remained unchanged, whereas the run
time for IsoPlotter increased to 329.1 s.

For the human genome data considered here, a cross-check
with the genome annotation revealed that several segments have
an interpretation in terms of genes/exons, repetitive elements or
CpG islands. Because the GC content may depend on several
functional and evolutionary factors, we do not expect simple
explanations for many of the identiﬁed segments. Nevertheless,
we explore the overlap of the identiﬁed segments with available
annotation in the Supplementary Material.

4 CONCLUSION

We introduced a new method (B-SMUCE) for the segmentation
of biological sequences. The segmentation is with respect to a
binary response; here, we have considered GC content, but it
might be interesting to apply the method to other applications
involving binary responses (such as ancestral/derived state of al-
leles in population genetic applications). Our approach provides
precise statistical error control and will produce a parsimonious
segmentation that does not contain more segments than there
actually are with a user-speciﬁed preassigned probability of
1— or. A comparison under the benchmark scenarios taken
from Elhaik et al. (2010a) suggests that the proposed method
B-SMUCE is more accurate than previously proposed
approaches.

Interestingly, the difference to the popular J ensen—Shannon
criterion in terms of the number of detected segments has been
particularly large for the human data.

ACKNOWLEDGEMENTS

We are grateful to Dr. Marlies Dolezal for her helpful comments.

Funding: The research of AM. and HS. is supported by
Deutsche F orschungsgemeinschaft (DF G) FOR 916, SF B 803
and the Volkswagen Foundation. The work by AF. is supported
by the Austrian Science Fund (F WF ; Vienna Graduate School of
Population Genetics).

Conﬂict of Interest: none declared.

REFERENCES

Amit,M. et al. (2012) Differential GC content between exons and introns establishes
distinct strategies of splice-site recognition. Cell Rep., 1, 543—556.

Benjamini,Y. and Speed,T.P. (2012) Summarizing and correcting the GC content
bias in high-throughput sequencing. Nucleic Acids Res, 40, e72.

Bernardi,G. (2001) Misunderstandings about isochores. Part I. Gene, 276, 3—13.

Boysen,L. et al. (2009) Consistencies and rates of convergence of jump-penalized
least squares estimators. Ann. Statist., 37, 157—183.

Braun,J.V. and Miiller,H.G. (1998) Statistical methods for DNA segmentation.
Stat. Sci, 13, 142—162.

Braun,J.V. et al. (2000) Multiple change-point ﬁtting via quasi-likelihood, with ap-
plication to DNA sequence segmentation. Biometrika, 87, 301—314.

Cristianini,N. and Hahn,M.W. (2007) Computational Genomics. Cambridge
University Press, Cambridge, UK.

Churchill,G.A. (1989) Stochastic models for heterogeneous DNA sequences. Bull.
Math. Biol, 51, 79—94.

Churchill,G.A. (1992) Hidden Markov chains and the analysis of genome structure.
Comp. Chem, 16, 107—115.

Clay,O. et al. (2001) Compositional heterogeneity within and among isochores in
mammalian genomes. I. CsCl and sequence analyses. Gene, 276, 1524.

 

2261

112 /810'S112umofpleXO'sot112u1101utotq//2d11q u1011 pepeolumoq

910K ‘09 tsnﬁnV uo 22

A.Futschik et al.

 

Cohen,N. et al. (2005) GC composition of the human genome: in search for iso-
chores. Mol. Biol. Evol., 22, 1260—1272.

Davies,L. et al. (2012) Recursive computation of piecewise constant volatilities.
Comput. Stat. Data Anal, 11, 3623—3631.

Dﬁmbgen,L. and Spokoiny,V.G. (2001) Multiscale testing of qualitative hypotheses.
Ann. Stat, 29, 124—152.

Dﬁmbgen,L. and Walther,G. (2008) Multiscale inference about a density. Ann.
Stat, 36, 1758—1785.

Elhaik,E. et al. (2010a) Comparative testing of DNA segmentation algorithms using
benchmark simulations. Mol Biol. Evol., 27, 1015—1024.

Elhaik,E. et al. (2010b) Identifying compositionally homogeneous and nonhomo-
geneous domains within the human genome using a novel segmentation algo-
rithm. Nucleic Acids Res., 38, e158.

Fickett,J.W. et al. (1992) Base compositional structure of genomes. Genomics, 13,
1056—1064.

Frick,K. et al. (2014) Multiscale change-point inference. J. R. Stat. Soc. Ser., 76,
495—580.

Friedrich,F. et al. (2008) Complexity penalized M- estimation: fast computation.
J. Comput. Graph. Stat, 17, 201—224.

Freudenberg,J. et al. (2009) Partial correlation analysis indicates causal relationships
between GC-content, exon density and recombination rate in the human
genome. BMC Bioinformatics, 10, S66.

Fullerton,S.M. et al. (2001) Local rates of recombination are positively
correlated with GC content in the human genome. Mol Biol. Evol., 18,
1 139—1 142.

Galtier,N. et al. (2001) GC-content evolution in mammalian genomes: the biased
gene conversion hypothesis. Genetics, 159, 907—911.

Keith,J.M. (2006) Segrnenting eukaryotic genomes with the generalized gibbs sam-
pler. J. Comput. Biol, 13, 1369—1383.

Killick,R. et al. (2012) Optimal detection of changepoints with a linear computa-
tional cost. J. Am. Stat. Assoc, 107, 1590—1598.

Oliver,J.L. et al. (1999) SEGMENT: identifying compositional domains in DNA
sequences. Bioinformatics, 15, 974—979.

Risso,D. et al. (2011) GC-Content Normalization for RNA-Seq Data. BMC
Bioinformatics, 12, 480.

Sueoka,N. (1962) On the genetic basis of variation and heterogeneity of DNA base
composition. PNAS, 48, 582—592.

Walther,G. (2010) Optimal and fast detection of spatial clusters with scan statistics.
Ann. Statist, 38, 1010—1033.

Winkler,G. and Liebscher,V. (2002) Smoothers for discontinuous signals.
J. Nonparametr. Stat, 14, 203—222.

Yao,Y.C. (1988) Estimating the number of change-points via Schwarz’ criterion.
Statist. Probab. Lett, 6, 181—189.

 

2262

112 /810'S112umofpleXO'sot112u1101utotq//2d11q wort pepeolumoq

910K ‘09 tsnﬁnV uo 22

