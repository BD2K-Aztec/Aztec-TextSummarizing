ORIGINAL PAPER

Vol. 29 no. 19 2013, pages 2395—2401
doi:10. 1093/bioinformatics/btt420

 

Sequence analysis

Advance Access publication August 5, 2013

Distilled single-cell genome sequencing and de novo assembly

for sparse microbial communities

Zeinab Taghavi”, Narjes S. Movahedi‘, Sorin Draghici“2 and Hamidreza Chitsaz1
1Department of Computer Science and 2Department of Obstetrics and Gynecology, Wayne State University,

Detroit, MI 48202, USA

Associate Editor: Gunnar Ratsch

 

ABSTRACT

Motivation: Identification of every single genome present in a
microbial sample is an important and challenging task with crucial
applications. It is challenging because there are typically millions
of cells in a microbial sample, the vast majority of which elude
cultivation. The most accurate method to date is exhaustive single-
cell sequencing using multiple displacement amplification, which is
simply intractable for a large number of cells. However, there is
hope for breaking this barrier, as the number of different cell types
with distinct genome sequences is usually much smaller than the
number of cells.

Results: Here, we present a novel divide and conquer method to
sequence and de novo assemble all distinct genomes present in a
microbial sample with a sequencing cost and computational complex-
ity proportional to the number of genome types, rather than the
number of cells. The method is implemented in a tool called
Squeezambler. We evaluated Squeezambler on simulated data. The
proposed divide and conquer method successfully reduces the cost of
sequencing in comparison with the naive exhaustive approach.
Availability: Squeezambler and datasets are available at http://
compbio.cs.wayne.edu/software/squeezamblerl.

Contact: ztaghavi@wayne.edu

Received on March 19, 2013; revised on May 22, 2013; accepted on
July 15, 2013

1 INTRODUCTION

Critical applications, including the Human Microbiome Project
(Methe et al., 2012), biothreat detection and combating antibi-
otic resistant pathogens, necessitate identiﬁcation of all distinct
genome sequences in a bacterial sample. When prior knowledge
is available about which organisms may be present in the
sample, ﬂow cytometry and 16S rRNA gene sequencing may
be used. However, metagenomics is usually used for analyzing
the genomics of relatively abundant microbes when no prior
knowledge is given. Metagenomics consists the study of the
variation of species in a complex microbial sample. Because
the vast majority of environmental bacteria elude cultivation,
metagenomics investigates microbial communities by sequen-
cing sampled genome fragments without the need for culturing.
Such a heterogeneous pool of sequencing reads can also be
assembled to yield a superposition of highly abundant genomes
in the sample (Treangen et al., 2013). There are two problems

 

*To whom correspondence should be addressed.

with metagenomics: (i) the resulting assembly contains multiple
genomes superimposed, and (ii) only highly abundant genomes
survive the sampling process.

Advances in DNA ampliﬁcation technology have enabled
whole genome sequencing directly from individual cells without
requiring growth in culture. Single-cell sequencing methods
have enabled investigation of novel uncultured microbes
(Kvist et al., 2007; Mussmann et al., 2007). These culture-inde-
pendent single—cell studies are a powerful alternative to metage-
nomics studies. Genomic sequencing from single bacterial
genomes was ﬁrst demonstrated with cells isolated by ﬂow cyto-
metry (Raghunathan et al., 2005), using multiple displacement
ampliﬁcation (MDA) (Dean et al., 2001, 2002; Hosono et al.,
2003). MDA is now the preferred method for whole genome
ampliﬁcation from single cells (Ishoey et al., 2008; Lasken,
2007). The ﬁrst attempt to assemble a complete bacterial
genome from one cell (Zhang et al., 2006) further explored
the challenges of assembly from ampliﬁed DNA, including
ampliﬁcation bias and chimeric DNA rearrangements.
Ampliﬁcation bias results in orders of magnitude difference in
coverage (Raghunathan et al., 2005) and absence of coverage in
some regions. Chimera formation occurs during the DNA
branching process by which the 4529 DNA polymerase generates
DNA ampliﬁcation in MDA (Lasken and Stockwell, 2007).
Subsequent studies continued to improve single-cell assemblies
(Hongoh et al., 2008; Marcy et al., 2007; Podar et al., 2007;
Rodrigue et al., 2009; Woyke et al., 2009). A nearly full poten-
tial of single-cell genome assembly has recently been realized by
the work of Chitsaz et al. (2011) followed by those of
Bankevich et al. (2012) and Peng et al. (2012).

Owing to recent progress in single-cell DNA ampliﬁcation
techniques and de novo assembly algorithms, the genomes of
all bacterial species in a sample can be captured one cell at a
time. However, there are often millions of cells per sample, in
which case the naive deep sequencing of every cell becomes
prohibitively costly. Moreover, it is expected that deep sequen-
cing of every cell is often not necessary, as the majority of
biologically important samples are sparse in the sense that
many cells are biological replicates. Compressed (Candes and
Tao, 2005, 2006; Donoho, 2006) and distilled (adaptive
sampling and reﬁnement) sensing methods (Haupt et al.,
2011; Wei and Hero, 2012) have been proposed in the past
decade to exploit sparsity for reducing the cost of sensing and
reconstructing signals in various spaces, ranging from Banach
spaces to Boolean algebras (Erlich et al., 2010; Stobbe and
Krause, 2012). Inspired by those advances, we give an

 

© The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2395

112 ﬁhO'smumo[pJOJXO'sor1BmJOJurorw/2d11q wort p9p1201umoq

910K ‘09 lsnﬁnV no :2

Z.Taghavi et al.

 

algorithm in this article that exploits sample sparsity to reduce
the cost of sequencing without compromising the accuracy of
identiﬁcation of all distinct genomes, even the ones that are
minimally represented in the sample.

2 APPROACH

A na'1've approach to solve the problem, which we call single-cell
co-assembly strategy, is to amplify the genome of each cell,
barcode them individually, pool them, sequence in one sequen-
cing run and demultiplex based on the barcode. In this ap-
proach, each cell should be isolated and its DNA extracted
and ampliﬁed using MDA. Although there is currently no
high-throughput device to perform these processes, one could
envision automated microﬁuidic devices that will be capable of
high-throughput separation, DNA extraction, ampliﬁcation and
barcoding of single cells in the near future. The output sequen-
cing reads could then be co-assembled using our tool HyDA
(Movahedi et al., 2012). In HyDA, the read dataset of each
cell is assigned a unique color. All the colors are co-assembled
in one colored de Bruijn graph. This approach requires enough
unique barcodes to tag the fragments of each cell. Also, bar-
codes attached to each fragment are sequenced, which imposes
additional sequencing cost. Fabrication of so many unique bar-
codes becomes prohibitively expensive for a large number of
cells, and therefore this na'1've approach will not work.

The number of distinct genomes in a microbial community is
often much less than the number of cells. For example, Qin
et al. (2010) estimated the number of detected distinct species
in the human gut to be in the order of 1000, whereas the
number of microbial cells in a human body, most of which
reside in the gut, is in the order of 100 trillion. We call this
effect the sparsity of distinct genomes in a sizable microbial
population. The na'1've approach does not exploit the sparsity
to reduce the cost of sequencing. Here, we proposed to exploit
the spareness by adopting a divide and conquer strategy to
reduce the amount of required barcodes and sequencing.
After isolation of each cell and extraction of the DNA, every
DNA is ampliﬁed and stored separately, e.g. in a microﬁuidic
droplet. The main idea is to sample the ampliﬁed DNAs adap-
tively, which is essentially allocating sequencing and barcoding
resources dynamically over the course of multiple sensing iter-
ations. Initially, the algorithm has one group of cells, which is
the entire sample. In each iteration, each group is divided into
two equally sized subgroups. A small amount of DNA from
each cell in a subgroup is sampled, pooled and sequenced. In
practice, one barcode per subgroup is used to multiplex and
demultiplex the sequencing in one run. The amount of sampling
from each cell is computed based on the results of previous
iterations. This is called resource allocation and is similar to
the one proposed by Haupt et al. (2011) and Wei and Hero
(2012). The resulting read datasets, one per subgroup, are then
co-assembled and compared using HyDA to decide pairwise sub-
sumption of subgroups. The cells in those subgroups that are
subsumed by other subgroups, even in previous iterations, are
eliminated from further analysis. This procedure is continued
until each remaining group contains only one cell. The resulting
non-redundant single element groups capture all of the distinct
genome sequences.

3 METHODS

Although distinct genomes are often identiﬁed as different species, there
are numerous cases where distinct genomes are categorized as varied
instances of the same species or even the same strain. Instead of identi-
ﬁcation of strains and species that are currently phenotypic notions, the
goal of our approach is to ﬁnd all distinct genomes in a sample. We deﬁne
two genome sequences to be distinct if the ratio of their differences over
the whole genome size is above a threshold. That threshold is input by the
user and controls a trade-off between sensitivity and speciﬁcity.

Co-assembly and comparison of multiple input read datasets lie at the
core of both approaches we take in this article. Although there are as-
sembly tools for single-cell genomic data, such as SPAdes (Bankevich
et al., 2012) and IDBA—UD (Peng et al., 2012), and also co-assembly tools
for normal multicell genomic data such as Cortex (Iqbal et al., 2012), we
use HyDA, which is the only tool to date that has both functionalities
(Movahedi et al., 2012). However, the novel ideas proposed here can also
be implemented using other assemblers. For the sake of completeness,
HyDA algorithm is summarized in the following.

3.1 Co-assembly algorithm

3.1.] Construction and condensation of the colored de Bruijn
graph The colored de Bruijn graph, a variation of the standard de
Bruijn graph, is a combinatorial structure that can be used to assemble
a number of input read datasets, each represented by a color, superim-
posed on a single de Bruin graph (Iqbal et al., 2012). The output of such
assembly methods is a number of assembled sequences (contigs) and the
corresponding average multiplicity in each color. Our de Bruijn graph of
the input reads is stored in a hashed collection of splay trees whose
vertices are k—mers with an array of multiplicity counts (one entry per
color), in— and out-edges and internal ﬂags. A l-in l-out chain of k—mers
is condensed into an equivalent long sequence, which is called a unitig.
A maximal unitig, which cannot be extended further because of a branch
in the graph, is a contig. Note that in HyDA, our condensation is solely
based on the topology of the graph without any attention to the colored
multiplicities. Ignoring multiplicities for condensation is purposefully
done, and constitutes the feature that allows the assembler to deal with
black out regions in single-cell MDA (Chitsaz et al., 2011).

Contigs with low coverage are often caused by sequencing error. The
low-coverage contig removal process is iterated with an increased cutoff
in each round. In each iteration, those contigs whose maximum coverage
over all colors is less than the cutoff are eliminated, and the remaining
graph is recondensed. This causes some contigs to merge into larger ones
with recomputed average coverages. This process is similar to Ve lvet—
SC’s low-coverage contig removal, but instead of considering one average
coverage per contig, HyDA considers the maximum of average coverages
for all the colors of each contig (Chitsaz et al., 2011). In this case, only
those contigs that have low coverage in all colors are considered errone-
ous and removed. Another possible approach is to eliminate those contigs
for which the mean of average coverages for all colors is less than the
cutoff. However, if we were to follow this approach, a contig that is well
covered in one color but is poorly covered or absent in hundreds of colors
would be lost, as the mean would dilute the effect of coverage in one color
among hundreds of colors. This approach would not work for us here
because our goal is to be able to preserve rare contigs.

3.1.2 Redundancy removal To remove redundant genomes, we
deﬁne a relation that is reminiscent of subset relation on the set of contigs
for each color. Note that our goal here is to remove redundant genomes,
which are collections of contigs, rather than to remove individually
redundant contigs. Let A = {a1,a2, ...,a,} be the set of remaining
contigs after iterative error removal. Let Adj-(a0 denote the average cover-
age of contig a, in color j, for 1 5 is r and 1 5 j 5 s, where s is the
number of colors. Pick 6 Z 0, and let Aj = {a,- e A | Alj(a,)>€} C A be

 

2396

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q wort pepeommoq

910K ‘09 lsnﬁnV no :2

Distilled genome sequencing and assembly

 

the set of contigs for each color j. The parameter 6 determines the trade-
off between speciﬁcity and sensitivity. We chose 6 = 0 in this study, but a
non-zero 6 might be needed if there are erroneous or contaminant k—mers
in one color that also occur in the true genomic sequence of another
color.

We deﬁne D,(A,-,Aj) e R on the set .7: = {A1,A2, ...,AS} as:
IIAi\Aj||
D A-,A- = ‘L’ — —, 1
,( . ,) “AM ( )
in which A,-\Aj = {a e A,-|a¢AJ-}, and H - M denotes the total assembly
size. We deﬁne:
AiﬁrAj iffo S Dr(AiaAj)a (2)

in which ‘L’ 2 0. Particularly, jo becomes the subset relation and can be
used to detect and remove redundant collections of contigs, i.e. those that
are subsumed by a larger collection. However, in reality, the mathemat-
ical subset relation is not adequate as there are various types of noise,
including sequencing errors, intrastrain variations such as single nucleo-
tide polymorphisms and indels, contaminations added in the ampliﬁca-
tion and sequencing process and lack of coverage in some regions caused
by the MDA. Hence, the deﬁnition of subset should be loosened by
choosing a small but non-zero value for ‘L’. Beside 6, the value of ‘L’
gives a trade-off between speciﬁcity and sensitivity of recognizing distinct
genomes. If ‘L’ is small, the algorithm detects two equivalent genomes as
distinct, and if ‘L’ is large, distinct genomes are declared equivalent. To see
how ‘L’ is chosen, refer to Sections 3.2 and 4.2. The results are shown in
Table 3. Finally, we compute a non-redundant set of assemblies 8 = {A ,1 ,
A,-,, ...,Ait} g .73, such that for every distinct pair 1 5 a,b 5 t, A,“ j, A,-b
and A,-b j, Aid.

3.2 Divide and conquer strategy exploiting sparsity

Let n be the number of cells in the sample, and denote the cells by
S’, i = 1, ...,n. Our algorithm aims to assemble all of the distinct gen-
omes and identify at least one cell per distinct genome. To reach this goal,
our algorithm iteratively pools samples of amplicons from different cells,
tags each pool with a unique barcode, mixes the barcoded pools and has
the result sequenced. The objective is to minimize the total number
of bases required to be sequenced as well as the number of different
barcodes needed.
In the ﬁrst iteration, we divide the n cells S1, . . . , S” into two sets

11,1 = {Sh MSW/21}.

ll,2 ={sL"/21+1, ...,sn}.

Our algorithm samples equal amount of amplicons from each cell in [1,1
and I1, 2. The amplicons in each set are pooled and tagged by two distinct
barcodes. The barcoded amplicons are sequenced to reach a desired
number of base pairs. This number is an input parameter of our algo-
rithm. We deﬁne the total number of base pairs sequenced from I 1,,- to be
b1, ,-, for i = 1, 2. The two read datasets are co-assembled by HyDA using
two colors. The result is two sets of contigs for each color, AU and ALz.
We calculate D,,(A1,1,A1,2) and D,,(A1,2,A1,1) as deﬁned in (1), in
which 11 = ‘E/ man |I1,j|, ‘L’ is an input parameter and | - | is the set car-
dinality. We choose ‘L’ to be the maximum allowable difference between
the assembly of two single cells from the same strain. Based on these
values, we decide whether the relations ALljnAm and AsznAU
hold. If A1,1 is a subset of A1,2, then all of the distinct genomes in [1,1
are present in 11, 2; therefore, the cells in [1,1 do not need further sampling.
This applies to [1,2 too, if A1, 2 is a subset of A1, 1. If both relations hold,
one of [1,1 or [1,2 is eliminated arbitrarily from further analysis. Each
remaining set IL. is divided into two subsets for analysis in the second
iteration. Figure 1 depicts an example of 10 cells with 3 distinct genomes
shown in different colors.

[1,1 [1,2

141,1 j 141,2 141,2 j 241,1

12,1 12,2

[3,1 13,2 [3,3 [3,4

A3,1 i 143,4 A3,3 j A3,4

14,1 14,2 14,3

Fig. 1. The divide and conquer algorithm for an example with 10 cells
and 3 distinct genomes shown in different colors. Each row corresponds
to one sequencing round. The number of barcodes in each round is the
number of blue boxes in the corresponding row

The same splitting process occurs in the subsequent iterations. Assume
Ii, 1, . . . , [Ami are the remaining sets in iteration i. Each set IL]- is sampled
to produce bid- base pairs, barcoded uniquely, pooled and sequenced. All
of the new sequence datasets and those obtained in all previous iterations
are co-assembled. In the co-assembly, the previous datasets help to
improve the assembly of the new ones. The resulting contig set of ILJ- is
denoted by AM. For all j,k = 1 .. .m,-, the relations Aij-L—iALk are eval-
uated, where t,- is a threshold whose calculation will be explained below.
The cells in those IL]- whose assemblies are subsumed will be removed
from further analysis. All the remaining ones are partitioned into two
disjoint subsets. Denote the new subsets by I,-+1,1, . . . , I,-+1,m,.+,. Note that
in iteration i, m, unique barcodes are needed. Therefore,

m = max m,- (3)

is the maximum number of barcodes required for the entire algorithm.

Parameters bid- play a key role in the algorithm. We propose an adap-
tive calculation of bid- to minimize, without losing accuracy, the total base
pairs sequenced:

b = 2b,, (4)
Li

Assume IL]- is a set that is created by dividing the set I,-_1,k in iteration
i —1 into two. We are motivated to choose the total number of sequenced
base pairs from cells in IL]- to be proportional to the total assembly size
“Ai—l,k||: i.e.

bi,j = C X IIAi—1,k||, (5)

where c is an input parameter indicating the estimated average coverage
of each iteration. We say AM are accurate enough if the partial order
relation in. can be assessed accurately. If c is large and the assembly of
iteration i — 1 is accurate enough, then in iteration i, adequate base pairs
are sequenced to allow an accurate enough assembly of set I“.

Another factor that affects accuracy of the assessment of these rela-
tions is the choice of I}. The threshold 1,- in the ith iteration is used to
detect cells with similar genomes despite small differences in their assem-
blies. We propose to use the following threshold:

1:

(6)

t,- = —.
maX1:j:m.- Vial

Recall that ‘L’ is the maximum allowable difference between the assembly
of two single cells with similar genome sequences. To account for the

 

2397

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q wort pepeommoq

910K ‘09 lsnﬁnV no 22

Z.Taghavi et al.

 

worst possible case, it is assumed that there are |I,-,j| distinct genomes in
each group I“. Therefore, maxl 51-5,", |I,-,j| captures the maximum
number of distinct genomes in I“ from any I,-, k. With these assumptions,
1,- is a conservative threshold. This threshold will guarantee that two
distinct genomes are detected, but it has the possibility of detecting simi-
lar genomes as distinct. In the last iteration of the algorithm, when every
group consists of one cell, the threshold is ‘L’. Note that the number of
iterations, which is the number of sequencing rounds, is always [logz 

3.3 Implementation

We implemented our algorithm in a tool called Squeezambler l . 0 in
C++. Our tool and datasets are available at http://compbio.cs.wayne.
edu/software/squeezambler/.

4 RESULTS

Because we did not have access to real data, we tested our algo-
rithm using simulated data. We used our tool MDAsim l . 0
(Taghavi and Draghici, 2012) to simulate 100 MDA processes
(one process per cell) from 9 distinct genomes. The output
of MDAs im 1 . 0 was fed into an Illumina read generator,
ART (Huang et al., 2012), to generate Illumina reads, with real-
istic errors, from the simulated amplicons. The set of generated
reads for each cell was treated like a microﬁuidic droplet from
which samples without replacement are extracted in each
iteration of Squeezambl er 1 . 0. We assume that MDA prod-
ucts are contamination-free, which require a contaminant-free
automated microﬁuidic cell sorting, ampliﬁcation and sampling
device.

4.1 Datasets

A total of 115 MDAs were simulated from nine distinct genomes
chosen from the list of species found in a gut metagenomics
study (Qin et al., 2010) that have a complete or draft reference
genome. Recall that we are simulating MDA from a reference

the diverse nature of MDA coverage bias. ART, an Illumina read
generator, was then deployed to generate 100 bp Illumina reads
from the simulated amplicons. The ampliﬁcation gain of
MDAsim l . 0 was 300x and that of ART was 8x from which
one-eighth were selected randomly to obtain a total gain of
300x. We assembled the dataset of each cell individually with
HyDA l . 0, and the resulting assemblies have between 0.1 and
4.2% missing reference bases measured by Gage (Salzberg et al.,
2012), which is similar to the real world situation with a success-
ful MDA reaction (Chitsaz et al., 2011). We made an error pro-
ﬁle that matches the error statistics of Illumina HiSeq 2000 for
ART. Using our proﬁle, ART injects on average 1% error into the
reads, because of which we need to eliminate erroneous contigs in
the assembler. HyDA l . 0, and also its predecessor Velvet—SC,
has an iterative algorithm to remove low-coverage contigs, which
is explained in Section 3.1.1. In each iteration, Squeezambler
l . 0 provides HyDA l . 0 with a coverage cutoff as a percentage
of the mean coverage of each color. That percentage is constant
in all iterations.

We designed three collections of cells, the statistics of which are
summarized in Table 2. In the ﬁrst collection, there are 62 cells
with 6 distinct genomes. In this collection, we put 22 different
MDA results from NC_004663.1 and 22 from FP929051.1 to

Table 2. Our simulation setups: (i) 62 cells; 6 distinct genomes,
(ii) 97 cells; 5 distinct genomes and (iii) 112 cells; 7 distinct genomes

 

 

NCBI ID Abundance (%)
62 cells; 97 cells; 112 cells;
6 distinct 5 distinct 7 distinct
genomes genomes genomes

 

NC_004663 .1 22 36 % 23 24% 23 21%

 

 

 

genome; therefore, we needed a reference genome for the chosen NC_009614-1 7 11% 0 0% 7 6%
species. Table 1 summarizes the identiﬁcation number in the NC_009615-1 8 13:4 0 0:4 8 7:4
National Center for Biotechnology Information database NC—008532°1 2 3 A’ 0 0 A’ 0 0 A’

. NC_016776.1 1 1% 0 0% 0 0%
(NCBI ID), name, s1ze, reference status (complete or draft)

. FP929046.1 0 0% 12 12% 12 11%

and the number of cells we have s1mulated. The number of FP929051.1 22 36% 35 36% 35 31%
cells 1s approx1mately proportlonal to the abundance mean of 131392905301 0 0% 12 12% 12 11%
the corresponding species in Qin et al. (2010). We ran MDAsim 13139290551 0 0% 15 16% 15 13%
l . 0 with a diverse set of parameters, one for each cell, to capture
Table 1. The nine chosen distinct genomes (species) for our simulation
NCBI ID Name Reference status Size (Mbp) Number of cells
NC_004663.1 Bacteroides thetaiotaomicron VPI-5482 chromosome Complete 6.29 23
NC_009614.1 Bacteroides vulgatus ATCC 8482 chromosome Complete 5.16 7
NC_009615.1 Parabacteroides distasonis ATCC 8503 chromosome Complete 4.81 8
NC_008532.1 Streptococcus thermophilus LMD-9 Complete 1.86 2
NC_016776.1 Bacteroides fragilis 638R Complete 5.37 1
FP929046.1 Faecalibacterium prausnitzii SL3/3 Draft 3.21 12
FP929051.1 Ruminococcus bromii L2-63 Draft 2.25 35
FP929053.1 Ruminococcus sp. SR1 /5 Draft 3.55 12
FP929055.1 Ruminococcus torques L2-14 Draft 3.34 15

 

 

2398

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q wort pepeommoq

910K ‘09 lsnﬁnV no 22

Distilled genome sequencing and assembly

 

play the role of highly abundant genomes in a sample as well as
1 from NC_016776.1 and 2 from NC_008532.1 to represent
low-abundance genomes in the same sample. In the ﬁrst collec-
tion, the number of distinct genomes is approximately one-tenth
of the number of cells, but with a wide range of abundances. The
second collection is the sparsest collection among the three, where
the number of distinct genomes is approximately one-twentieth of
the number of cells. The third collection is the most diverse of the
three, where the number of distinct genomes is approximately
one-sixteenth of the number of cells.

4.2 Simulation results

We ran Squeezambl er 1 . 0 for the three collections described
above, the results of which are summarized in Table 3. Most of
the Squeezambler l . 0 parameters were the same for all three
collections. The assembly inclusion threshold constant per cell
was chosen 1' = 0.2, which means at most 20% of the assembly
can vary among multiple instances of the same genome. Taking
into account the genomic sequence loss caused by the MDA,
sampling of the amplicons and sequencing errors, 20% is a rea-
sonable choice. This is not an optimized value and is chosen
based on the authors’ intuition. We chose 1' conservatively in
this work so that distinct genomes are not lost but some equiva-
lent genomes are detected as distinct. Finding the optimal value
for 1' needs a thorough study, which is beyond the scope of this
article.

The k-mer size for HyDA l . 0 was chosen to be k = 55, which
is a common choice for the chosen Illumina error proﬁle (Chitsaz
et al., 2011). The coverage cutoff, as a percentage of the coverage
mean, was chosen to be 100%, and the minimum contig length
was 100 bp for HyDA l . 0. The coverage mean is estimated based
on the assembly size in the ﬁrst iteration, which is often larger
than the actual genome size because of a myriad of erroneous
low coverage k—mers. This causes the initially estimated coverage
mean to be a small fraction of the ﬁnal coverage mean after error
removal.

Squeezambler l . 0 has an option to choose the number of
initial groups in the ﬁrst iteration, g. If g is chosen to be equal

to the number of cells, then Squeezambler l .0 simulates
the single-cell co-assembly of all the cells. If g = 2, then
Squeezambler l . 0 simulates the divide and conquer
algorithm described in Section 3.2. Although experimenting
with different g values may improve the results, we do not
have data for it.

Before any sequencing is done, the algorithm has no idea
about the genome sizes, various distinct genomes and abundance
of each genome. Therefore, an unbiased algorithm has to se-
quence from each cell exactly the same amount right in the
ﬁrst iteration. That amount in our algorithm, denoted by
blaj/lILJ-l, is an input parameter to Squeezambler l . 0,
which was chosen to be between 1 Mbp and 63 Mbp as reported
in the third column of Table 3. In our setup, the size of the nine
distinct genomes varies between 1.8 and 6.3 Mbp; see Table 1.
Therefore, lep sequencing provides between l/6x and l/2x
coverage, and 63 Mbp sequencing provides between 10x and
35 x coverage.

The input parameter c, which controls the amount of sequen-
cing in subsequent rounds, was chosen to be c = 10, which
means 10x expected coverage from each genome in each collec-
tion. We observed that in practice 10x coverage of each distinct
genome provides sufﬁcient information for reliable evaluation of
f. This is consistent with the Lander and Waterman (1988) ana-
lysis, in which the statistics of gaps and contigs in terms of cover-
age is characterized. Based on that analysis, 10x coverage yields
the entire genome without gap with high probability.

Our divide and conquer algorithm exhibits signiﬁcant im-
provement in maximum barcodes, and in most cases the total
number of base pairs sequenced, over the single-cell co-assembly
method. For the 97 cells, 5 distinct genomes collection, our
divide and conquer algorithm requires only 2.9 Gbp sequencing
and 10 barcodes in comparison with 3.0 Gbp sequencing and
97 barcodes consumed by the single-cell co-assembly method.
Similarly for the 62 cells, 6 distinct genomes collection, our
divide and conquer algorithm requires only 3.0 Gbp sequencing
and 10 barcodes in comparison with 3.9 Gbp sequencing and
62 barcodes required by the single-cell co-assembly method.

Table 3. Squeezambler l . 0 results for the three setups summarized in Table 2

 

 

Setup Method Sequencing per cell in Total sequencingb Max Number of predicted Iterations
the ﬁrst iterationa (Mbp) (Gbp) barcodesc distinct genomes

62 cells; 6 distinct Single-cell co-assembly 63 3.9 62 6 1
genomes Divide and conquer 7 3.0 10 8 6
97 cells; 5 distinct Single-cell co-assembly 63 6.1 97 5 1
genomes Single-cell co-assembly 31 3.0 97 1 1 1
Divide and conquer 1 3.2 17 5 7
Divide and conquer 7 2.9 10 6 7
112 cells; 7 distinct Single-cell co-assembly 63 7.1 112 7 1
genomes Single-cell co-assembly 31 3.5 1 12 14 1
Divide and conquer 1 7.1 33 11 7

 

Note: We report the results for two different values of initial sequencing coverage per cell for some methods. Bold numbers indicate the best results for the corresponding

parameters for each setup.
ab1,j/|Il,j|-

bb in (4).

cm in (3).

 

2399

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q wort pepeommoq

910K ‘09 lsnﬁnV uo 22

Z.Taghavi et al.

 

Even though for the 112 cells, 7 distinct genomes collection, our
divide and conquer algorithm outperforms single-cell co-assem—
bly in terms of the number of barcodes, by 33 versus 112, it
requires 7.1Gbp sequencing, which is more than that used by
single-cell co-assembly (3.5 Gbp).

In all of our experiments, all distinct genomes were correctly
detected. Therefore, our results exhibit ultimate sensitivity.
However, in some experiments, multiple cells with similar
genomes were identiﬁed as distinct, which is not an issue for
our problem, because, based on the results of Squeezambler
l . 0, those cells that are identiﬁed as with distinct genomes can
be deeply sequenced and assembled afterward. For the 62 cells, 6
distinct genomes collection, the number of detected distinct gen-
omes was between 6 and 8. For the 97 cells, 5 distinct genomes
collection, that number was between 5 and 11, and for the 112
cells, 7 distinct genomes collection, that was between 7 and 14.
This speciﬁcity is reported in the sixth column of Table 3. Note
that the number of sequencing rounds (iterations) for single-cell
co-assembly is always 1, and for divide and conquer with g = 2,
it is |_log2 

Owing to the computational intensity of MDAsim l . 0, HyDA
l . 0 and Squeezambler l . 0, we report our results for only
small examples to provide a proof of concept. We also chose
our parameters conservatively, and without optimization, so
that we do not compromise accuracy. Moreover, our examples
are in the order of 100 cells and 6 distinct genomes, whereas
real world samples are much sparser, as the number of cells
may be in the order of billions and the number of distinct gen-
omes at most in the order of thousands. Therefore, we expect the
reduction in the total sequencing and maximum barcodes to be
higher for real world applications than what we report in this
article.

5 CONCLUSION

We presented an adaptive divide and conquer algorithm for dis-
tilled sequencing and de novo assembly of distinct genomes in a
bacterial community, e.g. human gut microbiome. Samples
derived from such communities are often sparse in the sense
that the number of distinct genomes is much less than the
number of cells. Our algorithm exploits sparsity to decrease the
amount of sequencing and the number of multiplexing barcodes
needed for single-cell sequencing and de novo assembly.

We implemented our algorithm in a tool which we call
Squeezambler and performed simulation experiments to dem-
onstrate its power. Our results show that (i) the number of
required barcodes with our divide and conquer algorithm is
less than that required by the naive approach, and that (ii) the
amount of sequencing needed remains the same or decreases.
Owing to the computational intensity of the problem, only
small examples with low sparsity were studied in this work.
Real-world samples are much sparser (~1000 species in ~10”
cells) than the examples here (~5 species in ~100 cells). Also, the
parameters used to run our tool were chosen conservatively and
without optimization. Therefore, we expect the improvement of
our algorithm to be higher than what we reported in this article
in real-world situations. Squeezambl er 1 . 0 identiﬁes all dis-
tinct genomes in the sample, which are candidates for different
strains/species. Those cells that are identiﬁed as having distinct

genomes need to be subsequently deeply sequenced and
assembled to obtain a more detailed assembly.

Funding: NIH ROl DK089167, STTR R42GM087013 and NSF
DBI-O965741 (to SD).

Conflict of Interest: none declared.

REFERENCES

Bankevich,A. et al. (2012) SPAdes: a new genome assembly algorithm and its
applications to single-cell sequencing. J. Comput. Biol., 19, 455—477.

Candés,E. and Tao,T. (2005) Decoding by linear programming. IEEE Trans. Inf.
Theory, 51, 4203—4215.

Candés,E. and Tao,T. (2006) Near-optimal signal recovery from random
projections: Universal encoding strategies? IEEE Trans. Inf. Theory, 52,
5406—5425.

Chitsaz,H. et al. (2011) Efﬁcient de novo assembly of single-cell bacterial genomes
from short-read data sets. Nat. Biotechnol., 29, 915—921.

Dean,F.B. et al. (2001) Rapid ampliﬁcation of plasmid and phage DNA using Phi
29 DNA polymerase and multiply-primed rolling circle ampliﬁcation. Genome
Res., 11, 1095—1099.

Dean,F.B. et al. (2002) Comprehensive human genome ampliﬁcation using multi-
ple displacement ampliﬁcation. Proc. Natl Acad. Sci. USA, 99, 5261—5266.

Donoho,D. (2006) Compressed sensing. IEEE Trans. Inf. Theory, 52, 1289—1306.

Erlich,Y. et al. (2010) Compressed genotyping. IEEE Trans. Inf. Theory, 56,
706—723.

Haupt,J. et al. (2011) Distilled sensing: adaptive sampling for sparse detection and
estimation. IEEE Trans. Inf. Theory, 57, 6222—6235.

Hongoh,Y. et al. (2008) Complete genome of the uncultured Termite
Group 1 bacteria in a single host protist cell. Proc. Natl Acad. Sci. USA, 105,
5555—5560.

Hosono,S. et al. (2003) Unbiased whole-genome ampliﬁcation directly from clinical
samples. Genome Res., 13, 954—964.

Huang,W. et al. (2012) ART: a next-generation sequencing read simulator.
Bioinformatics, 28, 593—594.

Iqbal,Z. et al. (2012) De novo assembly and genotyping of variants using colored de
bruijn graphs. Nat. Genet., 44, 226—232.

Ishoey,T. et al. (2008) Genomic sequencing of single microbial cells from environ-
mental samples. Curr. Opin. Microbiol., 11, 198—204.

Kvist,T. et al. (2007) Speciﬁc single-cell isolation and genomic ampliﬁcation of
uncultured microorganisms. Appl. Microbiol. Biotechnol., 74, 926—935.

Lander,E.S. and Waterman,M.S. (1988) Genomic mapping by ﬁngerprinting
random clones: a mathematical analysis. Genomics, 2, 231—239.

Lasken,R.S. (2007) Single-cell genomic sequencing using Multiple Displacement
Ampliﬁcation. Curr. Opin. Microbiol., 10, 510—516.

Lasken,R.S. and Stockwell,T.B. (2007) Mechanism of chimera formation
during the Multiple Displacement Amplification reaction. BMC Biotechnol.,
7, l9.

Marcy,Y. et al. (2007) Dissecting biological “dark matter” with single-cell genetic
analysis of rare and uncultivated TM7 microbes from the human mouth.
Proc. Natl Acad. Sci. USA, 104, 11889—11894.

Methe,B.A. et al. (2012) A framework for human microbiome research. Nature, 486,
215—221.

Movahedi,N.S. et al. (2012) De novo co—assembly of bacterial genomes from
multiple single cells. In: IEEE Conference on Bioinformatics and Biomedicine.
Philadelphia, PA, USA, pp. 561—565.

Mussmann,M. et al. (2007) Insights into the genome of large sulfur bacteria revealed
by analysis of single filaments. PLoS Biol., 5, e230.

Peng,Y. et al. (2012) IDBA-UD: a de novo assembler for single-cell and
metagenomic sequencing data with highly uneven depth. Bioinformatics, 28,
1420—1428.

Podar,M. et al. (2007) Targeted access to the genomes of low-abundance
organisms in complex microbial communities. Appl. Environ. Microbiol., 73,
3205—3214.

Qin,J. et al. (2010) A human gut microbial gene catalogue established by metage-
nomic sequencing. Nature, 464, 59—65.

Raghunathan,A. et al. (2005) Genomic DNA ampliﬁcation from a single bacterium.
Appl. Environ. Microbiol., 71, 3342—3347.

 

2400

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q IIIOJJ pepeommoq

910K ‘09 lsnﬁnV uo 22

Distilled genome sequencing and assembly

 

Rodrigue,S. et al. (2009) Whole genome ampliﬁcation and de novo assembly of
single bacterial cells. PLoS One, 4, e6864.

Salzberg,S.L. et al. (2012) GAGE: a critical evaluation of genome assemblies and
assembly algorithms. Genome Res., 22, 557—567.

Stobbe,P. and Krause,A. (2012) Learning fourier sparse set functions. J. Mach.
Learn. Res., 22, 1125—1133.

Taghavi,Z. and Draghici,S. (2012) Mdasim: a multiple displacement ampliﬁcation
simulator. In: IEEE Conference on Bioinformatics and Biomedicine. Philadelphia,
PA, USA, pp. 575—578.

Treangen,T.J. et al. (2013) MetAMOS: a modular and open source metagenomic
assembly and analysis pipeline. Genome Biol., 14, R2.

Wei,D. and Hero,A. (2012) Multistage adaptive estimation of sparse signals. In:
IEEE Statistical Signal Processing Workshop (SSP). Ann Arbor, MI, USA,
pp. 153—156.

Woyke,T. et al. (2009) Assembling the marine metagenome, one cell at a time. PLoS
One, 4, e5299.

Zhang,K. et al. (2006) Sequencing genomes from single cells by polymerase cloning.
Nat. Biotechnol., 24, 680—686.

 

2401

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q IIIOJJ pepeommoq

910K ‘09 lsnﬁnV uo 22

