Bioinformatics, 31 (7), 2015, 1034—1043

doi: 10.1093/bioinformatics/btu766

Advance Access Publication Date: 18 November 2014
Original Paper

 

Systems biology

HyDRA: gene prioritization via hybrid
distance-score rank aggregation

Minji Kim*, Farzad Farnoud and Olgica Milenkovic

Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana,
IL 61801, USA

*To whom correspondence should be addressed.
Associate Editor: Jonathan Wren

Received on June 2, 2014; revised on October 26, 2014; accepted on November 13, 2014

Abstract

Summary: Gene prioritization refers to a family of computational techniques for inferring disease
genes through a set of training genes and carefully chosen similarity criteria. Test genes are scored
based on their average similarity to the training set, and the rankings of genes under various simi-
larity criteria are aggregated via statistical methods. The contributions of our work are threefold: (i)
first, based on the realization that there is no unique way to define an optimal aggregate for rank-
ings, we investigate the predictive quality of a number of new aggregation methods and known
fusion techniques from machine learning and social choice theory. Within this context, we quantify
the influence of the number of training genes and similarity criteria on the diagnostic quality of the
aggregate and perform in-depth cross-validation studies; (ii) second, we propose a new approach
to genomic data aggregation, termed HyDRA (Hybrid Distance-score Rank Aggregation), which
combines the advantages of score-based and combinatorial aggregation techniques. We also pro-
pose incorporating a new top-versus-bottom (TvB) weighting feature into the hybrid schemes. The
TvB feature ensures that aggregates are more reliable at the top of the list, rather than at the
bottom, since only top candidates are tested experimentally; (iii) third, we propose an iterative pro-
cedure for gene discovery that operates via successful augmentation of the set of training genes by
genes discovered in previous rounds, checked for consistency.

Motivation: Fundamental results from social choice theory, political and computer sciences, and
statistics have shown that there exists no consistent, fair and unique way to aggregate rankings.
Instead, one has to decide on an aggregation approach using predefined set of desirable properties
for the aggregate. The aggregation methods fall into two categories, score- and distance-based
approaches, each of which has its own drawbacks and advantages. This work is motivated by the
observation that merging these two techniques in a computationally efficient manner, and by
incorporating additional constraints, one can ensure that the predictive quality of the resulting
aggregation algorithm is very high.

Results: We tested HyDRA on a number of gene sets, including autism, breast cancer, colorectal
cancer, endometriosis, ischaemic stroke, leukemia, lymphoma and osteoarthritis. Furthermore, we
performed iterative gene discovery for glioblastoma, meningioma and breast cancer, using a se-
quentially augmented list of training genes related to the Turcot syndrome, Li-Fraumeni condition
and other diseases. The methods outperform state-of—the-art software tools such as ToppGene and
Endeavour. Despite this finding, we recommend as best practice to take the union of top-ranked
items produced by different methods for the final aggregated list.

Availability and implementation: The HyDRA software may be downloaded from: http://web.
engr.illinois.edu/~mkim158/HyDRA.zip

©The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com

 

1 034

112 ﬂJO'sleumo[pJOJXO'sopeuuogutotq/ﬁd11q mm; pepeolumoq

910K ‘09 lsnﬁnV no :2

Gene prioritization via HyDRA

1035

 

Contact: mkim158@illinois.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

Identification of genes that predispose an individual to a disease is a
problem of great interest in medical sciences and systems biology
(Adie et al., 2006). The most accurate and powerful methods used
for identification are experimental in nature, involving normal and
disease samples (Cardon et al., 2001). Experiments are time con-
suming and costly, complicated by the fact that typically, multiple
genes have to be jointly mutated to trigger the onset of a disease.
Given the large number of human genes (225 000), testing even rela-
tively small subsets of pairs of candidate genes is prohibitively ex-
pensive (Risch and Merikangas, 1996).

To mitigate this issue, a set of predictive analytical and computa-
tional methods have been proposed under the collective name gene
prioritization techniques. Gene prioritization refers to the complex
procedure of ranking genes according to their likelihoods of being
linked to a certain disease. The likelihood function is computed
based on multiple sources of evidence, such as sequence similarity,
linkage analysis, gene annotation, functionality and expression ac-
tivity, gene product attributes—all determined with respect to a set
of training genes.

A wide range of tools has been developed for identifying genes
involved in a disease (Kohler et al., 2008; Kolde et al., 2012; Pihur
et al., 2009), as surveyed (Tiffin et al., 2006). Existing software in-
cludes techniques based on network information, such as GUILDify
(Guney et al., 2014) and GeneMANIA (Warde-Farley et al., 2010),
data mining and machine learning-based approaches as described in
(Perez-Iratxeta et al., 2002), POCUS (Turner et al., 2003) SUSPECTS
(Adie et al., 2006) and (Yu et al., 2008), and methods using statistical
analysis, including Endeavour (Aerts et al., 2006; De Bie et al., 2007),
ToppGene (Chen et al., 2009) and NetworkPrioritizer (Kacprowski
et al., 2013). Here, we focus on statistical approaches coupled with
new combinatorial algorithms for gene prioritization, and emphasize
one aspect of the prioritization procedure: rank aggregation.

The problem of aggregating rankings of distinct objects or enti-
ties provided by a number of experts, voters or search engines has a
rich history (Fishburn, 1970). One of the key findings is that various
voting paradoxes arise when more than three candidates are to be
ranked: it is frequently possible not to have a candidate that wins all
pairwise competitions (the Condorcet paradox) and it is theoretic-
ally impossible to guarantee the existence of an aggregate solution
that meets certain predefined set of criteria [such as those imposed
by Arrow’s impossibility theorem (Fishburn, 1970)]. These issues
carry over to aggregation methods used for gene discovery, and as a
result, the rank-ordered lists of genes heavily depend on the particu-
lar aggregation method used.

Two families of methods have found wide applications in rank
aggregation: combinatorial methods (including score- and distance-
based approaches) (Kemeny, 1959) and statistical methods. In the
bioinformatics literature, the aggregation methods of choice are stat-
istical in nature, relying on pre-specified hypotheses to evaluate the
distribution of the gene rankings. One of the earliest prioritization
softwares, Endeavour, uses the Q-statistics for multiple significance
testing, and measures the minimum false discovery rate at which a
test may be called significant. In particular, rankings based on differ-
ent similarity criteria are combined Via order statistics approaches.
For this purpose, one uses the rank ratio (normalized ranking) of a

gene g for m different criteria, r1(g),. . ., rIn (g) and recursively com-
putes the Q-value, defined as

d d,,_,. . .dsl.

Sm

Qi(1‘1(g),. . .,rm(g)) : m!J‘:(8) J"2(g). . .J-rm(g)

51 sm—l

Post-processed Q-Values are used to create the resulting ranking
of genes. The drawbacks of the method are that it is based on a null
hypothesis that is difficult to verify in practice, and that it is compu-
tationally expensive, as it involves evaluating an m-fold integral. To
enable efficient scaling of the method, Endeavour resorts to approxi-
mating the Q-integral. The influence of the approximation errors on
the final ranking is hard to assess, as small changes in scores may re-
sult in significant changes of the aggregate orderings.

Likewise, ToppGene uses a well-known statistical approach,
called the Fisher X2 method. It first determines the p-values of
similarity score indexed by j, denoted by p(j), for j = 1,. . .,m. The
p-values are computed through multiple preprocessing stages,
involving estimation of the information contents (i.e. weights) of
annotation terms, setting-up a similarity criteria based on Sugeno
fuzzy measures (i.e. non-additive measures) (Popescu et al., 2006),
and performing meta-testing. The use of fuzzy measures ensures that
all similarities are non-negative. Then, under the hypothesis of
independent tests, ToppGene uses Fisher’s inverse X2 result, stating

that —ZZ:1logp(/') —> X2(2m). Here, X2 (2m) stands for the chi-

square distribution with 2 m degrees of freedom. The result is
asymptotic in nature, and based on possibly impractical independ-
ence assumptions.

A number of methods, and additive scoring methods in particu-
lar, have the drawback that they tacitly or implicitly rely on the as-
sumption that (i) only the total score matters, and the balance
between the number of criteria that highly ranked the gene and
those that ranked it very low is irrelevant. For example, outlier rank-
ings may reduce the overall ranking of a gene to the point that it is
not considered a disease gene candidate, while the outlier itself may
be a problematic criterion. To illustrate this observation, consider a
gene that was ranked 1st, 2nd, 1st, 20th by four criteria. At the
same time, consider another gene that was ranked 6th by all four cri-
teria. It may be unclear which of these two genes is more likely to be
involved in the disease, given that additive score methods would
rank the two genes equally (as one has (1 +2+ 1 +20)/4=6).
Nevertheless, it appears reasonable to assume that the first candi-
date is a more reliable choice for a disease gene, as it had a very high
ranking for three out of four criteria; and (ii) no distinction is made
about the accuracy of ranking genes in any part of the list; i.e. the
aggregate ranking has to be uniformly accurate at the top, middle
and bottom of the list. Clearly, neither of the two aforementioned
assumptions is justified in the gene prioritization process: there are
many instances where genes similar only under a few criteria (such
as sequence similarity or linkage distance) are involved in the same
disease pathway. Furthermore, as the goal of prioritization is to pro-
duce a list of genes to be experimentally tested, only the highest
ranked candidate genes are important and should have higher accur-
acy than other genes in the list. In addition, most known aggregation
methods are highly sensitive to outliers and ranking errors.

We propose a new approach to gene prioritization by introduc-
ing a number of novel aggregation paradigms, which we collectively

112 /810'S{12umo[pJOJXO'soiiemJOJutoiw/zdnq wort pepeolumoq

910K ‘09 lsnﬁnV no :2

1036

M.Kim et al.

 

refer to as HyDRA (Hybrid Distance-score Rank Aggregation). The
gist of HyDRA is to combine combinatorial approaches that
have universal axiomatic underpinnings with statistical evidence
pertaining to the accuracy of individual rankings. Our preferred
distance measure for combinatorial aggregation is the Kendall
distance (Kendall, 1938), which counts the number of pairwise
disagreement between two rankings, and was axiomatically postu-
lated by Kemeny (1959). The Kendall distance is closely related to
the Kendall rank correlation coefficient (Dwork et al., 2001;
Kendall, 1948). As such, it has many properties useful for gene
prioritization, such as monotonicity, reinforcement and Pareto
efficiency (Thanassoulis, 2001). The Kendall distance can be
generalized to take into account positional relevance of items, as
was done in our companion article (Farnoud et al., 2012, 2014).
There, it was shown that by assigning weights to pairs of positions
in rankings, it is possible to (i) eliminate negative outliers from the
aggregation process, (ii) include quantitative data into the aggregate
and (iii) ensure higher accuracy at the top of the ranking than at the
bottom.

The contributions of this work are threefold. First, we introduce
new weighted distance measures, where we compute the weights
based on statistical evidence of a function of the difference between
p-values of adjacently ranked items. Aggregation weights based on
statistical evidence improve the accuracy of the combinatorial aggre-
gation procedure and make them more robust to estimation errors.
Second, we describe how to scale the weights obtained based on
statistical evidence by a decreasing sequence of TVB (Top versus
Bottom) multipliers that ensure even higher accuracy at the top of
the aggregated list. As aggregation under the Kendall metric is
NP-hard (Non-deterministic Polynomial-time hard) (Bartholdi et al.,
1989), and the same is true of the weighted Kendall metric, we
propose a 2-approximation method that is stable under small per-
turbations. Aggregation is accomplished Via weighted bipartite
matching, such as the Hungarian algorithm and derivatives thereof
(Kuhn, 1955). Third, we test HyDRA within two operational scen-
arios: cross-validation and disease gene discovery. In the former
case, we assess the performance of different hybrid methods with re-
spect to the choice of the weighting function and different number
of test and training genes. In the latter case, we adapt aggregation
methods to gene discovery Via a new iterative re-ranking procedure.

2 Systems and methods

In our subsequent exposition, we use Greek lower case letters to
denote complete linear orders (permutations), and unless explicitly
mentioned otherwise, our findings also hold for partial (incomplete)
permutations. Latin lower case letters are reserved for score
vectors or scalar scores, and which of these entities we refer to will
be clear from the context. The number of test genes equals n,
while the number of similarity criteria equals m. Throughout the
article, we also use [la] to denote the set {1,. . ., la} and S, to denote
the set of all permutations on n elements—the symmetric group of
order n!.

For a permutation o = (0(1),. . ., o(n)), the rank of element i in
a, ranka(i), equals o_1(i), where 0‘1 denotes the inverse permuta-
tion of a. For a vector of scores x = (x(i)))‘=1 6 IR“, ox represents a
permutation describing the scores in decreasing order, i.e.
ox(i) = argmax ken x(k), where T; is defined recursively as
T; = T,_1 \ox(i), with To =  For example, if x: (2.5, 3.8, 1.1,
0.7), then 0,, = (2,1,3,4). Note that if p is a vector of p-values,

higher scores are associated with smaller p-values, so that argmax
should be replaced by argmin.

The terms gene and element are used interchangeably, and
each permutation is tacitly assumed to be produced by one
similarity criteria. For a set of permutations 2 = {01, . ., am},
0; = (0(1),. . ., 0; an aggregate permutation 0* is a permutation
that optimally represents the rankings in 2. Combinatorial aggre-
gates may be obtained using score- and distance-based methods.
Note that score and distance-based methods do not make use of
quantitative information, such as, e.g., p-values (for the case of gene
prioritization) or ratings (for the case of social choice theory and
recommender systems). In what follows, we brieﬂy describe score
and distance-based methods and introduce their hybrid counter-
parts, which allow to integrate p-values and relevance constraints
into combinatorial aggregation approaches.

2.1 Score-based methods

Score-based methods are the simplest and computationally least
demanding techniques for rank aggregation. As inputs, they take a
set of permutations or partial permutations, 2 = {01,. . ., am},
a; = (0(1),. . ., a; For each permutation o,- E 2, the scoring rule
awards s(oi(1), i) points to element oi(1), s(oi(2), i) points to element
oi(2), and so on. For a fixed i, the scores are non-increasing func-
tions of their first index. Each element la 6  is assigned a cumula-

tive score equal to 1s(le,j). The simplest scoring method is

Borda’s count, for which s(k, j) = n — la + 1 independent on i.

The Borda count and related scoring rules exclusively use pos-
itional information in order to provide an aggregate ranking.
Ignoring actual p-values (ratings) may lead to aggregation problems,
as illustrated by the next example.

Example 1: Assume that n = 5 elements were rated according to
x = (7.0, 7.01, 0.2, 0.45, 7.001). The ranking induced by this rating
equals ox = (2,5, 1, 4, 3), indicating that element 2 received the
highest rating, element 5 received the second highest rating and so
on. According to the Borda rule, element 2 receives 5 points, element
5 receives 4 points, etc. Despite the fact that candidates 2 and 1 are
almost tied with scores of 7.01 and 7.0, and that the difference in
their scores may be attributed to computational imprecision, elem-
ent 2 receives 5 points while element 1 receives only 3 points. As a
result, very small differences in ratings may result in large differ-
ences in Borda scores.

One way to approach the problem is to quantize the score and
work with rankings with ties, instead of full linear orders (i.e. per-
mutations). Elements tied in their rank receive the same number of
points in the generalized Borda scheme. A preferred alternative,
which we introduce in this work, is the Hybrid Borda method.

Let p(i, 7') denote the p-value of gene i computed under similarity
criteria 7', j = 1,. . .,m. The cumulative score of element i in the hy-
brid Borda setting is computed as

Si 2 in: 2,, 7,,.20(le,i)1{p(k./'>2p(z'.i>}
17(137')

i=1

 

The overall aggregate is obtained by ordering S in a descending
order. It is straightforward to see that the previous score function
extends Borda method in so far that it scores an element (gene) ac-
cording to the total score of elements ranked lower than the element.
Recall that in Borda’s method, the element ranked i is awarded n — i
+1 points, as n — i + 1 elements are ranked below it, each receiving
the same score 1. In our Hybrid Borda method, each element is

112 /810'S{12umo[pJOJXO'soiiemJOJutoiw/2dnq wort pepeolumoq

910K ‘09 lsnﬁnV no 22

Gene prioritization via HyDRA

1037

 

awarded a score in accordance with the p-values of elements ranked
below it.

Example 2: Let n=4 and m=2, where the two ratings equal
to p1 = (0.2, 0.3, 0.01, 0.12) and p2 = (0.1, 0.4, 0.2, 0.35). The
Hybrid Borda scores S; for genes i = 1, 2, 3, 4 are computed as
$1 = 0.3/0.2 + (0.4 + 0.2 + 0.35)/0.1 = 11, $2: 0, S3 = (0.2 + 0.3
+0.12)/0.01 + (0.4 + 0.35)/0.2 = 65.75 and S4 = (0.2 + 0.3)/0.12
+ 0.4 / 0.35 = 5.3. By ordering the values Si in a descending manner,
we obtain the overall aggregate CHI; 2 (3, 1, 4, 2).

The hybrid Borda method can be extended further by adding a
TVB feature, resulting in the Weighted hybrid Borda method. This is
accomplished by including increasing (multiplier) weights into
the score aggregates, thus stressing the top of the list more than the
bottom. More precisely, the score of gene i is computed as:

m Zk¢iwm(k,i)P(/€,i)1{p(k,i)2p(i,i)}

8,22

 mama,»

 

where one simple choice for the weight multipliers that provides
good empirical performance equals

1

WW) = 

2.2 Distance-based methods

Another common approach to rank aggregation is distance-based
rank aggregation. As before, assume that one is given a set of permu-
tations 2 = {01, . ., am}. For a given distance function between two
permutations o and TC, d(o, TC), aggregation reduces to

TC = arg minaZ d(o, 0;)

i=1

The aggregate TC is frequently referred to as the median of the
permutations, and is illustrated in Figure 1.

One of the most important features of distance-based approaches
is the choice of the distance function. Table 1 lists two of the most
frequently used distances, the Kendall tau distance and the
Spearman footrule. As may be seen from the table, the distance
measures are combinatorial in nature, and do not account for scores
or p-values. Furthermore, as already mentioned in the introduction,
it is known that aggregation under the Kendall metric is computa-
tionally hard. Nevertheless, there exists a number of techniques
which provide provable approximation guarantees for the aggre-
gate, including the weighted Bipartite Graph Matching (WBGM)
method (using the fact that the Spearman distance aggregate is a 2-
approximation for the Kendall aggregate), linear programing (LP)
relaxation and Page Rank/Markov chain (PR) methods (Dwork
et al., 2001; Farnoud et al., 2012; Raisali et al., 2013).

The Kendall distance also does not take into account the fact
that the top of a list is more important than the remainder of the list.
To overcome this problem, we introduced the notion of weighted
Kendall distances, where each adjacent swap is assigned a cost, and
where the cost is higher at the top of a list. This ensures that in an
aggregate, strong showings of candidates are emphasized compared
with their weaker showings, accounting for the fact that it is often
sufficient to have strong similarity with respect to only a subset of
criteria. Furthermore, such weights ensure that higher importance is
paid to the top of the aggregate ranking.

The idea behind the weighted Kendall distance dW is to compute
this distance as the shortest path in a graph describing swap relation-
ships between permutations. The key concepts are illustrated in

 

Fig. 1. Four rankings: 01, 02, 03, a4 and their aggregate (median) ranking 7t

Table 1. Two frequently used distance measures for permutations,
accounting for swaps or element-wise differences

 

Distance Measurement Example

 

Spearman’s Sum of differences of dp (abc, cba) = 2 —|— 0 —|— 2 = 4
footrule ranks of elements.

Kendall Minimum number of dK (abc, cba) = 3

adjacent swaps of

entries for transforming

one ranking into another.

 

In the second example, the Kendall tau distance between the permutation
01 = (a, b, c) and 02 = (c, b, a) equals 3: one ﬁrst swaps elements at positions
1 and 2 to get (b, a, c), then elements at positions 2 and 3 to get (b, c, a), and
ﬁnally elements at positions 1 and 2 to get 02 = (c, b, a). All swaps contribute
the same weight (one) to the distance.

Figures 2 and 3, where each edge is assigned a length proportional to
its weight W. This weight depends on the swap being made at the top
or at some other position in the ranking. Given that it is computation-
ally demanding to aggregate under the weighted Kendall distance, we
use a specialized approximation function Dw(o, (9) for dw, of the form

Dw(a, 0) = Z; war—1(2) : 04(0), (1)
where
j; W(h,h + 1), ifk <1,

We"): 2:;11W(b,h+1), 11/01, (2)
0, iszl,

denotes the sum of the weights of edges  representing adjacent
transpositions (kk + 1), (k + 1 k + 2),. . ., (l — 1l), if la < l, the sum
of the weights of edges  representing adjacent transpositions
(ll+1),(l+ 1l+2),...,(k— 1k),ifl<k,and0,ifk=l.

Example 3: Suppose that one is given four rankings, (1, 2, 3),
(1, 2, 3), (3, 2, 1) and (2, 1, 3). There are two optimal aggregates
according to the Kendall tau distance, namely (1, 2, 3) and (2, 1, 3).
Both have cumulative distance four from the set of given
permutations. If the transposition weights are non-uniform, say such
that W(12)>W(23), the solution becomes unique and equal to
(1, 2, 3). If the last ranking is changed from (2, 1, 3) to (2, 3, 1),
exactly three permutations are optimal from the perspective of
Kendall tau aggregation: (1, 2, 3), (2, 1, 3) and (2, 3, 1). These three
solutions give widely different predictions of what one should
consider the top candidate. Nevertheless, by choosing once
more W(12)>W(23) the solution becomes unique and equal to
(1,2,3).

It can be shown that for any non-negative weight function w,
and for two permutations o and (9, one has

1/2Dw(a, (9) S dw(7t, a) S DW(0, (9)

112 /810'S{12umo[pJOJXO'sotiemJOJutotw/2dnq wort pepeolumoq

910K ‘09 lsnﬁnV no 22

1038

M.Kim et al.

 

 

Fig. 2. The Kendall distance is the weight of the shortest path between two
vertices labeled by two permutations, with each edge having length (weight)
one. Edges are labeled by the adjacent swaps used to move between the
vertex labels. For example, the two vertices labeled by acb and cab are
connected via an edge bearing the label <12 >, indicating that the two
permutations differ in one swap involving the first and second element

 

Fig. 3. The weighted Kendall distance is the weight of the shortest path
between two permutations, with edges having possibly different lengths
(weights). Edges are labeled by the adjacent swaps used to move along the
vertices

In a companion article (Farnoud et al., 2012), we presented exten-
sions of the WBGM and PR aggregation methods for weighted Kendall
distances. Here, we will pursue the WBGM framework, and propose a
new method to compute the weights  of edges (swaps) based on
the p-values of the genes within each similarity criteria ranking. We
refer to the resulting weighted model as the Hybrid Kendall method.

To start, arrange the p-values of all genes based on all similarity-
criteria into an n x m matrix P. Next, rearrange the p-values
of genes for each criteria in an increasing order, and denote the re-
sultingrearranged matrix by P* = (p*(i,  We use the
following (n — 1) x m swap weight matrix W, with entries

. . P*(i+1,j) —P*(i,j) n_,—
W(z,/) =  x d ,
indicating how much it costs to swap positions i and i+ 1 for criteria
7'. The parameters c, d are constants independent of n and m, used
for normalization and for emphasizing the TVB constraint, respect-
ively. For our simulations, we set c=10 and d 21.05, as these
choices provided good empirical performance on synthetic data. The
swap matrix assigns high weight to the top of the list.

To compute the aggregate based on the approximate dis-
tance DW(0, a), we only need to accumulate each of the contribu-
tions from the training permutations in 2. This may be
achieved by using a n X n total cost matrix C, with entry C(i, j) indi-
cating how much it would ‘cost’ for gene i to be ranked at position i:

tnax(j,¢7Pk (i))—1

Cami) 2 MM)

 

Fig. 4. A matching in a weighted bipartite graph.

The total cost matrix C is the input to the WBGM algorithm,
where C(i, i) denotes the weight of an edge connecting gene i with
position i (see Fig. 4 for an example of the bipartite graph, with the
left-hand side nodes denoting genes and the right-hand side nodes
denoting their possible positions; the minimum weight matching is
represented by bold edges). To find the minimum cost solution, or
the maximum weight matching, we used the classical Hungarian al-
gorithm (Kuhn, 1955) implemented in (Melin, 2006).

Example 4: Let n = 4 and m = 2, where the two ratings equal to
p1 = (02,03, 001,012) and p2 = (01,04, 0.2,0.35). Then

0.01 0.1
10.61 5.79
0.12 0.2
P*= , W: 4.41 4.73,
0.2 0.35
3.5 1.31
0.3 0.4

7.51 5.1 5.23 7.67

15.18 6.98 2.4 0
2.9 5.3 9.88 12.28

10.57 2.37 2.2 4.61

For example, since gene 3 was ranked 1st and 2nd by the two
criteria, C(3, 3) = 1/2(10.61 + 4.41) + 1/2(4.73) = 9.88. The min-
imum cost solution of the matching with cost matrix C, based on
the Hungarian algorithm yields the aggregate oHK = (3, 1,4,2).

2.3 The Lovész-Bregman divergence method

A previously reported distance measure represents another possible
mean for performing HyDRA. The so called Lovasz-Bregman
method (Iyer and Bilmes, 2013) calls for a distance measure between
real-valued vectors x 6 [Rio and permutations.

To define the Lovasz-Eregman divergence that acts as a distance
proxy between rankings and ratings, we start with a submodular
set-function, i.e. a function f such that for a finite ground set V,
f22V —> IR, and for all S,T C V, it holds  +f(T) 2
f (S U T) + f (S F) T). The Lovasz extension of f, fL(x), equals

fL(x) = imam» (for) — f(S,":1)),
i=1

where S17" denotes the set {ox(1),. . ., ox(i)}. Note that under some
mild conditions, the Lovasz extension is convex. Let us next define
the differential of f as

h£,(0x(i)) = NS?) — “5711)
Then the Lovasz-Bregman divergence is defined via the dot product
dr(x||t7) = x ' ((72,, — (72)

Despite its seemingly complex expression, the Lovasz-Bregman di-
vergence allows for closed form aggregation for a large class
of submodular functions  The optimal aggregate reduces to the

112 /810'S{12umo[pJOJXO'sotiemJOJutotw/2dnq wort pepeolumoq

910K ‘09 lsnﬁnV no 22

Gene prioritization via HyDRA

1039

 

ranking induced by the sum of real-valued rating vectors, ordered in
a decreasing manner.

If, as before, p(i, i) denotes the p-value of gene i under criteria 7',
we define the normalized Lovasz-Bregman score for gene i as

. m p(Li)
5 1 = 11—,
( ) .2221, p(i,/3

where the sum of p-values over criteria is normalized by the average
of the p-values for each criterion. The aggregate equals 0;, where
5 = (5(0):;-

Example 5: Let n = 4 and m = 2, where the two ratings equal to p1
= (0.2, 0.3, 0.01, 0.12) and p2 = (0.1, 0.4, 0.2, 0.35). Note that
1mg; p(i, 1) = 1/4(0.2 + 0.3 + 0.01 + 0.12) = 0.1575, and 1/n
Z; p(i, 2) = 1/4(0.1 + 0.4 + 0.2 + 0.35) = 0.2625. The Lovasz-
Bregman scores £(i), i= 1,2,3,4, equal £(1) =0.2/0.1575+0.1/
0.2625 2 1.65, £(2) = 0.3/0.1575 + 0.4/0.2625 = 3.43, £(3) = 0.01/
0.1575 + 0.2/0.2625 = 0.83, £(4) = 0.12/0.1575 + 0.35/0.2625 = 2.1.

By ordering £(i) in an ascending manner, one arrives at
CL); = (3, 1,4,2).

3 Algorithms and implementation

We now turn our attention to testing different aggregation methods
on lists of p-values generated by Endeavour and ToppGene. The
aforementioned methods rely on a set of training genes known to be
involved in a disease. The test genes are compared with all the train-
ing genes according to a set of similarity criteria, and the p-value of
each comparison is computed in the process. For example, if the cri-
terion is sequence similarity, the p-value reﬂects the z-value, describ-
ing the number of standard deviations above the mean for a given
observation. Given the p-values, the question of interest becomes
how to aggregate them into one ranking. Computing the p-values is
a routine procedure, and the challenge of the prioritization process
is to most meaningfully and efficiently perform the aggregation step.

There are two settings in which one can use the aggregation
algorithms. The first setting is cross-validation, a verification step
that compares the output of an aggregation algorithm with existing,
validated knowledge. This mode of operation is aimed at discover-
ing shortcomings and advantages of different methods. In the
second setting, termed gene discovery, the aim is to identify sets
of genes implicated in a disease which are not included in the data-
base. Clearly, cross-validation studies are necessary first steps in
gene discovery procedures, as they explain best aggregation strat-
egies for different datasets and different similarity and training
conditions.

For both methods, a list of genes involved in a certain disease
(referred to as onset genes) was obtained from the publicly available
databases Online Mendelian inheritance in Man (OMIM) (Hamosh
et al., 2005) and/or the Genetic Association Database (GAD)
(Becker et al., 2004). Both of these sources rely on the literature for
genetic association for vast number of diseases, but OMIM typically
provides a more conservative (i.e. shorter) list than the GAD. Onset
genes were tested along with random genes, obtained by randomly
permuting 19, 231 human genes in the GeneCards database (Safran
et al., 2002), and retaining the top portion of the list according to
the chosen number of test genes.

3.1 Cross-validation
We performed a systematic, comparative performance analysis of
the ToppGene and Endeavour aggregation algorithms and the newly

proposed hybrid methods. Given a list of r onset genes, we first se-
lected t onset genes to serve as target genes (henceforth referred to as
target onset genes) for validation; we used the remaining r—t onset
genes as training genes. Of the n test genes, n—t genes were selected
randomly from GeneCards (Safran et al., 2002). Our cross-valid-
ation procedure closely followed that of Endeavour and ToppGene:
we fixed t: 1, and tested all r individual genes from the pool of
onset genes, and then averaged the results. Averaging was performed
as follows: we took target onset genes one-by-one and averaged their

r
rankings over < > = r experiments. Note that in principle, one
t=1

may also choose t 2 2; in this case, the lowest ranking of the t genes
(i.e. the highest positional value that a target onset gene assumed)
should serve as a good measure of performance. One would then

r
proceed to average the resulting rankings over < ) experiments,
t

producing a ‘worst case scenario’ for ranking of target onset genes.
For fair comparison with Endeavour and ToppGene, we only used
the first described method with t = 1 and the same set of p-values as
inputs. As will be described in subsequent sections, we used t 2 2 for
gene discovery procedures.

3.2 Gene discovery

The ultimate goal of gene prioritization is to discover genes that are
likely to be involved in a disease without having any prior experi-
mental knowledge about their role. We describe next a new, itera-
tive gene discovery method. The method uses aggregation
techniques or combinations of aggregation techniques deemed to be
most effective in the cross-validation study.

Given a certain disease with r onset genes, we first identify s sus-
pect genes. Suspect genes are genes that are known to be involved in
diseases related to that under study (as an example, a suspect gene
for glioblastoma may be a gene known to be implicated in another
form of brain cancer, say meningioma), but have not been tested in

 

Algorithm 1: Gene Discovery

 

Input: Set of onset genes, 0 = {01, 02,. . ., or}, set of sus-
pect genes, 8 = {$1, $2,. . .,ss}, number of test genes,
n 6 2+, a cut-off threshold, 1 6 2+, and the number of
allowed iterations, IE Z
Output: Set of potential disease genes, denoted by A
Initialization:
0 Set i=1, A20, R: {r1,r2,...,r,,_s} — a set of ran-
domly chosen genes, training set TR=0, test set
TS = S U R
For is I do
1. Run a gene prioritization suite using the training set TR,
test set TS, and m similarity criteria

5"

Run la aggregation methods on the p-values produced in
Step 1, and denote the resulting rankings by 01,. . ., 0k
3 LetB 2 {01(1), . .,O'1(‘C)} U - - - U {0k(1),. . ., ok(t)}
4. A<—AUB;TR<—TRUB;S<—S\B
5. TS <— S U R’, R’ = set of n — |S| randomly chosen genes
6 i <— i + 1
End
Return A

 

 

 

112 /810'S{12umo[p101x0'801112u1101u101qﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

1040

M.Kim et al.

 

this possible role. Suspect genes are processed in an iterative manner,
as illustrated in Algorithm 1. In the first iteration, r onset genes are
used for training, and s suspect genes, along with n — s randomly se-
lected genes, are used as test genes. From the aggregate results pro-
vided by different hybrid algorithms, we selected 6] top-ranked genes
and moved them to the set of training genes and simultaneously
declared them as potential disease genes. The choice for the param-
eter q is governed by the number of training and test genes, as well
as the empirical performance of the aggregation methods observed
during multiple rounds of testing. The second iteration starts with
r + 6] training genes, s — q suspect genes, and n — s + q randomly se-
lected genes; the procedure is repeated until a predetermined stop-
ping criteria is met, such as the size of the set of potential disease
genes exceeding a given threshold.

4 Results

We performed extensive cross-validation studies for eight diseases
using both Endeavour— and ToppGene-generated p-values. Our re-
sults indicate that the similarity criteria that exhibits the strongest
inﬂuence on the performance of the ToppGene and the Endeavour
method is the PubMed and literature criteria, which award genes ac-
cording to their citations in the disease related publications. In order
to explore this issue further, we performed additional cross-valid-
ation studies for both ToppGene and Endeavour datasets to examine
how exclusion of the literature criteria changes the performance of
the two methods as well as our hybrid schemes. Our results reveal
that HyDRA aggregation methods outperform Endeavour and
ToppGene procedures for a majority of quality criteria, but they
also highlight that each method offers unique advantages in priori-
tization for some specific diseases.

For gene discovery, we again used Endeavour and ToppGene
p-values, and investigated three diseases—glioblastoma, meningi-
oma and breast cancer—including all criteria available. We recom-
mend as best practice a nested aggregation method, i.e. aggregating
the aggregates of Endeavour, HyDRA and ToppGene, coupled with
iterative training set augmentation.

4.1 Cross-validation

Cross-validation for HyDRA methods was performed on autism,
breast cancer, colorectal cancer, endometriosis, ischaemic stroke, leu-
kemia, lymphoma and osteoarthritis. Table 2 provides the summary of
our results, pertaining to the average rank of one selected target gene.
Table 2 illustrates that HyDRA methods offer optimal performance in
11 out of 16 tests when compared with ToppGene aggregates, and in
12 out of 16 cases when compared with Endeavour aggregates. In the
former case, the Weighted Hybrid Kendall method outperformed all
other techniques. A detailed review of our cross-validation results is
given in the supplementary data Section S1. Note that in for all eight
diseases, we performed two tests, in one of which we excluded those
similarity criteria that contain strong prior information about disease
genes, such as the ‘Disease’ and ‘PubMed’ category. Table 2 demon-
strates the significant differences in average ranks of the target genes
when literature information is excluded, suggesting that ToppGene
and Endeavour both significantly benefit from this prior onset gene in-
formation when ranking the target genes. The Supplementary data
Section 52 contains a detailed description of our results.

Another means for evaluating the performance of HyDRA algo-
rithms compared with that of ToppGene and Endeavour is to exam-
ine the receiver operating characteristic (ROC) curves of the
techniques. In this setting, we follow the same approach as used by
both ToppGene and Endeavour. Sensitivity is defined as the fre-
quency of tests in which prospect genes were ranked above a par-
ticular threshold position, and specificity as the percentage of
prospect genes ranked below this threshold. As an example, a sensi-
tivity/specificity pair of values 90/77 indicates that the presumably
correct disease gene was ranked among the top-scoring 100 — 77
= 23% of the genes in 90% of the prioritization tests. The ROCs
plot the dependence between sensitivity and the reflected specificity,
and the area under the curve (AUC) represents another useful per-
formance measure. The higher the AUC and specificity, the better
the performance of the method. Endeavour reported 90/74 sensitiv-
ity/specificity values for their chosen set of test and training genes,
as well as an AUC score of 0.866. Similarly, ToppGene reported
90/77 sensitivity/specificity values and an AUC score of 0.916 for

Table 2. Cross-validation result of Endeavour, ToppGene and HyDRA methods for eight diseases

 

Disease No. onset ndeavour Lovasz-Bregman Hybrid Hybrid
genes Borda Kendall

 

Autism 40 7.275 1 1 .2

AutismI 40 21.675 25.4

Breast cancer 10 4.6 7.1 12
Breast cancerJr 10 17.8

Colorectal cancer 20

Colorectal cancerJr 20

Endometriosis 43

EndometriosisJr 43

Ischaemic stroke 44

Ischaemic strokeJr 44

Leukemia 10 12 .
LeukemiaJr 10 20.8 22.8 24.3
Lymphoma 42 3.74 6.45

LymphomaT 42 7.71 9.55 10.71
Osteoarthritis 41 6.44 6.51 13.54
Osteoarthritisf 41 8.73 8.32 14.1

 

17.96 19.3 17.78

 
   
   
     
 
    
 

21.65 23.35 24.5 24.38
14.4 15 15.7
7.1 16.6 15.5 17.8
8.7 8.55 8.65 8.1
12.5 9.75 10.65 11.2
7.74 5.3 6.37 5.65

9.7 _ 7.63 6.86 6.6

6.05 6.18 7.3 7.07 -

8.7 _ 9.66 9.86 8.86

  
 
   
 

10.2 13.7 14.8 12.1
19.5 19.9 21.3
9.57 10.69 9
12.52 12.9 13.67

6.32 7.46 6.29
7.41 6.51 7.22

 

Diseases without ‘1" refer to results using all 18 similarity categories both in Endeavour and ToppGene. Diseases indexed by ‘1" denote results which did not

use the ‘Human Phenotype, Mouse Phenotype, Pubmed, Drug, Disease’ similarity criteria in ToppGene. Similarly, for Endeavour, the indexing by ‘1" corresponds

to exclusion of similarity criteria ‘Precalculated-Ouzounis, Precalculated-Prospectr, Text’ on Endeavour data. The scores describing the best average rank are

bolded and shaded.

112 /810'S{12umo[p101x0'801112u1101u101qﬂ2d11q 111011 pepeolumoq

9106 ‘09 lsnﬁnV no 22

Gene prioritization via HyDRA

1041

 

Table 3. AUC and sensitivity/specificity values for ToppGene, Endeavour and HyDRA rankings, pertaining to diseases listed in

table 2 using all criteria

 

 

Endeavour Lovasz- Hybrid Hybrid
Bregman Borda Kendall

 

  
 

AUC 0.908 0.899

0.93 0.911 0.947
90/75 90/75 _Sensitivity/specificity 90/69 90/63

    
 

0.91
90/ 72

 

ROC Endeavour All Criteria

 

 

 

 

 

 

 

 d” - '
.13  i ---- Endeavuw
II‘
t D E / . . . ._._uu.u... L _
I . , eves: Bregman
E
i on f f —'Hybriu:l Borda:
1.1.2 ' i ' -r-« Hybrid Kendall
D ' I
0 CL? 0.4 {1.6 ELB
1 - Sp!!th

Fig. 5 Cross-validation results: ROC curves for disease listed in table 2 using
all criteria and Endeavour data.

ROC ToppGene All Criteria

— ToppGene

mmmrr Lovasz-Elreg ma n

Sensitivit'r

--I--- Hybrid Hulda

- - - - Hybrid Kendall

 

D ELI (1.4 0.5 0.3
1 - Speciﬁclw

Fig. 6. Cross-validation results: ROC curves for disease listed in table 2 using
all criteria and ToppGene data.

their tests of interest. Our specificity/sensitivity and AUC values are
listed in Table 3, with best AUC and Sensitivity/Specificity values
shaded in gray. Note that although the AUC values appear close in
all cases, the HyDRA methods have very low overall computational
complexity (Figs. 5 and 6).

4.2 Gene discovery

The genetic factors behind glioblastoma, the most common and ag-
gressive primary brain tumor, are still unknown. We study this dis-
ease, as well as meningioma and breast cancer, in the gene discovery
phase. Our choice is governed by the fact that few publications are
available pointing towards the causes of this form of brain cancer,
and by the fact that it is widely believed that the genetic base of this
disease is related to the genetic base of the Von Hippel-Lindau
(VHL), Li-Fraumeni (LF), and Turcot Syndromes (TS),
Neurofibromatosis (N) and Tuberous Sclerosis (TS) (Kyritsis et al.,
2009). Furthermore, recent findings (Pandey, 2014) indicate that
brain cancers and breast cancers share a common line of mutations
in the family of Immunoglobulin GM genes, and that the Human
cytomegalovirus puts patients at risk of both brain and breast
cancer.

Consequently, we used genes documented to be involved in glio-
blastoma as training genes for three discovery tests. In the first test,
for the suspect genes we selected a subset of 15 genes known to be
implicated in the VHL, LF, TS, N and TS syndromes. We subse-
quently ran Algorithm1 with l: 3, s: 15, n = 100, r: 3. In the se-
cond test, we selected 18 genes known to be involved in breast

cancer as suspect genes for glioblastoma, and run Algorithm1 with
l: 3, s = 18, n = 100, r = 3. Finally, we performed the same analysis
on suspect genes known to be involved in meningiomas, by setting
the parameters of iterative HyDRA gene discovery to l = 3, s = 19,
n = 100, r = 3. The results are shown in Table 4. Note that in our al-
gorithmic investigation, we used l = 3 (i.e. top-three) ranked genes,
since this parameter choice offered a good trade-off between the size
of the union of the top-ranked genes and the accuracy of the genes
produced by the HyDRA discovery methods. The number of suspect
genes was governed by the size of the available pool in OMIM/GAD
and was targeted to be roughly 20% of the size of the test set. Such a
percentage is deemed to be sufficiently high to allow for meaningful
discovery, yet sufficiently low to prevent routine gene identification.

Table 4 reveals a number of results currently not known from
the literature. The genes KRAS and CDH1, both implicated in breast
cancer and meningioma, as well as CCND1 involved in meningioma
(as well as in colorectal cancer) appear to be highly similar to genes
implicated with glioblastoma. KRAS is a gene encoding for the K-
Ras protein that is involved in regulating cell division, and hence an
obvious candidate for being implicated in cancer. On the other
hand, CDH1 is responsible for the production of the E-cadherin pro-
tein, whose function is to aid in cell adhesion and to regulate trans-
mission of chemical signals within cells, and control cell maturation.
E-cadherin also often acts as a tumor suppressor protein. GeneCards
reveals that the CCND1 gene is implicated in altering cell cycle pro-
gression, and is mutated in a variety of tumors. Its role in glioma
tumorogenesis appears to be well documented (Buschges et al.,
1999), but surprisingly, neither KRAS nor CDH1 nor CCND1 are
listed in the OMIM/GAD database as potential glioblastoma genes.

Another interesting finding involves genes ranked among the top
three candidates, but not identified as ‘suspect’ genes. For instance,
according to GeneBank, GSTM2 regulates an individual’s suscepti-
bility to carcinogens and toxins and may suggest glioblastoma being
in part caused by toxic and other environmental conditions; KAAG1
appears to be implicated with kidney tumors, while TP73 belongs to
the p53 family of transcription factors and is known to be involved
in neuroblastoma.

5 Discussion

We start by discussing the results in Table 2. The first observation is
that the Lovasz-Bregman method performs worse than any other ag-
gregation method. This finding may be attributed to the fact that the
p-values have a large span, and small values may be ‘masked’ by
larger ones. Scaling all p-values may be a means to improve the per-
formance of this technique, but how exactly to accomplish this task
remains a question.

In almost all cases, except for Leukemia and Lymphoma, the
average rankings produced by ToppGene and the Weighted Kendall
distance appear to be almost identical. But average values may be
misleading, as individual rankings of genes may vary substantially
between the methods, as can be seen from the supplementary mater-
ial. It is due to this reason that we recommend merging lists

112 /810'S{12umo[p101x0'801112u1101u101qﬂ2d11q 111011 pepeolumoq

9106 ‘09 lsnﬁnV no 22

1042

M.Kim et al.

 

Table 4. The union of top three ranked genes from ToppGene, Endeavour and HyDRA methods for the three suspect gene discovery sets,

with the 'suspect' genes in bold

 

Test disease Iteration 1

Iteration 2

 

Breast cancer
RADS 1, TP73

VHL, LF, TS, N, TS CCND1, CD28, CD74, CDK4, CHEKZ, MLH1, MSH2,

MSH6, NBPF4, PMS2, PRNT, TSC2
Meningioma

XRCCS

AKT1, ATM, BRIP1, CDH1, CHEKZ, GSTM2, KAAG1,

CCND1, HLA-DQBI, KLF6, KRAS, TGFBI, TGFBR2,

BARD1, CASP7, ITGA4, KRAS, PALB2, PHB, SMAD7,
UMOD

ALCAM, APC, MRC1, NCL, NF1, NF2, SNCA, TAF7,
TOPBP1, TSC1, VHL

BAGE, BAP1, CAV1, CD4, CDH1, NF2, PDGFB, PSMC2,
RFCI, SAMD9L, SERPING1, SMARCBI

 

In all cases, the training genes are genes implicated in glioblastoma. The ‘Disease’ category indicates from which family of diseases the test genes were drawn.

The results of the third iteration may be found in the Supporting ﬁle Section S3.

generated by different methods as best aggregation practice.
Another important observation is that HyDRA methods have sig-
nificantly lower computational complexity than ToppGene and es-
pecially, Endeavour, and hence scale well for large datasets.

Another finding is the fact that the good performance of
ToppGene and all other methods largely depends on including prior
literature on the genes into the aggregation process. We observed situ-
ations where the rank of an element dropped by roughly 90 positions
when this prior was not available. This implies that for gene discov-
ery, it is risky to rely on any single method, and it is again good prac-
tice to merge top-ranked entries generated by different methods.
Finally, it is not clear how to optimally choose the number of training
genes for a given set of test genes, or vice versa. Choosing more
training genes may appear to be beneficial at first glance, but it creates
a more diverse pool of candidates for which some similarity criteria
will inevitably fail to identify the right genes. In this case, we recom-
mend using the Weighted Kendall to eliminate outliers, and in add-
ition, we recommend the use of a fairly large TvB scaling parameter.

Acknowledgements

The work was supported in part by the National Science Foundation (NSF)
under grants CCF 0809895, CCF 1218764, CSoI-CCF 0939370, and 105
1339388.

Conﬂict of interest: none declared.

References

Adie,E.A. et al. (2006 ) SUSPECTS: enabling fast and effective prioritization of
positional candidates. Bioinformatics, 22, 773—774.

Aerts,S. et al. (2006) Gene prioritization through genomic data fusion. Nat
Biotechnol, 24, 537—544.

Bartholdi,]. et al. (1989) The computational difﬁculty of manipulating an elec-
tion. Soc. Choice Welfare, 6, 227—241.

Becker,K.G. et al. (2004) The Genetic Association Database. Nat Genet, 36,
431—432.

Buschges,R. et al. (1999). Ampliﬁcation and expression of cyclin D genes
(CCND1 CCND2 and CCND3) in human malignant gliomas. Brain
Pathol., 9, 435—442.

Cardon,L.R. et al. (2001) Association study designs for complex diseases. Nat
Rev Genet, 2, 91—99.

Chen,]. et al. (2009) ToppGene Suite for gene list enrichment analysis and can-
didate gene prioritization. Nucleic Acids Res, 37, W305—W31 1.

De Bie,T. et al. (2007) Kernel-based data fusion for gene prioritization.
Bioinformatics, 23, i125—i132.

Dwork,C. et al. (2001). Rank aggregation methods for the web. In:
Proceedings of the 10th international conference on World Wide Web
(WWWI 0), ACM. Hong Kong, China. pp. 613—622.

Farnoud,F. et al. (2012) Nonuniform vote aggregation algorithms. In: Signal
Processing and Communications (SPCOM), IEEE. Bangalore, India. pp. 1—5.

Farnoud,F. et al. (2014), An axiomatic approach to constructing distances for
rank comparison and aggregation. IEEE Trans Inform Theory, 60,
6417—6439.

Fishburn,P. (1970) Arrow’s Impossibility theorem: concise proof and inﬁnite
voters. ] Econ Theory, 2, 103—106.

Freudenberg,]. and Propping,P. (2002) A similarity-based method for genome-
wide prediction of disease-relevant human genes. Bioinformatics, 18,
5110—5115.

Guney,E. et al. (2014) GUILDify: a web server for phenotypic characterization
of genes through biological data integration and network-based prioritiza-
tion algorithms. Bioinformatics, 30, 1789—1790.

Hamosh,A. et al. (2005 ) Online Mendelian inheritance in Man (OMIM), a
knowledge base of human genes and genetic disorders. Nucleic Acids Res,
33, D514—D517.

Iyer,R. and Bilmes,].A. (2013) The Lovasz-Bregman divergence and
connections to rank aggregation, clustering, and web ranking. In:
Uncertainty in Artiﬁcial Intelligence (UAI), AUAI, Bellevue, Washington.
pp. 1—10.

Kacprowski,T. et al. (2013) NetworkPrioritizer: a versatile tool for network-
based prioritization of candidate disease genes or other molecules.
Bioinformatics, 29, 1471—1473.

Kemeny,J.G. (195 9) Mathematics without numbers. Daedalus, 88, 5 77—5 91.

Kendall,M.G. (1938) A new measure of rank correlation. Biometrika, 30,
81—93.

Kendall,M. (1948) Rank Correlation Methods. Charles Grifﬁn and Company
Limited, London.

K6hler,S. et al. (2008) Walking the interactome for prioritization of candidate
disease genes. Am] Hum Genet, 82, 949.

Kolde,R. et al. (2012) Robust rank aggregation for gene list integration and
meta-analysis. Bioinformatics, 28, 5 73—5 80.

Kuhn,H.W. ( 1955 ) The Hungarian method for the assignment problem. Nav
Res Log, 2, 83—97.

Kyritsis,A.P. et al. (2009) Inherited predisposition to glioma. Neuro Oncol,
12,104—113.

Melin,A. (2006) The Hungarian algorithm. MATLAB Central File Exchange.
http://www.mathworks.corn/matlabcentral/ﬁleexchange/l1609-hungarian-
algorithm (8 August 2006, retrieved).

Pandey,].P. (2014) Immunoglobulin GM genes, cytomegalovirus immunoeva-
sion, and the risk of glioma, neuroblastoma, and breast cancer. Front
Oncol, 4., 238.

Perez-Iratxeta,C. et al. (2002) Association of genes to genetically inherited dis-
eases using data mining. Nat Genet, 31, 316—319.

Pihur,V. et al. (2009) RankAggreg, an R package for weighted rank aggrega-
tion. BMC Bioinformatics, 10, 62.

Popescu,M. et al. (2006) Fuzzy measures on the Gene Ontology for gene product
similarity. IEEE/ACM Trans Comput Biol Bioinformatics, 3, 263—274.

Raisali,F. et al. (2013) Weighted rank aggregation via relaxed integer pro-
gramming. In: International Symposium on Information Theory (ISIT),
IEEE. Istanbul, Turkey. pp. 2765—2767.

Risch,N. and Merikangas,K. (1996) The future of genetic studies of complex
human diseases. Science, 273, 1516—1517.

Safran,M. et al. (2002) GeneCards 2002: towards a complete, object-oriented,
human gene compendium. Bioinformatics, 18, 1542—1543.

112 /810'S{12umo[p101x0'801112u1101u101qﬂ2d11q 111011 pepeolumoq

9106 ‘09 lsnﬁnV no 22

Gene prioritization via HyDRA

1043

 

Thanassoulis,E. (2001) Introduction to the Theory and Application of Data
Envelopment Analysis. Kluwer Academic Publishers, Dordrecht.

Tifﬁn,N. et al. (2006) Computational disease gene identiﬁcation: a concert of
methods prioritizes type 2 diabetes and obesity candidate genes. Nucleic
Acids Res, 34, 3067—3081.

Turner,F.S. et al. (2003) POCUS: mining genomic sequence annotation to pre-
dict disease genes. Genome Biol, 4, R75—R75.

Warde-Farley,D. et al. (2010) The GeneMANIA prediction server: biological
network integration for gene prioritization and predicting gene function.
Nucleic Acids Res, 38, W214—W220.

Yu,S. et al. (2008) Comparison of vocabularies, representations and ranking
algorithms for gene prioritization by text mining. Bioinformatics, 24,
i119—i125.

112 /810'S{12umo[p101x0'801112u1101u101qﬂ2d11q 111011 pepeolumoq

9106 ‘09 lsnﬁnV no 22

