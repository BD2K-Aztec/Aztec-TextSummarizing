ORIGINAL PAPER

Vol. 30 no. 5 2014, pages 712-718
doi: 1 0. 1093/bioinformatics/btt602

 

Data and text mining

Advance Access publication October 21, 2013

Exploring high dimensional data with Butterfly: a novel
classification algorithm based on discrete dynamical systems
Joseph Geraci1’2’*, Moyez Dharsee3, Paulo Nuin1’3, Alexandria Haslehurstl, Madhuri Koti4,

Harriet E. Feilotter1 and Ken Evans3

1Department of Psychiatry, University Health Network, Toronto, 2Department of Pathology and Molecular Medicine,
Queen’s University, Kingston, 8Ontario Cancer Biomarker Network, Toronto and 4Department of Biomedical and
Molecular Sciences, Queen’s University, Kingston, Ontario, Canada

Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: We introduce a novel method for visualizing high dimen-
sional data via a discrete dynamical system. This method provides a
2D representation of the relationship between subjects according to a
set of variables without geometric projections, transformed axes or
principal components. The algorithm exploits a memory-type mech-
anism inherent in a certain class of discrete dynamical systems col-
lectively referred to as the chaos game that are closely related to
iterative function systems. The goal of the algorithm was to create a
human readable representation of high dimensional patient data that
was capable of detecting unrevealed subclusters of patients from
within anticipated classifications. This provides a mechanism to further
pursue a more personalized exploration of pathology when used with
medical data. For clustering and classification protocols, the dynam-
ical system portion of the algorithm is designed to come after some
feature selection filter and before some model evaluation (e.g. cluster-
ing accuracy) protocol. In the version given here, a univariate features
selection step is performed (in practice more complex feature selec-
tion methods are used), a discrete dynamical system is driven by this
reduced set of variables (which results in a set of 2D cluster models),
these models are evaluated for their accuracy (according to a user-
defined binary classification) and finally a visual representation of the
top classification models are returned. Thus, in addition to the visual-
ization component, this methodology can be used for both supervised
and unsupervised machine learning as the top performing models are
returned in the protocol we describe here.

Results: Butterfly, the algorithm we introduce and provide working
code for, uses a discrete dynamical system to classify high dimen-
sional data and provide a 2D representation of the relationship be-
tween subjects. We report results on three datasets (two in the article;
one in the appendix) including a public lung cancer dataset that comes
along with the included Butterfly R package. In the included R script, a
univariate feature selection method is used for the dimension reduc-
tion step, but in the future we wish to use a more powerful multivariate
feature reduction method based on neural networks (Kriesel, 2007).
Availability and implementation: A script written in R (designed to
run on R studio) accompanies this article that implements this algo-
rithm and is available at http://butterflygeraci.codeplex.com/. For de-
tails on the R package or for help installing the software refer to the
accompanying document, Supporting Material and Appendix.
Contact: geraci.joseph@gmail.com

 

*To whom correspondence should be addressed.

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on March 19, 2013; revised on October 2, 2013; accepted
on October 16, 2013

1 INTRODUCTION

There is an n-dimensional geometry associated with any given
dataset consisting of any number of subjects and n variables.
Depending on the choice of which variables to include or em-
phasize, the geometry changes. For example, consider a dataset
consisting of two clusters, e. g. responders and non-responders to
some treatment. Under optimal circumstances, a small set of
variables (e.g. a subset of gene expression values) can be used
to separate the groups. These selected variables determine the
relationship between patients in a geometrical way: via the dis-
tance between patients. How can one explore this space in an
efﬁcient, accurate and reproducible way so that one can study
different scenarios, i.e. different sets of variables and the corres-
ponding relationships between subjects in two-dimensions?

Butterﬂy’s most powerful feature is its ability to reveal sub-
clusters of data points even within apparently homogeneous
main clusters. Thus, Butterﬂy provides a tool for the bottom
up exploration of data in addition to a procedure that can be
used for standard training and testing protocols. Real-life
datasets are invariably heterogeneous and many powerful non-
linear data exploration tools overﬁt the data due to the presence
of noise. Mainly, this is because conventional tools require the
establishment of complex frontiers to separate classes. In the case
of Butterﬂy, the data points are transformed into a 2D represen-
tative space, which is the attractor space of the dynamical system,
and clusters are separated by straight lines. Thus, non-linear cor-
relations are identiﬁed between features, whereas the relationship
in space between subjects (e.g. patients) remains simple.

The main purpose of this work is to introduce Butterﬂy and its
efﬁcacy in handling molecular proﬁling datasets. We present it as
a data exploration and machine learning classiﬁcation tool that
can be applied to high dimensional data following any feature
reduction step, which brings down the dimensionality to around
50 or below. We do not discuss the technical nuances behind the
algorithm nor compare it with other methods in this article. We
introduce the algorithm and highlight its ability to accurately
classify data. Future research will focus on Butterﬂy’s ability to

 

712 © The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com

112 /§JO'S{numo [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘09 lsnﬁnv uo ::

Exploring high dimensional data with Butterfly

 

conserve the relationships between high dimensional data points
even after they are projected to a 2D plane. The main use of
Butterﬂy in the research setting is the ability to view the relation-
ship between subjects, e.g. patients, from the vantage of a set of
(:5) interesting variables, with the speciﬁc goal of identifying
homogeneous subgroups. Further, the identiﬁcation of the
main variables that lead to a particular classiﬁcation is returned
to the user.

Many of the modern non-linear clustering/dimensional reduc-
tion methods rely on the mathematics that drives principle com-
ponent analysis (Abdi and Williams, 2010) or k-means (Larraaga
et al., 2006). Because the mathematics that drives Butterﬂy is
fundamentally different from these methods, we have found
that exploratory analyses based on Butterﬂy and one of these
other approaches provides comprehensive analyses and that
Butterﬂy complements these established approaches effectively.

2 BACKGROUND

The desire for accurate and fast classiﬁers has been inspired by
the recent inﬂux of high dimensional datasets from the medical
sciences and other ﬁelds. Bioinformatics makes regular use of
machine learning algorithms including decision trees, support
vector machines and regression methods (Larraaga et al.,
2006), as they supply researchers with a powerful armament
for building classiﬁers. An emerging challenge is the need to in-
tegrate different types of data including genomic [messenger
RNA (mRNA), microRNA (miRNA) expression, epigenetic
changes, copy number variants, single nucleotide polymorph-
ism], proteomic (mass spectrometry) and clinical data.
Platforms that could simultaneously consider heterogeneous
variables in an unbiased way are going to be required to effect-
ively use data produced from multiple high-throughput technol-
ogies such as microarrays, array comparative hybridization,
high-throughput sequencing and mass spectrometry for the
same individual. Each of these technologies is a different
window on the genome, and a method that can effectively
merge data from each of these sources will provide more infor-
mation about our molecular machinery than any method that
uses information from only a single source (Hamid et al., 2009).
Further, it is certain that this trend will continue as additional
types of data are generated in studies, e.g. metabolomic. Thus, a
method that is capable of efﬁciently working with high dimen-
sional data regardless of data type is a desirable commodity.

2.1 Approach and technical preliminaries

Formally, a dynamical system is the triple (I, M, (b), where I is a
subset of [R (in the continuous case) or ZJr (in the discrete case)
and M the space over which the mapping ¢ is deﬁned, i.e.
¢ : I x M —> M. The interval I is to be thought of as time and
this, as mentioned, can either be discrete or continuous, and M is
the space where the variables are deﬁned. Thus in general, one
can envision ¢ as describing the motion of a point in the space M
as a function of time. As an example one can consider the ex-
pression levels of a set of genes as time varies. In this case one
could deﬁne the system by ¢ : (0, T) x IR" —> IR". The n-dimen—
sions real space, IR", represents the fact that one starts with initial
expression values for the n genes as a real-valued vector

(i1, i2, ...,i,,), which evolves over time to the expression levels
(f1,f2, ...,f,,) at time T. ¢ contains the information regarding
how these particular genes will be expressed from time 0 to
time T.

The particular type of dynamical system that our classiﬁcation
algorithm is based on is referred to as an iterated function system
(IFS). This is a type of discrete dynamical system in that the time
evolution of the system occurs in discrete steps. Given a starting
point (or points in general) in the space M, the IFS consists of a
ﬁnite set of mappings that transforms the point. Each ‘time step’
corresponds to the selection of a function and its application to
the last mapping of the point. The best way to elucidate the idea
is to give a famous example that results in the Barnsley fern
(Fig. 1). Here the mapping referred to as ¢ actually consists of
the application of the following four transformations:

T1(x, y) = (0.8536 —l— 0043/, — 0.0436 + 0853/ +1.6)
T2(x, y) = (0.2x —l— 0.26y, 0.2336 + 0.2232 + 1.6)
T3(x, y) = (—0.15x —I— 0.2832, 0.2636 + 0.24y + 0.44)
T4(x,y) = (0, 0-16y)

Each of the T ,- is a mapping from [R2 —> [R2 and at each time
step one chooses one of these mappings and applies it to the
point that results from the previous application of a chosen
transformation. The passage of discrete time corresponds to iter-
ating this process over and over starting from an initial point. To
create the Barnsely fern, one starts with a point in the plane R2,
say the origin (0,0), and then at each time step one of the T ,- is
chosen with a given probability. T1 is chosen with a probability
of 85%, T 2 and T 3 are chosen with a probability of 7% each and
T4 is chosen 1% of the time. One iterates the process and ends up
with a chain of transformations starting with some mapping
applied to (0,0) and then another applied to the result of that
mapping and so on. Mathematically, after ﬁve iterations the
chain could look like T2(T1(T1(T4(T1(0,0))))) that is another
point in R2. To get the image in Figure 1, one keeps all the
resulting points for 30 000 iterations.

This process of randomly iterating over functions is commonly
referred to as the chaos game (Barnsley, 2006), and the resulting
image of such a process is known as an attracting set in math-
ematics. Another interesting example of a chaos game that can
be introduced non-technically is the following process that we
shall refer to as the dice chaos game. Take a triangle and label
one of the vertices 1 and 2 (12), the other vertex 3 and 4 (34) and
the ﬁnal one 5 and 6 (56). Now beginning on any vertex, say
vertex (12), roll an unbiased die and observe the result. Say it is
either a 3 or a 4. Find the midpoint between vertex (12) and (34)

Fig. 1. The Barnsley fern created by iterating the transformation T l—T 4
as described, 30 000 times

 

713

112 /310's113umo [p.IOJXO'SOIlBIIIJOJLIIOIQ/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘09 lsnﬁnv uo ::

J. Geraci et al.

 

and mark that point and call it P1. Now repeat. Say you roll a 1
or 2. Find the midpoint between P1 and (12) and place a point
there and call it P2 and continue. The attractor set for this pro-
cess is known as the Sierpinski triangle (Fig. 2) and there is also
an IFS to generate it.

2.2 Previous work

The algorithm we present is based on a dynamical system
(Martelli, 1999) that is a novel instance of the chaos game.
This particular algorithm was developed following the realization
that one could drive data through a variety of dynamical systems
and observe the resulting behavior. Some dynamical systems
have the ability to capture patterns inherent in the data through
a memory-type mechanism. An example of such a phenomenon
will become clear after we present the details behind the
algorithm.

There are several algorithms that are closely related to
Butterﬂy. As a related aside, we ﬁrst mention a class of algo-
rithms that are close in spirit, in that they may be viewed as
belonging to the class of data-driven dynamical system
approaches. We believe that this approach has never been for-
malized, but there do exists a set of algorithms designed for data
analysis based on cellular automata (W olfram, 2002). These are
discrete dynamical systems different from the ones used in
Butterﬂy, however, we include some references for the interested
reader (Fawcett, 2008; Ultsch, 2000, 2002).

The construction of Butterﬂy came about through an attempt
to study protein and DNA sequences, far before we turned our
sights to general data analysis. During the study of DNA se-
quences, several researchers have had the idea to replace the
usual chaos game (described previously as the dice chaos
game), with a square whose vertices are labeled A,G,C and T.
One would then ‘play’ the chaos game with the DNA sequence of
interest. The sequence would drive the dynamical system instead
of a die. This is precisely what the author in Jeffrey (1990) pre-
sented many years before our efforts. This line of research led to
the construction of a novel metric for protein sequences by the
ﬁrst author (unpublished), which eventually led to Butterﬂy.

Several publications exist dealing with the analysis of biolo-
gical sequences such as Basu et al. (1997), Dutta and Das (1992)
and Joseph and Sasikumar (2006) and recently Almeida et al.
(2012) and Vinga et al. (2012). These articles capture the essential
nature behind Butterﬂy: they all use the chaos game method-
ology and drive sequence data through it, via various innov-
ations, to detect patterns. Our idea was to extend this beyond
the analysis of sequence data to the analysis of general datasets in

:‘I’k
111%

" A};
 1;. 2. £11.21,
J. {In ,4}. .15. .ﬁﬂ.
st.§?...11h;:1tarmx
x 1  El.

Lira-1;. In ...... “,1

 

gm. 1.1.111, 212:1 111.11.
.1311“. 5*» .1“ .

XL n31. 1'
. 0.5:. fan-f}. I'L. .'. .._
  51.15}. h 2"“ 5's 15's. 3': A? 4”».

 

Fig. 2. The Sierpinski triangle is the attracting set of the triangle dice
chaos game

an essentially agnostic way. The main advancement we present is
a construction that allows one to move from a 4our feature space
(A,G,C,T) or 20 feature space (amino acids) to the analysis of
general data consisting of many variables.

Our algorithm is also distantly related to methods developed
from the perspective of functional data analysis (FDA) (Chen
et al., 2011; Wu and Mller, 2010), which was originally created to
statistically analyze continuous data. These two articles represent
recent advances that take advantage of the machinery inherent in
the ﬁeld of FDA (Ramsay and Silverman, 2005), by converting
high dimensional data to functional data (imagine curves in some
space that the data are embedded in). Even though these meth-
ods are not based on dynamical systems, they do use functional
analysis. Like Butterﬂy, these methods use the mathematics of
functions to analyze high dimensional data. The main difference,
however, is that Butterﬂy uses a discrete dynamical system that is
essentially an IFS to process discretized data, and these FDA-
based methods translate data into functions and then use the
methods established in FDA, e.g. functional principal compo-
nent analysis (Shang, 2013).

3 METHODS

We report results on three datasets: a synthetic dataset that we created in
Mathematica (shown and described in the Supporting Material and
Appendices), a publicly available gene expression lung cancer dataset
and an integrated ovarian cancer dataset that our group at Queen’s
University generated and analyzed.

The lung cancer dataset (gene expression microarray data) we used is
publicly available at GSE10245 (2009) and GSE18842 (2010). From
GSE10245 (2009), we extracted 40 lung cancer patient samples with histo-
logical subtype adenocarcinoma (AC) and 18 with histological subtype
squamous cell carcinoma (SCC). From GSE18842 (2010), we extracted
14 ACs and 32 SCCs for a total of 54 ACs and 50 SCCs.

The ovarian dataset was generated by our group. Ethics approval was
obtained from Queen’s University and the Ottawa Health Research
Institute Research Ethics Boards. Tumor samples were obtained from
the Division of Gynecologic Oncology Ovarian Tissue Bank and the
Ontario Tumor Bank. All tumors were chemonaive at the time of collec-
tion. Post debulking surgery, patients received combination chemother-
apy with carboplatin and paclitaxel. Histological classiﬁcation of the
tumors was performed following World Health Organization criteria,
and disease stage was determined according to the International
Federation of Gynecology and Obstetrics guidelines. Fourteen tumours
were classiﬁed as chemosensitive (progression-free interval of >18
months), and 11 tumours were classiﬁed as chemoresistant (progres-
sion-free interval of <8 months). Histopathological examination of
tumor sections identiﬁed >70% tumor in all samples.

For the gene expression proﬁling, total RNA was isolated from
tumour samples using a combination of Trizol (Invitrogen, CA, USA)
and Qiagen RNA isolation kit (Qiagen Inc., Mississauga, CA, USA) as
per manufacturer’s instructions. RNA integrity was assessed using RNA
6000 nano chips on a Agilent 2100 Bioanalyzer (Agilent Technologies,
USA) and concentration was determined using a NanoDrop ND-100
spectrophotometer (NanoDrop Technologies, USA). All downstream
microarray analysis was completed using Affymetrix Human Genome
U 133 Plus 2.0 arrays (Affymetrix Inc., USA) as per manufacturer’s in-
structions, at the Centre for Applied Genomics (The Hospital for Sick
Children, Toronto, ON, Canada). Our miRNA data were derived from
the Human miRNA Microarray Kit (V3) and the methylation data from
Human Promoter 1.0R Array.

 

714

112 /310's112umo [pJOJXO'SOIlBIIIJOJLIIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Exploring high dimensional data with Butterfly

 

3.1 The algorithm

A dataset is assumed to be an n X N matrix where there are N subjects
(patients for example) and 11 features (genes for example). Each entry of
the matrix will have a number indicating a level (continuous or discrete,
i.e. low, medium, etc) or the presence/absence of a feature (single nucleo-
tide polymorphisms for example). For this description of Butterﬂy, we
are assuming we have continuous data.

We provide an outline of the algorithm below. When reviewing the
outline, recall the previously described dice chaos game on the triangle.
The chaos game dynamical system, whose attracting set is the Sierpinski
triangle, has an alphabet consisting of {1, 2, 3, 4, 5, 6}, which correspond
to the six faces of a die. Instead of this alphabet, we will be interested in a
way to capture the nature of general datasets. In the simple triangle chaos
game, each vertex of the triangle is assigned two numbers from the al-
phabet {1, 2, 3, 4, 5, 6}, e.g. {1, 2} —> vertexl. The previously cited articles
that used the chaos game either dealt with the alphabet {A, G, C, T} or
the 20 amino acids. The mappings to a vertex of some polygon is straight-
forward in these cases, e. g. each nucleic acid can be mapped to a vertex of
a square in a one to one way and in the cases of the amino acids, one
could map several amino acids to the same vertex or use an icosagon for
example.

In our case, the ﬁrst issue is to understand how we are to map our data
to some space so that data can drive the chaos game. We chose to divide
our data into eight quantiles and label these from lowest to highest
{0, 1, 2, .. . , 7}. Each feature (dimension) will need to be considered and
each can be in one of the eight states. Consider f,- (feature 1') for example,
and note that, for a particular subject, it will be in one of eight quantiles.
Thus, the geometry that the system will run this on will need to have
enough space for an alphabet of size n X 8. Choosing a polygon with that
many vertices turns out not to be effective. The main issue with choosing
an appropriate geometry to accommodate all these features is that after
the algorithm projects the data to a 2D surface, one requires these pro-
jected points to cluster in sections that are far enough from each other so
that they are distinguishable. Mathematically, the geometry chosen de-
termines the characteristics of the 2D space to which the high dimensional
points (subjects) are mapped. Thus, we need a way to ensure that points
will cluster near other similar points and far enough away from dissimilar
points so that they are classiﬁed correctly. In other words, we need to
ensure that the clustering is discriminating.

3.1.] The underlying geOmetry The geometry we use is given in
Figure 3 and is to be placed on R2 so that each node is given a 2D
coordinate. This shape captures the following information: the large
nodes labeled from L (low) to H (high) represent the level of the features
(the eight quantiles) and around each of these there are smaller star
shaped ‘satellite’ nodes, which are the actual features, e.g. genes, proteins,
ﬁnancial predictors and so forth. The blue path in three shows a hypo-
thetical dynamical path that some data impose on the system. It begins at
some feature that has a medium low (L1) magnitude (relative to that
feature’s level across all subjects) then moves to some other feature that
has a high medium (M2) magnitude and continues. We ensure that

Fealures
II=5I ennui - a -. - 0 .,~.

  

.o._

uHZ.

Hem-a Duamll:

 

. M21.
E _ _ c: 
Emma-11m
u . 1
Elihu-nauanll: Tnmchmnlm

Fig. 3. This represents the geometry that the chaos game is played on in
Butterﬂy

adjacent quantiles are not nearest neighbors in this geometry as this en-
sures that differences are captured by the dynamical system. Butterﬂy
does not use the usual divide by two rule of the classical chaos game,
but uses a rule that changes as the data are processed. For a given ﬁxed
permutation of the features, the system proceeds and can be terminated
after any number of steps. Butterﬂy terminates the search after every
feature, evaluates the clustering and continues. Our in house version re-
turns the top clustering results. An example will make this clearer.

Suppose we have a system that proceeds as indicated in Figure 3 for a
particular subject. The string that Butterﬂy processes in this case is given
by flLlf2M2f3M2f4L2f5L2f6L2ﬂL2J8L2J9H2, where dots are
used to separate the steps (or characters that comprise the word).
f3M2, for example, just represents feature three in the ﬁfth quantile.
This string of variables, coupled with the quantile that maps from its
level (or category), informs the dynamical system’s next move. Each char-
acter causes the dynamical system to move toward the corresponding
labels in the geometry illustrated in Figure 3, according to the system’s
mathematical rules. Imagine that each character (e. g. f3M 2) tells a virtual
ball (corresponding to one patient or subject) to move toward the node
labeled as feature f in quantile M2. This is repeated for every character
(i.e. variable or feature). A snapshot of this virtual ball’s position in this
geometry is recorded for every step/character/feature, until features run
out. This is performed for all subjects and the result for every termination
point (e.g. the snapshot at a feature) will be a 2D clustering of all subjects.

The algorithm assesses how well the subjects cluster beginning with the
third feature as it requires the ﬁrst two features to initiate. Thus, in the
given example, it processes and terminates at f3M2, evaluate how well the
subjects cluster and then continue to process f4L2, as this is the next step
in the string. We shall refer to this cutoff as the CO-pt (Cut-Oﬂpoint).
Again it will evaluate how well the subjects cluster and continue until the
string terminates. The number of elements in the string is determined by
how much preliminary feature selection Butterﬂy is asked to perform. In
the lung cancer example presented later, 77 genes remained after the
initial feature selection step. Butterﬂy found a model including 13 of
these genes which, provided an excellent clustering. Thus, a string of
length 77 was input and Butterﬂy returned 11 genes after it found a
clustering with an overall accuracy of 90%.

The actual choice of the geometry given in Figure 3 was constructed in
such a way as to allow for clusters to form far enough from each other so
that a cluster discriminating algorithm would be able to easily score dif-
ferent models. The underlying geometry deﬁnes the space that the dy-
namical system drives the data through and therefore where clusters will
form. The algorithm moves subjects through this space according to the
corresponding set of variables, and subjects with similar patterns of vari-
ables will arrive at similar areas in the deﬁned geometry. The particular
conﬁguration given in Figure 3 is one of many possible conﬁgurations.
We encourage others to experiment with different conﬁgurations and
supply this one as a proof of principle to the overall technique and as
one that has been highly effective in practice.

A vital issue is with consistency. As long as the same geometry is used
for all subjects, then an evaluation of the clusters is possible. The rela-
tionship between different underlying geometries and the kinds of clus-
tering that will occur requires further exploration. Our particular
construction was arrived at by a desire to handle many variables while
maintaining the memory-type mechanism inherent in the chaos game.
What are recorded in this particular manifestation of Butterﬂy are the
ﬁnal points of the subject’s dynamics. Owing to the memory mechanism
of this dynamical system, the ﬁnal point corresponds to the particular
values of the variables: this is precisely where the dimension reduction
occurs.

Note that many more genes can be included, but the feature space will
be larger and will take longer to explore before acceptable clusters are
discovered and a set of discriminating features extracted. Different per-
mutations of the order that the features are input into Butterﬂy allow one

 

715

112 /810's112umo [pJOJXO'SOIlBIIIJOJLIIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

J. Geraci et al.

 

to explore different combinations of genes. It is clear that it would take an
impossible amount of time to input every possible permutation in the
order of a set of features. However, it appears that this is not necessary
with Butterﬂy to extract some meaningful information from data. This
has to be studied further and it is beyond the scope of this article, how-
ever, we shall make an effort to clarify this matter. Using a ﬁlter feature
selection method, such as our univariate approach, is common practice
and one can use this simple method or a more sophisticated procedure for
selecting sets of features. The main point is that the permutation ap-
proach would be inordinately expensive for a large number of variables,
and thus this particular method works well when the feature selection
ﬁlter returns between 30—50 variables. Of course the algorithm will not
attempt to visit all 1032 permutations of a list of 30 variables. With just 50
different random permutations, the more successful models can be ex-
tracted and the feature sets examined, compared and reduced. What
makes this possible is the aforementioned ‘memory’ that this particular
dynamical system exhibits: the string of variables can be looked at as
existing in chunks of length d, and if a variable appears in one of these
chunks [or regions of inﬂuence (ROIs), see Fig. 4] it inﬂuences the con-
ﬁguration of the dynamical system in accordance with how close it is to
the CO-pt. This provides a massive reduction in the number of permu-
tations required to ﬁnd a set of features that differentiates the given
groups. In practice, the models that do best are extracted and their fea-
tures truncated to within a few ROIs of the CO-pt, and the process re-
peated. This process is iterated to extract a set of features that together
can differentiate the groups of interest.
An overview of the Butterﬂy Algorithm

0 Run a feature selection method on the data and reduce the number
of features to F, which is selected by the user.

0 Create a new dataset with the reduced number of features. Note that
this may be a dataset constructed from different sources, e. g. mRNA,
methylation, miRNA, neuroimaging and so forth.

0 Discretize the data into quantiles, i.e. each feature gets ranked across
all subjects. We have found using eight quantiles is effective in
practice.

0 Map each subject to a string that captures the feature and quantile
information as in our example earlier mentioned in the text:

flLlf2M2f3M2f4L2f5L2f6L2ﬂL2f8L2j9H2

0 Each word segment or character, e.g. f6L2, is given a 2D coordinate
in R2 on the space given in Figure 3.

0 Run the aforementioned dynamical system. Each subject value drives
the path of a curve through the geometry given in Figure 3.

0 An array, Models, records different ﬁnal values achieved at different
feature randomizations and different features to ‘cut-off the dy-
namics or progression of the path. More clearly, the process is
halted at some CO-pt for all patients. That is, a feature is chosen
to terminate the process. The closest preceding features before the
CO-pt are the most signiﬁcant, as they have had the most inﬂuence.

0 The ﬁnal points for each subject, which corresponds to the (x, y)
coordinate of the dynamical system achieved at the CO-pt, is

Regions of Inﬂuence

rlmll sauna 1r lull-I1:

l Mums-“nu: uuuu u'- uuuuuuuu m-
I

1

ﬁlnlrmlurl'lnmre- Mgllu'hdlmmnriﬂMIi-ull nnnnn a. n.
m urn-m mun.- m Mutton ummn. n In In. ecu-:1. n:
'1‘.” INF. - I'Iﬂl'II Irrsr'l'. | In

Fig. 4. Sets of features become chunked into ROIs

recorded. Thus, the aforementioned array Models are constructed
and holds all models that correspond to feature randomization and
different CO-pts.

0 An additional method is used to evaluate the models via how well the
data clusters. A linear support vector machine (SVM) (Larraaga et
al., 2006) is performed on all models in Models and evaluated via
cross-validation (other methods have been used as well and an alter-
nate version of Butterﬂy will be made available). The top models,
according to the training set, are returned to the user, along with the
corresponding top features, i.e. the features closest to the particular
CO-pt for each model.

The complexity of this algorithm assuming that a dataset has N sub-
jects and 11 variables is 0((N-102) and is amenable to parallelization.
Please refer to the Supporting Materials and Appendices for more details
on the complexity and notes regarding using the accompanying R pack-
age, instructions on how to run it on RStudio and other technical issues.

4 RESULTS ON DATA

For a description and visualization of the synthetic dataset,
please see the Supporting Materials and Appendices Section.

4.1 Lung cancer data

After running Butterﬂy on the aforementioned lung cancer
dataset, we arrived at a model illustrated in Figure 5. For the
purpose of this article, we ﬁrst ran a univariate feature selection
algorithm [a Matlab version is freely available at (http://mat1ab
datamining.blogspot.ca/2006/12/feature— selection- phase-
1- e1iminate.html)], used the top 77 discriminating features,
then used Butterﬂy to identify a model using the following
genes: GBP6, CLCA2, ATPllA, COL4A6, KRTS, KRT6B,
XXYLTl (C3orf21), TRIM29 and SOX2 where the importance
of inﬂuence increases as you proceed through the list. Each of the
genes on this list has been associated with cancer (e. g. Lu, 2010;
Zhou, 2012) providing face validity for this simpliﬁed version,
despite the fact that it relies heavily on ﬁnding discriminating
univariate features. Butterﬂy has the ability to quickly project
high dimensional data onto 2D data while still preserving the
relationships between the patients. This means that in its simplest
form, one searches through many models (of low dimension) and
extract those that score highly on a training set, and thus extract
features on the basis of which features are nearest to the particu-
lar CO-pt, mentioned in Section 3.1. Note that the separation
between groups is achieved by a straight line. Even though the
relationship between patients and variables are non-linear, the
resulting 2D model is simple and thus more likely to generalize.

 

I I
II
HI I : . I: I
o. I- q .pl'u
an t I
I I H I
In ‘ .-
7 I I I
an.  = if
1D: ‘ . . . I 1 c
1 J.-
m .41: an an me f 15:

Fig. 5. The result of running Butterﬂy on a 77 gene lung cancer dataset

 

716

112 /810's112umo [pJOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Exploring high dimensional data with Butterfly

 

III
.-
I I
.'I
I
I:
I
f

Fig. 6. A model produced on a 48 patient lung cancer dataset. Blue in-
dicates AC cases, and red indicates SCC cases

b I: . I.-
.. .'-
I 'l .

2 '-' - ' f
:' - _ .

l - I"

Fig. 7. The model shown in Figure 6 applied to a test set consisting of 28
AC cases and 28 SCC cases

To demonstrate training and test set reproducibility, we in-
clude two ﬁgures (Figs. 6 and 7) arrived at by splitting the
above dataset into a training and test set. The training set con-
sists of 26 AC cases and 22 SCC cases, and the test set consists of
28 cases of each type. This model had an overall accuracy of over
95% on the training set, as it misclassiﬁed two AC cases. The
model performed with an accuracy of 85% on the test set, as it
misclassiﬁed four cases in each type. One can download
butterﬂyTest.R from http://butterﬂygeraci.codeplex.com/
SourceControl/latest to apply a particular model to a test set
found from running ButteRﬂy.R on a training set.

4.2 Ovarian cancer

Butterﬂy is effective with integrated datasets consisting of differ-
ent types of data. Our goal was to extract relevant biological
information with respect to how well 25 ovarian cancer patients
responded to cisplatin treatment. Our dataset consists of just
over 3300 methylation probes (after a reduction), ~900
miRNAs and ~19 000 genes. Using various univariate feature
selection tools, we assembled a dataset of 356 features coming
from each modality, i.e. 124 mRNA features, 82 miRNA fea-
tures and 150 methylation probe features. Various models were
constructed and their features extracted. Here we report on the
model that is given in Fig. 8 where it correctly separated 9 of 11
responders and 12 of 13 non-responders. The model was con-
structed by inputing this 356 feature dataset into our algorithm
and visually exploring the top models that were output.

The feature set we extracted from the model given in Figure 8
was as follows:

0 miR-l42 (micro-RNA)
o CEP192 (gene)

0 DLG2 (gene)
0 CENPQ (gene)

 

Fig. 8. Integrating mRNA, miRNA and methylation data for an ovarian
cancer project. The red points indicate 11 women who responded favor-
ably to cisplatin treatment, and the blue represents 14 women who did
not

alt-JEEEI-JI'H‘

CF "F'L'J Ear:

Fig. 9. Diagram of CENPQ’s involvement in various biological processes
related to cancer. Reference: http://biograph.be/concept/graph/C0033308/
CI82470

in addition to four methylation probes that are still being stu-
died. These features have been implicated in the literature and
even have relevance for chemoresistance (Andreopoulos, 2012;
Gomez-Ferreria et al., 2007; Sahab et al., 2010). If one refers to
Figure 9, one can see the various ways CENPQ can affect cancer
progression, including through the mitotic stages.

5 CONCLUSION

In this article we presented an algorithm for the visualization,
clustering and classiﬁcation of data that is based on a simple
discrete dynamical system. The novel aspect of the classiﬁcation
protocol is the dynamical system portion sandwiched between a
feature selection ﬁlter and model evaluation algorithm. The it-
erative dynamical system transforms a multidimensional dataset
into a 2D representation without using typical geometric and
algebraic approaches found in other methods. Thus, Butterﬂy
is ultimately a data visualization tool that allows researchers to
probe their data by reviewing a set of high ranking models and
observing the relationships between subjects in a 2D space. Each
model is based on giving priority to a set of features and provid-
ing a human readable representation of the resulting relation-
ships between subjects. However, our methodology allows for
both supervised and unsupervised machine learning. The main
beneﬁts of using Butterﬂy to build predictive models is that only
a simple linear split in a 2D space is required to separate groups,
and this minimizes the chances of over ﬁtting noise in data and
its ability to provide a human readable representation of the
structure of the data including subclusters within expected

 

717

112 /810's112umo [pJOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

J. Geraci et al.

 

clusters. The beneﬁt over support vector machines (Larraaga et
al., 2006) is that with Butterﬂy this is always done in a 2D space,
where as the support vector machine has to establish the separ-
ating contour in a space whose dimension is equal to the number
of variables considered. Butterﬂy has a lot in common superﬁ-
cially with principal components analysis (Abdi and Williams,
2010), but they are sufﬁciently different mathematically to justify
using both as data exploration tools. In fact, principal compo-
nents analysis can be used as a variable reduction tool before
using Butterﬂy to examine subgroups. Butterﬂy’s ability as an
effective multivariate feature selection tool will be the subject of a
future publication.

ACKNOWLEDGEMENTS

Joseph Geraci thanks Dr Igor Jurisica at the Ontario Cancer
Institute who helped him to initiate the project that eventually
transformed into Butterﬂy. His support and advice were invalu-
able. He also thanks Dr Sidney Kennedy and Dr Jonathan
Downar who were supportive of this endeavor during his time
as a fellow in the Department of Psychiatry at the University
Health Network. He also thanks Dr Jeremy Squire for allowing
him access to the integrated ovarian cancer dataset. The authors
would also like to thank the ovarian cancer patients who have
donated tumour to the Division of Gynecologic Oncology
Ovarian Tissue Bank at the Ottawa Hospital Research Institute.

Funding: NSERC IRDF 2010-2012, Eli Lilly Canada Fellowship
2012 - 2014, Ontario Brain Institute and The Buchan Family
Foundation. The Ontario Institute for Cancer Research through
funding provided by the Government of Ontario.

Conﬂict of Interest: none declared.

REFERENCES

Abdi,H. and Williams,L. (2010) Principal component analysis. Wiley Interdiscip.
Rev. Comput. Stat., 2, 433—459.

Almeida,J. et al. (2012) Fractal mapreduce decomposition of sequence alignment.
Algorithms Mol Biol, 7, 12.

Andreopoulos,B.A.D. (2012) Integrated analysis reveals hsa-mir-142 as a represen-
tative of a lymphocyte-speciﬁc gene expression and methylation signature.
Cancer Inform, 11, 61—75.

Bamsley,M. (2006) Super Fractals. Cambridge University Press, New York.

Basu,S. et al. (1997) Chaos game representation of proteins. J. Mol Graph Model,
15, 279—289.

Chen,K. et al. (2011) Stringing high-dimensional data for functional analysis. J. Am.
Stat. Assoc., 106, 275—284.

Dutta,C. and Das,J. (1992) Mathematical characterization of chaos game represen-
tation. new algorithms for nucleotide sequence analysis. J. Mol Biol, 228,
715—719.

Fawcett,T. (2008) Data mining with cellular automata. ACM SIGKDD Explor.
Newslett, 10, 32—39.

Gomez-Ferreria,M. et al. (2007) Human cep192 is required for mitotic centrosome
and spindle assembly. Curr. Biol, 17, 1960—1966.

GSE10245. (2009) Geo lung cancer data set - gse10245, http://www.ncbi.nlm.nih.
gov/geo/query/acc.cgi?acc =GSE10245 (18 March 2013, date last accessed).
GSE18842. (2010) Geo lung cancer data set - gse18842, http://www.ncbi.nlm.nih.
gov/geo/query/acc.cgi?acc =GSE18842 (18 March 2013, date last accessed).
Hamid,J. et al. (2009) Data integration in genetics and genomics: methods and

challenges. Hum Genomics Proteomics, 2009, doi:10.4061 /2009/ 869093.

J effrey,H. (1990) Chaos game representation of gene structure. Nucleic Acids Res,
18, 2163—2170.

J oseph,J . and Sasikumar,R. (2006) Chaos game representation for comparison of
whole genomes. BM C Bioinformatics, 7, 243.

Kriesel,D. (2007) A Brief Introduction to Neural Networks. http://www.dkriesel.com
(17 April 2013, date last accessed).

Larraaga,P. et al. (2006) Machine learning in bioinformatics. Brief Bioinform, 7,
86—1 12.

Lu,Y. et al. (2010) Evidence that sox2 overexpression is oncogenic in the lung. PLoS
One, 5, 611022.

Martelli,M. (1999) Introduction to Discrete Dynamical Systems and Chaos. Wiley-
Interscienoe, Hoboken, New Jersey, USA.

Ramsay,J. and Silverman,B. (2005) Functional Data Analysis. 2nd edn. Springer,
New York.

Sahab,Z. et al. (2010) Tumor suppressor rarresl regulates d1g2, pp2a, vcp, ebl, and
ankrd26. J. Cancer, 1, 14—22.

Shang,H. (2013) A survey of functional principal component analysis. AStA Advances
in Statistical Analysis, Springer.

Ultsch,A. (2000) An artiﬁcial life approach to data mining. In: Proceedings of
European Meeting of Cybernetics and Systems Research, Wein.

Ultsch,A. (2002) Data mining as an application for artiﬁcial life. In: Proceedings of
Fifth German Workshop on Artificial Life. pp. 191—197.

Vinga,S. et al. (2012) Pattern matching through chaos game representation: bridging
numerical and discrete data structures for biological sequence analysis.
Algorithms Mol Biol, 7, 10.

Wolfram,S. (2002) A New Kind of Science. Wolfram Media Inc., Champaign, IL.

Wu,P. and Mller,H. (2010) Functional embedding for the classiﬁcation of gene
expression proﬁles. Bioinformatics, 26, 509—517.

Zhou,Z.Y. et al. (2012) Signiﬁcance of trim29 and ﬁ-catenin expression in non-
small-cell lung cancer. J. Chin. Med. Assoc, 75, 296—74.

 

718

112 /810's112umo prOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

