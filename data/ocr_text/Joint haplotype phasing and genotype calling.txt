ORIGINAL PAPER

Vol. 29 no. 19 2013, pages 2427-2434
doi:10. 1093/bioinformatics/btt418

 

Genetics and population analysis

Advance Access publication August 13, 2013

Joint haplotype phasing and genotype calling of multiple
individuals using haplotype informative reads

Kui Zhang* and Degui Zhi*

Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham, Birmingham,

AL 35294, USA

Associate Editor: Gunnar Ratsch

 

ABSTRACT

Motivation: Hidden Markov model, based on Li and Stephens model
that takes into account chromosome sharing of multiple individuals,
results in mainstream haplotype phasing algorithms for genotyping
arrays and next-generation sequencing (NGS) data. However, existing
methods based on this model assume that the allele count data are
independently observed at individual sites and do not consider haplo-
type informative reads, i.e. reads that cover multiple heterozygous
sites, which carry useful haplotype information. In our previous work,
we developed a new hidden Markov model to incorporate a two-site
joint emission term that captures the haplotype information across two
adjacent sites. Although our model improves the accuracy of genotype
calling and haplotype phasing, haplotype information in reads covering
non-adjacent sites and/or more than two adjacent sites is not used
because of the severe computational burden.

Results: We develop a new probabilistic model for genotype calling
and haplotype phasing from NGS data that incorporates haplotype
information of multiple adjacent and/or non-adjacent sites covered
by a read over an arbitrary distance. We develop a new hybrid
Markov Chain Monte Carlo algorithm that combines the Gibbs sam-
pling algorithm of HapSeq and Metropolis—Hastings algorithm and is
computationally feasible. We show by simulation and real data from
the 1000 Genomes Project that our model offers superior performance
for haplotype phasing and genotype calling for population NGS data
over existing methods.

Availability: HapSeq2 is available at www.ssg.uab.edu/hapseq/.
Contact: dzhi@uab.edu or kzhang@uab.edu

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on January 10, 2013; revised on June 10, 2013; accepted on
July 15, 2013

1 INTRODUCTION

Low-coverage sequencing of multiple samples is an efﬁcient
strategy to proﬁle genetic variations in a population (Li et al.,
2011) because low-sequencing depth makes it affordable to
sequence a larger number of samples. The high accuracy of geno-
type calling and haplotype phasing of such a design strategy is
achieved by many innovative developments in the ﬁeld of bio-
informatics and statistical genetics. As demonstrated by the 1000
Genomes Project (Abecasis et al., 2012; Durbin et al., 2010),
for common variants, the accuracy of genotype calling from

 

*To whom correspondence should be addressed.

low-coverage sequencing is comparable with that from genotyp-
ing arrays.

Although haplotype phasing was not the primary goal of the
1000 Genomes Project, the linkage disequilibrium (LD)—based
reﬁnement method, Thunder (Li et al., 2011), used in the project
to reﬁne genotype calls from individual subgroups, also phases
genotypes into haplotypes.

Thunder, and most LD-based genotype reﬁnement algo-
rithms, is based on the Li and Stephens model (Li and
Stephens, 2003). This model takes into account chromosome
sharing among multiple individuals, and can be efﬁciently opti-
mized by hidden Markov model (HMM)-based algorithms. This
model was traditionally applied to array-based genotype data in
which, at each site, it only observed the unphased genotype.
HMM-based methods can phase the haplotypes of multiple in-
dividuals simultaneously through a population genetics model
that models the chromosome sharing among these individuals.
With a modiﬁcation of single-site emission probability, Thunder
extended this approach to phase population next-generation
sequencing (NGS) genotype data. By comparing with the
Illumina Omni 2.5M genotyping array data that were phased
by additional family samples, Thunder was reported to make
one switch error in about every 300—400 kilobytes (KB).

However, Thunder assumes that the allele count data are
independently observed at each site and does not consider haplo-
type informative reads, i.e. reads that cover multiple heterozy-
gous sites, which carry useful haplotype information. In our
previous work (Zhi et al., 2012), we developed the HMM
based on the Li and Stephens model to incorporate a two-site
joint emission probability that can capture the haplotype infor-
mation across two adjacent sites. Our method, which is imple-
mented in the software package HapSeq, has achieved a 9—12%
reduction of error rates compared with Thunder for genotype
calling of the sequencing data from the 1000 Genomes Project.

Still, haplotype information in sequencing reads was not fully
used in our previous work. Haplotype information in reads that
cover more than two adjacent sites is not used because of severe
computational burden of higher order HMMs. This throws away
valuable haplotype information, especially because newer
sequencing technologies can offer longer reads. In addition,
paired-end reads can cover non-adjacent sites and thus offer
haplotype information over multiple adjacent and/or non-
adjacent sites. Paired-end reads are routinely used in sequencing
projects in aiding read mapping and assembly (Venter et al.,
2001). It would be important to develop advanced statistical
methods that can fully use the haplotype information in reads.

 

© The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com 2427

112 /§.IO'S[BU.IHO[p.IOJXO'SallBIHJOJUIOIQﬂI(1111] uIOJj pepBOIUAAOG

9IOZ ‘091sn3nv uo ::

K.Zhang and D.Zhi

 

Notably, a probabilistic haplotype phasing model, HASH,
was proposed by Bansal et a]. (2008) for a single individual
using whole-genome sequencing reads. Their approach was
termed ‘haplotype assembly’ because of its resemblance to the
traditional fragment assembly problem. Traditional fragment as-
sembly generates a single consensus sequence out of a set of reads
from a single individual, ignoring the diploid nature of the
human genome. Bansal et al.’s haplotype assembly was to gen-
erate a pair of consensus sequences out of a set of reads from a
diploid individual. Their model is based on the haplotype likeli-
hood of sequencing reads—the probability of a haplotype pair
given the sequencing reads. With the assumption of the uniform
prior on the space of haplotypes, this probability is proportional
to the probability of reads given the haplotype pair.
A Metropolis—Hastings (MH) algorithm was proposed to
sample haplotype pairs in which ‘moves’ are ﬂipping of sub-
strings of the haplotypes. They estimated the switch error rate
of haplotypes inferred for a genome (Levy et al., 2007) sequenced
by 7.5X Sanger reads was ~1.1%. However, their method as-
sumes that genotypes are readily known, and it requires high-
sequencing coverage; thus, it is not applicable to low-coverage
sequencing in which read counts are sparse and joint genotype
calling and haplotype phasing are essential for high accuracy. In
addition, with the assumption of the uniform prior, their method
ignores the haplotype information contained by other individuals
and/or reference haplotypes.

Another notable work is by He et a]. (2012). Their Hap-seq
(not our program ‘HapSeq’) method extended the haplotype as-
sembly approach by incorporating population information.
Their haplotype likelihood was divided into two independent
parts: the probability of sequencing of reads given the haplotype
pair, which is similar to that used in HASH (Bansal et al., 2008),
and the probability of the haplotype pair given the set of refer-
ence haplotypes, which can be calculated using the HMM similar
to the HMM in Thunder/HapSeq. He et a]. (2012) designed a
dynamic programming algorithm to ﬁnd a haplotype pair to
maximize the haplotype likelihood. Their simulation results
showed that the haplotype inferred from such model had lower
switch error rates than those obtained from IMPUTE v1.0
(Marchini et al., 2007). The method of He et a]. (2012) can be
used for low-coverage sequencing but still assumes that the geno-
types at each site are already known. Essentially, they extended
the Li and Stephens model into higher-order Markov models,
and thus their method incurs a computational complexity of
0(4 V), for just running a Viterbi pass for phasing one individual,
where Vis the maximum number of sites spanned by reads. Their
approach is impractical if V is large. Unfortunately, paired-end
reads are commonly used in real sequencing projects, as such
reads generally span a large number of sites. To avoid this
potential problem, He et a]. (2012) had to split a long read to
the multiple reads that each span only three heterozygote sites.
Obviously, this approach is not optimal, as it does not fully use
the haplotype information of reads that cover a large number
of sites.

In this work, we develop a fully probabilistic model for joint
genotype calling and haplotype phasing that incorporates the
joint distribution of two or more sites covered by a read over
an arbitrary distance. Our model integrates elements of the
population-haplotype likelihood in Thunder/HapSeq and the

read-haplotype likelihood in HASH (Bansal et al., 2008), each
capturing complementary haplotype information. Because both
methods are Markov Chain Monte Carlo (MCMC)—based, we
develop a combined MCMC method that embeds a MH proced-
ure into a Gibbs sampling algorithm. Speciﬁcally, in each iter-
ation, we ﬁrst use the Thunder/HapSeq HMM to jointly perform
genotype calling and haplotype phasing, and then use the MH
algorithm to sample haplotypes of each individual according to
the likelihood based on sequencing reads and reference haplo-
types. Our method is implemented in the HapSeq2 program,
and is evaluated together with Thunder and HapSeq by using
simulation and real data.

2 METHODS

2.1 Overview

Our probabilistic model incorporates both the likelihood of the multi-
sample chromosome sharing and the likelihood of haplotypes given mul-
tisite—spanning reads. Although our model is similar to that of He at al.
(2012), our algorithm is an MCMC sampling algorithm that is practically
efﬁcient. Basically, our MCMC sampling method is a hybrid of the
HMM-based Gibbs sampling-like algorithm as in Thunder/HapSeq,
and the MH algorithm as in HASH. The overall algorithm is a Gibbs
sampling-type algorithm that updates each individual in turn and runs for
a number of iterations. For each individual in each iteration, we reﬁne its
genotypes and haplotypes in two steps. First, we perform the Thunder/
HapSeq HMM sampling to obtain the genotypes and haplotypes. After
that, with the assumption of ﬁxed genotypes for that individual, we per-
form the MH sampling to update the haplotype pair of that individual.
The efﬁciency of our algorithm comes from the idea that we identify three
kinds of genotype and haplotype information in reads (as detailed in
Section 2.2) and only use parts of the information in reads that are
suited in each step. In the ﬁrst step, we only use reads covering single
sites and covering two adjacent sites as in Thunder/HapSeq, and inten-
tionally ignore the haplotype information in multisite—spanning reads. In
the second step, the sampling procedure is according to the sequencing
reads that cover two or more heterozygote sites (adjacent and/or non-
adjacent) and the reference haplotypes. In summary, our procedure can
be described as the following.

Initialization: Assign genotypes and haplotypes of each individual ac-
cording to the sequencing reads;

Outer Iteration: For t = 1, 2, - - - , perform the inner iteration;

Inner Iteration: For each individual 11 = 1, 2, - - - , N:

(1) Perform the HMM sampling to obtain genotypes and
haplotypes,

(2) Perform the MH to update haplotypes;

Finalization: Construct the consensus haplotypes and genotypes of
each individual based on haplotypes and genotypes obtained from
each outer iteration. The detailed descriptions of each step are given
in subsequent sections.

2.2 Genotype and haplotype information in reads

For a typical NGS shotgun sequencing project, we observe reads covering
L polymorphic sites for N individuals. Throughout, we assume biallelic
sites, with alleles labeled as 0 (the reference allele) and 1 (the alternative
alleles). Based on the haplotype information contained, we identify three
sets of read information, R1, R2 and R3, according to the following rules: (i)
a read that covers a single site belongs to R1; (ii) a read that covers two

 

2428

112 /310's113umo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq uIOJj pepBOIUAAOG

9IOZ ‘091sn3nv uo ::

Haplotype phasing and genotype calling using haplotype informative reads

 

adjacent sites belongs to R2 and R3; (iii) for a read that covers three or more
adjacent sites, we do the following: ﬁrst, we put every two adjacent sites to
R2, second, if there is a site left (i.e. the read covers an odd number of
adjacent sites), we put the last site to R1, third, we put the entire read to R3;
(iv) for a read containing non-adjacent sites, e.g. a read pair, we ﬁrst do
step (iii) for each chunk of the consecutive sites covered by the read, and
then put the entire read to R3. In HapSeq, we use two types of reads, R1
and R2, where R3 is broken into R; and/or R2. In this work, we use R1 and
R2 in the HMM sampling and R3 in the MH sampling. It is worth noting
the classiﬁcation of a read to R1, R2 and R3 is based on the number of sites,
and not the number of heterozygote sites that it covers. Such classiﬁcation
is only performed once with the ﬁxed set of variant sites at the beginning of
algorithm; thus it is not changed according to genotypes or haplotypes. We
denote R1, {1"} as the set of reads that cover the single site [for the individ-
ual 11, R2, {1"} as the set of reads that cover two adjacent site l—l and [for the
individual 11 and R3, {1"} as the set of reads that end at site [and cover two
non-adjacent sites and/or three or more sites for individual 11.

2.3 The HMM for the whole-genome shotgun sequencing
data in Thunder/HapSeq

We denote the set of reference haplotypes as T, and the number of ref-
erence haplotypes as |T|. For genotype calling and haplotype phasing,
both external haplotypes (e.g. haplotypes obtained from the external ref-
erence data such as data from the HapMap Project or the 1000 Genomes
Project) and/or internal haplotypes (haplotypes estimated from
sequenced individuals in the same study) can be used as reference haplo-
types (Li et al., 2010; Marchini et al., 2007). For NGS data, external
reference haplotypes are often incomplete and/or unavailable. As a
result, Thunder and HapSeq often use internal reference haplotypes
only. For N individuals, the number of internal reference haplotypes is
2*(N—1) (and the reference haplotypes themselves are different across
different individuals). For the rest of manuscript, we will ignore the
individual index subscript n for the sake of simplifying notations. This
is ﬁne because our overall algorithm runs in a Gibbs sampler fashion and
iteratively infers the genotypes and haplotypes for each individual given
the reference haplotypes.

The HMM is the same as the HMM in HapSeq (Zhi et al., 2012),
which can be described as following:

L L L
P(RI, R2, S) = P(Sl)1—I P(SzlSz—1)H P(R1,z l Sol—[Pam l 521,51)
[:2 [:1 [=2

(1)

In formula (1), we use a series of indicator variables S;(l = 1, - - - , L) to
represent a hypothetical (and unobserved) state sequence for that indi-
vidual, indicating to which reference haplotypes that individual is closest
at the site I. At a speciﬁc site I, a diploid state S; = (x;, y;)(l = 1, - - - ,L)
indicates that the two haplotypes of the individual are x; and )2; out of the
|T| reference haplotypes, respectively. In addition, P(SI) denotes the prior
probability of the initial mosaic state and is usually assumed to be equal
for all possible compatible haplotype conﬁgurations of each individual;
P(S; | S;_1) denotes the transition probability between two mosaic states
and reﬂects the likelihood of historical recombination events between
the sites I and l—l; P(RL; | S;) denotes the emission probability, which
is the probability of observed R1 reads that cover the site I conditioning
on the underlying mosaic state at the site I; P(R2,; | S;_1, S;) denotes the
emission probability, which is the probability of R2 reads that cover two
adjacent sites (l—l and l) conditioning on the underlying mosaic state at
sites l—land Z. Note that the emission probability P(R2, ; | S;_1, S;) at site I
not only depends on S; but also depends on S;+1 because R2,; actually
reﬂects the haplotype information between the sites l—l and l.

The emission probability, P(R2,; | S;_1, S;), is based on two haplotypes
in; and h2; deﬁned by S;_1 and S; across the sites I — 1 and l, and the error
parameter 6, which is the per base sequencing error rate. We further

denote R2,; = (n00,;,n01,;,n10,;,n11,;) as the number of combinations of
alleles 0 and 1 across the sites I — 1 and I that are simultaneously observed
in the R2 reads. Then P(R2,; | S;_1, S;) is deﬁned to follow a multinominal
distribution (Zhi et al., 2012):

P(R2,z = (7100,19 n01,1,n10,z, 1111,!) | 51—1, 51))
= P(R2,z = (7100,19 n01,z,n10,1,n11,z)Imus/121))

o< H00 l (0119 11201100111101 I (011, 1121))"011 (2)
*PUO | (011,021))"10’IP01 | (011, 1121))"111
where
P(00 I (112,112)) 2 0.5 * P(00 I 121;) + 0.5 * P(00 I 122,) (3)
and

(1 — (3)2, if two hapolotypes are identical ([1 = 00),
P(00 | h) = 6(1 — 6), if two haplotypes differs at one site (11 = 01),
62, if two haplotypes differes at both sites (11 = 11).
(4)

P(Ol I (011, 021)), P(10|(011, 021)) and P(ll I (011, 021)) can b6 deﬁned
similarly.

Once the prior probability [P(S1)], the transition probability
[P(S; | S;_1)] and the emission probability [P(R1,;| S;) and
P(R2,; | S;_I,S;)] in formula (1) are deﬁned, we can use the standard
HMM Monte-Carlo procedure to sample S1, - - - , S L, impute the genotype
and determine the haplotype pair of each individual over a number of
iterations. The detailed description of all terms in the HMM and the
sampling procedure can be found in Zhi et a]. (2012).

Theoretically, we can incorporate the R3 reads into the HMM:

L L
P(R19R29R3, 5) = P(Sl)1—[P(SllSl—1)1—[P(R1,ZISZ)
1:2 [:1

L L (5)
HP(R2,1 | 51—1,SI)HP(R3,1 | Si, “3131—1951)
[:2 1:3

It can be seen that the emission probability P(R3,; | S1, ---,S;_1,S;)
depends on not only S; and S;_I if R3,; covers sites I and l—l and some
sites from 1 to l—2. This greatly increases the computational complexity
when we perform the forward probability calculation in Monte-Carlo sam-
pling. The computation increases rapidly with the inclusion of reads that
cover more sites. Note, when we only consider the reads that cover a single
site and two adjacent sites, the complexity of calculation of the forward
probability is still 0(| T | 2). Therefore, the above pure HMM is not prac-
tical to handle R3 reads because of the high computational complexity.

2.4 Metropolis—Hastings procedure

We denote H as a haplotype pair and P(H | R3, T) as the haplotype like-
lihood H of the given sequencing reads and the set of reference haplotypes
(T). We further denote Pr(H —> H*) as the proposed probability from a
haplotype pair H to a new haplotype pair H *. Our MCMC procedure is a
standard MH procedure and can be described as follows:

Initialization: Obtain H0, the haplotype pair of that individual from the
HMM procedure;
Iteration: For t = 1, 2, ---, obtain H’+1 from HI as follows:
(1) Propose H* according to HI and the sequencing reads with the
probability Pr(HI —> H*),

(2) With the probability min[1, ﬁ+£ﬁ*£ﬁZT—:gg] to set

H1+1 = H*, otherwise, set H’+1 = H,

Finalization: Construct the consensus haplotype pair from
H°,H1, ---,H’,  and use it in the next step of HMM.

 

2429

112 /§JO'SIBumo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq uIOJj pepBOIUAAOG

9IOZ ‘091sn3nv uo ::

K.Zhang and D.Zhi

 

We would like to make the following notes: (i) For this MH procedure,
we assume that the genotypes are ﬁxed, as they are already determined
from the HMM procedure so only haplotypes of that individual are
updated according to the sequencing reads and haplotypes from the refer-
ence haplotypes (internal and/or external reference haplotypes). The ra-
tionale behind this is that the HMM step already can generate highly
accurate genotypes. (ii) Because we assume that the genotypes are ﬁxed,
the homozygote sites covered by the R3 reads will not affect the proposed
probability [Pr(H* —> H’) or Pr(HI —> H*)] or the ratio of likelihood of
two haplotype pairs [Pr(H* | R3, T) / Pr(HI | R3, 1)], and only the hetero-
zygote sites need to be considered in the calculation of Pr(H | R3, T). Here
R3 are the reads spanning two or more sites, and T is the set of reference
haplotypes. It can be seen that we use both the information of haplotypes
from the sequencing reads (R3) and the LD information (T) from this set of
samples or the reference samples to update the haplotypes of that individ-
ual. (iii) The updated haplotypes will be used as the reference haplotypes
for other individuals in the next iteration of HMM. So we expect that the
updated haplotypes (more accurate) will then improve the overall accuracy
of HMM for genotype calling and haplotype phasing.

To describe our detailed algorithm of making proposal H*, we ﬁrst
introduce the following notations. As we have mentioned, we only need
to consider the heterozygote sites of that individual. We assume there are
K heterozygote sites: [1,12, - - - , 1K. For the sequencing read 1' spanning two
or more heterozygote sites (adjacent or non-adjacent), we use
Z,- = {2;k,k = [1, - - - , 1K} to represent the observed allele of the read 1' at
the site 1;, as the reference allele (0), the alternative allele (1) or no obser-
vation (—1). Similarly, we use H = {11, ii} = {0%}, {15;}, k = 11,12, - - -,1K}
to represent the haplotype pair of an individual, where [1]" = 0 or 1
(la—J- : 0 or 1) represents the observed allele of that haplotype.

Given the current haplotypes of that individual, H l , we only consider
the proposal H* that is a single crossover away from H’. A single cross-
over of haplotype pair at a recombinant point refers to that two haplo-
types beyond that point are swapped to form a new haplotype pair. We
choose the recombination point (between two adjacent heterozygote sites)
with the probability Pr(H —> H*) that is proportional to a weight. We
deﬁne the weight of two adjacent heterozygote sites, (lk_1, 1k) as
W(lk_1, 1k),k = 2, - - - ,K for the recombination point between heterozy-
gote sites lk_1 and lk. The weight is calculated according to H’ and H*
and the sequencing reads. Speciﬁcally, we ﬁrst calculate the total number
of sequencing reads that are in conﬂict with the current haplotype pair H’
and the proposed haplotype pair H* and denote them as C’and C*,
respectively. A conﬂict is claimed for a read if (i) the read spans the
recombination point, i.e. covers at least one site from [I to lk_1 and
one site from [k to 1K; and (ii) the read is not compatible (identical)
with either of haplotype of H’ at the heterozygote sites covered by this
read. If Cl 2 C*, the weight is 1 plus Cl — C*, otherwise the weight is 1
(to avoid weight of 0). Once a recombinant point is chosen, the new
haplotype pair H* is just the recombinant haplotypes of H’ at the recom-
bination point. Our procedure captures the essential element of HASH
(Bansal et al., 2008) that concentrates on ‘ﬂipping’ a subset of the entire
haplotype pair. In the same time, we restrict the allowed ﬂipping oper-
ation to just the single crossovers so the likelihood ratio in the MH pro-
cedure can be efﬁciently calculated, as described below.

In the second step of the MH algorithm, we accept or reject the
proposal H* according to Pr(H’ | R3, S) and Pr(H* | R3, S). To calculate
Pr(H | R3, S), we have:

Pr(HI R3, T) 0< P(HsRss T) = P(R3 IH)P(H| T) (6)

where P(R3 |H) 2 1‘1, P(Z, I H) = Hi%(P(Z,~ I h) + P(Z, I 12') is the haplo-
type likelihood of the sequencing reads (Bansal et al., 2008; He at al.,
2012) and is a function of per base sequencing error and P(H | T) is the
conditional probability of the haplotype pair H given the reference haplo-
types and reﬂects the LD information of sites. P(H | T) can be considered
as a prior distribution of a haplotype pair. In the article of Bansal et a].

(Bansal et al., 2008), the uniform prior was used. Here, P(H | T) incorp-
orates essential chromosomal sharing information and the HMM can be
used to calculate P(H | T) = P(hl T)P(0 | T). Again, the haplotype h is
considered as the recombination events of reference haplotypes and
each reference haplotype is considered as a hidden state. Therefore, the
probability P(hl T) is calculated across all possible hidden states:

P(hl T) = Z,“ ---Z,,K Pool—1;, Paw. ISzk)P<S;. I 51..) (7)

In formula (7), the prior probability [P(S;1)], the transition probability
[P(S;k | S;k_1)] and the emission probability [P(h;k | S;)] can be deﬁned simi-
larly as the HMM in HapSeq. Then P(h | T) can be easily calculated by the
Baum’s forward algorithm. Speciﬁcally, we deﬁne the forward probability:

ak(i):P(l/l[19 "'9h1k9Slk  19  19 "'9 

First we calculate 051(1) as: 051(1) 2 P(/1;1,S;1 = i) = P(h;1 |S;1 = i)
P(S;1 = 1'). Then the following recursion is used to calculate ozk+1(i):

Olk+1(i) = P(hII, - - '9hlk9hlk+19 Slk+1 = i)
= 21.13001, ---,hzk,hzk+1, 51,. =1; 51;.“ = i)
= 2, Po]... lSzk+1 = i)P(Szk,, = il SI. =j)P(hz., ---,h;., S]. =1)
= P(hzk+1 | 51H, = i) Z]. P(Szk+1 = il 51,, =j)05k(i)
(8)

Finally, we can calculate P(hl T) = 21.01141).

We would like to point out that the above computation can be greatly
reduced. It can be seen that the complexity of the naive implementation
of the calculation of the forward probability is 0(K* | T | 2), as we need
| T | (the number of reference haplotypes) additions for 05;,(1'). However,
the complexity can be reduced because the transition probability,
P(S;k 2 il S;k_1 = j), only depends on if i is same with j. Speciﬁcally,
P(Slk = iISlk—l 2]): 1 _6k+6k/| Tl  izj and P(Slk = iISZk—l 
= 6k/ | T | if i 75 j, where 6;, is the recombination rate between the sites
lk_1 and lk. Thus, we deﬁne 13;, = Z]. 05;,(1'), then

came = P(hz... lSzk+1 = i) 2, HS]... = il S]. = new)
= P (01“, | 51H, = l')[P(Szk+1 = il 51,, = 000')
+ 21.721. P(Szk+1 = il 51,, =j)05k(i)]
= P011... lSzk+1 = i)[(1 — 6;. + ek/ I TI me + an TI 2,7,, aim]
= P011... lSzk+1 = i)[(1 — 6mm) + an TI 21.02.01]
= P(hzk+, | 51H, = 0K1 — 6k)05k(i) + 9k/ | TI Wk]
(9)

The computational complexity is reduced to 0(K* | T | ). As the
probability P(hl T) for each haplotype is calculated independently, the
computational burden of this MH procedure is actually small compared
with the HMM step.

2.5 Evaluation using simulation

We used simulated sequencing data to compare the performance of
Thunder, HapSeq and HapSeq2. We generated chromosomes for two
populations using the cosi program (Schaffner et al., 2005). We adopted
the ‘bestﬁt’ model distributed with the cosi package, which takes into
account the HapMap LD patterns, local recombination rates and
recent human population demography. We generated 3000 chromosomes
from the ‘European population’ (EUR) and 3000 chromosomes from the
‘African population’ (AFR). Each chromosome is of length 100 KB. For
each population, we randomly sampled with replacement 60 sets of un-
related diploid individuals, each of N = 60 (120 chromosomes), to form a
‘population panel’. These 60 sets are simulated with 6 scenarios, each with
10 repetitions: (i) 36 bp reads, unpaired (coded as 36-0); (ii) 100 bp reads,

 

2430

112 /§JO'SIBumo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq uIOJj pepBOIUAAOG

9IOZ ‘091sn3nv uo ::

Haplotype phasing and genotype calling using haplotype informative reads

 

unpaired (100-0); (iii) 36 bp reads, paired with 250 bp insert (36-250);
(iv) 100 bp reads, paired with 250 bp insert (100-250); (v) 100 bp reads,
paired with 500 bp insert (100-500); and (vi) 100 bp reads, paired with
1000 bp insert (100-1000). These settings will allow us to test the perform-
ance of these methods in different sequencing settings with various read
length and insert length for paired-end reads. We ﬁxed the rest of the
simulation parameters: sequencing error rate to 0.5%, sequencing depth
of coverage to 4X, as we have shown that the trends observed from
different settings of these parameters tend to be similar (Zhi et al.,
2012). Generation of reads and site promotion follow that of HapSeq
(Zhi et al., 2012). Brieﬂy, read starting positions were placed uniformly
and randomly along the chromosome, and sequencing errors were gen-
erated uniformly and randomly along the length of the reads as well. For
paired-end settings, the starting positions of insert fragments were placed
uniformly and randomly along the chromosome, and a pair of reads from
each end of the insert fragment was generated. We followed Li et a].
(Li et al., 2010) and calculated the score w = 2le dn(dn + 1)/ 2, where
dn is the minor allele count of individual 11 at each site. We promoted sites
with w 2 5 as potential polymorphic sites.

For each dataset, we run four versions of programs with 100 iterations
of Gibbs sampling: (i) the original Thunder; (ii) Thunder + MH; (iii) the
original HapSeq; (iv) HapSeq + MH, i.e. HapSeq2. We ran 5c iterations
for the MH-ﬂipping after each HMM iteration where c is the total number
of heterozygote sites of the haplotypes obtained from the HMM (same as
below). For Thunder, we also ran 200 and 300 iterations of Gibbs sam-
pling. These may also improve the performance of Thunder with compar-
able running time as options (ii)—(iv) mentioned above. For each simulated
dataset, we computed the switch error rate, genotype calling concordance
rates and r2 between the estimated and true genotypes. The averages over
10 repetitions are presented in the Results section.

2.6 Evaluation using the 1000 Genomes Project
phase 1 data

To capture complexities in real sequencing data, we also evaluated these
methods using the 1000 Genomes Project phase 1 data. The low-coverage
read alignment data and the integrated variant calls of chromosome 20
were downloaded for 98 individuals of Utah residents with Northern and
Western European ancestry from the CEPH collection (CEID and 99
individuals of Yoruba in Ibadan of Nigeria (YRI) from http://www.
1000genomes.org/. We used VCFTools v0.1.9.0 (Danecek et al., 2011)
to extract the polymorphic sites (but not the genotypes) in the integrated
variant call sets for chromosome 20, removing any non-SNP (single nu-
cleotide polymorphism) variant sites. We used SAMTools version 0.1.18
(Li, 2011) to merge the BAM ﬁles of the same individual, and then used
an internal script to parse the BAM ﬁle of each individual to obtain the
read counts (R1), jumping reads (R2) and read site spanning information
(R3) over these sites.

Following the 1000 Genomes Project phase 1 evaluation (Abecasis
et al., 2012), we used the Omni 2.5 genotype data phased by SHAPEIT
(Delaneau et al., 2012) as released from the 1000 Genomes Project Web
site as the gold standard. Most CEU and YRI phase 1 samples are par-
ents of father—mother—child trios, and thus the Omni data, available for
all members of trios, can be phased with high accuracy. We calculated the
genotype concordance and haplotype switch error results against the
Omni data by using VCFTools v0.1.9.0 (Danecek et al., 2011).

3 RESULTS

3.1 Simulation results

As all calculation is done over the promoted potential poly-
morphic sites, the following measures are relevant to
LD-reﬁnement algorithms based on haplotype-informative

reads: (i) read-cover: the number of sites covered by a read; (ii)
read-span: the number of sites between the ﬁrst site and the last
site covered by a read. The only difference between these two
measures is that sites skipped by the gap between the paired-end
reads are counted in read-span, but not in read-cover. For non—
paired-end reads, the two statistics are the same.

Figure 1 shows, as expected, that whereas the read-cover of
paired-end reads is twice as that of single reads, the read-span of
paired-end reads is much longer. Noticeably, paired-end reads
that span longer distance (100—500 and 100—1000) have a clear
bimodal distribution of their read-span. The difference between
read-span and read-cover demonstrates the information can be
used by the MH haplotype ﬂipping (MH-ﬂipping), but not
Thunder/HapSeq.

As shown in Figure 2, Thunder and HapSeq with interlaced
MH-ﬂipping result in longer switch error-free (SEF) haplotype
blocks in both European and African samples. The average im-
provement with MH—ﬂipping is 46.1%. Therefore, the ability of
MH-ﬂipping in capturing haplotype information over multiple
sites in reads improves the haplotype phasing. If comparing
HapSeq2 (HapSeq+MH) and Thunder, the average improve-
ment across all datasets is 105.1%. Notice that running Thunder
for more iterations produces slightly longer SEF haplotype
blocks, but the magnitudes of improvement are not comparable
with Thunder+ MH and HapSeq methods, especially for
datasets with paired-end reads.

(a) 108 Distribution of number of sites covered by read — EUR

 

 

 

 

 

 

 

 

— 
6

10 - —36—250 —
g \ 100—250
g —100—500
g 104_  100—1000 _
G)
.0
E
E

102- -

10° - -

5 10 15

number of sites

(b) Distribution of number of sites spanned by read — EUR
10 . . - - -

 

_A.
O
0)

 

 

 

58 /\
8
.: 4 <\
210- \ —
(D
.Q
g \\
C 2
10- -
0
10 I I I I I
O 5 10 15 20 25 30

number of sites

Fig. 1. Site coverage (a) and site span (b) statistics of simulated sequencing
reads. Reads covering no potential polymorphic sites are not counted. The
distributions for the AFR population are similar (data not shown)

 

2431

112 /310's112umo fp101xo's31112u1101u101q//:d11q u1011 pep1201umoq

9IOZ ‘091sn3nv uo ::

K.Zhang and D.Zhi

 

In most simulated datasets, Thunder produced the shortest
SEF blocks, serving as baseline performance. Both HapSeq
(as Thunder+reads covering two adjacent sites) and
Thunder+MH produce longer SEF blocks, although the per-
formance of one is not always better than the other. Overall,
HapSeq2 always produces the longest SEF blocks.

(31 Average length between switch errors (hp)

  

 

 

 

 

 

 

30000-0
lThunder lThunder-200 
25mm . l.ThI.Inder:300. E: Thunders-MR
HapSeq HapSeq+MH
200000
150000 +_i_
100000 H I.
50000
0 - M . ~ . r
(b) 300 100-0 36050 100250 100600 100-10-00
200000 -
150000 - —
100000 - ‘ f__
50000 -
ﬂ- .

   

36-0 100-0 36-2 50 100-250 100-500 100- 1000

Fig. 2. Switch errors in simulated datasets: (a) EUR and (b) AFR. Six
datasets for each population panel are labeled with ‘x—y’, where ‘x’ is the
length of reads and ‘y’ is the length of inserts (0 if unpaired). Method with
‘+MH’ refers to the original method with interlaced MH-ﬂipping. All
methods run for 100 iterations of HMM, except Thunder-200 and
Thunder-300 (200 and 300 iterations, respectively)

(a) Overall discordance rate - EUR
0.010

0.012

0.000-
0001 - I
0'
36-0 100-0 36-250 1011-250 1011-500 1004000

(GI HET discordance rate - EUR

I103
0.025

0.02 -
0.015 -
0.01 -
0.005 -
D . _ _
36-0 1000

36-250 1.00-250 100-500 100-1000

(e) R-squared cIf estImated vs true
genotype bv MAF
1.0000
0.0500 -
0.9000 -
man I I I
0.0000 -
0.1500 - -
nil-mg . ._. _ _.
MAFCI‘XI 1%:=MAF<5% MIIIF5=55€I

Variations of HapSeq in general produce longer SEF blocks
compared with variations of Thunder with otherwise the same
settings. The average improvement is 41.4%. This is reassuring,
as the improvement from adding interlaced MH-ﬂipping is cu-
mulative to the improvement from considering joint emission
probabilities of reads covering two adjacent sites (HapSeq versus
Thunder).

The results are consistent across European and African popu-
lation data. Noticeably, haplotype phasing of European samples
is generally better than that of African samples. This is expected,
as European samples are simulated with severe bottlenecks and
are known to have longer shared haplotype blocks.

We also compared different sequencing strategies from short
and unpaired reads with long and paired-end reads. Throughout,
Thunder produced consistent short SEF blocks, reﬂecting its in-
ability to capitalize the haplotype information in sequencing
reads. All other methods beneﬁt from longer and paired-end
sequencing designs. The greatest improvements between methods
with MH-ﬂipping versus those without are for 100 bp reads with
500 bp or 1000 bp inserts, with an average improvement over
100%. It is clear that 100-bp-long paired-end reads offer the
best phasing results, although there are no major differences in
terms of performance of HapSeq2 between these 100-bp paired-
end designs.

Accurate haplotype phasing from interlaced MH-ﬂipping is
not an artifact of simply eliminating heterozygous sites. As
shown in Figure 3, genotype calling error rates are lower in
methods with MH-ﬂipping than those without in both heterozy-
gous sites (HET) and in overall sites. Looking across rare (minor
allele frequency (MAF)<1%), low-frequency (1% g MAF<
5%) and common (MAF: 5%) single nucleotide polymorph-
isms, Thunder+MH offers higher genotype concordance and
r2 between the estimated genotypes and the true genotypes
(Fig. 3, Supplementary Table S1). We think that the

(b) Overall discordance rate - AFR

0.015

0.012 -

0.IIIB -

0.314 -

D .
313-0 100-0

36-250 1130-250 1010-500 1010-1010

Id} HET discordance rate - AFR

0.03-

0.025 -
0.02 -
0.015 -
0.01 -
0.005 -
D . _ _ _
3&0

1.00-0 361250 100-250 100500 1001000

I thunder
I thunder+MH
hapseq

hapseq+MH

Fig. 3. Genotype calling accuracies of different methods over simulated datasets. (a—d) Genotype discordance rates. (e) r2 of estimated versus the true
genotypes of European dataset 100—250. See Supplementary Table S1 for results of other simulated datasets

 

2432

112 /310'S[12um0 fp101xo'sot112u1101u101q//:d11q 111011 pep1201um0q

9IOZ ‘OE lsnﬁnv uo ::

Haplotype phasing and genotype calling using haplotype informative reads

 

improvement of genotype calling is due to better haplotypes
(served as internal reference haplotypes) resulted from more ac-
curate haplotype phasing.

The interlaced MH-ﬂipping procedure results in longer run-
ning time. The time increased is linear to the number of ﬂips and
to the number of potential MCMC moves in each round. In
total, the running time for HapSeq2 is ~2—3 times that of
Thunder, and is thus still practical.

3.2 Results from 1000 Genomes Project phase 1 data

Although the patterns of read-cover in the 1000 Genomes Project
phase 1 data are consistent to what we observed in the simulated
data, the patterns of read-span is more complex (Fig. 4). There
are pairs of reads that span over 1000 sites. This is likely because
of structural variations or technical artifacts. Still, bimodal pat-
terns of read-span are observed in both CEU and YRI data.
Note that CEU has a fraction of 454 reads that are longer,
and thus CEU data have longer read-cover and read-span.
Over the entire chromosome 20, haplotype phasing by
interlaced MH-ﬂipping produced longer SEF-blocks, whereas
genotype calling accuracy is also improved, especially for hetero-
zygote genotypes (Fig. 5). For all pairs of methods, one with and
one without interlaced MH-ﬂipping, interlaced MH-ﬂipping
increases the average length of SEF block by 70—86 KB. This
represents 23.6—44.6% improvement. Between Thunder and
HapSeq2, the improvement of the length of the SEF block is
148 KB (77.6%) for CEU and 148 KB (66.7%) for YRI. All
these improvements coincide with improvement of genotype
calling accuracy. Interestingly, YRI has longer SEF blocks
than CEU, which is different from what we observed in the

 

 

 

 

 

 

 

 

 

 

 

1010 Read statistics of 1000G Phase 1 data
CEU—cover
8 CEU—span
10 I -
\ YRI—cover
g \ YRI—span
3 1o6 -
H5 L
‘D 4
.Q _
E 10
:3
C
102 -
10° - - m  LHJL :.J
0 50 100 150 200

number of sites

Fig. 4. Read cover and span distributions in the 1000 Genomes Project
datasets

 ammo {menu

IE 35mm ¥ NH
5 i: ammo-u i

-r E 2 250000 a arm
.: a a

a "M" E i 200000 E [was
i 1.-

” m E 15mm :3 sum
HIMH E a mason - _ - E

5 m I I 

G-
G

lCEU YRI

simulated data. This may be due to the signiﬁcantly higher het-
erozygote rate in the YRI samples compared with the CEU
sample, which would result in a greater number of sequencing
reads being useful for haplotype phasing. Another possible
reason may be due to the fact that we use the same set of sites
across YRI and CEU datasets in the real data analysis, whereas
we used the promoted sites individually deﬁned in each dataset in
simulations.

4 DISCUSSION

We developed a new approach for haplotype phasing and geno-
type calling from sequencing data of a set of population samples.
We designed an MH-ﬂipping algorithm that can be embedded
into traditional Gibbs sampling algorithms based on the Li and
Stephens HMM model. Using simulated and real datasets, we
showed that our new method can greatly improve the accuracy
of haplotype phasing over current state-of—the-art methods.
In the 1000 Genomes Project phase 1 data, our HapSeq2
method produces 60—80% longer SEF haplotype blocks than
Thunder. Although the primary goal of introducing the MH-
ﬂipping procedure is to improve haplotype phasing, we found
that this technique also improves genotype calling accuracy.

Accurate haplotype phasing will have broad impacts on gen-
omic and genetic research areas. First, reconstructing long haplo-
type blocks in reference panel will improve the accuracy of
genotype imputation. Second, long haplotype blocks will help
haplotype-based genetic association studies. Third, accurate
haplotype phasing will produce more insights into population
genetics inferences.

This work is one of the ﬁrst to prove the feasibility of incor-
porating haplotype information over multiple sites in ultra-long
reads and long insert paired-end reads for phasing sequencing
data with improved accuracy. This provides additional methodo-
logical support for the ultra-low coverage sequencing design
(Pasaniuc et al., 2012). In our simulation studies, we only used
the read length of 36 and 100 bp and the ﬁxed insert size of 250,
500 and 1000 bp. For the 1000 Genomes Project chromosome 20
data, the insert size varies and the portion of the proportion of
R2 and R3 reads also varies across different regions. For the
chromosome 20, the proportions of reads covering two sites
and at least three sites are 28.0% and 24.8% for the CEU sam-
ples and 27.3% and 24.1% for the YRI samples, respectively.
For the major histocompatibility complex region, the propor-
tions of reads covering two sites and at least three sites are
higher: 25.4% and 34.6%% for the CEU samples and 25.5%
and 31.5% for the YRI samples, respectively. The performance

[0] 0.025

enmva cll I:

I: 02 I 
CEU 'r'FII

G
car:-
car:-
._...-
mu:

CEU 'I'RI

Fig. 5. (a) Switch errors for haplotype phasing and (b) genotype discordance rates for all genotypes and (c) heterozygote genotypes in real data. Results
are over the 1000 Genomes Project phase 1 data for CEU and YRI individuals. Methods labels: T=Thunder, H=HapSeq and MH=interlaced

MH-ﬂipping

 

2433

112 /310's112umofp101xo'sot112u1101utotq//:d11q u1011 pep1201umoq

9IOZ ‘091sn3nv uo ::

K.Zhang and D.Zhi

 

of the proposed method for such regions is expected to be further
improved. Therefore, more studies are needed to show how the
accuracy of haplotype phasing and genotype calling is affected
by the length of reads, the length of inserts and the proportion of
R2 and R3 reads using our newly developed method. It will be
future work to conduct extensive simulations including the simu-
lation of reads with varied insert sizes to investigate the optimal
design strategies.

In the MH sampling, we proposed the new haplotype pair as a
single crossover of the current haplotype pair and chose the
recombinant point with the probability that is proportional to
a weight. We deﬁned the weight as the function of the difference
of the number of sequencing reads that are in conﬂict with the
current haplotype pair and the proposed haplotype pair.
Although we also used the uniform weight and found the results
from the uniform weight to be just slightly worse than the pro-
posed weight, it is not clear whether the proposed weight is
optimal. We will investigate this with more simulations in the
future. To investigate whether the single crossover is sufﬁcient
for convergence of the MH sampling, we ran HapSeq2 5c, 10c
and 20c iterations for the MH sampling, where c is the number of
heterozygote sites of that individual. We found the results from
5c are similar to those obtained from 10c and 20c. In addition,
we found the acceptance ratios from 5c, 10c and 20c are similar,
indicating it is sufﬁcient for convergence.

ACKNOWLEDGEMENTS

We thank Yingrui Li for helpful discussions. The content is
solely the responsibility of the authors and does not necessarily
represent the ofﬁcial views of the National Institutes of Health.

Funding: NIH RO0RR024163 (to D.Z.), NIH R01GM074913
(to K.Z.) and R01GM081488 (to K.Z.).

Conﬂict of Interest: none declared.

REFERENCES

Abecasis,G.R. et al. (2012) An integrated map of genetic variation from 1,092
human genomes. Nature, 491, 56—65.

Bansal,V. et al. (2008) An MCMC algorithm for haplotype assembly from whole-
genome sequence data. Genome Res., 18, 1336—1346.

Danecek,P. et al. (2011) The variant call format and VCFtools. Bioinformatics, 27,
2156—2158.

Delaneau,O. et al. (2012) A linear complexity phasing method for thousands of
genomes. Nat. Methods, 9, 179—181.

Durbin,R.M. et al. (2010) A map of human genome variation from population-scale
sequencing. Nature, 467, 1061—1073.

He,D. et al. (2012) Optimal algorithm for haplotype phasing with imputation
using sequencing data. In: The Fifteenth Annual Conference on Research in
Computational Biology {RECOMB—ZOIZ). Barcelona, Spain.

Levy,S. et al. (2007) The diploid genome sequence of an individual human. PLoS
Biol, 5, e254.

Li,H. (2011) A statistical framework for SNP calling, mutation discovery, associ-
ation mapping and population genetical parameter estimation from sequencing
data. Bioinformatics, 27, 2987—2993.

Li,N. and Stephens,M. (2003) Modeling linkage disequilibrium and identifying
recombination hotspots using single-nucleotide polymorphism data. Genetics,
165, 2213—2233.

Li,Y. et al. (2010) MaCH: using sequence and genotype data to estimate haplotypes
and unobserved genotypes. Genet. Epidemiol, 34, 816—834.

Li,Y. et al. (2011) Low-coverage sequencing: implications for design of complex
trait association studies. Genome Res., 21, 940—951.

Marchini,J. et al. (2007) A new multipoint method for genome-wide association
studies by imputation of genotypes. Nat. Genet., 39, 906—913.

Pasaniuc,B. et al. (2012) Extremely low-coverage sequencing and imputation
increases power for genome-wide association studies. Nat. Genet., 44, 631—635.

Schaffner,S.F. et al. (2005) Calibrating a coalescent simulation of human genome
sequence variation. Genome Res., 15, 1576—1583.

Venter,J.C. et al. (2001) The sequence of the human genome. Science, 291,
1304—1351.

Zhi,D. et al. (2012) Genotype calling from next-generation sequencing data using
haplotype information of reads. Bioinformatics, 28, 938—946.

 

2434

112 /310's112umofp101xo'sot112u1101utotq//:d11q u1011 pep1201umoq

9IOZ ‘091sn3nv uo ::

