APPLICA TIONS NOTE V0" 2305-1?b.’1%§§/liiiiiii§$i§$3§3

 

Data and text mining

Advance Access publication July 1, 2013

BNFinder2: Faster Bayesian network learning and

Bayesian classification

Norbert Dojer*, Pawel Bednarz, Agnieszka Podsiadlo and Bartek Wilczynski*

Institute of Informatics, University of Warsaw, 02—097, Warsaw, Poland

Associate Editor: Jonathan Wren

 

ABSTRACT

Summary: Bayesian Networks (BNs) are versatile probabilistic models
applicable to many different biological phenomena. In biological
applications the structure of the network is usually unknown and
needs to be inferred from experimental data. BNFinder is a fast soft-
ware implementation of an exact algorithm for finding the optimal
structure of the network given a number of experimental observations.
Its second version, presented in this article, represents a major
improvement over the previous version. The improvements include
(i) a parallelized learning algorithm leading to an order of magnitude
speed-ups in BN structure learning time; (ii) inclusion of an additional
scoring function based on mutual information criteria; (iii) possibility of
choosing the resulting network specificity based on statistical criteria
and (iv) a new module for classification by BNs, including cross-
validation scheme and classifier quality measurements with receiver
operator characteristic scores.

Availability and implementation: BNFinder2 is implemented in
python and freely available under the GNU general public license at
the project Web site https://Iaunchpad.net/bnfinder, together with a
user’s manual, introductory tutorial and supplementary methods.
Contact: dojer@mimuw.edu.pl or bartek@mimuw.edu.pl
Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on December 14, 2012; revised on May 29, 2013; accepted
on May 30, 2013

Bayesian Networks (BNs) are robust and versatile probabilistic
models applicable to many different phenomena (Needham
et al., 2007). In biology, the applications range from gene regu-
latory networks (Dojer et al., 2006) to protein interactions
(Jansen et al., 2003) to gene expression prediction (Beer and
Tavazoie, 2004) to relationships between chromatin-associated
proteins (Van Steensel et al., 2010) to chromatin state prediction
(Bonn et al., 2012). In many cases one needs to infer the structure
of the network to build a BN model. While this problem is NP-
hard in general (Chickering, 1995), it was shown by Dojer (2006)
that in cases where the acyclicity of the network is ensured, it is
possible to ﬁnd the optimal network in polynomial time.
BNFinder ONilczynski and Dojer, 2009) is a ﬂexible tool for
network topology learning from experimental data. Originally
developed for inferring gene regulatory networks from expres-
sion data (Dojer et al., 2006), it has been since successfully
applied to linking expression data with sequence motif

 

*To whom correspondence should be addressed

information (Dabrowski et al., 2010), identifying histone modi-
ﬁcations connected to enhancer activity (Bonn et al., 2012) and
to predicting gene expression proﬁles of tissue-speciﬁc genes
ONilczynski et al., 2012). The last study is also an example of
using BNFinder not as a standalone tool but as a software
library. Thanks to the availability of the source code and docu-
mented API it was possible to use BNs as a part of a larger
probabilistic model using Expectation-Maximization for param-
eter optimization.

BNFinder can be also used for classiﬁcation tasks (Fig. 1).
In this case the network topology is constrained to a bipartite
graph between feature and class variables. The structure repre-
sents conditional dependencies of classes on selected features.
This classiﬁer model is equivalent to diagnostic BN5 introduced
by Kontkanen et a]. (2001). The process of classiﬁcation consists
of several steps, carried out with dedicated BNFinder2 modules.
First, to train the classiﬁer, the optimal network structure and
the conditional probability functions (CPDs) are learned with the
basic bnf tool. Second, the bnc module makes predictions on
new examples using the learned network and CPDs.

Additionally, the bnf—cv tool facilitates using BNFinder2 in
a cross-validation framework by automatically dividing the input
dataset into training and testing sets. The performance can be
measured either with numerical measures such as speciﬁcity or
sensitivity or by generating receiver operator characteristic
(ROC) or precision-recall plots [using the Rocr package (Sing
et al., 2005) or a pure python implementation, example plots
shown in Fig. 1 and Supplementary Fig. S1]. All these tools,
together with other BNFinder2 features, like handling mixed
(both continuous and discrete) datasets, make it a complete
package for easily generating classiﬁers for a broad range of
biological datasets, as is illustrated by an application to histone
modiﬁcations measurements (Bonn et al., 2012).

Although BNFinder always ﬁnds optimal networks with re-
spect to a given score, the reliability of learned networks may
vary, depending on the input data. Therefore, BNFinder attaches
a couple of statistics to returned network features. This includes
relative posterior probability for each set of parents and each
variable as well as weighted frequency of occurrence in (sub-)
optimal regulator sets for each edge.

BNFinder2 is equipped with additional quality control mech-
anism, allowing the user to predetermine the speciﬁcity of opti-
mal network. Namely, the expected proportion of pairs of
unrelated variables wrongly connected by an edge may be speci-
ﬁed. Based on this proportion and the distribution of scoring
function, prior distributions of network structures are adjusted

 

© The Author 2013. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0/), which permits non—commercial re—use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial

re—use, please contact journals.permissions@oup.com

112 /310's113u1no [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(1111] 11101; pepBOIUAAOG

9IOZ ‘091sn3nv uo ::

BNFinder2

 

 

I . _
4 a i . y m 4 ' N . " ‘1:
H .2 m a a u  " as
3 :' ‘5: ‘ I £1,335  ill-P 3' ' ‘I .- r “9% mgr;
" Ll- “: a -. n3 *1.“ ° - ‘3' 
2 - I :{U‘I'C'mtg’ ' a: q- 2 "*  "I  I'-
f - I (Iv. .‘ "I
1_ I,”- 1 “I I _J _ 1  ".23
i .132. 2: .t ‘L '5 III '_:‘:’nt:'; _{_- I... ‘FP': \-
o _ g   a w. c u   '
a  ‘1- ‘; er H. I. : 4:23.?“ 0'" 1
_1 :5 l" g + _]_ E:  '
I I'. _ .

 

 

 

 

 

 

 

 

 

 

 

 

I“

 

 

Sensitivity

 

nwuwhmm

 

 

 

 

 

 

{12 . _ . .. . . . . . . . . .l _
-  . - . i I _ —1-

  (XIA.B). Auc=o.94 

“11.5 5: 6.2 0.3 54 {TE 55 53 [Ta is 1.0 '12 —'1

1 - Speciﬁcity

 

 

 

Fig. 1. An example of a classiﬁcation problem with three features (A, B, C) and two class variables (X, 30. The true dependency structure is depicted as a
graph (top left). Class variables are not predictable from any single feature, but from different pairs of features. Classiﬁcation of X is possible from
features A and B, while classiﬁcation of Y requires features A and C (scatter plots, top right, green and blue dots represent examples positive with respect
to X and Y variables, respectively). Continuous feature variables have different noise/signal ratios (gray histograms, top right), but all of them are
accurately described by the ﬁtted Gaussian model (orange and red lines). The exemplary ROC curve for classiﬁcation of variable X (bottom left)

to yield networks with the user-speciﬁed error rate
(Supplementary Methods and Tutorial).

After the publication of the original BNFinder method, it was
shown that the polynomial algorithm introduced by Dojer (2006)
can also be applied to the Mutual Information Test (MIT), an-
other BN scoring function based on mutual information (Vinh
et al., 2011). The authors have shown that the MIT score gives
more accurate results than the Minimal Description Length
(MDL) score, while taking less time than Bayesian Dirichlet
equivalence (BDe) score. As this compromise between accuracy
and speed is desirable, we decided to adapt BNFinder to include
the MIT score. This allows users to ﬁnd networks with optimal
MIT score not only in case of Dynamic BNs as presented
by Vinh et al. (2011) but also in the case of static BNs with
constrained topology. Our current implementation allows users
to freely choose from all three scoring functions: MDL, BDe
and MIT for static and dynamic BNs. Additionally, we provide
a generalized MIT score for continuous variables
(Supplementary Methods and Tutorial).

While BNFinder uses an efﬁcient algorithm for BN structure
learning, the original implementation was limited to running on a
single CPU due to the limitations of the Python interpreter. Since
then, multicore CPUs have become a majority and multiprocess-
ing support was introduced into the Python language.
BNFinder2 takes advantage of these developments to facilitate
using multiple CPU cores for faster computation. As the learning
method used in BNFinder performs parent-set optimizations in-
dependently for each variable, it can be parallelized efﬁciently.
Supplementary Figure S2 shows that using BNFinder2 one can

achieve speed-ups almost linearly scaling with the number of
cores available on different hardware platforms.

In summary, BNFinder2 represents a signiﬁcant improvement
over the original method in several aspects. From the user per-
spective, it allows for using BNFinder2 in classiﬁcation setting
with automated cross-validation, accuracy scoring and ROC
plotting. Methodologically, it also provides a more comprehen-
sive method for inferring networks with predeﬁned error rate and
introduces the possibility of calculating the optimal networks
under the MIT score adapted to handle continuous variables
as well as discrete ones. Last but not least, BNFinder2 can use
parallelization on muliplecore machines to greatly improve the
running times of BN learning, especially in case of the BDe score.

Funding: Polish Ministry of Science and Higher Education grant
[N N301 065236 to B.W. and ND] and Foundation for Polish
Science within Homing Plus programme co-ﬁnanced by the
European Union—European Regional Development Fund [to
AP. and PB].

Conﬂict of Interest: none declared.

REFERENCES

Beer,M.A. and Tavazoie,S. (2004) Predicting gene expression from sequence. Cell,
117, 185—198.

Bonn,S. et al. (2012) Tissue-speciﬁc analysis of chromatin state identiﬁes temporal
signatures of enhancer activity during embryonic development. Nat. Genet, 44,
148—156.

 

2069

112 /810'S[12u1no [pJOJXO'SOIJBIIIJO}LIIOIQ//Idllq 11101; pepeommoq

9IOZ ‘091sn3nv uo ::

N.Dojer et al.

 

Chickering,D. (1995) Learning Bayesian networks is NP-complete. In: Proceedings
of AI and Statistics. Vol. 1995, Fort Lauderdale, Florida.

Dabrowski,M. et al. (2010) Comparative analysis of cis-regulation following stroke
and seizures in subspaces of conserved eigensystems. BM C Syst. Biol, 4, 86.

Dojer,N. (2006) Learning Bayesian networks does not have to be NP-hard. LN CS,
4162, 305—3 14.

Dojer,N. et al. (2006) Applying dynamic Bayesian networks to perturbed gene
expression data. BM C Bioinformatics, 7, 249.

J ansen,R. et al. (2003) A Bayesian networks approach for predicting protein-protein
interactions from genomic data. Science, 302, 449—453.

Kontkanen,P. et al. (2001) Classiﬁer learning with supervised marginal likelihood.
In: Proceedings of the seventeenth conference on uncertainty in artificial intelli-
gence. Morgan Kaufmann Publishers Inc, Seattle, Washington, pp. 277—284.

Needham,C. et al. (2007) A primer on learning in bayesian networks for computa-
tional biology. PLoS Compat. Biol, 3, 6129.

Sing,T. et al. (2005) Rocr: visualizing classiﬁer performance in r. Bioinformatics, 21,
3940—3941.

Van Steensel,B. et al. (2010) Bayesian network analysis of targeting interactions in
chromatin. Genome Res, 20, 190—200.

Vinh,N. et al. (2011) GlobalMIT: learning globally optimal dynamic Bayesian net-
work with the mutual information test criterion. Bioinformatics, 27, 2765—2766.

Wilczynski,B. and Dojer,N. (2009) Bnﬁnder: exact and efﬁcient method for learning
Bayesian networks. Bioinformatics, 25, 286.

Wilczynski,B. et al. (2012) Predicting spatial and temporal gene expression using
an integrative model of transcription factor occupancy and chromatin state.
PLoS Comput. Biol, 8, 61002798.

 

2070

112 /810's112u1no prOJXO'SOIlBIHJOJUIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘091sn3nv uo ::

