ORIGINAL PAPER

Vol. 30 no. 21 2014, pages 3062—3069
doi:10. 1093/bioinformatics/btu488

 

Gene expression

Advance Access publication July 23, 2014

Mas-o-menos: a simple sign averaging method for discrimination

in genomic data analysis

Sihai Dave Zhao1 ’*, Giovanni Parmigiani2’3, Curtis Huttenhower2 and Levi Waldron4

1Department of Statistics, University of Illinois at Urbana—Champaign, Champaign, IL 61820, 2Department of
Biostatistics, Harvard School of Public Health, Boston, MA 02115, 3Department of Biostatistics and Computational
Biology, Dana—Farber Cancer Institute, Boston, MA 02115, 4City University of New York School of Public Health, Hunter

College, New York, NY 10035, USA

Associate Editor: Ziv Bar-Joseph

 

ABSTRACT

Motivation: The successful translation of genomic signatures into
clinical settings relies on good discrimination between patient sub-
groups. Many sophisticated algorithms have been proposed in the
statistics and machine learning literature, but in practice simpler
algorithms are often used. However, few simple algorithms have
been formally described or systematically investigated.

Results: We give a precise definition of a popular simple method we
refer to as més-o—menos, which calculates prognostic scores for
discrimination by summing standardized predictors, weighted by
the signs of their marginal associations with the outcome. We
study its behavior theoretically, in simulations and in an extensive
analysis of 27 independent gene expression studies of bladder,
breast and ovarian cancer, altogether totaling 3833 patients with
survival outcomes. We find that despite its simplicity, mas-o-menos
can achieve good discrimination performance. It performs no
worse, and sometimes better, than popular and much more
CPU-intensive methods for discrimination, including lasso and ridge
regression.

Availability and Implementation: Mas-o-menos is implemented for
survival analysis as an option in the survHD package, available
from http://www.bitbucket.org/lwaldron/survhd and submitted to
Bioconductor.

Contact: sdzhao@illinois.edu

Received on April 19, 2014; revised on June 23, 2014; accepted on
July 11, 2014

1 INTRODUCTION

The successful translation of genomic signatures into clinical
settings relies on good discrimination between patient subgroups
that should receive different clinical management. Relatively,
sophisticated methods such as penalized regression, support
vector machines, random forests, bagging and boosting have
seen detailed treatments in the statistics and machine learning
literature (Biihlmann and Van De Geer, 2011; Hastie et al.,
2005; Scholkopf and Smola, 2002); however, in practice many

 

*To whom correspondence should be addressed.

researchers prefer simpler algorithms (Hand, 2006). A systematic
meta-analysis of prognostic models for late-stage ovarian cancer
WValdron et al., 2014) found that the most common methods in
the ﬁeld, and those used to generate the best-performing models
on independent datasets, were of the ‘univariate ensemble’ type,
where results of univariate regressions are aggregated to formu-
late a risk score.

The simplest of the univariate ensemble class of prediction
methods sets the coefﬁcients of a linear risk score for
standardized covariates equal to the signs of their univariate
associations with the clinical outcome of interest. In other
words, for survival analysis it produces a risk score equal to
the sum of the ‘bad prognosis’ features minus the sum of the
‘good prognosis’ features. This method and closely related vari-
ants can be found in the top clinical, bioinformatic and general
science journals (Bell et al., 2011; Colman et al., 2010; Dave
et al., 2004; Reme et al., 2013) and in commercially available
prognostic gene signatures, such as the MyPRS signature for
multiple myeloma prognosis (Shaughnessy et al., 2007). It has
even been proposed, in a formula-free article, as a practical al-
gorithm that can be performed in a spreadsheet with the ‘soft—
ware and skill sets available to the cancer biologist’ (Hallett et al.,
2010).

Despite the popularity and apparent effectiveness of
this simplest of methods, to our knowledge, it has never been
formally described or systematically investigated. We give a pre-
cise deﬁnition of the procedure and study its behavior theoretic-
ally, in simulations and in an extensive analysis of 27
independent gene expression studies of bladder, breast and ovar-
ian cancer, altogether totaling 3833 patients with survival out-
comes. We provide theoretical arguments that this method has
good discrimination power and low variability when positively
correlated features tend to have the same directions of marginal
association with outcome. In simulations under a variety of
sparsity and covariance structures, it performs competitively
with lasso and ridge regression under all situations except the
unlikely scenario of independent features, and was more than
an order of magnitude faster. In application to survival analysis
of three large microarray databases, it performed better than
lasso and ridge regression in two of three cancer types, and
comparably in the third. We refer to the method as mas-
o-menos because in Spanish the phrase ‘mas o menos’ means
both ‘plus or minus’, describing the method’s implementation,

 

3062 © The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com

112 [glO'SIBILInO[plOJXO'SODBIILIOJHIOIQ/[ldllq IIIOJJ popcolumoq

910K ‘09 lsnﬁnV no :2

Mas-o-menos

 

and ‘so-so’, describing its theoretically non-optimal but still prac-
tically useful discrimination ability.

2 METHODS

2.1 Mas-o-menos

Let each component X i]- of the p x 1 covariate vector X,- = (X ,1, . . . , X ip)T
be a quantitative measurement of the jth gene from the ith subject. The X i]-
could represent various types of genomic information, such as expression
levels from microarrays or next-generation sequencing experiments, or
non-genomic data. Mas-o-menos uses a patient’s X,- to calculate a
signed sum of that patient’s covariate values. The procedure is as follows:

(1) Standardize the covariates such that
(n —1)_IZ(X,-j — 192 = 1,j= 1, . . . ,p, where 71- = n‘IZXU.

(2) Perform univariate regressions of the outcome on each igene to
obtain marginal estimates of the regression coefﬁcient 65,-.

(3) Let 1?,- = sgn(&j)/p1/2, where sgn(c) = 2I(c>0) — 1 for c 75 0 and
sgn(c) =0 for c = 0.

(4) The risk score for the 1'” patient is calculated as  e, where
I]; = (91,...,ﬁp)T.

The factor of 121/2 in the deﬁnition of the 171- merely serves to ensure the
arbitrary scaling ||v| |2 = 1. By changing the regression model used in step
(3), mas-o-menos can be used with clinical outcomes of any type, such as
continuous, binary or censored data. The discrimination performance of
9 can be quantiﬁed using correlation for continuous outcomes, the
area under the receiver operating characteristic curve for binary outcomes
(Bamber, 1975) or the C-statistic for censored outcomes (Uno et al.,
2011).

Mas-o-menos, and procedures similar to it, is already in use for ana-
lyzing genomic data. For example, Donoho and Jin (2008) introduced a
family of classiﬁers, one of which, called HCT-clip, is equivalent to mas-
o-menos. They found that HCT-clip performed surprisingly well in
cross-validation experiments using standard datasets with uncensored
outcomes. Some also use marginal regression to identify good and bad
prognosis covariates, which are then used to rank patients by risk.
Ranking methods include the t-statistic for difference in expression of
good versus bad prognosis genes (Bell et al., 2011; Verhaak et al.,
2013) and signed averaging of discretized or continuous expression
values (Colman et al., 2010; Dave et al., 2004; Hallett et al., 2010;
Kang et al., 2012; Rome et al., 2013). Replacing lasso coefﬁcients by
their signs has been proposed for summarizing gene pathway activity
(Eng et al., 2013).

It may sometimes be helpful to perform an initial feature selection
step before implementing mas-o-menos, as we argue in Section 2.3.
Feature selection has been the subject of a great deal of research, and a
detailed discussion is beyond the scope of this article. In our data analysis
in Section 3.3, we found that selection had little effect on the discrimin-
ation ability of mas-o-menos. However, selection can provide more
interpretable models by dramatically reducing the number of genes
required for prediction.

2.2 Discrimination for survival outcomes

We focus on survival outcomes because they are typically the most
difﬁcult to deal with and the most clinically relevant and are the outcomes
collected in our real data. Let T, be the survival time of the ith
subject. To measure discrimination in the survival setting, we use
the C-statistic over the follow-up period (0,1), deﬁned by Uno et al.
(2011) as

CAB) = P{g(Xz-) > g(Xj)| Ti < Tj, Ti < T}, (1)

where g(X) is the risk score for a subject with covariate vector X. We
consider linear risk scores of the form g(X) = XTB for B = (,81, . . . , ,8p)T.
We deﬁne the optimal weight vector to be

30 = argmaxP(Xl-Tﬂ > ijmT, < T], T, < r),
ﬂillﬂo "2:1
where we have arbitrarily scaled Bo to have norm 1 because C,(B) is
invariant to scaling of [3.

To implement mas-o-menos in this setting, we will obtain the 651- by
ﬁtting univariate Cox models. We choose the Cox model because it is a
well-established and well-understood procedure in clinical research.
In addition, the estimators 641- converge to well-deﬁned aoj even when
the Cox model is not correctly speciﬁed (Lin and Wei, 1989; Struthers
and Kalbﬂeisch, 1986), as is likely to be the case in our marginal regres-
sions. Finally, if the data truly come from a Cox model, the true
parameter vector should maximize Cr and should be a scalar multiple
of the optimal Bo.

2.3 Statistical properties

We show that under certain conditions, the mas-o-menos weights
can have good discrimination power along with low variability. Hand
(2006) provided similar arguments to justify equalization of regression
coefﬁcients when all covariates have the same directions of effect
on the outcome, and this direction is known a priori. Hand describes
this in terms of the ‘ﬂat maximum effect’: that in the context of classiﬁers,
often little advantage can be gained in prediction accuracy over simple
models. Here, we do not assume that the directions of effect are known.

Let v* = (v’f,  , v3)T be the probability limit of 9, such that v —> v*.
Because 17}- = sgn(6tj), if 651- —> my in probability, then by the continuous
mapping theorem V; = sgn(ocoj). We will analyze the performance of the
mas-o-menos estimator o in terms of the discrimination ability of v*
relative to that of Bo, and the variability of 9 around v*. For now, we
assume vj’l‘ 75 0 for all genes j. At the end of the section we discuss the
implications if this is not true.

By the deﬁnition of C1, the discrimination performance
of v*=(v’f,...,v1’,j‘)T depends only on the degree of linear association
between Bo and v*. In addition,

cov(X,.T 0, v*) = Z ,BOJ-cov(X,-j, X ,7,v,’:)
j,k

= Z ,BOJ-VJ’FZ cov(X,-jvj’l‘, Xikvl’ﬁ) 2 E: ,BOJ-vj’i,
j k j

where To=minjp‘lzk cov(X,-jvj’5‘,X,-kv;:). The second equality follows

because vj’l‘ - V;

with [30, and will have similar discriminative ability, under the condi-

always equals 1. Thus, v* will be highly correlated

tion that Z ,BOJ-vj’l‘ and E have the same sign.
J

It is not unreasonable to expect these terms to be positive. First,
each ,BOj quantiﬁes the association between X i]- and T,- conditional on all
genes in X,, while each vj’l‘ reﬂects its univariate association. If a gene has
the same direction of effect in both the conditional and marginal
models, then ,BOJ-vj’l‘ >0. This is plausible for at least some genes, and
even if it does not hold for all genes :1. ,BOJ-vj’i can still be positive.
Second, the To term is the minimum average covariance between X
and X ikvlt. This will be positive if genes with the same marginal
directions of effect tend to be positively correlated, while genes with dif-
ferent marginal directions of effect tend to be negatively correlated.
Indeed, the encoded proteins of conserved co-expressed gene pairs are
likely to be part of the same biological pathway (van Noort et al., 2003).
Again, 70 can be positive even if this covariance condition holds only for
some pairs of genes, as we merely need the average covariance to be
positive.

 

3063

112 /810's112umo[pJOJXO'soi1chOJuioiw/2d11q IIIOJJ popcommoq

910K ‘09 lsnﬁnV no :2

S.D.Zhao et al.

 

Restricting the mas-o-menos weights to be either + 1 or —1 endows it
with low variability, which has been shown to be especially important in
classiﬁcation (Friedman, 1997). The variability of 171- is given by

 <   Otoj > 0,
 75 11;):  >   Otoj < 0,
Ma,- 72 0) if a0,- = 0.

Lin and Wei (1989) showed that 641- —> N(Otoj,0’12/I’l) for some aoj and a}.
This approximation, combined with Mill’s inequality, gives the approxi-
mate relation

0’

P(‘ 75 *) 1 ex N31"
v- v. — ———
J J nl/zlaojlv2n p 2 012

when my 75 0, which approaches 0 much faster than var(6tj). For large n
and/or large laojl, the variability of 171- will be close to zero. Thus, 6 is
likely to be less susceptible to overﬁtting and, as a result, can have better
out-of-sample discrimination performance.

Difﬁculties arise when v’l‘ = 0 for some marginally unimportant genes j.
First, cov(Xl.T 0, v*) will depend in part on the covariances between
these genes and the marginally important ones, and it is unclear how
these covariances will behave. Second, as 651- is a continuous estimator, P
(65}- 75 0) will equal 1 for any sample size. In other words, mas-o-menos
may be less predictive and more variable when used on data where many
of the covariates are not marginally associated with the outcome. An
initial feature screening step may remove many such covariates, so that
there are few j such that aoj = 0. On the other hand, because gene

Sparse, p=100

Sparse, p=10000

expression levels tend to be correlated, even genes not involved in the
disease process may be correlated to important genes and may have non-
zero marginal associations.

3 RESULTS
3.1 Competing methods

We compared mas-o-menos to three popular analysis methods
that also generate linear risk scores, lasso (Tibshirani, 1996,
1997), ridge regression (Hoerl and Kennard, 1970; Verweij and

Table 1. Average simulation runtimes

 

 

Method P = 100 P = 10 000
Lasso 8.914 47.238
Ridge 0.645 30.124
Marginal 0.016 2.209
Mas-o-menos 0.023 2.408
Single 0.017 1.674
Random 0.001 0.004

 

Runtimes are reported in seconds

Non-sparse, p=100 Non-sparse, p=10000

 

05 07 09
—>—
I-O—

69

«e—

I

:E-

I

I

I

é;

-e—

I

41 ------- -- -ir-+-+®+-i

 

Easy covariance

 

“up

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

p=0.3§+++® *++®
:' <1 4, i‘ <l> 4’
C: II A 9%) E A .@
p=0_5g:+++®¢ I++®¢ 4, <1
2ill-519911114499-14114-l-®-¢-il~+-+®M
2 Uni-@434 4-I-®-l’-Ii--t-+®¢-4lw—+-+®i-i

 

 

 

Fig. 1. Average validation C-statistics of different discrimination methods in simulated data. Mas-o-menos results highlighted by circle. Vertical bars

represent conﬁdence intervals

 

3064

112 /810's112umo[pJOJXO'soi1cm101uioiqj/2d11q 111011 p9p1201umoq

910K ‘09 lsnﬁnV no 22

Mas-o-menos

 

Van Houwelingen, 1994) and marginal regression (Emura et al.,
2012), which gives risk scores of the form 2]. X yo? j. For all meth-
ods we ﬁrst standardized all covariates to have unit variance. We
also included two negative controls: (i) the single gene with the
largest 07]- estimated from the training set and (ii) randomly gen-
erated risk scores 2]. XiJ-Zj, where the Zj were drawn independ-
ently from a standard normal.

We implemented lasso and ridge regression for the Cox model
using the package glmnet (Friedman et al., 2010), selecting the
penalty parameter using 3-fold cross-validation using the built-in
function. Marginal Cox regressions and mas-o-menos are imple-
mented in the package survHD (Bernau et al., 2012).

3.2 Simulations

To simulate training data, we generated p x 1 covariate vectors
X,- and survival times from a Cox model with a p x 1 true par-
ameter vector 30. We let the true Cox regression coefﬁcient
vector 30 have s non-zero components all with magnitude
5—1/2, such that llﬂollz = 1. The ﬁrst s/2 non-zero components
were positive and the rest were negative. We generated censoring
times from an independent exponential distribution to give
~50% censoring. In each testing dataset, we replaced the positive
entries of 30 by random uniform draws from (0, 4/51/2), and the
negative entries by random draws from (—4/sl/2, 0). Each train-
ing and testing dataset contained 11 = 200 observations.

We considered the low-dimensional case of P = 100 and the
high-dimensional one of P = 10000. To generate sparse 30, we
lets = 10, and for non-sparse 30 we lets = P. We drew X,- from
a multivariate normal with mean zero and unit marginal
variance. From Section 2.3, the discrimination ability of mas-
o-menos depends on the covariance structure of the X. In an
‘easy’ setting, the covariates were divided into two blocks, with
X i]- positively correlated within blocks and negatively correlated
between blocks. Those Xij with ,BOJ->0 were assigned to one
block, those with ,BOJ-<0 were assigned to the other and those
with ,BOJ- = 0 were assigned equally between the blocks. In a ‘hard’
setting, we let cov(X,-J-, Xik) > 0 for j and k both even or both
odd, and cov(X,-J- Xik) < 0 otherwise. We let |cov(X,-J- Xik)| =0,
0.3 or 0.5 for all j and k and ran 200 simulations.

The computations in this article were run on the Odyssey
cluster supported by the Faculty of Arts and Sciences (FAS)
Science Division Research Computing Group at Harvard
University. Table 1 illustrates the speed advantage enjoyed by
mas-o-menos.

In general, mas-o-menos kept pace with lasso, ridge and mar-
ginal regression. Each of these performed better than the single
best gene and the randomly generated negative control. Figure 1
reports the average out-of-sample C-statistics obtained by the
different methods. The C-statistics were calculated at T: 2,
where ‘L' is deﬁned in (1). Conﬁdence intervals represent the em-
pirical 2.5 and 97.5% quantiles. The results clearly illustrate the
importance of the covariance structure. All of the methods
except for the negative control performed better under the easy
covariance setting than under the hard one. The easy covariance
satisﬁes the assumptions of the theoretical discussion in Section
2.3: cov(X,-J-v;‘, T i) > 0 and cov(X,-J-v;‘, Xika) > 0 for all j, k.
The difﬁculty of the hard covariance structure arises from
the fact that it is impossible to meet this condition. For example,

by construction, cov(X,-1, T i) > 0 and cov(X, , T i) > 0, but
cov(X,-1,X,-2)<0. In other words, the signs of the ,BOJ- and the
covariances are incoherent in the hard covariance case.

When the covariates were independent, higher dimensionality
made discrimination harder regardless of sparsity, perhaps
because there was no way to borrow information across the
covariates. Under the easy covariance structure with a dense
30, however, high dimensionality was actually beneﬁcial, per-
haps because if the effects of some covariates were by chance
incorrectly estimated, there were many other correlated ones that
could be used as surrogates. On the other hand, with a hard
covariance matrix, dimensionality added difﬁculty even in the
non-sparse case because of the incoherence between the ,BOJ- and
the covariate correlations.

With no correlation, sparsity allowed for easier discrimination.
When correlation was introduced in the easy covariance setting,
sparsity was detrimental to prediction. This might have been
owing to the screening step because univariate screening is
liable to retain unimportant covariates simply because they are
correlated with important ones. These incorrectly retained
covariates can degrade performance. In the hard covariance set-
ting, however, sparsity was helpful regardless of the level of
correlation. This may be because in the sparse case, there were

Table 2. Cancer gene expression datasets

 

 

Reference Sample size Events
Bladder, 2463 common probesets
Als et al. (2007) 30 25
Blaveri et al. (2005) 80 44
Kim et al. (2010) 165 69
Lindgren et al. (2010) 87 26
Riester et al. (2012) 93 65
Sjodahl et al. (2012) 224 25
Breast, 9768 common probesets
Desmedt et al. (2007) 134 35
Foekens et al. (2006) 710 191
Minn et al. (2005) 245 76
Minn et al. (2007); Wang et al. (2005) 209 80
Schmidt et al. (2008) 162 33
Sotiriou et al. (2006) 85 19
Symmans et al. (2010) 164 38
Ovarian, 6138 common probesets
Bentink et al. (2012) 128 73
Crijns et al. (2009) 98 72
Bonome et al. (2008) 185 129
Denkert et al. (2009) 41 13
Dressman et al. (2007) 59 36
Ferriss et al. (2012) 30 22
Konstantinopoulos et al. (2010) 28 17
Konstantinopoulos et al. (2010) 42 23
Mok et al. (2009) 53 41
Bell et al. (2011) 452 239
Tothill et al. (2008) 140 72
Yoshihara et al. (2010) 43 22
Yoshihara et al. (2012) 129 60
Yoshihara et al. (2012) 17 10

 

 

3065

112 /810's112umo[pJOJXO'soi1cm101uioiqj/2d11q 111011 p9p1201umoq

910K ‘09 lsnﬁnV no 22

S.D.Zhao et al.

 

 

 

 

 

 

 

 

 

112 /810's112umo[pJOJXO'sog1cm101utogqj/2d11q 111011 p9p1201umoq

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Bladder, no screening Bladder, HC screening
Lasso  Lasso 
'3 I- ' I—I—> 5' I 'I—I—>
_ O 0.63 [0.58,0.67] 5 . 0.64[0.60,0.68]
' 5' ' ' I—I ' ; ' ' I—I—>
 - 0.69 [065,072]  - 0.64[0.60,0.68]
Marginal  Marginal  I—I—I
- 0.71 [067,074]  - 0.69[0.65,0.73]
Més-o-menos  Més-o-menos 
_ - 0.71 [067,074] 5 - 0.71 [067,074]
Single Gene  Single Gene 
,_.'—_'—:'. ._’—'._5‘:.'
I—e—u—I H—I—I
 0.54[0.49,0.58]  0.54[0.49,0.58]
Random  Random 
 0.45[0.40,0.50] g - 0.57[0.53,0.62]
I I g I I I I I g I I I
0.25 0.39 0.54 0.68 0.83 0.25 0.40 0.54 0.69 0.83
C-statistics C-statistics
Breast, no screening Breast, HC screening
Lasso  'I—._I.—I_." Lasso  I—I:L_."'
- I—I—> . |—l—>
. s '—'—’I—I—«
5 - 0.73[0.69,0.76] 5 - 0.70[0.67,0.74]
Rid e  ﬂ: Rid e '
9 5 .—I_.i 9
g I—I—I I
d38[0.75,0.81] 5 .0.75[0.72,0.7s]
Marginal  '—'—’I—I—a Marginal  ' I—I—I' ’
a E a it
I—I—I f I—I—I
-0.74[0.70,0.77] 5 -0.74[0.71,0.78]
Més-o-menos  ' I—I—I' Més-o-menos  :Ei'l—I—I"
5 - 0.72[0.69,0.76] g .0.75[0.72,0.7s]
Single Gene I I—I—E—I,’—'—' Single Gene 
I—l—I I—l—I
‘—'—._'.'_. ‘—'—._.‘_.
Q 0.49 [045,053] ‘2» 0.49[0.45,0.53]
Random .—I—.I——I__.  ' Random ' ,—.__. 'I—I—I 
 I ‘  ‘
‘3» 0.49 [045,053]  0.47[0.44,0.51]
I I Q I I I I I 5 I I I
0.25 0.39 0.53 0.67 0.81 0.25 0.39 0.54 0.68 0.82
C-statistics C-statistics
Ovarian, no screening Ovarian, HC screening
Lasso . H—_._ Lasso :*':__,_
o 0.57 [054,059] g ; 0.58[0.55,0.60]
Ridge  Ridge ‘ —'—'._—._,

.—.—q
l—I—l

 

0.60 [0.58 , 0.63] 0.58 [ 0.56 , 0.60 ]

I.

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Marginal 5 '—.:._. Marginal 5 ’—'.;._.
 o 0.59 [0.57 , 0.61 ] 5 o 0.59 [0.57 , 0.61 ]
Més-o-menos 5 —'—'.—.— Més-o-menos 3 —'—_.—
)—-—I : D—I—I
5 - 0.59 [0.56 , 0.61 ] 5 o 0.59 [0.57 , 0.62]
- ———'—I=-.;— - —_——.='-.:—'—

 

 

 

 

0.51 [0.49 , 0.54] 0.51 [0.49 , 0.54]

 

 

 

 

 

 

 

 

 

Random w 5"— Random :—'—.—.—.

 

 

 

 

: 0.51[0.48,0.53] g - 0.55[0.52,0.57]
I I 3 I I I I I 3 I I I
0.25 0.39 0.53 0.66 0.80 0.25 0.39 0.53 0.66 0.80
C-statistics C-statistics

Fig. 2. Validation C-statistics at T: 5 years using different discrimination methods

910K ‘09 lsnﬁnV no 22

 

3066

Mas-o-menos

 

Bladder

 

Ovarian

 

0.70
|

C-statIstIc

04 05 06 07 08
I I
cum-1
ID]
|.-

I--|]:I-|

 

 

 

 

I-ﬂji
D
1

 

C-statistic
0 5

 

 

 

I.--
-+I:I1—-+
03 04
|
|._

 

’b-Iu-ml
C-statistic
0.50 0.60
I I I I
+I:II+
+--:II+

 

+ —
' _ 8 _ _ o o
I QI \I I QI C5 I I I I I I I \I I I I
o to 9 \ o o
’00“? ‘qu 50° 60° "’0 6° 69° 69% ‘5‘) cog (79% 60$ 990 ‘qu ‘60 00% 9° 60$
Q7 K 92 0 ’0 \ o ’0 «Q2 (’4 0.:
\/ Q’b ’0 \6 Q9» \/ QT <0 \QQ’ (09 V Q. ’0’ (Q \Q ’00
,o 609 5 ,o/ .09 3 S ,o’ 5.0% 3
$0 $0 ‘5‘ $59 ‘5

Fig. 3. Average 3-fold cross-validation C-statistics at T: 5 years, calculated within each dataset of each disease type; no feature screening was

implemented

fewer important covariates with which the hard covariance struc-
ture could cause difﬁcultly.

3.3 Application to bladder, breast and ovarian cancer

We applied mas-o-menos, lasso, ridge, marginal regression and
the two negative control methods to an extensive compendium of
real cancer gene expression data (Table 2). We obtained six blad-
der cancer datasets totaling 679 patients from Riester et al.
(2012), seven breast cancer datasets totaling 1709 patients from
Haibe-Kains et al. (2012) and 14 ovarian cancer datasets totaling
1445 patients from Ganzfried et al. (2013). We processed
the breast cancer data as in Bernau et al. (2014). The bladder
and ovarian cancer data have been manually curated to have
standardized clinical annotations, probeset identiﬁers and micro-
array preprocessing, and are available in the Bioconductor pack-
ages curatedBladderData and curatedOvarianData,
respectively.

For each disease, we limited our analyses to the probesets
common to all studies. We trained each algorithm on the largest
available study and evaluated its performance on each of the
remaining datasets using the C-statistic calculated at T: 5
years, where ‘L' is deﬁned in (1). Roughly 60% of all study
participants, combined across all diseases, were still alive after
5 years. The C-statistic is robust to the choice of 1' unless few
deaths or censoring events occur at times greater than T (Uno
et al., 2011).

We generated 100 bootstrap samples of each validation dataset
to obtain 95% conﬁdence intervals. In addition to applying the
methods without feature selection, we also implemented higher
criticism thresholding (Donoho and J in, 2008), which screens out
covariates with high marginal Cox regression P—values but is
entirely data-driven and automatically chooses the number of
covariates to retain. Summary statistics were calculated by
ﬁxed effects meta-analysis with the metafor package
Wiechtbauer, 2010).

Figure 2 reports the results. Selecting only a single gene or
using random weights gave the lowest performance, conﬁrming
the appropriateness of our negative controls. Mas-o-menos was
consistently on par with lasso, and even outperformed lasso in
several cases. Its performance was much more similar to those of

ridge and marginal regression. Screening did not dramatically
affect the performances of any of the methods.

A referee noted that it is unclear how well mas-o-menos
performs within a single dataset, as opposed to across datasets.
To answer this question, we evaluated the performance of each
risk prediction algorithm within each dataset of each disease type
by calculating the average 3-fold cross-validated C-statistic at
T: 5 years. No feature screening was implemented. Figure 3 re-
ports the results and shows that mas-o-menos was again on par
or better than the other methods. It appears that in addition to
being robust across studies, mas-o-menos is also simply a good
predictor.

4 DISCUSSION

We have studied mas-o-menos, a simple algorithm for classiﬁca-
tion and discrimination that has seen popular adoption but has
not been formally investigated. We gave a precise deﬁnition of
the algorithm, showed theoretically and in simulations that it can
perform well and demonstrated in an extensive analysis of real
cancer gene expression studies that it can achieve good discrim-
ination performance in realistic settings, even compared with
lasso and ridge regression. Our results provide some justiﬁcation
to support its widespread use in practice. We hope our work will
help shift the emphasis of ongoing prediction modeling efforts in
genomics from the development of complex models to the more
important issues of study design, model interpretation and inde-
pendent validation.

One reason why mas-o-menos is comparable with more
sophisticated methods such as penalized regression may be that
we often use a prediction model trained on one set of patients to
discriminate between subgroups in an independent sample,
usually collected from a slightly different population and pro-
cessed in a different laboratory. This cross-study variation is not
captured by standard theoretical analyses, so theoretically
optimal methods may not perform well in real applications
(Hand, 2006). Bernau et al. (2014) proposed a method for
giving a realistic measure of the practical utility of algorithms
in the presence of cross-study variation. At the same time, we
found using cross-validation experiments that even within the

 

3067

112 /810's112umo[pJOJXO'sog1cm101utogqj/2d11q 111011 p9p1201umoq

910K ‘09 lsnﬁnV no 22

S.D.Zhao et al.

 

same dataset, mas-o-menos remained competitive with more
sophisticated methods.

Batch effects create study-speciﬁc measurement bias, and are
widespread and often unidentiﬁed in genomic data (Leek et al.,
2010). They may be responsible for the cross-study variation that
degrades the performance of algorithms such as lasso or ridge
regression. Although certain batch-correction techniques have
gained widespread use (Leek and Storey, 2007; Li and
Rabinovic, 2007), these have been motivated primarily by class
comparison rather than class prediction. In a genomic prediction
competition, batch correction was seen to provide no overall
beneﬁt for validation accuracy (MAQC Consortium, 2010).
Rather, we propose that the impact of unknown batch effects
may be best mitigated by using methods less prone to over-
ﬁtting. Mas-o-menos risk scores have lower variability, and
may be less associated with batch, than those of the other
methods, which might explain its robust performance in both
cross-validation and cross-study validation in 27 datasets from
three cancer types.

While we focused on microarray data and survival endpoints,
mas-o-menos can be applied to any type of outcome variable,
using any regression model, and has precedents for application in
diverse settings outside of genomics (Davis-Stober et al., 2010;
Wainer, 1976; Laughlin, 1978; Lovie and Lovie, 1986). It is fast
to implement, simple to interpret, comparable in performance
with more complex methods and appears robust to cross-study
variation. Mas-o-menos should be useful for developing predic-
tion models from high-dimensional data in any situation where
the covariates are sufﬁciently correlated and the true effect is
roughly linear.

ACKNOWLEDGEMENT

The authors thank the anonymous referees for comments, which
substantially improved this article.

Funding: This work was funded by the National Cancer Institute
at the National Institutes of Health (1RC4CA156551-01 and
5P30 CA006516-46 to GP.) and by the National Science
Foundation (CAREER DBI-1053486 to C.H.).

Conflict of Interest: none declared.

REFERENCES

Als,A.B. et al. (2007) Emmprin and survivin predict response and survival following
cisplatin-containing chemotherapy in patients with advanced bladder cancer.
Clin. Cancer Res., 13, 4407—4414.

Bamber,D. (1975) The area above the ordinal dominance graph and the area below
the receiver operating characteristic graph. J. Math. Psychol., 12, 387—415.
Bell,D. et al. (2011) Integrated genomic analyses of ovarian carcinoma. Nature, 474,

609—615.

Bentink,S. et al. (2012) Angiogenic mRNA and microRNA gene expression
signature predicts a novel subtype of serous ovarian cancer. PloS One, 7, 630269.

Bemau,C. et al. (2012) survHD: Synthesis of M icroarray-based Survival Analysis. R
package version 0.5.0. https://bitbuck6t.org/lwaldron/survhd.

Bemau,C. et al. (2014) Cross-study validation for assessment of prediction models
and algorithms. Bioinformatics, 30, i105—ill2.

Blaveri,E. et al. (2005) Bladder cancer outcome and subtype classiﬁcation by gene
expression. Clin. Cancer Res., 11, 4044—4055.

Bonome,T. et al. (2008) A gene signature predicting for survival in suboptimally
debulked patients with ovarian cancer. Cancer Res., 68, 5478—5486.

Bﬁhlmann,P. and Van De Geer,S. (2011) Statistics for High-dimensional Data:
Methods, Theory and Applications. Springer, Heidelberg.

Colman,H. et al. (2010) A multigene predictor of outcome in glioblastoma.
Neuro-oncology, 12, 49—57.

Crijns,A. et al. (2009) Survival-related proﬁle, pathways, and transcription factors in
ovarian cancer. PLoS Med., 6, 61000024.

Dave,S.S. et al. (2004) Prediction of survival in follicular lymphoma based on mo-
lecular features of tumor-inﬁltrating immune cells. N. Engl. J. Med., 351,
2159—2169.

Davis-Stober,C. et al. (2010) A constrained linear estimator for multiple regression.
Psychometrika, 75, 521—541.

Denkert,C. et al. (2009) A prognostic gene expression index in ovarian cancer-
validation across different independent data sets. J. Pathol, 218, 273—280.
Desmedt,C. et al. (2007) Strong time dependence of the 76-g6n6 prognostic
signature for node-negative breast cancer patients in the transbig multicenter

independent validation series. Clin. Cancer Res., 13, 3207—3214.

Donoho,D. and Jin,J. (2008) Higher criticism thresholding: Optimal feature selec-
tion when useful features are rare and weak. Proc. Nat Acad. Sci. USA, 105,
14790—14795.

Dressman,H. et al. (2007) An integrated genomic-based approach to individualized
treatment of patients with advanced-stage ovarian cancer. J. Clin. Oncol., 25,
517—525.

Emura,T. et al. (2012) Survival prediction based on compound covariate under cox
proportional hazard models. PLoS One, 7, 647627.

Eng,K.H. et al. (2013) Pathway index models for construction of patient-speciﬁc
risk proﬁles. Stat. Med, 32, 1524—1535.

Ferriss,J.S. et al. (2012) Multi-gene expression predictors of single drug responses to
adjuvant chemotherapy in ovarian carcinoma: predicting platinum resistance.
PloS One, 7, 630550.

Foekens,J.A. et al. (2006) Multicenter validation of a gene expression—based
prognostic signature in lymph node—negative primary breast cancer. J. Clin.
Oncol., 24, 1665—1671.

Friedman,J.H. (1997) On bias, variance, 0/lloss, and the curse-of-dimensionality.
Data Min. Knowl. Discov., 1, 55—77.

Friedman,J.H. et al. (2010) Regularization paths for generalized linear models via
coordinate descent. J. Stat. S0ftw., 33, 1—22.

Ganzfried,B.F. et al. (2013) curatedOvarianData: clinically annotated data for the
ovarian cancer transcriptome. Database, 2013, bat013.

Haibe-Kains,B. et al. (2012) A three-gene model to robustly identify breast cancer
molecular subtypes. J. Nat Cancer Inst, 104, 311—325.

Hallett,R.M. et al. (2010) An algorithm to discover gene signatures with predictive
potential. J. Exp. Clin. Cancer Res., 29, 120.

Hand,D.J. (2006) Classiﬁer technology and the illusion of progress. Stat. Sci., 21,
1—14.

Hastie,T. et al. (2005) The elements of statistical learning: data mining, inference
and prediction. Math. Intell., 27, 83—85.

Hoerl,A. and Kennard,R. (1970) Ridge regression: biased estimation for nonortho-
gonal problems. T echnometrics, 12, 55—67.

Kang,J. et al. (2012) A dna repair pathway-focused score for prediction of outcomes
in ovarian cancer treated with platinum-based chemotherapy. J. Nat Cancer
Inst, 104, 670—681.

Kim,W.J. et al. (2010) Predictive value of progression-related gene classiﬁer in
primary non-muscle invasive bladder cancer. Mol. Cancer, 9, 3.

Konstantinopoulos,P. et al. (2010) Gene expression proﬁle of BRCAness that cor-
relates with responsiveness to chemotherapy and with outcome in patients with
epithelial ovarian cancer. J. Clin. Oncol., 28, 3555—3561.

Laughlin,J.E. (1978) Comment on Estimating coefﬁcients in linear models: it don’t
make no nevermind. Psychol. Bull, 85, 247—253.

L66k,J.T. and Storey,J.D. (2007) Capturing heterogeneity in gene expression studies
by surrogate variable analysis. PLoS Genet, 3, 6161—6161.

L66k,J.T. et al. (2010) Tackling the widespread and critical impact of batch effects in
high-throughput data. Nat. Rev. Genet, 11, 733—739.

Li,C. and Rabinovic,A. (2007) Adjusting batch effects in microarray expression data
using empirical Bayes methods. Biostatistics, 8, 118—127.

Lin,D. and W6i,L. (1989) The robust inference for the Cox proportional hazards
model. J. Am. Stat. Assoc., 84, 1074—1078.

Lindgren,D. et al. (2010) Combined gene expression and genomic proﬁling
deﬁne two intrinsic molecular subtypes of urothelial carcinoma and gene
signatures for molecular grading and outcome. Cancer Res., 70, 3463—3472.

Lovie,A. and Lovie,P. (1986) The ﬂat maximum effect and linear scoring models for
prediction. J. Forecast, 5, 159—168.

 

3068

112 /810's112umo[pJOJXO'sot1em101utotqj/2d11q 111011 pep1201umoq

910K ‘09 lsnﬁnV no 22

Mas-o-menos

 

MAQC Consortium (2010) The microarray quality control (maqc)-ii study of
common practices for the development and validation of microarray-based pre-
dictive models. Nat. Biotechnol, 28, 827—865.

Minn,A.J . et al. (2005) Genes that mediate breast cancer metastasis to lung. Nature,
436, 518—524.

Minn,A.J. et al. (2007) Lung metastasis genes couple breast tumor size and meta-
static spread. Proc. Nat Acad. Sci. USA, 104, 6740—6745.

Mok,S. et al. (2009) A gene signature predictive for outcome in advanced ovarian
cancer identiﬁes a survival factor: microﬁbril-associated glycoprotein 2. Cancer
Cell, 16, 521—532.

R6me,T. et al. (2013) Modeling risk stratiﬁcation in human cancer. Bioinformatics,
29, 1149—1157.

Riester,M. et al. (2012) Combination of a novel gene expression signature with
a clinical nomogram improves the prediction of survival in high-risk bladder
cancer. Clin. Cancer Res., 18, 1323—1333.

Schmidt,M. et al. (2008) The humoral immune system has a key prognostic impact
in node-negative breast cancer. Cancer Res., 68, 5405—5413.

Sch61kopf,B. and Smola,A.J. (2002) Learning with Kernels: Support Vector
Machines, Regularization, Optimization, and Beyond. MIT press.

Shaughnessy,J. et al. (2007) A validated gene expression model of high-risk
multiple myeloma is deﬁned by deregulated expression of genes mapping to
chromosome 1. Blood, 109, 2276—2284.

Sj6dahl,G. et al. (2012) A molecular taxonomy for urothelial carcinoma.
Clin. Cancer Res., 18, 3377—3386.

Sotiriou,C. et al. (2006) Gene expression proﬁling in breast cancer: understanding
the molecular basis of histologic grade to improve prognosis. J. Nat Cancer
Inst, 98, 262—272.

Struthers,C. and Kalbﬂeisch,J. (1986) Misspeciﬁed proportional hazard models.
Biometrika, 73, 363—369.

Symmans,W.F. et al. (2010) Genomic index of sensitivity to endocrine therapy for
breast cancer. J. Clin. Oncol., 28, 4111—4119.

Tibshirani,R.J. (1996) Regression shrinkage and selection via the lasso. J. R. Stat.
Soc. Ser. B, 58, 267—288.

Tibshirani,R.J. (1997) The lasso method for variable selection in the Cox model.
Stat. Med, 16, 385—395.

Tothill,R. et al. (2008) Novel molecular subtypes of serous and endometrioid ovar-
ian cancer linked to clinical outcome. Clin. Cancer Res., 14, 5198—5208.

Uno,H. et al. (2011) On the c-statistics for evaluating overall adequacy of risk
prediction procedures with censored survival data. Stat. Med, 30, 1105—1117.

van Noort,V. et al. (2003) Predicting gene function by conserved co-expression.
Trends Genet, 19, 238—242.

Verhaak,R.G. et al. (2013) Prognostically relevant gene signatures of high-grade
serous ovarian carcinoma. J. Clin. Invest, 123, 517.

Verweij,P. and Van Houwelingen,H. (1994) Penalized likelihood in cox regression.
Stat. Med, 13, 2427—2436.

Viechtbauer,W. (2010) Conducting meta-analyses in R with the metafor package.
J. Stat. S0ftw., 36, 1—48.

Wainer,H. (1976) Estimating coefﬁcients in linear models: it don’t make no never-
mind. Psychol. Bull., 83, 213—217.

Waldron,L. et al. (2014) Comparative meta-analysis of prognostic gene signatures
for Late-Stage ovarian cancer. J. Nat Cancer Inst, 106, pii: dju049.

Wang,Y. et al. (2005) Gene-expression proﬁles to predict distant metastasis of
lymph-node-negative primary breast cancer. Lancet, 365, 671—679.

Yoshihara,K. et al. (2010) Gene expression proﬁle for predicting survival in advanced-
stage serous ovarian cancer across two independent datasets. PloS One, 5, 69615.

Yoshihara,K. et al. (2012) High-risk ovarian cancer based on l26-gene expression
signature Is uniquely characterized by downregulation of antigen presentation
pathway. Clin. Cancer Res., 18, 1374—1385.

 

3069

112 /810's112umo[pJOJXO'soi1em101uioiqj/2d11q 111011 pep1201umoq

910K ‘09 lsnﬁnV no 22

