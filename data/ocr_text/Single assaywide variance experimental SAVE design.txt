ORIGINAL PAPER

Vol. 29 no. 23 2013, pages 3067-3072
doi:10. 1093/bioinformatics/btt538

 

Systems biology

Advance Access publication September 20, 2013

Single assay-wide variance experimental (SAVE) design for

high-throughput screening

Carl Murie1’2, Caroline Barette3, Laurence Lafanechere3’4’5’6 and Robert Nadon1’2’*

1McGill University and Genome Quebec Innovation Centre, Montreal, Quebec H3A 0G1, Canada, 2McGill Department of
Human Genetics, McGill University, Montreal, Quebec H3A 1B1, Canada, 8Equipe Criblage pour des Molecules Bio—
Actives (CMBA), CEA Grenoble, Grenoble Cedex 09, France, 4INSERM, U823, 5Universite Joseph Fourier—Grenoble 1

and 6Institut Albert Bonniot, Grenoble F—38706, France
Associate Editor: Martin Bishop

 

ABSTRACT

Motivation: Advantages of statistical testing of high-throughput
screens include P-values, which provide objective benchmarks of
compound activity, and false discovery rate estimation. The cost of
replication required for statistical testing, however, may often be pro-
hibitive. We introduce the single assay-wide variance experimental
(SAVE) design whereby a small replicated subset of an entire screen
is used to derive empirical Bayes random error estimates, which are
applied to the remaining majority of unreplicated measurements.
Results: The SAVE design is able to generate P—values comparable
with those generated with full replication data. It performs almost as
well as the random variance model t—test with duplicate data and
outperforms the commonly used Z—scores with unreplicated data
and the standard t—test. We illustrate the approach with simulated
data and with experimental small molecule and small interfering
RNA screens. The SAVE design provides substantial performance
improvements over unreplicated screens with only slight increases
in cost.

Contact: robert.nadon@mcgill.ca

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on July 8, 2013; revised on September 5, 2013; accepted on
September 11, 2013

1 INTRODUCTION

High-throughput screening (HTS) provides concurrent testing of
large libraries for detecting biological activity among large num-
bers of compounds. For ease of exposition, we refer throughout
to compounds although the points made apply to other screened
objects such as small interfering RNAs (siRNAs). Advances in
combinatorial chemistry, robotic processing and plate miniatur-
ization have dramatically increased throughput. Large screens of
one million compounds or more, termed ultra-HTS, are increas-
ingly common in industry (Bobkova et al., 2010; Chung et al.,
2010; Madoux et al., 2010). This has led to pressure to reduce
costs associated with the increased volume of screens.

 

*To whom correspondence should be addressed.

Techniques that can maintain performance in identifying rare
biological events while reducing costs are invaluable in the
drug discovery process.

Replicated screens, which allow for statistical testing of
biological activity, are becoming more common (Boutros
and Ahringer, 2008; http://nsrb.med.harvard.edu/_downloads/
NSRB_newscreener201106.pdf; Malo et al., 2006; Seiler et al.,
2008). Statistical testing offers numerous advantages for detect-
ing active compounds relative to ranking or using biologically
motivated thresholds, neither of which takes compound variabil-
ity into account. With statistical testing, estimates of uncertainty
can be associated with activity measurements; power analyses
can be performed to determine cost-effective number of repli-
cates for future screens; false discovery rate procedures can
guide decisions for selecting compounds for follow-up screen
validation. Obtaining replicates can be prohibitively expensive,
however, particularly for ultra-HTS Mahome and Mantis,
2001).

One way to reduce costs is to use shrinkage statistical tests that
combine individual compound variances obtained from repli-
cates with a screen-wide estimate of the variance. Developed
speciﬁcally for studies with few replicates, these methods produce
more accurate and more precise variance estimates for statistical
testing than do classical methods such as the t—test (Allison et al.,
2006; Efron, 2005; Tong et al., 2007). The random variance
model (RVM), for example, has been shown to be substantially
superior to the standard t-test (Murie et al., 2009; Wright and
Simon, 2003) and has been successfully applied to HTS data
(Malo et al., 2006, 2010). Although the RVM test performs
well with as few as two replicates, cost considerations may
argue against obtaining even this minimal level of replication
for an entire screen.

We introduce the single assay-wide variance experimental
(SAVE) design as a means of generating an RVM error estimate
that is based on a small replicated subset of a screen, which can
be applied to the remaining majority of unreplicated measure-
ments. We show that SAVE produces P-value distributions and
rank-order statistics comparable with fully replicated screens for
both simulated and experimental data. SAVE also outperforms
the popular Z—score and standard one-sample t—test. Finally, we
provide guidelines for determining the number of compounds
and replicates required to produce error estimates for use
within the SAVE design.

 

© The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 3067

112 /310's113u1no [p.IOJXO'SOllBIIHOJUTOTQ/ﬁdllq 11101; popeoIII/noq

9IOZ ‘09 lsnﬁnv uo ::

C.Murie et aI.

 

2 METHODS
2.1 Z—score
The Z—score normalizes for additive and multiplicative effects across plates:
Z = xi__““1’ (1)
0p

where x,- is the signal intensity of the ith compound and up and Up are the
mean and standard deviation, respectively, of the raw well intensities per
plate excluding controls. P—values are derived from the standard normal
distribution.

We note that Z—scores are linear transformations of other normaliza-
tion methods that likewise apply within-plate arithmetic operations
(e.g. percent of control, normalized percent inhibition/activation and
plate median normalization). We note also that Z—scores are not to be
confused with the quality control Z and Z’ factor scores (Zhang et al.,
1999) commonly used by HTS screeners. Although selection of hit detec-
tion thresholds differs (e.g. compounds with Z—scores exceeding 2 or 3 are
often considered active, whereas thresholds for normalized percent inhib-
ition/activation are tailored to each assay), scores of the various methods
correlate one on a plate-by-plate basis.

2.2 Spatial polish and well normalization (SPAWN)

SPAWN normalization is a two-step method, which ﬁrst uses a trimmed
mean polish (here set to a trim value of 0.2) on individual plates to
remove row and column effects. The ﬁrst step ﬁts the assay plates to
the following model:

yijp = Mp + Rip + ij + eijp (2)

where yijp is the well intensity for the ith row and jth column of the pm
plate. up is the grand mean of the pm plate, Rip is the ith row effect and CJ-p
is the jth column effect of the pm plate. eijp are the residuals after removing
the grand mean, row and column effects. The residuals are rescaled by
dividing by the median absolute deviation of the plate and are used as the
post-normalized well scores. A second (optional) individual well normal-
ization step used here calculates a spatial bias template (SBTU), which is
the median of the scores at each well location, the ith row and jth column,
across all plates. The spatial bias template scores are then subtracted from
the scores from step 1 at each well location (ﬁg, 232,1}, — SBTU). The
resulting scores are again rescaled by dividing by the median absolute
deviation of each plate.

2.3 Standard one-sample t—test

The one-sample t-test is calculated as follows:

t=ﬁﬁfc (3)

0‘

 

where Li, 6 and n are the compound average, compound standard devi-
ation and number of replicates, respectively. c is the measure of null
activity, typically zero. P—values are derived from the t distribution with
n-I degrees of freedom.

2.4 RVM one-sample t—test

In the RVM test, the empirical Bayes posterior variance for each com-
pound is obtained based on a weighted combination of the compound-
speciﬁc variance and a prior variance estimate that is derived from the
variances of all the replicated compounds in the screen. The shape (a) and
scale (17) parameters for the prior variance distribution are estimated by
ﬁtting the observed variances of all compounds to an inverse gamma
distribution. The RVM one-sample t-statistic takes the form:

hall—c (4)

0 pool

 

where L2, 11 and c are as for the standard one-sample t—test. The posterior,
or pooled, variance is
-2 _ (n — naz + 2a(ab)_1

01’00]— n—l+2a

(5)

where 62 is the compound-speciﬁc sample variance and (ab)_1, the prior
variance estimate, is the mean of the ﬁtted inverse gamma distribution.
A large number of replicates give increased weight to the sample variance.
A large shape value (a), which indicates that the inverse gamma is highly
peaked (i.e. most compound-speciﬁc variances are close to the mean),
gives increased weight to the prior variance. P-values are derived from
a t distribution with (n — l) + 2a degrees of freedom.

2.5 SAVE one-sample t—test

In the SAVE design, a subset of plates within a screen is randomly se-
lected for replication. An RVM one-sample t-test prior (assay-wide) vari-
ance estimate is obtained for the replicated subset. This estimate is then
used to calculate the error term for the statistical tests of the unreplicated
compounds in the screen. The SAVE one-sample t—test is calculated as:

361—6 361—6

— — (6)

izagzbrl _ ./ 1 /(ab)

where x, is the ith compound of the unreplicated data and c is the measure
of null activity, typically zero. a and b are the RVM shape and scale
parameters, respectively, of the inverse gamma distribution ﬁtted to the
replicated subset. The assay-wide variance is the mean of the ﬁtted inverse
gamma distribution, deﬁned as I/ ( ab ). P—values are derived from a t
distribution with 2a degrees of freedom.

SA VEt, =

2.6 Data

2.6.] Simulated data methods Two sets of simulated data were
generated. Simulation A examined the effect of compound number and
replicate number on the prior variance distribution parameter estimates
and the assay-wide variance used in the SAVE t-test. A set of simulated
compounds with normal error, whose variances were drawn from an
inverse gamma distribution with deﬁned shape (a j and scale (17) param-
eters, was generated with a given number of replicates. The shape, scale
and assay-wide variance [mean of the prior inverse gamma variance dis-
tribution = l/ (ab )] estimates for each simulation run were compared with
the true parameter values. The ranges of the simulated data parameters
were as follows: 1—10 plates (80 compounds/plate), 2—11 plate replicates
and shape (a) and scale (17) parameters that ranged from 1 to 10. Each
combination of parameters was simulated 1000 times.

For Simulation B, P—values were derived from one-sample t-tests and
SAVE t-tests of both raw and Z—score data (n = 2), RVM t-tests of raw
data (n = 2) and Z—scores (n = 1). Simulation B consisted of two separate
datasets. For Simulation B1, 1000 population variances were ﬁrst drawn
from an inverse gamma distribution with speciﬁed shape values (a = l, 2,
or 3) chosen to be comparable with values commonly found in high-
throughput screens (Supplementary Information Section 1); scale value
(b), which had no effect on output (see Results), was set to 1. Two rep-
licate intensities were then generated for each compound by drawing from
a normal distribution with the corresponding population variance. Ninety
percent of the compounds were simulated to be inactive (p. = 0) and the
remaining 10 percent were simulated to be active (with effects ranging
continuously from —2 to —3 and from 2 to 3 standard deviations away
from the null value of 0).

Simulation B2 was used to generate SAVE assay-wide variance esti-
mates for normally distributed data with the population shape and scale
parameters used in B1. The number of compounds for B2 ranged from 80
to 480 (1—6 plates with 80 compounds each), and the number of replicates
(n) ranged from 2 to 7. Sample variances for the replicates for each

 

3068

112 /310's113u1no [p.IOJXO'SOllBIIHOJUIOIQ/ﬁdllq 11101; pepeoIII/noq

9IOZ ‘09 lsnﬁnv uo ::

SAVE design for screening

 

compound were generated by drawing randomly from the x2 distribution
with n — 1 degrees of freedom and applying the following formula (Hays,
1994):

3.2 = —"i2 W _ 1) (7)

l n — l

where 01.2, 61.2 and n are the ith (compound) population variance, sample
variance and number of replicates, respectively. The SAVE assay-wide
variance estimate [the denominator in Equation (6)] was calculated from
the set of sample variances for each simulation run. Simulations B1 and
B2 were repeated in parallel 1000 times for each combination of replicate
number, plate number, shape (a) and scale (17) value.

2.6.2 Experimental data methOds P—values were derived from one-
sample t—tests and SAVE t—tests of both Z—score and SPAWN normalized
data (n = 2), RVM t-tests of SPAWN scores (n = 2) and Z—scores (n = 1).
Two experimental datasets, an in—house (Centre de Criblage pour des
Molecules Bio-Actives; CMBA) small molecule cell-based primary
screen (Supplementary Information Section 2) and an siRNA screen
(Wiles et al., 2008), were examined. The CMBA screen, which contained
520 active and 40 inactive compounds in seven 96-well plates, was run in
quadruplicate. The Wiles et al. data, which contained 22915 siRNAs of
unknown activity levels in 62 384-well plates, were run in duplicate.

P—values were generated with the experimental data by ﬁrst creating
two mutually exclusive sets (1 and 2) for each assay. Set 1, the replicated
subset of the assay as described in Section 2.5, was used to generate an
RVM prior (assay-wide) variance estimate. The process was iterated
across all combinations of replicate and plate numbers. Assay-wide vari-
ance estimates from Set 1 were used in the SAVE t-test of each single
replicate compound in Set 2. Results of the SAVE t-tests were compared
with results of other tests applied to the same compounds.

3 RESULTS
3.1 Quality of prior variance distribution parameter
estimates

Simulated and experimental data were used to examine effects of
compound and replicate number on the accuracy and precision
of SAVE assay-wide variance estimates and to provide guidance
for cost-effective experimental designs.

3.1.] Simulated data—quality of parameter estimates Simulated
data were used to examine the effect of numbers of plates and
replicates across a range of shape (a) and scale (b) parameters on
the estimation of the prior variance distribution parameters
(Section 2.6.1).

Shape (a) values of 1—3 are commonly found in HTS assays
when estimating the assay-wide variance distribution
(Supplementary Information Section 1). Figure 1, which shows
simulation results for true shape values within this range, indi-
cates that the accuracy of the SAVE shape estimates was inde-
pendent of true shape value, number of replicates and number of
plates. Precision of the shape estimates, by contrast, improved
with increasing plate numbers, although the extent of the gains
depended on both number of replicates and true shape values. At
true shape 2 1, increasing replicates provided little or no gains in
precision; at true shapes 2 2 and 3, large gains in precision were
observed by increasing replicates from 2 to 3 but not from 3 to 4.
The full set of graphs showing the number of replicates from 2 to
11 and true shape values from 1 to 10 are in Supplementary
Information Section 3. The true scale value had no effect on

Number of Replicates

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

   

 

 

 

 

 

 

 

 

2 3 4
*5: ' 1.: . “5".
._ ‘1‘H .— -—
aux-TE" \_ I‘K
 . u r r: + "-
m ---""---"' ‘ rﬁﬁ + Lit—mfg w ..... _ﬁ___/#__
____,, r. a F
9 f D ff— ff"
V «r
C” d E c.
z :1..
_ a 3
1T; a Ln, Kr I q q
:5 m '— l  .
1'1 5 I m II. \"
~5- 1“ l  e 1 a \
CU N '5 1? I ~  teak? ..,_
D. E II fwd—F ' ""-u..____::'_:a_______l ---....::“_-::r_m___ a
m "3 II '— ‘f ‘5’ ~   ‘5‘ '
5  L” l 2 4 5 510 r“   ___' a N ,__,_
w 3 I"o|-_:.T.T”"—"“—"”"m _f {1"—
= m "' _--_—— ...— E E
1_ a . c . . . - - - -
I—
CI-
ﬂ 1:: c, _  ..: ,.. ..
'- ...upperflowerhinge
D “‘3 l “9 —50th percentiie
‘3 1
m '- \ kn
a  -=r
'_':‘_'.—— —~———- n.
CI-
2 4 6 a m 2 4 5 3 1n 2 4 e B 10

Number of Plates

Fig. 1. SAVE estimated shape (a) values of simulated data by number of
replicates, true shape and number of plates (80 wells /plate) at scale (17) = 1

either the accuracy or precision of the estimated shape param-
eters (Supplementary Information Section 4); the true shape
value, plate number and replicate number had little to no
effect on the accuracy and precision of the scale and assay-
wide variance estimates (Supplementary Information Section 5).

3.1.2 Experimental data—quality of parameter estimates The
quality of the SAVE variance estimates was investigated with
experimental data by comparing all possible subsets of number
of plates and replicates from the small molecule CMBA and the
siRNA Wiles assays to their assay-wide variances estimated from
their respective full datasets.

Figure 2 shows that SAVE produced accurate estimates of
shape (a) for the CMBA data with two or more plates (all rep-
licate numbers) and with good precision at four replicates.
Accurate estimates with good precision were obtained for the
Wiles et al. data with four or more plates [see Supplementary
Information Section 6 for scale (b) and assay-wide variance
(1 /ab) estimates].

3.2 P—value distributions

Simulated and experimental data were used to generate P—values
derived from the various methods to assess their respective
performances.

3.2.] Simulated data—P-value distributions Figure 3 shows
P—values for the six methods generated with simulated data
that included 10% active compounds (Section 2.6.1). Figure 3a
shows that four of the methods (RVM t—test, t-test, t-test with
Z—scores and SAVE) met the theoretical expectation of uniformly
distributed P—values for inactive compounds, whereas two meth-
ods did not (Z—scores and SAVE with Z—scores). For P—values
generated by the active compounds, SAVE showed P—values
almost as small as those generated by RVM, increasingly so as
shape values increased, and smaller than for any other method

 

3069

112 /310's112u1no [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

C.Murie et al.

 

E

I All Data: 1:: =1.65

‘ Nb. of Replicates

. ' I 2
. I 3

3 4

CMBA
Estimated shape [:11

i:
e
15-
I.

. Ilil-i-f'r’lil -— —-— _m _—
vl'3-5 2'3 E'i' (209140 3‘5} H215 34 2f] 1'15 4 |',l
” i123 e4 2:: are 1411 351 r42 23 F'l
1 2 3 4 5 6 I"
Number of Plates
lb)
' All Datam = 1.63
E i _ No. of Replicates
g _ . - 2
I1- ' l
m E ' .
g e ' ‘ g
a E l i L I I —I— I
-.: l
c.1153 = E -I-

n {:24} {10001 {10001 rmaui poem “0001110001 ileum 11015301 new»
1 2 3 4 s a r a 9 ID
Number of Plates

Fig. 2. Boxplots of SAVE estimated shape (a) values of experimental
data normalized with SPAWN. (a) CMBA data (96-well plates with 80
non-control wells per plate). Ten extreme outliers from 1, 2 or 3 plates
(two replicates) were removed for sealing purposes. 0)) Wiles data
(384-well plates with 320 non-control wells per plate) in duplicate

(Fig. 3b). These results indicate that SAVE generates correct P-
values under the null hypothesis with almost as much statistical
power as RVM and with more power than the t-test at consid-
erably reduced cost in that, unlike with the t-test, only a small
subset of the screen need be replicated.

3.2.2 Experimental data—P-value distributions Obtaining cor-
rect P—values with experimental HTS data is a more difﬁcult task
because of the likely presence of numerous sources of bias in the
measurements. Normalization methods must remove the bias
while simultaneously maintaining statistical test assumptions
(e.g. normally distributed error for the t-test, RVM t-test and
SAVE and the added assumption of inverse gamma distributed
variances for RVM and SAVE).

Figure 4a and b show that when normalized with SPAWN, the
t-test, RVM t-test and SAVE tests produced similar P—values
with both the CMBA small molecule and the Wiles et al. RNA
interference datasets. Importantly, all three tests showed the
expected uniformly distributed P—values for inactive CMBA mol-
ecules (Fig. 40). As with the simulated data, SAVE generated P-
values almost as small as RVM for active molecules and outper-
formed the t-test (Fig. 4d). All three tests performed poorly with
Z—score normalized data.

3.3 Power analysis of SAVE

Figure 5 shows the power levels of the SAVE method at a
P—value threshold of 0.01 with shape values ranging from 1 to
3 and the scale parameter set to 1. The power levels were calcu-
lated using a standard power analysis with the SAVE assay-wide
variance used as the variance estimate. The power of the SAVE
method improved as the shape value of the inverse gamma

 

 

 

 

 

 

 

 

(a) Inactive Features
Shape WI :1 Shape Id} = 2 shape {a} = 3
a!
1:
cu
,E
“U 1
i c:
:2. .
1:: r T ' v ‘ H F ‘
0.0 0.4 0.3 0.0 0.4 0.3 0-0 0.4 DIE _ _.
Uniform Distribution SAVE
(b) Active Features  -

 

P-value

 

 

 

 

   

' u 41:-
Rank

Fig. 3. Two-tailed P-values generated with simulated data. The SAVE
assay-wide variance was generated with 240 compounds (equivalent to
three 96-well plates, 80 compounds each) and 4 replicates. The RVM
t-test, t—test and t-test with Z—scores were generated with 1000 compounds
and 2 replicates; the SAVE, SAVE with Z—scores and Z—scores were
generated with 1000 compounds and l replicate. The simulated data vari-
ances were generated from a prior inverse gamma variance distribution
with shape values 1—3 and a scale value of l. (a) QQ plot of P—values
of the inactive compounds compared with the uniform distribution.
(b) Rank-ordered P-values of the active compounds

distribution increased. This is due to the compound variances
clustering more strongly around the center of the variance dis-
tribution at higher shape values. The power analysis of the shape
parameter at P—value thresholds of 0.001 and 0.05 are shown in
Supplementary Information Section 7.

4 DISCUSSION

Statistical testing and concomitant P—values provide an objective
way to benchmark false-positive and false-negative rates in HTS
assays. The SAVE method can be used to generate P—values that
are comparable with those generated with full replication, pro-
viding a reasonable alternative when the latter is not possible due
to cost considerations. Replication that captures the true vari-
ability of the assay rather than only technical variation is the
preferred approach (e.g. by replicating sample preparation and
by randomly assigning replicated compounds to different well
locations across plates). This approach to the minimal replication
required of the SAVE design would improve generalizability of
results and their validation.

As with other statistical approaches, SAVE results are best
when data are adequately normalized, which is often not the
case with frequently used methods such as the Z—score or
normalized percent inhibition/activation. As a consequence of
not correcting for spatial biases within plates, compound activity
with data normalized by these latter methods will appear higher
or lower than the true biological signal, depending on where the
compound is located on a plate (Brideau et al., 2003). An add-
itional problem of using Z—scores for purposes of generating

 

3070

112 /310's112u1no [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

SAVE design for screening

 

SAVE [SPAWN]

1"“!!-
DJ
“in—II"

i-test [SPAR-251'-
Z

1112
If"!
g
{D
I?

T
l
i
.1
I

one
1

D

 

 

 

 

 

CI 0.5 I
(b),
Em wws
a: 3  _
ta “(7— 
ﬂ.
I: I] 0.5 I
Pavalue
(C) Inactive [CMBA] (‘0 Active [CMBA]
S__” ,3
saveapawui

OB

' t-IL‘SL'ISF'AVJNI 
Z XXI

P-value
Prvalue
05
'|.

0.4

02
I

   

 

 

 

 

 

 

ti 0'; 0:4 01s 01s 1.}: ti m 20 in 43:: 53::

Uniform Distribution Flank
Fig. 4. Two-tailed P—values generated with experimental data. The SAVE
assay-wide variance was generated with three plates and four replicates
for the CMBA data and two plates and two replicates for the Wiles data.
The t-test and RVM t-test P—values (Z—score and SPAWN normalized)
were generated with all n=2 combinations; SAVE (both Z—score and
SPAWN normalized) and Z—scores were generated with n = l. (a and b)
Histogram of P—values for CMBA and Wiles assays generated with two-
tailed tests. (c) QQ plot of P—values of the CMBA inactive compounds
compared with the uniform distribution. (d) Rank-ordered P-values of
the CMBA active compounds

P—values is the incorrect assumption that all compounds share a
common population variance (Malo et al., 2006). The incorrect-
ness of the P—values associated with Z—scores can be readily
observed by their deviations from a uniform distribution for in-
active molecules. This graphical approach can be used to assess
SAVE’s appropriateness for datasets and normalization methods
not addressed in our study; when used with primary screen data
of mostly inactive compounds, P—values should be approximately
uniformly distributed in all but the lower P—value range. We
demonstrated that SPAWN normalization provides good results
in line with statistical expectation; other methods that similarly
correct for spatial bias, such as the R score (Wu et al., 2008), may
also be considered.

The standard t-test has been widely criticized for use with
high-throughput studies because of its low power and poor
random error estimation when applied to screens with few rep-
licates (Hu and Wright, 2007; Murie et al., 2009; Qin and Kerr,
2004; Tong and Wang, 2007; Xie et al., 2004).We showed that
SAVE error estimates provided by partial replication are

 

 

CI
.—' Shapeiel a __ _s -o- — ___—,arnH-a
__.25 " .- ‘D- 0
D: __"J l I I"
.....I.s r’ . " o
_Iz 0‘
u} I J
:- c‘ D .- I-
a ,r --°
D f
n.  IF I.
D ,D’ .... .. O
'“1' ----° "" '—
D .. ___
0' "'3
g 8 o e o

 

 

 

 

 

 

‘|.D 1:5 in is aln
Effect Size
Fig. 5. Power levels of the SAVE design across effect sizes [measured
intensity difference from zero divided by the SAVE assay-wide variance
(I/ab)] and different shape parameters of the prior variance distribution
at a critical P—value threshold of 0.01

superior to full replication t-test estimates. This superiority is
reﬂected in part by the typically larger degrees of freedom asso-
ciated with the SAVE method. Standard t-tests with n :2 pro-
vide only one degree of freedom (df), whereas the SAVE t-test
provides 2a dfs. Shape parameter values (a) of 1 through 3 are
common. In the two empirical datasets we examined, for ex-
ample, a was ~1.6, providing 3.2 dfs for the statistical test.
Thus, by using the assay-wide variance as the random error es-
timate rather than the individual feature compound error esti-
mates of the standard t-test, SAVE provides greater statistical
power that comes with more dfs, while avoiding the unrealistic-
ally ‘small denominator’ problem of the t-test observed in high-
throughput data (Tusher et al., 2001).

Obtaining accurate and precise shape estimates is crucial to the
success of the SAVE approach because it is the critical variable in
estimating the prior variance distribution and because it deﬁnes
the degrees of freedom used in generating P—values (Smyth, 2004;
Wright and Simon, 2003). In general, SAVE shape estimates
improve with increasing numbers of plates and replicates but
the overall number of plates required is small relative to the
number of plates in a typical screen, in particular for ultra-
HTS screens for which the SAVE design is most useful.
Finally, although SAVE was created for and tested with HTS
assays, the method is readily transferrable to other types of
high-throughput assays whose variances are distributed accord-
ing to an inverse gamma distribution (e.g. gene expression
microarrays).

ACKNOWLEDGEMENTS
The authors thank Alexander Bishop and Amy Wiles for provid-
ing their data and information in numerous email exchanges.

Funding: Le Fonds Quebécois de la Recherche sur la Nature et
les Technologies (FQRNT) grants (119258 and 173878), by the
French national network of Genopoles and by a Walter Sumner
Foundation Fellowship (to CM.)

Conﬂict of Interest: none declared.

REFERENCES

Allison,D.B. et al. (2006) Microarray data analysis: from disarray to consolidation
and consensus. Nat. Rev. Genet, 7, 55—65.

 

3071

112 /310's112u1no [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

C.Murie et al.

 

Bobkova,E.V. et al. (2010) Discovery of PDKl kinase inhibitors with a novel
mechanism of action by ultrahigh throughput screening. J. Biol. Chem, 285,
18838—18846.

Boutros,M. and Ahringer,J. (2008) The art and design of genetic screens: RNA
interference. Nat. Rev. Genet, 9, 554—566.

Brideau,C. et al. (2003) Improved statistical methods for hit selection in high-
throughput screening. J. Biomol. Screen, 8, 634—647.

Chung,N. et al. (2010) A 1,536-well ultra-high-throughput siRNA screen to identify
regulators of the Wnt/beta-catenin pathway. Assay Drug Dev. T echnol., 8,
286—294.

Efron,B. (2005) Fifty Years of Empirical Bayes (lecture, Université de Montreal,
Montreal, QC, September 23).

Hays,W.L. (1994) Statistics. Harcourt Brace & Co., Forth Worth, TX.

Hu,J. and Wright,F.A. (2007) Assessing differential gene expression with small
sample sizes in oligonucleotide arrays using a mean-variance model.
Biometrics, 63, 41—49.

Madoux,F. et al. (2010) Small molecule inhibitors of Weel degradation and mitotic
entry. In: Probe Reports from the NIH Molecular Libraries Program. Bethesda,
MD, http://www.ncbi.nlm.nih.gov/books/NBK47352/ (25 June 2013, date last
accessed).

Malo,N. et al. (2006) Statistical practice in high-throughput screening data analysis.
Nat. Biotechnol, 24, 167—175.

Malo,N. et al. (2010) Experimental design and statistical methods for improved hit
detection in high-throughput screening. J. Biomol. Screen, 15, 990—1000.

Murie,C. et al. (2009) Comparison of small 11 statistical tests of differential expres-
sion applied to microarrays. BM C Bioinformatics, 10, 45.

Qin,L.X. and Kerr,K.F. (2004) Empirical evaluation of data transformations and
ranking statistics for microarray analysis. Nucleic Acids Res., 32, 5471—5479.

Seiler,K.P. et al. (2008) ChemBank: a small-molecule screening and cheminfor—
matics resource database. Nucleic Acids Res., 36, D351—D359.

Smyth,G. (2004) Linear models and Empirical Bayes methods for assessing differ-
ential expression in microarray experiments. Statistical Applications in Genetics
and Molecular Biology, 3, Article 3.

Tong,T.J. and Wang,Y.D. (2007) Optimal shrinkage estimation of variances with
applications to microarray data analysis. J. Am. Stat. Assoc., 102, 113—122.
Tong,D.D.M. et al. (2007) Application of a mixture model for determining the
cutoff threshold for activity in high-throughput screening. Comput. Stat. Data

Anal, 51, 4002—4012.

Tusher,V.G., Tibshirani,R. and Chu,G. (2001) Signiﬁcance analysis of microarrays
applied to the ionizing radiation response. Proceedings of the National Academy
of Sciences, 98, 5116—5121.

Wahome,P.G. and Mantis,N.J. (2001) High-throughput, cell-based screens to iden-
tify small-molecule inhibitors of ricin toxin and related category B ribosome
inactivating proteins (RIPS). In: Current Protocols in Toxicology. John Wiley &
Sons, Inc, doi: 10.1002/0471l40856.tx0223s55.

Wiles,A.M. et al. (2008) An analysis of normalization methods for drosophila
RNAi genomic screens and development of a robust validation scheme.
J. Biomol. Screen, 13, 777—784.

W1ight,G.W. and Simon,R.M. (2003) A random variance model for detection of
differential gene expression in small microarray experiments. Bioinformatics, 19,
2448—2455.

Wu,Z.J. et al. (2008) Quantitative assessment of hit detection and conﬁrmation in
single and duplicate high-throughput screenings. J. Biomol. Screen, 13,
159—167.

Xie,Y. et al. (2004) A case study on choosing normalization methods and
test statistics for two-channel microarray data. Comp. Funct. Genomics, 5,
432—444.

Zhang,J.H. et al. (1999) A simple statistical parameter for use in evaluation and
validation of high throughput screening assays. J. Biomol. Screen, 4, 67—73.

 

3072

112 /810's112u1no [pJOJXO'SOIlBIIIJOJUIOIQ/ﬂdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

