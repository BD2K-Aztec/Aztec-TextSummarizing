ORIGINAL PAPER

Vol. 30 no. 9 2014, pages 1214—1219
doi: 1 0. 1093/bioinformatics/btu010

 

Sequence analysis

Advance Access publication January 9, 2014

BlindCall: ultra-fast base-calling of high-throughput sequencing

data by blind deconvolution

Chengxi Yew, Chiaowen Hsia02’3 and Hector Corrada Bravo

123*

1Department of Computer Science, 2Center for Bioinformatics and Computational Biology and 8Applied Mathematics
and Scientific Computing, University of Maryland, College Park, USA

Associate Editor: Dr John Hancock

 

ABSTRACT

Motivation: Base-calling of sequencing data produced by high-
throughput sequencing platforms is a fundamental process in current
bioinformatics analysis. However, existing third-party probabilistic or
machine-learning methods that significantly improve the accuracy of
base-calls on these platforms are impractical for production use due
to their computational inefficiency.

Results: We directly formulate base-calling as a blind deconvolution
problem and implemented BlindCall as an efficient solver to this in-
verse problem. BlindCall produced base-calls at accuracy comparable
to state-of—the-art probabilistic methods while processing data at
rates 10 times faster in most cases. The computational complexity
of BlindCall scales linearly with read length making it better suited
for new long-read sequencing technologies.

Availability and Implementation: BlindCall is implemented as a set of
Matlab scripts available for download at http://cbcb.umd.edu/~hcor
rada/secgen.

Contact: hcorrada@umiacs.umd.edu

Received on August 1, 2013; revised on December 12, 2013;
accepted on January 6, 2014

1 INTRODUCTION

Second-generation sequencing technology has revolutionized
high-throughput genomics in life science and clinical research.
The sheer scale of sequence generated by these instruments has
allowed unprecedented views into a number of molecular phe-
nomena, including population genetics, transcriptomics, epigen-
etics and translational proﬁling. Both the throughput and
accuracy of second-generation sequencing instruments has
increased at an accelerated pace in the last few years due to
the use of high-resolution optics and biochemical methods that
allow sequencing of billions of DNA fragments in parallel by
generating ﬂuorescence intensity signals that can be decoded
into DNA sequences. However due to experimental and hard-
ware limitations, these raw signals are inherently noisy (Aird
et al., 2011; Bravo and Irizarry, 2010; Dohm et al., 2008;
Erlich et al., 2008). Base-calling is the essential step of converting
these noisy ﬂuorescent intensity signals into sequences used in
downstream analysis. Providing accurate base-calls greatly re-
duces many difﬁculties in downstream bioinformatics analysis
like genome assembly and variant calling (Alkan et al., 2011;
Bravo and Irizarry, 2010).

 

*To whom correspondence should be addressed.

Sequencing-by-synthesis (Bentley et al., 2008) generates mil-
lions of reads of short DNA sequences by measuring in parallel
the ﬂuorescence intensity of billions of PCR—ampliﬁed and
labeled clusters of DNA from a sample of interest. The
DNA fragments attach to a glass surface where it is then PCR-
ampliﬁed in situ to create a cluster of DNA fragments with iden-
tical nucleotide composition. Sequence reads are generated from
these DNA clusters in parallel and by cycles. A single nucleotide
is sequenced from all DNA clusters in parallel by adding labeled
nucleotides that incorporate to their complementary nucleotide.
This synthesizes DNA fragments complementary to the frag-
ments in each cluster as sequencing progresses. A set of four
images is created measuring the ﬂuorescence intensity along
four channels to detect incorporation at each cycle. These
images are then processed to produce ﬂuorescence-intensity
measurements from which sequences are then inferred by base-
calling. In the default base-calling process for Illumina sequen-
cers, called Bustard, the highest intensity in each quadruplet
of intensity measurements determines the base at the correspond-
ing position of the corresponding read. For current Illumina
technologies, sequencers can produce up to 600 GB per run
(Illumina, 2013).

The raw intensity signals generated by this process are known
to be subject to several biases (Aird et al., 2011; Bravo and
Irizarry, 2010; Dohm et al., 2008; Erlich et al., 2008) (Fig. 1A
and B). (i) Cross talk: there are signiﬁcant correlations between
different nucleotide channels; (ii) phasing/pre—phasing: the signal
in one cycle can spread to the cycles ahead and the cycles after it;
(iii) signal decay: where signal intensities become lower in later
sequencing cycles; (iv) background noise: the signal to noise ratio
becomes lower in later sequencing cycles. A signiﬁcant challenge
in base-calling is accounting for these biases.

Existing base-calling methods can be classiﬁed into two major
groups: (i) unsupervised model-based methods that capture the
sequencing-by-synthesis process in a statistical model of ﬂuores-
cence intensity from which base-call probabilities can be
extracted directly (Bravo and Irizarry, 2010; Kao and Song,
2011; Kao et al., 2009; Massingham and Goldman, 2012) and
(ii) supervised methods that train a statistical model on a set of
base-calls whereby ﬂuorescence intensity measurements are clas-
siﬁed into base-calls (Erlich et al., 2008; Kircher et al., 2009). The
former methods have been shown to signiﬁcantly improve the
accuracy of Bustard base-calls. These model-based methods aim
to capture the sequencing process described above in a statistical
model from which base-call probabilities are usually obtained.
While these probabilistic or machine-learning methods improve

 

© The Author 2014. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which
permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.

112 /810's113umo [p.IOJXO'SOllBIIHOJUTOTQ/ﬁdllq 11101; prBOIIIAAOG

910Z ‘091sn8nv uo ::

BIindCaII

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
   
 
   

 

 

 

 

 

 

 

 

 I I I l I I I I I 
A " Crass talk effect: A B A
Bow?- I n " CD I WhenAls hfgh,Cls else high. —' ‘3- " I C I
.. II WhenGls hlthisalse high. —: ‘3 sauna 1' —-I e I
TDDD- 3 '"I "1" r l " | In H — * ‘T
l I *
‘L I l l " I ' I 1' SAUDI]
EWD— ‘- "I T I t¥u * n.  I I _
 5mm in I _  clone
'3' m
e | e
E 4030‘ + I — in mm]
amn- l | —
I I . I I 3000 Phaeing * 1,
20m:— ' I I ' I E . I I '
inun- I"III- * _. I: .III I :l I I * _ _ 1am: '.
*W'FTH :- 1 'l' =r * 1"  - IT I U il' '1‘:   1"
DH ll. .ﬂlrenr hhlll‘l'luehrlnll‘f . .: .T...H‘l 171'. 'I I I  l I T
5 1|} 15 El] 25 3|:I 35 4|] 45 5‘] u 32 3“ 3.5 33 ,4”
Cycle Cycle
Flew order: EGT CGT CGT EGT CGT...

Fig. 1. Signal properties in the base-calling problem. (A) Fluorescence intensity measurements from one cluster for 50 sequencing cycles. Cross-talk and
signal decay effects are clearly observed in this data. Background intensity increases as sequencing progresses. (B) The phasing effect demonstrated on a
subset of data from (A). High intensity in the C channel in cycle 32 affects background intensity in the C channel in neighboring cycles

the accuracy of base-calls, they are impractical for use due to
their computational inefﬁciency, which usually scales quadrati-
cally with read length since most of them resort to dynamic
programming for model ﬁtting (Kao and Song, 2011; Kao
et al., 2009; Massingham and Goldman, 2012).

In this article, we show that the base-calling problem can be
formulated as an optimization problem called blind deconvolu-
tion. Based on this observation, we developed BlindCall as a
method that treats base-calling as a blind deconvolution problem
(Levin et al., 2011; Xu et al., 2013). We model intensity signals
(B) output by the sequencer as the convolution of a latent sparse
signal of interest X and a convolution kernel k modeling cross-
talk and phasing biases, plus background noise N:

B=k>I<X—l—N.

The blind deconvolution problem is to recover the latent signal X
given only the observed B. This reduces the base-calling problem
into solving an inverse problem that admits computationally
efﬁcient solutions. The blind deconvolution problem has been
a research hotspot in recent years (Levin et al., 2011; Xu et al.,
2013) and we adapt methods for its solution to the base-calling
problem (Wang and Yin, 2010).

BlindCall was able to provide base-calls at comparable accur-
acy to state-of-the-art probabilistic methods while processing
data at rates ten times or faster in most cases. It scales linearly
with read length and is thus better suited for new long-read
sequencing technologies. Direct blind deconvolution modeling
and the ultra-efﬁcient processing based on optimization methods
presented here are essential for bioinformatics analysis work-
ﬂows to cope with increased throughput and read lengths in
new sequencing technologies.

2 METHODS

BlindCall follows the following architecture (Fig. 2A): a training module
uses blind deconvolution (Fig. 2B) on a randomly sampled subset (e.g.
1000 reads) of the intensity data to iteratively estimate the convolution
kernel k and produce a deconvolved signal from which base-calling is
performed. The base-calling module then uses the convolution kernel

A Training Step
Ilimt :l cycles:
'l'

Nun-blind
IJeeum-ululirm

 

 

Icy-El»: 'pr'-l_c:.-'c|e Ewl
lI-.....

Raw {Truss Tell: Icy-c]: l‘ “Fall: “I
:-

Kcnml

blgnal Estlmullun hltmatinn

 

 

 

 

 

 

 

 

 

 

[lust-Calling ﬁll-p

 

 

leI'eh: I. cycle wI Ityclt‘ u" ]. L'}'L'IL' 2w]

 

 

 

 

 

 

 

Rim.- an1-I'IIIII1-d
Signal i llwum'elutllm '- 
B Non-blind Deennvnlutlun
_ . Consume: .
Ra“. S'gnal II- f‘nm'nlutlnn Matrix II- Demnwwe m (NIX I ‘11: 11 libertarian
B H |_K.-Il'l-HII+I'::'||I|I|".I::'l'||| h PP“
a. 1.

 

 

 

 

 

 

 

 

 

 

.  I. :II
1. :Li'lih |:I|I-c. H H

.. . H:-:—.'.'..||i.r:Ll:nII.
.':'":-.-||'I::

 

 

 

 

"u':1i'l'.II:.. IL l'-||-.|,li-'"I

 

 

Fig. 2. The BlindCall architecture. BlindCall consists of two modules: (A)
the training module uses blind deconvolution and (B) to simultaneously
estimate model parameters and produce a deconvolved signal from which
base-calling is done. The calling module uses the parameters estimated in
the training module to produce a deconvolved output signal

estimated in the training module to produce a deconvolved output
signal for the entire dataset and call bases.

2.1 Blind deconvolution

We solve the blind deconvolution problem using an iterative procedure:
(i) ﬁxing k and estimating latent signal X using a speciﬁc non-blind de-
convolution method based on iterative support detection (ISD) (described
below) and then (ii) ﬁxing X to estimate convolution kernel k to cor-
rect for cross-talk and phasing effects. We divide the signal into non-
overlapping windows: in each 20-cycle window we assume an invariant
convolution kernel. The discrete convolution can be written as matrix
multiplication B=KX, where K is a convolution matrix constructed
from the kernel k. A normalization procedure is used in each iteration
to account for intensity biases across channels.

 

1215

112 /810's113umo [p.IOJXO'SOIlBIHJOJUIOICI/ﬁdllq 11101; pepequmoq

910Z ‘091sn8nv uo ::

C. Ye et aI.

 

2.2 Channel intensity normalization

Intensity data for Illumina sequencing show certain biases, speciﬁcally
(i) signal strength variation across channels, (ii) signal strength variation
across clusters and (iii) signal decay over sequencing cycles. For accurate
base-calling, these biases must be addressed through normalization.
Traditionally, read normalization is applied to tackle the second and
third problems ﬁrst, in order to address the ﬁrst problem. In our
method, we circumvent the read normalization problem by analyzing
the relative intensity ratio of successive calls across sequence reads.

After an initial deconvolution in which cross-talk is corrected, we nor-
malize each channel by scaling the intensities across reads by the same
quantile (95%) in the respective channels and select the strongest channel
after normalization as candidate base-calls. We then select successive
candidate calls that are of different bases and construct a set of linear
equations of the form xik — rka-k = 0, where xik and xJ-k are the relative
intensity of channels in the k-th relation and rk is the observed intensity
ratio for the k—th relation. The set of linear equations is then Rx = 0,
where R is a M x 6 matrix, with M being the total number of base-calls
pairs within consideration. To estimate x, we solve a least-squares prob-
lem under the constraint that ||x||2= 1. The solution is obtained by sol-
ving an eigenvalue problem since it can be formulated into the Rayleigh
quotient minllxllzzlllellz, and its solution must satisfy the eigenvalue
equation R’Rx = 2.x. Since the number of base-calls across channels
varies, the solution of this optimization problem favors channels that
are called frequently. We normalize the problem using the number of
base-calls and solve the generalized eigenvalue problem R’ Rx = le
where D is a diagonal matrix that records the number of base-calls in
each channel. This formulation can be interpreted as ﬁnding the stable
state of a normalized non-linear diffusion, and is used in normalized cut
(Shi and Malik, 2000), Laplacian Eigenmaps (Belkin and Niyogi, 2001),
and PageRank (Page et al., 1999). The estimated vector x is the relative
intensity of each channel and we use it to normalize each channel in
subsequent steps.

2.3 Sparse signal reconstruction through ISD

To perform base-calling we need to reconstruct latent sparse signal X,
corresponding only to nucleotide incorporation measurements given a
convolution kernel k. A straightforward l2 optimization problem to es-
timate latent signal X minimizes ||B — k >1< X “2. We know the latent signal
is sparser than the observed signal, so we add this property as a constraint
to the least squares problem and use an iterative procedure to solve the
problem under the sparsity constraint. This idea is termed ISD in the
mathematical community (Wang and Yin, 2010), and can also be applied
to deconvolution problems stemming from image deblurring applica-
tions. In our case, the support (non-zero entries) detected for latent
signal X corresponds exactly to base-calls. Assuming X5upp is the signal
taking non-zeros only in the support set obtained using our support
detection algorithm, we want to ﬁnd an X that minimizes
||B — k >1< X ||2+2||X — XSupp This optimization outputs a corrected
signal subject to the support set constraint. The support detection pro-
cedure is critical to the output accuracy—if the support set is correct, we
are close to our solution. At the beginning, we have no knowledge of the
support set, since that directly tells us the answer. To tackle this, we use
an increasing series {24”} that puts increasing weight on the second con-
straint. This weight is low at ﬁrst since the support set is not accurate. As
we gradually reﬁne the estimates we increase this weight. In our imple-
mentation, support detection is conducted by incorporating the channel-
normalization method discussed in the previous section and picking the
strongest normalized channel.

We provide further mathematical justiﬁcation as to why this iterative
procedure recovers the clear intensity signals of incorporation events.
For reference to the applications in image deblurring we refer to the

convoluted signal B as the blurred signal, and to the latent signal X,
the clear signal.

Observation 1: Assume the clear signal is a non-negative signal with
spikes, the convolution (blur) kernel is non-negative and ||k||1= 1, then
the convoluted (blurred) signal is denser than the latent (clear) signal.

This observation holds for all blurs since the blur spreads the spikes
thus creates more non-zero intensities, so the support set becomes larger
with the blurred signal. This observation hints us to design an optimiza-
tion that favors sparse solutions:

mInIIB —k*Xll2+lllel1’.0 5p 5 1.

The second term is a sparse-inducing penalty. This sparse regulariza-
tion problem is well known in wavelet analysis (Mallat, 2009). We also
have the following observation.

Observation 2: By comparing the [1’ norm (0 5 p 5 2) of the clear/
blurred signal, we discover that the sparse norm penalty favors the
clear signal.

As special cases:

0 l1 norm measures the total variation of the signal, thus the blurred
signal and clear signal have the same I1 norm.

0 The l2 norm of the blur signal is smaller than that of the clear signal.

0 The support set for the blurred signal is larger than the clear signal,

therefore it has larger 10 cost.

The above observations suggest that we use a sparse norm to penalize
the blur signal and make it resemble the clear signal. Thus, we analyze the
deconvolution model with an [0 penalty:

mJInllB — k*Xll2+ozllel°.

By introducing an auxiliary variable and using an exterior penalty
technique, the above minimization problem is equivalent to solving the
following optimization problem:

mJInllB — k >1 X||2+oz||w||0+2||w — X||2,2. —> +oo.

One strategy to solve the above optimization is the alternating mini-
mization technique (Wang et al., 2008) and cast the problem into two
sub-problems: (i) ﬁxing X and analyzing the terms containing w, we have
the w sub-problem:

- 2 0
mjnnw — XII +%llwll .

The solution can be found by entry-wise comparison (Mallat, 2009; Xu
et al., 2013) and the result is the so-called hard thresholding:

W1, 2 III..if|X.I>¢%

0, otherwise
Then (ii) ﬁx w, and analyze the terms containing X, we have

mJInllB — k >1 X||2+2||w — X||2.

This optimization problem has the same form with our deconvolution
model when w = X Supp. In our ISD method, X Supp is obtained by adaptive
hard thresholding, where at is set adaptively to select strictly one non-zero
element into the support set by selecting the channel with maximum inten-
sity. Thus, our ISD method solves an optimization problem with an [0
penalty favoring sparse signals corresponding to nucleotide incorporation.

2.4 Convolution kernel estimation

Given latent signal X we use a least-squares method to estimate the con-
volution kernel k modeling cross-talk and phasing effects by solving:

IIIinIIB — k * X||2.

 

1216

112 /810's112umo IpJOJXO'SOIlBIIIJOJUIOICI/ﬁdllq 111011 pepcqumoq

9IOZ ‘091sn8nv uo ::

BIindCaII

 

Table 1. Base callers accuracy and runtime comparison

 

 

Bustard AYB BlindCall slow BlindCall fast freeris
Perfect reads 1 446 079 1 532 000 1 509 451 1 508 779 1 530 099
Error rate (0%) 0.29 0.21 0.23 0.23 0.21
Time (minimum) 17 217 8/12 4/8 9/126
Assembly results N50 Maximum N50 Maximum N50 Maximum N50 Maximum N50 Maximum
5X 610 1122 628 1155 629 1164 623 1167 649 1184
10X 3 375 3469 3198 3322 3382 3487 3389 3485 3306 3418
20X 4466 4478 4627 4637 4511 4523 4470 4483 4333 4357

 

AYB, accuracy and run times for Bustard. freeris and BlindCall for a dataset of 1.9 million reads from a HiSeq 2000 run of PhiXl74. BlindCall Fast corresponds to non-
iterative version of the blind-deconvolution method. Running times for BlindCall are reported as (processing time/total time), where the total time includes reading intensity
data from disk and writing base-calls to disk. For freeris, we report the time as (predicting time with single thread/ training time with 10 threads). BlindCall was able to
produce base-calls of comparable accuracy to AYB and freeris at signiﬁcantly faster computational time (8 min/12min versus 217 min and 126 min, respectively). It is also
faster than Bustard (8 min/ 12 min versus 17min). AYB, freeris and BlindCall all improve on Bustard base calls. We also compared assemblies of the PhiXl74 genome using
reads generated by Bustard, BlindCall, freeris and AYB. The reported N503 and Max contig lengths are averages >100 random samples with the corresponding coverage (5 x,
10x or 20x). While BlindCall is able to process data at a signiﬁcantly lower computational cost, the assemblies obtained using BlindCall are of comparable quality to those

obtained using AYB or freeris.

We estimate convolution kernel k in two distinct steps: we use data from
the ﬁrst four cycles and only model cross-talk in the convolution kernel
and use the blind-deconvolution iterative procedure to estimate cross-talk
effects. We then ﬁx the components of the convolution kernel corres-
ponding to cross-talk effects for the remaining windows and estimate
the components of the convolution kernel corresponding to phasing
effects only. We assume the phasing effect is the same across channels.

2.5 Deriving quality scores from deconvolved signal

We measure the quality of a base-call by the ratio of the intensity of the
strongest channel and the sum of the two strongest channels after the
deconvolution procedure. This number ranges between 0.5 and 1.0 and is
used as the raw quality score. This scheme is similar to the one in
Illumina’s Bustard basecaller. Like most existing base-callers, we calibrate
these raw quality scores by aligning reads to the reference genome and
mapping raw quality scores to the alignment error rate.

2.6 Validation methods

The following datasets were used to test the accuracy and computational
efﬁciency of BlindCall and state-of—the-art probabilistic methods:

Illumina HiSeq 2000 phiXI74: 1926 928 single-end reads of 101 cycles
from a single tile. Data was sequenced at the University of Maryland,
College Park and is available for download at http://cbcb.umd.edu/
~hcorrada/secgen.

Ibis Test: 200K single-end reads of phiX174 >51 sequencing cycles.
Bordetella pertussis: 100 tiles of 76-cycle single-end reads from the cocco-
bacillus B.pertussis, using the complete genome of the Tohoma I strain as
a reference.

AYB phiX I 74: released with AYB and contains human sequence with a
PhiXl74 spike-in.

The last three datasets were downloaded from the AYB authors’ website
(http://www.ebi.ac.uk/goldman-srv/AYB/#data).

To calculate accuracy we align the reads based on the phiX174 refer-
ence using Bowtie2 (Langmead and Salzberg, 2012) with —end—to—end
and —sensitive settings. Reported error rates are based on reads with
no more than ﬁve substitution errors, following the methodology
in Massingham and Goldman (2012). We used SparseAssembler
(Ye et al., 2012) to obtain assemblies from base-calls obtained by each
method. To derive assembly statistics, we sub-sampled 100 datasets from

the complete set of reads at 5 X, 10X and 20X coverage, and perform
assemblies on each of these. We report N50 and maximum contig length
for each resulting assembly.

Version 1.9.4 of the Off-line basecaller was downloaded from Illumina
to run Bustard. Version 2 of AYB was downloaded from http://www.ebi.
ac.uk/goldman—srv/AYB. We ran AYB for 5 iterations as per its default
setting.

3 RESULTS

BlindCall is implemented as a set of Matlab scripts available
at http://cbcb.umd.edu/~hcorrada/secgen. As an example of
its computational efﬁciency, running BlindCall on a single-core
Matlab instance on an Intel i7 3610QM laptop with 2.3—3.3 GHz
processor and 8 GB of memory, we found that it was able to pro-
cess 1 million bases/s, or >85 billion bases/CPU day. We note
that a signiﬁcant portion of its running time (50%) is spent on
disk IO to read intensity data and write the fasta/fastq outputs.
To the best of our knowledge, BlindCall is one of the fastest
base-callers available at this time, even though it is implemented
in a scripting language. A port of this algorithm into a lower-
level language (C/C++) will give further improvements on speed
over the current Matlab version.

We compared the running time of BlindCall to the state-of-the
art probabilistic base-caller AYB (Massingham and Goldman,
2012) and the state-of-the-art supervised learning method
freeris (Renaud er al., 2013) on a dataset of 1.9 million reads
from a PhiXl74 run on an Illumina HiSeq 2000 (Table 1). We
found that BlindCall was able to process this dataset ~20 times
faster than AYB and 10 times faster than freeris while retaining
similar accuracy. A plot of per cycle error rate of these base-
callers (Fig. 3) shows that all methods produce signiﬁcant
improvements over Bustard, especially in later sequencing
cycles. We observed a similar pattern when testing other datasets
(Table 2).

We also obtained better assemblies, especially at low cover-
age, using BlindCall, AYB and freeris relative to Bustard

 

1217

112 /810's112umo IpJOJXO'SOIlBIIIJOJUIOICI/ﬁdllq 111011 popcqumoq

9IOZ ‘091sn8nv uo ::

C. Ye et aI.

 

base-calls (Table 1). We also found that the calibrated quality
values obtained from BlindCall are very accurate (Fig. 4).

We next compared each base-calling method’s ability to scale
to longer read lengths by calculating running time as a function
of read length for the same dataset (Fig. 5). Like most probabil-
istic model-based base callers, AYB resorts to a dynamic pro-
gramming strategy with quadratic running time complexity with
respect to the read length. In contrast, BlindCall scales linearly
with read length. freeris uses supervised learning approach, and
while it also scales linearly with read length, its training time is
much slower than BlindCall (even using 10 threads for freeris,
compared to a single thread for BlindCall). Base-callers based on
the blind deconvolution framework will be able to scale as se-
quencers produce longer reads.

4 CONCLUSION

BlindCall is a simple and ultra-fast non-probabilistic base-calling
method for Illumina high-throughput sequencing data based on
blind deconvolution. We have shown that it provides comparable

III1I'.'IEl
I"

 

 

— AYB

— Busterd

B — BIindCellSlew
— BIindCellFeet
— Freelbie

 

 

 

Error Rate

 

 

 

I} 111 EU 3"?  50 ﬁll) 7'11 Bill BID 10D
Cycle
Fig. 3. Third-party base callers improve Bustard per-cycle error rate. We
plot error rate of each base-caller per sequencing cycle on the PhiXl74
test data. All three base callers signiﬁcantly improve accuracy over
Bustard, especially in later cycles. BlindCall is able to achieve comparable

accuracy while processing data at a much faster rate

Table 2. Accuracy comparison

 

 

—BlindCell
Lie- YB _
LII:-
E “"1.
g r-QFV F”—
525 W
31 .. l r
29- MI v”
E l"
"J 11-
all
'ItI- II'I.‘\/ "I
:IJ é 'IIZI 1'5 3] II!- !IZI 3'!- I1-I'J I1!-

 

Predicted Ifluelilyr Score

Fig. 4. BlindCall produces accurate calibrated quality scores. We plot
observed error rates (on the PHRED scale) for Bustard, AYB and
BlindCall as predicted by quality scores and observed high correlation
for all base callers

 

 

250 '—'1 I l—

: —II— Bustercl
AYB
2”” -— — BlindCeIISlew
BIir‘IdCallFast
— Freel hie {10threeclej

 

.-
LII
D

Time {min}

“JD -

 

 

 
   

"10 211 3.1:: I: ‘5': e: :Iin- all] e: we
Sequencing cycles
Fig. 5. Base-calling by blind deconvolution is scalable to long read
lengths. We compare the computational time of BlindCall with a state-
of—the—art probabilistic base caller AYB, the state-of—the—art supervised
learning method freeris and Illumina’s Bustard on the PhiXl74 dataset
reported in Table 1 as a function of the number of sequencing cycles. Since
most model-based base callers resort to a dynamic programming solution,
running time is quadratic with respect to the read length. In contrast,
BlindCall scales linearly with read length. Base callers based on the
blind deconvolution framework will be able to scale as sequencers produce
longer reads. freeris also scales linearly but is much slower than BlindCall

 

Ibis Test B.pertussis

 

PhiX l 74 (AYB)

 

Perfect reads Error rate (%)

Perfect reads

 

Error rate (%) Perfect reads Error rate (%)

 

Bustard 99 834 1.45 1 557 963 2.01 24 478 0.49
AYB 133 537 0.73 2 304 005 1.26 26 878 0.38
BlindCall slow 110 951 1.12 1902 621 1.61 25 144 0.45
BlindCall fast 105 312 1.26 1856 286 1.66 24 740 0.47
Time Slow 0.08/0.3/1 0.11/6/10 0.15/14/22

Fast 0.08/0.1/1 0.11/3/8 0.15/7/16

 

Accuracy for Bustard, AYB and BlindCall on various datasets. BlindCall was able to produce comparable accuracy to state-of—the—art base callers at signiﬁcantly faster
computational time. All methods improve on Bustard base calls. Run times for BlindCall are reported as (training time/processing time/total time in minutes) where the total

time includes reading intensity data from disk and writing base-calls to disk.

 

1218

112 /810's112umo IpJOJXO'SOIlBIIIJOJUIOICI/ﬁdllq 111011 popcqumoq

9IOZ ‘091sn8nv uo ::

BIindCaII

 

accuracy to probabilistic base-calling methods while producing
base-calls at rates more than ten times faster.

Almost all probabilistic methods solve the base-calling prob-
lem in a ‘forward’ way, i.e. by setting a set of basis functions and
searching for an optimal path, which often leads to dynamic
programming solutions. Fitting these statistical methods is com-
putationally expensive, and will not scale as the increase in
sequencing throughput continues. Also, a stationarity assump-
tion must be made in order to estimate parameters in these prob-
abilistic methods through a Markov process. In contrast,
BlindCall models base-calling as an ‘inverse’ problem of blind
deconvolution, which requires no probabilistic assumptions of
the sequencing process.

As steady progress has been made to improve the accuracy of
probabilistic methods, we expect that similar progress will be
made on non-probabilistic methods based on the blind deconvo-
lution methods described in this article. Furthermore, these
methods will be better suited to cope with increased throughput
and read lengths of new sequencing technologies.

ACKNOWLEDGEMENTS

We thank Najib El-Sayed and the University of Maryland IBBR
Sequencing core for their assistance with test data, James A.
Yorke and his research group in University of Maryland for
insightful discussions and Gabriel Renaud at Max Planck
Institute for assistance with freeris.

Funding: National Institute of Health [R01HG005220, in part]
and [R01HG006102, in part].

Conﬂict of Interest: none declared

REFERENCES

Aird,D. et al. (2011) Analyzing and minimizing PCR ampliﬁcation bias in Illumina
sequencing libraries. Genome Biol, 12, R18.

Alkan,C. et al. (2011) Limitations of next-generation genome sequence assembly.
Nat. Methods, 8, 61—65.

Belkin,M. and Niyogi,P. (2001) Laplacian eigenmaps and spectral techniques for
embedding and clustering. Adv. Neural Inf Process. Syst., 14, 585—591.

Bentley,D.R. et al. (2008) Accurate whole human genome sequencing using revers-
ible terminator chemistry. Nature, 456, 53—59.

Bravo,H.C. and Irizarry,R.A. (2010) Model-based quality assessment and base-
calling for second-generation sequencing data. Biometrics, 66, 665—674.

Dohm,J.C. et al. (2008) Substantial biases in ultra-short read data sets from high-
throughput DNA sequencing. Nucleic Acids Res, 36, 6105.

Erlich,Y. et al. (2008) Alta-Cyclic: a self-optimizing base caller for next-generation
sequencing. Nat. Methods, 5, 679—682.

Illumina (2013) HiSeq Systems Comparison. http://www.illumina.com/systems/
hiseq_2 500_l 500/performance_speciﬁcations.ilmn.

Kao,W.-C. and Song,Y.S. (2011) naiveBayesCall: an efﬁcient model-based
base-calling algorithm for high-throughput sequencing. J. Comput. Biol. A J.
Comput. Mol. Cell Biol, 18, 365—377.

Kao,W.-C. et al. (2009) BayesCall: A model-based base-calling algorithm for high-
throughput short-read sequencing. Genome Res, 19, 1884—1895.

Kircher,M. et al. (2009) Improved base calling for the Illumina Genome Analyzer
using machine learning strategies. Genome Biol, 10, R83.

Langmead,B. and Salzberg,S.L. (2012) Fast gapped—read alignment with Bowtie 2.
Nat. Methods, 9, 357—359.

Levin,A. et al. (2011) Understanding blind deconvolution algorithms. IEEE Trans.
Pattern Anal. Mach. Intell, 33, 2354—2367.

Mallat,S.G. (2009) A Wavelet Tour of Signal Processing .' the Sparse Way. Elsevier/
Academic Press, Amsterdam/Boston.

Massingham,T. and Goldman,N. (2012) All Your Base: a fast and accurate prob-
abilistic approach to base calling. Genome Biol, 13, R13.

Page,L. et al. (1999) The PageRank citation ranking: bringing order to the web.
Stanford InfoLab. Technical Report. Stanford InfoLab.

Renaud,G. et al. (2013) freeris: an efﬁcient basecaller with calibrated quality scores
for Illumina sequencers. Bioinformatics, 29, 1208—1209.

Shi,J.B. and Malik,J. (2000) Normalized cuts and image segmentation. IEEE Trans.
Pattern Anal. Mach. Intell, 22, 888—905.

Wang,Y. and Yin,W. (2010) Sparse signal reconstruction via iterative support
detection. SIAM J. Imaging Sci., 3, 462—491.

Wang,Y.L. et al. (2008) A new alternating minimization algorithm for total vari-
ation image reconstruction. SIAM J. Imaging Sci., 1, 248—272.

Xu,L. et al. (2013) Unnatural L 0 sparse representation for natural image deblur-
ring. IEEE Conference on Computer Vision and Pattern Recognition ( C VPR
’13), 1107—1114.

Ye,C. et al. (2012) Exploiting sparseness in de novo genome assembly. BMC
Bioinform, 13 (Suppl 6), Sl.

 

1219

112 /810's112umo IpJOJXO'SOIlBIHJOJUIOICI/ﬁ(1111] 111011 pepequmoq

9IOZ ‘091sn8nv uo ::

