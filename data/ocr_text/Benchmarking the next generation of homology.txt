Bioinformatics Advance Access published June 9, 2016

Bioinformatics, 2016, 1—6

doi: 10.1093/bioinformatics/btw305

Advance Access Publication Date: 1 June 2016
Original Paper

 

Sequence analysis

Benchmarking the next generation of homology
inference tools

Ganapathi Varma Saripella1, Erik L. L. Sonnhammer1 and
Kristoffer Forslund2'*

1Science for Life Laboratory, Stockholm Bioinformatics Center, Department of Biochemistry and Biophysics,
Stockholm University, Stockholm SE-10691, Sweden and 2European Molecular Biology Laboratory, Structural and
Computational Biology Unit, Heidelberg 69117, Germany

*To whom correspondence should be addressed.
Associate Editor: Burkhard Rost

Received on July 2, 2015; revised on April 11, 2016; accepted on May 5, 2016

Abstract

Motivation: Over the last decades, vast numbers of sequences were deposited in public databases.
Bioinformatics tools allow homology and consequently functional inference for these sequences.
New profile-based homology search tools have been introduced, allowing reliable detection of
remote homologs, but have not been systematically benchmarked. To provide such a comparison,
which can guide bioinformatics workflows, we extend and apply our previously developed bench-
mark approach to evaluate the ’next generation’ of profile-based approaches, including CS-BLAST,
HHSEARCH and PHMMER, in comparison with the non-profile based search tools NCBl-BLAST,
USEARCH, UBLAST and FASTA.

Method: We generated challenging benchmark datasets based on protein domain architectures
within either the PFAM+C|an, SCOP/Superfamily or CATH/Gene3D domain definition schemes.
From each dataset, homologous and non-homologous protein pairs were aligned using each tool,
and standard performance metrics calculated. We further measured congruence of domain archi-
tecture assignments in the three domain databases.

Results: CSBLAST and PHMMER had overall highest accuracy. FASTA, UBLAST and USEARCH
showed large trade-offs of accuracy for speed optimization.

Conclusion: Profile methods are superior at inferring remote homologs but the difference in
accuracy between methods is relatively small. PHMMER and CSBLAST stand out with the highest ac-
curacy, yet still at a reasonable computational cost. Additionally, we show that less than 0.1% of
Swiss-Prot protein pairs considered homologous by one database are considered non-homologous
by another, implying that these classifications represent equivalent underlying biological phenom-
ena, differing mostly in coverage and granularity.

Availability and Implementation: Benchmark datasets and all scripts are placed at (http://sonnham
mer.org/download/Homology_benchmark).

Contact: forslund@embl.de

Supplementary information: Supplementary data are available at Bioinformatics online.

 

©The Author 2016. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unre-

stricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.

 

112 ﬂJO'sleumo[pJOJXO'sopeuuogutotq/ﬁd11q mm; papeolumoq

910K ‘09 lsnﬁnV no :2

G. l/.Saripella et al.

 

1 Introduction

Modern molecular biology relies on evolutionary conservation of
properties between entities such as genes and proteins that are hom-
ologous, i.e. share descent from a common ancestor. As a historical
property homology is unobservable but can be inferred from statis-
tically significant similarity under the proper conditions (Henikoff
and Henikoff, 1992). Through homology relationships (and within
them, specifically orthology relationships where common ancestry
dates back to a species diversification rather than a gene duplica-
tion), insights into molecular function of whole sequences (Bork
et al., 1998) or specific sites (Yao et al., 2003), 3D structure
(Chothia and Lesk, 1986), (Todd et al., 2001) or context such as
regulation can be transferred. Such transfer of results from direct ex-
perimentation to the components of the vast number of genomes for
which only molecular data is available, courtesy of ‘next-generation’
nucleotide sequencing techniques, means homology inference forms
a mainstay in bioinformatics research as well as in its applications in
organismal, clinical and evolutionary biology. These methods
started with the Smith—Waterman algorithm (Smith and Waterman,
1981) for exact computation of the minimal number of changes
needed to convert one sequence into another. Gradually more com-
plex probabilistic models were developed taking implicitly into ac-
count the structural constraints and codon properties of nucleic acid
substitutions, insertions and deletions. Sequence alignment/hom-
ology search/homology scoring methods quickly became over-
whelmed by computational complexity as database sizes increased,
prompting development of heuristic tools like FASTA (Pearson and
Lipman, 1988) or NCBI-BLAST (Altschul et al., 1990) which func-
tion fast enough to screen the whole of the known sequence universe
for similarity to a novel uncharacterized query.

With heuristic approaches come increased risk of error, and
given the potential importance of downstream applications such as
function prediction, the need becomes clear to properly evaluate the
reliability of homology inference tools. This is in itself not a trivial
problem, since such benchmarking ideally should involve a ‘gold
standard’ where homology status—whether shared common ances-
try holds or not—should be known with perfect certainty, which is
in principle never the case.

The existence of well-conserved ‘building blocks’ of protein se-
quence and structure, as in domain/gene families where in many
cases subtle sequence similarity is supported by clearer similarity of
the slower-evolving protein 3D structure (Chothia and Lesk, 1986),
makes for a potential workaround. Early on a preferred benchmark
was evaluating single-domain sequences from same or different
structural superfamilies as a proxy for certain positive or negative
homology status (Chandonia et al., 2004). This disregards the theor-
etical and practical difficulties which arise when domain rearrange-
ment or other forms of horizontal evolution causes mosaic gene
lineages (Vogel et al., 2004), where different regions have different
homologs, which is a complexity that the approach described here
also disregards. More tractable difficulties for homology inference
arises either when sequences have diverged too far (risk of failing to
detect homology) or are unexpectedly similar due to similar se-
quence composition biases and/or low-complexity region features
(risk of falsely inferring homology).

Several issues in creating benchmarking datasets have been dis-
cussed earlier (Aniba et al., 2010). Low-complexity regions occur
relatively seldom within well-characterized single-domain se-
quences, but will occur elsewhere in proteins, making single-domain
benchmarks underestimate the risk of false positives in genome-scale
homology inference applications. To remedy this, we previously

(Forslund and Sonnhammer, 2009) described an approach for gener-
ating ‘gold standard’ test cases for homology inference by selecting
pairs of multi-domain proteins where either all corresponding do-
mains match at the super-family/clan level (positive gold standard)
or where none of them do (negative gold standard). Using this ap-
proach, we compared different low-complexity filter settings for the
NCBI-BLAST homology search tool, and found that compositional
adjustment of score matrices allowed minimization of false posi-
tives, though sometimes at the price of truncated alignments.

More recent developments in homology inference involve
profile-based tools for detecting remote homologies, using profile-
specific score matrices (PSSMs) (Gribskov et al., 1987), Hidden
Markov Models (HMMs) (Eddy, 1998) or other techniques
(Altschul et al., 1997, Altschul and Koonin, 1998). These ‘next-gen—
eration’ homology search tools may offer greater sensitivity and
search speed (Elofsson, 2002), and because of these promises, the
need for formal evaluation of their reliability arises (Muller et al.,
1999). Consequently, we expanded on our previous benchmark ap-
proach to construct an updated evaluation dataset, then tested the
latest versions of the ‘next-generation’ homology search tools for
precision, accuracy and speed.

Additionally, we applied our benchmarking method to all three
major domain family databases: SUPERFAMILY (extending SCOP,
Fox et al., 2014; Gough et al., 2001; Hubbard et al., 1999; Oates
et al., 2015), Gene3D (extending CATH, Lees et al., 2013) and
Pfam (Finn et al., 2014), where previously only Pfam was used. This
was done with the intent that the similarity of benchmark results
derived from different databases would provide a test of to what ex-
tent, beyond differences in scope or coverage, that these resources,
built from different types of data and using different curation proto-
cols, reflect the same underlying evolutionary entities seen through
different definition schemes, a question which has been raised in
some recent studies (Csaba et al., 2009).

2 Methods

As previously described (Forslund and Sonnhammer, 2009), pairs of
multi-domain proteins are seen as homologous for the purpose of
the benchmark if their domains, in consecutive order, belong to the
same family or clan (in the case of Pfam) or the same superfamily (in
the case of Gene3D or SUPERFAMILY). If no domain in the first
protein is part of the same family/clan/superfamily as any domain in
the second protein, the pair is instead considered non-homologous
for the purpose of the benchmark. Protein pairs where neither condi-
tion held are considered potentially ambiguous and not used. All do-
main architectures and sequences were acquired from the source
databases (version 28.0 of Pfam, version 1.75 of SCOP/
SUPERFAMILY, version 3.5.0 of Gene3D), retrieving all domain
matches via v5 3.0 of the InterPro database (Mitchell et al., 2015 ),
restricting the analysis to sequences present in SwissProt
(UniProtKB/Swiss-Prot, downloaded on August 24 2015). To ac-
count for incompleteness of present domain annotations, any se-
quence was discarded for which at least fifty consecutive residues
were not assigned to a protein domain, as has been done in previous
studies (Forslund et al., 2008; Gough, 2005). Figure 1 displays ex-
amples of homologous and non-homologous pairs based on domain
architectures from each source database.

For the specific benchmark dataset, all sequences from a specific
set of genomes were included, chosen to represent the span of
(model organism) diversity while remaining small enough to be
manageable (Sayers et al., 2012)—see Supplementary Table S1 for

112 ﬂJO'sleumo[pJOJXO'soneuuoguioiq/ﬁdnq wort papeolumoq

910K ‘09 lsnﬁnV no :2

Benchmarking the next generation

 

 

multi-domain 1; csvosz

2: P07244 architectures

Homomgous Protein pair:
architectures

Protein pair; Non-homologous
1: QSSPQ7 multi-domain

2: oowrsz

 

 

2:PF02844_CL0179_PF02843_PF00586_PF02769 2:PF08766_PF02229 A) PFAM

 

 

2:52440_56059_51246_55326_56042

L1:PF02844_CL0179_PF02843_PF00586_PF02769 ] [1:CL0164_PF03815 ]
] 2:109715_54447

[ l :52440_56059_51246_55326_56042 [ l :49854_69848

] B) SUPERFANIILY

 

 

1:3.40.50.20_3.30.1490.20_3.30.470.20_3.90.600.10
_3.30.1330.10_3.90.650.10
2:3.40.50.20_3.30.1490.20_3.30.470.20_3.90.600.10
_3.30.1330.10_3.90.650.10

 

 

Fig. 1. Diagram illustrating how multi-domain homologous and non-homolo-
gous protein pairs were selected from the three databases Pfam (with clans),
SUPERFAMILY and Gene3d. Pfam architectures were considered at the Clan
level by replacing Pfam domain IDs with Clan IDs where defined. Architectures
are listed as consecutive domain identifiers separated by an underscore (_).
Only architectures with two or more domains were considered

details on this set of genomes. Within this set of sequences, for each
domain database, we considered each distinct protein multi-domain
architecture (PMDA) separately. In the case of Pfam, consecutive
repeat/motif-type domains, were collapsed to a single instance as in
Forslund and Sonnhammer (2009), because repeat numbers are
highly variable. Protein pairs were sampled to avoid biasing the ana-
lysis towards highly populated gene families. For each architecture,
one (if only one exists) or two proteins with that architecture were
randomly chosen from each genome in the benchmark, and the set
of pairs these proteins define were included, aiming to ensure both
within-species and across-species homologies at different evolution-
ary distance was sampled for each architecture. Negative test cases
(pairs of non-homologous proteins) were sampled by choosing a
protein from the architecture in question and another randomly se-
lected architecture meeting the criterion for non-homology, i.e. no
domains shared in any order even at clan or superfamily level, until
there were as many negatives as positives for each PMDA. See
Supplementary Table S2 for details on the number of pairs generated
for the final benchmark dataset.

For each protein pair evaluated, each pair was aligned (i.e. one
protein used as database, one as query) using each of the profile-
based homology search tools CS-BLAST (Biegert and Soding, 2009),
HHSEARCH (Soding, 2005) and PHMMER (Finn et al., 2011) as
well as the non-profile based NCBI-BLAST (Boratyn et al., 2013),
USEARCH/UBLAST (Edgar, 2010) and FASTA (Pearson and
Lipman, 1988) for comparison. All methods were run with default
parameters where not otherwise noted (see Supplementary Table S3
for details). The recently developed DELTA-BLAST (Boratyn et al.,
2012) was omitted, because it relies on a database of sequence fami-
lies aside from what is provided at runtime via query and search
database input. Similarly tools relying on iterative searches to build
intermediate profiles from additional database sequences (e.g. PSI-
BLAST; Altschul et al., 1997; or CSI-BLAST) were not included,
since their performance depends strongly on the number of iter-
ations and the composition of the database relative to the query,
making their evaluation in the present pairwise context difficult.
While HHsearch primarily is intended for use with multiple-
sequence queries, here only its performance with single-sequence
queries is evaluated, in line with the other methods tested—perform-
ance thus might be relatively better in a context other than pairwise
sequence comparisons. The score of the best high-scoring segment
pair (HSP) reported was used, with no attempt to merge together
multiple hit fragments, which also matches the common use cases
for these tools. Each tool was applied using default settings except
for setting any inclusion/reporting thresholds maximally inclusive so
as to be able to compare scores also for non-homologous pairs. Even

i— Inte;pro

Pfam SUPERFAMILY Gene3D

i i

I with and without excluding proteins with >50 unassigned AAs I

Clan-Filter l
Uniprot-SP ‘—
J.

Sixteen selected species NCBI Species
Two proteins per species
for each UPMDA
Pairs agreed and disagreed
on homology status

Homologous Non-homologous
pairs pairs

 

 

 

    

 
    
   

 

V
Selected only characterized
protein pairs

 

 

 

 

 

Removed all ambiguous
pairs based on UPMDAs

 

 

 

Agreement and

Disagreement check

Query Database Query Database

 

 

1. BLAST
2. CSBLAST
3. FASTA
> 4. HHSEARCH <
5. PHMMER
6. UBLAST
7. USEARCH

E-values & bit scores

Fig. 2. Flowchart illustrating the construction of the benchmark dataset. Protein

 

 

 

 

 

 

pairs were selected from the UniProt—SP database based on three domain data-
bases, removing any proteins with more than 50 consecutive residues not as-
signed to any domains as an initial filtering step. The dataset was restricted to
16 selected species. Pairs of proteins were subsequently retained if definable as
clearly homologous or clearly non-homologous based on our domain architec-
tu re criterion, for all three ofthe compared domain databases

so, some very divergent or non-homologous sequence pairs were not
reported even as very poorly-scoring alignments. For these pairs, a
maximally poor ‘proxy’ score (bit score=0) was assigned. When
ordering pairs by score for comparisons (e.g. Receiver Operating
Curves (ROC)) (Gribskov and Robinson, 1996), in cases of multiple
pairs sharing the same score (either the not-found proxy or other-
wise), positive and negative cases were evenly distributed within
these stretches of pairs so as not to introduce artifacts. See Figure 2
for a schematic of the workflow as a whole.

3 Results

3.1 Accuracy of different next-generation homology
search tools

Three challenging homology benchmarks were set up using protein
domain architectures based on either the Pfam, SUPERFAMILY, or
Gene3D domain definitions. True homologs were defined as multi-
domain protein pairs with identical domain architecture, while true
non-homologs were randomly picked as multi-domain proteins pairs
with no domain in common. The main advantage of using protein
domain databases instead of protein structure databases is that also
domains with unknown structure are included, such as domains
with low sequence complexity. The benchmarks contain 455, 330
and 339 architectures for Pfam, SUPERFAMILY, or Gene3D, re-
spectively. Protein pairs for these architectures were then sampled
from 16 species to build a benchmark set of 5245, 5047 and 5656
homologous protein pairs, respectively, with equal numbers of non-
homologous protein pairs sampled as well.

112 ﬂJO'sleumo[pJOJXO'sopeuJJOJutotq/ﬁdnq wort papeolumoq

910K ‘09 lsnﬁnV uo ::

G. l/.Saripella et al.

 

In total, seven homology search methods were benchmarked:
the three profile search tools CS-BLAST, HHSEARCH and
PHMMER, as well as the four single sequence search tools
FASTA, NCBI-BLAST, UBLAST and USEARCH. To make a fair
comparison, we ran all tools with single sequence queries, that is
searching the proteins of each benchmark pair against each other
in a 1 to 1 setup. Comparing the accuracy (recall/true positives re-
covered versus precision/false positives avoided) of the tested
search tools on all three benchmarks (Fig. 3A—C) shows that
CSBLAST and PHMMER perform best, though all profile-based
methods perform similarly. They range in AUC1000 (Area Under
Curve for the first 1000 false positives) between 0.89 and 0.92.
The classic FASTA method performs considerably poorer at AUC
~0.83-0.89, with USEARCH only slightly better and UBLAST
consistently scoring poorest, which makes sense as these two meth-
ods were optimized primarily for speed, but surprisingly the faster
tool, USEARCH, is clearly more accurate than the slower
UBLAST. Overall, the results were very similar using either Pfam,
SUPERFAMILY or Gene3D domains to generate the benchmark
data. To investigate whether results are stable also with proteins
that contain significant disordered regions, the analysis was also
run on a version of the benchmark dataset where pairs of proteins
with unassigned regions longer than 50 residues were not
excluded, with results shown in Supplementary Figure S1A—C. The
same overall trends were replicated. Supplementary Figure S2
show corresponding method performance on the benchmark at dif-
ferent specified E-value cutoffs.

3.2 Different domain definitions largely agree

How different are the three benchmarks? As they are all mapped to
UniProt identifiers, we can compare how often a pair in two bench-
marks have the same homology or non-homology status. Restricting
to protein pairs present in all three databases controls for difference
in coverage, as well as somewhat for differences in hierarchical
granularity. Agreement between the databases with respect to hom-
ology status reflects the extent to which their differing source data,
methodologies and curation efforts uncover the same underlying
biological entities, even though it does not guarantee that the do-
main architectures are identical. As seen in Table 1, the three data-
bases are almost never in opposition on the homology status of
shared protein pairs. Inspection of randomly sampled cases of dis-
agreement between the databases under this test indicate they largely
correspond to differences in granularity, where the databases differ
in how their hierarchies are structured, but where comparison at a
higher level would resolve the disagreement.

3.3 Run time evaluation

As a complement to benchmarking method accuracy, we also bench-
marked run time by applying each tool to 100 randomly chosen pro-
tein pairs (repeated 10 times to achieve robust run time estimates),
as shown in Figure 4. Profile-HMM methods were generally slower
than heuristic string matching searches, with HHSEARCH taking
the longest followed by CS-BLAST. PHMMER and NCBI-BLAST
were intermediate, possibly due to speed being longtime develop-
ment targets for both tools, and USEARCH and FASTA overall fast-
est. UBLAST is supposedly optimized for speed but ranked among
the slower methods here. It should be noted that some methods may
run faster on other hardware or in setups other than pairwise com-
parisons, e.g. by building a larger database and running multiple
queries against it.

 

   

 

   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

  

 

A PFAM + Clan
O
o-
0
L0
8
> o
1:- 0—
'17; Q
o
o.
a) Search tools: AUC1000 scores
2 8_ — CSBLAST: 0.9236
1— g — PHMMER: 0.9226
— HHSEARCH:0.9167
— NCBI—BLAST:0.9087
— USEARCH: 0.8956
8 — FASTA: 0.8879
10' — UBLAST: 0.8561
m I I I l l I
1 5 10 50100 500 5000
False posrtlves
B SCOP/Superfamily
O
o-
0
LO
O
O-
LO
a) V
a)
.2 o
.1: 8-
8 <1
0.
(D 8 Search tools: AUC1000 scores
2 Ln' — PHMMER: 0.9031
l- °° — CSBLAST: 0.8999
G — HHSEARCH:0.8774
o_ — NCBI—BLAST:0.8570
g — USEARCH: 0.8533
— FASTA: 0.8343
— UBLAST: 0.7846
I I I I I I
1 5 10 50100 500 5000
False posntlves
C CATH/Gene3D
O
o-
LO
LO
0
o-
:0 o
a) LO
.2
-|—l
Q V
a) Search tools: AUC1000 scores
2 8_ — CSBLAST: 0.9100
1— g — PHMMER: 0.9032
— HHSEARCH:0.9009
o — NCBI—BLAST:0.8784
o_ — USEARCH: 0.8613
g — FASTA: 0.8523
— UBLAST: 0.8158
I I I

 

 

 

 

1 5 10 50100 500 5000
False positives

Fig. 3. ROC plots showing cumulative true and false positive counts as tested
protein pairs (single-sequence query and search database for each pair) are
sorted based on the bit scores provided by each method. The curves are
ranked by corresponding Area Under Curve scores computed for the first
1000 false positives (AUC1000). Results are shown based on Pfam (A),
SUPERFAMILY (B) and Gene3D (C). These benchmarks exclude any proteins
with >50AA regions without domain assignments. Supplementary Figure
S1A—C show corresponding plots for a dataset where this constraint is
removed, leading to the inclusion of many more proteins with disordered re-
gions; the here observed trends were largely replicated

4 Discussion

Given the role of homology inference in genome-scale biology, val-
idation and comparative benchmarking of the tools in use is import-
ant, even where it is difficult in both theory and practice to

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/ﬂ(11111 wort papeolumoq

910K ‘09 lsnﬁnV uo ::

Benchmarking the next generation

 

Table 1. Table graphic showing for the three benchmark datasets derived from each database to what extent homologous pairs are homolo-

gous, ambiguous or non-homologous in the other three databases

 

 

Database Pfam Superfamily Gene3D
#Homologous pairs in total: 147 5 70 142 666 141 262

Also homologous in: Pfam — 138 084 (96.78%) 136 578 (96.68%)
Superfamily 147259 (99.78%) — 141 226 (99.97%)
Gene3D 147 155 (99.71%) 142 478 (99.86%) —

Ambiguous in: Pfam — 4582 (3.21%) 4652 (3.29%)
Superfamily 180 (0.12%) — 4 (0.002%)
Gene3D 284 (0.19%) 188 (0.13%) —

Non-homologous in: Pfam — 0 (0%) 32 (0.02%)
Superfamily 131 (0.08%) — 32 (0.02%)
Gene3D 131 (0.08%) 0 (0%) —

 

The three databases generally agree on homology/non-homology of protein pairs under our domain-based deﬁnition. Note that ambiguous pairs are not used in

the ROC analysis.

'0. _
(\l
O. _
N

(D

9 m

e e- -

.E

“5’

'—

 

 

Methods

Fig. 4. Run time for each homology inference method on a test set of 100 ran-

domly sampled homologous protein pairs from the Pfam-based benchmark
dataset, replicated ten times with different randomizations (mean and stand-
ard deviation shown as bars and error bars). All methods were run on an Intel
Xeon E5540 @ 2.53 GHz with 24 GB RAM on a single core

construct such benchmarks so that they will reflect the issues that
may come into play in ‘live’ applications. We previously described
an extensible strategy for such benchmarking and applied it to the
then state-of—the-art of homology inference methods. In the present
work, we have updated this approach and applied it to the ‘next
generation’ of such methods. We have shown these benchmark re-
sults to be robust to the choice of underlying domain definitions,
and we make the method available in script distribution for bioin-
formaticians seeking e.g. to optimize their particular analysis
pipelines.

From our benchmark we observe that most profile methods have
similar accuracy, with top performance from CSBLAST and the
HMMER 3 protein search application PHMMER, whereas the
speed-optimized FASTA and UBLAST/USEARCH are substantially
less accurate. All profile-based methods outperform ‘classic’ single-
sequence homology inference tools in terms of accuracy, but some
of them do this with great sacrifice of speed.

Additionally, we show that the three most widely used protein
domain definition schemes are similar with regards to which conclu-
sions on protein full-length homology or non-homology they lead
to, implying that the differences between them with regards to
source data, curation or methods chiefly lead to differences in cover-
age and granularity, but not so much to differences in what evolu-
tionary entities end up classified as domain families. Consequently,
analysis results from one generally transfers well to the others.

It is important to note that development of tools do not take
place in a vacuum separated from curation and compilation of pro-
tein domain databases. It is therefore conceivable that currently un-
known classes of protein folds exist where method performance is
different. However, it is likely that most existing folds already are
known (Roche and Briils, 2015 ).

As stated previously, this benchmark leaves out recent develop-
ments (Boratyn et al., 2012) that rely on information not contained
within the query and database sequences. Such methods may im-
prove performance beyond plain sequence comparison or iterative
query tools. Evaluating them will however be a challenge for future
benchmark efforts since they depend on additional data beyond the
family membership being tested.

Funding

This work was supported by an Alexander von Humboldt Fellowship to KF.

Conﬂict of Interest: none declared.

References

Altschul,S.F. et al. (1997) Gapped BLAST and PSI-BLAST: A New Generation
of Protein Database Search Programs. NAR, 25, 3389—3402.

Altschul,S.F. and Koonin,E.V. (1998) Iterated proﬁle searches with PSI-
BLAST — a tool for discovery in protein databases. Trends Biochem. Sci., 23,
444—447.

Altschul,S.F. et al. (1990) Basic local alignment search tool. ]MB, 215,
403—410.

Aniba,M.H. et al. (2010) Issues in bioinformatics benchmarking: the case
study of multiple sequence alignment. NAR, 38, 735 3—7363.

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/ﬂ(11111 moi; papeolumoq

910K ‘09 isnﬁnV uo ::

G. l/.Saripella et al.

 

Biegert,A. and SédingJ. (2009) Sequence context-speciﬁc proﬁles for hom-
ology searching. PNAS, 106, 3770—3775.

Boratyn,G.M. et al. (2012) Domain enhanced lookup time accelerated
BLAST. Biol. Direct., 7, 12.

Boratyn,G.M. et al. (2013) BLAST: a more efﬁcient report with usability im-
provements. Nucleic Acids Res., 41, W29—W33.

Bork,P. et al. (1998) Predicting function: from genes to genomes and back. ].
Mol. Biol., 283, 707—725.

Chandonia,].M. et al. (2004) The ASTRAL Compendium in 2004. NAR, 32,
D189—D192.

Chothia,C. and Lesk,A.M. (1986) The Relation between the Divergence of
Sequence and Structure in Proteins. Embo ], 5, 823—826.

Csaba et al. (2009) Systematic comparison of SCOP and CATH: a new gold
standard for protein structure analysis. BMC Struct. Biol., 9, 23.

Eddy,S.R. (1998) Proﬁle Hidden Markov Models. Bioinformatics, 14, 755—763.

Edgar,R.C. (2010) Search and clustering orders of magnitude faster than
BLAST. Bioinformatics (Oxford, England), 26, 2460—246 1.

Elofsson,A. (2002) A study on protein sequence alignment quality. Proteins:
Struct. Funct. Bioinf., 339, 330—339.

Finn,R.D. et al. (2014) Pfam: the protein families database. Nucleic Acids
Res., 42, 13222—13230.

Finn,R.D. et al. (2011) HMMER web server: interactive sequence similarity
searching. Nucleic Acids Res., 39, W29—W37.

Forslund,K. et al. (2008) Domain tree-based analysis of protein architecture
evolution. Mol. Biol. Evol, 25, 254—264.

Forslund,K. and Sonnhammer,E.L.L. (2009) Benchmarking homology detec-
tion procedures with low complexity ﬁlters. Bioinformatics, 25,
2500—25 05.

Fox,N.K. et al. (2014) SCOPe: structural classiﬁcation of proteins — extended,
integrating SCOP and ASTRAL data and classiﬁcation of new structures.
NAR, 42, D304—D309.

Gough,]. et al. (2001) Assignment of homology to genome sequences using a
library of Hidden Markov Models that represent all proteins of known
structure. ]MB, 313, 903—919.

Gough,]. (2005 ) Convergent evolution of domain architectures (is rare).
Bioinformatics, 21, 1464—1471.

Gribskov,M. et al. (1987) Proﬁle analysis: detection of distantly related pro-
teins. PNAS, 84, 4355—4358.

Gribskov,M. and Robinson,N.L. (1996) Use of receiver operating characteris-
tic (ROC) analysis to evaluate sequence matching. Comput. Chem., 20,
25—33.

Henikoff,S. and Henikoff,].G. (1992) Amino acid substitution matrices from
protein blocks. PNAS, 89, 10915—10919.

Hubbard,T.]. et al. (1999) SCOP: a structural classiﬁcation of proteins data-
base. Nucleic Acids Res., 27, 254—256.

Lees,J.G. et al. (2013) Gene3D: multi-domain annotations for protein se-
quence and comparative genome analysis. Nucleic Acids Res., 42, 240—245.

Mitchell,A. et al. (2015) The InterPro protein families database: the classiﬁca-
tion resource after 15 years. Nucleic Acids Res., 43, D213—D221.

Miiller,A. et al. (1999) Benchmarking PSI-BLAST in Genome Annotation. ].
Mol. Biol., 293, 1257—1271.

Oates,M.E. et al. (2015 ) The SUPERFAMILY 1.75 database in 2014: a dou-
bling of data. Nucleic Acids Res., 43, D227—D233.

Pearson,W.R. and Lipman,D.J. (1988) Improved tools for biological sequence
comparison. PNAS, 85, 2444—2448.

Roche,B. and Briils,T. (2015 ) An assessment of the amount of untapped
fold level novelty in under-sampled areas of the tree of life. Sci. Rep., 5,
14717.

Sayers,E.W. et al. (2012) Database resources of the national center for biotech-
nology information. NAR, 40, D13—D25.

Smith,T. and Waterman,M. (1981) Identiﬁcation of common molecular subse-
quences.]. Mol. Biol., 147, 195—197.

SédingJ. (2005 ) Protein homology detection by HMM-HMM Comparison.
Bioinformatics (Oxford, England), 21, 951—960.

The Uniprot Consortium (2010) The Universal Protein Resource (UniProt) in
2010. NAR, 38, D142—D148.

Todd,A.E. et al. (2001) Evolution of function in protein superfamilies, from a
structural perspective. ]MB, 307, 1113—1143.

Vogel,C. et al. (2004) Structure, function and evolution of multidomain pro-
teins. Curr. Opin. Struct. Biol., 14, 208—216.

Yao,H. et al. (2003) An accurate, sensitive, and scalable method to identify
functional sites in protein structures. ]MB, 326, 255—26 1.

112 /810'S{12umo[p101x0'sot112u1101utotq/ﬁd11q 111011 papeolumoq

910K ‘09 isnﬁnV uo ::

