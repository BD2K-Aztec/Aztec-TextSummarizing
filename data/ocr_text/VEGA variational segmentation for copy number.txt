ORIGINAL PAPER

Vol. 26 no. 24 2010, pages 3020-3027
doi: 10. 1093/bioinformatics/btq586

 

Genome analysis

Advance Access publication October 19, 2010

VEGA: variational segmentation for copy number detection

Sandro Morganellam, Luigi Cerulol’Z, Giuseppe Vigliettoz’3 and Michele Ceccarelli1’2’*

1Department of Biological and Environmental Studies, University of Sannio, Via Port’Arsa 11, 82100, Benevento,
2Bioinformatics Core, IRGS Istituto di Ricerche Genetiche “G. Salvatore”, BioGeM s.c.a r.|. Ariano Irpino (AW and
3Dipartimento di Medicina Sperimentale e Clinica G Salvatore; Universit Magna Graecia, Catanzaro, Italy

Associate Editor: John Quackenbush

 

ABSTRACT

Motivation: Genomic copy number (CN) information is useful to
study genetic traits of many diseases. Using array comparative
genomic hybridization (aCGH), researchers are able to measure the
copy number of thousands of DNA loci at the same time. Therefore,
a current challenge in bioinformatics is the development of efficient
algorithms to detect the map of aberrant chromosomal regions.
Methods: We describe an approach for the segmentation of copy
number aCGH data. Variational estimator for genomic aberrations
(VEGA) adopt a variational model used in image segmentation. The
optimal segmentation is modeled as the minimum of an energy
functional encompassing both the quality of interpolation of the data
and the complexity of the solution measured by the length of the
boundaries between segmented regions. This solution is obtained
by a region growing process where the stop condition is completely
data driven.

Results: VEGA is compared with three algorithms that represent
the state of the art in CN segmentation. Performance assessment
is made both on synthetic and real data. Synthetic data simulate
different noise conditions. Results on these data show the robustness
with respect to noise of variational models and the accuracy of VEGA
in terms of recall and precision. Eight mantle cell lymphoma cell lines
and two samples of glioblastoma multiforme are used to evaluate
the behavior of VEGA on real biological data. Comparison between
results and current biological knowledge shows the ability of the
proposed method in detecting known chromosomal aberrations.
Availability: VEGA has been implemented in R and is available at
the address http://www.dsba.unisannio.it/Members/ceccarelli/vega
in the section Download.

Contact: ceccarelli@unisannio.it

Supplementary information: Supplementary information is
available at Bioinformatics online.

Received on July 22, 2010 ; revised on October 11, 2010 ; accepted
on October 12, 2010

1 INTRODUCTION

Recent biological studies show the close relationship between
chromosomal regions aberrant in copy number (CN) and diseases
like tumor (Beroukhim et al., 2010; Harada et al., 2008; Zhao et al.,
2003) and mental retardation (Fan et al., 2007; Sebat et al., 2007).
High resolution CN estimation makes use of comparative genomic
hybridization arrays. DNA from a test sample and normal reference

 

*To whom correspondence should be addressed.

sample are labeled differentially, using different ﬂuorophores, and
hybridized to several thousand probes. The ratio of the ﬂuorescence
intensity of the test to that of the reference DNA is then calculated,
to measure the CN changes for a particular location in the genome.
In particular, the logR ratio (LLR) gives an indirect measure of
CN of each probe by plotting the ratio of observed to expected
hybridization intensity. After a microarray has been constructed and
hybridized, the corresponding image can be acquired and additional
analysis steps can be used both to reduce noise and to increase the
statistical conﬁdence of the observations (generally each probe is
spotted in several copies) (Khoj asteh et al., 2005). The output of this
process is a list of LRR values with the respective genomic positions.
The so called segmentation algorithms use this list of measurements
to compute the features (breakpoint positions and kind of mutation)
of the aberrant regions along the genome. The availability of efﬁcient
segmentation algorithms plays an important role in the mapping
of aberrant chromosomal regions. Accurate aberration mapping
can be used to extract new insight on the mechanisms leading to
genetic diseases. For this reason in literature, several segmentation
approaches have been proposed.

In likelihood function—based approaches (J ong et al., 2003, 2004;
Myers et al., 2004), breakpoint positions are estimated by using
a maximum likelihood criterion in which penalty terms are used
to limit the complexity of the solution. Often penalty terms are
controlled by weights which can be chosen adaptively to the
data (Hupe et al., 2004; Picard et al., 2005). An interesting
likelihood function—based approach is DNACopy (Olshen et al.,
2004) which is based on a modiﬁcation of the original binary
segmentation proposed by Sen and Srivastava (1975). DNACopy
segments the chromosome into contiguous regions of equal CN
using a non—parametric permutation reference distribution which
takes in account the effect of noise. In particular, the authors model
CN data as a sequence of random variables and the maximum
likelihood is used recursively to look for change points where
adjacent random variables have a different distribution function.
In addition, DNACopy uses a pruning algorithm to control the
number of regions. Willenbrock and Fridlyand (2005) and Lai et al.
(2005) showed that DNACopy algorithm performs well in terms of
sensitivity and false discovery rate both on synthetic and real data.
Other statistical models frequently used for CN segmentation are
Bayesian approaches and Hidden Markov models. In the Bayesian
framework, the prior distributions are combined with some posterior
distribution functions to construct the most plausible hypothesis
concerning the data segmentation (Daruwala et al., 2004; Pique—Regi
et al., 2008). In Hidden Markov model—based approaches, hidden
states represent the underlying CN of probes. In Fridlyand et al.

 

3020 © The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com

112 /§.IO'SIBUJHOprOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq 11101; popaommoq

9IOZ ‘Ig lsnﬁnv uo ::

VEGA

 

(2004), the model is characterized in terms of three parameters: the
initial state probability, the transition probability and the collection
of Gaussian emission probability functions deﬁned within each state.
SMAP (Andersson et al., 2008) is a recent approach based on the
discrete—index hidden Markov model where a maximum a posteriori
approach is used to split the chromosome into regions. The authors
adapt the maximum a posteriori approach so that user—deﬁned priori
informations can be integrated within their model for limiting noise
inﬂuence (modeled by a Gaussian distribution).

In recent literature, variational—based approaches are emerging to
deal with the CN segmentation problem (Nilsson et al., 2008, 2009).
The works of Mumford and Shah (1989) and Rudin et al. (1992)
are the pioneers of discontinuity—adaptive variational models which
have been successfully applied in a wide variety of problems. The
original model, based on the Total Variation norm (Giusti, 1984), was
proposed to recover image corrupted by noise preserving important
image features such as object edges (Ceccarelli, 2007a). Afterwards,
discontinuity—adaptive variational models have been applied in
many different research areas, such as texture segmentation (Vese
et al., 2002), medical image analysis (Ceccarelli et al., 2007b) and
shape identiﬁcation in ‘synthetic—aperture radar’ imagery (Redding
et al., 1999). Variational models are based on the minimization
of a functional controlling the similarity between the computed
segmentation and the observed image, penalizing at the same time
complex solutions. The complexity of the solution is controlled
by the scale parameter (also called regularization parameter). As
the regularization parameter increases less regions are computed,
therefore the choice of a good regularization parameter is a common
open question in many variational data analysis algorithms.

Discontinuity—adaptive variational models are very skillful in
segmentation of piecewise constant (PWC) images. In PWC images,
the pixels belonging to the same object have the same intensity, but
noise changes image features and the segmentation task becomes
more difﬁcult. This situation is very similar to aCGH data, for which
segmentation errors are due to noise that shifts LRR values. A recent
work (Nilsson et al., 2009) presents a CN segmentation algorithm
based on the total variation minimization process proposed by Rudin
et al. (1992).

Here, we propose a new segmentation algorithm (VEGA) based
on the Mumford and Shah variational model (Mumford and
Shah, 1989). The PWC assumption is used to deﬁne a functional
considering both accuracy and parsimony of the boundaries. The
segmentation problem is put as a minimization problem of an
energy functional encompassing both the quality of interpolation
of the data by a piecewise constant function and the ‘complexity’ of
the solution measured by the length of the boundaries between
segmented regions. It is well known that the resulting energy
functional is non—convex and can have many local minima. In order
to efﬁciently compute a solution here we adopt a greedy steepest—
descent algorithm based on a pyramidal multiscale approach.
The resulting algorithm belongs to the class of region growing
segmentation algorithms similar to that proposed in (Koepﬂer
et al., 1994). In addition, we propose a data—driven heuristics
for the computation of a suitable regularization parameter. The
use of a variational segmentation approach for CN variation
estimation has also been proposed in (Nilsson et al., 2009), but
there are some signiﬁcant differences with the method proposed
here. First, VEGA is based on the Mumford and Shah model while
Ultrasome (Nilsson et al., 2008, 2009) adopts the Rudin’s model

(Rudin et al., 1992). Moreover, VEGA performs the minimization
of the energy functional with a bottom—up approach, by a sequence
of successive merging of smaller regions into larger ones. This
leads to a greedy multiscale algorithm driven by an increasing
series of values of the regularization parameter similar to the image
segmentation approach proposed by Koepﬂer et al. (1994). Whereas,
in (Nilsson et al., 2008) a dynamic programming approach is used,
by choosing a ﬁxed value of the regularization parameter.

In order to validate our approach, we choose as comparison
methods DNACopy (a likelihood function—based approach whose
good performance have been demonstrated), SMAP (a recent
statistical model—based approach) and Ultrasome (that uses a
variational model as in VEGA). Results are compared both on
synthetic and on real biological data. Both SMAP (version 1.12.0)
and DNACopy (version 1.16.0) are available as Bioconductor R
packages, while Ultrasome (version 2.0) is available in a command
line version (for Windows and Linux) and a graphical user interface
version (for Windows).

2 METHODS

2.1 Mumford and Shah model

The basic idea of the Mumford and Shah model (Mumford and Shah, 1989) is
the so—called piecewise smooth model. Given an observed signal n0 deﬁned
on the domain 52, we can model no by a partition of 52 into a set of disjoint
connected components 52,-, with

QzﬂlngU...Qn

in such a way that the signal no varies smoothly within each 52,- and it
varies discontinuously across the boundaries between different 52,-. The set
of points on the boundary between the 52,- is denoted as I‘. This means that
the segmentation problem is put as a problem of optimal piecewise smooth
approximation, i.e. we look for an approximation n of no whose restrictions
to the regions 52,- are smooth. The search of the optimal piecewise smooth
approximation of no can be cast into the minimization of the following
functional:

E(n,F)=a/(n—n0)2dx dy+f lvnlzdx dy+x|r| (1)
s2 s2\r

where a and A are two non—negative parameters weighting the different terms
in the energy: the ﬁrst term requires that n approximates no, the second term
takes in account the variability of it within each connected component 52,-
and the third term penalizes complex solutions in terms of the length of
the boundaries |I‘|. Smaller values of E are associated with better solutions
(n, I‘) for the observed signal no. A special case of Equation (1) is obtained
when the approximation n of the signal n0 is considered to be a piecewise
constant function (n constant within each connected components 52,-). For this
case, Mumford and Shah (1989) proposed the so—called piecewise constant
Mnmford—Shah model:

E(u, rpZ/ﬂ (n0 —n,-)2dx dy+A|F| (2)

It is easy to show that, given a ﬁxed set of boundaries I‘, in order to have
a minimum the variables n,- should be set as the mean of no within of each
connected component 52,-.

In this work, we adopt the Mumford and Shah model deﬁned in (2) for
segmenting CN data. The role of the two terms of (2) is important, the ﬁrst
term can be considered as the error in the approximation of n by a constant
function within each region and the second term as a penalty to complex
segmentations consisting of many small regions with irregular boundaries.
Therefore, this kind of functional is a compromise between the accuracy
of the approximation within each region and parsimony of the boundaries.

 

3021

112 /§JO'S{BUJnofp.IOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 11101; popaommoq

9IOZ ‘lg lsnﬁnv uo ::

S.Morganella et al.

 

The resulting segmentation depends on the scale parameter A, indeed it
determines the amount of regions of the computed segmentation: when A
is small many boundaries are allowed so the resulting segmentation will be
ﬁne, while as A increases the segmentation will be coarser and coarser.

2.2 The proposed approach

2.2.1 The model Let DER” the data vector containing n LRR probes
of a chromosome where the observations are ordered by the respective
genomic position. We deﬁne a segmentation S of D as a set of ordered
positions (breakpoints) b1, ...,bM+1 partitioning D into M connected regions
R={R1,...,RM}. The region R,- is identiﬁed by the indexes in [b,-,b,-+1)
with i=1,...,M and where the breakpoints b1 and bM+1 are ﬁxed to the
values 1 and n+1, respectively. We use the one—dimensional version of the
piecewise constant Mumford and Shah functional, in this case the length of
the boundaries between regions has no inﬂuence on the segmentation, and
the second term of (2) reduces to the number of regions, denoted here as M.

E(n,I‘)=z:v/g‘2 (no—n,)2dx dy-l-AM (3)

Given the n—dimensional data D, it is easy to show that the optimal
segmentation must be chosen among the 2” possible solutions. In genomic
data, we have a resolution that provides tens of thousands of observations, so
brute force algorithms cannot be applied and suitable solutions must be found
by using heuristic strategies. Here, we use a greedy procedure as explained
below.

2.2.2 Minimization process The minimization of (3) is carried out by a
region growing process with small regions progressively merged to create
larger ones leading to a pyramidal algorithm going from ﬁner segmentations
to coarser segmentations. Given two adjacent regions R,- and Rj, it can be
shown that the reduction of the energy (3) after the merging of these two
regions is given by:

Em. F\R.-UR,-)—E(u, r»: Mllut—u-llz—A (4)

le-l + |le ’

where R[,Rj e R with i# j, |R,| and n,- are the length and LRR mean value of
the i—th region, respectively. ||'|| represents the L2 norm. Following a greedy
procedure, we start with a segmentation having n regions each for each LRR
measure, then at each step we choose as the next pair of regions to be merged
that producing the maximum decrease of the energy functional. For a ﬁxed
value of A, the algorithm iteratively computes the pair of adjacent regions
for which (4) is as negative as possible, if such pair of regions exists. If no
such pair of regions exists, then the value of A is increased. The resulting
method is therefore considered a multiscale algorithm Koepﬂer et al. (1994)
since the value of A represents the scale, as A grows the segmentation gets
coarser. The algorithm stops when the maximum value of the scale parameter
is reached. The sequence of values of this parameter is called A—schedule by
analogy with temperature schedule of simulated annealing.

2.2.3 A-schednle selection The A values determine the quality of the ﬁnal
segmentation so the choice of the A—schedule is very important for ﬁnal
segmentation. Here, we propose a dynamic A—schedule selection where the
A stop value is computed considering both the sequences of A values and
the data variability. We modify the F nll A-Schednle Segmentation approach
proposed by Redding et al. (1999) so that it can work on one—dimensional
spaces. In particular from Equation (4) we associate to each breakpoint b,-
with i =2, ...,M (191 and bM+1 breakpoints are ﬁxed) the value:

A__ lRi—ll lRil

——iiu-_1—u-ii2 (5)
’ lRt—1|+|Rtl ’ ’

Note that A,- represents the cost required for merging the regions R,_1 and
R,. The i—th breakpoint can be deleted (and the adjacent region are merged) if
A,- < A. If more regions remain and no A,- agrees the previous inequality, then
there is no merging that decreases the functional and a new scale parameter,

A, must be chosen. Here, we select the next scale parameter value as the
smallest A,- and adding to this value a positive constant 6 close to zero. By
using this update rule, new region merges are allowed, so the region growing
process will be composed by ﬁne merging operations.

2.2.4 Optimal A selection Acritical point for many variational approaches
is the selection of the stop condition, i.e. the selection of the last value of A for
which the output solution is obtained. Different values of the regularization
parameter can be associated to suitable segmentations. In order to provide
a stopping criterion, we use a modiﬁed version of the minimum variance
method which was ﬁrst studied by Otsu (1979) in image segmentation. Otsu
(1979) proposed a stopping criterion based on the maximization of the ratio
02 (B) / 02(T ) where 02 (B) and 02(T) are the between class—variance and the
total variance, respectively. 02 (B) measures the variability between different
segmented regions and it can be calculated considering only the adjacent
regions.

Our idea starts from the consideration that the A,- measures the degree of
compatibility between two adjacent regions, so we can use A,- to estimate
the variability between adjacent regions (similarly to the between class—
van'ance). Therefore, measuring the distance between two consecutive
A—schedule values (AA =Al+1 —Al), we can obtain information on the
consistency of the segmentation. In particular, small AA values indicate a
merging of compatible regions, in contrast the more AA grows the more we
deviate from the compatibility between adjacent regions. In order to take also
in account the total variability of the data we use the standard deviation (SD),
1), computed chromosome by chromosome, and the proposed stop criterion
is:

AA=M+1—Aiiﬁv (6)

where p is a positive constant. We tested different values for p and we
obtained the best performance by using ﬁ=0.5. In absence of further prior
information, this value allows to obtain segmentation results consistent to
the data taking also in account the complexity of the solution. All results
reported in this article were obtained by using ﬁ=0.5. The detailed VEGA
algorithm is summarized in pseudocode in the Supplementary Material.

2.2.5 Compntational complexity If we have n probes then the starting
segmentation will have n regions corresponding with n+1 breakpoints that
have to be maintained in order to efﬁciently extract the minimum at step 8
of the Algorithm 1 (Supplementary Material). Here, we use a priority queue
based on a heap data structure (Connen et al., 2009). Therefore, step 4
requires 0(n), step 8 requires 0(1), whereas steps 11 and 12 require 0(logn)
each. Considering that the cycle in steps 7—18 is repeated at maximum n
times, the complexity of the algorithm VEGA is 0(nlogn).

2.2.6 Region labeling The region growing process described above
produces a segmentation S composed by M regions R: {R1,...,RM} each
represented by the value n,-, the mean of the observations contained in the i—th
region (with i=1,...,M). In order to assign a label to each region indicating
if this region correspond to a normal, loss or gain aberration we use the
rule proposed by Willenbrock and Fridlyand (2005): a region R,- is labeled
as loss if n,- < —0.2, while it is labeled as a gain if n,- >0.2 and for values
—0.2 5 n,- 5 0.2 the region is considered normal.

3 RESULTS

In order to evaluate the performance of our approach, we use both
synthetic and real data. We compare our results with the ones
obtained by DNACopy (Olshen et al., 2004), Ultrasome (Nilsson
et al., 2009) and SMAP (Andersson et al., 2008). Among the
considered methods just SMAP provides a label assignment for
the segmented regions, while Ultrasome and DNACopy (similar
to VEGA) provide the LRR mean value of each region. Therefore,
when the quantitative analysis requires for each region a discrete

 

3022

112 /B.IO'SIBUJHOprOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 11101; popaommoq

9IOZ ‘lg lsnﬁnv uo ::

VEGA

 

 

ﬁnMH—ﬁﬂmﬂnﬂlﬂﬁliﬂﬂ—“mm

.._SHELLWJ.¥.W;LM__

    

 

 

EELEHIEIEUJJ... ....._..

r-

    

 

 

 

BEE El - W'Idill: an ENE; 3 - Wllﬂh: ﬂ

 

_|.

.n.

 

_.

.-_..
_..n..-.-..-_—.
_.. .1“

SEE: 3 - Wldth: 'IIIJ SIH' 3 - W'Idﬂl' 5
—F-

Haw—n

 

    

 

 

 

 

 

SHE: 2 * Wldih: #0 ENE: 2 * Wldth: 20
4|:-

 

SNH: 2 * Wldth: I'D 5m: 2 * II"Ii"lll:l‘ll1: 5

 

 

.n.

 

 

__a.u-— _d__.9_——

.1-9—

 

 

SNH: ‘l - Wldih: IIIJ SHE: ‘I - Wld'lh: '20

 

 

SHH: ‘l -Wldth: I'D

 

 

 

 

 

 

- '1.
. “1

 

 

 

 

 

   

 

0' Vega 0 DNACopy

Ultrasome —S— SMAP

Fig. 1. ROC curves at different aberration widths and SNR. The x—axis is the FPR and the y—axis is the TPR. The curves were generated by measuring the
TPR and FPR on the simulated data published in Lai et al. (2005). Blue is VEGA, red is DNACopy (Olshen et al., 2004), green is Ultrasome (Nilsson et al.,

2009) and black is SMAP (Andersson et al., 2008).

label (loss, normal or gain), we apply to Ultrasome and DNACopy
the same label assignment rules used in our approach (see Section
2.2.6), while when the ﬁtted LRR in each region is required we
use for SMAP the mean value of all LRRs contained in the region.
Algorithms ran with their default parameters, except for SMAP for
which parameters were chosen by the user.

3.1 Results on synthetic data

3.1.] Evalnation metric For a quantitative evaluation of the
performance we used the Precision, the Recall and their harmonic
mean (F —measure) which are three widely used statistical
classiﬁcations. The Precision can be seen as a measure of exactness
or ﬁdelity, whereas Recall is a measure of completeness. Both
measures are deﬁned by using the concepts of true positive (TP),
false positive (FP) and false negative (FN). A TP represents a perfect
correspondence between the computed label and the true ground, a
FP occurs when the algorithm detects a mutation that is not present
in the true ground and we have a FN evaluation when a mutation
in the true ground is not detected by the algorithm. Algorithm
accuracy has also been reported by calculating the receiver operating
characteristic (ROC) curve as described in Lai et al. (2005) where
the true positive rate (TPR) was deﬁned as the number of probes
inside the aberration whose ﬁtted values are above the threshold
level divided by the number of probes in the aberration and the false
positive rate (FPR) was deﬁned as the number of probes outside the

aberration whose ﬁtted values are above the threshold level divided
by the total number of probes outside the aberration.

3.1.2 Validation on Lai et al. synthetic data Given that several
different segmentation methods have been published in literature,
this makes it difﬁcult to have a fair comparison between all of
them. Here, as in Magi et al. (2010), we address this problem
by using already available synthetic data previously published in
Lai et al. (2005). About a dozen methods have been benchmarked
using this dataset, and we use it to evaluate the performance of
VEGA. Moreover, Lai et al. (2005) found DNACopy as the method
performing consistently well on both synthetic and real data, so we
include the performance of DNACopy in our comparison.

The synthetic dataset proposed by Lai et al. (2005) simulates four
aberration widths (5, 10, 20 and 40) in different noise conditions
(signal—to—noise ratio SNR of 1, 2, 3 and 4). For each aberration
width and SNR, 100 artiﬁcial chromosomes of 100 probes were
generated. As shown in Figure 1, in high SNR conditions (SNR
values of 3 and 4) VEGA results are very similar to the ones of
DNACopy, while for low SNRs and small aberration widths (lower
right panels) VEGA appears to perform better than DNACopy. By
analyzing SMAP’s performance we can notice how it is strongly
inﬂuenced by the aberration width and for SNR of 1 its performance
is not simple to be interpreted. Eventually this may be due to the
used parameter setting. For Ultrasome, we can notice that although
it has acceptable performance for high SNR levels (4 and 3), it has
some problems in low SNR scenarios.

 

3023

112 /3.IO'SIBUJHOprOJXO'SOI]BIII.IOJUIOIQ//Zd11q 111011 pop1201umoq

9IOZ ‘lg lsnﬁnv uo ::

S.Morganella et al.

 

Table 1. Results on synthetic data for the considered approaches

 

o VEGA Ultrasome

DNACopy SMAP

 

Precision Recall F-measure Precision Recall F-measure

Precision Recall F-measure Precision Recall F-measure

 

0.00 1.000 1.000 1.000 0.937 0.926 0.931
0.10 1.000 1.000 1.000 0.938 0.926 0.932
0 20 0 998 0 999 0.999 0 938 0 920 0 929
0 30 0 968 0 978 0.973 0 933 0 898 0 915
0.40 0.876 0.928 0.902 0.912 0.852 0.881
0.50 0.825 0.891 0.856 0.892 0.824 0.857
0.60 0.679 0.828 0.746 0.819 0.748 0.782
0.70 0.586 0.804 0.678 0.762 0.681 0.719
0.80 0.556 0.792 0.653 0.728 0.669 0.697
0.90 0.487 0.787 0.601 0.654 0.623 0.638
1.00 0.440 0.793 0.566 0.607 0.578 0.592
Mean 0.765 0.891 0.816 0.829 0.786 0.807

0.999 1.000 1.000 1.000 1.000 1.000
0.999 1.000 0.999 1.000 1.000 1.000
0.996 0.999 0.997 0.999 0.999 0.999
0.960 0.977 0.968 0.985 0.982 0.983
0.860 0.931 0.894 0.931 0.892 0.911
0.789 0.881 0.832 0.869 0.771 0.817
0.643 0.780 0.705 0.516 0.900 0.656
0.581 0.730 0.647 0.306 0.985 0.467
0.545 0.711 0.617 0.287 1.000 0.446
0.493 0.644 0.558 0.270 0.998 0.425
0.460 0.521 0.489 0.275 0.991 0.430
0.757 0.834 0.791 0.676 0.956 0.739

 

0 represents the SD of the white Gaussian noise. Bold represents the best performance for each noise level.

3.1.3 Validation on the proposed synthetic data Although the
dataset proposed by Lai et al. (2005) allows an extensive comparison
of segmentation algorithms it is far from real aCGH data where, for
each chromosome, thousands of probes are observed and multiple
gain and loss mutations are expected. In order to overcome these
limitations we created an artiﬁcial dataset simulating the proﬁles
of three chromosomes having different size of 500, 750 and 1000
probes (50 proﬁles for each chromosome were generated). In each
sample, a set of mutations were randomly inserted with size ranging
from 11 to 25 where both position and class (loss or gain) of each
aberration was randomly chosen. In particular, 10 mutations (with
size ranging from 11 to 20) were inserted within the data with 500
observations and 15 aberrations (with size ranging from 11 to 25)
were inserted within the samples having 750 and 1000 probes. The
model used for the generation of the synthetic proﬁles follows:

dm =xm +8", (7)

where dm is the observed LRR for the probe m which is the sum of
two components, the ﬁrst one is the real LRR xm for this probe and
the second one, 8m is the noise component corrupting the data. The
true component xm can assume values log2(%)=—1, log2(%)=0

and log2( %) = 0.58 for loss, normal and gain, respectively. The noise
component is modeled as a white Gaussian process 8m ~N(0,o).
Performance assessment is made by varying for each sample the
value of o from 0 to 1 with step 0.1.

In Table 1, Recall, Precision and F —measure of each considered
method are reported with respect to the noise SD 0.

Observing the results obtained for the different chromosome sizes
(Supplementary Figs S2—S4), we note that the number of probes does
not affect the performance of the compared algorithms. Analysing
the trends of the considered approaches with respect to the noise
level a (Table 1 and Fig. S2), we note that SMAP works well until
the value of o is not greater than 0.5, after this value its performance
tends to drop down. Also DNACopy’s performance is negatively
affected by the noise, but the trend is less steep than SMAP. In
contrast, both VEGA and Ultrasome results are not drastically
affected by the values of a but Ultrasome does not compute the
correct segmentation in no—noise condition (0:0), this is caused
by the number FN and FF that produce a Precision of 0.937 and
a Recall of 0.926. This ﬁrst analysis demonstrates that variational
approaches tend to be more robust to noise than the other considered

ones. These considerations are also supported from the ROC curves
and the corresponding area under the curves (AUCs) reported in
Supplementary Figures S4—S11 where in addition we can see that
these algorithms are more skillful at detecting losses than gains.
Figure 2 shows the results of the compared algorithms on a
simulated chromosome proﬁle of 1000 probes for a noise values
of 0 (A) , 0.5 (B) and 1 (C). In these Figures, black lines represent
the true proﬁles and the red lines show the proﬁles computed by
the algorithms. Comparing computed and true proﬁles we can note
that in absence of noise (0:0), all algorithms provide the correct
segmentation, while for 0:05 VEGA and SMAP compute more
consistent proﬁles. Finally in high noise condition (0:1), only
VEGA and Ultrasome seem to provide an acceptable segmentation.

3.2 Results on real data

3.2.] Glioblastoma Mnltiforme (GBM) data GBM is a particular
malignant and aggressive type of brain tumor. Several chromosomal
mutations have been observed in glioma as gain on chromosome 7
and losses of chromosomes 10, 13 and 22. We used two samples
(GBM31 and GBM29) representing primary GBMs in the glioma
data from Bredel et al. (2005) which were used in Lai et al. (2005). In
sample GBM31, chromosome 13 is characterized by a large region
of loss (Fig. 3A). Results show that VEGA, DNACopy and SMAP
identiﬁed the expected deletion while Ultrasome did not detect this
mutation. For the chromosome 7 of the sample GBM29, three small
ampliﬁcations with high amplitude around EGFR locus are expected
(Fig. 3B). Among the compared algorithms, SMAP is the only
one that did not ﬁnd the gains, DNACopy combined the ﬁrst two
ampliﬁcations together while both VEGA and Ultrasome detected
all three mutations.

3.2.2 Mantle Cell Lymphoma (MCL) data MCL is an aggressive
lymphoma with median patient survival times of ~ 3 years. We used
eight MCL cell lines (Granta—5 19, HBL—2, JVM—2, NCEB—l, REC—1,
SP49, UPN—l and Zl38C) previously analyzed by DeLeeuw et al.
(2004). This analysis was performed by SMRT aCGH containing
97 299 elements, representing 32433 overlapping genomic segments
spanning the entire human genome (Ishkanian et al., 2004).
DeLeeuw et al. (2004) provided a comprehensive list of cytobands
with the respective biological references for these cell lines. In

 

3024

112 /§.IO'S[BU.IHO[p.IOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘lg lsnﬁnv uo ::

VEGA

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

A Venn gamm- unmm sum!
In In In‘ In
a ' I: T I: T I: '
1:1- _ D _ CI _ D -
BI :- EI- El
9 Q _ U E
B Hun auto-um ulna-um _ an"!
ID _ D- _ D- _ ﬂ _
q I a. I a I a I
'9 D D- ID
=1 I =- I =- I =- :
CI _ CI _ III _ CI _
‘1' a" :-
c Venn uncom- Ullnnuma sun
In.- N — N- -.

 

 

 

—| N—
D—' 1:!—
_. -
'14—- ril-
_.

 



 

 

 

 

 

Fig. 2. Segmentation results on a simulated chromosome proﬁle of 1000 probes. Red line reports the segmentation computed by the algorithm, black line is
the true ground. In (A) the results on the simulated data without the noise component. In (B) the results on the simulated data with Gaussian noise, zero mean
and SD equal to 0.5. In (C) the results on the simulated data with Gaussian noise, zero mean and SD equal to 1.

“CUP!

Llllrnw rm! SMAP

 

'3 " ‘gLW' '7-'—'-.'.'_-"—'u.;,':'_‘_l_"“'"""'] a ' '—"""""'—l"""'

 

 

 

 

 

 

 

 

Hump-um- SMAP

 

 

 

 

 

 

Fig. 3. Segmentation results on Glioblastoma Multiforme (GBM) data published in Bredel et al. (2005). In (A) the results on the chromosome 13 of the
sample GBM31 are shown. This chromosome has a partial loss of low magnitude which is detected by VEGA, DNACopy and SMAP, only Ultrasome does
not detect this mutation. In (B) the results around EGFR (chromosome 7) of the sample GBM29 are shown. This chromosomal region has three ampliﬁcations
which are properly detected by VEGA, DNACopy and Ultrasome, only SMAP does not segment these aberrations.

addition, they conﬁrmed the deletion of 13q14.3 cytoband in Granta—
519 by using ﬂuorescence in situ hybridization (FISH) analysis. This
list was used as our ‘ground truth’ to assess the performance of
VEGA, Ultrasome, DNACopy and SMAP (Fig. 4).

By using this ‘ground truth’ we can see that Ultrasome did
not identify some interesting mutations such as the gain of
8q24.13—8q24.21 [this cytoband contains the well—characterized
MYC oncogene that is reported to be overexpressed in MCL
(Hofmann et al., 2001)] and the loss of 13q14.2—13q14.3 which has
been validated for Granta—519 by using FISH analysis. Moreover,
for this last chromosomal region SMAP found a gain which is in
contradiction with respect to FISH analysis. Loss of 9p21.3 was
conﬁrmed by all approaches and only Ultrasome considered this
region as normal in 2138. In Granta—519, the loss of 1p36.11 was
detected only by VEGA, while SMAP did not ﬁnd a loss for this
cytoband for Granta—519, SP49 and 2138. By analyzing Granta—
519, we can see that VEGA and DNACopy agreed with DeLeeuw’s
analysis for all reported cytobands except for the mutation in
12q13.13—12q13.2 for which no method provided a loss. In contrast,
both Ultrasome and SMAP had some problems in region detection
for this cell line.

As a further a qualitative analysis of VEGA, Ultrasome,
DNACopy and SMAP approaches, we analyzed the chromosome 8
of NCEB—l for which a gain covering the whole long branch is

expected (DeLeeuw et al., 2004; Martinez—Climent et al., 2001;
Rinaldi et al., 2005). In Supplementary Figure S12, the segmented
regions for this chromosome are shown, and this ﬁgure shows
that Ultrasome detected very few and small aberrant regions on
the long branch of this chromosome, SMAP provided a very
‘jagged’ segmentation, while VEGA and DNACopy computed the
expected ampliﬁcation, but DNACopy detected an unexpected
normal region.

Supplementary Table S1 shows the number of aberrant regions
obtained by the different approaches. From this table, we note that
SMAP computed the maximum amount of regions (97.06), on the
contrary Ultrasome provided a mean of 25 aberrant regions for cell
line, in the middle we ﬁnd VEGA and DNACopy algorithms with a
similar mean of aberrant regions (85.94 and 86.75, respectively).

4 DISCUSSION AND CONCLUSIONS

In this article, we present VEGA: a new approach for DNA copy
number segmentation. VEGA uses a variational—based method for
image segmentation, known as Mumford and Shah model. This
model is modiﬁed so that it can be efﬁciently applied in CN
segmentation. A greedy multiscale region growing process is used to
ﬁnd the solution. The region growing process follows a A—schedule
selection that provides an efﬁcient scheme to control the quality of

 

3025

112 /3.IO'SIBUJHOIPJOJXO'SOI]BIII.IOJUIOIQ//Zdllq 111011 pop1201umoq

9IOZ ‘lg lsnﬁnv uo ::

S.Morganella et al.

 

 

Fig. 4. This ﬁgure shows the cytobands reported in DeLeeuw et al. (2004) with the respective mutations: grey and red boxes indicate loss and gain, respectively.
For each cytoband the results of VEGA (V), Ultrasome (U), DNACopy (D) and SMAP (S) are reported. L indicates loss, N indicates normal and G indicates

gain.

the segmentation. The optimal scale parameter value is computed
in an automatic way considering both the A-schedule and the data
variability. VEGA algorithm works separately on each chromosome
and it has computational complexity of 0(nlogn) where n is the
number of observed probes for the considered chromosome.

We compare VEGA with three approaches that can be considered
the state of the art in CN segmentation: DNACopy (a likelihood
function-based approach), SMAP (an algorithm based on discrete
hidden Markov model) and Ultrasome (an algorithm that as VEGA
uses a variational-based model). Results on synthetic data show
the expected robustness to noise of variational-based approaches
(VEGA and Ultrasome), and the performance of VEGA in all noise
conditions. DNACopy and SMAP have similar performance for low
noise levels but their performance may be signiﬁcantly affected by
noise. In order to assess the performance of the compared approaches
on real data, we use eight MCL cell lines and two samples of
glioblastoma multiforme. The ‘true ground’ for this data is composed
by a list of cytobands which are extracted from current biological
knowledge. Results on real data show the ability of VEGA in
segmentation of well-characterized mutations and they also conﬁrm
the properties of the DNACopy algorithm. In contrast, real data
analysis reveals some limitations of SMAP and Ultrasome. In
addition, both synthetic and real results show important differences
between VEGA and Ultrasome performance. These differences are
mainly due to: the underlying model (VEGA uses Mumford and
Shah model while Ultrasome uses Rudin model), the minimization
process (VEGA uses a region growing process while Ultrasome uses
a top-down approach) and the selection of the scale parameters used
in our segmentation process. We think that SMAP and Ultrasome
performance can be improved by a tuning of their input parameters.
The problem is that these algorithms require a signiﬁcant number of
arguments and the tuning process can be hard for non-expert users.

ACKNOWLEDGEMENTS

We thank the anonymous reviewers for their constructive comments.

Funding: MiUR (Ministero dell’Universita e della Ricerca) under
grant (PRIN2008—20085CH22F).

Conﬂict of Interest: none declared.

REFERENCES

Andersson,R. et al. (2008) A segmental maximum a posteriori approach to genome-wide
copy number proﬁling. Bioinformatics, 24, 751—758.

Beroukhim,R. et al. (2010) The landscape of somatic copy-number alteration across
human cancers. Nature, 463, 899—905.

Bredel,M. et al. (2005) High-resolution genome-wide mapping of genetic alterations in
human glial brain tumors. Cancer Res., 65, 4088—4096.

Ceccarelli,M. (2007a) A ﬁnite Markov random ﬁeld approach to fast edge-preserving
image recovery. Image st. Comput, 25, 792—804.

Ceccarelli,M. et al. (2007b) Automatic measurement of the intima-media thickness
with active contour based image segmentation. In IEEE International Workshop
on Medical Measurement and Applications. MEMEA ‘07, IEEE, Washington, DC,
pp. 321—33 1.

Cormen,T.H. et al. (2009) Introduction to Algorithms, 3rd edn. MIT Press, Cambridge,
MA.

Daruwala,R.S. et al. (2004) A versatile statistical analysis algorithm to detect genome
copy number variation. Proc. Natl Acad. Sci, 101, 16292—16297.

DeLeeuw,R.J. et al (2004) Comprehensive whole genome array CGH proﬁling of mantle
cell lymphoma model genomes. Hum. Mol. Genet, 13, 1827—1837.

Fan,Y.S. et al. (2007) Detection of pathogenic gene copy number variations in patients
with mental retardation by genomewide oligonucleotide array comparative genomic
hybridization. Hum. Mntat., 28, 1124—1132.

Fridlyand,J. et al. (2004) Hidden Markov Models approach to the analysis of array
CGH data. J. Multivariate Anal, 90, 132—153.

Giusti,E. (1984) Minimal Surfaces and Functions of Bounded Variation. Birkhauser,
Basel, CH.

Harada,T. et al. (2008) Genome-wide DNA copy number analysis in pancreatic
cancer using high-density single nucleotide polymorphism arrays. Oncogene, 27,
1951—1960.

Hofmann,W.K. et al. (2001) Altered apoptosis pathways in mantle cell lymphoma
detected by oligonucleotide microarray. Blood, 98, 787—794.

Hupe,P. et al (2004) Analysis of array CGH data: from signal ratio to gain and loss of
DNA regions. Bioinformatics, 20, 3413—3422.

Ishkanian,A.S. et al. (2004) A tiling resolution DNA microarray with complete coverage
of the human genome. Nat. Genetics, 36, 299—303.

Jong,K. et al. (2003) Chromosomal breakpoint detection in human cancer. Vol. 2611 of
Lecture Notes in Computer Science, Springer, Berlin, pp. 54—65.

 

3026

112 /810's1eu1nofp101x0'soi112u1101uioiq//:d11q 11101; pap1201umoq

9IOZ ‘IE lsnﬁnv uo ::

VEGA

 

Jong,K. et al. (2004) Breakpoint identiﬁcation and smoothing of array comparative
genomic hybridization data. Bioinformatics, 20, 3636—3637.

Khojasteh,M. et al. (2005) A stepwise framework for the normalization of array CGH
data. BMC Bioinformatics, 6.

Koepﬂer,G et al. (1994) A multiscale algorithm for image segmentation by variational
method. SIAM J. Numer. Anal, 31, 282—299.

Lai,W.R. et al. (2005) Comparative analysis of algorithms for identifying
ampliﬁcations and deletions in array CGH data. Bioinformatics, 21,
3763—3770.

Magi,A. et al. (2010) A shifting level model algorithm that identiﬁes aberrations in
array-CGH data. Biostatistics, 11, 265—280.

Martinez-Climent,J.A. et al. (2001) Loss of a novel tumor suppressor gene locus at
chromosome 8p is associated with leukemic mantle cell lymphoma. Blood, 98,
3479—3482.

Mumford,D. and Shah,J. (1989) Optimal Approximations by piecewise smooth
functions and associated variational problems. Commnn. Pure Appl. Math, 41,
577—684.

Myers,C.L. et al. (2004) Accurate detection of aneuploidies in array CGH and gene
expression microarray data. Bioinformatics, 20, 3533—3543.

Nilsson,B. et al. (2008) An improved method for detecting and delineating genomic
regions with altered gene expression in cancer. Genome Biol, 9, R13.

Nilsson,B. et al. (2009) Ultrasome: efﬁcient aberration caller for copy number studies
of ultra-high resolution. Bioinformatics, 25, 1078—1079.

Olshen,A.B. et al. (2004) Circular binary segmentation for the analysis of array-based
DNA copy number data. Biostatistics, 5, 557—572.

Otsu,N. (1979) A threshold selection method from gray-level histograms. Sys. Man
Cybern. IEEE Trans, 9, 62—66.

Picard,F. et al. (2005) A statistical approach for array CGH data analysis. BMC
Bioinformatics, 6.

Pique-Regi,R. et al. (2008) Sparse representation and Bayesian detection of genome
copy number alterations from microarray data. Bioinformatics, 24, 309—318.

Redding,N.J. et al., (1999) An efﬁcient algorithm for Mumford-Shah segmentation
and its application to SAR imagery. In Procedings Conference on Digital Image
Computing Techniques and Applications (DICTA’99), pp. 35—41.

Rinaldi,A. et al. (2005) Genomic and expression proﬁling identiﬁes the B-cell associated
tyrosine kinase Syk as a possible therapeutic target in mantle cell lymphoma. Br. J.
Haematol, 132, 303—316.

Rudin,L. et al. ( 1992) Nonlinear total variation based noise removal algorithms. Physic.
D, 60, 259—268.

Sebat,J. et al. (2007) Strong association of de novo copy number mutations with Autism.
Science, 316, 445—449.

Sen,A. and Srivastava,M.S. (1975) On tests for detecting change in mean. Ann. Stat,
3, 98—108.

Vese,L.A. et al., (2002) A multiphase level set framework for image segmentation using
the Mumford and Shah Model. Int. J. Comput. st., 50, 271—293.

Willenbrock,H. and Fridlyand,J. (2005) A comparison study: applying segmentation to
array CGH data for downstream analyses. Bioinformatics, 21, 4084—4091.

Zhao,X. et al. (2003) An integrated view of copy number and allelic alterations in
the cancer genome using single nucleotide polymorphism arrays. Cancer Res, 64,
3060—3071.

 

3027

112 /B.IO'SIBUJHOIPJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘lg lsnﬁnv uo ::

