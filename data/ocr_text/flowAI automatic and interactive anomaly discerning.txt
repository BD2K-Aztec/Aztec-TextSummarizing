Bioinformatics, 32(16), 2016, 2473—2480

doi: 10.1093/bioinformatics/btw191

Advance Access Publication Date: 10 April 2016
Original Paper

 

Data and text mining

flowAl: automatic and interactive anomaly
discerning tools for flow cytometry data

Gianni Monaco1'2'*, Hao Chen1, Michael Poidinger‘, Jinmiao Chen‘,
Joao Pedro de Magalhaes2 and Anis Larbi1'*

1Singapore Immunology Network (SlgN), Agency for Science Technology and Research (A*STAR), Singapore
138648, Singapore and 2Integrative Genomics of Ageing Group, Institute of Integrative Biology, University of
Liverpool, Liverpool L69 723, UK

*To whom correspondence should be addressed.
Associate Editor: Robert Murphy

Received on December 17, 2015; revised on April 3, 2016; accepted on April 4, 2016

Abstract

Motivation: Flow cytometry (FCM) is widely used in both clinical and basic research to characterize
cell phenotypes and functions. The latest FCM instruments analyze up to 20 markers of individual
cells, producing high—dimensional data. This requires the use of the latest clustering and dimen—
sionality reduction techniques to automatically segregate cell sub—populations in an unbiased man—
ner. However, automated analyses may lead to false discoveries due to inter—sample differences in
quality and properties.

Results: We present an R package, flowAl, containing two methods to clean FCM files from un—
wanted events: (i) an automatic method that adopts algorithms for the detection of anomalies and
(ii) an interactive method with a graphical user interface implemented into an R shiny application.
The general approach behind the two methods consists of three key steps to check and remove
suspected anomalies that derive from (i) abrupt changes in the flow rate, (ii) instability of signal ac—
quisition and (iii) outliers in the lower limit and margin events in the upper limit of the dynamic
range. For each file analyzed our software generates a summary of the quality assessment from
the aforementioned steps. The software presented is an intuitive solution seeking to improve the
results not only of manual but also and in particular of automatic analysis on FCM data.
Availability and implementation: R source code available through Bioconductor: http://bioconduc
tor.org/packages/flowAl/

Contacts: mongianni1@gmail.com or Anis_Larbi@immunol.a—star.edu.sg

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

 

Flow cytometry (FCM) is a laser—based methodology designed to
capture the physical and biochemical characteristics of a cell or a
particle in a stream of fluid. Fluorescence—conjugated antibodies are
used to target antigens expressed inside or at the surface of the cells
of interest. As cells pass through the laser (excitation), the ﬂuoro—
chrome Will change its state of energy and emit a light (emission)
that is captured by a series of detectors. FCM applications have been
developed mainly for both research and clinical settings in medicine
but also for other non—biomedical domains such as marine and plant

biology. The most common application is the immune-phenotyping
of blood samples and thus the quantification of the number and fre-
quency of various immune cell populations. In hematology, FCM is
the technology of choice, as, for example, it requires only few drops
of blood to diagnose leukemia through the detection of the perturb—
ation of normal cell frequencies (Brown and Wittwer, 2000).
Moreover, FCM helped increase our understanding of cellular func-
tions of the immune system and is Widely used in cell cycle analysis,
pre—transplant crossmatching, cell sorting, apoptosis, vaccine devel—
opment and other applications that scrutinize cellular properties

©The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2473

9mg ‘09 1sn3nv uo sopﬁuv s01 ‘etulomeg aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

2474

G. Monaco et al.

 

(Jaye et al., 2012; Mulley and Kanellis, 2011; Pozarowski and
Darzynkiewicz, 2004; Vermes et al., 2000).

The data are stored in Flow Cytometry Standard (FCS) files that
include the ﬂuorescence and scattered light levels for each cell that
passed through the laser beams. Nowadays it is possible to analyze
up to 20 markers at a time in a single staining panel by using an
equal number of different ﬂuorochromes detected in separate chan—
nels. The common approach used to analyze the data produced by
FCM is to visually select cells of interest through 1 or 2 markers
known to be highly specific. However, to delineate the high hetero—
geneity of immune cell populations, it is necessary to look simultan—
eously at the whole staining panel. Principal component analysis has
been used to detect the complexity in CD8 T cell populations char-
acterized by intermediate phenotypes that show a continuum of ex—
pression of different combinations of cytokines and surface markers
(Newell et al., 2012). Another dimensionality reduction technique
called t—Distributed Stochastic Neighbor Embedding (t—SNE)
(Becher et al., 2014; Maaten and Hinton, 2008; Shekhar et al.,
2014) was successfully applied to identify ambiguous cell popula—
tions, including monocyte—macrophage intermediates and granulo—
cyte variants in a mass cytometry experiment based on a
38—antibody panel (Becher et al., 2014).

Several computational tools that aim to automatically charac—
terize cell populations without losing multi-dimensional informa-
tion are constantly developed and periodically benchmarked by the
FlowCAP consortium (Aghaeepour et al., 2013). Undoubtedly, the
widest range of tools has been distributed by the BioConductor
platform based on the R programming language. The root package
for FCM data is flowCore, since it defines the container class and
it enables to perform essential manipulations such as compensation
and transformation (Hahne et al., 2009). In addition, a series of
complementary packages has been developed for further oper—
ations, such as visualization, quality assessment, statistical analysis
and automated gating (Finak et al., 2014; Hahne et al.; Sarkar
et al., 2008).

To accompany and support the large development of automatic
methods to define populations, it is crucial to use high quality FCM
data as input in order to optimize the robustness of the results. This
is especially true since research is looking deeper into the complexity
of cell distribution. For instance, target cell sub—populations may
represent as low as 0.05% of the total cell population suggesting
that minute variation in the quality of the data may lead to false
positive results or loss of signal. Standardization, calibration and
quality control guidelines using beads have been defined to ensure
that the signal acquired is the most accurate and with the least vari—
ation (Oldaker, 2007; Perfetto et al., 2006). Nonetheless, these pro—
cedures are not always carefully monitored and even having the
FCM instrument at optimal conditions before sample processing
does not exclude electronic drifts or ﬂuidic instability issues at the
time of data recording. An R package, flowQ (Bashashati and
Brinkman, 2009; Gentleman et al., 2006), creates concise reports of
quality checks on single and multi-panel experiments to highlight
issues that can be encountered in data acquisition. The reports indi-
cate the number of cells, percentage of boundary events and anoma—
lies on the fluidics and signal acquisition over time. Another
package, ﬂowClean (Fletez—Brant, 2014), determines and marks low
quality cells using compositional data analysis. In brief, it splits the
time in equally sized bins and ﬂags the events that are within time
frames containing unusual ratios of cell populations. However,
ﬂowQ does not actively detect and remove the anomalies and
ﬂowClean is poorly intuitive and thus it does not allow to infer the
source of the anomalies.

Import to a quality control tool

,A. - Flow rate  -
the median of the ﬂow rate
Signal acquisition

Removal ofsurges and large
deviations ofthe trend from
manual selection signal decomposition and automatic selection
M Removal ofacquisition regions whose MW
statistics are shifted from the most
manual selection stable acquisition region

.
Dynamlc Range
Removal of outliers in the lower limit
and margin events from the upper limit
Of the dynamic range automatic selection

\/ Legend

 _ Flow rateznumber of
w

 

events per unit of time
Intensity line: Signal per

 

unit of events

Channel density plot
processed FCS ﬁles _
Anomalies selected

Fig. 1. Workflow of the quality control of FCM data using the flowAI package.
Data can be processed manually with a Shiny application or automatically
with the call of an R function. The steps are complementary in both cases. On
the one hand, the manual method allows the user to interactively choose ap-
propriate thresholds on plots portraying flow rate and signal acquisition
through visual inspection. On the other hand, the automatic method performs
this selection through anomaly detection algorithms. Both the interactive and
automatic methods eliminate events recorded outside an acceptable dynamic
range using standard thresholds

 

 

 

 

We present our package called flowAI that provides two solu—
tions, one automatic and one interactive, to discard cells from FCM
data that do not reach appropriate quality standards. Our workﬂow
adapts and expands previous ideas with methods never implemented
before to provide a more objective, efficient and intuitive solution
for the quality control of FCM data.

2 Implementation and methods

2.1 The software

Both the automatic and interactive methods have been implemented
in the R package flowAI and distributed by the Bioconductor plat—
form (http://bioconductor.org/packages/flowAI/). Our tools incorp—
orate functionalities from several other R packages. For example,
the automatic method integrates functions from the mFilter
(Balcilar, 2007) and changepoint (Killick and Eckley, 2014) pack-
ages in the algorithms aiming to automatically detect the anomalies
while the interactive method leverages on the R shiny package
(Chang et al., 2105) to build the web graphical interface.

2.2 Workflow

The entire quality control analysis of flowAI contains three main
steps to detect and remove anomalies from FCM data complemen-
tary for both the automatic and the manual methods (Fig. 1).

2.2.1 Flow rate check

The first step evaluates the steadiness of the ﬂow rate of the analysis.
The flow rate is reconstructed by reporting the number of cells
acquired per unit of time. This is only possible for FCS files of ver-
sion equal or greater than 3.0 which implement the keyword
$TIMESTEP to allow for kinetic analysis (Seamer et al., 1997).

9mg ‘09 1sn3nv uo sopﬁuv s01 ‘etulomeg aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

flowAI

2475

 

The keyword stores a value corresponding to the resolution of the
‘Time’ channel in terms of seconds or fractions of a second. Ideally,
the detection of anomalies in the ﬂow rate check should be per—
formed at the maximum time resolution allowed by the FCM instru—
ment. However, the setting of a larger time step for the analysis
greatly decreases the running time and memory usage.

A stable ﬂow rate of FCM instruments can be pictured by a line
with non—periodic ﬂuctuations but with a constant variation. The
anomalies in the ﬂow rate that mostly affect the quality of signal ac—
quisition are abrupt surges and significant changes in the speed of
the ﬂuid, generally caused by factors such as debris and air intrusion
in the ﬂuidic system. To discard anomalies through the interactive
method, users can adjust two horizontal sliding bars to eliminate
ﬂow rate surges and two vertical sliding bars to discard regions at
the beginning and the end of the ﬂow rate where the instabilities
mostly occur. Instead, for the automatic version we designed an
anomaly detection algorithm built upon the generalized extreme stu—
dentized deviate (ESD) test (Rosner, 1983) and optimized to work
on time series data.

As stated in a review of outlier detection methods, the anomalies
are contextual to the nature of the data (Chandola et al., 2009) and
hence it is preferable to develop techniques customized for the do—
main of interest. The patterns depicted by the ﬂow rate of FCM data
are generally similar to the ones treated by economists, engineers
and social scientists in time series analyses, whose basic idea is to ex—
tract additional information from time series data by splitting into
its components.

As a first step for our automatic method, we implemented the
Christiano—Fitzgerald band pass filter (Balcilar, 2007; Christiano
and Fitzgerald, 2003) to split the value (3),), corresponding to the
number of events recorded at the time point t, into the trend (It) and
cyclical (6,) components:

3%: Tt‘l‘ Ct (1)

The trend component will be a smooth line that indicates long—
term increase or decrease in the ﬂow rate, while the cyclical compo—
nent will contain the non—periodic ﬂuctuations and abrupt surges
from the trend line.

Second, the ﬂow rate values are penalized by adding or subtract—
ing the corresponding absolute values of the cyclical component ac—
cording to their direction from their median:

y, —I— |ct|, y, 2 median(y)
y.pent = , (2)
y, — |ct|, y, < med1an(y)

Lastly, the generalized ESD test is applied on the penalized ﬂow
rate to detect the anomalies. This method, with an iterative process,
searches for a number outliers not exceeding a predefined threshold
12, 71,k:{71, 1'2, . . ., 17, . . ., he}, in a dataset of sample size 11. At each
iteration, an observation 1’,- is tested as a potential outlier and it is
removed from the data before the next iteration. Practically, an ex—
emplary iteration has the following steps:

1. Extraction of the observation that largely deviates from the cen—
tral tendency indicator (mean or median) scaled by the measure
of dispersion (standard deviation or median absolute deviation):

max |y.pen,- — median(y)|
MAD(y)

 

(3)

2. Computation of the critical value lambda 2,- from the t distribu—
tion using a deﬁned level of signiﬁcance or. The observation is
ﬂagged as an outlier if its value is higher than lambda: 17> 2,.

3. The observation 1’,- is removed from the data that is now reduced
to the sample size n — 1'.

Our procedure uses the median and the median absolute devi—
ation (MAD) because, particularly in presence of outliers, they are a
more robust alternative to the mean and standard deviation (Leys
et al., 2013).

2.2.2 Signal acquisition check

The second step verifies the stability of the signal acquired over
time. A common practice to verify the quality of signal acquisition is
to use Levy—Jennings—type graphs, where fluorescence is plotted
against time (Barnett and Reilly, 2007). A stable signal acquisition
should produce intensity values whose distribution is consistent
throughout the course of the entire experiment. This is the expected
behavior if we assume that cells from a heterogeneous sample are
randomly aspirated by the FCM tube over time. Therefore, changes
in the signal intensities are not due to biological variation but rather
to technical issues such as defective laser—detection system, voltage
instability or poor quality of sample preparation, for example, inad—
equate vortexing.

For each channel, flowAI creates Levy—Jennings—type graphs by
splitting the intensity values of a marker in equally sized bins and
plotting their median against time. This method is already imple—
mented by the flowQ package, where the user can infer the quality
of an FCS file from the visualization of time line plots. However,
in addition to that, flowAI allows the removal of the regions with
an unstable signal. As for the ﬂow rate, this operation can be per—
formed manually through visual inspection or automatically. The
latter method implements a step detection algorithm to identify
shifts in the mean and variance of the intensity values. The algo—
rithm used, binary segmentation, is implemented in the change—
point package (Killick and Eckley, 2014). Its basic concept has
been firstly described by the genetists Edwards and Cavalli—Sforza
as a new clustering method based on the analysis of variance
(Edwards and Cavalli—Sforza, 1965). This method is computation—
ally fast and most frequently used among the changepoint detec—
tion methods.

This approach iteratively splits the data in two groups at a time
simply applying the method of least squares. In our case, given an
ordered set of n fluorescence values m1,,,:(m1, m2, ..., mi, ...,
mn) corresponding to the medians of all bins, the total sum of
squares (SST) from their mean is calculated as a measure of
dispersion:

SST = E”: (m,- — ml (4)
i=1

A changepoint m,- that splits the data in two segments,
512(m1, ..., mi) and $2:(m,~+1, . . ., m"), is detected when the cost
function, represented by the within—groups sum of squares (SSW),
is minimized:

1 7L
arg 'min 2041,, — 14—151)2 —1— Z (ms2 — 14—15,)2 (5)
1 51:1 $2=i+1

The minimization of the cost function (5 ) is equivalent to the
maximization of the between—group sum of squares (SSB), and the
sum between SSW and SSB results in the SST.

Each new segment created is in turn split in two segments by the
repetition of the same procedure. The search of new changepoints
terminates if either the minimized cost function is higher than a
defined threshold or if a pre—established maximum number of

91% ‘09 1sn3nv uo sopﬁuv s01 ‘1211110111123 310 Amie/xtqu 112 /§.IO'S[BU.ITIO[p.IOJXO'SODBIHJOJUTOTQﬂIdllq 11101; pop1201umoq

2476

G. Monaco et al.

 

changepoints has been detected. In ﬂowAI we used a variant of this
method provided by the changepoint package that not only searches
for shifts in the mean but also in the variance.

The binary segmentation algorithm is performed independently
on each ﬂuorescence channel and lastly the longest region that does
not contain changepoints in any of the channels is chosen as high
quality signal.

2.2.3 Dynamic range check

A third quality step is performed on the lower and upper limit of the
dynamic range. Signals recorded by FCM instruments can only fall
within a determined dynamic range. The last generation of FCM has
reached a dynamic range of 224 channels (Novo and Wood, 2008),
but most of the instruments nowadays used in laboratories and clin—
ics have a range of 218. Due to this limitation, all measurements
with a real value higher than the upper limit will be recorded in the
last channel of the dynamic range causing an accumulation of sig—
nals that is not directly comparable with the rest of the data. These
values are commonly called margin events. Our package allows the
removal of events where at least one of the parameters has an inten—
sity value on the upper limit of the dynamic range.

The values of the lower limit are treated in a different way. For
the signal of the light scatter channels (reflecting the morphology of
the cells) any value less than zero is removed. Instead, for the im—
munoﬂuorescence channel, small fluctuations in the range of nega—
tive values are usually acceptable since they are the byproduct of
standard operations such as correction of background noise, auto
ﬂuorescence and spectral overlap. Nonetheless, technical issues,
such as ﬂow rate surges or voltage instability, can exacerbate the
magnitude of a negative value to an unacceptable range that would
also interfere with the downstream signal processing, such as logicle
transformation or automatic gating.

The flowAI package uses an outlier detection method to remove
the outliers among the negative values. Every value that is inferior to
a certain threshold is labelled as outlier and consequently removed.
For each channel, a threshold referred to as Z—score is computed
with a method recommended by Iglewicz and Hoaglin (1993). The
formula is given in (6), where the threshold is obtained for a set of 11
negative values x1,,,:(x1, . . ., x"):

—3.5 MAD(x1,,,)

Z 2 0.6745

—1— median(x1;,,) (6)

Alternatively to the removal of negative outliers, the lower limit
of the dynamic range can be truncated to the cut—off suggested by
the FCS file. This method was previously adopted as preprocessing
step for the cleaning of FCM data from erroneous measurement
(Qian et al., 2012; Van Gassen et al., 2016).

2.2.4 Results evaluation

At the completion of the analysis with the automatic method, a re—
port is generated indicating the percentage of cells that did not pass
the quality checks and a series of graphs showing where the anoma—
lies in terms of time and parameters were detected. Our suggestion
is first to run the automatic method with default settings on a small
sample of FCM data, second to customize the settings if necessary,
third to perform the quality control automatically on the entire data—
set and lastly to intervene manually only for those files whose auto—
matic control is not able to meet the accuracy required.

3 Results and discussion

Here, we provide analysis results obtained using the automatic
method in flowAI on several FCM data. We studied the nature of
the abnormalities detected in each quality control step and then we
evaluated the overall improvement of computational analysis with
the cleaned data.

3.1 Overview of the datasets

A total of 4469 FCM files from 11 different datasets, precisely 2 in—
house and 9 from the online database FlowRepository (Spidlen
et al., 2012), were used for our evaluation. The two in—house data—
sets contain 84 samples each, and are part of a larger project called
the Singapore Longitudinal Aging Study (SLAS). Ethical approval
was obtained from the National University of Singapore
Institutional Review Board for SLAS blood collection and experi—
ments. A different panel was used for the two datasets. Panel 1 con—
sisted of 16 antibodies targeting markers for the overall white blood
cell populations: CD16, CD4, CD38, CD62L, CD19, CD66b,
CD45, CD27, CD56, CD3, CD8, CD14, CD123, HLA-DR. Panel 2
consisted of 14 antibodies targeting the B lymphocyte populations:
CD19, CD20, CD21, CD23, CD24, CD27, CD38, IgG, IgM, IgD,
HLA-DR. Regarding the 9 datasets retrieved online, we selected the
ones used for the ﬂowCAP contests. Data and details are available
on ﬂowrepository.org under the IDs with the prefix FR-FCM- and
followed by: ZZYA, ZZZU, ZZYZ, ZZY3, ZZYY, ZZY6, ZZYZ,
zzzv, 2299.

3.2 Examination of anomalies in FCM data from
different perspectives

In this section, the anomalies detected in each quality control step is
analyzed separately. The main consideration is that even though our
workﬂow schematizes the quality control in three different steps,
they are usually strictly related. For example, a surge in the ﬂow
rate often corresponds to an unstable signal acquisition that in turn
would potentially result in a value in the upper margin or in the
negative outlier space of the dynamic range. Nonetheless, given the
high variability of anomalies that can occur in a FCM experiment,
the division of the quality control in the three steps defined in our
work is necessary to assure the detection of those anomalies that are
not visible from a single perspective.

In this manuscript, we focus on the file 220662.fcs from the
ZZZV dataset to show how a complete quality control with flowAI
works on an FCS file. In addition, numerous other examples are re—
ported in the supplementary material.

3.2.1 Surges and trend shifts in the ﬂow rate

The ﬂow rate was recreated dividing the time channel of an FCS file
in equal intervals with a time step of 1/10 of a second. Fluidics’ sta—
bility in the sample is a good indicator for the absence of anomalies
such as clogging and air bubbles in the ﬂow cell and other disturb—
ances in the ﬂow stream. Our algorithm has been designed to ac—
knowledge cyclical patterns to detect local anomalies, i.e. surges, as
well as to remove global anomalies, i.e. large deviations of the trend
from the median ﬂow rate (Fig. 2a). From all the FCS files analyzed,
we verified that the beginning and the end of the ﬂow rate are the re—
gions where irregularities occur the most. FCM experts recognize
these patterns as being frequent and mainly due to air bubbles, deb—
ris or clogged cells (Supplementary Fig. 81a, e, f). In Figure 2a, the
ﬂow rate takes about 10 s to stabilize but usually strong ﬂuctuations
vanish more quickly (Supplementary Figs 81a, S2a and 83a).

91% ‘09 1sn8nv uo sojoﬁuv s01 1111110111123 310 [(1319111qu 112 /§.IO'S[BU.ITIO[p.IOJXO'SODBIHJOJUTOTQﬂIdllq 11101; pop1201umoq

flowAI

2477

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

(a)
1500'
313
D- 'o
u) C
E 8 1000-
0 Cl.)
> m
2 m
E “6
g e 500-
E >
3
Z
0' .
0 10 20 30 40
(b) mm Seconds
i§§§§ WWWMW FSC-A
gégggj “Mt-..- '-" -'-:.-n'a."-.v'-"-c—;..'-.'~'-e--1£-'-.'-=---s--:.-_‘,:.-"'b‘~ -. --"-:: ' n .1..~,3, FSC'H
1200 I
13881 -. ..   .  .'   .'~’ .. ', | FlTC-A‘
3 21111 SSC-A
m y.
  MIMI 
.03 .7333) Alexa 680-A
C
E ﬁgga l APC-A ‘
E 550:] PE C 7 A
500 y '
E 700 I.“-
W WWI-m” _
2831 PE Cy55 A
2200 .- I I-
33831 E ' ' | PE Tx RD-A I
 Mill-Irﬁ'i'l. - ' “ *-"- PE Green laser-A
0 50 100 150 200 250 300 350 400 450
Bin ID
C O _ to _
( ) ‘— LowQ '  — Raw data
> — HEQh Q _ sampl!n9 1 — Without negative outliers
E 0C! _ H'gh Q _ sampl'ng 2 m - Truncated at -111
5 0 High Q - sampling 3
S s —
9 g - 3
CL 3 m _
O.) 0.)
e 22- o
(13 N _
E N
3 o' _ 1— _
0
o_ _ -
o I I I I I I O I I I I I
-2000 -1000 0 1000 2000 3000 0 1 2 3
PE Tx RD-A Logicle PE Tx RD-A

Fig.2. Quality control results of the file 220662.fcs from the ZZZV dataset. The
plots (a) and (b) were extracted from the report generated by the automatic
method of the flowAI package using default settings. (a) Strong fluctuations
are detected in the flow rate at the beginning of the experiment. The anoma-
lies detected are indicated with green circles. (b) Changepoint detection in
signal intensity over time, represented as median of equally sized bins. The
region discarded is complementary to the one detected as instable in the flow
rate check. The yellow region is selected as being steady and therefore cate-
gorized as high quality. (c) ECDF curves of raw intensity values of the low (in
red) and high (shades of blue) quality events of the PE Tx RD-A channel. The
sample size of the three high quality samplings equals the number of low
quality events detected. (d) Density plots of the logicle transformed data of
the PE Tx RD-A channel using the logicle parameters estimated from raw
data (green line), from data with negative values truncated at -111 (blue line),
and from data without negative outliers (red line). The density curves vary
among the three sets of data, indicating the repercussions on the estimation
of the logicle parameters according to the dynamic range used for the data

Nevertheless, there are cases of ﬂow rate surges interspersed over
the entire course of the experiment (Supplementary Figs S4a and
85a) possibly caused by clusters of debris suddenly aspirated by the
FCM tube (Supplementary Fig. SSa—c). However, even though it
was not always possible to associate ﬂow rate surges with debris or
clogged cells, surges removal is still necessary because of their asso—
ciation with signal intensity variation.

Lastly, in an FCS file we observed a steady change of the ﬂow
rate, and hence the signal, in the last part of the analysis. The result—
ing low quality cells have a distribution uniformly shifted compared
to the one of the high quality cells. This is probably due to the ma—
nipulation of the speed settings by the instrument operator during
the running of the experiment (Supplementary Fig. S6).

3.2.2 Mean and variance deviation from stable acquisition regions
For each channel, the signal acquisition over time is reconstructed
first dividing the total number of cells in equally sized bins and se—
cond calculating the median value of each bin. The output is

graphically shown with line plots (Fig. 2b). Mean and variance shifts
in the signal acquisition are detected using the binary segmentation
method from the changepoint package (see Section 2.2.2).

In most of the analyzed cases, signal instability is strongly related
to ﬂow rate fluctuations (Fig. 2, Supplementary Figs 81—83 and S6).
However, anomalies caused by laser—detection systems can eventu—
ally occur independently of the speed variations of the ﬂow rate. In
Supplementary Figure S4, for example, the numerous ﬂow rate
surges are hardly detectable in the signal plots and the channels stor—
ing the signal elicited by the green laser (G780—A, G710—A, G660—A
and G610—A) show a delay in the reaching of stability that warrants
a careful monitoring of the functionality of that specific laser—detec—
tion system.

In Supplementary Figure S5 , even though the ﬂow rate surges are
associated clearly with the signal plots, the signal acquisition grad—
ually weakens at different rates in different channels after a first re-
gion of steadiness (FSC—A, FSC—H and APC-A), while in other
channels it remains constant for a longer period. In this rare case,
other technical issues should be investigated. Some of the factors
that might cause less common anomalies, but have to be kept in
mind, are laser power instability, detection system irregularities,
poor quality of the sheath fluid and accumulation of dirt in the ﬂow
cell.

3.2.3 Refining the dynamic range: removal of negative outliers
and margin events

Because of the quantum nature of light, both the scatter and fluores—
cence channel values cannot theoretically fall in the negative range
of values. However, because of the background and noise correction
of the optical detection system of FCM instruments, negative values
are recorded for both light scatter and immunofluorescence chan—
nels. This problem is also exacerbated by instable signal acquisition,
for instance during ﬂow rate surges (Supplementary Figs S2a—c and
S4a—c), or by compensation, where a value proportionate to the
spectra overlap of other channels is subtracted from each channel.
Negative estimates are considered part of a negative population of
cells with a low mean and a large coefficient of variation. Therefore,
with the logarithmic transformation not being able to handle nega—
tive values, new transformation methods have been developed.
Probably the most popular one is the logicle transformation, also
called ‘bi—exponential’ (Parks et al., 2006). With this method, values
with an absolute small magnitude are scaled linearly, while large
values are scaled in a log—like fashion. The transition from the linear
to the logarithmic scaling is defined by the a) parameter of the for—
mula. It determines the width of the linearized data and its value is
directly estimated from the fifth percentile of the values below zero.
We noticed that this estimation method lacks accuracy when the
outliers in the negative range are more than 5% of negative values
and precision when the negative values acquired are low and with
sparse values. To overcome the arbitrary estimation of the a) param-
eter, a cut—off at the value —111 has been suggested (Qian et al.,
2012). Nevertheless, this procedure does not have any theoretical
explanation either and, as the authors of the logicle transformation
method also implied, the truncation of the values would deform the
distribution of the negative population and result in an improper es—
timation of its statistics (Parks et al., 2006). Our idea is to use an
outlier detection method to remove only the negative values that
stray from the ones that compactly aggregate around zero. In Figure
2d, we depicted the differences among the distributions of the logicle
transformed data for a channel of the 220662.fcs file where the a)
parameter was estimated on the raw data, after removing the

91% ‘09 1sn8nv uo sojoﬁuv s01 1111110111123 310 [(1319111qu 112 /§.IO'S[BU.ITIO[p.IOJXO'SODBIHJOJUTOTQﬂIdllq 11101; pop1201umoq

2478

G. Monaco et al.

 

negative outliers and after truncating the data at —111. Generally
speaking, a better estimation of the parameters of a negative cell
population is expected, since the data are neither affected by outliers
nor by a truncation to an arbitrary threshold. Overall, although this
procedure might not give any substantial advantage for downstream
manual analysis, it should improve the quality of the results for any
kind of automatic analysis, from simple statistics calculations to
gating.

A last issue to consider when analyzing FCM data is the signal
which value exceeds the limitations of the machine, thus generating
the so called margin events. In fact, the signal can only be recorded up
to the upper value of a dynamic range pre—set by the manufacturer of
a FCM instrument. Therefore, it is impractical to discern subpopula—
tions of cells whose values are stored in the upper margin of the dy-
namic range. This is already a common practice especially among
computational biologists that require clean data to improve the qual—
ity of the analysis which is why we implemented it in our pipeline.

3.3 Overall improvement using computational methods
In the previous sections, we described each step of our pipeline sep—
arately in order to examine the anomalies from different perspec—
tives. Instead, in this section, we look at the final results using
approaches to analyze the multi—dimensionality data in its entire
complexity.

3.3.1 Disappearance of undefined populations in high quality data
We used SPADE to identify and visualize populations from high di-
mensional FCM data (Qiu et al., 2011). In brief, SPADE first prunes
high density regions, second identifies clusters and third links them
together with a minimum spanning tree.

The SPADE results before and after quality control of the file
220662.fcs are reported in Figure 3. The FCS file was part of an ex—
periment where the functionality of CD4 and CD8 T cells in re-
sponse to an HIV vaccination was assessed through intracellular
cytokine staining. Looking at the SPADE results through the
markers CD3, CD4 and CD8 it is possible to identify CD4 T cells at
the bottom—right branch and CD8 T cells at the top—right branch
(Fig. 3a).

The analysis was made with default settings and, from the 200
populations identified by SPADE in the original file (Fig. 3a), 43 dis-
appeared in the high quality data (Fig. 3b and Supplementary Fig.
S7). To explain the nature of the faulty populations, we examined
the graphs reporting the coefficient of variation and a high variabil-
ity was found for the markers CD3 and CD8 in the discarded popu—
lations. One may also suspect that those are new undefined
populations that solicit further investigation. However, plotting the
CD3 channel against FSC—A with the ﬂowJo software, it was pos—
sible to identify the faulty populations only in the files with high in-
stability in the ﬂow rate (Supplementary Fig. S7).

3.3.2 Erratic populations revealed using dimensionality reduction
Another approach consisted in applying a dimensionality reduction
method, t—SNE (Maaten and Hinton, 2008), to capture non—linear
relationships in the high dimensional space with the intensity values
of high and low quality events. For the analysis we used the R pack—
age cytofkit that includes also an algorithm based on support vector
machine to identify the clusters from the new components defined
by t—SNE (Supplementary Fig. S8a and b).

Using 2D plots of the first two components, we noticed that in
most of the files a fraction of low quality cells was still superimpos—
ing to the populations of high quality cells while a remaining

(a) Before QC

CD3 (PE Tx RD-A)

1%....l I
'3' ' s,"
3.3" '
‘1
I. I O O
_ $2.... , a
raw median ,- 3,.“ CV ...
c ‘ $
0
-2384.63 2384.63
1.36 6.50

CD4 (FlTC-A)

-.°- ,
- °" . .5“...
F - .s; - th- ,.
‘ . col"..:§.f'0#‘.
'. . :51" .1.
"I?! a ' I ﬂ!
raw median .',- '2: .. CV :1;- as;
o o '1..- ..,$ .
. ... . . C...
-1430.08 1430.08 5. 0.62 20.82 .

 . v,
w" is x . . . . .. .
.. 13....1- .-

raw median

-1625.3 1625.3 1_68 20.41

 

(b) After QC

CD3 (PE Tx RD-A) .
0..
.0
-. -° :~° - ' '
:0... o o. .
0‘. 0 °
. O... . ~§:.. .
".
c
. 0.0 so. a 0
.° . :
. .oo 0.
.. o o.
. o o
raw median . .0 .
-2384.63 2384.63

Fig. 3. SPADE analysis of the file 220662.fcs from the ZZZV dataset (a) before
and (b) after quality control. The raw intensity median values and the coeffi-
cient of variation of the CD3, CD4 and CD8 channels are used as color-code
for the population identified by SPADE. In (a) it is possible to localize the
populations of CD4 and CD8 T cells and nodes with high coefficient of vari-
ation. In (b) the grey nodes are the population removed by the quality control

fraction formed separate sub—populations of events. In an FCS file
from the SLAS dataset (Panel 1), we ascertained that the new popu—
lations in the low quality data mainly derived from dead cells and
margin events; the borders are jagged and the shape is irregular re—
ﬂecting the erratic nature of the acquired signal (Supplementary Fig.
S8b). In contrast, the populations of high quality cells have smooth
borders and a regular round shape.

T—SNE was then computed on a B cell population preprocessed
with ﬂowJo, where debris, doublets and dead cells were removed
(Supplementary Fig. S8c and d). In Supplementary Figure S8c, an ir-
regular CD19 population is revealed that was not found in the ana—
lysis of the raw data (Supplementary Fig. S8b). Further analysis
revealed that the expression values of the CD19 channel were re—
corded at the upper margin of the dynamic range. This demonstrates
that anomalies in only one channel can be easily camouﬂaged as
valid cell populations in a multi—dimensional analysis if a careful
quality control has not been applied beforehand. Lastly, in
Supplementary Figure S8d, a significant shift in the average acquisi—
tion signal is visible in the t—SNE analysis by the formation of adja—
cent complementary population.

In summary, we advocate the importance of making a compre—
hensive cleaning on the data from different perspectives. Once faulty

9mg ‘09 1sn8nv uo sojoﬁuv s01 1111110111123 310 [(1319111qu 112 /§.IO'S[BU.ITIO[p.IOJXO'SODBIHJOJUTOTQﬂIdllq 11101; pop1201umoq

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

fIOWAI 2479
Table 1. Pairwise agreement scores among the quality control FCS ﬁles characteristics
made manually with flowJo, and automatically with flowAI and R 10MB 10 MB 33.3 MB 33.3 MB
fIOWCIGan eport 11 parameters 22 parameters 11 parameters 22 parameters
1”" ~250,000 events ~125,000 events ~800,000 events ~400,000 events
Dataset (n)"‘ Median kappa coefficients (n) "‘ "‘ mm'
40'
ﬂowJo — ﬂowJo — ﬂowAI —
flowAI ﬂowClean ﬂowClean A
.E 30-
ZZZV (240) 0.9 (177) 0.25 (88) 0.26 (86) E
ZZZU (308) 0 33 (255) 0 33 (3) 0.26 (64) E;
ZZ99 (766) 0.81 (390) 0.7 (327) 0.82 (328)  20_
SLAS panel I (84) 0.07 (73) 0.23 (4) 0.018(3) a
SLAS panel II (84) 0.57 (82) 0 1 (43) 0.07 (39) E
C
C 10-
"‘Total number of ﬁles per dataset. g
""“Total number of Cohen’s kappa tests with P-Value < 0.05 selected for
the calculation of the median kappa coefﬁcient. 0 _
\Q (30 NOON?) (199 \Q (30 \QQQD (190 a.) \(D (50 bf!) 69 a.) \(D (50 bit) ‘29

signals are included in downstream analyses, it becomes hard to de—
tect them and they would eventually lead to false discoveries.

3.4 Benchmarking and performance

The automatic method in ﬂowAI was compared both with a manual
quality control using ﬂowJo and the method in R package
ﬂowClean. The ﬂowQ package was excluded from the comparison
because it does not actively detect anomalies.

3.4.1 Agreement assessment with other approaches

A fundamental element for the quality control of an FCS file to is
the time channel. The datasets ZZYA, ZZY2, ZZY3, ZZYY, ZZY6
and ZZYZ seemed to be already pre—processed and did not have a
proper time channel. Although ﬂowAI is still able to check the signal
and dynamic range of a FCS file without the time channel, in this
case it is impossible for ﬂowClean and impractical for ﬂowJo to do
the quality control. Therefore, only the remaining datasets with a
proper time channel were used for the benchmarking.

The ﬂowJo analysis was executed by removing the margin events
from the FSC—A and SSC—A scatterplot and unstable acquisition re—
gions from the channel with more visible anomalies plotted against
time. Regarding ﬂowClean and the automatic method in ﬂowAI, they
were both run with default settings. The Cohen’s kappa test was used
to measure the agreement of two quality control methods on each
FCS file. For the kappa statistic, a minimum value of anomalies was
required to reach the significance level. For each dataset, the median
of the significant kappa coefficients has been reported in Table 1.

Overall, flowAI showed a stronger agreement with the manual
quality control than with ﬂowClean. Also, ﬂowAI was the most strin—
gent towards anomalies while ﬂowClean was the most tolerant (Table
1 and Supplementary Fig. S7). Nonetheless, both ﬂowAI and
ﬂowClean still require a fine tuning of the settings for certain datasets
to perform optimally. For example, better agreements would have
been reached for the SLAS panel I dataset if less stringent settings
were used for ﬂowAI. In this respect, a decisive advantage of ﬂowAI
is its intuitiveness. In fact, based on the ﬂow rate and signal plots, it is
relatively easy to establish if the settings have to be more or less strin—
gent. On the contrary, we found the diagnostic plot produced by
ﬂowClean harder to interpret.

3.4.2 Running time

The running time of the automatic method in ﬂowAI was measured
on a laptop with a 2.7 GHZ CPU and 16 GB of RAM. We used four
batches of datasets to evaluate the time performance. Each batch

Number of files

(respectively corresponding to a total size of 100, 500,
1000, 1500 and 2000 MB in each group of bar charts)

Fig. 4. Running time of a quality control analysis with the automatic method
of flowAI. The graphics' creation for the full report, that is fundamental for an
accurate examination, takes a considerable amount of time. Alternatively, a
mini-report containing only the percentages of anomalies is produced with-
out significant running time increase

consists of five datasets of increasing size (100, 500, 1000, 15 00 and
2000MB) formed using an increasing number of FCS files with
same size, number of events and parameters (Fig. 4).

The speed of ﬂowAI is mostly inﬂuenced by the size of the FCS
file rather than the number of parameters or events and the creation
of the graphics for the full report takes the greatest amount of time.
The possibility of creating a mini report containing only the percent—
ages of anomalies is provided but it is discouraged for now, unless the
user is sure of the nature of the anomalies in the entire dataset.

On the contrary, the running time for ﬂowClean increases con—
siderably with the number of parameters because of its way of defin—
ing cell populations through combinations of positive signals from
the different parameters (Supplementary Fig. S9).

Overall, flowAI performance was faster for all the datasets used
and, in particular, at least 3 times faster when using FCS files with
22 parameters (Fig. 4 and Supplementary Fig. S9).

4 Conclusion

Over the last few years, we have seen increasing efforts in automa—
tizing pipelines of biomedical data analysis through computational
algorithms. FCM is still one technique that hardly abandons the
concept of manual analysis since usually the data produced has high
variability that requires human interpretation. Often, the analysis
demands high expertise and the results are still conditioned by a sub—
jective evaluation. Our idea was born from the intention of remov-
ing the technical variability of FCM data in an objective way, thus
reducing subjectiveness in interpretations and improving the per-
formance of downstream computational analyses. This is especially
the case when a high number of files is analyzed and when anoma-
lies are generated by multiple sources.

We defined an approach and created an R package, ﬂowAI, to
automatically or interactively detect anomalies in FCM data. First,
anomalous patterns and peaks are removed from the ﬂow rate auto—
matically by a method built upon time series decomposition and the

91% ‘09 1sn3nv uo sojoﬁuv s01 1111110111123 310 [(1319111qu 112 /§.IO'S[BU.ITIO[p.IOJXO'SODBIHJOJUTOTQﬂIdllq 11101; pop1201umoq

2480

G. Monaco et al.

 

Generalized ESD test. Second, the tool checks the stability of the sig—
nal over time for each channel; here the automatic method uses a
changepoint algorithm to detect durable shifts in the mean or variance
of the acquisition values. Lastly, the dynamic range of the values
acquired for each channel is refined. The upper limit is cleared of the
margin events and the lower limit is cleared of the negative outliers.

From the use of the ﬂowAI package, we expect a general im—
provement in the quality of research that employs FCM instruments.
Removing events with erratic intensity values will facilitate different
aspects of FCM analysis such as: (i) more effective compensation
since the overlap signal is subtracted only from real values; (ii) more
accurate detection of rare cells due to the removal of background
noise; (iii) easier characterization of the nature of an ambiguous cell
population (either as undefined cell type or as technical issue).

When using the automatic method for the quality control of a
dataset of FCS files, it is preferable to infer the optimal settings for a
dataset using a sample of few FCS files. In fact, because of the intui—
tiveness of the flowAI report, it is easy to infer the source of recurrent
anomalies in a FCM experiment. Subsequently, the automatic
method of ﬂowAI can be run on the entire dataset with customized
settings. Lastly, because the automatic quality control might still not
meet the expectations for certain FCS files, the checking of the full re-
ports reveals where it is necessary to intervene manually with the
interactive method of ﬂowAI or with another method. This last point
is a limitation of flowAI that could be overcome by the dynamic ad—
justment of the settings of the automatic method, but for now it re—
mains an open question that warrants further investigation. An
additional consideration is that flowAI is designed to detect anoma—
lies within a single FCS file, hence, other tools are necessary to check
for anomalies between batches of FCS files. Also, another challenging
task is the designing of a complete automatic pre—processing pipeline.

In conclusion, our quality control approach produces a compre—
hensive check of the FCM data implementing algorithms never
employed before. We recommend the usage of ﬂowAI as a first pre—
processing step of the data right after they are obtained from the
FCM instrument so that all the downstream analyses, from compen—
sation to detection or rare cells, will benefit from it.

Acknowledgements

We thank Xavier Camous and Immanuel Kwok for the helpful discussions
about the manual gating of B cell subpopulations, Bernett Lee for providing
critical comments about FCM instrumentations and the ﬂow cytometry facil-
ity at Singapore Immunology Network (SIgN) for processing the data.

Funding

This work was supported by the A’iSTAR/SIgN core grant, the A’TSTAR Joint
Council Ofﬁce DP grant [1434m00115] and the A’PSTAR Research
Attachment Program (ARAP) to GM.

Conﬂict of Interest: none declared.

References

Aghaeepour,N. et al. (2013) Critical assessment of automated ﬂow cytometry
data analysis techniques. Nat. Methods, 10, 228—238.

Balcilar,M. (2007) mFilter: Miscellaneous time series ﬁlters. R Packag. version
0.1—3.

Barnett,D. and Reilly,].T. (2007) Quality control in ﬂow cytometry. In: Flow
Cytometry: Principles and Applications. Humana Press, Totowa, NJ,
pp. 1 13—13 1.

Bashashati,A. and Brinkman,R.R. (2009) A survey of ﬂow cytometry data
analysis methods. Adv. Bioinf., 2009, 584603.

Becher,B. et al. (2014) High-dimensional analysis of the murine myeloid cell
system. Nat. Immunol, 15, 1181—1191.

Brown,M. and Wittwer,C. (2000) Flow cytometry: principles and clinical ap-
plications in hematology. Clin. Chem., 46, 1221—1229.

Chandola,V. et al. (2009) Anomaly detection: a survey. ACM Compnt. Snrv.,
41, 1—5 8.

Chang,W. et al. (2105 ) shiny: Web Application Framework for R.

Christiano,L.]. and Fitzgerald,T.]. (2003) The band pass ﬁlter. Int. Econ. Rev.
(Philadelphia), 44, 435—465.

Edwards,W.F. and Cavalli-Sforza,L.L. (1965) A method for cluster analysis.
Biometrics, 21, 362—375.

Finak,G. et al. (2014) OpenCyto: an open source infrastructure for scalable,
robust, reproducible, and automated, end-to-end ﬂow cytometry data ana-
lysis. PLoS Compnt. Biol., 10, e1003806.

Fletez-Brant,K. (2014) ﬂowClean: ﬂowClean. R Packag. version 1.6.0.

Gentleman,R. et al. (2006) ﬂowQ: Quality control for ﬂow cytometry. R
Packag. version 1.30.0.

Hahne,F. et al. (2009) ﬂowCore: a Bioconductor package for high throughput
ﬂow cytometry. BMC Bioinformatics, 10, 1—8.

Hahne,F. et al. (2009) ﬂowStats: Statistical methods for the analysis of ﬂow
cytometry data. R Packag. version 3.28.1.

Iglewicz,B. and Hoaglin,D.C. (1993) How to Detect and Handle Outliers.
ASQC Basic References in Quality Control, ASQC, Milwaukee, WI, Vol. 16.

Jaye,D.L. et al. (2012) Translational applications of ﬂow cytometry in clinical
practice. ]. Immunol, 188, 4715—4719.

Killick,R. and Eckley,I. (2014) changepoint: an R Package for changepoint
analysis]. Stat. Softw, 58, 1—19.

Leys,C. et al. (2013) Detecting outliers: do not use standard deviation around
the mean, use absolute deviation around the median. ]. Exp. Soc. Psychol.,
49, 764—766.

Maaten,L.V.D. and Hinton,G. (2008) Visualizing data using t-SNE. ]. Mach.
Learn. Res, 9, 25 79—2605.

Mulley,W.R. and Kanellis,]. (2011) Understanding crossmatch testing in
organ transplantation: a case-based guide for the general nephrologist.
Nephrology, 16, 125—133.

Newell,E.W. et al. (2012) Cytometry by time-of-ﬂight shows combinatorial
cytokine expression and Virus-speciﬁc cell niches within a continuum of
CD8—(— T cell phenotypes. Immunity, 36, 142—152.

Novo,D. and Wood,]. (2008) Flow cytometry histograms: transformations,
resolution, and display. Cytometry A, 73A, 6 85—692.

Oldaker,T.A. (2007) Quality control in clinical ﬂow cytometry. Clin. Lab.
Med., 27, 671—685.

Parks,D.R. et al. (2006) A new ‘Logicle’ display method avoids deceptive ef-
fects of logarithmic scaling for low signals and compensated data.
Cytometry A, 69A, 541—55 1.

Perfetto,S.P. et al. (2006 ) Quality assurance for polychromatic ﬂow cytometry.
Nat. Protoc., 1, 1522—1530.

Pozarowski,P. and Darzynkiewicz,Z. (2004) Analysis of cell cycle by ﬂow
cytometry. Methods Mol. Biol., 281, 301—311.

Qian,Y. et al. (2012) FCSTrans: an open source software system for FCS ﬁle
conversion and data transformation. Cytometry A, 81A, 35 3—35 6.

Qiu,P. et al. (2011) Extracting a cellular hierarchy from high-dimensional
cytometry data with SPADE. Nat. B iotechnol., 29, 886—891.

Rosner,B. (1983) Percentage points for a generalized ESD many-outlier pro-
cedure. Technometrics, 25, 165—172.

Sarkar,D. et al. (2008) Using ﬂowViz to Visualize ﬂow cytometry data.
Bioinformatics, 24, 878—879.

Seamer,L.C. et al. (1997) Proposed new data ﬁle standard for ﬂow cytometry,
Version FCS 3.0. Cytometry, 28, 118—122.

Shekhar,K. et al. (2014) Automatic classiﬁcation of cellular expression by nonlinear
stochastic embedding (ACCENSE). Proc. Natl. Acad. Sci. USA, 111, 202—207.
Spidlen,]. et al. (2012) FlowRepository: a resource of annotated ﬂow cytome-
try datasets associated with peer-reviewed publications. Cytometry A, 81A,

727—731.

Van Gassen,S. et al. (2016) FloReMi: ﬂow density survival regression using
minimal feature redundancy. Cytometry A, 89, 22—29.

Vermes,I. et al. (2000) Flow cytometry of apoptotic cell death. ]. Immunol.
Methods, 243, 167—190.

91% ‘09 1sn3nv uo sojoﬁuv s01 ‘121u10111123 310 [(1319111qu 112 /§.IO'S[BU.ITIO[p.IOJXO'SOTmIHJOJUTOTQﬂIdllq 11101; pop1201umoq

