ORIGINAL PAPER

Vol. 26 no. 18 2010, pages 2281-2288
doi: 10. 1093/bioinformatics/btq422

 

Gene expression

Advance Access publication July 16, 2010

Multiple gene expression profile alignment for microarray

time-series data clustering

Numanul Subhanil, Luis Rueda“, Alioune Ngom1 and Conrad J. Burden2

1School of Computer Science, 5115 Lambton Tower, University of Windsor, 401 Sunset Avenue, Windsor, Ontario
NQB 3P4, Canada and 2Mathematical Sciences Institute, The Australian National University, Canberra ACT 0200,

Australia
Associate Editor: Martin Bishop

 

ABSTRACT

Motivation: Clustering gene expression data given in terms of time-
series is a challenging problem that imposes its own particular
constraints. Traditional clustering methods based on conventional
similarity measures are not always suitable for clustering time-series
data. A few methods have been proposed recently for clustering
microarray time-series, which take the temporal dimension of the
data into account. The inherent principle behind these methods is to
either define a similarity measure appropriate for temporal expression
data, or pre-process the data in such a way that the temporal
relationships between and within the time-series are considered
during the subsequent clustering phase.

Results: We introduce pain/vise gene expression profile alignment,
which vertically shifts two profiles in such a way that the area
between their corresponding curves is minimal. Based on the
pairwise alignment operation, we define a new distance function
that is appropriate for time-series profiles. We also introduce a new
clustering method that involves multiple expression profile alignment,
which generalizes pairwise alignment to a set of profiles. Extensive
experiments on well-known datasets yield encouraging results of at
least 80% classification accuracy.

Contact: lrueda@uwindsor.ca

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on May 7, 2010; revised on July 13, 2010; accepted on
July 15, 2010

1 INTRODUCTION

An important process in functional genomic studies is clustering
microarray time—series data, where genes with similar expression
proﬁles are expected to be functionally related (Cho et al., 1998).
A Bayesian approach (Ramoni et al., 2002), a partitional clustering
based on k—means (Tavazoie et al., 1999) and a Euclidean distance
approach (Tamayo et al., 1999) have been proposed for clustering
time—series gene expression proﬁles. They have applied self—
organizing maps (SOMs) to visualize and to interpret the gene
temporal expression proﬁle patterns. Ahidden phase model was used
for clustering time—series data to deﬁne the parameters of a mixture
of normal distributions in a Bayesian—like manner that are estimated
by using expectation maximization (EM; Brehelin, 2005). Also,
the methods proposed in Chu et al. (1998) and Heyer et al. (1999)

 

*To whom correspondence should be addressed.

are based on correlation measures. A method that uses jack—knife
correlation with or without using seeded candidate proﬁles was
proposed for clustering time—series microarray data as well (Heyer
et al., 1999), where the resulting clusters depend upon the initially
chosen template genes, because there is a possibility of missing
important genes. A regression—based method was proposed in Ernst
et al. (2005) to address the challenges in clustering short time—series
expression data. Analyzing gene temporal expression proﬁle data
that are non—uniformly sampled and can contain missing values
has been studied in Bar—Joseph et al. (2003). Clustering temporal
gene expression proﬁles was studied by identifying homogeneous
clusters of genes in Dejean et al. (2007). The shapes of the
curves were considered instead of the absolute expression ratios.
Fuzzy clustering of gene temporal proﬁles, where the similarities
between co—expressed genes are computed based on the rate of
change of the expression ratios across time, has been studied in
Moller—Levet et al. (2005). In Peddada et al. (2005), the idea of
order—restricted inference levels across time has been applied to
select and cluster genes, where the estimation makes use of known
inequalities among parameters. In Rueda et al. (2008), pairs of
proﬁles represented by piece—wise linear functions are aligned in
such a way to minimize the integrated squared area between the
proﬁles. An agglomerative clustering method, combined with an
area—based distance measure between two aligned proﬁles, was used
to cluster microarray time—series data. Using natural cubic spline
interpolations, we re—formulated the pairwise gene expression proﬁle
alignment problem of Rueda et al. (2008) in terms of arbitrary
functions that are continuously integrable on a ﬁnite interval, and
extended the concept of pairwise alignment to multiple expression
proﬁle alignment. Finally, we combined k—means and EM clustering
with multiple alignment to cluster microarray time—series data,
yielding at least 80% classiﬁcation accuracy on well—known data.

2 SYSTEM AND METHODS

2.1 Pairwise expression proﬁle alignment

Given two proﬁles, x(t) and y(t) (either piece—wise linear or continuously
integrable functions), where y(t) is to be aligned to x(t), the basic idea
of alignment is to vertically shift y(t) towards x(t) in such a way that the
integrated squared errors between the two proﬁles is minimal. Let 52(t) be
the result of shifting y(t). Here, the error is deﬁned in terms of the areas
between x(t) and ya) in interval [0, T]. While x(t) and 90) may cross each
other many times, we want that the sum of all the areas where x(t) is above
ya) minus the sum of those areas where 90) is above x(t) is minimal (Fig. 1).
Let a denote the amount of vertical shifting of y(t). Then, we want to ﬁnd

 

© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 2281

112 /§.IO'SIBUJHOlpJOJXO'SOTlBIHJOJUlOTCI/ﬁdnq U101} popnommoq

9IOZ ‘19 lsnﬁ'nv I102:

N.Subhani et al.

 

 

' (a)

    

45 ___x
' —y

Expression ratio
a:

 

 

 

 

 

 

.5
Time in hrs. Time in hrs.

Fig. 1. (a) Unaligned proﬁles x(t) and y(t). (b) Aligned proﬁles x(t) and y(t),
after applying y(t) <— y(t) — amin.

the value amin of a that minimizes the integrated squared error between x(t)
and y(t). Once we obtain amin, the alignment process consists of performing
the shift on y(t) as y(t) =y(t) —amin.

The pairwise alignment that we propose here applies to proﬁles, that
are any integrable functions on a ﬁnite interval. Suppose that we have two
proﬁles, x(t) and y(t), deﬁned on the time—interval [0, T]. The alignment of
x(t) and y(t) consists of ﬁnding the value a that minimizes

T
fa(x,y)=f0 [x(t)—[y(t)—a]]2dt, (1)

which is a quadratic function involving a vertical shift factor, a.
Differentiating yields
d T
Efa(x,y)=2f [x(t)—y(t)]dt+2aT- (2)
0

Setting % a(x,y) =0 and solving for a gives
1 T
amin=—— f [x(t)—y(t)]dt. (3)
T 0

. 2 . . . .
S1nce :7 a(x,y)=2T>O then amin 1s a m1n1mum. Thus, there 1s only a
single vertical shift factor that minimizes the integrated squared error. The
integrated error between x(t) and the shifted y(t) = y(t) —amin is then

T T
f0[x(t)—§i(t)ldt=f0 [x(I)—y(t)]dt+aminT=0. (4)

Given an original proﬁle x(t)= [e1,e2,...,en] (with n expression values
taken at n time—points t1,t2, ...,t,,), in our approach, we use natural cubic
spline interpolation, with n knots, (t1,e1), ...,(tn,en), to represent x(t) as a
continuously integrable function

X10) if tlstsn
x(t)= xj(t) if thtStj+1 (5)

xn—IU)  l‘n—l Stitn
where Xj(t)=x]'3(t—tj)3 +xj2(t—tj)2+xj1(t—tj)1+xj0(t—tj)0 interpolates
x(t) in interval [tj, 5+1], with spline coefﬁcients xjk 6 ER, for 1 51': n — 1 and
0§k§3
For practical purposes, given the coefﬁcients, xjk GER, associated with
x(t)= [e1,e2, ...,en] 6 ER”, we only need to transform x(t) into a new space
as x(t):[xl3a x12, X11, 9610, m, 193, sza lea ija-na x(n—l)3a x(n—1)2,
x(n_1)1, x(n_1)0] 6 81401—1). We can add or subtract polynomials given their
coefﬁcients, and the polynomials are continuously differentiable. This yields
an analytical solution for amin in Equation (3) as follows:
)k+l

_ 1  (Xjk—yjk) (6+1 —tj

__T k+1

 

0min 
j=1k=0
Figure lb shows a pairwise alignment, of the two initial proﬁles in

Figure 1a, after applying the vertical shift y(t) <— y(t) — amin. The two aligned

proﬁles cross each other many times, and the integrated error, Equation (4),
is zero. In this example, from Equation (4), the horizontal t—axis will bisect
a proﬁle x(t) into two halves with equal areas, when x(t) is aligned to the
t—axis. In Section 2.2, we use this property of Equation (4) to deﬁne the
multiple alignment of a set of proﬁles.

2.2 Multiple expression proﬁle alignment

Given a set X = {x1(t), ...,xs(t)}, we want to align the proﬁles in such a way
that the integrated squared error between any two vertically shifted proﬁles
is minimal. Thus, for any xl-(t) and xj(t), we want to ﬁnd the values of a,- and
aj that minimize

T
fa,,aj (xi(t)axj(t)) =f0 {[9640—6111—[Xj(t)—aj]}2dt,

where both xl-(t) and xj(t) are shifted vertically by an amount a,- and
Clj, respectively, in possibly different directions, whereas in the pairwise
alignment of Equation (1), proﬁle y(t) is shifted towards a ﬁxed proﬁle
x(t). The multiple alignment process consists then of ﬁnding the values of
a1, ...,as that minimize

 (x10), ...,xs(r)) = Z rm,- (xi(t),xj(t)), (7)

1§i<j§s

We use Lemma 1 to ﬁnd the values a,- and Clj, 1 5 i < j 5 s, that minimize
Fa1,...,as ~

LEMMA 1. If x,- (t) and xj (t) are pairwise-aligned each to a ﬁxed proﬁle, z(t),
then the integrated error fOT [fa-(t) 49-0)] dt = 0.

PROOF. If xl-(t) and xj(t) are pairwise—aligned each to z(t), then
from Equation (3), we have amini:_% 0T[Z(t)_xi(t)]dt and aminj:
—% 0T[Z(t)—xj(t)]dt. Then, f0T[xi(t)—xj(t)]dt

= if [he-(t) —amin,.] — [xjm — amin, 1] dt
= foTinMt +foT [Zm ‘ximldt — fOij(t)dt — fOT [Z(t) —xj(t)] dt = 0. I

In other words, 590) is automatically aligned relative to an), given z(t)
is ﬁxed.

COROLLARY 1. If xl-(t) and xj(t) are pairwise-aligned each to a ﬁxed proﬁle,
z(t), then faminqamm (xi(t),xj(t)) is minimal.
1 J

PROOF. This follows immediately from Lemma 1, which shows the
property implied by the single vertical shift minimizing the integrated
squared error, i.e. fOT [Sq-(t) —xj(t)]dt=0=>

T 2 . . .
f0 [[xl-(t)—amini]—[xj(t)—aminj]] dt 1s m1n1mal. I

LEMMA 2. prroﬁles x1(t),...,xs(t) are pairwise-aligned each to a ﬁxed
proﬁle, z(t), then FaIninl awamins (x1(t),...,xs(t)) is minimal.

PROOF. From Corollary 1,
fa”, (xi(t),xj(t)) :faminiﬂmmj (xi(t),xj(t)), with equality holding when ak =
amink, which is attained by aligning each xk(t) independently with
z(t), 1 5k 5s. From the deﬁnition of Equation (7), it follows that
Fa1,...,as (x1 (0a ~~~axs(t)) Z Zlfi<jfsfamini,aminj (xi(t)axj(t))
=Faminl “Haamins (x1 (t), ...,xs(t)), with equality holding when ak =amink, 1 5
k S s. I

Thus, given a ﬁxed proﬁle z(t), applying Corollary 1 to all pairs of proﬁles
minimizes Falywas (x1(t), ...,xs(t)) in Equation (7).

THEOREM 1. Given a ﬁxed proﬁle, z(t), and a set of proﬁles,
X ={x1(t),...,xs(t)}, there always exists a multiple alignment, X =
{x1(t),...,xs(t)}, such that

 

2282

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIHJOJUIOICI/ﬁdnq 1110131 papeoIUAAoq

9IOZ ‘Ig lsnﬁnv uo ::

Multiple expression profile alignment

 

T
)ACi(t)=xi(t)—aminia where, amini=_% f [z(t)—xt(t)ldt, (8)
0

and, in particular, for proﬁle z(t)=0, deﬁned by the horizontal t-axis, we
have

. 1 T
xi(t)=xi(t)—amini, where, amini =  xl-(t)dt. (9)
0

PROOF. The proof follows from Corollary 1. Since each proﬁle is aligned
to a ﬁxed proﬁle, z(t), it implies that we can either align each proﬁle and
z(t) individually, or all proﬁles at a time, implying a ‘universal’ multiple
alignment. I

We use the multiple alignment of Equation (9) in all subsequent
discussions. Using spline interpolations, each proﬁle xl-(t), lgigs, is a

continuously integrable proﬁle

961,10) if tlstsn
in): xi,j(t) if ijtStj+1 (10)

xiii—10) if tn—l S t S In
where, xi,j(t) =xl-j3 (t — tj)3 +xl-J-2(t — tj)2 +xl-J-1(t—tj)1+x,-jo(t—tj)0 represents

xl-(t) in interval [tj, 5+1], with spline coefﬁcients xl-jk for 1 5 i 5 s, 1 51': n — 1
and 0 5 k 5 3. Thus, the analytical solution for amini in Equation (9) is

k+l

a .  (11)
mlni T j=1 k=0 k+1 .

2.3 Distance function

The distance between any two piecewise linear proﬁles is deﬁned as follows:

1 1 T
d(x,y)= ;f(amin)= ; f0 {x(t)+amin —y(t)}2dt. (12)

For any function ¢(t) deﬁned on [0, T], we also deﬁne

1 T
<¢> é ; f made (13)
0

Then, from Equations ( 1) and (3) we have

decay)

1 T
a [0 {[x(t)—y(t)]2+2amm[x(t)—y(t)]+afn,n}dt

T
= l f {hm—y(r)]}2dt—2a3mn+a3nm
T 0

= ([x(t)—y(t)]2)— (x(t)—y(t)>2- (14)

By performing the multiple alignment of Equation (9) to obtain new
proﬁles x(t) and y(t), we have

T

1
d(x,y)=<[%(t)—9(r)]2)=; f0 {x(t)—90)}2dt. (15)

Thus, d(x,y)% is the 2—nonn, satisfying all the properties of a metric. On
the other hand, it is easy to show that d (x, y) in Equation (15) does not satisfy
the triangle inequality, and hence it is not a metric. We, however, use d (x, y)
in Equation (15) as our distance function, since it is algebraically easier to
work with than the metric d(x,y)%. Equation (15) is closer to the spirit of
regression analysis, and thus, we can dispense with the requirement for the
triangle inequality.

With the spline interpolations of Equation (5), we derived the analytical
solution for d(x, y) in Equation (15), using the symbolic computational
package Maplel. Full details can be found in Subhani et al. (2009).

2.4 Centroid of a cluster

Given a set of proﬁles X = {x1(t), ...,xs(t)}, we aim to ﬁnd a representative
centroid proﬁle Mt), that well represents X. An obvious choice is the function
that minimizes

Aiui=Zd(x,-,u), (16)
i=1

where A plays the role of the within-cluster—scatter deﬁned in Rueda et al.
(2008), and the distance between two proﬁles, x(t) and y(t), is deﬁned in
Equation (15). The distance d (e, e) as deﬁned in Equation ( 15) is unchanged by
an additive shift x(t) —> x(t) — a in either of its arguments, and hence, is order—
preserving; i.e.: d (u, v) 5 d (x, y) if and only if d (it, 9) 5 d (x, 52). Therefore, we
have

s 1 T s
Am1=Zd(a-,u) = a [0 Ewe—mmzdt, (17)
i=1 i=1

where X = {21 (t), ...,xs(t)} is the multiple alignment of Equation (9). This is
a functional of u; i.e. a mapping from the set of real valued functions deﬁned
in [0, T] to the set of real numbers. To minimize A with respect to u, we set
the functional derivative to zeroz. This functional is of the form

F[¢]= [Lemma (18)

for some function L, for which the functional derivative is simply % =

dL(¢(I))
d¢(t)

 

. In our case, we have

 

SAW] 2 S A 2 s .
W) =—?Z[xi(t)_llu(t)]=—f(in(t)—SM(I)) (19)

i=1 i=1

Setting % =0 gives
1 S A
W) = ; Zea). (20)
i=1

With the spline coefﬁcients, xijk, of each xl-(t) interpolated as in Equation
(10), the analytical solution for Mt) in Equation (20) is

s 3
1
#10): E Z [injk (f—fj)k] _amin,-a (21)
— k=0

in each interval [tj, 5+1]. Equation (20) applies to aligned proﬁles whereas
Equation (21) can also apply to unaligned proﬁles.

3 ALGORITHMS

3.1 k-means clustering via multiple alignment

Our approach allows us to apply a clustering algorithm such as
k—means or EM, which, though not optimal, provide a fast and
practical solution to the problem. In k—means (Xu and Wunsch,
2008), we want to partition a set of s proﬁles, D: {x1 (t), . . . ,xs (t)},
into k disjoint clusters C1,...,Ck, lfkfs; such that (i) C,- 7E0,i=
1,...,k; (ii) alga-=13; and (iii) Cincjzu; i7éj; i,j=1,...,k.

 

1All the analytical solutions in this article were veriﬁed with Maple.
2For a functional F [o], the functional derivative is deﬁned as %

(t) =
0 (F[¢+esti—Fi¢

lim6_> 6 I), where 8t(‘C)=8(‘E—I) is the Dirac delta function

centered at t.

 

2283

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIHJOJUIOICI/ﬁdnq 1110131 papeoIUAAoq

9IOZ ‘Ig lsnﬁnv uo ::

N.Subhani et al.

 

Also, each proﬁle is assigned to the cluster whose mean is the closest.
It assumes that the object features form a vector space. Let U : { u,:,-}
be the membership matrix

1 if d(xi,,uj) :minl=1w,kd(xi,,ul) ,where i: 1, ...,s

u”:
l] 0 otherwise

(22)

The aim is to minimize the sum of squared distances: 1(6, U):

Zil=12f=1uzjd0bﬂjla Where 9=M1,M2, 

 

Algorithm 1 k-MCMA: k-means clustering with multiple alignment

 

Require: Set of proﬁles, D: {x1(t), ...,xS (t)}, and desired number
of clusters, k
Ensure: Clusters C [,1 , . . . , CW
1. apply natural cubic spline interpolation on xi(t) e D, for 1 5 i 5 k
(see Section 2.1)
2. multiple—align transformed D to obtain D: {x1(t),...,xs(t)},
using Equation (9)
. randomly initialize centroid ill-(t), for 1 5 i 5 k
. repeat

ewe»:

assign 2,- (t) to cluster CAM with minimal d (2,- , 11,-), for 1 5 j 5
s and 1 5 i 5 k

update ill-(t) of CAM, for 15i5k
8. until Convergence: that Ais, no change in ill-(t), for 1 5 i 5k

return Clusters Cm , ...,C

>‘

in.

 

In k—MCMA (see Algorithm 1), we ﬁrst multiple—align the set
of proﬁles D, using Equation (9), and then cluster the multiple
aligned D with k—means. Recall that the process of Equation (9) is
to pairwise-align each proﬁle with the t—axis. The k initial centroids
are found by randomly selecting k pairs of proﬁles in D, and then
take the centroid of each pair. In Step (4.6), we do not use pairwise
alignment to ﬁnd the centroid ill-(t) closest to a 39-0); since, by
Lemma 1, they are automatically aligned relative to each other.
When proﬁles are multiple—aligned, any arbitrary distance function
other than Equation (15) can be used in Step (4.6), including the
Euclidean distance. Also, by Theorem 2 below, there is no need to
multiple—align CAM in Step (4.7), to update its centroid ill-(t).

THEOREM 2. Let ,17.(t) be the centroid of a cluster of m multiple-
aligned proﬁles. Then 11(t):,i7.(t).

PROOF. We have ,0.(t):,t7.(t)—aminﬂ. However, aiming:

% fOT ,17.(t)dt:% fOT% 1)Acl-(t):0, since each SCI-(t) is aligned
with the t—axis. I

Thus, Lemma 1 and Theorem 2 make k—MCMA much faster
than applying k—means directly on the non—aligned dataset D. An
important implication of Equation (15) is that applying k—means on
the non—aligned dataset D (i.e. clustering on D), without any multiple
alignment, is equivalent to k—MCMA (i.e. clustering on D). That is,
if a proﬁle xi(t) is assigned to a cluster Cut. by k—means on D, its

shifted proﬁle xi(t) will be assigned to cluster C111. by k—MCMA

(k—means on D). This can be easily shown by the fact that multiple
alignment is order—preserving. In k—means on D, Step (6) would
require 0(sk) pairwise alignments to assign s proﬁles to k clusters;
whereas no pairwise alignment is needed in k—MCMA. In other
words, we show that we can multiple—align once, and obtain the same

k—means clustering results, provided that we initialize the means in
the same manner. This also, reinforces a known fact demonstrated
in Roth et al. (2003); which is a dissimilarity function that is not a
metric can be made metric by using a shift operation. In this case,
the objective function of k—means does not change, and convergence
is assured. Thus, this saves a lot of computations.

3.2 EM clustering via multiple alignment

In this section, we present the EM clustering algorithm combined
with the alignment methods. EM is used for clustering in the context
of mixture models (Dempster et al., 1977). The goal of EM clustering
is to estimate the means and covariances for each cluster so as to
maximize the likelihood of the observed data distribution. In EM,
we want to partition a set of s proﬁles, D:{x1(t), ...,xS(t)}, into k
disjoint clusters C1 , ...,Ck, 15k 5s, such that: (i) C,- :0, i: 1, ...,k;
(ii) (ﬁle-=13; and (iii) CiﬂCj:0,i,j:1,...,k and i7éj. Let D
be the complete—data space drawn independently from the mixture

density
k

E-SteP= 19(xl9) = ZPOCICi , 9i)P(Ci) (23)
i=1
where parameter 6 :[61, . . . , 6;] is ﬁxed but unknown and P(C,-) the

known posterior probability of class Ci. The aim is to maximize the
likelihood

S
M-SteP= 19(Dl9) = “19(er9) (24)
e:l

We consider normal distributions, p(xk|Ci,6,-)~N(ui,2i), where
6,-:[,u,-,Ei]t; ,ul- and E,- are the means and the covariances of
classes, respectively. Both steps iterate until the log—likelihood
reaches a maximum. Thus, EM assigns proﬁles to multiple clusters,
as in fuzzy clustering. Also, unlike in k—means, EM assigns each
proﬁle to the cluster that ﬁnds the maximum posterior probability.

 

Algorithm 2 EMMA: EM clustering with multiple alignment
Require: Set of proﬁles, D: {x1 (t), ...,xs(t)}, and desired number
of clusters, k
Ensure: Clusters CAM , 
1. apply natural cubic spline interpolation on xi(t) e D, for 1 5 i 5 s
(see Section 2.1)
2. multiple—align transformed D to obtain D: {21 (t), ...,xs(t)},
using Equation (9)
. initialize centroid ill-(t), for 1 5i 5k
. compute the initial log—likelihood (see Equation (24))
. repeat A A
E-step: p(x|9) = Z§=1p(xlCh,,91)P(Ch,)
assign 2,- (t) to cluster C111. with maximum log—likelihood, for
15j5s and 15i5k

 

>1.0\U1-l>w

8. M-step=p(DI6)=H:=1p(xei9)
9. until The log—likelihood reaches its maximum
10. return Clusters C [,1 , ...,C m

 

In EMMA (see Algorithm 2), we ﬁrst multiple—align the set
of proﬁles D, using Equation (9), and then cluster the multiple—
aligned D with EM. Recall that the process of Equation (9) is to
pairwise-align each proﬁle with the t—axis. The k centroids can be
initialized randomly in Step (3) of EMMA, or by any initialization
approach. However, to obtain better clustering results with EMMA,
it is necessary to start with near—optimal centroids; thus, we applied

 

2284

112 /§JO'SIBUJHOIP.IOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 1110131 pop1201umoq

9IOZ ‘Ig lsnﬁnv uo ::

Multiple expression profile alignment

 

 

 

 

 

 

 

 

 

 

 

 

| | I | | | | I | | |
GeneI Gene1 Gene1
Sphase
C5 C5 C5
1" a~ I-‘ —- I" " “'- —-
~’ ~‘_’/ s_. _’ s‘—” s -’ \~~”¢ ~~l _’ \~__’ .--
o— — o— o— — o— —
Mphase E E E
.- — ex
\ I ‘ _ .. "'
1’ \ «T. t \ ” ” \ ’I ” ‘s~ ’,_
-§” ~—’ -~” ~~’ II-” ~" —~” ~’
.9
go- — o— o— — o— —
E LateG1 ‘
g o I C3 ' C3 I‘ C3
9 I\ ,“ I ‘ ,"\ I\ ,~‘ I \ rs
% I \~ I ~~ I ‘~ , ~~ I \~ I ~ I x‘ I ‘~
L|J ’ ~~’ ~- , ~~’ ~ 9 ~~’ ‘_- , ~-/ s_
0‘ ' 0‘ 0‘ — 0‘ Gene1 j
G2phase (32 C2 C2
— " ﬂ~
’l-Tx "\ ’ Ts ‘-~ I ‘s a~— ’ ~ /‘-~
0— — o— o— — o— —
EarlyG1 C1 C1 C1
'5 I\
I \ ’ I‘s "\ I \ 4
0 | | | 0 | | 0 | | | 0 | | |
0 50 100 150 0 50 100 150 0 50 100 150 0 50 100 150

(Yeast phases) Time in min. (EMMA) Time in min.

 

(k—MCMA) Time in min. (VCD) Time in min.

Fig. 2. (a) EMMA clusters, (b) S. cerevisiae phases (Cho et al., 1998), (c) k—MCMA clusters and (d) VCD clusters, with centroids shown.

k—MCMA to generate the k initial centroids in Step (3) (we have
also tried different initialization methods but with less success).

By Theorem 2, there is also no need to multiple—align a cluster CAM
in Step (6) of EMMA, for updating its centroid ill-(t). Likewise, any
arbitrary distance function can be used in Step (6), for computing
the centroids. EMMA is not a distance—based clustering method.
Nevertheless, the quantities p(x|6), p(x|CAﬁi,6,-), P(CA[M) and p(D|6)
are also preserved when the distances are preserved.

To conclude this section, we note that all the above theoretical
results on Natural Cubic Spline representation of proﬁles and
clustering algorithms that are proposed in the previous section also
apply to piecewise linear representations of time—series proﬁles.

4 RESULTS AND DISCUSSION

One of the datasets, the pre—clustered budding yeast genes of Cho
et al. (1998), contains time—series gene expression proﬁles of the
complete characterization of mRNA transcript levels during the
yeast cell cycle. These experiments measure the expression levels
of the 6220 yeast genes during the cell cycle at 17 time points, from
0 to 160 min. From those gene proﬁles, 221 proﬁles were analyzed,
and normalized as in Cho et al. (1998), i.e. dividing each transcript
level by the mean value of the proﬁle. The dataset contains ﬁve
known clusters called phases: early G1 phase (32 genes), late G1
phase (84 genes), S phase (46 genes), G2 phase (28 genes) and

M phase (31 genes); the phases are visualized in Figure 2a. Another
dataset used in the experiments is the Pseudomonas aeruginosa,
which contains expressions of the transcriptomes from planktonic
clusters at eight different points, from 0 to 48 h (Waite et al.,
2006). The clustering methods were also tested on the dataset
containing the expressions of the cell—cycle progressions of the
ﬁssion yeast, Schizosaccharomyces pombe (Peng et al., 2005).
This dataset contains 747 genes, representing the expression ratios
measured at 14 different time points, for two types of cells, namely,
wild—type and cdc25 mutant cells.

Setting k:5, we applied k—MCMA and EMMA on the yeast
dataset to see if k—MCMA and EMMA are able to ﬁnd these phases
as accurately as possible. Once the clusters have been found, to
compare the clustering with the pre—clustered dataset of Cho et al.
(1998), the next step is to label the clusters, where the labels are the
‘phases’ in the pre—clustered dataset. To measure the performance of
k—MCMA and EMMA, we assigned each EMMA cluster to a yeast
phase using the Hungarian algorithm (Kuhn, 2005). The Hungarian
method is a combinatorial optimization algorithm, which solves
the assignment problem in polynomial time. Our phase assignment
problem and the complete discussion of the solution can be found in
Subhani et al. (2009). In Figure 2, the cluster and the phase of each
of the ﬁve selected pairs, found by the Hungarian algorithm, are
shown at the same level; e. g. cluster C3 of Figure 2b—d is assigned
to the late G] phase of Cho et al. (1998) by our phase assignment

 

2285

112 /§JO'SIBUJHOIP.IOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 1110131 pop1201umoq

9IOZ ‘Ig lsnﬁnv uo ::

N.Subhani et al.

 

approach, and hence they are at the same level in the ﬁgure. The
same procedure by using k—MCMA of Subhani et al. (2009) and the
results are in Figure 2c.

The ﬁve clusters found by EMMA are shown in Figure 2b
and those found by k—MCMA are shown in Figure 2c, while the
corresponding phases of Cho et al. (1998) after the phase assignment
are shown in Figure 2a. The horizontal axis represents the time
points in minutes and the vertical axis represents the expression
values. The dashed black lines are the cluster centroids learned by
EMMA (Fig. 2b) and the known phase centroids of the yeast data
(Fig. 2a). In the ﬁgure, each cluster and phase were multiple—aligned
using Equation (9) to enhance visualization. Figure 2 clearly shows
a high degree of similarity between the EMMA clusters and the yeast
phases. Visually, each EMMA cluster on the left is very similar to
exactly one of the yeast phases, which we show at the same level on
the right. Also visually, it even ‘seems ’that EMMA clusters are more
accurate than the yeast phases and k—MCMA clusters, which suggests
that EMMA can also correct manual phase assignment errors, if any.

An objective measure for comparing EMMA and k—MCMA
clusters with the yeast phases was computed as follows. For each
EMMA or k—MCMA cluster, C110 (1 5 c 5 k : 5), we ﬁnd the shortest

distance between each proﬁle xi(t), 1 5 i 5 lam |, and all ﬁve—phase
centroids vj(t), 15 j 5k:5, using Equation (16) of Subhani et al.
(2009). Proﬁle xi(t) will be assigned the correct label (i.e. assigned
to phase label of 759].) whenever xi(t) 67513]. and £16,759!) 68 the
set of selected cluster—phase pairs; otherwise, xi(t) will be assigned
the incorrect label, if cluster C110 was not paired with phase 759}. by
our pair—assignment method. The percentage of correct assignments
over the 221 proﬁles was used as our measure of accuracy, resulting
in 83.26% for EMMA and 79.64% for k—MCMA. That is

22121-33150 ’ argminlsiskd (xi, VJ) )
221 ’

where E (a, 19) returns 1 when a : b, and zero otherwise. This criterion
is reasonable, as k—MCMA is an unsupervised learning approach
that does not know the phases beforehand, and hence the aim is to
‘discover’ the phases. In Cho et al. (1998), the ﬁve phases were
determined using biological information, including genomic and
phenotypic features observed in the yeast cell—cycle experiments.
EMMA’s accuracy of 83.26% is quite high considering that it is an
unsupervised learning method.

Acc : (25)

 

Comparison with previous approaches We have compared our
approaches with the following two previously published approaches:
(i) a clustering method that uses piecewise linear proﬁles in Rueda
et al. (2008); and (ii) the variation—based coexpression detection
(VCD) algorithm, which is described in Zong—Xian and Jung—Hsien
(2008).

We used an objective measure for comparing EMMA clusters
with the yeast phases. The measurement was computed by taking the
average classiﬁcation accuracy, as the number of genes that EMMA
correctly assigned to one of the phases. Considering each EMMA
cluster as a class, C110 (1 5 c 5 k : 5), we trained a c—nearest neighbor
(c—NN) classiﬁer with clusters to classify the data with a 10—fold
cross validation procedure, where c is the number of nearest proﬁles
from the centroids. We found that k : 5 is the best number of clusters
for the dataset, and we used the distance function of Equation 15 to
measure the distance between the centroids and the nearest proﬁles.

We applied the same procedure for k—MCMA clusters too. In Cho
et al. (1998), the ﬁve phases were determined using biological
information, including genomic and phenotypic features observed
in the yeast cell—cycle experiments. EMMA’s average classiﬁcation
accuracy is 91.03%, whereas for k—MCMA it is 89.51%.

We also applied the same objective measure as described above
for comparing the EMMA clusters with the P.aeruginosa dataset,
obtaining an average classiﬁcation accuracy of 91.40%. In Waite
et al. (2006) and Rueda et al. (2008), the correlation coefﬁcient is
used as the distance measure between gene proﬁles while here, we
used the distance as deﬁned in Equation (15). Figure 3 shows that
EMMA yields better results than k—MCMA and the methods used
in Waite et al. (2006). The same objective measure as described
above was applied in order to compare the k—MCMA clusters,
using piecewise linear proﬁles (an approach of Rueda et al., 2008)
with the yeast phases, which yielded an average classiﬁcation
accuracy of 86.12%. For the P. aeruginosa dataset, we obtained
an average classiﬁcation accuracy of 90.90%. Table 1 shows the
average classiﬁcation accuracies of our approaches and the approach
of Rueda et al. (2008).

From Table 1 and Supplementary Figure 1, we observe that
natural cubic spline proﬁles performed better than piecewise linear
proﬁles. k—MCMA and EMMA clusters using natural cubic spline
proﬁles on both datasets obtained over 90% classiﬁcation accuracy,
which is very high considering that they are both unsupervised
methods, while EMMA yields better results than k—MCMA. The
same comparison was carried out against the VCD algorithm (Zong—
Xian and Jung—Hsien, 2008). In that approach, gene expressions are
translated into gene variation vectors whose cosine values are then
used to evaluate the variation vector similarities over time. EMMA
and VCD are compared on two datasets: Saccharomyces cerevisiae
and S.pombe datasets (Table 2).

In Figure 2, cluster number 5 of EMMA and k—MCMA are
similar to the corresponding S phase, whereas VCD assigns many
differentially expressed genes to it—the same situation occurs for
cluster number 2 as well. From the ﬁgure, we observe that EMMA’s
clusters are more compact than those of all other methods. EMMA’s
clusters are even more well— separated than pre—characterized phases,
at least visually. In Figure 4, VCD identiﬁed three clusters that
contain only two genes and many genes are assigned to incorrect
clusters. In this dataset, k—MCMA’s clusters are more well—separated
than EMMA’s.

On the S.cerevisiae dataset, both EMMA and VCD found ﬁve
clusters, whereas EMMA clusters obtained over 90% classiﬁcation
accuracy. On the S.pombe dataset, we ran EMMA in conjunction
with four validity indices. We found eight meaningful clusters in this
dataset. EMMA was applied by setting of k : 8, and yielded 89.53%
classiﬁcation accuracy. Setting )1 : 0.59 and zp : 7, we applied VCD
on S.pombe as well to ﬁnd the clusters. VCD also identiﬁed eight
clusters and yielded 70.46% classiﬁcation accuracy. VCD identiﬁed
33 unique genes that do not belong to any cluster. According to
Peng et al. (2005), 71 clusters were obtained in the S. pombe dataset
with parameters 2:075 and zp : 1.96. In their method, )1 covers
the similarity between sets and zp determines the number of clusters.
The eight EMMA and k—MCMA clusters on S. pombe yielded 86.94%
and 87.63% classiﬁcation accuracies, respectively, which shows
that S.pombe contains eight meaningful clusters. In fact, EMMA
and VCD are both unsupervised learning methods, while EMMA
performs much better than VCD.

 

2286

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq 1110131 pop1201umoq

9IOZ ‘Ig lsnﬁnv uo ::

Multiple expression profile alignment

 

 

(a) ' ' ' ' _

Expression ratio
I
\
l
l
I

 

 

 

| |
0 10 20 30 40
Time in hrs. (k—MCMA clusters)

 

 

 

 

 I I I I _

I—\

\
~’ ‘ ,——---——_‘
\~_’¢
oi _

4'

’ ‘\ —----—_
~—’ ~—-—“— —
o—’\ —
’ \

' ‘_”_---—-----_—_
.9
EO— —
8
 "I‘ ’——~~-----—————
e ‘v’
5%
UJO- -
’4—~~~-__ __—
’ ---
"~~’
Ol— -
i \
’ \ —-- _-
‘—‘ ‘-——-——-_
oi _
\
\\a—‘
~--___—-—----__
0 I I I I
0 10 20 30 40

Time in hrs. (EMMA clusters)

Fig. 3. (a) k—MCMA clusters and (b) EMMA clusters of Raeruginosa dataset, with centroids shown.

Table 1. Experiment results overview of k—MCMA and EMMA with
piecewise linear proﬁle of Rueda et al. (2008)

 

 

Proﬁles Approaches S accha romyces Pseudomonas
cerevisiae (%) aeruginosa (%)

NCS k—MCMA 89.51 91.40

PL k—MCMA 86.12 90.90

NCS EMMA 91.03 92.71

PL EMMA 86.43 89.37

 

NCS: natural cubic spline; PL: piecewise linear proﬁles.

Table 2. Experiment results overview of EMMA approach and the VCD
method of Zong—Xian and J ung—Hsien (2008)

 

 

Approaches Saccharomyces S chizosaccharomyces
cerevisiae (%) pombe (%)

k—MCMA 89.51 87.63

EMMA 91.03 86.94

VCD 80.68 70.46

 

5 CONCLUSION

We propose k—MCMA and EMMA, two methods that combine
k—means and EM with multiple proﬁle alignment of gene expression

proﬁles to cluster microarray time—series data. The proﬁles are
represented as natural cubic spline functions, where the expression
measurements are not necessarily taken at regular time—intervals.
Four cluster validity indices are used in conjunction with the
above methods to determine the appropriate number of clusters
and also the validity of the clusters. An objective measure for
comparing the k—MCMA and EMMA clusters with the yeast
phases is computed by taking the average classiﬁcation accuracy.
EMMA combined with natural cubic spline proﬁles performs better
than piecewise linear proﬁles, and also outperformed VCD. Our
experiments also show that EMMA is able to ﬁnd better clusters
than biologically characterized yeast phases. We ﬁnally note that our
vertical alignment method is different from the temporal alignment
of Bar—Joseph et al. (2003) and Ernst et al. (2005), where the
alignment is horizontal, i.e. it is performed along the time axis to
match the time points of one proﬁle to the time points of the other
proﬁle, in such a way that the integrated squared error between
the horizontally aligned proﬁles is minimal. Temporal alignment is
used for proﬁles that are either sampled at different time points, have
different number of time points, or have different time extents.

In the future, we plan to study other distance—based clustering
approaches using our multiple alignment method. Other clustering
algorithms with multiple alignment, cluster validity indices based
on multiple alignment, phase detection by aligning over a portion
of the time series expression and studying the effectiveness of our
clustering methods in dose—response microarray datasets can also

 

2287

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq urorj pop1201umoq

9IOZ ‘Ig1sn8nv uo ::

N.Subhani et al.

 

 

 

 

 

 

 

 

 

I I I I I I I I I I I I I I I I
_ __-- ——__ _ _ ———- ’——— _ _~ _——-~ _—_—- —
" '~
’-‘ "~\ I’ \\ ’ ‘ "~ "~
I \ _ _
0— [ \\~” ~~—_0_ I \ ” S  ” ‘~—” ~~—
" C7 -' \_ Me C7
0_——--~~_ﬂ——----— _0_—"--~‘V ”—~‘—- _0_-—_--‘-uu’—-~—‘---_
C6 cs C6
ﬂ " — ﬂ
I S I s I ‘ .. -
.9 0" x I, s‘ ‘0" ‘ ‘\ ‘O‘T ~T~ «’T ~~_._ ‘
s ‘- cs " C5
5
§0_~”’—n-\Vl---"——~- _0_~"’-~~---’—-—~-—_0_~”¢—-~l.--‘———~_—_
a C4 C4 C4
E
o—“~~_-v"~~-_-—--—o—""~~-_ —"~-——-ro—“~--—-—"‘--~—,"-
0—N~—_———-~~___’——__0—§___“—-~-__’_——_0_~-’__—-——_____— __
E” E 02
"l‘ ——-_ f—. .— -- —~
0'\ 1’ ~‘\”’ "0's ” ~~_¢" T 0_~_¢” ~‘~..v' -“
‘ ' E01 " E CC:
I I I I I I I I I I I I I I I I I I
1 2 3 4 6 1 2 3 4 5 6 'I 2 3 4 5 6

5
(k—MCMA) Time in hrs.

(EMMA) Time in hrs.

(VCD) Time in hrs.

Fig. 4. (a) k—MCMA clusters, (b) EMMA clusters and (c) VCD clusters on S.pombe dataset, with centroids shown.

be interesting to investigate. Though our main focus is clustering,
the effect of using different imputation methods rather than natural
cubic spline in representing the proﬁles are also worth investigating.

Funding: Natural Sciences and Engineering Research Council of
Canada, Grants #RGPIN228117—2006 and #RGPIN261360—2009
(partial).

Conﬂict of Interest: none declared.

REFERENCES

Bar-Joseph,Z. et al. (2003) Continuous representations of time series gene expression
data. J. Comput. Biol., 10, 341—356.

Bre’he’lin,L. (2005) Clustering gene expression series with prior knowledge. Lect. Notes
Comput. Sci., 3692, 27—38.

Cho,R. et al. ( 1998) A genome-wide transactional analysis of the mitotic cell cycle.
Mol. Cell, 2, 65—73.

Chu,S. et al. (1998) The transcriptional program of sporulation in budding yeast.
Science, 282, 699—705.

De’jean,S. et al. (2007) Clustering time-series gene expression data using smoothing
spline derivatives. EURASIP J. Bioinform. Syst. Biol, 70561, 705—761.

Dempster,A. et al. (1977) Maximum likelihood from incomplete data via the em
algorithm. J. R. Stat. Soc., 39, 1—38.

Ernst,J. et al. (2005) Clustering short time series gene expression data. Bioinformatics,
21 (Suppl. 1), i159—i168.

Heyer,L. et al. (1999) Exploring expression data: identiﬁcation and analysis of
coexpressed genes. Genome Res., 9, 1106—1115.

Kuhn,H. (2005) The hungarian method for the assignment problem. Nav. Res. Logist,
52, 7—21.

Moller-Levet,C. et al. (2005) Clustering of unevenly sampled gene expression time-
series data. Fuzzy sets Syst., 152, 49—66.

Peddada,S. et al. (2005) Gene selection and clustering for time-course and dose-
response microarray experiments using order-restricted inference. Bioinformatics,
19, 834—841.

Peng,X. et al. (2005) Identiﬁcation of cell cycle-regulated genes in ﬁssion yeast. Mol.
Biol. Cell, 16, 1026—1042.

Ramoni,M. et al. (2002) Cluster analysis of gene expression dynamics. Proc. Natl
Acad. Sci. USA, 99, 9121—9126.

Roth, V., Laub, J ., Kawanabe, M., and Buhmann, J. (2003). Optimal cluster preserving
embedding of nonmetric proximity data. IEEE Trans. Pattern Anal. Mach. Intell.,
25, 1540—1551.

Rueda,L. et al. (2008) Clustering time-series gene expression data with unequal time
intervals. Springer Trans. Comput. Syst. Biol. X, LNBI, 5410, 100—123.

Subhani,N. et al. (2009) Microarray time-series data clustering via multiple alignment
of gene expression proﬁles. In Fourth IAPR International Conference on Pattern
Recognition in Bioinformatics. Vol. 5780 of Lecture Notes in Bioinformatics,
Springer, New York, USA, pp. 377—390.

Tamayo,P. et al. (1999) Interpreting patterns of gene expression with soms: methods
and application to hematopoietic differentiation. Proc. Natl Acad. Sci. USA, 96,
9121—9126.

Tavazoie,S. et al. (1999) Systematic determination of genetic network architecture.
Nat. Genet, 22, 281—285.

Waite,R. et al. (2006) Clustering of pseudomonas aeruginosa transcriptomes from
planktonic cultures, developing and mature bioﬁlms reveals distinct expression
proﬁles. BMC Genomics, 7, 162—175.

Xu,R. and Wunsch,D. (2008) Clustering. Wiley-IEEE Press, New Jersey.

Zong-Xian,Y. and J ung-Hsien,C. (2008) Novel algorithm for coexpression detection in
time-varying microarray data sets. IEEE/ACM Trans. Comput. Biol. Bioinform, 5,
120—135.

 

2288

112 /B.IO'SIBUJnOprOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 1110131 pop1201umoq

9IOZ ‘Ig lsnﬁnv uo ::

