Bioinformatics, 31 (18), 2015, 2947—2954

doi: 10.1093/bioinformatics/btv304

Advance Access Publication Date: 15 May 2015
Original Paper

 

Sequence analysis

Repeat- and error-aware comparison of
deletions

Roland Wittler1'*, Tobias Marschal|2'*, Alexander Schonhuth“ and
Veli Makinen‘”

1Genome Informatics, Faculty of Technology and Center for Biotechnology (CeBiTec), Bielefeld University,
Germany, 2Center for Bioinformatics, Saarland University and Department of Computational Biology and Applied
Algorithmics, Max Planck Institute for Informatics, Saarbriicken, Germany, 3Centrum Wiskunde & Informatica
(CWI), Life Sciences Group, Amsterdam, The Netherlands and 4Helsinki Institute for Information Technology (HIIT),
Department of Computer Science, University of Helsinki, Finland

*To whom correspondence should be addressed. The authors wish it to be known that, in their opinion, the first two
authors should be regarded as Joint First Authors

TThe authors wish it to be known that, in their opinion, the last two authors should be regarded as Joint Last Authors
Associate Editor: John Hancock

Received on October 6, 2014; revised on May 7,2015; accepted on May 8,2015

Abstract

Motivation: The number of reported genetic variants is rapidly growing, empowered by ever faster
accumulation of next—generation sequencing data. A major issue is comparability. Standards that
address the combined problem of inaccurately predicted breakpoints and repeat—induced ambigu—
ities are missing. This decisively lowers the quality of ‘consensus’ callsets and hampers the re—
moval of duplicate entries in variant databases, which can have deleterious effects in downstream
analyses.

Results: We introduce a sound framework for comparison of deletions that captures both tool—
induced inaccuracies and repeat—induced ambiguities. We present a maximum matching algorithm
that outputs virtual duplicates among two sets of predictions/annotations. We demonstrate that
our approach is clearly superior over ad hoc criteria, like overlap, and that it can reduce the redun—
dancy among callsets substantially. We also identify large amounts of duplicate entries in the
Database of Genomic Variants, which points out the immediate relevance of our approach.
Availability and implementation: Implementation is open source and available from https://
bitbucket.org/readdi/readdi

Contact: roland.wittler@uni—bielefeld.de or t.marschall@mpi—inf.mpg.de

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

1 Introduction

Next—generation sequencing (NGS) technology has led to generation
of ‘Big Data’ also in biology. The rapid accumulation of NGS data
has triggered the development of an equally overwhelming amount
of tools for their exploration, including many tools for the predic—
tion of structural variants, see the reviews by Alkan et al. (2011) and
Medvedev et al. (2009). An immediately arising, pressing concern

are cross—genome and cross—project comparability of variant call sets
(e.g. from The 1000 Genomes Project Consortium, 2010; The
Genome of the Netherlands Consortium, 2014). While resolution of
related issues is instrumental for successful genetics research, there
are only little statistically and algorithmically rigorous approaches
addressing this. Here we suggest a formal framework for identifying
duplicate deletion calls.

©The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2947

9mg ‘09 1sn3nv uo sopﬁuv soq ‘BTUJOJTIBD aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

2948

R. Witt/er et al.

 

A major source of problems about NGS data formats and tool
evaluation is the repetitiveness inherent to the majority of genomes
(Treangen and Salzberg, 2012). The resulting read mapping ambi-
guity can decisively hamper the exact allocation of structural vari—
ations (SVs) as well as insertions and deletions (indels) within a
genome. On top of that, another major source of prediction inac—
curacies are the technical and theoretical, tool—specific limitations.
These are often well—known. For instance, sequencing errors,
ambiguities during the alignment of reads to a reference, or point
mutations close to the breakpoints might cause split—read
approaches to be inaccurate by a few bases. Paired—end mapping
approaches, on the other hand, infer the deletion size according to
the difference of the expected fragment length and the resulting
distance of the mapped reads. Since the original fragment length is
only known approximately, the deletion size predictions are less
accurate than for split—read aligners. In addition, the location of
the deletion needs to be confined to the region between the paired
ends, which introduces further inaccuracies. See for example
Alkan et al. (201 1) for details on the different kinds of approaches;
popular split—read aligners are Pindel (Ye et al., 2009) and
Platypus (Rimmer et al., 2014), while Breakdancer (Chen et al.,
2009) and Clever (Marschall et al., 2012) are paired-end mapping
approaches.

As we will outline in the following, the simultaneous presence of
repeats and (even slightly) inaccurate breakpoint predictions makes
it difficult to compare two deletion calls, as done when merging call
sets created by different tools (as e.g. in the recent consensus caller
by Trubetskoy et al., 2015) or when searching variant databases
(e.g. Sherry et al., 2001; Zhang et al., 2006). Since indels and SVs
play important roles in cancer and many other diseases (Raphael,
2012; Xi et al., 2010), and in general populations (Zhang et al.,
2006), alleviating such issues can make a highly beneficial contribu—
tion to the field.

1.1 Example

As a simple example for the issues to be discussed, consider the toy
reference genome ACTGCTGCA, which has CTG repeated two times.
First, consider two tools one of which predicts CTG at positions 2—
4 to be deleted, while the second one predicts TGC at positions 6—8
to be deleted. The two predictions are equivalent insofar as the re—
sulting donor genome sequence is, in both cases, ACTGCA. Let us
assume that this is the correct donor genome sequence to be pre—
dicted. The VCF format (Danecek et al., 2011) addresses this by
‘left-aligning’ all predictions, that is, by reporting the leftmost de—
letion which is equivalent to the prediction made. Note that, after
left-aligning, the calls of the two tools in our example are
identical.

Now consider that the second tool errs, and mistakenly pre-
dicts that only nucleotides 7—8 are deleted. In this case, left—
aligning the call of the second tool has no effect, because the pre—
dicted deletion differs from the repeat unit. As a result, the two
predictions, although virtually identical, do not only deviate by
1 base pair in length, but also by 5 base pairs in terms of their
left breakpoint. In particular, the two predictions do not over—
lap. Overall, induced by the combination of repeat structure and
a (minor) misprediction, spotting their similarity has become
more difficult.

1.2 Our contribution
We suggest a formal model for the identiﬁcation of similar deletions,
which takes both repeat structure and prediction inaccuracies into

account. Furthermore, we present an efficient algorithm based on
this model that allows for (i) pairwise comparison of all elements of
a set of deletions and (ii) comparison of all elements of one set of de—
letions to all elements of a second set. The first mode of operation
facilitates the identification of (clusters of) duplicate entries in data—
bases while the second mode allows comparing deletion calls made
by different tools.

In the latter case of comparing two call sets, one hopes to obtain
a one—to—one mapping, that is, each deletion from one set matches
exactly one deletion from the other set. In practice, however, several
deletions in one set may match one or more deletions in the other,
or do not match any of the other deletions at all. Also, deletions
within one set may already be redundant, because they are similar
or even equivalent to one another. To address this, we introduce a
maximal matching based framework to distinguish all relevant cases
and compute appropriate matching statistics.

As experiments, we first screen the Database of Genomic
Variants (DGV, Zhang et al., 2006) for duplicates, and reveal hun—
dreds of clusters of similar deletions. We also run the four state—of—
the—art deletion prediction methods Breakdancer (Chen et al.,
2009), Clever (Marschall et al., 2012), Pindel (Ye et al., 2009) and
Platypus (Rimmer et al., 2014) on an approved benchmarking
dataset which reflects real human genome sequence context (Levy
et al., 2007; Marschall et al., 2013). Furthermore, we demonstrate
that using our comparison procedure is superior to using ad looc
criteria like 50% reciprocal overlap, which has been popular both
in evaluating calls and merging independent callsets into a ‘consen—
sus’ callset.

The developed algorithms are implemented in the easy—to—use
open source software package Repeat— and Error—Aware Detection
of Duplicate Indels (READDI) to compare sets of deletions given in
VCF or BED format, facilitating its use in NGS data analysis pipe—
lines and for curating databases.

1.3 Related work

Our approach on taking repeat structure into account is related
to the problem of tandem repeat finding, see e.g. Gusfield and
Stoye (2004). We use the same machinery of Longest Common
Extension (LCE) queries (Landau and Vishkin, 1989), now for
identifying leftmost and rightmost shifts for each deletion. The
fact that deletions and insertions can be shifted without altering
the resulting sequence has already been observed by Krawitz et
al. (2010) and Assmus et al. (2013), but the connection to LCEs
has been missed there.

Assmus et al. (2013) conducted a study of indel equivalence
classes based on the same notion of equivalence as we study here for
the case of deletions, i.e. taking repeat—induced equivalence into ac—
count, but not the notion of similarity we propose for inaccurate
predictions. They call an indel ambiguous if it belongs to an equiva—
lence class consisting of more than one element. Then they analyse
ambiguous indels in the Ensembl database (Hubbard et al., 2002)
and reveal that the exact position of such variants can affect the
functional annotation; they show examples of ambiguous indels
crossing transcript boundaries, affecting start codons and splice
sites, and being involved with triple—repeat diseases.

The study of Assmus et al. (2013) emphasizes the importance of
robust methods to identify potentially identical variations in data—
bases. We complement their study by extending the model of simi-
larity to involve inaccurate predictions. From the algorithmic
perspective, we also give a faster routine to detect equivalent dele—
tions with the connection to longest common extension queries. We

91% ‘09 1sn3nv uo sojoﬁuv soq ‘BTUJOJTIBD aIo Amie/xtqu 112 /§.IO'S[BU.IT10[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

Repeat— and error-aware comparison of deletions

2949

 

also complement the experimental analysis by screening a different
variant database, and by studying the hybrid effect of repeats and in—
accurate predictions with several existing deletion prediction tools
on realistic ground—truth datasets.

Rather than comparing sets of deletions directly, there exists also
a quite different approach based on alignments: Apply each set of
deletions to the reference sequence and compare the created se—
quences using optimal pairwise alignments. The alignment score
gives a ranking for deletion prediction in the case that one of the sets
corresponds to the ground truth. This approach was recently ex—
tended to the diploid ground—truth setting (Makinen and Rahkola,
2013) with an O(dn) algorithm, where d is the unit cost edit distance
between predicted sequence and ground—truth, and n is the max-
imum sequence length. In practice, this approach is not scalable to
whole—genome comparisons (Makinen and Rahkola, 2013); compu-
tation took 6 to 11.5 hours, depending on prediction accuracy, only
for the 63 Mbp long human chromosome 20.

Even if the alignment—based approach could be sped up with
more algorithm engineering, one should notice that extracting vari—
ants from the alignment result in a canonical manner is a non-trivial
problem. Placing gaps within alignments has remained one of the
most prevalent computational challenges in bioinformatics: See for
example Lunter et al. (2008) for an illustration of effects such as
‘gap wander’ or ‘gap annihilation’, all of which, of course, equally
apply when aligning NGS reads. One can try to attach more biolo—
gical semantics to indels by modeling them as traces of recombin—
ation events (Giegerich et al., 1999), but the optimal solution of
such recurrence takes cubic time.

2 Methods

We first formalize the phenomenon that deleting two different inter—
vals from a given reference results in the same string. In the second
section, we extend this concept to an error—tolerant model of similar-
ity. After that, we introduce an algorithm to find all pairs of similar
deletions from two given sets.

2.1 Model: exact case
In the following, let |S| be the length of a string S. We denote dele—
tions by intervals [i, j], where S\ [i, 1'] denote the string that results
from removing all characters from (and including) position i to (and
including) j from S.

As discussed in Section 1.1, deleting different segments of a given
string can yield the same result. We call two such deletions equivalent.

DEFINITION 1: Deletions [i, j] and [i’, j’] are equivalent w.r.t. a refer—
ence sequence S, written [i, j] ¢> [i’ , j’], if and only if S \ [i, j] = S \ [i’ , 1"
We further define their shift being s([i, j], [i’ , j’ :2 |i’ — i

Out of a set of equivalent deletions, we are especially interested in
the leftmost and rightmost representative, formally defined as follows.

DEFINITION 2: (rightmost and leftmost shift): Let S be a reference
string. Then the leftmost and rightmost shift of a deletion [i, j] are
defined as: L([i,j]) :2 argmin{ i’ | [i’,j’] ¢> [i,j]} and R([i,j]) :2
argmax{ i’ | [i’, j’] ¢> [i, 1]}, respectively.

PROPERTY 1: Given two deletions d1 and d2 of the same length, the
following statements are equivalent:

(1)611 ¢> d2 (ii) L011) 2 L(d2) (iii) R(d1) = R(d2)

The left- or rightmost shift of a deletion [i, 1'] can be computed
quickly in practice by shifting the deletion one by one as long as
S [i — 1] = S or S = S —l— 1], respectively. They can even be com—
puted in constant time after preprocessing the reference:

LEMMA 1: The left- or rightmost shift of a deletion can be com—
puted efficiently by preprocessing the reference sequence to allow
for constant time longest common extensions.

PROOF: The longest common extension LCE5(i, j) = l is such that
S[i,i—l— l — 1]: S[/,j—l— l — 1] and S[i—l— l] 7E S[/—l— l]. After linear time
preprocessing of S, every LCE5(i,j) can be computed in constant
time (Landau and Vishkin, 1989). The rightmost shift of a deletion
[i,j] is [i —l— l,j —l— l] where l : LCE5(i,j —l— 1). The leftmost shift can be
computed analogously. CI

Due to the repetitive structure of genome sequences, large shifts
are possible—even larger than the deletions, that is, there are dele—
tions which are equivalent but not even overlapping. When compar—
ing two sets of deletions, e.g. in benchmarking different deletion
prediction tools, or searching for deletions in a database, the
phenomenon of equivalent deletions has to be kept in mind.
Equivalency in the exact sense is not a matter of sequencing depth,
read quality or read length, but of the repeated nature of genome se—
quences. Additionally, since in practice, both predictions and data—
base entries do usually not come at base pair resolution, some error—
tolerance is necessary to account for equivalence.

2.2 Model: similarity

Even a deviation of only a single base in deletion breakpoint predic—
tions can implicate or prevent that deletions are shiftable, which can
lead to very large differences in the resulting repeat—corrected break—
points. To account for such breakpoint inaccuracies, we define the
distance

K(Ii7jla Ii/aj/I) == Ii — 1"I + Ii —i’|,

which, like all following terms, takes both left and right breakpoint
equally into account. Based on this, we define neighborhoods
around deletions as follows.

DEFINITION 3 (la—neighborhood): The le—neighborhood of a deletion
d = [i, 1'] comprises all deletions with a distance of at most la:

Nk(d) :2 {d’ |K(d, d’)gle}

The value k is called neighborhood size.

For comparing two predictions made by two different methods
or called on different data, we use separate neighborhood sizes 131
and kg for each of the two data sets. That means, when comparing
predictions from a highly accurate method (or called from very ac—
curate data) with less accurate ones, we can set 131 to a smaller value
than 132.

Note that the output of some deletion callers already explicitly
includes tool—specific neighborhoods (a.k.a. confidence intervals),
for example, in form of windows for both position and length, or
both breakpoints.

We will, in the following, base all our considerations on the
le—neighborhood model from above. We do this for the sake of sim—
plicity; our approach to similarity of deletions is generic in the
choice of neighborhood definition, such that also other definitions
can be used.

We say that two deletions are similar if there are equivalent dele—
tions within their neighborhoods.

9mg ‘09 1sn3nv uo sojoﬁuv soq ‘BTUJOJHEQ aIo Amie/nun 112 /B.IO'S[BU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq U101} popeommoq

2950

R. Witt/er et al.

 

DEFINITION 4 ((k1,k2)—similarity): Deletions d1 and d2 are (k1,le2)—simi-
lar, if and only if there are deletions d’1 E Nk1(d1) and d’2 E Nk2(d2)

such that d’1 and d’2 are equivalent according to Definition 1.

For one pair of deletions d1 and d2, there might exist several
choices of d’1 ENk1(d1) and d’2 ENk2(d2) that establish (121,122)—

similarity between d1 and d2. We summarize all such choices as
5k1.k2(d17d2) == {( 17612) E Nk1(d1) >< Nk2(d2) Idi <=> 61/2}-

To assess by how many base pairs the breakpoints of two deletions
need to be corrected to render them equivalent, we define

K2712 (dladz) 1: min {K(d1ad'1) + K(d2,d’2) | (611, dé) E Sk1,k2(d1,d2)}-

This quantity is instrumental for distinguishing between two factors
of similarity: The neighborhood size that is required to overcome a
possible inaccuracy of deletion predictions on the one hand, and the
actual shift due to a repetitive structure of the sequence on the other
hand. Motivated by maximum parsimony, we minimize the inaccur-
acy first and the shift second, describing a scenario with as few
errors as possible as well as a minimum shift.

DEFINITION 5 (minimum shift): Given two (k1,le2)—similar deletions
d1 and d2, their minimum shift is defined as

521%.(6117612) == min {s(d’1,d’2) | ( ’1, d3) 6 8m. (d1, d2)
A K(d17  + K(d27  : K211i:ng (d1: d2) 

2.3 Matching sets of deletions

By determining similar deletions within one dataset, we can identify
duplicate calls and merge them, e.g. by selecting one representative.
To compare two datasets D1 and D2, we compute the similarity re-
lations between all deletions in D1 to all others in D2. This can be
modeled as a bipartite graph with node sets D1 and D2. Two nodes/
deletions d1 E D1 and d2 E D2 are connected by an edge (d1, d2) if
they are (121, k2)—similar. Then, a maximum cardinality matching
allows to compare or merge the two datasets: Each deletion is
related to at most one in the other set. Matched deletions are in com—
mon, unmatched are unique. However, we have to keep in mind
that both D1 and D2 might contain duplicates, i.e. we have to take
(121, k1)—similar deletions within D1 and (k2, k2)—similar deletions
within D2 into account. These can be taken care of either prior to
building the graph or in a post—processing step.

To evaluate a callset P against a given ‘truth’ T, e.g. calls pre—
dicted by a different tool or a collection of deletions in a database,
the obtained bipartite matching can easily be interpreted as follows.
Matched (lap, leg—similar deletions correspond to true positives
(TPs), and unmatched deletions in P and T correspond to false posi—
tives (FPs) and false negatives (FNs), respectively. To account for du—
plicates within the two sets, after performing the matching, we also
determine all (lap, lep)—similar deletions in P and (let, k,)-similar dele-
tions in T. If a deletion in P is unmatched but similar to a TP, it
might be considered as being a duplicate of a TP and should thus
not be counted as a FP. We report those deletions as similar positives
(SP5) and do not count them as FPs. Vice versa, we report un—
matched deletions in D as similar negatives (SNs) and do not count
them as FNs. Further, we do not count several unmatched deletions
as individual false positives (or negatives) if they are similar. Instead,
we report components of (lap, lep)—similar deletions in P as false posi-
tive components (FPCs) and components of (let, leg—similar deletions
in T as false negative components (FNCs), see Figure 1. This allows

Pred , ——————— \(kp, kp)-siniilar

 

 

(hp, leg-similar

ﬂ
(kt, kt )—sin1ila1:"~---—”’ ........ x’
TP SP TP SN FN FN KFP Fp PP]
F NC

FPC

 

 

Truth

 

 

 

 

Fig. 1. Visualization of maximum matching framework. Deletions are drawn
as boxes on a line representing the reference. The dashed lines indicate pairs
of similar deletions

us to define a duplicate—aware recall by ﬁgNC and precision by

TP
TP+FPC‘

2.4 Algorithm

In the following, we describe an algorithm that, for two given lists
of deletions, as specified by reference coordinates, determines all
pairs of similar deletions. We assume the lists being sorted by dele—
tion start coordinates. The algorithm outputs all pairs of deletions
for which the deletion in the first list is left of or at the same position
as the one in the second list. To obtain all pairs of similar deletions
of two distinct lists, the algorithms is executed twice: to get the pairs
where the deletion from the first list is left and from the second list is
right and vice versa. To screen a single list for duplicates, the algo—
rithm is called once by passing this list twice as parameter. Pseudo
code is given in Algorithm 1.

The for-loop in line 2 iterates over all deletions in the first list.
For each considered deletion d1, we aim at finding similar dele-
tions d2 in the second list with a starting position right of or at the
same position as d1. How far a particular deletion can be shifted
depends on whether its length matches a repeat unit. Therefore,
we enumerate all possible lengths of deletions in the neighborhood
of d1 (line 3); for a given length E, we compute where the rightmost
such deletion starts (line 4) and use an LCE query to determine
how far it can be shifted to the right (line 5). In line 6, we then iter-
ate over all potentially similar deletions d2 in the second list, skip-
ping those whose neighborhood does not contain deletions of
length E (lines 7 and 8). In case d2 is so far to the right that a shift—
able deletion of length E cannot ‘mediate’ a similarity relationship,
we can stop and do not need to consider any deletions further to
the right in the second list (lines 9 and 10). For the remaining can-
didates d2, we check in lines 11 and 12 whether there is a length-E
deletion in its neighborhood that can establish (k1, k2)—similarity
(cf. Definition 4): Line 11 computes the leftmost length—E deletion
in the neighborhood of d2. Recall that the length—E deletion start—
ing at start_max1 is still in the neighborhood of d1 and that all
length—E deletions starting between start_max1 and shifted1 are
equivalent. Therefore, testing for (121, k2)—similarity (mediated by
a length—E deletion) of d1 and d2 boils down to a simple compari—
son in line 12.

The three nested loops in Algorithm 1 give rise to a worst—case
runtime of O(|L1| - |L2| -le1), where |L1| and |L2| are the lengths of
the two deletion lists. In practice, however, the runtime behaves
linearly in |L1| —)— |L2| (rather than being linear in |L1| - |L2|) since
for each deletion d1 E L1, only a local neighborhood is considered
for the search of candidates in L2: the loop in line 6 only considers
deletions d2 E L2 that are right of d1 and the search is terminated in
line 10 as soon as d2 is too far right. This ‘locality’ of the algorithm
is achieved by considering each candidate length E separately (line 3)
and was a major design goal. Since no recursion stack or complex
auxiliary data structures are required, the memory requirement is

91% ‘09 1sn3nv uo sojoﬁuv soq ‘BTUJOJHEQ 10 Amie/nun 112 /§.IO'S[BU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(1111] U101} pop1201umoq

Repeat— and error-aware comparison of deletions

2951

 

mainly given by the input and output—in practice dominated by the
size of the reference sequence.

 

Algorithm 1. Computation of (k1 , k2)-similar deletions

 

Input: Two lists of deletions L1 and L2, sorted by deletion start
positions; reference sequence S.

Output: Set Pairs of all pairs of indices of (k1, k2)-similar deletions
for which the one in the ﬁrst list is left of or at the same
position as the one in the second list.

1 Pairs <— (l);
2 for each deletion d1 = [start(d1), end(d1)] in L1 do

3 for each possible deletion length E of d1
(i.e., E = length(d1) — k1, . . . ,length(d1) —1— 121) do

 

 

4 start_ma:v1 <— ]Start(d1)+eng(dl)_e+kl+l];
5 shiftedl <— start_maa:1
+LCES(start_maa:1, staeraasl —)—E);

6 for each deletion d2 = [start(d2), end(d2)] in L2

with start(d1) S start(d2) do
7 ifE < length(d2) — k2 orE > length(d2) —I— k2 then
8 L continue; // lengths incompatible
9 if shiftedl < start(d2) — k2 then
10 L break; // no candidate in range
11 start_min2 <— Iswrt(d2)+eng(d2)_e_k2+l];

12 if shiftedl Z start_min2 then

/* deletion Of length E can be
shifted from [cl—neighborhood Of
d1 to leg—neighborhood Of d2 */

13 Pairs <— Pairs U {(d1, d2)};

 

 

 

14 return Pairs;

 

3 Results and discussion
3.1 Datasets

Venter predictions and venter truth. We use a benchmark dataset
based on Craig Venter’s genome (Levy et al., 2007) that was
described in Marschall et al. (2013). It consists of three human gen—
omes that represent a mother—father—child trio and are realistic in
particular in terms of true sequence context and amounts of variants
across the whole variant spectrum (including also mixed events and
inversions, for example). Here, we use the father genome. By Venter
Truth, we refer to the set of known true differences of this genome
to the reference genome. From this genome, we sample 2 X 100 bp
reads with HiSeq error profiles to 30 X coverage using SimSeq (Earl
et al., 2011) and run Breakdancer (Chen et al., 2009, version 1.4.4),
Clever (Marschall et al., 2012, version 2.0rc3), Pindel (Ye et al.,
2009, version 0.2.4 t) and Platypus (Rimmer et al., 2014, version
0.7.9.1) to produce several call sets referred to as Venter
Predictions. While Breakdancer and Clever are internal—segment-
size based tools that yield rather inaccurate deletion calls, Pindel and
Platypus, as split—read aligners, yield calls that are often highly ac—
curate. In our experiments, in particular the results for the Platypus
calls show a very similar behaviour to those for the Pindel set. These
call sets serve as examples to demonstrate the behavior of our simi-
larity criterion on realistic datasets produced by state—of—the—art
tools. Here, we do not focus on comparing the tools’ performance
rates.

Database of Genomic Variants. The DGV (Zhang et al., 2006) con—
tains curated structural variations in human, detected in healthy

control samples. It comprises different types of structural variations,
predictions from different studies found by different techniques. We
downloaded DGV variants mapped to GRCh 37 (release date 2014—
10—16) and extracted deletion predictions (varianttype ‘CNV’ and
variantsubtype ‘deletion’ or ‘loss’).

Throughout our experiments, we focus on deletions between 20
and 10 000 bp. Note that our tool is generic in deletion size.
However, shorter deletions are still within reach of standard read
mappers, and therefore less prone to prediction inaccuracies.
Removal of duplicates among very long deletions is easy due to their
size and because they are very few in number.

3.2 Removing duplicates in single datasets

We determined all (la, la)—similar deletions in Venter Truth and in the
DGV for la :25, and for each (la, la)—similar pair of deletions d1, d2
(excluding cases where d1 :dz), we computed their minimum shift
sgjikn(d1,d2). In addition to about 605 for reading the reference se—
quence, this took about 8 s (Venter) and 95 s (DGV) on a standard
laptop without computing the minimum shift, and about 45 s
(Venter) and 600 s (DGV) including the computation of the minimum
shift. The peak memory usage was reached after reading the input
files, where the reference sequence of about 3 GB clearly dominated
all other data structures since the given 10—20 000 deletions are repre—
sented by four integers each, i.e. only some kilobytes were used in
total. A general observation is that a small minimum shift often
implies that the le—neighborhoods of d1, d2 overlap. For increasing
minimum shift, however, the amount of overlapping neighborhoods
necessarily decreases—for pairs with a minimum shift larger than la,
by definition, a shift is required, which translates into the fact that the
le—neighborhoods are disjoint. Note that a shift might not be required
even if sgjlﬂdh d2) is larger than zero, because the definition of s21]?
prioritizes minimizing le over minimizing the shift.

Venter truth. This dataset is based on a de novo sequence assembly
using Sanger sequencing (Levy et al., 2007). Therefore it is of very
high quality and presumably contains nearly no duplicates due to
technical errors. Duplicates reported by our algorithm are thus likely
to be false positives, that is, cases where two deletions are indeed
biologically different, but are falsely assumed to be the same by our
method. In total, we found 25 such pairs of similar deletions involv-
ing 50 out of 10001 deletions in the dataset (0.5%), 32 of which
(0.3%) required shifting. The fraction of 0.5% can be interpreted as
an estimate of the false positive rate of our method. When manually
inspecting the reported pairs, however, one can hypothesize that
some of them are not wrongly called by our method but indeed rep—
resent artifacts in the dataset, meaning that the false positive rate
could be even lower. Some such cases are listed in Section A of the
Supplement. When choosing la larger than 25, the resulting rates nat—
urally increase. For la : 60 and la : 120, we obtain 190 and 464 dele—
tions involved in similar pairs, respectively. Depending on the
application, the corresponding false positive rates of 1.9 and 4.6%
may still be acceptable.

Database of genomic variants. Unlike the Venter dataset, the
DGV contains massive amounts of virtual duplicates (15.8%): See
Figure 2 for a histogram of the number of similar deletions versus
the minimum shift observed. For about one third of the non—unique
deletions, KW” : 0; for larger values of Km", about 70—500 dele—
tions have been found each. (See Supplement B for a plot of the dis—
tribution.) Since the DGV is a collection of deletions resulting from
many, often large—scale studies, and entries are merged per study

91% ‘09 1sn3nv uo sojeﬁuv s01 ‘BTUJOJTIBD 10 Amie/nun 112 /§.IO'S[BU.IT10[p.IOJXO'SOllBIIIJOJUIOIQ/ﬁ(1111] U101} pop1201umoq

2952

R. Witt/er et al.

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

O

O

8 ‘7 I: total
g '— EI shift required
E 0 [Z detectable by 70% overl.
% E ‘ 77'
(D _
‘3 a 7 100
c ——__ > :
t F— 4% ————_— 
o —— 257
E 77—7 24
O
E $2 — 77
E 77 7'
:5 7—
Z _ 7— 7

O

I I I I I I
0 20 40 60 80 100
Minimum shift (bp)

Fig.2. Non-unique deletions in the DGV dataset. Minimum deletion size was
48 bases. Identical predictions and deletions larger than 10K bases have
been filtered out (118349 deletions of 159136 were left). Pairs of similar dele-
tions with k: 25 have been computed and these pairs involved 18753
(15.8%) deletions, the minimum shift to any similar deletion has been re-
corded. Gray bars indicate those deletions that are similar with a shift
required, i.e. the 25-neighborhoods of the two deletions are disjoint. The
striped bars indicate those deletions which are also non-unique according to
70% overlap. (An overlap of gray and striped areas does not imply an overlap
of the underlying sets of deletions.) Note the logarithmic scale of the y-axis

only and not across studies, this high rate is expected and reﬂects
concordance of the contained studies. But it is noteworthy that there
is a large amount of deletion duplicates with large minimum shifts,
which could not be detected without shifting the calls, as indicated
by the gray part of the bars in Figure 2. As shown by the striped
bars, about 7.3% of those deletions that we detected being non—
unique cannot be detected by the criterion used in DGV, i.e. 70%
overlap. The experiment described in the previous paragraph sug—
gests that this discrepancy is unlikely caused by false positives from
our approach. To collect further evidence of a low false positive
rate, we analyzed pairs of matching deletions in DGV for which one
deletion originated from Venter’s genome and one deletion origi—
nated from the 1000 Genomes Project and observed that the 1000
Genomes deletions that are part of such a pair are strongly enriched
for events called in Caucasian individuals, which is consistent with
Craig Venter’s ancestry (see Section C in the Supplement for details).
We are thus confident that our false positive rate is low. Based on
the evidence presented in this section, we conclude that ad—hoc crite—
ria alone are insufficient when it comes to creating consensus call
sets from multiple, individual call sets.

3.3 Pairwise comparison of call sets

We evaluated our matching approach by identifying duplicates
among the call sets from the four tools mentioned above (Venter
Predictions) and also by identifying duplicates among the individual
call sets and the true annotations.

Tools versus ‘Truth’. As outlined above, for each pair of sets of dele—
tions, we consider a graph where nodes are calls and edges are
drawn if two deletions are (la, leT)—similar, where la refers to the tool
in use and leT refers to the ‘Truth’. Thereby, we fix leT to 10—since
the ‘Truth’ has been determined experimentally, it may be prone to
inaccuracies itself, which justifies a choice of [QT larger than zero.
However, we vary la, so as to explore the corresponding effects for
the different tools. As shown in Figure 3, the running times for
determining similarity and performing the matching increase ap—
proximately linearly from about 65 for 13:0 for each dataset to,

 

 

 

 

 

 

 

 

A
7'0’? a — A/ /El
8 o _ / /121
8 N A D/El
59, In A/ D/
GE) 1— — 9% EI/
-.: o _ a D/ —EI— Breakdancer
E I—  DO/ —A— Clever
E ,0 _ @0969 —e— Pindel
E —e— Platypus
o _
I I I I I
0 50 100 150 200
k(k_T=10)

Fig. 3. Running times on a standard laptop (2 GHz, 8 GB memory) for deter-
mining similarity and performing the matching for the Venter dataset, not
including ~50 s for reading the reference sequence once

 

 

 

 

 

 

 

 

 

 

 

0. _
‘— —EI— Breakdancer
—A— Clever
00 —e— Pindel
o' — —e— Platypus
0000000
9 3 — A/A’A
53 A/
8 A/
f
V. _
LI. o 000 000 D D D
I:‘/—l:|
D/
N _ /
o' A /I:I
I:I
0. _ n/
O
I I I I I
0 50 100 150 200

k (k_T=10)

Fig. 4. F-measure for callsets of different tools compared with truth (Venter
dataset). Predictions have been compared with varying neighborhood sizes
to the truth with a fixed neighborhood size of kT=10. Precision and recall
have been determined by the matching approach described in Section 2.2
and are shown in Section D in the Supplement

e.g. ~26 s for the Clever set of size 7473 with la : 100, not including
~50 s for initial imports of the reference sequence. Results are
shown in Figure 4 and Supplement D. We observe that, first, both
precision and recall, and thus F—measure, approach a stable value
for increasing la and, second, the speed and the limit of this trend dif—
fer between the tools. The two insert size based approaches, Clever
and Breakdancer, reach their limits slower (in la) than Pindel and
Platypus, which are split—read aligners, hence are more accurate.
The limits, in turn, give evidence of the quality of the call sets.

For further analyses of the different datasets, we determined the
minimum value of la (in steps of 10) for which the F—measure exceeds
95 % of its limit. This method is also included in our software pack—
age READDI. For the Clever data, we obtained la : 60 and for
Breakdancer la : 120. For Pindel and Platypus, the above procedure
yielded la : 0. To nevertheless allow for some minimum ﬂexibility, we
chose la : 10 for these data sets in all experiments reported below.

Choice of criteria: (k1, k2)-similarity versus overlap. We ran our
matching algorithm both using similarity as edge criterion and defin—
ing similarity by 5 0% reciprocal overlap, which reﬂects a naive, but
popular criterion for comparing results and merging duplicate calls
(Lam et al., 2012; Malhotra et al., 2013; Teer et al., 2013; The 1000
Genomes Project Consortium, 2010).

Figure 5 shows Venn diagrams for Clever and Pindel predictions.
The amount of duplicates identified varies drastically between the

91% ‘09 1sn8nv uo sojeﬁuv s01 ‘BTUJOJTIBQ 10 Amie/nun 112 /§.IO'SIBU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(11111 U101} pop1201umoq

 

is based on similarity, where we used Word order: k: 10 for Pindel and

 

 

 

 

 

 

 

 

Repeat— and error-aware comparison of deletions 2953
. O
Clever Pindel Clever Pmdel 3 - - 8
(k=60) (k=10) + Similarity — precision ‘0
00 —e— Overlap — precision _ a)
c; —  Similarity— recall g
= I  was, Overlap — recall ! /_! o E
g Q _ O\i,x: number of deletions .3? e  — § 
8 O  /0\./2"i   — E)
:2, a " i  i  o I  E 8
0 o' — o o \-- g  : ‘ ' ‘ I ~ I' 0 ~—
&’ ° e - $0 / \ — 8 3
Fig. 5. Venn diagrams comparing deletion predictions on the Venter dataset O “ O 0\o '- g
(\l
by Clever and Pindel. The numbers of common and unique deletions are 0 _ _ a?) g
determined by counting the components resulting from running the matching
algorithm (see Section 2.3). Diagram (a) is based on matchings of predictions  — I I I I I I I I I I I I I — 0
where the edges are defined by a reciprocal overlap of 50% and Diagram (b) m o o o o o o o o o o x x
‘1' ‘1’ “I” “i ‘1’ ‘1’ 52 E 8 8 8 ‘7 52
o I I I I l
(\l

k: 60 for Clever. Note that, due to the abovementioned usage of compo-
nents, the total number of calls differs slightly between the diagrams

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

0. _
E w . " <>'
LL . _ .
+ o 3'
o. _-
L: to 3
E o' _ g A
l— I;
g :- - _.-" D / I Breakdancer—overI./k=120
.9 _.-" A” A / A CIever—overI./k=60
8 3 —  <>/ o Pindel—overI./k=10
9 D O / 0 PIatypus—overl /k=10
o. q _ -
o I I I I I I
0.0 0.2 0.4 0.6 0.8 1.0
Recall = TP/(TP+FNC)
S — 0
E2
(1)
“r o' — o ___,- A
E w. _ A”
ﬂ 0 III.-
2 :- - D / I Breakdancer—overI./k=120
.9 A / A CIever—overI./k=60
'8 2 — <>/ o Pindel—over|./k=10
g o O / 0 PIatypus—overI./k=10
d _ I I I I I I
0.0 0.2 0.4 0.6 0.8 1.0

Recall = TP/(TP+FNC)

Fig.6. Effect of using our similarity criterion instead of 50% reciprocal overlap
for comparing precision and recall of different tools with respect to Venter
Truth (separated by deletion size). Lines connect corresponding statistics for
the two criteria. Recall has been determined by comparing all predictions to
only small or large true deletions, resp. Precision has been determined by
comparing only small or large predictions, resp., to all true deletions. The
used definition of neighborhood for the tools is given in the legend. For
‘truth’, k: 10 has been chosen

two different criteria, where the similarity criterion detects substan—
tially more duplicates than the overlap criterion, 3225 common calls
compared with 2193 (47.1 % more). When comparing Pindel to
Breakdancer and Clever to Breakdancer, we observe an increase in
the number of common calls of 49.1 % and 60.0 %, respectively
(see Venn diagrams in Section E of the Supplement). As we demon—
strated in Section 3.2, the false discovery rate of our similarity criter-
ion is rather negligible, which points out that overlap leaves
substantial amounts of common calls unidentified.

Figure 6 shows precision/recall plots for evaluating the tools rela—
tive to the two criteria. The results demonstrate that the choice of
criterion can distort qualitative statements about the accuracy of
call sets substantially. For example, Breakdancer and Clever per—
form worse than Pindel under the overlap criterion, whereas they
perform better than Pindel in the length range 41—10K under the
similarity model. These comparisons demonstrate that a sound def—
inition of two predictions ‘being the same’ is crucial for the purposes
of evaluating SV discovery tools.

I
Size range (bp)

Fig. 7. Comparison of the consensus sets based on (k, k)-similarity and based
on 50% reciprocal overlap to the ‘truth'. Precision (TP/(TP+FP)) and recall
(TP/(TP+ FN)) are stated in terms of deleted bases

3.4 Model accuracy
To gather additional evidence that our model is superior to the over—
lap criterion, we performed the following experiment.

We computed all pairs of similar deletions within and between
the call sets of the three tools Breakdancer, Clever and Pindel. For
each connected component in the resulting graph of deletions, we
replaced all similar deletions by one representative, favoring predic—
tions by Pindel over those by Clever over those by Breakdancer and
favoring left deletions over right. In the end, 11 095 of 16 813 dele—
tions were left in the consensus set. We repeated the above steps
defining edges by 5 0% reciprocal overlap instead of by our model of
similarity and obtained a consensus of 12 947 deletions.

To assess the two consensus sets by a method independent of the
two criteria, we compare them to the ground truth on single-nucleo-
tide level. That is, for each nucleotide that is part of a deletion in
each consensus set, we determine whether it is also part of a deletion
in Venter Truth. On that basis, we compute recall and precision for
the two consensus sets, stratified by deletion length ranges. This
stratification is important as not to skew statistics towards longer
deletions. Results are visualized in Figure 7.

Although the consensus set based on similarity was by 14.3 %
smaller than the one based on overlap (11 095 versus 12 947 dele—
tions), recall was virtually the same across all length ranges. The pre-
cision of our model was higher across all size ranges and the
difference is especially large for medium size deletions (100—200
bases), where similarity outperforms overlap by about 20 percentage
points. We hypothesize that flexibility plays an important role espe—
cially in this range, because split read approaches lose predictive
power while deletions of a few hundred bases are usually detected
with some inaccuracy by paired—end mapping approaches. Further,
shifts can be large in this length range in comparison to the deletion
size—covered by (la, la)—similarity but not by the overlap criterion.

4 Conclusions

The above analyses show that a mistaken ansatz to duplicate identifi—
cation can have negative effects. We have pointed out that repeats lead
to ambiguities that have the potential to introduce errors. We have
also pointed out that the quality of breakpoint predictions can vary
substantially among variant discovery tools, which can equally hamper
the identification of duplicates among deletion calls. In the light of
increasing amounts of projects that aim at large—scale discovery of gen—
etic variants in populations or in diseased cells, sound standardization
and consistency among calls reported is an urgent and vital issue.

91% ‘09 1sn8nv uo sopﬁuv s01 ‘BIUJOJIIBD 10 Amie/nun 112 /§.IO'SIBU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(11111 U101} pop1201umoq

2954

R. Witt/er et al.

 

To overcome this, we have presented a framework that accounts for
repeat—aware and error—tolerant duplicate identification, hence soundly
captures both error sources. We have devised a maximum matching algo-
rithm that can make use of this framework, and which one can employ
to spot duplicates among deletions. As we demonstrated, the algorithm
operates at negligible false discovery rates. Thereby, it outperforms
ad—hoc criteria, such as 5 0% reciprocal overlap substantially.

As future work, we will invest in adjusting our framework,
which is generic in its core ideas, to other variant types. Including in—
sertions, although being the reversal process of deletions, is not
straightforward. The complexity arises from the difference that a de—
letion is uniquely described by its coordinates, but in contrast, an in—
sertion prediction also includes the inserted sequence. In particular,
allowing for small errors in the predictions is not trivial. Another
interesting, and potentially promising line of research is to integrate
allele frequency related statistics, likely as a postprocessing step.
Moreover, it may be interesting to study selecting la not only condi—
tioned on the method in use, but also on coverage and/or on locus,
and combinations thereof, in a sound machine learning framework.

Funding

R.W. is partially funded by the International DFG Research Training Group
‘Computational Methods for the Analysis of the Diversity and Dynamics of
Genomes’, GRK 1906/1. AS is funded by the Dutch Scientific Organization
(NWO) through Vidi grant 639.072.309. V.M. is partially funded by the
Finnish Centre of Excellence in Cancer Genetics Research (grant 250345) and
the Finnish Cultural Foundation.

Conﬂict of Interest: none declared.

References

Alkan,C. et al. (2011) Genome structural variation discovery and genotyping.
Nat. Rev. Genet., 12, 363—376.

Assmus,]. et al. (2013) Equivalent indels—ambiguous functional classes and re-
dundancy in databases. PLOS ONE, 8, e62803.

Chen,K. et al. (2009) Breakdancer: an algorithm for high-resolution mapping
of genomic structural variation. Nat. Methods, 6, 677—6 81.

Danecek,P. et al. (2011) The variant call format and VCFtools.
Bioinformatics, 27, 2156—2158.

Earl,D. et al. (2011) Assemblathon 1: A competitive assessment of de novo
short read assembly methods. Genome Res., 21, 2224—2241.

Giegerich,R. et al. (1999) An algebraic dynamic programming approach to the
analysis of recombinant DNA sequences. In: Workshop on Algorithmic
Ascpects of Advanced Programming Languages (WAAAPL), pp. 77—88.

Gusﬁeld,D. and StoyeJ. (2004) Linear time algorithms for ﬁnding and representing
all the tandem repeats in a string. ]. Comput. Syst. Sci, 69, 525—546.

Hubbard,T. et al. (2002) The ensembl genome database project. Nucleic Acids
Res., 30, 38—41.

Krawitz,P. et al. (2010) Microindel detection in short-read sequence data.
Bioinformatics, 26, 722—729.

Lam,H.Y. et al. (2012) Detecting and annotating genetic variations using the
hugeseq pipeline. Nat. Biotechnol, 30, 226—229.

Landau,G.M. and Vishkin,U. (1989) Fast parallel and serial approximate
string matching. ]. Algorithms, 10, 15 7—1 69.

Levy,S. et al. (2007) The diploid genome sequence of an individual human.
PLOS Biol, 5, e254.

Lunter,G. et al. (2008) Uncertainty in homology inferences: assessing and im-
proving genomic sequence alignment. Genome Res., 18, 29 8—309.

Makinen,V. and Rahkola,]. (2013) Haploid to diploid alignment for variation
calling assessment. BMC Bioinformatics, 14, 813.

Malhotra,A. et al. (2013) Breakpoint proﬁling of 64 cancer genomes reveals
numerous complex rearrangements spawned by homology-independent
mechanisms. Genome Res., 23, 762—776.

Marschall,T. et al. (2012) CLEVER: clique-enumerating variant ﬁnder.
Bioinformatics, 28, 2875—28 82.

Marschall,T. et al. (2013) MATE-CLEVER: Mendelian-inheritance-aware
discovery and genotyping of midsize and long indels. Bioinformatics, 29,
3143—3150.

MedvedeV,P. et al. (2009) Computational methods for discovering structural
variation with next-generation sequencing. Nat. Methods, 6, 813—820.

Raphael,B.]. (2012) Structural variation and medical genomics. PLoS
Comput. Biol, 8, e1002821.

Rimmer,A. et al. (2014) Integrating mapping-, assembly-and haplotype-based
approaches for calling variants in clinical sequencing applications. Nat.
Genet., 46, 912—918.

Sherry,S. et al. (2001) dbSNP: the NCBI database of genetic variation. Nucleic
Acids Res., 29, 308—1 1.

Teer,].K. et al. (2013) Massively-parallel sequencing of genes on a single
chromosome: a comparison of solution hybrid selection and ﬂow sorting.
BMC Genomics, 14, 253.

The 1000 Genomes Project Consortium (2010) A map of human genome vari-
ation from population-scale sequencing. Nature, 467, 1061—1073.

The Genome of the Netherlands Consortium (2014) Whole-genome sequence
variation, population structure and demographic history of the Dutch popu-
lation. Nat. Genet., 46, 818—825.

Treangen,T. and Salzberg,S. (2012) Repetitive DNA and next-generation
sequencing: computational challenges and solutions. Nat. Rev. Genet., 13,
55 7—5 67.

Trubetskoy,V. et al. (2015) Consensus genotyper for exome sequencing
(CGES): improving the quality of exome variant genotypes.
Bioinformatics, 31, 187—193.

Xi,R. et al. (2010) Detecting structural variations in the human genome using
next generation sequencing. Brief Funct. Genomics, 9, 405—415.

Ye,K. et al. (2009) Pindel: a pattern growth approach to detect break points of
large deletions and medium sized insertions from paired-end short reads.
Bioinformatics, 25, 2865—2871.

Zhang,]. et al. (2006) Development of bioinformatics resources for display
and analysis of copy number and other structural variants in the human gen-
ome. Cytogenet. Genome Res., 115, 205—214.

91% ‘09 1sn8nv uo sopﬁuv s01 ‘BIUJOJIIBD 10 Amie/nun 112 /§.IO'SIBU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(11111 U101} pop1201umoq

