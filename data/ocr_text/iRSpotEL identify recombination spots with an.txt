Bioinformatics Advance Access published August 16, 2016

 

Sequence analysis

iRSpot-EL: identify recombination spots with
an ensemble learning approach
Bin Liu1’2’3*, Shanyi Wang1,Ren Longl, Kuo-Chen Chou3’4

1 School of Computer Science and Technology, Harbin Institute of Technology Shenzhen Graduate School,
Shenzhen, Guangdong 5 1805 5, China. 2 Key Laboratory of Network Oriented Intelligent Computation, Harbin
Institute of Technology Shenzhen Graduate School, Shenzhen, Guangdong 518055, China.3 Gordon Life Sci-
ence Institute, Belmont, Massachusetts02478, USA.4 Center of Excellence in Genomic Medicine Research
(CEGMR), King Abdulaziz University, Jeddah 21589, Saudi Arabia

*To whom correspondence should be addressed.
Associate Editor: Dr. John Hancock

Abstract

Motivation: Coexisting in a DNA system, meiosis and recombination are two indispensible aspects
for cell reproduction and growth. With the avalanche of genome sequences emerging in the post-
genomic age, it is an urgent challenge to acquire the information of DNA recombination spots be-
cause it can timely provide very useful insights into the mechanism of meiotic recombination and the
process of genome evolution.

Results: To address such a challenge, we have developed a predictor, called iRSpot—EL, by fusing
different modes of PseKNC (pseudo K—tuple nucleotide composition) and mode of DACC (dinucleo-
tide-based auto-cross covariance) into an ensemble classifier of clustering approach. 5 fold cross
tests on a widely used benchmark dataset have indicated that the new predictor remarkably outper-
forms its existing counterparts. Particularly, far beyond their reach, the new predictor can be easily
used to conduct the genome-wide analysis and the results obtained are quite consistent with the ex-
perimental map.

Availability: For the convenience of most experimental scientists, a user-friendly web-server for iR-
Spot-EL has been established at http://bioinformatics.hitsz.edu.cn/iRSpot—EL/, by which users can
easily obtain their desired results without the need to go through the complicated mathematical equa-
tions involved.

Contact: bliu@qordon|ifescience.orq or bliu@insun.hit.edu.cn

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

 

1 Introduction

Recombination plays an important role in genetic evolution, which de-
scribes the exchange of genetic information during the period of each
generation in diploid organisms. Recombination provides many new
combinations of genetic variations and is an important source for biodi-
versity, which can accelerate the procedure of biological evolution.
Knowledge of recombination spots may also provide very useful infor-
mation for in-depth understanding the reproduction and growth of cells.
Therefore, it is highly demanded to develop computational methods for
predicting the recombination spots.

Actually, many efforts have been made in this regard. For instance,
based on the gapped dinucleotide composition features, Jiang et a1.
(Jiang et al., 2007) developed a predictor called RF-DYMHC to do the
job. Liu et a1. (Liu et al., 2012), using the kmer approach and the incre-
ment of diversity combined with quadratic discriminant analysis, devel-
oped the IDQD predictor for the same purpose. In the above two predic-
tors, however, only the local DNA sequence information was utilized,
and hence their prediction quality may be limited. To improve this situa-
tion, recently two new predictors, iRSpot-PseDNC (Chen et al., 2013)
and iRSpot-TNCPseAAC (Qiu et al., 2014) were developed. The former
was based on the DNA local structural properties (Chen et al., 2012) and
pseudo dinucleotide composition (Chen et al., 2014); while the latter

© The Author (2016). Published by Oxford University Press. All rights reserved. For Permissions, please email:

journals.permissions@oup.com

9mg ‘09 1sn8nV uo seleﬁuV s01 ‘BIIIJOJHBQ JO AusmAru [1 112 ﬁlm'spaumo[pJOJXO'sonemJogurorq/ﬁd11q urog pepeolumoq

 

based on the DNA trinucleotide composition (Chen et al., 2014) as well
as the corresponding pseudo amino acid components (Chou, 2001).

Each of the aforementioned methods has its own advantage, and did
play a role in stimulating the development of this important area. Mean-
while, they also have some disadvantages, as reﬂected by the following
facts. (1) Although powerful predictors have been proposed, there is no
efﬁcient approach to combine them to further improve the predictive
performance. (2) None of these methods allows users to set the desired
parameters for prediction, and hence it is difﬁcult for them to optimize
the predictor system according to the need of their focus. (3) Except the
RF-DYMHC (Jiang et al., 2007), all the other predictors cannot be di-
rectly used for genome-wide analysis. Even for the RF-DYMHC predic-
tor, its approach is not accurate because the window size therein is arbi-
trary.

The current study was initiated in an attempt to address these
shortcomings by developing a more powerful predictor for identifying
DNA recombination spots. The proposed predictor is called iRSpot—EL,
where “i” stands for “identify”, “RSpot” for “recombination spot”, and
“EL” for “ensemble learning”.

To develop a new predictor usually consists of two purposes. One is to
stimulate theoretical studies in the relevant areas, and the other is to
make experimental scientists easier to get their desired information. To
realize these, the rest of this article is presented according to the
following ﬁve guidelines (Chou, 2011): (1) benchmark dataset, (2)
sample representation, (3) operation algorithm, (4) validation, and (5)
web-server.

2 MATERIALS AND METHOD

2.1 Benchmark Dataset

A reliable and stringent benchmark is pivotal to the development of an
accurate prediction method. In literature, the benchmark dataset usually
consists of a training dataset and a testing dataset: the former is for the
purpose of training a proposed model, while the latter for the purpose of
testing it. As pointed out by a comprehensive review (Chou and Shen,
2007b), however, there is no need to separate a benchmark dataset into a
training dataset and a testing dataset for validating a prediction method if
it is tested by the jackknife or subsampling (K-fold) cross-validation
because the outcome thus obtained is actually from a combination of
many different independent dataset tests. In this study, for facilitating
the comparison of the proposed predictor with the existing ones, we
adopted the widely used benchmark dataset (Chen et al., 2013; Jiang et
al., 2007; Liu et al., 2012; Qiu et al., 2014) that can be formulated as

S = S+US‘ (1)
where S is the benchmark dataset, 8+ the positive subset containing 490
DNA segments (hotspot samples) with the relative hybridization ratios
(Gerton et al., 2000) higher than 1.5 (Jiang et al., 2007), S‘ the negative
subset containing 591 DNA segments (coldspot samples) with the rela-
tive hybridization ratios (Gerton et al., 2000) lower than 0.82 (Jiang et
al., 2007), and the symbol U denotes the union in the set theory. In order
to reduce redundancy and homology bias, the CD-HIT software (Li et al.,
2001) was used to remove sequences whose similarity is higher than
75%. Finally, 478 hotspots (positive samples) and 572 coldspots (nega-
tive samples) were obtained. For readers’ convenience, the 478 hotspot
samples and 572 coldspot samples as well as their detailed sequences are
given in Supporting Information 81.

2.2 Pseudo k—tuple nucleotide composition (PseKNC)

With the avalanche of biological sequences emerging in the post-
genomic age, one of the most challenging problems in computational
biology is how to formulate a biological sequence with a vector, yet
essentially still keep its key pattern or characteristics. This is because
nearly all the existing machine-leaming algorithms were developed to
handle vector but not sequence samples, as elaborated in a recent review
(Chou, 2015). Unfortunately, a vector deﬁned in a discrete model may
completely lose all the sequence-order information or sequence pattern
characteristics. To overcome such a problem for protein/peptide se-
quences, the pseudo amino acid composition (PseAAC) (Chou, 2001)
was introduced, and has become an important tool (Cao et al., 2013; Du
et al., 2014; Du et al., 2012) widely used in nearly all the areas of com-

putational proteomics (see a long list of references cited in (Chou, 2011)).

Encouraged by the successes of PseAAC, the pseudo nucleotide compo-
sition (PseKNC) (Chen et al., 2014; Chen et al., 2015b; Liu et al., 2015a;
Liu et al., 2016b) was introduced to formulate DNA/RNA sequences,
and it has been increasingly used in computational genetics and ge-
nomics (see, e.g., a recent review (Chen et al., 2015a) as well as a long
list of references cited therein). Recently, a web-server called “Pse-in-
One” was developed for generating various modes of pseudo compo-
nents for DNA/RNA and protein/peptide sequences (Liu et al., 2015b).

Here the concept of PseKNC was used to deﬁne the feature vectors for
identifying recombination spots via 15 indices (Table 1) of local DNA
structural properties, which were selected ﬁom (Friedel et al., 2009).
Note that PseKNC model contains three uncertain parameters: k is the
number of neighboring nucleic acid residues; 9» is the highest ranks or
tiers (Chou, 2005); w is the weight factor. These three parameters will be
discussed in the Ensemble Learning Section.

2.3 Dinucleotide—based auto-cross covariance (DACC)

In this study, the DNA sequences were generated by a very special mode
of PseKNC (Liu et al., 2015b), the so-called DACC approach, which is a
combination of dinucleotide-based auto covariance (DAC) and dinucleo-
tide-based cross covariance (DCC). The former is based on a same phys-
icochemical property listed in Table 1; while the latter, based on two
different ones. Note that there is one shift parameter lag in the DACC, as
will be discussed later.

2.4 Support vector machine (SVM)

Support vector machine (Suykens and Vandewalle, 1999) is an efﬁcient
supervised learning approach in the ﬁeld of machine learning, and has
been widely used for classiﬁcation and regress analysis. The basic idea
of SVM is to transform the input data into a high dimensional feature
space and then determine the optimal separating hyperplane. For more
details about SVM, see (Cristianini and Shawe-Taylor, 2000; Vapnik,
1999).

In the current study, the LIBSVM package (Chang and Lin, 2001)
with RBF kernel was used to implement SVM, in which there are two
parameters: one is the regularization parameter C, and the other is the
kernel width parameter 7). Thus, there are a total of ﬁve uncertain param-
eters when using SVM on the PseKNC model, while three uncertain
parameters on the DACC model. All these parameters were optimized on
the validation sets

9mg ‘09 isnﬁnV uo seleﬁuV s01 ‘BIIIJOJHBQ JO AiiSJQAiu [1 112 ﬁlm'spaumo[pJOJXO'sonemJoguioiq/ﬁdnq moi; pepeolumoq

Table 1. The values of the ﬁfteen DNA dinucleotide properties

 

 

Structural

index AA/TT AC/GT AG/CT AT CA/TG CC/GG CG GA/TC GC TA
F-roll 0.04 0.06 0.04 0.05 0.04 0.04 0.04 0.05 0.05 0.03
F-tilt 0.08 0.07 0.06 0.10 0.06 0.06 0.06 0.07 0.07 0.07
F-twist 0.07 0.06 0.05 0.07 0.05 0.06 0.05 0.06 0.06 0.05
F-slide 6.69 6.80 3.47 9.61 2.00 2.99 2.71 4.27 4.21 1.85
F-shift 6.24 2.91 2.80 4.66 2.88 2.67 3.02 3.58 2.66 4.11
F-rise 21.34 21.98 17.48 24.79 14.51 14.25 14.66 18.41 17.31 14.24
Roll 1.05 2.01 3.60 0.61 5.60 4.68 6.02 2.44 1.70 3.50
Tilt -1.26 0.33 -1.66 0.00 0.14 -0.77 0.00 1.44 0.00 0.00
twist 35.02 31.53 32.29 30.72 35.43 33.54 33.67 35.67 34.07 36.94
Slide -0.18 -0.59 -0.22 -0.68 0.48 -0.17 0.44 -0.05 -0.19 0.04
Shift 0.01 -0.02 -0.02 0.00 0.01 0.03 0.00 -0.01 0.00 0.00
Rise 3.25 3.24 3.32 3.21 3.37 3.36 3.29 3.30 3.27 3.39
Energy -1.00 -1.44 -1.28 -0.88 -1.45 -1.84 -2.17 -1.30 -2.24 -0.58
Enthalpy -7.60 -8.40 -7.80 -7.20 -8.50 -8.00 -10.60 -8.20 -9.80 -7.20
Entropy -21.30 -22.40 -21.00 -20.40 -22.70 -19.90 -27 .20 -22.20 -24.40 -21.30

 

2.5 Ensemble Learning

As demonstrated by a series of previous studies, such as protein fold
pattern recognition (Shen and Chou 2006), membrane protein type clas-
siﬁcation (Chou and Shen, 2007a), signal peptide prediction (Shen and
Chou, 2007a), protein subcellular location prediction (Chou and Shen,
2008), enzyme functional classiﬁcation (Shen and Chou, 2007b),
identifying phosphorylation sites (Qiu et al., 2016b) and multiple lysine
PTM sites in proteins (Qiu et al., 2016a), the ensemble predictor formed
by fusing an array of individual predictors via a voting system can yield
much better prediction quality.

There are two main components in the ensemble learning framework:
1) How to select the basic classiﬁers? 2) How to ensemble the basic
classiﬁers so as to make the ﬁnal prediction? In order to select the repre-
sentative basic classiﬁers, the distance between any two classiﬁers (C(i)
and (CO) was measured by the following equation considering both the
diversity and complementarity of the classiﬁers:

1 m
Distance((C(i), (1:0)) = 1 — %;(dikAdJ-k) (2)

where m represents the number of training samples, dik represents the
misclassiﬁcation probability of classiﬁer (EU) on the k-th sample, and
dikAdJ-k can be calculated by:

2 S k S 6 withstepA= 1
OSw31 withstepA=0.1 (4)
1 SAS 10 withstepA= 1
Likewise, 10 different DACC classiﬁers were generated with different
values of lag (lag = 1, 2, ..., 10). By using the aforementioned methods,
510 different classiﬁers were obtained, which were then clustered into
seven clusters by using the afﬁnity propagation clustering (Frey and
Dueck, 2007). For each cluster, the top performing one was selected. For
the current study, the ensemble classiﬁer can be formulated by (see
Table 2)

(CE = (C(1)V(C(2)(C(3)V(C(4)V(C(5)V(C(6)V(C(7) = Vi7=1(C(i) (5)

where (CE denotes the ensemble classiﬁer, the symbol V denotes the
fusing operator (Chou and Shen, 2007b), and the fusion was operated via
the following fractional votes

7
1
i=1

where P,- denotes the probability ﬁom the classiﬁer (EU), and Ft its frac-

tion used, which was optimized on the validation sets (see Table 2). If Y >

0.5, the sample is predicted as a hotspot; otherwise, coldspot.

For more detailed about the process of fusing individual basic classiﬁ-
ers into an ensemble classiﬁer, see a comprehensive review (Chou and
Shen, 2007b) where a crystal clear elucidation with a set of elegant equa-

dikAdjk = tions are given and hence there is no need to repeat here.
{dik + djk, if (Ca) and (C0) incorrectly predicts the kth sample (3) The ﬂowchart of ensemble strategy on different clustering is given in
0, otherwise Fig-1-

The range of the distance deﬁned in Eq. 2 is from 0 to 1, where a dis-
tance of 1 indicates the predictive results of two classiﬁers are complete-
ly complementary, and 0 means that their results are identical. Based on
the distance, the afﬁnity propagation clustering algorithm (Frey and
Dueck, 2007) was employed, which is quite suitable for the current task
since the center clusters are not required in this algorithm.

For the PseKNC (Chen et al., 2014), different values of l», k, and w
will correspond to different input types. In the present study, 500 differ-
ent PseKNC classiﬁers were constructed by using the following parame-
ter combinations:

2.6 Cross-Validation

Three cross-validation methods are often used in literature; they are
independent dataset test, K-fold cross-validation test, and jackknife test
(Chou and Zhang, 1995).

In this study, the ﬁve-fold cross-validation was used. The benchmark
dataset was randomly divided into ﬁve subsets with an approximately
equal number of samples. Each predictor runs ﬁve times with ﬁve differ-
ent training and test sets. For each run, three sets were used to train the

9mg ‘09 1sn8nV uo seleﬁuV s01 ‘121u10111123 10 A1is19Aiuf1 112 /810's112umo[p101x0'soi112u1101uioiq/ﬁd11q 111011 pepeolumoq

 

Table 2. List of the seven basic classiﬁers selected by using afﬁnity
propagation clustering algorithm

 

 

Basic classiﬁer Feature Dimension Fraction
(C(1) PseKNCa 20 0.25
(C(Z) PseKNCb 22 0.05
(C(3) PseKNCc 26 0.10
(C(4) PseKNCd 26 0.00
(C(5) PseKNCe 67 0.05
(C(6) PseKNCf 72 0.05
(C(7) DACCg 1125 0.50

 

a The optimal parameters were k=2, 9» =4, w=0.5.
b The optimal parameters were k=2, 9» =6, w=0.8.
° The optimal parameters were k=2, 9» =10, w=0.9.
d The optimal parameters were k=2, lt=10, w=1.0.
e The optimal parameters were k=3, 9» =3, w=0.8.
fThe optimal parameters were k=3, 9» =8, w=0.9.
g The optimal parameter was lag=5.

 

[ Input DNA sequences ]
Constructing 510 classiﬁers‘based on PseKNC and DACC
[ (C(1), (C(2),  , (C(510) ]
Clustering into 7 clusters based‘on afﬁnity propagation clustering

 

 

 

 

 

[Clusterl] Cluster“ [ Clus-teﬁ  Cluster4 ]LCluster5  Cluster“  Cluster" ]

Seleiting tht] top erforrning, classiﬁer,» in each ,L cluster 1
|_ 11(1) ll 6(2) ll 12(3) |[ (£14) ][ «2(5) ][ «2(6) ][ 1:0) ]
F11 F21! F31 F51! Fair F7114

F4

 

 

    
  
     

Figure l. A ﬂowchart to show how the iRSpot—EL predictor works.

predictor, one set was used as the validation set to optimize the parame-
ters, and the remaining one was used as the test set to give the ﬁnal re-
sults.

2.7 Metrics Used to Reﬂect the Success Rates

For a binary classiﬁcation system such as the one in the current study,
the following set of four metrics are often used to quantitatively measure
the quality of a predictor (see, e.g., (Guo et al., 2014; Jia et al., 2016; Liu
et al., 2016c; Qiu et al., 2016a))

r +

 

 

 

Sn=1—N—_+ OSSn31
N+
Sn=1—N—_+ OSSp31
N_++N_
i ACC=1—W1Vt 0<ACC<1 
+ _
1_(%+%)
MCC: N_ N+ N+ N_ —1SMCCSl
+_ — —_ +
1 (0+ N+ )(1+ N— )

where Sn, Sp, Ace, and MCC represent sensitivity, speciﬁcity, overall
accuracy, and Mathew’s correlation coefﬁcient, respectively (Chen et al.,

2007). The total numbers of recombination hotspots and coldspots are
denoted by N + and N ‘, respectively. The number of hotspot samples
incorrectly predicted to be of coldspot is denoted by Ni, while the num-
ber of coldspot samples incorrectly predicted to be of hotspot is by N_+ .
As for the meanings of the four metrics in Eq.7 along with their score
regions, see (Lin et al., 2014) where a clear and incisive analysis has
been elaborated and hence there is no need to repeat here.

2.8 F-Score

The F -score can be calculated by using the following equation:

F _ (if) 402 + (if) 402 (8)
i _ 1 _ 1 — _ _ —
n. _ 1211:1098? — x§+))2 + n_ _ 1221:1092.) — x? 52

where n+ stands for the total number of the positive samples, n‘ for the

 

 

 

total number of the negative samples, it”) for the mean value of the i-th
feature of entire positive samples, EH for the mean value of i-th feature
of entire negative samples, it for the mean value of the i-th feature of
the total samples. 36$? for the value of the i-th feature of the k-th sample
in the positive data set, and 39$? for the value of the i-th feature of the k-

th sample in the negative data set. The larger the F—score is, the more
important the feature is (Akay, 2009).

3 RESULTS AND DISCUSSION

3.1 Comparison with Basic Methods and Existing Methods

Listed in Table 3 are the ﬁve-fold cross-validation results by iRSpot—EL
on the benchmark dataset of Eq.1 (see Supporting Information Sl). For
facilitating comparison, listed in that table and Fig. 2 are also the corre-
sponding results obtained by the RF-DYMHC predictor (Jiang et al.,
2007), IDQD predictor (Liu et al., 2012), iRSpot-PseDNC predictor
(Chen et al., 2013), and iRSpot-TNCPseAAC (Qiu et al., 2014).

From the table, we can see the following. (1) Among the ﬁve predic-
tors the newly proposed one achieved the highest success rates in both
Ace and MCC, the two most important metrics used to measure the
quality of a predictor as elucidated in the follow-up text to Eq.7. (2)
Although the Sn rate by the proposed predictor was about 4% lower than
that by IDQD, its Sp rate was about 7% higher than that by IDQD. As
mentioned in Section 2.7, the two metrics are used to measure a predictor
ﬁom two opposite angles, and they are constrained with each other.
Therefore, it is meaningless to use only one of the two for comparing the
quality of two predictors. In other words, a meaningful comparison in
this regard should count the rates of both Sn and Sp, or even better, the
rate of their combination that is none but MCC. As shown in Table 3,
the MCC rate achieved by the proposed predictor iRSpot—EL is higher
than other existing predictors by about 3.5%-17.7%.

3.2 Feature Analysis

In order to further investigate the discriminant power of different fea-
tures and basic classiﬁers, the F—score method (Lin et al., 2014) was
adopted to analyze the seven basic classiﬁers listed in Table 2.

The top 10 most important features for each basic classiﬁer are listed
in Table 4, ﬁom which we can see that the important features between
PseKNC and DACC classiﬁers are different, indicating that these classi-
ﬁers are mutually complementary. Therefore, performance improvement

9mg ‘09 1sn8nV uo seleﬁuV s01 ‘121u10111123 10 A1is19Aiuf1 112 ﬁlo's112umo[p101x0'soi112u1101uioiq/ﬁd11q 111011 pepeolumoq

Table 3. List of the metrics scores (cf. Eq.7) obtained by various meth-
ods via 5-fold cross-validation on the same benchmark dataset of Sup-
porting Information 81

 

Methods Sn(%)f Sp(%)f Acc(%)f MCCf AUCg

 

RF-DYMHCa 73.01 86.56 80.40 0.6049 0.8777
IDQDb 79.52 81.82 80.77 0.6160 0.8822

iRSpot-

PSCDNC. 71.75 85.84 79.33 0.5830 0.8631
iRSpot-

TNCPSCAAC, 76.56 70.99 73.52 0,4737 0,8138
iRSpot-ELe 75.29 88.81 82.65 0.6510 0,8922

 

a The predictor reported in (J iang et al., 2007).
b The predictor reported in (Liu et al., 2012).

c The predictor reported in (Chen et al., 2013).
d The predictor reported in (Qiu et al., 2014).

e The proposed predictor in this paper.

f See Eq.7 for the metrics deﬁnition.

g See Fig.2 and its legend

can be observed by combining these classiﬁers via an ensemble learning
approach. Some common patterns can also be observed, for examples,
CG, AT, TA, GC are very important for all the six PseKNC classiﬁers,
which is fully consistent with Jiang et al‘s study (Jiang et al., 2011).

 

 

 

 

 

 

 

 

100%
B 80%
CG
i—t
CD
> 60%
'5
.'—1 —
w " .
840% — _.
g - g  — iRSpot-EL
'   ----- -- IDQD
H 20%?  iRSpot-PseDNC
_   - ------ '- iRSpot-TNCPseAAC
_   RF-DYMHC
0% "'...i...|...l...l...l

 

 

0% 20% 40% . 00% 80% 100%
False p081t1ve rate

Figure 2. The ROC (receiver operating characteristic) curves obtained by
different methods. The area under the ROC curves is called AUC. They are 0.8922,
0.8138, 0.8822, 0.8631 and 0.8777 for iRSpot—EL, iRSpot—TNCPseAAC, IDQD, iRSpot-
PseDNC and RF-DYMHC, respectively. The larger the AUC, the better the correspond-
ing predictor is GDaVis and Goadrich, 2006; Fawcett, 2005).

3.3 Performance on Analysis of the Whole Genome

To further demonstrate its practical application, the genome-wide analy-
sis by iRSpot—EL was performed on the yeast chromosome III. In order
to avoid the homology redundancy bias, the CD-HIT software (version
4.6) (Li et al., 2001) was used to remove those DNA sequences ﬁom the
benchmark dataset that have more than 75% sequence identity to the 1kb
length DNA fragments in chromosome III. Trained with such a reduced
benchmark dataset, the iRSpot—EL predictor was used to identify the
hotspots in chromosome III with reliability index (RI) value set as 6 as

suggested by (Jiang et al., 2007). For investigation into the effects of
different parameters on the predictive performance, the genome-wide
prediction was conducted with different sliding windows and step sizes.
The predicted results of the center position were smoothed by using the
average value of 200-bp in a sliding window. The results predicted by
iRSpot-EL on yeast chromosome III are given in Fig.3, where for facili-
tating the comparison the corresponding recombination proﬁle by exper-
iments (Mancera et al., 2008) is also given. It can be clearly seen that the
recombination proﬁle predicted by iRSpot-EL is highly consistent with
that of experimental observations (Mancera et al., 2008), further demon-
strating that iRSpot-EL is indeed a very useful high throughput tool for
genome-wide analysis of recombination spots. Interestingly, we have
also observed that the cases with lager sliding window sizes tend to show
better results. The reason is that larger window sizes can incorporate
more global sequence information, which is critical for improving the
performance (Liu et al., 2016a). Another important observation is that
the step size has little impact on the predictive performance. Based on
the aforementioned experimental outcomes, we suggest the users to set
the parameters of sliding window size and its step size as 2000 bp and
200 bp, respectively, for the genome-wide analysis when using iRSpot-
EL.

Table 4. List of the top 10 important features in the basic classiﬁers

 

# Pse PseK Pse PseK PseK Pse DACCg
KN NCb KN ch NCe KN
Ca Cc cf

 

1 CG CG CG CG GCC GCC DAC(lag=2,F-

tilt)
2 AT AT AT AT AAT AAT DCC(lag=1,F-
shift, Shift)
3 TA TA TA TA TTA TTA DCC(lag=1,

Energy, Shift)
4 GC GC GC GC CGC CGC DCC(lag=1,F-

tilt, Shift)

5 cc cc cc cc TAA TAA DAC(lag=1,F-
shift)

6 AA AA AA AA ATT ATT DCC(lag=1,

Shift, F-shift)

7 AC AC AC AC CGG CG DCC(lag=1,

G Shift, Energy)
8 CA CA CA CA CCG CCG DCC(lag=1,
Roll, F-tilt)

9 TT =6 TT TT ACG AC DCC(lag=l, F-
G shift, F-tilt)

1 GG TT GG GG GGC GG DCC(lag=l, F-

0 C tilt, F-shift)

 

aParameters were k=2, A =4, w=0.5, C=215, and 1/ =2.

bParameters were k=2, A =6, w=0.8, C=215, and 1/ =23.

cParameters were k=2, A =10, w=0.9, C=215, and 1/ =23.

dParameters were k=2, A=10, w=1.0, C=215 and y=23.

6 Parameters were k=3, A =3, w=0.8, C=213, and 1/ =23.

fParameters were k=3, A =8, w=0.9, C=213, and 1/ =23.

g Parameters were lag=5, C=25, and )/ =2'5. The values of DNA dinucleo-
tide properties are given in Table 1.

9mg ‘09 1sn8nV uo seleﬁuV soc) ‘121u10111123 10 A1is19Aiuf1 112 /810's112umo[p101x0'soi112u1101uioiq/ﬁd11q 111011 popcolumoq

 

   

 

 

 

 

 

      

 

 

 

 

 

   

 

 

 

 

—5‘=1 W=500 ‘5‘
1.0 — —3=1 I/l/=1000 — 20 8
g _ —.s'=1 VI/tzooo E
g 0.5 — — 10 
0.0 — - 0 8
' I ' I ' I ' i ' I ' I n:

0.0 50.0k 100.0k 150.0k 200.0k 250.0k 300.0k

B
—S=1O W=500 E
1.0 — —s=10 W=1000 — 20 .‘E’
g, _ —.9=1o I/I/=2000 _ g
i: 0.5 — I. I, _ 1o 
i  “it " E
' I ' I ' I ' t ' I ' I
0.0 50.0k 100.0k 150.0k 200.0k 250.0k 300.0k
C
—5‘=100 Ill/=5OG g
1.0 — S=100 Vl/=1OGO — 20 3
a —s=100 W=2000 _ E
E 0.5 — T 10 
CL ' ,Aa' 
0.0 —  _ O E
' I ' I ' I ' I ' I ' I
0.0 50.0k 100.0k 150.0k 200.0k 250.0k 300.0k

Figure 3. Comparison between prediction results of iRSpot—EL and experimental map along yeast chromosome III. The red line represents the recombination event rate deter-

mined experimentally by Mancera et a]. GVIancera et al., 2008). The other curves represent the probability values calculated by iRSpot—EL with different sliding window sizes and step

sizes.

3.4 Web Server and User Guide

As pointed out in two recent review papers (Chou, 2015; Chen et al.,
2015b), a prediction method with its web-server available will attract
more users. In view of this, the web-server for iRSpot-EL has been
established. Moreover, to maximize the convenience for users, a step-by-
step guide is provided below.

Step 1. Open the web server by clicking the link at
http://bioinformatics.hitsz.edu.cn/iRSpot-EL/ and you will see the home
page of iRSpot—EL. Click on the ReadMe button to see a brief introduc-
tion about the server.

Step 2. Click on the Server button. Either type or copy/paste the query
DNA sequence into the input box. You can also upload your input data
via the Browse button. The input sequence should be in the FASTA
format. For the examples of sequences in FASTA format, click the Q
@191; button right above the input box.

Step 3. Users are able to set three parameters for iRSpot—EL, includ-
ing the size of sliding windows and step size. For more information of
these parameters, please click the “?” symbol nearby.

Step 4. Click on the Submit button to see the predicted results. For
example, if you use the query DNA sequence in the Example window as
the input with “2” for the size of sliding windows and “200” for the step
size, you will see the following results on the screen: (1) The query
sequence contains one hotspot (sub-sequences: 3601-4200), and one

 

coldspot (sub-sequence: 1-2400). (2) By clicking Sequence Information,
you will see the sequence information of the corresponding sub-
sequence. (3) By clicking Detailed results, you will see the detailed
prediction results for each sliding window in the sub-sequence.

Step 5. The distributions of the hotspots and coldspots along the input
sequence can be visualized by clicking the Result visualization button
near the query sequence name.

4 CONCLUSION

The iRSpot—EL predictor is a new bioinformatics tool for predicting
DNA recombination spots. Compared with the existing state-of-the-art
predictors in this area, the new predictor yielded remarkably better pre-
diction quality as demonstrated by rigorous cross-validation and ge-
nome-wide analysis. We anticipate that the web-server of iRSpot—EL
will become a very useful high throughput tool for conducting genome
analysis.

ACKNOWLEDGEMENTS

This work was supported by the National High Technology Re-
search and Development Program of China (863 Program)
[2015AA015405], the National Natural Science Foundation of
China (No. 61300112, 61573118 and 61272383), the Natural
Science Foundation of Guangdong Province (2014A030313695),

9mg ‘09 1sn8nV uo seleﬁuV soc) ‘121u101q123 10 A1is19Aiuf1 112 /810's112umo[p101x0'soi112u1101uioiq/ﬁd11q 111011 popcolumoq

Guangdong Natural Science Funds for Distinguished Yong
Scholars (2016A030306008), and Scientiﬁc Research Founda-
tion in Shenzhen (Grant No. JCYJ20150626110425228), and.

Conﬂict of Interest: none declared.

References

Akay, M.F. (2009) Support vector machines combined with feature selection for
breast cancer diagnosis, Expert Systems with Applications, 36, 3240-3247.

Cao, D.S., et a1. (2013) propy: a tool to generate various modes of Chou's PseAAC,
Bioinformatics, 29, 960-962.

Chang, C. and Lin, C.J. (2001) LIBSVM: A Library for Support Vector Machines,
ACM Transactions on Intelligent Systems and Technology, 2, 1-27.

Chen, J., et a1. (2007) Prediction of linear B-cell epitopes using amino acid pair
antigenicity scale, Amino Acids, 33, 423-428.

Chen, W., et a1. (2013) iRSpot-PseDNC: identify recombination spots with pseudo
dinucleotide composition Nucleic Acids Res., 41, e68.

Chen, W., et a1. (2014) PseKNC: a ﬂexible web-server for generating pseudo K-
tuple nucleotide composition, Anal. Biochem., 456, 53-60.

Chen, W., et al. (2015a) Pseudo nucleotide composition or PseKNC: an effective
formulation for analyzing genomic sequences, Mol BioSyst, 11, 2620-2634.

Chen, W., et a1. (2012) iNuc-PhysChem: A Sequence-Based Predictor for
Identifying Nucleosomes Via Physicochemical Properties, PLoS ONE, 7,
e47843.

Chen, W., et al. (2015b) PseKNC-General: a cross-platform package for generating
various modes of pseudo nucleotide compositions, Bioinformatics, 31, 119-120.

Chou, KC. (2001) Prediction of protein cellular attributes using pseudo amino acid
composition, PROTEINS: Structure, Function, and Genetics (Erratum: ibid.,
2001, Vol.44, 60), 43, 246-255.

Chou, KC. (2005) Using amphiphﬂic pseudo amino acid composition to predict
enzyme subfamily classes, Bioinformatics, 21, 10-19.

Chou, KC. (2011) Some remarks on protein attribute prediction and pseudo amino
acid composition (50th Anniversary Year Review), J. Theor. Biol, 273, 236-
247.

Chou, K.C. (2015) Impacts of bioinformatics to medicinal chemistry, Medicinal
Chemistry, 11, 218-234.

Chou, KC. and Shen, H.B. (2007a) MemType-2L: A Web server for predicting
membrane proteins and their types by incorporating evolution information
through Pse-PSSM, Biochem Biophys Res Comm (BBRC), 360, 339-345.

Chou, KC. and Shen, H.B. (2007b) Review: Recent progresses in protein
subcellular location prediction, Anal. Biochem., 370, 1-16.

Chou, KC. and Shen, HE. (2008) Cell-PLoc: A package of Web servers for
predicting subcellular localization of proteins in various organisms, Nature
Protocols, 3, 153-162.

Chou, KC. and Zhang, CT. (1995) Review: Prediction of protein structural
classes, Crit. Rev. Biochem. Mol. Biol., 30, 275-349.

Cristianini, N. and Shawe-Taylor, J. (2000) An introduction of Support Vector
Machines and other kernel-based learning methodds. Cambridge University
Press, Cambridge, UK.

Davis, J. and Goadrich, M. (2006) The relationship between Precision-Recall and
ROC curves. Proceedings of the 23rd international conference on Machine
learning. ACM, pp. 233-240.

Du, P., et al. (2014) PseAAC-General: Fast building various modes of general form
of Chou's pseudo amino acid composition for large-scale protein datasets,
International Journal of Molecular Sciences, 15, 3495-3506.

Du, P., et a1. (2012) PseAAC-Builder: A cross-platform stand-alone program for
generating various special Chou's pseudo amino acid compositions, Anal.
Biochem., 425, 117-119.

Fawcett, J .A. (2005) An Introduction to ROC Analysis, Pattern Recognition
Letters, 27, 861-874.

Frey, B.J. and Dueck, D. (2007) Clustering by passing messages between data
points, Science, 315, 972-976.

Friedel, M., et al. (2009) DiProDB: a database for dinucleotide properties, Nucleic
Acids Res, 37, D37-40.

Gerton, J .L., et a1. (2000) Global mapping of meiotic recombination hotspots and
coldspots in the yeast Saccharomyces cerevisiae, Proc. Natl. Acad. Sci. U. S. A.,
97, 11383-11390.

Guo, S.H., et a1. (2014) iNuc-PseKNC: a sequence-based predictor for predicting
nucleosome positioning in genomes with pseudo k-tuple nucleotide composition,
Bioinformatics, 30, 1522-1529.

Jia, J., et a1. (2016) pSumo-CD: Predicting sumoylation sites in proteins with
covariance discriminant algorithm by incorporating sequence-coupled effects
into general PseAAC, Bioinformatics, doi: 10.1093/bioinformatics/btw387.

Jiang, H., et a1. (2011) High recombination rates and hotspots in a Plasmodium
falciparum genetic cross, Genome Biol, 12, R33.

Jiang, P., et al. (2007) RF-DYMHC: detecting the yeast meiotic recombination
hotspots and coldspots by random forest model using gapped dinucleotide
composition features, Nucleic Acids Res., 35, W47-51.

Li, W., et al. (2001) Clustering of highly homologous sequences to reduce the size
of large protein databases, Bioinformatics, 17, 282-283.

Lin, H., et a1. (2014) iPr054-PseKNC: a sequence-based predictor for identifying
sigma-54 promoters in prokaryote with pseudo k-tuple nucleotide composition,
Nucleic Acids Res., 42, 12961-12972.

Liu, B., et al. (2016a) iEnhancer-2L: a two-layer predictor for identifying enhancers
and their strength by pseudo k-tuple nucleotide composition Bioinformatics, 32,
362-389.

Liu, B., et al. (2015a) repDNA: a Python package to generate various modes of
feature vectors for DNA sequences by incorporating user-defmed
physicochemical properties and sequence-order effects, Bioinformatics, 31,
1307-1309.

Liu, B., et al. (2016b) repRNA: a web server for generating various feature vectors
of RNA sequences, Molecular Genetics and Genomics, 291, 473-481.

Liu, B., et al. (2015b) Pse-in-One: a web server for generating various modes of
pseudo components of DNA, RNA, and protein sequences Nucleic Acids Res.,
43, W65-W71.

Liu, B., et al. (2016c) iDHS-EL: Identifying DNase I hypersensi—tivesites by ﬁJsing
three different modes of pseudo nucleotide composition into an en—semble
learning framework, Bioinformatics, doi: 10. 1093/bioinformatics/btw186.

Liu, G., et a1. (2012) Sequence-dependent prediction of recombination hotspots in
Saccharomyces cerevisiae, J. Theor. Biol., 293, 49-54.

Mancera, E., et a1. (2008) High-resolution mapping of meiotic crossovers and non-
crossovers in yeast, Nature, 454, 479-485.

Qiu, W.R., et al. (2016a) iPTM-mLys: identifying multiple lysine PTM sites and
their different types, Bioinformatics, doi: 10.1093/bioinformatics/btw380.

Qiu, W.R., et a1. (2014) iRSpot-TNCPseAAC: Identify recombination spots with
trinucleotide composition and pseudo amino acid components, Int J Mol Sci
(IJMS), 15, 1746-1766.

Qiu, W.R., et al. (2016b) iPhos-PseEn: identifying phosphorylation sites in proteins
by ﬁising different pseudo components into an ensemble classiﬁer, Oncotarget,
doi: 10. 1 863 2/oncotarget. 9987.

Shen, HE. and Chou, KC. (2006) Ensemble classiﬁer for protein fold pattern
recognition, Bioinformatics, 22, 1717-1722.

Shen, HE. and Chou, K.C. (2007a) Signal-3L: a 3-layer approach for predicting
signal peptide, Biochem Biophys Res Comm (BBRC), 363, 297-303.

Shen, HE. and Chou, K.C. (2007b) EzyPred: A top-down approach for predicting
enzyme ﬁinctional classes and subclasses, Biochem Biophys Res Comm
(BBRC), 364, 53-59.

Suykens, J.A. and Vandewalle, J. (1999) Least squares support vector machine
classiﬁers, Neural processing letters, 9, 293-300.

Vapnik, V.N. (1999) An overview of statistical learning theory, IEEE transactions
on neural networks / a publication of the IEEE Neural Networks Council, 10,
988-999.

9mg ‘09 1sn8nV uo seleﬁuV soc) ‘121u101q123 10 A1is19Aiuf1 112 /810's112umo[p101x0'soi112u1101uioiq/ﬁd11q 111011 popcolumoq

