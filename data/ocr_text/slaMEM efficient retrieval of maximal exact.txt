ORIGINAL PAPER

Vol. 30 no. 4 2014, pages 464—471
doi: 1 0. 1093/bioinformatics/btt706

 

Sequence analysis

Advance Access publication December 11, 2013

slaMEM: efficient retrieval of maximal exact matches using a

sampled LCP array

Francisco Fernandes1 and Ana T. Freitas1 ’2’*

1Knowledge Discovery and Bioinformatics Group (KDBIO), Instituto de Engenharia de Sistemas e Computadores
Investigacao e Desenvolvimento (lNESC—ID), Rua Alves Redol, 9, 1000—029 Lisbon and 2Department of Computer
Science and Engineering, Instituto Superior Técnico (IST) — Universidade de Lisboa, Avenida Rovisco Pais, 1, 1049—001

Lisbon, Portugal
Associate Editor: Martin Bishop

 

ABSTRACT

Motivation: Maximal exact matches, orjust MEMs, are a powerful tool
in the context of multiple sequence alignment and approximate string
matching. The most efficient algorithms to collect them are based on
compressed indexes that rely on longest common prefix array-cen-
tered data structures. However, their space-efficient representations
make use of encoding techniques that are expensive from a compu-
tational point of view. With the deluge of data generated by high-
throughput sequencing, new approaches need to be developed to
deal with larger genomic sequences.

Results: In this work, we have developed a new longest common
prefix array-sampled representation, optimized to work with the back-
ward search method inherently used by the FM-lndex. Unlike previous
implementations that sacrifice running time to have smaller space,
ours lead to both a fast and a space-efficient approach. This imple-
mentation was used by the new software slaMEM, developed to effi-
ciently retrieve MEMs. The results show that the new algorithm is
competitive against existing state-of—the—art approaches.

Availability and implementation: The software is implemented in C
and is operating system independent. The source code is freely avail-
able for download at http://github.com/fjdf/slaMEM/ under the GPLv3
license.

Contact: atf@inesc-id.pt

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on August 11, 2013; revised on November 20, 2013;
accepted on November 28, 2013

1 INTRODUCTION

With the new high-throughput sequencing technologies becoming
faster, cheaper and more accurate, the number of available gen-
omes is growing fast. Metagenomics is also pushing forward the
need to align new sequences to those already known to compare
different strains or assemblies, build phylogenetic trees, identify
new genes, identify mutations or polymorphisms, observe struc-
tural variations and perform other relevant operations. It is well
known that dynamic programming approaches are prohibitive,
both in terms of required memory and processing time, when
aligning large genomes or a number of different genomes. To
approach these problems, strategies using seeded alignments

 

*To whom correspondence should be addressed.

with shared segments, which are identical among the sequences
and act as anchor points for the alignment, have been developed.
These anchors can be fixed-length exact matches, or k—mers, as
those used in the BLAST (Altschul et al., 1990) tool. However,
this type of match is inefficient because it can lead to an oversized
number of hits, and these still have to be extended in both direc-
tions using pairwise comparisons, implying a significant process-
ing time. Much more efficient is the identification of maximal
unique matches (MUMs) that have been introduced ﬁrst by
MUMmer (Delcher et al., 1999). MUMs are identical substrings
that occur exactly once in each sequence and whose occurrences
cannot be extended to either side without producing a mismatch.
The second version of MUMmer (Delcher et al., 2002) introduced
a new more compact sufﬁx tree (ST) representation, and the third
and last one (Kurtz et al., 2004) added the ability to output max-
imal exact matches (MEMs). These are similar to MUMs but can
occur any number of times, which is useful when the number of
MUMs is insufficient to produce enough anchors for a solid
alignment, e.g. when many repeated regions exist. Also, using
MEMs instead of MUMs multiplies the regions covered by an-
chors, reducing considerably the areas requiring further process-
ing. However, the bottleneck of MUMmer is the memory
requirements of its ST index structure, which can become prob-
lematic when it does not fit into the main memory. Other closed-
source tools based on enhanced suffix arrays (ESAs) such as
Vmatch (Abouelhoda et al., 2004) and CoCoNUT
(Abouelhoda et al., 2008) have also been released, but they
share the same problem. For this reason, and to deal with
larger sequences, other approaches to find MEMs have been de-
veloped. The sparseMEM approach (Khan et al., 2009) makes
use of a sparse SA as an index, which trades memory space for
extra computational time. Later, backwardMEM (Ohlebusch
et al., 2010) used a backward search method over a compressed
ESA. More recently, essaMEM (Vyverman et al., 2013)
improved sparseMEM by enhancing it with a sparse child
array that reduces computational time maintaining the same
memory footprint. This method currently shows the best trade-
off between time and memory consumption for MEM
identification.

In this work, we propose another approach as an alternative
to these previous tools. We have developed a new sampled repre-
sentation of the longest common prefix (LCP) array, optimized
to work with the backward search method inherent from the

 

464 © The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com

112 /§.IO'SIBU.IT10[p.IOJXO'SOTlBIHJOJUTOTCI/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘091sn3nv uo ::

slaMEM

 

FM-Index. Results show the effectiveness of the new method for
a number of different genomes.

1.1 Basic notions

STs (\Neiner, 1973) are fundamental data structures in the ﬁeld
of string processing. However, despite being linear (Ukkonen,
1995), their space requirements are large. Consequently, they
have been progressively replaced by SAs (Manber and Myers,
1993) and more recently by more space-efﬁcient Burrows—
Wheeler Transform (BWT) (Burrows and Wheeler, l994)—based
indexes, namely, the FM-Index (Ferragina and Manzini, 2000).
Although these more advanced indexes work just ﬁne for stand-
ard pattern matching, they lack certain functionalities originally
present in STs, including the possibility to follow sufﬁx links. To
overcome these limitations, other data structures have been pro-
posed, like the ESA (Abouelhoda et al., 2004), which extends the
original SA with additional information to simulate the behavior
of STs. Other alternatives are reviewed in (Navarro and
Makinen, 2007) and (Vyverman et al., 2012).

Let E = {051, . . . ,aIZI} be a ﬁnite ordered alphabet, and 2* be
the set of all strings over 2, including the empty string 8. Let T be
a string or text over 2*, which is always terminated by a special
character S, which is lexicographically smaller than any character
in E and does not occur anywhere else in T. Let T[i] denote the
character at position i in T, for 0 g i< n, where n = |T|. This way,
we deﬁne T[i. . . j] as the substring of length (1' — i + 1) starting at
the ith position and ending at the jth position of T, where
0§i§j<n. We call T, the ith suﬁ‘ix of T, i.e. the substring
T[i...(n—1)], with 0§i<n. In the same way, the substring
T[0 . . .i], 0 §i<n corresponds to a preﬁx of T.

1.2 STs and SAs

The ST of T is a rooted tree that represents all the non-empty
sufﬁxes of T in the following compact way. Each node has a
label corresponding to a substring that occurs in T. The special
top node is called the root and corresponds to the empty string.
Each internal node has at least two children, and no two children
branching from the same node can have labels starting with
the same character. Each node can also be identiﬁed by its
path label, i.e. the string obtained by concatenating all the node
labels on the path from the root down to that node. The tree has
exactly n leaves, corresponding to the n sufﬁxes of T, where the
path label of the ith leaf spells the ith sufﬁx. A sufﬁx link is a
pointer that connects a node to its subsequent sufﬁx node, i.e. it
associates each node with path label aw, such that 0562 and
(062*, to the node whose path label is a).

The SA of T is an array of size n of numbers corresponding
to the lexicographical ordering of the n sufﬁxes of T, i.e. a
permutation of the integers {0,...,(n— 1)} such that TSA[0]<
TSA[1]<. . . <TSA[n_1]. The SA takes O[n*log(n)] bits of
space and can be built using linear time and space
(Karkkainen and Sanders, 2003; Kim et al., 2003; K0 and
Aluru, 2003; Nong et al., 2009). Taking advantage of the SA
as an index structure, a pattern P can be matched in
O[m*log(n)] time using binary search. The term w-interval
(Abouelhoda et al., 2004) is often used to denote the interval
in the index obtained from matching the string a).

1.3 BWT and FM-Index

The BWT of T is a permutation of the characters of T such that
BWT[i] corresponds to the character preceding the ith lexico-
graphically ordered rotation of T, i.e. BWT[i]=T[SA[i]—1] if
SA[i] 75 0 and BWT[i] = $ otherwise. If we consider the concep-
tual matrix M consisting of all the sorted rotations of T, the
BWT array corresponds to the last column of M. In the example
of Figure 2, the BWT of the previously illustrated string (Fig. l)
is ‘TCACCG$GAATAGC’. The BWT array takes O[n*log(| ED]
space and can be constructed in linear time and space, e.g. using
the induced sorting approach from Okanohara and Sadakane
(2009), among others.

Using the BWT together with some extra information, we can
build another index structure called the FM—Ina’ex (Ferragina
and Manzini, 2000). One of its key concepts is the Last-to—First
column mapping (LF-mapping), which ﬁnds, for each position i,
the position j such that SA[j]=(SA[i]— 1) (mod n). Like the
name suggests, it simply maps the kth occurrence of each
symbol in the last column L to the kth occurrence of the same
symbol in the ﬁrst column F. In other words, and noting that the
BWT is in fact the last column L, if L[i] = BWT[i] =
T[(SA[i] — 1)(mod n)] =c is the kth occurrence of the character
c in the last column L, then we will have LF[i] = j where
F[j]=T[SA[j]]=c is the kth occurrence of the same character
in the ﬁrst column F. For the example in Figure 2, LF[0] = 12
for character ‘T’ and LF[l] = 5 for character ‘C’. The LF-map-
ping can be efﬁciently computed by setting: LF[i] = C[c] —l—
occ(c,i) — l, where:

o c = BWT [i]
o C[c] is the total number of occurrences in T of all the char-
acters strictly smaller than c

o occ(c,i) is the number of occurrences of c in BWT[0 . . .i]

Pattern matching on a pattern P of size m is done in O(m) time
according to the BackwardSearch procedure (Ferragina and
Manzini, 2005) detailed in the Supplementary Material. The
search is performed backward by iteratively applying the
LF-mapping rule to obtain the P[i. ..(m— l)]-interval from
the P[(i—l— l) . . . (m— l)]-interval, for 0 5 i<(m— l).

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

i SA[i] Tam - -
u 13 $

I 1  4 AACTGCAGT$ " 13 n a
2 5 ACTGCﬂGTfB ,, c  n T c T E
3 I AGCAACTGCAGTS- c T a A s 12 c
4 10 AGT$ ; f n: 1 A a I: u 2
5 3 CAACTECAGW : 2 2 :0 E g 2 ;
ﬁ 0 CAGCMCTGCAGTEL G T c .5 E s T 5 T
T 9 CAGT$ T s E E ,, 9 a g B

a 6 [Tamers : 5 c G c A

a 2 GCAACTGCAGH : T; l g

10 8 scams T 3 c $

ll 11 GT$ i 2 2

12 12 T55 1 1

13 ? TGCAGTSL %

 

 

 

 

Fig. 1. SA and ST for the string CAGCAACTGCAGT$. Each leaf node
in the ST corresponds to an SA entry and Vice versa, while internal nodes
correspond to shared preﬁxes among consecutive ordered sufﬁxes

 

465

112 /§.IO'SIBU.IT10[p.IOJXO'SOIlBIHJOJUIOICI/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘091sn3nv uo ::

F.Fernandes and A.T.Freitas

 

 

uncle,“
C G T
Cl 0 l
1 I3_1
1'01
2'0-1.

 

BWT F L

 

.11.
t} T $=---..‘..'.': . 5
{I C AACTGCAGT$... -.
1 ﬂ. A'ETGEAGTS.’ 
1 C AECAACTGCAGT?
1 3 U l C AIET$. -.  i--
1311 G CAACTGEAGTﬁ... -.
1 3'1-1 $- CIAGCAACTGEAET$
1 G
2 ﬂu
3 n.
3 T
d D.
1i G
i C

 

 

.11me:- #-

 

 

12 1 CAGT$ - --u= u
121 I
321
12}
322
is}
4 32

CTGCﬂGT$'*“=~1
GEAACTGanT$ -
eCAGTs-Il '. i
1111.-  -  -- -
f$ : u n..
TGCAGT$.: ..m

 

'CCDﬁIU‘I'LFl

l
1
1:1
[3

 

#:-

 

 

 

 

 

 

 

 

 

Fig. 2. Matrix of all the rotations of the string CAGCAACTGCAGT$
evidencing its BWT, the ﬁrst and last columns F and L and the counts of
each alphabet character c along the BWT in occ(c,i). The last characters
of the rotations are grayed out to show the difference from each corres-
ponding sufﬁx

Because the BWT stores characters and not numbers, the FM-
Index space requirements of O(n*log(|2|)) are much lower than
those of ST and SA, O(n*log(n)). More speciﬁcally, these values
are typically ~10*n—20*n bytes for ST and 5*n bytes for SA,
assuming 32-bit integers (Kurtz, 1999).

1.4 LCP array and lcp-intervals

The ESA can simulate all the functionality of the original ST
while improving the SA’s pattern matching time to O(m), and
consists of the basic SA augmented with two additional struc-
tures, the LCP array and the lcp interval tree represented by a
child table.

The LCP of T is an array of numbers with size n that stores the
length of the lcp between each sufﬁx and the previous one, i.e.

O  = I 1Cp(TSA[i_1], TSAm) I fOI'  S 11
. LCP[O] = (—1)

It can be built in both linear time and space using the SA (Kasai
et al., 2001). An lcp-interval with lcp-value l is named an l—interval
and is denoted by l — [i,j], where 0 5 i< j 5 (n—1) and the follow-
ing properties hold:

0 LCP[i] < l

o LCP[k] zl for all k with (i + l) 5 k 5j

o LCP[k] = l for at least one k with (i + l) 5 k 5 j
o LCP[j+1] < lifj 75 (n—1)

Consequently, if we have an lcp-interval l — [i,j], this means that
the substring T[(SA[i]) . . . (SA[i]+l— 1)] of size I is the longest
common preﬁx between all the (j — i + l) sufﬁxes TSA[i] . . . TSAU]
of that SA interval. Note that because the lcp is calculated be-
tween the current SA position and its predecessor, the ﬁrst pos-
ition i of an lcp-interval l— [i,j] always has an lcp-value lower than
I. In this way, it is sometimes useful to refer to the depth of an
interval or a single position, which for an lcp-interval l — [i,j] is
always I, but for a general w—interval given by [i,j], it can be
obtained from the LCP as:

Depth([i, j]) = max{LCP[i], LCP[i + 1]}, ifi =j
min{LCP[i + 1], LCP[i]}, ifi as j

 

1

LCP Tum
— 1
AACTGCAGT$
ACTGCAGT$
AﬁcnncTGCAGT$
AGT$
CAACTGCAGT$
CAGCAACTGCAGT$
31311

ETECAGT$
GCAACTGCAGT$
GCAGT$

GT$

T$

TGCAGTt

 

 

 

 

 

 

 

WHDUILWMI—‘DF-

 

113'

 

11'}
11
12
13
14 -

 

 

DRDKDDmChEHCWI—‘h‘ﬂl

 

I—‘CPII—‘QJDI—IUJNCMH—lﬂ

1....
N
._..
.p.

 

 

 

 

 

 

 

I
p.11

 

Fig. 3. LCP, PSV and NSV arrays for the string CAGCAACTGCAGT$.
The shaded characters represent the shared preﬁxes between adjacent
sufﬁxes

The parent interval of an lcp-interval l — [i,j] is an lcp-interval
q — [r,s] such that q< l, r 5i and s 2 j, and there is no other lcp-
interval of lcp-value t enclosing l — [i,j] such that q< t< l.
Therefore, it corresponds to the ﬁrst larger lcp-interval that en-
closes l — [i,j]. To calculate a parent interval, we can use the next
smaller value (NSV) and the previous smaller value (PSV) arrays
introduced in Fischer et al. (2009) and deﬁned as:

o PSV[i] = max{k:(0 5 k < i and LCP[k] < LCP[i]) or k = 0}
o NSV[i] = min{k:(i < k 5 n and LCP[k] < LCP[i]) or k = n}

As their names suggest, the PSV/NSV arrays contain the ﬁrst
position above/below in the LCP array that has an lcp-value
lower than the current one, respectively. Because in an lcp-inter-
val l — [i,j] the nearest lcp-values lower than I are located at LCP[i]
and LCP[j + 1], its ﬁrst enclosing interval will have an lcp-value
equal to the higher of these two values. Therefore, the resulting
parent interval is deﬁned by:

Parent(l — [i,j]) = (LCP[k]) — [PSV[k], (NSV[k] — 1)], with

. k :1, if LCP[i] 3 LCP[j + 1]
. k =j + 1, ifLCP[j + 1] > LCP[i]

Some illustrative lcp-intervals in Figure 3 make this more clear,
e.g. the parent of the 3—[6,7] interval, corresponding to the
‘CAG’-interval, is the 2—[5,7] interval corresponding to the
‘CA’-interval, and lcp-interval 3—[9,10] has l—[9,ll] as parent,
coinciding with the ‘GCA’ and ‘G’ intervals, respectively.

From the parent/child relations of the lcp-intervals, an lcp-
interval tree can also be built to simulate the topography of the
ST. Instead of pre-computing and storing the PSV/NSV arrays
explicitly, they can also be calculated on the ﬂy using Range
Minimum Queries (RMQ) (Fischer and Heun, 2007) that rely
on other auxiliary data structures. Although many applications
exist that use these last two methods, they have not been applied
in this work.

1.5 LCP array representations

Some direct representations of the LCP include storing each
value using only 1 byte with the larger values going in a separate
array (Abouelhoda et al., 2004), or encoding it with a wavelet

 

466

112 /§JO'S]Bumo [p.IOJXO'SOllBIIHOJUIOIQ/ﬁ(1111] 1110131 prBOIIIAAOG

910Z‘0918030V'u0::

slaMEM

 

tree using the different lcp values as the alphabet (Kulekci et al.,
2012).

A succinct representation of the LCP exists (Sadakane, 2007),
based on the fact that the property LCP[SA_1[j+1]]:
LCP[SA_1[j]] — 1 always holds. In this case, SA_1[j] =i gives
the position i in the SA where the text position j is stored, i.e.
SA[i] = j. This means that if we rearrange the LCP entries in text
order rather than lexicographic order, the values decrease by at
most 1. From this observation, a new array of size n deﬁned by
Hgt[j] =(j +LCP[SA_1[j]]) and composed entirely of non-
decreasing integers can be constructed and stored using only
2n+O(n) bits, with a special data structure used to encode
sorted numbers. Given SA[i]: j, LCP[i] can then be derived
from Hgt[j]. This method of storing the LCP in text order and
not in SA order originated the concept of the permuted longest-
common-prefix array (Karkkainen et al., 2009) deﬁned by
PLCP[j]= LCP[SA_1[j]]. The major drawback of this approach
is that it is dependent on the time needed to retrieve SA[i] = j,
which can be expensive when SA is not available explicitly.

Another representation of the LCP array is the sampled LCP
(SLCP) described in Siren (2010). It introduces the notions of
maximal or irreducible values, which satisfy PLCP[j] 75
(PLCP[j— l]— l), and minimal values, if either j=(n— l) or
PLCP[j + 1] is maximal, i.e. if it is the last value of the array or
the last one of a run of decreasing values ﬂanked by a larger
value on the right. The LCP is then sampled at these minimal
PLCP values, which are as many as the number of equal letter
runs in the BWT, and stored in SA order using a bit vector to
mark their positions. To retrieve the value of LCP[i], the 1PG)
function is iterated k times until we fall over a sample, and ﬁnally
it outputs LCP[i] = (LCP[lle(i)] + k). The 1110) function is deﬁned
as l11(i) = SA_1[SA[i] + 1], meaning that it is the converse of the
LF(i) function but returning the position in the SA of the sufﬁx
one text position to the right instead of to the left.

2 METHODS
2.1 SLCP array

The main motivation for our sampled version of the LCP is the obser-
vation that when performing the backward search over the BWT, if we
want to retrieve the parent interval of the current BWT interval through
the LCP, PSV and NSV arrays, we only need the values located at the
two positions corresponding to both ends of the interval (more accur-
ately, we need the top end and the position next to the bottom end) and
not on any of the values in between. Therefore, it sufﬁces to store the data
only for positions that correspond to edges of non-singular BWT search
intervals instead of storing it for all the positions of the BWT. This can be
seen in Figure 4, where, for example, at the ‘AG’-interval, given by
2—[7,11], we only need the values of the mentioned arrays at positions
7 and 12: 11+ 1.

As mentioned before, to be able to retrieve LCP[i], previous LCP
representations need to ﬁrst perform a series of 111 steps to compute the
value of SA[i], and in Virtually all implementations of compact indexes,
the SA array is already stored in some sampled form. Unlike them, our
approach does not require this time penalty cost for any supplemental
computation of SA or LF values. Because we need to access the LCP
array quite often for the purpose of resolving parent intervals, the re-
trieval of the lcp values should be as fast as possible. Therefore, the efforts
in this work have been made in the direction of reducing the LCP space
requirements with this SLCP approach, but without making use of any

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

i rsv 11151.1 DEF T3“

1 1:1  1:1 A 1.1  ..

2 1 E- 2 A A  ..

3 1 6 2 11 .1 E 

4 3 6 3 A 11 G i

5 3 E- 3 .11 11 G]?

6 1 13 1 11[-.-

2 1 13 1 11 6].“-

8 7 12 2 A G c c G]?-
9 3 11:1 5 11 G c c G]-
10 2 12 2 it sit:

11 7 12 2 .1 11:1

12 1 13 1 .111

13 

 

Fig. 4. Example of a hypothetical section of an index structure showing
arrays LCP, PSV and NSV. The sampled values of these three arrays are
emphasized in gray. Only top and bottom corner positions are sampled
for the LCP. The PSV is only sampled at top corners and the NSV only at
bottom corners

other space-oriented representations that would sacriﬁce speed, such as
representing it with a wavelet tree (Kulekci et al., 2012). Unlike the
sampled version from Sirén (2010), our SLCP method takes the positions
in the LCP that correspond to the boundaries of the search intervals in
the BWT. More precisely, these positions of interest are the ones delimit-
ing BWT ranges with the same depth, i.e. the positions whose lcp value
differs from the next one: SLCP = {LCP[i]:i = (n — 1) or LCP[i] 75
LCP[i + 1]}.

This is the same as discarding the positions with consecutive equal lcp
values, similar to what is done in run length encoding, but without the
need to store the length of each run. The rest of the positions, if needed,
can be deduced from the sampled ones. We use the terms top corner and
bottom corner to refer to the lower value/topmost position and to the
higher value/bottommost position of the BWT search interval, respect-
ively. Attending to this, every sampled position is either a top corner or a
bottom corner. Formally, the sets of both types of corners are deﬁned by:

c TopCorners = {i:(i + 1) 75 n and LCP[i] < LCP[i + 1]}
o BottomCorners = {i:(i + 1) = n or LCP[i] > LCP[i + 1]}

2.2 Sampled smaller values

While calculating parent intervals when executing a BWT search, we only
need to perform PSV requests on the higher edge of each interval, i.e. on
top corners, and NSV requests on the lower edge, i.e. on bottom corners.
Therefore, it is sufﬁcient to keep one single sampled smaller value (SSV)
array instead of both PSV and NSV arrays. SSV[i] will automatically
return the value of PSV[i] or NSV[i] if position i corresponds to a top
corner or to a bottom corner, respectively. More correctly, SSV[i] of
bottom corners stores (NSV[i + 1] — 1), as NSVs are always one position
ahead of bottom corners. Hence, PSV and NSV values for sampled pos-
itions can be recovered from the SSV array using the relation:

. SSV[i’] = PSV[i], if SSV[i’] < i
. SSV[i’] = NSV[i + 1] — 1, if SSV[i’] > i

Where i’ is the number of sampled positions in the interval [0,(i— 1)]
because SSV does not have the same size as PSV/NSV, as it only stores
the sampled positions.

Algorithm 1 associates each SLCP position with its corresponding PSV
or NSV positions depending on whether it is a top or bottom corner, and
stores it in the uniﬁed SSV array. It shares some resemblances with the
procedure from (Abouelhoda et al., 2004) to calculate the lcp-interval

 

467

112 /§JO'S]Bumo [p.IOJXO'SOllBIIHOJUIOIQ/ﬁ(1111] 1110131 prBOIIIAAOG

9IOZ ‘091sn3nv uo ::

F.Fernandes and A.T.Freitas

 

tree, as the PSV/NSV queries are the basis for the parent/child relation-
ships in the tree’s hierarchy. For simplicity, it uses the full LCP and SSV
arrays with size n, but it is easy to adapt it to use the sampled versions
instead.

Algorithm 1. GetSmuller‘v'alunf ,1

 

11:11] tepCorners t {[0, -I J}:

{02] hotternCorners -— ] ].'

103] LCP[n] <— —l:

{04] for i <— 1  n-J do

{[15] if ] LC P[i+ I] e LC P]i]] then

101)] SSV[i] «— topCornerstopHpos;

{01] topCorneripush] i , LCP[i] ];

103] else if]LEP[i+ 1] r. LCP[i]] then

{[19] while “not bottomCornersemptym and [hertomComerstopﬂJcp 2* LCP[i+1]}]
] ID] SSV] bottomCorne-rspopupos ] t-- i;

] I 1'] end

{12] bottemCerne-rs.push] i. LCP[i1 l] 1;

{13] while “not tepCe-rnersem p1y]]] and [teptiemerstep] ].lcp 2 LC P[i+ 1]]]
] I 4] topComcrspopﬂ:

] I 5] end

1113] end

 

 

 

Algorithm 1 maintains two stacks, one for top corners (line 1) and another
for bottom corners (line 2). Each stack stores pairs of values containing
the position of the corner in the BWT and an lcp-value. This lcp-value is
LCP[i] for top corners and LCP[i+ 1] for bottom corners, as we are
interested in how low the lcp-value was before and how low will it de-
crease next, respectively. This means the top corners stack stores
{i,LCP[i]} and the bottom corners stack stores {i,LCP[i+1]}. At every
moment, the set of pairs stored in both stacks is always ordered by
increasing positions and non-decreasing lcp-values. To ﬁll the SSV
array, the LCP is scanned from top to bottom. When a top corner is
found (line 5), it is linked to the previous found top corner (line 6) and
added to the stack (line 7) to be later linked to by another top corner.
When a bottom corner is found (line 8), all the active previous bot-
tom corners with an lcp-value higher than the current one (line 9)
are linked to it and removed from the stack (line 10), as they were already
used. This new bottom corner is saved (line 12) to be later linked to
the next lower such corner. All the top corners with lcp-value higher or
equal than the current bottom corner are also removed from its stack
(lines 13 and 14), as these will not have a chance of being linked to
anymore.

Algorithm 2 allows us to obtain the parent interval of a given interval
by relying solely on the sampled arrays, SLCP and SSV.

Algorithm 2. GeIPurentlntervtilt ,1 1'. j 1’ 1

 

1' O l] i' :— GetF'ositionlnSampledArray] i ];
1' DZ] _]' t GetF'ositionlnSampledArray] j ];
[[13] if ]SLCF']i'] e SLCPU'H ]] then

[04] depth <— SLCP[1"].'

[E15] toime < SSV[i];

11115.] hettornFos t—j;

[0?] else if [SLCPﬁ‘+ l] 3* SLCP[i’]] then
108] depth t— SLCPH'+ 1];

[E19] topPus <— 1';

[ID] hotterum <— SSV[J'];

[I 1] else

“2] depth 1 SLCPfl'];

] l 3] tepPos «— SSV[i]:

[l4] hotterum 1— 55113];

[15] return {depth [tepPe-s. bottomPosl}

 

 

 

For clarity reasons, the check to ensure that (j’ + 1) does not go
beyond the size of the SLCP was omitted from the pseudo-code
above to facilitate its reading. First, the edge positions of our initial
interval in the full arrays, i and j, are translated into positions in the
sampled arrays, i’ and j’ (lines 1 and 2). At this point, we cannot
simply set each corner to its SSV position because we also have to
take into consideration the depth of the parent interval. Similarly to
the Parent operation on lcp-intervals, we need to check which side of
the interval will lead to a higher lcp-value (lines 3 and 7), because the

i
o
1
2
3
4
5
e
'2
3
9
1o
11

bhbbhhhhhhhh

.14
I“)

 

13

Fig. 5. Parent interval relations in a section of a hypothetical index. The
arrows connect the top/bottom corners of each interval to their respective
parent interval’s top/bottom corners at the appropriate destination depth.
In the SLCP and SSV sampled arrays, dashes represent un—sampled
positions

lcp-value of the parent is always max{LCP[i’],LCP[j’ +1]}. The corner
displaying this property is expanded and replaced by the corner at its
SSV position and the other corner remains unchanged. If both corners
share the same value (line 11), they are both updated. Finally, it out-
puts the parent interval in the BWT along with its destination depth
(line 15).

In Figure 5, the illustrated arrows are connecting the top/bottom cor-
ners of the child intervals with the top/bottom corners of their parent
intervals at their corresponding depths. Note that because intervals with
different depths can share one of their borders, these arrows do not ne-
cessarily correspond to the destination SSV positions. For example, in the
succession of parent intervals 3—[3,5], 2—[1,5] and 1—[1,12], the ﬁrst two
share the same bottom corner at position 5, so SSV[5] points directly to
position 12, the bottom corner of the last one.

When we have an interval composed of a single position, we ﬁnd its
parent interval by doing a simple scan in the SLCP for the closest top
and bottom corners around that position. Because we use the SLCP in-
stead of the LCP, the search is faster. The boundaries of our target
interval are promptly determined by starting at those initial corners
and iteratively following the SSV values until the required destination
depth is reached.

Because in the current context only parent-interval queries are
required and we have no need for child-interval queries, this new SSV
array replaces the lcp-interval tree and it also eliminates the need for
other representations of the ST topology such as balanced
parenthesis (Geary et al., 2006) or RMQs (Fischer and Heun, 2007). We
give the term Sampled Search Intervals from Longest Common Preﬁxes
(SSILCP) to the structure combining the described SLCP and SV arrays.

Each interval with no children intervals is of size no larger than IE], as
there are only IE] distinct characters (including the terminator character
‘$’) that can be used to extend the common preﬁx in each sufﬁx, other-
wise if at least one of the characters was repeated, it would create a child
interval. This means that in each childless interval, we will have at most
(lEl—2) un-sampled positions, because we always need one sample for
each edge. Therefore, theoretically, the maximum number of positions
saved by using the SLCP instead of the full LCP will be of 3*(n/5) for
DNA alphabet, which means, at most, a 60% size reduction, although in
practice that value will be lower.

2.3 Finding MEMS

The MEM searching algorithm is based on the one proposed in Section
4 of (Ohlebusch et al., 2010) and used in backwardMEM, as the

 

468

112 /§JO'S]12umo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(1111] 111011 pep1201umoq

9IOZ ‘091sn3nv uo ::

slaMEM

 

underlying index structure of both works is supported by backward
matching.

Algorithm 3. GetMEMH P . 11111112411423 1

 

 

{91] ll. [Lilli—1040.211]:

{[12] forke—m-l  Odo

{[13] {nextL nextj] {— BackwardSearchStep] P[lt] , ]i, j] j

{[14] while {[next'r, nextj] = ] ]] do

{05] l—[i.]'] 2— Parent] I-[i. j] j;

{[115] [nextL ncxtj] <— BackwardSearthStep] P[lt] . [i,j] ];
{[12] end

{[18] [l. [1. j]] +— |l+l. [nextl nextjl]:

{09] [12 lili'll *- ll- Hill:

{10] [NEWS PFWJ'J *— 1131+”:

{I I] while {1' e minLength] do

{12] 1.11.:'l"lil1‘i~ {preui'e 1"] do

{13] if {{k = 0] 0r {BWT[previ’] e P[k—im Output ll'. SA[prEVi’], k];
{14] previ’ «— preui'—I;

{l5] end

{113] while {prev} 5]] do

{12] 12111: = D] or {BWT[preuj‘] at Hit—1]] ] output 11', SA[preuj‘], 11],-
{IS] preq' « prevj‘+ I;

{112] end

1201 1:11.11 e Parentl 111:1] 1:

{21] end

{22] end

 

 

Basically, Algorithm 3 processes the query sequence backward (line 2),
and for each interval [i,j] found (line 3), it keeps following parent intervals
[i’ ,j’] (line 20) until the length l’ of the current match is lower than a given
threshold minLength (line 11). Because the right-maximality is already
assured (lines 4—7), we check for left-maximality by verifying that each
position inside [i’ ,j’] can no longer be further extended to the left, i.e. if the
character to the left in the text, given in the BWT array, is not the same as
the character to the left in the pattern (lines 13 and 17). Because each new
parent interval [i’,j’] encloses the previous one [previ’,prevj’], only the
newly found positions above (lines 12—15) and below (lines 16—19) are
checked. This algorithm runs in 0(m+RL+ML*tSA) time, where m is
length of the query sequence, RL and ML are the number of right max-
imal matches and MEMs, respectively, of size at least L = minLength and
ISA is the time needed to obtain a value from the SA, which is constant in
our case.

2.4 Implementation

The SSILCP is built from the full LCP, presenting a variable sampling
rate of ~1.2 based on the test results of Table 1, and is used as a
replacement for both the LCP and the PSV/NSV arrays. Following the
same idea as in (Abouelhoda et al., 2004), based on the observation
that the vast majority of the values in the LCP array are small, the lcp
values <255 are stored using 8 bits per number, while the remaining
values go into a complementary table containing only larger numbers.
We also use an additional space-saving trick based on the fact that
most of the PSV[i] and NSV[i] values do not jump too far away from
its position i. Therefore, the SSV array can also take advantage of
a similar approach as the LCP array by storing the differential values
between the source and destination positions, with negative values
representing PSV jumps and positive values NSV jumps. Now the
values represented using only 8 bits are within the range from —127
to +127.

To comply with the most commonly used computer memory architec-
tures, the SA array coupled to the FM-Index uses a ﬁxed sampling rate of
32. Further details about the index and SSILCP implementations are
available in the Supplementary Material. All algorithms and data struc-
tures have been developed from scratch without relying on any other
existing code base.

Table 1. LCP statistics for the used datasets

 

 

Dataset Drosophila Human versus
mouse
Genome reference size 162 Mbp 2897 Mbp
Sampled positions 88.3% 86.9%
Oversized LCP samples 8.2% 1.6%
Oversized SV samples 2.6% 2.8%
Average lcp value 100 1059
Maximum lcp value 48 382 2 339 520
SSILCP structure size 416 MB 6680 MB
Index size 182 MB 3259 MB

 

Note: The reference genome size considers {A,C,G,T} chars only. Samples with an
lcp value >254 and SV samples with an absolute value >127 are considered over-
sized. The maximum lcp value indicates the length of the largest repeat present in
the genome. The full SSILCP size accounts for the SLCP and SSV arrays and all the
supporting data structures, excluding the FM-Index. MB, Megabyte; Mbp, Mega
base pair.

3 RESULTS
3.1 Datasets

As test suites, we have chosen two real-life scenarios that feature
signiﬁcantly sized genomes. The ﬁrst dataset is constituted by
two species of the fruit ﬂy, Drosophila melanogaster and
Drosophila yakuba, with 162 and 163 Mbp, respectively, as this
setting was also featured in the publications of every other tested
tool. The second dataset includes the complete genomes of Homo
sapiens, build 19 (HG19) (Church et al., 2011), and Mus
musculus, build 10 (MMlO) (VVaterston et al., 2002), with 3.1
and 2.7 Gbp, respectively. The chosen references for each dataset
were D. melanogaster and HGl9. Speciﬁc LCP-related charac-
teristics for each one are depicted in Table 1.

Using this new SSILCP data structure, we get 0(1) time for
LCP and parent operations. It also scales linearly with the size of
the reference genome. The space requirements are typically
around 2.2*n bytes for practical applications on DNA according
to the tests presented in the second last row of Table l, consum-
ing ~19% of the space we would have used by storing the full
LCP, PSV and NSV arrays in the naive way.

3.2 Tested programs

MUMmer builds an ST for the reference using the compact rep-
resentation from (Kurtz, 1999) that requires ~15.4 bytes per
input character and streams the query sequences against it.
sparseMEM indexes the reference with a sparse SA and uses
the LCP and SA‘1 arrays to simulate sufﬁx links, which are
essential to accelerate the computation of MEMs in that data
structure. Its time complexity is O(m*log(n) + q) for a reference
of size n, query of size m and q dependent on the sparseness
factor and minimum matches length. A sampled SA approach
keeps all the sufﬁxes of the text but only stores each kth entry of
the SA array, whereas the sparse SA approach only maintains
each Kth sufﬁx of the text and their corresponding SA entry.
essaMEM works over an enhanced sparse SA that replaces the
SA‘1 array of sparseMEM with a sparse child array, greatly

 

469

112 /§JO'S]12umo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(1111] 111011 pep1201umoq

9IOZ ‘091sn3nv uo ::

F.Fernandes and A.T.Freitas

 

reducing the time complexity by removing the log(n) term while
maintaining a similar memory usage of (9/K+ l)*n bytes.
backwardMEM uses an enhanced compressed SA supported
by a BWT encoded as a wavelet-tree and adapted existing
MEM locating algorithms to work with backward search. It fea-
tures a balanced parentheses representation of the lcp-interval
tree capable of constant time parent interval queries. Its
memory requirements are ~(4/k + 2)*n bytes in practice.

When available, the tools were given different SA sampling
values of powers of 2 ranging from 1 to 32, using the run-time
parameter ‘-k’ in sparseMEM and essaMEM and the compile-
time ﬂag ‘3 WT K’ in backwardMEM. All tools were run with the
same parameters ‘-maxmatch -n -l L’ to report all MEMs, with
minimum length L: 50 for the Drosophila dataset and L: 100
for the human/mouse dataset.

The source code of each tool was edited to launch a process in
the background that starts collecting the time and memory
values right after the data structures were built and just before
the actual MEM ﬁnding algorithms take place. Because each
tool uses different index structures and different construction
algorithms that would be difﬁcult to compare as a whole, this
allows the benchmarks to reﬂect the MEM retrieving efﬁciency
only.

3.3 Benchmarks

Time corresponds to the elapsed real time and memory to the
maximum physically resident memory, ﬁelds ‘etime’ and ‘rss’,
respectively, in the Unix system command ‘ps’, and measured
using the ‘memusgpid’ script included in the source package.
All tests were run on a Linux server machine featuring an Intel
Xeon CPU clocked at 2.13 GHz with 256 GB of RAM and 64
cores, but none of the tools was run with multi-threading op-
tions. The results are presented in Table 2 and Figures 6 and 7
and detailed in the Supplementary Material.

Because all the tools only index the reference genome, the used
memory is determined by the reference size, with the addition of
the currently loaded query. As the results show, slaMEM’s
approach consumes ~3.3*n bytes in practice. In the
Drosophila dataset, it uses approximately the same memory as
backwardMEM and sparseMEM, both with a sampling value of
32, while being almost 7 times faster than backwardMEM and 25
times faster than sparseMEM. Therefore, between the two back-
ward searching—based methods, slaMEM achieves the best per-
formance. It is only outperformed in terms of memory by
essaMEM with K: 16 and K:32, while still running slightly
faster. Compared with the un-sampled approach used in
MUMmer, slaMEM runs in half the time and uses almost four
times less space. In the human/mouse dataset, MUMmer,
backwardMEM and essaMEM with K: 1 all failed or crashed
possibly due to the use of signed integer variable types, which do
not support arrays with sizes larger than 2 billion positions.
Theoretically, for a comparable memory usage, slaMEM is
equivalent to a sampling rate of K:6 in the sparse methods
and still almost 8 times faster than the closest test results
(K:4 and K:8). The best time/memory ratio belongs to
essaMEM. Nevertheless, slaMEM achieves the fastest running
times among all the tested tools and sampling values in both
datasets.

 

I|1000

 

 

 

' XMUM
. Dresephtfa m”
3500 _ I sparseMEM
essaMEM
3000 - I :1 backwardMEM
IslaMEM
2500 -
7.: I l
ﬂl .
E 2000
1.
1500 -
1000 -
51111 - A -
.*'- it 1:] _r't_ . x
11 " .
0 500 1000 1500 2000 2500 3000
Memory IMB]

Fig. 6. Plot comparing the time and memory used by the different MEM
locating tools in the Drosophila dataset. Multiple points for the same tool
represent distinct values of K, if available

 

 

 

 

130000
Human vs Mouse “mm”
11501100 - I lsparseMEM
essaMEM
140000
e backwardMEM
120000 I IslaMEM
I
3 11111111111 --
E
1: 311111111
60000
4111:1011 - I
20000 -
I
n , I .
0 5000 10000 15000 20000 25000
MemnnrlMB]

Fig. 7. Plot displaying the results of all the tested tools over the human
dataset

Table 2. MEM statistics for the used datasets showing the number of
found MEMs and their average size in each dataset

 

 

Dataset Drosophila Human versus
mouse

Number of MEMs 1 461 805 537438

Average MEM size 82 114

 

Note: Only MEMs with size at least 50 and 100, respectively, have been considered.

4 CONCLUSIONS

An algorithmic improvement that can be further explored is
based on the observation that on applications that involve pur-
suing parent intervals only when a mismatch occurs, e. g. match-
ing statistics (Chang and Lawler, 1994) or super-maximal
matches (Gusﬁeld, 1997), we only need to retrieve parent inter-
vals when the current BWT search interval does not include at
least one of the letters of the alphabet, which might be the one we
were interested in following backward. This way, the SSILCP
memory requirements can be lowered even further by ignoring

 

470

112 /§JO'S]12umo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(1111] 111011 pep1201umoq

9IOZ ‘091sn3nv uo ::

slaMEM

 

the samples for LCP intervals that contain all the DNA letters.
slaMEM could also take advantage of multi-threading to speed
up computation by processing many queries or parts of the same
query in parallel. Furthermore, by extending the current imple-
mentation to support some missing ST operations, the combin-
ation of the FM-Index with the SSILCP could be used as a full
compressed ST representation.

We observed that because the boundaries of non-unitary BWT
search intervals can only fall in certain positions, it is enough to
sample the LCP, PSV and NSV arrays at those speciﬁc positions.
Therefore, we engineered the SSILCP speciﬁcally to closely wrap
around the string matching mechanism that characterizes the
FM-Index. This added ability to the index enables faster
parent interval queries, which makes it especially useful for cal-
culating matching statistics and maximal exact matches, where
its absence would otherwise render the MEM retrieval algorithm
impractically slow. Unlike other representations of the LCP,
ours does not depend on the calculation of any previous SA or
LF values, resulting in a strategy with a good space/time tradeoff
to replace both the LCP array and the lcp-interval tree. Results
on real data show that, for this application, our new combined
SLCP and PSV/NSV representation proves to be a competitive
approach against other equivalent structures such as the lcp-
interval tree, thus making slaMEM a useful backbone for any
project in the ﬁeld of comparative genomics that relies on
MEMs.

ACKNOWLEDGEMENTS

The authors thank Arlindo Oliveira for proofreading and pro-
viding valuable suggestions for this document and Michael
Vyverman for his help on tracking down a bug in our sequence
parsing code.

Funding: This work was supported by National Funds from
FCT—Fundacﬁo para a Ciéncia e a Tecnologia, through pro-
jects PEst-OE/EEI/LA0021/2013 and PT DC/EIA-EIA/ 112283/
2009. FE was supported by grant [SFRH/BD/45586/2008].

Conﬂict of Interest: none declared.

REFERENCES

Abouelhoda,M.I. et al. (2004) Replacing sufﬁx trees with enhanced sufﬁx arrays.
J. Discrete Algorithms, 2, 53—86.

Abouelhoda,M.I. et al. (2008) CoCoNUT: an efﬁcient system for the comparison
and analysis of genomes. BM C Bioinformatics, 9, 476.

Altschul,S.F. et al. (1990) Basic local alignment search tool. J. Mol Biol, 215,
403—410.

Burrows,M. and Wheeler,D.J. (1994) A Block-Sorting Lossless Data Compression
Algorithm. Digital Systems Research Center, Palo Alto, CA.

Chang,W.I. and Lawler,E.L. (1994) Sublinear approximate string matching and
biological applications. Algorithmica, 12, 327—344.

Church,D.M. et al. (2011) Modernizing reference genome assemblies. PLoS Biol, 9,
61001091.

Delcher,A.L. et al. (1999) Alignment of whole genomes. Nucleic Acids Res., 27,
2369—2376.

Delcher,A.L. et al. (2002) Fast algorithms for large-scale genome alignment and
comparison. Nucleic Acids Res., 30, 2478—2483.

Ferragina,P. and Manzini,G. (2000) Opportunistic data structures with applica-
tions. In: Proceedings of the 41st Annual Symposium on Foundations of
Computer Science, 2000. pp. 390—398.

Ferragina,P. and Manzini,G. (2005) Indexing compressed text. J. ACM, 52,
552—581.

Fischer,J. et al. (2009) Faster entropy-bounded compressed sufﬁx trees. T hear.
Comput. Sci., 410, 5354—5364.

Fischer,J. and Heun,V. (2007) A new succinct representation of RMQ-information
and improvements in the enhanced sufﬁx array. In: Chen,B. et al. (eds)
Combinatorics, Algorithms, Probabilistic and Experimental Methodologies.
Springer, Berlin, pp. 459—470.

Geary,R.F. et al. (2006) A simple optimal representation for balanced parentheses.
Theor. Comput. Sci., 368, 231—246.

Gusﬁeld,D. (1997) Algorithms on Strings, Trees and Sequences: Computer Science
and Computational Biology. Cambridge University Press, Cambridge, MA.
KéirkkéiinenJ. et al. (2009) Permuted longest-common—preﬁx array. In:

Combinatorial Pattern Matching. Springer, Berlin, pp. 181—192.

KéirkkéiinenJ. and Sanders,P. (2003) Simple linear work sufﬁx array construction.
In: Baeten,J. et al. (eds) Automata, Languages and Programming. Springer,
Berlin, pp. 943—955.

Kasai,T. et al. (2001) Linear-time longest-common—preﬁx computation in sufﬁx
arrays and its applications. In: Proceedings of the 12th Annual Symposium on
Combinatorial Pattern Matching. pp. 181—192.

Khan,Z. et al. (2009) A practical algorithm for ﬁnding maximal exact matches in
large sequence datasets using sparse sufﬁx arrays. Bioinformatics, 25, 1609—1616.

Kim,D.K. et al. (2003) Linear-time construction of sufﬁx arrays. In: Combinatorial
Pattern Matching. pp. 186—199.

Ko,P. and Aluru,S. (2003) Space efﬁcient linear time construction of suffix arrays.
In: Baeza—Yates,R. et al. (eds) Combinatorial Pattern Matching. Springer, Berlin,
pp. 200—210.

Kulekci,M.O. et al. (2012) Efﬁcient maximal repeat ﬁnding using the Burrows-
Wheeler transform and wavelet tree. IEEE/ACM Trans. Comput. Biol.
Bioinform, 9, 421—429.

Kurtz,S. (1999) Reducing the space requirement of sufﬁx trees. Softw. Pract. Exp.,
29, 1149—1171.

Kurtz,S. et al. (2004) Versatile and open software for comparing large genomes.
Genome Biol, 5, R12.

Manber,U. and Myers,G. (1993) Sufﬁx arrays: a new method for on-line string
searches. SIAM J. Comput., 22, 935—948.

Navarro,G. and Méikinen,V. (2007) Compressed full-text indexes. ACM Comput.
Surv., 39, 2.

Nong,G. et al. (2009) Linear sufﬁx array construction by almost pure induced-
sorting. In: Data Compression Conference, 2009. DCC’09. pp. 193—202.

Ohlebusch,E. et al. (2010) Computing matching statistics and maximal exact
matches on compressed full-text indexes. In: Chavez,E. and Lonardi,S. (eds)
String Processing and Information Retrieval. Springer, Berlin, pp. 347—358.

Okanohara,D. and Sadakane,K. (2009) A linear-time burrows-wheeler transform
using induced sorting. In: String Processing and Information Retrieval.
pp. 90—101.

Sadakane,K. (2007) Compressed sufﬁx trees with full functionality. Theory Comput.
Syst., 41, 589—607.

Sirén,J. (2010) Sampled longest common preﬁx array. In: Combinatorial Pattern
Matching. pp. 227—237.

Ukkonen,E. (1995) On—line construction of suffix trees. Algorithmica, 14, 249—260.

Vyverman,M. et al. (2012) Prospects and limitations of full-text index structures in
genome analysis. Nucleic Acids Res., 40, 6993—7015.

Vyverman,M. et al. (2013) essaMEM: ﬁnding Maximal Exact Matches using
enhanced sparse sufﬁx arrays. Bioinformatics, 29, 802—804.

Waterston,R.H. et al. (2002) Initial sequencing and comparative analysis of the
mouse genome. Nature, 420, 520—562.

Weiner,P. (1973) Linear pattern matching algorithms. In: IEEE Conference Record
of 14th Annual Symposium on Switching and Automata Theory, 1973. S WAT ’08.

pp. 1—11.

 

471

112 /§JO'S]12umo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁ(1111] 111011 pep1201umoq

9IOZ ‘091sn3nv uo ::

