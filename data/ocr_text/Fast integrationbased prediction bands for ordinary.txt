Bioinformatics, 32(8), 2016, 1204—1210

doi: 10.1093/bioinformatics/btv743

Advance Access Publication Date: 17 December 2015
Original Paper

 

 

Systems biology

Fast integration-based prediction bands for
ordinary differential equation models

Helge Hass1'*, Clemens Kreutz‘, Jens Timmer1'2 and Daniel Kaschek1

1Institute of Physics, University of Freiburg and 231088 Centre for Biological Signalling Studies, University of
Freiburg, Freiburg im Breisgau, Germany

*To whom correspondence should be addressed.
Associate Editor: Jonathan Wren

Received on 22 July 2015; revised on 26 November 2015; accepted on 14 December 2015

Abstract

Motivation: To gain a deeper understanding of biological processes and their relevance in disease,
mathematical models are built upon experimental data. Uncertainty in the data leads to uncertainties
of the model’s parameters and in turn to uncertainties of predictions. Mechanistic dynamic models of
biochemical networks are frequently based on nonlinear differential equation systems and feature
a large number of parameters, sparse observations of the model components and lack of information
in the available data. Due to the curse of dimensionality, classical and sampling approaches
propagating parameter uncertainties to predictions are hardly feasible and insufficient. However, for
experimental design and to discriminate between competing models, prediction and confidence
bands are essential. To circumvent the hurdles of the former methods, an approach to calculate a
profile likelihood on arbitrary observations for a specific time point has been introduced, which pro—
vides accurate confidence and prediction intervals for nonlinear models and is computationally feasible
for high—dimensional models.

Results: In this article, reliable and smooth point—wise prediction and confidence bands to assess
the model’s uncertainty on the whole time—course are achieved via explicit integration with elabor—
ate correction mechanisms. The corresponding system of ordinary differential equations is derived
and tested on three established models for cellular signalling. An efficiency analysis is performed
to illustrate the computational benefit compared with repeated profile likelihood calculations at
multiple time points.

Availability and implementation: The integration framework and the examples used in this article
are provided with the software package Data2Dynamics, which is based on MATLAB and freely
available at http://wvmvdataZdynamics.org.

Contact: helge.hass@fdm.uni—freiburg.de

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 IntrOducuon models of choice are crucial. Subsequently, predictions about the

91% ‘09 1sn3nv uo sopﬁuv s01 ‘eruiomeg aIo [SHSJQAIUH 112 /§.IO'S[BU.IHO[p.IOJXO'SODBIHJOJUIOIQ/ﬁdllq 11101; popeopimoq

One major task in Systems Biology is to infer knowledge about biolo—
gical processes via mathematical representations of the underlying
biochemical reactions. At the beginning, information given in experi-
mental data is exploited to build a suitable model, either biology—
driven or by reverse—engineering algorithms (Hecker et 61]., 2009;
Karlebach and Shamir, 2008). An important step of this process is the
model selection. For this purpose, reliable confidence intervals on the

models’ unobserved components or extrapolation to different experi-
mental conditions are desired. In Systems Biology, mechanistic mod—
els based on ordinary differential equations (ODEs), i.e. Where each
model component has a biological process as counterpart, are fre—
quently used to describe the dynamics of biological interactions.
Thus, calculation of confidence intervals typically has to deal With
nonlinear, stiff ODE systems With a large number of parameters and

©The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 1204

Fast integration-based prediction bands

1205

 

sparse observations of the model components. In the case of linear
models, propagation of uncertainties is well studied. Yet, in ODEs,
parameter transformations to link the model responses linearly to its
parameters are in general not achievable. As a consequence, the clas—
sical approach based on Fisher—information (Fisher, 1912; Sachs,
1984) is insufficient. Alternatively, sampling approaches like Markov
chain Monte Carlo (Gilks, 2005) can be applied to infer knowledge
about the model behaviour through dense sampling of the parameter
subspace which is in agreement with the measured data. Nevertheless,
a dense sampling is not feasible for high—dimensional spaces, known
as curse of dimensionality (Scott, 2009). In addition, prior informa-
tion which is essential for some sampling methods is normally not
given in the context of biochemical models, which often results in a
weakly confined parameter space from which samples have to be
taken.

To remedy these deficiencies, the validation and prediction profile
likelihood for arbitrary model observables have been introduced in
Kreutz et al. (2012), based on theoretical foundations made in Hinkley
(1979) and Bjornstad (1990). While the prediction profile likelihood
determines confidence intervals on the model response, the validation
profile likelihood includes the noise of a potential validation measure—
ment. Both are generated without sampling of a high-dimensional
space. Instead, the one—dimensional model prediction space is evaluated
and parameters are computed via penalized maximum likelihood esti-
mation. Thereby, an efficient and reliable propagation of uncertainties
from the experimental data to the model response is accomplished and
predictions as well as confidence intervals are attained.

In this study, we exploit that prediction intervals (PIs) for differ-
ent time points are connected through an implicit function. This en-
ables us to calculate a fast approximation of point—wise prediction
bands (PBs) for a certain confidence level. The term point-wise will
be omitted from here on. To obtain PBs, a system of ODEs for the
time propagation of a specified point on the validation profile will
be derived and a dedicated explicit integration scheme is applied to—
gether with elaborate correction mechanisms. In contrast to PBs,
which includes the uncertainty of an additional measurement (Hahn
and Nelson, 1973), point—wise confidence bands (CBs) represent the
uncertainty of the current model, only. To deduce the latter, PBs can
be calculated for the limit case of a decreasing uncertainty of the
additional measurement, 0' —> 0 (Powell, 1970). The presented
method is tested and verified on three established models for cellular
signalling, published in Raia et al. (2011), Swameye et al. (2003)
and Bachmann et al. (2011).

2 Methods

2.1 Profile likelihood and validation profiles
Biochemical components in a reaction network can be described by
ODEs

x(t7u(t)78) :f(x(t)7u(t)78)' (1)

Thereby, the time evolution of the concentrations of the molecular
compounds is given through integration of Equation (1). The internal
model state x(t,u(t), 0) can depend on an external, time—dependent
input function u(t). In addition, it is dependent on dynamic and initial
value parameters, which are comprised in 0 together with observa—
tional parameters. Further, the model response g(x(t, u(t), 0), 0) links
the internal state to observed data y(t) via

3)“) : g(x(t7 “(07 0):  + EU): (2)

where additive Gaussian errors 6 N N (0, 02) are assumed.

To assess the discrepancy between model and experimental data,
the scaled log—likelihood can be calculated through

 

—210g(8) : 12(0) : Z (3)1 g( (t1, (t1)’0)’0)> —l— coast, (3)

i 07
further denoted as 12(0). Except for a constant, Equation (3) is
equivalent to a least—squares function. In the maximum likelihood es-
timation framework, the estimated parameters 0 are determined by

X2(g):moinz(% g( (t1: (t1)70)70)> . 

01'

 

Further information on the integrator and optimization routines
used in this article can be found in Supplementary Section S1.

An accurate confidence interval for a parameter of interest can
be deduced with the profile likelihood approach of Venzon and
Moolgavkar (1988) through

PL(e,-) = min 12(9). (5)
ea
The confidence interval to a given confidence level or spans all
values of 0,- with PL(0,-) below a threshold given by the oc—quantile of
a XZ—distribution with one degree of freedom, denoted by icdf(ﬁ7a):

co... = {6,- | no» 3 N) + admin}. <6)

For weak assumptions (Feder, 1968), e.g. for a high amount of
informative data, (1 — or) specifies the probability that, for repeated
experiments, the true value of 0,- lies within the boundaries of the
confidence interval.

If a ﬂat profile is observed for a parameter, it indicates a structural
non-identifiability, meaning that either no information about the re—
spective parameter is given in the measurements, or that other param—
eters can fully compensate for changes in the model response arising by
fixation of the parameter of interest (Merkt et al., 2015). Besides, a
profile likelihood which exceeds the threshold icdf(xia) in maximal
one parameter direction is called practically non-identifiable (Raue
et al., 2009), indicating that the information within the data is not suf—
ficient to restrict the parameter to a finite confidence interval. With
additional information provided through measurements or through
model reduction, practical non-identifiabilities can be resolved.

In Kreutz et al. (2012), profile likelihood—based confidence inter—
vals and their computation have been generalized to confidence and
prediction intervals for arbitrary observables. For its calculation, an
auxiliary data point zI with standard deviation 6' is added to the log—
likelihood at time—point t and observable gz by the algorithm.

Since no experimental data are necessary for the observable of
interest, gz, it allows for computation of PIs on new experimental con—
ditions or previously non—observed model components. The extended
12 then reads

X2“, Zr) 2 2 (y.- —g(x<t.-,u<t.->, 0), of

i 07

+ (z. —gz<x<r,u<r>, may (7)

 

 

0

\ j
V

Contribution of auxiliary data point =22 (0%,)
and the estimation for the validation profile likelihood is given by

VPL(z.) = meinxzw, a) (8)

with optimized parameter set 0, which is now optimized for both
the measurements 3) and the fixed auxiliary data point z,. Thereby,

9mg ‘09 1sn3nv uo sopﬁuv s01 ‘BIUJOJIIBD aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SODBIHJOJUIOIQ/ﬁdllq 11101; popeopimoq

1206

H. Hass et al.

 

zI can be interpreted as a parameter for which a PI can be computed.
The PI

Pig)“, 2 (z, | VPL(z,) g mzin VPL(z,) +icdf(xia)} (9)

reﬂects the expectation that a validation experiment lies within a
given confidence level or. In accordance with the parameter profile
likelihood described above, ﬂat validation profiles or ones that do
not exceed the threshold in both directions are called structural or
practical non-observable, respectively. As zI can be interpreted as
parameter of VPL(z,), structural or practical non—observability
arises if an adapted 0 can alter the model response for observable gz
while preserving the 12 value or keeping it below the threshold set
by or in at least one direction.

On the contrary, the confidence interval represents a prognosis
of the current model structure and parameter calibration, without
noise of an additional measurement. Thus, the auxiliary data point
zI can be substituted by a model constraint gz(x(t,u(t), 0), 0) E z,.
Alternatively and to avoid the challenging task of constrained opti—
mization (Nocedal and Wright, 2006), the limiting case 6' —> 0 can
be used to calculate the prediction profile likelihood (Powell, 1970),
as outlined in Kreutz et al. (2012).

2.2 Integration method for PBs

Based on the validation profile likelihood, PBs can be deduced via
calculation of PIs for multiple time points, linked through e.g. a
smoothing spline (De Boor, 1978). To compute them more accur—
ately and efficiently, an integration method is derived in this study.
For the integration, the auxiliary data point zI at the threshold of a
specified confidence level or, determined by Equation (9), serves as
starting point. It is treated explicitly time dependent. For given con—
fidence level or and time t, a unique upper and lower time—course of z
(t) with corresponding  constitutes the PBs . To obtain PBs for a
specified confidence level or, the corresponding XZ—level sets a con—
straint for the integration. Further, the parameters are supposed to
satisfy the optimality condition of Equation (8). This leads to

3809(1), z(t)) = mzin VPL(Z(T)) + “#06110 , V9X2(é(r),z(r)) = 0.

V

 

26071515.

(10)

Equation (10) cannot be resolved for the desired quantity z(t)
analytically. However, its derivative and the corresponding change
in the optimized model parameters 0 can be computed via the impli—
cit function theorem. As shown in Supplementary Section S2, after
differentiation of Equation (10) with respect to t, the following set
of differential equations is obtained:

d

Ez=ﬂx<r>au<r>aé<r>>a <11a>

 

 

dr 62

61 ~ _ _ 2M?) —gz(x(fau(f)aé(f))a9(0)] 8gz 8 8x
_9_H1< >X8x8t80

aa'
(11b)
The system of differential equations can be solved in forward dir—
ection as well as in backward direction after the transformation
t —> —t, which helps to reveal partial non-observabilities as dis—
cussed in more detail in Section 3.1.
The Hessian matrix in Equation (1 1b) is given by

H = Wanton), z(r)), (12)

whereby second derivatives are omitted due to their expensive nu—
merical computation. In addition, the inﬂuence of the term with se—
cond derivative can destabilize the optimization process, since the
approximation is strictly positive definite (Press at al., 1996).

2.3 Explicit integration and correction mechanisms
Systems of ODEs describing biochemical reactions are in general
stiff, thus they require an implicit integration scheme. Yet, these
need the Jacobian of the right—hand side of the ODE system, which
is in this case composed of first derivatives of the underlying mech-
anistic model. For that reason, exact second derivatives would be ne—
cessary for an implicit integration of Equations (11) (Terms
including third derivatives would emerge if the correct Hessian is
utilised, but are dropped in the approximation of Equation (12)),
but are computationally too expensive. Thus, explicit integration via
the Runge—Kutta scheme of fourth—order (Butcher, 1963) with elab—
orate correction mechanisms is executed. The stiffness of the ODE
system of Equations (11) rules out integrators with adaptive step—
size as well, because the chosen step size quickly approaches 0. To
compensate for mis—specifications made in Equation (12) and to
overcome integration artefacts due to the explicit integration, the
appendage

i

dréi = —H—1ivlea(., (13)

is added to $0 in Equation (11b) as self—correction term (Chen and
Jennrich, 2002). For 1) : 1, Equation (13) represents a gradient des—
cent approach. The correction strength 1) is adjusted throughout the
integration by comparison of the vector norm between the suggested
correction and the uncorrected step:

(

 

y/2 if l|0Y=0H<2,

y><2 if “i=0”>1o,

 

 

1 1» else.

Still, the explicit integration scheme can lead to a 12 value outside
of the chosen confidence level and the parameter set after an integra—
tion step can be off its minimum. An additional correction to the ex—
plicit integration steps can take advantage of the fact that the desired
12 value is known beforehand and is to be satisfied within close
bounds throughout the integration. In every step of a correction, the
present 12 value and its optimized parameters are obtained via con—
strained optimization of the likelihood given the auxiliary data point.
If the current 12 value leaves the interval [icdf(ﬁ7a), icdf(xia+0.01)],
the auxiliary data point is interpolated by a quadratic fit between the
two points defined by the best fit 12(0) and the current auxiliary data
point with its corresponding 12 value. If the re—optimized value re—
mains outside of the [icdf(xia),icdf(ﬁ7a+0.01)] band, a polynomial,
succeeded by a cubic interpolation spline is fit to the old plus updated
auxiliary data points with their respective 12 values. As last resort, the
validation profile likelihood is computed for the current time point
and serves as new starting point for further integration.

Non—identifiabilities of the model are dealt with a cut—off toler—
ance on the singular values that come up in the inversion of the
Hessian matrix. Nearly flat parameter profiles would lead to large

91% ‘09 1sn3nv uo sopﬁuv s01 ‘1211110111123 310 Amie/xtqu 112 /§.IO'S[BU.IT10[p.IOJXO'SODBIHJOJUIOIQ/ﬁdllq 11101; pop1201umoq

Fast integration-based prediction bands

1207

 

 

Algorithm 1 Computation of PBs

 

: Initialize with to, 0(t0),gz,z(t0), 1), At, or
: C1,, = minzVPL(z(t0)) + z‘cdﬂﬁﬂ)

. _ T d—To
- "steps — enAr

1
2
3
4: for i = 0 to i.< amps do
5 ~ ~
6
7

 

(Equations (11b) and (13))
(Equation 14)
(Equations 11,

Compute 0,20 and 0,
Update 1» .
Compute Z, 0 via RK4
Supplementary
_ Section S2)
8: if (EH 9 - At a [15, “191) then
: ﬂzub—ﬂorlb—ﬂ
10: end if .
11: 0(ti —I— At) : 0(ti) —I— 0 - At
12: z(t,- + At) = z(t,-) + z' - At
13: Compute current 12(9, z(t,-))
14: if (X2(9=Z(Ti)) 13 [Clara CIa+0.01l) then

(Equation (7))

15: Start correction mechanism

16: Set corrected 0(ti —I— At), z(t,- —I— At)
17: end if

18: n+1 =Ti+At

19: end for

 

parameter changes hampering the integration of the models’ ODE
system and bursting any validity of the linear sensitivities of
Equation (11b). The pseudocode illustrating the integration proced—
ure described in this section is outlined in Algorithm (1).

3 Results

3.1 Illustrative model
A small model (ABC) of two consecutive reactions

AﬂBEC on

with estimated initial concentration of A is utilized here to demon—
strate the performance of the integration method and illustrate the
scenario of non—observability. For 121 = 0.05, kg = 0.1 and A0 : 1,
11 data points with Gaussian noise 6 N N (0, 0'2) with 0' = 6' = 0.1
were simulated for states B and C, spaced equidistantly between
t : 0  100. In this setting, all three parameters are identifiable.
To evaluate the accuracy of the integrated PBs, PIs for distinct time

 

 

 

 

 

points were calculated utilizing the analytic solution of the ABC
model. The analytic solution and derivatives together with detailed
information about the toy model can be found in Supplementary
Section S4. These are shown together with the integrated PBs
for or : 95% in Figure 1. The PIs comprise negative measurements,
because Gaussian errors are assumed for the auxiliary data point.
Since a high time resolution is achieved by integration of PBs and be—
cause no time points have to be specified beforehand, the time point
for complete transition of state A to state B and C with confidence
level or can be specified, in this example at roughly 7 min. Also, the
peak concentration of state B in consistency with the data can be
determined to lie between 7 and 12 min. In a second experimental
setup with measurements for state B at the beginning and end of the
shown time interval only, the height and time point of the peak of
state B are not determined. Figure 2 illustrates the lack of informa-
tion in the available data. Since the rise in concentration of state B is
not covered, backward integration of Equation (11) from t :
100 min is performed. An agreement between integrated PBs and

     

13 (t)
2


3

..::i

E1

"2‘ 3F
U

E

D

.2.

$.0

2

=1: :1:

 

 

0 20 40 60 80 100

time [min]

Fig. 2. PBs for component B of the ABC model with only two hypothetical
data points for state B at time points t = 0 and 90 min, shown as dots. The
best fit is depicted as solid line and stars indicate the 95% thresholds of mul-
tiple validation profiles. Between t =0 and t =18 min, the concentration of B
is non-observable, indicated by the shaded area excessing the y-axis

 

 

 

 

Alt} B {t} {Ht}
* :4:
1 _ g, I
 g [1.5 a. E
E E E
g {1.5   o 5
a T3 3
1: I: 2
CI 3 D
u U U U
o o
T * a: a: :1: :1: :1: :1: a:
n on 'I on o 50 1 on o 50 l on

time [min]

time [min]

time [min]

Fig. 1. Model response of the ABC model. Simulated data points for state B and C are pictured as dots. For all three states, the integrated PBs for confidence level
or = 95% are shown in grey, with the best fit as black line. In addition, stars indicate the 95% thresholds of the P13 calculated with the analytic solution of the ABC

model for distinct time points

91% ‘09 1sn3nv uo sopﬁuv s01 ‘1211110111123 310 Amie/xtqu 112 /§.IO'S[BU.IT10[p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 11101; pop1201umoq

1208

H. Hass et al.

 

validation profile—based PIs can be seen for the chosen time points
60, 80 and 90 min. However, the PBs widen to very large concentra—
tions of state B while lowering t, with the last time point of the inte—
gration at t : 18min and an integrated upper threshold of 280.
Hence, a partial non-observability arises between t = 0 and 18 min.

3.2 Application to an established model

To demonstrate the efficiency and robustness of the integration
method on biochemical models, a model of the Epo—induced signal—
ling via the Janus family of kinases (JAK) and the signal transducer
and activator of transcription (STAT), published by Swameye et al.

(2003) is utilized here. The model revealed that rapid
P -P
P- h i -P
P- -P .
P— -P
P- —p ’
Cytoplasm

Nucleus

Fig. 3. Model structure of the JAK—STAT signalling pathway, as published in
Swameye et al. (2003). After binding of Epo to the Epo-receptor, JAK2 is acti-
vated and the intracellular domain of the receptor gets tyrosin-phosphory-
lated in turn. Subsequently, STAT5 is recruited to the receptor, gets
phosphorylated and dimerises, then migrates to the nucleus where gene tran-
scription is initiated. Thereafter, de-phosphorylated STAT5 is exported to the
cytoplasm

 

 

 

 

 

 

 

 

 

 

nucleocytoplasmic cycling of STAT5 is a key component and acts as
remote sensor between nucleus and receptor within the JAK—STAT
pathway. The model scheme is depicted in Figure 3. To visualize the
capabilities of the integration approach, the model was extended by
a hypothetical observation of the STAT5 concentration in the
nucleus.

In addition, a model without relocation of STAT5 from the nu-
cleus to the cytoplasm is constructed, which is used for model selec—
tion between these two opposing hypotheses. The PBs on all model
observables, namely the phosphorylation of STAT5 (pSTAT) and
the total STAT5 (tSTAT) concentration in the cytoplasm as well as
for the introduced concentration of STAT5 in the nucleus (nSTAT)
were computed and are shown in Figure 4 together with the 95 %
threshold points of the validation profile—based PIs. Apart from a
good agreement of both, the distinction of the conditions with and
without export of STAT5 from the nucleus to the cytoplasm can be
observed. The model output of the latter could be verified by e.g. an
experiment with inhibited relocation of STAT5 to the cytoplasm.
Also, the transient versus sustained STAT5 concentration in the nu—
cleus could be taken as hypothesis for a validation experiment. To
distinguish between both proposed models and as model selection
step, the measurements of the total STAT5 concentration for late
time points could be consulted. Since the PBs of the concurring mod-
els are clearly apart there, the available data evidently favours the
model with relocation, as it is identified in Swameye et al. (2003).

3.3 Efficiency of the integration method

The efficiency of the integration method compared with validation pro—
file—based PIs was assessed with the illustrative model and three estab—
lished models, published in Swameye et al. (2003), Raia et al. (2011)
and Bachmann et al. (2011). More information about their ODE sys—
tems and the utilized datasets can be found in the Supplementary
Section S5. It was measured on a MacBookPro from Mid-2014 with a
2.8—GHz Intel Core i5. Due to conceptional differences of the valid—
ation profile likelihood approach and an integration of PBs, a direct
comparison is not feasible without specification of some assumptions.
To obtain fast and sufficiently accurate upper and lower bounds of the
PIs via the validation profile likelihood method, roughly 10 steps of

 

 

 

 

DSTAT tSTAT nSTAT
1.2 r;
—Centrul Ht g,
 Inhibition l 3* *
4
 1  as 
S E E 3 ..------"
.53 mi 0.6 a * r
m E at e:
—. , H. , 7 2
E “P E [1.4 i E
’3' D *1. C-
u u .I u l
[1.2 :1.
*iafql *
o o * ‘55" o
o 20 4:] oo o 2:] 411 on o 20 40 on

time [min]

time [min]

time [min]

Fig. 4. Phosphorylated STAT5 (pSTAT) and total STAT5 (tSTAT) in the cytoplasm with data points as dots, as well as the STAT5 concentration in the nucleus
(nSTAT). The best fit is shown as solid black line for the model with allowed export of STAT5 from the nucleus back to the cytoplasm (Control) and as dashed
grey line without this relocation (Inhibition). Integrated PBs for confidence level or = 95% are indicated as grey area, the corresponding 95% thresholds of the P13

via validation profiles as stars

91% ‘09 1sn3nv uo sopﬁuv s01 ‘1211110111123 310 Amie/xtqu 112 /§.IO'S[BU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 11101; pop1201umoq

Fast integration-based prediction bands

1209

 

Table 1. Computation time per time point of validation profile
based and integrated PBs in seconds

 

 

Time (5) ABC Swameye Raia Bachmann
Validation proﬁles 4.1 5 .5 15 .3 61.1
Integration 0.27 0.53 2.75 5.32
Precise integration 0.82 1.53 3.14 10.98

 

Precise integration labels an integration with initiated correction at every
step. The respective models are published in Swameye et al. (2003), Raia et al.
(2011) and Bachmann et al. (2011).

VPL(zr) with varying zI were calculated. In addition, the validation
profiles were evaluated for 10 distinct time points equidistantly spread
over the model’s time horizon. Considering the integrated bands, two
integration steps per time unit (mostly minutes) were taken. For both
methods, the total computation times were averaged afterwards to at—
tain the runtime per time point. The results shown in Table 1 illustrate
that the integration is performed roughly 6—15 times faster. Even with
precise integration, denoting an integration procedure with a correction
after each step, re—assuring that the at threshold is maintained, the time
span for integrated PBs is around five times lower compared with mul—
tiple computation of validation profiles. The difference in the relation
of both integration times originates from the number of correction
cycles needed during the integration procedure. Also, the optimization
time at each point on the validation profile can vary by a factor of 10,
together with a variation of the actual required steps. As further advan—
tage of the integration approach, its accuracy does not depend on the
amount of points calculated on the PI, since the confidence level or is
maintained through a constraint. In addition, the true PBs can differ
from those interpolated through few distinct time points, especially in
areas of high variability and in vicinity of sharp peaks.

4 Discussion

One of the main purposes of mathematical modelling is to acquire
knowledge about the outcome of perturbed experimental conditions
or not yet measured model components, which includes arbitrary
functions like the integral of time courses, total concentrations or
the recurrence time after stimulation. This constitutes a challenging
task for large non—linear models with sparse observations, as they
typically arise in biological applications. Sampling approaches like
MCMC have serious drawbacks in this setup due to the curse of
dimensionality. They are feasible within low parameter dimensions
or if appropriate prior knowledge is present. In contrast, models in
Systems Biology often possess non—identifiable parameters where the
search space is weakly confined. The nonlinearity also hampers
translation of one—dimensional parameter profiles into PBs (Raue
et al., 2009). Thereby, the trajectories associated to the optimized
parameter sets for each point on the parameter profiles (see
Equation 6) are utilized. Subsequently, the envelopes of these trajec—
tories constitute an approximation of the PBs. Yet the uncertainty is
in general underestimated, because comprehensive sampling of the
model prediction space is not guaranteed by evaluation along one—
dimensional parameter manifolds (see Section 2.1). To resolve the
mentioned impediments, a new approach based on re—optimization
of the likelihood with a varying constraint or an auxiliary data point
was introduced in Kreutz et al. (2012). Therein, the one-dimensional
prediction space is evaluated to directly infer the prediction and con—
fidence intervals from the measured data. Apart from a constraint
on the model response, the confidence interval can be obtained

through decreasing the standard deviation of the auxiliary data
point (Powell, 1970), too. As a result, PBs can be obtained by inter—
polation between PIs for multiple time points.

In this article, a fast integration method based on the validation
profile likelihood approach is developed in order to attain accurate
PBs. The integration starts from an arbitrary point in time on the
corresponding PI, e.g. the 95 % thresholds for t = 0, leading to the
95 % PBs for the observable of interest. In the context of statistical
testing, the PBs enclosing the confidence region control the probabil—
ity of errors of type 1, hence they specify the probability that a single
validation measurement at a specific time point is within the inter-
val. If PBs with high precision are desired, the integration procedure
can be performed coupled with a correction at every step. Thereby,
robust and precise PBs, still faster than distinct validation profile
likelihood computations, are achieved. The superiority originates
from the relationship between two adjacent time points, expressed
in Equation (11) and because only the auxiliary data point on the
specified confidence level or is required. In contrast, the validation
profile likelihood approach provides a number of possible validation
measurements with their corresponding 12 value, which can be used
to compute PIs to arbitrary confidence levels or.

The efficiency advantage compared with distinct validation pro—
files is eliminated when only a rough estimate of the PBs is desired,
or when the linear Taylor approximation of the required sensitivities
breaks down or requires a very small step size. In addition, the meth—
ods mentioned above can be faster and still reliable if the model is in
the so—called asymptotic setting and behaves approximately linear
(Neale and Miller, 1997).

An explicit integration scheme was chosen for the integration of
PBs, since the computation of second derivatives arising within the
Jacobian matrix of the right—hand side of Equation (11b) is not effi-
cient. To circumvent the latter, automatic differentiation (Griewank
and Walther, 2008) was carried out for comparison, yet it was sig—
nificantly slower compared with the implemented explicit integra—
tion followed by elaborate correction mechanisms.

The scope of PIs is to provide a powerful tool for experimental
design and model selection as well as to determine observability of
different model components. Through integration, PBs are available
for the whole time span of an observable. The latter comprises ex—
perimentally measured conditions as well as extrapolation to new
experimental conditions and new arbitrary functions of both, e.g.
ratios or sums. In addition, availability of smooth PBs provides new
possibilities for those functions, like the duration for the recurrence
to the initial (steady—state) concentration or the area under the curve.
The information provided by PBs can also be included in reverse en—
gineering algorithms for the inference of ODE systems, e.g. for the
description of gene regulatory networks via genetic programming
(Floares and Luludachi 2014; Krishnan et al., 2007; Sakamoto and
Iba, 2001; Spieth et al., 2006). For this purpose, the observability
and width of PBs for specified model components can be included in
the applied fitness functions (Zhang and Muhlenbein, 1995).

For the special case of fixed model parameters, the width of the
PBs will be exclusively determined by the uncertainty 6 of the auxil—
iary data point, i.e. the penalty term in Equation (7). Therefore, 26
provides a lower bound to the width of PBs for or = 95 %. For ex—
perimental design and the improvement of model observability, re—
gions with PI >> 26 indicate that the current model exhibits vast
uncertainty there. In such a case, a measurement would provide add—
itional information for reducing parameter and prediction uncer—
tainties. On the contrary, a PI approaching its minimum
characterizes an informative observable to discriminate the current
from alternative model structures.

91% ‘09 1sn3nv uo sojoﬁuv s01 ‘1211110111123 310 Amie/xtqu 112 /§.IO'S[BU.IT10[p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 11101; pop1201umoq

1210

H. Hass et al.

 

Concerning model observability, an inﬂating size of PBs can be
interpreted as partial non-observability, as there might be lack of in—
formation for the long—term behaviour or the primary activation, re—
spectively. In addition, non-observability of a model component is
detected in the integration procedure, since the requirement on the
12 level cannot be satisfied and the integration fails.

5 Conclusion

The propagation of parameter uncertainties to model predictions is
non-trivial for large, non—linear models. Yet besides Systems Biology,
various areas in science apply computer—aided simulations based on
large non-linear differential equations to study a system’s behaviour.
All attempts to attain model prediction uncertainties are hampered by
the curse of dimensionality and a weakly confined parameter space.
Also, the non—linear dependence of parameters results in an arbitrarily
complex shape of confidence regions for parameter estimates, which
cannot be translated into PIs through error propagation. To elude
sampling of a high-dimensional parameter space, the validation pro—
file likelihood approach was introduced in Kreutz et al. (2012) to
compute data—based PIs. Thereby, statistically accurate PIs are ob—
tained by continuous variation of an auxiliary data point, whereby
parameters are re—optimized. In this article, reliable and smooth PBs
over time are achieved via integration techniques with elaborate cor—
rection mechanisms, which detect non—observabilities of the model
during the integration. The idea is related to the validation profile
likelihood and takes the auxiliary data point at the threshold of a
specified confidence level or as starting point. By decreasing the error
of the data point, the integrated PBs converge into CBs. The efficiency
and applicability of the integration method was successfully demon—
strated on three established ODE models for cellular signalling. The
results of the validation profile likelihood approach for distinct time
points were reproduced and an accurate integration could be executed
roughly five times faster. The introduced approach helps to resolve a
main impediment in current applications of System Biology, namely
an accurate and efficient computation of PBs and CBs, which help to
perform experimental design, model selection and network inference
through e.g. reverse engineering. The presented framework and the
examples used in this article are available within the software package
Data2Dynamics (Raue et al., 2013, 2015), which is MATLAB based,
open source and freely available at http://www.data2dynamics.org.
Further instructions to execute the presented framework therein are
given in Supplementary Section S3.

Funding

This work was supported by the German Ministry of Education and Research
through the grants LungSys II (0316042A) and ReelinSys (0316174C). It was
also supported by the Mechanism Based Integrated Systems for the Prediction
of Drug Induced Liver Injury project, Innovative Medicines Initiative Joint
Undertaking under Grant Agreement No. 1 15336.

Conﬂict of Interest: none declared.

References

Bachmann,]. et al. (2011) Division of labor by dual feedback regulators con-
trols JAK2/STAT5 signaling over broad ligand range. Mol. Syst. Biol., 7,
5 1 6.

Bjornstad,].F. (1990) Predictive likelihood: a review. Stat. Sci., 5, 242—254.

Butcher,].C. (1963) Coefﬁcients for the study of runge-kutta integration proc-
esses]. Aust. Math. Soc., 3, 185—201.

Chen,].S. and Jennrich,R.I. (2002) Simple accurate approximation of likeli-
hood proﬁles.]. Comput. Graph. Stat., 11, 714—732.

De Boor,C. (1978). A Practical Guide to Splines, Vol. 27. Springer, New
York.

Feder,P.I. (1968) On the distribution of the log likelihood ratio test statistic
when the true parameter is “near” the boundaries of the hypothesis regions.
Ann. Math. Stat., 39, 2044—2055.

Fisher,R.A. (1912) On an absolute criterion for ﬁtting frequency curves.
Messenger Math., 41, 155—160.

Floares,A.G. and Luludachi,I. (2014). Inferring transcription networks from
data. In: Kasabov,N. (ed), Springer Handbook of Bio—/Neuroinformatics,
Springer Science and Business Media, pp. 31 1—326.

Gilks,W.R. (2005). Markov Chain Monte Carlo. Wiley Online Library.

Griewank,A. and Walther,A. (2008). Evaluating derivatives: principles and
techniques of algorithmic differentiation. SIAM ]. Sci. Comput. 32,
3323—33 5 1.

Hahn,G.]. and Nelson,W. (1973) A survey of prediction intervals and their ap-
plications]. Qual. Technol., 5, 178—188.

Hecker,M. et al. (2009) Gene regulatory network inference: data integration
in dynamic models—a review. Biosystems, 96, 86—103.

Hinkley,D. (1979) Predictive likelihood. Ann. Stat., 7, 718—728.

Karlebach,G. and Shamir,R. (2008) Modelling and analysis of gene regulatory
networks. Nat. Rev. Mol. Cell Biol., 9, 770—780.

Kreutz,C. et al. (2012) Likelihood based observability analysis and conﬁdence
intervals for predictions of dynamic models. BMC Syst. Biol., 6, 120.

Krishnan,A. et al. (2007) Indeterminacy of reverse engineering of gene regula-
tory networks: the curse of gene elasticity. PLoS One, 2, e562.

Merkt,B. et al. (2015) Higher-order lie-symmetries in identiﬁability and pre-
dictability analysis of dynamic models. Phys. Rev. E, 92, 12—20.

Neale,M.C. and Miller,M.B. (1997) The use of likelihood-based conﬁdence
intervals in genetic models. Behav. Genet., 27, 113—120.

Nocedal,]. and Wright,S. (2006). Numerical Optimization. Springer Science
85 Business Media, New York.

Powell,M.]. (1970) A new algorithm for unconstrained optimization. In:
Rosen,].B. et al (eds). Nonlinear Program, Academic Press, New York, pp.
31—65.

Press,W.H. et al. (1996). Numerical Recipes in C. Cambridge University Press,
Cambridge.

Raia,V. et al. (2011) Dynamic mathematical modeling of IL13-induced signal-
ing in Hodgkin and primary mediastinal B-cell lymphoma allows prediction
of therapeutic targets. Cancer Res., 71, 693—704.

Raue,A. et al. (2009) Structural and practical identiﬁability analysis of par-
tially observed dynamical models by exploiting the proﬁle likelihood.
Bioinformatics, 25, 1923—1929.

Raue,A. et al. (2013) Lessons learned from quantitative dynamical modeling
in systems biology. PloS One, 8, e74335.

Raue,A. et al. (2015) Data2dynamics: a modeling environment tailored to par-
ameter estimation in dynamical systems. B ioinformatics, 31, 35 5 8—3560.

Sachs,L. (1984). Applied Statistics. Springer, New York.

Sakamoto,E. and Iba,H. (2001). Inferring a system of differential equations
for a gene regulatory network by using genetic programming. In
Proceedings of the 2001 Congress on Evolutionary Computation, volume 1,
pp. 720—726. IEEE.

Scott,D.W. (2009). Multivariate Density Estimation: Theory, Practice, and
Visualization. John Wiley 85 Sons, New York.

Spieth,C. et al. (2006). Comparing mathematical models on the problem of
network inference. In Proceedings of the 8th annual conference on Genetic
and evolutionary computation, pp. 279—286. ACM.

Swameye,I. et al. (2003) Identiﬁcation of nucleocytoplasmic cycling as a re-
mote sensor in cellular signaling by databased modeling. Proc. Natl Acad.
Sci. USA, 100, 1028—1033.

Venzon,D. and Moolgavkar,S. (1988) A method for computing proﬁle-likeli-
hood-based conﬁdence intervals. Appl. Stat., 37, 87—94.

Zhang,B.T. and Muhlenbein,H. (1995) Balancing accuracy and parsimony in
genetic programming. Evol. Comput., 3, 17—38.

91% ‘09 1sn3nv uo sojoﬁuv s01 ‘1211110111123 10 Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SODBIHJOJUIOIQ/ﬁdllq 11101; pop1201umoq

