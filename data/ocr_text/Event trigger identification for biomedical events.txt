ORIGINAL PAPER

Vol. 30 no. 11 2014, pages 1587—1594
doi: 10. 1 093/bioinformatics/btu061

 

Data and text mining

Advance Access publication January 30, 2014

Event trigger identification for biomedical events extraction using

domain knowledge

Deyu Zhou”, Dayou Zhong1 and Yulan He2

1School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration,
Ministry of Education, Southeast University, Nanjing 210096, China, and 2School of Engineering and Applied Science,

Aston University, Birmingham B4 7ET, UK

Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: In molecular biology, molecular events describe observ-
able alterations of biomolecules, such as binding of proteins or RNA
production. These events might be responsible for drug reactions or
development of certain diseases. As such, biomedical event extrac-
tion, the process of automatically detecting description of molecular
interactions in research articles, attracted substantial research interest
recently. Event trigger identification, detecting the words describing
the event types, is a crucial and prerequisite step in the pipeline pro-
cess of biomedical event extraction. Taking the event types as
classes, event trigger identification can be viewed as a classification
task. For each word in a sentence, a trained classiﬁer predicts whether
the word corresponds to an event type and which event type based on
the context features. Therefore, a well-designed feature set with a
good level of discrimination and generalization is crucial for the per-
formance of event trigger identification.

Results: In this article, we propose a novel framework for event trigger
identification. In particular, we learn biomedical domain knowledge
from a large text corpus built from Medline and embed it into word
features using neural language modeling. The embedded features are
then combined with the syntactic and semantic context features using
the multiple kernel learning method. The combined feature set is used
for training the event trigger classifier. Experimental results on the
golden standard corpus show that >2.5% improvement on F-score
is achieved by the proposed framework when compared with the
state-of—the—art approach, demonstrating the effectiveness of the
proposed framework.

Availability and implementation: The source code for the proposed
framework is freely available and can be downloaded at http://cse.seu.
edu.cn/people/zhoudeyu/ETI_Sourcecode.zip.

Contact: d.zhou@seu.edu.cn

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on October 1, 2013; revised on January 23, 2014; accepted
on January 24, 2014

1 INTRODUCTION

In molecular biology, molecular events describe observable alter-
ations of biomolecules, such as binding of proteins or RNA
production. These molecular events inﬂuence the formation of
a phenotype, which may be responsible for drug reactions or

 

*To whom correspondence should be addressed.

development of certain diseases. However, knowledge about
these events is scattered in the scientiﬁc literature with continuing
fast growth. Tremendous systematic and automated efforts are
required to use the underlying information. As such, biomedical
event extraction attracted much research interest recently.
Several evaluation tasks, such as BioNLP’09 (Kim et al., 2009),
BioNLP’ll (Kim et al., 2012) and BioNLP’13 (Nédellec et al.,
2013) shared tasks, have been held in recent years to allow re-
searchers to develop and compare their methods for biomedical
events extraction.

In general, each biomedical event consists of a trigger and one
or more arguments. For example, ‘. . .inhibiting tyrosine phos-
phorylation of STAT6 . . .’ describes two events, one is the phos-
phorylation event and the other is the negative regulation event,
which is signaled by the word ‘inhibiting’ and takes the ﬁrst
phosphorylation event as its argument. In a typical biomedical
event annotation, these two events are represented as follows:

E1 (Event Type:Phosphorylation, Theme:STAT6, ToLoc:
tyrosine)

E2 (Event Type: Negative_regulation:inhibiting Theme:E1)

Biomedical event extraction aims to extract such event informa-
tion from biomedical literature and reformats this extracted
information in structures as represented by the two annotations
presented above. By extracting detailed behaviors of biomol-
ecules, biomedical event extraction can be used to support the
development of biomedical-related databases.

To extract events from texts, most systems rely on a pipeline
procedure, which usually consists of three cascaded modules
including biomedical term identiﬁcation, event trigger identiﬁca-
tion and event argument detection (Zhou and He, 2011). In such
pipeline-based approaches, it is crucial to identify event triggers
reliably, as errors in an early stage will be propagated and hurt the
performance of the subsequent module. Analysis on the event
extraction results show that >60% of extraction errors are attrib-
uted to the errors of event trigger identiﬁcation (Pyysalo et al.,
2012). To achieve a better performance, existing approaches to
event trigger identiﬁcation are mostly based on learning classiﬁers
from annotated data instead of using manually constructed dic-
tionaries containing a list of trigger words or manually deﬁned
linguistic rules. In such approaches, event types are treated as
classes, and the aim is to classify words in sentences as indicating
a particular event type or not by taking the context features
including the syntactic and semantic features into account.

 

© The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 1587

112 ﬂJO'smumo[pJOJXO'sopchOJuioiq/ﬁd11q IIIOJJ pepcolumoq

910K ‘09 lsnﬁnV no :2

D.Zhou et al.

 

Table 1. The sentences in the MLEE Corpus in which ‘hydrolysis’ was
annotated as an event trigger

 

Sentences

 

1 Angiostatin inhibits both ATP synthesis and ATP hydrolysis (Moser
et al., 2001) and interferes with intracellular pH regulation Wahl and
Grant, 2002; Wahl et al., 2002).

2 Our data suggest that VEGFR2—mediated regulation of endothelial
function is dependent on different, but speciﬁc, Rab-mediated GTP
hydrolysis activity required for endosomal trafﬁcking.

 

Table 2. Examples of the similar contexts where the two words
‘proteolysis’ and ‘hydrolysis’ occur in Medline

 

Hydrolysis Proteolysis

 

Use of indices of proteolysis of
caseins such as the protease—
peptone, m-casein and PI

An increase of the products of
casein hydrolysis, the protease—
peptone (p—p) fraction and
minor ( m ) caseins

With the ease of resistance to
proteolysis, the development of
sequence-speciﬁc AApeptides. . .

AApeptides are resistant to
enzymatic hydrolysis

 

However, such approaches rely on abundant annotated train-
ing data and may not work well when certain event instances are
rare in the training data. For example, the word ‘proteolysis’
does not occur as an event trigger for catabolism type in the
training data of the multi-level event extraction (MLEE)
corpus (Pyysalo et al., 2012). Therefore, it is difﬁcult to recognize
it as an event trigger in the sentence ‘The effects of IGF-1 are
mediated principally through the IGF-IR but are modulated by
complex interactions with multiple IGF binding proteins that
themselves are regulated by phosphorylation, proteolysis, poly-
merization, and cell or matrix association’, which appears in the
test set. Nevertheless, we notice that another word ‘hydrolysis’
was annotated as an event trigger in the training data as shown in
Table 1. If we search through Medline (http://www.ncbi.nlm.nih.
gov/entrez/query/static/overview.html), we can ﬁnd that the two
words ‘proteolysis’ and ‘hydrolysis’ occur in similar context thus
tend to have similar meanings following the distributional hy-
pothesis (Harris, 1970). Examples of the similar context where
‘proteolysis’ and ‘hydrolysis’ occur in Medline are presented in
Table 2. If we can learn such domain knowledge and incorporate
it into trigger word identiﬁcation, then ‘proteolysis’ might be
correctly identiﬁed as an event trigger even if it did not appear
in the training data at all.

In this article, we argue that biomedical domain knowledge,
such as words, tends to occur in similar context, is highly related
and this can be incorporated into the learning process of the
event trigger classiﬁer to improve the performance of trigger
word identiﬁcation. In speciﬁc, we propose a novel framework
to learn biomedical knowledge from a large text corpus built
from Medline and embed it into word features using neural lan-
guage modeling. The embedded features are further combined

with the well-designed syntactic and semantic context features
using the multiple kernel learning (MKL) method for classiﬁer
training. We conducted extensive experiments on the MLEE
corpus (Pyysalo et al., 2012), and the results show that >2.5%
improvement on F-score is achieved using the proposed frame-
work when compared with the state-of-the-art approach, demon-
strating the effectiveness of the proposed framework.

The rest of the article is organized as follows. Section 2 pre-
sents the proposed framework, which consists of three steps,
domain knowledge embedding, local context features extraction
and MKL. Experimental setup and results are discussed in
Section 3. Finally, Section 4 concludes the article.

2 OUR APPROACH

Our proposed framework for event trigger identiﬁcation works
as follows, which is illustrated in Figure 1. First, scientiﬁc pub-
lications from Medline are crawled to form a corpus where
domain knowledge can be obtained. Then a neural language
model is built from such a corpus using unsupervised learning.
The distributional representation for each word is induced as the
feature of the word (word embedding). Then, for sentences in the
training and testing datasets, protein name identiﬁcation, syntac-
tic parsing and dependency parsing are performed and local
context features are extracted from the parsing results. After
that, features induced by neural language model and features
extracted from syntactic and dependency parsing results are com-
bined through MKL. Finally, training and testing are conducted
on the combined feature set.

In what follows, we ﬁrst describe how to formulate the task of
event trigger identiﬁcation as a classiﬁcation problem, in which
two sets of features, domain knowledge embedding and local
context features, are used. Then, we present how to learn the
parameters of our proposed uniﬁed classiﬁcation framework
using MKL. Finally, we discuss how the two feature sets can
be constructed.

2.1 Problem deﬁnition

Event trigger identiﬁcation in the biomedical domain can be seen
as the task of assigning labels to words. Existing approaches for
event trigger identiﬁcation typically rely on annotated training
data where those event trigger words are labeled with their cor-
responding event types. A rich set of manually designed features
are then extracted from annotated sentences and fed into a clas-
siﬁcation algorithm such as support vector machines (SVMs) for
training. In our approach here, we adopt a similar procedure
of training a classiﬁer from annotated data for trigger word
identiﬁcation. However, apart from the annotated training
data, we additionally crawled articles from Medline to form a
corpus where domain knowledge can be extracted.

Given sentences 8 = {s,- : wilwiz...w,-,,i, i = l...L}, their corres-
ponding trigger annotations T ={t,-:a,-1a,-2...a,-,,i,i= l...L}
and an additional unannotated corpus where domain knowledge
can be extracted, 8” = {s,- : wilwiz...w,-ni, i = (L + l), (L + 2)...
(L + UL)} where L and UL are the numbers of sentences in
the training data and the domain corpus, respectively, the object-
ive is to estimate a hypothesis f : SH?" minimizing the prediction
error on unseen data. For traditional machine learning

 

1588

112 ﬂJO'sleumo[pJOJXO'sopemJOJutoiq/ﬁd11q IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV no :2

Event trigger identification using domain knowledge

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Medhne _ Unsupervised
Corpus Learning
Feature
Setl
pr.-.
processmg Local

Context
Features Set 2
Etraction

 

 

 

    
   

Training
D ata

V
Kernel _ SVM
Combination Clas sifier

v
Testing Event

Data Tri ers

    
   

      
 

 

 

 

 

 

 

Fig. 1. The system architecture of our proposed framework for event trigger identiﬁcation

approaches, f is determined by minimizing the loss between the
prediction f(<I>(w)) for the training instance w and its actual label
aw based on some loss function Loss. Here <I>(w) is the feature set
related to w. As will be shown in Section 2.4, local context
around w is used for constructing <I>(w). Moreover, to make
sure that words occurring in similar contexts share the same
class label, the loss between the prediction f2(\11(w’ )) of w’ and
aw is also minimized, where w’ is the word that is found to have
highest contextual similarity with w from in the domain corpus
and \Il(w’) is another type of feature set related to w’ . As will be
shown in Section 2.3, contextually similar words can be modeled
using neural language modeling. Because w’ is the word with the
highest contextual similarity with w, \Il(w’) can be approximated
as \Il(w). Our ﬁnal objective function is

f: argmin Z<Loss(f1<<1>(w».aw>+rLoss<f2<w(w)>.aw» <1)
f=(f1,f2)e® w

where r is a parameter controlling the trade-off between two
losses. When r: 0, Equation (1) reduces to the object function
for classiﬁcation based on local context features only.

2.2 Parameter learning

In our framework, we use the local context features derived from
the annotated training data for CI) and use word embeddings
induced from the domain corpus using neural language modeling
for \11. We use SVM for both f1 and f2 and f1 2 (WI, <I>(w)) + b1
and f2 = (w;, \Il(w)) + b2. Therefore, the above problem can then
be solved by optimizing the parameters of W1,W2,b1, b2, r.
However, these parameters cannot be optimized directly using
the general learning approach for SVM. By considering param-
eters optimization as learning the optimal weights of different
types of features from the data automatically, the problem is
converted into to feature combination. Under kernel learning,
feature combination is translated into kernel combination by
deﬁning two kernels K1, K2 based on <I>(w), \Il(w). There are
many possible ways for kernel combination. A simplest one is
to average several kernels by setting r: 1.

In our work here, we use MKL (Bach et al., 2004), which has
been shown to produce good results in object classiﬁcation in
computer vision (Gehler and Nowozin, 2009). The aim of MKL
is to learn a kernel combination during the training phase of the
algorithm by optimizing jointly over a linear combination of
kernels 1 ,8,K,-(w, w’) and the parameters of an SVM, where

m is the number of kernels to be combined. Under MKL, the
object function described in Equation (1) is changed to

2 N 2
Egg; 2 ﬁiaTKia + C 2 L<aw,. b + Z [sin-Wot) (2)
’ ’ i=1 j=1 i=1
where N is the number of training instances, C is a predeﬁned
positive trade-off parameter between model simplicity and clas-
siﬁcation error, typically used in SVMs, or = (a1, ...,aN)T is the
vector of dual variables corresponding to each separation con-
straint, K1 (W) = ((<I>(W1), c1>(W)),  (<1>(WN), <I>(W)))T, K2(W) =
((‘I’(W1)a $04)») "-9 (WW/N)» \IJ(W)))T9 K1 2 «(DOW)» q>(wj)))NxNa
K2 2 ((\II(w,-), \II(wJ-))) NX N and L(awj, t) = max(0, 1 — awjt) is the
hinge loss. For efﬁciency and interpretability, the objection func-
tion subjects to

131+l32=lal3120n3220 (3)

Here, ,61 and ,62 are the weighting of two features set. The prob-
lem can be solved using the SimpleMKL (Rakotomamonjy et al.,
2008) Toolbox (http://asi.insa—rouen.fr/enseignants/~arakotom/
code/mklindex.html). The decision function is of the following
form,

2
sign(Z ﬁi(Ki(x)TOt + 13)) (4)
i=1

2.3 Word embeddings learned by neural
language modeling

We use neural language modeling (Huang et al., 2012) to learn
word representations by discriminating the next word given its
local context and global context. Given a word sequence
s,- = (wi1,w,-2, ..., win) and a document  = (Wj1,WJ‘2, ..., wJ-m),
which contain s,, the goal of the model is to discriminate the
win (the correct one) from a random word w. Thus, the object
function of the model is to minimize the ranking loss for each

(Siadj):
22 Z max(0,1—f(sl-,cé)+f(s}’»aI-), (s)

i j we V\wi,,

where sl” 2 wi1,w,-2, ..., wi,n_1, w is the sequence by changing the
last word win into w. The dataset for learning the language model
can be constructed by considering all the word sequences in the
Medline corpus. Positive examples are the word sequences from

 

1589

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/[Z(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV no 22

D.Zhou et al.

 

Medline, whereas negative examples are the same word sequence
with the last word replaced by a random one.

Instead of using only local context for language model learn-
ing, document context (or global context) is also considered.
Thus, the score function f(s,-, (1,) is replaced by two functions,
score’(s,-, dj) and scoreg(s,-, 61,-), which are deﬁned to capture
local context and global context, respectively.

The score function of local context score’(s,-, dj) is calculated by
a neural network with one hidden layer:

d=amf+d) a

score] = Wéa’1 + bé (7)

where X1 = [x1,x2, ...,xn] is the concatenation of the n word
embeddings representing sequence s,-, g is an element-wise acti-
vation function such as tanh, a’1 is the activation of the hidden
layer with h’ hidden nodes, W’1 and WE are the ﬁrst and second
layer weights of the neural network, respectively, and bi, b3 are
the biases of each layer.

The score function of global context scoreg(s,-, dj) is calculated
by a two-layer neural network:

é=hwtw+ﬁ) c)
scoreg =  + bi (9)
where
fawm
ﬁ=ﬁ%——am
X; ¢(sz)
t:

which is the weighted average of all word vectors in the docu-
ment dj, q) is a weighting function describing the importance of
word wj, in the document a}, h is an element-wise activation func-
tion such as tanh, a? e Rhg X1 is the activation of the hidden layer
with hg hidden nodes, W? and W are the ﬁrst and second layer
weights of the neural network, respectively, and bf, bi are the
biases of each layer. The local score preserves word order and
syntactic information, whereas the global score uses a weighted
average that is similar to bag-of—words features, capturing more
of the semantics and topics of the document.

The gradient of the objective is sampled by randomly choosing
a word from the vocabulary as a corrupted example for each
sequence—document pair (si, dj). The derivative of the ranking
loss is taken with respect to the parameters and these weights
are updated via backpropagation.

2.4 Local contexts features

The syntactic and semantic features used in the framework are
generated from the outputs of GDep (a dependency parser)
(Sagae and Tsujii, 2007) and Enju parser (a syntactic parser)
(Miyao and Tsujii, 2008).

All the features used in the framework are extracted based on
(Pyysalo et al., 2012), described as follows:

0 Lexical and syntactic features of the word itself. The features
such as whether the word has a capital letter, whether it is at
the beginning of the sentences, whether it has a number,

whether it has a symbol, whether it is in a trigger word
dictionary, whether it is in a protein base form, its POS
tag and n-grams of characters (n = 2, 3, 4) are extracted.
For features like whether it has certain property, boolean
value is used for the feature value. In addition, to check
whether a word is in the trigger word dictionary, we con-
structed a dictionary by collecting all the trigger words from
the training set. Triggers that contain more than one word
are ﬁltered. Also, hyphenated compound words are added
into the dictionary if one of its words already appears in the
trigger word dictionary.

Local context features. For the sequence of three words
before or after the candidate word, n-grams (n = 1, 2, 3, 4)
are used. For example, for the word ‘retarget’ in the sentence
‘The binding of I kappa B/MAD—3 to NF-kappa B p65 is
sufﬁcient to retarget NF-kappa B p65 from the nucleus to
the cytoplasm’, the word sequence ‘is sufﬁcient to retarget
protein from the’ is used to generate the relevant n-grams.
Also, each word is represented by its base form, the POS tag
and the relative position (before or after) to the target word.

Local dependency features. The two-depth path started from
the candidate word in the dependency tree generated from
the GDep parser is identiﬁed ﬁrst. Features are then ex-
tracted from the path such as n-grams (n = 2) of dependen-
cies, n-grams (n = 2, 3) of words represented by their base
forms and the POS tags and n-grams (n = 2, 3, 4) of depen-
dencies and words. For word tokens not having two-depth
paths, such as the root node or the direct children of the root
node, these types of features are ignored. N-grams (n = 2) of
dependencies are represented as dependencyl—dependency2.
Similarly, n-grams (n = 2, 3) of words or n-grams
(n = 2, 3,4) of dependencies and words are represented as
wordl—word2—word3 or wordl—dependencyl—word2 and so
on. For example, for the word ‘retarget’ in the sentence ‘the
binding of I kappa B/MAD—3 to NF-kappa B p65 is sufﬁ-
cient to retarget NF -kappa B p65 from the nucleus to the
cytoplasm.’, its two-depth path ‘retarget —> AMOD —> suf-
ﬁcient —> PRD —> is’ can be retrieved from the GDep par-
sing results. Its n-grams (n = 2) of dependencies are given as
‘AMOD PRD’.

Shortest path features. The shortest path, a directed path
between the candidate and the closest protein, is also
retrieved from the dependency parse generated from GDep
parser. The vertex walks, edge walks, n-grams (n = 2, 3, 4) of
dependencies, n-grams (n = 2, 3, 4) of words represented as
base forms plus POS tags and the length of path are ex-
tracted as the path features. For example, for the word
‘retarget’ in the sentence ‘The binding of I kappa B/MAD-
3 to NF-kappa B p65 is sufﬁcient to retarget NF -kappa B
p65 from the nucleus to the cytoplasm.’, its shortest path is
‘retarget<— OBJ <—protein’. The length of path that is 1,
edge walks as retarget<— OBJ <—protein, vertex walks as
OBJ can be extracted. The reason of using shortest path is
that a candidate and its closest proteins are much more
likely to be involved in a biomedical event. Thus, features
extracted from the shortest path should be useful for detect-
ing triggers in biomedical event extraction.

 

1 590

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/[Z(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV uo 22

Event trigger identification using domain knowledge

 

3 EXPERIMENTS

In this section, we present our experiments to evaluate the effect-
iveness of the proposed framework. We will ﬁrst discuss results
obtained on event trigger identiﬁcation in comparison with the
best performance obtained so far. We will then present perform-
ance comparison results with or without using the MKL method
for comparison, followed by the results of using neural language
models trained under different corpora. Finally, we compare our
results with those obtained using the latent Dirichlet allocation
(LDA) model as another distributional semantics approach
instead of neural language modeling.

3.1 Experimental setup

We used MLEE corpus for our experiments on trigger words
identiﬁcation. Instead of focusing exclusively on molecular-
level entities and process, MLEE corpus is extended to encom-
pass all levels of biological organization from the molecular to
the whole organism. The corpus is generated from 262 PubMed
abstracts on angiogenesis, which involves a tissue/organ—level
process closely associated with cancer and other organism-level
pathologies. Texts in that domain represent a good test case for
event extraction across multiple levels of biological organization.
The annotation follows the guideline formalized in the BioNLP
2009 Shared Task on event extraction. In this guideline, events
are n-ary associations of participants (entities or other events)
with speciﬁc role such as theme and cause. Each event is assigned
a type from a ﬁxed set deﬁned for the task (e.g. binding and
phosphorylation) and is associated with a speciﬁc span of text
stating the event, termed the event trigger. The events are cate-
gorized as four groups such as ‘ANATOMICAL’,
‘MOLECULAR’, ‘GENERAL’ and ‘PLANNED’, which are
further classiﬁed into 19 classes. These 19 classes are the target
classes of our trigger word classiﬁer. It is worth noting that we
used a combination of training and development datasets of the
MLEE corpus for training, and the test set for testing.

To train a neural language model, we additionally built a
corpus from Medline because of its wide coverage of topics in
the biomedical domain. Abstracts of biomedical literature pub-
lished in 2011 and 2012 were retrieved to build the corpus.

All the sentences in the Medline corpus were preprocessed
such as lowercasing and stemming. We chose the most frequent
words in the corpus to construct vocabularies with different size
D = {15, 000, 30, 000, 60, 000, 90, 000}. Words starting with
a digital number are mapped to the ‘NUMBER’ token. Words
starting with a special character are mapped to the ‘UNUSUAL’
token. Other rare words not in the dictionary are replaced with
the ‘UNKNOWN’ token. For neural language model training,
we used 50 dimensional embeddings and set the number of
hidden units to 100.

3.2 Experimental results

This section presents the evaluation results in details. In our
framework, the one-versus-rest SVMs are used for trigger word
classiﬁcation. To alleviate the unbalanced classiﬁcation problem,
we boosted the positive examples by placing more weights on
them during training.

Table 3. Comparison of the performance of event trigger identiﬁcation

 

 

Method Recall (%) Precision (%) F-score (%)
Baseline 81.69 70.79 75.84
Proposed 81.29 75.56 78.32

 

3.2.1 Event trigger identification results We implemented a
baseline following the approach proposed in (Pyysalo et al.,
2012), which achieved the state-of-the-art performance on trigger
word identiﬁcation using the features extracted from the syntac-
tic and semantic parsing results as described in Section 2.4. We
conducted experiments on the MLEE corpus and compared our
framework with the baseline approach. Table 3 lists the recall,
precision and F-score obtained on the test set of the MLEE
corpus. In the results reported here, we trained a neural language
model on the Medline corpus with the vocabulary size of 30 000.
Using the features induced from the learned neural language
model, the performance of event trigger identiﬁcation is
improved signiﬁcantly with ~5% on precision. The overall im-
provement on F -score is ~2.5%. To further investigate how the
improvement is achieved, we analyzed the experimental results of
the baseline approach and the proposed framework. We found
that positive instances identiﬁed correctly by the baseline ap-
proach are still identiﬁed correctly by the proposed framework
in 97.8% of cases. Out of the false-negative instances identiﬁed
by the baseline, 7.8% were correctly identiﬁed as positive in-
stances by our framework.

To further study the difference of our proposed framework
against the existing state-of-the-art approach in different event
categories, we list the detailed results in each event category in
Table 4. It can be observed from the table that of 19 event types,
our proposed framework outperforms the baseline approach on
13 event types and gives almost identical results on another 5
event types. To investigate the performance improvement under
different event types, we analyze the relationship between per-
formance improvement and the size of the training data in each
event category. The results are illustrated in Figure 2. It can be
observed that the performance improvement decreases when the
size of the training data increases. The largest improvement
(100%) is achieved in the ‘dephosphorylation’ event type when
there are only ﬁve training instances. Our approach successfully
identiﬁed the ‘dephosphorylation’ event triggers in all three in-
stances in the test set, while the baseline approach failed to iden-
tify any of them. When the training data are relatively abundant,
our approach appears to have less improvement compared with
the baseline.

From the above observations, we can speculate that our
proposed framework with domain knowledge incorporated is
particularly effective when facing with scarce training data.
The only exception is the ‘transcription’ event type with 30 train-
ing instances for which the baseline identiﬁed one event trigger
correctly from the test set, while our approach failed to recognize
any. It is shown as negative performance improvement in
Figure 2. One possible reason is that words contextually similar
to ‘transcription’ are not annotated in the training set either.

 

1591

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/[Z(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV uo 22

D.Zhou et al.

 

Table 4. Performance comparison of event trigger identiﬁcation in
different event types

 

Event Event type Method Recall Precision F-score
category (%) (%) (%)

 

69.77 63.83 66.67
67.44 78.38 72.5
83.51 68.07 75
81.44 69.30 74.88
96.33 95.70 96.01
97.33 98.65 97.99

Anatomical Cell proliferation
Development

Blood vessel develop

Growth 83.93 69.12 75.81
83.92 77.05 80.34
Death 94.29 56.90 70.97
88.57 72.09 79.49
Breakdown 34.78 80 48.48
34.78 80 48.48
Remodeling 60 85.71 70.59

60 85.71 70.59
50 33.33 40

50 40 44.44
93.94 83.78 88.57
92.42 84.72 88.41

Molecular Synthesis

Gene expression

Transcription 14.28 25 18.18
0 0 0
Catabolism 0 0 0
33.33 16.67 22.22
Phosphorylation 100 50 66.66
100 75 85.71
Dephosphorylation 0 0 0
100 100 100
General Localization 83 .46 79 .86 81.62
85.71 80.85 83.21
Binding 76.36 84 80
78.18 81.13 79.63
Regulation 60.37 46.48 52.52

53.05 56.49 54.72
86.73 67.85 76.14
86.41 71.58 78.30
77.03 74.35 75.66
78.83 77.09 77.95
75 53.92 62.73
75.64 56.46 64.66

Positive regulation
Negative regulation

Flamed Flamed process

"UW’UW’UW’UW’UW’UW’UW’UW’UW’UW’UW’UW"UWFUWFUWFUWFUWFUWFUW

 

Note: ‘B’ denotes the baseline approach, ‘P’ denotes our proposed method in the
‘Method’ column and the better performance is shown in boldface.

3.2.2 Comparison of feature combination methods To investigate
the effectiveness of the feature combination method based on
MKL, experiments were conducted where MKL is replaced
with a simple averaging method. In the average method, features
induced by neural language model and features extracted from
syntactic and semantic parsing results are combined with equal
weights. Table 5 shows the comparison result of the two meth-
ods. It can be observed that the precision of event trigger iden-
tiﬁcation is improved by >3% when using MKL for feature
combination. Nevertheless, its recall value slightly dropped.
The overall improvement on F-score is ~1.2%. Although the
improvement appears to be marginal, the MKL method should
still be favored for feature combination when precision value

100

 

80' -

4o— -

20' -

F—score Improvement (%)

 

 

 

1 2 3 4 5 6 7
Training size (2")

Fig. 2. Performance improvement versus size of training data in each
event category

Table 5. Event trigger identiﬁcation results with or without MKL

 

 

Method Recall (%) Precision (%) F-score (%)
Averaging 82.89 72.14 77.14
MKL 81.29 75.56 78 .32

 

Table 6. The coverage of all the distinct words and the coverage of all the
words in our crawled Medline corpus for each vocabulary

 

 

Size of Coverage of all the Coverage of all
vocabulary distinct words (%) the words (%)

15 000 0.84 95.07

30 000 1.68 96.57

60 000 3.36 97.56

90 000 5.04 97.98

 

could well be regarded as much more important than recall in
the open biomedical domain.

3.2.3 Impact of dictionary size on neural language modeling The
vocabulary size D in the neural language model is set in advance.
If D is too small, some semantically important words might be
omitted. On the contrary, if D is too big, some noisy words might
be included and it becomes expensive to train the neural lan-
guage model. To explore whether and how vocabulary size in
the neural language model impacts the trigger word identiﬁca-
tion performance of the proposed framework, four different
vocabularies were used in neural language model learning. We
ﬁrst list in Table 6 the coverage of all the distinct words and the
coverage of all the words in our crawled Medline corpus for each
vocabulary. It shows that the top most frequent words occur
most of the time. For all the vocabularies we experimented

 

1 592

112 ﬂJO'sleumo[pJOJXO'soi1emJOJuioiw/2d11q IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV uo 22

Event trigger identification using domain knowledge

 

Table 7. Event trigger identiﬁcation performance with neural language
model with different vocabularies

 

Size of vocabulary Recall (%) Precision (%) F-score (%)

 

15 000 82.03 73.90 77.75
30 000 81.29 75.56 78.32
60 000 81 .29 75 78.02
90 000 80.60 74.68 77.53

 

Table 8. Event trigger identiﬁcation performance with neural language
model trained from difference sources

 

 

Method Recall (%) Precision (%) F-score (%)
Wikipedia 82.60 70.50 76.07
Medline 81.29 75.56 78.32

 

here, they cover at least 95% of word occurrences in the whole
corpus.

Table 7 lists the results obtained on the test set of the MLEE
corpus with different vocabulary size. It can be observed that the
ﬁnal performance of the proposed framework outperforms the
baseline approach regardless which vocabulary was used. The
relative improvement on F -score ranges between 1.7 and 2.5%.
We also observe that increasing the vocabulary size improves the
performance with the peak reached at 30 000. Based on the above
observation, we can conclude that the choice of the vocabulary
can be made by considering its coverage of the words in the
corpus.

3.2.4 Learning neural language model from difference source To
explore the effectiveness of embedding domain knowledge into
language model, we compare the event trigger identiﬁcation re-
sults with neural language model trained on Wikipedia
(Collobert et al., 2011). The Wikipedia corpus contains a wide
range of topics in general domains. The results are shown in
Table 8. Compared with the baseline approach, using the
Wikipedia corpus did not appear to improve the performance
of event trigger identiﬁcation. Nevertheless, learning the neural
language model from the Medline corpus gives superior perform-
ance on event trigger identiﬁcation than the baseline. Only
domain-speciﬁc knowledge can be used to improve the perform-
ance of event trigger identiﬁcation.

3.2.5 Neural language model versus topic model To further in-
vestigate the effectiveness of neural language model, we compare
the event trigger identiﬁcation results with word classes induced
by the LDA model, which is a generative graphical model ori-
ginally proposed for topic discovery (Blei et al., 2003). Assuming
that each document is represented as an unordered collection of
words and characterized by a particular set of topics, disregard-
ing grammar and word order, the LDA model can be used for
grouping the words in similar topics in an unsupervised way.
Each word in the LDA model is represented as probability

Table 9. Event trigger identiﬁcation performance using neural language
modeling versus LDA

 

 

Method Recall (%) Precision (%) F-score (%)
Baseline 81.69 70.79 75.84
LDA 81.12 71.64 76.08
NLM 81.29 75.56 78.32

 

distribution over topics, and then combined with the features
described in Section 3.2 for training SVM classiﬁers for event
trigger identiﬁcation. In our experiments, the LDA model by
varying the number of topics {50, 100, 150, 200, 250} using the
Stanford topic modeling toolbox (http://nlp.stanford.edu/down—
loads/tmt/tmt-0.4/). The optimal topic number is chosen using
the perplexity measure on the 10% held-out set from our
Medline corpus. The ﬁnal event trigger identiﬁcation results
using LDA are reported in Table 9 by setting the topic number
to 200. It can be observed that LDA only gives an almost neg-
ligible improvement of 0.24% in F -score compared with the
baseline and it performs worse than our proposed framework
using neural language modeling. Two possible reasons are (i)
LDA ignores word ordering in documents, which is important
when comparing words occurring in similar semantic context and
(ii) it is difﬁcult to choose the proper number of topics (or word
classes) that group words into well-separated semantic clusters.
On the contrary, our proposed framework is based on neural
language modeling, which learns the distributional representa-
tion of words without the need of specifying the number of
induced word classes.

4 CONCLUSIONS AND FUTURE WORK

In this article, we have proposed a novel framework to construct
a feature set for learning classiﬁers for event trigger identiﬁca-
tion. In particular, biomedical domain knowledge is learned
from a large text corpus built from Medline and embedded
into word features using neural language modeling. The
embedded features are combined with the well-designed syntactic
and semantic context features, which is further used for event
trigger classiﬁer learning. Experimental results on the MLEE
corpus show that >2.5% improvement on F -score is achieved
by the proposed framework when compared with the state-of-
the-art feature-based approach, demonstrating the effectiveness
of our proposed framework. In future work, we will further in-
vestigate the feasibility of our proposed framework on other
corpora. Another possible future direction is to incorporate
domain-speciﬁc prior knowledge into neural language model
learning using semi-supervised learning to further improve the
performance of event trigger identiﬁcation.

ACKNOWLEDGEMENTS

The authors thank the anonymous reviewers for their insightful
comments. They also thank Dr Makoto Miwa for his suggestions
on constructing the baseline system.

 

1 593

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/[Z(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV uo 22

D.Zhou et al.

 

Funding: This work was funded by the National Natural Science
Foundation of China (61103077), PhD. Programs Foundation
of Ministry of Education of China for Young Faculties
(20100092120031), the Scientiﬁc Research Foundation for the
Returned Overseas Chinese Scholars, State Education
Ministry, the Cultivation Program for Young Faculties of
Southeast University and the Shenzhen International
Cooperation Research Funding (GJHZ20120613110641217).

Conflict of Interest: none declared.

REFERENCES

Bach,F.R. et al. (2004) Multiple kernel learning, conic duality, and the SMO algo-
rithm. In: Proceedings of the 21st International Conference on Machine Learning.
New York.

Blei,D. et al. (2003) Latent Dirichlet allocation. J. Mach. Learn. Res, 3, 993—1022.

Collobert,R. et al. (2011) Natural language processing (almost) from scratch. J.
Mach. Learn. Res, 12, 2493—2537.

Gehler,P. and Nowozin,S. (2009) On feature combination for multiclass object clas-
siﬁcation. In: IEEE 12th International Conference on Computer Vision 2009,
Vol.1. pp. 221—228.

Harris,Z. (1970) Distributional structure. In: Papers in Structural and
Transformational Linguistics. D. Reidel Publishing Company, Dordrecht,
Holland, pp. 775—794.

Huang,E.H. et al. (2012) Improving word representations via global context and
multiple word prototypes. In: Annual Meeting of the Association for
Computational Linguistics 2012, Vol. 1. pp. 873—882.

Kim,J.-D. et al. (2009) Overview of bionlp’09 shared task on event extraction. In:
Proceedings of the Workshop on BioNLP. NJ, pp. 1—9.

Kim,J.D. et al. (2012) The genia event and protein coreference tasks of the bionlp
shared task 2011. BM C Bioinformatics, 13, SI.

Miyao,Y. and Tsujii,]. (2008) Feature forest models for probabilistic hpsg parsing.
Comput. Linguist., 34, 35—80.

Nédellec,C. et al. (2013) Overview of bionlp shared task 2013. In: Proceedings of the
BioNLP Shared Task 2013 Workshop. Bulgaria, Soﬁa, pp. 1—7.

Pyysalo,S. et al. (2012) Event extraction across multiple levels of biological organ-
ization. Bioinformatics, 28, i575—i581.

Rakotomamonjy,A. et al. (2008) SimpleMLK. J. Mach. Learn. Res, 9, 2491—2521.

Sagae,K. and Tsujii,]. (2007) Dependency parsing and domain adaptation
with LR models and parser ensembles. In: EMNLP-CoNLL’2007, Vol. 1,
pp. 1044—1050.

Zhou,D. and He,Y. (2011) Biomedical events extraction using the hidden vector
state model. In: Artificial Intelligence in Medicine, Vol. 53, pp. 205—213.

 

1 594

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/[Z(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV uo 22

