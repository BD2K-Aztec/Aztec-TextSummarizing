ORIGINAL PAPER

Vol. 27 no. 22 2011, pages 3102-3109
doi: 1 0. 1 093/bioinformatics/btr545

 

Sequence analysis

Advance Access publication September 28, 2011

Fast filtering for RNA homology search

Diana L. Kolbe and Sean R. Eddy*

Janelia Farm Research Campus, Howard Hughes Medical Institute, Ashburn, VA 20147, USA

Associate Editor: Ivo Hofacker

 

ABSTRACT

Motivation: Homology search for RNAs can use secondary structure
information to increase power by modeling base pairs, as in
covariance models, but the resulting computational costs are high.
Typical acceleration strategies rely on at least one filtering stage using
sequence-only search.

Results: Here we present the multi-segment CYK (MSCYK) filter,
which implements a heuristic of ungapped structural alignment
for RNA homology search. Compared to gapped alignment, this
approximation has lower computation time requirements (O(N4)
reduced to O(N3)), and space requirements (O(N3) reduced to
O(N2)). A vector-parallel implementation of this method gives up
to 100-fold speed-up; vector-parallel implementations of standard
gapped alignment at two levels of precision give 3- and 6-fold
speed-ups. These approaches are combined to create a filtering
pipeline that scores RNA secondary structure at all stages, with
results that are synergistic with existing methods.

Availability: http://selab.janelia.org/publications.html#KolbeEddy11
Contact: eddys@janelia.hhmi.org

Received on July 13, 2011; revised on September 22,2011; accepted
on September 23, 2011

1 INTRODUCTION

A covariance model (CM) is a probabilistic proﬁle model of one or
more structural RNAs with a consensus secondary structure. CMs
are used for database search and for multiple alignment, and form
the basis for the Rfam database of known structural RNAs (Gardner
et al., 2011). Explicitly modeling the secondary structure allows the
model to capture information about an RNA when the base pairs are
preserved even if the sequence changes. A CM includes states that
can describe a base pair as a single unit, so that the score can favor
good combinations rather than only single residue conservation; the
states are arranged in a branching tree structure that reﬂects the
shared consensus fold of the RNA. Inclusion of secondary structure
increases the sensitivity and speciﬁcity of homology searches for
RNA compared to sequence proﬁle methods (Freyhult et al., 2007).
CMs do neglect some higher order features of RNA structure, such as
pseudoknots, but this is generally acceptable for homology search.
A large obstacle to the application of CMs is one of the computational
costs: both memory and time requirements have worse scaling
behavior than their sequence—only counterparts.

Many different approaches have been used for increasing the
speed of CM search and alignment. Acceleration methods generally
fall into three classes: direct hardware acceleration of the base

 

*To whom correspondence should be addressed.

method (Liu and Schmidt, 2005), heuristic ﬁlters that reduce the
number of sequences to be searched and heuristic bands that reduce
the number of possible alignments per sequence. Filtering and
banding techniques for RNA search can be based on sequence—
only or sequence—and—structure models, but one common approach
is a sequence—only ﬁlter such as the BLAST ﬁlter used in the
Rfam database pipeline (Gardner et al., 2011). Recent work in
ﬁltering methods has focused on the automatic design of proﬁle
HMMs and on models that include small amounts of structural
information (Weinberg and Ruzzo, 2004a, b, 2006). Structure
description languages and heuristic RNA structural search methods
stand on their own, but can also be used as structure—based ﬁlters for
CM search (Bafna and Zhang, 2004; Lowe and Eddy, 1997; Macke
et al., 2001). A recent example in this area also focuses on automatic
rather than manual creation of ﬁlters (Sun and Buhler, 2008).
Banding approaches for CM search include HMM bands (Brown,
2000) and structure—derived bands (Nawrocki and Eddy, 2007), and
similar methods are used in other types of RNA algorithms such as
combined alignment and folding (Havgaard et al., 2005; Mathews
and Turner, 2002).

The Infernal software package includes an accelerated search
pipeline that incorporates several of these ideas (Nawrocki et al.,
2009). This pipeline begins with maximum—likelihood HMM ﬁlters
derived from the CM (Weinberg and Ruzzo, 2006), followed by
HMM—banded structural alignment (Brown, 2000). These results are
further passed to alignment using structure—based query—dependent
banding (QDB) (Nawrocki and Eddy, 2007). The ﬁnal scoring is
done by the Inside algorithm, which integrates over all possible
alignments rather than only considering the single best alignment.
The use of ﬁlters does decrease sensitivity somewhat, but it provides
~30—fold speed improvements (Nawrocki et al., 2009).

The 3.0 version of the HMMER software package for proﬁle
hidden Markov models (http://hmmer.janelia.org) also includes an
acceleration pipeline for searches, but its approach is conceptually
quite different. HMMER3 begins with ungapped alignment, under
a model that produces short alignment segments with position—
speciﬁc scores and no indels, and also includes a loop that allows the
detection and combined scoring of a set of these hits interspersed
with unaligned sequence; this is called the multi—segment Viterbi
(MSV) algorithm. A second stage performs more typical Viterbi
alignment including gaps, before a ﬁnal ﬁlter that calculates the
Forward score, the total likelihood of the sequence, integrating
over all possible alignments. Sequences that pass all three ﬁlter
stages are subjected to some additional processing before being
displayed in the results. In addition to this tiered approach moving
from simpler to more complex models, HMMER3 uses SIMD
vector parallelization at each ﬁlter stage to decrease the time
requirements. The ﬁrst stage MSV calculation runs with 16—fold

 

© The Author(s) 2011. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0), which permits unrestricted non—commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.

112 /§.IO'SIBUJHOprOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq 11101; prBOIUAAOG

9IOZ ‘09 lsnﬁnv uo ::

Fast filtering for RNA Search

 

vector parallelization, and the successive stages gradually reduce
the number of simultaneous operations in order to increase the
precision of the calculations. This acceleration strategy has been
quite effective, with internal benchmarks indicating that HMMER
now has speed comparable to BLAST for many typical searches.
Because of the similarity between the underlying models of
HMMs and CMs, we reasoned that Infernal might also beneﬁt from
an acceleration pipeline modeled after the one in HMMER. We knew
that the HMM—based ﬁlters are less effective for RNA families that
have diverse members and little primary sequence conservation,
so we wanted to design an approach that would use structural
information at all stages. This necessitated a somewhat different
design of each pipeline stage, but we sought to retain the core ideas:
short, ungapped, multi—hit alignment for initial screening; gradually
increasing alignment complexity through multiple ﬁlter stages; and
parallelization to increase the base speed of each alignment stage.

2 ALGORITHM

Before moving to a description of the method, we give a brief
overview of an established notation for covariance models; a more
complete description is available in earlier works (Durbin et al.,
1998; Eddy, 2002). Sequence positions are indexed by i, j, and k;
x,- indicates the residue of sequence x at position i. A subsequence
xi..xj has length d = j — i—l— l. A covariance model is represented as
M states of various types—Start (S), Pair emit (P), Left emit (L),
Right emit (R), Delete (D), Bifurcation (B), End (E), with the type of
state v represented by SV—related by transition probabilities tv(y)
for moving from state v to state y. For those states which model
residues, there is also a set of emission probabilities ev (xi) for single
bases and ev (xi,xj) for pairs.

The states are conceptually ordered into larger groups called
nodes, where one state in each node represents consensus, and
the remainder provide alternatives of insertions and deletions. The
nodes are organized in a branching tree structure that represents
the consensus fold of the RNA: beginning from a single Start
state, proceeding through various states to produce residues, and
branching at bifurcation states to produce new stems, with each
branch ﬁnally terminating at an End state. An overview of the
relationship between a multiple alignment, a structure and a CM
is given in Figure l.

2.1 Ungapped single-hit consensus matches

The ﬁrst step in our heuristic ﬁlter considers ungapped consensus
hits. By removing the possibility of gaps, we simplify the model
considerably, removing all insertion and deletion states and leaving
each consensus state as the only representative of its node. This also
eliminates the need for transition probabilities, with a deterministic
path describing the complete model. We can then deﬁne a consensus
hit to be a match to an unbranched continuous range of these
states. The unbranched nature of matches is a key step in model
simpliﬁcation: as long as matches are unbranched, extending an
alignment that currently includes (v, j ,d) is a ﬁxed time operation,
since the next state is uniquely deﬁned and it corresponds to known
changes in the values of j and d. In contrast, extending through a
bifurcation requires time proportional to d, since each position could
split the sequence between the two halves of the branch. Although
match extension is ungapped, we do not constrain the initial value

of d, allowing signiﬁcant variation in the length of sequence outside
the match, unlike the otherwise conceptually similar SSP ﬁlters (Sun
and Buhler, 2008). The scoring of a match is still based on the
emission probabilities of its states, so a hit need not contain the
exact consensus sequence.

We can represent each possible hit as a state range w..y in our
simpliﬁed consensus model. The state which ‘begins’ the hit (closer
to the root of the model), w, will always be a state that represents at
least one residue. The hit may extend through an arbitrary number
of model states, matching 5’ and 3’ residues as described by the
consensus model. The ﬁnal state of the match y may be another
emitting state or it may be an end state (6). In the ﬁrst case, the
total match consists of two (possibly distant) subsequences aligned
to this range of states, xw"y and 37W” corresponding to the 5’ and
3’ portions, respectively (one but not both of these may be empty).
In the second case, reaching a model end connects the two portions
of sequence, leaving only a single uninterrupted subsequence xW"€.
These cases are similar to the V—type and wedge—type subproblems
described in Eddy (2002).

In outline, an optimal dynamic programming (DP) algorithm
matching only these single—hit consensus segments would look like
this: for each model state v in our consensus model, and for each
sequence position j from 1 to L, and for each subsequence length d
from 1 to j, the score 05(1), j ,d) is the better of either starting a new
alignment at that triple, or continuing an existing alignment from
the next state in the consensus path, if any. The best alignment then
corresponds to the set of (v,j,d) that maximize 05. Because these
hits are by deﬁnition unbranched, there is no point where we need
to consider subdividing the sequence in order to ﬁnd the best hit.
This reduces the time complexity of the algorithm from 0(N4) to
0(N3). Further, since we can calculate 05(1), j ,d) in one slice of the
DP cube, analogous to sequence alignment scores in one row of a
DP matrix, as long as traceback is not required memory usage can
be reduced from 0(N3) to 0(N2).

2.2 Multi-hit consensus matches

We expect that a single unbranched consensus match will be short,
being limited both by the presence of insertions and deletions in real
sequences, and by the branch divisions in the complete structure.
Therefore, we believe single—hit matches will be insufﬁcient to
reliably discriminate between homologous sequences and random
similarities. Our approach was designed to be multi—hit, ﬁnding local
groups of hits which can provide stronger signal than a single match.
Requiring these sets of hits to be fully consistent with the CM would
re—introduce the complexity that was eliminated in the unbranched
match stage, bringing the running time back up to 0(N4). Instead,
we derive a simpler probabilistic model from the CM that allows
these short hits to form arbitrary nested structures, possibly—but not
necessarily—consistent with the original consensus fold, as shown
in Figure 2. It is possible at this stage to have high—scoring regions
that are signiﬁcantly rearranged compared with the CM, but because
this is designed only as a ﬁlter, these sequences will be eliminated
at later, more stringent alignment stages.

A simple grammar provides the connections between the
ungapped segments in order to allow nested and sequential hits,
potentially with intervening unaligned sequence. This grammar has
two non—terminals: H, which produces an ungapped homologous
model segment, and J, which produces unaligned sequence and

 

3103

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq 11101; prBOIUAAOG

9IOZ ‘09 lsnﬁnv uo ::

D.L.Kolbe and S.R.Eddy

 

A C
human AAGACUUCGGAUCUGGCGACACCC
mouse UACACUUCGGAUGACGCCAAAGUG

r'at CACGCUUCGGAUGACACCACAGUG

.<<<....>.>>.<<.<...>>>

ED
Us
U1
iii r—
H H
V 63

A
\A 00
IIIIPII

G
C
G

 

'0
L0
CD

 

 

'—
|_\
S

 

 

 

'—
|_\
|_\

'—
|_\
W

C

/
m\

I>

\

('3

606 C e

l—

|_\

N

I'l'l
H
4s

    

CM construction

 

  
     

 
   

MATL 16

  
            
       
                
 

$534!“

A\A‘ ‘
w—A_ .: 7 ~

I-\

’0

1.
Ir

 

Z
l—
U'l
N
Z
50
U1
U)
U

MATP 17

I

w

i v

«1
IL

 

I1.
,4
11>
1x I

|_\
00
n

I
1
I
I
l
i .
I
1

    

l
l
1

k0
U

MATP 18

'UI—'U
Nl—‘
SLO
n

 

 

 

 

\N y“:

l—
N
|_\

'—
N
N

consensus-only
conversion

'—
N
U)

rn
N
4;

Fig. 1. Structure of a CM from a multiple sequence alignment. (A) A toy multiple sequence alignment, with conserved base pairs annotated by angle brackets.
(B) Corresponding structure for the human sequence. (C) Model construction of a CM. On the left is the ‘guide tree’, corresponding to the consensus structure,
with node types and numbers in boxes, and sequence residues in circles (the human sequence is shown). On the right is a small section of a full CM with insert
and delete states. Converting the CM to be consensus—only produces a model identical to the guide tree, except that the consensus state now also includes

residue probabilities, where the guide tree does not.

i

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq 11101; prBOIIIAAOG

A\
G o C /IJ
A /A°U
c‘ I ‘A
A U[U [G/
\C/G

Consensus hits,
consistent ordering

Consensus model

 

l:| HHL

G .C G\0C\
\ \G G.C\ U.A
C. \ U] C C/ \A
I ° / .
C\G-C \G ,U G/
U G

\C/

Consensus hits,
alternative ordering

Fig. 2. Multi—hit ungapped consensus matches. (A) Example of non—coding RNA, from Figure 1. Each shaded block represents one of many potential consensus
match segments. (B) Two consensus match segments in a database sequence. (C) Two consensus match segments to the same portions of the model, but in a

rearranged conﬁguration.

connects model segments under the following rules:

J—>Ja|JH|6 H—>xw"€|xw"yJ)_cW”y

where a is any unaligned residue, and w..e and w..y can be any
valid ranges in the model. This model has the effect of replacing all
model bifurcations with a single bifurcation capable of joining any
two segments.

Like the CM it is derived from, this model is intended to be
probabilistic, and so each of the possible rules described above has
an associated probability. The ﬁrst rule chooses between these three
potential productions with probabilities t1, t2 and t3, respectively.
The second rule potentially has a very large number of different

productions, depending on the number of valid state ranges w..y in
the model. We intend for all possible hits to be equally likely [similar
to HMMER3’s uniform segment length distribution (Eddy, 2008)],
so this transition is given a uniform value of tH for all possibilities
of w..y. The relative weight of V—type (y7ée) to wedge—type cases
(y =6) is determined by the numbers of each type that are possible
in the model. The choice of these parameters will be described in
more detail below.

Given a consensus model with M states, a window length W, and
a sequence of length L to search, we calculate a semi—HMM with two
states, alternating between segments of non—homologous sequence
and segments matching to the grammar non—terminal J, similar

 

3104

9IOZ ‘09 lsnﬁnv uo ::

Fast filtering for RNA Search

 

Multi—Segment CYK Algorithm (MSCYK)

7(0) = 0
for j = 1 to L
dMAX = min(j, W)
for d = 0 to dMAX
for szdownto 1 f

 

—oo
log(e,,(:1:j_d+1,  + J(j — 1, d — 2) + log(tH) if 8,, = P, d 2 2
log(e,,(xj_d+1,a:j)) + H(u —l— 1,j — 1,d — 2) if 8,, 2 Rd 2 2
Hmjad) = max, 10g(€v($j—d+1)) + JOBd- 11+10g(tH) if 8v = L,d 2 1
log(e,,(mj_d+1)) —l— H(’U + 1,3, 01 — 1) 1f 8,, = L, d 2 1
log(e,,(:1:j)) + J(j — 1,d — 1) + log(tH) if 8,, = R, d 2 l
log(e,,($j))—l—H(v—l—1,j—1,d—1) if8,,=R,d21
Klog,(tH) if 8,, = E, d = 0

Hbest<ja d) = maX1§U§M(H(vaj7 d»

J(j—1,d—1)+log(t1) idel

J(j, d) = max maxlgkgduo' — k, d — k) -l— Hbest(j, k) -l— log(t2)) if d 2 1

log(t3)

70') = max {78 ‘ 1)

maX1gdngAx(7(j — d) + J0: d»

ifd=0

Fig. 3. Pseudo—code for the MSCYK algorithm. State types 8, are Pair, Left, or Right emitting, or End.

to models used in gene ﬁnders (Burge and Karlin, 1997; Durbin
et al., 1998). We then use the score y to track all positive—scoring
alignments as given in Figure 3. For hit detection, y is traced back,
and each usage of J (j ,d) is checked against a minimum reporting
threshold. This algorithm has the same general time complexity as
other variants of the CYK algorithm adapted for scanning long
sequences, namely 0(MLW—l—BLW2), where B is the number of
bifurcation states (B <M, and generally B~log(M)). The major
changes for MSCYK are a large reduction of M, and B ﬁxed at
1, rather than being a variable deﬁned by the model, reducing time
complexity to 0(LW2) ~ 0(N3). As full traceback of which model
segments were used is not required, memory requirements can also
be reduced from 0(MW2) to 0(W2).

3 IMPLEMENTATION

3.1 Parameterization

In the above description, we have used the values t1, t2, t3 and tH
without discussion of how these parameters are set or determined.
Because they represent probabilities, they are constrained to the
[0, 1] interval, and we introduce an additional constraint, which is
the expected sequence length generated by the model. We set the
expected length to be equal to the consensus length of the CM,
a proxy for the expected length of that CM. Given the expected
sequence length (n), the expected length of a single consensus hit
mm and the fraction of all model fragments that are V—type r (those
that do not reach an End state),
t2: <n>—t1(<n>+1)

(1+r)<n>+<nH>
and

t3 = I — t1 — t2

leaving t1. Intuitively, t1 describes the proportion of unaligned
residues—higher values imply longer stretches of unaligned residues
and fewer model segments overall, and the converse, lower values
favor fewer unaligned residues and more frequent matches. Based
on anecdotal testing of discrimination between real and random
sequences, the default for t1 is set to 0.25.

The parameter tH is designed to provide a uniform distribution
across all model fragments w..y that non—terminal H could match,
deﬁned as W. The number of fragments, expected length of
fragments mm and proportion of V—type fragments r are entirely
dependent on the original CM, and are calculated when building the
consensus—only model. (Implementation details are available in the
function cm_consensus_Convert ( ) .)

3.2 P-Value determination

In order to effectively use this short match alignment method as a
ﬁlter, we must be able to determine a score threshold for each model
that will pass a certain percentage of all input sequences. Although
this model is unusual in terms of sequence alignment, it is still a
probabilistic model with log—likelihood scoring, so we expect that
maximum scores will follow an Extreme Value Distribution (EVD,
speciﬁcally a type I EVD or Gumbel distribution). An EVD had
parameters ,u. for location, and A. for scale, here corresponding to
the rate of decrease in the frequency of increasingly higher scores.
With the accurate parameters for the EVD, we can easily convert
between scoring thresholds, P—values and expected ﬁlter pass rates.
Ideally, these parameters would conform to the conjectures of Eddy
(2008), with A. =log(2). Otherwise, if A. values for the full CM and
MSCYK models were near—equal, this value could be derived from
the EVD already ﬁt for the CM.

To test the ﬁt of an EVD, and the behavior of A. if so, we performed
simulations of the scores for alignment of random sequences under

 

3105

112 /§.IO'SIBUJHOIPJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 11101; papaoIUAAoq

9IOZ ‘09 lsnﬁnv uo ::

D.L.Kolbe and S.R.Eddy

 

 

 

 

Lambda for MSCYK EVD

 

 

A Score distribution for tRNA
1 
E Perfect EVD,
>< ‘ lambda = 0.958
A 10'1 ——
G.) E
L _
o _
o _
w _
:5 10'2 —.
3 E
U) I
G)
g _
a.) 10'3 _:
5 I
C' :
a) _
a) _
I..—
0 10-4 _:
C :
.9 :
E : Large simulation, ,
L 10-5 E 300,000 sequences ‘1‘
E ‘\
_ \
I I I
0 5 10

MSCYK score (bits)

 

  
 

B Estimated lambda for full CM and MSCYK
1.0 —  
0.9 —  
 3% tolerance
I. .  ' for lambda = ln(2)
0.5 —

 

 

 

| | I | : | | |
0.5 0.6 0.7 0.8 0.9 1.0

Lambda for CM EVD

Fig. 4. Extreme value distribution ﬁts for MSCYK scores. (A) An example EVD (in red) ﬁt to the scores for simulated random sequences against a model
of tRNAs (RF00005; 1052 sequences, average length 73). The default score simulation is shown in green (10 000 sequences); a larger simulation of 300 000
random sequences is in black. Dotted lines at the end of each simulation indicate uncertainty due to small numbers of sequences observed. (B) Estimated
lambda values for both CM scores and MSCYK scores, across all Rfam families. Tolerances of :l:3% are shown for approximating with a constant lambda of
1n(2), or for setting lambda for MSYCK equal to the lambda for the (already—simulated) EVD for the CM.

MSCYK alignment. Figure 4A gives a typical example, with some
divergence from an EVD for low scoring sequences, but quickly
converging to an exponential tail for higher scoring sequences.
Testing across all models in Rfam conﬁrmed that scores ﬁt an
exponential tail reasonably well. Unfortunately, the parameter values
,u. and A. show no particular trends. Although centered near 1n(2),
A. has too much variation to be approximated as constant, neither
,u. or A. is correlated with the corresponding parameters from the
full CM (Fig. 4B). We concluded that individual EVD ﬁtting
of each model is required. By default, the score simulation is
performed with 10000 random sequences of 1kb each, ﬁtting an
exponential tail to the 20% of sequences with the highest maximum
scores.

3.3 Vector parallelization

Dynamic programming algorithms are highly amenable to
acceleration by vector parallelization (Farrar, 2007; Rognes and
Seeberg, 2000; Wozniak, 1997); the HMMER3 pipeline applied
these techniques to its ﬁlter stages with good synergistic effect
(http://hmmer.janelia.org). We have implemented three versions
of vector parallel alignment; two of them score standard CYK
alignment (at 4X and 8X parallelism) and one implements the
MSCYK heuristic at 16X.

At 4X parallelism, CYK is implemented in single—precision
ﬂoating—point log—odds probabilities, fully replicating the calculation
of the non—parallel reference algorithm. The code release provides
both SSE_CYKInsideScore ( ), a score—only version and

SSE_CYKDivideAndConquer ( ) , a version with memory—
efﬁcient alignment traceback. Empirically, they give ~ 3 X speed—up
compared with the serial reference versions (without and with
traceback, respectively).

The 8 X parallel version of CYK uses 16—bit numbers rather than
32—bit; this necessitates a switch from ﬂoating—point representation
to scaled and rounded integers. Internally, all log—likelihood score
values are scaled up by 500 and rounded, with the maximum possible
score corresponding to a score of approximately 65 under the CM.
We use saturated arithmetic to ensure that extending an alignment
with the maximum score retains that score. High—scoring sequences
will have multiple alternative alignments that should exceed the
cap by variable amounts, so arbitrarily choosing one of those
alignments no longer makes sense. Full details for this score—only
implementation can be found in SSE_CYKFilter_epil6 ( ) in
the code. Observed speed—up is ~6—fold (Fig. 5A).

The MSCYK short match algorithm described above is
implemented at even higher parallelism, using 16 simultaneous
calculations. This allows only 8 physical bits per score, with
the extremely limited range of 0—255. To accommodate this, the
ﬂoating point values are scaled scaled by 3 and offset for an
effective range of —65 to 20 bits of information; again, saturated
arithmetic prevents overﬂow. This implementation also switches
from vectorization of adjacent cells in the matrix to using the striped
method introduced by Farrar (2007). The full implementation is
in function SSE_MSCYK ( ) . The empirical speed—up of this stage
depends both on the parallelization and on the MSCYK heuristic; we
compare MSCYK to its closest equivalent, a CYK algorithm adapted

 

3106

112 /§.IO'S[BU.IHOIp.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Fast filtering for RNA Search

 

 

A Vector CYK speed-up

1000 —E

I 2.9x
' speed-up
g 100 -E
C :
o _
o _
c0
3 _
K _
>_ 10 E
0 3
‘8 : 4x parallel
a; 1 __ 32-bit floating point
'6 E CYK implementation
“a; 3 8X parallel
E Z ,, f. ' 16-bit integer
'—  CYK implementation
0.1 —E
0.01 -E I I

 

     
    
  
 

 

 

0.01 0.1 1 10 100

1000

Time for scalar CYK (seconds)

B Vector MSCYK speed-up

 

1000

_\
O
O

A
O
I I IIIIIII

Time for MSCYK (seconds)

0.1

1x

 

 

 

 

0.01 0.1 1 10 100

1000

Time for CYK scan (seconds)

Fig. 5. Speed—up for vector CYK and MSCYK methods. (A) Time for 4x (red) and 8x (blue) vector CYK implementations, compared with time for scalar
implementation, log—log scale. Times measured are for alignment of a sequence of the window length of the model, median of ﬁve trials, for all Rfam families.
(B) Time for MSCYK search compared to time for scalar CYK search. Red dots are the subset of Rfam families with no bifurcations (simple stems), green
dots are for families with a single branch point and blue dots represent more complex families with multiple branches. Times measured are for search of a

10 kb randomly generated sequence.

for scanning long sequences. Total speed—up is model—dependent and
ranges from 5— to 100—fold, with larger, more complicated models
generally having better relative performance (Fig. SE).

3.4 Pipeline

The methods described above yield three main components for
assembling a search pipeline. The MSCYK scanning algorithm
considers a long input sequence, and identiﬁes regions containing
ungapped hits to the consensus model. The medium—precision
alignment ﬁlter examines a sequence window and returns an
approximate score for the best gapped alignment within that window.
The high—precision alignment function not only determines the best
gapped alignment, but also provides an exact score, the boundary
coordinates of the alignment, and optionally can give the complete
alignment.

To connect these pieces, we also need some post—processing of the
initial MSCYK hits to create appropriately sized sequence windows
for the later stages. For each CM, there is a W such that no true
hits are expected to have length greater than W. The value of W
is derived from the query—dependent bands, which calculate the
probability distribution over the lengths of hits, meaning we can
select a maximum length that sacriﬁces only a minimal amount of the
total probability. Each hit from MSCYK—potentially smaller than
the true bounds of the alignment—is expanded from initial bounds
(i , j) to (j —W, i —l—W) so that all sequences of length W that include
(i, j) are part of the ﬁnal window. Separate MSCYK hits which are
within W of each other are also merged to reduce redundancy in the
list of sequence windows that pass this ﬁrst ﬁlter. The resulting list

of sequence windows is appropriate for scoring under the medium—
precision ﬁlter; those sequences that pass a pre—deﬁned threshold are
further passed to the high—precision ﬁnal alignment.

Each of these main stages has a tunable threshold parameter to
control the amount of the search database that reaches the later, more
computationally intensive steps. These thresholds are expressed in
terms of P—values, requiring calibrated models in order to convert
between bit scores and P—values. The MSCYK consensus—hit model
is calibrated by score simulation at the beginning of each search, as
described above; the medium— and high—precision alignment steps
rely on a required CM calibration step as part of the model creation
process. By default, the threshold for MSCYK is set such that the
hit windows are expected to amount to 2% of the total database size.
In general, for a ﬁlter pass rate of x, we want one hit (approximate
size after padding is 2W) per every ¥ bases. The simulation is set

per—kilobase of sequence, so the necessary P—value is  Since
the subsequent stages are markedly slower, this parameter has the
largest tunable effect on the speed of the pipeline. The medium—
precision ﬁlter stage requires individual windows to pass a P—value
cutoff, by default 10‘5. Finally, the results reported from the ﬁnal
alignment stage are ranked by E —value, with the default showing all
hits with E <1.

4 RESULTS

MSCYK is a heuristic designed for search acceleration; we expect
that its speed comes with a loss of sensitivity, but we want the loss
to be minimal. To quantify this performance trade—off, we evaluated
the MSCYK pipeline using the rmark—2 benchmark used in earlier

 

3107

112 /§JO'S[BUJHOIPJOJXO'SOTlBIHJOJUTOTQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘OE lsnﬁnv uo ::

D.L.Kolbe and S.R.Eddy

 

development of the Infernal package (Nawrocki and Eddy, 2007;
Nawrocki et al., 2009). It features 450 test sequences, from 51 known
ncRNA gene families, embedded in a 10 Mb ‘pseudogenome’. The
test sequences are separated from their corresponding alignments in
such a way that no test sequence is >60% identical to any sequence
that remains in the set of training alignments. The 51 training
alignments contain from 5 to 1080 sequences (median 20); each
is used to create a single CM as a search query. The pseudogenome
itself is randomly generated from an HMM that produces sequence
modeled from a variety of species, such that it includes regions of
biased nucleic acid composition.

Homology search methods are evaluated based on their ability to
detect the embedded test sequences, given the known members of
the family in the training set, while also minimizing the number of
false positive hits. A reported alignment is considered a hit if the
overlap between the reported sequence and the embedded sequence
corresponds to at least half of the shorter of the two. Hits against
a true sequence of a different family are considered to be neither
true positives or false positives, because there are known to be
evolutionary relationships between at least some of the ncRNA
families, but these are not all well characterized. (For example, Rfam
operationally classiﬁes RNase P into four families.)

We use this benchmark to make two comparisons about the
performance of the ﬁltering strategy described here. First, to address
whether MSCYK is an effective ﬁltering strategy, we compare the
MSCYK pipeline to the reference (unaccelerated) implementation
of CM search in Infernal. In addition, Infernal has an existing
acceleration pipeline; we compare the results between the two
heuristics for their relative performance. The MSCYK ﬁlter’s
model and parameters were not optimized directly against the
rmark—2 benchmark; in development, they were trained with Rfam
seed alignments and tested for score discrimination between IID
background sequence and either sequences from the Rfam full
alignments or sequences randomly generated from the training CM.

The existing acceleration pipeline operates in four stages: an
HMM ﬁlter, an HMM—banded structural ﬁlter, a structural ﬁlter
using query—dependent banding (QDB) and ﬁnally alignment with
the Inside algorithm. The ﬁrst HMM—based ﬁlter is a sequence—only
method, while the second uses an HMM alignment to constrain a
structural alignment. QDB is structural alignment constrained by
subsequence lengths; these constraints are complementary to the
sequence—based HMM constraints. The ﬁnal alignment stage uses
the total log—likelihood calculation (Inside algorithm), rather than
the maximum log—likelihood calculation that we have referred to
throughout this work (CYK algorithm).

The performance of different ﬁltering approaches on the rmark—2
benchmark are shown in Figure 6. Full search without any ﬁltering
stages (black line) has the best sensitivity and speciﬁcity trade—offs,
and also has by far the longest running time of 648 CPU hours.
(All times are aggregate results for the benchmark, with each search
being run on a single 2.66 GHz Intel X5550 processor.) At slightly
lower sensitivity for a given false positive rate is the existing ﬁlter
strategy (green). Although these ﬁlters do miss some sequences that
would be detected without using any ﬁlters, the run time of only
23.5 CPU hours makes the trade—off generally worthwhile.

The MSCYK pipeline (dashed blue line), has notably worse
sensitivity than either unﬁltered search or the previous ﬁltering
methods. The time required to run the MSCYK pipeline is only
a little slower than the existing ﬁlter strategies. The ﬁrst—stage

0.8 . .

 

Baseline
(unaccelerated, 648 hr)
0.75 -

   
 

......  heuristics
............. .. (Slug—hi, 11X Speed_up)_

--- PulrIfeInal 1.0 heuristic filters

0.7 E ..... ..

 

 

 

a ....................  
'5 ..................... .. . (23.5 hr, 28x speed-up)
"-1:- | _I___.-_.
',7, 0.65- ,————:---  _
c — — — — — — —- "__u ______ __.
g  ----------- " MSCYK heuristic filters
0.6 -  (37.4 hr, 18x speed-up).
0.55- _
0.5 .
0.001 0.01 0.1

False positives per Mb searched per query

Fig. 6. ROC curves for the nnark—2 benchmark. Performance plots are
shown for Infernal version 1.0, with and without the standard ﬁltering
strategy, and the new structure—based parallel ﬁltering strategy both alone and
in combination with the existing ﬁlters. All methods use default parameters
for their ﬁlter cut—off values; the curve reﬂects only the E —value—based sort
order of the ﬁnal output.

structural ﬁlter alone here requires 25.4 CPU hours, with the second
and third stages combining to require about half as much time again,
for a total run time in the range of 37 CPU hours. Although this is a
signiﬁcant speed—up over the reference implementation, it is not an
improvement over the existing acceleration pipeline.

The major loss in sensitivity for the new ﬁltering approach occurs
at the very beginning of the pipeline, at the ungapped consensus
alignment stage. We looked at the sequences that fail to pass this
stage, and they broadly share two general features. First, they
have lower than average information content per position (i.e. less
conservation), and require longer alignments in order to produce
a signiﬁcant hit, but the requirement of ungapped, unbranched
alignment limits the possible length of hits. Second, they have
insertions or deletions at all (or nearly all) of the stem—loops in
the model. This is not inherently surprising; the ends of stem—loops
commonly show less conservation and more changes in length.
However, the model has a signiﬁcant score preference for alignments
that reach the end of a hairpin with no intervening unaligned
sequence; without at least one well—conserved stem—loop to anchor
or seed the potential hit, the scores of these sequences are well down
into the noise of scores from random sequences.

Despite its lower sensitivity when evaluated alone, MSCYK
should be complementary to the existing Infernal pipeline, because
it implements structure—based rather than sequence—based ﬁlters. To
test this, we examined the overlap in hits between the acceleration
strategies, and found that MSCYK identiﬁed a signiﬁcant number
of hits that had been missed by the sequence—based approach. To
leverage this complementarity, we designed a small driver script
which runs both pipelines and determines a union set of their results.
Because the two pipelines use different scoring methods for their
ﬁnal stages (CYK versus Inside), all hits are re—scored under the
Inside algorithm to provide uniﬁed output. This combined approach
has sensitivity and false positive results which are competitive with
running Infernal without any ﬁlters at all (Fig. 6, dotted red line).

 

3108

112 /§JO'S[BUJHOIPJOJXO'SOTlBIHJOJUTOTQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Fast filtering for RNA Search

 

The running time for the combined approach is the sum of the
time required for each pipeline, plus some overhead. In the proof—of—
concept runs, the benchmark run took 61.2 CPU hours, still 10—fold
better than the time required when running the search without any
ﬁlters. This gives only a rough upper bound on the time required if
a pipeline was designed from the ground up to use both methods;
since the majority of sequences are identiﬁed in common by both
approaches, many alignments are unnecessarily performed multiple
times, in addition to the simple overhead of running two searches
and combining the results.

5 DISCUSSION

Although MSCYK does not have the sensitivity required to stand on
its own, this structure—based heuristic is successful in identifying true
hits that are missed by sequence—based methods. The combined set of
hits from both pipeline methods has sensitivity approaching that of
unﬁltered search; although there are some sequences which are not
found by either method, they are few in number. These performance
gains in sensitivity relative to the existing ﬁlters are large enough
to suggest that this method or a similar structure—based approach
will be an important component of improving the performance of
CM—based RNA search in the future.

In this work, we have not implemented a production—quality
ﬁlter pipeline in Infernal; the results shown here are from a simple
proof—of—concept script. A more efﬁcient production pipeline would
take steps to reduce the amount of time spent in the structure—
based portion of the analysis. This could be done both toward the
end of the pipeline—combining the sets of hits earlier to reduce
redundant alignment of sequences found by both methods—and at
the beginning of the pipeline, reducing the number of sequences that
are subjected to the structure—based pipeline at all. One approach
to this might be to start with an HMM—based sequence—only ﬁlter,
with sequences that clearly pass being moved directly to the main
processing pipeline, but with a second group of sequences with lower
but potentially interesting ‘twilight—zone’ scores being analyzed
under a structure—based pipeline optimized for alignments with lower
sequence identity. These adjustments will be increasingly important
with an expected upcoming move of Infernal from HMMER2
to HMMER3 for its underlying engine for HMM ﬁlters. The
dramatically increased speed of HMMER3 should provide large
automatic speed gains for the existing HMM ﬁlters, rendering the
structure—based ﬁlters increasingly slow by comparison.

Funding: Howard Hughes Medical Institute.

Conﬂict of Interest: none declared.

REFERENCES

Bafna,V. and Zhang,S. (2004) FastR: fast database search tool for non-coding RNA
Proc. IEEE Comput. Syst. Bioinform. Conf, pp. 52—61.

Brown,M.P. (2000) Small subunit ribosomal RNA modeling using stochastic context-
free grammars. Proc. Int. Conf. Intell. Syst. Mol. Biol, 8, 57—66.

Burge,C. and Karlin,S. (1997) Prediction of complete gene structures in human genomic
DNA. J. Mol Biol, 268, 78—94.

Durbin,R. et al. (1998) Biological Sequence Analysis: Probabilistic Models of Proteins
and Nucleic Acids. Cambridge University Press, Cambridge, UK.

Eddy,S.R. (2002) A memory-efﬁcient dynamic programming algorithm for optimal
alignment of a sequence to an RNA secondary structure. BMC Bioinformatics,
3, 18.

Eddy,S.R. (2008) A probabilistic model of local sequence alignment that simpliﬁes
statistical signiﬁcance estimation. PLoS Comput. Biol, 4, e1000069.

Farrar,M. (2007) Striped Smith-Waterman speeds database searches six times over other
SIMD implementations. Bioinformatics, 23, 156—161.

Freyhult,E.K. et al. (2007) Exploring genomic dark matter: A critical assessment of the
performance of homology search methods on noncoding RNA. Genome Res., 17,
1 17—125.

Gardner,P.P. et al. (2011) Rfam: Wikipedia, clans and the “decimal” release. Nucleic
Acids Res., 39, D141—D145.

Havgaard,J.H. et al. (2005) Pairwise local structural alignment of RNA sequences with
sequence similarity less than 40%. Bioinformatics., 21, 1815—1824.

Liu,T. and Schmidt,B. (2005) Parallel RNA secondary structure prediction using
stochastic context-free grammars. Concurr. Comput. Pract. Exp, 17, 1669—1685.

Lowe,T.M. and Eddy,S.R. (1997) tRNAscan-SE: a program for improved detection of
transfer RNA genes in genomic sequence. Nucleic Acids Res., 25, 955—964.

Macke,T.J. et al. (2001) RNAMotif, an RNA secondary structure deﬁnition and search
algorithm. Nucleic Acids Res., 29, 4724—4735.

Mathews,D.H. and Turner,D.H. (2002) Dynalign: an algorithm for ﬁnding the secondary
structure common to two RNA sequences. J. Mol. Biol, 317, 191—203.

N awrocki,E.P. and Eddy,S.R. (2007) Query-dependent banding (QDB) for faster RNA
similarity searches. PLoS Comput. Biol, 3, e56.

N awrocki,E.P. et al. (2009) Infernal 1.0: Inference of RNA alignments. Bioinformatics,
25, 1335—1337.

Rognes,T. and Seeberg,E. (2000) Six-fold speed-up of Smith-Waterman sequence
database searches using parallel processing on common microprocessors.
Bioinformatics, 16, 699—706.

Sun,Y. and Buhler,]. (2008) Designing secondary structure proﬁles for fast ncRNA
identiﬁcation. Comput. Syst. Bioinformatics Conf, 7, 145—156.

Weinberg,Z. and Ruzzo,W.L. (2004a) Exploiting conserved structure for faster
annotation of non-coding RNAs without loss of accuracy. Bioinformatics, 20
(Suppl. 1), 1334—1341.

Weinberg,Z. and Ruzzo,W.L. (2004b) Faster genome annotation of non-coding RNA
families without loss of accuracy. In RECOMB ’04. ACM, New York, NY,
pp. 243—25 1.

Weinberg,Z. and Ruzzo,W.L. (2006) Sequence-based heuristics for faster annotation of
non-coding RNA families. Bioinformatics, 22, 35—39.

Wozniak,A. ( 1997) Using video-oriented instructions to speed up sequence comparison.
Comput. Appl. Biosci., 13, 145—150.

 

3109

112 /B.IO'SIBUJHOIPJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

