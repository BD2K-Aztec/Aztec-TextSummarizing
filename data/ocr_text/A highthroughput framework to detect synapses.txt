Vol. 29 lSMB/ECCB 2013, pages i9—i 17
doi:10. 1093/bioinformatics/btt222

 

A high-throughput framework to detect synapses in electron

microscopy images

Saket Navlakhal, Joseph Suhan2, Alison L. Barth2’3 and Ziv Bar-Joseph”

1Machine Learning Department, School of Computer Science, 2Department of Biological Sciences and 8Center for the
Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, PA 15213, USA

 

ABSTRACT

Motivation: Synaptic connections underlie learning and memory in the
brain and are dynamically formed and eliminated during development
and in response to stimuli. Quantifying changes in overall density and
strength of synapses is an important pre-requisite for studying con-
nectivity and plasticity in these cases or in diseased conditions.
Unfortunately, most techniques to detect such changes are either
low-throughput (e.g. electrophysiology), prone to error and difficult
to automate (e.g. standard electron microscopy) or too coarse (e.g.
magnetic resonance imaging) to provide accurate and large-scale
measurements.

Results: To facilitate high-through put analyses, we used a 50-year-old
experimental technique to selectively stain for synapses in electron
microscopy images, and we developed a machine-learning framework
to automatically detect synapses in these images. To validate our
method, we experimentally imaged brain tissue of the somatosensory
cortex in six mice. We detected thousands of synapses in these
images and demonstrate the accuracy of our approach using cross-
validation with manually labeled data and by comparing against exist-
ing algorithms and against tools that process standard electron mi-
croscopy images. We also used a semi-supervised algorithm that
leverages unlabeled data to overcome sample heterogeneity and im-
prove performance. Our algorithms are highly efficient and scalable
and are freely available for others to use.

Availability: Code is available at http://www.cs.cmu.edu/
~saketn/detect_synapses/

Contact: zivbj@cs.cmu.edu

1 INTRODUCTION

The mammalian brain can contain hundreds of millions of
neurons, each with thousands of specialized connections called
synapses that enable indirect communication between cells.
Estimates for the number of synapses in the mammalian brain
ranges into the trillions. Synapses are essential for the transfer of
information across neuronal ensembles, and individual synapses
can be modulated by patterns of incoming neural activity, a phe-
nomenon thought to underlie learning and memory.

Changes in the relative strength and number of synapses can
be regulated by a myriad of factors, including developmental
age (Cowan et al., 1984; Huttenlocher and Dabholkar, 1997;
Stoneham et al., 2010), sensory experience (Klintsova and
Greenough, 1999), drug addiction (Van den Oever et al., 2012),
estrus cycle (Cooke and Woolley, 2005) and brain pathology.
For example, in a form of autism linked to mutation of the
Fragile X gene, spine density in the neocorteX is elevated

 

*To whom correspondence should be addressed.

(Hinton et al., 1991; Pfeiffer and Huber, 2009), a feature that
has also been observed in mice carrying the same genetic muta-
tion (Nimchinsky et al., 2001). Rett syndrome, another neurode-
velopmental disorder, is characterized by smaller brain size
caused by deficits in synaptogenesis (Glaze, 2004; Johnston
et al., 2005; Na and Monteggia, 2011) that results in fewer
spines. Similarly, in Alzheimer’s disease and other dementias,
cognitive deficits are associated with reduced synapse density in
the hippocampus, a brain structure critical for learning (Clare
et al., 2010). Understanding how connectivity across neurons can
change is thus an important question that drives contemporary
neuroscience research.

Because synapse distribution is a useful and diagnostic criter-
ion to evaluate circuit function in learning and disease, there
have been a variety of methods used to estimate synaptic con-
nectivity or overall synapse numbers. Electrophysiological meth-
ods to estimate connectivity and the number of inputs per cell
can be informative (e.g. Lefort et al., 2009; Yassin et al., 2010),
but these approaches are low-throughput and can typically only
capture tens or hundreds of connections in reasonable amounts
of time ONalz, 2007). MRI-based techniques can be used to study
network function at the level of brain regions or voxels, but they
do not provide enough spatial resolution to estimate neural con-
nectivity (Sporns, 2010). Anatomically, synapse densities are
measured via light-microscopy to identify specialized substruc-
tures called spines that stud the dendrites of neurons or using
electron microscopy (EM) to identify ultrastructural features
that correspond to pre- and post-synaptic elements. Traditional
approaches have used cumbersome manual detection to count
synapses in these images (e.g. White et al., 1986; Knott et al.,
2002; da Costa et al., 2009; Morshedi et al., 2009) and were thus
constrained to small-scale measurements or required the use of
specialized transgenic animals (Feng et al., 2012; Kim et al.,
2012) limiting their usage for studying plasticity and develop-
ment in wild-type mice.

Since the early 1990s, bioimage informatics has emerged as an
important area in the analysis of biological images (Peng, 2008).
Imaging datasets are usually much larger than other high-
throughput biological datasets (e.g. confocal microscopy data
can range in the hundreds of gigabytes for a single imaging ses-
sion). Accurately identifying elements of interest (molecules,
cells, synapses, etc.) within these massive datasets requires the
development of sophisticated and efﬁcient computational
models. This often involves a classiﬁcation-based strategy in
which a (small) manually labeled training set is used to learn a
general model that can be used to analyze a larger collection of
images automatically. The key computational challenges involve
the reliability and speed at which the analysis is done, as well as
dealing with the heterogeneity of biological structures and noise

 

© The Author 2013. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0/), which permits non—commercial re—use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial

re—use, please contact journals.permissions@oup.com

112 /310's113umo [p.IOJXO'SOllBIIHOJUIOIQ/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘09 lsnﬁnv uo ::

S.Navlakha et al.

 

present in each image. Electron microscopy data suffer particu-
larly from these problems and often contain undesired variation
in intensity and contrast within and across samples and prepar-
ations. This presents a major computational challenge because
model parameters learned from one sample may not generalize
to other samples. Although reconstruction and segmentation of
conventional EM images has helped answer important questions
about brain structure and function (Beck et al., 2011; Denk
et al., 2012), these approaches have yet to reach the point of
full automation (Merchan—Perez et al., 2009; Jain et al., 2010;
Cardona et al., 2012), which has limited their scale and accuracy
(Kreshuk et al., 2011; Morales et al., 2011).

2 APPROACH

To aid in identifying and quantifying synapses in EM images, we
used a 50-year-old experimental technique (Bloom and
Aghajanian, 1966, 1968) to selectively stain for synapses in any
animal model (Fig. 1A). Unlike conventional EM, this protocol
uses ethanolic phosphotungstic acid (EPTA) to pronounce elec-
tron opacity at synaptic sites by targeting speciﬁc proteins in
contact zones. This technique typically leaves non-synaptic mem-
branes (e.g. plasma membranes, neurotubules and vesicles) un-
stained, though considerable variation can exist from sample to
sample. We dissected brain tissue in the mouse somatosensory
cortex and performed EM experiments using the EPTA method.
We used mice from different ages (P14, P17 and P75) and iso-
lated the same cortical region in each animal to gauge variance in
sample quality.

To demonstrate the advantages of this protocol for large-scale
synapse identiﬁcation, we developed a machine-learning frame-
work to detect synapses in these images in a high-throughput and
fully-automated manner. We describe a two-step approach. First,
we use a highly accurate ﬁrst-pass ﬁltration step to reduce the
search space of possible synapses by 1—2 orders of magnitude,
thereby signiﬁcantly reducing false positives. Second, we train a
classiﬁer to recognize synapses using texture- and shape-based
features extracted from small image patches around potential
objects of interest. We show that our approach is highly accurate
and that it outperforms correlation-based (Roseman, 2004) tech-
niques and an automated technique designed to detect synapses
in conventional EM images (Morales et al., 2011).

To further improve classiﬁcation and adjust for varying ex-
perimental conditions (different sample, different microscope,
different person performing experiments, etc.), we developed a
model that classiﬁes synapses in images using both labeled and
unlabeled data. This type of approach is known as semi-super-
vised leaming (Zhu, 2005), as it combines ideas from supervised
learning (classiﬁcation) and unsupervised learning (clustering).
This technique can be used to build more robust classiﬁers in
cases (such as ours) where large imaging datasets can easily be
collected but where it is much harder to manually annotate these
images. By integrating unlabeled data in the learning phase, a
new sample can help ﬁne-tune parameters of a model built from
a previous sample, which can improve accuracy without requir-
ing users to manually annotate images in the new sample.
Indeed, we show that a classiﬁer learned only on labeled data
from our P14 samples and tested on our P75 samples performs

worse than a semi-supervised classiﬁer that also leverages un-
labeled data from P75.

3 METHODS

First, we describe the experiments we performed to gather and process
mouse brain tissue for EM imaging with EPTA, and then we describe our
machine-learning framework to automatically detect synapses in these
images.

3.1 Experimental approach and data collected

We gathered tissue from the mouse somatosensory cortex because it is a
well-characterized anatomical area in the cortex (Fox, 2008) and thus
serves as an important benchmark for the validity of our experimental
approach. To prepare the tissue for EM analysis, we extracted, ﬁxed
(using 2.5% glutaraldehyde buffered with phosphate buffered saline)
and sectioned 50-um thick tissue from wild-type C57bl6 mice at ages
P14, P17 and P75 with two animals per time point. This range of tissue
was collected to determine whether our experimental procedure and sub-
sequent computational analysis remained robust to natural variation in
tissue samples within and across time points and to variation in the image
acquisition process. Each mouse whisker is somatotopically mapped to a
single neocortical column. To ensure that the same cortical region was
identiﬁed in each sample, we applied a mitochondrial stain (cytochrome
oxidase) to each section to visually identify layer 4 (called the barrel) of
the D1 column/whisker. The barrel was extracted using a dissecting light
microscope.

Tissue was prepared for transmission electron microscopy in a series of
steps. First, the tissue was washed with three changes (5 min each) of
distilled water, followed by an incubation in 0.02% NaOH for 10min.
This latter step was absent from the original procedure of Bloom and
Aghajanian (1966, 1968), but we found that it helped increase the contrast
of synapses (Fig. 1). Second, the tissue was dehydrated with an ascending
series of EtOH (25, 50, 70, 80, 90 and 100%), followed by ﬁxation with
1% phosphotungstic acid (PTA) in 100% EtOH. Third, a small amount,
7 ul, of 95% ethanol, was added to each 1000 ul of PTA stain used, and
the PTA was washed from the sample with two changes of 100% ethanol.
Fourth, propylene oxide was used as a transitional solvent (the ﬁrst
change of propylene oxide was on ice), and then the specimen was inﬁl-
trated with Spurr embedding resin, which was polymerized at 60°C for
48 h. Finally, 100nm sections were cut using a diamond knife on an
ultramicrotome, which were picked up using 50 or 75 mesh copper
grids. The specimen was observed using a transmission electron micro-
scope, and images were taken digitally.

We took roughly 130 images per animal (each image is of size 5 pm by
5 gm) covering a total surface area of ~3000 um2 per sample and with a
total of six samples (see Supplementary Information for additional details
about image acquisition). Images were taken from a single plane, and
therefore no correction was necessary to account for double-counting
synapses across serially sectioned images. There was signiﬁcant sample-
to-sample variability in the images, but synapses were typically dark with
most other biological structures washed away (Fig. 1A). In total, we
collected >800 images each containing between 0 and 12 synapses. The
raw images were provided as input to the machine-learning algorithms
described later in the text.

3.2 Strategies for effectively detecting synapses

As described earlier in the text, electron microscopy images are inherently
noisy owing to variations in the samples (e.g. different age), in the manual
processing steps and in the image acquisition process. To overcome these
issues, we developed a pipeline that uses object segmentation, background
information, normalization and alignment to obtain a better feature
set that can be used for effective classiﬁcation.

 

HQ

112 /810's113u1no [p.IOJXO'SOIlBIHJOJUIOICI/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘09 lsnﬁnv uo ::

Detecting synapses in electron microscopy images

 

A Experimental Technique

Conventional EM

    

Hard to discern synapses

B Training Data

Positive examples

 

Normalized and rotated

 

Selectively stains for synapses...

 

 

 

 

...but with variability in intensity and
contrast and with some preservation
of other structures.

Negative examples

 

Original Normalized and rotated

Fig. 1. Experimental technique and training data collected. (A) Comparison of conventional and EPTA-stained EM images shows a marked difference in
clarity of synaptic structures, albeit high sample-to-sample variability. (B) Subset of positive and negative examples taken from multiple images across all
samples. The original examples exhibit high variance and noise; normalization and alignment reduces this heterogeneity

1. Reducing the search space of possible synapses via
segmentation One popular technique to search for objects in an
image is the sliding window approach (Szeliski, 2010). In this approach,
non-overlapping windows of a pre-deﬁned size are slid across the image,
and each window is classiﬁed as synapse-containing (positive) or not
(negative). One drawback to this technique is that it can double-count
synapses that lie in multiple windows or miss synapses that lie adjacent to
each other. A more thorough approach is to use overlapping windows,
but this greatly increases computational complexity when using large
images, and subsequent post-processing steps still need to account for
double-counting synapses. Further, this technique creates a large imbal-
ance of negative-to-positive examples (windows), which may lead to
many false positive predictions.

To circumvent these problems, instead of using sliding windows, we
apply a ﬁltration step to reduce the number of windows to test by lever-
aging the fact that the experimental procedure outlined earlier in the text
is designed speciﬁcally to stain synapses (there may be other biological
structures, such as mitochondria and membranes, that also appear in the
image, but rarely are there synapses that do not appear as dark). To avoid
the challenge of selecting thresholds to segment the image (which may not
generalize across samples owing to differences in intensity and enhance-
ment), we adopt the contrast-limiting adaptive histogram equalization
algorithm (Zuiderveld, 1994). This method enhances the contrast of
each window T in the image to approximately match a ﬂattened histo-
gram by mapping each pixel value v e [0, 255] to its value in the cumu-
lative distribution f(v) computed in T:

f(v) =  hist(i) =f(v — 1) + %hist(v), (1)
i=0

where hist(-) represents the original histogram of the image and n is the
number of pixels in the window. We also limit the enhancement by clip-
ping the histogram at a scalar value of 0.20 before enhancement. The
window is then rescaled to [0,255]. The equalization is performed in each
local window of the image, and then the windows are combined using

bilinear interpolation to eliminate artiﬁcially induced boundaries. By only
considering small windows of the image, this technique prevents the over-
ampliﬁcation of noise or artifacts that only appear in localized regions of
the image.

Next, we binarize the equalized image using a single, sample-independ-
ent threshold, which was determined manually to be 10% (i.e. only the
top 10% of pixels values are kept). The ﬁnal segmentation is produced by
computing connected components (segments) in the binary image.
Compared with a non-overlapping sliding window approach that
would produce roughly 300 windows to test per 1016 X 1024—sized pixel
image on average, our segmentation produces 25—35 candidate segments
per image and an overall ratio of negative-to-positive examples of 9:1. We
also allow for optional ﬁltration of segments that are too small or too
large to be synapses, as deﬁned by the user. This step is only designed to
produce segments and not to normalize the image, which we do separ-
ately later in the text.

To validate that the segmentation step preserves synapses, we looked
at two samples (P14 and P75) and manually checked what percentage of
the ﬁrst 100 synapses encountered were correctly segmented. We found
that only 1% (1 in each sample) of the synapses were lost, and these were
always due to two synapses touching each other, which caused them to be
merged into a single segment.

2. Using background cues to augment synapse identification One
key indicator to decide whether a candidate segment is a synapse is the
physical context in which it lies. We consider a local 75 X 75-pier window
around the centroid of each segment to capture information about the
object and the neighborhood surrounding the object. This is important
because elongated synapse-like segments may also appear within mito-
chondria, but such segments are always surrounded by an oval-like con-
tour marking the boundary of the mitochondria, which can be a useful
cue for classiﬁcation. Similarly, dark circular spots in the nucleus may
also be stained (see Fig. 1A), but their neighborhoods typically contain
other such spots, which also serve as strong discriminators. These are not

 

H1

112 /3.IO'SIBUJHO[p.IOJXO'SOIlBUIJOJUIOIQ/ﬂdllq 11101; papeommoq

9IOZ ‘OE lsnﬁnv uo ::

S.Navlakha et al.

 

steadfast rules (synapses can certainly lie adjacent to mitochondria), but
local neighborhoods are nonetheless a strong visual cue used by EM
experts when annotating images (Arbelaez et al., 2011).

3. Handling experimental variation across samples The aforemen-
tioned technique produces a set of windows (in which each candidate
segment is embedded), but the actual pixel values within these windows
may vary signiﬁcantly from sample-to-sample and image-to-image.
Figure 1B exempliﬁes the discrepancy that can exist across both negative
and positive examples in the original images. These issues may be caused
by a variety of factors (e.g. consistency of chemical reactions during
sample preparation, age of the sample, skill of the experimenter, differ-
ential illumination in the microscope, etc.) that are extremely difﬁcult to
overcome experimentally and thus must be accounted for computation-
ally. To reduce the effect of these differences, we normalize each candi-
date window W by computing (Arbelaez et al., 2011): W = W,
where ny is the current value at pixel (x,y) and p. and o are the mean
and standard deviation of the pixel intensities in W. Figure 1B shows that
this signiﬁcantly reduces the variance across windows, which helps fea-
tures dependent on pixel intensities to be compared in an equal setting.

3. Adjusting for synapse heterogeneity Synapses in EM images may
be angled at any 2D orientation, which may add undesirable variation in
training examples. To create a more invariant set of synapses, we applied
the generalized Hough transformation (Duda and Hart, 1972) to auto-
matically rotate the segment (within the candidate window) such that its
major axis points vertically. Brieﬂy, this is done by computing the Hough
transform matrix H, where entry i,j of H corresponds to the number of
points in the segment that fall along a line parameterized in polar coord-
inates as r, = xcos(6,) + y sin(6,). We ﬁnd the element (r*, 6*) in H that
corresponds to the (peak) line for which the most segment points lie. The
corresponding 6* is used to compute the angle of rotation. We then
cropped the image to 60 X 60 pixels to remove the effects of the interpol-
ation (this size is still large enough to ﬁt almost all synapses). The out-
come (Fig. 1B) shows much greater uniformity for both synapses and
non-synaptic structures compared with the original images.

3.3 Supervised learning framework and features used to
detect synapses

After the processing steps aforementioned, each image is reduced to a set
of candidate segments deﬁned by a (normalized and aligned) square
window around the centroid of the segment. Next, we build an accurate
and robust classiﬁer to discriminate between positive (synapses) and
negative candidates using texture— and shape-based features.

Texture is a common cue used by humans when manually segmenting
structures from electron micrographs, and its use has become popular in
many image processing tasks today (Arbelaez et al., 2011; Varma and
Zisserman, 2003). In their seminal article, Leung and Malik (2001)
deﬁned texture by convolving an image with a bank of 48 Gaussian ﬁlters
and used the ﬁlter responses at each image location to deﬁne a ‘texton’.
Textons were clustered and used to represent and classify images in a
reduced dimension. Recently, more effective ﬁlter banks have been pro-
posed to represent texture based on modeling joint distributions of inten-
sity values over small and compact neighborhoods of the image (as
opposed to the entire image), an approach we also adopt here.

The maximum response (MR8) is one such technique that is derived
from a set of 38 ﬁlters: 6 orientations X 3 scales X 2 oriented ﬁlters+2
isotropic ﬁlters. By recording only the maximum response across orien-
tations, the number of responses is reduced to 8 (V arrna and Zisserman,
2003). Each pixel is now represented as an 8D vector of responses at its
(x, y) location. For each dimension d, we compute a normalized histo-
gram with 17 bins (larger bin sizes yielded marginal gain in performance
but increased computational complexity) composed of responses for d
over all pixels in the window. Thus, the texture of the window is

represented as a 8 X 17-sized vector in R". We used the default parameters
for MR8 (V arma and Zisserman, 2003).

Synapses also have a characteristic shape (typically long and elon-
gated) that we also attempt to capture by extracting the following
10 shape descriptors for each segment. These features operate on the
binary segment only (they ignore the intensity values of the pixels) and
therefore contribute different information than texture alone.

(1) Area: the number of pixels in the segment.

(2) Perimeter: the number of pixels in the boundary of the segment.

(3) Major axis: the number of pixels constituting the major axis of the
ellipse that has the same normalized second central moments (co-
variance) as the segment.

(4) Minor axis: same as above but for the minor axis of the ellipse.

(5) Orientation: the angle between the x—axis and the major axis of the
ellipse.

(6

v

Eccentricity: the ratio of the distance between the foci of the ellipse
and its major axis length.

(7) Convex area: the number of pixels in the convex hull of the
segment.

(8) Solidity: the proportion of pixels in the convex hull that are also in
the segment.

(9) Diameter: the diameter of the circle with the same area as the
segment.

(10) Extent: the ratio of pixels in the segment to pixels in the smallest
bounding box of the segment.

The ﬁnal feature we use is the histogram of oriented gradients (HOG)
descriptor proposed by Dalal and Triggs (2005). We used nine orientation
bins, cell and block sizes of 10 X 10 and 6 X 6, respectively, and a value of
0.2 for clipping the L2—norm. Intuitively, this 334D feature describes the
appearance of an object by concatenating the distributions of intensity
gradients (edge directions) in different subregions of the window. This
descriptor has been shown to outperform other popular feature sets
(e.g. PCA-SIFT and generalized Haar wavelets) in a variety of object
detection tasks (Dalal and Triggs, 2005; Skibbe et al., 2011). In total,
each window is represented by a 480D feature vector in R". All features
are scaled to lie in [0, 1].

These features were then used to build a support vector machine (SVM)
classiﬁer (Chang and Lin, 2011) using a radial basis function kernel, and
we performed a grid search to optimize parameters of the model. We also
learned a Random Forest (Breiman, 2001) classiﬁer and an AdaBoost
ensemble model (Freund and Schapire, 1995) using 100 trees/learners, re-
spectively. An overview of the supervised algorithm is shown in Figure 2.

3.4 Semi-supervised learning

The supervised algorithm described earlier in the text only uses labeled
data to train a classiﬁer. We now show how unlabeled data can be used to
further improve the classiﬁer using co-training. The co-training algorithm
(Blum and Mitchell, 1998) assumes that features can be split into two
different and fairly independent sets (in our case, texture and shape).
Blum and Mitchell (1998) proved that for a classiﬁcation problem with
two such feature sets, the target concept can be learned based on a few
labeled and many unlabeled examples, provided that the views are com-
patible and uncorrelated. The compatibility condition requires that all
examples are identically labeled by the two classiﬁers (one for each of
the feature sets). The uncorrelated condition means that for any pair of
features, the two sets of features are independent, given the label. In real
applications, these two conditions are rarely satisﬁed simultaneously. For
example, in our task, compatibility may be hindered due to noise and
imaging artifacts. Still, co-training has proven useful in several real-world
applications (Zhu, 2005).

 

“2

1e /810's113u1no [p.IOJXO'SOIlBIHJOJUIOIQ/ﬁdllq 11101; popeommoq

9IOZ ‘09 lsnﬁnv uo ::

Detecting synapses in electron microscopy images

 

 

 

; '-- 

 

 

 

 

Algorithm 1 DetectSynapses(I,Model,7)
1: Ihisteq = HistogramEqual (I)

 

2: S = FindCandidateSegments(Ihisteq)
3: S = FilterSegments(S, min_size, maX_size)
4: for all remaining segments Si 6 S d0

 

 

For each candidate segment:

   
 

Shape

/
 Texture
i

 

 

 

 

*7

 

 

 

 

 

 

—| Features Extracted '—

—| Synapses Classified '—

5: W = NormalizeWindow(I,Si)

& W = VerticalHoughTransform(W)

7: Etext = ExtractTextureFeatures(W)
8: Ehog = ExtractHoGFeatures(W)

9: Fshape = ExtractShapeFeatures(Si)
10:

11: if Model(Ptext, Phog, Eshape) > Tthen
12: Predict Si as synapse

13: else

14: Predict Si as not a synapse
15: end if

16: end for

Supervised algorithm to detect synapses in an EM image.

 

 

Fig. 2. Main steps of the supervised synapse-detection algorithm and corresponding pseudocode. High-contrast objects are automatically segmented
using histogram equalization. Shape-based features are extracted from these objects, as well as texture-based features from a small window surrounding
the object. A model is learned from these two features types and is used to classify synapses

In a co-training algorithm, two separate classiﬁers are trained with the
labeled data using the two subfeature sets, respectively. Each classiﬁer is
applied to the unlabeled examples, and it outputs a list of positive (pu-
tative synapses) and negative examples, ranked by conﬁdence of assign-
ments. We consider all the predictions in each list above a given threshold
and any example for which both independent classiﬁers agree on its label
is added to the labeled dataset. We iterate this process once and then
retrain a ﬁnal single classiﬁer using all features from the original set of
labeled examples and the new (predicted) set of labeled examples obtained
during this iterative process.

In addition to our attempts to normalize each image, this approach
provides another way to account for variability in never-before—seen sam-
ples without requiring explicit annotation, which can be cumbersome to
obtain in practice.

3.5 Testing and comparing with other approaches

For experiments using supervised learning, we manually labeled 11% (59)
of the 520 images from P14 and P75 distributed equally across each
sample. To do so, we performed the ﬁrst-pass segmentation described
earlier in the text and labeled the resulting windows (segments) as positive
or negative. A total of 230 synapses were identiﬁed (each showing a clear
post-synaptic density and elongated shape) along with 2062 negative ex-
amples. The MR8, HoG and shape descriptors were extracted from each
example and stored as a 480D feature vector. We performed 10-fold
cross-validation and report precision, recall and area under the ROC
and precision-recall curves. The conﬁdence in each prediction was mea-
sured based on the distance from the test vector to the decision boundary
in feature space (for SVM) and based on the proportion of tree agree-
ments for the Random Forest classiﬁer. For supervised learning, we did
not use any unlabeled data.

For the semi-supervised approach, we selected all the labeled images
from one sample (sample A, e.g. P14) and trained two classiﬁers using
texture and shape features, respectively. Each classiﬁer was then applied
to the R 90% of unlabeled images in sample B (P75), and all predictions

in either the positive or negative set in which both classiﬁers agreed (i.e.
both predicted the same label with conﬁdence above a given threshold)
were added to the training set. A new single classiﬁer C/ was then built
using the known labeled examples from sample A as well as the high-
conﬁdence examples predicted by the co-trained classiﬁers. We also
learned a baseline classiﬁer C that was only trained on the known
labels from sample A. Both classiﬁers were then tested for accuracy on
the true labeled examples from sample B.

We compared our supervised approach against a correlation-based
technique (Roseman, 2004) that classiﬁes a test window W as synapse-
containing with respect to training set T if max, corr( W, T i) > t; i.e. if the
correlation coefﬁcient between W and any positive example in the train-
ing set is > t, where t e [0, 1]. We also compare against Espina (Morales
et al., 2011), a tool designed to detect synapses in conventional EM
images (see Supplementary Information).

4 RESULTS AND DISCUSSION
4.1 Validating against conventional EM

One potential concern with using the EPTA method is that some
synapses may be washed away alongside other non-synaptic
structures. To validate the correctness of our experimental pro-
cedure, we tested whether EPTA-stained images preserve roughly
the same density of synapses that appear in conventional EM
images of the same region. First, we isolated tissue corresponding
to the D2 barrel of the mouse somatosensory cortex at P75. In
one hemisphere, we performed standard EM chemistry and in
the other hemisphere, we applied our EPTA stain. We then asked
an expert EM biologist (J .S.) and an expert neuroscientist
(A.L.B.) to manually annotate 26 conventional EM images for
high- and medium-conﬁdence synapses, and we compared dens-
ity ratios versus our automated algorithm on the EPTA-stained
tissue.

 

H3

112 /810's113u1no [p.IOJXO'SOilBIIHOJUIOIQ/ﬁdllq 11101; popeommoq

9IOZ ‘09 lsnﬁnv uo ::

S.Navlakha et al.

 

Table 1. EPTA-stained EM images preserve synapse density

 

Technique Number of images

Number of synapses Ratio Time

 

Expert 1 (Standard EM, manual counting)

High conﬁdence only 26

High and medium conﬁdence 26
Expert 2 (Standard EM, manual counting)

High conﬁdence only 24

High and medium conﬁdence 24
Algorithm (EPTA EM, automatic counting)

Threshold 2 0.7 275

Threshold 2 0.5 (default) 275

0.77 min/image

71 2.73 :l: 1.66

88 3.38 :l: 1.90
0.58 mins/image

65 2.71 :l: 1.55

89 3.71 :l: 1.85
0.06 mins/image

745 2.71 :l: 2.00

893 3.25 :l: 2.19

 

Note: We manually counted high and medium conﬁdence synapses in 24—26 conventional EM images and used our algorithm to automatically count synapses in 275 EPTA-
stained EM images of the same region. Different classiﬁer thresholds allow us to closely approximate the true number of synapses.

EPTA appears to conserve synaptic density compared with
conventional EM (Table 1). In particular, the two experts
found an average of 3.55 high and medium-conﬁdence synapses
per image within the conventional EM data versus 3.25 using the
EPTA-stained images (an average difference of only 8%). We
can even more closely approximate the number of high-conﬁ-
dence-only synapses by increasing the stringency of the classiﬁer
(a difference of <1 %). Because synaptic density may slightly vary
according to pial depth of the specimen even within D2, some
variation may be expected across hemispheres.

If the EPTA stain were selectively staining for only asymmetric
(excitatory) synapses and not symmetric (inhibitory) synapses,
then we would expect a roughly 20% difference (Micheva and
Beaulieu, 1995) between the number of synapses counted using
EPTA and conventional EM. However, the close correspondence
between the two methods suggests that we may be capturing both.
This further demonstrates the validity of the EPTA stain as syn-
apse-preserving (Bloom and Aghajanian, 1966) and provides a
way of choosing an appropriate threshold for classiﬁcation.

4.2 Detecting synapses using supervised and
semi-supervised learning

As aforementioned, we used texture- and shape-based features to
train several different classiﬁers (SVM, Random Forest and
AdaBoost). We next compared the performance of these classi-
ﬁers as well as a template-matching algorithm previously sug-
gested for this task (Roseman, 2004) (Fig. 3). The SVM trained
on both texture and shape features (MR8, HoG and Shape)
performed best with an accuracy ranging from 54.8 to 81.3%
on the positive set and 99.6 to 96.8% on the negative set depend-
ing on the classiﬁer threshold used. Speciﬁcally, the default
threshold of 0.5 allowed us to recall 67.8% of the true synapses
with a precision of 83.3% (Fig. 3B). This signiﬁcantly outper-
formed all other classiﬁers, as well as the correlation-based
template-matching algorithm. These results suggest that the
EPTA stain facilitates the high-throughput and automated
detection of synapses compared with conventional EM. Such a
performance would enable the large-scale use of this method
to study experience-dependent plasticity in the brain and to
detect abnormal changes in synaptic density owing to neuro-
logical disorders.

 

    
      

 ' ' ' ' ' ' '? ' ' ' ' ' "7 ' ' ' ' '  ' ' ' ' ' ' "z ' ' ' ' ' "26b'n'14'n' ' ' ' '  ' ' ' ' ' ' '—

 

P
on

 

0.4

as ----  ------  ------  -----  ------  ------  -----  ------  ------  ------ --

 

 

SVM Shape+Texture (AUC=0.964) _

AdaBoost (AUC=0.956)

0 1 _ I I I I I I I: I I I I I I I I: I I I I I I I : : Random Forest (AUC=0.949) _
' f f E ' ' ' ' ' '  SVM Shape (AUC=0.944)

' ' ' ' Template Matching (AUC=0.849)

0 0.1 0I2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
False positive rate (1 —Specificity)

True positive rate (Sensitivity)
O

0.2 -----  ------  ------  ----- 

 

 

 

 

 

 

 

 

 

09 .......  ....... 
 .......  .......  ......  .......  ................................ .-
 -------  -------  -----  -------  ------ 
 -------  -------  ------  ------  ------  ------  ------  ---- --j

05 .......  . . . . . . .  . . . . . .  . . . . . .  . . . . . .  . . . . . . 

Recall

0.4 -------  -------  ------  -------  -----  ------  -------  ------ 

 

 

 

 

 

 

 

 

 

 

as -------  -------  ------  -------  ------  ------  ------  ----- --i ---- 
0 2 _ SVM Shape+Texture (AUC=0.738) ' '
' AdaBoost (AUC=0.708)
1 Random Forest (AUC=0.695)
0- ‘ SVM Shape (AUC=0.641)
Template Matching (AUC=0.401) _ _ _ I
G I I I I I I I I
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Precision

Fig. 3. Cross-validation accuracy of all methods. AUC of the ROC
curve (top) and precision-recall curve (bottom) show that the SVM
trained using both texture and shape descriptors outperforms all other
methods

 

H4

112 /810's113u1no [p.IOJXO'SOilBIIIJOJUIOIQ/ﬁdllq 11101; popeommoq

9IOZ ‘09 lsnﬁnv uo ::

Detecting synapses in electron microscopy images

 

The shape descriptors by themselves worked well for identify-
ing positive examples but predicted many false positives owing to
similar contours in, for example, nucleus regions, which are
better discriminated using texture. The HoG features especially
beneﬁted from the vertical alignment of the synapses (a 7—10%
decrease in false negatives with similar false positives comparing
classiﬁers trained with and without alignment).

To further validate our classiﬁer with respect to human anno-
tation, we took 30 unlabeled images from our P14 sample and
asked an independent party (a technician in the Barth lab famil-
iar with the EPTA protocol) to manually annotate all high-con-
ﬁdence synapses. We then applied our supervised classiﬁer to
these images using the default classiﬁer threshold of 0.5 and ob-
tained an accuracy of 87.25% (89/ 102) on the set of positive
predictions (66.6% recall) and 96.28% (1164/1209) on the nega-
tive predictions. These percentages are similar to those obtained
using cross-validation.

Next, we applied semi-supervised learning to detect synapses
in new samples for which training data is not available (Table 2).
Here, we trained a single classiﬁer C on one sample (either P14 or
P75) and used co-training to learn another classiﬁer C’ using
unlabeled examples from the other sample. We found that the
accuracy of C’ increases amongst the positive class by 8—12% and
increases the AUC by 141% compared with the baseline classiﬁer
C (see Section 3). We varied the number of unlabeled examples to
transfer into C’ and found that using the top 0.5% of positive
examples (with a corresponding number of negative examples to
maintain the same ratio of positive-to-negative) improved accur-
acy but that including the top 1.5% led to loss in performance.

To explore how semi-supervised learning can account for the
variance between mice at the same age, we trained on positive
and negative examples from one P75 mouse and used the
examples from the other P75 mouse to test (and vice versa).
The baseline without semi-supervised learning had an average
precision-recall AUC of 68.89% (78.81 and 58.97% individually)
and an average ROC AUC of 95.80% (98.48 and 93.12% indi-
vidually). Then, we used co-training to train a new classiﬁer and

Table 2. Semi-supervised learning boosts cross-sample accuracy

 

 

 

Train/Test Co-training Accuracy AUC

Positive Negative Prec—recall ROC

(0%) (0%) (0%) (0%)
P75/P14 No 66.36 98.20 73.65 96.91
P75/P14 Yes (0.5%) 72.90 98.60 75.75 97.14
P75/P14 Yes (1.5%) 74.77 96.91 73.06 96.65
P14/P75 No 48.78 98.96 60.50 90.38
P14/P75 Yes (0.5%) 60.16 98.21 64.23 92.89
P14/P75 Yes (1.5%) 60.98 97.55 63.80 92.83

 

Note: We trained a classiﬁer using images from one sample and tested it on images
from another sample (ﬁrst column). This was done without co-training as a baseline
and with co-training using two thresholds for selecting the number of unlabeled
examples to include (second column). The third and fourth columns show accuracy
on the positive and negative classes, and the last two columns show the precision-
recall and ROC AUCs, respectively. Bold cells indicate best performance.

improved the average precision-recall AUC to 73.06% (82.45
and 63.66%) and the ROC AUC to 97.15% (98.78 and
95.52%). Both these results demonstrate the power of using
semi-supervised learning on unlabeled data, which is often plen-
tiful but ignored in bioimage applications.

Our approach is also scalable and efﬁcient: using unoptimized
MATLAB code, we can process a single image in 3.4s on a
standard desktop machine using a single processor.

4.3 Development changes in the mouse barrel cortex

Next, we used our method to study developmental changes in
synapse density and size in a deﬁned area of the mouse brain, the
representation of a single speciﬁed (D1) whisker in layer 4 of
somatosensory cortex. We performed additional experiments
and imaged the D1 barrel in two P17 mice following the same

 

 

 

 

 

    

 

 

 

 

 

 

A  ! ! ! !
 - P14+Log—normal fit
45o : - P17+Log—normal fit'
400   P75+LIog—norIma| fit
  -----  -------  -------  ------  -------  ------  ------- --
,>,~ 300 2 2 2 2 2 2 2
g 2 a 2 a 2 2 2
3 250 g .I  . . . . . . .  . . . . . .  . . . . . . .  . . . . . .  . . . . . . .  . . . . . . . ._
0' 2 2 s 2 s 2 2 2
9 200 :-- 2-  - - - - - - - -2 - - - - - - --: - - - - - - - --: - - - - - - --: - - - - - - - --: - - - - - - - --
LL 3 E E E E E E E
150    -------  ------  -------  ------  -------  ------- --
100 2 -.   -----  ------  -------  ------  -------  ------- --
so --  -  ------  ------  ------  ------  ------- --
o_ 2 \ — —- i  i
0 500 1000 1500 2000 2500 3000 3500 4000 4500
Size of synapse perimeter (nanometers)
B 2 3 3 .... ._
g I : éP-value < 0.501 foréall
"g """"""""""""""""""""" 't‘hréég'pairwisé'te'sts """ "
r9  , I . , I . I I: , I . , I . I I ,2 I . , I . I  I . , I . I I H: I , I . I I , _
h _
175 ...................................................................... ._
'6 2/ 2
a) . . . . . . . . . _ . . . . . . . . . . . . . . . . _ . . . . . . . . . . . . . . . . . . . . . . . . . . _ . . . . . . . . . . . . . . . . . _ . . . . . . . ._
.2
.|_a
c—U  . . . . . . . . _ . . . . . . . . . _ . . . . . . . . _ . . . . . . . . . _ . . . . . . . ._
3
E _ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ._
3 :
O — P14
— P17 -
P75

 

 

 

 

 

 

0 1500 1000 1500 2000 2500 3000 3500 4000 4500
Size of synapse perimeter (nanometers)

Fig. 4. Developmental changes and log-normal distribution of synaptic
strength. (A) Histogram of synapse sizes (as measured by length of the
perimeter of the synapse) from two P14 (blue), two P17 (red) and two P75
(green) samples. There is signiﬁcant growth in number of synapses from
P14 to P17, followed by pruning by adulthood (P75). Further, all three
distributions closely approximate a log-normal curve, which matches elec-
trophysiological data on synaptic connection strengths (Song et al., 2005).
(B) Cumulative distribution of synapse sizes suggest a shift in synapse
strength over time (P< 0.01, Kolmogorov—Smirnov test)

 

H5

112 /810's113umo [p.IOJXO'SOilBIIIJOJUIOIQ/ﬁdllq 11101; popeommoq

9IOZ ‘09 lsnﬁnv uo ::

S.Navlakha et al.

 

procedure as outlined in Section 3. We used our classiﬁer to
count synapses in images from both time points and, consistent
with previous ﬁndings (De Felipe et al., 1997), synapse density
appeared to rapidly increase from P14 to P17 (2.73 synapses per
image at P14 versus 4.25 at P17; Fig. 4A). Further, we found that
synapse density decreases in adults to about the same level as P14
(2.78 synapses per image at P75), which is also consistent with
prior work on pruning (\Nhite et al., 1997). Thus, our pipeline
can be used to better understand the rates of developmental
processes and can be used to deﬁne the precise timelines of
their occurrence.

Finally, to demonstrate the utility of the EPTA stain beyond
simply detecting synapses, we used shape features to characterize
the strength of each synapse based on its well-established correl-
ation with spine size (Lee et al., 2012). Modulation in synaptic
strength is an important facet of neuroplasticity and develop-
ment (\Nen and Barth, 2011) with larger contact areas likely to
transmit more current to the post-synaptic neuron. We used our
classiﬁer-predicted synapses in all samples (P14, P17 and P75)
and plotted the distribution of the perimeter of all synapses de-
tected (larger perimeter —> larger size —> stronger synapse).
Structurally similar synapses may appear to have different sizes
when projected onto 2D because the image cross-sections may be
taken at any angle. Exactly correcting for this bias would involve
3D reconstruction of synapses from stacks of EM images, which
is a separate and interesting problem in its own right (Jain et al.,
2010; Kreshuk et al., 2011; Merchan-Perez et al., 2009; Morales
et al., 2011).

We found that the distribution of synapse size at all ages ﬁts a
log-normal distribution (P<0.01 by Shapiro—Wilk and
Anderson—Darling tests; Fig. 4A), which is consistent with pre-
vious electrophysiological data (Song et al., 2005). We also
observed that there was a signiﬁcant shift in the distribution of
synapse size toward the emergence of small synapses during the
period of rapid increase in synapse density at P17, without a
concomitant loss of large synapses within this short developmen-
tal time window (Fig. 4B). These data suggest that developmen-
tal processes may preferentially enable the addition of new
synapses without necessarily augmenting the size of already-
existing synapses. The data analysis pipeline that we have estab-
lished can thus be used to generate and test speciﬁc hypotheses
about synapse growth and maturation in the developing neocor-
tex in a high-throughput and statistically robust manner.

5 DISCUSSION AND CONCLUSIONS

Synaptic density and strength are dynamically modulated in the
brain and are important facets for understanding neural circuitry
and function. Experience-dependent plasticity, circuit develop-
ment and neuropathologies have all been linked to changes in
the number and strength of synapses in the brain, and thus their
characterization is a useful parameter to facilitate our under-
standing of network function. Although current experimental
techniques for studying these conditions have many advantages
[e. g. electrophysiology provides a wealth of data not extractable
from images, and conventional EM can be used to resolve syn-
apses to extract pre— and post-synaptic partners and thus poten-
tially allow for reconstruction of microcircuits (Denk et al.,
2012)], several interesting questions can also be answered by

sampling from brain regions of interest over several conditions
or time points and generating high-conﬁdence large-scale statis-
tics of synaptic structures present. But to do so requires both
clarity in the data and robust algorithms to explore this data.

We used an old experimental technique for selectively staining
synapses in EM images. This technique does not require specia-
lized animal models for enhancing synapses, and we validated it
on new tissue of the mouse somatosensory cortex and against
conventional EM. We collected >800 images from three time
points and developed a fully automated and high-throughput ma-
chine-learning framework that detected thousands of synapses in
these images. We also used semi-supervised learning to learn
models that can adapt to variability in new samples by leveraging
unlabeled data. Such an approach is suitable for several other bio-
image classiﬁcation problems that also face issues of sample het-
erogeneity. Our approach is general and scalable enough to
handle large datasets and is freely available for others to use.

For future work, it would be a great interest to perform im-
munocytochemistry using EPTA against GABA and AMPA re-
ceptors to separately classify symmetric and asymmetric
synapses. Accuracy could also be improved by detecting synapses
in 3D, though this would require many more images and more
sophisticated computational techniques that can automatically
segment, align and reconstruct synapses across serial sections.
The 2D sampling-based strategies (e. g. considering sections sepa-
rated by 10 um) may certainly miss synapses, but if the same
procedure is applied to each sample at each time point, the rela-
tive number of synapses per image or unit area can still be com-
pared in a fair manner. Further, to remove some biases in 2D
analysis caused by larger synapses, previous works have pro-
posed formulas to adjust counts based on the average size of
synaptic proﬁles observed in the sample (Coggeshall and
Lekan, 1996; Mayhew, 1996; Huttenlocher and Dabholkar,
1997), which we can also use.

ACKNOWLEDGEMENTS

S.N. would like to thank Fernando Amat and Gustavo Rohde
for advice on developing the image processing algorithms and
Patrick Beukema for manual annotation of EPTA images.

Funding: National Institutes of Health (lROl GM085022) and
National Science Foundation (DBI—09653l6) awards to Z.B.J.

Conﬂict of Interest: none declared.

REFERENCES

Arbelaez,P. et al. (2011) Experimental evaluation of support vector machine-based
and correlation-based approaches to automatic particle selection. J. Struct.
Biol, 175, 319—328.

Bloom,F.E. and Aghajanian,G.K. (1966) Cytochemistry of synapses: selective stain-
ing for electron microscopy. Science, 154, 1575—1577.

Bloom,F.E. and Aghajanian,G.K. (1968) Fine structural and cytochemical analysis
of the staining of synaptic junctions with phosphotungstic acid. J. Ultrastruct.
Res., 22, 361—375.

Blum,A. and Mitchell,T. (1998) Combining labeled and unlabeled data with
co-training. In Proceedings of the 11th Annual Conference on Computational
Learning Theory ( COLT ), COLT ’ 98. pp. 92—100, ACM, New York, NY, USA.

Bock,D.D. et al. (2011) Network anatomy and in vivo physiology of visual cortical
neurons. Nature, 471, 177—182.

Breiman,L. (2001) Random forests. Mach. Learn, 45, 5—32.

 

HS

112 /810's113umo [p.IOJXO'SOilBIIIJOJUIOIQ/ﬁdllq 11101; popeommoq

9IOZ ‘09 lsnﬁnv uo ::

Detecting synapses in electron microscopy images

 

Cardona,A. et al. (2012) TrakEM2 software for neural circuit reconstruction.
PLoS One, 7, 638011.

Chang,C.-C. and Lin,C.-J. (2011) LIBSVM: A library for support vector machines.
ACM Trans. Intell. Syst. Technol., 2, 27:1—27:27.

Clare,R. et al. (2010) Synapse loss in dementias. J. Neurosci. Res., 88, 2083—2090.

Coggeshall,R.E. and Lekan,H.A. (1996) Methods for determining numbers of cells
and synapses: a case for more uniform standards of review. J. Comp. Neurol,
364, 6—15.

Cooke,B.M. and Woolley,C.S. (2005) Gonadal hormone modulation of dendrites
in the mammalian CNS. J. Neurobiol, 64, 34—46.

Cowan,W.M. et al. (1984) Regressive events in neurogenesis. Science, 225,
1258—1265.

da Costa,N.M. et al. (2009) A systematic random sampling scheme optimized to
detect the proportion of rare synapses in the neuropil. J. Neurosci. Methods, 180,
77—81.

Dalal,N. and Triggs,B. (2005) Histograms of oriented gradients for human detec-
tion. In: Schmid,C., et al. (eds), Proceedings of the International Conference on
Computer Vision and Pattern Recognition ( C VPR ), Vol. 2, IEEE Computer
Society, Washington, DC, USA, pp. 886—893.

De Felipe,J. et al. (1997) Inhibitory synaptogenesis in mouse somatosensory cortex.
Cereb. Cortex, 7, 619—634.

Denk,W. et al. (2012) Structural neurobiology: missing link to a mechanistic under-
standing of neural computation. Nat. Rev. Neurosci., 13, 351—358.

Duda,R.O. and Hart,P.E. (1972) Use of the hough transformation to detect lines
and curves in pictures. Commun. ACM, 15, 11—15.

Feng,L. et al. (2012) Improved synapse detection for mGRASP-assisted brain con-
nectivity mapping. Bioinformatics, 28, 25—31.

Fox,K. (2008) Barrel Cortex. Cambridge University Press, Cambridge.

Freund,Y. and Schapire,R.E. (1995) A decision-theoretic generalization of on—line
learning and an application to boosting. In Proceedings of the Second European
Conference on Computational Learning Theory (EuroCOLT). pp. 23—37.
Springer-Verlag, London, UK.

Glaze,D.G. (2004) Rett syndrome: of girls and mice—lessons for regression in
autism. Ment. Retard Dev. Disabil. Res. Rev., 10, 154—158.

Hinton,V.J. et al. (1991) Analysis of neocortex in three males with the fragile X
syndrome. Am. J. Med. Genet, 41, 289—294.

Huttenlocher,P.R. and Dabholkar,A.S. (1997) Regional differences in synaptogen-
esis in human cerebral cortex. J. Comp. Neurol, 387, 167—178.

J ain,V. et al. (2010) Machines that learn to segment images: a crucial technology for
connectomics. Curr. Opin. Neurobiol, 20, 653—666.

Johnston,M.V. et al. (2005) Rett syndrome and neuronal development. J. Child
Neurol, 20, 759—763.

Kim,J. et al. (2012) mGRASP enables mapping mammalian synaptic connectivity
with light microscopy. Nat. Methods, 9, 96—102.

Klintsova,A.Y. and Greenough,W.T. (1999) Synaptic plasticity in cortical systems.
Curr. Opin. Neurobiol, 9, 203—208.

Knott,G.W. et al. (2002) Formation of dendritic spines with GABAergic synapses
induced by whisker stimulation in adult mice. Neuron, 34, 265—273.

Kreshuk,A. et al. (2011) Automated detection and segmentation of synaptic con-
tacts in nearly isotropic serial electron microscopy images. PLoS One, 6, 624899.

Lee,K.F. et al. (2012) Examining form and function of dendritic spines. Neural
Plast., 2012, 704103.

Lefort,S. et al. (2009) The excitatory neuronal network of the c2 barrel column in
mouse primary somatosensory cortex. Neuron, 61, 301—316.

Leung,T. and Malik,J. (2001) Representing and recognizing the visual appearance
of materials using three-dimensional textons. Int. J. Comput. Vision, 43, 29—44.

Mayhew,T.M. (1996) How to count synapses unbiasedly and efﬁciently at the
ultrastructural level: proposal for a standard sampling and counting protocol.
J. Neurocytol., 25, 793—804.

Merchan—Perez,A. et al. (2009) Counting synapses using FIB/SEM microscopy:
a true revolution for ultrastructural volume reconstruction. Front. Neuroanat.,
3, 18.

Micheva,K.D. and Beaulieu,C. (1995) An anatomical substrate for experience-de-
pendent plasticity of the rat barrel ﬁeld cortex. Proc. Natl Acad. Sci. USA, 92,
1 1834—1 1838.

Morales,J. et al. (2011) Espina: a tool for the automated segmentation and
counting of synapses in large stacks of electron microscopy images. Front.
Neuroanat., 5, 18.

Morshedi,M.M. et al. (2009) Increased synapses in the medial prefrontal cortex are
associated with repeated amphetamine administration. Synapse, 63, 126—135.

Na,E.S. and Monteggia,L.M. (2011) The role of MeCP2 in CNS development and
function. Horm. Behav., 59, 364—368.

Nimchinsky,E.A. et al. (2001) Abnormal development of dendritic spines in FMRl
knock-out mice. J. Neurosci., 21, 5139—5146.

Peng,H. (2008) Bioimage informatics: a new area of engineering biology.
Bioinformatics, 24, 1827—1836.

Pfeiffer,B.E. and Huber,K.M. (2009) The state of synapses in fragile X syndrome.
Neuroscientist, 15, 549—567.

Roseman,A.M. (2004) FindEM—a fast, efﬁcient program for automatic selection of
particles from electron micrographs. J. Struct. Biol, 145, 91—99.

Skibbe,H. et al. (2011) SHOG: spherical hog descriptors for rotation invariant 3d
object detection. In Proceedings of the 33rd International Conference on Pattern
Recognition, DAGM’ll. pp. 142—151. Springer-Verlag, Berlin, Heidelberg.

Song,S. et al. (2005) Highly nonrandom features of synaptic connectivity in local
cortical circuits. PLoS Biol, 3, e68.

Sporns,O. (2010) Networks of the Brain. MIT Press, Cambridge.

Stoneham,E.T. et al. (2010) Rules of engagement: factors that regulate activity-de-
pendent synaptic plasticity during neural network development. Biol. Bull, 219,
81—99.

Szeliski,R. (2010) Computer Vision: Algorithms and Applications. lst edn. Springer-
Verlag New York, Inc, New York, NY.

Van den Oever,M.C. et al. (2012) The synaptic pathology of drug addiction. Adv.
Exp. Med. Biol, 970, 469—491.

Varma,M. and Zisserman,A. (2003) Texture classiﬁcation: are ﬁlter banks neces-
sary? In Proceedings of the 2003 IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), Vol. 2, pages II—691—8 vol. 2.

Walz,W. (2007) Patch-Clamp Analysis: Advanced Techniques. Humana Press,
Neuromethods Series, Totowa, New Jersey, USA.

Wen,J.A. and Barth,A.L. (2011) Input-specific critical periods for experience-de-
pendent plasticity in layer 2/3 pyramidal neurons. J. Neurosci., 31, 4456—4465.

White,E.L. et al. (1997) A survey of morphogenesis during the early postnatal
period in PMBSF barrels of mouse SmI cortex with emphasis on barrel D4.
Somatosens. Mot. Res., 14, 34—55.

White,J.G. et al. (1986) The structure of the nervous system of the nematode
Caenorhabditis elegans. Philos. Trans. R. Soc. Lond. B Biol. Sci., 314, 1—340.

Yassin,L. et al. (2010) An embedded subnetwork of highly active neurons in the
neocortex. Neuron, 68, 1043—1050.

Zhu,X. (2005) Semi-supervised learning literature survey. Technical report.
Computer Sciences, University of Wisconsin-Madison, Madison.

Zuiderveld,K. (1994) Graphics Gems IV. Chapter Contrast Limited Adaptive
Histogram Equalization. Academic Press Professional, Inc, San Diego, CA,
pp. 474—485.

 

H7

112 /810's113umo [p.IOJXO'SOllBIIIJOJUIOIQ/ﬁdllq 11101; popeommoq

9IOZ ‘09 lsnﬁnv uo ::

