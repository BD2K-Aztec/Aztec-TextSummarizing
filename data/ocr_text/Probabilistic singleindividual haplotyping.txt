Vol. 30 E008 2014, pages i379—i385
doi: 10. 1 093/bioinformatics/btu484

 

Probabilistic single-individual haplotyping

Volodymyr Kuleshov

Department of Computer Science, Stanford University, Stanford, CA 94305, USA

 

ABSTRACT

Motivation: Accurate haplotyping—determining from which parent
particular portions of the genome are inherited—is still mostly an un-
resolved problem in genomics. This problem has only recently started
to become tractable, thanks to the development of new long read
sequencing technologies. Here, we introduce ProbHap, a haplotyping
algorithm targeted at such technologies. The main algorithmic idea of
ProbHap is a new dynamic programming algorithm that exactly opti-
mizes a likelihood function speciﬁed by a probabilistic graphical model
and which generalizes a popular objective called the minimum error
correction. In addition to being accurate, ProbHap also provides con-
fidence scores at phased positions.

Results: On a standard benchmark dataset, ProbHap makes 11%
fewer errors than current state-of—the-art methods. This accuracy
can be further increased by excluding low-confidence positions, at
the cost of a small drop in haplotype completeness.

Availability: Our source code is freely available at: https://github.com/
kuleshov/ProbHap.

Contact: kuleshov@stanford.edu

1 INTRODUCTION

Although modern sequencing technology has led to rapid ad-
vances in genomics over the past decade, it has largely been
unable to resolve an important aspect of human genetics: gen-
omic phase. Each human chromosome comes in two copies: one
inherited from the mother, and one inherited from the father.
Despite the fact that differences between these copies play an
important biological role, until recently, decoding these differ-
ences (a process known as haplotyping or genome phasing) has
been a major technological challenge.

In recent years, however, we have seen an emergence of new
long read technologies (Kaper et al., 2013; Kitzman et al., 2010;
Peter et al., 2012; Voskoboynik et al., 2013) that may one day
enable routine cost-effective haplotyping. Because a long read
comes from a single chromosome copy, it reveals the phase of
all heterozygous genomic positions that it covers. By connecting
long reads at their overlapping heterozygous positions, it is pos-
sible to extend this phase information into haplotype blocks, in a
process referred to as single-individual haplotyping (SIH)
(Browning and Browning, 2011).

Although from the molecular biology side, routine haplotyp-
ing seems close to becoming a reality, dealing with long read data
remains non-trivial computationally. Under most formulations
of the problem, it is NP-hard to recover the optimal haplotypes
from noisy sequencing reads (Gusﬁeld, 2001). This has led to a
vast literature on heuristics for dealing with this problem as ac-
curately as possible.

Here, we propose a new algorithm, PROBHAP, which offers an
11% improvement in accuracy over the current leading method,

REFHAP. Unlike most other algorithms, PROBHAP also provides
conﬁdence scores in addition to genomic phase. These scores can
be used to prune low-accuracy positions and further improve
haplotype quality, at the cost of phasing fewer variants.

The main algorithmic ideas of PROBHAP are a new dynamic
programming algorithm and a probabilistic graphical model.
The dynamic programming algorithm determines the haplotypes
that maximize the likelihood function P(reads|true haplotypes)
speciﬁed by the probabilistic model as well as the probability
that these haplotypes are correct. It can be seen as a special
case of the well-known variable elimination algorithm (Koller
and Friedman, 2009).

From a theoretical point of view, the likelihood function spe-
ciﬁed by our probabilistic model generalizes a well-known ob-
jective called the minimum error correction (MEC). Previously
proposed exact dynamic programming algorithms for the MEC
can be easily derived as special cases of the general variable elim-
ination algorithm within our model. More interestingly, alterna-
tive formulations of this algorithm (corresponding to different
variable orderings) result in novel exact algorithms that are sig-
niﬁcantly faster than previous ones. Thus, our work generalizes
several previous approaches and provides a systematic way of
deriving new haplotyping algorithms.

2 RELATED WORK

Most phasing algorithms solve a formally deﬁned computational
problem called SIH, in which the goal is to minimize an objective
called the MEC (see Section 5). This objective is NP-hard
(Gusﬁeld, 2001); therefore, most early work on the SIH problem
involved simple greedy methods (Geraci, 2010). More recently,
these methods have been superseded by more sophisticated heur-
istics such as RefHap (Duitama et al., 2012) or HapCut (Bansal
and Bafna, 2008) that involve solving a Max-Cut problem as a
subroutine. There is also an exact dynamic programming solu-
tion to the SIH problem; its running time is exponential in the
length of the longest read (He et al., 2010).

Several probabilistic approaches have also been previously
proposed, including HASH (Bansal et al., 2008), MixSIH
(Matsumoto and Kiryu, 2013) and an algorithm used for recon-
structing the diploid genome of Ciona intestinalis (Kim et al.,
2007). These methods optimize an objective function similar to
that of PROBHAP using heuristics based on Markov chain Monte
Carlo (MCMC). They differ in the way in which they implement
MCMC. In addition, MixSIH (Matsumoto and Kiryu, 2013) is
to our knowledge the only package that also provides conﬁdence
scores at phased positions.

Probabilistic graphical models are widely used in the statistical
phasing literature to determine haplotypes from a panel of indi-
viduals using linkage disequilibrium patterns. However, the vast

 

© The Author 2014. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits
non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com

112 /810's112umo[pJOJXO'soi1BmJOJuioiw/2d11q IIIOJJ popeolumoq

910K ‘09 lsnﬁnV no :2

V.Kuleshov

 

majority of statistical methods do not use the partial phase in-
formation provided by long reads, and are not applicable to our
setting. A notable exception is a recent method called Hap-Seq
(He et al., 2012); without its statistical component it reduces to
the well-known exact exponential-time algorithm mentioned
above (He et al., 2010).

Also, there exists an extensive literature on the SIH problem
from the perspective of combinatorial optimization (Lippert
et al., 2002). Research in this ﬁeld is aimed at optimizing com-
binatorial objectives such as minimum fragment removal, min-
imum SNP removal or MEC. This research is of a more
theoretical nature and aims at providing a rigorous theoretical
understanding of the SIH problem (Lippert et al., 2002).

3 RESULTS
3.1 Overview of PROBHAP

PROBHAP is based on a new exact dynamic programming solu-
tion for the SIH problem, which makes it more accurate than
many existing methods. Its main drawback is a higher computa-
tional cost: its worst-case running time increases exponentially
with the read coverage. Fortunately, modern long read technol-
ogies cover the genome at a relatively low depth (Duitama et al.,
2012; Kitzman et al., 2010), making it possible to apply our al-
gorithm to such data. In cases when the coverage is extremely
high, PROBHAP also uses a preprocessing heuristic to merge simi-
lar reads (see Section 4). In our experience, PROBHAP handles
long read coverages of up to 20x; however, it is not appropriate
for higher coverage short read datasets.

The output of PROBHAP is a set of haplotype blocks in the
format of RefHap and HapCut. In addition, PROBHAP also pro-
duces at each position three conﬁdence scores that can be used to
identify locations where the phasing results are less accurate. The
posterior score represents the probability of correctly determining
the phase of a SNP with respect to the ﬁrst SNP in the block. The
transition score represents the probability of correctly determin-
ing the phase of a SNP with respect to the previous one. Finally,
the emission score is often helpful in ﬁnding sequencing errors
and other issues with the underlying data.

Whenever the transition score is too low, we suggest breaking
the haplotype block at a position. Whenever the posterior or the
emission scores are low, we suggest leaving that position
unphased.

3.2 Comparison methodology

We compared PROBHAP to three state-of-the art algorithms—
RefHap (Duitama et al., 2010), F astHare (Panconesi and
Sozio, 2004) and DGS (Panconesi and Sozio, 2004) as well as
to HapCut (Bansal and Bafna, 2008), a historically important
phasing package, and to MixSIH (Matsumoto and Kiryu, 2013),
the only method that we know that produces conﬁdence scores.
Previous studies (Duitama et al., 2012; Geraci, 2010) have iden-
tiﬁed the above methods as being the current state-of-the—art in
single-individual haplotype phasing.

Note that we do not compare our method to HapSeq (He
et al., 2012) because this package additionally uses population-
based statistical phasing techniques to improve accuracy. We
also do not consider previously proposed exact dynamic

programming methods (He et al., 2010), as they do not scale
to long reads: their running time increases exponentially in the
number of variants in a read, and some of the reads in our
datasets have >50 variants.

The heuristics we consider work as follows. In brief, F astHare
sorts the input reads, and then traverses this ordering once,
greedily assigning each read to its most probable chromosome
given what has been seen so far. The DGS method is equally
simple: it iterates until convergence between assigning each frag-
ment to its closest chromosome, and recomputing a set of
consensus haplotypes. The RefHap and Hapcut algorithms con-
struct a graph based where each vertex is either associated with a
position (HapCut) or with a sequencing read (RefHap); then, the
algorithms approximately solve a MaxCut problem on this
graph.

We test the above methods on a long read dataset from
HapMap sample NA12878 that was produced using a fosmid-
based technology (Duitama et al., 2012). The long reads have an
average length of ~40 kb and cover the genome at a depth of
~3x. This dataset is a standard benchmark for SIH algorithms
(Duitama et al., 2012; Matsumoto and Kiryu, 2013) in part
because HapMap sample NA12878 has also been phased mul-
tiple times based on the genomes of its parents. In this work, we
take the trio-phased variant calls from the GATK resource
bundle (DePristo et al., 2011); these provide accurate phase at
l 342 091 heterozygous variants that are also present in the long
read dataset.

We measure performance using the concept of a switch error
(Browning and Browning, 2011). A switch error is said to occur
when the true parental provenance of SNPs on a haplotype
changes with respect to the previous position. For example, if
the true SNP origins of a phased block can be written as MMF F ,
then we say there is a switch error at the third position. In this
analysis, we differentiate between two types of switches: a long
switch corresponds to an inversion that lasts for more than one
position (e. g. MMF F); a short switch, on the other hand, affects
only a single position (e. g. MMF M). Switch accuracy is deﬁned
as the number of positions without switch errors, divided by the
number of positions at which such errors could be measured.
Long switch accuracy is deﬁned accordingly in terms of long
switch errors. We also measure accuracy in terms of switches
per megabase (Sw./Mb).

Finally, a block N50 length of x signiﬁes that at least 50% of
all phased SNPs were placed within blocks containing x SNPs or
more. The percentage of SNPs phased was deﬁned as the number
of SNPs in blocks of length two or more, divided by the total
number of SNPs.

3.3 Results

Given comparable phasing rates and N50 block lengths,
PROBHAP produced haplotype blocks with more accurate long-
range phase: the long-range switch error of PROBHAP was 11%
lower than that of the second best algorithm, RefHap (Table 1).
In addition, PROBHAP also produced 6% fewer short switch
errors than RefHap.

Note that long switch accuracy is substantially more import-
ant than short switch accuracy, as it drastically changes the
global structure of haplotypes. Short switch errors, on the

 

i380

112 /810's112umo[pJOJXO'sot1emJOJutotw/2d11q IIIOJJ popeolumoq

910K ‘09 lsnﬁnV no :2

Probabilistic single-individual haplotyping

 

Table 1. Comparison of algorithm performance

 

 

 

 

 

 

 

 

 

Algorithm Long sw./Mb Short sw./Mb % phased N50
PROBHAP 1.07 3.70 91 .83 227
Refhap 1.20 3 .91 91.75 226
FastHare 1.32 4.03 91.76 227
DGS 1.48 4.18 91.66 227
HapCut 1.61 4.93 91.61 227
MixSH-I 1.41 5.43 92.64 229
Haplotype accuracy
5 99.3  i i 
E I
a 99.2 g
g 99.1 
E 99.0 5
U) I i
98.9 . .......| . .......| . .......l . .......| . .......
10'5 10'4 10'3 10'2 10'1 10"
400 . . . ..".'.?p'°.tyPe? ."inﬁth . . . . ...

 
    

 

N50 length
m w
.b
O
l

 

 

 

10'3 10'2 10'1 10°

88
l—I

000

U1

1—13 :
ol;n._nn_nnn_nnx
.|>

Haplotype completeness

 

0.95 . 
§ 0.90 '
E
Q 0.85
4E
a, 0.80
e
g 0.75

10'5 10'4 10'3 10'2 10'1 10"

Probability cutoff

 

 

 

 

Fig. 1. Accuracy/completeness trade-off for PROBHAP

other hand, introduce relatively small amounts of noise in the
data.

3.4 Evaluating conﬁdence scores

In addition to being more accurate, PROBHAP is also one of the
few algorithms which can provide estimates of their accuracy in
the form of conﬁdence scores. As an example of how such scores
might be used, we pruned phased positions that were deemed by
PROBHAP to be uncertain and measured the resulting accuracy.

More speciﬁcally, we deﬁned thresholds for each of the three
conﬁdence scores reported by PROBHAP. Whenever the posterior
or emission scores were lower than a threshold, we treated that
position as unphased. Whenever the transition probability was
below a threshold, we split the phased block into two parts at
that position.

Figure 1 shows that after pruning, one obtains phased blocks
that are 30—40% more accurate than the unpruned blocks (recall
that we describe them in Table l); the price to pay is a drop of
10—25% in N50 and phasing rate. The particular numbers shown
in Figure 1 were achieved by ﬁxing the posterior and transition

Accuracy/N50 tradeoff
l l

 

l l
— ProbHap
— MixSIH _

 

99.4 .

    

99.2

 

 

 

 
    
  

Switch accuracy

 

 

 

| |
150 200 250 300 350 400
N50

99 3 Accuracy/percent phased tradeoff
' l l l l l

 

 -------  ---------  --------  ---------  -------  --------  ---------  --------  ------- 

 -------  ---------  --------  ---------  --------  -------  ---------  --------  ------- 

 .......  —————————  ........  —————————  ........  ........  ........  .......  ....... 

 -------  ---------  --------  ---------  --------  --------  ---------  --------  ------- 

 -------  --------  ------  ---------  --------  --------  ---------  --------  ------- 

Switch accuracy

 -------  ---------  --------  --------  --------  --------  ---------  --------  ------- 
98.6— -------  ---------  --------  ---------  --------  --------  --------  ------  ------- 

98.5 i i
0.87 0.88 0.89

       

 

 

 

i i i i
0.91 0.92 0.93 0.94 0.95 0.96
Percent phased

i
0.90

Fig. 2. Comparison of the accuracy/completeness trade-off of PROBHAP
and MixSIH. The top panel compares the trade-off between the N50 and
the phasing accuracy; the phasing rate was the same for both algorithms
at each point. Similarly, the bottom panel examines the phasing rate
trade-off

Table 2. Running time of each algorithm on chromosome 22

 

Refhap FastHare DGS MixSHI PROBHAP

 

Running time 3.65 s 1.85 s 1.99 s 274.82 s 58.53 s

 

cutoffs to 0.6 and 10—5, respectively, and setting the emission
cutoffto 10-5, 10-4, 10-3, 10-2, 0.05, 0.1, 0.4 and 0.99.

Next, we compared the pruned regions from PROBHAP to those
of MixSIH, the only other package that allows the user to ex-
clude low-conﬁdence positions. We chose thresholds so as to
keep either the N50 or the phasing rate constant across both
algorithms, and measured how accuracy varied with the remain-
ing non-ﬁxed parameter. We present the results of our experi-
ment in Figure 2.

Overall, we see that given the same level of haplotype com-
pleteness, the pruned blocks of PROBHAP contain 20—30% fewer
switching errors than those from MixSIH.

3.5 Running time

We measured the running times of the algorithms on a laptop
computer (Table 2). We did not include HapCut in this compari-
son, as it is several orders of magnitude slower that the other
methods (Duitama et al., 2012). Although the three heuristics ran
faster than PROBHAP and MixSIH, a major reason for their speed
was due to not having to compute conﬁdence scores. In fact,
PROBHAP spends roughly two-thirds of its running time

 

i381

112 /810's18umo[pJOJXO'sot18mJOJutotw/2d11q IIIOJJ popeolumoq

9108 ‘09 lsnﬁnV no 22

V.Kuleshov

 

Table 3. Example of a 2 x 4 phasing matrix M, in which two reads cover
three positions each

 

 

1 2 3 4
Read 1 0 1 0 —
Read 2 — 1 0 0

 

computing such scores. Nonetheless, it phases chromosome 22 in
just under a minute; the total time for phasing a human genome
was under 30 minutes.

4 METHODS
4.1 Notation

Formally, an instance of the SIH problem is deﬁned by a pair of n x m
matrices M, Q, whose columns correspond to heterozygous positions
(indexed by j= 1, . . . , m), and whose rows correspond to reads (indexed
by i= 1, . . . , n). We refer to M as the phasing matrix; its entries take
values in the set {0, 1, —}. These values indicate the allele carried by a
read at a given position: for example, M i,- = 0 signiﬁes that read i covers
position j and carries allele 0 at j. A value of — indicates that read i did not
cover position j. See Table 3 for an example of a 2 x 4 phasing matrix.

The n x m matrix Q e [0, 1]”’”” is referred to as the q-score matrix; it
encodes the probability of observing a sequencing error at a given pos-
ition in a read. Such scores are available on virtually all sequencing
platforms.

A solution to an instance of the SH-I problem consists of a pair of
vectors h e {0, 1}”’ and r e {0, 1}”. The former determines the subject’s
haplotypes: at each genomic position j, it speciﬁes an allele h, e {0, 1}. We
consider only one haplotype, as the second is always the complement h of
the ﬁrst. The second vector r 6 {0,1}” indicates the true provenance
r,- e {0, 1} of each read i (i.e. whether i was obtained from the ‘maternal’
or the ‘paternal’ copy; because we do not have information to deter-
mine which copy comes from which parent, we refer to them as 0, 1).
We also use

hj ifri=0

h-ri= _
’0 {hj ifri=1

to denote alleles on the haplotype from which read i originated.

Next, let Po(i)={j|M,-j 7E —} denote the set of positions covered by
read i. Let also H,- = {hjlmin Po(i) 5 j 5 max Po(i)} be the set of haplo-
type variables spanned by read i and let R, = {r,-|min Po(i) 5
j 5 max Po(i)} be the set of read provenance variables spanning a pos-
ition j. We will use this notation to simplify several expressions through-
out the article. In particular, if position j is spanned by, say, reads 2, 3,
then we will use the notation maij f(Rj) =max,.,,,.3 f(r2, r3) and

ZRjﬂRj) = Zr2,r3f(r2, 7‘3).

4.2 Probabilistic model

We deﬁne the probability P(r, h, 0) over haplotypes h E {0, 1}’”, assign-
ments of reads r e {0, 1}” and observed data 0 e {0, 1, —}”Xm to be a
product of factors

n

m, h, o) = 1‘1 1‘1 P(oijlri, hj)1'[ P(r,->11 P(hj),
i=1 j=1

i = 1j:jePo(z)

where

Qij if 00' 75 hj(ri)

P 0.. r.’ h. =

(yll J)  ifo,-j=hj(r,-)
is the probability of observing the allele on the j-th position in read i, and
the factors P(r,) and P(hj) are priors that we leave as uniform, except for
P(h1 =0) = 1. This last choice eliminates the ambiguity stemming from
the fact that a solution h can be always replaced with its complement h; it
resolves this ambiguity by always choosing the solution with h1 = 0.
Finally, note that the r and h variables are hidden, while the 0 variables
are observed; the observed values are deﬁned by the matrix M.

The dependency structure of P can be represented in terms of a
Bayesian network whose topology mirrors the two-dimensional structure
of the matrix M. See Figure 3 for the Bayesian network associated with
the phasing matrix in Table 3, which we gave earlier as an example.

4.3 Maximum likelihood haplotypes

We determine maximum-likelihood haplotypes h* = arg maxh log P(o =
M |h) using the belief propagation algorithm, also known as max-sum
message passing over a junction tree (Koller and Friedman, 2009). In
brief, this algorithm involves groups of variables passing each other in-
formation about their most likely assignment; a well-known special case
of this method is the Viterbi algorithm for hidden Markov models
(HMMs).

4.3.] Definition of max-sum message passing We start by brieﬂy
deﬁning the max-sum message passing algorithm for graphical models.
Readers familiar with the subject may skip this subsection.

DEFINITION 1. Let P be a probability over a seltC of variables
X= {x1,...,x,,} that is a product of k factors P=Hi=1¢i(X,-), with
each factor ¢,. being deﬁned over a subset of variables X ,- g X. A junction
tree T over P is a tree whose set of nodes is a family of subsets
C = {C1, . . . , Cm}, with  g X and that satisfies the following properties:

(1) For each factor ¢,, there is a cluster c( i ) such that X ,- C Cc“).

(2) (Running intersection) If x e C,- and x e Cj, then x e Ck for all Ck
on the unique path from C, to  in T.

Given this deﬁnition, we now deﬁne max-sum message passing. We
restrict our deﬁnition to the case when the junction tree T is a path, which
is going to be the case for our model.

DEFINITION 2. Let P be a probability distribution as in Definition 1. Let T
be a junction tree over clusters  for j = 1, . . . , m connected into a path and
ordered by j, with Cm serving as the root. The max-sum message from  to
Cj+1 is a function  defined over the variables in Cj ﬂ Cj+1 as

Mj(Cj n Cj+1) = 512g; (i-gjlog (bl-(Xi) +Mj—1(Cj—1 n (31)),

with the additional deﬁnition that M0 E 0.

The max-sum message passing algorithm recursively computes the
above messages and determines that max XP(X) is

mCax < 2 log ¢,(X,-)+Mm_1(Cm_1 ﬂ Cm)).

m i:c(i) =m

The actual assignment that maximizes P can be found by storing the
variable assignments that maximize each Mj. Unfortunately, proving
the correctness of this algorithm is beyond the scope of this article. For
a complete discussion that holds for arbitrary junction trees, we refer the
reader to a textbook on graphical models (Koller and Friedman, 2009).

 

i382

112 /810's18umo[pIOJXO'soIIBmIOJquIqj/2dnq IIIOJJ popcolumoq

9108 ‘09 lsnﬁnV no 22

Probabilistic single-individual haplotyping

 

Fig. 3. Bayesian network associated with the problem instance deﬁned in
Table 3. The shaded nodes represent hidden variables; unshaded variables

are observed. Variables belonging to cluster C3 of the associated junction
tree are shown in bold

4.3.2 Applying max-sum message passing to the PROBHAP
model We now deﬁne how the max-sum message passing algorithm
is applied to the graphical model we deﬁned in Section 4.2.

DEFINITION 3. Let T be a junction tree for P deﬁned by clusters
Cj = {r,-, hj, oijlmin Po(i) 5j 5 max Po(i)}

for j= 1, . . . , m connected into a path ordered by j, with Cm serving as the
root.

Each cluster C,- contains h, and all the o,-,- and r,- variables associated
with reads that span across position j. For an example of one such cluster,
see Figure 3.

LEMMA 1. The tree T in Deﬁnition 3 is a valid junction tree for the distri-
bution P deﬁned in Section 4.2.

PROOF. It is easy to check that the scope of each factor of P is in a unique
cluster. We therefore focus on proving that T has the running intersection

property.

Let Cx, Cy be two clusters in T with x 5 y, and let CZ be a cluster on
the path between Cx and Cy. Because T is a path, we must have
x 5 Z 5 y. We need to show that CJ, O C, Q CZ.

Observe that by construction C, O Cx can only contain r-variables. Let
r; 6 CJ] (1 Cx be one such variable. We need to show that r, e CZ, i.e. that
min Po(l) 5 z 5 max Po(l).

From r, e C, O Cx, we have that Po(l) 5 y 5 x 5 max Po(l). Because
we also have x 5 z 5 y, our claim follows. I

Now let Rjnj+1=RjﬂRj+1 and RjV+1=Rj\Rj+1. The interested
reader may verify that the message from cluster j to cluster j + 1
during a run of max-sum message passing with Cm as the root of T
equals for j > 1,

2%(Rjnj4—1) = max max 2 log P(oijlri,  + Till-_1(Rj_lnj) , 

. R .
h] N“ i:r,-eRj

and for j = 1, M1(Rmz)=max R,\2 log P(o,-1|r,-,h1=0)). Note

that we disregard the priors P(r,), P(hj) in all messages except the ﬁrst
because they are uniform.

Intuitively, M (Rm-Jr 1) represents the maximum likelihood of the data
at positions 1, . . . , j assuming that reads spanning both j and j + 1 have
provenances speciﬁed by Rm“. The maximum of P is computed using
the recursion

i:r,-eC1

1 P . . +M _ R _ .
U223? U323 (tn-g]; 0g (01min, hm) m 1( m lﬂm))

Table 4. Example of a sequencing error that confounds the long-range
structure of the haplotypes

 

 

1 2 3 4 5
Read 1 0 0 1 0 —
Read 2 — — 0 0 0

 

Note. If the quality scores are the same at all positions, the haplotypes h = 00000,
h = 00111 have the same probability.

4.3.3 Running time The above algorithm computes one message for
each of m. A message speciﬁes a value for each assignment of variables
in Rm“; this value is the maximum over all assignments to h, and to
RN“, and for each such assignment, we need to compute 2,3761%], log P
(oil-lri, hj) in 0(|Rj|) time. Therefore, computing a message requires |le
x2 x 2'anffll x 2'RJV'f1'=|Rj|2IRf|Jr1 iterations. Thus, the total running
time of the algorithm is 0(m/c2"+1), where K=man|Rj| is the maximal
coverage across all the positions.

4.4 Conﬁdence scores

Next, we turn our attention to deriving conﬁdence estimates for genomic
regions. As an example of why such estimates are useful, we show in
Table 4 that, somewhat counter-intuitively, two SNPs may be unphased
even when they are connected by accurate reads.

4.4.1 Motivating example In Table 4, the data contains sequencing
errors at position 3 or 4. If the error occurs at position 3 (in either row),
then the two reads come from the same haplotype and the correct solu-
tion is h = 00000. If, on the other hand, the error occurs at position 4,
then the two reads come from different chromosomes and the true haplo-
type is h = 00111. If the quality scores are the same at all positions, the
four errors are equally likely, and the haplotypes h = 00000, h = 00111
have the same probability.

Simple optimization-based algorithms would likely produce a single
haplotype in the above example; our probabilistic model, however, would
assign a transition probability of 0.5 to position 3.

4.4.2 Dynamic programming recursion We again perform probabil-
istic inference in our model using belief propagation. Our particular im-
plementation of this method is inspired by the sum-product message
passing algorithm (Koller and Friedman, 2009) over the previously
deﬁned junction tree T. In sum-product message passing, clusters of vari-
ables pass to each other information about their local probability distri-
bution; after two rounds of message passing (referred to as ‘forwards’ and
‘backwards’), the clusters become calibrated and can be queried for vari-
ous probabilities. A well-known special case of this method is the for-
wards—backwards algorithm for HMMs.

More concretely, we compute for each node j two factors, PIhj, Rj] and
B[hj, Rj], using the dynamic programming recursions below.

Fihj’ Rj]

= Z Z Fihj—r, Rj—1]P(0jihj’ Rj)P(Rj)P(hj) (2)
hj—l R'—1~Rj
Bihj, Rj]
=2 2 B[hj+le+1]P(0j+lihj+l9 Rj+1)P(Rj+l)P(hj+1) (3)
hj+1 Rj+1~Rj

The notation Rj~ j_1 indicates that the r,- variables common to both R,-

and Rj_1 have been assigned the same value, and P(Ojlhj, Rj) is short-
hand for H P(oijlri, hj). It follows from our deﬁnition of the prior

i:r,-eRj

 

i383

112 /810's112umo[pIOJXO'soI112uIIOJHIoIq/pd11q 111011 popcolumoq

9108 ‘09 lsnﬁnV no 22

V.Kuleshov

 

P(h1) that the initial values equal PIh1 = 0, R1] = P(Rl) and
PIhl = 1, R1] = 0; in addition, B[hm, Rm] = 1.
It is easy to show by induction that

FIhj, R1] = P(Oly', h!" R1) (4)

where 0k;l={o,-j|k 5j 5 l}.

4.4.3 Computing conﬁdence probabilities From (4), (5), we can
now easily compute conﬁdence scores. One such score is the posterior
probability P(hjl01;m). It represents the probability that h,- was deter-
mined correctly with respect to hl and can be computed as
P(hj|01:m) = ZRJ- P(hj’ RjI01:m)a Where

P(hj’ RjI01:m) =P(01:j’ hj’ Rj)P(0j+l:thji Rj)/P(01:m)-

Next, the transition probability P(hjlhj_1,01;m) represents the prob-
ability of consecutive SNPs being phased correctly; it can be used to
detect potential errors like the one shown in Table 4. We compute this
value using the identity P(hjlhj_1, 01;m)=P(hJ-,hj_1|01;m)/P(hj_1|01;m),
where the denominator is the posterior probability and the numerator
is computed as

ZR,—,R,-_1 P(hj’ hj—l ’ R1" Rj—h Olim)
P(01:m)

_ Ewe,- P(Oj+ 1:m|hj’ R1) T011" R1, 01')

— P(01:m) ’

P(hj’ hj—1I01:m)=

 

 

where

T021, Rj, 0,) = Z P(o,|h,-, Rj)P(hj)P(Rj)P(01:J-, h,, 11,-)

hj—l aRj—l

Additionally, we found that the emission probability P(Ojlthj) was
useful in detecting errors in the data. Computing this value only involves
the expression P(Ojlthj) = Hijepow P(o,-j|r,-, hj).

Finally, note that in general, one can compute any set of probabilities
P(hklhl, 01m) in the model. However, this involves doing potentially up
to a full run of message passing.

4.5 A merging heuristic

The exact dynamic programming algorithm described above is practical
for coverages of up to 10—12x. For deeper or for highly uneven cover-
ages, we propose a simple preprocessing heuristic. The heuristic consists
in reducing the coverage by repeatedly merging reads that are likely to
come from the same haplotypes until there are no reads that we can
conﬁdently merge.

To determine whether to merge reads k, l, we consider the ratio

I—IjePo(k)ﬂPo(l) (P (ij, 0’ (DP (011" 1,0)1‘ P (ij, 1, (DP (011', 0, 0))
Hjepoampow (P(okj, 0, 0)P(olj, 0, 0) + P(okj, 1, 0)P(olj, 1, 0)) ’

where P(ij, x, y) is shorthand for P(okj, rk=x, hj= y). Intuitively, the
denominator is associated with the likelihood that the two reads come
from the same haplotype and the numerator is associated with the like-
lihood that the reads’ origins are different. Both terms are estimated by a
heuristic formula that decomposes over each position. If reads k, l are
merged, then position j of the resulting new read is assigned the allele that
has the highest q-score in the initial reads k, l (i.e. arg maxk,l{QkJ-, Qlj});
the q-score at that position is set to the difference of the initial reads’
q-scores (i.e. |ij — Qljl).

In practice, one may select a conﬁdence threshold for (6) and only
merge reads that are below this threshold. We found empirically a
value of 1 — 10—9 to work well.

 

(6)

4.6 A post-processing heuristic

In addition, PROBHAP admits an extra post-processing heuristic for ad-
justing the optimal haplotypes h*. This heuristic was initially proposed for
the algorithm RefHap; PROBHAP currently uses it by default, although it
can be disabled. The heuristic starts with the optimal read assignments r*
and determines at each position j a pair of sets

Sj’o ={i|(r,-=0 ﬂ  U (ri=1 (1 My: 
S},1={i|(r,-=0 (1 My:  U (ri=1 ﬂ 
It then outputs a new haplotype hnew deﬁned as
0  ISjaol>|Sjall
hjl-leW: 1  ISjaol<|Sjall
— otherwise.
We found that this heuristic increases the short switch accuracy of
PROBHAP on the NA12878 dataset; the long switch accuracy remains

the same. We suggest using this heuristic in settings where the quality
scores may not be well calibrated.

5 DISCUSSION: THEORETICAL ASPECTS

Interestingly, the probabilistic framework of PROBHAP general-
izes the SIH formalism on which most existing methods are based.
This allows us to easily derive well-known exact dynamic pro-
gramming algorithms as special cases of the variable elimination
algorithm for graphical models. More interestingly, the variable
elimination algorithm with different variable orderings results in
novel exact algorithms that are far more efﬁcient than existing
ones.

5.1 Generalizing the SIH framework

In its standard formulation, the SIH problem consists in ﬁnding a
haplotype h that minimizes the MEC criterion:

MEC(h, M)
= 2min L: [(Mij = hj), Z [(1%] 241)],
i = 1 ':jePo(z) j:jePo(i)

where I : {True, False} —> {0, 1} is the indicator function, and the
remaining notation is the same as deﬁned in the Section 4. The
MEC measures the total number of positions within all the reads
that need to be corrected to make the reads consistent with a
haplotype h.

It is easy to show that the MEC objective can be recovered as a
special case of our framework. Indeed, if we deﬁne the factors
¢(o,-J-, r,-, hj) (which we have previously set to P(Oijlri, hj)) in a way
that

l”, 13),. =
¢(01 r J) [exp (0) if oij=hj(ri),

then log P(M, r, h) equals MEC(h, M), although P is no longer a
probability.

Thus, our dynamic programming algorithms can also produce
exact solutions to the MEC objective, and just as interestingly,
they can produce conﬁdence probabilities associated with the
MEC.

 

i384

112 /810's112umo[pIOJXO'soI112uIIOJHIoIq/pd11q 111011 popcolumoq

9108 ‘09 lsnﬁnV no 22

Probabilistic single-individual haplotyping

 

5.2 Rederiving existing SIH algorithms

Interestingly, we can easily recover an existing dynamic program-
ming algorithm (He et al., 2010) for the MEC as a special case
of variable elimination in our graphical model. Indeed, con-
sider the junction tree deﬁned by n variable clusters
C,={r,-, hj, o,-J-| j e Po(i)} connected into a path ordered by i. If
we assume for simplicity that the data have no contained reads,
then the message from cluster i —l to cluster i during a run of
max-sum message passing with C,, as the junction tree root
equals precisely

M(H,-n,-+1) = maxmax

7i Hi\i+1

2 log P(Oijlri, hj) +M(Hi—lﬂi) ,
jlhjEHi

(7)

where Hini+1 2 Hi 0 Hi+1 and HIV—1.1: Hi\Hi+1.  is essen-
tially the well-known dynamic programming recursion (He et al.,
2010) we were looking to ﬁnd.

Unfortunately, the time to compute the above recursion in-
creases exponentially in the length of the reads, which is precisely
the data we want to use for phasing.

5.3 Deriving novel SIH algorithms

Fortunately, as we have seen, we can derive from our framework
exact algorithms that are suitable for long read data.
Interestingly, these methods are in a sense dual to equation (7):
the structure of the probabilistic model P is entirely symmetric in
r, h. If we reverse h and r in Section 4, we obtain recursion (7).

Potentially, our framework allows deriving other exact algo-
rithms by deﬁning alternative junction trees for the max-sum
message passing algorithm. One way to do this involves using
minimizing their tree-width using some well-known heuristics
(Koller and Friedman, 2009). Because the running time max-
sum message passing is exponential in the tree-width of a junc-
tion tree, this would lead to much faster running times.

6 CONCLUSION

In summary, we have introduced a new single-individual phasing
algorithm, PROBHAP, that offers an 11% improvement in accur-
acy over the current state-of-the-art method, RefHap. In add-
ition, it is one of the only methods to provide the user with
conﬁdence scores at every position; these conﬁdence scores can
be used to prune positions whose phase is uncertain and thus
substantially increase the overall accuracy.

The advances behind PROBHAP are made possible by framing
the phasing problem within a probabilistic graphical models
framework. This framework makes it particularly easy to
reason about the problem; in fact, all our algorithms are special
cases of standard procedures for optimizing graphical models.

On the theoretical side, this work generalizes the MEC criter-
ion used by existing methods. Our approach allows us to obtain
existing algorithms as special cases of well-known optimization

procedures, and also easily derive new, more efﬁcient algorithms;
it may thus serve as a foundation for further algorithmic insights.

ACKNOWLEDGEMENT

We thank Sivan Berovici for important suggestions regarding the
model deﬁnition, as well as Dmitry Pushkarev and Michael
Kertesz for helpful discussions. This research was partly done
at Moleculo Inc.

Funding: This work was partly funded by NIH/NHGRI grant
T32 HG000044.

Conflict of Interest: none declared.

REFERENCES

Bansal,V. and Bafna,V. (2008) HapCUT: an efﬁcient and accurate algorithm for the
haplotype assembly problem. Bioinformatics, 24, i153—i159.

Bansal,V. et al. (2008) An MCMC algorithm for haplotype assembly from whole-
genome sequence data. Genome Res., 18, 1336—1346.

Browning,S.R. and Browning,B.L. (2011) Haplotype phasing: existing methods and
new developments. Nat. Rev. Genet., 12, 703—714.

DePristo,M.A. et al. (2011) A framework for variation discovery and genotyping
using next-generation DNA sequencing data. Nat. Genet., 43, 491—498.

Duitama,J. et al. (2010) ReFHap: a reliable and fast algorithm for single individual
haplotyping. In: Proceedings of the First ACM International Conference on
Bioinformatics and Computational Biology. ACM, New York, NY, USA,
pp. 160—169.

Duitama,J. et al. (2012) Fosmid-based whole genome haplotyping of a HapMap
trio child: evaluation of Single Individual Haplotyping techniques. Nucleic Acids
Res., 40, 2041—2053.

Geraci,F. (2010) A comparison of several algorithms for the single individual SNP
haplotyping reconstruction problem. Bioinformatics, 26, 2217—2225.

Gusﬁeld,D. (2001) Inference of haplotypes from samples of diploid populations:
complexity and algorithms. J. Comput. Biol, 8, 305—323.

He,D. et al. (2010) Optimal algorithms for haplotype assembly from whole-genome
sequence data. Bioinformatics, 26, i183—i190.

He,D. et al. (2012) Hap-seq: an optimal algorithm for haplotype phasing with im-
putation using sequencing data. In: RECOMB’I2: Proceedings of the 16th
Annual international conference on Research in Computational Molecular
Biology. Springer-Verlag, Berlin.

Kaper,F. et al. (2013) Whole-genome haplotyping by dilution, ampliﬁcation, and
sequencing. Proc. Natl Acad. Sci. USA, 110, 5552—5557.

Kim,J.H. et al. (2007) Diploid genome reconstruction of Ciona intestinalis and
comparative analysis with Ciona savignyi. Genome Res., 17, 1101—1110.

Kitzrnan,J.O. et al. (2010) Haplotype-resolved genome sequencing of a Gujarati
Indian individual. Nat. Biotechnol, 29, 59—63.

Koller,D. and Friedman,N. (2009) Probabilistic Graphical Models: Principles and
Techniques - Adaptive Computation and Machine Learning. The MIT Press,
Cambridge, MA.

Lippert,R. et al. (2002) Algorithmic strategies for the single nucleotide polymorph-
ism haplotype assembly problem. Brief. Bioinformatics, 3, 23—31.

Matsumoto,H. and Kiryu,H. (2013) MixSIH: a mixture model for single individual
haplotyping. BMC Genomics, 14 (Suppl. 2), S5.

Panconesi,A. and Sozio,M. (2004) Fast hare: a fast heuristic for single individual
snp haplotype reconstruction. In: Jonassen,I. and Kirn,J. (eds) Algorithms in
Bioinformatics. Springer, Berlin Heidelberg, pp. 266—277.

Peters,B.A. et al. (2012) Accurate whole-genome sequencing and haplotyping from
10 to 20 human cells. Nature, 487, 190—195.

Voskoboynik,A. et al. (2013) The genome sequence of the colonial chordate,
Botryllus schlosseri. eLife, 2, e00569.

 

112 /810's112umo[pIOJXO'soI112uIIOJHIoIq/pd11q 111011 popcolumoq

9108 ‘09 lsnﬁnV no 22

