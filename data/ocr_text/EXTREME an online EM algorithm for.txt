ORIGINAL PAPER

Vol. 30 no. 12 2014, pages 1667—1673
doi: 10. 1 093/bioinformatics/btu093

 

Sequence analysis

Advance Access publication February 14, 2014

EXTREME: an online EM algorithm for motif discovery

Daniel Quangl’2 and Xiaohui Xie1’2’*

1Department of Computer Science, University of California, Irvine, CA 92697, USA and 2Center for Complex Biological

Systems, University of California, Irvine, CA 92697, USA

Associate Editor: John Hancock

 

ABSTRACT

Motivation: Identifying regulatory elements is a fundamental problem
in the field of gene transcription. Motif discovery—the task of identify-
ing the sequence preference of transcription factor proteins, which
bind to these elements—is an important step in this challenge.
MEME is a popular motif discovery algorithm. Unfortunately,
MEME’s running time scales poorly with the size of the dataset.
Experiments such as ChlP-Seq and DNase—Seq are providing a rich
amount of information on the binding preference of transcription fac-
tors. MEME cannot discover motifs in data from these experiments in
a practical amount of time without a compromising strategy such as
discarding a majority of the sequences.

Results: We present EXTREME, a motif discovery algorithm designed
to find DNA-binding motifs in ChlP—Seq and DNase—Seq data. Unlike
MEME, which uses the expectation-maximization algorithm for motif
discovery, EXTREME uses the online expectation-maximization algo-
rithm to discover motifs. EXTREME can discover motifs in large data-
sets in a practical amount of time without discarding any sequences.
Using EXTREME on ChlP-Seq and DNase—Seq data, we discover
many motifs, including some novel and infrequent motifs that can
only be discovered by using the entire dataset. Conservation analysis
of one of these novel infrequent motifs confirms that it is evolutionarily
conserved and possibly functional.

Availability and implementation: All source code is available at the
Github repository http://github.com/uci-cbcl/EXTREME.

Contact: xhx@ics.uci.edu

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on October 23, 2013; revised on January 24, 2014; accepted
on February 7, 2014

1 INTRODUCTION

Transcription factors (TFs) are proteins that play an important
role in transcriptional regulation by promoting or blocking the
recruitment of RNA polymerase 11. They can bind speciﬁcally to
recognition sequences on the genome or to other TFs in a com-
plex. High-throughput assays generate a rich amount of infor-
mation on the sequence preference of TFs. ChIP-Seq (Johnson
et al., 2007) can provide the genome-wide binding sites of a single
TF. DNase-Seq, which sequences open chromatin regions in the
genome, can provide single nucleotide resolution for the binding
sites of many TFs (Hesselberth et al., 2009). When sequenced
deep enough, binding sites appear as dips, or footprints (FPs), in
the DNase—Seq signal. FPs only identify the locations of the TF

 

*To whom correspondence should be addressed.

binding sites; they do not identify the proteins that are bound
there. These assays can provide functional information for thou-
sands to millions of base pair regions in the genome.

The task of identifying the sequence preference of a TF is
called motif discovery. Motif discovery algorithms can be classi-
ﬁed as either search-based or probabilistic. Search-based algo-
rithms infer motifs as consensus sequences. Probabilistic
algorithms infer motifs as position frequency matrices (PFMs),
which specify the frequency of nucleotides for each position in
the binding site.

While PF Ms provide more information about a TF’s binding
speciﬁcity than consensus sequences, inferring PFMs is not
always practical. Probabilistic motif discovery programs usually
use algorithms such as expectation-maximization (EM)
(Dempster et al., 1977) for inference. These algorithms scale
poorly with dataset size. Search-based algorithms are therefore
preferred for large datasets. DREME (Bailey, 2011) is an ex-
ample of a search-based algorithm designed for large datasets.

MEME is a popular probabilistic motif discovery program
(Bailey and Elkan, 1994). It uses the EM algorithm to infer
PFMs. Since its inception in 1994, it has gone through several
versions. However, MEME scales poorly with large datasets.
One strategy to improve MEME’s performance is to discard
many of the sequences. This is the strategy used by MEME-
ChIP (Machanick and Bailey, 2011). However, discarding
sequences can decrease the chance of discovering motifs corres-
ponding to infrequent cofactors. Another strategy, as used in
STEME, applies sufﬁx trees to accelerate MEME (Reid and
Wernisch, 2011). However, STEME is only practical for ﬁnding
motifs of up to width 8 on large datasets because its efﬁciency
tails off quickly as the motif width increases. Other strategies for
accelerating MEME involve specialized hardware such as paral-
lel pattern matching chips on PCI cards (Sandve et al., 2006).
However, these implementations require hardware not available
to most researchers.

To overcome these issues, we propose an online implementa-
tion of the MEME algorithm that we have named EXTREME.
The online EM algorithm sticks closely to the original EM algo-
rithm (hereafter referred to as the batch EM algorithm) (Cappé
and Moulines, 2009). Normally, the online EM algorithm is de-
signed for cases where not all data can be stored at once.
Although most computers have enough memory to store entire
sequence datasets at once, the online EM algorithm is still ad-
vantageous for motif discovery because, for large sample sizes,
the online EM algorithm is more efﬁcient, from a computational
point of View, than the batch EM algorithm. We show that many
of the features of the original MEME algorithm can be adapted

 

© The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 1667

112 ﬂJO'slcumo[pJOJXO'sopchogurorq/ﬁd11q IIIOJJ pepcolumoq

910K ‘09 lsnﬁnV no :2

D. Quang and X.Xie

 

to the online methodology. Furthermore, we show that
EXTREME can achieve similar results to MEME in a fraction
of the execution time. We also show that using the entire dataset
is necessary to discover infrequent motifs, which is not always
practical to do with MEME. To the best of our knowledge, this
is the ﬁrst application of the online EM algorithm to motif
discovery.

2 MATERIALS AND METHODS

2.1 MEME

The original MEME algorithm applies the batch EM algorithm to infer
PFMs. Here, we provide a brief overview of MEME’s model and how
MEME applies the batch EM algorithm to infer parameters.

2.1.] MEME’S model Let Y: (Y1, Y2, ..., YN) be the dataset of
sequences, where N is the number of sequences in the dataset. Each se-
quence is over the alphabet A = (A, C, G, T). MEME uses a mixture
model that breaks up the dataset into all n (overlapping) subsequences
of length W, which it contains. We will refer to this new dataset as
X = (X 1,X2, ...,Xn). The mixture model is a two-component
model that assumes each subsequence is either an instance of the motif
or background. Other variants of MEME place additional constraints.
The one occurrence per sequence variant assumes that each sequence
contains one instance of the motif. The zero or one occurrence per
sequence variant assumes each sequence can have zero or only one oc-
currence of the motif. These two variants make slight modiﬁcations to
MEME’s probabilistic model. We will only consider the two-component
model.

The background component is characterized as a zero-order Markov
model parameterized by the vector Obg = (fo, A,fo, C,fo, g,f(), T) where f0 ,1, is
the background frequency of letter k. The motif model is characterized by
the PFM 0m 2 (f1, f2, .. . ,fW). Each f]: A, Jig, fjﬁ, fJ-J) is a parameter
of an independent random variable describing a multinomial trial repre-
senting the distribution of letters at position j in the motif. Am param-
eterizes the probability that any W—mer is generated by the motif model
while Abg = 1 — Am is the probability that any W—mer is generated by the
background model. 0 = (0m, Obg) and A 2 (Am, Abg) are unknown param-
eters that are inferred from the known data X. Therefore, the MEME
model is

p(Z,-=1|0,A)=Am,15i5n (1)

“Xx-'21» 9) = p(XiI0m)Zip(Xiiebg)‘—Zi (2)

where Z,- is a binary latent variable that has a value of 1 if X ,- is drawn
from the motif model or 0 if X ,~ is drawn from the background model. Zi’s
true value is unknown, but its conditional expected value, deﬁned here as
ZEO), for a given set of parameters can be calculated as follows:

p(Xi|0m)}“m
P(Xi|9m)}~m +P(Xi|9bg)}~bg
To calculate ZEO), we need to know the form of p(X iIOm) and the form of

p(X,-|0bg). MEME assumes the distributions of the motif class and back-
ground class are

2?” = EiZiIX. 0. A] =

 

(3)

W
17(Xz-l0m) = H 1141?“) (4)
j=1 keA
W k X- -)
panes) = H Hféfk’  (5)
j=1 keA

where X ,~ J- is the letter in the jth positon of subsequence X ,~, and I ( k,a ) is
an indicator function

1 ifazk

0 otherwise

I(k, a) = { (6)

2.1.2 Batch EM A and 0 are iteratively improved in the batch EM
algorithm. In the E-step, the expected counts of all nucleotides at each
position are calculated based on the current guess of the parameters. In
the M-step, the parameters are updated based on the values calculated in
the E-step. MEME repeats the E and M steps until the change in em
(Euclidean distance) falls below a threshold (default: 10—6). The E and M
steps are as follows:

3

CLk = EiZ§0)I(kaXi,j)
i=1
n W
E — step : co k = 2 2(1— Zim)l(kaXi,j)
i=1j=1
forkeAandj: 1,2, ...,W
fjak =W—+’5kforj=0,l, ...,W
M — step : igm’kwk)
n 
Am 2 7

To discover multiple motifs, MEME associates an ‘erasing factor’ E,-
for each position in the data. The erasing factors vary between 0 and 1
and are set to I initially to indicate no erasing has taken place. Each time
a motif is discovered, the erasing factors are reduced by a factor repre-
senting the probability that the position overlaps an occurrence of
that motif. More details concerning how MEME erases are in Bailey
and Elkan (1995a). MEME also implements pseudo counts
,8 = (13A,,8C,,Bg,,BT) in the M-step to prevent any letter frequency 
from becoming 0. This is because if any letter frequency becomes 0,
its value cannot change.

EM performs maximum likelihood estimation to maximize an object-
ive function. The new estimates in the M-step are always guaranteed to
increase the value of the objective function. As the E and M steps are
repeated, EM algorithms converge to a maximum. For MEME, the ob-
jective function is the expected value of the log likelihood of the model
parameters 0 and A given the joint distribution of the data X and missing
data Z:

Eilong. AIX. 2)] = i 2?” log(p(X.-iem)xm)
i=1
+ i (1 — ZS”) Iog<p(X.-iebg)xbg)

1:1

(7)

2.1.3 Seeding The EM algorithm is sensitive to initial conditions and
prone to converging to local maxima. To mitigate this problem, MEME
tests many seeds and runs the EM algorithm to convergence from the
‘best’ seed. The exact details of how MEME performs seeding can be
found in Bailey and Elkan (1995b).

2.1.4 Scoring the motifs Motif instances are determined according to
Bayesian decision theory. After a motif is discovered, a subsequence X ,- is
classiﬁed as being an occurrence of the motif only if

log —(Xi|0bg)) > log(Am (8)

For each motif discovered, MEME calculates its E—value. This E—value
is the number of motifs, with the same width and number of occurrences,
that can generate an equal or higher log likelihood ratio if the dataset had
been generated according to background model. The log likelihood ratio
[Zr 2 log(p(sites|m0tif)/ log(sites|backgr0und)) is a measure of how differ-
ent the sites are from the background model. Calculating the E—value

 

112 /810's112umo[pJOJXO'sopemJogutoiq/ﬁd11q IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV no :2

EXTREME

 

exactly can be time consuming, so it is not computed directly. It is instead
heuristically calculated as a function of the total information content and
the number of occurrences (Bailey et al., 2010).

2.1.5 Time complexity For each iteration of the batch EM algo-
rithm, the number of operations performed is approximately propor-
tional to W. Each batch EM iteration has a time complexity of 001 W).
Although the number of iterations can vary, it is typically proportional to
n. Therefore, the algorithm scales quadratically with the size of the data-
set and has a time complexity of 0(n2W). The seed searching also scales
quadratically with the size of the dataset (Bailey and Elkan, 1995b).

2.2 EXTREME

EXTREME shares many similarities with MEME, especially in the im-
plementation. At the center of the EXTREME algorithm is the online
EM algorithm. We provide an overview of the online EM algorithm and
how EXTREME implements the online EM algorithm to discover
motifs.

2.2.] Online EM Like the batch EM algorithm, the online EM algo-
rithm also repeatedly iterates between E and M steps, which update the
parameters. In contrast to the batch EM algorithm, each iteration of the
online EM algorithm operates on only one observation, X ,~, instead of the
whole dataset X.

Following the instructions in Cappé and Moulines (2009), the E and M
steps, as derived from (7), are as follows:

0
Sm,i = Sm,i—l + Vi<Z§ ) _ Sm,i—l)

0
Wm = Cj,k,i—1 + Vi )IU‘a X131) — Gym—1)
E — step: co, [m- = 60,)“ i_1

W
+Vi (1 — 210))106 Xi,j) — Co,k,i—1
forkEA,j=1,2, ...,W,and >i=1,2, ...,n
M—step: ﬁsz’gikiforjzmhan
keA ’,
Am =Sm,i

 

The step size is y,- 2 yo 1"“. a and yo are set to 0.6 and 0.05, respectively.
These are by no means the most optimized set of parameters, but they are
adequate for accurate motif discovery. As shown in Cappé and Moulines
(2009), the online EM algorithm converges to a local maximum of the
likelihood function (7) for or e (05, 1].

The E and M steps are repeated until a convergence threshold (default:
10—6) in terms of the symmetrized Kullback—Leibler divergence between
the PFM estimates at a user-deﬁned number of intervals (default: 100) of
W-mers at the end of a complete pass through the dataset is satisﬁed. The
Kullback—Leibler divergence between two PFMs A and B is calculated as
follows:

1 W AL], BL],
KLD(A,B) 2  (Ajaklog(Bjak) + B,,klog(Aj,k)) (9)
If convergence is not reached at the end of a pass, the exponent a is
updated to the midpoint between or’s current value and one and
EXTREME performs another pass through the dataset. EXTREME
repeats these steps until the convergence threshold is met.
To accommodate pseudo counts, we modify the indicator function
from (6):

I(k,a)={1+’8k ika (10)

,8k otherwise

By default, EXTREME sets ,Bk to 0.0001 times the frequency of letter k in
the entire dataset.

To accommodate reverse complements, we also modify the calculation
of Z10) from (3) so that for each X Z, the reverse complement is also
evaluated and Z10) takes the higher of the two values. MEME, in con-
trast, handles reverse complements by adding a reverse-complemented
copy of the data, essentially doubling the size of the data.

2.2.2 Seeding Before running the online EM algorithm, the order of
the W—mers X ,~ is randomized. The online EM algorithm is therefore a
stochastic algorithm. This means that different runs of the online EM
algorithm can yield different results, even if ran multiple times from the
same initial conditions. This can present a problem for seeding because
even using the best seed from MEME’s heuristic is not guaranteed to
generate the optimal or even consistent solutions, causing EXTREME to
converge to local maxima. On the other hand, this also means that seeds
that would yield non-optimal solutions in MEME can yield optimal so-
lutions in EXTREME. In fact, local maxima may actually correspond to
biologically relevant motifs, especially in datasets that are rich in motifs
such as DNase-Seq data. Furthermore, an efﬁcient online EM implemen-
tation of MEME offers little beneﬁt if runtimes are dominated by the
inefﬁcient seed search.

EXTREME’s seeding strategy applies a search-based motif discovery
algorithm to ﬁnd motifs to initialize the online EM algorithm. Similar to
DREME (Bailey, 2011), the seeding algorithm ﬁnds words that are en-
riched in a sequence dataset relative to a negative sequence dataset. We
use the same dinucleotide shufﬂe algorithm used in DREME to generate
a dinucleotide-shufﬂed version of the input sequence set as the negative
sequence set. The seeding algorithm counts the number of occurrences of
words in the positive sequence set and the negative sequence set and
associates a ‘z-score’ with each word. The z-score is given by

S+—S_

y:

where s+ and s_ are the number of occurrences of the word in the positive
sequence and negative sequence sets, respectively. If s_ is zero for a word,
it is changed to one to prevent division by zero. Unlike DREME, our
seeding algorithm searches for words that are not exact. Each word con-
tains g universal wildcard letters surrounded by ﬂanking sites of l unam-
biguous letters. For example, TCAGNNGGAC is a word with a gap
length, g, of 2 and a half length, l, of 4. The gap length, g, varies between
the user-defmed parameters gm,” and gmax. Z-scores for each value of g
are normalized by dividing by the standard deviation of all z-scores for
each respective value of g. Words that have a normalized z-score that
exceed a user-defmed threshold, zthresh, and have at least a user-deﬁned
number of occurrences, smm, in the positive sequence set are aligned and
grouped together using a hierarchical clustering algorithm we adapted
from Xie et a]. (2005). Word clusters are converted to frequency count
matrices by counting the number of occurrences of each letter at each
position along the alignment. The counts are weighted by the normalized
z-score of each word in a cluster so that more signiﬁcant words will
contribute more to the count matrix than less signiﬁcant words. A
count matrix is converted to a PFM, 0m, by dividing each matrix element
by its respective row sum. The initial expected counts, c, is initially set to
the initial em as well. ng and the expected background counts Co are set to
the nucleotide frequency in the dataset. Am and sm,0 are initialized to the
predicted number of motif occurrences divided by n, the total number of
W—mers. We predict the number of motif occurrences for a given PFM
seed as the number of W-mers that have a goodness-of—ﬁt score >0.7 [see
Pan and Phan (2009) for details].
We also alter the form of p(X,-|0m) from (4):

W
p(Xi|0m) = 10“ “ﬂax-J) (12)

j=1 keA

(11)

Z:

 

The bias factor 10 has a value between 0 and 1. A bias factor closer to 0
biases the motif discovery toward subsequences that more closely match

 

1669

112 /810's112umo[p101x0'soi112u1101u101qﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

D. Quang and X.Xie

 

the current motif guess, decreasing the number of discovered motif oc-
currences. A bias factor closer to 1 makes the motif discovery less select-
ive, increasing the number of motif occurrences. After convergence, motif
occurrences are identiﬁed using (8). 10 is initially set to 1, and its value is
varied in a binary search fashion until the number of discovered motif
occurrences is between sitesmm (default: 10) and sitesmax (default: 5 times
the number of predicted motif sites). Up to 15 different values of 10 are
tried before EXTREME stops. Because each initial PFM guess can be
tested independently, this seeding strategy can be parallelized to allow
multiple motifs to be discovered simultaneously. Hierarchical clustering
of the discovered motifs can then identify individual motif classes.

2.2.3 Time complexity Each pass through the dataset with the online
EM algorithm has a time complexity of 0(n W). Typically, the online EM
algorithm reaches convergence after one to ﬁve passes through the data,
so the overall time complexity is proportional to the width of the motif
and the size of the dataset. The seeding algorithm’s word search also
scales linearly with the dataset size, while the hierarchical clustering is
inefﬁcient and can scale cubically with the number of words to cluster. In
practice, EXTREME as a whole scales linearly in time complexity with
the dataset size.

2.2.4 Implementation EXTREME is written in Python and is avail-
able on Github. To calculate E—values, EXTREME uses Cython bindings
to the original MEME C source code to call the appropriate functions.
EXTREME requires ~8 GB of memory for a 10 Mb dataset. Most of the
memory is devoted to MEME’s E—value calculation, which involves a
preprocessing step that does not scale well to large numbers of motif sites.

3 RESULTS

MEME is a popular motif discovery algorithm. It has been a
valuable tool in the ongoing challenge of identifying regulatory
elements. However, its performance scales poorly with large
datasets. Experiments such as ChIP-Seq and DNase—Seq gener-
ate data that are too large for MEME to process in a practical
amount of time without discarding most of the data. To over-
come this challenge, we have developed EXTREME, a motif
discovery algorithm that can process ChIP-Seq and DNase—Seq
data efﬁciently without discarding any data. We ﬁrst show, using
simulated datasets, that MEME’s running time scales much
faster than EXTREME’s running time with respect to dataset
size. Using a ChIP-Seq dataset and a DNase—Seq dataset, we
demonstrate that using the entire dataset of sequences is neces-
sary to discover infrequent motifs. We also show that the motifs
discovered by EXTREME are similar in quality to the motifs
discovered by MEME.

3.1 Comparison of MEME and EXTREME performance

We compare MEME and EXTREME using several simulated
datasets. Simulated datasets are generated with the RSAT suite
of tools (Thomas-Chollier et al., 2011). We generate four se-
quence datasets, each containing 1000 random masked hg19 gen-
omic sequences of a single length (100, 200, 300 or 400 bp), using
the RSAT random-genome—fragments tool. This masked reference
genome was preprocessed with RepeatMasker (Smit et al., 1996—
2010) and Tandem Repeats Finder (Benson, 1999) so that re-
peats (with period of 512) are masked by capital Ns. For each of
the four sequence datasets, we implant 50, 100, 500 or 1000 in-
stances of the JASPAR (Sandelin et al., 2004) VDR/RXRA het-
erodimer motif (Supplementary Fig. S1) using the RSAT

random-motifs and implant-sites tools, yielding 16 simulated
datasets, each containing 1000 sequences of varying lengths
and number of motif sites.

For the seeding step of each EXTREME run, we search for
words with a half-length l = 6, a gap length g between gm,” 2 0
and gmax = 2, a normalized z—score greater than the threshold
zthresh=5 and at least smin=5 occurrences in the positive se-
quence set. The words are clustered and we select the cluster
containing the most words to convert to a PFM seed from
which to initialize the online EM algorithm. Because the online
EM algorithm is a stochastic algorithm, we repeat the online EM
portion of the run 30 times for each dataset with different
random seeds to initialize the pseudorandom number generator
to get a good estimate of performance. We also run MEME on
each of the 16 simulated datasets to ﬁnd a single motif of a width
between 12 and 17 under the two-component model to approxi-
mate the same parameters for the EXTREME run. Figure 1
shows that MEME’s running time scales much faster than
EXTREME’s running time with respect to the input size for
all ‘noise’ levels. Extrapolating from these data, MEME can
take weeks to discover a motif in a 10 Mb dataset. EXTREME
can complete this same task in hours. With the exception of one
of the datasets, MEME is marginally more accurate than
EXTREME in each case (Supplementary Fig. S3). In the one
exception, MEME fails to converge to the correct motif because
there are not enough true motif occurrences relative to the data-
set size for MEME’s seeding algorithm to pick a good seed. As
the number of motif occurrences increases, both MEME and
EXTREME better approximate the true PF M and the relative
difference between their results diminish. Although
EXTREME’s running time and accuracy vary more as the
noise level increases (Supplementary Figs. S2 and S3),
EXTREME still consistently generates results comparable with
those of MEME in a fraction of MEME’s running time.

 

 

 

 

 

O
O
8 _
N I 50sites
0 100sites
o A 5OOSites
o 0 1000 sites
8 ‘ — MEME
A N --- EXTREME
§
8 §_
:51 a
(D
.E
'— 8
O)
o _
E e
C
D
a:
O
o _
0
l0
0 _

 

 

 

 

Input Size (kilobase-pairs)

Fig. 1. Comparison of MEME and EXTREME performance on simu-
lated datasets of varying sequence length and motif sites. The x-axis is the
total number of base pairs in the simulated dataset. The y-axis is the total
running time it takes for MEME or EXTREME to complete seeding and
reach convergence

 

1 670

112 /810's112umo[p101x0'sor112u1101urorq/ﬁd11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

EXTREME

 

3.2 Discovering motifs in ChIP-Seq data

We compare the performance of MEME and EXTREME for
discovering motifs in ChIP-Seq data using a dataset generated by
the Myers Lab at the Hudson Alpha Institute for Biotechnology
(Birney et al., 2007). The ChIP-Seq data correspond to an NRSF
ChIP performed on the GM12878 cell line. Peaks were already
called and organized into BED ﬁles by the authors. We further
process the data by intersecting replicates and extracting genomic
sequences from the middle 100 bp of the intersected regions from
the same hg19 masked reference genome we use for the simulated
data. The resulting sequence dataset consists of 2849 sequences
and 282 980 bp.

We run EXTREME on the ChIP-Seq dataset to discover mul-
tiple motifs. For the seeding step, we search for words with a
half-length of 8 bp, a gap length between 0 and 10 bp (inclusive),
a normalized z—score >5 and at least ﬁve occurrences in the posi-
tive sequence set. The word search takes 32 s to ﬁnd 1248 words.
Hierarchical clustering groups these words into 23 clusters,
taking 91 s to complete. These 23 clusters are converted to
PFMs of widths between 16 and 29 bp, providing seeds for the
online EM algorithm. Each seed is processed by the online EM
algorithm on a separate core in parallel. Of the 23 seeds, 20
successfully yield motifs within 15 different values of the bias
factor it (12). The Supplementary Material contains these 20
motifs in MEME Minimal Motif Format. Hierarchical clustering
of the 20 motifs groups them into 10 clusters. Online EM running
times range from 67 to 859 s, taking an average of 361 s. Running
times vary because different seeds can converge to different
motifs and may require additional passes through the data to
reach convergence. For comparison, we also run MEME on the
ChIP-Seq dataset to ﬁnd a single motif of a width between 16
and 29 bp under the two-component model using a single core.
MEME takes 8191s to ﬁnd a single motif. While comparison
between the multi-core EXTREME run to the single-core
MEME run is not straight-forward, it should be noted that the
total computing time for EXTREME, which sums the running
times for the seeding and each of the online EM runs, is 8305 s.
In the computing time it takes for MEME to discover a single
motif, EXTREME ﬁnds 10 motif clusters in roughly the same
amount of time. The disparity between the two programs’ per-
formances is compounded by the fact that MEME discovers
multiple motifs in serial, and would require roughly the same
running time to ﬁnd each additional motif.

Many of the discovered motifs are novel, demonstrating vary-
ing half-site distances and orientations (Fig. 2). Interestingly, two
of the discovered motifs show that the half-sites are reversed. To
determine whether the reversed motif is functional, we scan for
sequences in the ChIP-Seq dataset matching one of the reversed
motifs’ consensus sequence, align these sequences and extract
GERP scores (Cooper et al., 2005). Sequences containing this
reversed motif are enriched in high GERP scores, showing that
these sequences are conserved and possibly functional (Fig. 3).

Some of the motifs discovered in this dataset have a low
number of occurrences. One of the motifs, for example, only
has 11 sites in the data. It would be unlikely to discover these
infrequent motifs if the majority of sequences are discarded. This
highlights the importance of using the entire dataset for thorough
motif discovery.

1’lsites = 
E = 2.5)(10'257

sawlMtaMl

nap—mm.“

11sites =  g‘
E=4.3><10'5202  C  c c c

'B'F‘--F---=:==:a:a
_..........

EﬂWMMWLlIMh

n-F--2=s==2===:a==::::§
...............

a
I
1’lsites =  £1
E = 1.5)(10'467 T c

'=-~-°sr_====:=:=

   CA  .ACA 
ahim.ll 2?”

—Nnvlaov--n°ru g===g

Fig. 2. Motifs discovered by EXTREME in the GM12878 NRSF ChIP-
Seq dataset. Each motif comes from one of the 10 motif clusters. Motifs
are aligned to highlight the varying distances and orientations between
the half-sites. Number of non-overlapping motif sites in non-repetitive
regions and E—values shown next to each motif. E—values are calculated
according to MEME’s heuristic

 

 

3.3 Discovering motifs in DNase-Seq data

To assess the performance of MEME and EXTREME for
DNase—Seq data, we use a DNase—Seq FP dataset generated by
the Stamatoyannopoulos Lab at the University of Washington
(Neph et al., 2012). The DNase—Seq data correspond to a foot-
printing experiment performed on the K562 cell line. F Ps are
already organized into a BED ﬁle by the authors. We further
process the FP data by extending each F P by 5 bp on each side
and then merging any intersecting regions. Genomic sequences
are extracted from the masked hg19 reference genome. The re-
sulting dataset consists of 198 527 sequences and 10 487 345 bp.

We ﬁrst discover motifs in the DNase—Seq dataset using
MEME. We do not run MEME on the whole dataset because
we know MEME can take months to complete for a dataset of
this size. We therefore run MEME-ChIP on the dataset, which
runs MEME on 600 randomly selected sequences. For the data
subset, MEME discovers two motifs that strongly resemble pre-
viously discovered motifs (CTCF and SP1). The other discovered
motifs are repetitive or fail to meet our E—value threshold of 0.01.

In the seeding step of EXTREME, we ﬁrst search for words
with a half-length of 4bp, a gap length between 0 and 10 bp
(inclusive), a normalized z—score >5 and at least 10 occurrences
in the positive sequence dataset. The word search takes 836 s to

 

1671

112 /810's112umo[p101x0'sor112u1101urorq/ﬁd11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

D. Quang and X.Xie

 

chr1.26798270.26798304

chr17.67563479.67563513
chr19.42501420.42501454

' I
I 5
I o
chr19.42817927.42817961
I _

chr20.62106741.62106775 5
chr20.62276759.62276793 . l
(b)

 111111. I ll”

chr2.26915551.26915585

chr5.161273973.161274007 I 

chr5.173472728. 173472762
chr5.175298895. 175298929

chr8.99439161.99439195 I
chr11.17756647.17756681
chr12.75603450.75603484 I
chr14.71271440.71271474 L
chr16.24267395.24267429

 

3

0

Average GERP Score
1 1

 

 

 

I I
-15 15

-10 -5 0 5 10
Relative Nucleotide Position

Fig. 3. Conservation analysis of the reversed NRSF motif. Sequences in
the GM12878 NRSF ChIP-Seq dataset containing the consensus se-
quence GCTGTCCNTTCAGCA or its reverse complement are aligned
with 10 bp ﬂanking sequences. (a) GERP scores are plotted for each
nucleotide in a heatmap. The motifs sequence logo is aligned at the
top for reference. 0)) The average GERP score plotted against the gen-
omic positions, relative to the center of the alignment

yield 761 words. Hierarchical clustering of the words takes 23 s to
group the words into 129 clusters. We then convert the clusters to
129 PFM seeds of widths between 8 and 19 bp. Each seed is
processed independently by the online EM algorithm on a sep-
arate core in parallel. Running times vary for each of the online
EM runs, ranging from 4475 to 18300 s, completing in an average
of 7390 s. Hierarchical clustering groups the discovered motifs
into 22 distinct clusters.

To discover additional motifs in the DNase—Seq data, we mask
the seven most abundant motifs from different motif clusters by
replacing instances of those motifs with capital Ns and restart the
motif discovery. We remove these motif instances because the
ﬁrst round of motif discovery shows that many different seeds
can converge to the same motif, and we want to bias the motif
discovery toward different motifs. Based on TOMTOM (Gupta
et al., 2007) analysis, the seven motifs strongly match known
motifs (TOMTOM E < 0.01): CTCF, SP1, SRF, NRF 1,
JUNDM2, ZNF 143 and TALl /GATA1. In this second round
of motif discovery, we search for words with a half-length of
5 bp, a gap length between 0 and 10 bp (inclusive), a normalized
z—score>8 and at least 10 occurrences in the positive sequence
dataset. The word search takes 888 s to yield 1187 words.
Hierarchical clustering of the words completes in 102 s and
yields 357 clusters, which are then converted to PFM seeds of
widths between 10 and 21 bp. Each seed is independently pro-
cessed by the online EM algorithm on a separate core in parallel.
Online EM run times range from 3330 to 22 702 s, completing in
an average of 7605 s. Hierarchical clustering condense the motifs
into 131 clusters.

Examples of motifs discovered in the K562 dataset are shown
in Figure 4. All motifs discovered by EXTREME in the K562
dataset are available in MEME Minimal Motif Format in the
Supplementary material. Many of the motifs discovered by
EXTREME have a low number of occurrences relative to the
total size of the dataset. One motif only has 464 occurrences in
the 10.5 Mb dataset (Fig. 4e). These kinds of motifs are too in-
frequent to be discovered in subsets of the data. Discovering
motifs in a subset of the data is only possible for motifs that
are present in high abundance, such as the ones shown in
Figure 4a and b, which are also the motifs discovered by the
MEME run on the data subset. Again, this highlights the im-
portance of using the whole dataset for motif discovery. Using
MEME to discover these infrequent motifs is not practical be-
cause MEME can take months to discover a motif in a dataset as
large as the K562 dataset. Furthermore, the number of occur-
rences for motifs is less than expected. For example, EXTREME
only ﬁnds 1771 occurrences of the CCAAT box motif (Fig. 4f),
even though the ENCODE NFYA ChIP-Seq data indicate it
should be present in at least a third of all human promoters.
The reason for the discrepancy is likely due to the way Neph
et al. (2012) called FPs. Neph et al. (2012) reported high-conﬁ-
dence FPs at an FDR of 1%. This is a stringent threshold and we
therefore expect their footprinting algorithm to call many false
negatives as a result.

3.4 Comparison to known motifs

We assess the similarity of the motifs discovered by EXTREME
in the DNase-Seq and ChIP-Seq datasets to known motifs using
TOMTOM. Some of the motifs discovered by EXTREME have
highly signiﬁcant matches to known motifs (Fig. 5). Many of the
motifs discovered, however, are novel and fail to meet our
TOMTOM E—value threshold of 0.01. Validating these novel
motifs requires further computational or experimental scrutiny.

4 DISCUSSION

A search-based seeding strategy combined with the online EM
algorithm is effective for efﬁcient de novo motif discovery in large
datasets. EXTREME uses the online EM algorithm to discover
motifs that closely match motifs discovered by MEME. MEME
can take months to discover even a single motif in a large dataset
like the DNase—Seq dataset. While strategies such as discarding
sequences are effective for quickly discovering abundant motifs,
it is insufﬁcient for ﬁnding infrequent motifs, which are numer-
ous in DNase—Seq data. EXTREME can quickly process entire
large datasets without discarding sequences or using specialized
hardware. If available, EXTREME can take advantage of par-
allelized hardware conﬁgurations, which is useful for rapidly dis-
covering multiple motifs in large datasets. Although such
conﬁgurations are not available to all researchers, EXTREME
can still be used with more traditional conﬁgurations to serially
discover multiple motifs at a substantially faster rate than
MEME can.

We expect EXTREME to be a valuable tool for thorough
motif discovery in large datasets. Its ability to discover multiple
motifs in DNase—Seq data will be especially useful for under-
standing transcriptional regulation. Because motifs discovered

 

1 672

112 /810's112umo[p101x0'sor112u1101urorq/ﬁd11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

EXTREME

 

 i...

(a) = 10186, E = 1.8 x 10—8878 (b) = 11072, E = 5.0 x 10—7021

Litllmll



(d) “sites = 923, E = 43 X 10—1130

(elnsites = 464, E = 2_4 X 10—897

 1.1111111

(c) ns'ites :  E = 4.5 X 10—353

'hlllllg...

(f) “sites = 1771, E 2 cm X 10—184

Fig. 4. Six examples of motifs discovered by EXTREME in the K562 dataset. Number of non-overlapping motif sites in non-repetitive regions and E-
values shown below each motif. The E—values show how signiﬁcant the motifs are, calculated according to MEME’s heuristic

'iéﬂegaégi
(b) CTCF, E = 1.2 x 10—21

'] -.Utgedlm 1] AIMEE
(c) STAT1,E = 5.6 x 10—6 (d) NFYA, E = 3.1 x 10—10

Fig. 5. TOMTOM comparisons of motifs discovered by EXTREME
with motifs in databases. Each panel shows the logo of the motif dis-
covered by EXTREME (lower logo) aligned with the best matching motif
in the databases (upper logo), along with the name of the best matching
motif and signiﬁcance value of the match

(a) NRSF, E = 3.1 x 10—25

by EXTREME closely match motifs discovered by MEME,
the results can be used to reliably associate F Ps with well-studied
TFs. This also means that any discovered novel motifs can con-
ﬁdently be associated with TFs. This is especially useful for the
study of TFs that lack a suitable antibody for ChIP experiments.

While EXTREME is effective in motif discovery, there is
still much room for improvement. EXTREME’s performance
can be vastly improved if it were reimplemented in C. Future
implementations of EXTREME can also incorporate
more MEME elements such as the one occurrence per sequence
and zero or one occurrence per sequence models. To encourage
further investigation, we have made EXTREME publicly avail-
able at the Github repository http://github.com/uci-cbcl/
EXTREME.

Funding: National Institute of Biomedical Imaging and
Bioengineering, National Research Service Award (EB009418)
from the University of California, Irvine, Center for Complex
Biological Systems.

Conﬂict of Interest: none declared.

REFERENCES

Bailey,T.L. (2011) DREME: motif discovery in transcription factor ChIP-seq data.
Bioinformatics, 27, 1653—1659.

Bailey,T.L. and Elkan,C. (1994) Fitting a mixture model by expectation maximiza-
tion to discover motifs in bipolymers. Proc. Int. Conf. Intell. Syst. Mol Biol, 2,
28—36.

Bailey,T.L. and Elkan,C. (1995a) Unsupervised learning of multiple motifs in bio-
polymers using expectation maximization. Mach. Leam., 21, 51—80.

Bailey,T.L. and Elkan,C. (1995b) The value of prior knowledge in discovering
motifs with MEME. Proc. Int. Conf. Intell. Syst. Mol Biol, 3, 21—29.

Bailey,T.L. et al. (2010) The value of position-speciﬁc priors in motif discovery
using MEME. BM C Bioinformatics, 11, 179.

Benson,G. (1999) Tandem repeats ﬁnder: a program to analyze DNA sequences.
Nucleic Acids Res, 27, 573—580.

Birney,E. et al. (2007) Identiﬁcation and analysis of functional elements in 1% of
the human genome by the ENCODE pilot project. Nature, 447, 799—816.

Cappé,0. and Moulines,E. (2009) On-line expectation—maximization algorithm for
latent data models. J. R. Stat. Soc. Series B Stat. Methodol, 71, 593—613.

Cooper,G.M. et al. (2005) Distribution and intensity of constraint in mammalian
genomic sequence. Genome Res, 15, 901—913.

Dempster,A.P. et al. (1977) Maximum likelihood from incomplete data via the EM
algorithm. J. R. Stat. Soc. Series B Methodol, 39 (1), 1—38.

Gupta,S. et al. (2007) Quantifying similarity between motifs. Genome Biol, 8, R24.

Hesselberth,J.R. et al. (2009) Global mapping of protein-DNA interactions in vivo
by digital genomic footprinting. Nat. Methods, 6, 283—289.

Johnson,D.S. et al. (2007) Genome-wide mapping of in vivo protein-DNA inter-
actions. Science, 316, 1497—1502.

Machanick,P. and Bailey,T.L. (2011) MEME-ChIP: motif analysis of large DNA
datasets. Bioinformatics, 27, 1696—1697.

Neph,S. et al. (2012) An expansive human regulatory lexicon encoded in transcrip-
tion factor footprints. Nature, 489, 83—90.

Pan,Y. and Phan,S. (2009) Threshold for positional weight matrix. Eng. Lett., 16,
498—504.

Reid,J.E. and Wemisch,L. (2011) STEME: efﬁcient EM to ﬁnd motifs in large data
sets. Nucleic Acids Res, 39, 6126.

Sandelin,A. et al. (2004) JASPAR: an open-access database for eukaryotic tran-
scription factor binding proﬁles. Nucleic Acids Res, 32, D91—D94.

Sandve,G.K. et al. (2006) Accelerating motif discovery: motif matching on parallel
hardware. In: Algorithms in Bioinformatics. Springer, Berlin Heidelberg,
pp. 197—206.

Smit,A. et al. (1996—2010) RepeatMasker Open-3.0.

Thomas-Chollier,M. et al. (2011) RSAT 2011: regulatory sequence analysis tools.
Nucleic Acids Res, 39, W86—W91.

Xie,X. et al. (2005) Systematic discovery of regulatory motifs in human promoters
and 3’ UTRs by comparison of several mammals. Nature, 434, 338—345.

 

1 673

112 /810's112umo[p101x0'sor112u1101u101qﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

