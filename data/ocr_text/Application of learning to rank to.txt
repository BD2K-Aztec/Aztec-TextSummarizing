Bioinformatics, 31 (21 ), 2015, 3492—3498

doi: 10.1093/bioinformatics/btv413

Advance Access Publication Date: 10 July 2015
Original Paper

 

Sequence analysis

Application of learning to rank to protein
remote homology detection

Bin Liu1'2'3'*, Junjie Chen1 and Xiaolong Wang1'2

1School of Computer Science and Technology, 2Key Laboratory of Network Oriented Intelligent Computation,
Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, Guangdong 518055, China and 3Gordon Life
Science Institute, Belmont, MA 02478, USA

*To whom correspondence should be addressed.
Associate Editor: John Hancock

Received on June 4, 2015; revised on July 3, 2015; accepted on July 7, 2015

Abstract

Motivation: Protein remote homology detection is one of the fundamental problems in computa—
tional biology, aiming to find protein sequences in a database of known structures that are evolu—
tionarily related to a given query protein. Some computational methods treat this problem as a
ranking problem and achieve the state—of—the—art performance, such as PSI—BLAST, HHblits and
ProtEmbed. This raises the possibility to combine these methods to improve the predictive per—
formance. In this regard, we are to propose a new computational method called ProtDec—LTR for
protein remote homology detection, which is able to combine various ranking methods in a super—
vised manner via using the Learning to Rank (LTR) algorithm derived from natural language
processing.

Results: Experimental results on a widely used benchmark dataset showed that ProtDec—LTR can
achieve an ROC1 score of 0.8442 and an ROC50 score of 0.9023 outperforming all the individual
predictors and some state—of—the—art methods. These results indicate that it is correct to treat pro—
tein remote homology detection as a ranking problem, and predictive performance improvement
can be achieved by combining different ranking approaches in a supervised manner via using LTR.
Availability and implementation: For users’ convenience, the software tools of three basic ranking
predictors and Learning to Rank algorithm were provided at http://bioinformatics.hitsz.edu.cn/
ProtDec—LTR/home/

Contact: bliu@insun.hit.edu.cn

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

 

Using sequence similarity between protein pairs to detect evolu—
tionary relationships is one of the central tasks in bioinformatics,
which can be applied to the protein 3D structure and function pre—
diction (Bork and Koonin, 1998). Unfortunately, remote homology
protein pairs have similar structures and functions, but they lack
easily detectable sequence similarity, because the protein tertiary
structure is more conserved than protein sequence. Therefore, it is
often difficult to detect protein remote homology by computa—
tional approaches.

Some effective computational methods have been developed to
address this challenging problem, which can be mainly divided into
two groups, including discriminative methods and ranking methods.
The first group discriminative methods treat protein remote hom—
ology detection as a classification problem using both the positive
and negative samples to train the classification models, and then
they are used to predict unseen samples. Among this kind of
approaches, the methods based on Support Vector Machines
(SVMs) achieve the state—of—the—art performance with appropri-
ate kernel functions, which measure the similarity between any

©The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 3492

9mg ‘09 1sn3nv uo sopﬁuv soq ‘BTUJOJTIBD aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

Application of LTR to protein remote homology detection

3493

 

pair of samples (Liu et 61]., 2014a). These methods employ various
features to represent the protein sequences, such as SVM—fisher
(Leslie et al., 2002), SVM-PDT (Liu et al., 2012), SVM-pairwise
(Muh et 61]., 2009), SVM—LA (Saigo et 61]., 2004) and some profile—
based methods (Liu et 61]., 2008, 2013, 2014c, 2015a).

In contract, the second group ranking methods treat protein re—
mote homology detection as a ranking task or database searching
task, where the query protein is searched against a protein database
with known structures and functions, and a ranking list of the pro-
teins in the database is returned according to their identified evolu—
tionary relationships to the query protein. Early ranking methods
were based on sequence alignment algorithms, such as Smith—
Waterman algorithm (Smith and Waterman, 1981). Later, some
more efficient algorithms were proposed so as to trade reduced ac—
curacy for improved efficiency, such as Basic Local Alignment
Search Tool (BLAST) (Altschul et 61]., 1990) and FASTA (Pearson,
1991). Because the evolutionary relations of remote homology pro-
teins cannot be easily detected by sequence similarity, these methods
can only achieve limited performance. The predictive accuracy was
significantly improved by using the profile—based alignment algo—
rithms, e.g. PSI-BLAST method (Altschul et 61]., 1997) iteratively
builds a probabilistic profile of a query sequence and therefore a
more sensitive sequence comparison score can be calculated. Several
ranking methods employed the generative models iteratively trained
by using positive samples of a protein family or superfamily and
achieved better performance, e.g. HHblits (Remmert et 61]., 2012)
generates a profile hidden Markov model (profile hidden Markov
model (HMM)) (Eddy, 1998; Karplus et 61]., 1998) from the query
sequence and iteratively searches through a large database.
Recently, some ranking methods based on graph theory or semantic
embedding techniques were proposed, e.g. motivated by the success—
ful applications of Google’s PageRank algorithm, an unsupervised
algorithm called RankProp (Melvin et 61]., 2009; Weston et 61].,
2004) was proposed, which is a network—based inference method.
Later, this method was further improved by a semi—supervised ap—
proach using labeled samples to learn a new network (Weston et 61].,
2006). Based on the similarity between protein sequences and nat—
ural languages, the techniques derived from the field of natural lan-
guage processing were applied to protein remote homology, e.g.
ProtEmbed (Melvin et 61]., 2011) converts a large—scale embedding
of protein feature vectors into a low—dimensional ‘semantic space’.
Therefore, evolutionarily related proteins are embedded in close
proximity in this ‘semantic space’.

The aforementioned ranking methods are based on different the—
ories and achieve the state—of—the—art performance in the field of pro-
tein remote homology detection. Therefore, it is interesting to
explore whether these approaches can be combined to further im—
prove their performance. However, how to combine these ranking
methods into one predictor is a challenging problem, because they
are based on different techniques and their predictive results are
often different. To address this problem, we employed the Learning
to Rank (LTR) algorithm (Li, 2011) to combine different ranking
methods in a supervised fashion. LTR is a supervised algorithm for
training the model in a ranking task, which has been successfully
applied to information retrieval, natural language processing, data
mining, etc. (Li, 2011), e.g. LTR is severing as one of the key algo—
rithms in many well-known searching engines, such as Bing (Liu
et 61]., 2007), Yahoo! (Figueroa and Neumann, 2013) and Google
(Sculley, 2009).

In this study, we proposed a new computational method called
ProtDec—LTR, which combines three state—of—the—art ranking meth—
ods by using LTR, including PSI—BLAST (Altschul et 61]., 1997),

HHblits (Remmert et 61]., 2012) and ProtEmbed (Melvin et 61].,
2011). To our best knowledge, ProtDec—LTR is the first computa—
tional predictor that can combine various ranking methods via using
a supervised framework.

2 Methods and algorithms

2.1 Method overview

Protein remote homology detection can be viewed as a ranking task
or database searching problem. The aim is to search the query pro—
tein against a protein database and return the top ranked proteins in
the database according to their evolutionary relationships to the
query protein. This problem is particularly similar to the document
retrieval task. In document retrieval, given a query, the system re—
trieves documents containing the query words from a collection of
documents, ranks the documents and returns the top ranked docu—
ments. To apply information retrieval techniques to protein remote
homology detection, the basic protein ranking algorithms should be
identified. Here, PSI-BLAST (Altschul et 61]., 1997), HHblits
(Remmert et 61]., 2012) and ProtEmbed (Melvin et 61]., 2011) were
selected as the basic ranking algorithms, which are similar as the
document retrieval engines in the field of information retrieve.
Below is a brief description of the three methods.

PSI-BLAST (Altschul et 61]., 1997) searches a query protein se—
quence against a database based on the profile generated from the
multiple sequence alignment. In this study, PSI-BLAST version
2.2.29 (Altschul et 61]., 1997) was employed to search the benchmark
dataset with default parameters (E value and number of iterations
were set as 0.001 and 3, respectively). HHblits (Remmert et 61].,
2012) is another powerful computational method for protein remote
homology detection, which generates a profile HMM from the
query sequence and iteratively searches through a database of profile
HMMs. HHblits version 2.0.16 (Remmert et 61]., 2012) was used as
the implementation of this method. All its parameters were set to de—
fault except that the number of iterations was set as 2. ProtEmbed
(Melvin et 61]., 2011) converts a query protein into a low dimen—
sional ‘semantic space’ and measures the ‘distance’ between a query
protein against all other proteins. We re—ran the ProtEmbed method
(Melvin et 61]., 2011) on the benchmark dataset with the optimized
parameters (Melvin et 61]., 2011).

The proposed ProtDec—LTR method is able to combine the
aforementioned three methods in a supervised manner by using
LTR. The flowchart of ProtDec-LTR is shown in Figure 1. Similar
as the application of LTR in information retrieve, for protein re-
mote homology detection, each protein sequence is treated as a
‘document’. Three ranking lists are obtained by using the three
aforementioned ranking methods, and then they are embedded as a
feature matrix to train the LTR model. Finally, for an unseen query
sample, its homologous proteins can be detected by the trained
model of LTR. As a result, the three ranking predictors are com—
bined in a supervised manner considering the advantages of all the
three individual predictors for more accurate protein remote hom—
ology detection.

2.2 Feature representation

To apply LTR to protein remote homology detection, the protein
sequences should be converted into feature matrices based on the
three ranking methods, including PSI-BLAST (Altschul et 61].,
1997), HHblits (Remmert et 61]., 2012) and ProtEmbed
(Melvin et 61]., 2011). Below is the description on how to generate
the feature matrix. Given the benchmark dataset with 11 proteins,

91% ‘09 1sn8nv uo sopﬁuv s01 ‘BTUJOJTIBD aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 11101; popeommoq

3494

B.Liu et al.

 

Training phase Testing phase

 

 

 

 

I
I
[ Training protein sequences ] l [ Testing protein sequences ]
I
I

r _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _.

I I I
: [ Psi-Blast  HHblits  ProtEmbed ] i
._ _________________ _ j _________________ _ _I

< Retrieval G

Ranking results

 

Ranking results

 

SCOP

 

   

Feature representation process

Psi- Blast HH blits Prot Embed

Learning to Rank

Learning to rank process
A

 

 

l Re-ranking results I

Fig. 1. The flowchart of ProtDec-LTR. There are three main phases in
ProtDec-LTR, including feature representation, LTR training and testing
phases. The proteins are first embedded into feature matrices constructed
based on three basic ranking methods: PSI-BLAST, HHblits and ProtEmbed,
and then they are fed into LTR for training the model. For an unseen protein,
its homologous proteins can be detected by the trained model. Therefore,
these three methods are combined in a supervised framework by using LTR

for a given protein q, its feature matrix can be represented as a

matrixH:
8101: P1) 52(q7 P1) "' 58(q7 P1)
8101: P2) 52(q7 P2) "' 58(q7 P2)
H: (1)
81(qapn) 82(qapn)  88(q7pn)

where pi(p,- E S, lgign) represents the ith protein in the ranking
list, which is a potential homologous protein related with q
retrieved by three basic ranking methods; 51 (q, pi) and 52(61, pi) rep—
resent the bitscore and E value calculated by PSI—BLAST, respect—
ively; 53(q, pi) and 54(q,p,-) represent the probability and E value
calculated by HHblits, respectively; 55(q,p,-) is the distance be—
tween two proteins in the ‘semantic space’ generated by
ProtEmbed and the last three elements 56(q, pi), 57(q,p,-) and
58(q, pi) represent the reciprocal of ranking position in three rank-
ing results.

Each element 5,-(q, p,) in feature matrix H [Equation (1)] should
be normalized by using the following equation:

51(q7pi) 

5"(q7  Z n
I I531X{Si(q, 191)}

The label list Y of H can be represented as:
11
12
Y = , (3)

In

where l,- (l, E N) represents the grade of relevance of a protein pair
(q, pi) labeled based on the Structure Classification of Proteins

(SCOP) (Koehl and M, 2000). If the protein pair q and p,- are in the
same superfamily, l,- is set as 1, otherwise, it is 0.

2.3 Learning to rank

As an efficient supervised ranking algorithm, LTR algorithm has
been successfully applied to document retrieval, question answering,
computational advertising (Li, 2011), etc. Three different versions
of LTR have been proposed, including pointwise approach, pairwise
approach and listwise approach (Liu, 2009). They are different in in-
put representations and loss functions. Among the three methods,
the listwise approach outperforms the other two methods because it
can take ranking lists as input samples in both learning and predic—
tion steps. Therefore, the group structure of ranking can be main-
tained and ranking evaluation measures can be more directly
incorporated into the loss functions.

In this study, the listwise approach of LTR algorithm was used
to construct the ProtDec—LTR. LTR is a supervised learning algo-
rithm and thus has training and testing phases. Given m training
samples, each sample should be first converted into feature matrix
H based on Equations (1) and (2). The goal of LTR is to automatic—
ally learn a ranking function F(-) from feature matrix H to a list of
labels Y of training samples [Equation (3)]. A loss function L(-,-) is
utilized to evaluate the predictive results of F(-). Each row x in fea—
ture matrix H is ranked according to F(x), then the top [a remote
homologous proteins in the ranking list are evaluated by using the
grades 3) in label list Y. The loss function is represented as L(F(x), y).
The risk function R(-) can be defined as the expected loss function:

W) =  L(F(x,-), 2) (4)

where x,- represents the 1th row in H [Equation (1)], y,- is the grade of
protein pair in label list Y [Equation (3)]. The learning task then be—
comes the minimization of the empirical risk function that can be
solved by using Gradient Descent (Bottou, 2010; Burges et al.,
2005).

In this study, we employed a listwise algorithm of LTR,
LambdaMART (Burges, 2010), to learn a ranking model. Given a
set of training samples, LambdaMART trained a boosted tree model
(a linear combination of a set of regression trees) with Normalized
Discounted Cumulative Gain (NDCG) loss function (Burges, 2010;
Donmez et al., 2009). Because the size of the ranking list was very
large in the current study, only the top 50 detected remote homolo—
gous proteins were considered by the LTR, so as to reduce the com—
putational cost. The loss function can be represented as:

L(F(x)a y} = €XP(—NDCG(50)) (5)

11(1) £50 2%. _ 1
NDCG(50) = G;;X(50) Z — (6)
i=1 logz <1 —I— H(i)>
where H(i) is the ranking position of protein in predictive results
and GmaX(50) is the normalizing factor. For a perfect ranking, the
proteins with higher grades are always ranked higher. The corres—
ponding empirical risk function of LambdaMART can be written as

followings:
1 m “(0350 231i) _ 1
R F = — 6X _GrT1:xi 50 —' (7)

The pseudo codes of the training phase of LTR algorithm for
protein remote homology detection are shown in Algorithm 1.

91% ‘09 1sn8nv uo sopﬁuv s01 ‘BIUJOJIIBD aIo AliSJQAIUn 112 /§JO'S[BUJHO[p.IOJXO'SOTlBIHJOJUiOTQ/ﬁdllq 11101; popeommoq

Application of LTR to protein remote homology detection

 

 

Algorithm 1. The training phase of LTR for protein remote
homology detection

 

1: Parameters: number of basic methods m, number of
training samples n

2: Input: training protein sequences

3: Output: the ranking model F(x)

4: Initialize the basic methods and LambdaMART model

5: For i=0 to 11 do

6: Forj=0tomdo

7: Retrieve the benchmark database by using the
basic methods

8: End for

9: Embed the feature vectors by using Equations (1)
and (2)

10: Label the feature vectors based on Equation (3)

11: End for

12: For 12:1 tondo

13: Train LambdaMART ranking model F(x) by using
Equations (5 ) and (7)

14: End for

 

For an unseen query protein, its three ranking lists generated by
PSI-BLAST (Altschul et al., 1997), HHblits (Remmert et al., 2012)
and ProtEmbed (Melvin et al., 201 1) were converted into the feature
matrix H [Equation (1)], then its homologous proteins can be identi—
fied based on learnt ranking function F(-).

To help the readers to understand its processes, the training and
testing phases of LTR are illustrated in Figure 2.

2.4 Dataset

An updated benchmark dataset (Melvin et al., 2011) was employed
to evaluate the performance of different ranking methods, because
it can provide good comparability with previous methods. This
benchmark dataset was constructed based on SCOP database
(Koehl and M, 2000) containing 7329 proteins from 1070 different
superfamilies. These proteins were extracted from the Astral data—
base (Brenner et al., 2000), and the identity of any two sequences
was lower than 95%. For readers’ convenience, the codes of
the 7329 proteins and their sequences as well as the attributes of
their families and superfamilies are given in Supplementary
Material 81.

2.5 Evaluation methodology

How to evaluate the prediction quality is a key for developing a new
predictor and estimating its potential application value. The 5—fold
cross—validation has been used to evaluate the performance of each
method. The benchmark dataset was randomly divided into five
subgroups with approximately equal number of proteins. Each
method was trained and tested five times with five different training
and test sets. For each time, four subsets were used as training data
and the remaining one was used as test data.

Two performance measures were employed to evaluate the per—
formance of each method, including ROC1 score and ROC50
score (Gribskov and Robinson, 1996). ROC1 and ROC50 scores
represent the area under ROC curve up to the first false positive
and the 50th false positives, respectively. Both ROC1 and ROC50
scores were normalized. A socre of 1 means perfect perdiction,
whereas a score of 0 means that none of the protens is correctly
identified.

 

 

 

3495
Training phase
p” 51(9'12Pu) SS (91 1 191,1) I1,1
pl 2 S] (91 2PM) 5!! (qt 2 171,2) [1,2
qt :1 q]  : .'
P1,» 5] (qr 2pm) 58 (q! a P1,") [1,: Learning a
: Feature : Ranking
Matrix ' Function
 =  Fe)
pm,l 31(qva) "' Se (qmapmJ) Iii-1,1
qm p’gﬂ gm 31 (qn:P..,2) Ss (qm:pnt,2) [In-,2
p“ 312.111....) 38 (22,192.) 1.1,.
Testing phase
pm“,l Feature 51 (qu 9171mm) 53 (gym a pm+l,1)
Pm+1,2 Matrix S1 (qm+1 r Pm+1,2 ) 33 (93m a Pm+1,2)
qm+l 5 (Eq. 1 and 3: gm“ - ;
Pew S] (qumm) SS (22.1mm... )
F([:Sl (anl s Pm+1,l) 58 (9111“ rpm” 
Ranking base F0391 (Q n+1 a Pm+1,2) 5:; (9mg l-an-LZ 
on F(x) “+1
F([Sl (qnwl 5 pm+1,n) SS (qty-r] ’Pm+l,n 

 

 

 

Fig. 2. The training and testing phases of LTR. In training phases, the training
samples are represented as feature matrices based on Equations (1) and (3),
and then they are used to train a ranking function F(-) based on Equations (5)
and (7). In the testing phases, the testing samples are re-ranked by using the
learnt ranking function F(-) to detect their homologous proteins

3 Results and discussion

3.1 The ranking methods are complementary

In the field of protein remote homology detection, several ranking
methods have been proposed. Among these approaches, PSI-BLAST
(Altschul et al., 1997), HHblits (Remmert et al., 2012) and ProtEmbed
(Melvin et al., 2011) showed the state—of—the—art performance.
Therefore, it is particularly interesting to explore if these three pre—
dictors are complementary or not. In this regard, pairwise comparisons
among the three basic methods in the superfamily—level and sequence—
level were conducted, respectively, and the results are shown in
Figure 3. Identical results of the two methods will fall on the diagonal
line, from which we can see that the three methods are complementary
because only a few points fall on the diagonal line. These results are
not surprising, because they are based on different techniques and the—
ories, e.g. PSI—BLAST is based on sequence—sequence alignment, while
HHblits is based on profile—profile alignment. ProtEmbed employs the
semantic embedding, a technique from natural language processing, to
construct a low—dimension ‘semantic space’.

3.2 ProtDec—LTR can improve the performance by
combining three ranking methods in a supervised
manner
The predictive results of the three basic ranking methods on the
benchmark dataset are listed in Table 1, from which we can see that
ProtEmbed achieved the best performance and HHblits outper—
formed PSI-BLAST. These results are fully consistent with previous
studies (Melvin et al., 2011).

As mentioned above, these three ranking methods are comple—
mentary. Therefore, performance improvement would be achieved

91% ‘09 1sn8nv uo sopﬁuv s01 ‘121u10111123 310 [(1319111qu 112 /810's112umo[p101x0's3112m101urorq//:d11q 111011 pop1201umoq

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

3496 B.Liu et al.
A B C
1.0 4 . ;_ ,_ v.1. 1.0 4 _ . _. _ . ._ 1.0 . . _
IIII IIIII I" IIr'IIII II.- I I I-- lfl:£III ' I 'I III- I4
 .143 --:..':' - - .  1..
0.8 " I I. : I I ll. — I 0.8 I l l I-II I I: I " 0.8 ' II I. I III -|
I.- I I I l I I fIIfI I I I iI I I I
I I I I I .- I l :!I I I .l I I
m0.6— -- ' .' .' 980.6 -".-' - -Bo.6- - ".'- 1
f: I -l I. I v-Q I II II ' v-D I - I l
g I I I. Lg II I I I I ' Lg I I II:- I I I I
:04 r ' - - £20.4— + §0.4- - ' «
I OI I III I I l I m I I I I I I I
02 _ ' 02 _ _ ' -_ 0.2-_ _ '. -- '
0.0 I - - - 0.0 - - I - 0.0 I I - -
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 _0.6 0.8 1.0
Ps1-BLAST P51—BLAST HHbllts
1 0 D I 0 E 1 0 F
I I. I: ' i' I':' 3:. [Id-I III. ’ ""1: III-11*. féﬁ ’ .ﬁI' - "- i'""I""I".'."I.III 
I I I I I I'III I I I -I II I II :  II— I I I II I I I III II:  l‘ I I:
0.8% I. I I :I. I I. I I I: 0.8 I I: I I E I :- 0.8 _ ‘ :Il': II I‘ll  IIIIII]:
I I II I I I III I II: I I l i l I IFIIII- I II. I II III-III‘II I I I
I I I.- I II I I I I l .l I I I If - t -III I‘ I ill
' ' I I :I I :- .I III I I I.'- :: I III I ﬁr. III I I II: I'II III :IIIII'II
 I I : I I I I IIII l-lgl‘ I‘  I I I IE lfi?:-l I'  {If-II l- .ILLIf .fl . I.
E I I 1I|.I:- I:- E I I I I : I. 'I' I “a II ' I I I I : I III l II I
E” : '- . -.:.:-'-'-"'.'.' E9 -.. .'-.~-'-‘. EH -  
E041 :! uh"; r'a-"EO-‘I’ ' ' '-'. :"'=" '-. 'E‘W "" .a" 1'! : 1
I I I I II: I :III ’I-FII. I I I II. II I I I ’- I I II III. I I II I I'
I I I I I II— I — III I I II II. II I I I I Ir.- II-II-I I I l I I II II
0.2+ ' '  '.':|:I 0.2) '.: '-- .-: III“ 02+.--'I.-:f-gi-EE--_i':.5'.--
I I . . l I ' - ' '. ' ' I I I I I I- III I - '
I II I I II I I l I I I II I II - II II I f I III I
0.0 J.- I I I I .1 .1 I 0.0 I... I I i I I : I ' II I‘ll-II T- J. Ilnl J. I.
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Ps1—BLAST Ps1-BLAST HHblits

Fig. 3. Comparisons of three basic ranking methods. (A—C) The superfamily-level comparisons between two methods labeled near the axis, and the sequence-
level comparison results are shown in the (D—F). The coordinates of the points in the plot represent the ROC1 scores obtained by the two methods labeled near

the axis. Identical results will fall into the diagonal line

Table 1. A comparison of the 5-fold cross-validation results by
computational predictors for protein remote homology detection
on the benchmark dataset

 

 

Methods ROC1 ROC50
PSI—BLAST 0.7504 0.8007
HHblits 0.8399 0.8820
ProtEmbed 0.8136 0.8897
ProtDec—LTR (PSI—BLAST+HHb1its) 0.663 1 0.7910
ProtDec—LTR (PSI—BLAST+ProtEmbed) 0.8 133 0.8907
ProtDec—LTR (HHblits+ProtEmbed) 0.8442 0.9023
ProtDec—LTR (PSI—BLAST+th1its+ProtEmbed) 0.8437 0.9021

 

by combining them in a supervised fashion by using LTR algorithm.
We applied LTR to combine the three ranking methods, and the re—
sults of different combinations are listed in Table 1, from which we
can see that the best performance of ProtDec—LTR was obtained
when combining HHblits and ProtEmbed. When using PSI-BLAST
as a basic predictor for ProtDec—LTR, the predictive performance
decreased. It is not surprising because the performance of PSI-
BLAST is much lower than that of other two approaches as listed in
Table 1. Much noise can be introduced when incorporating it into
the framework of ProtDec-LTR.

The performance of various methods is plotted in Figure 4. In
each graph, a higher curve corresponds to better performance. As
shown in this figure, ProtDec-LTR (HHblits —I— ProtEmbed) achieved
the best performance, outperforming other three ProtDec-LTR
approaches and it also outperformed all the three basic ranking
methods, including PSI-BLAST (Altschul et al., 1997), HHblits
(Remmert et al., 2012) and ProtEmbed (Melvin et al., 2011), indi-
cating that it is correct to combine different ranking methods in a
supervised manner by using the LTR algorithm and performance im-
provement can be achieved by using this approach. This conclusion

is further supported by Figure 5, which compares the performance
of ProtDec-LTR against the three individual ranking methods. For
most query proteins and superfamilies, ProtDec—LTR outperformed
the basic methods, especially, ProtDec—LTR can obviously improve
the predictive performance for some superfamilies, e.g. PSI-BLAST,
HHblits and ProtEmbed achieved ROC50 scores of 0.5997, 0.8613
and 0.8474 on superfamily a.74.1, respectively, while ProtDec-LTR
achieved an ROC50 score of 0.9276, which significantly outper-
formed all the three basic methods.

4 Conclusion

Based on the similarities between protein sequences and natural lan—
guages, some studies have applied the theories and techniques from
natural language processing to the field of protein remote homology
detection, e.g. Latent Semantic Analysis was used to extract the con—
textual usage of the word—document matrix based on several build—
ing blocks of protein sequences and improved performance for
protein remote homology detection has been acquired in comparison
with basic formalisms (Dong et al., 2005; Liu et al., 2008).
Recently, the semantic embedding method was used to convert a
large—scale embedding of protein feature vectors into a low—dimen—
sional ‘semantic space’ and the homologous proteins can be inferred
based on this ‘semantic space’ (Melvin et al., 2011).

Motivated by the successful applications of these natural lan-
guage processing techniques, in this study, we applied the LTR algo-
rithm, a technique derived from natural language processing, to
detect remote homologous proteins and a new computational pre—
dictor called ProtDec—LTR was proposed, which combines three
(PSI-BLAST, HHblits and
ProtEmbed) in a supervised manner. In this approach, protein re—

state—of—the—art ranking methods

mote homology detection is treated as a document retrieval task,
where the protein sequences are viewed as documents. Experimental

91% ‘09 1sn8nv uo sopﬁuv s01 ‘121u10111123 310 [(1319111qu 112 /8.IO'SIBU.IHO[p.IOJXO'SOTlBIIIJOJUTOTCI/ﬁdllq 111011 pop1201umoq

Application of LTR to protein remote homology detection

3497

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

A 1.0 ' I ' I ' I ' I B 1 0 \‘ I I I I
weigh, . N. . T \ \i\:\ m ‘ e \ \ \§\¢\a\
\ .\I \Q‘q:S-E§=§§ﬁ$éz\‘\  _ ¥ _ - ‘ _ :_:>  \
"‘ T‘ \ \ ‘ O\D§g\{v§ _ _ +§3\ \l\
a 0 8 - \ x - \ \m \\M a o 8 \.\‘
w A \r\ \'\\‘ §g\o\* '” A \-
3 \o \ \ \ \D\  . 3 \o
[A O \ \ O (I) S
g goa- \\ - g goa-
e e \ x a e
a) g \ ' 0 g
L” <2 '\ a: <8.
0 33 0-4 - . o a; 0.4 - _
a) Q — — P51-BLAST ago 9., — — Ps1—BLAST
g3 5 . —v— HHblits g g . —v— HHblits
a "a —D— ProtEmbed I I g  —D— ProtEmbed _ .
e ODOQ — —-— ProtDec-LTR (P51-BLAST+HHb11ts) - 8 0,2 - —-— ProtDec-LTR (P31-BLAST+HHb11ts)
a: —<>— ProtDec-LTR (Psi-BLAST+ProtEmbed) a: + ProtDec-LTR (Psi-BLAST+ProtEmbed)
' — — ProtDec-LTR (HHblits+ProtEmbed) ' — — ProtDec-LTR (HHblits+ProtEmbed)
O 0  ProtDec-LTR (Psi-BLAST+HHb1its+ProtEmbed) 0 0  ProtDec-LTR (Psi-BLAST+HHb1its+ProtEmbed)
'0.0 0.2 0.4 0.6 0.8 1.0 '0.0 0.2 0.4 0.6 0.8 1.0

ROC1 score

ROC50 score

Fig. 4. Relative performance of various computational predictors. The graph plots the percentage of sequences for which the method exceeds a given perform-
ance. The higher curve means the method performs better. ROC1 and ROC50 are used as the performance measures for (A) and (B), respectively

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

A B C
1.0 I... 1.0 _ : - 1.0 - . r 1:..1
I. II: I.- l  € -' I. I IEHFI I. I I. I'. III¥I .
I. I l l I; .l I I I. I I I} l- I l.-
08" l .I I I :l-- I. I. -I  I I I. i I 1  I I I, II. I. I III-1
m I I I I I m I I. I M I - I. I. II
:06- I I. - - 5'06- . I - - $0.6- I I I - 4
§0.4 r - §0.4 - _ - §0.4 - - - -
D—I D—I 9-4
0.2 - 0 2 0.2 -
0.0 ' ' ' ' 0.0 ' ' ' ' 0.0 ' ' ' '
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 .0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Ps1—BLAST HHblits ProtEmbed
10 . _ __ I?" _ 1.0 _ _ _ IE"; 1.0 ._ t F'- Inn.
I I I I h‘ II. I l I I ii i I. Iii-In I I I I: I I :I I... II I
E II II? 1.. '. I..- r .- Iﬁli‘i'ﬂf. ‘ I III r I?l
I I. I : _ I i I I. I. I I I I I. I I —I I
0.8 I I I -- l '5-- I 0.8 I 1. II IIIII‘IILIf I :I  I III I l '-  I- i I!
I I I I I .I I. I I. ll II'I-IIIII I I I I'- l l-- I. ll I
a - - :  t a . .  - i“ a ---’ -- :r.  1""
 I I I I II q0'6— I III-- E II I. - 540'6— I I I I : I. I
(I) l I I I I I (I) l-Il- I ' .- CI) I I ‘I I h
E - - 5  "- " 5 -'.-- -' -- .
I I l i I l 'l I I I I I I .I I I
E0_4l. . I 1504- .I- . _ §0_4L I I _
m _ m . - cu - d.
02L 0.2L . " 0.2- . -' '
0.0 ' ' ' ‘ 0.0 ' ' 0.0 ' ' ' "
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 _0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
PSI-BLAST HHBlIts ProtEmbed

Fig. 5. Performance comparison between ProtDec-LTR against three predictors. (A—C) The superfamily-level comparisons between two methods labeled near
the axis, and the sequence-level comparison results are shown in the (D-F). The coordinates of the points in the plot represent the ROC50 scores obtained by the

two methods labeled near the axis

results on a widely used benchmark dataset showed that ProtDec—
LTR outperformed other competing methods, especially for some
protein superfamilies, performance improvement was obvious.
ProtDec—LTR employs a supervised approach to train a model based
on the labeled data and the three complementary ranking methods,
which considers the advantages of all these individual predictors. It
is the main reason for the better performance of ProtDec—LTR.
These results further confirm that application of techniques from
natural language processing is an efficient way for protein remote
homology detection.

It has not escaped our notice that the current approach can be
easily applied to other tasks in bioinformatics, because many prob—
lems in this field can be formulated as ranking tasks, such as fold

recognition (Dong et al., 2009; Lin et al., 2013), etc. Our future
studies will focus on exploring new features or ‘grammar rules’ of
protein sequences (Liu et al., 2014b, 2015b) and applying other lan-
guage processing techniques to protein remote homology detection,
such as deep learning (Bengio, 2009; Hinton et al., 2006), etc.

Acknowledgements

The authors would like to thank Hang Li and Jun Xu for their helpful discus-
sions. The authors also Wish to thank the three anonymous reviewers for their
constructive comments, which are very helpful in strengthening the presenta-
tion of this study. This work was supported by the National Natural Science
Foundation of China [61300112 and 61272383], the Scientiﬁc Research

91% ‘09 1sn3nv uo sopﬁuv $01 ‘etuiomeg aIo Amie/xtqu 112 /§.IO'S[BU.IT10[p.IOJXO'SOllBIIIJOJUTOTQ/ﬁdllq 11101; prBOIUAAOG

3498

B.Liu et al.

 

Foundation for the Returned Overseas Chinese Scholars, State Education
Ministry, the Natural Science Foundation of Guangdong Province
[2014A030313695], Strategic Emerging Industry Development Special Funds
of Shenzhen [ICY]20140508161040764], Shenzhen Municipal Science and
Technology Innovation Council [CXZZ20140904154910774] and National
High Technology Research and Development Program of China (863
Program) [2015AA015405].

Conﬂict of Interest: none declared.

References

Altschul,S.F. et al. (1990) Basic local alignment search tool. ]. Mol. Biol., 215,
403—410.

Altschul,S.F. et al. (1997) Gapped BLAST and PSI-BLAST: a new
generation of protein database search programs. Nucleic Acids Res., 25,
33 89—3402.

Bengio,Y. (2009) Learning deep architectures for AI. Foundations Trends
Machine Learn., 2, 1—127.

Bork,P. and Koonin,E.V. (1998) Predicting functions from protein se-
quences—where are the bottlenecks? Nat. Genet., 18, 313—318.

Bottou,L. (2010) Large-scale machine learning with stochastic gradient
descent. In: Lechevallier,Y. and Saporta,Gi. (eds) Proceedings of
COMPSTAT’ZOI 0, Springer-Verlag Berlin Heidelberg, pp. 177—186.

Brenner,S.E. et al. (2000) The ASTRAL compendium for sequence and struc-
ture analysis. Nucleic Acids Res., 28, 254—256.

Burges,C. et al. (2005) Learning to rank using gradient descent. In:
Proceedings of the 22nd International Conference on Machine Learning.
ACM, New York, NY, USA, pp. 89—96.

Burges,C.]. (2010) From ranknet to lambdarank to lambdamart: an overview.
Learning, 11, 23—5 81.

Dong,Q. et al. (2005) Application of latent semantic analysis to protein remote
homology detection. Bioinformatics, 22, 285—290.

Dong,Q. et al. (2009) A new taxonomy-based protein fold recognition ap-
proach based on auto-cross covariance transformation. Bioinformatics, 25,
2655—2662.

Donmez,P. et al. (2009) On the local optimality of LambdaRank. In:
Proceedings of the 32nd international ACM SIGIR conference on Research
and development in information retrieval. ACM, New York, NY, USA, pp.
460—467.

Eddy,S.R. (1998) Proﬁle hidden Markov models. B ioinformatics, 14, 755—763.

Figueroa,A. and Neumann,G. (2013) Learning to rank effective paraphrases
from query logs for community question answering. In: AAAI Press, Palo
Alto, California. Citeseer.

Gribskov,M. and Robinson,N.L. (1996) Use of receiver operating characteristic
(Roc) analysis to evaluate sequence matching. Comput. Chem., 20, 25—33.

Hinton,G.E. et al. (2006) A fast learning algorithm for deep belief nets. Neural
Comput., 18, 1527—1554.

Karplus,K. et al. (1998) Hidden Markov models for detecting remote protein
homologies. Bioinformatics, 14, 846—85 6.

Koehl,P. and M, M.L. (2000) The ASTRAL compendium for sequence and
structure analysis. Nucleic Acids Res., 28, 254—256.

Leslie,C.S. et al. (2002) The spectrum kernel: a string kernel for SVM protein
classiﬁcation. Pac. Symp. Biocomput., 7, 5 66—5 75.

Li,H. (2011) A short introduction to learning to rank. IEI CE Trans. Inf. Syst.,
94, 1854—1862.

Lin,C. et al. (2013) Hierarchical classiﬁcation of protein folds using a novel en-
semble classiﬁer. PLoS One, 8, e5 6499.

Liu,B. et al. (2008) A discriminative method for protein remote homology de-
tection and fold recognition combining Top-n-grams and latent semantic
analysis. BMC Bioinformatics, 9, 510.

Liu,B. et al. (2012) Using amino acid physicochemical distance transformation
for fast protein remote homology detection. PLoS One, 7, e46633.

Liu,B. et al. (2013) Protein remote homology detection by combining Chou’s
pseudo amino acid composition and proﬁle—based protein representation.
Mol. Inform., 32, 775—782.

Liu,B. et al. (2014a) Combining evolutionary information extracted from fre-
quency proﬁles with sequence-based kernels for protein remote homology
detection. Bioinformatics, 30, 472—479.

Liu,B. et al. (2014b) iDNA-Prot|dis: identifying DNA-binding proteins by
incorporating amino acid distance-pairs and reduced alphabet proﬁle into
the general pseudo amino acid composition. PLoS One, 9, e106691.

Liu,B. et al. (2014c) Using distances between top-n-gram and residue pairs for
protein remote homology detection. BMC Bioinformatics, 15, S3.

Liu,B. et al. (2015a) Protein remote homology detection by combining Chou’s
distance-pair pseudo amino acid composition and principal component ana-
lysis. Mol. Genet. Genomics, doi: 10.1007/s00438-00015-01044-00434.

Liu,B. et al. (2015b) Pse-in-One: a web server for generating various modes of
pseudo components of DNA, RNA, and protein sequences. Nucleic Acids
Res., W1, W65—W71.

Liu,T. (2009) Learning to rank for information retrieval. Foundations Trends
Inf. Retrieval, 3, 225—33 1.

Liu,T. et al. (2007) Letor: benchmark dataset for research on learning to rank
for information retrieval. In: Proceedings of SI CIR 2007 Workshop on
Learning to Rank for Information Retrieval. ACM, New York, NY, USA,
pp. 3—10.

Melvin,I. et al. (2009) RANKPROP: a web server for protein remote hom-
ology detection. Bioinformatics, 25 , 121—122.

Melvin,I. et al. (2011) Detecting remote evolutionary relationships among
proteins by large-scale semantic embedding. PLoS Comput. Biol., 7,
e1001047.

Muh,H.C. et al. (2009) AllerHunter: a SVM-pairwise system for assessment of
allergenicity and allergic cross-reactivity in proteins. PLoS One, 4, e5861.
Pearson,W.R. (1991) Searching protein sequence libraries: comparison of the
sensitivity and selectivity of the Smith-Waterman and FASTA algorithms.

Genomics, 11, 635—650.

Remmert,M. et al. (2012) HHblits: lightning-fast iterative protein sequence
searching by HMM-HMM alignment. Nat. Methods, 9, 173—175.

Saigo,H. et al. (2004) Protein homology detection using string alignment ker-
nels. Bioinformatics, 20, 1682—1689.

Sculley,D. (2009) Large scale learning to rank. In: NIPS Workshop on
Advances in Ranking. pp. 1—6.

Smith,T.F. and Waterman,M.S. (1981) Identiﬁcation of common molecular
subsequences.]. Mol. Biol., 147, 195—197.

Weston,]. et al. (2004) Protein ranking: from local to global structure in the
protein similarity network. Proc. Natl. Acad. Sci. USA, 101, 6559—65 63.
Weston,]. et al. (2006) Protein ranking by semi-supervised network propaga-

tion. BMC Bioinformatics, 7, S10.

91% ‘09 1sn8nv uo sopﬁuv s01 ‘nrulomng JO Amie/nun 112 /§.IO'S[BU.IHO[p.IOJXO'SOUBIHJOJUIOIQ/ﬁ(1111] 11101; p9p1201umoq

