Bioinformatics Advance Access published August 25, 2016

Bioinformatics, 2016, 1—7

doi: 10.1093/bioinformatics/btw483

Advance Access Publication Date: 19 July 2016
Original Paper

 

Gene expression

Variance adaptive shrinkage (vash): flexible
empirical Bayes estimation of variances

Mengyin Lu1 and Matthew Stephens1'2'*
1Department of Statistics, University of Chicago, Chicago, 60637, USA and 2Department of Human Genetics,
University of Chicago, Chicago, 60637, USA

*To whom correspondence should be addressed.
Associate Editor: Oliver Stegle

Received on April 19, 2016; revised on June 21, 2016; accepted on July 9, 2016

Abstract

Motivation: Genomic studies often involve estimation of variances of thousands of genes (or other
genomic units) from just a few measurements on each. For example, variance estimation is an im-
portant step in gene expression analyses aimed at identifying differentially expressed genes. A
common approach to this problem is to use an Empirical Bayes (EB) method that assumes the vari-
ances among genes follow an inverse-gamma distribution. This distributional assumption is rela-
tively inflexible; for example, it may not capture ’outlying’ genes whose variances are considerably
bigger than usual. Here we describe a more flexible EB method, capable of capturing a much wider
range of distributions. Indeed, the main assumption is that the distribution of the variances is uni-
modal (or, as an alternative, that the distribution of the precisions is unimodal). We argue that the
unimodal assumption provides an attractive compromise between flexibility, computational tract-
ability and statistical efficiency.

Results: We show that this more flexible approach provides competitive performance with existing
methods when the variances truly come from an inverse-gamma distribution, and can outperform
them when the distribution of the variances is more complex. In analyses of several human gene
expression datasets from the Genotype Tissues Expression consortium, we find that our more flex-
ible model often fits the data appreciably better than the single inverse gamma distribution. At the
same time we find that in these data this improved model fit leads to only small improvements in
variance estimates and detection of differentially expressed genes.

Availability and Implementation: Our methods are implemented in an R package vashr available
from http://github.com/mengyin/vashr.

Contact: mstephens@uchicago.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

 

Genomic studies often involve estimation of variances of thousands of
genes (or other genomic units) from just a few measurements on each.
For example, variance estimation is an important step in gene expres-
sion analyses aimed at identifying differentially expressed genes. The
small number of measurements on each gene mean that simple esti-
mates of the variance at each gene (e.g. the sample variance) can be
quite unreliable. A common solution to this problem is the use of
Empirical Bayes (EB) methods, which combine information across all

genes to improve estimates at each gene. In particular they have the ef-
fect of ‘shrinking’ the variance estimates towards a common mean
value, which has a stabilizing effect, avoiding unusually large or small
outlying estimates that may have high error. A key question is, of
course, how much to shrink. While all EB methods aim to learn the
appropriate shrinkage from the data, existing EB approaches make
relatively inﬂexible modelling assumptions that could limit their ef-
fectiveness. Here we propose a new, more ﬂexible, EB approach,
which can improve variance estimation accuracy in some settings.

©The Author 2016. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 1

9mg ‘09 isnﬁnV uo salaﬁuV soq ‘eiulomeg JO AiiSJQAiu [1 112 ﬂJO'sleumo[pJOJXO'soneuuoguioiq/ﬁdnq mm; papeolumoq

M.Lu and M.Stephens

 

Perhaps the most commonly encountered example of the use of
EB methods is in gene expression analyses that aim to identify differ-
ences in gene expression among conditions. A typical pipeline for
identifying differentially expressed genes computes a P-value for
each gene using a t-test (two condition experiments) or F-test (mul-
tiple condition experiments), both of which require an estimate of
the variance in expression of each gene among samples. In the clas-
sical t-test or F—test, sample variances are used as plug-in estimates
of gene-specific variances. However, when the sample size is small,
sample variances can be inaccurate, resulting in loss of power
(Murie et al., 2009). Hence, many methods have been proposed to
improve variance estimation. For example, several papers (Broberg
et al., 2003; Efron et al., 2001; Tusher et al., 2001) suggested adding
an offset standard deviation to stabilize small variance estimates. A
more sophisticated approach (Baldi and Long, 2001) used paramet-
ric hierarchical models to combine information across genes, using
an inverse gamma prior distribution for the variances, and a
Gamma likelihood to model the observed sample variances. This
idea was further developed by L6nnstedt and Speed (2002) and
Smyth (2004) into an Empirical Bayes (EB) approach that estimates
the parameters of the prior distribution from the data. This im-
proves performance by making the method more adaptive to the
data. Smyth (2004) also introduces the ‘moderated t—test’, which
modifies the classical t-test by replacing the gene-specific sample
variances with estimates based on their posterior distribution. This
pipeline, implemented in the software limma, is widely used in gen-
omics thanks to its adaptivity, computational efficiency and ease of
use.

While assuming an inverse-gamma distribution for the variances
yields simple procedures, the actual distribution of variances may be
more complex. Motivated by this, Phipson et al. (2016) (limma with
robust option, denoted by limmaR) modified the procedures from
Smyth (2004) to allow for some small proportion of ‘outlier’ genes
that have higher variability than expected under the inverse-gamma
assumption. Specifically, the limmaR procedure changes the moder-
ated t statistics from limma by decreasing their degrees of freedom
(df) in a way that varies for each gene, depending on whether the
gene looks like an outlier. Genes that look like an outlier have their
df reduced appreciably, making them less significant, whereas other
genes have their df unchanged or reduced very little. They showed
that, in the presence of such outliers, this procedure could improve
on the standard limma pipeline.

Here we consider a more formal EB approach to this problem,
which generalizes previous EB methods by replacing the usual in-
verse gamma prior distribution with a substantially more flexible
family of distributions. The main constraint we place on this prior is
that the distribution of the variances (or, alternatively, the preci-
sions) is unimodal. This unimodal assumption not only seems likely
to be plausible in many settings, but also provides an attractive com-
promise between flexibility, statistical stability and computational
convenience. Specifically it provides more flexibility and generality
than many parametric models while avoiding potential over-fitting
issues of fully non-parametric methods. (An alternative approach
would be to use some kind of regularization to prevent over-fitting;
see Efron (2016) for example.) We use a mixture of (possibly a large
number of) inverse-gamma distributions to flexibly model this uni-
modal distribution, and provide simple computational procedures to
fit this model by maximum likelihood of the mixture proportions.

Our procedure provides a posterior distribution on each variance
or precision, as well as point estimates (posterior mean). The meth-
ods are an analogue of the ‘adaptive shrinkage’ methods for mean
parameters introduced in Stephens (2016), and are implemented in

the R package vashr (for ‘variance adaptive shrinkage in R’). We
compare our method with both limma and limmaR in various simu-
lation studies, and also assess its utility on real gene expression data.

2 Methods

2.1 Models

Suppose that we observe variance estimates 3%, . . . 312 that are esti-
mates of underlying ‘true’ variances 5%, . . . ,512. Motivated by stand-

ard normal theory, we assume that
A2 - A2
57-  ~ sI-thzii/di, 1.e. sl-  ~ Gamma(d,-/2,d,~/(2sl-2)). (1)

where the degrees of freedom d,- depends on the sample size and we
assume it to be known.

Empirical Bayes (EB) approaches to estimating 57-2 (e.g. Smyth,
2004) are commonly used to improve accuracy, particularly when the
degrees of freedom d,- for each observation are modest. The EB ap-
proach typically assumes that the variances 57-2 are independent and

identically distributed from some underlying parametric distribution g:

2 .
where the parameters 0 are to be estimated from the data.
Equivalently, that the precisions (inverse variances), 5/72, are i.i.d.

from some h(-; 0). A standard approach (Smyth, 2004) assumes that
g is an inverse-gamma distribution (i.e. h is a gamma distribution)
which simplifies inference because of conjugacy. Here we introduce
more flexible assumptions for g or I): specifically that either g or b is
unimodal. By using a mixture of inverse gamma distributions for g
(i.e. a mixture of gamma distributions for h), we can ﬂexibly capture
a wide variety of unimodal distributions for g or I), while preserving
many of the computational benefits of conjugacy.

2.2 A unimodal distribution for the variances

Let InvGamma(-;a, (9) denote the density of an inverse-gamma dis-
tribution with shape a and rate 19. This distribution is unimodal with
mode at c = b/(a + 1). To obtain a more ﬂexible family of uni-
modal distributions with mode at c we consider a mixture of
inverse-gamma distributions, each with mode at c:

K
g(-; n, a, c) = Z nkInvGammac; at, bk), (3)
[2:1
where
bk 1: (“k + 1)C, (4)

and nk are mixture proportions. Each component in (3) has mode at c,
and the variance about this mode is controlled by ak, with large ak cor-
responding to small variance. By setting a to a large fixed dense grid of
values that range from ‘small’ to ‘large’, we obtain a ﬂexible family of
distributions, with hyperparameters TC, that are unimodal about c.

We emphasize that the representation (3) is simply a computa-
tionally convenient way to achieve a flexible family of unimodal
distributions. Our goal is that K be sufficiently large, and the grid
of values a be sufficiently dense, that results would not change
much by making the grid larger and denser. In practice modest val-
ues of K (e.g. 10—16) are sufficient to give reasonable performance
(see below for specific details on choice of grid for a). Using a dense
grid makes the hyperparameters TC non-identifiable, because differ-
ent values for TC can lead to similar values for g(-; TC, a, c), but this is
not a concern here because accurate EB inference requires only a

9mg ‘09 isnﬁnV uo salaﬁuV soq ‘eiulomeg JO AiiSJQAiu [1 112 ﬂJO'smumo[pJOJXO'soneuuoguioiq/ﬁdnq wort papeolumoq

Variance adaptive shrinkage (vash)

 

good estimate for g and not 7w. This approach is analogous to
Stephens (2016), which uses mixtures of normal or uniform distri-
butions, with a fixed grid of variances, to model unimodal distribu-
tions for mean parameters.

2.3 Estimating hyper-parameters
For K = 1 we estimate the hyperparameters (a, c) by maximizing the

likelihood

L(a,c;§%, . . . 3}) :2 p(§1,...,§]|a,c) (5)
I
= Hp(?,-;a,c) (6)
i=1
where
P(?i;a,c) = jp(?,‘lsf)g(sfla,c)ds,-2 <7)
41,—1/2

Si N4 + di/ZW
F(d,-/2)r(a)(d,-§f/2 + b)a+d,-/2 ’

 

= (er/2W

lb: (4+1)/CI- (9)

We use the R command optim to numerically maximize this likeli-
hood. The approach is similar to Smyth (2004), except that we use
maximum likelihood instead of moment matching.

For K > 1, as noted above, we use K ‘large’ (e.g. 10—16), fix the
values of ak to a grid of values from ‘small’ to ‘large’, and estimate
the hyper-parameters c, TC by maximizing the likelihood

L(n,c;a,§§,...,§}) =p(§1,...,§]|7t,a,c) (10)
J
= HZWkP(5/'§akac) (11)
i=1 k

where p(§,-; ak, c) is given by (8). We center the grid of ak values on
the point estimate 3 obtained for K = 1, to ensure that the grid val-
ues span a range consistent with the data (typically ak lies between 0
and 100). Moreover, if the data are consistent with K = 1 then the
estimated TC will be concentrated on the component with ak = 3, and
thus lead to similar results to limma.

To maximize the likelihood we use an iterative procedure that
alternates between updating c and TC, with each step increasing the
likelihood. Given c, we update TC using a simple EM step
(Dempster et al., 1977). Given TC we update c by optimizing (11)
numerically using optim. We use SQUAREM (Varadhan and
Roland, 2004) to accelerate convergence of the overall procedure.
See Appendix for details.

2.4 Posterior calculations

Using (3) as a prior distribution for 57-2, and combining with the like-
lihood (1) the posterior distribution of 57-2 is also a mixture of
inverse-gamma distributions:

P($,—2 = Z ﬁikInvGamma(sl-2;&,-k, 137k), (12)
k

where

a), :2 ak + d,/2, (13)

 

 

 

3
" A2
bik :2 bk + disl- /2, (14)
Adi—2 Hawaii/2) bf."
~ TCkSI' 1“(ak) (bk+dlgj/2)ak+di/2 
r(..,+d,./2) a < >
k, k ’ Wk” (bk,+d,?,‘/2)“kl+di”

Following Smyth (2004) we use the posterior mean of 5/72 as a

point estimate for the precision 5/72:

~_ _ ~ ﬁ'k
s, =E(s,2|§f)=zn,kl%. (16)
k jk

Note that each riﬂe/15,12 can be interpreted as a shrinkage-based esti-
mate of 5/72, since it lies between the observation 372 and the prior
mean of the lath mixture component ak /bk.

When estimating variances we use the inverse of the estimated pre-
cision (16). While it may seem more natural to use the posterior mean
of 57-2 as a point estimate for 57-2, we found that this can be very sensitive
to small changes in the estimated hyper-parameters a, and so can per-
form poorly. And while it may also be more natural to estimate vari-
ances on a log scale, for example using the posterior mean for log(s,-),

the absence of closed-form expressions makes this less convenient.

2.5 Unimodal prior assumption on variance or precision
The above formulation is based on assuming a unimodal prior distri-
bution for the variance 57-2, specifically by using a mixture of inverse-
gamma distributions all with the same mode. An alternative is to as-
sume a unimodal prior distribution for the precision 1 / 51-2, by using a
mixture of gamma distributions, all with the same mode. This is
equivalent to using a mixture of inverse-gamma distributions for the

variance 57-2 as in (3) above, but with

bk 2: (ak—1)/c (17)

in place of (4), because the mode of a Gamma(a, 19) distribution is at
c = (a — 1) / b. We present results for both approaches. In practice
one can assess which of the two models provides a better fit to the
data by comparing their (maximized) likelihoods (11). Note that in
many (but not all) cases the fitted prior distributions under either or
both approaches will end up being unimodal for both the variance
and the precision. However, even in these cases, the optimal likeli-
hood under each approach will typically differ because the family of
unimodal distributions being optimized over is different.

2.6 Testing effect size
In differential expression analysis, testing if ﬁl- = 0 is of primary inter-
est. Smyth (2004) suggested using the ‘moderated t—test’, which mod-
erated the sample variance and degree of freedom by the shrunk
variance estimates and its posterior degree of freedom. Here we derive
an analogue of this moderated t—test in our mixture prior setting.

The distribution of? given 3’ is:

more?) = jp<B,I/s,,s%>p<s%rs%>ds,~ <18)
2 JN(Bi; ﬁi,  - Z ﬁI-kInvGamma(s,-;&,-k,15,0615) (19)
k

= 2k) elm; 2&1, rips-k) (20)

where pt(-; U, u, 0) denotes the density of a generalized t-distribution
with degree of freedom V, location parameter )1 and scale parameter

9mg ‘09 isnﬁnV uo salaﬁuV soq ‘eiulomeg JO AiiSJQAiu [1 112 ﬂJO'smumo[pJOJXO'soneuuoguioiq/ﬁdnq wort papeolumoq

M.Lu and M.Stephens

 

Table 1. Parameters for the simulation scenarios with unimodal
prior on variance

Table 2. Parameters for the simulation scenarios with unimodal
prior on precision

 

 

 

 

Scenario Description Prior of 5,.2 Scenario Description Prior of 1 / 51.2

A Single IG InvGamma(10,11) E Single gamma Gamma(10,9)

B Single IG with outliers 0.1InvGamma(3,4)—l— F Single gamma with outliers 0.1Gamma(2,1)+
0.9InvGamma(10,11) 0.9Gamma(10,9)

C IG mixture 0.1InvGamma(3,4) —l— G Gamma mixture 0.1Gamma(2,1) —|—
0.4InvGamma(5,6) —l— 0.4Gamma(5,4) —l—
0.51nvGamma(20,21) 0.5Gamma(30,29)

D Long tail 0.7logN(0.0625,0.0625) —l— H Long tail 0.7logN(0.0625,0.0625) +

0.3logN(0.64,0.64)

log-normal mixture

0.3logN(0.64,0.64)

log-normal mixture

 

a (i.e. the density of u + oTy where TV is a standard If distribution on
V degrees of freedom).

Hence, under the null (ﬁl- = 0), :0,- follows a mixture of general-
ized t-distributions:

“Elem = 0) = Zﬁikpxﬁﬁzak, 03,1). (21)
k

A p-value for testing ﬂ,- = 0 can therefore be computed as
p,- = Pr(|X)| > IEI), (22)

where X,- follows the mixture of generalized t-distributions in
(21). In the special case where the mixture involves K = 1 compo-
nents this is equivalent to the P value from Smyth’s moderated t
test.

The P-value P,- measure the significance of gene 7'. To select signifi-
cant differentially expressed genes and control the false discovery
rate, these P values can be subjected to the Benjamini-Hochberg pro-
cedure (Benjamini and Hochberg, 1995), or Storey’s procedure
(Storey, 2002, 2003), for example. Alternatively, the methods in
Stephens (2016) can be extended to incorporate the mixture likeli-
hood (20).

3 Results

3.1 Simulation studies

To compare and contrast our method with limma and limmaR we
simulate data from the model (1)—(3), with G = 10 000, and degrees
of freedom df= 3, 10, 50 (corresponding to sample sizes 4, 11 and
51 respectively) under various scenarios for the actual distribution
of variances (scenarios A—D) or precisions (scenarios E—H), as sum-
marized in Tables 1 and 2.

The simulation scenarios are designed to span the range from a
single inverse-gamma prior as assumed by limma, to more complex
distributions under which we might expect our method to outper-
form lz'mma. Specifically we consider:

° Single IG (or Single Gamma): single component inverse-gamma
prior on variance (or gamma prior on precision), which satisﬁes
the assumptions of limma.

° Single IG (or Single Gamma) with outliers: two component
inverse-gamma prior on variance (or gamma prior on precision),
where one component models the majority of genes and the other
component, being more spread out, attempts to capture possible
outliers. The method limmaR is speciﬁcally designed to deal with
the case where large variance outliers exist.

° IG (Gamma) mixture: a more ﬂexible inverse-gamma mixture
prior on variance (or mixture gamma prior on precision) with
multiple components.

 

° Long tail log-normal mixture: log-normal mixture prior on vari-
ance or precision, which yields a longer tail than either the
inverse-gamma or the gamma distribution.

We also assume that 90% of the genes are not differentially ex-
pressed (ﬁg 2 0), while the rest of the genes are (ﬁg ~ N(0, 02)).
Here a is held fixed at 2.

For each simulation scenario we simulate 50 datasets and apply
limma, limmaR, and our proposed method (vash) to estimate 57-2 (or
1 /sl-2). We compare the relative root mean squared errors (RRMSEs)

of the shrinkage estimators, which we define by

(/IE(1/sl-2 — 1/§,.2)2
RRMSEprec :2 —, (23)
(um/5,2 — Us}?

 — El-Z)2
RRMSEvar :2 —A22. (24)
 — sl- )

The RRMSE measures the improvement of a shrinkage estimator
. . . A2 . . A2 -

over s1mply us1ng the sample variance Si or prec1s1on 1/sl- , w1th
RRMSE: 1 indicating no benefit of shrinkage. (We also show the
absolute RMSEs, i.e. the numerators of (23) and (24), in
Supplementary Materials; Tables S1, S2.)

Figure 1 and 2 show the RRMSEs of limma, limmaR and vash
for all scenarios. We summarize the main patterns as follows:

1. Across all scenarios, the mean RRMSE of vash is consistently no
worse than either limma or limmaR, and is sometimes appre-
ciably better. In contrast, limmaR sometimes performs better
than limma and sometimes worse. In this sense vash is the most
robust of the three methods.

2. In simulations under the simplest scenario (A and E) where the
assumptions of limma are met, all three methods perform simi-
larly. In particular, the additional ﬂexibility of vash does not
come at a cost of a drop of performance in the simpler scenarios.

3. When sample sizes are small (df = 3) all methods perform simi-
larly under all scenarios. This highlights the fact that the beneﬁts
of more ﬂexible methods like vash are small if samples sizes are
too small to exploit the additional ﬂexibility. Put another way,
for small sample sizes simple assumptions sufﬁce.

4. When sample sizes are large (df = 50) vash can outperform the
other methods, particularly under the more complex scenarios
(C,D; G,H), which most strongly violate the assumptions of
limma. Indeed, in these cases both limma and limmaR can have
RRMSE > 1, indicating that they perform worse than the
unshrunken sample estimators. That is, when sample sizes avail-
able to estimate each variance are relatively large shrinkage

9mg ‘09 isnﬁnV uo salaﬁuV soq ‘eiulomeg JO AiiSJQAiu [1 112 ﬂJO'smumo[pJOJXO'soneuuoguioiq/ﬁdnq moi; papeolumoq

Variance adaptive shrinkage (vash)

 

A Variance Prior: B Variance Prior: C Variance Prior: D Variance Prior:
single 16 In single 16 with outliers m 16 mixture log—normal mixture

 

density

 

 

07

a
_,_

.
a. —L
;;E
A. m_ A.

df=3
1:. maijl ._ '5-
O O : O

a u 4—
W- ‘— Biz:
9 E55; EEEE A.

0.5

I
_I_ _I_

3
3
3
3

 

I I l d— I I l d— I I l d— I I l
vash limmalimmaR vash limmalimmaR vash limmalimmaR vash limmalimmaR

df=10 df=10 df=10 df=10
, m  m' """""""""""" " c; """""""""""" '-
$ 0' ' o' ' E -  o' ' o' '
E _ —I— —I— —I— _ I I —‘— _ —I— _
3:: v~. _ -'- -'- _ : T vs. _ E E % vs. _
o o _I_ o _I_ —'— o —‘I—

 

I I I d - I I I d - I I I o I I I
vash limma limmaR vash limma limmaR vash limma limmaR vash limma limmaR
df=50 df=50 df=50 df=50

 

I91
D-

0.80 0.90 1.00 1.10
|

 

RRMSE

0.80 0.90 1.00 1.10

+131.
=E4T

_I_—I—

 

 

 

 

 

 

 

 

0.80 0.90 1.00 1.10
| I I I
0.80 0.90 1.00 1.10

 

va'sh liminalimrhaFI va'sh liminalimrhaFI va'sh liminalimrhaFI va'sh Iim'maIimriIaR
Fig. 1. RRMSEvar of three gene-specific variances estimators, limma, limmaR
and our proposed estimator (vash) in the 4 simulation scenarios A-D with uni-

modal variance prior

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

E Precision Prior: F Precision Prior: G Precision Prior: H Precision Prior:
single gamma l“single gamma wI outliersIn gamma mixture log—normal mixture
.30. _ 0. _ 0. _ 0. _
u, v— v— v— v-
C
(I)
'5
In _ In _ In _ In _
O O
. _ 0. _ 0. _ 0. _
‘3 'l—l—l—l—l—l' ‘3 I I I I I I o I I I I I I o I I I I I I
o 1 2 3 4 5 o 1 2 3 4 5 o 1 2 3 4 o 1 2 3 4 5
df=3 df=3 df=3 df=3
a) a) a) a)
O _ O _ O _ O _
Lu 0 o' o' o
g _ _ —I— —I— —I— _ —I— —:— —:— _
a: T T T l 1 i i - - T T T
n: 3. - ' ' ' 3. - 3. - 3. -
° SEE ° ° °
' : : : ' : : : ' E E E ' E E E
8 _ ___ _._ __  _ —I— —l— —-—  _ _._ _._ _._  _ _I_ _l— —l—
o I _ l _ I O I _ l _ I O I _ l _ I O I _ l _ l
vash IImma IImmaR vash IImma IImmaR vash IImma IImmaR vash IImma IImmaR
df=10 df=10 df=10 df=10
h. _ h. _ h. _ h. _
Lu 0 o o o
w
E - - - _I— —I— - _'_ _I— —I—
“3- 3%— E: =: 35+ é? 3%? ET
- é é é - - . - ; .
_._ _._ _._ .
n _ n. _ n. _ n. _
I _ I _ I o I _ I _ I o I _ I _ I o I _ I _ I
vash IImma IImmaR vash IImma IImmaR vash IImma IImmaR vash IImma IImmaR
df=50 df=50 df=50 df=50
s. _ s. _ v _ s. _ T
Lu T E
g “I _ “I _ N _,_ «I _ E —1—
.— .— .— .— _,_
a: —.— E
a: 0. 0. _.- o  0. __
' ' a: % =_._ ' —— ' E
— _|_
g- —---sg--sa- g- 2. ﬁ— :—
I _ l _ I I _ l _ I I _ l _ I I _ l _ l
vash IImma IImmaR vash IImma IImmaR vash IImma IImmaR vash IImma IImmaR

Fig. 2. RRMSEIDrec of three gene-specific variances estimators, limma, robust
limmaR and our proposed estimator (vash) in the 4 simulation scenarios E-H
with unimodal precision prior

estimates based on oversimpliﬁed assumptions can make estima-

tion accuracy worse rather than better. (In contrast, for small

sample sizes, the beneﬁts of shrinkage greatly outweigh any cost
of oversimpliﬁed assumptions.)

We also note that in scenario B where variances are sampled
from a two component inverse-gamma mixture prior (one ‘majority’
component and one ‘outlier’ component), both vash and limmaR
perform similarly on average (and slightly outperform limma), but
results of vash are slightly more variable than limmaR. Possibly this
reﬂects the fact that limmaR was specifically designed to deal with
such cases.

Another metric for comparing EB methods is in the accuracy of
the estimated prior distribution. We measure this using Dcdf, the
average distance between the estimated and true cumulative distri-
bution functions (cdfs):

1 M
Dcdf 3: M Z lCdftrue  _ Cdffitted(xm)|7 
m=1

where we take xm ranging from 0 to 10 with increment size 0.01.
The results (Supplementary Fig. S1) show that, regardless of sample
size, the estimated mixture prior is consistently as accurate as the
single inverse-gamma prior, and noticably more accurate in scen-
arios C, D and G.

We also compare the final differential expression analysis results.
All genes are ranked by the P-values given by limma, limmaR and
vash (see Section 2.6) respectively. Supplementary Figure 52 shows
the AUC (area under ROC curve) of these methods in simulation
scenarios A—H. The three shrinkage methods perform very similar in
all scenarios.

3.2 Assessment of variances in gene expression data
The results above demonstrate that the more flexible mixture prior
implemented in vash, can in principle provide more accurate vari-
ance and precision estimates than the simple inverse-gamma prior
implemented in limma. However, in practice these gains will only be
realized if the actual distribution of variances differs from the single
inverse-gamma model. Here we examine this issue using RNA
sequencing data from the Genotype-Tissue Expression (GTEx) pro-
ject (Lonsdale et al., 2013). The GTEx Project is an extensive re-
source which studies the relationship among genetic variation, gene
expression, and other molecular phenotypes in multiple human tis-
sues. Here we consider RNA-seq data (GTEx V6 dbGaP accession
phs000424.v6.p1, release date: Oct 19, 2015, http://www.gtexpor
tal.org/homel) on 53 human tissues from a total of 8555 samples
(ranging from 6 to 430 samples per tissues).

Since in practice variance estimation is usually performed as part
of a differential expression analysis (Smyth, 2004), we mimicked
this set-up here: specifically we considered performing a differential
expression analysis between every pair of tissues. We selected the
top 20 000 most highly expressed genes, transformed their read
counts into log-counts-per-million using the ‘voom’ transformation
(Law et al., 2014), and used the lmFit function in the limma package
to estimate the effects and de-trended variances. Since there are 53
tissues this resulted in 1378 datasets of variance estimates.

First, for each dataset, we quantified the improved fit of the mix-
ture prior versus a single component prior by comparing the max-
imum log-likelihood under each prior. (For the mixture prior we
fitted both the unimodal-variance and unimodal-precision priors,
and took the one that provided the larger likelihood.) In principle
the mixture prior log-likelihood should always be larger because it
includes the single component as a special case; we observed rare
and minor deviations from this in practice due to numerical issues.
Across all 1378 datasets the average gain in log-likelihood of the
mixture prior versus the single component prior was 34.1. The 25%
quantile, median, 75% quantile, 90% quantile and maximum of the
difference are given by 2.9, 15.8, 42.9, 77.4 and 705.2 respectively.
A log-likelihood difference of 15.8 is already quite large: for com-
parison the maximum difference in log-likelihood for simulations
under a single component model, Scenario A, df = 50, was 1.9. We
therefore conclude that the mixture component prior fits the data
appreciably better for many datasets.

9mg ‘09 1sn8nV uo salaﬁuV soq ‘121u10111123 10 A11819A1ur1 112 /810'SI12umo[p101x0'soi112u1101u101q/ﬁd11q 111011 papeolumoq

 

 

  
   

 

  
  
     
  

 
 

 

 

 

 

 

 

 

 

    
 
    
 
 

 

 

 

 

 

 

 

 

 

 

 
   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

6 M.Lu and M.Stephens
Cervix-Ectocervix Brain-Anteriorcingulatecortex(BA24) FallopianTube Brain-Anteriorcingu- B rai n_c e r eb e" a r_ F a" o ian Tube vs Adrenal Gland
vs. vs. vs. latecortex vs. III . . p '
Tesﬁs Cewix_End°cewix Skin_N°tsIInExposed(5uprapubic) CervirEndocerva’ emIspherefvs. Stomach, SkIn-NotSflinExposed, vs. Stoinach,
b _ w E _ “=3 E _ d —3 E _ d —3 E _ df—3
 — Mixture Io _ — Mixture 0' ' — Mixture $6 ‘5 d d
g g - --- Single 0 _ --- Single — --- Single E S _ T T T S _ S3 _ S3 _
‘- V o : I I O 0 _I_ _I_ _I_ ‘3 —.— —.— —.—
.9 <1- “: _ o' ' a: _I_ _I_ _I_ I I I . . .
5°" °_ -  é'EEE é'EEE é-EEE
I: . . . . I . I I I . . .
_c_><\1_ N- - g_ + + —— g_ 2'- 2'- 2'- g_ + + + g_ _'_ _:_ _:_
 ° ° — — ° va'sh Iim'maIimrlIaR ° va'sh Iim'maIimr'naR ° va'sh Iim'maIimr'naR ° va'sh Iim'maIimrlIaR
‘- 0. _ 0. _ 0. _
D' o I I I I I I o I I I I I I o I I I I I I _ _
o 1 2 3 4 5 o 1 2 3 4 5 o 1 2 3 4 5 “1'10 41:10 41:10 “1'10
Cervix-Ectocervix Brain-Anteriorcingulatecortex(BA24) FallopianTube Lu  _  '  '  '
vs. vs. vs. ‘0 o ' o ' o ' o '
Testis Cervix-Endocervix Skin-NotSunExposed(Suprapubic) E g ' _I_ ‘1— ‘l‘ g ‘  ‘ I II  ‘
a: _ I ' ' _ _ —-— _._ _,_ _
«2-, .3 I maﬁa o_—~ —— + °_E.' EE o_T T T
153 — ". — Mixture ° 1 — Mixture 0' _ ' — Mixture 3_ : l l g _  E E 3_ —-— _:_ .1. g_   E
g '.I --- Single g _ --- Single )9 _ --- Single gt _ ‘— —i— —i— gt _ T T T g _ ° 3 _ —‘— T T
5 ' II ° ° va'sh Iim'maIimrIIaR ° va'sh Iim'maIimr'naR ° va'sh Iim'maIimr'naR ° va'sh Iim'maIimrIIaR
a ‘r — o' ' 2,1- -
g o III _ “I _ df=50 df=50 df=50 df=50
 _ o o O O O O
m o o o 3 ' 3 ' 3 ' 3 '
>  -  - I I I I I I  - I I I I I I % _ T T _ _ _
o 1 2 3 4 5 o 1 2 3 4 5 go __ El E o o -:- T o
Brain-Amygdala Brain-CerebellarHemisphere AdrenalGland o _I_ ‘L ‘L o _ é é  o _   E o _ é é é
vs. vs. vs. .1. —I— —-— T _l_ _l_ T "‘ —‘—
Brain—Cerebellum Stomach Stomach 8 — I I I 8 — I I I 8 — I I I 8 — I I I
3 ° vash limmalimmaR ° vash limmalimmaR ° vash limmalimmaR ° vash limmalimmaR
 - 'n‘, — Mixture ' — Mixture _ — Mixture
% <1; _ --- Single s1: _ --- Single 2 — Single _ _ _ _ _ _ _
.5 0 0 HQ. 4. RRMSEIDII,c of three gene-speCIfIc varIances estImators, IImma, IImmaR
EN N a! _ and our proposed estimator (vash) in simulation scenarios, which simulate the
o o' - o' ' ° . . . , . . .
2g _ _ _ last four GTEx tIssue paIr comparIsons ( BraIn-AnterIorcmgulatecortex (BA24) vs
ID . . , , - - I l -
a 8 - I I I I I I 8 - I I I I I I 8 - I I I I I I CerVIx-EndocerVIx , BraIn-CerebellarHemIsphere vs Stomach , FallopIan Tube vs
0 1 2 5 4 5 ° 1 2 5 4 5 ° 1 2 5 4 5 Skin-Not Sun Exposed (Suprapubic)’ and ’Adrenal Gland vs Stomach’) in Figure 3
Brain-Amygdala Brain-CerebellarHemisphere AdrenalGland
V5. V5. V5.
Brain—Cerebellum Stomach Stomach
3 - _ The method makes use of a mixture model to allow for a flexible
 _ — Mixture w — Mixture In — Mixture _ _ _ _ _ _ _ _
g g _  Smgle o' -  Smgle o' -  Single family of unimodal prior distributions for either the variances or
‘5 — — . . . .
'3 II - II II prec1s1ons, and uses an accelerated EM-based algorithm to effi-
‘D o' - d _ 0' _ . . . . . . .
 _ _ _ c1ently estimate the underlying prior by max1mum likelihood.
E . . .
> 8 - 8 -I I I I I I 8 -I I . . I I Although slower than lzmma, vash is computationally tractable for
o 1 2 3 4 5 o 1 2 3 4 5

 

Fig. 3. The variance priors (the 2nd and 4th row) and precision priors (the 1st
and 3rd row) fitted by mixture prior model (solid line) or single component prior
model (dashed line) for 6 tissue pair comparisons. The differences in the log-
Iikelihood between the mixture prior model and the single component prior
model for tissue pair comparisons ’Cervix-Ectocervix vs Testis’, ’Brain-
Amygdala vs Brain-Cerebellum’, ’Brain-AnteriorcinguIatecortex (BA24) vs
Cervix-Endocervix’, ’Brain-CerebellarHemisphere vs Stomach’, ’Fallopian Tube
vs Skin-Not Sun Exposed (Suprapubic)’, ’Adrenal Gland vs Stomach’ are given
by 705, 166, 78, 78, 44, 44 respectively (from top-left to bottom-right)

To visualize the deviations from a single component prior pre-
sent in these data, we examine the fitted priors in datasets where the
log-likelihood differences are about 42.9 (75% quantile), 77.4 (90%
quantile) and higher. Figure 3 compares the fitted single component
prior and mixture prior on several typical scenarios. Generally, the
mixture priors use extra components to better fit the middle portion
of distribution. The single component priors can match the tails
pretty well, but often fails to accurately capture the peak.

Overall, our impression from Figure 3 is that differences between
the fitted priors seem relatively minor, and might be expected to
lead to relatively small differences in accuracy of shrinkage esti-
mates, despite the large likelihood differences. To check this impres-
sion we simulated data where the variances are generated from the
fitted mixture priors for four of these datasets (the four datasets on
the right hand side of Fig. 3). Figure 4 compares the RRMSEs of
vash, limma and limmaR in these four scenarios. In general the re-
sults confirm our impression: the three methods perform very simi-
larly in most scenarios, although vash shows some gain in accuracy
in two scenarios with df = 50.

4 Discussion

We have presented a ﬂexible empirical Bayes approach (‘variance
adaptive shrinkage’, or ‘vash’) to shrinkage estimation of variances.

large datasets: for example, for data with 10 000 genes, vash typic-
ally takes about 30 s (limma takes just a few seconds).

Our results demonstrate that vash provides a robust and effective
approach to variance shrinkage, at least in settings where the distribu-
tion of the variances (or precisions) is unimodal. When the true vari-
ances come from a single inverse-gamma prior, vash is no less accurate
than the simpler method. When the variances come from a more com-
plex distribution vash can be more accurate than simpler methods if
the sample sizes to estimate each variance are sufficiently large.

In the gene expression datasets we examined here, the gains in
accuracy of vash versus limma are small, and likely not practically
important. While this could be viewed as disappointing, it nonethe-
less seems useful to show this, since it suggests that in many gene ex-
pression contexts the simpler approaches will suffice. At the same
time, it remains possible that our method could provide practically
useful gains in accuracy for other datasets, and as we have shown, it
comes at little cost. In addition, our work provides an example of a
general approach to empirical Bayes shrinkage—use of mixture
components with a common mode to model unimodal prior distri-
butions—that could be useful more generally.

Our method is implemented in an R package vashr available from
http://github.com/mengyin/vashr. Codes for reproducing analyses and
figures in this paper are at https://github.com/mengyin/vash.

Acknowledgements

We thank the NIH GTEx project for providing RNA-seq datasets. We thank
N. Ignatiadis, W Huber, and two anonymous referees for detailed comments
on the submitted manuscript.

Funding

This work was supported by NIH grant HG0025 85 and by a grant from the
Gordon and Betty Moore Foundation (Grant GBMF #4559).

Conﬂict of Interest: none declared.

9mg ‘09 1sn8nV uo salaﬁuV soq ‘121u101n123 10 A1ISJQAIur1 112 /810'S{12umo[p101x0'soI112u1101quIq//2d11q 111011 papeolumoq

Variance adaptive shrinkage (vash)

 

References

Baldi,P. and Long,A.D. (2001) A Bayesian framework for the analysis of
microarray expression data: regularized t-test and statistical inferences of
gene changes. Bioinformatics, 17, 5 09—519.

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: a
practical and powerful approach to multiple testing. ]. R. Stat. Soc. Ser. B
(Methodological), 57, 289—300.

Broberg,P. et al. (2003) Statistical methods for ranking differentially expressed
genes. Genome Biol., 4, R41.

Dempster,A.P. et al. (1977) Maximum likelihood from incomplete data via
the EM algorithm. ]. R. Stat. Soc. Ser. B (Methodological), 39, 1—38.

Efron,B. (2016) Empirical Bayes deconvolution estimates. Biometrika, 103,
1—20.

Efron,B. et al. (2001) Empirical Bayes analysis of a microarray experiment.
]. Am. Stat. Assoc., 96, 1151—1160.

Law,C.W. et al. (2014) Voom: precision weights unlock linear model analysis
tools for RNA-seq read counts. Genome Biol., 15, R29.

L6nnstedt,I. and Speed,T. (2002) Replicated microarray data. Stat. Sin., 12,
31—46.

Lonsdale,]. et al. (2013) The genotype-tissue expression (GTEx) project. Nat.
Genet., 45, 580—585.

Murie,C. et al. (2009) Comparison of small n statistical tests of differential ex-
pression applied to microarrays. BMC Bioinformatics, 10, 1—18.

Phipson,B. et al. (2016) Robust hyperparameter estimation protects against
hypervariable genes and improves power to detect differential expression.
Annals of Applied Statistics, 10, 946—963.

Smyth,G.K. (2004) Linear models and empirical Bayes methods for assessing
differential expression in microarray experiments. Statistical Applications in
Genetics and Molecular Biology, 3, Article 3.

Stephens,M. (2016) False Discovery Rates: A New Deal. hioinU, p. 038216.

Storey,J.D. (2002) A direct approach to false discovery rates. ]. R. Stat. Soc.
Ser. B (Stat. Methodol.), 64, 479—498.

Storey,J.D. (2003) The positive false discovery rate: a Bayesian interpretation
and the q-value. Ann. Stat., 31, 2013—2035.

Tusher,V.G. et al. (2001) Signiﬁcance analysis of microarrays applied to
the ionizing radiation response. Proc. Natl. Acad. Sci. U. S. A., 98,
5116—5121.

Varadhan,R. and Roland,C. (2004) Squared extrapolation methods
(SQUAREM): A new class of simple and efﬁcient numerical schemes for
accelerating the convergence of the em algorithm. johns Hopkins
University, Dept. of Biostatistics Working Papers. Working Paper 63.

9mg ‘09 1sn8nV uo salaﬁuV sorl ‘121u101n123 10 A1ISJQAIur1 112 /810'S{12umo[p101x0'soI112u1101quIq//2d11q 111011 papeolumoq

