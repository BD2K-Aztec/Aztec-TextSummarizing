ORIGINAL PAPER

Vol. 28 no. 22 2012, pages 2891-2897
doi: 10. 1093/bioinformatics/bts552

 

Sequence analysis

Advance Access publication September 8, 2012

Comparing clustering and pre-processing in taxonomy analysis
Marc J. Bonderl’2’*, Sanne Abeln2, Egija Zaural and Bernd W. Brandt”

1Department of Preventive Dentistry, Academic Centre for Dentistry Amsterdam (ACTA), University of Amsterdam and VU
University Amsterdam and 2Centre for Integrative Bioinformatics (IBIVU), VU University Amsterdam, The Netherlands

Associate Editor: Inanc Birol

 

ABSTRACT

Motivation: Massively parallel sequencing allows for rapid sequencing
of large numbers of sequences in just a single run. Thus, 16S ribo-
somal RNA (rRNA) amplicon sequencing of complex microbial
communities has become possible. The sequenced 16S rRNA frag-
ments (reads) are clustered into operational taxonomic units and taxo-
nomic categories are assigned. Recent reports suggest that data
pre-processing should be performed before clustering. We assessed
combinations of data pre-processing steps and clustering algorithms
on cluster accuracy for oral microbial sequence data.

Results: The number of clusters varied up to two orders of magnitude
depending on pre-processing. Pre-processing using both denoising
and chimera checking resulted in a number of clusters that was closest
to the number of species in the mock dataset (25 versus 15). Based on
run time, purity and normalized mutual information, we could not iden-
tify a single best clustering algorithm. The differences in clustering
accuracy among the algorithms after the same pre-processing were
minor compared with the differences in accuracy among different
pre-processing steps.

Supplementary information: Supplementary data are available at
Bioinformatics online.

Contact: bonder.m.j@gmail.com or b.brandt@acta.nl

Received on July 6, 2012; revised on August 27, 2012; accepted on
September 1, 2012

1 INTRODUCTION

Recent developments in massively parallel sequencing allow for
rapid characterization of a large number of sequences in a single
run. 16S ribosomal RNA (rRNA) amplicon sequencing can
reveal the composition of complex microbial communities
(Schuster, 2008). The unprecedented sequencing depth means
that even less abundant species can be detected via their se-
quences. The taxonomic composition of such samples may be
characterized by grouping the sequence fragments (reads) into
clusters of operational taxonomic units (OTUs).

For many, often uncultivable, microbes, the 168 rRNA
sequences are unknown. To avoid the dependency on incomplete
databases (Cole et al., 2005; Sun et al., 2012), microbial community
composition is typically determined by using a taxonomy-
independent analysis (TIA). In this approach, the 16S rRNA
sequences are compared against each other without directly assign-
ing a taxonomy to the sequence; the number and size of the clusters

 

*To whom correspondence should be addressed.

(OTUs) indicate the diversity of the sample.
Recent benchmark studies have revealed several clustering pro-
grams that adequately cluster into OTUs (Huse et al., 2010;
Schloss and Westcott, 2011; Sun et al., 2012). For this study, we
selected all commonly used clustering approaches implemented in
Quantitative Insights Into Microbial Ecology (QIIME) (Caporaso
et al., 2010), and we also included ESPRIT-Tree as it performed
well in a recent comparison of clustering methods (Sun et al., 2012)
and as well as methods that include rRNA secondary structure
information Wang et al., 2012).

Recent reports suggest that before the clustering step several
data cleaning, or pre-processing, steps should be performed to
correct errors introduced during (pyro)sequencing (Edgar et al.,
2011; Haas et al., 2011; Kunin et al., 2010; Quince et al., 2011;
Reeder and Knight, 2010; Schloss et al., 2011). The two most
important pre-processing steps are denoising, which corrects
errors within the reads based on raw sequencing output (ﬂow-
grams), and chimera checking, which removes chimeric
sequences. The aim of this study is to identify suitable combin-
ations of pre—processing steps and clustering methods for oral
microbial sequence data.

We used two sets of pyrosequenced reads of 168 rRNA to
evaluate cluster accuracies. The ﬁrst set, a mock dataset, had a
known species composition (15 species; Supplementary Table l).
The second set, a clinical dataset, has reads from samples of
human saliva collected in a study on the inﬂuence of Candida
on the composition of the oral microbiome (Kraneveld et al.,
2012).

Assessing the performance of the pre-processing and clustering
combinations is non-trivial, since no gold standard is available
for the taxonomic composition of the samples. In this work, we
use two strategies to assess this performance. First, we take a
simple approach and check whether the number of clusters
agrees with the expected number of species in the mock
sample. The taxonomic composition of the clinical sample may
be approximated by assigning a taxonomic label from a reference
rRNA database to each read.

Second, we assess the clusters based on labelling of sequences.
Therefore, we calculate the purity and normalized mutual infor-
mation (NMI) scores (Press et al., 2007). Purity scores reﬂect the
homogeneity of a cluster. If the majority of the labels in each
cluster are the same, the purity score is high. However, the purity
score does not penalize for the creation of multiple clusters that
contain the same label(s). The NMI score, in addition, reﬂects
the mutual information between the clusters and the taxonomic
labels; a high NMI score is achieved when high purity is reached
with a minimum number of clusters.

 

© The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e—mail: journals.permissions@oup.com 2891

112 /310's113umo [p.IOJXO'SOllBIIIJOJUIOIQ/ﬁdllq 11101; peptaoIHAAoq

9IOZ ‘09 lsnﬁnv uo ::

M.J.Bonder et aI.

 

2 METHODS
2.1 Data

2.1.] Datasets We used a mock and clinical dataset. Both sets were
pyrosequenced (Margulies et al., 2005). Ampliﬁcation was performed
using 16S rRNA PCR primers targeting the V5—V7 hypervariable
region: forward primer 785F (GGATTAGATACCCBRGTAGTC) and
reverse primer 1175R (ACGTCRTCCCCDCCTTCCTC). The primers
included the 454 Life Sciences (Branford, CT, USA) Adapter A (for for-
ward primers) and B (for reverse primers) fused to the 5’ end of the 16S
rDNA bacterial primer sequence and a unique 10 nucleotide molecular
identiﬁcation code.

From the clinical dataset, all samples with at least 1250 reads and at
most 20 000 reads were selected. These thresholds were chosen to exclude
samples with possible errors in sample preparation and over- or under
ampliﬁcation before sequencing.

2.1.2 Reference database A 16S rRNA reference is necessary for
chimera checking (UCHIME), clustering (QIIME BLAST, UCLUST
reference) and for evaluating clustering results. This reference database
was produced by an in Silica ampliﬁcation of the SILVA SSU 16S rRNA
reference database, version 108 (Pruesse et al., 2007). A single nucleotide
mismatch was allowed for each primer and the longest amplicon was
taken in case multiple amplicons were formed from one sequence. The
resulting amplicon sequences were made non-redundant. If identical se-
quences had different taxonomic lineages, the longest shared lineage was
used. A sufﬁx was added if multiple different sequences had exactly the
same lineage.

2.2 Read preparation and pre-processing

QIIME (Caporaso et al., 2010) was used to pre—process the reads. Default
settings were used, except for the following: minimum sequence length:
150; sliding window size: 50; reverse primer removal: truncate_only. The
reverse primer was removed when it was found. Reads with one or more
mismatch to the forward primer were discarded.

Next, the two sets were pre-processed in four different ways: (i) no
cleaning (NC), (ii) chimera checked (CC), (iii) denoised (D) and
(iv) denoised and chimera checked (DCC). This resulted in eight different
test sets for further analysis.

The reads were denoised with denoiser with default settings for
denoising 454 GS FLX Titanium (Reeder and Knight, 2010), which is
now part of QIIME (Caporaso et al., 2010). For chimera checking, we
used UCHIME (Edgar et al., 2011) in both the reference and the de novo
mode. If a read was marked as chimeric in either of the two methods,
the read was ﬁltered out. We used our non-redundant SILVA database
(see above) as the reference for UCHIME.

2.3 Clustering algorithms

The datasets, pre-processed in the four different ways, were all clustered
into OTUs with ﬁve different clustering approaches: UCLUST version
4.2.40 (Edgar, 2010), mothur clustering version 1.6.0 (Schloss et al.,
2009), ESPRIT-Tree beta release September 2011 (Cai and Sun, 2011),
CD-HIT version 3.1.1 (Li and Godzik, 2006) and QIIME BLAST cluster-
ing (QIIME 1.3.0 and BLAST 2.2.22) (Altschul et al., 1990). The QIIME
BLAST clustering approach matches the reads to the closest sequence in
the database and groups the reads based on the BLAST label. For
UCLUST, we used both the de novo mode and the reference mode. For
the ‘denoised and chimera checked’ set, the UCLUST reference optimal
mode was also tested. This method often gives the same output as
UCLUST reference but has a much longer run time (Edgar, 2010). For
mothur, both average and complete linkages were tested. Furthest linkage
is the default, but in a recent study (Huse et al., 2010), it was concluded that
average linkage outperforms furthest linkage. For both BLAST and

UCLUST in reference mode, we used our primer-speciﬁc non-redundant
SILVA rRNA database as reference. Except for the distance, which we set
to 97% sequence identity, we used default settings for the clustering algo-
rithms as these were found to be optimal by the authors of the different
(respective) clustering methods.

2.4 Clustering accuracy

To determine the accuracy of clustering, we labelled the reads with a
taxonomic lineage by BLASTing (Altschul et al., 1997) (BLAST
2.2.25+) all reads to our (trimmed) SILVA reference database (95%
identity threshold). It is not trivial to assign a unique taxonomic label
to a read, since a single read sometimes can be mapped to two labels with
equal BLAST scores (this can also occur at 100% identity and 100%
coverage). To solve this problem, we use either a consensus or a unique
labelling approach. In the consensus approach, the labels were merged to
the highest shared taxonomic category when a query had two or
more hits with equal score. The sufﬁx, added during reference database -
creation, was removed. For instance, when a read is labelled
with: ‘Bac teria;FirmicuteS;Bacilli;Lact0bacillales;Lactobacillaceae_2I ’
and ‘Bacteria,‘FirmicuteS;Bacilli;Lact0bacillaleS;Lactobacillaceae;Lact0-
bacillus_2’, then the label of the sequence in the consensus treatment
becomes: ‘Bacteria;FirmicuteS;Bacilli;Lact0bacillaleS;Lactobacillaceae’.

In the unique approach, all the labels remain unique: if a query had
two or more hits with equal score, they were combined into one header by
adding a separation mark. The headers were always written in alphabet-
ical order. The appended number, which made the header unique, was
not removed in the unique treatment. For instance, if a read is assigned
the same labels as the previous example, the unique treatment would
result in this label: ‘Bacteria;FirmicuteS;Bacilli;Lact0bacillaleS;Lact0-
bacillaceae,‘Lactobacillus_2_ _Bacteria,‘FirmicuteS;Bacilli;Lact0bacillales;
Lactobacillaceae_21’.

Clustering accuracy was evaluated with cluster purity (Press et al.,
2007) and the NMI (Press et al., 2007). For both scoring functions, we
discarded the reads that did not have a label assigned after BLASTing as
there is no obvious way to evaluate clusters, including reads with ‘un-
known’ labels. Cluster purity is calculated as:

1
purity(§2, C) = max lwk ﬂ cjl (1)

where S2 = {w1, w2, . . . , wk} is the set of clusters, C: {C1, c2, . . . , cj} is the
set of classes as deﬁned by the taxonomic labels and N is the total number
of sequences. As a second scoring function, the NMI was used. The NMI
is calculated as:

[(32, C)
[11(9) + H(O]/2

where I(S2,C) is the mutual information gain, H(X) is the entropy.

The NMI and purity were calculated using the lineage returned by
BLAST for both unique and consensus treatments. Depending on the
BLAST results, the lineages can be up to any taxonomic level.

NMI(S2, C) = (2)

3 RESULTS

The accuracy of several clustering algorithms was assessed using
two test sets of sequence reads: a mock dataset and a clinical
dataset. The datasets were pre—processed in four ways: (i) no
cleaning (NC), (ii) chimera checked (CC), (iii) denoised (D)
and (iv) denoised and chimera checked (DCC), for further details
see Methods section. The resulting sets were all clustered using
ﬁve different clustering algorithms: UCLUST, mothur cluster-
ing, ESPRIT-Tree, CD-HIT and QIIME BLAST.

 

2892

112 /310's113umo [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq 11101; peptaoIHAAoq

9IOZ ‘09 lsnﬁnv uo ::

Clustering and pre-processing in taxonomy analysis

 

The clustering results were evaluated in two ways: a consensus
and a unique method (see Methods section). The consensus
method merges the assigned lineages to a highest shared taxo-
nomic level, while the unique method only merges the labels.
Here, the number of unique labels in the unique set is larger
than in the consensus set (Table l). The clustering accuracy
was measured with the purity and the NMI. Below, the results
of the clustering evaluation on the mock and clinical datasets are
presented.

3.1 Mock dataset

The mock community test set contained 15 oral microbial species
(Supplementary Table 1). All pre—processing steps affected the
number of reads and unique reads (Table 1).

First, we compared the total run time of the pre-processing
and clustering algorithms combined (Table 2). The QIIME
BLAST clustering method required the most time. The fastest
QIIME BLAST clustering, on ‘denoised and chimera checked’
data, was around 118 h slower than the other clustering methods
on the same dataset.

Next, the number of clusters formed was compared (Table 3).
Ideally, in a TIA, the number of species is identical to the
number of clusters. However, this was not the case. Even
the lowest number of clusters (25) was 66% higher than
expected (15), based on the number of species in the mock.
Furthermore, the effect of denoising is much larger than chimera
checking on both the number of clusters and the number of
unique reads (Tables 1 and 3).

Since the composition of the mock set is known, we also tested
whether all taxa present in the mock could be identiﬁed (using

the consensus taxonomic labels). It was not always possible to
unambiguously assign a taxonomic lineage, including the species
level, by BLASTing the reads against our reference database.
However, this was mainly caused by the extensive reference data-
base and not by the reads themselves. For most species, even in
silico produced amplicons match more than two species in our
reference database (with the same score and at 100% identity).
For example, the Streptococcus mutans amplicon is 100% iden-
tical to Streptococcus uncultured Streptococcus sp. and Strepto-
coccus uncultured bacterium, allowing only the assignment of the
genus name. Most importantly, all 10 genera present in the mock
could be found after any pre—processing of the data. Next, we will
evaluate the different clustering methods and pre—processing
steps based on consensus and unique labelling of the reads.

3.1.1 Consensus labelling of reads The cluster purities depend
on the speciﬁc clustering algorithm and on the pre—processing
approach (Fig. 1A). The clusters based on ‘denoised and chimera
checked’ data had the highest purity. The clustering methods
QIIME BLAST, ‘UCLUST reference’ and ‘UCLUST reference
optimal’ resulted in a cluster purity of one while the others were
very close to one. The purity showed a larger variation for the
other pre—processing steps, especially when the data was not
denoised (Fig. 1A). It should be noted that high purity is easier
to acquire when the number of clusters is high. Indeed, a positive
correlation between the number of clusters and the purity was
observed. However, for mothur clustering with average linkage,
this was not the case. The NMI shows a similar trend (Fig. 1B):
the ‘denoised and chimera checked’ data again showed superior
scores. CD-HIT, ESPRIT-Tree and UCLUST were the best
performing clustering algorithms on this dataset with a score

Table 1. Comparison of the number of total reads, non-redundant (unique) reads, removed reads, number of reads without a label and number of labels

for each pre-processing method on the mock set

 

 

Pre—processing No. of reads No. of unique reads No. of removed No. of reads No. of No. of
reads labelled as unknown unique labels consensus labels
NC 38612 11618 0 371 637 106
CC 33375 8431 5237 15 390 61
D 38612 190 0 192 85 42
DCC 34885 45 3727 18 29 23

 

NC stands for no cleaning, CC stands for chimera checked, D stands for denoised and DCC stands for denoised and chimera checked.

Table 2. Comparison of the total run time of the clustering algorithms and pre-processing methods on the mock dataset

 

Pre—processing

Clustering algorithms

 

 

QIIME BLAST CD-HIT ESPRIT-Tree Mothur Mothur UCLUST UCLUST ref UCLUST
furthest average ref optimal
NC 141:49:27 0:18:00 0:15:48 2:44:30 3:19:13 0:12:59 0:14:53
CC 138:53:15 14:56:23 14:57:23 15:54:17 16:06:13 14:54:51 14:56:06
D 140:28:04 1:44:09 1:42:55 1:42:54 1:42:55 1:42:55 1:43:21
DCC 120:09:04 1:56:46 1:56:17 1:56:17 1:56:18 1:56:18 1:56:41 1:59:03

 

Run time is given in hours:minutes:seconds.

 

2893

112 /810's112u1no [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq U101} pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

M.J.Bonder et aI.

 

Table 3. Comparison of the number of clusters formed for each clustering algorithm and pre—processing method

 

Pre-proces sing

Clustering algorithms

 

 

 

QIIME BLAST CD-HIT ESPRIT-Tree Mothur Mothur UCLUST UCLUST ref UCLUST ref
furthest average optimal
NC 562 485 328 3286 2236 379 651
CC 288 131 66 2107 1373 77 323
D 95 112 104 155 154 104 124
DCC 30 25 25 38 38 25 31 31
Am purityconsensus 1930 NM. 3.2 Clinical dataset
0:91 0.91 The same evaluations of clustering as above were performed on
0.82 0.82 the clinical dataset. For the two most time-consuming methods,
namely mothur and QIIME BLAST, we made the reads
073 0‘73 non-redundant before clustering; after clustering, the reads
“4 0'64 were reinﬂated to the input sample size. The time it took to
0-55 BLAST co..." agmtfmhhmmommucwaucasrgc.uaI 0-55 m cm envoy: mothurucwauaufswfcuiaI make the reads unique and to inﬂate was included in the total
C   re r mm D   re m cm run time of mothur and QIIME BLAST OTU picking methods.
1°" "0° In addition, a distance cutoff (5% for furthest linkage and 15%
0-91 0-9‘ for average linkage) was used during the distance matrix calcu-
0~82 0.82 lation in mothur, such that this matrix still ﬁts in memory. In
0.73 0.73 both cases, clustering was performed at 97% sequence identity.
054 064 For mothur average, the matrix was still too large for the NC

0.55
BLAST CD-HIT ESPRIT— mothur mothur UCLUST UCLUST UCLUST

Tree furthest average ref ref optimal

55
BLAST CD-HIT ESPRIT— mothur mothur UCLUST UCLUST UCLUST
Tree furthest average ref ref optimal

- Denoised and Chimera Checked - Denoised - Chimera Checked - No Cleaning

Fig. 1. The purity and NMI scores for the consensus and unique treat-
ments on the mock dataset. (A) Consensus purity, (B) consensus NMI,
(C) unique purity and (D) unique NMI

of 0.94. All results for the consensus read labelling are shown in
Supplementary Table 2.

Among the different pre—processing steps, the’denoised and
chimera checked’ pre—processing showed the best results. Based
on purity, NMI scores and run time, CD—HIT, ESPRIT-Tree
and UCLUST performed equally well after this pre-processing
(NMI of 0.94, purity of almost 1 and 25 clusters).

3.1.2 Unique labelling of reads As in the consensus read label-
ling, the average purity and NMI was highest for the ‘denoised
and chimera checked’ pre—processing (Fig. 1). UCLUST in ref-
erence modes and mothur resulted in the best purity scores
(about one). However, both the NMI scores and the number
of clusters showed that mothur formed too many clusters. Out
of the non-reference based cluster methods, CD-HIT,
ESPRIT-Tree and UCLUST perform similarly well based on
purity, NMI and number of clusters.

The average cluster purity was generally lower in the unique
than in the consensus read labelling. The average NMI scores,
for all pre—processing steps, were higher in the unique than in the
consensus read labelling. Both are consequences of the higher
number of unique labels in the unique set, which is due to mer-
ging the labels differently. The complete results of the unique
read labelling are shown in Supplementary Table 3.

and CC set.

The four different pre-processing steps resulted in different
numbers of (unique) reads (Table 4). Denoising was the most
time-consuming step (~552 CPU hours). The QIIME BLAST
clustering method required the most time while only clustering
the unique reads. The run times of the pre—processing procedures
and clustering methods are shown in Table 5.

Since the species composition of clinical data is unknown, the
correct number of clusters is unknown. However, there was a
large difference in the number of clusters formed, especially
among the pre—processing methods (Table 6). The number of
unique reads decreased enormously after denoising or chimera
checking, but especially after doing both. When one compares
the decrease in number of unique reads per clusters between the
mock and the clinical set after each cleaning step, a similar trend
can be observed. Roughly the same decrease in number of clus-
ters per unique read is observed.

3.2.1 Consensus labelling of reads The cluster purity for all
the clustering algorithms and the different pre-processing
approaches are shown in Figure 2A and B. The ‘denoised and
chimera checked’ data had overall the highest purity and NMI
scores, as was the case for the mock set. The clustering methods
‘UCLUST reference’ and ‘UCLUST reference optimal’ had the
highest purity (about one). Out of the non-reference based cluster
methods, ESPRIT-Tree and UCLUST perform similarly well
when combining purity, NMI scores and number of clusters.
The complete consensus results are in Supplementary Table 4.

3.2.2 Unique labelling of reads As with the consensus
treatment, generally, the purity and NMI scores were highest
for the ‘denoised and chimera checked’ pre-processing

 

2894

112 /810's112umo proJIxo'soi112u1101uioiq//:d11q U101} pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Clustering and pre-processing in taxonomy analysis

 

Table 4. Comparison of the number of total reads, non-redundant (unique) reads, removed reads, number of reads without a label and number of labels

for each pre-processing method on the clinical set

 

 

Pre—processing No. of reads No. of unique No. of removed No. of reads labelled No. of No. of
reads reads as unknown unique labels consensus labels
NC 496 149 110 508 0 11449 2754 854
CC 391136 61571 105013 731 1850 62
D 496 148 2933 1 7702 1109 33
DCC 418469 591 77 680 517 356 200

 

Table 5. Comparison of the total run time of the clustering algorithms and pre-processing methods on the clinical dataset

 

Pre—procesing

Clustering algorithms

 

 

 

 

 

 

QIIME BLAST CD-HIT ESPRIT-Tree Mothur Mothur UCLUST UCLUST ref UCLUST ref
furthest average optimal
NC 426:49207 13:41:22 4:51:37 19:01:07 * 2:51:17 2:46:40
CC 407:55:49 179:14:54 176:09:02 181:12:24 * 175:23:37 175:25:18
D 566:02:45 555:59:20 555:06:41 555:05:36 555:05:34 555:05:15 555:06:39
DCC 560:17:08 558:37:20 558:18:45 558:18208 558:18:04 558:18:04 558:18:35 560:22:45
Run time is given in hours:minutes:seconds. *Mothur average could not be used for the NC and CC set.
Table 6. Comparison of the number of clusters formed for each clustering algorithm and pre-processing method
Pre—processing Clustering algorithms
QIIME BLAST CD-HIT ESPRIT-Tree Mothur Mothur UCLUST UCLUST ref UCLUST ref
furthest average optimal
NC 3915 8985 7299 28711 * 7707 9517
CC 1874 1585 1018 11932 * 1091 2784
D 1048 2031 1941 2364 2314 1971 2112
DCC 309 332 306 458 453 318 421 425

 

*Mothur average could not be used for the NC and CC set.

(Figure 2C and D). Interestingly, for CD-HIT, the NMI was
(marginally) higher for the ‘denoised’ data than for the ‘denoised
and chimera checked’ data. ‘UCLUST reference optimal’ and
‘UCLUST reference’ performed the best with the purity very
close to one. Based on the NMI, the highest scoring algorithms
were ‘UCLUST reference optimal’ and ‘UCLUST reference’
(NMI very close to one). The complete results of the unique
read labelling are shown in Supplementary Table 5.

4 DISCUSSION

We compared different pre-processing and clustering methods
with respect to the clustering of sequences into OTUs. The dif-
ferent pre—processing methods showed clear differences in the
number of clusters that were formed.

The ‘denoised and chimera checked’ data formed the number
of clusters that was closest to the number of species in the mock.

The cluster algorithms formed minimally 25 clusters (Table 3),
whereas 15 species were present in the mock community.

In the clinical dataset, we observed around 300—450 clusters
after denoising and chimera checking. When using only one of
the two pre—processing methods, 1000—3000 clusters were
formed. Without any pre-processing, the number of clusters
reached beyond 7000. As with the mock community data, in
the clinical dataset clustering the ‘denoised and chimera checked’
data performed best if the NMI and purity scores were used as
the quality criterion. The actual number of valid clusters in the
clinical dataset is unknown. Based on cloning and traditional
Sanger sequencing, currently, there are 600—1200 species reported
that are associated with the human oral microbiome (Dewhirst
et al., 2010; Paster et al., 2001). However, the oral microbiome
diversity is estimated to be at least an order of magnitude higher
based on data from high-throughput sequencing approaches
(Keijser et al., 2008; Yang et al., 2012). Considering the decreas-
ing number of clusters in the mock set in relation to increasing

 

2895

112 /810's112u1no [p.IOJXO'SOIlBIIIJOJUIOIQ/ﬁdllq U101} pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

M.J.Bonder et al.

 

A Purity consensus B NMI consensus
1.00 1.00
0.89 0.89
0.78 0.78
0.67 0.67
O 56 0.56
0.45 45
BLAST CD-HIT ESPRIT- mothur mothur UCLUST UCLUST UCLUST BLAST CD-HIT ESPRIT- mothur mothur UCLUSTUCLUST UCLUST
Tree furthest average ref ref optimal Tree furthest average ref ref optimal
C Purity unique D NMI unique
1.00 1.00
0 89 0 89
0 78 0 78
0 67 0.67
0.56 0.56
0.45 0.45

BLAST CD-HIT ESPRIT— mothur mothur UCLUST UCLUST UCLUST
Tree furthest average ref ref optimal

BLAST CD-HIT ESPRIT— mothur mothur UCLUST UCLUST UCLUST
Tree furthest average ref ref optimal

- Denoised and Chimera Checked - Denoised - Chimera Checked - No Cleaning

Fig. 2. The purity and NMI scores for the consensus and unique treat-
ments on the clinical dataset. Mothur average could not be used for the
NC and CC set. (A) Consensus purity, (B) consensus NMI, (C) unique
purity and (D) unique NMI

read pre—processing and a similar trend in the reduction of
number of clusters in the clinical set, it is likely that the previous
estimates are at the higher end of the actual diversity. We observe
the same overestimation in microbial diversity as the authors of
pre-clustering (Huse et al., 2010) and denoising algorithms
(Quince et al., 2011; Reeder and Knight, 2010).

The differences in the NMI and purity scores for the clustering
methods are minor when compared with the differences for the
pre-processing methods. The UCLUST reference-based methods
generally outperform the other methods based on the NMI
score, while the purity scores were also high. Both suggest that
the UCLUST reference methods are the methods of choice.
However, it is important to note that these methods form a
larger number of clusters than expected and larger than the min-
imal number of clusters found and use the same reference data-
base on which the taxonomic labels are based, making such a
statement too bold. In general, UCLUST and ESPRIT-Tree
came out top among the non-reference based methods. They
showed a similar performance based on purity and NMI
scores, while giving the lowest number of clusters.

A reference database is required for chimera checking in ref-
erence mode and for UCLUST in the reference modes. Here, we
used a trimmed and non-redundant reference, which greatly re-
duces run times (Brandt et al., 2012). In this study, we did not use
the trimmed set for training a classiﬁer, but it has been found
that this improves taxonomic classiﬁcation (Werner et al., 2012).

The majority of the mock reads (99.8%) has been labelled with
expected lineages. Although the mock contains 15 species, we do
not expect 15 clusters. The V5—V7 regions of Streptococcus mitis
and Streptococcus oralis are almost identical (99 - 100%). Thus,
the expected number of clusters is (at least) 14. The different
clustering algorithms returned 25 clusters at best. However, 11
of these 25 clusters have very few members (four are even single-
tons). If we use a relaxed threshold on cluster size of only >18
members, indeed, the 14 expected clusters remain. Given the
relatively large number of very small clusters, we do not expect

this to generalize to a clinical sample. While a threshold on clus-
ter size is more difﬁcult to determine for a clinical sample, very
small clusters (e.g. with less than ﬁve members) could also be
disregarded here (onk et al., 2012), though at the risk of under-
estimating diversity.

The determination of the microbiome, based on a few hyper-
variable regions of the 16S rRNA gene, makes it difﬁcult to
differentiate between several taxa on species level or even genus
level. Furthermore, the sequencer creates errors (noise), which
makes it even more difﬁcult or impossible to differentiate be-
tween related species, such as Streptococcus species. In such
cases, denoising, to ﬁlter out errors created by the sequencer,
may regard the small differences between sequences as noise.
Thus, pyrosequencing (a region of) 16S rRNA can distinguish
between different genera or species, possibly in combination with
denoising, only when sequences of the related taxa differ enough.

It is important to note that denoising, chimera checking and
clustering methods are context dependent: the result for a single
read depends on the entire input set. This is speciﬁcally relevant
for denoising of data from large studies, since it is typically done
on several input ﬁles, like in this study. For example, similar
sequences in one ﬁle can be denoised to Sequence A, while in
another he denoised to Sequence B, simply because Sequence A
is more dominant in the one ﬁle and Sequence B in the other.

There was a remarkable difference in the number of reads
discarded by chimera checking before and after denoising. On
average, there was a 27% decrease in the number of non-unique
reads when denoising was performed ﬁrst. Moreover, denoising,
which can also be seen as a pre-clustering step, has a huge inﬂu-
ence on the number of clusters generated. However, denoising
differs from the (other) clustering methods as it takes ﬂowgram
data into account. This potentially allows denoising to differen-
tiate between true sequence differences and sequencing noise.
The results of this study and other studies (Kunin et al., 2010;
Schloss et al., 2011; Schloss and Westcott, 2011) suggest that it
remains important to further investigate combinations of
pre—processing steps.

We ﬁnd that the number of OTUs varies between one and two
orders of magnitude depending pre—processing methods and clus-
tering algorithms. Using a single-species reference (Escherichia
coli), it was found that stringent ﬁltering and low clustering
thresholds should be applied to prevent overestimation of diver-
sity (Kunin et al., 2010): unﬁltered reads overestimated the
number of OTUs by two orders of magnitude (Kunin et al.,
2010). With respect to technical variation, pre-processing and
reduction of error rate, the thorough work of Schloss et al.
(2011) on mock communities is interesting. They also report
that ﬁltering (sliding window quality ﬁlter or denoising combined
with chimera removal) is required to reduce the number of OTUs
closer to the number of expected OTUs. Even after a 30-fold
reduction in sequencing error rate, the number of expected
OTUs and genera was not obtained (Schloss et al., 2011).
More recently, it was also recommended to remove pyrosequen-
cing errors and chimeras before clustering (Jiang et al., 2012).

While we could not identify a single best clustering algorithm,
CD-HIT, ESPRIT-Tree and UCLUST perform well. In another
study, UCLUST also performs well and comparable to CD-HIT
but is outperformed by an average neighbour algorithm (Schloss
and Westcott, 2011). ESPRIT-Tree, an average linkage-based

 

2896

112 /810's112umo proJIxo'soi112u1101uioiq//:d11q U101} pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Clustering and pre-processing in taxonomy analysis

 

hierarchical clustering algorithm, was found to outperform
CD-HIT, UCLUST and mothur (average linkage) in another
benchmark study (Sun et al., 2012).

In summary, we tested four pre—processing methods and mul-
tiple clustering algorithms to cluster sequences into OTUs. By
combining these steps, we assessed the inﬂuence of read ﬁltering
on clustering. We showed that cleaning inﬂuences the number of
OTUs much more when compared with the different clustering
methods. The pre—processing method that resulted in the highest
NMI, the highest purity and the number of clusters closest to the
expected number of clusters was the combination of denoising
with chimera checking.

Our results give strong evidence that without pre-processing
steps the data contains too many errors in order for any cluster-
ing algorithm to perform well. This warrants further investiga-
tion in pre-processing techniques that allow for the correction of
such errors, as more accurate pre—processing will have a larger
effect than improving current clustering techniques.
Alternatively, integrated approaches may be investigated.

ACKNOWLEDGEMENTS

The authors thank Eefje Kraneveld, Mark Buijs and Jessica
Koopman for providing the sequence datasets.

Funding: University of Amsterdam under the research priority
area ‘Oral Infections and Inﬂammation’ and the Netherlands
Organisation for Scientiﬁc Research (N WO) (to SA.)

Conﬂict of Interest: none declared.

REFERENCES

Altschul,S.F. et al. (1997) Gapped BLAST and PSI-BLAST: a new generation of
protein database search programs. Nucleic Acids Res, 25, 3389—3402.

Brandt,B.W. et al. (2012) TaxMan: a server to trim rRNA reference databases and
inspect taxonomic coverage. Nucleic Acids Res., 40, W82—W87.

Cai,Y. and Sun,Y. (2011) ESPRIT-Tree: hierarchical clustering analysis of millions
of 16S rRNA pyrosequences in quasilinear computational time. Nucleic Acids
Res., 39, 695.

Caporaso,J.G. et al. (2010) QIIME allows analysis of high-throughput community
sequencing data. Nat. Methods, 7, 335—336.

Cole,J.R. et al. (2005) The Ribosomal Database Project (RDP-II): sequences and
tools for high-throughput rRNA analysis. Nucleic Acids Res., 33, D294—D296.

Dewhirst,F.E. et al. (2010) The human oral microbiome. J. Bacterial, 192,
5002—5017.

Edgar,R.C. (2010) Search and clustering orders of magnitude faster than BLAST.
Bioinformatics, 26, 2460—2461.

Edgar,R.C. et al. (2011) UCHIME improves sensitivity and speed of chimera de-
tection. Bioinformatics, 27, 2194—2200.

Haas,B.J. et al. (2011) Chimeric l6S rRNA sequence formation and detection in
Sanger and 454-pyrosequenced PCR amplicons. Genome Res., 21, 494—504.
Huse,S.M. et al. (2010) Ironing out the wrinkles in the rare biosphere through

improved OTU clustering. Environ. Microbial., 12, 1889—1898.

Jiang,X.T. et al. (2012) Two-stage clustering (TSC): a pipeline for selecting oper-
ational taxonomic units for the high-throughput sequencing of PCR amplicons.
PLaS ONE, 7, 630230.

Keijser,B.J.F. et al. (2008) Pyrosequencing analysis of the oral microﬂora of healthy
adults. J. Dent. Res., 87, 1016—1020.

Kraneveld,E.A. et al. (2012) The relation between oral Candida load and bacterial
microbiome proﬁles in Dutch older adults. PLaS ONE, 7, 642770.

Kunin,V. et al. (2010) Wrinkles in the rare biosphere: pyrosequencing errors can
lead to artiﬁcial inﬂation of diversity estimates. Environ. M icrabial., 12, 118—123.

Li,W. and Godzik,A. (2006) Cd-hit: a fast program for clustering and comparing
large sets of protein or nucleotide sequences. Bioinformatics, 22, 1658—1659.

Margulies,M. et al. (2005) Genome sequencing in microfabricated high-density
picolitre reactors. Nature, 437, 376—380.

Ozok,A.R. et al. (2012) Ecology of the microbiome of the infected root canal
system: a comparison between apical and coronal root segments. Int. Endad.
J., 45, 530—541.

Paster,B.J. et al. (2001) Bacterial diversity in human subgingival plaque. J.
Bacterial., 183, 3770—3783.

Press,W.H. et al. (2007) Numerical Recipes: The Art of Scientific Computing.
Cambridge University Press, NY, USA.

Pruesse,E. et al. (2007) SILVA: a comprehensive online resource for quality checked
and aligned ribosomal RNA sequence data compatible with ARB. Nucleic Acids
Res., 35, 7188—7196.

Quince,C. et al. (2011) Removing noise from pyrosequenced amplicons. BM C
Bioinformatics, 12, 38.

Reeder,J. and Knight,R. (2010) Rapidly denoising pyrosequencing amplicon reads
by exploiting rank-abundance distributions. Nat. Methods, 7, 668—669.

Schloss,P.D. et al. (2011) Reducing the effects of PCR ampliﬁcation and sequencing
artifacts on 168 rRNA-based studies. PLaS ONE, 6, 627310.

Schloss,P.D. and Westcott,S.L. (2011) Assessing and improving methods used in
operational taxonomic unit-based approaches for 168 rRNA gene sequence
analysis. Appl. Environ. M icrabial., 77, 3219—3226.

Schloss,P.D. et al. (2009) Introducing mothur: open-source, platform-independent,
community-supported software for describing and comparing microbial com-
munities. Appl. Environ. M icrabial., 75, 7537—7541.

Schuster,S.C. (2008) Next-generation sequencing transforms today’s biology. Nat.
Methods, 5, 16—18.

Sun,Y. et al. (2012) A large-scale benchmark study of existing algorithms for
taxonomy-independent microbial community analysis. Brief. Biainfarm., 13,
107—121.

Wang,X. et al. (2012) Secondary structure information does not improve OTU
assignment for partial l6s rRNA sequences. ISME J., 6, 1277—1280.

Werner,J.J. et al. (2012) Impact of training sets on classiﬁcation of high-throughput
bacterial l6s rRNA gene surveys. ISME J., 6, 94—103.

Yang,F. et al. (2012) Saliva microbiomes distinguish caries-active from healthy
human populations. ISME J., 6, 1—10.

 

2897

112 /810's112u1no [progxo'sor1nu1101urorq//:d11q urorar pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

