ORIGINAL PAPER

Vol. 26 no. 11 2010, pages 1423-1430
doi: 10. 1093/bioinformatics/btq 162

 

Gene expression

Advance Access publication April 15, 2010

A hidden Markov support vector machine framework
incorporating profile geometry learning for identifying microbial

RNA in tiling array data

Wen-Han Yum, Hedda Hovik3 and Tsute Chen“

1Department of Molecular Genetics, The Forsyth Institute, Boston, MA 02115, 2Bioinformatics Graduate Program,
Boston University, Boston, MA 02118, USA and 8Department of Oral Biology, Faculty of Dentistry, University of Oslo,

Oslo, Norway
Associate Editor: Ivo Hofacker

 

ABSTRACT

Motivation: RNA expression signals detected by high-density
genomic tiling microarrays contain comprehensive transcriptomic
information of the target organism. Current methods for determining
the RNA transcription units are still computation intense and lack the
discriminative power. This article describes an efficient and accurate
methodology to reveal complicated transcriptional architecture,
including small regulatory RNAs, in microbial transcriptome profiles.
Results: Normalized microarray data were first subject to support
vector regression to estimate the profile tendency by reducing
noise interruption. A hybrid supervised machine learning algorithm,
hidden Markov support vector machines, was then used to classify
the underlying state of each probe to ‘expression’ or ‘silence’
with the assumption that the consecutive state sequence was a
heterogeneous Markov chain. For model construction, we introduced
a profile geometry learning method to construct the feature vectors,
which considered both intensity profiles and changes of intensities
over the probe spacing. Also, a robust strategy was used to
dynamically evaluate and select the training set based only on prior
computer gene annotation. The algorithm performed better than
other methods in accuracy on simulated data, especially for small
expressed regions with lower (<1) SNR (signal-to-noise ratio), hence
more sensitive for detecting small RNAs.

Availability and implementation: Detail implementation steps of the
algorithm and the complete result of the transcriptome analysis for a
microbial genome Porphyromonas gingivalis W83 can be viewed at
http://bioinformatics.forsyth.org/mtd

Contact: tchen@forsyth.org

Received on 15 January 2010; revised on 22 March 2010; accepted
on 9 April 2010

1 INTRODUCTION

Current microarray manufacturing technology can synthesize
millions of oligonucleotide probes in situ on a single microscopic
glass slide. This great capacity of probes allows the design
of genomic tiling microarrays containing probes covering both
sense and antisense strands with a great frequency for most
microbial genomes (Akama et al., 2009; Selinger et al., 2000;

 

*To whom correspondence should be addressed.

Tjaden et al., 2002) as well as many eukaryotic genomes (Bertone
et al., 2004; David et al., 2006; Kapranov et al., 2002; Li et al., 2007;
Schadt et al., 2004; Selinger et al., 2000; Stolc et al., 2004; Yamada
et al., 2003). These high—density genomic tiling arrays can be used to
detect the expression for all RNA species including protein coding
RNAs and non—coding RNAs (ncRNAs).

Although becoming popular, the data analysis for expression
data obtained from the high—density tiling microarrays remains to
be challenging. A fundamental task is how to precisely identify
expression from noisy background. One common approach has been
to segment the probe signals along the genomic coordinates. The
assumption of this approach is that intensities within a transcript
distribute as Gaussian noise. Thus, the breakpoints detected by
the abrupt changes between two adjacent segments may represent
the boundaries of the RNA transcripts. A segmentation algorithm
(Bai and Perron, 2003; Huber et al., 2006; Picard et al., 2005)
was developed to model the signal distribution that ﬁtted Gaussian
noise. Finding an optimal set of breakpoint locations that minimized
the sum of squared residuals was accomplished by the dynamic
programming algorithm with a ﬁxed number of segments. However,
it is not robust to estimate the total number of segments. Also, long
computation time 0(nzS) was required, where S is the number of
segments and n is the genome size. For this, Huber et al. (2006)
attempted to simplify the complexity of the algorithm with ﬁxed
maximum length l of segment and reduced the computation time
to 0(nlS). The determination of expression status for each segment
relied, however, on a ﬁxed cutoff value (David et al., 2006), which
may overlook RNA with low expression level.

A supervised learning algorithm using Hidden Markov Models
(HMMs) has been introduced to directly distinguish transcribed and
non—transcribed regions (Du et al., 2006; Li et al., 2005; Munch
et al., 2006). This approach successfully incorporated validated
biological knowledge into the model, instead of only considering
the signal distribution that might be biased by noises or system
errors. By given a training set, HMMs constructs a probabilistic
model that connects the hidden states to the observables as well as
to the adjacent states. Viterbi algorithm is then used to compute the
most likely hidden state sequence. However, higher order HMMs
are known to be a better model to describe the dependency between
neighbors than typical ﬁrst—order HMMs, although it has not been
applied widely due to the complexity and computational demands.
In addition, several limitations of the conventional HMMs have

 

© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org 1423

112 /§JO'SIBUJn0[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁdnq mm; pepBOIUAAOG

9IOZ ‘Ig1sn8nv I102:

W.-H.Yu et aI.

 

been noted, such as that it typically trains a conditional probabilistic
model rather than a discriminative hyperplane, and it lacks the power
of processing highly dimensional feature vectors which represent the
observed input sequence (Rabiner, 1989).

A different classiﬁcation algorithm, support vector machines
(SVMs) (Cortes and Vapnik, 1995) providing a discriminative
model, has been commonly used in various biological applications,
such as the classiﬁcation of the normal and cancer tissues from
microarray expression data (Furey et al., 2000). SVMs are capable
of ﬁnding a linear discriminative hyperplane for classiﬁcation in
a high—dimensional feature space, projected from the input object
space by either linear or non—linear mapping via the kernel functions.
However, the classiﬁcation of individual object only estimates from
the corresponding feature vectors. This approach is inappropriate
for interpreting the transcriptome data directly because conditional
dependency of the neighbors along the sequence needs to be
considered as well.

To take advantage of both learning algorithms, we implemented
a novel discriminative algorithm ‘hidden Markov support vector
machines’ (HM—SVMs). HM—SVMs combines HMMs and SVMs
(Altun et al., 2003; Joachims et al., 2009; Zeller et al., 2008)
and retains the Markov chain dependency structure between the
hidden states as well as the efﬁciency of dynamic programming
by Viterbi algorithm. Additional important components inherited
from SVMs are also retained. The discriminative hyperplane is
learned by kernel functions and determined by the maximum—margin
principle with soft margin violation adjustment. At the same time,
HM—SVMs show the capability to handle high—dimensional feature
vectors and overlapping features. As a result, the input data of the
HM—SVMs for feature vector construction can be readily extended
through incorporating multiple experimental validated data. Zeller
et al. (2008) implemented a similar SVM discriminative technique
to analyze Arabidopsis thaliana tiling data. They modeled the exon—
intron expression mechanism speciﬁc to the eukaryotes, which
may not be suitable to the operon expression mechanism of the
prokaryotes. In addition, recent tiling array probe design methods
generate probe sets with unequal probe spacing (Hovik and Chen,
2010), therefore a probabilistic model that considers both intensity
proﬁle and change of intensity across the probe location will be more
adequate for describing the transcriptome proﬁle detected with such
probe design. In this study, we constructed a heterogeneous HMM
model with proﬁle geometry learning to include both intensity proﬁle
and positional changes. Together with normalization and dynamic
training data screening, we present a comprehensive and robust
methodology for predicting the occurrence of the transcription
units across the genomic sequence on both strands from the tiling
array expression data. We used this new method to study the
architecture and dynamics of transcription activity of a model
organism, Porphyromonas gingivalis W83, which is an important
periodontal pathogen.

2 MATERIALS AND METHODS
2.1 Experimental data

Microarrays used in this study were fabricated by Roche NimbleGen, Inc.
(Madison, WI, USA) and each contained 385 000 unique 50mer sequences
covering both sense and antisense strands of the entire genome of P. gingivalis
W83 at a frequency of ca. one probe per 12 bases in average. Probe
sequences were designed by using a dynamic genomic tiling array probe

design pipeline (Hovik and Chen, 2010). The probe set can be downloaded
from http://bioinformatics.forsyth.org/mtd.

Total RNA and genomic DNA were extracted from Rgingivalis W83
grown on TSA sheep blood agar plates containing Hemin and Vitamin K
(BAPHK) for 2 days in an anaerobic chamber at 37°C (Duncan et 01.,
1993), and were labeled with Label IT uArray Cy3 Labeling Kits (Mirus
Bio LLC, Madison, WI, USA). Microarray hybridizations were performed
at 42°C for 16h in the chamber with the Long Oligo hybridization buffer
[80 mM Tris—HCl, pH 7.0, 8 mM ethylenediaminetetraacetic acid (EDTA),
25% formamide, 5x SSC (75mM Trisodium Citrate, 750mM Sodium
Chloride), 0.1% sodium dodecyl sulfate, 0.7 mg/ml salmon sperm DNA].
Post—hybridization procedures including array washing and signal acquisition
were done according to Nimblegen’s manufacturer protocol. Three biological
replicates for both RNA and DNA samples were used for data analysis.

2.2 Data normalization

Raw microarray intensities were adjusted with data from DNA reference
arrays using the Bioconductor package ‘tilingArray’ under R statistical
programming environment (Huber et al., 2006). A variety of factors affect the
range of hybridization signals including different thermodynamic properties
imposed by probe sequences (Royce et al., 2005), biases in labeling
efﬁciency and the abundance of target sequences. The abundance of target
molecule y;j can be modeled as,

/ Yij —Bi
y.) Ai ( 1)
where yl-j is the observed intensity of i—th probe on the j—th array, B,- is
the unspeciﬁc background ﬂuorescence and A,- is the proportional factor
speciﬁc to the abundance of  The unknown parameters A,- and B,- were
estimated directly or indirectly from the corresponding genomic DNA
reference intensities. Non—speciﬁc background for B,- was estimated from
80% of the probes with lowest intensities in the intergenic regions of the
genome. The probe intensities with repeated sequences in the genome were
regressed to the level equivalent to that of a single copy of the sequence.
Between—array normalization (Huber et al., 2002) included in the tilingArray
package was used for adjusting systematic signal variations among the arrays
and base 2 logarithm of probe intensities were scaled.

2.3 Signal noise reduction by support vector regression
normalization

We applied SVMs (Cortes and Vapnik, 1995) to intensity regression
implemented by the ‘kemlab’ package in R (Karatzoglou et al., 2004). The
SVMs is a kemel—based machine learning algorithm. It maps the input data
x into a high—dimensional feature space H deﬁned by a kernel function and
then searches for a hyperplane, i.e. a linear relation f (x), among the data
points in the feature space:

f(x)=<w,<l>(x)>+b (2)

where CI>(x) is projection CI>2x—>H by the corresponding feature vector
x e R”; w is the weight vector perpendicular to the hyperplane and weighting
the corresponding dimension, and beR. The SVMs were developed to
solve pattern classiﬁcation (support vector classiﬁcation) and regression
problem [support vector regression (SVR)]. The SVR has been extensively
implemented in studying ﬁnancial time series prediction (Huang et al., 2006).

2.3.1 The model In this study, the model was learned by giving
the input data, which in our case was the hybridization measurements
{(xl, yl), (x2, yz)...(x,-, y,)}, where x,- is the probe genomic coordination
and y,- the normalized intensity. To perform regression, SVR uses a different
loss function compared to common SVMs called 8—insensitive loss function:

0, 'f —
ly—f(x)l={ 1 'y mm“ (3)

I37 —f(x)| < 8 otherwise

 

1 424

112 /§JO'SIBUJHOIP.IOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 11101; pepaommoq

9IOZ ‘Ig lsnﬁnv uo ::

HM-SVMS

 

Only the data points larger than the threshold of :I:8 from the predicted linear
function f (x) were subjected to the penalty. The complete optimization of
SVR minimizes sum of the loss function and regularization item below:
Minimize t(w,§)= C27;1(e3,-+a3;'<)+ % ||w||2
Subject to (< w, CI>(x,-) > +b) —y,- 5 8 —.§,-
yi —(<w, C1>(xi-) > +12) 5 8—51
El :07  :07  1727 "Mm?

(4)

where m is the number of total probes on the genome; C is the trade—off
value, and S,- and Sf are the corresponding positive and negative errors at the
i—th probes, respectively. The epsilon tube around the decision line of f (x)
was created by the loss function. Therefore, only the data points outside the
tube area had impact on the ﬁnal decision line and the degree of inﬂuence
was determined by the distance to the decision line.

2.4 RNA transcripts identiﬁcation by HM-SVMS

HM—SVMs was used to decode transcribed (expressed) and non—transcribed
(silent) regions from the complicated probe intensity proﬁles. This hybrid
algorithm allowed labeling the hidden state of sequential data based on the
model learned from a training dataset integrating with prior knowledge.

2.4.1 The model To reﬁne the problem, the transcriptome data D from
hybridization measurements consisting of probes x=(x1, x2, ..., 9%,) are
associated with the unknown hidden state sequence e=(e1, e2,...,em)
generated by an unknown model M. The feature vector VE {xi=(v1,
vz,...,vn)}i=1...meR”, where x,- is i—th probe on the genome and v is
one of n features, was constructed from D to characterize every probe. In
order to predict the unknown state e over the sequence (i.e. expressed or silent
states), we constructed a learning model M/ representing a true model M.
The constraint data X z{(x,-, e,-)} e D, in which the hidden state sequence
econstraim has been characterized by prior knowledge, were selected as a
training dataset for algorithm modeling. A w—parameterized discriminative
function F: X x E e R was generated by maximizing F over the response
variable econstraint e E for a speciﬁc input X:

ﬁx):argmaxnxveconstraint? W) (5)

The optimized function conjugated the pair of observation and hidden
state sequences by a mapping CD, which extracted the features from
observation/hidden state sequence pairs (x, e):

F(Xieconstraintiw)= <qu)(xve)> (6)

Suggested by the concept of HMM, the hidden state of probe intensity along
the genome was considered as a Markov chain. Two types of the features that
jointed input—output mapping were derived from the emission and transition
matrices. The emission matrix combined attributes of the observation vectors
with a speciﬁc hidden state. The transition matrix described the neighbor
hidden states which depended on each other along the sequence. Therefore,
the function F was rewritten as following:

F(Xieconstraint?w)=

Z? 2 He“—1 =eri=rii+iiei=riw (xi) (7)
1:1 QTGK y

where [[ei = r]] ghy(xi) represents combination of hidden states and
observation in which ghy(xi) maps observation vector associated with the
observation r from the i—th point in the sequence. In our case, ghy(xi)
denotes the observed intensity yeR at i—th probe in the sequence. And
[[ei = r]] shows an indicator function for the hidden state I located at the i—th
probe. [[e’._1 = 0A ei = r]] displays the dependencies of states a, r e K at the
(i — 1)—th and i—th positions, where K denotes all possible states. In our case, K
is either expressed or silent state. The equation mentioned above corresponds
to ﬁrst—order models, and higher order models can be generalized as well.
F (X ,econstraint; w) accumulates all extracted features along the sequence of
length T. The maximum separation margin deﬁned by the kernel function

from the training data points in the feature space, which minimized errors
of misclassiﬁcation, was used to construct the discriminative function F.
As described before, to solve possible non—separable data points, 5 slack
variables and error cost C controlling the trade off were introduced to create
a soft margin to allow margin violations. More detail HM—SVMs optimization
combining the loss function with regularization item was described in Altun
et al. (2003). As a result, the hidden state sequence e’ was estimated by the
function F, giving a complete test data with associated feature vector.

2.4.2 Extraction of feature vector We introduced a proﬁle geometry
learning method to construct feature vectors. In order to depict the proﬁle
terrain shaped by probe intensity and position, the feature vectors were
composed of two terms including elevation and change of slopes. Given
a search window (the range of the ﬂanking regions of the current probe j)
S 2 (xi, xi+1,...,xs) which represents the probe j, its feature vector can be
written as Vj E {U(<P)i,i+1f(<ﬂ)i+1,i+2,---f(<P)s—1,s), (Zi, Zi+1, .-~,Zs)}~ Zi is
the Z—score converted from the probe intensity under the assumption of the
probe signals distributed by Gaussian. Therefore, Z—score normalizes the
signals and presents the elevation of the terrain. f (<p),-,,-+1 shows the score of
jumping from probe x,- to xi+1 as below:

__ : Ayi,i+1) (0(Ay)Ax) 8
ﬂwl’lﬂ (Axi,i+1 E(Ay)Ax ( )

where y and x showed the probe intensity and position. The ﬁrst factor is
the slope between probe xi, xi+1; the second was a weight which compared
0(Ay)Ax (the observed y difference at the distance of x,- and xi+1) to E ( Ay) M
(the expected y difference at the same distance). E (Ay) M can be estimated
by averaging Ay calculated from all probe distances. Note that the probes
were not equally distributed on genomic sequence. E ( Ay) M is considered as
signal noise due to distance change of the probe. Therefore, f (<p),-, i+1 presents
the change of the slope between two probes on the proﬁle terrain. The feature
vector V was composed of an n x m matrix, where the row m represents total
probes with n features. In contrast to the conventional HMM, the observed
atomic data point was transformed to the numerical feature vector for SVM
pattern recognition.

 

2.4.3 Hidden state assignment In order to combine the observation of
sequence Y represented by the feature vector V with the hidden state sequence
e, each probe was assigned with one of following labels: expressed or
silent state. The assigning criteria were initially based on the NCBI genome
annotation data, which serves as a good starting systematic biological
knowledge. The sequences were preliminarily labeled as expressed or silent
state corresponding to coding and non—coding regions, respectively.

2.4.4 The training set selection To select the training set X, we used a
comprehensive and objective scheme to determine subregions from the array
data only based on genome annotation data. It has been known that >90%
of open reading frames (ORFs) were expressed in Escherichia coli (Selinger
et al., 2000). Under this assumption, ﬁrst type of the subregions, which were
restricted to the ORF, tRNA and rRNA regions identiﬁed by the annotation,
was used as training data for learning the expressed state. For learning the
silent states, second type of the subregions located at intergenic regions
was extracted and 300 bp of the DNA sequence was trimmed from both 5/
and 3/ ends. The trimming was to remove potential ncRNA signals from
the untranslated regions (UTRs) both upstream and downstream of ORFs.
According to these criteria, 955 regions were selected. Different experimental
conditions may inﬂuence the selection of the training set. Therefore, leave—
one—out cross—validation was used to evaluate each member of the training set
for different conditions. Those with accuracy predicted by cross validation
lower than 0.9 were considered non—informative or misinformative, and were
removed.

2.4.5 The post-processing In the output, every probe was tagged with
either expressed or silent state. Therefore, the boundaries of the segments

 

1 425

112 /§.IO'SIBUJnoprOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pep1201umoq

9IOZ ‘Ig lsnﬁnv uo ::

W.-H.Yu et aI.

 

were deﬁned as the junctions between two regions of different states. In
addition, to remove possible false segments, labels of segments consisting
fewer than four probes were averted to the same states as the neighbors. In
other words, we ignored the small RNA transcripts covered by fewer than
four probes (ca. 50 bp in size).

The source code of SVMhmm V3.10 written in C was downloaded from
http://www.cs.cornell.edu/People/tj/svm_light/svm_hmm.html (Joachims
et al., 2009). The HM—SVMs algorithm was directly implemented in R
and the input ﬁle for model learning and classiﬁcation was formatted as
described by the program. The results of transcriptome proﬁle, algorithm
classiﬁcation and detail program scripts can be accessed on the website at
http://bioinfonnatics.forsyth.org/mtd.

2.5 Strand-speciﬁc reverse transcription polymerase
chain reaction

For standard reverse transcription—polymerase chain reaction (RT—PCR),
the false positive PCR artifact was detected in the absence of added RT
primer due to self—priming of RNA or non—speciﬁc small DNA or RNA
contaminants in the RNA extraction, which acted as the primers for RT
reaction. To avoid the artifacts, a DNA tag non—homologous to P. gingivalis
W83 genomic sequence was added to the 5/ end of the synthesized RT—
primer for reverse transcription. After cDNA was synthesized, regular PCR
was performed with the tag and a gene—speciﬁc oligo as the primer pair
(Purcell et al., 2006). Reverse transcription was initiated with 2 ug RNA
and 20 pmol tagged primer. The procedures of RT—PCR followed Invitrogen
SuperScript II’s manual.

3 RESULTS AND DISCUSSION

3.1 Data normalization and regression

To monitor the signal adjustments during different stages of data
processing, we plotted the probe intensities along the genomic
coordinate. Raw signal intensities were ﬁrst adjusted using genomic

DNA hybridization data as the reference. Figure 1a shows the
genomic DNA intensities on a region of genome. The probe
intensities with repeated sequences which may mislead abundance of
RNA molecules were regressed to a single copy level. Theoretically,
every DNA signal based on single copy number should be of the
same level. However, the result showed a much ﬂuctuated intensity
proﬁle on the plot because of various factors. One major factor was
oligonucleotide composition (Royce et al., 2005), which directly
affects the afﬁnity between targets and probes. Another involved
the labeling efﬁciency of the probe. In our study, the genomic DNA
was labeled by covalently attaching ﬂuorescent dye to a heteroatom
on guanine residues, thus the efﬁciency of labeling depended on
the nucleic acid composition of the probe. The ﬂuctuated DNA
hybridization proﬁle was used to adjust the expression proﬁles so
that the bias due to sequence composition can be eliminated.
Figure 1c shows the signal intensities adjusted by DNA reference
signals and between—array normalization. Compared to Figure 1b,
which plotted original RNA hybridization measurements on a base
2 logarithmic scale, the ﬂuctuation of adjusted intensities was
notably reduced within the expressed regions (Fig. 1c), but was
ampliﬁed in the background regions. This can be conﬁrmed by
quantitative comparison of standard deviation of RNA raw data
and normalization data in Table 1. Also, the background noise
in Figure 1c shows a symmetric and stochastic distribution not
similar to Figure 1b. Our explanation is that background intensities
are mainly contributed by non—speciﬁc noises without perfectly
matched RNA target binding. Thus, the background regions are
not the suitable targets for the DNA normalization method. Despite
of this caveat, two major advantages gained still justiﬁed the use
of normalization with DNA signals. First, the difference between
the positive and the background signals was enhanced, which
increased the sensitivity for detecting low level of expression

 

1? III 1|
I:
I

. . I...
+ F.
i...

1|
‘
5+ 1'

 

I !|:|12 III- IE

 

III-El |21E

 

 

 

EIII1I1E

 

 

 

Il:]l I I I III IIIDDI:I El [:I

 

I - I I I |
him 1m 1mm 1mm 151m 19mm: 1mm .‘HIHIIDII Jamil mmn 21mm: 211MB

I I
21:“: 215mm 22mm“: 225m!!! 22Iﬂdﬂ 2:1 ﬂﬂﬂ- 231mm- 211mm- Edllﬂﬂ 21—h!“ ldim ldm

Fig. 1. Intensity proﬁles of tiling microarray data at various stages of data processing. Logz probe intensities (y—axis) from a range of 90—kbp of the genome
on the sense strand of the sequence were plotted on the genome coordinates (x—axis). The plots are (a) signal intensities of DNA reference array, (b) RNA
raw intensities from microarray, (c) signal intensities after normalization, (d) after adjustment by SVR and (e) the corresponding ORFs. The gray areas
were selected as the positive signals for further quantitative evaluation of data processing performance as shown in Table 1. The green areas were visually
determined as background noise and its quantitative evaluation can be seen in Table 1.

 

1 426

112 /§JO's112u1nofp101x0'sor112u1101urorq//zd11q 111011 pep1201umoq

9IOZ ‘Ig lsnﬁnv 110::

HM-SVMS

 

Table 1. Quantitative assessment of different steps of data processing by signal to noise ratio (SNR)a

 

 

 

 

Type Start (bp) Stop (bp) RNA raw intensities Normalization SVR

Mean SD SNR Mean SD SNR Mean SD SNR
Positive 189 800 194 400 9.7 0.66 4.8 0.50 4.8 0.36
Positive 218 300 223 000 14.1 0.98 7.7 0.47 7.6 0.29
Positive 216 550 217 650 12.4 0.60 8.1 0.62 8.1 0.47
Positive 224 200 230 400 10.5 0.93 5.5 0.63 5.5 0.53
Background 181700 189 000 7.4 0.34 6.99 2.0 0.67 6.85 2.1 0.37 996
Background 194 500 197 650 7.5 0.46 2.1 0.76 2.2 0.60
Background 238 400 242 300 7.3 0.38 2.0 0.72 2.0 0.38
Background 244 500 251 000 7.6 0.49 2.2 0.80 2.3 0.48

 

aSNR was calculated as the following where ages deﬁnes the mean of all positive intensities within 2.5—97.5% quantiles of total, and arQreposmeg indicates the mean of the SDs

from both positive and negative signals within the same quantiles. SNR = (11305 — “ﬁg/agrepomg.

signals. Table 1 shows the difference of mean intensities between
positive and background regions prior to and after normalization.
Second, the normalized intensities within a transcript expressed a
much condensed level and thus better represented the pattern proﬁle
of a RNA transcript.

For this reason, SVR was applied to predict the local tendency
from the scattered data distribution and eliminated the outliers.
In Figure 1d and Table 1, the noises presented by the standard
deviations were signiﬁcantly reduced in all regions after SVR
adjustment. The moderation of SD mainly contributed to the
improvement of signal—to—noise ratio (SNR), since the difference of
positive and background signals did not change after normalization
and SVR. To maintain the local tendency of the distribution, we
empirically set the parameter a to 5 X 104, which could ﬁt our
highly non—linear data model and reduce the cross—validation error.
The smaller the a was, the much smoother the distribution became.
But more informative intensities were lost and cross—validation error
increased.

Our major goal was to more accurately differentiate the transcript
units (expressed signals) from the background (silent regions).
The combination of DNA normalization and SVR enhanced the
separation of positive signals from background noises. Figure 2a—c
compares the histograms of raw, normalized and SVR transformed
intensities. For raw intensities, the majority of transcribed signals
are located at levels just above the dominant background noises
in accordance with a power—law distribution (Royce et al.,
2005). The mixed distribution obscured the recognition of the
transcribed regions by the following algorithm. After adjustment
by normalization and SVR, the data transformed to a bimodal—like
distribution composed of a mixture of two Gaussian distributions.
The lower dominant peak comprised the background signals and the
right small one represented the transcript signals (Fig. 2b and c). The
much—separated distributions between transcript and background
signals improved the performance of the machine learning algorithm
described next.

3.2 Performance measurement on simulated data

To compare the performance of our HM—SVMs and other methods,
the synthetic dataset with four different sizes (10, 20, 30 and
40K data points) simulating probe intensity distribution along the
genomic coordination were constructed. Data points were randomly

.1
[I in” m m m
I I I

 

 

I rig? IIIIIII-ulIII-Ic

 

 

 

iIbI

i-
‘- ‘il 1' 15
311:1


E-

1' II 1'. 15
g

d
g__II

{curl
m

 

 

I. uu'} IIIIIIIuIIn-

Fig. 2. Histogram of frequency intensity distribution at different stages
of data processing. (a) RNA raw intensities from microarray; (b) RNA
intensities after normalization; (c) RNA intensities after adjustment by
SVR; and ((1) component distributions combining the background noise
distribution (purple area) and positive signal distribution (orange area) from
the predicted HM—SVMs results.

generated with Gaussian noise by ﬁxing mean and SD (noise). Two
hidden states (positive and background) were pre—assigned and the
level of positive signals was controlled by SNR.

To optimize the algorithm, several parameters were systematically
explored in order to minimize misclassiﬁcation rate on the simulated
dataset, which included the cost of constraints violation C, precision
value epsilon 8 and the search window size s. Increasing the value
of C expanded the cost of misclassiﬁed points and forced to create
a more accurate model. The value of C was set as 170 in this study.

 

1 427

112 /810's112u1nofp101x0'soneumoJIquIq/ﬁdnq 111011 pep1201umoq

9IOZ ‘Ig lsnﬁnv 110::

W.-H.Yu et aI.

 

hnruuu ungnulnﬁ Luann“! :III'.|I'I1IH'I Illli1|1 Emir-nun :I-Igm-Im :IIII:2I!|

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

:I a :I
- - ' - - - -- _ I-- -- I.
.._._.._. ring-ﬂirt! I 'rrtﬁ—l—riil l Irv-'Efmg: |Il
II-I' 111
II u_ u 
I:I -I:I I:
n in_ n
=1 a :1 ‘ﬁ :1 :-
1‘ H 1‘
I:'I '5 I:'I
E E E
z _ z z E
I
E E' Z
r: r. I! .
ﬂ__,,.l,’ﬂrl cl-"l-‘I-H. u
I: -I:I I:
{'5 I'} IE 1'“ RI III D: I11 II 3‘" 2!- JII {'5 1'! IE 1'“ 25 III
I"? if“! in"!
Ilprllllﬂ Illarl'llfll III-:5 Ilprllllﬂ :IlngrIl ll:l:1|l hﬂr‘llllﬂ llgmlnl III-:ilr
:I a :I
- n F EH" ' i - wﬁ'ﬂ'r "I
a. '- I' ' '- II
V In"
: 3" + :- ' i : I“ I
a: .d

III
Tuuﬂen J
I“
E.
lH—l
l—IEI—I
I-_-q-_I
I—d—I
I—-:—I
Twin 4
III

TUNE-HI" I

a:
a:

f {a j - ' ;} jfjllllI l
fitf : -'

a.  E {Q l i r

1..

I32

1- "1r

 

 

 

 

 

 

: II-Ir-l-F'T I- i ill-'15- - I- : Fir? I-

llﬂ

 

 

 

an I3: 1': HI 2:. :I'I: bl I-:I II'I in 2: :II on III 1': HI 2': III:-
SH'I' in” 5".

accuracy

Tnuﬂm' I

hpmnld II-arrIIrII 1IIIE4U Lunar-Incl :IIgm-Irn Hamil] LlnrﬂI-IIEI :I-IgrrI-Im Ilnnilil

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

E rr'rj-jr’r-II E rrgﬁ-y-j-r-JI E r.....-*-I.ir-:I
if E! l- } I III I: *- ﬁ ‘1'- .
2;, g ' T g f E
:3 h: I 13.4.4”... i
E E
I i i
E - I. E “Oi-1' I' E
E In" 2 E
III III- II II: II. In {-5 HI I: :-II 2: 3:- GE III I: In 2.1 I:-
‘H' 5"" SHII'
hurl-III! ligmln‘l llﬂllﬂ Lulllllﬂ llgmlnl ll:l:ﬂ|1 llﬁlﬂlllﬂ llgmlrrl III-Hill
E . E - .- 1"- - 'i
rwrtff i ivrrrtt * .wrervt
1" __ «at + a:
' i’ ' T d 4
III   I  - I I
: - - 3 I' - :
[El _ a I E I.
II- I. :E I- i :2 Ir  I
-' 1' . I I 1
IF .
: I'll II- '1" 1- g 1|- Ir ' l- i g 1" 1" i- -I- II:
III: III II: Ill! 1': :I'II on III! I]. :I-'II 2: llb III III II in 2.1 II-
:H.‘ 5"” SHI'

Fig. 3. The performance versus different SNRs and segment sizes among three algorithms—HM—SVMs, HMM and Segmentation (shown in blue, green and
red lines, respectively). The bar denotes the 95% conﬁdence level for each data point.

Smaller precision value 8 enhanced the prediction accuracy, but the
computing time and memory usage increased. In this study 8 was
set at 0.5. The search window in size S was set at 5. Furthermore,
we tested both directions of reading the sequential data points, HM—
SVMs generated exactly the same classiﬁcation with simulated data.

On four different sizes of simulated data, we measured
performance of our HM—SVMs and two other methods—the
segmentation method by Huber et al. (2006) and HMM—based
method by Nicolas et al. (2009). Since the level of SNR and the
size of segment may inﬂuence the performance, we challenged
the algorithms with various combinations of the two parameters.
When the data represent gene expression level, the level of SNR
corresponds to the amount of RNA. The size of segment suggests
the length of RNA transcript. Some small regulatory RNAs may
be found in small segments and operons consisting multiple
cotranscribed genes may correspond to large segments. To access
the performance of the three algorithms, accuracy and Youden’s
index (the difference of sensitivity and false positive rate) were
calculated with different SNRs and segment sizes (Fig. 3). At low
SNR (<1.5), our algorithm outperformed other two methods in
different segment sizes. The accuracy of our algorithm was equal
or higher than that of other algorithms under all conditions. The
accuracy decreased with lower SNR and larger segment size. This
may be due to that some data points in segments with larger size and
low SNR were classiﬁed as background. Comparison of Youden’s
index, our algorithm showed a better power to discriminate true
positive and true negative. However, when SNR was lower (<0.5),
all algorithms showed poor Youden’s indices, suggesting more false
positive predictions. Overall, compared to the other two methods,
our HM—SVMs showed higher discriminative power for classifying
the underline states under all test conditions.

3.3 Identiﬁcation of transcription units by HM-SVMs

We applied this algorithm to the analysis of the transcriptome proﬁle
for P. gingivalis W83. The selected training data for model learning

consisted of pairs of input and output objects. The input was the
feature vector, based on the distribution of probe intensity expression
level described above, and the output was desired hidden states
(expressed or silent) retrieved from NCBI genome annotation data.
Additionally, any other system—wide experimental data can also be
incorporated into the feature vector to enhance the discriminating
ability of SVMs. The strategy of training set selection described in
the methods was to extract the most informative regions by removing
those that may be undergoing post—transcriptional modiﬁcations or
transcription regulations. The probes in the selected regions were
tagged with conﬁdent hidden states and were used in the learning of
the discriminative function F. In addition, we included leave—one—
out cross—validation to evaluate each member of the training set,
and the one with non—informative or misinformative was eliminated.
This annotation—based selecting strategy was objective but may
include false labeling, which can be alleviated by implementing a
soft margin created by the error cost C and the slack variable if in
the discriminative function F.

The distributions of probe intensities associated with both
expressed and silent states from HM—SVMs results were plotted
in Figure 2d. Degrees of separation of these two distributions
showed that HM—SVMs were able to recognize the patterns from
both states and to discriminate them correctly. Notably, there
was an overlap between the two distributions, suggesting that the
decision of classiﬁcation was determined by corresponding feature
vector, which was highly related to local tendency (subsequent
dependency), instead of by a simple cutoff. Therefore, the algorithm
could recognize the complex pattern of the expression proﬁle and
make a decision on the expression state intelligently.

Examples of transcription proﬁle analysis using HM—SVMs were
shown in Figure 4. The ﬁgure shows that the algorithm was able
to correctly distinguish the expressed transcripts from background
noises consistent to the annotated genes and intergenic regions,
respectively. Several types of RNA transcripts were classiﬁed by
comparing the HM—SVMs results with the genome annotation.
Examples of different types of RNAs were shown in Figure 4.

 

1 428

112 /810's112u1nofp101x0'soneumoJIquIq/ﬁdnq 111011 pep1201umoq

9IOZ ‘Ig lsnﬁnv 110::

HM-SVMS

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

E Z 1 a 1' 1', 2 I b :' II. IE
"* 3  ...,-h! I: v.1
—.  I - : INN“ I r.
n L . I -:I .' -:I
_ J. _ 1‘ 1- “, .- j  I
D _ , - i : I ‘" 1II ‘" -. I: " I 
1- — _'J_ ..r . n- 1 . I H . .
rI _ n "I
a g D
— _ I - —-_ _
- —_ — - f -
E — :2 - IE
:- 3 1: :2 III
I I .'
n . " -=I _-'l -:|
.— I  .— I a“. .- 5?!“ I
" _' 5 E ' ' " 2 ..f- . ‘I I' ' ' Jr . 1la... -'II
 'i I?" a    I- .- a II -. In “I:
1I' - . 'Ir .- 1r I ' _ '1
m : n "I
"' | ' I ' I ' I " l I" I I | I I I' I" I '9 I I I I In. . - I I . I I I. . I . I
1W|IIIZIIIIIII 1lJ-J-EIIIIIJ 13m 1333“ 1'!I1!IIID€I 1mﬂDD ICIEEIDW 1=CIETIIID€I HEREIN) 152N301) 21m 11mm 2133mm HEM 21ml]
5 — I d :l :3 1 E l
2 : I ‘1 'I j szbe labelled expression in sens:- :lrlnd
s- : r- i
n _I.~\,'_“-\\’rﬁ"' '1- .n   Hub: labelled silence- in sense strand-
. m l
I. . i P n H II .1 I. t
. : W1,“ ' ... -" i PTUbEIIbElEd caprﬂsiunin anlilarnsc strand
_ 'I
H — ﬂ 1
p : u Prob: labelled ail-anal: in antisense EI-lrinﬂ
— I *
I .WFi Il'l HHSI‘IIFHI'IH
—
E — :3
— .W: "I inhuman strand
E -- 11
3 _ ' _..n...-‘J-._..._.-""JI & hymnlhmnmm
m- : III-‘1 Il—rﬁ a:
_ v:
- : JUM -
'I — f
H — '91
=' I I '=' I I I . I I I I - I I I I I I I I
Janna sauna JIII-DD Janna Hanna mum: Inna-m uzunn manna um ulnnn mun um ulnun

Fig. 4. Examples of transcription prediction made by HM—SVMs. Normalized log intensities (y—axis) of the probes were plotted against the actual probe
coordination of the genome (x—axis). The data predicted with the ‘expressed’ states were colored in red and green on the sense and antisense genomic sequences,
respectively; data with ‘silent’ states were colored in pink and light green on the sense and antisense, respectively. Computer predicted ORFs were shown
in red and green boxes on the sense and antisense strand, respectively. Putative boundaries of the transcripts were indicated as vertical gray lines. Several
different types of RNA transcripts (exempliﬁed by arrowheads) categorized are as follows: (a) novel RNA transcripts, (b) antisense RNAs, (c) non—coding
small RNAs, (d) putative 5/ UTR region and (e) potential operon containing multiple ORFs.

We found a large number of transcripts containing potential novel
ORFs in not yet annotated regions (Fig. 4a). Several cis—encoded
antisense RNAs (Brantl, 2007) opposite to the location of the
sense transcripts were also identiﬁed in many regions (Fig. 4b).
Small ncRNAs which may be responsible for regulation of its
antisense gene expression were also observed (Fig. 4c). The 5’
and 3’ UTR regions of the transcripts (Fig. 4d) may provide useful
resource for studying post—transcriptional regulation. Furthermore,
large transcription units were frequently found to contain several
ORFs (Fig. 4e) and are the typical operons transcribed from the
same promoters in bacterial cells.

3.4 Benchmark comparison

The HM—SVMs algorithm used in this study is highly efﬁcient in
terms of computational time. The analysis of the single strand of
P. gingivalis genomic tiling array expression proﬁle (ca. 200 K data
points) required less than 1 min of computation time and consumed
only 120 Mb system memory on a single core 2.3 MHz Intel—based
computer. For the same analysis on the same computer platform,
the segmentation algorithm published by Huber et al. (2006) took
more than 16h [parametersz maximum segment length l=2500
(25 kbp) and maximum segment number K = 1900] and the method
implementing HMM framework (Nicolas et al., 2009) took more
than 6 h (with the parameter hidden state K set at 100). Clearly, the
HM—SVMs based algorithm reported here is much more efﬁcient
compared to other algorithms used for transcriptome proﬁle analysis.

3.5 Predicted transcripts validated by RT—PCR

To validate the novel transcripts and transcriptional architectures by
the HM—SVMs algorithm, a total of 36 regions predicted by HM—
SVMs as either expression or silence were subjected to experimental
veriﬁcation by RT—PCR. Of 15 selected expressed regions by
HM—SVMs, 13 showed positive RT—PCR signals, indicating the
presence of RNA. Of 21 selected silent regions, 18 showed no
sign of RT—PCR product, thus conﬁrming the lack of RNA in these
regions. By calculating hypergeometric distribution probability of
classiﬁcation from both experiment and computer, it suggested that
the prediction of the algorithm signiﬁcantly matched the results of
the experiment (P—value <0.05). Moreover 7 of total 15 predicted
expressed regions conﬁrmed by RT—PCR are novel RNAs that have
never been described before. Of three regions which were predicted
as silent but showed positive RT—PCR signals, the intensities in
these regions were very close to the background noises (SNR N 0.01)
and thus the expression patterns were masked or disrupted by the
background. Localized and better background correction algorithm
may be needed in order to increase the accuracy for the prediction
of the low intensity area.

4 CONCLUSIONS

A comprehensive method combining multiple innovative algorithms
was devised and used for transcriptome proﬁle analysis. This method
starts with raw data normalization using DNA reference array to

 

1 429

112 /§JO'SIBUJn0[pJOJXO'SOllBIIIJOJUIOIQ/ﬁdnq 11101; prBOIUAAOG

9IOZ ‘Ig lsnﬁnv uo ::

W.-H.Yu et al.

 

estimate probe—speciﬁc scaling and background parameters and to
adjust probe intensity accordingly. SVR algorithm, a regression
model preserving the local tendency of the proﬁle, was then used
to minimize the noises caused by the stochastic measurement
error. Normalized and smoothed proﬁle data were then subjected
to expression status prediction using heterogeneous HM—SVMs,
which incorporates proﬁle geometry learning and transforms the
hybridization signals into the high—dimensional feature vector for
the discriminative model training. Viterbi algorithm was then used
to decode the most likely underlying sequential states, considering
the dependencies on the neighboring states. The performance was
evaluated with the simulated data and our HM—SVM outperformed
two other algorithms designed for similar purpose. The HM—SVMs
algorithm has the ﬂexibility of combining different types of validated
biological information in learning the feature vector for constructing
the predicting function. We believe this method will be a great
addition to the current methods available for transcriptome proﬁle
analysis. Furthermore, this method can also be applied to the analysis
of other types of time serial data, such as CGH, ChIP—on—chip and
RNA—sequencing data for predicting hidden states of the data points.

ACKNOWLEDGEMENTS

We thank Dr Mark Kon at Boston University for valuable comments
on the writing of the manuscript.

Funding: National Institute for Dental and Craniofacial Research
(grant no. R21 DE018803—01A1); Mobility grant from the Faculty
of Dentistry, University of Oslo, Oslo, Norway (to H.H.).

Conﬂict of Interest: none declared.

REFERENCES

Akama,T. et al. (2009) Whole-genome tiling array analysis of Mycobacterium leprae
RNA reveals high expression of pseudogenes and noncoding regions. J. Bacteriol,
191, 3321—3327.

Altun,Y. et al. (2003) Hidden Markov support vector machines. In Proceedings of the
Twentieth International Conference on Machine Learning. Washington, DC, pp.
3—10.

Bai,J. and Perron,P. (2003) Computation and analysis of multiple structural change
models. J. Appl. Econometrics, 18, 1—22.

Bertone,P. et al. (2004) Global identiﬁcation of human transcribed sequences with
genome tiling arrays. Science, 306, 2242—2246.

Brantl,S. (2007) Regulatory mechanisms employed by cis-encoded antisense RNAs.
Curr. Opin. Microbiol, 10, 102—109.

Cortes,C. and Vapnik,V. (1995) Support-vector networks. Mach. Learn., 20,
273—297.

David,L. et al. (2006) A high-resolution map of transcription in the yeast genome.
Proc. Natl Acad. Sci. USA, 103, 5320—5325.

Du,J. et al. (2006) A supervised hidden Markov model framework for efﬁciently
segmenting tiling array data in transcriptional and chIP-chip experiments:
systematically incorporating validated biological knowledge. Bioinformatics, 22,
3016—3024.

Duncan,M.J. et al. (1993) Interactions of Porphyromonas gingivalis with epithelial cells.
Infect. Immun, 61, 2260—2265.

Furey,T.S. et al. (2000) Support vector machine classiﬁcation and validation of cancer
tissue samples using microarray expression data. Bioinformatics, 16, 906—914.
Hovik,H. and Chen,T. (2010) Dynamic probe selection for studying microbial
transcriptome with high-density genomic tiling microarrays. BMC Bioinformatics,

11, 82.

Huang,K. et al. (2006) Local support vector regression for ﬁnancial time series

prediction. International Joint Conference on Neural Networks. Sheraton Vancouver
Wall Centre Hotel, Vancouver, BC, Canada, pp. 1622—1627.

Huber,W. et al. (2002) Variance stabilization applied to microarray data calibration
and to the quantiﬁcation of differential expression. Bioinformatics, 18 (Suppl. 1),
896—8104.

Huber,W. et al. (2006) Transcript mapping with high-density oligonucleotide tiling
arrays. Bioinformatics, 22, 1963—1970.

Joachims,T. et al. (2009) Cutting-plane training of structural SVMs. Mach. Learn., 77,
27—59.

Kapranov,P. et al. (2002) Large-scale transcriptional activity in chromosomes 21 and
22. Science, 296, 916—919.

Karatzoglou,A. et al. (2004) Kernlab—an S4 package for kernel methods in R. J. Stat.
Software, 11, 1—20.

Li,W. et al. (2005) A hidden Markov model for analyzing ChIP-chip experiments on
genome tiling arrays and its application to p53 binding sequences. Bioinformatics,
21 (Suppl. 1), i274—i282.

Li,L. et al. (2007) Global identiﬁcation and characterization of transcriptionally active
regions in the rice genome. PLoS One, 2, e294.

Munch,K. et al. (2006) A hidden Markov model approach for determining expression
from genomic tiling micro arrays. BMC Bioinformatics, 7, 239.

N icolas,P. et al. (2009) Transcriptional landscape estimation from tiling array data using
a model of signal shift and drift. Bioinformatics, 25, 2341—2347.

Picard,F. et al. (2005) A statistical approach for array CGH data analysis. BMC
Bioinformatics, 6, 27.

Purcell,M.K. et al. (2006) Strand-speciﬁc, real-time RT-PCR assays for quantiﬁcation of
genomic and positive-sense RN As of the ﬁsh rhabdovirus, Infectious hematopoietic
necrosis virus. J. Virol. Methods, 132, 18—24.

Rabiner,L.R. (1989) A tutorial on hidden Markov models and selected applications in
speech recognition. Proc. IEEE, 77, 257—286.

Royce,T.E. et al. (2005) Issues in the analysis of oligonucleotide tiling microarrays for
transcript mapping. Trends Genet, 21, 466—475.

Schadt,E.E. et al. (2004) A comprehensive transcript index of the human genome
generated using microarrays and computational approaches. Genome Biol, 5, R73.

Selinger,D.W. et al. (2000) RNA expression analysis using a 30 base pair resolution
Escherichia coli genome array. Nat. Biotechnol, 18, 1262—1268.

Stolc,V. et al. (2004) A gene expression map for the euchromatic genome of Drosophila
melanogaster. Science, 306, 655—660.

Tjaden,B. et al. (2002) Transcriptome analysis of Escherichia coli using high-density
oligonucleotide probe arrays. Nucleic Acids Res., 30, 3732—3738.

Yamada,K. et al. (2003) Empirical analysis of transcriptional activity in the Arabidopsis
genome. Science, 302, 842—846.

Zeller,G. et al. (2008) Transcript normalization and segmentation of tiling array data.
Pac. Symp. Biocomput., 527—538.

 

1 430

112 /§.IO'SIBUJnoprOJXO'SOIlBIHJOJUIOICI/ﬁdnq 11101; popuoIUAAoq

9IOZ ‘Ig lsnﬁnv uo ::

