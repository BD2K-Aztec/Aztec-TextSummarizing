Bioinformatics, 31 (5), 2015, 682—690

doi: 10.1093/bioinformatics/btu726

Advance Access Publication Date: 29 October 2014
Original Paper

 

Sequence analysis

Computational framework for next-generation
sequencing of heterogeneous viral populations
using combinatorial pooling

Pavel Skums1'*, Alexander Artyomenkoz, Olga Glebovaz,
Sumathi Ramachandran1,lon Mandoiu3, David S. Campo‘,
Zoya Dimitrova‘, Alex Zelikovsky2 and Yury Khudyakov1'*

1Division of Viral Hepatitis, Centers of Disease Control and Prevention, Atlanta, GA, USA, 2Department of Computer
Science, Georgia State University, Atlanta, GA, USA and 3Department of Computer Science and Engineering,
University of Connecticut, Storrs, CT, USA

*To whom correspondence should be addressed.
Associate Editor: lnanc Birol

Received on July 25, 2014; revised on October 7, 2014; accepted on October 24, 2014

Abstract

Motivation: Next—generation sequencing (NGS) allows for analyzing a large number of viral
sequences from infected patients, providing an opportunity to implement large—scale molecular
surveillance of viral diseases. However, despite improvements in technology, traditional protocols
for NGS of large numbers of samples are still highly cost and labor intensive. One of the possible
cost—effective alternatives is combinatorial pooling. Although a number of pooling strategies for
consensus sequencing of DNA samples and detection of SNPs have been proposed, these strat—
egies cannot be applied to sequencing of highly heterogeneous viral populations.

Results: We developed a cost—effective and reliable protocol for sequencing of viral samples, that
combines NGS using barcoding and combinatorial pooling and a computational framework includ—
ing algorithms for optimal virus—specific pools design and deconvolution of individual samples
from sequenced pools. Evaluation of the framework on experimental and simulated data for hepa—
titis C virus showed that it substantially reduces the sequencing costs and allows deconvolution of
viral populations with a high accuracy.

Availability and implementation: The source code and experimental data sets are available at
http://alan.cs.gsu.edu/NGS/?q=content/pooling

Contact: kki8@cdc.gov, yek0@cdc.gov

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

1 Introduction

Next—generation sequencing (NGS) generates a large number of viral
sequences carried in samples of infected individuals, offering novel
prospects for studying microbial populations and understanding
pathogen evolution and epidemiology. NGS provides an opportun—
ity to implement a large—scale molecular surveillance of infectious
diseases for monitoring of disease dynamics and providing for
informed guidance for planning public health interventions.

Although NGS offers a significant increase in throughput, sequenc—
ing of viral populations from a large number of specimens is prohibi—
tively expensive and time consuming. Therefore development of a
strategy for rapid and cost—effective massive viral sequencing is a key
to effective molecular surveillance.

Owing to a high mutation rate, RNA viruses exist in infected
hosts as highly heterogeneous populations of genetic variants, which
are commonly referred to as quasispecies. Genetic viral variants can

Published by Oxford University Press 2014. This work is written by US Government employees and is in the public domain in the US. 682

112 /§JO'S{eumo [p.IOJXO'SOTlBIHJOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

Computational framework for NGS

683

 

be detected using highly variable subgenomic regions that can be
easily amplified and sequenced. Although genetic information pre-
sented in short subgenomic regions does not allow for identification
of all variants, it is sufficient for transmission networks inference
(Holodniy et 61]., 2012; Wertheim et 61]., 2014), study of drug resis—
tantce (Campo et 61]., 2014a; Dierynck et 61]., 2014; Wang et 61].,
2014) and intrahost viral evolution (Culasso et 61]., 2014; Palmer
et 61]., 2012; Ramachandran et 61]., 2011).

To reduce the cost of sequencing of multiple viral samples, multi-
plexing through barcoding is usually used. Although this is a
straightforward approach to a simultaneous sequencing of many
viral strains, it requires individual handling of each sample starting
from nucleic acid extraction to PCR and library preparation, which
increases the costs of sequencing per specimen (Duma et 61]., 2013;
Lonardi et 61]., 2013). Decoding of samples sequenced using large
libraries of barcodes may be highly affected by NGS errors (Deakin
et 61]., 2014). Additionally, besides introduction of bias in amplifica-
tion of different viral variants using PCR primers with different
barcodes (that may affect distribution of reads) (Alon et 61]., 2011
Duma et 61]., 2013), maintaining a large library of barcodes is daunt—
ing (Duma et 61]., 2013; Lonardi et 61]., 2013).

An alternative strategy is combinatorial pooling. Commonly,
it was used for tests producing binary results (Berman et 61]., 2004;
Du et 61]., 2006; Wu et 61]., 2006). Recently, several pooling strategies
were proposed for more complex assays based on DNA sequencing,
SNP calling and a rare alleles detection (Bansal, 2010; Erlich et 61].,
2009; Golan et 61]., 2012; He et 61]., 2011; Lonardi et 61]., 2013;
Prabhu et 61]., 2009; Shental et 61]., 2010).

The pooling problem for viral quasipecies sequencing is funda—
mentally different from all existing pooling protocols. Previously de—
veloped methods assume that a single (consensus) sequence must be
reconstructed for each sample. In contrast, for viral quasispecies
sequencing it is imperative to reconstruct the whole population
structure of each sample that includes multiple sequence variants
and their frequencies. This problem formulation and the nature
of heterogeneous viral populations require a completely novel ap—
proach for pool design and deconvolution.

We propose a protocol for a cost—effective NGS of complex
viral populations, which combines barcoding and pooling and
includes the following steps (Fig. 1): (i) mixing samples in a spe-
cially designed set of pools so that the identity of each sample
is encoded in the composition of pools; (ii) sequencing pools using

Viral samples Pools

._,.-u--
-r.-

._ . 
. I. I “I - ___ F-
 .q _- 
1"- --—- ‘
-'- r---. L

"'1.

 

.t

barcoding; (iii) pools deconvolution (PD); i.e. assignment of viral
variants from the pools to individual samples. This approach signifi-
cantly minimizes the number of PCR and NGS runs, reducing the
cost of testing and hands—on time. Additionally, pooling provides
opportunity for PCR amplification of viral variants from each
sample in different mixtures of samples generated in each pool, thus
introducing variation in amplification biases and contributing to
sequencing of a more representative set of viral variants from
each sample.

Pooling—based sequencing of highly mutable viruses such as
human immunodeficiency virus and hepatitis C virus (HCV) is
particularly difficult because of the complexity of intrahost viral
populations, the assessment of which can be distorted by PCR or
sampling biases. It is essential to detect both major and minor viral
subpopulations, since the latter often have important clinical impli-
cations (Campo et 61]., 2014a; Metzner et 61]., 2009; Skums et 61].,
2012b). Mixing of a large number of specimens or specimens with
significant differences in viral titers may contribute to underrepre—
sentation of viral variants from some samples in pools, suggesting
that size and composition of pools should be carefully designed.
Stochastic sampling from genetically diverse intra—host viral popula—
tions usually produces variability in compositions of sets of variants
in different pools obtained from the same sample. Additionally, mix-
ing specimens may differentially bias PCR amplification, contribu—
ting to mismatching between viral variants sampled from the same
host in two pools with different specimen compositions. Thus,
straightforward approaches cannot be used for samples deconvolu—
tion, indicating that a more complex approach based on clustering
techniques is needed. To increase the effectiveness of cluster—based
deconvolution and minimize possible clustering errors, it is import-
ant to minimize mixing of genetically close samples as can be
expected in epidemiologically related samples and samples collected
from a small geographic region.

In this article, we present the first computational framework
for combinatorial pool—based sequencing of highly heterogeneous
viral samples. The framework includes pools design and PD stages.
We formulate the pool design problem as an optimization problem
and propose a heuristic algorithm to solve it. We propose a method
for inference of samples from sequenced pools based on a novel
maximum likelihood clustering algorithm for heterogeneous viral
samples. We report the results of the framework evaluation using
simulated and experimental HCV data.

Amplicnn reads quasispecies

 

# ‘7’;

 

 

 

 .  . K—J "—"- Paul
 ..   . p535 wf sequencmg‘g‘ %  decanvaiuﬁan
  :ET: barcoded harm? 5 "WW"? ..
Mixing E, primers “tawny identiﬁcation r
into pools

Fig. 1. Combinatorial pooling strategy for viral samples sequencing

[I'-

112 /310'spaumo [p.IOJXO'SSUBUHOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

684

P. Skums et al.

 

2 Methods
2.1 Pools design

The basic idea of the overlapping pools strategy for sequencing n
samples is to generate m pools (mixtures of samples) with m << n
in such a way that every sample is uniquely identified by the pools
to which it belongs (Prabhu et al., 2009). Then, after sequencing
of pools the obtained amplicon reads can be assigned to samples by
a sequence of set—theoretic intersections and differences of pools.
The unique assignment is only possible if for any two samples there
is a pool separating them, i.e. containing exactly one of those
samples.

Example. Consider 3 samples 51,52, S3 and 2 pools P1 : S1 U 52,
P2 : Sz US3 (Fig. 2). These pools satisfy the separation require—
ment, and, therefore, each sample can be recovered, e.g.
52 = P1 {1132,51 = P1 \P2,andS3 = P2\P1.

Without constraints, n samples can be inferred using [log 
+1 pools (Theorem S1, also indirectly follows from Prabhu
et al., 2009). However, heterogeneous viral samples impose
restrictions on pools composition: (i) the number of samples per
pool should not be too high; (ii) samples with drastically different
viral titers or samples, which may be epidemiologically related,
should not be mixed together. These constraints make the pool
design problem computationally hard. We formalize the constraints
and formulate the pool design problem as an optimization problem
on graphs.

For a set of samples 8 : {S1, . . ., Sn} consider a samples compati-
bility graph G : G(S) with the vertex set V : V(G) and the edge
set E : E(G), such that V(G) : S and 515,- E E(G) if and only if the
samples S,- and S,- could be mixed together. As aforementioned, infor-
mation on viral load, epidemiological linkage, geographic location,
age/social groups, time of infection, risk factors, etc. may be used to
determine compatibility of specimens. Every feasible pool is a clique
of the graph G. Let T be an upper bound for pools size. The problem
of optimal pool design for viral samples sequencing can be formu—
lated as follows:

Viral Sample Pool Design (VSPD) Problem: given a graph
G : (V,E) and T > 0, find a minimum set of cliques
P = {P1, . . ., Pm} such that 1) UZ—ZlP, : V; 2) for every u, v E V there
is a clique P,- E P separating u and v; 3) |P,-| g T for every
i = 1, . . ., m.

Due to the condition 2), at most one vertex v E V(G) is not cov—
ered by a clique from P. Thus, any family of cliques satisfying 2)

E‘s-u.

 

Fig. 2. Two pools for 3 samples: 81 has 3, 82 has 4 and 83 has 2 variants

and 3) can be forced to satisfy 1) by adding the single clique {v}.
Therefore the condition 1) is not essential and can be dropped.
VSPD is NP—hard (Theorem S2), and we propose a heuristic
(Algorithm 1) for it. We consider a graph H with V(H) : V and
if E E(H) if and only if the pair of vertices (i, j) is not separated yet.
Initially, H is a complete graph. For A Q V a cut in the graph H is
the pair (A, V\A), the size of the cut c(A, V\A) is the number of
edges with one end in A and the other end in V\A. At each iter-
ation, Algorithm 1 finds and adds to the solution a locally optimal
pool, i.e. a clique of G that separates the maximal number of non-
separated samples (see example in Supplementary Figure 82).

 

Algorithm 1 VSPD Algorithm

 

1: 73 <— 0; H <— complete graph on n vertices

2: while E(H) 7E (0 do

3: find a subset AX g V such that |AX| g T, AX is a
clique of the graph G and C(AX, V\AX) in the graph H

is maximal.
4: P <— PU{AX}
5: remove from H all edges uv with u E AX and
v E V\AX.
6: end while
7: return P

 

 

 

The crucial step of Algorithm 1 is locally optimal pool finding
(step 3), which represents a previously unstudied discrete optimiza—
tion problem further referred as Locally Optimal Pool (LOP)
Problem. LOP is not approximable within the factor 111—8 for any
8 > 0 (Theorem S3), and it can be reformulated as follows: find a
partition X : (Ax, Bx) of the set Vminimizing the function

f(X) = C(Axan) — M|E(Elel)| (1)

subject to the constraint |Ax| g T. Here M :  —l— 1, G is a
complement of a graph G, and G[Ax] is the subgraph of G induced
by a set Ax. So, f (X) Z 0 if and only if Ax is a clique. Therefore, for
any optimal solution of the problem (1), the set Ax is a clique.

We propose a heuristic to solve the problem (1). Initially,
we relax the constraint |Ax| g T. For a vertex v E Ax consider the
solution X’ : (AM, BM) : (Ax \ {v}, Bx U  Then

A1 = f(X’) — too = degtgz») — degtuz») + Mdegi. <2)

where deg 5 (v) denotes the number of vertices from the set U Q V
adjacent to v in a graph H. In particular, if v is non—adjacent to some
vertex u E Ax, then A1 > 0. For v E Bx and the solution X’ : (sz,
sz) : (Ax U {v}, Bx \  we have

A2 = f(X’) — too = deg E. (v) — deg tic») — Mdeg 2. <3)

According to (2) and (3), any initial solution can be iteratively
improved by moving vertices from one part of the partition to the
other until a locally optimal solution (A1, B1) cannot be further im-
proved. According to (2), A1 is a clique. However, the objective func—
tion value in a local optimum may be significantly lower than the
value of the global optimum. It is also possible that c(Al,Bl) : 0,
when E(H) 7E 0, which will cause Algorithm 1 to go into an infinite
loop. To overcome these problems we use a tabu search strategy.
The basic idea is that if after the moving of a vertex v the algorithm
arrives at a local optimum, its value is compared with the current
best solution (A*,B*), v is moved back and the moving of v is

112 /310'spaumo [p.IOJXO'SSUBUHOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

Computational framework for NGS

 

prohibited for the next let iterations. The process stops, when it
reaches a local optimum, which has been visited before with the
same configuration of the algorithm states. Finally, the set A* is
reduced to the allowed size. This idea is implemented in Algorithm 2
(see also Supplementary Figure S3). The default value of la, is 1.
If c(A*, B*) = 0, we increase let by one and repeat Algorithm 2.

2.2 Deconvolution of viral samples from pools
2.2.1 Deconvolution using generalized intersections and differences
Let P be the set of pools designed using Algorithm 1 and sequenced
by NGS. As aforementioned, the obtained reads theoretically can be
assigned to samples using set—theoretic intersections and differences
of pools. However, owing to the heterogeneity of viral populations
and sampling bias, individual viral variants and even viral subpopu—
lations sequenced from a certain sample may be different in each
pool containing that sample (see Supplementary Figure S1). It ham-
pers the usage of straightforward set—theoretic operations.

For a pool Pi, let S(Pi) be a set of IDs of samples mixed in it.
In particular, we consider each individual sample R,- as a pool
with |S(R,-)| : 1. A generalized intersection (GI) of pools P1 and P2 is a
pool P1ﬁP2 with S(P1ﬁP2) : S(P1) ﬂ S(Pz), consisting of sequences
from P1 U P2 that belong to the samples from S(P1) ﬂ S(Pz). A gener-
alized difference (GD) PSPZ is a pool with S(P1TP2) : 8(P1) \S(P2)
that contains sequences of the set P1 \ (P 1ﬁP2).

685
and forbid to move v for the next kt iterations:
tabuj,“ <— kt;

(AijM) : {(A‘t\{v},B"U {v}), ifv 6 At;

(A’ U {v},B’ \ {v}), ifv E B’.

16: end if
17: s a ((A’+1,B’+1),tabui+1)
18: if s E optStates then
19: i <— i+ 1; optStates <— optStates U {3}; continue
20: else
21: while |A*| > T do
22: a* <— arg minaeAi{degEL(a) — degﬂ.(a)}
23: (A*, B*) <— (A* \ {a}, B* U {a})
24: end while
25: return A*
26: end if
27: end if
28: end while

 

 

 

 

Algorithm 2 Locally Optimal Pool Problem Algorithm

 

1: Find the solution (X, Y) of Max-Cut problem using
0.5-approximation algorithm (Khuller et al., 2007)
applied to the graph H. Consequently apply the
stages 2—28 to two initial solutions: (A0, B0) = (X, Y)
and (A0, B0) = (Y, X)

2: i<— 0; tabui <— (0, . . .,0); optStates <— 0; moveList <— (D;
(A*, B*) = (A0, B0).

3: while true do

4: for every u E V calculate

A1, ifu E Aiandtabu; : 0(see (2));
5u <— Az, ifu E Biandtabu; : 0(see (3));
0, iftabu; > 0.
5: 6* <—  {Su}; u* <— arg  {8”}

6: Update the tabu state:

tabu,“ (— {tabu} — 1, iftabu} > 0;
1

0, otherwise.

7: if 8* > 0 then
8: update the current cut by moving the vertex u*:
(Ai\{u*},B" U {u*}), ifu* E A’";

(Ai+17Bi+1) <_{ ' ' '
(A’ o {u*},B’\{u*}), ifu* e B’.

9: Push u* into the stack moveList; i<— i+ 1

10: else

11: if f(Ai, Bi) > f(A*, B*) then

12: (A*, B*) <— (A’, B’)

13: end if

14: if moveList 7A (0 then

15: Pop a vertex v from the stack moveList,

 

Individual samples are inferred from pools by a sequence of
GIs and GDs (Algorithm 3). GDs reduce to GIs, which are calcu—
lated using a clustering—based approach (Algorithm 4). In some
cases, when samples with substantial difference in heterogeneity are
mixed together, highly heterogeneous samples can be partitioned
into multiple clusters, while samples with lower heterogeneity are
joined into one cluster. Such clustering may lead to incorrect detec—
tion of GIs and consecutive fail of samples separation. To avoid this
effect, the parameter W of Algorithm 4 with the default value
W = 2 is introduced. If certain samples are not found by Algorithm
3 (i.e. some sets from R are empty), we increase W and repeat
Algorithm 3.

 

Algorithm 3 PD Algorithm

 

Require: The set of pools 73 = {P1,. . ., Pm}

Ensure: The set of individual samples R = {R1,. . ., Rn}
1: define two queues Q <— 73 and R’ <— (D.
2: while Q 7E (0 do
3: P’ <— the first element of Q; Q <— Q\P’

4: if |S(P’)| : 1 then

5: 72’ <— R’ U {P’}

6: end if

7: find the first element P” E Q such that
S(P’) ﬂ S(P”) 7E (D

8: if such element exists then

9: Q<— QU{P’ﬁP”}

10: if S(P’)\S(P”) 7A (0 then

11: Q<— QU{P’TP”}

12: end if

13: if S(P”)\S(P’) 7A (0 then

14: Q a Q o {P”TP’}

15: end if

16: end if

17: end while
18: return last n elements of R’

 

 

 

 

restore the cut, which was changed by the move of v

112 /310'spaumo [p.IOJXO'SSUBUHOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

686

P. Skums et al.

 

 

Algorithm 4 GI Algorithm

 

Require: Pools P1, P2, parameter W 2 1

Ensure: The GI P1ﬁP2

1: K <— |8(P1) US(P2)|

2: Partition P1 U P2 into WK clusters using maximum
likelihood k-Clustering described in Subsection 2.2.2
(Algorithm 5).

3: return union of clusters containing reads from both P1
and P2.

 

 

 

2.2.2 Maximum Likelihood k-Clustering of viral samples

In this section, we consider Viral Sample Clustering (VSC) Problem:
given a set R of N GS reads drawn from a mix of kl viral samples,
partition R into la : Wk’ subsets consisting of reads from a single
sample. The presence of numerous variants, extreme heterogeneity
of viral populations and sequencing errors make VSC challenging.
Although a commonly used clustering objective is to minimize intra-
cluster distances or distance to cluster centers (e.g. the le—means
algorithm), we propose to use a statistically sound objective of maxi—
mizing likelihood. An input of our algorithm is a multiple sequence
alignment of R represented as a matrix with columns corresponding
to the consensus positions and rows corresponding to aligned reads.
Our model assumes that each read is emitted by a particular geno—
type. The proposed clustering (a) finds la genotypes G1, . . . , Gk that
most likely emitted R; (b) assigns each read to a cluster correspond—
ing to a genotype that most likely emitted it.

Formally, given a set of reads Ci, a genotype Gi : g(Ci) is a ma—
trix with columns corresponding to an alignment positions and 5
rows corresponding to the alleles {a, c, t, g, d}, where each entry
Géam is a frequency of allele e in m—th position among all variants in
C. Given a set of reads R, an optimal le-genotype is a set 9* = {
G1, . . . , Gk} of la distinct genotypes that most likely emitted R:

G* : arg max HPr(r|g)°’,
Igl=k .672
k - . . .
where Pr(r|g) : 2,21 ﬁPr(r|G’) IS the probablllty to observe read
r = (r1, . . . , rm), or is its observed multiplicity,  is the frequency of
the genotype Gi and

L
Pr(r|Gi) = H Girmam, (4)
m=1

The log-likelihood of the set of genotypes g equals to
E(G) : ZreRorlogPng). We iteratively estimate the missing data
f, and pir (the frequency of genotype G1 and the portions of reads ori—
ginated from G, that mathches r) using Expectation Maximization
algorithm and solve the easier optimization problem of maximizing

the log-likelihood of the hidden model
k .
(1981(9) =  Pi.r108(ﬁPr(7|G1))-
rER i=1

Our clustering method is described in Algorithm 5. The param-
eters 6 there is the mutation rate.

 

Algorithm 5 Maximum Likelihood k-Clustering Algorithm

 

1: Find k seed reads 31,...,sk by iteratively selecting
the most frequent read maximizing the minimum
Hamming distance to the previously selected reads.

 

 

Then define the initial k-genotype g0 = {Gl,...,Gk}
as follows:
. 1—48,ifsfn:e;
G’em e
7 8, otherwise.
2: hi), <— Pr (r|G’) (see (4)); t <— O;
3: repeat
4: ﬁ(°)<—%foralli=1,...k;t<—O;
5: repeat
6: For each read r and genotype Gi E g“ com-
pute ei,,— the expected number of reads emitted
by Gi that match r.
ff” a.
piJ (— k (I) 7 ei,r ‘— Or ' pi,r
ijlfi ‘blvr
7: Calculate the updated frequency of each
genotype Gi E gt as the portion of all reads emitted
by G:
(1+1) ZTERei’r -
fi <—k—,Z=1,...,l€;T<—T+1;
ijl ZrERei’r
8- until 2k (16(1) — rlttilf > 5
' i=1 I I —
9: Calculate the updated k-genotype gt“ 2
{Gl,...,G"}:
1 — 48, ife : argmax Z piar;
 (— el€{avcvt7g7d} 76722711126,
8, otherwise.
10: hi), <— Pr (r|Gi) (see (4)); t <— t+ 1;
11: until gt 72 gt+1
12: Assign each read r to the cluster in where
jr E are maxmrr

 

 

 

2.3 NGS errors and sequencing failures processing
Before applying deconvolution algorithms, the data are preprocessed
to remove sequencing errors and PCR chimeras. Since errors may
be sample—specific, the following pipeline is used: (i) each pool is
partitioned into clusters using Algorithm 5 ; (ii) NGS error correction
algorithm is applied to each cluster. This algorithm is specific to
sequencing platform and sequenced species. (iii) Corrected reads
from each cluster are used to reinstate pools.

Failure to recover sequences from some samples within certain
pools may result in algorithm’s inability to separate these samples.
Given the aforementioned pools design constraints, use of appropri—
ate PCR conditions and high NGS throughput, we expect that the
probability of a complete loss of a sample within a pool is very low.
Nevertheless, if sequencing of some samples within certain pools
fails, the workflow summarized in Algorithm 6 allows to detect and
eliminate the negative effects of the failures.

 

Algorithm 6 Failure Detection and Processing

 

Require: Datasets R={R1,...,Rn} produced by

Algorithm 3.

1: Identify failed samples Sf <— {jsz =0} (the sample
can be also considered failed, if it does not have

 

 

a required number of reads, i.e. |Rj|gA) and

112 /810'spaumo [p.IOJXO'SSUBUHOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

 

 

 

 

Computational framework for NGS 687
re-sequence them (either individually or using the (3)" ()3),
same pooling framework). For every j E 8f replace R] u, M I
by the obtained data set. E... H
2:foreveryiE{1,...,n}\Sf andjESf do Ens 
3: on = RiﬁRj, Ri <— Ri \ Oiaj, Rj <— Rj U Oiaj :ua  E ___ 
4: end for Eu:   M M”:-
5: return R 3,, ________ _ H _  g n. -
"L  |2I|
“ﬂames assessessses "eeassssssassstsss

2.4 Experimental pools and sequencing

Serum specimens collected from HCV—positive cases (Holodniy
et al., 2012) were used to sequence HCV HVR1 region. Seven sam—
ples S1, . . ., S7 were mixed to form 4 pools P1, . . .,P4 as follows: P1
was created by mixing samples S1,S2, S3, PZ—S4, S5,S6,S7, P3—S1,
S4,S 5 and P4—S2,S4,S6. Specimens and pools were sequenced
using 454 GS Junior System (454 Life Sciences, Branford, CT).
Total nucleic acids extraction was performed using MagNA Pure
LC Total Nucleic Acid Isolation Kit (Roche Diagnostics,
Mannheim, Germany) and reverse—transcribed using SuperScript
Vilo cDNA synthesis kit (Invitrogen, Carlsbad, CA).

HVR1 amplification was accomplished using two rounds of
PCR. For the 1st round, regular region—specific primers were used.
Forward and reverse tag sequences consisting of primer adaptors
and multiple identifiers (MID) were added to the HVR1—specific
nested primers. Pools were processed as a single specimen, tagged
with a single MID. PCR products were pooled and amplified by
emulsion PCR using the GS FLX Titanium Series Amplicon kit, and
bi—directionally sequenced. The NGS reads were identified and sepa—
rated using sample—specific MID tag identifiers. Low quality reads
were removed using GS Run Processor v2.3 and the obtained data—
sets were processed using error correction pipeline with algorithms
KEC and ET (Skums et al., 2012a).

3 Results
3.1 Pools design

Pool design algorithm was evaluated using 3 sets of simulated data.

1) Complete graphs with n : 4,. . ., 1024 vertices and with
T : 00. For every test instance, exactly (log  —l— 1 pools were
constructed, coinciding with the theoretically justified estimation.
Hence, in this case Algorithm 1 produces optimal solutions.

2) Random graphs, where each vertex v receives a random titer
wV E {1, L}, and two vertices u and v are adjacent, when
|ivu — ivV| g R. This family of instances represents titer compatibil-
ity model, i.e. it simulates the case when two samples could be
mixed together only if their viral titers are not sufficiently different.
25 000 test instances were generated with n = 10, . . ., 1000, L : 20
,R : 4 and with the pools sizes thresholds T = n, 55, 35, 25, 15.
For each n the mean reduction coefficient (the ratio of a number of
pools and a number of samples) was calculated (Fig. 3a). For
n = 1000 the reduction of the number of sequencing runs varies
from more than 21 for T = n to 6 for T = 15.

3) Random graphs, where each edge is chosen with probability
p = 0.25, 0.5, 0.75, 1 and pools sizes are bounded by T = 35.
20 000 test instances with n : 10,...,1000 were generated (Fig.
3b). A reduction of the sequencing runs number is also high, al-
though it is generally lower than in 2) (from ~13-fold reduction for
P : 1 to more than 3—fold reduction for P = 0.25, n = 1000).

The reduction coefficient in all these cases is a decreasing
function of n, which suggests a higher reduction for the larger n.

Numb-r DImele

Fig. 3 Reduction coefficients for the pools generated by Algorithm 1 for (a)
random titer compatibility model graphs; (b) random graphs

Working time of the pool design algorithm is shown in
Supplementary Figure S4.

3.2 Pools deconvolution

3.2.1 Simulated pools of experimental data

450 test instances with n = 10, . . ., 150 samples and with pool sizes
thresholds T = 15, 25, 35 were generated using 155 HCV HVR1
samples from the collection of Centers for Disease Control (Campo
et al., 2014a,b; Dimitrova et al., 2012; Lara et al., 2012).
Samples were cleaned using KEC and ET (Skums et al., 2012a).
Test instances were generated as follows: (i) n samples were chosen
randomly; (ii) a random samples compatibility graph on n vertices
was generated based on the titer compatibility model and pools
were designed using Algorithm 1; (iii) pools were created by taking
D = 10 000 randomly selected reads from the samples composing
each pool (in order to simulate a sampling bias). The number
of reads per pool corresponds to the sequencing settings, under
which the data used for simulation were obtained [454 GS Junior
System (454 Life Sciences, Branford, CT) with 8—10 MIDs per
sequencing run].

For all test instances all samples were inferred, i.e. all n data sets
produced by Algorithm 3 were non—empty. The number of reads,
which were not classified into samples was extremely low (Fig. 4a):
in average 99.996% of reads (T: 15), 99.993% (T: 25) and
99.984% (T: 35) were assigned. An overwhelming majority of
reads was classified correctly (Fig. 4b): in average, 99.998% for
T = 15, 99.982% for T = 25 and 99.959% for T = 35. There is no
clear correlation between percentages of classified and correctly
classified reads and the samples number.

We call an incorrect assignment of reads to samples in silico
contamination. The average percentage of samples without in silico
contamination ranges from 100 to 98.13% (T: 15), from 100
to 96.13% (T: 25) and from 100 to 93.8% (T: 35) (Fig. 4c).
In silico contaminants within contaminated samples in average con—
stitute 0.163% (T = 15), 0.545% (T = 25) and 0.892% (T = 35)
of all reads (Fig. 4d). Root Mean Square Error (RMSE) of deconvo—
luted haplotypes frequencies estimation is in average 0.031—0.107%
(T = 15), 0.025—0.139% (T = 25) and 0.028—0.174% (T = 35)
(Fig. 4e). Both the percentages of in silico contaminated samples and
RMSE increase with n.

The accuracy of samples deconvolution is affected by the number
of allowed samples per pool. The algorithm is more accurate for
smaller pools, although the accuracy for larger pools remains high.
Working times of pools deconvolution are shown in Supplemetary
Figure S4.

To test failure detection and processing workflow, 150 test
instances with T = 15 were generated, where in addition to steps

112 /810's112u1no [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

688

P. Skums et al.

 

“I '

37 5111'
QRFFRBQQREERRRH ERRRRERBRSSRRFR

nnnnnn nun-nun

   ‘7”  

'\

EERRREPEFSSRREE

I  ELIE
- ' u ' 01a 
a I ,
. i _ _ 1 . I: n 
I . {4, —r- 1.5-
..-' = 1.5 u I. W _r-Js
i on: -

.  - ... ﬂ 

D _—'
H _ _ _ _“ sssssssssgggagﬁ

u
RRRQREPBREERFHH

Fig. 4 (a) Percentage of classified reads. (b) Percentage of correctly classified reads. (c) Percentage of in silico contamination——free samples. (d) Total frequency of
in silico contaminants within contaminated samples. (e) Root-mean-square error of haplotypes frequencies estimation. Bars represent a standard error

(1)—(3) a random subset of up to 50% of pools was selected, and
in each of these pools all sequences originated from a random subset
of up to 25% of samples were removed. The instances were pro—
cessed by Algorithms 3 and 6 (resequencing was simulated by taking
sequences from the corresponding individual samples). For all test
instances all samples were inferred, and the quality of deconvolution
was comparable with the quality without failures (Supplementary
Figure SS).

3.2.2 Experimental pools

Experimental pools (Section 2.4) were deconvoluted using
Algorithm 3, and the obtained samples (further refered as
p-samples) were verified by comparison with the individually
sequenced samples (i-samples). 10 references were taken from each
i—sample, and the correctness of deconvolution was assessed by
finding the closest reference to each p—sample sequence. Sequences
were aligned using Muscle (Edgar, 2004).

In average, 259 unique haplotypes per p—sample were obtained,
which exceeds the numbers obtained in other studies after the stand—
ard sequencing using 454 Junior System and error correction (Bull
et al., 2011; Caraballo Cortes et al., 2013; Gregori et al., 2013).
In total 99.96% (5463 of 5465) of reads were correctly assigned to
samples. Two reads assigned to sample S7 showed a higher similarity
to a reference from S6. The subsequent analysis showed that these
reads are distant from S6 and S7 as well as from each other: min-
imum distance from these reads to haplotypes from S6 and S7 is 25
and 26, respectively, and the distance between them is 20, while the
mean distance among haplotypes of i—samples S6 and S7 is 3.64 bp
(std 1.21 bp) and 6.12 bp (std 5.25 bp), respectively. Therefore,
these two reads are likely to be sequencing artifacts.

In general, the percentage of haplotypes from i—samples found in
p—samples was not high (Fig. 5a), with an average of 14.66%.
However, when the frequencies of these haplotypes were considered,
the level of agreement was much higher, with an average total fre—
quency of 56.94% (Fig. 5 b). In particular, all individually sequenced
haplotypes with frequencies 210% and 72.73% of haplotypes with
frequencies 25% were found in p—samples.

In general haplotypes from i— and p—samples cover the same
areas of the sequence space, although some branches are formed
by variants sequenced in only one of experiments (Fig. 6). The
differences between haplotype frequencies distributions for i— and
p—samples were measured using Jensen—Shannon Divergence (JSD)
and correlation coefficient (Corr) (Table 1). JSD varies from
0.15 (S1) to 0.65% (S7). A correlation between frequencies dis—
tributions is positive and statistically significant for all samples
except S7, in which a large cluster of variants was not detected by
the individual sequencing, but was found in the pooling experiment
(Fig.6).

1':

H

F:

R

 

I."-

lllllli

Fig. 5 (a) Percentage of haplotypes from i-samples found by pooling. (b) Total
frequency of haplotypes from i-samples found by pooling

.  Tit-Ti” - .

   

Fig. 6 Phylogenetic trees of viral populations of samples 81-87. Haplotypes
of i-samples and p-samples are shown in red (light) and blue (dark)

Table 1. Comparison of frequency distributions for i- and
p-samples

 

JSD Corr (P—value) JSD Corr (P—value)

 

51 0.15 0.95 (1.710”) 55 0.50 0.25 (8.610”)
52 0.57 0.30 (0.0023) 56 0.17 0.99 (0)

S3 0.32 0.89 (2710—173) S7 0.65 —0.07 (0.16)

S4 0.37 0.66 (4.4140—99)

 

112 /810'S[12u1no [p.IOJXO'SOTlBIIlJOJUTOTQ/ﬂClllq 111011 pep1201umoq

9IOZ ‘OE lsnﬁnv uo ::

Computational framework for NGS

689

 

4 Discussion

In this study, we present a novel computational framework for mas—
sive NGS of highly mutable viruses. To the best of our knowledge,
this is the first pooling framework applicable for sequencing of viral
quasispecies, which takes into account extensive heterogeneity of
viral populations, the large number of distinct viral variants
sequenced from each sample and the effects of PCR and sampling
biases. The proposed strategy drastically reduces the cost of
sequencing per specimen (Supplementary Section 85), while still pro-
viding sufficient amount of information in support of molecular sur—
veillance and other applications of viral sequences in clinical and
epidemiological settings. The framework is applicable to viral agents
infecting humans and animals and, with further development of
experimental protocols, it should serve as a cost—effective foundation
for molecular surveillance of infectious diseases.

Ultra—deep sequencing of viral samples produces a wide range of
intrahost viral variants and allows for detecting even minor viral
subpopulations. Pooling of several specimens reduces the depth of
sequencing for each specimen, but this reduction is not detrimental,
since each specimen is usually used in more than one pool. As speci—
men is tested more than once, the number of sequenced variants
is increased, so representative sampling of viral subpopulations
infecting each patient can be improved. The experiments conducted
here showed that comparable subpopulations were recovered
from individual specimens and from pools, at least at the pooling
scale used in this study. Both individual sequencing and pooling
produce sequences covering approximately the same areas of the
sequence space, thus providing a consistent structure of a viral
population.

Repeat sampling from the same complex viral population often
results in poorly matched sets of sequences, thus presenting a signifi-
cant challenge to pools deconvolution. Such stochastic sampling
has a potential to diminish the effectiveness of pool—sequencing and
usefulness of the obtained sequences by impeding the correct alloca—
tion of sequences to samples, leaving some samples without
sequences assigned or allocating only a fraction of the sequences.
The clustering approach developed in this study significantly
improves assignment of sequences to samples and, thus, not only
substantially overcomes the aforementioned potential pitfalls, but
converts stochastic sampling into an advantage. Clustering also
eliminates the detrimental effect of NGS errors, since erroneous
reads tend to concentrate around correct haplotypes.

The sequencing cost and accuracy of deconvolution are two
major measures of quality of our framework. These two measures
are in conflict with each other: while increase in pool size improves
cost—effectiveness of sequencing by reducing the number of sequenc—
ing runs, it reduces accuracy of deconvolution. Considering that
deconvolution accuracy significantly depends on the genetic com—
plexity of intrahost viral populations, an optimal pool size should be
carefully selected for each virus and genomic region.

In conclusion, success of the pool—based sequencing of viral
populations depends to a significant degree on the efficacy of
sequence assignments and the risk of under—representation of
viral variants from some samples, owing to PCR and sample
biases. The pool design and clustering algorithms presented
here substantially minimize the detrimental effect of these biases
on the sequencing quality. Further reduction of the biases using
generalizations of error—correcting codes and optimization of experi—
mental conditions may further improve the strategy, facilitating
its application to molecular surveillance and study of infectious
diseases.

Acknowledgements

We thank reviewers for helpful comments and Seth Sims and Vernard Martin
(CDC/NCEZID) for help with CDC cluster.

Conﬂict of interest: none declared.

References

Alon,S. et al. (2011) Barcoding bias in high-throughput multiplex sequencing
of mirna. Genome Res, 21, 1506—151 1.

Bansal,V. (2010) A statistical method for detection of variants from next-
generation resequencing of dna pools. Bioinformatics, 26, i318—i324.

Berman,P. et al. (2004) Tight approximability results for test set problems in
bioinformatics. Lect. Notes Comput. Sci., 3111, 39—50.

Bull,R. et al. (2011) Sequential bottlenecks drive Viral evolution in early acute
hepatitis c Virus infection. PLOS Pathog, 7, e1002243.

Campo,D. et al. (2014a) Drug-resistance of a Viral population and its individ-
ual intra-host variants during the ﬁrst 48 hours of therapy. Clin. Pharmacol.
Then, 95, 627—635.

Campo,D. et al. (2014b) Next-generation sequencing reveals large connected
networks of intra-host hcv variants. BMC Genomics, 15 (Suppl 5), S4.

Caraballo Cortes,K. et al. (2013) Ultradeep pyrosequencing of hepatitis c Virus
hypervariable region 1 in quasispecies analysis. Biomed. Res. Int., 2013,
626083.

Culasso,A. et al. (2014) Intra- host evolution of multiple genotypes of hepatitis
c Virus in a chronically infected patient with HIV along a 13-year follow-up
period. Virology, 449, 317—327.

Deakin,C.T. et al. (2014) Impact of next-generation sequencing error on ana-
lysis of barcoded plasmid libraries of known complexity and sequence.
Nucleic Acids Res., 42, e129.

Dierynck,I. et al. (2014) Deep sequencing analysis of the hcv ns3-4a region
conﬁrms low prevalence of telapreVir-resistant variants at baseline and end
of the realize study. ] Infect Dis., pii, jiu340.

Dimitrova,Z. et al. (2012) Assessments of intra- and inter-host diversity of
hepatitis c Virus using next generation sequencing and mass spectrometry.
In Silico Biol., 11, 183—192.

Du,D.-Z. et al. (2006) Pooling Design and Nonadaptive Group Testing:
Important Tools for DNA Sequencing, volume 18. World Scientiﬁc
Publishing Company. Series on Applied Mathematics.

Duma,D. et al. (2013) Accurate decoding of pooled sequenced data using com-
pressed sensing. Lect. Notes Comp. Sci., 8126, 70—84.

Edgar,R. (2004) Muscle: multiple sequence alignment with high accuracy and
high throughput. Nucleic Acids Res., 32, 1792—1797.

Erlich,Y. et al. (2009) Dna sudoku — harnessing high-throughput sequencing
for multiplexing specimen analysis. Genome Res, 19, 1243—125 3.

Golan,D. et al. (2012) Weighted pooling-practical and cost-effective tech-
niques for pooled high-throughput sequencing. Bioinformatics, 28,
i197—i206.

Gregori,]. et al. (2013) Ultra-deep pyrosequencing (udps) data treatment to
study amplicon hcv minor variants. PLOS One, 8, e83361.

He,D. et al. (201 1) Genotyping common and rare variation using overlapping
pool sequencing. BMC Bioinformatics, 12(Suppl. 6), 82.

Holodniy,M. et al. (2012) Results from a large-scale epidemiologic look —
back investigation of improperly reprocessed endoscopy equipment. Infect
Control Hosp. Epidemiol., 33, 649—656.

Khuller,S. et al. (2007) Greedy methods. In: T.F., Gonzalez (ed.) Chapter
Handbook of Approximation Algorithms and Metaheuristics. Chapman
and Hall/CRC, Boca Raton.

Lara,]. et al. (2012) Coordinated evolution among hepatitis c Virus genomic
sites is coupled to host factors and resistance to interferon. In Silico Biol.,
11, 213—224.

Lonardi,S. et al. (2013) Combinatorial pooling enables selective sequencing of
the barley gene space. PLOS Comput. Biol., 9, e1003010.

Metzner,K.]. et al. (2009) Minority quasispecies of drug-resistant hiV-1
that lead to early therapy failure in treatment-naive and -adherent patients.
Clin. Infect Dis., 48, 239—247.

112 /810's112u1no [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

690

P. Skums et al.

 

Palmer,B.A. et al. (2012) Insertion and recombination events at hypervariable
region 1 over 9.6 years of hepatitis c Virus chronic infection. ]. Gen. Virol.,
93,2614—2624.

Prabhu,S. et al. (2009) Overlapping pools for high-throughput targeted
resequencing. Genome Res., 19, 1254—1261.

Ramachandran,S. et al. (2011) Temporal variations in the hepatitis c Virus
intrahost population during chronic infection. ]. Virol., 85, 6369—63 80.

Shental,N. et al. (2010) Identiﬁcation of rare alleles and their carriers using
compressed se(que)nsing. Nucleic Acids Res., 38, 1—22.

Skums,P. et al. (2012a) Efﬁcient error correction for next-generation
sequencing of Viral amplicons. BMC B ioinformatics, 13(Suppl 10), S6.

Skums,P. et al. (2012b) Numerical detection, measuring and analysis of
differential interferon resistance for individual hcv intra-host variants and
its inﬂuence on the therapy response. In Silico Biol., 11, 263—269.

Wang,W. et al. (2014) High-resolution quantiﬁcation of hepatitis c Virus
genome-wide mutation load and its correlation with the outcome of
peginterferon-alphaZa and ribavirin combination therapy. PLOS One, 9,
e100131.

Wertheim,]. et al. (2014) The global transmission network of HIV-1. ] Infect
Dis, 209, 304—313.

Wu,W. et al. (2006) On error-tolerant dna screening. Discrete Appl. Math.,
154, 1753—1758.

112 /810's112u1no [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

