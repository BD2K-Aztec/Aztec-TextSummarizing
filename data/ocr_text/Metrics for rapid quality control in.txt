Bioinformatics Advance Access published August 6, 2016

 

Structural Bioinformatics

Metrics for rapid quality control in RNA struc-
ture probing experiments

Krishna Choudharyl, Nathan P. Shihl, Fei Dengl, Mirko Leddal, Bo Liz, and Sha-
ron Aviran1’*

1Department of Biomedical Engineering and Genome Center, University of California at Davis, Davis, Califor-
nia, USA

2Center for RNA Systems Biology, University of California at Berkeley, Berkeley, California, USA

*To whom correspondence should be addressed.

Associate Editor: Prof. lvo Hofacker

Abstract

Motivation: The diverse functionalities of RNA can be attributed to its capacity to form complex and
varied structures. The recent proliferation of new structure probing techniques coupled with high-
throughput sequencing has helped RNA studies expand in both scope and depth. Despite differences
in techniques, most experiments face similar challenges in reproducibility due to the stochastic nature
of chemical probing and sequencing. As these protocols expand to transcriptome-wide studies, quali-
ty control becomes a more daunting task. General and efficient methodologies are needed to quantify
variability and quality in the wide range of current and emerging structure probing experiments.
Results: We develop metrics to rapidly and quantitatively evaluate data quality from structure probing
experiments, demonstrating their efficacy on both small synthetic libraries and transcriptome-wide
datasets. We use a signal-to-noise ratio concept to evaluate replicate agreement, which has the ca-
pacity to identify high-quality data. We also consider and compare two methods to assess variability
inherent in probing experiments, which we then utilize to evaluate the coverage adjustments needed
to meet desired quality. The developed metrics and tools will be useful in summarizing large-scale
datasets and will help standardize quality control in the field.

Availability: The data and methods used in this article are freely available at:
http://bme.ucdavis.edu/aviranlab/SPEQC software.

Contact: saviran@ucdavis.edu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

1 Introduction

RNA plays an integral role in many biological processes, spanning an
enormous range of functionalities (Sharp et al., 2009), whose root often
lies in structure. Discerning structure is thus of paramount importance,
but it remains a challenging task, as traditional methods such as crystal-
lography are time consuming whereas computational approaches strug-
gle to correctly predict it by sequence alone. The recent advent of afford-
able and efﬁcient high-throughput structure probing experiments has
helped address these deﬁciencies (Smola et al., 2015; Watters et al.,
2016; Poulsen and Kielpinski, 2015; Sager et al., 2015; Spitale et al.,

2015; Cheng et al., 2015; Spitale et al.,2014; Ding et al., 2014; Rouskin
et al., 2014; Kielpinski and Vinther, 2014; Hector et al., 2014; Seetin et
al., 2014; Talkish et al., 2014; Wan et al., 2013; Mortimer et al., 2012;
Lucks et al., 2011; Underwood et a], 2010; Kertesz, et al., 2010). Fur-
thermore, their outputs can be used to constrain structure prediction
algorithms and improve prediction accuracy (Deigan et al., 2009; Reuter
and Mathews, 2010; Lorenz et al., 2015; Markham and Zuker, 2008;
Lorenz et al., 2016) or utilized in other applications (Kutchko et al.,
2015, Lavender et al., 2015). Probing experiments use reagents, such as
SHAPE and DMS, which modify RNA residues in a structure-dependent
manner Weeks, 2010). Modiﬁcations are detected via reverse transcrip-
tion, which terminates at modiﬁed sites. Noise due to random termina-

© The Author (2016). Published by Oxford University Press. All rights reserved. For Permissions, please email:

journals.permissions@oup.com

9mg ‘09 1sn8nV uo soroﬁuV soq ‘BlIIJOJﬂBQ JO AllSJQAlII [1 112 [glO'SIBILInO[plOJXO'SODBIILIOJHlOlQ/[Zdinq IIIOJJ popcorn/hog

 

tions is measured in a control assay. Modiﬁcation and control measure-
ments are then combined to yield a ﬁnal reactivity score: residues with
high reactivities are more likely to be unstructured, while low reactivities
are suggestive of pairing interactions (SukOSd et al., 2013).

The newest generation of experiments utilizes high-throughput se-
quencing to detect modiﬁcations, allowing for unprecedented multiplex-
ing capabilities. Focus is now shifting towards in viva and transcriptome-
wide studies, leading to a breadth of new insights (Mortimer et al.,
2014). While these developments are exciting, they face signiﬁcant
challenges in standardizing data due to differences in chemistries, proto-
cols, and analysis strategies. For example, most techniques detect modi-
ﬁcations as reverse transcriptase (RT) terminations, but others induce
mutations at modiﬁed sites (Smola et al., 2015). Despite these differ-
ences, reactivity calculation reduces to a comparison of detection rates
between modiﬁed and control channels, giving rise to a uniﬁed approach
for evaluating and optimizing data analysis (Shih et al., in revision). But
even if methods are standardized, tools are needed to evaluate data quali-
ty obtained by each of these experiments (Aviran and Pachter, 2014).

The problem of quality control can be addressed in rudimentary ways
when examining a few transcripts, through visual inspection or simple
statistical tests. As the ﬁeld moves towards large-scale genome-wide and
in viva experiments, evaluating quality of datasets or individual tran-
scripts becomes increasingly difﬁcult. Examination of these data must
consider issues such as non-uniform coverage, priming biases, increased
transcript lengths, large number of transcripts, and increased number of
replicates. Similar to challenges faced in early stages of microarrays and
RNA-Seq (Bolstad et al., 2003; Ritchie et al., 2015), a convenient and
standardized method for quality control must be developed.

We present broadly applicable methods to analyze and to improve re-
producibility of structural data. At the core of our approach is a general-
izable metric that we introduce, which quantiﬁes agreement among
replicates. We validate and characterize it on SHAPE-Seq data obtained
in highly controlled in vitra conditions, featuring multiple replicates and
very deep coverage across eight well-characterized RNAs (Loughrey et
al., 2014). Our validation then reveals a quality threshold to be used with
this metric, thereby facilitating simple and rapid preliminary quality
screenings. We also address situations where multiple replicates are not
available and present methods for quality control, which quantify tech-
nical variability in experiments. Finally, we explore additional applica-
tions of our approach, such as analysis of large-scale in viva datasets,
reproducibility veriﬁcation for differential analysis, and experiment
design. Our tools are designed with simplicity in mind, making quality
assessment accessible to experimentalists. Our work represents the ﬁrst
generation of broadly applicable quality control methods in structure
probing experiments, a necessary step in the maturation of this ﬁeld.

2 Methods

We extracted SHAPE-Seq counts for three replicates of eight RNAs with
lengths ranging from 74 to 338 nt and for a single replicate of TPP ri-
boswitch in absence and presence of ligand, all probed in vitra. Three
processed SHAPE-Seq replicates of HIV RRE before and after Rev-RRE
complex formation in vitra were provided by Yun Bai. We also pro-
cessed raw reads into counts from two replicates of yeast and mouse
transcriptome-wide in viva Mod-Seq and icSHAPE experiments, respec-
tively. See Supplementary Information for details.

2.1 Reactivity reconstruction
Extracted counts tally the number of modiﬁcations detected at each
residue k in the modiﬁed (plus) and control (minus) channels. In

SHAPE-Seq and similar assays, counts represent RT stop or termination
events, obtained by identifying all sequenced cDNAs whose 3’ ends map
to one residue downstream of k. SHAPE-Seq proﬁles were obtained by
initializing RT at a single priming site at each transcript’s 3’ end, result-
ing in cDNAs spanning sequences between priming and stop sites. Such
targeted priming allowed us to recover the local coverage, which is the
sequencing depth at a residue, deﬁned as the number of reads that either
stop at or pass through said residue (see Supplementary Figure 1). We
denote stop counts in plus and minus channels by Xk and Yk, respectively,
and local coverages in said channels by CH and Ck_, respectively. We
then converted counts into two stop rates, Xk/CH and Yk/Ck_, to normalize
them for variation in local coverages among residues and channels.

Transcriptome-wide proﬁles were obtained from random primer ex-
tension (RPE) experiments coupled with single-end reads to identify stop
sites only. In such protocols, absence of mate-pair reads precludes recov-
ery of local coverages (Supplementary Figure 1). Instead, for each tran-
script, we used its average number of mapped reads per residue.

Plus channel stop counts reﬂect a combined effect of modiﬁcation and
natural RT termination, or noise. To measure the degree of modiﬁcation
at residue k, we deﬁned its reactivity, ﬂk, as its probability of being modi-
ﬁed. To estimate the noise component in the plus channel counts, we
introduced an auxiliary parameter, 7],, as the probability that RT stops at
residue k due to factors others than modiﬁcation. Our goal was to esti-
mate the ﬂk ’s from sequencing data.

We used a model-based maximum-likelihood (ML) approach to esti-
mation, previously developed for similar data (Aviran et al., 2011a). The
ML estimate (MLE) of yk was directly recovered from minus channel
data as the ratio of the kth stop count to the kth local coverage count,
Yk/Ck_. A simple and intuitive way to account for noise in plus channel is
to estimate ﬂk as the difference of stop rates between channels (Eq. 1):

A k A A k

5k — a — Yki Yk — a
We chose this estimate for its simplicity and because its outputs closely
matched those of ﬂk’s MLE, which takes a more complex form (Aviran
et al., 2011b; Shih et al., in revision). Note that while ﬂk is constrained
by deﬁnition to lie in the unit interval, there is no guarantee that Bk 2 0,
as it is a difference of two terms from independent channels. Indeed,
such data inconsistencies between channels arise in practice, and we
employed a standard remedy of setting negatives to 0. Notably, ML
estimation yields the same principle (Aviran et al., 2011b).

Differences in experimental conditions and transcript properties result
in varying degrees of modiﬁcation (i.e., signal power) among reactivity
proﬁles. The extent to which a transcript was modiﬁed, or its modiﬁca-
tion rate, was computed by summing the Bk’s. To bridge these differ-
ences, we normalized each proﬁle with the commonly used 2%-8%
strategy (Sloma and Mathews, 2015; Low and Weeks, 2010). This step
amounts to scaling by a constant and it is necessary for placing all meas-
urements on common scale prior to any comparative or joint analysis.
Normalized values would then be placed both below and above 1.

For transcriptome-wide data, reactivities were similarly reconstructed,
with the difference that stop rates were evaluated with respect to tran-
script coverages. See Supplementary Information for further details.

2.2 SNR calculation
SNR per residue k was calculated as the ratio of its reactivity’s sample
mean to sample standard deviation (Equation 2):
SNRk = 
0k
It is undeﬁned when standard deviation is zero (reactivities are equal).

SNR can be summarized over a stretch of residues or entire transcript in
various ways, e.g., mean, boxplot, or pie chart. To reduce the sensitivity

9mg ‘09 isnﬁnV uo soroﬁuV soq ‘BIHJOJIIBQ JO AiiSJQAiu [1 112 ﬂJO'srcumo[pJOJXO'sopchoguiotq/ﬁdnq IIIOJJ popcorn/hog

 

 

 

 

 

 

   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

(D o . . _
A hepC IRES cyclic di—GMP D § §‘ "0“
S 2 c '
U E § -— . . o
>- g . o: O a
E  ° ‘ . I. ' “I . I
0
w 5 1o 15
E 3 § — r=o.75‘
9 °° o '
I I I I I I I I g 2 0 . .
o 100 200 300 o o 9 §- " . °
residue 3 . “3° . .
B . . C 0' ° _ ° I . I I
hepC IRES cyclrc dI-GMP 8. — . ,., ... o . 5 1o 15
0 ° C F . . o. ' I .
N N ° ° ‘32 153.— . ’. I 5 °— -- r=—0.14
2 as o 3 o o g E D  2 o
8 t? 8 o m 9 8-“ . I  r" o I o
= m?” = a (D L 0 'D h c: _ a
Q. 0 Q. 0 n- 8 . I o ‘- . I ' '
a) a) g _ E g o ‘c o '
L  r=-98 L "° ° r=.57 d .- | 3- . - . .°
° l l | I I |
2 4 1 00 2.5 so 75 10.0 5 1o 15
replicate 1 replicate 1 mean SNR b00t3trap SNR

Fig. 1. Validation and characterization of SNR as a measure of replicate agreement in a small synthetic library. (A) Two RNAs that display strong or poor replicate agreement (continu-

ous and dashed lines). Insets show box plots of their residue SNR distributions, with corresponding mean SNRs marked by blue lines as well as annotated on SNR axes. The box plots reveal the

presence of high residue SNR values, leading to high mean SNR, for hepC IRES, while for chMP, residue SNR is concentrated at low values, resulting in low mean SNR. (B). Scatter plot

representations of pairwise replicate agreement for each RNA. (C) Relationship of mean SNR and Pearson correlation for 24 pairwise replicate comparisons. Line marks high-quality threshold

of 5. (D) Correlation of mean SNR with the following controllable experimental parameters (top to bottom): minus channel coverage rate, plus channel coverage rate, and modiﬁcation rate.

Each panel features 24 dots corresponding to 24 SHAPE-Seq proﬁles. SNR for each proﬁle was estimated from bootstrap simulations of stop counts.

of the mean to outliers and improve its robustness, we clipped all values
above 35 to 35 (see Supplementary Information for details).

2.3 Bootstrap analysis

Bootstrap resampling was performed using the sample ﬁinction in R.
Resampling of both start and stop counts could be done for paired-end
reads. However, SHAPE-Seq experiments used single-primer extension
with ﬁxed start site. Hence, only resampling of stop counts was required.
Local coverage was determined by summing stop counts at or down-
stream of a residue. More detail and performance evaluation are included
in Supplementary Information.

2.4 Variance estimates

A closed-form expression was derived to estimate variances of reactivity
estimates as alternative to bootstrap. Assuming (1) binomial distribution;
(2) statistical independence of terminations in plus and minus channels;

and (3) ﬁxed local coverage; variance can be estimated as (Equation 3):
V’cIr(Xk) V’aTr(Y,,)

 

VaT(Bk) = _ 613+ C]?—
_ (3k+?k(1-l7k))(1-l?k-I7k(1—l7k)) 17k(1—17k)
— Ck+ Ck- I

Its derivation and the derivation for reactivity calculated as a ratio are
described in Supplementary Information.

2.5 Coverage Quality Index (CQI)

We developed a scoring strategy — coverage quality index (CQI) — to
assess coverage adjustments required to meet user-speciﬁed quality
criteria. Speciﬁcally, we asked for an acceptable range of variation (8k)
around the mean reactivity and a signiﬁcance level, which represents the
likelihood that reactivity estimates from experiments with predicted
coverage level would deviate from current estimates within that allowed
range. Range of variation is deﬁned as a percentage error around the
reactivity. Given the percentage error and z-value corresponding to sig-
niﬁcance level, we estimated the variance of reactivities, under the as-
sumption that they are Gaussian random variable, as (Equation 4):

e * B 2
V/ErNarmal =  '

value
This variance is then substituted into Equation (3) to solve for desired
local coverage, CH, keeping Bk and 7k ﬁxed. CQI is calculated as the
ratio of desired coverage to current coverage. The indices for low, medi-
um, and high reactivities were summarized as the 95th percentile for
each category and presented together as what we call “95% CQI”. See

Supplementary Information for more details and for validation.

3 Results

Differences in experimental conditions result in inevitable variability
between replicates. For experiments that probe a few RNAs, visu-
al/manual inspection of replicate data makes quality control relatively
straightforward (Aviran and Pachter, 2014). However, the recent emer-
gence of transcriptome-wide experiments presents challenges in rapidly
screening a multitude of long transcripts or regions within them for
strong or weak replicate agreement. Here, we propose a quantitative and
broadly applicable approach to automatically assess this, which will be
useﬁil for researchers as they evaluate small or large datasets. We ﬁrst
introduce the basic concept and validate its efﬁcacy using a small high-
quality dataset obtained in well-controlled conditions. This not only
conﬁrms the method’s indicative power but also results in simple guide-
lines for rapid quality assessment. With a simple approach at hand, we
strive to broaden its scope through its application to additional problems
and biological scenarios. These include reproducibility assessment in the
absence of replicates, experiment design for improved reproducibility,
analysis of transcriptome-wide data, and reproducibility measurement in
differential analysis situations. Some of these instances also triggered us
to develop novel adjoining methods, which we describe below.

3.1 Using signal-to-noise ratio to assess reproducibility

At the core of our approach is a concept co-opted from signal processing,
the signal-to-noise ratio (SNR), as a simple and informative metric of
reproducibility, which quantiﬁes disagreement between replicates irre-

910z ‘09 1sn8nV uo sojoﬁuV soq ‘121u10111123 10 A11819Atuf1 112 /810'S{12umo[p101x0'sot112u1101uiotq/ﬁd11q 111011 popcorn/hog

 

spective of the underlying sources of variation. Here, we calculate SNR
as ratio of a reactivity’s mean to its standard deviation (see Methods), as
commonly done in image analysis (Bushberg et al., 2012).

We use a SHAPE-Seq dataset (Loughrey et al., 2014) to demonstrate
our metric’s capacity to discern high-quality data, as this set encom-
passes numerous well-characterized and highly structured RNAs, featur-
ing three replicates for each RNA (see Methods). Even though replicates
were generated under the same conditions, differences arise in a similar
manner to those observed in biological replicates, though in this case
RNAs were transcribed in vitro. This allows us to validate our method in
a simple setting before applying it to more complex situations.

To establish the diagnostic capacity of SNR, we look at agreement
among pairs of replicates. We generate reactivity proﬁles for each repli-
cate using a previously derived estimation method coupled with a widely
used normalization strategy (see Methods). Three replicates of eight
RNAs give rise to 24 pairwise comparisons. To qualitatively demonstrate
how SNR measures replicate concurrence, consider two pairs that con-
trast in their level of agreement: the hepC IRES domain features con-
sistent overlaps, while cyclic di-GMP has several regions of discrepan-
cies (Figure 1A-B). SNR captures these differences well, as can be seen
from box plots of residue SNR distributions per transcript. Such differ-
ences are clearly observed when represented as the mean value of a
transcript (Figure 1A, insets). Thus, summary statistics such as mean
SNR may be useﬁil in assessing agreement over regions of RNA.

Next, we quantitatively evaluate how well mean SNR captures repli-
cate agreement for all 24 pairwise comparisons. We examine mean
SNR’s relationship with a common pairwise evaluation statistic - Pear-
son correlation. We ﬁnd that both provide reliable evaluations of agree-
ment, as replicate pairs with strong SNR also display high correlation
coefﬁcients (Figure 1C). Notably, a sharp increase in correlation coefﬁ-
cients toward 1 is associated with mean SNR values ranging from 3 to 5,
with 5 marking a plateauing of such step-like relationship. This observa-
tion ﬁirther simpliﬁes the use of mean SNR, as it allows for rapid prelim-
inary screening: replicates with SNR greater than 5 can be conﬁdently
classiﬁed as high quality. It is also worth noting that values between 3 to
5 may also signify good replicate agreement, although with lower conﬁ-
dence. For transcripts that fall in this ambiguous range, we recommend
ﬁirther examination via boxplot analysis of residue SNR scores, to reveal
where the bulk of the distribution lies (Figure 1A, insets). Finally, SNR
confers another advantage: it accommodates an arbitrary number of
replicates, a feature that traditional correlation tests do not have unless
they involve complex statistical considerations.

3.2 Reproducibility assessment in the absence of replicates
Numerous factors other than biological variation exert their effect on
probing measurements. For example, chemical reactions and detections
are inherently stochastic, and repeated library preparation followed by
sequencing results in technical variability. In the absence of multiple
replicates, it is still possible to assess such form of variability. Here, we
propose two methods, one data-driven and the other model-based.
Non-parametric approach. A simple and well-established approach
is to leverage resampling methods in order to synthesize “fake” repli-
cates in lieu of real ones. An appealing feature is their capacity to gener-
ate large numbers of replicates, which is infeasible in the lab. This has
the potential to improve mean and variance estimation precision. It is
thus advantageous to use SNR in such setting, as traditional reproducibil-
ity metrics or visual inspection become prohibitive when replicate num-
bers exceed 2 or 3. By readily accommodating a multitude of replicates,
SNR allows us to reap the beneﬁts of both powerﬁil computers and
large-sample statistics. We mimic replicates through bootstrap simula-

tions, synthesizing multiple datasets from the original one rather than
relying on any model assumptions. We repeatedly resample the distribu-
tion of SHAPE-Seq counts a hundred times and reconstruct reactivities
as described above, keeping coverage at original level (approximately
8,000 reads per residue on average). See Methods and Supplementary
Information for implementation details.

Parametric approach. It is important to acknowledge potential limi-
tations of bootstrap. The computational resources required in resampling
can be limiting, especially as complexity and scale of experiments in-
crease. Bootstrapping SHAPE-Seq data is straightforward because of the
small number of RNAs and the usage of a single primer. Thus, all reads
start at the same site and one merely resamples stop sites. In contrast,
paired-end reads originating from RPE experiments warrant greatly
increased computational effort to account for both start and stop sites,
amounting to quadratic grth in the size of count distributions from
which one resamples. This is exacerbated in transcriptome-wide studies,
as transcript numbers, lengths, and the sequencing volume render
resampling computationally demanding, if not infeasible.

To address such issues, we derive a formula to estimate variance in
reactivities given stop counts and local coverage at a residue (see Meth-
ods). We treat the probability of a read as binomially distributed and then
express the standard deviation of the simpliﬁed MLE described in Meth-
ods. To validate the efﬁcacy of such formula-based estimate, we com-
pare it to the bootstrap-based one (see Supplementary Information for
details). Overall, we ﬁnd that formula calculations yield results similar to
those generated by laborious simulations.

3.3 Application to experiment design

In experiment design, one seeks to identify key controllable determinants
to data variability (Aviran and Pachter, 2014). We accomplish this by
comparing mean SNR per transcript with controllable factors from each
probing experiment: plus and minus channel per-residue coverage, total
coverage per channel, ratio of channel coverages, and modiﬁcation rate
(see Methods). Interestingly, we ﬁnd that plus channel coverage shows a
stronger correlation (r = 0.74) than minus channel coverage (r = 0.4)
G‘igure 1D). In contrast, modiﬁcation rate (Figure 1D) and ratio of cov-
erage between plus and minus channels (not shown) have no correlation
with SNR strength. Notably, we see similar trends for experimental
replicates, with moderate correlation between SNR and coverage levels
(not shown). The agreement between experimental and simulated results
not only validates our method, but more importantly highlights how SNR
elucidates key determinants of quality.

3.3.1 Data-informed coverage adjustment

Increasing coverage is an obvious route to improving quality; yet, it is
costly. One may want to ﬁrst evaluate the extent of necessary adjust-
ments — a non-trivial task. Here, we address this need by developing a
new metric: coverage quality index (CQI). Given desired reproducibility,
CQI measures if current local coverage levels are sufﬁcient to maintain
them and, if not, approximates how much more coverage is needed.

We ﬁrst frame reproducibility in terms of individual constraints on
admissible degrees of ﬂuctuation at each residue. For realistic modeling,
we turn to SHAPE-Seq data, where we observe differing variabilities.
We ﬁnd that the relationship between a reactivity’s mean and its stand-
ard deviation is linear on a log scale, such that standard deviation in-
creases at nearly the same rate as the mean (Supplementary Figure 2).

Based on this, we assume that a reactivity’s variability is proportional
to itself. A target coefﬁcient of proportion (8k) is to be set by the user.
For example, if a reactivity is 0.5, a=20% would result in values within
(0.4, 0.6). We use 8k and a user-deﬁned signiﬁcance level (cc) to calcu-

910z ‘09 1sn8nV uo sojoﬁuV soq ‘121u10111123 10 A11819Atuf1 112 /810'sp2umo[p101x0'sot112u1101uiotq/ﬁd11q 111011 popcorn/hog

SAM-l riboswitch

 

N

3‘

lg

% x—

9

D
0 60
r ’ d 'I
: : user-defined
I 8k, Otk . variability
I I parameters
I I
I I
I I
I l
' i i '
I I
I _i I
I. — — _ — _ _ — — — _ J
extrapolate variance 2k = f(8k, 01k)

solve for coverage quality CQI =g(<53k, Bk, ‘i’k. Ck)

CQI distribution

 

 

 

 

 

3 :95%
5 _ I
C
0N I
30' '
9 I
., mmm
o 4 a

CQI

I

high medium low

95%CQI 1.19

2

reactivity

 

20 60 1 00
residue

Fig. 2. Workﬂow for CQI calculations. Top bar graph shows data for SAM-I ri-
boswitch. Dashed lines separate reactivities into low/medium/high categories. Zoomed
inset of reactivities highlights two user-deﬁned parameters: signiﬁcance level, illustrat-
ed by the shaded area under the Gaussian curves placed on top of each reactivity bar,
and desired ﬂuctuation intensity, depicted by the dashed error bar. Vertical arrow and
formulas below the inset represent core calculations for each residue: extrapolation of
desired variance and its subsequent use in conjunction with reactivity and noise esti-
mates to determine desired local coverage and ultimately the ratio of desired to existing
coverages (CQI). Lower two panels show the resulting CQI residue distribution and its
summarization for each category into a single number by taking the 95% percentile of
Cle in that category (vertical dashed line). Reactivities and Cle in bottom panel are

color-coded by categories (low/medium/high).

late the corresponding variance (02k) of reactivities, under the assump-
tion that ﬂuctuation magnitudes are G ussian (Figure 2; see Methods).
For example, if we use 0F95%, then 6 k would be the variance at which
Gaussian s les fall within the set interval with 95% conﬁdence. We
then insert 0' k into our variance estimation formula, which allows us to
solve for the local coverage (Ck*) required for maintaining the target
variability (Equation 4; see Methods). CQI is the ratio of desired cover-
age to original coverage (Cf/Ck). Residues with CQI scores less than 1
are considered adequately covered, while those higher than 1 may war-

rant higher coverage to ensure desired quality. Cle that exceed 1 can
also provide an estimate of the fold-increase in coverage required.

An example of CQI calculation is shown for the SAM-I riboswitch
(Figure 2). As CQI is generated for each residue, we summarize indices
for an entire transcript by taking the 95th percentile of Cle (95% CQI)
(vertical dashed line). This conservative metric identiﬁes the residue
requiring the most coverage to ensure desired quality after trimming
potential outliers (see Supplementary Information for details). Since low
probability events require large sample sizes for precise estimation,
lower reactivities demand higher coverage to meet desired quality crite-
ria and can push 95% CQI to a high value. But small reactivities remain
small even in the face of large ﬂuctuations, and such imprecision may
not be a major concern. To provide a comprehensive yet structurally
relevant View of coverage, we apply the same approach to three ranges:
low, medium and high. In our example, the SAM-I riboswitch has ade-
quate coverage to limit variability to 10% in high and medium reactivi-
ties, but not in low ones (Figure 2). 95% Cle for each transcript and
reactivity category correlate well with their corresponding bootstrap-
based mean SNRs, where low 95% Cle correlate with high mean SNRs
(Supplementary Figure 3). This is consistent with our ﬁndings that cov-
erage and mean SNR are correlated (Figure 1D).

For the target variabilities we tested, we ﬁnd that all high reactivities
and most medium ones in our data are adequately covered (Supplemen-
tary Figure 3), as well as a majority of low reactivities. To test whether
CQI is a good estimator of the coverage necessary to conﬁne variability,
we simulate predicted coverage adjustments via bootstrap (see Supple-
mentary Information for details). We ﬁnd that CQI is an accurate predic-
tor of necessary coverage adjustment; it appropriately limits variability
in 85% of our simulations, with better success in high reactivities (94%)
than low reactivities (71%) (Supplementary Table F1). The dependence
of success rates on reactivity magnitude is consistent with our formula’s
tendency to be less accurate at low coverage. By utilizing variance esti-
mates from both bootstrapping and formula, we validate CQI as another
informative quality control and experiment design metric.

3.4 Application to other biological scenarios

3.4.1 Transcriptome proﬁling in viva

Having demonstrated our method on a small synthetic library, we now
examine quality characteristics when data are obtained with more ad-
vanced protocols and in a cellular environment. Such data display signif-
icantly higher complexities in terms of spectrum of coverages, lengths,
and structural properties. A Mod-Seq experiment (Talkish et al., 2014)
used DMS to probe yeast cells via RPE coupled with single-end reads to
map stop sites. To showcase SNR’s application to identifying regions of
high or poor quality within a long transcript, we consider a well-covered
18S rRNA from this dataset. We calculate rolling mean SNR for center-
aligned windows of 51 nt (Figure 3A). Since DMS probes only A and C
and since zero reactivities frequently arise in both replicates, the rolling
mean summarizes only a subset of residues in a window. For robust
inference, we limit attention to means reporting a relatively high fraction
of residues (dark bars) and identify two regions whose good/poor quality
stands out. We ﬁnd that this quality disparity could be explained by local
stop counts statistics (see inset), which are less controllable with RPE.
Interestingly, the poor-quality region has very low counts in all four
channels, hinting at a possible systematic bias. Similar cause-and-effect
relationship can be seen at the 3’ end, as commonly observed in stop-
based data. This analysis demonstrates SNR’s utility in picking up varia-
tions within transcripts and in exploring technical biases.

9mg ‘09 1sn8nV uo sojoﬁuV soq ‘121u10111123 10 A1ISJQAIu [1 112 /810'sp2umo[p101x0'sot112u1101quIq/ﬁd11q 111011 popcorn/hog

 

Fraction of
residues

0.3

R>
a

_x
N

  
 

* 0.2

0.1

4:.

ii. iii Hi  H 
0 | 5 III! H

0 500 1000 1500 1800
5 Residue 3

Rolling mean SN
00

 

B Gini index |_'_| 00-025 0 1125-05 A 0.5-0.75 + 0.75-1.0

 

Coverage I 0-10 I 10-15 0 15-20 20-25 0 >25
+ A +
It“; s‘ ‘1- + ‘
+q. a.
0.8- " +
1..

 

- icSHAPE
2‘ SHAPE-Seq
— Theoretical ﬁt

Pearson correlation
O
4:.
l

 

 

 

 

 

 

 

Mean SNR

‘ AA A A A AAA AA AA AAAAA AA

     
  

Pearson
correlatlon

0.9
0.8
0.7
0.6
0.5

Fig. 3. Transcriptome profiling in viva. (A) Mod-Seq data: bars represent center-aligned rolling mean of SNR over windows of 51 nt. Color gradient indicates fraction of residues in a window
for which SNR is deﬁned. Windows of considerably high or low quality, where SNR is deﬁned for high fraction of residues (dark bars), are marked with arrows pointing to window range in
inset. Inset shows mean of stop counts in both channels of two replicates. (B-C) icSHAPE data: (B) Pearson correlation vs. mean SNR. Marker shapes denote Gini index of residue SNRs for a
transcript. Colors indicate plus coverage rate averaged over replicates. Inset highlights a more pronounced trend in well-covered transcripts (labeled blue in B) and their ﬁt to a theoretical rela-
tionship. Also shown is a similar trend in pairwise SHAPE-Seq comparisons. (C) Tukey boxplots of residue SNRs for well-covered transcripts (labeled blue in B) with mean SNR > 5. A contin-
uous line connects their mean SNRs. Markers on top indicate their Gini index (as labeled in B) and color gradient indicates correlation. Ensembl gene IDs are given, where * stands for

ENSMUSGOOOOOO. Background colors in panels A, C mark quality zones: green for good (> 5), yellow for ambiguous (3-5), red for poor (<3).

9mg ‘09 1sn8nV uo sojoﬁuV soq ‘121u10111123 10 A1ISJQAIu [1 112 /810'S{12umo[p101x0'sot112u1101quIq/ﬁd11q 111011 popcorn/hog

Furthermore, differences in counts may be more dramatic when
gleaned across a transcriptome. Since Mod-Seq contains robust infor-
mation for a small portion of cellular RNAs, we analyze a more compre-
hensive icSHAPE dataset (Spitale et al., 2015) of mouse stem cells in
viva. Here, large variation in transcript abundances, manifested as cover-
age differences, is an additional factor modulating quality. An SNR-
Pearson plot reveals a trend reminiscent of SHAPE-Seq’s step-like be-
havior, albeit with much greater scatter (Figure 3B). While this scatter
may be expected due to noisy conditions, we ﬁnd that much of it is at-
tributed to transcripts with low coverage and to those in which a small
proportion of residues dominates the overall sum of residue SNRs (quan-
tiﬁed by high Gini index, marked by ‘+’ in Figure 3B). Indeed, when
restricting analysis to well-covered transcripts, a clearer and tighter trend
emerges, which closely matches SHAPE-Seq’s characteristics (Figure
3B, inset). This suggests simple guidelines for identifying subsets of
better precision and more robust information. Interestingly, both datasets
are ﬁt well by known theoretical relationship (see Supplementary Infor-
mation). Such quantitative agreement between two vastly different da-
tasets attests to the generality of SNR as a quality metric.

Since coverage re-emerges as major determinant of quality, we next
screen for transcripts with mean SNR > 5 and plus coverage rate > 25.
Boxplot analysis (Figure 3C) shows that for most of them, SNR distribu-
tions substantially overlap yellow and green zones. With the exception of
a few RNAs with borderline mean SNR, they display good correlation.
This ﬁirther validates mean SNR’s discriminative power in preliminary
screening. We ﬁirther ﬁnd that most transcripts with poor correlation
also have high Gini index (+ marks), suggesting simple quantitative tools
for ﬁirther reﬁnement. Our analysis also highlights that challenging
conditions might impact screening speciﬁcity, warranting careﬁil analy-
sis. It is worth noting that both datasets appear to be of poorer quality
than SHAPE-Seq, possibly because of less favorable conditions, ran-
domness in priming, and less precise reactivity calculation due to miss-
ing coverage information when using single-end reads (see Methods).

3.4.2 Reproducibility of differential signals

Thus far, we have deﬁned reproducibility in a restricted sense as mean
SNR > 5, but other experimental situations may justify other criteria. For
example, Bai et a]. (2014) used SHAPE-Seq to detect differences be-
tween protein-bound and protein-free states of HIV’s Rev-response
element (RRE) in vitro. Reactivity changes observed in three replicates,
each consisting of proﬁles before and after Rev-RRE complex formation,
signiﬁed protein binding. In such differential analysis situations, we
consider data as sufﬁciently reproducible if replicate agreement within
conditions exceeds that of in-between conditions. This conﬁrms that
differential signals can be reliably estimated. To address this notion
quantitatively, we analyze ﬁve SNR distributions: within conditions (two
distributions, three replicates each) and between conditions (one distribu-
tion each for three replicates). Restricting analysis to binding sites
(which consist a small fraction of the entire sequence), we ﬁnd that with-
in each condition, a greater fraction of residues shows strong agreement,
whereas agreement degrades in between-conditions comparisons (Sup-
plementary Figure 4). This quantitatively validates that data are sufﬁ-
ciently reproducible. See Supplementary Information for an additional
application to differential analysis of structural changes in a riboswitch.

4 Scope and Constraints

Current techniques encompass diverse chemistries, modiﬁcation detec-
tion methods, library preparation strategies (random/targeted priming,
size selection), sequencing choices (single/paired-end reads), and analy-

sis pipelines. This diversity presents challenges for proposed quality
control methods, as they should bridge these differences to standardize
assessment and facilitate comparative analysis.

Aside from its simplicity and computational ease, SNR is a versatile
metric applicable directly to reactivities, irrespective of how they were
reconstructed or of the speciﬁcs of the experiment and sequencing. An-
other advantage that renders SNR suitable for comparative analysis of
datasets is that it accommodates an arbitrary number of replicates.

While SNR calculations may follow any reactivity reconstruction, for
a given transcript, different reconstructions might result in different SNR
values. Consistency in the informatics approach taken is thus imperative
to quality comparisons across datasets. Due to a multitude of proposed
analysis options (Shih et al., in revision), here we carried out all analyses
using a single choice. We caution, however, that the dependency of SNR
values on the analysis method may warrant recharacterizing the “high
quality” threshold for other choices. Note that we repeated the analysis in
Figure 1C for another commonly used alternative (i.e., ratio of stop rates)
and found that the general SNR-Pearson trend remains the same (see
Supplementary Information). Also, in less controlled conditions, it may
be beneﬁcial to reﬁne the threshold test by closely examining its out-
comes. Accounting for additional metrics may also be informative.

Direct applicability to reactivities grants SNR its universality, yet it
also results in ambiguity, particularly when zeros are concordantly ob-
served across replicates. If capturing a structure signal, they are informa-
tive, but they could also be a manifestation of a fading signal (i.e., no
counts). Irnportantly, coverage disparities within transcriptome-wide data
make them more prone to this deﬁciency, which can be remedied by
sensible integration of coverage information. Resolving such ambiguity
may also improve data-directed structure inference (Deng et al., 2016).

Finally, while SNR reveals discordant measurements, it cannot re-
solve sources of variation. Possible sources include poor coverage, low
sequencing or alignment quality, structure differences, biologi-
cal/technical variability, high background, and inefﬁcient reactions. Even
design choices, such as single-end reads or cDNA size selection, discard
information that might then affect reproducibility. Because SNR
measures a compound effect as well as lacks an underlying statistical
model, it cannot determine, for example, if variation can be explained by
changes in structure (up to a desired conﬁdence level). Although the
approach can be equipped with such model to facilitate hypothesis test-
ing, this would compromise its simplicity, which we consider to be its
most appealing property for practical purposes. Yet, in its present form,
it may become useﬁil as rapid pre-screen for differential analysis, based
on the expectation that when differential effects are present, replicates
would better agree within conditions than between conditions.

The two approaches we proposed for estimating SNR’s variance com-
ponent differ in their generality. Bootstrap is straightforward to apply
and requires no modeling assumptions. In contrast, the formula relies on
simplifying assumptions and requires re-derivation to other reconstruc-
tion methods, e.g., when estimating reactivity as a ratio between plus and
minus channel rates (see Supplementary Information). It also makes
direct use of local coverage information. In its absence (e. g., when com-
bining single-end sequencing with RPE), its accuracy might degrade.
Note that these limitations carry over to CQI.

When deriving the formula, we also ﬁxed the local coverage, although
it is currently unclear how realistic this is, especially in transcriptome-
wide setting, where coverage is not easily controllable. Loss of coverage
may also adversely affect the formula’s performance, as we diverge from
our assumption as well as deviate in the parameter estimates we use. Our
tests using simulations indicate that while our formula performs well at

9mg ‘09 1sn8nV uo sojoﬁuV soq ‘121u10111123 10 A1ISJQAIu [1 112 /810'sp2umo[p101x0'sot112u1101quIq/ﬁd11q 111011 popcorn/hog

 

high coverage, its robustness breaks down at low coverage (see Supple-
mentary Information). Thus, we recommend using it in high coverage
situations to save time while maintaining accuracy, whereas bootstrap
may be favorable at low coverage, for its consistency and speed.

5 Discussion

As structure probing experiments increase in scope and complexity,
analytical tools must keep pace to ensure efﬁcient processing and relia-
ble results. Whereas manual inspection of data was once sufﬁcient, the
extent of newer experiments precludes such approaches. The quantitative
tools and framework we presented here are a ﬁrst step in addressing this
deﬁciency, providing quality controls that are standardized, generally
applicable, automatable, and scalable. We envision these tools to be used
in design and analysis of new and emerging large-scale experiments.

To evaluate reproducibility, we used the concept of SNR as well as
developed a new metric, CQI, which predicts coverage levels needed to
achieve a desired ﬂuctuation level. Both metrics involve straightforward
calculations; yet they are informative at both the replicate and transcript
levels. One favorable characteristic of SNR is its ﬂexibility to handle
multiple replicates, experimental or simulated. While it is a useﬁil quan-
tiﬁcation at both the residue and whole-transcript levels, the mean SNR
statistic has the advantage of distilling reproducibility information across
any number of residues into a single number, allowing for rapid prelimi-
nary screening of large-scale datasets. More elaborate summarizations of
residue SNR distributions or subsets thereof, such as boxplot and cate-
gorical chart analyses, may complement this approach as means of in-
specting borderline outcomes, detecting regions of special interest, or
accommodating alternative criteria for overall reproducibility.

CQI performs a similar task, aggregating coverage information across
a transcript into three indices. This metric has similar advantages as
SNR: it serves as rapid quantiﬁcation with a clear quality threshold and
is easily automated. It provides a preliminary estimate of the coverage
increase necessary to limit variability, and can be subsequently ﬁne-
tuned via resampling. Irnportantly, the variability we simulated does not
encapsulate all sources of noise; thus, recommendations by CQI should
be seen as a minimum recommended coverage increase rather than a ﬁx-
all solution. This metric builds off of our formula-based estimate, which
explicitly links coverage to data variability. It thereby demonstrates the
useﬁilness of this classical approach compared to modern resampling
methods. The formula also has the added beneﬁt of rapid estimation
compared to bootstrap, though the latter may be more accurate at low
coverage. Nonetheless, the tandem of bootstrap and formula provide a
computational way to quantitatively evaluate data quality.

The data summarization we employed here is readily generalizable to
other proposed quality measures (Smola et al, 2015; Talkish et al,
2014; Yang et al, 2002). One common strategy in microarrays is to
report the ratio of signal to background (Yang et al, 2002). We derived a
formula for this ratio’s variability (see Supplementary Information).
While this may be a good way to evaluate enrichment, it did not perform
as well as the mean SNR as summary statistic when correlated with
coverage or modiﬁcation rate (not shown). The ratio measure is also not
as broadly applicable, as it is limited to single residues/transcripts.

The presented methods are relatively straightforward and by no means
address all issues, but are a ﬁrst step towards ensuring high-quality data.
As the ﬁeld continues to grow, effort must be spent on both pioneering
new techniques as well as analysis and visualization tools (Choudhary et
al, in revision). One plausible avenue for improvement is to combine
RPE with paired-end sequencing for better consistency in recovering
local coverage information. Our methods attempt to unify how research-

ers quality-control their data. We kept our work simple and accessible, to
make its adoption as painless and ﬁ'uitful as possible. We aim to estab-
lish a foundation for more sophisticated platforms, which will ultimately
bridge differences among protocols and expedite the ﬁeld’s maturation.

Acknowledgements
We thank Yun Bai for providing us with SHAPE-Seq data for HIV-1 RRE.

Funding

This work was supported by National Institutes of Health (NIH) grant
[HG006860] to SA B.L. is supported by the Center for RNA Systems Biology at
UC Berkeley [NIH grant P50GM102706].

Conﬂict of In terest: none declared.

References

Aviran,S. et al. (2011a) Modeling and automation of sequencing-based characteri-
zation of RNA structure. Proc Natl Acad Sci., 108, 11069—11074.

Aviran,S. et al. (2011b) RNA structure characterization from chemical mapping
experiments. Proceedings of the 49th Annual Allertan Conference on Communi-
cation, Cantral, and Computing, pp. 1743—1750, Monticello, IL.

Aviran,S. and Pachter,L. (2014) Rational experiment design for sequencing-based
RNA structure mapping. RNA, 20, 1864-1877.

Bai,Y. et al. (2014) RNA-guided assembly of Rev-RRE nuclear export complexes.
Elife, 3, e03656.

Bolstad,B.M. et a]. (2003) A comparison of normalization methods for high density
oligonucleotide array data based on variance and bias. Bioinformatics, 19, 185-93.

Bushberg,J.T. et al, (2012) The essential physics of medical imaging. Lippincott
Williams & Wilkins.

Cheng,C.Y. et a]. (2015) Consistent global structures of complex RNA states
through multidimensional chemical mapping. Elife, 4, e07600.

Deigan,K.E. et al. (2009) Accurate SHAPE-directed RNA structure determina-
tion. Proc Natl Acad Sci, 106, 97—102.

Deng,F. et al. (2016) Data-directed RNA secondary structure prediction using
probabilistic modeling. RNA, in press.

Ding,Y. et al. (2014) In viva genome-wide proﬁling of RNA secondary structure
reveals novel regulatory features. Nature, 505, 696—700.

Hector,R.D. et al. (2014) Snapshots of pre-rRNA structural ﬂexibility reveal eu-
karyotic 4OS assembly dynamics at nucleotide resolution. Nucl. Acids. Res., 42,
12138-12154.

Kendall,M. and Stuart,A. (1977) Advanced theory of statistics. Charles Grifﬁn &
Company.

Kertesz,M. et al. (2010) Genome-wide measurement of RNA secondary structure
in yeast. Nature, 467, 103-107.

Kielpinski,L.J. and Vinther,J. (2014) Massive parallel-sequencing-based hydroxyl
radical probing of RNA accessibility. Nucl. Acids. Res., 42, e70.

Kutchko,K.M. et al. (2015) Multiple conformations are a conserved and regulatory
feature ofthe RBI 5’ UTR. RNA, 21, 1274-1285.

Kwok,C.K. et al. (2013) Determination of in viva RNA structure in low-abundance
transcripts. Nat Commun, 4, 2971.

Lavender,C.A. et al. (2015) Model-free RNA sequence and structure alignment
informed by SHAPE probing reveals a conserved alternative secondary structure
for 168 rRNA. PLaS Camput. Biol, 11, e1004126.

Lorenz,R. et a]. (2015) SHAPE directed RNA folding. Bioinformatics, 32, 145-147.

Lorenz,R. et a]. (2016) Predicting RNA secondary structures from sequence and
probing data. Methods, 103, 86-98..

Loughrey,D. et al. (2014) SHAPE-Seq 2.0: systematic optimization and extension
of high-throughput chemical probing of RNA secondary structure with next gen-
eration sequencing. Nucl. Acids. Res., 42, e165.

Low,J.T. and Weeks,K.M. (2010) SHAPE-directed RNA secondary structure
prediction. Methods, 52, 15 0—15 8.

Lucks,J.B. et al. (2011) Multiplexed RNA structure characterization with selective
2’-hydroxy1 acylation analyzed by primer extension sequencing (SHAPE-Seq).
Proc Natl Acad Sci, 108, 11063-11068.

Markham,N.R. and Zuker,M. (2008) UNAFold: software for nucleic acid folding
and hybridization. Methods Mal Biol, 453, 3-31.

Mortimer,S.A. et al. (2012) SHAPE-Seq: high throughput RNA structure analy-
sis. Curr Protoc Chem Biol, 4, 275—297.

9mg ‘09 1sn8nV uo sojoﬁuV soq ‘121u101q123 10 A1ISJQAIu [1 112 /810'sleumo[p101x0'soi112u1101quIq/ﬁd11q 111011 popcorn/hog

Mortimer,S.A. et al. (2014) Insights into RNA structure and fImction ﬁom genome-
wide studies. Nat Rev Genet, 15, 469-479.

Poulsen,L.D. and Kielpinski,V. (2015) SHAPE Selection (SHAPES) enrich
for RNA structure signal in SHAPE sequencing-based probing data. RNA, 21,
1042-1052.

Reuter,J.S. and Mathews,D.H. (2010) RNAstructure: software for RNA secondary
structure prediction and analysis. BMC Bioinformatics, 11, 129.

Ritchie,M.E. et al., (2015) limma powers differential expression analyses for RNA-
sequencing and microarray studies. Nucleic Acids Res, 43, e47.

Rouskin,S. et al. (2014) Genome-wide probing of RNA structure reveals active
unfolding of mRNA structures in viva. Nature, 505, 701—705.

Sager,J.G. et al. (2015) Global analysis of the RNA-protein interaction and second-
ary structure landscapes of the Arabidapsis nucleus. Mal Cell, 57, 376-388.

Seetin,M.G. et al. (2014) Massively parallel RNA chemical mapping with a re-
duced bias MAP-seq protocol. Methods Mol Biol, 1086, 95—117.

Sharp,P.A. (2009) The centrality of RNA. Cell, 136, 577-580.

Sloma,M.F. and Mathews,D.H. (2015) Improving RNA secondary structure predic-
tion with structure mapping data. Methods Enzymal, 553, 91-114.

Smola,M.J. et al. (2015) Selective 2’-hydroxyl acylation analyzed by primer exten-
sion and mutational proﬁling (SHAPE-MaP) for direct, versatile and accurate
RNA structure analysis. Nature Protoc.,10, 1643-1669.

Spitale,R.C. et al. (2014) RNA structural analysis by evolving SHAPE chemistry.
Wiley Interdiscip Rev RNA, 5, 867-81.

Spitale,R.C. et al. (2015) Structural imprints in viva decode RNA regulatory mech-
anisms. Nature, 519, 486-490.

Sukesd,Z. et al. (2013) Evaluating the accuracy of SHAPE-directed RNA second-
ary structure predictions. Nucleic Acids Res., 41, 2807—2816.

Talkish,J. et al. (2014) Mod-seq: high-throughput sequencing for chemical probing
of RNA structure. RNA, 20, 713—720.

Underwood,J.G. et al. (2010) FragSeq: transcriptome-wide RNA structure probing
using high-throughput sequencing. Nat Methods, 7, 995—1001.

Wan,Y. et al. (2013) Genome-wide mapping of RNA structure using nuclease
digestion and high-throughput sequencing. Nat Protoc, 8, 849—869.

Watters,K.E. et al. (2016) Simultaneous characterization of cellular RNA structure
and ﬁinction with in-cell SHAPE-Seq. Nucleic Acids Res, 44, e12.

Weeks,K.M. (2010) Advances in RNA structure analysis by chemical probing.
Curr. Opin. Struct. Biol, 20, 295-304.

Yang,Y.H. et al. (2002). Normalization for cDNA microarray data: a robust com-
posite method addressing single and multiple slide systematic variation. Nucleic
Acids Res., 30, e15.

9mg ‘09 1sn8nV uo sojoﬁuV soq ‘121u101q123 10 A1ISJQAIu [1 112 ﬁlo'8112umo[p101x0'soi112u1101quIq/ﬁd11q 111011 popcorn/hog

