ORIGINAL PAPER

Vol. 27 no. 16 2011, pages 2216-2223
doi: 1 0. 1 093/bioinformatics/btr3 78

 

Structural bioinformatics

Advance Access publication July 8, 2011

Biologically inspired EM image alignment and neural

reconstruction

Seymour Knowles-Barley1’*, Nancy J. Butcher2, Ian A. Meinertzhagen2

and J. Douglas Armstrong“

1School of Informatics, The University of Edinburgh, Edinburgh, UK and 2Life Sciences Centre, Dalhousie University,

Halifax, Nova Scofia, Canada
Associate Editor: Anna Tramontano

 

ABSTRACT

Motivation: Three-dimensional reconstruction of consecutive serial-
section transmission electron microscopy (ssTEM) images of neural
tissue currently requires many hours of manual tracing and
annotation. Several computational techniques have already been
applied to ssTEM images to facilitate 3D reconstruction and ease
this burden.

Results: Here, we present an alternative computational approach for
ssTEM image analysis. We have used biologically inspired receptive
fields as a basis for a ridge detection algorithm to identify cell
membranes, synaptic contacts and mitochondria. Detected line
segments are used to improve alignment between consecutive
images and we have joined small segments of membrane into cell
surfaces using a dynamic programming algorithm similar to the
Needleman—Wunsch and Smith—Waterman DNA sequence alignment
procedures. A shortest path-based approach has been used to close
edges and achieve image segmentation. Partial reconstructions
were automatically generated and used as a basis for semi-
automatic reconstruction of neural tissue. The accuracy of partial
reconstructions was evaluated and 96% of membrane could be
identified at the cost of 13% false positive detections.

Availability: An open-source reference implementation is available
in the Supplementary information.

Contact: seymour.kb@ed.ac.uk; douglas.armstrong@ed.ac.uk
Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on March 11, 2011; revised on May 13, 2011; accepted on
June 1, 2011

1 INTRODUCTION

Serial—section transmission electron microscopy (ssTEM) can
produce reconstructions of neuronal morphology at very high
resolution, including synaptic organelles and the contacts between
neurons that constitute circuits. Alignment and reconstruction
of ssTEM images is currently performed manually or semi—
automatically, with the aid of computer software, to generate a 3D
model of the imaged neuron and, with other such neurons, of the
synaptic circuits to which that neuron contributes (Meinertzhagen
and O’Neil, 1991; Takemura et al., 2008; White et al., 1976). In some

 

*To whom correspondence should be addressed.

cases, approximate alignment can be achieved automatically but,
even so, high—quality circuit reconstructions still require many hours
of manual tracing and annotation, and are highly dependent upon
the interpretative skill of the human observer and the complexity
of neuronal arborizations being reconstructed (Briggman and Denk,
2006; Eisenstein, 2009; Smith, 2007). For example, neurites are
simple and have been completely reconstructed by manual means
in the nematode Caenorhabditis elegans (White et al., 1976) but
are complex, highly branched and reconstructed only with great
difﬁculty or incompletely in the fruit ﬂy Drosophila melanogaster
(Takemura et al., 2008).

Existing methods of image alignment usually rely on a control
point selection method. Semi—automatic alignment can be carried
out by identifying control points manually and aligning these
by means of a particular algorithm (Fiala, 2005; Kremer et al.,
1996). Automatic alignment can be carried out with control point
detection algorithms (Anderson et al., 2009; Saalfeld et al., 2010),
and works best when image quality is consistent throughout the
dataset, but performance can be degraded when artefacts such
as gaps, noise, differing levels of brightness and/or contrast are
present in the images being aligned. Such artefacts are unfortunately
fairly common in ssTEM because of the complicated preparative
procedures and increase as the series of images becomes longer.

Most currently used systems for automatically annotating electron
microscopy (EM) data rely on some variant of the watershed
algorithm to detect boundaries between cells (Beucher, 1991;
Chklovskii et al., 2010). This method usually results in over—
segmentation, and several methods have been identiﬁed to reunite
incorrectly over—segmented areas after the watershed algorithm is
run (Andres et al., 2008; Jurrus et al., 2008; Mishchenko, 2009).

A commonly used method to detect membrane present in an
image is to pre—process the image by a Gaussian blur combined with
image derivative or Hessian matrix analysis. Also called Gaussian
smoothed Hessian (GSH), this method is effective at ﬁltering out
noise while retaining membrane edges in the image (Mishchenko,
2009; Venkataraju et al., 2009). Random forest classiﬁers have
also been used to successfully combine outputs from a range of
generic feature detectors (Kaynig et al., 2010; Sommer et al., 2011).
GSH, and other generic feature detectors, are efﬁcient to implement
and make reasonable assumptions when membrane proﬁles are
Gaussian, but when line proﬁles are predictable the construction
of a speciﬁc ﬁlter may improve performance (Lorenz et al., 1997;
Ziou, 1991). For this reason, we have customized a set of receptive
ﬁelds to speciﬁc features Visible in EM images.

 

2216 © The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com

112 /§.IO'SIBUJHOprOJXO'SOllBIIIJOJUTOTQ/ﬁdnq 11101; prBOIUAAOG

9IOZ ‘09 lsnﬁnv uo ::

 

  
  
 

  

-I
. I
I

"‘Eﬂiﬁﬂ‘lﬂ
1- . I .— r.
mi: ..

  

Fig. 1. Examples of manually annotated training image patches from 50 nm
thick EM images of the calycal neuropiles of the Drosophila mushroom body
(Leiss et al., 2009). Four categories have been annotated: sharp membranes
that pass vertically through the section thickness (3), blurred images of
obliquely sectioned membrane (b), synaptic proﬁles (c) and mitochondria
((1). Each image patch is 227 x 227 nm.

Here, we explored a novel approach based on receptive ﬁelds to
identify the likely locations for cell membranes, and a ridge detection
approach to identify lines within the receptive ﬁeld responses. We
have then used a shortest path approach to close the edges detected in
the image. Lines of cell membranes are aligned in 3D to improve the
image alignment and generate partial 3D reconstructions. Detected
membrane points are further analysed to identify likely organelle
and synapse locations within the ssTEM images.

Receptive ﬁelds are a well-studied feature of many sensory
interneurons, especially in visual systems, and deﬁne a region
within which the neuron responds to a particular stimulus, such
as a line segment at a particular orientation (Angelucci et al.,
2002; Fitzpatrick, 2000; Hubel and Wiesel, 1959; O’Carroll, 1993).
Computational models of the brain also use receptive ﬁelds to further
understand the visual system (Carandini et al., 2005; Olshausen
and Field, 1996, 2005). In the system presented here, receptive
ﬁelds are learnt from examples of image patches taken from ssTEM
training data using supervised learning techniques. The resulting
Gabor-like receptive ﬁelds are applied to ssTEM data images to
annotate automatically neuronal membranes, synaptic connections
and organelles such as mitochondria. Objects recognized by the
system are then used to improve the alignment of consecutive
images and produce partial 3D reconstructions as a starting point
for manual annotation. Using this biologically inspired approach
to analyse and understand biological images has the potential for
further improvements in semi-automatic segmentation by applying
additional properties of biological vision.

2 METHODS
2.1 Receptive ﬁelds

Over 500 examples of membrane, synapses and mitochondria from serial 50
nm thick sections of the mushroom body calycal neuropiles of Drosophila
were manually annotated (Fig. 1). The images were generated by Zhiyuan
Lu and Ian Meinertzhagen, Dalhousie University, see Leiss et al. (2009) for
details.

. "3‘ mm":- . .UI Eh}

Biologically inspired neural reconstruction
m 'Hmml ‘    I I  I UR
Fig. 2. Weight matrices obtained after training on over 500 manually
annotated image patches, such as those in Figure 1, and 400 randomly
selected image patches from the same dataset. Supervised learning using
a pattern recognition neural network produced results shown in (a).
Unsupervised learning using SOM produced similar results (b). Weight
matrices from (a) were used as a basis for the membrane detection algorithm.

Pixel colours represent weights from input pixels, as shown in the right—hand
keys.

Jun.-
3:8

     

52.51%

a.

C'-

Ef-

   

Training images were ﬁrst normalized to have a range between —1 and 1.
Then line detection Gabor ﬁlters at different orientations were used to detect
the best orientation for each image automatically. Images were rotated so that
a vertical Gabor patch produced the largest response. In the case of images of
mitochondria and synapses, rotation was performed to orientate the darkest
half of the image to the left. Examples of resulting image patches are shown
in Figure 1.

In the next step, a neural network was trained on the manually annotated
image patches, randomly split into training and test groups, and a selection
of 400 random images from the same dataset. A standard feed forward back
propagation neural network was used, with a single input per pixel and
as many outputs as target classes. All weights and biases in the network
were initialized to zero and mean—squared error was used as the error
function. Membrane receptive ﬁelds were trained by specifying just one
target class and training on membrane (or oblique membrane) from the
training images with random images provided as negative examples. Synapse
and mitochondria receptive ﬁelds were trained at the same time by specifying
two target classes and training on positive examples from the manually
annotated dataset, with membrane and random images used as negative
examples. Training continued until classiﬁcation performance on the test
images stopped improving, typically after 10—20 iterations. Resulting weight
matrices for each class are shown in Figure 2a. Note that a self—organizing
map (SOM) learning system also produced similar results and was able
to identify membrane, synapse and mitochondria classes unsupervised, as
shown in Figure 2b.

2.2 Membrane detection

Space—ﬁlling 3D reconstructions require us to identify the surfaces of
neurons. These are necessary as the ﬁrst step in identifying sites of contact
between reconstructions of neighbouring neurons. As the basis to detect
membranes, we therefore used the membrane weight matrices from the neural
network training to build a membrane detection tool. Weights were multiplied
with a Gaussian probability density having a standard deviation chosen so
that a constant background input produced a response of 0. The resulting
Gabor—like patches were rotated to create a ﬁlter bank of membrane receptive
ﬁelds. Atotal of 36 orientations was sufﬁcient to produce reasonable accuracy
to detect membranes (Table 1). Filters were convolved over large image
patches from the same data to produce ﬁlter response images as shown in
Figure 3B.

Membrane detection based on these responses was carried out by
choosing high—scoring local maxima as seed points and then searching for
neighbouring areas of high response and similar orientation. The search
area was modiﬁed so that response scores very near the seed point were
inhibited and responses with similar orientation to the seed point, in the

 

2217

112 /3.IO'SIBUJHOIPJOJXO'SOIIBIIIJOﬂIIOIQ/ﬁC1111] 11101; pepBOIUAAOQ

9IOZ ‘OE lsnﬁnv uo ::

S.Knowles-Barley et aI.

 

 

 

. -  Drgaelle '
   O Synapse

‘T'.’ IF:I.£' .
‘mﬁ‘ﬁm-Jw‘i

4r

 

Fig. 3. Membrane detection steps. (A) Original EM image. (B) Maximum ﬁlter responses (combined over all angles). (C) Results from automatic membrane
detection and mitochondria / synapse classiﬁcation results. Green lines indicate automatically detected membrane, red circles highlight automatically detected
membrane that is classiﬁed as organelle (and therefore possibly false positive) and blue circles highlight automatically detected membrane that is classiﬁed

as synapse. Each image is 1.4 x 1.4um.

expected direction, were facilitated (or received less inhibition). Modifying
the scores for nearby receptive ﬁeld responses in this way can also be thought
of as an approximation to the lateral inhibition and excitation observed in
biological visual systems (Hartline et al., 1956; Ichida et al., 2007; Ozeki
et al., 2004, 2009; Palagina et al., 2009). This search was repeated in a step—
wise manner to propagate the current line of membrane progressively until a
lower bound at some limit was reached. Neighbouring areas of high response
with different orientations were marked as potential junction points and
investigated in the same manner. An example from this membrane detection
process is shown in Figure 3. Dataset S2 contains an open—source reference
implementation of the membrane detection algorithm.

2.3 Feature detection

Each point of membrane so detected was then classiﬁed as synaptic proﬁle,
mitochondrion or normal membrane. Filter banks were created by rotating
synapse and mitochondron weight matrices to the same orientations to
which the membrane Gabor—like patches were rotated. Note that twice the
number of orientations were required, because these weight matrices were
not symmetrical.

At each point of detected membrane, synapse and mitochondria ﬁlter
responses were calculated by element—wise multiplication and summation.
Only two ﬁlter responses were calculated for each feature; one at the same
orientation of rotation as the detected membrane, and one at the same
orientation plus 180°. Filter response thresholds were chosen to achieve
acceptable error rates for synapse or mitochondria classiﬁcation.

2.4 Edge closure

Membranes detected in this way usually failed to produce a fully segmented
proﬁle because many lines from obliquely sectioned membranes remained
unclosed. We were able to complete closure by identifying end points and
joining them to neighbouring lines based on the shortest path through the
energy function of the receptive ﬁeld responses. Dijkstra’s shortest path
algorithm was used to calculate the shortest path over a four—connected
image graph based on the distance function shown in Equation ( 1), where
Rxag represents the ﬁlter response at angle 6, centred at pixel x.

Distxy = maxQ [Rxag] *max¢ [Ryatﬁ] (1)

For correctly detected edges, reasonable closure was achieved with this
method, but incorrectly detected edges introduced additional edge errors
when closing lines were added.

2.5 Alignment improvement

Sequential images can be manually aligned by selecting several pairs of
control points corresponding to the same x, y location for consecutive images
z1 and z2. This approach is adopted by widely used software, Reconstruct
(Fiala, 2005). Automatic selection of control points is also possible by
searching for unique image features in both images, as demonstrated
by software TrakEM2 (Cardona et al., 2010a; Saalfeld et al., 2010).
Automatic methods are usually effective at performing a global alignment,
but signiﬁcant local errors can be introduced when too few control points are
detected, or when image features are inconsistent between images, as when
sections have been locally distorted during microtomy or imaging, resulting
in the need for manual correction (Cardona et al., 2010a).

Lines of detected membrane are a useful means to improve an existing
image alignment. Because membrane is abundant in EM images, many
potential control points can be found by aligning ridge detection results.
Drawing on experience with the linear alignment of other biological
structures for this purpose, we therefore developed a dynamic programming
algorithm, similar to the Needleman—Wunsch (Needleman and Wunsch,
1970) and Smith—Waterman (Smith and Waterman, 1981) DNA sequence
alignment procedures, with a cost metric based on the euclidean distance
and angular subtense.

The algorithm also has similarities with sequence matching algorithms
implemented in 2D for curve morphing (Jiang et al., 2002) and in 3D
for neuron shape recognition (Cardona et al., 2010b). We introduced a
different cost metric and a modiﬁed three—pass alignment procedure that
could perform many—to—many alignments and allows branching to occur
within sequences. Combinations of this new alignment procedure with the
existing application areas allowed morphing of multiple curves at once,
and recognition of branching neuron shapes or even networks of branching
neurons. Dataset S2 includes an open—source reference implementation of
the alignment procedure that can be easily modiﬁed for application to other
alignment problems such as these.

Two consecutive images (z1, z2) from the image stack were aligned by
matching sections of detected membrane in z1 with sections in z2, so that the

 

2218

112 /3.IO'SIBUJnOprOJXO'SOllBIIlJOJUlOIQ/ﬂdnq 11101; pepBOIUAAOQ

9IOZ ‘OE lsnﬁnv uo ::

Biologically inspired neural reconstruction

 

distance and angular subtense between all matched points were minimized.
This problem was similar to a many—to—many ends—free DNA sequence
alignment with the cost metric shown in Equation (2), where (£091,192) is
the euclidean distance between points p1 and p2, and a is an arbitrary angle
constant (a = 20 for our implementation). In principle, alignment can occur
in either the forwards or backwards direction, so that low—cost diagonal
lines in the cost matrix indicate the best alignment. Similarity matrix H
was calculated and the traceback procedure (Needleman and Wunsch, 1970)
used to ﬁnd the best alignment of points in z1 to points in z2. An example of

Mgnmem Coal

F1 {333 pun-n13]

 

 

3]]
F2 [392 minlsl

Fig. 4. Cost matrix obtained by calculating distance cost in Equation (4)
(a=20) for each combination of points between z1 and z2. Points
of membrane from consecutive images z1 and z2 were ordered into
two sequences preserving individual line segments, as described in
Supplementary Material S1. Each row corresponds to a point in z1 and
each column corresponds to a point in z2. Cost matrix entries (orange to
yellow) give the cost of matching points from z1 and z2. The best matching
line segments appear as low cost (yellow) diagonal lines in this matrix. Blue
dots highlight the resulting alignment after calculating similarity matrix H
(data not shown) and performing the traceback procedure. This alignment
corresponds to the alignment shown in Figure SE.

a cost matrix and the corresponding alignment points is shown in Figure 4.
Further details, including the calculation of the similarity matrix, are included
in Supplementary Text S1.

Cost(p1,p2) =d(P1 7192) +a|P10 —P29| (2)

Once alignment was complete, the average offset between aligned points
was calculated and used to improve alignment between z1 and z2. This
process was repeated until the average directional offset was <1 pixel. The
result from a single alignment is shown in Figure 5.

This alignment method assumes that the direction of membrane movement
between consecutive images, when averaged over a sufﬁciently large area,
is close to zero. For example, in a given alignment the amount of membrane
moving to the left is assumed to be approximately equal to the amount of
membrane moving to the right. Depending on the angle of ultrathin sectioning
and the particular area of neural tissue being imaged, it is possible that there
will be a bias in the direction of overall membrane movement. This bias may
exist for the entire image, or for small sections of it, especially where there
are large bundles of neurites all running in the same direction.

Image alignment in this case does not differentiate between distortions due
to preparation or imaging artefacts and areas of bias resulting from membrane
movement. Ideally, we would like to correct for distortions while preserving
any movement bias. However, considering 2D control points alone makes
this problem ambiguous without further information.

One solution to this ambiguity is to perform membrane alignment only on
the highest—scoring sections of membrane; these sections of membrane have
clearer, thinner proﬁles in the image and are expected to be perpendicular to
the cutting plane. In this way, we can assume that any alignment errors are
more likely to be from distortions rather than membrane movement and can
use a deformation transform with greater conﬁdence. However, this method
can still introduce small errors that accumulate, resulting in large errors over
many sections.

A second solution is to simply use linear translation and rotation for the
alignment to ensure that no unwanted distortions are introduced. This method
may result in poor alignment where there are large areas of imaging artefacts.

Alignment results are considered as the surfaces of cell membranes or
organelles in 3D. By combining multiple alignment results, it was possible
to generate partial 3D reconstructions as shown in Figure 6.

 

 

 

 

 

     
 

 

 

 

 

 

 

 

 

 

 

 

 

C
(It: égitth iii. 7
e 1 ﬂat
"" I? C: H.
'ﬁiiéﬁ) 4r": fﬂ‘iﬂ””<x
'lu 
r63!" ‘I‘kiﬁgtw a 5%
l “a
05: o" It" '30 huh, +1“¢";l§§
a  EH1 w 1!. K  {it \p’ it:
hull- “ \X‘kira g ll 1%“ “ﬁ-‘VZH‘Q é
afﬁx“! HIQIHIH'LE I  ﬁf}}};,;n~M
ﬁght». i {Kfo
‘5'" K =1 Du‘fba‘; K z=1
1' XXI!“ —-—D :EQEFIEEI “Ii-'1 g; gIXK-Kf —'—D :11:in

 

 

Fig. 5. Alignment is improved by minimizing the average distance between all pairs of aligned points. (A) Start state. Points from z1(><) and z2(o) are shown
before alignment. (B) Alignment results based on Figure 4. Each pair of aligned points is shown as connected dots. Unmatched points remain as x or o. A
transformation was applied to z1 to minimize the distance between pairs of aligned points. (C) End state after repeated iteration of the alignment algorithm.

Average directional offset between all aligned points is <1 pixel.

 

2219

112 /3.IO'SIBUJHOIpJOJXO‘SOIlBUIJOJUIOIQ/ﬂdnq 11101; papeoIHAAoq

9IOZ ‘OE lsnﬁnv uo ::

S.Knowles-Barley et aI.

 

3 RESULTS

Manual reconstructions of EM data are difﬁcult to compare directly
with segmentation derived from algorithms. Reconstructions are

 

Fig. 6. 3D rendering of membrane based on images from Figures 3 and 5.
Segments of membrane aligned by the algorithm are represented as surfaces
in this image. Six consecutive image patches were used. Surface colour
(green to blue) represents z depth. Volume reconstructed is 1.4><1.4><
0.3 gm.

A

r a -
__.m:.

I.

usually performed with the intention of tracing the neuron correctly
over many sections rather than identifying the exact location of
the cell membrane in every image. With these goals in mind,
manual reconstructions generate the general shape of the neuron
and overall neuron morphology along with the contacts made with
other neurons correctly, but with the exact location of membrane not
necessarily accurate in all places. In areas where a membrane runs
obliquely in the section and appears blurred in its corresponding
projection image, or where a large presynaptic density is present
(Fig. 1b and c), membrane signal can occupy a width of 20 pixels
or more at a resolution of 3.7 nm per pixel. For the same dataset,
tracing variation between experts can be up to 20 pixels, or 74 nm,
depending on both the acceptable level of accuracy of tracing with
a manually controlled mouse and true uncertainty in the location
of oblique membranes (data not shown). This looseness in manual
tracing makes direct comparison between manual and automatic
tracing methods difﬁcult to achieve. Choosing a performance metric
that recognizes topological correctness rather than small differences
in boundary locations (Jain et al., 2010) and using high-quality
datasets against which to assess automatic tracing are both important
considerations.

To overcome the problem of the disparity between manual
and automatic tracing methods, an interactive web interface was
developed to view and correct membrane automatically traced from
EM images that had previously been annotated manually. Errors
made by the algorithm were classiﬁed as either false positives
(locations where membrane was detected by the algorithm but
was not actually present) or false negatives (where membrane was
present but not detected) as shown in Figure 7. Using the web
interface, we identiﬁed false positive lines by clicking on them,

 

Fig. 7. Segmentation evaluation. (A) Test EM image. (B) After ridge detection, edge closure and manual correction. True positives (green, 97.4%) false

positives (red, 14.9%), false negatives (blue 2.6%). Image size is 2.8 x 2.8 gm.

 

2220

112 /810's12urnofp101x0's31112u1101u101q/ﬁd11q 111011 pap1201umoq

9IOZ ‘OE lsnﬁnv uo ::

Biologically inspired neural reconstruction

 

 

‘5’:
7!

Fig. 8. 3D renderings of a reconstructed bouton and axon of a mushroom
body calycal projection neuron. Left: manual alignment and tracing. Right:
the same volume after alignment improvement and semi—automatic tracing.
Small alignment errors are improved, resulting in a less jagged surface
proﬁle. Scale bars: 0.5 gm.

   

and drawing in manually the missing, or false negative, lines. Using
this method, all errors were identiﬁed and a fully traced membrane
dataset was constructed within a small volume (Dataset S1).

Selected trace results and alignment improvements were imported
into manual reconstruction software, Reconstruct (Fiala, 2005), for
direct visual comparison with manual tracing. 3D renderings of
results are shown in Figure 8. Alignment improvement and semi—
automatic tracing produced a more accurate representation of the
reconstructed bouton of a projection neuron, the main input neuron
to the mushroom body calyx. The semi—automatic annotation is
smoother and small misalignments in the z direction are corrected.
The correlation coefﬁcient between pairs of consecutive images was
also calculated for the volume shown in Figure 8. The average
correlation coefﬁcient was 0.29 after manual alignment, and 0.32
after alignment improvement using a linear transformation. Note
that this level of accuracy can also be achieved by careful manual
annotation but would take much longer time to complete. Exact
membrane accuracy is usually traded for faster, less accurate tracing
that preserves topological correctness.

The fully traced membrane dataset was used to optimize and
test algorithm performance. Convolutions necessary for the line
detection algorithm were implemented on a graphics processing
unit (GPU) to improve algorithm speed. Edge detection parameters
were ﬁrst estimated empirically, and then optimized by simplex or
gradient descent optimization to maximize metric scores. The Rand
index, a commonly used measure of segmentation performance
(Rand, 1971; Turaga et al., 2009; Unnikrishnan et al., 2007), was
used to assess performance, as shown in Table 1. Performance
was also measured by the number of separating pixels between
segments that were correct or incorrect as a proportion of total true
positive separating pixels, as shown in Table 1 and displayed in

Table 1. Membrane detection performance

 

 

Rand index Tp Fp Fn
Open edges 0.791 0.976 0.254 0.024
Closed edges 0.762 0.978 0.282 0.022
Ilastik/watershed 0.711 0.973 0.283 0.027
GSH/watershed 0.718 0.948 0.521 0.052

 

Rand index is expressed as a measure of similarity, with 1 being identical to the manually
corrected segmentation. Separating pixel true positive (Tp) false positive (Fp) and false
negative (Fn) rates are shown as a proportion of the total true positive separating pixels.
Algorithm parameters were optimized by simplex or gradient descent to ﬁnd ~10 times
more false positives than false negatives or to maximize the Rand index score. The
5-fold cross-validation was used to validate Rand index scores.

Membrane Detectien ROC

E
I:

 

ED
U1

'Lﬂ-
D

|Il
U1

 

 

“at
Ur
—. _ _._....__

"-14
III

 

- Open Edges

1  — Closed Edges
.r’ ---GSHrWa1mhed ‘
_'  — — 'Ilaslllr .I'Walershed

True positiree {‘13 by pixel count}
E

IJ'I
I'J‘1
1..

 

 

 

 

 

13'!
D

 

nemfszneaseaem
False peantires 1% of true pixel count}

Fig. 9. ROC curve for membrane detection performance after optimization.
Results were assessed before and after edge closure (open edges and
closed edges, respectively). Performance is compared against the watershed
algorithm applied to an optimized GSH, and to a manually trained random
forest classiﬁer (Ilastik). False positives are expressed as a percentage of true
separating pixels, as determined by manual annotation.

a receiver operator characteristic (ROC) in Figure 9. Membrane
detected within 10 pixels of manually annotated membrane was
considered correct, because for the dataset used here this width
would correspond to a ﬂat section of membrane at an oblique angle
of 36°.

Performance was benchmarked against GSH (Mishchenko, 2009;
Venkataraju et al., 2009) and a freely available random forest
classiﬁer, ilastik (Sommer et al., 2011), manually trained on a range
of generic features to identify cell membrane. Scores from both
these benchmarks were segmented by the watershed algorithm.
Parameters were optimized to maximize metric scores in both cases.

Responses of the Gabor—like receptive ﬁelds were robust to several
types of noise sometimes encountered in ssTEM images such as low—
contrast images, blurred or out—of—focus areas and sudden or gradual
changes in brightness. After optimization, the ridge detection and
edge closure methods were able to join gaps where noise such as
oblique membrane or stitching artefacts obscured the receptive ﬁeld
responses.

Line segments identiﬁed by edge detection and edge closure
operations were further classiﬁed as enclosing the proﬁle of either
a synapse or a mitochondrion by the receptive ﬁelds shown in

 

2221

112 /3.IO'SIBUJHOIPJOJXO'SODBIHJOJUIOIQ/ﬂdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

S.Knowles-Barley et aI.

 

 

Feature detection ROC

'EIEI-

Elﬁ-

Ell]-

F5~

 

.T"|I|-

ES - Synapse- I
- - - lu'lilnthendria

n in 15 2s 25 s: as is

False pusilises ('11: of false segments]

True pusihves (es of Hue segments:

 

 

 

 

Fig. 10. ROC curve for feature detection performance of synapse and
mitochondria proﬁles. Line segments found by the edge detection and edge
closure were classiﬁed as either synapses or mitochondria, and results were
manually corrected. False positive rates are expressed as a percentage of line
segments not in the target class (line segments that do not form part of any
synapse or mitochondria).

Figure 2a. Feature detection performance is shown in Figure 10.
False positive rates were higher than those for membrane detection;
however, many false positives were identiﬁed in regions near an
actual synapse or mitochondria. This level of performance could be
useful for narrowing down search areas for manual classiﬁcation of
such biologically signiﬁcant features.

We also trained the ilastik classiﬁer using the membrane receptive
ﬁeld responses as input features. When trained on receptive ﬁeld
responses alone, results were slightly better than those when trained
on generic features (0.72 Rand index). Results improved further
when trained on both receptive ﬁeld responses and generic features
(0.74 Rand index).

4 DISCUSSION

We have presented a set of computational methods for EM image
alignment and reconstruction, based on a set of receptive ﬁelds learnt
from EM image data. The identiﬁcation of many control points for
aligning consecutive images can improve upon manual alignment
methods and is robust to many types of noise encountered in EM
images. Closing edges based on a shortest path algorithm can also
achieve a full segmentation of images and additional receptive ﬁelds
can be used to identify the proﬁles of synapses and other organelles
present in ssTEM images.

The ridge detection approach is complementary to existing
regional or watershed—based methods, and achieves similar or
superior results. Aligning points of membrane by the dynamic
programming algorithm is also complementary to existing control
point—based alignment methods and can improve upon these in
some cases, especially at places where areas of noise or imaging
artefacts affect control point properties. An open—source reference
implementation of the ridge detection and alignment algorithms is
available for download in Dataset S2.

The manual alignment and segmentation of detailed ssTEM
images is very time consuming, but information on synaptic
connections obtained by these means is essential for research in

systems neuroscience (Briggman and Denk, 2006). This reawakened
need has recently received renewed recognition, identiﬁed in the
recently designated ﬁeld of connectomics (Lichtman and Sanes,
2008). Inspired by the example of tools used in biology for molecular
alignment, the set of methods we report for improved alignment
and detection of membrane is able to assist in the time—consuming
process of manual annotation.

Further information about likely membrane locations is also
available from consecutive images in the stack. Areas where
membrane alignment is poor between two images in the z—axis
may indicate a false positive or false negative identiﬁcation in
either image. Utilization of this additional information and further
improvements in both image processing techniques and image
quality will help lead to the complete automation of neuronal
reconstruction in 3D, and the complete identiﬁcation and deﬁnition
of circuits constituted by such reconstructed neurons.

Approaches to image analysis based on receptive ﬁelds are
inspired by research into the visual systems especially of mammals
(Hubel and Wiesel, 1959) and insects (O’Carroll, 1993), in which
visual intemeurons have been shown to respond to bars, lines or
edges. That area of vision research is under constant evaluation,
and advances in it can lead to improved accuracy for segmentation
and feature detection. Future avenues of research include identifying
additional useful receptive ﬁeld types and combining outputs from
different receptive ﬁelds into a layered system for more accurate
detection of cell membranes and other organelles. Applying these
techniques to ssTEM data offers for the future an improved
understanding not only of visual systems but in turn also a further
improvement of such computational techniques.

ACKNOWLEDGEMENT

We thank Zhiyuan Lu for cutting and imaging the series of ultrathin
sections used in our analysis.

Funding: Engineering and Physical Sciences Research Council (to
S.K.—B., J.D.A.); Medical Research Council (to S.K.—B., J.D.A.);
Biotechnology and Biological Sciences Research Council (to
J.D.A.); British Society for Developmental Biology (to S.K.—B.);
Natural Sciences and Engineering Research Council (NSERC)
Discovery program (to I.A.M.); Julie Payette—NSERC and Killam
Scholarships (to N.J.B.); GPU access and funding provided by
University of Edinburgh iDEA Lab (to S.K.—B.).

Conﬂict of Interest: none declared.

REFERENCES

Anderson,J.R. et al. (2009) A computational framework for ultrastructural mapping of
neural circuitry. PLoS Biol, 7, e1000074, 0493—05 12.

Andres,B. et al. (2008) Segmentation of SBFSEM volume data of neural tissue by
hierarchical classiﬁcation. In Rigoll,G. (ed) Pattern Recognition, Vol. 5096 of
Lecture Notes in Computer Science, chapter 15. Springer, Berlin, Heidelberg, pp.
142—152.

Angelucci,A. et al. (2002) Anatomical origins of the classical receptive ﬁeld and
modulatory surround ﬁeld of single neurons in macaque visual cortical area V1.
Progr. Brain Res., 136, 373—388.

Beucher,S. (1991) The watershed transformation applied to image segmentation.
Scanning Microscopy International, 6, 299—314.

Briggman,K.L. and Denk,W. (2006) Towards neural circuit reconstruction with volume
electron microscopy techniques. Curr. Opin. Neurobiol, 16, 562—570.

 

2222

112 /810's12u1nofp101x0'sor112u1101urorq//zd11q 111011 pep1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Biologically inspired neural reconstruction

 

Carandini,M. et al. (2005) Do we know what the early visual system does? J. Neurosci.,
25, 10577—10597.

Cardona,A. et al. (2010a) An integrated micro- and macroarchitectural analysis of the
Drosophila brain by computer-assisted serial section electron microscopy. PIoS
Biol., 8, e1000502, 1—17.

Cardona,A. et al. (2010b) Identifying neuronal lineages of Drosophila by sequence
analysis of axon tracts. J. Neurosci., 30, 7538—7553.

Chklovskii,D.B. et al. (2010) Semi-automated reconstruction of neural circuits using
electron microscopy. Curr. Opin. Neurobiol, 20, 667—675.

Eisenstein,M. (2009) Neural circuits: putting neurons on the map. Nature, 461,
1149—1152.

Fiala,J.C. (2005) Reconstruct: a free editor for serial section microscopy. J. Microsc,
218 (Pt 1), 52—61.

Fitzpatrick,D. (2000) Seeing beyond the receptive ﬁeld in primary visual cortex. Curr.
Opin. Neurobiol, 10, 438—443.

Hartline,H.K. et al. (1956) Inhibition in the eye of Limulus. J. Gen. Physiol., 39,
651—673.

Hubel,D.H. and Wiesel,T.N. (1959) Receptive ﬁelds of single neurones in the cat’s
striate cortex. J. Physiol., 148, 574—591.

Ichida,J.M. et al. (2007) Response facilitation from the ‘Suppressive’ receptive ﬁeld
surround of Macaque V1 neurons. J. Neurophysiol, 98, 2168—2181.

Jain,V. et al. (2010) Machines that learn to segment images: a crucial technology for
connectomics. Curr. Opin. Neurobiol, 20, 653—666.

Jiang,X. et al. (2002) Curve morphing by weighted mean of strings. In IEEE 16th
International Conference on Pattern Recognition, v01. 4, IEEE Press, pp. 192—195.

Jurrus,E. et al. (2008) An optimal-path approach for neural circuit reconstruction. In
IEEE International Symposium on Biomedical Imaging: From Nano to Macro,
vol. 2008, IEEE Press, pp. 1609—1612.

Kaynig,V. et al. (2010) Neuron geometry extraction by perceptual grouping in ssTEM
images. In IEEE Conference on Computer Vision and Pattern Recognition ( C VPR ),
IEEE Press, pp. 2902—2909.

Kremer,J.R. et al. ( 1996) Computer visualization of three-dimensional image data using
IMOD. J. Struct. Biol., 116, 71—76.

Leiss,F. et al. (2009) Synaptic organization in the adult Drosophila mushroom body
calyx. J. Comp. Neurol., 517, 808—824.

Lichtman,J.W. and Sanes,].R. (2008) Ome sweet ome: what can the genome tell us
about the connectome? Curr. Opin. Neurobiol, 18, 346—353.

L0renz,C. et al. (1997) A multi-scale line ﬁlter with automatic scale selection
based on the Hessian Matrix for medical image segmentation. In Proceedings
of the First International Conference on Scale-Space Theory in Computer Vision,
SCALE-SPACE ’97. Springer, London, UK, pp. 152—163.

Meinertzhagen,I.A. and O’Neil,S.D. (1991) Synaptic organization of columnar elements
in the lamina of the wild type in Drosophila melanogaster. J. Comp. Neurol., 305,
232—263.

Mishchenk0,Y. (2009) Automation of 3D reconstruction of neural tissue from
large volume of conventional serial section transmission electron micrographs.
J. Neurosci. Methods, 176, 276—289.

Needleman,S.B. and Wunsch,C.D. (1970) A general method applicable to the search
for similarities in the amino acid sequence of two proteins. J. Mol. Biol., 48,
443—453.

O’Carroll,D. (1993) Feature-detecting neurons in dragonﬂies. Nature, 362,
541—543.

Olshausen,B.A. and Field,D.J. (1996) Emergence of simple-cell receptive ﬁeld
properties by learning a sparse code for natural images. Nature, 381, 607—609.
Olshausen,B.A. and Field,D.J. (2005) How close are we to understanding V1? Neural

Comput, 17, 1665—1699.

Ozeki,H. et al. (2004) Relationship between excitation and inhibition underlying
size tuning and contextual response modulation in the cat primary visual cortex.
J. Neurosci., 24, 1428—1438.

Ozeki,H. et al. (2009) Inhibitory stabilization of the cortical network underlies visual
surround suppression. Neuron, 62, 578—592.

Palagina,G. et al. (2009) Strengthening of lateral activation in adult rat visual cortex
after retinal lesions captured with voltage-sensitive dye imaging in vivo. Proc. Natl
Acad. Sci. USA, 106, 8743—8747.

Rand,W.M. (1971) Objective criteria for the evaluation of clustering methods. J. Am.
Stat. Assoc, 66, 846—850.

Saalfeld,S. et al. (2010) As-rigid-as-possible mosaicking and serial section registration
of large ssTEM datasets. Bioinformatics, 26, i57—i63.

Smith,S.J. (2007) Circuit reconstruction tools today. Curr. Opin. Neurobiol, 17,
601—608.

Smith,T.F. and Waterman,M.S. (1981) Identiﬁcation of common molecular
subsequences. J. Mol. Biol., 147, 195—197.

S0mmer,C. et al. (2011) ilastik: Interactive Learning and Segmentation Toolkit. In IEEE
International Symposium on Biomedical Imaging: From Nano to Macro, 201 I IEEE
International Symposium on. IEEE Press, pp. 230—233.

Takemura,S.-Y.Y. et al. (2008) Synaptic circuits of the Drosophila optic lobe: the input
terminals to the medulla. J. Comp. Neurol, 509, 493—513.

Turaga,S.C. et al. (2009) Maximin afﬁnity learning of image segmentation. In Neural
Information Processing Systems (NIPS). V01. 22, NIPS Foundation, pp. 1865—1873.

Unnikrishnan,R. et al. (2007) Toward objective evaluation of image segmentation
algorithms. IEEE Trans. Pattern Anal. Mach. Intell., 29, 929—944.

Venkataraju,K.U. et al. (2009) Automatic markup of neural cell membranes using
boosted decision stumps. In Proceedings of the Sixth IEEE international conference
on Symposium on Biomedical Imaging, pp. 1039—1042.

White,J.G. et al. (1976) The structure of the ventral nerve cord of Caenorhabditis
elegans. Philos. Trans. R. Soc. London Ser. B Biol. Sci., 275, 327—348.

Ziou,D. (1991) Line detection using an optimal IIR ﬁlter. Pattern Recognit, 24,
465—478.

 

2223

112 /810's12u1nofp101x0'sor112u1101urorq//zd11q 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

