Bioinformatics, 32(6), 2016, 955—957

doi: 10.1093/bioinformatics/btv686

Advance Access Publication Date: 20 November 2015
Applications Note

 

Bioimage informatics

CellTracker (not only) for dummies

Filippo Piccinini”, Alexa Kissz'T and Peter Horvath3'4'*

1Advanced Research Center on Electronic Systems for Information and Communication Technologies "E. De
Castro" (ARCES), University of Bologna, 1-40125 Bologna, Italy, 2Department of Biochemistry and Cell Biology, Max
F. Perutz Laboratories (MFPL), University of Vienna, Vienna Biocenter (VBC), A-1030 Vienna, Austria, 3Synthetic
and System Biology Unit, Hungarian Academia of Sciences, Biological Research Center (BBC), H-6726 Szeged,
Hungary and 4Institute for Molecular Medicine Finland, University of Helsinki, FI-00014 Helsinki, Finland

*To whom correspondence should be addressed.
TThe authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.
Associate Editor: Robert Murphy

Received on July 20, 2015; revised on November 7, 2015; accepted on November 14, 2015

Abstract

Motivation: Time—lapse experiments play a key role in studying the dynamic behavior of cells. Single—
cell tracking is one of the fundamental tools for such analyses. The vast majority of the re—
cently introduced cell tracking methods are limited to fluorescently labeled cells. An equally important
limitation is that most software cannot be effectively used by biologists without reasonable expertise in
image processing. Here we present CellTracker, a user—friendly open—source software tool for tracking
cells imaged with various imaging modalities, including fluorescent, phase contrast and differential
interference contrast (DIC) techniques.

Availability and implementation: CellTracker is written in MATLAB (The MathWorks, Inc., USA).
It works with Windows, Macintosh and UNIX—based systems. Source code and graphical user
interface (GUI) are freely available at: http://celItracker.website/.

Contact: horvath.peter@brc.mta.hu

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

 

The migration analysis of in vitro cultured cell populations plays a
key role in a wide range of dynamic cell behavior studies (Li et 61].,
2008). In the last decade, dozens of methods have been proposed for
such analyses (Hand et 61]., 2009; Meijering et 61]., 2012). There is no
universally best, but a great variety of methods eXist for different
ﬂuorescent microscopic scenarios (Chenouard et 61]., 2014; Maska
et 61]., 2014). However, very few tracking tools can analyze images
taken by phase contrast, DIC, or other label—free microscopy (i.e.
techniques using transmitted light or its modulations), which are com—
mon ways to observe living cells. Furthermore, the majority of these
tools require relevant image processing skills, which strongly limits
their practical usefulness within the biologist community (Cordeliéres
et 61]., 2013). For instance, BioImageXD (Kankaanpaa et 61]., 2012),
TimeLapseAnalyzer (Huth et 61]., 2011) and TACTICS (Shimoni

et 61]., 2013) require segmented cells for tracking, and cell segmenta—
tion on label—free microscopic images is very challenging.
Accordingly, so—called point-and—click manual tracking tools are often
used (Meijering et 61]., 2012) and they are considered as the gold stand—
ard for cell tracking (Cordeliéres et 61]., 2013; Hand et 61]., 2009).
Nevertheless, manual tracking is operator—dependent, laborious and
error—prone (Sacan et 61]., 2008). An automated, user—friendly, and ver—
satile open source software with track editing possibilities would boost
live cell analysis research. In this work we present CellTracker, a cell—
center detection and tracking tool for different imaging modalities. An
early version of CellTracker was already used in (Kiss et 61]., 2014;
Klingauf et 61]., 2013). Here we describe its implementation and usage
(Supplementary Material 81) with the intention of providing a tool also
for users with limited image processing background.

©The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 955

91% ‘09 1sn3nv uo sopﬁuv s01 111110;th aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

956

F. Piccinini et al.

 

2 Methods

The GUI of CellTracker (Fig. 1a) is designed to intuitively support
users during the analysis. Several functions are included in order to
pre—process images (tiff, avi and Bioformats files are supported), track
cells, edit and analyze tracks. Microscopes are imperfect systems both
in terms of optics and mechanics. Any microscopic image has a cer—
tain degree of uneven illumination (Smith et al., 2015), which may af-
fect cell tracking algorithms (Li et al., 2008). Furthermore, during
time—lapse acquisition, spatial misalignments can occur due to stage
imperfections. CellTracker is capable of correcting such imperfec—
tions. Three different tracking modalities are available and can be
combined. Fully automatic tracking is a combination of template
matching and a tracking algorithm (Crocker and Grier, 1996). Using
semiautomatic tracking, the user selects the cells to be tracked. The al—
gorithm defines a specific template for each selected cell and searches
for best match on the consecutive frames. An adaptive template
method is used to handle slight cellular deformations over time. The
manual tracking option provides a point—and—click solution, wherein
the user defines the position of the cell either on each frame or on key
frames. In the latter case, intermediate cellular positions are deter—
mined by using a novel dynamic programming method described in
Section 2.1. For the semiautomatic and manual tracking, histogram
or template matching search algorithms may be chosen to determine
the position of selected cells on consecutive frames. Several additional
functions enable the user to merge, delete, move, display, save and
load the tracks (Fig. 1b). A great variety of measurements at single—
cell and population level are available (Fig. 1c).

 

{a}   - (bi 

 

 

 

 

{a} '

r-I-r-l-Iralhl IIIIr-wl 1": hull-hr lull-Ia :Waswfl'l I-CI'I:

I: lal EL"! II "|.'l.l"llll'| u HIP-dur- I I .|.I~1m.'" LIME-Id “II-LEI- 1|" :III'

 

iiﬁiiﬁﬂii
II-1"'-I:I:
'i T
i
1 1
1. I'.
J
1
.l'
|
J I
:I

'I
I
.L
J
I
J

 

 

 

 Manual Manual ManuaF Samlautcmatlc Sammutomallc mlnmalic
Tamp. Match. Hist. Match. Linear il'llE'l'FI. Tamp. Malch. Hist. Match.
0.4? '3-55
E122 0.2? 0.23 CLEB
WEE I I I I I

 

 

CLBEII GEE I193 [193 )3 3|} G a?

II I
“MECDCDCDQQQ

Fig. 1. (a) CellTracker GUI. (b) Cell trajectories on phase contrast images. (c)
Statistics tab. (d) Comparison of CellTacker's different working modalities.
Time region black: tracking time; gray: post-processing time

 

2.1 Atrack refinement approach for manual tracking
based on dynamic programming

Typically, manual tracking tools allow the user to define the pos—
ition of the individual cell simply by clicking every kth frame. In
case k > 1, missing positions are usually determined by linear inter-
polation. Besides this approach, we present a new solution to find
the globally optimal track between key frames. A globally optimal
track maximizes the match between the template of the shape (cell)
of interest and the image, while large, unrealistic jumps are re—
stricted. This global optimization problem can be solved very effi—
ciently using dynamic programming approach (Cormen et al., 2001)
by building a directed graph over all possible tracks. Dynamic pro—
gramming methods solve a complex problem by breaking it into a
collection of simpler sub—problems. In brief, we search the optimal
path between the nth and mth frames such that we recursively find
optimal paths for every position at frame m-1 and select the most
optimal amongst these. The method is described in Supplementary
Material S2.

3 Results

A qualitative comparison of CellTracker with relevant tracking tools
is shown in Supplementary Material S3. Furthermore, we quantita—
tively compared six different settings of CellTracker (details in
Supplementary Material S4) by using three different datasets (fluor—
escence, DIC and phase contrast images, Supplementary Material
S5). We only tracked cells that are present in the first frame, and
excluded those touching image borders (ground truth is provided in
Supplementary Material 6). Figure 1d summarizes the obtained re—
sults (Supplementary Material S7). We used three metrics for this
comparison (Supplementary Material S8). Relative root mean
squared error, normalized to the cell size (rRMSE), Jaccard similar-
ity coefficient (JSC, Chenouard et al., 2014) and overall processing
time. Automatic tracking was considerably precise (average rRMSE
0.28), but it required the most time for post—processing of the de—
tected tracks. Automatic tracking might be the best choice for appli-
cations where the detection of cells is relatively easy. Semiautomatic
tracking was the fastest modality and represents a good trade—off be—
tween cell detection and tracking accuracy. As expected the most ac—
curate solution was manual tracking. The best solution was
obtained by manual tracking combined with template matching
(rRMSE 0.22, JSC 0.99). In conclusion, CellTracker is a versatile
tool able to track cells and other objects (Supplementary Material
S9) in different scenarios. Combining accuracy and usability, it is an
easy—to—use and efficient solution especially for users with limited ex-
pertise in image processing.

Acknowledgements

The authors would like to thank Dr. Zoltan Asztalos (BRC, Szeged) for pro-
viding some of the datasets used to test the software.

Funding

P.H. acknowledges support from the Finnish TEKES FiDiPro; Hungarian
National Brain Research Programme (MTA-SE-NAP B-BIOMAG). EMBO,
Heidelberg, Germany for the short-term fellowship granted to FF (EMBO
ASTF 233-2015).

Conﬂict of Interest: none declared.

9mg ‘09 1sn3nv uo sojoﬁuv s01 ‘ETUJOJHBQ aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

CellTracker (not only) for dummies

957

 

References

Chenouard,N. et al. (2014) Objective comparison of particle tracking meth-
ods. Nat. Methods, 11, 281—289.

Cordeliéres,F.P. et al. (2013) Automated cell tracking and analysis in phase-
contrast Videos (iTrack4U): development of Java software based on com-
bined mean-shift processes. PLoS One, 8, e81266.

Cormen,T.H. et al. (2001) Introduction to Algorithms. 2nd edn. MIT Press 85
McGraw—Hill, ISBN 0-262-03293-7, Cambridge, Massachusetts (MA), pp.
327—328.

Crocker,].C. and Grier,D.G. (1996) Methods of digital Video microscopy for
colloidal studies. ]. Colloid Interface Sci., 179, 298—310.

Hand,A.]. et al. (2009) Automated tracking of migrating cells in phase-contrast
Video microscopy sequences using image registration. ]. Microsc., 234, 62—79.
Huth,]. et al. (2011) TimeLapseAnalyzer: multi-target analysis for live-cell imag-
ing and time-lapse microscopy. Comput. Methods Programs Biomed., 104,

227—234.

Kankaanpaa,P. et al. (2012) BioImageXD: an open, general-purpose and high-

throughput image-processing platform. Nat. Methods, 9, 6 83—6 89.

Kiss,A. et al. (2014) Nuclear Motility in glioma cells reveals a cell-line depend-
ent role of various cytoskeletal components. PloS One, 9, e93431.

Klingauf,M. et al. (2013) The tumour suppressor DiRas3 interacts with C-
RAF and downregulates MEK activity to restrict cell migration. Biol. Cell, 105,
91—107.

Li,K. et al. (2008) Cell population tracking and lineage construction with spa-
tiotemporal context. Med. Image Anal, 12, 546—566.

Maska,M. et al. (2014) A benchmark for comparison of cell tracking algo-
rithms. Bioinformatics, 30, 1609—1617.

Meijering,E. et al. (2012) Methods for cell and particle tracking. Methods
Enzymol., 504, 183—200.

Sacan,A. et al. (2008) CellTrack: an open-source software for cell tracking and
motility analysis. B ioinformatics, 24, 1647—1649.

Shimoni,R. et al. (2013) TACTICS, an interactive platform for customized
high-content bioimaging analysis. Bioinformatics, 29, 817—818.

Smith,K. et al. (2015) CIDRE: an illumination-correction method for optical
microscopy. Nat. Methods, 12, 404—406.

91% ‘09 1sn3nv uo sojoﬁuv s01 ‘ETUJOJHBQ aIo Amie/xtqu 112 /§.IO'S[BU.IHO[p.IOJXO'SOTlBIHJOJUTOTQ/ﬁ(1111] 11101; popeommoq

