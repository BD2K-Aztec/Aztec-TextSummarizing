APPLICATION NOTE

Vol. 28 no. 19 2012, pages 2520—2522
doi: 10. 1093/bioinformatics/bts480

 

Genome analysis

Advance Access publication August 20, 2012

Snakemake—a scalable bioinformatics workflow engine

Johannes Koster1’2’* and Sven Rahmannl

lGenome Informatics, Institute of Human Genetics, University of Duisburg—Essen and 2Paediatric Oncology,

University Childrens Hospital, 45147 Essen, Germany
Associate Editor: Alfonso Valencia

 

ABSTRACT

Summary: Snakemake is a workflow engine that provides a readable
Python-based workflow definition language and a powerful execution
environment that scales from single-core workstations to compute
clusters without modifying the workflow. It is the first system to sup-
port the use of automatically inferred multiple named wildcards (or
variables) in input and output filenames.

Availability: http://snakemake.googlecode.com.

Contact: johannes.koester@uni—due.de

Received on May 14, 2012; revised on June 28, 2012; accepted on
July 28, 2012

1 INTRODUCTION

Large-scale data analyses in bioinformatics involve the chained
execution of many command line applications. Workﬂow en-
gines help to automate these pipelines and ensure reproducibility.

Systems such as Biopipe (Hoon et al., 2003), Taverna (Oinn
et al., 2004), Galaxy (Goecks et al., 2010), GeneProf (Halbritter
et al., 2011) or PegaSys (Shah et al., 2004) are easy to learn and
use through their graphical user interface. Others such as Ruffus
(Goodstadt, 2010), Pwrake (Tanaka and Tatebe, 2010), GXP
Make (Taura et al., 2010) and Bpipe (Sadedin et al., 2012) use
text-based deﬁnition of workﬂows, which can be advantageous:
workﬂows can be edited without a graphical environment (e. g.
directly on a remote server); and developers can collaborate on
them through source code management tools. Similar to Pwrake
and GXP Make, Snakemake is inspired by the build system
GNU Make (Stallman and McGrath, 1991). They all infer the
actual workﬂow (dependencies, parallelization) from a set of
rules with input and output ﬁles. Snakemake complements
these prior works with a syntax close to pseudocode, in the
spirit of the Python language.

Snakemake interoperates with any installed tool or available
web service with well-deﬁned input and output (ﬁle) formats.
Although this approach lacks type checking of intermediate
ﬁles, it does not require tight integration of tools into the work-
ﬂow system, such as with PegaSys (Shah et al., 2004), and thus is
most ﬂexible. Snakemake itself is fully portable, as only a Python
installation is required to run Snakeﬁles. It provides automatic
scalability because it optimizes the number of parallel processes
w.r.t. provided CPU cores and needed threads and can make use
of single machines as well as cluster engines without modifying
the workﬂow. In contrast to Pwrake and GXP Make,
Snakemake does not rely on any password-less SSH setup or

 

*To whom correspondence should be addressed.

custom server processes running on the cluster nodes. Finally,
Snakemake is the ﬁrst system to support ﬁle name inference with
multiple named wildcards in rules.

2 SNAKEMAKE LANGUAGE

A workﬂow is deﬁned in a ‘Snakeﬁle’ through a domain-speciﬁc
language that is close to standard Python syntax. It consists of
rules that denote how to create output ﬁles from input ﬁles. The
workﬂow is implied by dependencies between the rules that arise
from one rule needing an output ﬁle of another as an input ﬁle.

A rule deﬁnition speciﬁes (i) a name, (ii) any number of input
and output ﬁles and (iii) either a shell command or Python code
that creates the output from the input. Input and output ﬁles
may contain multiple named wildcards, whose values are inferred
automatically from the ﬁles desired by the user. Listing 1 shows
an example Snakeﬁle for mapping sequence reads to a reference
genome, which is a typical task in, e.g. cancer genomics
(Meyerson et al., 2010): paired-end sequence reads are given as
.fastq ﬁles for four samples named 100—103 and mapped to the
human reference genome. Then, a histogram of the
per-nucleotide coverage is generated. There are two variable def-
initions (here SAMPLES and REF) that may also be included
from external ﬁles or environment variables and ﬁve rules that
each start with the keyword rule followed by a name and the
deﬁnitions of input and output ﬁles and shell commands or
Python code. Although Python code can be directly integrated
into the workﬂow deﬁnition, Snakemake is not limited to Python
scripts: any available tool or service may be invoked in a
shell— or run—block and its output further processed.

The rule f as tq_to_sai (1. 6—9) describes how to map the
reads given the .fastq ﬁle and the reference. It uses two named
wildcards, so it can be applied to the ﬁrst and the second read of
each read pair (wildcard {group }) from each sample (wildcard
{sample}). If the rule is requested to create the ﬁle
100 . l . sai, the wildcard {sample} becomes 100 and
{group} becomes 1, so that the input ﬁle 100 . l . fastq is
expected. To resolve ambiguity, wildcards can be restricted to
regular expressions (e.g. {group, [12] } only allows a single
character from the set {1 , 2}, while {group, \d+} allows
any number of numeric characters). Here, BWA (Li and
Durbin, 2009) is used for read mapping, which produces sufﬁx
array interval (. sa i) ﬁles that must be converted to the common
format .bam for aligned reads; this is done by the rule sai_to_
barn (1. 10—14). In the rule fastq_to_sai, input
ﬁles are named (as ref and reads) and can be accessed as
{input . ref} or {input . reads} in the shell block (1. 9).

 

2520 © The Author 2012. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com

112 [glO'SIBILInO[plOJXO'SODBIILIOJIITOIQ/[Z(11111 IIIOJJ papeolumoq

910K ‘09 lsnﬁnV no :2

Snakemake

 

 

Listing 1. Example Snakeﬁle for mapping paired-end reads with BWA.

 

(1) SAMPLES = "100 101 102 103" .split()

(2) REF 2 "hgl9 . fa"
(3) rule all:
(4) input : " {sample} . coverage .pdf " . format (sample 2 sample)
(5) for sample in SAMPLES
(6) rule fastq_to_sai :
(7) input: ref 2 REF, reads 2 " {sample} . {group} . fastq"
(8) output: temp ( " {sample} . {group} . sai ")
(9) shell : "bwa aln {input . ref} {input . reads} > {output} "
(10) rule sai_to_bam:
(11) input: REF, " {sample} . l . sai" , " {sample} . 2 . sai " ,
(12) " {sample} . l . fastq" , " {sample} . 2 . fastq"
(13) output: protected( " {sample} .bam")
(14) shell : "bwa sampe {input} I samtools View —Sbh — > {output} "
(15) rule remove_duplicates:
(16) input: " {sample} .bam"
(17) output : " {sample} . nodup . bam"
(18) shell: "samtools rmdup {input} {output} "
(19) rule plot_coverage_histogram:
(20) input: " {sample} .nodup .bam"
(21) output: hist = " {sample} . coverage.pdf"

(22) run:

(23) from matplotlib.pyplot import hist, savefig
(24) hist (list (map (int ,

(25) shell ( "samtools mpileup {input} I cut —f4 " ,
(26) iterable=True) ) ) )

(27) savefig (output . hist)

 

In the rule sai_to_bam, all input ﬁles are accessed at once
through {input} (1. 14). BWAs internal. sai ﬁles can be
deleted automatically once the . bam ﬁles are created, which
are in turn worth to be write-protected to avoid accidental dele-
tion. Snakemake supports this by marking ﬁles as temp (l. 8)
and protected (1. 13). The rule remove_duplicates removes
polymerase chain reaction-induced duplicate reads from the
.bam ﬁles using the ‘samtools’ package (Li et al., 2009).
Finally, the rule plot_coverage creates a coverage histogram
for each position of the reference using Python’s ‘matplotlib’
(Hunter, 2007). This rule illustrates how shell output from sam-
tools is directly iterated over by Python code with Snakemake’s
built-in shell function in a run-block.

When Snakemake is invoked without a speciﬁc target, the ﬁrst
rule (here the input-only rule all) is executed. It ensures that the
coverage plot and hence all needed intermediate ﬁles are created
for each sample. See http://snakemake.googlecode.com for fur-
ther examples and detailed documentation.

3 SNAKEMAKE ENGINE

Upon invocation, Snakemake creates a directed acyclic graph
(DAG) that represents a plan of rule executions (Fig. 1). The
nodes of the DAG are jobs (i.e. the execution of a rule), a dir-
ected edge between job A and B means that the rule underlying
job B needs the output of job A as an input ﬁle. A path in the

 

 

fastq_to_sai fastq_to_sai fastq_to_sai fastq_to_sai fastq_to_sai fastq_to_sai fastq_to_sai fastq_to_sai
sample: 101 sample: 101 sample: 102 sample: 102 sample: 100 sample: 100 sample: 103 sample: 103
group: 2 group: 1 group: 2 group: 1 group: 2 group: 1 group: 1 group: 2

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Iremove_duplicates l lremove_duplicates l Iremove_duplicates I

lremove_duplicates l

 

 

 

Iplot_coverage_histogram llplot_coverage_histogram IIplot_coverage_histogram IIplot_coverage_histogram l
Fig. 1. DAG of jobs for the example workﬂow

 

DAG represents a sequence of jobs that have to be executed
serially. Importantly, two disjoint paths in the DAG can be
executed independently from each other, i.e. in parallel. Since
individual jobs can use multiple threads themselves,
Snakemake can be instructed to solve a 0/1-knapsack problem
to optimize the usage of CPUs, given a threshold of available
cores. This mechanism allows to scale Snakemake to environ-
ments with a hard limit of used CPU cores, e. g. a shared compute
server. Furthermore, using only as many threads as there are
cores available can be beneﬁcial for performance since it reduces
the amount of context switching.

By default, Snakemake only executes rules if the output ﬁles
are not present or the modiﬁcation time of the input ﬁles is
newer. Together with the automatic deletion of output ﬁles
from incomplete rule executions (e. g. due to a failing shell com-
mand), this enables Snakemake to avoid duplicate work when
resuming workﬂows.

To analyse the workﬂow, Snakemake provides options to per-
form a dry-run without actual execution of jobs, give the reason
for each executed job and print the DAG to the graphvizdot
format (Gansner and North, 2000) for visualization.

Apart from running on single machines, Snakemake contains
a generic mechanism that allows the execution of j obs on a batch
system or a compute cluster engine that is only constrained by
the availability of a submit command that handles shell scripts
(e. g. qsub) and a shared ﬁle system accessible by all cluster nodes.
Hence, a Snakeﬁle scales from single-core workstations over
multi-core servers to compute clusters of different architectures,
without the need to modify the workﬂow.

ACKNOWLEDGEMENTS

The authors thank Tobias Marschall (CW1 Amsterdam) and
Marcel Martin (TU Dortmund) for their tremendously helpful
testing work, feature requests and comments.

Conﬂict of Interest: None declared.

REFERENCES

Gansner,E.R. and North,S.C. (2000) An open graph visualization system and its
applications to software engineering. Software Pract Exper, 30, 1203—1233.
Goecks,J. et a]. (2010) Galaxy: a comprehensive approach for supporting accessible,
reproducible, and transparent computational research in the life sciences.
Genome Biol, 11, R86.

Goodstadt,L. (2010) Ruffus: a lightweight Python library for computational pipe-
lines. Bioinformatics, 26, 2778—2779.

Halbritter,F. et a]. (2011) GeneProf: analysis of high-throughput sequencing experi-
ments. Nat. Methods, 9, 7—8.

 

2521

112 [glO'SIBILInO[plOJXO'SODBIILIOJIIIOIQ/[Z(11111 IIIOJJ pepnolumoq

910K ‘09 lsnﬁnV uo ::

J.K6ster and S.Rahmann

 

Hoon,S. et al. (2003) Biopipe: a ﬂexible framework for protocol-based bioinfor-
matics analysis. Genome Res., 13, 1904—1915.

Hunter,J. (2007) Matplotlib: a 2D graphics environment. Comput. Sci. Eng., 9,
90—95.

Li,H. and Durbin,R. (2009) Fast and accurate short read alignment with Burrows—
Wheeler transform. Bioinformatics, 25, 1754—1760.

Li,H. et al. (2009) The sequence Alignment/Map format and SAMtools.
Bioinformatics, 25, 2078—2079.

Meyerson,M. et al. (2010) Advances in understanding cancer genomes through
second-generation sequencing. Nat. Rev. Genet, 11, 685—696.

Oinn,T. et al. (2004) Taverna: a tool for the composition and enactment of
bioinformatics workﬂows. Bioinformatics, 20, 3045—3054.

Sadedin,S.P. et al. (2012) Bpipe: a tool for running and managing bioinformatics
pipelines. Bioinformatics, 28, 1525—1526.

Shah,S.P. et al. (2004) Pegasys: software for executing and integrating analyses of
biological sequences. BMC Bioinformatics, 5, 40.

Stallman,R.M. and McGrath,R. (1991) GNU Make—A Program for Directing
Recompilation. http://wwwgnu.org/software/make/ .

Tanaka,M. and Tatebe,0. (2010) Pwrake: a parallel and distributed ﬂexible work-
ﬂow management tool for wide-area data intensive computing. In HPDC’IO,
ACM. pp. 356—359. http://dl.acm.org/citation.cfm?id= 1851529.

Taura,K. et al. (2010) Design and Implementation of {GXP} Make — A Workﬂow
System Based on Make. In IEEE International Conference on eScience, IEEE
Computer Society, pp. 214—221, Los Alamitos, CA, USA.

 

2522

112 [3.10811211an[plOJXO'SODBIIIJOJIIIOIQ/[Zdllq 111011 p9p1201umoq

910K ‘09 lsnﬁnV uo ::

