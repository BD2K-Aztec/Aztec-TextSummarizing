Vol. 27 no. 22 2011, pages 3200-3201
APP S N O  doi:10.1093/bioinformatics/btr554

 

Genome analysis

Advance Access publication October 7, 2011

Knime4Bio: a set of custom nodes for the interpretation of
next-generation sequencing data with KNIME”r

Pierre LindenbaumI, Solena Le ScouarnecZ, Vincent Portero1 and Richard Redonm

1Institut du thorax, Inserm UMR 915, Centre Hospitalier Universitaire de Nantes, 44000 Nantes, France and
2The Wellcome Trust Sanger Institute, Hinxton, Cambridge CB10 18A, UK

Associate Editor: John Quackenbush

 

ABSTRACT

Summary: Analysing large amounts of data generated by next-
generation sequencing (NGS) technologies is difficult for researchers
or clinicians without computational skills. They are often compelled
to delegate this task to computer biologists working with command
line utilities. The availability of easy-to-use tools will become essential
with the generalization of NGS in research and diagnosis. It will
enable investigators to handle much more of the analysis. Here,
we describe Knime4Bio, a set of custom nodes for the KNIME (The
Konstanz Information Miner) interactive graphical workbench, for the
interpretation of large biological datasets. We demonstrate that this
tool can be utilized to quickly retrieve previously published scientific
findings.

Availability: http://code.google.com/p/knime4bio/.

Contact: richard.redon@univ-nantes.fr

Received on August 11, 2011; revised on September 13, 2011;
accepted on September 29, 2011

1 INTRODUCTION

Next—generation sequencing (NGS) technologies have led
to an explosion of the amount of data to be analysed. As
an example, a VCF (Danecek et al., 2011) ﬁle (Variant
Call Format—a standard speciﬁcation for storing genomic
variations in a text ﬁle) produced by the 1000 Genomes Project
contains about 25 million Single Nucleotide Variants (SNV),
[http://tinyurl.com/ALL2of4intersection (retrieved September
2011)], making it difﬁcult to extract relevant information using
spreadsheet programs. While computer biologists are used to
invoke common command line tools—such as Perl and R—when
analysing those data through Unix pipelines, scientiﬁc investigators
generally lack the technical skills necessary to handle these tools
and need to delegate data manipulation to a third party.

Scientiﬁc workﬂow and data integration platforms aim to make
those tasks more accessible to those research scientists. These tools
are modular environments enabling an easy visual assembly and an
interactive execution of an analysis pipeline (typically a directed
graph) where a node deﬁnes a task to be executed on input data
and an edge between two nodes represents a data ﬂow. These
applications provide an intuitive framework that can be used by

 

*To whom correspondence should be addressed.

IDuring the reviewing process of this article another solution based on
KNIME but focusing on FASTQ data ﬁles was published by J agla er al (J agla
et 61]., 2011).

the scientists themselves for building complex analyses. They allow
data reproducibility and workﬁows sharing.

Galaxy (Blankenberg et al., 2011), Cyrille2 (Fiers et al., 2008) and
Mobyle (Nron et al., 2009) are three web—based workﬁow engines
that users have to install locally if computational needs on datasets
are very large, or if absolute security is required. Alternatively,
softwares such as the KNIME (Berthold et al., 2007) workbench
or Taverna (Hull et al., 2006) run on the users’ desktop and can
interact with local resources. Taverna focuses on web services and
may require a large number of nodes even for a simple task. In
contrast, KNIME provides the ability to modify the nodes without
having to re—run the whole analysis. We have chosen this latest tool
to develop Knime4Bio, a set of new nodes mostly dedicated to the
ﬁltering and manipulation of VCF ﬁles. Although many standard
nodes provided by KNIME can be used to perform such analysis,
our nodes add new functionalities, some of which are described
below.

2 IMPLEMENTATION

The java API for KNIME was used to write the new nodes,
which were deployed and documented using some dedicated XML
descriptors. A typical workﬂow for analysing exome sequencing data
starts by loading VCF ﬁles into the working environment. The data
contained in the INFO or the SAMPLE columns are extracted and
the next task consists in annotating SNVs and/or indels. One node
predicts the consequence of variations at the transcript/protein level.
For each variant, genomic sequences of overlapping transcripts
are retrieved from the UCSC knownGene database (Hsu et al.,
2006) to identify variants leading to premature stop codons, non—
synonymous variants and variants likely to affect splicing. Some
nodes have been designed to ﬁnd the intersection between the
variants in the VCF ﬁle and a various source of annotated genomic
regions, which can be: a local BED ﬁle, a remote URL, a mysql
table, a ﬁle indexed with tabix (Li, 2011), a BigBed or a BigWig
ﬁle (Kent at al., 2010). Other nodes are able to incorporate data from
other databases: dbSNFRP (Liu et al., 2011), dbSNP, Entrez Gene,
PubMed, the EMBL STRING database, Uniprot, Reactome and
GeneOntology (von Mering et al., 2007), MediaWiki, or to export
the data to SIFT (Ng and Henikoff, 2001), Polyphen2 (Adzhubei
et al., 2010), BED or MediaWiki formats. After being annotated,
some SNVs (e. g. intronic) can be excluded from the dataset and the
remaining data are rearranged by grouping the variants per sample
or per gene as a pivot table. Some visualization tools have also
been implemented: the Picard API (Li et al., 2009) or the IGV

 

© The Author(s) 2011. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non—Commercial License (http://creativecommons.org/licenses/
by—nc/3.0), which permits unrestricted non—commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.

112 /§.IO'SIBUJHOprOJXO'SOTlBIIIJOJUTOTQ/ﬁdnq mm; popeoIIJ/noq

9IOZ ‘091sn8nv uo ::

knime4bio

 

"Ill'l'Il-I'IE Kw

Epll'ttir
{PI} E I:- Culumn Fll‘llr
Ilaw FlrI-lr I
Int-ulctlun l' I: at: Fri
, ucsc EQL re. 3.}. pm I: sarn pleisnp EEK E“
Hum-m: Btu-w 'l htﬁullD-nflrjdul: [. I w
spllﬂJIr “If— rEmﬂVE Ex ' rm some cells III
“Rt: 1., Ira—i l_l .ll [ .1
[:1 r5## :i .' vine”;
: spilt lndelslisnp 'II
samplersnp I I" :1: "I": '.

I
Numeric: new Eﬂum" "If"

i .
Spll‘ﬂ‘Ir ___Dr #5 hi
_ _— .

+ '.
I m II it [—1
DEF I: IT'I'I SI'JFFIE EDIE
flll'a: depth

Fig. 1. Screenshot of a Knime4Bio workﬂow for the NOTCH2 analysis.

browser (Robinson et al., 2011) can be used visualize the short reads
overlapping a variation.

As a proof of concept, we tested our nodes to analyse the exomes
of six patients from a previously published study (Isidor et al., 2011)
related to the Hajdu Cheney syndrome (Fig. 1). For this purpose,
short reads were mapped to the human genome reference sequence
using BWA (Li and Durbin, 2010) and variants were called using
SAMtools mpileup (Li et al., 2009). Homozygous variants, known
SNPs (from dbSNP) and poor—quality variants were discarded,
and only non—synonymous and variants introducing premature stop
codons were considered. On a RedHat server (64 bits, 4 processors,
2 GB of RAM), our KNIME pipeline generated a list of six genes in
45 min: CELSRI, COL4A2, MAGEFI, MY 0] 5A, ZNF34] and more
importantly N OTCHZ, the expected candidate gene.1

3 DISCUSSION

In practical terms, a computer biologist was close to our users to help
them with the construction of a workﬂow. After this short tutorial,
they were able to quickly play with the interface, add some nodes
and modify the parameters without any further assistance, but the
suggestion or the conﬁguration of some speciﬁc nodes (for example,
those who require a snippet of java code). At the time of writing,
Knime4Bio contains 55 new nodes. We believe Knime4Bio is an
efﬁcient interactive tool for NGS analysis.

ACKNOWLEDGEMENTS

We want to thank the Biostar community for its help, Jim Robinson
and his team for the BigWig java API, and Dr Cedric Le Caignec
for the NOTCH2 data.

 

1The workﬂow was posted on
www.myexperiment.org/workﬂows/2320.

myexpen'mentorg at:

Funding: Inserm, the ‘Centre Hospitalier Universitaire’ of Nantes;
the ‘Federation Francaise de Cardiologie’ (FFC); ‘Fondation pour
la Recherche Médicale’ (FRM). Solena Le Scouarnec is supported
by the Wellcome Trust (Grant n WT077008).

Conﬂict of Interest: none declared.

REFERENCES

Adzhubei,I.A. et al. (2010) A method and server for predicting damaging missense
mutations. Nat. Methods, 7, 248—249.

Berthold,M.R. et al. (2007) Knime: the konstanz information miner. In Preisach,C. et al.
(eds) Gle, Studies in Classification, Data Analysis, and Knowledge Organization,
Springer, pp. 319—326.

BlankenbergD. et al. (2011) Integrating diverse databases into an uniﬁed analysis
framework: a Galaxy approach. Database, 2011, bar011.

Danecek,P. et al. (2011) The variant call format and VCFtools. Bioinformatics, 27,
2156—2158.

Fiers,M.W.E.J. et al. (2008) High-throughput bioinformatics with the Cyrille2 pipeline
system. BMC Bioinformatics, 9, 96.

Hsu,F. et al. (2006) The UCSC Known Genes. Bioinformatics, 22, 1036—1046.

Hull,D. et al. (2006) Taverna: a tool for building and running workﬂows of services.
Nucleic Acids Res., 34, W729—W732.

Isidor,B. et al. (2011) Truncating mutations in the last exon of NOTCH2 cause a rare
skeletal disorder with osteoporosis. Nat. Genet, 43, 306—308.

J agla,B. et al. (2011) Extending KNIME for next generation sequencing data analysis.
Bioinformatics, 27, 2907—2909.

Kent,W.J. et al. (2010) BigWig and BigBed: enabling browsing of large distributed
datasets. Bioinformatics, 26, 2204—2207.

Liu,X. et al. (2011) deSFP: a lightweight database of human nonsynonymous SNPs
and their functional predictions. Hum. Mutat, 32, 894—899.

Li,H. and Durbin,R. (2010) Fast and accurate long-read alignment with Burrows-
Wheeler transform. Bioinformatics, 26, 589—595.

Li,H. et al. (2009) The Sequence Alignment/Map format and SAMtools. Bioinformatics,
25, 2078—2079.

Li,H. (2011) Tabix: fast retrieval of sequence features from generic TAB-delimited ﬁles.
Bioinformatics, 27, 718—719.

Nron,B. et al. (2009)M0by1e: a new full web bioinformatics framework. Bioinformatics,
25, 3005—3011.

N g,P.C. and Henikoff,S. (2001) Predicting deleterious amino acid substitutions. Genome
Res., 11, 863—874.

R0binson,J.T. et al. (2011) Integrative genomics viewer. Nat. Biotechnol, 29, 24—26.

von Mering,C. et al. (2007) STRING 7—recent developments in the integration and
prediction of protein interactions. Nucleic Acids Res., 35, D358—D362.

 

3201

112 /§JO'S[BUJHOIPJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 11101; prBOIUAAOG

9IOZ ‘09 lsnﬁnv uo ::

