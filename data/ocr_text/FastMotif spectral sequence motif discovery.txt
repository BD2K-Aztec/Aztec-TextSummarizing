Bioinformatics, 31 (1 6), 2015, 2623—2631

doi: 10.1093/bioinformatics/btv208

Advance Access Publication Date: 16 April 2015
Original Paper

 

 

Sequence analysis

FastMotif: spectral sequence motif discovery

Nicolé Colombo1 and Nikos Vlassisz'*

1Luxembourg Centre for Systems Biomedicine, University of Luxembourg, Luxembourg and 2Adobe Research, San

Jose, CA, USA

*To whom correspondence should be addressed.
Associate Editor: John Hancock

Received on September 18, 2014; revised on March 20, 2015; accepted on April 9, 2015

Abstract

Motivation: Sequence discovery tools play a central role in several fields of computational biology.
In the framework of Transcription Factor binding studies, most of the existing motif finding algo-
rithms are computationally demanding, and they may not be able to support the increasingly large
datasets produced by modern high-throughput sequencing technologies.

Results: We present FastMotif, a new motif discovery algorithm that is built on a recent machine
learning technique referred to as Method of Moments. Based on spectral decompositions, our
method is robust to model misspecifications and is not prone to locally optimal solutions. We ob-
tain an algorithm that is extremely fast and designed for the analysis of big sequencing data. On
HT-Selex data, FastMotif extracts motif profiles that match those computed by various state-of—the-
art algorithms, but one order of magnitude faster. We provide a theoretical and numerical analysis
of the algorithm’s robustness and discuss its sensitivity with respect to the free parameters.
Availability and implementation: The Matlab code of FastMotif is available from http://lcsb-portal.

uni.lu/bioinformatics.
Contact: vlassis@adobe.com

Supplementary information: Supplementary data are available at Bioinformatics online.

 

1 Introduction

In the last decades, due to the advent of new sequencing technolo-
gies, motif discovery algorithms have become an essential tool in
many computational biology fields. In cell biology, sequence motif
discovery plays a primary role in the understanding of gene expres-
sion through the analysis of sequencing data and the identification
of DNA-transcription factor binding sites (Annala et al., 2011;
Berger et al., 2006; Cheng et al., 2013; Wei et al., 2010; Zhang
et al., 2013; Zhao et al., 2012).

Various experimental techniques are nowadays available to ex-
tract DNA-protein binding sites in vivo [ChIP-Seq (Johnson et al.,
2007)] and in vitro [protein binding microarray (PBM) (Berger and
Bulyk, 2009), HT-Selex (Jolma et al., 2010, 2013; Kinzler and
Vogelstein, 1990; Tuerk and Gold, 1990)]. Thanks to the quantity
and quality of the generated data, HT-Selex is considered one of the
most promising high-throughput techniques for studying transcrip-
tion factor binding affinity in vitro [see the recent work (Orenstein
and Shamir, 2014) for a quantitative comparison between HT-Selex

and other high-throughput techniques as ChIP-Seq and PBM]. In the
HT-Selex protocol, tens of thousands enriched DNA fragments are
obtained through a series of incubation/selection cycles. In each
cycle, an initial pool containing randomized ligands of length 14—40
bp is incubated with an immobilized DNA-binding protein. Bound
ligands are amplified by polymerase chain reaction steps (PCR),
sequenced and then used as initial pool for a next cycle, until the
pool is saturated (Jolma et al., 2010, 2013; Kinzler and Vogelstein,
1990; Tuerk and Gold, 1990; Zhao et al., 2009).

Due to the high but not exact specificity of transcription factor
binding affinities, enriched DNA fragments in a dataset typically
contain similar but not exactly conserved instances of the same bind-
ing motif. This calls for algorithms that can extract simple and intui-
tive binding motifs that are robust to such stochasticity (Berger and
Bulyk, 2009; Jolma et al., 2010; Zhao et al., 2009). In the simplest
case, the binding preferences are modelled by means of consensus se-
quences, obtained by selecting a few deterministic character strings
that are over-represented in the dataset. A more flexible

©The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com 2623

112 [3.10811211an[plOJXO'SODBIILIOJIIIOIQ/ﬂ(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV no :2

2624

N. Colombo and N. Vlassis

 

representation is provided by Position Weight Matrices (PWM) that
describe binding sites as probability distributions over the DNA al-
phabet. Based on the simplifying assumption that the total binding
energy is a site-by-site sum of single protein-nucleobase interactions,
PWM’s are only approximate models of the true transcription factor
preferences. A debate is still open on whether such an approxima-
tion gives a satisfactory picture of the DNA-protein interaction or it
is a too simplified reduction of the real biological process (Badis et
al., 2009). More sophisticated models, that go beyond the PWM
representation by taking into account multi-base probability distri-
butions or long-distance interactions, have been proposed and tested
in the literature (Badis et al., 2009; Bulyk, 2002; Chen et al., 2007;
Mathelier and Wasserman, 2013; Santolini et al., 2013). However,
in most cases, these improvements did not bring about cogent evi-
dence against the simpler and more intuitive approach based on pos-
ition independent distributions (Zhao and Stormo, 201 1).

In statistics and machine learning, factorized (aka product) dis-
tributions like PWMs and their linear combinations (aka mixtures)
are commonly used in modelling empirical distributions from vari-
ous kinds of data, and an important problem is how to estimate
such models from data (Lindsay, 1995; Titterington, 1985). In pion-
eering work, Chang (1996) showed that it is possible to infer a mix-
ture of product distributions via the spectral decomposition of
‘observable’ matrices, i.e. matrices that can be estimated directly
from the data using suitable combinations of the empirical joint
probability distributions (Chang, 1996). Extensions and improve-
ments of this idea have been developed more recently in a series of
remarkable works, where the spectral approach is applied to a larger
class of probability distributions, and robust versions of the original
method have been analysed theoretically (Anandkumar et al.,
2012a, c; Hsu et al., 2012; Mossel and Roch, 2006).

In this article, we further develop the original spectral technique
of Chang (1996) and study its application to the problem of learning
probabilistic motif profiles from noisy sequencing data. The key ob-
servation is that, under the PWM approximation, motif discovery
reduces to the more general problem of learning a mixture of prod-
uct distributions, and hence, it is possible to extract motif profiles
from sequencing data using usual spectral decompositions.

We present FastMotif, a new motif finding algorithm that is
faster than other sequence discovery tools and is designed for pro-
cessing noisy high-throughput datasets. Based on a new and more
stable version of the spectral techniques introduced in (Anandkumar
et al., 2012a; Corless et al., 1997; Mossel and Roch, 2006), our al-
gorithm is robust to model misspecification, is not prone to local op-
tima, and it can be adapted to searching for motifs of arbitrary
length. In addition, the method is completely general and, upon
minor modifications, can be used for sequence discovery over any
sequence alphabet and for analyzing datasets with binding affinity
scores (Berger and Bulyk, 2009; Johnson et al., 2007). Throughout
this work, we assume that transcription factor specificities are well
described by product distributions, i.e. PWM’s, and leave for future
work the spectral inference of more advanced motif representations.

Finally, a comment on the claimed optimality of FastMotif. It
has been shown [see for example Anandkumar et al. (2012c)] that in
the limit of infinitely many data and under no model misspecifica-
tion, a spectral method is statistically consistent, that is, it always
recovers the true underlying model. FastMotif, being a spectral
method, inherits this optimality property by the way of the unique-
ness of matrix eigen decomposition. This is in marked contrast to
algorithms like Expectation Maximization (EM) that can easily get
trapped in poor local optima even under favourable sample condi-
tions. In practice, we expect the output of FastMotif to approach

optimality when the true binding model approaches a PWM and the
size of the training dataset is big enough, as for example in the case
of HT-SELEX data.

The article is organized as follows: In Section 2, we give a brief
overview of related work; in Section 3, we describe FastMotif and
its application to sequencing data; and in Section 4, we show our re-
sults. More mathematical details about spectral approaches in gen-
eral and FastMotif in particular can be found in the Supplementary
Material. The Matlab code of FastMotif is available from http://
lcsb-portal.uni.lu/bioinformatics.

2 Related work
2.1 Motif finding

The literature on sequence motif discovery is vast. We refer to (Das
and Dai, 2007; Sandve et al., 2007; Simcha et al., 2012; Tompa
et al., 2005) for reviews and additional references. There are two
main classes of motif finding algorithms, probabilistic and word-
based. Probabilistic algorithms search for the most represented un-
gapped alignments in the sample to obtain deterministic consensus
sequences, PWM models, or more advanced models that take into
account multi-base correlations (Bulyk, 2002; Badis et al., 2009;
Chen et al., 2007; Mathelier and Wasserman, 2013; Santolini et al.,
2013). Word-based algorithms search the dataset for deterministic
short words, measure the statistical significance of small variations
from a given seed, or transform motif discovery into a kernel feature
classification problem (Lee et al., 2011; Leslie et al., 2002; Vert
et al., 2005). Our method and well known motif discovery algo-
rithms as MEME (Bailey and Elkan, 1994) and STEME (Reid and
Wernisch, 2011), belong to the probabilistic class, while the two
algorithms we have used for evaluating our results, namely the
method used in (Jolma et al., 2013) and DREME (Bailey, 2011) are
word-based algorithms. The latter algorithms can also compute
PWM models, so it is of interest to compare algorithms of different
classes (Section 4).

2.2 Spectral methods

Spectral methods have been applied as an alternative to the EM al-
gorithm (Dempster et al., 1977) for inferring various kinds of prob-
ability distributions, such as mixtures of product distributions,
Gaussian mixtures, Hidden Markov models, and others
(Anandkumar et al., 2012a, b, c; Boots et al., 2011; Chang, 1996;
Hsu et al., 2012; Mossel and Roch, 2006) [see (Balle et al., 2014)
for a recent review]. These methods are not as ﬂexible as the EM al-
gorithm, but they are not prone to local optima and have polyno-
mial computational time and sample complexity. Various spectral
decomposition techniques have been proposed: Chang’s spectral
technique (Chang, 1996; Mossel and Roch, 2006), a symmetric
tensor decomposition method (Anandkumar et al., 2012a), and an
indirect learning method for inferring the parameter of Hidden
Markov Models (Hsu et al., 2012). The practical implementation of
the spectral idea is a non-trivial task because the stability of spectral
decomposition strongly depends on the spacing between the eigen-
values of the empirical matrices. In (Anandkumar et al., 2012a;
Mossel and Roch, 2006) certain eigenvalue separation guarantees
for Chang’s spectral technique are obtained via the contraction of
the higher (order three) moments to Gaussian random vectors. In
the tensor approach presented in (Anandkumar et al., 2012a), the
non-negativity of the eigenvectors is ensured by using a deflating
power method that generalizes usual deﬂation techniques for matrix
diagonalization to the case of symmetric tensors of order three. A
third possibility involves replacing the random vector of Chang’s

112 [3.10811211an[plOJXO'SODBIILIOJIIIOIQ/ﬂ(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV no :2

Spectral sequence motif discovery

2625

 

spectral technique with an ‘anchor observation’ that, for each hid-
den state, ‘tends to appear in the state much more often than in the
other states’ (Song and Chen, 2014) and guarantees the presence of
at least one well separated eigenvalue (Arora et al., 2012; Song and
Chen, 2014). Finally, as briefly mentioned in (Anandkumar et al.,
2012a; Hsu and Kakade, 2013), the stability of Chang’s technique
can be significantly improved through the simultaneous diagonaliza-
tion of several random matrices. Here, we present a new approach
based on the simultaneous Schur triangularization of a set of nearly
commuting matrices (Corless et al., 1997).

2.3 Spectral methods and sequence analysis

To the best of our knowledge, spectral methods have not been applied
so far to the problem of DNA sequence motif discovery that we ad-
dress here. Nevertheless, spectral techniques have been applied to
other types of sequence analysis problems, such as poly(A) motif pre-
diction (Xie et al., 2013), chromatin annotation (Song and Chen,
2014), and sequence prediction (Quattoni et al., 2014). The tech-
niques used in these works are all based, with minor modifications, on
the spectral algorithm of Hsu et al. (2012) for learning Hidden
Markov Models, in which a dataset of time-series of observed values
{x1,x2, .. . } is used to recover a single observation matrix (Ox)
whose columns are the conditional probabilities associated with the
hidden states. Our approach marks a significant departure from these
methods by allowing the recovery of distinct observation matrices
(Ox, 0),, ...) and hence the extraction of motif PWM’s. Finally, we
note that a general technique for learning mixture of product distribu-
tions in the presence of a background has been recently presented
(Zou et al., 2013); it would be interesting to study how this technique
could be applied to the problem of sequence motif discovery.

3 Materials and methods

Binding site models represent the binding preferences of DNA-
binding proteins via probability distributions over the set of all pos-
sible ‘words’ of some given length. If the DNA-protein interaction is
assumed to be the sum of single protein-nucleobase interactions,
these probability distributions can be represented by PWM’s
(Stormo et al., 1986; Stormo, 2000). Given the length of the binding
site Z, a position weight matrix is a 4 X Z matrix whose columns are
interpreted as the probability distribution associated to the various
position within the binding site. Then, according to the factorizabil-
ity assumption, the total binding score of a particular sequence is
obtained by summing (in the log domain), over all positions, the
matrix entries corresponding to the sequence letters.

De novo motif discovery algorithms compute one or more binding
motifs from a set of enriched sequences, i.e. a set of sequences that
contain, with high probability, several instances of the protein binding
site. FastMotif computes the binding motifs in three steps: First the en-
riched sequences dataset is modelled using a special class of probabil-
ity distributions (mixture of product distributions). Then the model
parameters are estimated using a powerful machine learning technique
(spectral method). Finally, the binding profile is identified as one of
the components in the obtained model. Next we provide a high-level
description of the above three steps, in a simple (ideal) case where
a single binding site (no secondary motif) of length three is over-
represented in the dataset, and the protein binding preferences are
exactly described by a 4 X 3 position weight matrix PWM.

In the first step we assume that the dataset is drawn from a suit-
able probability distribution. Given three consecutive letters in the
sample, one should consider two cases: (i) the three letters belong to

one instance of the binding site or (ii) the three letters belong to the
background. When the three letters belong to a binding site their
probability is given by the binding model
Pmoﬁfay, K) = PWM(I, 1) Pix/Mg, 2) PWM(K, 3), where I, ], K
take values from the set {A, C, G, T}. When the three letters do not
belong to a binding site, their probability is given by the (constant)
background distribution Pbackgmund(1,],K) = B(I) BU) B(K), where
B(I) is the frequency of the letter I E {A,C,G,T} in the dataset.
Then the probability of observing three consecutive letters (I, ], K)
at a random position in the sample is given by
Psample(17]7K) = WPmotifU’LK) + (1 _ W)Pbackground(17]7K)’ Where
W is the overall probability of finding a binding site in the sample.
In other words, each overlapping subsequence of length three in the
dataset can be assumed to be drawn either from Pmotif or Pbackground,
with probability given by the coefficient W and 1 — W, respectively.
In particular, letting S3 be the set of all overlapping sub-sequences of
length 3, one can write S3 ~ Psample.

The second step consists of recovering the entries of both Pmotif
and Pbackgmund from the dataset. In a general, that would require solv-
ing a hard non-convex constrained optimization problem, with a large
number of parameters. Spectral methods provide a powerful technique
to obtain the entries of Pmotif and Pbackground directly. The parameters
are obtained from the eigenvalues of suitable ‘observable’ matrices,
computed by counting joint frequencies in S3. The observable matrices
are formed out of the empirical pairwise and triple probability distri-
butions, defined as the probabilities of observing two or three consecu-
tive letters in S3. For any three letters I, ], K, where each letter belongs
to {A, C, G, T}, the corresponding triple empirical probability,
denoted by 13(1, ], K), is obtained by the number of occurrences of the
sub-sequence [1, f, K] in S3, normalized by the total number of elements
in S3. Since I, ], K assume discrete values in an alphabet of four letters,
the triple empirical distribution P(I,], K) is a 4 x 4 x 4 multi-dimen—
sional array (tensor), obeying ZLLKP (I, f, K) = 1. Equivalently, the
triple empirical distribution can be represented as a set of four 4 X 4
matrices, namely P(I,],A),P(I,], C),P(I,], G),P(I,], T), whose col-
umns sum to one. The main idea behind FastMotif is that, assuming
the factorizability of the position weight matrix PWMmotif and the
background matrix Pbackground, triple and pairwise empirical distribu-
tions can be written in a very simple form, as we will explain next.
Moreover, by multiplying different empirical distributions together, it
is possible to form ‘observable’ matrices, whose eigenvalues are dir-
ectly related to the entries of PWMmotjf and Pbackground.

The last step consists of identifying PWMmotif with the binding
model and Pbackground with the background distribution. This is
done via an exact P-value test where the matrices are used to define
a classifier to distinguish between sequences containing the binding
site and randomly reshufﬂed sequences.

3.1 Detailed description of FastMotif

3.1.1 Estimating the motif length

In the earlier example, we assumed an a priori knowledge of the tar-
get motif length (Z = 3). In general, the expected length of the bind-
ing site is not known a priori, and it should be estimated via a
statistical test over the sample. FastMotif obtains an estimation of
the binding site length by measuring the Pearson test statistic of all
sub-sequences of length k appearing in it. For k = 3, . . . , 15 the ex-
pected length is defined as

M

Ek (1)

Z = arg max
k

where Ok is the frequency of the most represented subsequence of

—k

length k in the random subset and Bk 2 4 is an expected

112 /810'S{12umo[p101x0'831112u1101utotqﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

2626

N. Colombo and N. Vlassis

 

theoretical frequency, based on the null hypothesis
P(A) = P(C) = P(G) = P(T) = %. For speed reasons the statistical
test is performed on a small random subset of the whole dataset
(N5 000 sequences).

Given an expected motif length Z of the target binding site, we
define S1; to be the collection of all overlapping sub-sequences of
length Z in the dataset. Equivalently, S1; can be thought as the set of
all records of a sliding window of length Z running over the sample.

3.1.2 Modelling secondary motifs

To relax the assumption of a single binding site, the two-component
mixture in the earlier example is replaced in FastMotif by a p-com-
ponent mixture with factors PWM,, with r = 1,2,  ,p. In this
case, the set S); is modelled by a convex combination of PWM mod-
els, that is S); N 2:1 w, PWM, with 20,20 and 2:1 w, = 1.
Intuitively, the p PWMs are associated to the primary motif, the
background, and the remaining p — 2 secondary motifs, respectively.
We note that, even if the dataset is expected to contain a single bind-
ing motif, working with a p-component mixture increases the ro-
bustness of the model, as it allows taking into account possible
constant patterns that often appear in the background.

3.1.3 The spectral method

We now describe how we can extract the entries of each matrix
PWM, from a set of ‘observable’ matrices using the spectral method.
For illustration purposes, let us assume again that Z = 3, and let S3
denote the set of all 3-mers in the dataset. Let P be the empirical
joint distribution whose entry P(I, ], K) is the frequency of the sub-
sequence [I , ] , K] in S3. Pairwise joint probability matrices are
defined analogously and can be obtained from P by marginalization,
for example P12 2  -,K). More generally, the 3D array 13
can be transformed into a matrix by considering a linear combin-
ation of its 2D slices. For example, slicing on the 3-direction, one
can select one of the four slices by setting P,- = ZKPC, -,K)[e,-]K,
where i E {A, C, G, T} and e,- is a 4D basis vector with 1 on the i—th
entry and 0 elsewhere.

Assuming a p-component mixture model 2:1 wrPWMr, we
define each component as PWM, = [X,,Y,,Z,] E [0,1]4X3, where
each column X, (idem Y ,, Z,) is a probability distribution over the
alphabet {A, C, G, T}. We also define a 4 X p conditional probabil-
ity matrix X 2 [X1, . . . ,Xp], whose r-th column is the first column
(X,) of the r-th matrix PWM,, and analogously for Y and Z. Then,
assuming that the data are drawn exactly from a mixture of p =4
product distributions, and under the factorizability assumption of
the PWM model, it is easy to verify the following identities:

P

P = ZerrYrZr, P12 = Xdiag(w)YT, (2)
r=1

13,- : Xdiag(w)diag(ezT Z) YT, ie {A, c, G, T}, (3)

where w = (w,) is the vector of mixing weights, and diag(v) denotes
a diagonal matrix with the entries of the vector v on the diagonal.

The key idea in spectral methods is that, provided that (2) and
(3) hold and the matrices X and Y are invertible, we can recover the
entries of the matrix Z from the eigenvalues of four ‘observable’
matrices defined as

M,- =  = Xdiag(e,TZ)X_1, i6 {14, C, G, T}- (4)

According to (4), the observable matrices M,- are simultaneously
diagonalizable for all i E {A,C,G,T}. From the definition of

Z = [Z1,  Zp], one has ezTZ = [[Z1]i,  [ZPL], where Z, is the
probability distribution at position 3 according to the r-th model.
Given the set of observable matrices MA,MC,MG,MT, we can
recover all entries of the matrix Z from the matrix of their eigen-
values A,, = 2,013,), where we denote by 2,(A) the r-th eigenvalue of
a matrix A. The entries of X and Y are obtained from analogous
observable matrices, where the role of the three variables (I, ], K) is
interchanged.

3. 1 .4 Model misspecification

So far we have assumed that the model is exact, i.e. the data are
drawn exactly from a mixture of p product distributions and an in-
finite size sample is available. When the model is misspecified, (4)
holds only approximately and the observable matrices M,- are not
exactly simultaneously diagonalizable. In this case, the entries of the
conditional probability matrices can be recovered via an approxi-
mate diagonalization of the matrices M), for i = A, C, G, T. Letting
M,- = M,- + E, where M,- = Xdiag(ez-TZ)X_1 and E is the misspecifi-
cation term, it is then possible to obtain upper bounds for the eigen-
value estimation error in terms of  =  The standard
procedure consists of choosing an arbitrary linear combination of
the observable matrices MW) 2 ZiMiﬂi, compute its eigenvectors
and use them to approximately diagonalize all single M ,-, for i E {
A, C,G,T} (Anandkumar et al., 2012c; Hsu et al., 2012; Mossel
and Roch, 2006). The choice of the linear combination coefficients
0,- is crucial and the stability of the method depends strongly on the
eigenvalues separation of the matrix MW) (Hsu et al., 2012). Some
separation guarantee can be obtained from classic concentration
bounds on the Gaussian distribution, if the vector 0 is chosen to be a
random Gaussian vector of zero mean and unit variance (Mossel
and Roch, 2006).

In FastMotif, we depart from the standard spectral procedure in
two ways. First, in order to improve the stability of the spectral de-
composition, we compute an ad hoc vector 0 from a previous esti-
mate of the conditional matrix Z. This estimate is obtained from the
eigenvectors of a different observable matrix, obtained by exchang-
ing the role of the sub-sequence positions in the definition of P,- and
P12, and we can show that the resulting 0 has good separation guar-
antees (depending on the previous estimate’s error). Second, instead
of using the eigenvectors of the matrix M to diagonalize the matrices
M), we estimate the eigenvalues of M,- using the orthogonal matrices
appearing in the Schur decomposition of M instead of its eigenvec-
tors. Intuitively, we exploit the fact that the Schur form of a matrix
A is not unique on its upper-diagonal terms but it always contains
the eigenvalues of A on the diagonal (Corless et al., 1997). In the
Results section, we provide a numerical comparison between the
standard spectral approach and the simultaneous diagonalization
approach of FastMotif based on the Schur decomposition, demon-
strating the advantages of the proposed method (Fig. 4).

3.1.5 General setup

For simplicity, we have presented so far the simple special case of
motifs of length three and have restricted the number of mixture
components to pzd. Binding site models of general length Z > 3
can be obtained by iterating the procedure described earlier with I,
], K assigned to different positions within the motif. Regarding the
number of components in the mixtures, one should distinguish be-
tween two situations. The case p < d can be handled by reducing the
size of the empirical matrices by means of a set of p X d orthogonal
matrices obtained from the truncated singular value decomposition
of P(x, y), P(y,z) and P(x,z) (Anandkumar et al., 2012c). The case

112 /810'S{12umo[p101x0'831112u1101utotqﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

Spectral sequence motif discovery

2627

 

CTCF ELF3

HMBOX1 HNF4

MAFK RFX3 ZIC1 ZSCAN4

 

£1.11 £1.11 £1.11 £1.11
D  ‘n 0.0M 0.0M 0.0M 0.0M

5

Multinomial -9 [QGGCTEGAQ E    gall] gixﬁchl

FastMotif

 

2.11 2.11 2.11 2.11
     !   £1.0M
11.11 g 11.11 11.11
..3. . 5......_.. 5

11.11 g
2.11
.4! 1.11
.n
G I
11.11 '

   

S

 1119111311  1.9 (.610 

fl 

5

1

5  19,. . 5 ...TP.  .

1sz..th 2211111110, ,1 121423.601: 59 til...th 96c  111311000 00 1311112111

Fig. 1. PWM computed by different algorithms on the datasets of Jolma et al. (2013). 'Multinomial’ is the algorithm described in Jolma et al. (2013) and DREME
(Bailey, 2011) is the motif discovery algorithm of the MEME suite designed for processing big datasets. All logos were obtained using weblogo 3 .3 (Schneider
and Stephens, 1990). Except for some discrepancies on the motif lengths, we observe very good agreement between the output of the three algorithms

12 > d requires the definition of a new working space of dimensional-
ity D > 12, that can be obtained by considering grouped consecutive
bases of length n > 1. For example, choosing n = 2, the set S); of all
sub-sequences of length Z over the DNA alphabet {A, C,G,T} is
transformed into the equivalent set of sub-sequences of length § over
the grouped alphabet {AA,AC, . . . ,TT} and one has D = 4” = 16.
Because higher dimensional variables are able to capture inter-
dependences between neighbouring positions of the binding sites,
FastMotif maximizes the length of grouped variables.

Note that binding sites of general length Z > 3 can be represented
in terms of length-3 ‘high-dimensional’ binding sites. Given Z > 3 it
is always possible to define grouped variables of different lengths,
say 111,112,113, such that 111 + 112 + 113 = Z and recover the binding
model via the method described in the previous sections. However,
in the case of grouped variables, the output of the spectral algorithm
is a set of p frequency matrices HPWM, = [X,, Y,,Z,] E [0,1]D><3
whose columns are probability distributions over the alphabet of
grouped variables. The corresponding 4D models are then obtained
from the set S1; as follows. According to the model assumption, the
set S1; of all sequences of length Z is the direct sum of exactly 12 sub-
sets each of them containing the sub-sequences of length Z generated
by the r-th model. Letting, S; be the subset of sub-sequences gener-
ated by the model 1', the corresponding 4D position weight matrix
PWM, is defined by the frequencies of each letter A, C, G, T at each
position i = 1, . . . ,K in S2. To select whether a sub-sequence has to
be included in a subset S2, we define a scoring function
f,(s) = log (HPWM,(s)/HB(s)), where HE is a background model
computed over S). The subsets S; are defined by

S2 = {S E S! 3  > fr(s)l < 6match} 

where b is a random sequence of length Z and ematch is a user defined
P-value matching threshold. In practice, since the computation of Pr
 > f,(s)] can be expensive, we approximate the exact P-value
computation by introducing a threshold 6, such that Pr[f,(b) > 5,]
< ematch is true over a finite set of Nmatch ~

 

1 random
6In t h

sequences. Finally, we admit a sequence 5 6 S1; to the set S; if
79(5) > ©-

The last step consists of isolating the model corresponding to the
protein binding site from the other p — 1 models in the mixture. For
that we use the ame tool of the MEME suite (McLeay and Bailey,
2010), which allows computing the exact P-value of each model
over a test dataset consisting of positive sequences from the dataset
and negatives obtained by random reshufﬂing of the positives.

4 Results

The present version of FastMotif has been optimized to process data-
sets from HT-Selex experiments on transcription factor binding.

Due to the enormous number of sequences, HT-Selex data are hard to
analyse using other available motif discovery algorithms. Designed
to fill this gap, FastMotif is able to process HT-Selex datasets in few
seconds and extract high quality probabilistic binding models that
match those produced by other state-of-the-art algorithms.

In this section, we present and discuss the performance of the al-
gorithm on various HT-Selex datasets and compare the motifs pro-
duced by FastMotif with the ones produced by other algorithms. To
test the robustness of FastMotif to model misspecification, we
have also tested FastMotif on semi-synthetic data with
increasing amounts of noise. Finally, we report some important the-
oretical features of the algorithm and discuss its sensitivity with re-
spect to some user-defined parameters that can be tuned to optimize
the search.

4.1 HT-Selex data

What distinguishes FastMotif from other sequence discovery algo-
rithms is the inference technique based on spectral methods. HT-
Selex is a domain where high quality and biologically meaningful
outputs can be obtained directly form spectral learning.

To test FastMotif on real data, we have focused on the
HT-Selex experiments described by Jolma et al. (2013). All data
are available at the European Nucleotide Archive (ENA) database
under accession number ERP001824. For a given transcription fac-
tor, we have downloaded the dataset corresponding to the Selex
cycle used to compute the binding models published in the
Supplementary Material of (Jolma et al., 2013). We have selected
the following datasets: HMBOX1 (cycle 4, 29 156 sequences),
HNF4A (cycle 4, 80491 sequences), RXF3 (cycle 3, 195 356 se-
quences), ZIC1 (cycle 3, 267963 sequences) ZSCAN4 (cycle 3,
68 378 sequences), CTCF (cycle 4, 134 566 sequences), ELF3 (cycle
3, 78 124 sequences), and MAFK (cycle 3, 144 041 sequences). All
sequences have length ~20 bp.

The models computed by FastMotif have been compared with
the ones computed on the same datasets by two other algorithms:
the algorithm described in Jolma et al. (2013) (which we will refer
to as ‘Multinomial’), and the large-dataset motif discovery tool
DREME of the MEME suite (Bailey, 201 1).

Other available motif discovery tools, as for example the popular
Expectation-Maximization algorithm MEME (Bailey and Elkan,
1994) or STEME (Reid and Wernisch, 201 1), were unable to process
files of the size of the original datasets and could not be included in
the comparison. Moreover, since the code of ‘Multinomial’ is not
available, we have only considered the PWM published in Jolma
et al. (2013). Both FastMotif and DREME ran on the same machine
with default settings: for FastMotif we set the number of mixture
components 1): 15 and the matching P-value threshold to 0.001,
and DREME was launched with the option ‘—m1’ that stops the

112 /810'S{12umo[p101x0'831112u1101u101qﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

2628

N. Colombo and N. Vlassis

 

[HMBOX1 HNF4A RFX3 ZIC1 ZSCAN4 CTCF MAFK ELF3

 

DREME 2337 14217 84858
Multinomial 1243 1405
FastMotif 135 1 19243 92281

9315 9550 58695 23971 12057

18904 29410 1665 10153 10118 6125

8866 10435 57656 18384 17914

Fig.2. Number of sequences used to compute the binding models shown in Figure 1. In same cases, the columns of the PWM computed by 'Multinomial’ (Jolma
et al., 2013) do not sum to the same value. In those cases, we report the number of sites of the most deterministic columns

 

P-valuo comparison {test sample 511a =1nﬂﬂ sequences]
I T T T I I I T

UP a o o o n
a o
.513- ..
i 3.
3 ill
11:11:1— - 'i _
gieo- a -

I I

 

.300 _ D Mu Itino-I'niel a, _
o DREME
.o Feetlulotif
I

 

 

l 1 l I 1
CTCF ELF3 HMBOX1 HNF4 MAFK FIFXS ZIC1 ZSCAN4
Dalaeel

 

Huntimoo comparison [ELIE dotaoot}
I I I I I T I

133 I r

l' T

    

150—

1411’

M
Q
I

runlime (sew ride] _.
P .3

no
G-
I

.3

20-

1 l I

l 1 I I l I I
{II [1.2 11.4 ISLE ELB ‘I 1.2 1.4 1.6 1.3 2
number of sequences {20 hp) 1. 1:15

 

 

 

Fig. 3. Model quality (left): exact P—value of the models in Figure 1 computed via ground-truth tests. For each transcription factor, we show the logarithm of the
average P—value obtained using the tool ame (McLeay and Bailey, 2010) over 20 distinct test datasets. The motifs computed by FastMotif obtained the best score
for all the datasets except one. Running times (right): execution times of DREME and FastMotif plotted against the size of the dataset. All algorithms ran on the
same machine and on the same datasets. For each dataset-size we have repeated the experiment 20 times and each point corresponds to the average runtime,

with variances represented by the errorbars. For all the datasets considered, FastMotif has been about 10 times faster than DREME

search when one motif has been found. In Figures 1 and 2, we show
respectively the models obtained by the different algorithms on the
various datasets, and the corresponding number of sites used to com-
pute the frequency matrices. All logos in Figure 1 were computed
using the application weblogo 3 .3 (Schneider and Stephens, 1990).
In some case the columns of the models computed by ‘Multinomial’
do not sum to the same values and we have reported the sum of the
entries in the most deterministic column. In general, the numbers
shown in Figure 2, compared with the total amount of sequences in
the datasets, show that only a relatively small subset of sequences
contains the expected binding site. The experimental interpretation
of this fact goes beyond the scope of this paper, but we only note
that, except for one case, the number of ‘sites’ used to compute the
final model by ‘Multinomial’ is significantly smaller than for
DREME and FastMotif. This can partially explain the difference in
length between the models computed by FastMotif and
‘Multinomial’. Because we do not know how the motif length is
fixed by ‘Multinomial’, we do not discuss further the possible biolo-
gical meaning of such discrepancies. Conversely, on approximately
the same amount of sites, FastMotif is able to compute models that
are two or more positions longer than the models computed by
DREME. The number of binding sites used to compute the model by
FastMotif depends on the choice of a user defined P-value matching
threshold 6mm}, (Section 3), which is here set to its default value
0.001. Assuming the set S); of all sub-sequences of a given length Z to
be drawn from a mixture of product distributions, the role of such
matching threshold is to assign each sub-sequence in the dataset to
the correct component in the mixture. We show in Figure 4 (centre)
that, for HT-Selex data, small variations of ematch do not signifi-
cantly affect the quality of the output, but we expect that a fine tun-
ing may be needed for more noisy data.

A quantitative comparison between the logos shown in Figure 1
has been obtained by computing the exact P-value of each model on
a series of ground-truth test samples. For each transcription factor
we have created 20 test samples containing 1000 positive sequences
from the original dataset and 1000 negatives. The negative
sequences were obtained by reshuffling of the positives. Given
such test samples and the models in Figure 1, the corresponding
P-values were computed using the tool ame (McLeay and
Bailey, 2010), launched as >ame —fix—partition 1000 —
bgfile <background fi1e><model>, where the option
—fix—partition 1000 fixes the size of the positive set and the
background file contains the single letter frequencies in the test data-
set. In Figure 3 (left), we show the logarithm of the average P-value
over the 20 tests and the corresponding variances 6(logy) 2%631 as
error bars. We observe that FastMotif obtains the best score for all
the models shown in Figure 1, except for the HMBOX1 model
where the low performance of FastMotif is probably due to the
small size of the dataset. A possible weakness of this evaluation is
the uncertainty about the ground-truth test sample, built on the
probably false assumption that all sequences in a dataset contain the
relevant binding site. However, since all algorithms were tested on
the same datasets, we expect the true number of false positives to af-
fect only mildly the validity of our comparison test.

We have already brieﬂy commented on the limited length of the
models computed by DREME, that restricts the search to sub-se-
quences of length Z = 8 for speed reasons. As it is shown in Figure 1,
the motifs computed by DREME coincide with the most deterministic
part of the models computed by FastMotif. The presence of several
ﬂanking positions is perhaps one reason for the better classification
performance of the motifs computed by FastMotif. Another reason of
the slightly better performance of the models computed by FastMotif

112 /810'S{12umo[p101x0'831112u1101u101qﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

Spectral sequence motif discovery

2629

 

is probably their fully stochastic profile, compared with the almost de-
terministic models computed by DREME.

Finally, in Figure 3 (right), we show the execution times of
FastMotif and DREME on datasets of increasing size. ‘Multinomial’
has been excluded from this comparison because we could not have
access to any estimation of its running time. FastMotif was about 10
times faster than DREME, in each of the datasets considered.

4.2 Sensitivity with respect to noise level

To test the robustness of FastMotif with respect to the level of noise in
the data and model misspecification, we created semi-synthetic data
and studied the performance of the algorithm in increasing levels of
noise. The semi-synthetic data were generated by implanting instances
of a stochastic motif on random genome sequences of increasing
length. The motif instances were generated by sampling from a pos-
ition weight matrix [the ELF3 binding site model computed by
FastMotif on the corresponding dataset of (Jolma et al., 2013)] via the
Matlab function discrete sample. In total, we created 50 datasets,
each containing 1000 sequences of length L = 10 + 5 >1< n, with
n = 1, .. . ,5 0. FastMotif ran on each dataset and the obtained mod-
els were compared with the reference ELF3 model by computing the
distance in norm between the two PWM. With default settings,
FastMotif outputs three models ranked according to their P-value and
we have chosen for the comparison the model of lowest P-value.
Moreover, when the matrices computed by FastMotif and the refer-
ence model had different lengths we restricted the comparison to the
eight most informative positions. In Figure 4 (top), we report the dif-
ference in norm between the reference and the estimated model as a
function of the amount of noise in the dataset, i.e. the length of back-
ground random genome sequences. Due to the presence of secondary
motifs in the random genome sequences, the lowest P-value motif that
we chose for the comparison did not always correspond to the ex-
pected target motif. We expect this issue to be the main cause of the
big jumps in the error function (dashed line) shown in Figure 4 (top).
When the length of the sequences becomes too large, trivial secondary
sub-sequences start being over-represented in the dataset and the algo-
rithm cannot distinguish between them and the instances of the refer-
ence motif. We also repeated the experiment by replacing the random
genome sequences with random sequences generated using the Matlab
function randseq, and the jumps disappeared (solid line). In sum-
mary, the above analysis seems to indicate that any use of our algo-
rithm to noisy in vivo data, as for example ChIP-Seq data, may
require some pre-processing steps that we do not address here.

4.3 Sensitivity with respect to user-defined parameters

FastMotif depends on two user-defined parameters: the number of
mixture components (12) and a P-value matching threshold (ematch).
The number of mixture components (12) defines the number of PWM
to be included in the probability distribution that is used to model S),
the set of sub-sequences of length Z. Extra components are ideally
associated to secondary motifs or over-represented redundant parts of
the background, and make the algorithm more stable in the case of
noisy data. The matching threshold (ematch) is used to assign each se-
quence in S1; to the correct mixture component and extract the corres-
ponding position weight matrix. Small matching thresholds make this
selection restrictive and the final position weight matrix more deter-
ministic, while bigger matching thresholds increase the number of
sites used to compute the model, and hence the noise. A careful trade-
off between the information content of the final logo and the number
of enriched sites to be used (Fig. 2) is often required. In this article, we
have always set the user-defined parameters to their default values

"III-5m: ELFB him IIIIIIII1 rInIIoln ammo-oofdﬂ'l'lﬂrl innit

1-5 I r I I | e- I

; 1. .11., "
_. i '3' : If! '.

i: ' ': Pba'ﬁﬁﬁl :I P":

 

Qt". :-

IIP'I'I'Mﬁy-FIII'MMII n'l F'WMWIII

 

 

 

 

I
11:11} 151] BI: 25!] 31:11:!
Emmolarglh inmberofbﬂ

BIrlll‘Itliﬂl'll on [Ilf' EII'I'I'IIIII Fmle ll'llll'lj

 

 

ﬁ-
ILII

“menu Ingmlenrﬂm a
|'.'.
I11- E

b
.1
'In

 

 

 

 

. 1 1 _I_
DDS H $1 W  HIP" '32 El 3'!

Fig. 4. Synthetic data experiment (top): distance between a ground-truth
model and the FastMotif prediction on semi-synthetic data (dashed line) and
synthetic data (solid). A set of motif instances, generated from a given bind-
ing site model (ELF3), have been inserted at random positions on random
genome sequences (semi-synthetic data) or on randomly generated se-
quences (synthetic data) of increasing length. Better performances on the
synthetic data can be explained by the presence of secondary motifs in the
genome background. Parameter sensitivity (centre): P—value of the output
model as a function of varying user-defined parameters, on HT-Selex data
(MAFK dataset). For reasonable values of the parameters, the quality of the
output is substantially constant (plateau). Noise sensitivity (bottom): a ran-
dom four-components mixture Ttrue e [0,1]""4’<4 is perturbed by adding an
extra component associated to the mixing weight wp+1 = 1-: e [0, 0.2] and com-
pared with its estimations Test obtained via a standard spectral algorithm
(Chang, 1996) (solid line) and FastMotif (dashed line). For each value of the
misspecification parameter, we plot the average normalized distance
M over 50 equivalent experiments. In all cases, the Schur-based de-

“Ttruell‘l‘HTestH
composition turned out to be more stable than the standard one

12 = 15 and ematch = 0.001. In Figure 4 (centre), we show the quality
of the output as a function of such user-defined parameters. The plot
shows that for reasonable (not extreme) values of the two free param-
eters, the quality of the output is rather constant (plateau).

Finally, we comment on the new fully probabilistic motif discov-
ery approach implemented in FastMotif. One of the main features is
that no deterministic consensus sequence is required to initialize the
search and models are computed directly from the empirical joint fre-
quency matrices. The search strategy is analogous to the one used by
MEME (Bailey and Elkan, 1994), where the sequence discovery prob-
lem is translated to the problem of learning a mixture of product dis-
tributions. The key novelty of FastMotif is the spectral learning
algorithm that is used to infer the parameters of the mixture. In

112 /810'S{12umo[p101x0'831112u1101u101qﬂ2d11q 111011 pepeolumoq

910K ‘09 lsnﬁnV no 22

2630

N. Colombo and N. Vlassis

 

particular, FastMotif is built on a new and more stable spectral tech-
nique based on the Schur decomposition of matrices (Section 3). The
new method comes with a theoretical analysis and we provide bounds
of the error of parameter estimation as a function of the amount of
noise (Supplementary Material). In particular, we generated a set of
triple joint probability distributions using a random five-components
mixture, and used FastMotif and the standard spectral algorithm
(Chang, 1996) to infer the parameters of the corresponding four-com-
ponents approximations. The weight of the fifth component 6 E [0,
0.2] has been used as a misspecification parameter. In Figure 4 (bot-
tom), we compare the distance in norm between the original four-
components model, obtained by subtracting the fifth component, and
its estimation for increasing values of 6. In average, and for almost all
values of the misspecification parameter, the FastMotif decomposition
scheme performs better than the standard approach.

5 Conclusions

Under the approximation that TF-DNA binding affinities are pos-
ition-independent, the problem of finding over-represented motifs in a
set of sequences is equivalent to the problem of learning a mixture of
product distributions. The inference of mixtures of product distribu-
tions is a well-known problem in statistics and machine learning, and
powerful techniques have been developed to solve the problem based
on spectral decompositions. We described FastMotif, a spectral motif
discovery algorithm that is fast, robust to model misspecification, not
prone to local optimal solutions, and that can search for motifs of ar-
bitrary length. We have tested the algorithm on HT-Selex experimen-
tal data and produced PWM’s that match the proﬁles obtained by
other state-of—the-art motif finding algorithms, but one order of mag-
nitude faster. FastMotif is based on a new approximate simultaneous
matrix diagonalization scheme, for which we provide theoretical and
numerical error bounds. We have analysed the robustness of the algo-
rithm theoretically and via numerical experiments on semi-synthetic
data. Moreover, we have studied the sensitivity of the algorithm on its
input parameters and shown that, at least for HT—Selex data, small
variations around their default values do not affect the quality of the
extracted motifs. Designed for the analysis of large-scale transcription
factor binding data, the current version of FastMotif restricts the
search to sub-sequences of relatively small length (from 3 to 15 nucle-
obases), but the arbitrary-length case can be handled with minor
modifications. For increasing search ranges, the complexity of the
spectral decomposition part of FastMotif, which is linear in the sam-
ple size, is substantially unchanged.

Because of its flexibility and speed, FastMotif can be a useful
tool in many important biological applications that go beyond the
identification of transcription factor binding sites. In future work,
we would like to extend our method to the more challenging domain
of RNA-binding proteins and consider applications in other kinds of
amino acid sequence analysis.

Acknowledgments

We would like to thank Anima Anandkumar, Anke Wienecke-Baldacchino,
Merja Heinaniemi, Matthieu Sainlez, Luis Salamanca and Cédric Laczny for
useful discussions, comments and questions.

Funding

This work was supported by FNR-Luxembourg CORE grant 12/BM/
3971381 HIBIO. The bulk of this work was carried out when N.V. was with
the Luxembourg Centre for Systems Biomedicine.

Conﬂict of Interest: none declared.

References

Anandkumar,A. et al. (2012a) Tensor decompositions for learning latent vari-
able models. ]. Mach. Learning Res., 15, 2773—2832.

Anandkumar,A. et al. (2012b) Learning high-dimensional mixtures of graph-
ical models. arXiv:1203.0697.

Anandkumar,A. et al. (2012c) A method of moments for mixture models and
hidden Markov models. arXiv:1203.0683.

Annala,M. et al. (201 1) A linear model for transcription factor binding afﬁnity
prediction in protein binding microarrays. PLoS One, 6, e2005 9.

Arora,S. et al. (2012) Learning topic models-going beyond SVD. In:
Foundations of Computer Science (FOCS), 2012 IEEE 53rd Annual
Symposium on, pp. 1—10. IEEE.

Badis,G. et al. (2009) Diversity and complexity in DNA recognition by tran-
scription factors. Science, 324, 1720—1723.

Bailey,T. and Elkan,C. (1994) Fitting a mixture model by expectation
maximization to discover motifs in biopolymers. In: International
Conference on Intelligent Systems for Molecular Biology; ISMB, Vol. 2, pp.
28—36.

Bailey,T.L. (2011) DREME: motif discovery in transcription factor ChIP-Seq
data. Bioinformatics, 27, 1653—165 9.

Balle,B. et al. (2014) Methods of moments for learning stochastic languages:
uniﬁed presentation and empirical comparison. In: Jebara,T. and Xing,E.P.
(eds), Proceedings of the 31st International Conference on Machine
Learning (ICML-14), pp. 1386—1394. JMLR Workshop and Conference
Proceedings.

Berger,M.F. and Bulyk,M.L. (2009) Universal protein-binding microarrays for
the comprehensive characterization of the DNA-binding speciﬁcities of tran-
scription factors. Nat. Protoc., 4, 393—411.

Berger,M.F. et al. (2006) Compact, universal DNA microarrays to compre-
hensively determine transcription-factor binding site speciﬁcities. Nat.
Biotechnol., 24, 1429—1435.

Boots,B. et al. (2011) Closing the learning-planning loop with predictive state
representations. Int. ]. Robot. Res., 30, 954—966.

Bulyk,M.L. (2002) Nucleotides of transcription factor binding sites exert
interdependent effects on the binding afﬁnities of transcription factors.
Nucleic Acids Res., 30, 1255—1261.

Chang,].T. (1996) Full reconstruction of Markov models on evolutionary
trees: identiﬁability and consistency. Math. Biosci., 137, 51—73.

Chen,X. et al. (2007) RankMotif++z a motif-search algorithm that accounts
for relative ranks of k-mers in binding transcription factors. Bioinformatics,
23,172—179.

Cheng,Q. et al. (2013) Computational identiﬁcation of diverse mechanisms
underlying transcription factor-DNA occupancy. PLoS Genet., 9,
e1003571.

Corless,R.M. et al. (1997) A reordered Schur factorization method for zero-
dimensional polynomial systems with multiple roots, pp. 133—140. ACM
Press.

Das,M.K. and Dai,H.-K. (2007) A survey of DNA motif ﬁnding algorithms.
BMC Bioinformatics, 8(Suppl. 7), 521.

Dempster,A.P. et al. (1977) Maximum likelihood from incomplete data via
the EM algorithm. ]. R. Stat. Soc. Ser. B (Methodol.), 1—38.

Hsu,D. and Kakade,S.M. (2013) Learning mixtures of spherical gaussians:
moment methods and spectral decompositions. In: Proceedings of the 4th
conference on Innovations in Theoretical Computer Science, ACM,
pp. 11—20.

Hsu,D. et al. (2012) A spectral algorithm for learning hidden Markov models.
]. Comp. Syst. Sci., 78, 1460—1480.

Johnson,D.S. et al. (2007) Genome-wide mapping of in vivo protein-DNA
interactions. Science, 316, 1497—1 5 02.

Jolma,A. et al. (2010) Multiplexed massively parallel SELEX for characteriza-
tion of human transcription factor binding speciﬁcities. Genome Res., 20,
861—873.

Jolma,A. et al. (2013) DNA-binding speciﬁcities of human transcription fac-
tors. Cell, 152, 327—339.

112 /810'S{12umo[p101x0'831112u1101u101qﬂ2d11q u1011 pepeolumoq

910K ‘09 lsnﬁnV no 22

Spectral sequence motif discovery

2631

 

Kinzler,K.W. and Vogelstein,B. (1990) The GLI gene encodes a nuclear pro-
tein which binds speciﬁc sequences in the human genome. Mol. Cell. Biol.,
10, 634—642.

Lee,D. et al. (2011) Discriminative prediction of mammalian enhancers from
DNA sequence. Genome Res., 21, 2167—2180.

Leslie,C. et al. (2002) The spectrum kernel: a string kernel for SVM protein
classiﬁcation. In Paciﬁc symposium on biocomputing, 7, 5 66—5 75 .

Lindsay,B.G. (1995) Mixture models: theory, geometry and applications. In:
NSF-CBMS Regional Conference Series in Probability and Statistics, pp.
1—163. JSTOR.

Mathelier,A. and Wasserman,W.W. (2013) The next generation of transcrip-
tion factor binding site prediction. PLoS Comput. Biol., 9, e1003214.

McLeay,R.C. and Bailey,T.L. (2010) Motif enrichment analysis: a uniﬁed
framework and an evaluation on ChIP data. BMC Bioinformatics, 11, 165.

Mossel,E. and Roch,S. (2006) Learning nonsingular phylogenies and hidden
Markov models. Ann. Appl. Probab., 16, 5 83—614.

Orenstein,Y. and Shamir,R. (2014) A comparative analysis of transcription
factor binding models learned from PBM, HT-SELEX and ChIP data.
Nucleic Acids Res., 42, e63.

Quattoni,A. et al. (2014) Spectral regularization for max-margin sequence tag-
ging. In: Proceedings of the 31st International Conference on Machine
Learning (ICML-14), 1710—1718.

Reid,].E. and Wernisch,L. (2011) STEME: efﬁcient EM to ﬁnd motifs in large
data sets. Nucleic Acids Res., 39, e126.

Sandve,G. et al. (2007) Improved benchmarks for computational motif discov-
ery. BMC Bioinformatics, 8, 193.

Santolini,M. et al. (2013) Beyond position weight matrices: nucleotide correl-
ations in transcription factor binding sites and their description.
arXiv:1302.4424.

Schneider,T.D. and Stephens,R.M. ( 1990) Sequence logos: a new way to dis-
play consensus sequences. Nucleic Acids Res., 18, 6097—6100.

Simcha,D. et al. (2012) The limits of de novo DNA motif discovery. PLoS
One, 7, e47836.

Song,]. and Chen,K.C. (2014) Spectacle: faster and more accurate chromatin
state annotation using spectral learning. bioRXiv: 002725

Stormo,G.D. (2000) DNA binding sites: representation and discovery.
Bioinformatics, 16, 16—23.

Stormo,G.D. et al. (1986) Quantitative analysis of the relationship between
nucleotide sequence and functional activity. Nucleic Acids Res., 14,
6661—6679.

Titterington,D.M. (1985) Statistical Analysis of Finite Mixture Distributions.
Wiley Series in Probability and Mathematical Statistics. Wiley, Chichester,
NY.

Tompa,M. et al. (2005 ) Assessing computational tools for the discovery of
transcription factor binding sites. Nat. Biotechnol., 23, 137—144.

Tuerk,C. and Gold,L. ( 1990) Systematic evolution of ligands by exponential
enrichment: RNA ligands to bacteriophage t4 DNA polymerase. Science,
249, 505—510.

Vert,].-P. et al. (2005) Kernels for gene regulatory regions. In: Advances in
Neural Information Processing Systems, pp. 1401—1408.

Wei,G.-H. et al. (2010) Genome-wide analysis of ETS-family DNA-binding
in vitro and in vivo. EMBO]., 29, 2147—2160.

Xie,B. et al. (2013) Poly (a) motif prediction using spectral latent features from
human DNA sequences. Bioinformatics, 29, i316—i325.

Zhang,Z. et al. (2013) Simultaneously learning DNA motif along with its pos-
ition and sequence rank preferences through expectation maximization al-
gorithm. ]. Comput. Biol., 20, 237—248.

Zhao,Y. et al. (2009) Inferring binding energies from selected binding sites.
PLoS Comput. Biol., 5, e1000590.

Zhao,Y. et al. (2012) Improved models for transcription factor binding site
identiﬁcation using nonindependent interactions. Genetics, 191, 781—790.
Zhao,Y. and Stormo,G.D. (2011) Quantitative analysis demonstrates most
transcription factors require only simple models of speciﬁcity. Nat.

Biotechnol., 29, 480—483.

Zou,].Y. et al. (2013) Contrastive learning using spectral methods. In:

Advances in Neural Information Processing Systems, pp. 223 8—2246.

112 /810'S{12umo[p101x0'831112u1101u101qﬂ2d11q u1011 pepeolumoq

910K ‘09 lsnﬁnV no 22

