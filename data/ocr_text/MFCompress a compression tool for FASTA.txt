APPLICATIONS NOTE

Vol. 30 no. 1 2014, pages 117—118
doi:10. 1093/bioinformatics/btt594

 

Sequence analysis

Advance Access publication October 16, 2013

MFCompress: a compression tool for FASTA and

multi-FASTA data

Armando J. Pinho* and Diogo Pratas

IEEI'A, Department of Electronics, Telecommunications and Informatics, University of Aveiro, 3810—193 Aveiro, Portugal

Associate Editor: John Hancock

 

ABSTRACT

Motivation: The data deluge phenomenon is becoming a serious
problem in most genomic centers. To alleviate it, general purpose
tools, such as gzip, are used to compress the data. However, although
pervasive and easy to use, these tools fall short when the intention is
to reduce as much as possible the data, for example, for medium- and
long-term storage. A number of algorithms have been proposed for
the compression of genomics data, but unfortunately only a few of
them have been made available as usable and reliable compression
tools.

Results: In this article, we describe one such tool, MFCompress, spe-
cially designed for the compression of FASTA and multi-FASTA files.
In comparison to gzip and applied to multi-FASTA files, MFCompress
can provide additional average compression gains of almost 50%, i.e.
it potentially doubles the available storage, although at the cost of
some more computation time. On highly redundant datasets, and in
comparison with gzip, 8-fold size reductions have been obtained.
Availability: Both source code and binaries for several operating sys-
tems are freely available for non-commercial use at http://bioinfor
matics.ua.pt/software/mfcompress/.

Contact: ap@ua.pt

Supplementary information: Supplementary data are available at
Bioinformatics online.

Received on July 29, 2013; revised on September 20, 2013; accepted
on October 13, 2013

1 INTRODUCTION

Saying that the volume of genomic data produced every day is
large is clearly a euphemism. With the dramatic drop in price of
the sequencing machines (the $1000 limit for sequencing a
human genome will be history shortly), virtually everyone will
want to sequence everything. Unfortunately, the pace at which
storage and communication resources are evolving is not enough,
and the genomic data centers are being ﬂooded with data. It is a
data deluge (Berger et al., 2013).

The interest for DNA compression was started with the
Biocompress algorithm of Grumbach and Tahi (1993). The sub-
sequent two decades have seen the publication of a considerable
number of algorithms for compressing DNA sequences and sev-
eral other forms of genomic data (e. g. Bonﬁeld and
Mahoney,2013; Cao et al., 2007; Cox et al., 2012; Hach et al.,
2012; Jones et al., 2012; Korodi and Tabus,2007; Matos et al.,
2013; Pinho et al., 2011,2012; Popitsch and Haeseler, 2013),

 

*To whom correspondence should be addressed.

although usually aiming more at proving the concept than at
providing usable compression tools. For example, the majority
of these algorithms assume data drawn from the four-letter al-
phabet, ACGT, ignoring other letters that can be found in DNA
data sequences. No doubt that for the purpose of showing the
potentialities of the algorithms, this is often a fair approach,
because those letters outside the main alphabet are usually rare
and, therefore, represent only a small fraction of the bits required
to represent the sequence. However, a usable lossless compres-
sion tool needs to be capable of handling every letter that it ﬁnds
in the ﬁle and to reproduce it exactly during decompression.
Moreover, genomic f11es rarely contain only sequence informa-
tion. Usually, they also include additional data, such as headers,
quality scores and alignment information. Therefore, the com-
pression tools need to compress these data as well in an efﬁcient
way.

In this article, we describe MF Compress, a tool for compress-
ing FASTA and multi- FASTA ﬁles. Recently, Mohammed et al.
(2012) proposed DELIMINATE, also a compression method for
FASTA and multi-FASTA files, which relies on a preprocessing
stage, where header and sequence data are separated and trans-
formed, followed by a general purpose compressor (7-Zip).

The MF Compress tool described here provides better com-
pression than DELIMINATE for the large majority of the ﬁles
used in the benchmarking dataset, at a similar compression
and decompression time. This dataset is an extended version of
the benchmarking dataset used by Mohammed et al. (2012), to
which we added some larger f11es, due to its increasing import-
ance and commonness. MF Compress relies on multiple compet-
ing ﬁnite-context models and arithmetic coding, a powerful
approach for DNA data compression (Pinho et al., 2011).

2 METHODS

The compression tool that we describe in this article relies on probabilistic
models (ﬁnite-context models) that comply to the Markov property, i.e.
that estimate the probability of the next symbol of the information source
using the k>0 immediate past symbols (order-k context) to select the
probability distribution. MFCompress uses single fmite—context models
for encoding the header text, as well as multiple competing ﬁnite-context
models for encoding the main stream of the DNA sequences (Pinho et al.,
201 1).

The compression algorithm divides the data source into two separate
sub-sources: one containing the headers of the FASTA records, the other
one the sequences. The sub-source that deals with the sequences may be
further divided into two or three streams (Supplementary Fig. S4 of the
Supplementary Material): the main stream, the extra stream and the case
stream. The main stream is a four-symbol information source, conveying

 

© The Author 2013. Published by Oxford University Press.

This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by—nc/3.0/), which permits non-

commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com

112 [3.10811211an[p.IOJXO'SODBIIHOJIITOTQ/ﬂ(11111 IIIOJJ popcolumoq

910K ‘09 lsnﬁnV no :2

A.J.Pinho and D.Pratas

 

most of the information of the four DNA bases. Both upper and
lower case characters representing the four DNA bases are converted
to this four-symbol alphabet. If characters other than the four DNA
bases are also present, they are all mapped to the ‘0’ symbol in the
main stream.

When the sequences contain other characters besides the DNA bases,
another coding stream must be present to disambiguate the occurrences
of the ‘0’ symbol in the main stream. This extra stream is responsible for
representing all non-acgt/ACGT characters that have been found in the
sequences, as well as to indicate when the ‘0’ in the main stream is an a/A
DNA base.

If the sequences contain both DNA bases in upper and lower case, an
additional binary symbol is associated to each symbol in the main stream,
indicating the respective case type (the case stream).

A more detailed description of the methods is provided in the
Supplementary Material.

3 RESULTS AND DISCUSSION

In the Supplementary Material, we provide compression results
obtained using several popular general purpose compression
methods, namely gzip, bzip2, ppmd and lzma (the last two
using the versions implemented in the 7z archiver), as well as
by the recent special purpose compressor DELIMINATE
(Mohammed et al., 2012) and by the compressor that we describe
in this article.

Supplementary Table S1 in the Supplementary Material shows
the total compressed ﬁle size, in bytes, obtained with gzip in the
F FN and F NA datasets (composed of all bacteria in the NCBI),
as well as the compressing gains attained by the other methods in
relation to gzip. We can see that MFCompress provides a com-
pression gain of ~3.5% in relation to DELIMINATE for the
F FN dataset and of ~4% for the FNA dataset. Compared with
gzip, the compression gain of MFCompress is ~25%.

In Supplementary Table S2 of the Supplementary Material, we
present the compression results for the human genome dataset
(HG19). The gain of the default mode of MFCompress is mar-
ginal in comparison with DELIMINATE (only 1.8%). For the
more complex coding mode, the gain is ~3.3%. In relation to
gzip, the gain is >34%.

Regarding the CAMERA dataset, in Supplementary Table S4
of the Supplementary Material, we provide compression results
regarding the 26 ﬁles that have been used in this dataset, showing
signiﬁcant gains over DELIMINATE for most of them. To give
a wide range of examples, we chose ﬁles with sizes from ~5 x 105
to >35 x 1010 characters, i.e. covering ﬁve orders of magnitude.
For three of these ﬁles, DELIMINATE was not able to provide
reliable results: in two cases the decoded ﬁle was different from
the original ﬁle and in one case the encoder crashed. In relation
to gzip, the size was reduced to almost half.

In Supplementary Table S5 of the Supplementary Material, we
show the compression results of two highly redundant datasets
(all Escherichia and Salmonella genomes of the FNA dataset). In
this case, MF Compress attained an 8-fold ﬁle size reduction over
gzip and >44% gain in relation to DELIMINATE.

4 CONCLUSION

For daily use, general purpose compression tools, such as gzip,
may continue to play an important role in the context of genomic
data processing, mainly due to its pervasiveness and relatively
good speed. However, as shown in this article, special purpose
compression tools can sometimes attain additional ﬁle reductions
as large as 50% or even more, in relation to gzip. In our opinion,
the possibility to virtually double the amount of sequence data
that can be stored in a given space, exclusively by means of
software compression tools, is an opportunity worthy of consid-
eration by the genomic laboratories. Higher compression can
only be obtained using more complex algorithms, often requiring
some more time and memory to run. However, these additional
requirements are compensated by the relief attained in terms of
storage requirements. In conclusion, we believe that the compres-
sion tool reported in this article is a relevant contribution to slow
down the negative impact of the data deluge that we are facing
nowadays.

Funding: European Fund for Regional Development (FEDER)
through the Operational Program Competitiveness Factors
(COMPETE) and by the Portuguese Foundation for Science
and Technology (FCT), in the context of projects F COMP-01-
0124-FEDER-022682 (F CT reference PEst-C/EEI/UIOl27/2011)
and Incentivo / EEI/ U10 1 27 / 20 1 3.

Conflict of Interest: none declared.

REFERENCES

Berger,B. et al. (2013) Computational solutions for omics data. Nat. Rev. Genet, 14,
333—346.

Bonﬁeld,J.K. and Mahoney,M.V. (2013) Compression of FASTQ and SAM format
sequencing data. PLoS One, 8, e59190.

Cao,M.D. et al. (2007) A simple statistical algorithm for biological sequence com-
pression. In: Data Compression Conference, DCC—2007, Snowbird, Utah. IEEE
Computer Society, pp. 43—52.

Cox,A.J. et al. (2012) Large-scale compression of genomic sequence databases with
the Burrows-Wheeler transform. Bioinformatics, 28, 1415—1419.

Grumbach,S. and Tahi,F. (1993) Compression of DNA sequences. In: Data
Compression Conference, DCC—93, Snowbird, Utah. IEEE Computer Society,
pp. 340—350.

Hach,F. et al. (2012) SCALCE: boosting sequence compression algorithms using
locally consistent encoding. Bioinformatics, 28, 3051—3057.

J ones,D.C. et al. (2012) Compression of next-generation sequencing reads aided by
highly efﬁcient de novo assembly. Nucleic Acids Res., 40, e171.

Korodi,G. and Tabus,I. (2007) Normalized maximum likelihood model of order-1
for the compression of DNA sequences. In: Data Compression Conference,
DCC—2007, Snowbird, Utah. IEEE Computer Society, pp. 33—42.

Matos,L.M.O. et al. (2013) A compression model for DNA multiple sequence align-
ment blocks. IEEE Trans. Inf. Theory, 59, 3189—3198.

Mohammed,M.H. et al. (2012) DELIMINATE - a fast and efﬁcient method for
loss-less compression of genomic sequences. Bioinformatics, 28, 2527—2529.
Pinho,A.J. et al. (2011) On the representability of complete genomes by multiple

competing ﬁnite-context (Markov) models. PLoS One, 6, e21588.

Pinho,A.J. et al. (2012) GReEn: a tool for efﬁcient compression of genome rese-
quencing data. Nucleic Acids Res., 40, e27.

Popitsch,N. and Haeseler,A. (2013) NGC: lossless and lossy compression of aligned
high-throughput sequencing data. Nucleic Acids Res., 41, e27.

 

118

112 [3.10811211an[p.IOJXO'SODBIIIJOJIIIOIQ/[Z(11111 IIIOJJ pepeolumoq

910K ‘09 lsnﬁnV no :2

