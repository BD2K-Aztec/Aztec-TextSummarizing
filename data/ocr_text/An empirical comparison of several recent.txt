REVIEW

Vol. 27 no. 21 2011, pages 2936-2943
doi: 10. 1093/bioinformatics/btr5 12

 

Genetics and population analysis

Advance Access publication September 7, 2011

An empirical comparison of several recent epistatic interaction

detection methods

Yue Wang“, Guimei Liu2, Mengling Feng3 and Limsoon Wong2

1NUS Graduate School for Integrative Sciences and Engineering, 2Department of Computer Science, School of
Computing, National University of Singapore and 3Data Mining Department, Institute for Infocomm Research,

Singapore
Associate Editor: Jonathan Wren

 

ABSTRACT

Motivation: Many new methods have recently been proposed for
detecting epistatic interactions in GWAS data. There is, however, no
in-depth independent comparison of these methods yet.

Results: Five recent methods—TEAM, BOOST, SNPHarvester,
SNPRuler and Screen and Clean (SC)—are evaluated here in terms
of power, type-1 error rate, scalability and completeness. In terms
of power, TEAM performs best on data with main effect and BOOST
performs best on data without main effect. In terms of type-1 error
rate, TEAM and BOOST have higher type-1 error rates than SNPRuler
and SNPHarvester. SC does not control type-1 error rate well. In
terms of scalability, we tested the five methods using a dataset with
100000 SNPs on a 64 bit Ubuntu system, with Intel (R) Xeon(R)
CPU 2.66 GHz, 16GB memory. TEAM takes ~36 days to finish and
SNPRuler reports heap allocation problems. BOOST scales up to
100000 SNPs and the cost is much lower than that of TEAM. SC
and SNPHarvester are the most scalable. In terms of completeness,
we study how frequently the pruning techniques employed by
these methods incorrectly prune away the most significant epistatic
interactions. We find that, on average, 20% of datasets without main
effect and 60% of datasets with main effect are pruned incorrectly
by BOOST, SNPRuler and SNPHarvester.

Availability: The software for the five methods tested are available
from the URLs below. TEAM: http://csbio.unc.edu/epistasis/
download.php. BOOST: http://ihome.ust.hk/~eeyang/papers.html.
SNPHarvester: http://bioinformatics.ust.hk/SNPHarvester.html.
SNPRuler: http://bioinformatics.ust.hk/SNPRuler.zip. Screen and
Clean: http://wpicr.wpic.pitt.edu/WPICCompGen/.

Contact: wangyue@nus.edu.sg

Received on June 2, 2011; revised on August 13, 2011; accepted on
September 4, 2011

1 INTRODUCTION

A genome—wide association study (GWAS) examines the
association between phenotypes and genotypes in a study
group. The ﬁrst exciting ﬁnding was on age—related macular
degeneration (AMD) (Klein, 2005), which uncovers a disease allele
(tyrosine—histidine polymorphism) with an effect size of 4.6 in
~100 000 single nucleotide polymorphisms (SNPs). Since then,
over 600 GWASs have been conducted for 150 diseases and traits;

 

*To whom correspondence should be addressed.

and ~800 associated SNPs have been reported. The methodologies
of these studies are similar: a quality control criteria is ﬁrst deﬁned
to ﬁlter the genotype data; then the remaining genotypes are each
tested for association with the disease phenotypes. Finally, the
signiﬁcant SNPs are reported after multiple testing correction. Most
of these GWASs could only identify disease alleles with moderate
effect size. Thus, single SNP association studies could explain very
limited heritability of these diseases (Emahazion et al., 2001).

Consequently, researchers have started exploring multi—SNP
interactions in the hope of discovering more signiﬁcant associations.
Multi—SNP interactions are also called ‘epistatic interactions’. This
term originated from Bateson’s deﬁnition of epistasis 100 ago
(B ateson, 1909). It was deﬁned as the change of segregation ratio and
the interaction of genes. However, in the current literature, there is a
debate on the exact deﬁnition of epistasis (Phillips, 1998, 2008). Our
article focuses on evaluating epistatic interaction detection methods
in their computational aspect and all the experiments are based
on simulation data. Thus, we consider epistatic interactions as the
statistically signiﬁcant associations of k—SNP interaction (k 2 2) with
phenotypes.

There are mainly two types of epistatic interaction detection
methods: model—based methods and model—free methods. In general,
model—based methods (Wan et al., 2010a; Wu et al., 2009, 2010;
Yang et al., 2009) predeﬁne a statistical model between phenotypes
and genotypes; then they ﬁt the data to the model; and ﬁnally they
output the signiﬁcant SNPs. They work well for only a small number
of important and ﬁltered candidate SNPs; but they often fail when
the number of SNPs grows to hundreds of thousands. To make
model—based methods more efﬁcient, researchers have proposed a
variety of heuristic and ﬁltering techniques. For example, Wan et al.
(2010a) develop an upper bound of the likelihood ratio test statistic
for two—locus epistatic interaction to prune the search space and a
Boolean transformation of data to make collection of contingency
table information faster. As another example, Wu et al. (2010)
devise a two—stage analysis so that the overall analysis is more
efﬁcient. As a third example, Yang et al. (2009) use a stochastic
search to identify only 40—50 (set by the user) groups of candidate
epistatic interactions for follow—up model—ﬁtting analysis.

In contrast, model—free methods (Ritchie et al., 2001; Wan et al.,
2010b; Zhang et al., 2010) have no prior assumption on the data and
the model. Given the genotype data, these methods only examine the
test statistic of each possible epistatic interaction with phenotypes.
Zhang et al. (2010) propose a minimum spanning tree (MST)
structure to represent the data; by traversing this MST, exhaustive

 

2936 © The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com

112 /§.IO'SIBUJHOprOJXO'SOllBIIIJOJUTOTQ/ﬁdllq 11101; prBOIIIAAOG

9IOZ ‘09 lsnﬁnv uo ::

Comparison of epistatic interaction detection methods

 

Table 1. Summary of the features of the ﬁve methods

 

 

B T SR SH SC
Exhaustive Search X \/ x x x
Lo git model assumed \/ x x \/ \/
Multistage x x x x \/
Permutation test >< \/ x x x
Bonferroni correction \/ >< \/ \/ \/
Programming language C C++ Java Java R

 

B, BOOST; T, TEAM; SR, SNPRuler; SH, SNPHarvester; SC, Screen and Clean.

search of every epistatic interaction is an order faster than that
of brute—force search. Wan et al. (2010b) connect the epistatic
interactions with predictive rules and use a rule mining strategy
to ﬁnd epistatic interactions.

Our evaluation study of epistatic interaction detection methods
is different from earlier studies such as Motsinger—Reif et al.
(2008a), Motsinger—Reif et al. (2008b) and Sucheston et al. (2010).
First, Motsinger—Reif et al. (2008b) compare only approaches
based on neural networks while our selected methods cover
both data mining and statistical methods. Second, Motsinger—
Reif et al. (2008a) evaluate multifactor dimensionality reduction
(MDR) (Ritchie et al., 2001), grammatical evolution neural
networks (GENN) (Motsinger—Reif et al., 2006), focused interaction
testing framework (FITF) (Millstein et al., 2006), random forests
(RF) (Breiman, 2001) and logistic regression (LR) (Hosmer and
Lemeshow, 2000) methods. They show that MDR is superior
in all settings. After 2 years of advancement, most methods
selected in this article have demonstrated that their performance
is better than that of MDR; we therefore omit discussing methods
mentioned in Motsinger—Reif et al. (2008a). Third, Sucheston
et al. (2010) compare AMBIENCE (Chanda et al., 2008) with
MDR, restricted partitioning method (RPM) (Culverhouse, 2007)
and logistic regression. They conclude that the performance of
AMBIENCE is equivalent to that of logistic regression for two—locus
models and better than that of RPM and MDR. However, according
to Wan et al. (2010a), the performance of BOOST is better than that
of PLINK (Purcell et al., 2007), which uses a pure logistic regression
model. Therefore, we omit the evaluation of AMBIENCE and RPM
in our study. Lastly, Wan et al. (2010b) and Yang et al. (2009) have
shown that their overall performance is much better than that of
BEAM (Zhang and Liu, 2007). We thus omit BEAM.

In this article, we give an independent empirical comparison
of ﬁve methods for detecting epistatic interactions—namely,
TEAM (Zhang et al., 2010), BOOST (Wan et al., 2010a),
SNPRuler (Wan et al., 2010b), SNPHarvester (Yang et al., 2009) and
Screen and Clean (Wu et al., 2010)—to help users better understand
which method is more suitable for their data, which method is good
for detecting epistatic interactions with and without main effect and
which method is scalable to larger datasets. We also analyze why
combining several of these methods cannot enhance power. Their
basic characteristics are given in Table 1.

The organization of this article is as follows. We ﬁrst formula—
tion the problem in Section 2. Then we brieﬂy introduce each of the
ﬁve methods in Section 3. We describe how the evaluation data is
simulated in Section 4 and the detailed setting of each experiment
in Section 5. After that, we present the results under each setting in

Section 6. Finally, we discuss the performance of each method and
provide advice to users in Section 7.

2 PROBLEM FORMULATION

In a typical GWAS, researchers collect two types of data: genotype
data that encodes the genetic information of each individual,
and phenotype data that measures the quantitative traits of each
individual. Here, we consider only bi—allelic SNPs. The allele that
occurs more frequently is called the major allele, denoted as A. The
allele that occurs less frequently is called the minor allele, denoted
as a. The two alleles form three genotypes—AA, Aa and aa—and
they are encoded as 0, 1 and 2 in raw data. For phenotype data, we
consider the binary form (0 for control and 1 for case). With minor
modiﬁcation, current methods can handle other types of phenotype
data, e. g. by discretizing a continuous phenotype.

The goal of each method is to identify k—SNP (k22) epistatic
interactions signiﬁcantly associated with the phenotype. Thus, each
method outputs a list of epistatic interactions, each involving up to
k—SNPs (usually k is set to 2) and is accompanied by its P—value
after correction for multiple testing.

There are two challenges. First, if we constrain k to be 1, then
the number of statistical tests is equal to the number of SNPs in
a dataset. When k increases by 1, the number of tests grows by
n—fold (n is the number of SNPs in a dataset). Thus, the total number
of tests grows quickly as k increases, resulting in the inability of
current methods to test all the combinations. For example, to study a
moderate size of 500 000 SNPs, we can test only two—locus epistatic
interactions if we use the EPISNP program (Ma et al., 2008) on a
2.66 GHz single processor, as it may take 1.2 years to ﬁnish all the
tests. Therefore, heavy computation cost is one of the challenges for
current methods (Wang et al., 2011). Second, since a huge number
of possible combinations are tested, a large proportion of signiﬁcant
associations are expected to be false positives. Thus, reducing the
number of false positives while retaining power is another challenge.

3 METHODS

3.1 SNPRuler

SNPRuler (Wan et 01., 2010b), MDR (Ritchie et 01., 2001) and a few
other pattern—based methods (Li et al., 2006; Long et al., 2009) adopt data
mining approaches for detecting epistatic interactions. These methods do
not assume a model—ﬁtting procedure, but use some ﬁltering methods to
reduce the number of SNP combinations to be tested. SNPRuler (Wan et al.,
2010b) is a rule—based approach motivated by the fact that each epistatic
interaction induces a set of rules. For example, SNP1 /\ SNP2 => Disease
contains nine rules, they are SNP1 =i /\ SNP2 = j => Disease, i, j e {0, 1, 2}.
In this article, the quality of a rule is given by its X2 test value. We deﬁne
SNP1 /\ SNP2 => Disease as a SNP—level epistatic interaction and SNP1 =i
/\ SNP2 = j => Disease, i, je{0,1,2} as allele—level epistatic interactions.
To identify epistatic interactions that are signiﬁcant, SNPRuler traverses a
set enumeration tree where the nodes of the tree are the genotypes of the
SNPs, the leaves of the tree are the phenotypes, and the path from the root
to a leaf is an allele—level epistatic interaction. Exhaustive tree traversal
is theoretically possible but practically impossible due to the explosive
number of combinations as the tree grows. Therefore, the authors propose
an upper bound on the X2 test statistic to prune the search space. After the
search procedure, a post—processing step is used to get and rank SNP—level
interactions. There are two hidden problems in this work. First, the upper
bound they derived from the X2 formula is not a true upper bound and does not

 

2937

112 /B.IO'SIBUJnOprOJXO'SOIlBIHJOJUIOICI/ﬁdnq 11101; popaommoq

9IOZ ‘09 lsnﬁnv uo ::

X Wang et aI.

 

possess the anti—monotone property (Agrawal and Sn'kant, 1994). Although
it helps prune a large search space, it also prunes many true—positive epistatic
interactions. Second, the upper bound is based on the assumption that the
number of cases should be larger than or equal to that of controls in a dataset;
otherwise, the upper bound does not hold. This assumption is inconvenient
since the number of controls is larger than that of cases in most GWAS
datasets.

3.2 SNPHarvester

SNPHarvester (Yang et al., 2009) is a stochastic search algorithm to identify
epistatic interactions. It consists of two steps: a ﬁltering and a model—ﬁtting
step. The ﬁltering step is to identify m (40—50) signiﬁcant SNP groups
for the subsequent model—ﬁtting step. In the ﬁltering step, it ﬁrst removes
signiﬁcant single SNPs according to their X2 test values, because this method
is only interested in epistatic interactions that have weak marginal effect but
signiﬁcant joint effect. Then it randomly picks k—SNPs. These form an active
set S = {SNP1, SNP2, ..., SNPk}. The rest of the SNPs form a candidate set
SC. After all these preparations are done, the nested PathSeeker algorithm is
called to swap SNP,- e S with 13ij 6 SC to get the group with the highest X2
test value. A total of k(n — k) combinations need to be tested to identify such a
group. After this, the identiﬁed group is removed from the n SNPs. The next
iteration continues to select k—SNPs to form an active set and the remaining
n—2k SNPs form a candidate set. The same procedure is repeated again.
The complexity to identify m groups is 0(knm), which is affordable even
when there are >100 000 SNPs. In the second step, each of the m signiﬁcant
groups is ﬁtted into the L2 penalized logistic regression model; see Park and
Hastie (2008) for details.

3.3 Screen and Clean

The Screen and Clean method (Wu et al., 2010) uses a two—stage analysis;
datasets from Stage 1 for the screening and datasets from Stage 2 for the
cleaning. In the screening stage, it only considers tag SNPs and marginal
signiﬁcant SNPs. These SNPs are ﬁrst ﬁtted into the main effect lasso logistic
regression model,

N
g(E[YIX])=ﬁo+ZIBJ-Xj,

j=1
where X]- is the encoded genotype value 0, 1 or 2, Y is the encoded phenotype
value 0 or 1. This model ﬁrst identiﬁes a set of SNPs whose coefﬁcients
satisfy 61-750, je {1,2,...,n}; then it obtains the least square estimates 3k,
ke {1,2,...,n} of these SNPs. To test the signiﬁcance of each regression
coefﬁcient, the t—test statistic value is calculated. Only the signiﬁcant SNPs
and their corresponding two—SNP combinations enter the interaction model

N
8(EIYIXI)=ﬁ0+Zﬁij+ Z ﬁthr-Xj.
j=1 i<j;i,j=l,...,N
A similar procedure applies to interaction model ﬁtting. After this stage,
the ‘surviving’ SNP pairs go to the second cleaning stage for controlling
type—1 error. T—test is used again to remove SNP pairs whose signiﬁcance
level is lower than a user—speciﬁed threshold.

3.4 BOOST

BOOST (Wan et al., 2010a) contributes to the epistatic detection problem
in two aspects. First, it provides a new Boolean representation of the
data. By transforming the data representation to the Boolean type, BOOST
uses established methods (Wegner, 1960) of logic operations to collect
contingency table information, which is very efﬁcient. Second, it proposes
an upper bound for the likelihood ratio test statistic to prune insigniﬁcant
epistatic interactions. The likelihood ratio test is originally based on the
deviance of difference between the full logistic regression model,

  :iaXlz  X11 X12 XZIXIZ
P(Y=2|X11:i,Xl2  —ﬁ0+ﬁi +ﬁj +ﬁij ,

 

log

where X11 and X), are genotype variables, i, j 6 {0,1,2}, and the main logistic
regression model
P(Y=1IXl1 =i,X12 =1)
P(Y:2IXI1:i7Xlz =1)

 

X1 X1
ZﬁO‘I‘ﬁi l+ﬁj 2-

We denote the log likelihood of the full model under maximum likelihood
estimate (MLE) as LAF, the log likelihood of the main model under MLE
as L14, the log likelihood of log—linear saturated model as [:5 and the
homogeneous model as LAH. The likelihood ratio statistic between the main
model and the full model is —2(L3t4—EF). The log—linear homogeneous
association model corresponds to the main logistic regression model and
the log—linear saturated model corresponds to the full logistic regression
model (Agresti, 2002). This leads to an upper bound for the two log—
linear models: —2(I:S —L}{). Matsuda (2000) uses Kirkwood Superposition
Approximation to get a lower bound of the homogeneous association model
(11m 5 L2,). Therefore, the upper bound of the likelihood is established
(1:5 —L}{ 5 [:5 —LKSA). This upper bound is tight and most non—signiﬁcant
interactions can be pruned. Its GPU version GBOOST (Yung et al., 2011)
provides 40—fold speedup compared with that of BOOST.

3.5 TEAM

TEAM (Zhang et al., 2010) is an exhaustive algorithm to detect two—
locus epistatic interactions in GWAS. It controls false positives by using
permutation test. Permutation test is generally more accurate at ﬁnding the
cut—off P—value threshold than direct adjustment methods like Bonferroni
correction (Benjamini and Hochberg, 1995), but at a much higher cost.
TEAM needs to compute the contingency table for every pair of SNPs
on all the permutations to calculate P—values, which is very expensive. To
reduce the computation cost, the authors observe that if two SNPs have the
same genotype values on many individuals, then the computation of their
contingency tables can be shared by considering only those individuals with
different values. TEAM uses an MST, where nodes are SNPs and the weight
of edges is the number of individuals with different values on the two SNPs, to
maximize the sharing of contingency table computation. As the construction
of MST can be costly, TEAM constructs an approximate MST instead. The
performance of TEAM is faster than the brute—force approach by an order of
magnitude. As TEAM does not presume any statistical model, it is applicable
to any test statistic—e. g. X2 test, exact likelihood ratio test and entropy—based
test—based purely on contingency table information.

4 DATA SIMULATION

We simulate different types of datasets to evaluate the power, type—1
error rate and scalability of each method.

4.1 Power

For each setting in both data with and without main effect below,
100 datasets are generated. In each dataset, we embed one ground—
truth epistatic interaction. Power is deﬁned as the fraction of the 100
datasets on which the top prediction matches the ground—truth.

Data with main eﬁ‘ect: the embedded epistatic interaction
demonstrates both main effect and interaction effect. There are at
least 50 different models that satisfy the constraints for two—locus
epistatic interactions (Li and Reich, 2000). We consider the three
commonly used models (Marchini et al., 2005) given in Figure 1.
We simulate the data based on these three models. For each model,
we try two different minor allele frequencies (MAF) at 0.2 and 0.5,
and three different main effect values at 0.2, 0.3 and 0.5; thus giving
a total of six different settings. These values represent the low and
high value for each parameter. We use 2000 samples and 1000 SNPs

 

2938

112 /B.IO'SIBUJHOIPJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Comparison of epistatic interaction detection methods

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

AA Aa aa AA
BB a a(1+6) a(1+6)2 BB a
Bb a(1+6) a(1+6)2 a(1+0)3 Bb a
bb a(1+6)2 a(1+6)3 a(1+6)4 Bb a

 

Aa aa AA Aa aa

A a BB a a a
a(1+6) a(1+0)2 Bb a a(1+6) a(1+6)
a(1+6)2 a(1+6)4 bb a a(1+9) a(1+6)

 

 

 

 

 

 

 

 

 

Model 1: two-locus multiplicative
disease effect between and within loci

Model 2: two-locus multiplicative
disease effect between loci

 

Model 3: two-locus threshold effect

Fig. 1. Illustraion of three main models. For the two—locus problem, suppose the baseline odds of getting a disease is 06, and having the disease allele (a or b)
increases the odds by 1+6. A person with genotype Aa or Bb has an 0t(1 +6) odds of getting a disease, while one with genotype aa or bb has an odds of
0t(1+6)2. Model 1 means the ﬁnal odds is multiplied by the odds of two loci. Model 2 requires both the loci to contain at least one disease allele before the
odds can be multiplied within and between loci. For Model 3, the odds is kept the same if both loci contain the disease allele.

for each dataset, as per previous works. These datasets are available
from http://compbio.ddns.comp.nus.edu.sg/~wangyue/.

Data without main eﬁ‘ect: this type of epistatic interaction
demonstrates weak main effect, but strong interaction effect. Finding
such type of epistatic interactions is a challenging ‘dark area’ which
many methods fail to explore. We use data from Dartmouth Medical
School. The website, http://discovery.dartmouth.edu/epistatic_data,
provides 70 models, composed of combinations of the following
parameter values: (i) two MAF settings of 0.2 and 0.4; (ii) seven
heritability settings of 0.4, 0.3, 0.2, 0.1, 0.05, 0.025 and 0.01 and
(iii) ﬁve different penetrance tables. Each model is simulated using
four sample sizes of 200, 400, 800 and 1600. The number of SNPs
is 1000 for each dataset.

4.2 Type-1 error rate

We simulate 1000 datasets without embedding any epistatic
interaction, each with 2000 samples and 1000 SNPs. The MAF of
each SNP is uniformly distributed in (0.05, 0.5). Type—1 error rate
of the methods is deﬁned as the proportion of the 1000 datasets
on which the signiﬁcance level of the top prediction satisﬁes the
user—speciﬁed threshold.

4.3 Scalability

To test the scalability, we use datasets with 100, 1000, 10000 and
100 000 SNPs. Each of the four datasets has 2000 samples.

5 EXPERIMENTAL SETTING

All the experiments are conducted on a 64 bit Ubuntu system, with
Intel (R) Xeon(R) CPU 2.66 GHz, 16 GB memory.

SNPRuler provides a Java program. The heap size is set to
—me7 O O OM, giving the maximum memory for the program to use.
The maximum number of rules is set as 50 000. The rule length is set
to 2 since we focus on two—locus epistatic interactions. The pruning
threshold is set as 0, to test as many combinations as possible.

SNPHarvester also provides a Java program; it has two running
modes. One is the ‘Threshold—Based’ mode, where the user indicates
the threshold signiﬁcance level and the program outputs all results
whose signiﬁcance level is lower than the threshold. Another is the
‘Top—K Based’ mode, where the program outputs the top K most
signiﬁcant results regardless of their signiﬁcance level. The ‘Top—K
Based’ mode is used for our analysis.

TEAM provides a C++ program that consists of two subprograms:
(i) to test all combinations and record the corresponding test statistic

value and (ii) to get the SNP pairs according to the user—speciﬁed
false discovery rate (FDR). We use the default setting of other
parameters and set the FDR value to 1.

BOOST provides a C program that only runs on Windows system.
To let all programs run on the same hardware conﬁguration, we use
the Wine program (http://www.wine.org) which allows us to run a
Windows program on a Unix system. There is no setting for BOOST;
the output is the list of results whose likelihood ratio test statistic
values are >30 with 4 degrees of freedom.

Screen and Clean provides an R program; it has four running
strategies, among which we choose the ‘Kitchen Sink’. We set the
P—value threshold to 0.1 and the number of pairs to be tested to 100.

BOOST ﬁlters out epistatic interactions with test statistic values
<30 with 4 degrees of freedom. This corresponds to 0.1 signiﬁcance
level. For fair comparison, we add a post—processing step to ﬁlter
output with P > 0.1 for other methods.

6 EXPERIMENT RESULTS
6.1 Model with main effect

The results here are obtained by using data generated in the ﬁrst
part of Section 4.1. Figure 2 shows that in each setting, TEAM
outperforms all other methods. For the other four methods, different
model settings lead to different rankings. For example, in Model 1
with )t :03, SNPRuler is second; in Model 2 with )t :05, Screen
and Clean is second. The different performance of TEAM and
BOOST is due to a key difference in deﬁning the interaction effect.
TEAM uses the X2 test to measure the signiﬁcance of two—locus
interactions and thus makes no assumption about the data. BOOST
uses a log likelihood ratio test to get the deviance difference between
the log likelihood of the log—linear homogeneous association model
and log—linear saturated model. BOOST performs well when the
interaction terms contribute signiﬁcantly to the model. However,
when single SNP association terms ﬁt the model well and interaction
terms do not contribute signiﬁcantly, BOOST may not be able
to detect the ground—truth. This type of epistatic interactions is
often referred as ‘statistical epistasis’ (Cordell, 2002) and is widely
accepted by the statistical community. SNPRuler is not an exhaustive
method, but the test used is the same as that of TEAM. We set the
pruning threshold to 0; thus, it explores as many epistatic interactions
as possible. Compared with TEAM, this method potentially misses
true positives. The result of SNPHarvester is expected as its
randomization technique makes it difﬁcult to perform better than
exhaustive search. Screen and Clean performs poorly, due to its
numerous ﬁltering steps in the two—stage design. In the screening

 

2939

112 /B.IO'SIBUJHOIpJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

X Wang et aI.

 

I A=0.2
IA=0.3

Power
Power

SC T B SR SH SC T B SR SH SC

Model 1 Model 2 Model 3

MAF = 0.2

1 II- A=0.2 1 H 71:0.2 1 1.1 1:02 1 a. 1:01 1 1.11:0; 1
0.8 I A=0.3 0.8 I A=o.3 0.8 I i=0.3 0.8 - “:03 0.8 IA=0.3 0.8
A=0.5 A=O.5 = . = . = . A=0.5
0.6 0.6 g 0.6 " 05 a; 0.6 " 05 g 0.6 " 05 g 0.6
0.4 0.4 8 0.4 8 0.4 8 0.4 E 0.4
0.2 0.2 0.2 J 0,2 0.2 0.2
- l _ I J .l J I I I 0 — .- _ o - -
T B SR SH T B SR SH

SC T B SR SH SC T B SR SH SC

Model 1 Model 2 Model 3

MAF = 0.5

Fig. 2. Power comparison under three main effect models. Each model has two MAF settings and three A settings which control the main effect of the

ground—truth SNP. For each model, we generate 100 datasets. For each dataset, the sample size is 2000 (1000 cases and 1000 controls) and the number of

SNPs is 1000. Abbreviations of the methods are: T (TEAM), B (BOOST), SR (SNPRuler), SH (SNPHarvester) and SC (Screen and Clean). The P—value for

one—way ANOVA test is 0.0009.

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

201: Simple: 400 Simple: mammal 16m Sunqu
D- Cl U a
.—' — — — .—" — — .2 — — —I—E ._--
: —-— 2' 3' 3' 
g gs:- 36- is
at 9-1. T. £1.
D — n a “I:
N. N. 64. at. 
D U a _ ﬂ — =
D. _ _ _ a. _|_  _ a. —'—   a.
a B T as d a T 61:1 '5 a 1' 61:1 '3‘ a T an

 

Fig. 3. Power comparison under 70 models without main effect. For each model, we simulate data using four different sample sizes. These sizes simulate the
study design from small scale to large scale. Abbreviations of the methods are: T (TEAM), B (BOOST), SR (SNPRuler) and SH (SNPHarvester).

step, before the main—effect lasso procedure starts, it includes only
marginally signiﬁcant and tag SNPs. After that, it still only considers
n (set by the user) pairs of SNPs instead of all the possible pairs
to continue the interaction model ﬁtting procedure. In the cleaning
step, the ﬁltering test is applied to only a small number of SNP pairs,
resulting in little power to detect the ground—truth.

All ﬁve methods perform best on Model 1 compared with
Models 2 and 3. This is because of the multiplicative effect
between and within the two loci, making the epistatic interaction
effect stronger and easier to detect. Model 2 only considers the
multiplicative effect between two loci; the power to detect epistatic
interactions drops obviously for all methods. The interaction effect
of Model 3 is even weaker than Model 2, leading to the lowest power
in all methods. It is also noted that the higher the main effect of the
model, the easier it is for each method to detect epistatic interactions.
However, SNPRuler and SNPHarvester do not follow this pattern
because, when the main effect of the ground—truth pair is large, these
two methods prune such main effect SNPs at the ﬁltering stage. This
leads to the missing detection of ground—truth.

6.2 Model without main effect

The results here are obtained using data generated in the latter
part of Section 4.1. Screen and Clean is applicable only to data
with main effect; thus we omit it here. Figure 3 gives an overall
picture of the performance of the methods for each sample size,
while Figure 4 gives the details. The median power of BOOST is
the highest followed by TEAM. The performance of SNPRuler is
close to that of an exhaustive method (TEAM), but is at a lower
computational cost. BOOST performs the best in each setting and
TEAM second; but the difference is not as obvious as that in data
with main effect. SNPHarvester performs relatively poorly for each
sample size. All methods perform well when heritability is high;

when heritability reduces to 0.001, all methods have little power.
Lescai and Franceschi (2010) point out in their study of neurological
cancers that low heritability caused by phenocopy level (PE) is the
main reason for the methods to lose power. We also notice that
increasing the sample size helps all these methods to improve their
power in each heritability setting.

When we evaluate the four methods on data without main effect,
we use all datasets that are publicly available. They include 70
models and 4 different sample sizes for each model. Part of these
datasets are also used in BOOST, SNPRuler and SNPHarvester.
BOOST does not include the results of 70 models for 200 samples.
SNPRuler and SNPHarvester merely show results of 60 models and
each model with 400 samples. Our reported results are consistent
with previous reported results and are complementary to them. In
particular, for those models with 0.001 heritability, 0.2 MAF and 200
samples, the results of these datasets were not reported previously;
and all four methods have zero power (Fig. 4). This shows the
limitations of purely statistical methods.

6.3 Scalability

We apply all methods to datasets with 100, 1000, 10000 and
100 000 SNPs. From Table 2, BOOST is the fastest under the ﬁrst
three settings. This is due to its fast Boolean operation to collect
contingency tables and upper bound—pruning technique. When the
SNP size grows to 100 000, it is much slower than the two non—
exhaustive methods SNPHarvester and Screen and Clean. TEAM is
the slowest in all settings for two reasons. First, the overall running
time is only an order faster than that of a brute—force approach.
Second, the permutation procedure makes it even more expensive,
although traversing MST helps reduce the cost. SNPRuler cannot
execute on the dataset with 100 000 SNPs because we get the ‘out
of memory’ error, even though we have set the heap size to 12.8 GB

 

2940

112 /B.IO'SIBUJHOIpJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Comparison of epistatic interaction detection methods

 

ZOO Samples 400 Samples 800 Samples 1600 Samples
1 1 ' ' 1 1 '
IB IB 5 [3 IB
5 0.8 h 0.8 0.8 h 0.8 I
“0.6 'T “0.6 'T “0.6 'T “0.6 T
5 SR 5 SR 504 SR 504 SR
10.4 n_0.4 a. l.
0.2  ISH 0.2 i ISH 0.2 ISH 0.2 i lSH
0 - '- ' '- - o ' ' l - 0 ' ' ' ‘- 0 ' -
$833§§§ E838§§§ §SSSS§§ $883§§§
Heretability 0' 0' Heretability d 0' Heretability 0' d Heretability 0' 0'
02MAF
200 Samples 400 Samples 800 Samples 1600 Samples
1
I3

E
_ T
SR
I 'SH
L
PI Ln

1 I B -

h0.8 I h 0.8

$0.6 T $05

30.4 SR 30.4

0.2 l l SH 02

.I ._ _ 0 ' '
H
O

<r. "2 N. m m H s: "2 N. g N g
o o o  g 8 o o o o. o. Q Q
Heretability 0 o Heretabllty o o

O
00
O
00

0

1 ' ' I B 1 -' ' I B
. h .

(T) 0.6 'T c£06 'T

E 0.4 5R 80.4 SR

1:.

0.2 I SH 0.2 - - SH
. I 0 - - -

<1- m N H In Ln
:5 ' 0

0.025
0 001

0

0

0

O

0
0.025
0 001

o o' o" .
Heretablltyo

0.4 MAF

Fig. 4. Detailed results of four methods on data without main effect. In particular, for models with heritability 0.001, MAF 0.2 and sample size 200, the
results of these datasets were not reported previously; all four methods have zero power on them. This shows the limitations of purely statistical methods.

The P—value for one—way ANOVA test is 0.0997.

Table 2. Running time comparison of the ﬁve methods

 

No. of SNPs TEAM BOOST (s) SR (s) SH (s) SC (s)

 

100 58.23 s 0.16 2.43 2.29 7.39
1000 353.20 s 2.47 21.73 22.33 55.48
10 000 7406.29 s 156.16 1097.65 224.24 626.96

100000 ~36 days 15010.42 NA 6616.65 5858.34

 

SR, SNPRuler; SH, SNPHarvester; SC, Screen and Clean.

for the Java virtual machine, which is the maximum on our PC.
SNPHarvester and Screen and Clean only identify a ﬁxed number
of candidate epistatic interactions, and then ﬁt them to a statistical
model for follow—up analysis. Thus, their scalability is much better
than the other three methods when SNP size grows.

6.4 Type-1 error

We deﬁne the type—1 error rate of a method as the proportion
of datasets that the method reports as the existence of signiﬁcant
epistatic interactions, out of the 1000 datasets in which no epistatic
interactions are actually embedded. The signiﬁcance level is set to
0.05 after Bonferroni correction. The type—1 error rate for TEAM
is 0.018, BOOST is 0.065 and SNPRuler and SNPHarvester both
are 0.003. TEAM and BOOST have higher power, and thus higher
type—1 error rates are reasonable. Screen and Clean has problems
controlling type—1 error, as its type—1 error rate is as high as 0.86.

6.5 Completeness

SNPRuler, SNPHarvester and BOOST use some pruning techniques
to speed up the search. Hence, they have better scalability than
TEAM as shown in Table 2. The side effect of using pruning
techniques is the loss of power—the most signiﬁcant SNP pairs
may be thrown away. To study the magnitude of this side effect, we

pick the most signiﬁcant SNP pair on each dataset and study how
many of them are pruned. For each method, the most signiﬁcant
SNP pair is the SNP pair with the lowest P—value calculated using
the statistical test used by the method. Thus, for BOOST, the
most signiﬁcant SNP pair is the SNP pair with the lowest P—value
calculated using likelihood ratio test. For the other two methods, the
most signiﬁcant SNP pair is the SNP pair with the lowest P—value
calculated using X2 test. BOOST prunes away the most signiﬁcant
SNP pair on 4195 out of the 26 860 datasets without main effect,
and on 756 out of 1698 datasets with main effect. Among these
4195 datasets, the power of BOOST is 12.2% compared with 18.3%
for the corresponding exhaustive method. Figure 5 also shows that
the number of incorrectly pruned datasets of SNPRuler is smaller
than that of SNPHarvester for both types of data. Correspondingly,
the power of SNPRuler is higher than that of SNPHarvester.

6.6 Comments on Completeness

In the completeness analysis of BOOST, we discovered a bug in
our program script while this paper was in press. In particular,
we missed out in our program script a step to sort the output of
BOOST—this caused the top interacting SNP pair to be not always
chosen in each test. Consequently, we misreported in Section 6.5
that BOOST wrongly pruned the most signiﬁcant SNP pairs in 4195
datasets without main effect and 756 datasets with main effect. After
correcting the program script, BOOST was veriﬁed to be complete
and did not mis—prune any most signiﬁcant SNP pairs.

7 DISCUSSION

The ﬁve methods all demonstrate respective utilities through the
experiments results above. No single method is simultaneously the
most powerful, the most scalable and has the lowest type—1 error
rate in every setting. When users want powerful results and are
not concerned with computation cost, we recommend using TEAM
and BOOST. Compared with TEAM, BOOST uses a model—ﬁtting
procedure. If the data ﬁts the model well, the result is usually good;

 

2941

112 /3.IO'SIBUJHOIpJOJXO'SOIlBIIlJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

X Wang et al.

 

compiatanaa: space at the methods
Data 111.1ltl'111:1ut main effect
Exhaustive Likelihood-ratio

I- :I1.‘1I:.¢.f1'.ur.= I:I1l-HT[IJI!FIEZ-I I I-1"-Iu'-_1

  
    

   

. J 41111: 
.x .
a..- ea” .-

SNPHaruester SNPRuler EDDGT

Data. with main effect
Exhaustive Likelihood—ratio

M}

5:!!I'IEEIJHII'111'E‘. Lilli-Huumm'lt ref-'1:-

 9511 1:231” 6311 
1k  

-1.
Man. __.—"f '

 

SNPHarvesm SNPRuler BOOST

Fig. 5. The completeness space for the four methods. As there are two
types of datasets and two types of test statistics, four venn diagrams
are drawn, respectively. In (a), all three methods—TEAM, SNPRuler
and SNPHarvester—use X2 test. TEAM’s outputs represent the 28 000
(20 320 +1977 + 2660 +3043) top signiﬁcant SNP pairs in 28 000 datasets.
SNPHarvester can identify 22 297 (20 320+1977) of them. Among the
28 000 top SNP pairs, 20 320 of them can be identiﬁed by all three methods.
(b—d) follow similar explanations.

(a) Data with main effect  Data without main effect
BOOST
SNPRuler anus-J  _ 
11 n SNP-Ruler  
_ _ H I" 11110
361 a?  Ia  ' 4?  —
’1 “H. 11 - a ' m “  21111
x 11?
5' 253 x___ a, u 61'
1 a1  ' - 21
2 't SNPHarwster 9 .* .__1am .I, I - SNPHarWt-‘tar
I.in -..-._.1_5- If -"
I‘LL-- .

mlaalng ground-truth 1WD missing ground-truth: HF!

Fig. 6. The power space for the four methods on data with and without
main effect. In (a), there are in total 1800 datasets for 18 settings of the
simulated datasets, which corresponds to 1800 ground—truth. Among these
ground—truth, only 800 of them can be detected by at least one of the four
methods, while the best method—TEAM—identiﬁes 787 ground—truth out of
800. This explains why using ensemble methods cannot outperform TEAM.
Similar observation is illustrated in (b).

otherwise, a model—free method may be the alternative choice. When
users expect moderate running time and power, we recommend using
SNPRuler. Its pruning technique helps reduce running time albeit
at the risk of losing power. If users are conscious of computation
cost and have to run very large datasets, we recommend using
SNPHarvester because it only identiﬁes a small number (40—50)
of groups for the model—ﬁtting procedure.

Our evaluations are based on simulation results. In a real study,
users usually have no idea of the ‘ ground—truth’ in the dataset. Hence,
it may not be sufﬁcient to rely only on one method to obtain results.

We suggest that, if time and computation resources permit, users try
both the recommended model—free (i.e. TEAM) and model—ﬁtting
(i.e. BOOST) methods.

It is tempting to consider taking a ‘majority vote’ of the results
of two or more methods. For example, let every algorithm report
their top three predictions. An SNP pair receives k votes if it is
reported by k methods. We select the one with the highest vote as
the ﬁnal prediction. When there is a tie, we choose the one with
the lowest P—value. Unfortunately, for both types of data tested,
we ﬁnd that an ensemble using such a strategy cannot increase
power over using solely BOOST or TEAM. In Figure 6, we see
that for data without main effect, BOOST’s ground—truth predictions
highly overlap with the other three methods, so any ensemble cannot
contribute a signiﬁcant number of new ground—truth predictions.
Speciﬁcally, the proportion of BOOST’s ground—truth predictions
that are not predicted by the other three methods is 4.1%, while
the proportion of the other methods’ ground—truth predictions not
predicted by BOOST is 0.2%. Similarly, for data with main effect,
no ensemble can outperform TEAM.

Our evaluations above only focus on two—locus epistatic
interaction. Recently, Wang et al. (2010) and Liu et al. (2011)
provide a general model that can be extended to n—locus epistasis.
They also provide mathematical details of dissecting the X2 test
into different epistatic components. For example, two—way epistatic
interaction can be partitioned into four epistatic components:
additive X additive, additive X dominant, dominant >< additive and
dominant >< dominant. This helps characterize epistatic interactions
in a more speciﬁc way and provides more physiological insights.

F anding: National University of Singapore NGS Scholarship (to
Y.W., in part); Singapore Agency for Science Technology &
Research Grant (SERC 102 101 0030 to L.W., G.L.).

Conﬂict of Interest: none declared.

REFERENCES

Agrawal,R. and Srikant,R. (1994) Fast algorithms for mining association rules in large
databases. In Proceedings of 20th International Conference on Very Large Data
Bases. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, pp. 487—499.

Agresti,A. (2002) Categorical Data Analysis. John Wiley & Sons, Hoboken, New Jersey.

Bateson,W. (1909) Mendel’s Principles of Heredity. University Press, Cambridge.

Benjamini,Y. and Hochberg,Y. (1995) Controlling the false discovery rate: A practical
and powerful approach to multiple testing. J. R. Stat. Soc. Ser. B , 57, 289—300.

Breiman,L. (2001) Random forest. Mach. Learn, 45, 5—32.

Chanda,P. et al. (2008) AMBIENCE: a novel approach and efﬁcient algorithm for
identifying informative genetic and environmental associations with complex
phenotypes. Genetics, 180, 1191—1210.

Cordell,H.J. (2002) Epistasis: what it means, what it doesn’t mean, and statistical
methods to detect it in humans. Hum. Mol. Genetics, 11, 2463—2468.

Culverhouse,R. (2007) The use of the restricted partition method with case-control data.
Hum. Heredity, 63, 93—100.

Emahazion,T. et al. (2001) SNP association studies in Alzheimer’s disease highlight
problems for complex disease analysis. Trends Genetics, 17, 407—413.

Hosmer,D.W. and Lemeshow,S. (2000) Applied Logistic Regression. John Wiley &
Sons, Hoboken, New Jersey.

Klein,R.J. (2005) Complement factor H polymorphism in age-related macular
degeneration. Science, 308, 385—389.

Lescai,F. and Franceschi,C. (2010) The impact of phenocopy on the genetic analysis of
complex traits. PlpS One, 5, e11876.

Li,W. and Reich,J. (2000) A complete enumeration and classiﬁcation of two-locus
disease models. Hum. Heredity, 50, 334—349.

Li,Z. et al. (2006) Pattern-based mining strategy to detect multi-locus association and
gene >< environment interaction. BMC Proc., 1 (Suppl. 1), S16.

 

2942

112 /B.IO'SIBUJHOIpJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Comparison of epistatic interaction detection methods

 

Liu,T. et al. (2011) Asymptotic distribution for epistatic tests in case-control studies.
Genomics, 98, 145—151.

Long,Q. et al. (2009) Detecting disease-associated genotype patterns. BMC
Bioinformatics, 10 (Suppl. 1), S75.

Ma,L. et al. (2008) Parallel and serial computing tools for testing single-locus and
epistatic SN P effects of quantitative traits in genome-wide association studies. BM C
Bioinformatics, 9, 315.

Marchini,J. et al. (2005) Genome-wide strategies for detecting multiple loci that
inﬂuence complex diseases. Nat. Genetics, 37, 413—417.

Matsuda,H. (2000) Physical nature of higher-order mutual information: intrinsic
correlations and frustration. Phys. Rev. E, 62, 3096.

Millstein,J. et al. (2006) A testing framework for identifying susceptibility genes in the
presence of epistasis. Am. J. Hum. Genetics, 78, 15—27.

Motsinger-Reif,A.A. et al. (2006) Understanding the evolutionary process of
grammatical evolution neural networks for feature selection in genetic
epidemiology. In Proceedings of IEEE Symposium on Computational Intelligence
in Bioinformatics and Computational Biology, IEEE, pp. 1—8.

Motsinger-Reif,A.A. et al. (2008a) A comparison of analytical methods for genetic
association studies. Genetic Epidemiol, 32, 767—778.

Motsinger-Reif,A.A. et al. (2008b) Comparison of approaches for machine-learning
optimization of neural networks for detecting gene-gene interactions in genetic
epidemiology. Genetic Epidemiology, 32, 325—340.

Park,M.Y. and Hastie,T. (2008) Penalized logistic regression for detecting gene
interactions. Biostatistics, 9, 30—50.

Phillips,P.C. (1998) The language of gene interaction. Genetics, 149, 1167—1171.

Phillips,P.C. (2008) Epistasis-the essential role of gene interactions in the structure and
evolution of genetic systems. Nat. Rev. Genetics, 9, 855—867.

Purcell,S. et al. (2007) PLINK: a tool set for whole-genome association and population-
based linkage analyses. Am. J. Hum. Genetics, 81, 559—575.

Ritchie,M.D. et al. (2001) Multifactor-dimensionality reduction reveals high-order
interactions among estrogen-metabolism genes in sporadic breast cancer. Am. J.
Hum. Genetics, 69, 138—147.

Sucheston,L. et al. (2010) Comparison of information-theoretic to statistical methods
for gene-gene interactions in the presence of genetic heterogeneity. BM C Genomics,
11, 487.

Wan,X. et al. (2010a) BOOST: a fast approach to detecting gene-gene interactions in
genome-wide case-control studies. Am. J. Hum. Genetics, 87, 325—340.

Wan,X. et al. (2010b) Predictive rule inference for epistatic interaction detection in
genome-wide association studies. Bioinformatics, 26, 30—37.

Wang,Z. et al. (2010) A general model for multilocus epistatic interactions in case-
control studies. PLoS One, 5, e11384.

Wang,Z. et al. (2011) eCEO: an efﬁcient Cloud Epistasis cOmputing model in genome-
wide association study. Bioinformatics, 27, 1045—1051.

Wegner,P. (1960) A technique for counting ones in a binary computer. Comm. ACM,
3, 322.

Wu,T.T. et al. (2009) Genome-wide association analysis by lasso penalized logistic
regression. Bioinformatics, 25, 7 14—72 1.

Wu,J. et al. (2010) Screen and Clean: a tool for identifying interactions in genome-wide
association studies. Genetic Epidemiol, 34, 275—285.

Yang,C. et al. (2009) SNPHarvester: a ﬁltering-based approach for detecting epistatic
interactions in genome-wide association studies. Bioinformatics, 25, 504—511.
Yung,L.S. et al. (2011) GBOOST: A GPU-based tool for detecting gene-gene

interactions in genome-wide case control studies. Bioinformatics, 27, 1309—1310.

Zhang,Y. and Liu,J.S. (2007) Bayesian inference of epistatic interactions in case-control
studies. Nat. Genetics, 39, 1167—1173.

Zhang,X. et al. (2010) TEAM: efﬁcient two-locus epistasis tests in human genome-wide
association study. Bioinformatics, 26, i217—i227.

 

2943

112 /B.IO'SIBUJHOIpJOJXO'SOIlBIHJOJUIOIQ/ﬁdnq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

