Bioinformatics, 31 (10), 2015, 1577—1583

doi: 10.1093/bioinformatics/btv024

Advance Access Publication Date: 20 January 2015
Original Paper

 

Sequence analysis

Ultrafast SNP analysis using the
Burrows—Wheeler transform of short-read data

Kouichi Kimura* and Asako Koike

1Biosystems Research Department, Central Research Laboratory, Hitachi, Ltd., 1-280 Higashi-Koigakubo,
Kokubunji, Tokyo 185-8601, Japan

*To whom correspondence should be addressed.
Associate Editor: John Hancock

Received on September 11, 2014; revised on December 24, 2014; accepted on January 12, 2015

Abstract

Motivation: Sequence—variation analysis is conventionally performed on mapping results that are
highly redundant and occasionally contain undesirable heuristic biases. A straightforward ap—
proach to single—nucleotide polymorphism (SNP) analysis, using the Burrows—Wheeler transform
(BWT) of short—read data, is proposed.

Results: The BWT makes it possible to simultaneously process collections of read fragments of the
same sequences; accordingly, SNPs were found from the BWT much faster than from the mapping
results. It took only a few minutes to find SNPs from the BWT (with a supplementary data, fragment
depth of coverage [FDC]) using a desktop workstation in the case of human exome or transcrip—
tome sequencing data and 20 min using a dual—CPU server in the case of human genome sequenc—
ing data. The SNPs found with the proposed method almost agreed with those found by a time—
consuming state—of—the—art tool, except for the cases in which the use of fragments of reads led to
sensitivity loss or sequencing depth was not sufficient. These exceptions were predictable in ad—
vance on the basis of minimum length for uniqueness (MLU) and FDC defined on the reference
genome. Moreover, BWT and FDC were computed in less time than it took to get the mapping re—
sults, provided that the data were large enough.

Availability and implementation: A proof—of—concept binary code for a Linux platform is available
on request to the corresponding author.

Contact: kouichi.kimura.hh@hitachi.com

Supplementary information: Supplementary data are available at Bioinformatics online.

 

 

1 Introduction

Since the advent of so—called next—generation DNA sequencers
(NGSs), which rapidly and cost—effectively generate billions of short
reads, large—scale analysis of sequence data of a few—hundred giga
base pairs (Gbp), requiring a large computational resources, is not
uncommon anymore. The first step to eXtract biologically meaningful
information from sequence data often involves analysis of the vari—
ation (mutation) of that data in comparison with a reference genome
sequence data. Billions of short reads are first mapped onto the refer—
ence genome, and unambiguous and recurrent mismatches between
the short reads and the reference genome are identified as candidate
mutations (DePristo et al., 2011). This line of approach is hereafter

referred to as the mapping-based approach. Although it is the most
appreciated and most commonly used approach, it has the following
basic weak points. (i) The computation of mapping is highly redun-
dant because of large sequencing depth (typically ranging from 30x
to 100x). (ii) Some mutations can be lost by mapping tools because
such tools use certain heuristics of their own to resolve mapping
ambiguities. (iii) It is not easy to switch from one reference genome to
another after the computation of mapping has been completed.

To address these weak points, an alternative solution, the dic-
tionary-based approach, is proposed. The short—read data are con—
verted into a dictionary of reads, so that numbers of occurrences of
any sequence in the short—read data are immediately obtained. Then,

©The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 1577

112 /§JO'S{eumo [p.IOJXO'SOTlBIHJOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

1578

K.Kimura and A.Koike

 

mutations can be inferred on the basis of these numbers by means of
querying genomic subsequences with and without the mutations
(Fig. 1). The dictionary can be implemented efficiently by means of
the Burrows—Wheeler transform (BWT) (Burrows and Wheeler,
1994) [a.k.a. FM index (Ferragina and Manzini, 2000)] because it is
simple and particularly suitable for DNA sequences.

Although the proposed approach appears to be too naive, it has the
following potential advantages. (i) Redundancy due to deep sequenc—
ing coverage is efficiently managed by the dictionary of reads. (ii) The
dictionary of reads does not suffer information loss or heuristic bias be—
cause it is essentially constructed by means of sorting the data in alpha—
betical order. (iii) It is easy to switch from one reference genome to
another one after the dictionary of reads is constructed. However, the
following issues of the proposed approach remain to be addressed.

1. The construction of BWT for large data (more than 100 Gbp) is
very time—consuming even with the fastest known algorithm,
BCRext (Bauer et al., 2011; Cox et al., 2012).

2. A large number of occurrences in the short—read data of a genomic
subsequence with a candidate mutation do not necessarily imply
the existence of the mutation because some of them might be
derived from different genomic regions with similar subsequences.

3. To get useful information from the dictionary of reads, it is ne—
cessary to prepare effective queries that are likely to contain can—
didate mutations. Namely, it is necessary to locate genomic
positions with a signiﬁcant chance of ﬁnding mutations.

To address these issues, the following algorithm and concepts
are introduced in this study.

1. BWT/\X/T, a modiﬁed and parallelized BCRext algorithm for
computing the BWT of reads.

2. The minimum length for uniqueness (MLU), a simple criteria for
evaluating the uniqueness of the subsequence.

3. The fragment depth of coverage (FDC), an estimate of sequenc—
ing depth of coverage on the basis of exact matching of read
fragments at single—base resolution.

2 Dictionary-based approach

2.1 Notations

For any DNA sequence, A : a0a1 - - - aL_1, A[i, 1'] denotes the subse—
quence aiai+1 - - - a,- for 0 g i g j < L, and A denotes the reverse com—
plement. Let C0, C1, . . . , C1_1 be the DNA sequences of chromosomes
(or contigs) in the reference genome, where I is the number of them.
Let G+ = C0$C1$---C1_1$ and G_ = E[_1$ - - -  denote
the concatenations on the positive and negative strand in mutually re—
verse order, where $ denotes a sentinel (punctuation) symbol. The
whole—genome sequence on both strands is represented by
G* : G+G_, and the BWT, denoted by T(G*), is used as the diction—
ary of the reference genome, where the alphabetical order $ < A < C
< G < T < N is assumed and $ does not to match any other symbols,
including itself. Let L be the total length of the genome on a single
strand including the sentinels; namely, L = | GJr | = | G‘ | . For a gen—
omic coordinate, 0 3x < L, the reference base at x on the positive
(negative) strand is given by G*[x] (G*[x]), where x = 2L — 1 — x.
Similarly, a genomic subsequence on the positive (negative) strand of
length equal to E with the left (right) end at x is given by G+(x,E)
: G*[x,x +E — 1] (G_(x,E) : G*[x,x +E — 1]).

Let r1, r2, . .. ,r] be the DNA sequences of the short reads, and
R : r1$r2$ - - - $r]$ be the concatenation, where ] denotes the num—
ber of reads. The BWT of R, denoted by T(R), is used as the diction—
ary of the reads.

For any DNA sequence, w, the number of occurrences of w in
the reference genome and that in the short—read data, denoted by
NGi(w) and NR(u/), are immediately computed from T(G*) and
T(R), respectively, by using rank functions (Gonzalez et al., 2005)
[a.k.a. LF mappings (Ferragina and Manzini, 2000)].

2.2 MLU

The MLU at x in the positive (negative) direction, denoted by 2+
(2_(x)), is defined as the minimum length of the subsequence with
the left (right) end at x, such that the subsequence appears only once
in both strands of the genome. Namely,

ﬁx) 2 min {E|NG*(G:(x,E)) = 1}. (1)

MLU is closely related to the suffix array (SA) and the longest com—
mon prefix (LCP) array (Manber and Myers, 1990) and is thereby
computed efficiently (see Section 3).

MLU varies with position on the genome and mostly takes a
moderate value, except in the case of repetitive or duplicated re—
gions. For example, MLU is 40 or less (more than 100) in 88.2%
(3.9%) of the reference human genome, hg19, excluding long runs
of N with more than 500 Kbp.

2.3 FDC

When a genomic subsequence with the left end at x is taken as a
query, namely, w : G+(x,E), the number of occurrences of w in
short—read data, N R(u/), reﬂects the sequencing depth at x, provided
that the length E is properly chosen. If E is less than 2+ (x), the number
is clearly overestimated because some of the occurrences come from
different positions. If E is equal to 2+ (x), the number is expected to be
a proper estimation of the sequencing depth because of the uniqueness
condition. However, it is in fact prone to be affected by occasional
contributions from reads [with sequencing errors or single—nucleotide
polymorphisms (SNPs)] derived from different genomic regions with
similar sequences. Therefore, E somewhat larger than MLU should be
taken. On the other hand, if E is too large, the number is underesti—
mated because of the finite read length.

The FDC at x in the positive (negative) direction, denoted by dJr
(d_(x)), is defined as the number of occurrences of w in the short—read
data when the length is chosen, such that E 2 2+ —l— or
(E = f  —l— or) for a small positive constant, or. Namely,

61:06) = NR(G(xaE:(x)))a 5:06) = 4:06) + 06- (2)

As is clear from the above definitions, FDC has single—base reso—
lution and is sensitive to direction (Fig. 2a). For example, FDCs in

 

 

 

 

 

 

 

 

A96? Genome Number of Scenario of SNP analysis
2 E occurrences Cases Implications
qo: EATTCTAAGTCE => => n0
  (a) no 3 n1 >>1 Hetero. SNP
‘713 EATTCTEAGTCE => => "1 (b) nO z 0, n1 >>1 Homo. SNP
Genomic subsequence A diCtionarV (c) n0 >> 1, n1 z 0 Not SNP
with/without SNP of reads

 

Fig. 1. Basic concept of dictionary-based SNP analysis. Given a SNP candi-
date on the genome, appropriate genomic subsequences with and without
the SNP, namely, q1 and qo, are chosen as queries. The numbers of occur-
rences of the queries in short read-data, n1 and no, are immediately obtained
from the dictionary of short reads. The candidate is evaluated on the basis of
n1 and no as follows. (a) If both no and n1 are sufficiently large and almost
equal, the candidate is likely to be a heterozygous SNP. (b) If no is sufficiently
small, and n1 is sufficiently large, the candidate is likely to be a homozygous
SNP. (c) Conversely, if no is sufficiently large, and n1 is sufficiently small, the
candidate is likely to be false

112 /§JO'S{eumo [p.IOJXO'SOTlBIHJOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

Ultrafast SNP analysis

1579

 

both directions suddenly drop in the vicinity of a SNP in a character—
istic pattern (Fig. 2b).

Although FDC is an approximation of sequencing depths, it is pro—
gressively underestimated as MLU increases because of the finite read
length. In particular, when MLU is greater than the read length, FDC
is zero and useless. Otherwise, on the assumption that the sequencing
errors are randomly distributed according to a Poisson distribution
with an average frequency of rE per base, the underestimation factor
is given by (1 — Ei /ER)e_’E€:(x), where ER denotes read length.

2.4 Overall scheme

The reference genome sequence and the short—read data are separately
transformed into dictionaries (BWTs). The MLU is computed from the
dictionary of the reference genome sequence alone. The FDC is com—
puted from the dictionary of the short—read data and the MLU. These
precomputations are necessary for genetic—variation analysis down—
stream (Fig. 3a). In contrast, as for the conventional mapping—based ap—
proach, the reference genome sequence is formatted into a convenient
form, which is sometimes implemented by means of BWT (Li and
Durbin, 2009). The short reads are mapped onto the reference genome
using the formatted data, and the results are sorted and indexed accord—
ing to the positions on the genome (Li et al., 2009). These precomputa—
tions are necessary for downstream analysis (Fig. 3b).

In contrast to the mapping—based approach (by which reads are
treated individually), the dictionary—based approach is expected to be
efficient in the downstream—analysis phase because collections of read
fragments with the same sequences can be processed simultaneously.

3 Methods

3.1 Calculation of BWTs

Contigs separated by long runs of N (500 Kbp or more),
C1, C2,  , C1, are extracted from the reference genome sequence,
and the concatenated genome sequence (on both strands), G*, is ob—
tained. In the case of the reference human genome, hg19, I : 47
contigs and G* of length 2L 2 5.75 x 109 are thus obtained. The
BWT and SA of G* are calculated using the induced—sorting algo—
rithm (Nong et al., 2011). The SA—IS code presented in Nong et al.
(2011) is modified, so that it can treat data larger than 4 Gbp and
cope with multiple occurrences of sentinels.

Large short—read data of more than 100 Gbp is beyond the scope
of the induced—sorting algorithm. The BWT of short reads is incre—
mentally calculated from smaller partial BWTs in a cache—oblivious
manner, which basically follows the BCRext algorithm (Bauer et al.,
2011; Cox et al., 2012). The lath partial BWT is defined as the BWT
of le—suffixes of reads, where the le—suffix is a suffix of length la (if the

(a)
depth: d—(x) d+(x)

T T
length:4 a-(x) I a+(x) ‘
‘ 5c 'genome

 

 

 

Fig. 2. FDC has base-level resolution and is sensitive to direction. (a) The
FDCs at X in the positive and negative directions, d+ (X) and d‘ (X), are defined
as the number of occurrences in the short-read data of genomic fragments on
the positive and negative strands starting at xwith length E+(X) and E‘(x),
which are chosen to be larger than MLU: Ei(x) = F(x) + or for a small posi-
tive constant or. (b) The FDC in the positive (negative) direction drops at a SNP
position and in its left (right) vicinity because of the difference between the
reference genome and short reads at the SNP position. The widths of drops
are determined by the MLU and or. The depths of drops are halved when the
SNP is heterozygous

read length is larger than la) or the entire read otherwise. Both of the
partial BWTs and the remaining prefix data are compactly encoded
into wavelet trees (Grossi et al., 2003), resulting in a memory require-
ment of about 0.6N GB for data of N Gbp. The incremental calcula—
tions are executed in parallel according to the first bases of the
suffixes, thus accelerating the calculation three to four times. The
modified BCRext algorithm is hereafter referred to as ‘BWT/WT’.

3.2 Calculation of MLU
The SA of both strands of the reference genome,

SAG. = (SAG. [0], SAG. [1], ... ,SAG.]2L — 1]), (3)

is a permutation of 0,1,  ,2L— 1, such that the sequence of
suffixes,

(G*lSAG* [Ila 2L — 1] )i=0,1,...,2L—1=

is sorted alphabetically (Manber and Myers, 1990). The LCP array
of the genome,

LCPG. : (LCPG. [0], LCPG. [1], ... ,LCPG. [2L — 1]) (4)

is an array of integers, where LCPG*  is the length of the LCP of
suffixes G* [7, 2L] with j : SAG*  and j : SAG* [i — 1] (Manber and
Myers, 1990). The LCP can be efficiently calculated from the SA
and its relatives (Karkkainen et al., 2009). Then, MLU is given by

it (x) = max (LCPG. [5A3 [x]], LCPG. [5A3 [x] + 1]) + 1, (5)
i— (x) = max (LCPG. [5A3 [2]], LCPG. [5A3 [x] + 1]) + 1 (6)

for 0 3x < L, where SAE: denotes the inverse suffix array, i.e. the
inverse permutation of the SA.

All of the values of the MLU are compactly encoded into a bit
array as follows. Since G*(x —l— 1, 2+ (x —l— 1)) occurs exactly once in
both strands of the genome, its leftward one—base extension,
G*(x, 2+ (x —l— 1) —l— 1), occurs at most once in both strands. This fact
implies that

i+(x)gi+(x+1)+1 (ng<L), (7)

and hence 2x —1— 2+ is strictly increasing with x. Similarly,

 

 

 
  
 

 

 

 

 

 

xl_(x)g/l_(x—1)+1 (ng<L), (8)
(a) Short__reads Referencegenome (b) Short__r_eads Reference genome
 :3:- i:\)[l1_ll‘:}‘ '1; {,9 (1)] n)
“ﬁ—Precomputations ﬂ NHPrecomputationsIL .......... I.
BWT<}  BWT<2 Mapping<2  Format
Dictionary  Dictionary  Reference
of reads  of genome results  genome
%  & Sort/index@  data
a  ﬂ
 resu ts  E
V

.......................................  

I Genetic variation analysis I

 

 

I Genetic variation analysis I

 

 

Fig. 3. Comparison of the overall schemes. (a) Proposed approach. The refer-
ence genome sequence is transformed into the dictionary (BWT), and MLU is
calculated. The short-read data are transformed into the dictionary (BWT),
and FDC is calculated from the BWT and MLU. The calculation results are
used in the genetic-variation analysis downstream. (b) Conventional ap-
proach. The reference genome sequence is formatted into a convenient form
(sometimes BWT), and the short reads are mapped onto the reference gen-
ome. The mapping results are sorted and indexed and used in downstream
analysis

112 /§JO'S]eumo [p.IOJXO'SOTlBIHJOJUTOTQ/ﬁdllq 11101; popeoIII/vxoq

9IOZ ‘09 lsnﬁnv uo ::

1580

K.Kimura and A.Koike

 

and hence 2x —1— 27 is strictly decreasing with x. On the basis of
these implications, the MLU values are compactly encoded into bit
array M of length 4L as follows:

1 (y:2x—l—2+(x) forsome0§x<L),
MM 2 1 (y = 2x —1— 2_(x) for some0 3x < L), (9)
0

(otherwise).

Conversely, they are immediately decoded from M as follows:
2+(x) : selectM(x) — 2x, 27 : selectM(x) — 2x (10)

for 0 g x < L, where selectM (i.e., the select function on M) gives
the index of the xth occurrence of a set bit (‘1’) in M (Gonzalez et
al., 2005). The select function is efficiently calculated using the hier-
archical binary strings (HBS) (Kimura et al., 2009).

3.3 Calculation of FDC
The SA of the short reads (only in the direct strand),

SAR = (SARlolasARllla  ,SARlN — 1]): (11)

is a permutation of 0,1,  ,N — 1, such that the sequence of
suffixes,

(RISARlilaN — 1I)i=0,1,...,N—17

is sorted alphabetically, where N is the total length of the short—read
data including sentinels, namely, N : | R | .

For any DNA sequence, w, a collection of all occurrences of w in
the short—read data is represented by the SA interval of w (Li and
Durbin, 2009), [IR(w),IR(u/)], which is defined by

IR(u/) : min{0 3i < N| wisaprefixofR[SAR[i],N — 1]}, (12)

IR(w) : max{0 Si < N| wisaprefixofRISARIi],N —  (13)
The initial value for the empty sequence (w = 8) is given by
[1(8), I(8)] : [0, N — 1]. It is then recursively calculated as follows.

111011”) 2 C(61) + rankT(R)(aa 7R0”) )7 (14)

— 1
IR(aw) = C(a) + rankT(R)(a,IR(w) + 1) (15)

for a = A, C, G, Tand N, where C(a) is the number of bases in R
that are lexicographically smaller than a, and rankT(R)(a, i) is the
number of occurrences of a in T(R)[0, i — 1]. The rank function is ef-
ficiently computed using the HBS.

Then, FDCs are given by the lengths of the SA intervals as
follows:

61:06) = 7R(G:(xaE:(x))) — lR(G:(xaE:(x))) + 1, (16)

for 0 g x < L. Therefore, FDCs are calculated using Equations
(14—16)

Moreover, the calculation is accelerated according to an idea
similar to (Karkkainen et al., 2009). It is common for adjacent pos—
itions, x and xi 1, to have the subsequences, G:(x, E)
and G:(x:1, E), in Equation (1), such that they have the same end
position, namely x:2:(x) : x:1:2:(x:1). Then, d: (x: 1) is re-
ducible in the sense that it is immediately given by Equation (16)
with the known values of IR and IR that are obtained during the cal—
culation of di  using Equations (14—16).

3.4 Search for SNP candidates
Two methods for searching for SNP candidates, namely the drop-
scan method and the step-scan method, are proposed in the

following. As for the drop—scan method, SNPs are searched for only
around significant drops in the precomputed FDC (since they are un—
likely to be found elsewhere). As for the step—scan method, the
whole genome is exhaustively scanned by a sliding window of a
fixed size, and reads with exactly matching subsequences around the
window on either side are collected, and their extensions into the
window are examined to find any SNPs therein. The latter method
does not require the precomputed FDC.

3.4.1 Drop-scan method
A simple criterion for genomic coordinate x to be a significant left—
ward (rightward) drop in the positive (negative) direction is

dum<u—nwo+1)(wqu1—mﬁo—n) on

where 0 < r < 1 is a small constant, referred to as drop ratio.
However, random fluctuations of the FDC may sometimes satisfy
the criteria; besides, reads that are derived from different homolo-
gous genomic regions and altered by SNPs or sequencing errors may
affect the criteria. The criteria are therefore made more stringent by
the additional following procedures (Fig. 4).

1. Take s : G:(x:1,E:(x: 1)), a seed (of a sufﬁcient length) adja—
cent on the right (left) of x, and collect all of its occurrences in
the forward (reverse) reads.

2. Collect all possible leftward (rightward) extensions beyond x in
a sufﬁcient length, E1F (x I]: 1) —l— 1.

3. Align the extensions with the reference genome using a fast dy—
namic programming (DP) algorithm (Kimura et al., 2012).

4. Select valid extensions that have at most nc mismatches or small
indels (insertions or deletions), where no is a positive constant
integer.

5. Find any mismatches or small indels that are repeatedly observed
in the alignments of the valid extensions in at least nm cases and
with a relative frequency of at least r, where nm is a positive con—
stant integer.

6. Filter out any mismatches or small indels that are not found con—
sistently from both strands.

3.4.2 Step-scan method
SNP candidates are located by using a sliding window of fixed
length W along the genome in the following steps (Fig. 5).

depth

  
  
 

d+(x +1)

    
 
 
 
  

 

d +(x)

   
  

—1 +1

(genome)

extenSIODS (short reads)

Fig. 4. Drop-scan method. A leftward drop of the FDC at Xin the positive direc-
tion, such that d+(x) < (1 — r)d+(x +1) is located by scanning the whole gen-
ome, where 0 < r <1 is the drop ratio. For such X, a seed is taken as a
genomic subsequence on the positive strand started at X +1 and with length
equal to E+(X + 1). The occurrences of the seed in the short read-data and all
possible leftward extensions are collected by using the dictionary of short
reads. The extensions (including xand beyond) are aligned with the reference
genome sequence, and repeatedly observed mismatches or small indels are
extracted. Likewise, rightward drops of the FDC in the negative direction are
considered. The mismatches and indels consistently extracted from both dir-
ections are then obtained as SNP candidates

112 /§JO'S]12umo [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Ultrafast SNP analysis

 

 
  

(genome)

sliding windows

(short reads)
extensions

Fig. 5. Step-scan method. The whole-genome region is scanned by a sliding
window of length W at every W/2 bp position. Two adjacent seeds on the
right and left sides, starting, respectively, at X + Wand X — 1, are taken on the
positive and negative strand. Their lengths are, respectively, equal to
E+(X-l- W) and E_(X — 1). The occurrences of the right-hand (left-hand) seed
in the short-read data and all possible leftward (rightward) extensions into
the window are collected by using the dictionary of short reads. The exten-
sions are aligned with the reference genome sequence, and consistent mis-
matches or small indels are extracted as SNP candidates

1. Take a window of length W with the left end at x : kW/Z for
le 2 0, 1,2,  ,[ZL/W].

2. Take s : G+(x —l— W,E+(x —l—  (s : G_(x — 1,E_(x — 1)), a
seed (of a sufﬁcient length) adjacent on the right (left) side of the
window and collect all occurrences of s in the forward (reverse)
reads.

3. Collect all possible leftward (rightward) extensions into the
window.

4. Align the extensions with the reference genome using a fast DP
algorithm.

5. Select valid extensions that have at most nc mismatches or small
indels.

6. Find any mismatches or small indels that are repeatedly observed
in the alignments of the valid extensions in at least nm cases and
with a relative frequency of at least r.

7. Filter out any mismatches or small indels that are not found con—
sistently from both strands.

4 Results and discussion

The dictionary—based methods were implemented in C—l——l— and Perl
for proof—of—concept experiments. The test data included actual bio—
logical data downloaded from public websites and simulation data

(Table 1).

4.1 Precomputation time

The BWT and MLU of both strands of the reference human genome
sequence (hg19) were calculated once, and the calculation results
were stored and reused. The total computation time was 2h and
16min by a single core of an Intel Xeon CPU (X7560, 2.3 GHz);
and the maximum memory usage was 71.3 GB.

The precomputation for short—read data was performed in
parallel; 10 threads were used for the exome and transcrip—
tome sequencing data, and 24 threads were used for the whole—
genome sequencing data. In the case of transcriptome and
genome sequencing data, the computation time was much shorter
than that required by the conventional mapping—based method
(Table 2).

Although the computation time of BWT/\X/ T was almost linear
in relation to the data size, the computation time of FDC was mostly
dominated by the length of the reference genome and was not much
affected by the data size owing to the nature of the dictionary. Thus,
the precomputation time for the smaller data size was largely occu—
pied by the latter time.

 

 

1581
Table 1. Test data for experiments
Data Source Type Size Read length
81 (simulation) Exome 10.0 Gbp 100 bp
E1 SRX043462 Exome 6.7 Gbp 120 bp
E2 SRX253902 Exome 12.4 Gbp 100 bp
E3 SRX5 06949 Exome 16.8 Gbp 100 bp
E4 SRX097050 Exome 22.9 Gbp 101 bp
T1 SRX472980 Transcriptome 6.3 Gbp 100 bp
T2 SRX5 88484 Transcriptome 14.3 Gbp 100 bp
T3 SRX105217 Transcriptome 20.3 Gbp 99 bp
G1 ERX009609 Whole genome 135.3 Gbp 100 bp
G2 ERX069715 Whole genome 137.1 Gbp 100 bp
G3 ERX168840 Whole genome 163.4 Gbp 100 bp

 

Actual biological data were downloaded from the NCBI Sequence Read
Archive. They were paired-ended reads of human samples obtained by
Illumina Genome Analyzer II, IIX and HiSeq 2000. The simulation data were
generated from the human reference genome sequence (hg19) around NCBI
RefSeq coding exons with randomly introduced homozygous and heterozy-
gous SNPs (0.1%) and sequencing errors (1%), each of which consists of sin-
gle-base substitutions (98%), insertions (1%) and deletions (1%); the
insertion lengths of the paired reads were assumed to be distributed normally
with 300-bp mean and 20-bp standard deviation.

Table 2. Comparison of precomputation time for short-read data

 

 

 

Data Dictionary—based method Mapping
basedmethod
BWT/\X/T FDC Total
81 31m225 1h06m49s 1h38m115 41m14s
E1 22m505 1h05m53s 1h28m43s 51m505
E2 33m25s 1h12m29s 1h45m54s 1h57m388
E3 44m385 1h14m285 1h59m06s 2h02m458
E4 1h11m37s 1h14m225 2h25m59s 2h53m058
T1 16m24s 1h03m455 1h20m09s 4h21m01s
T2 32m305 1h10m505 1h43m19s 10h32m518
T3 48m415 1h22m25s 2h11m07s 19h59m558
G1 11h46m19s 1h16m37s 13h02m56s 32h02m33s
G2 11h58m225 1h14m54s 13h13m15s 34h07m408
G3 13h42m13s 1h18m16s 15h00m29s 56h57m17s

 

BWT/\WT and FDC were computed as described in the text. As for the
mapping-based method, BWA 0.7.8 mem (Li and Durbin, 2009) was used for
the exome and genome data, and TopHat 2.0.7 (Kim et al., 2013) was used
for the transcriptome data; conversion into BAM ﬁles, sorting, and merging
was done by SAMtools 0.1.19 (Li et al., 2009). A Linux workstation with a
single CPU (Intel Core i7-4930 K, 3.4GHz) and 64-GB memory was used
with 10 threads in parallel for the exome and transcriptome data; and a Linux
server with double CPUs (Intel Xeon X7560, 2.3 GHz) and 25 6-GB memory
was used with 24 threads in parallel for the genome data.

4.2 Example of FDC plots

Although FDC plots, as illustrated in Figure 2b, are informative
and meaningful, they are usually degraded by noises induced by
randomly matched sequences. However, as parameter or increases, the
noise reduces rapidly, while the signal degrades slowly. Thus, at = 3
was chosen tentatively so as to make the plots clear and sensitive. In
the case of the exome data, the signals were apparently localized
around captured regions and clearly dropped at SNPs. An example
of actual biological data (E1) is shown in Figure 6. Similarly, in the
case of transcriptome data, the signals were apparently localized in-
side exons; besides, considerable amounts of signals and noises,
seemingly to reﬂect complex alternative splicing and other miscellan-
eous transcriptional activities, were also observed. In the case of the

112 /810'S]12umo [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

1582

K.Kimura and A.Koike

 

whole—genome data, copy—number variations and loss of heterogen—
eity were also observed as expected.

4.3 Search for SNP candidates

Parameters nc : 8, nm : 2, r = 0.2 and W = 40 were chosen ex—
perimentally using simulation data (S1), so as to trade—off computa—
tion time and sensitivity. The sensitivities of finding homozygous
and heterozygous single—base substitutions were 94.3% and 93.6%
by the drop—scan method and 94.5% and 94.3% by the step—scan
method. They were slightly smaller than 95.8% and 95.4% attained
by a conventional mapping—based method, GATK (DePristo et al.,
2011). The primary reason for slightly lower sensitivity of the two
proposed methods is thought to be the fact that the methods do not
use full lengths of reads (with paired—end information); instead, they
only use fragments of reads.

It is expected that the sensitivity is prone to decrease as MLU in—
creases. In fact, the sensitivity of the drop—scan method for the simulated
exome data was 99.2% when MLU was at most 40 (93.3% of the cases),
while it decreased to 26.9% when MLU was >40 (6.7% of the cases).

Table 3. Comparison of times for searching for SNPs

 

 

 

Data Dictionary—based method Mapping—based
method (GATK, Picard)
Drop—scan Step—scan

81 1m14s 17m105 3h11m085
E1 1m19s 15m56s 1h40m24s
E2 2m18s 21m305 2h31m37s
E3 2m33s 24m56s 3h13m19s
E4 6m21s 25m34s 12h28m205
T1 2m23s 16m225 2h46m05s
T2 2m315 20m39s 9h35m13s
T3 9m51s 32m485 2h58m13s
G1 19m415 2h23m57s 39h34m19s
G2 20m05s 2h24m17s 41h10m19s
G3 14m24s 2h13m225 44h01m33s

 

Precomputed FDC was used for the drop-scan method but not for the step-
scan method. GenomeAnalysisTK 2.1-8 (DePristo et al., 2011) and Picard
tools 1.77 (http://picard.sourceforge.net/) were used. Each data were com-
puted in parallel with the same number of threads by the same computer as
for Table 2.

Times for searching for SNPs in the whole human genome by
different methods are compared in Table 3. As expected, the
drop—scan method is much faster than the step—scan method, and
the latter is much faster than the conventional mapping—based
method.

The agreement of the results given by the proposed and conven—
tional methods is assessed as follows. It is known that GATK is one
of the most—sensitive mapping—based tools and that the ratio of
agreement of results given by different tools is not generally high
(Pabinger et al., 2014). Therefore, the result given by the proposed
method (the drop—scan method) and that given by GATK confi-
dently (after Q—filtering, where the quality value was not <300) in
less repetitive (with M—filtering, where the MLU was at most 40 bp)
and deeply covered (with D—filtering, where FDCs around the drops
were at least 10) regions were compared (Table 4). As indicated by
the relative sensitivity and specificity of the proposed method on the
assumption that the results given by GATK were correct, high ratios
of agreement were obtained.

100

 

 

 

 

 

SNP: I, . I, I, I,
3'3 ' 1 - ‘3']
eo- _‘|d+(x) . an
111 | I - 7::
rl _
count 50 I” IL 1'] W length
 , f  . l ,1. * St (bp)
4o - l' I: I] I | H I 40
'l l 1"] Hunt".
1'" 'Mx) 21x) 1": .  - ti
an i' . ] I - 2::
  ';: ' ' _  '.-'. .- '_'I: '. "  ' it -
to I  I (I - 11::
0 El I 52"]. : 11:,IEI‘D 15m] II 2000' 2501:?
x (bp)

Fig. 6. MLU and FDC plots in a captured region of exome sequencing data
(E1). The MLUs on the positive and negative strand, 1+(X) and 1‘ (X), along
the right-hand ordinate (in length), and the FDCs on the positive and negative
strand, d+(X)and (II—(X), along the left-hand ordinate (in count), are plotted
against the relative coordinate in a genomic region (chr17:3 100 001-3 102 500
in hg19). The SNP candidates, located at sharp drops of FDCs, are indicated by
downward arrows

Table 4. Agreement of SNPs found by the drop-scan method and the mapping-based method

 

Data Mapping—based

Dictionary—based

Relative accuracy of (a) assuming that (b) is true

 

 

All Q—filtered Q/M—filtered (ratio) Q/IVUD—filteredb D—filtereda TP FP Sensitivity Specificity
81 133 361 106 148 100 977 (95.1%) 79 506 112 303 79 186 79 069 117 99.5% 99.9%
E1 237 562 75 692 68 727 (90.8%) 21 885 67 820 20 689 20 457 232 93.5% 98.9%
E2 442 788 156 336 135 716 (86.8%) 58 027 110 219 51 561 50 585 976 87.2% 98.1%
E3 414 171 103 431 96 204 (93.0%) 41 015 87 588 36 925 36 576 349 89.2% 99.1%
E4 222 419 67 441 61 609 (91.4%) 33 053 85 298 28 234 27 708 526 83.8% 98.1%
T1 112 071 26 742 24 196 (90.5%) 7891 54 324 7894 7099 795 90.0% 89.9%
T2 175 395 44 654 39 570 (88.6%) 18 529 73 207 16 829 15 848 981 85.5% 94.2%
T3 579 699 112 103 103 636 (92.4%) 32 402 275 562 35 005 30 547 4458 94.3% 87.3%
G1 5 043 802 4 522 189 3 817 262 (84.4%) 2 869 000 3 939 619 2 844 998 2 686 923 158 075 93.7% 94.4%
G2 5 102 468 4 608 488 3 884 808 (84.3%) 2 989 489 3 988 886 2 961 803 2 799 135 162 668 93.6% 94.5%
G3 4 289 853 3 915 819 3 264 571 (83.4%) 2 773 595 3 305 833 2 726 082 2 592 566 133 516 93.5% 95.1%

 

Numbers indicate the number of SNP candidates (only for single-base substitutions) found by each method and those ﬁltered under speciﬁed conditions. Q-ﬁlter

removed those with a quality value <300; M-ﬁlter removed those with MLU > 40 and D-ﬁlter removed those with FDC around the drops <10. The mapping-
based results were obtained by GATK 2.1-8, and the dictionary-based results were obtained by the drop-scan method. The Q-ﬁltering eliminates the SNP candi-

dates to which GATK does not give high conﬁdence. The M-ﬁltering eliminates those in regions where the drop-scan method is known to be insensitive. The ratios
of the numbers in the third and fourth columns are given in the ﬁfth column; they are larger in the exome and transcriptome data than in the genome data (see
text). The D-ﬁltering eliminates those in regions where the sequencing coverage is not deep enough. aFinal results given by the dictionary-based method. bFinal

results given by the mapping-based method, tentatively assumed to be correct. (TP: true positives, FP: false positives).

112 /810'S]12umo [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

Ultrafast SNP analysis

1 583

 

The M-filtering eliminates the SNP candidates in regions where
the dictionary—based methods are known to be insensitive. The re—
duction ratios (in the fifth column in Table 4) are generally larger
for the exome and transcriptome data and smaller in the genome
data in comparison to 88.2%, which is the proportion of genomic
regions where MLU is 40 or less. This result seems to be reasonable
because the former data mostly consist of reads from gene regions
where MLU generally takes smaller values and because the latter
data also contain many reads from repetitive regions where MLU is
very large and mutation rate (including SNPs) is relatively high.
Thus, the ratio of useful SNPs that are predicted to be undetectable
by the drop—scan method is estimated to be around 10%.

Similar results to those given in Table 4 were also obtained by
the step—scan method (Supplementary Information, Supplementary
Table S1). The step—scan method generally gives higher relative
accuracy than the drop—scan method for exome and genome
sequencing data but not for transcriptome data. The primary reason
for this lower accuracy in the latter case is thought to be the fact
that the sliding windows often cross the exon boundaries, making it
impossible to start effective searches from either side of the
windows.

5 Conclusion and future works

In contrast to the conventional mapping—based approach, a diction—
ary—based approach to sequence analysis is proposed. It is expected
to be efficient because the dictionary (BWT) of short—read data
makes it possible to simultaneously process collections of read frag—
ments with the same sequences. In particular, SNPs were found from
the dictionary much faster than from the mapping results. It was ex—
perimentally shown that it took only a few minutes to find SNPs
from the BWT and FDC using a desktop workstation in the case of
human exome or transcriptome sequencing data and 20 min using a
double—CPU server in the case of human genome sequencing data.

However, the use of read fragments (instead of full—lengths of
reads with paired—end information) sometimes leads to sensitivity
loss. Such cases are predictable in advance on the basis of MLU and
are estimated to generally occupy about 10% of the cases; therefore,
the proposed approach should be taken only in the majority of other
cases.

The SNPs obtained by the proposed methods mostly agreed with
those obtained by a time—consuming state—of—the—art tool, except for
the cases in which loss of sensitivity was predicted in advance on the
basis of MLU or sequencing depth was estimated to be low on the
basis of FDC.

The dictionary of short—read data was computed in less time
than it took to map them onto a reference genome and to sort the
mapping results along the genome, provided that the data was large
enough. It was free from heuristic bias or information loss, unlike
the mapping results. Since it does not depend on any particular refer—
ence genome sequence, the dictionary—based approach will be ad—
vantageous when multiple reference sequences are available.

Although this study focuses exclusively on SNP analysis, it is
clear that the proposed approach is generally applicable to many
other kinds of sequence analysis. In particular, straightforward and
promising applications include:

1. Alternative splicing analysis of transcriptome data

a. Sensitive detection of different combinations of exon junc-
tions by means of consulting the dictionary of reads.

b. Detection of novel alternative exons from FDC plots.
2. Structural variation analysis of genome data

a. Sensitive detection of split reads (across break points associ—
ated with deletions or translocations) by means of consulting
the dictionary of reads.

b. Identiﬁcation of insertions as extensions (by repeatedly
performing LF mappings on the dictionary of reads) from
partially mapped read fragments.

c. Copy number variation analysis on the basis of FDC plots.

MLU will be useful to avoid false detections in many of these
applications.

Conﬂict of Interest: none declared.

References

Bauer,M.]. et al. (2011). Lightweight BWT construction for very large string
collections. In: Giancarlo,R. and Manzini,G. (eds) Combinatorial Pattern
Matching, volume 6661 of Lecture Notes in Computer Science. Springer,
Berlin, pp. 219—231.

Burrows,M. and Wheeler,D.]. (1994). A block-sorting loss-less data compres-
sion algorithm. SRC Res. Rep., 124.

Cox,A.]. et al. (2012). Large-scale compression of genomic sequence databases
with the Burrows-Wheeler transform. Bioinformatics, 28, 1415—1419.

DePristo,M.A. et al. (2011). A framework for variation discovery and geno-
typing using next-generation DNA sequencing data. Nat. Genet., 43,
491—498.

Ferragina,P. and Manzini,G. (2000). Opportunistic data structures with appli-
cations. In: Proceedings of the 415t Annual Symposium on Foundations of
Computer Science, Redondo Beach, 2000, IEEE, pp. 390—398.

Gonzalez,R. et al. (2005). Practical implementation of rank and select queries.
In: Proceedings of the 4th International Workshop on Experimental and
Efﬁcient Algorithms (WEA’05), Santorini, 2005, pp. 27—38.

Grossi,R. et al. (2003). High-order entropy-compressed text indexes. In:
Proceedings of the Fourteenth Annual ACM—SIAM Symposium on Discrete
Algorithms, SODA ’03, Baltimore, 2003, pp. 841—850. Society for
Industrial and Applied Mathematics, Philadelphia, PA.

Karkkainen,]. et al. (2009). Permuted longest-common-preﬁx array. In:
Kucherov,G. and Ukkonen,E. (eds.) Combinatorial Pattern Matching,
volume 5577 of Lecture Notes in Computer Science. Springer, Berlin,
pp. 181—192.

Kim,D. et al. (2013). Tophat2: accurate alignment of transcriptomes in the
presence of insertions, deletions and gene fusions. Genome B iol., 14, 1—13.
Kimura,K. et al. (2009). Computation of rank and select functions on hier-
archical binary string and its application to genome mapping problems for

short-read DNA sequences]. Comput. Biol., 16, 1601—1613.

Kimura,K. et al. (2012). A bit-parallel dynamic programming algorithm suit-
able for DNA sequence alignment. ]. Bioinform. Comput. Biol., 10,
1250002.

Li,H. and Durbin,R. (2009). Fast and accurate short read alignment with
Burrows-Wheeler transform. B ioinformatics, 25, 1754—1760.

Li,H. et al. (2009). The sequence alignment/map format and samtools.
Bioinformatics, 25 , 2078—2079.

Manber,U. and Myers,G. (1990). Sufﬁx arrays: a new method for on-line
string searches. In: Proceedings of the First Annual ACM—SIAM Symposium
on Discrete Algorithms, SODA ’90, pp. 319—327. Society for Industrial and
Applied Mathematics, Philadelphia, PA, USA.

Nong,G. et al. (2011). Two efﬁcient algorithms for linear time sufﬁx array
construction. IEEE Trans. Comput., 60, 1471—1484.

Pabinger,S. et al. (2014). A survey of tools for variant analysis of next-
generation genome sequencing data. Brief. B ioinform., 15, 25 6—278.

112 /810'S]12umo [p.IOJXO'SOTlBIIIJOJUTOTQ/ﬁdllq 111011 pop1201umoq

9IOZ ‘09 lsnﬁnv uo ::

