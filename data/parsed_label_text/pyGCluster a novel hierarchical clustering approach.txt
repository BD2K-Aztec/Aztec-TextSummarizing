pyGCluster is a clustering algorithm focusing on noise injection for subsequent cluster validation. The reproducibility of a large amount of clusters obtained with agglomerative hierarchical clustering is assessed. Furthermore, a multitude of different distance-linkage combinations are evaluated. Finally, highly reproducible clusters are meta-clustered into communities. Graphical illustration of the results as node and expression maps is implemented. Availability and implementation: pyGCluster requires Python 2.7, it is freely available at http://pyGCluster.github.io and published under MIT license. Dependencies are NumPy, SciPy and optionally fastcluster and rpy2.
INTRODUCTION'Omics' technologies yield large data sets, which are commonly subjected to cluster analysis to organize them into comprehensible, i.e. coregulated groups, which might be functionally related (). A critical step in cluster analysis is cluster validation (), the most stringent form of validation being the assessment of exact reproducibility of a cluster in the light of the uncertainty of the data. This issue is addressed by pyGCluster, an algorithm working in two steps. First, it creates many agglomerative hierarchical clusterings (AHCs) of the input data by injecting noise based on the uncertainty of the data and clusters them using different distance linkage combinations (DLCs). Second, pyGCluster creates a meta-clustering, i.e. clustering of the resulting highly reproducible clusters into communities to gain a most complete representation of common patterns in the data. Communities are defined as sets of clusters with a specific pairwise overlap. The first key concept is based on the importance of the uncertainty in the data set, which can be assessed by biological and/or technical repetitions. Classical bootstrapping offers a way to include the repetitions to estimate the uncertainties of the data points. For example, one could cluster each repetition separately, and clusters consistently formed would be highly reliable. However, a more refined approach would be to use the repetitions to derive the shape of the value distributions. These shapes and their describing functions can be used to define the noise injecting function in pyGCluster that allows a new data set to be generated during each iteration. The second key concept is the evaluation of different DLCs. Although all clustering algorithms require a method to calculate the distance, i.e. a similarity metric between objects, the linkage method is specific for AHC. In a classical AHC approach, one has to define a specific distance metric (e.g. correlation, aiming at relative distances) and linkage method, albeit other distance metrics (e.g. Euclidean, aiming at absolute distances) and linkage methods may also yield interesting clusters. Using a variety of different DLCs results in a broader result spectrum and in a reduction of user bias in data evaluation. These key concepts coupled with high numbers of iterations and meta-clustering of highly reproducible clusters into communities make pyGCluster a novel hierarchical clustering approach. approach with a specifically developed distance metric (1) and complete linkage. Complete linkage was chosen because it insures that all clusters or meta-clusters have overlapping objects. The distance between two objects i and j is defined as follows:disti, j  root j j 1, if i orj root root j j, if i\j max i j j, j j j 5 minimal required overlap max i j j, j   i \ j