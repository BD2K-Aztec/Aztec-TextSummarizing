Motivation: The identification of drug–target interaction (DTI) represents a costly and time-consuming step in drug discovery and design. Computational methods capable of predicting reliable DTI play an important role in the field. Recently, recommendation methods relying on network-based inference (NBI) have been proposed. However, such approaches implement naive topology-based inference and do not take into account important features within the drug–target domain. Results: In this article, we present a new NBI method, called domain tuned-hybrid (DT-Hybrid), which extends a well-established recommendation technique by domain-based knowledge including drug and target similarity. DT-Hybrid has been extensively tested using the last version of an experimentally validated DTI database obtained from DrugBank. Comparison with other recently proposed NBI methods clearly shows that DT-Hybrid is capable of predicting more reliable DTIs. Availability: DT-Hybrid has been developed in R and it is available, along with all the results on the predictions, through an R package at the following
INTRODUCTIONDetecting and verifying new connections among drugs and targets is a costly process. From a historical point of view, the pharmaceutical chemist's approach has been commonly focused on the development of compounds acting against particular families of 'druggable' proteins (). Drugs act by binding to specific proteins, hence changing their biochemical and/or biophysical activities, with many consequences on various functions. Furthermore, because proteins operate as part of highly interconnected cellular networks (i.e. the interactome networks), the 'one gene, one drug, one disease' paradigm has been challenged in many cases (). For this reason, the concept of polypharmacology has been raised for those drugs acting on multiple targets rather than a single one (). These polypharmacological features of drugs bring a wealth of knowledge and enable us to understand drug side effects or find their new uses, namely, drug repositioning (). Nevertheless, many interactions are still unknown, and given the significant amount of resources needed for in situ experimentation, it is necessary to develop algorithmic methodologies allowing the prediction of new and significant relationships among elements interacting at the process level. In the literature, several computational tools have been proposed to afford the problem of DTI prediction and drug repositioning. Traditional methods rely either on ligand-based or receptorbased approaches. Among ligand-based methods, we can cite quantitative structure-activity relationships, and a similarity search-based approach (). On the other hand, receptor-based methods, such as reverse docking, have also been applied in drugtarget (DT) binding affinity prediction, DTI prediction and drug repositioning (). However, the latter have the shortcoming that cannot be used for targets whose 3D structures are unknown. Recently, much attention has been devoted to network-based and phenotype-based approaches. Most of these methods rely on the successful idea of using bipartite graphs. In, a bipartite graph linking US Food and Drug Administration-approved drugs to proteins by DT binary associations is exploited.identified new DTIs using side effect similarity.make use of transcriptional responses, predicted and validated new drug modes of action and drug repositioning. Recently,have presented drug repositioning methods exploiting public gene expression data. Furthermore,developed a bipartite graph learning method to predict DTI by integrating chemical and genomic data.present a technique based on network-based inference (NBI) implementing a naive version of the algorithm proposed by. All these results clearly show the good performance of this approach. On the other hand, knowledge about drug and protein domain is not properly exploited. vanuse a machine learning method starting from a DTI network to predict new ones with high accuracy. The calculation of the new interactions is done through the regularized least squares algorithm. The regularized least squares algorithm is trained using a kernel (GIPGaussian interaction profile) that summarizes the information in the network. The authors developed variants of the original kernel by *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com taking into account chemical and genomic information. This improved the accuracy, in particular for small datasets.introduced their Network-based Random Walk with Restart on the Heterogeneous network (NRWRH) algorithm predicting new interactions between drugs and targets by means of a model based on a random walk with a restart in a 'heterogeneous' network. The model is constructed by extending the network of DTI interactions with drugdrug and proteinprotein similarity networks. This methodology shows excellent performance in predicting new interactions. However, its disadvantage is due to its random nature, mainly caused by the initial probabilities selection.proposed the Bipartite Local ModelInteraction-profile Inferring (BLM-NII) algorithm. Interactions between drugs and targets are deduced by training a classifier (i.e. support vector machine or regularized least square). This is achieved by exploiting interaction information, drug and target similarities. This classifier is appropriately extended to include knowledge on new drug/target candidates. This is used to predict the new target probability of a specific drug. The algorithm is highly reliable in predicting interactions between new drug/target candidates. On the other hand, its capability of training several distinct classifiers to obtain the final model is not strong enough. In this present article, we propose a novel method called domain tuned-hybrid (DT-Hybrid). It extends the NBI algorithm proposed inand applied in Cheng et al.(2012) by adding application domain knowledge. Similarity among drugs and targets is plugged into the model. Despite its simplicity, the technique provides a complete and functional framework for in silico prediction of drug and target relationships. To demonstrate the reliability of the method, we conducted a wide experimental analysis using four benchmark datasets drawn from DrugBank. We compared our method with the one proposed by. The experiments clearly show that DT-Hybrid overcomes the problems shown by the naive NBI algorithm, and it is capable of producing higher quality predictions.
CONCLUSIONDT-Hybrid is a technique proposed for the prediction of new interactions between small molecules. Thanks to the domain-dependent additional knowledge, it clearly outperforms the NBI algorithm for DTI prediction. DT-Hybrid integrates biological knowledge and the bipartite interaction network into a unified framework. This yields high quality and consistent interaction prediction, allowing a speedup of the experimental. Comparison of DT-Hybrid, Hybrid, and NBI through the precision and recall enhancement metric, and the average area under ROC curve (AUC) calculated for each of the four datasets listed inPrecision enhancementNote: The results were obtained using the optimal values for and parameters as shown in the supporting materials. We set for both Hybrid and DT-Hybrid  0:5. Concerning the parameter, we have the following setting: enzymes  0:4; ion channels  0:3; GPCRs  0:2; nuclear receptors  0:4. Bold values represents best results.