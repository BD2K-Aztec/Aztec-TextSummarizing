Motivation: Accurate large-scale phenotyping has recently gained considerable importance in biology. For example, in genome-wide association studies technological advances have rendered genotyping cheap, leaving phenotype acquisition as the major bottleneck. Automatic image analysis is one major strategy to phenotype individuals in large numbers. Current approaches for visual phenotyping focus predominantly on summarizing statistics and geometric measures, such as height and width of an individual, or color histograms and patterns. However, more subtle, but biologically informative phenotypes, such as the local deformation of the shape of an individual with respect to the population mean cannot be automatically extracted and quantified by current techniques. Results: We propose a probabilistic machine learning model that allows for the extraction of deformation phenotypes from biological images, making them available as quantitative traits for downstream analysis. Our approach jointly models a collection of images using a learned common template that is mapped onto each image through a deformable smooth transformation. In a case study, we analyze the shape deformations of 388 guppy fish (Poecilia reticulata). We find that the flexible shape phenotypes our model extracts are complementary to basic geometric measures. Moreover, these quantitative traits assort the observations into distinct groups and can be mapped to polymorphic genetic loci of the sample set.
INTRODUCTIONWith the advent of high-throughput genotyping techniques an unprecedented breadth of genotypic datasets can be generated, opening doors to large-scale association studies, promising sufficient power to understand the genetic underpinning of more subtle phenotypes that characterize the sample. As phenotyping often * To whom correspondence should be addressed. requires manual labor and expert knowledge, a major bottleneck now lies with the identification and quantification of informative traits. Currently, the quantification of phenotypic traits is predominantly done in a semi-manual fashion, rendering the task of analyzing large datasets expensive, time-consuming and error-prone. In order to address these shortcomings, the automated analysis of biological images has become a staple in modern biology. High-throughput imaging techniques for various types of microscopy and other imaging modalities have become common in the experimental environment. Automated image analysis for bioimaging attempts to deal with the flood of data and subsumes a large variety of tasks and methods; for a comprehensive review, see Peng (2008) and. Common tasks include the counting of cells in microscopy images and differential analysis of distinct cell types (). Key challenges in bioimage informatics stem from the breadth and individuality of natural variation within these images and dealing with the inherent noise in biological imaging tasks. In order to deal with these factors, machine learning techniques have raised considerable attention and are used to tackle various complicated tasks in realistic settings (). For example, in the analysis of appearance phenotypes machine vision has been used to quantify the extent of existence of predefined visual features or detect interesting appearance features that characterize the data (). Visual appearance features usually pertain to specific local properties of the depicted objects. However, more general visual phenotypes often are also biologically informative, such as the description of the shape of an object and the quantification of global (including size and height) as well as local (i.e. locally deformed parts of an image) shape variations. An example where such a method is useful is the characterization of the shapes of guppy fish, which so far can only be analyzed by labor-intensive manual geometric phenotype measurements on hundreds of fish, as performed in (). Our goal is to automatically determine and quantify differences among observed shapes in biological images in order to interpret them as shape phenotypes and facilitate downstream analysis, for instance association tests of traits with putative causal factors in the genome. In this work, we propose an unsupervised machine learning method to quantify shape variations of a given object class depictedin a set of images, one per individual or sample. We postulate the existence of an unobserved reference shape, called a template. We proceed with joint learning of this shared template and the imagespecific shape deviation from this reference, allowing every image to be aligned to it. The resulting template iteratively converges to an idealized mean image from which the observed images are generated through deformation fields that explain the variation in shape of each image (). The converged model can also be run backwards, yielding a reconstruction of every image from the template and the mapping fields (R in). The general task of aligning two or more images is also known as registration, where a correspondence between pixels of one image and pixels of another image is established. For exampleperform a simpler form of registration, where images are aligned to a known template. In contrast to previous studies, our method does not require explicit knowledge of the template a priori; neither is supervision like setting of landmarks or outline selection/binarization on each image required. Instead, ShapePheno discovers and objectively quantifies deformation phenotypes on unannotated images in a fully unsupervised fashion while retaining interpretable features and results. Thus, our approach facilitates obtaining accurate non-trivial measurements on large datasets where human labor is costly and error-prone. In Section 3, we present a case study of our method on guppy fish, Poecilia reticulata. The individuals in this dataset are subject to variation in appearance and shape. Interestingly, both appearance and shape variability have previously been shown to exhibit considerable genetic components (). In Section 3.3, we describe the basic approach of quantifying shape phenotypes using our model. We demonstrate that these quantitative traits are orthogonal to traditional geometric measures (Section 3.4) and show practical utility of these traits in the context of two fundamental types of downstream analyses. First, in Section 3.5, we show how learned shape features allow for grouping the observed images into plausible similarly shaped or deformed subgroups based on characteristic deformation patterns. Second, in Section 3.6, we show that quantitative shape phenotypes can be associated to variable genetic loci in the guppy genome. This analysis serves both as a step towards obtaining further knowledge as to the underlying biological processes that lead to variation of these phenotypes as well as a natural validation step, suggesting that the automatically determined phenotypes are biologically relevant.
DISCUSSIONWe have proposed a generative probabilistic model that extracts deformation phenotypes by registering images to a latent, learned template in an unsupervised fashion. Our method presents a novel, clean framework for researchers to quantify and describe subtle local deformation patterns and use them for downstream analyses, like clustering or genetic association tests. We applied our method to a bioimaging task, where we discovered significant deformation patterns in images of guppy fish. We also showed that ShapePheno can be used for automated quantification of geometric measurements and showed good correspondence to manually labeled data. More important than accurate geometric traits, ShapePheno yielded deformation fields that characterize the variability in shape and could be used to identify low-rank PCA factors. Genome-wide association plot, showing the association strengths with the first two PCA-deformation phenotypes corresponding to the X and Y direction. The significance threshold of 10% false discovery rate (FDR) is shown as thin line in the diagram. SNPs are plotted in order of linkage groups, while significant hits on LG12 as described in Section 3.6 are highlighted. LG13 contains markers with function in sex determination yielding additional informative peaks for shape determination. of shape variability. While simple distance measurements intercorrelate strongly, the deformation phenotypes we propose describe orthogonal shape factors and are thus novel holistic descriptors of shape. We showed practical utility of these PCA-deformation phenotypes in the context of clustering, grouping the data into clusters exhibiting characteristic deformation. We also performed a GWAs with the same traits, which yielded biologically sound results in agreement with previous results on geometric approximations of shape (seeand unpublished observations of C.D.). We are convinced that comprehensive genomic analyses on larger datasets can be performed by using this method with a rigorous treatment of image acquisition, higher image resolution and higher marker density. Unsupervised extraction and quantification of subtle morphological phenotypes, as done here, is the logical next step in automated image analysis. The relevance of these new types of methods is expected to rise quickly as dataset sizes increase, providing the necessary statistical power to identify and quantify complex phenotypic variation.