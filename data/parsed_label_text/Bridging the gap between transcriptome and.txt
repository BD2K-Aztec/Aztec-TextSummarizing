Motivation: Despite much dynamical cellular behaviour being achieved by accurate regulation of protein concentrations, messenger RNA abundances, measured by microarray technology, and more recently by deep sequencing techniques, are widely used as proxies for protein measurements. Although for some species and under some conditions, there is good correlation between transcriptome and prote-ome level measurements, such correlation is by no means universal due to post-transcriptional and post-translational regulation, both of which are highly prevalent in cells. Here, we seek to develop a data-driven machine learning approach to bridging the gap between these two levels of high-throughput omic measurements on Saccharomyces cerevisiae and deploy the model in a novel way to uncover mRNA-protein pairs that are candidates for post-translational regulation. Results: The application of feature selection by sparsity inducing regression (l 1 norm regularization) leads to a stable set of features: i.e. mRNA, ribosomal occupancy, ribosome density, tRNA adaptation index and codon bias while achieving a feature reduction from 37 to 5. A linear predictor used with these features is capable of predicting protein concentrations fairly accurately (R 2 Â¼ 0:86). Proteins whose concentration cannot be predicted accurately, taken as outliers with respect to the predictor, are shown to have annotation evidence of post-translational modification, significantly more than random subsets of similar size P50:02. In a data mining sense, this work also shows a wider point that outliers with respect to a learning method can carry meaningful information about a problem domain.
INTRODUCTIONThe analysis of high-throughput experimental data has played a dominant role in biological research over the last decade or so. Advances in instrumentation, coupled with our ability to archive and share data, have revolutionized the way one approaches biological problems, more at a systems level than at the individual component level. Terabytes of data from thousands of experiments at the transcriptome, proteome and metabolome levels are now available along with metadata corresponding to the primary scientific question. There is, however, a massive skew in the amount of interest shown across the above omic scales, gene expression measurements made with microarray technology being highly dominant with respect to the other two. The rapid take-up of this technology by the experimental community, the monotonic reduction in cost of arrays and the early establishment of data archiving initiatives () have led to a large community-wide focus on the transcriptome. Functional inference about co-regulated genes or genes along a signalling pathway (), disease state classification focusing at the molecular level subtypes (), subspace projections () and the reconstruction of regulatory networks () have been a number of notable success stories with transcriptome-level studies. However, the transcriptome itself can, at best, give an approximate picture of cellular state and function. Useful biological phenomena such as dynamic cellular function and differential spatiotemporal behaviours arise from quantitatively and precisely regulating protein levels. Such behaviours arising from protein-level regulations have been modelled extensively by mathematical and computational models. Examples include controlled progression through the cell cycle (), transcription delay-driven oscillations () and spatial selectivity in morphogenesis (). Several authors have evaluated the correlation between mRNA measurements and the corresponding protein measurements () and report varying levels of correlation.have developed a machine learning-based predictor of protein concentrations, which takes a different approach to previous research. In addition to mRNA levels, they construct a dataset with several properties of mRNAprotein pairs and train a linear predictor to predict protein levels. They carry out a greedy feature selection procedure to select a subset of relevant features. By this process,achieved a correlation of 0.76 between the true concentrations and the corresponding linear predictions. Their greedy feature selection approach selects three input features as relevant predictors:(i) mRNA levels; (ii) tRNA adaptation index (tAI); and (iii) evolutionary rate (ER), determined by rate of evolution of a gene by comparison with orthologous in other organisms. Data-driven models have been used extensively in the analysis of genomic data. Clustering, classification and time series analysis of microarray data have been carried out by several authors. Probabilistic approaches such as coupled mixture model with clustering () and Bayesian model () on transcriptomic and proteomic expressions investigate the relationship between these measurements. An approach that has not attracted much usage in genomic data *To whom correspondence should be addressed. analysis is novelty detection, in which one builds a statistical model of normal data and tests these against newly arriving abnormal data. The basic premise in such an approach is that when a data-driven model is applied to data, examples (or subsets of data) on which the model fails will also be informative. We build on this notion and, by seeking to develop a predictor of protein concentrations in the same spirit as in previous work (), identify mRNAprotein pairs that are novel with respect to the performance of such a predictor. We construct a data-driven linear predictor of protein concentrations, using as input mRNA concentrations and other proxy variables that can potentially regulate protein levels. Once we construct such a predictor, we look for systematic errors made by the predictor; i.e. we hypothesize that those mRNAprotein pairs for which construction of a data-driven predictor is difficult and also predicted protein abundance is lower than the measured abundance, are likely candidates for post-translational regulation. This follows from the fact that the input features used in constructing a regressor have no information pertaining to post-translational modifications (PTMs). Post-translational regulation of proteins is important in many biological processes. For example,demonstrate significant response variations at the translational level, decoupled from the transcriptional level, of mammalian cells under various stimuli. O'show that animal and plant cells have prominent post-translational contributions to timekeeping with respect to biochemical oscillations. Further, powerful computational models are also being applied to correcting measurements of post-translationally modified proteins (). PTMs are known to be triggers of intracellular proteolytic degradation (). In vivo stability of proteins can be substantially influenced by specific amino acid substitutions. PTMs such as phosphorylation and acetylation can act as proxies for such mutations by attachments at specific local sites, increasing the susceptibility of the protein to proteinase action (). Localized PTMs, such as methylation, can be equivalent to site-specific amino acid substitutions, affecting the degradation rate of proteins ()., reviewing PTMs, suggest that glycosylation (glycoprotein) and N-link acetylation influence protein stability. They also claim modifications caused by isopeptide bond formations with members of the ubiquitine family can be implicated in protein turnover, post-translationally. Swaney et al.'s (2013) study shows that phosphorylation machinery can be regulated by ubiquitination. Further, motif information on determinants of protein stability and degradation under PTMs is often available. The presence of PEST motif sequences located in flexible regions accelerates degradation under phosphorylation (). N-terminus segments act as degradation signals in cellular proteins. Thus, N-actelylation with N-acetyltransferase segments is directly involved in protein degradation process (). D and KEN Box motifs signal the anaphase promoting complex machinery that leads to ubiquitination and subsequent protein degradation (). The previously mentioned are observations we will exploit to confirm that proteins found by our novelty-detection framework are likely candidates for post-translational regulation of their concentrations (see Section 3). This article makes two contributions to data-driven modelling at the transcriptomeproteome interface. First, the linear regression with sparsity inducing regularization (LASSO) method can identify features that are relevant to a prediction problem. This, in the context of computational biology problems, is an alternate approach to the often used greedy forward selection of features. The accuracy of prediction of protein concentrations shows improvement over previous efforts at this problem. Second, model failures carry useful information, and this is demonstrated by identifying genes whose predicted protein concentrations are outliers () with respect to predictions obtained by a global regression. These are confirmed by checking functional annotations.