Motivation: In the noisy cellular environment, stochastic fluctuations at the molecular level manifest as cellâ€“cell variability at the population level that is quantifiable using high-throughput single-cell measurements. Such variability is rich with information about the cells underlying gene regulatory networks, their architecture and the parameters of the biochemical reactions at their core. Results: We report a novel method, called Inference for Networks of Stochastic Interactions among Genes using High-Throughput data (INSIGHT), for systematically combining high-throughput time-course flow cytometry measurements with computer-generated stochastic simulations of candidate gene network models to infer the networks stochastic model and all its parameters. By exploiting the mathematical relationships between experimental and simulated population histograms, INSIGHT achieves scalability, efficiency and accuracy while entirely avoiding approximate stochastic methods. We demonstrate our method on a synthetic gene network in bacteria and show that a detailed mechanistic model of this network can be estimated with high accuracy and high efficiency. Our method is completely general and can be used to infer models of signal-activated gene networks in any organism based solely on flow cytometry data and stochastic simulations.
INTRODUCTIONGene regulation has been long recognized as an intrinsically stochastic process (). The possibly low copy numbers of the molecules involved, together with their random motion inside the cell, can cause genetically identical organisms to display different phenotypes based on variability alone (). Ongoing progress in single cells measurement techniques is producing highthroughput datasets that allow for an increasingly accurate characterization of such variability.Stochastic computational models of gene regulation can be of great assistance in processing large amounts of experimental data and extracting information from it. The framework of stochastic chemical kinetics () has been successfully used to develop predictive models of systems in which random fluctuations are important (). Although models of this type cannot be solved directly, except for small-dimensional cases (), they can be simulated exactly for however long and however many times is necessary to obtain the desired statistical information (). However, stochastic simulations are computationally expensive; therefore, estimating distributions or computing summary statistics to a high accuracy can be prohibitive. Alternatively, one can resort to more compact approximate descriptions of the stochastic models, which are easier to simulate, but introduce additional error and are not applicable in all cases (). Computational models have proven to be a valuable tool in advancing the understanding of complex biological phenomena and in assisting the design of synthetic gene networks (). Ideally, models should be able to recapitulate the known experimental observations on a process of interest and to generate new insights, which are in turn testable in new experiments. Even when pathway structure inference is able to identify the key players in the process under study, and their interactions (), to build a complete model, one critical challenge must be overcome: the determination of the many unknown parameters that will inevitably appear in it. These are numbers such as production and degradation rates, binding affinities and so forth, which are difficult to measure directly. Usually, the only available option is to measure other variables involved in the models, such as abundances of proteins of interest, and to use these measurements to infer the parameters indirectly using a dedicated computational procedure. The problem of parameter inference for stochastic gene network models has attracted much interest in recent years, and a number of solutions have been proposed. In maximum-likelihood approaches, one tries to select the parameter values that maximize the probability that the model generates the observed experimental data. This has been achieved using approximations (), stochastic simulations () and by direct solution of the stochastic models (). Maximum-likelihood *To whom correspondence should be addressed.  The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com techniques have been demonstrated on biological examples, albeit on relatively small-dimensional models. Bayesian methods represent another attractive option. Unlike the maximum-likelihood ones, these algorithms can find many parameter values that are compatible with the experimental data, thereby producing not only point estimates but also confidence intervals. The issues related to computational cost, however, become even more severe in this case because Bayesian methods operate by testing a large number of candidate parameter values. For each candidate, many simulations are needed to determine whether the model output is consistent with the data. Consequently, the Bayesian framework has been mostly applied to approximate models (). Simulation-based methods have also been proposed () and applied with success (). In the present study, we extend their applicability to higher-dimensional stochastic chemical reaction networks by exploiting the properties of flow cytometry and other high-throughput datasets to significantly improve the computational efficiency of the inference process.