Motivation: Error correction is critical to the success of next-generation sequencing applications, such as resequencing and de novo genome sequencing. It is especially important for high-throughput short-read sequencing, where reads are much shorter and more abundant, and errors more frequent than in traditional Sanger sequencing. Processing massive numbers of short reads with existing error correction methods is both compute and memory intensive, yet the results are far from satisfactory when applied to real datasets. Results: We present a novel approach, termed Reptile, for error correction in short-read data from next-generation sequencing. Reptile works with the spectrum of k-mers from the input reads, and corrects errors by simultaneously examining: (i) Hamming distance-based correction possibilities for potentially erroneous k-mers; and (ii) neighboring k-mers from the same read for correct contextual information. By not needing to store input data, Reptile has the favorable property that it can handle data that does not fit in main memory. In addition to sequence data, Reptile can make use of available quality score information. Our experiments show that Reptile outperforms previous methods in the percentage of errors removed from the data and the accuracy in true base assignment. In addition, a significant reduction in run time and memory usage have been achieved compared with previous methods, making it more practical for short-read error correction when sampling larger genomes. Availability: Reptile is implemented in C++ and is available through the link: http://aluru-sun.
INTRODUCTIONHigh-throughput sequencing is profoundly changing the way genetics data are collected, stored and processed (). The advantages of the new technology have led to revitalization of old techniques and discovery of novel uses, with growing applications in resequencing, de novo genome assembly, metagenomics and beyond (). New technology inevitably comes with challenges. For many next-generation sequencers, the advantage of deeper and cheaper * To whom correspondence should be addressed. coverage comes at the cost of shorter reads with higher error rates compared with the Sanger sequencing they replace. Genome assembly, the de novo inference of a genome without the aid of a reference genome, is challenging. Sanger reads, typically 7001000 bp in length, are long enough for overlaps to be reliable indicators of genomic co-location, which are used in the overlap-layout-consensus approach for genome assembly. However, this approach does poorly with the much shorter reads of many next-generation sequencing platforms (e.g. 35100 bp for Illumina Genome Analyzer II). In this context, de Bruijn graph () and string graph () based formulations that reconstruct the genome as a path in a graph perform better due to their more global analysis and ability to naturally accommodate paired read information. As a result, they have become de facto models for building short-read genome assemblers, e.g. ALLPATHS (), Velvet (), ABySS () and Yaga (). Error correction has long been recognized as a critical and difficult part of these graph-based assemblers. It also has significant impact in other next-generation sequencing applications such as resequencing. We give a brief review of several well-known error correction methods. Alignment-based error correction methods, such as MisEd () for Sanger reads, require refined multiple read alignments and assume unusually isolated bases to be read errors. Like the Sanger-motivated assembly algorithms, these approaches do not adapt well to short reads. Hence,proposed the spectral alignment problem (SAP): in a given dataset, a kmer is considered solid if its multiplicity exceeds a threshold, and insolid otherwise. Reads containing insolid kmers are corrected using a minimum number of edit operations so that they contain only solid kmers post-correction. Similar approaches have been adapted and used by others (). To overcome the typically long run times of SAP-based approaches,proposed SHREC, a method based on a generalized suffix tree constructed from short-read data using both forward and reverse complementary strands. SHREC compares the multiplicity of a substring, represented by a node in the suffix tree, with its expected frequency of occurrence calculated analytically, assuming uniform sampling of the genome and uniformly distributed sequencing errors. The nodes with observed counts that deviate beyond a tolerable threshold from their expected values are considered erroneous. An erroneous node is corrected to a sibling when applicable, and all its descendants are transferred to the selected sibling. Well-engineered code is necessary to cope with the largePage: 2527 25262533
DISCUSSIONThe proposed error correction algorithm is conservative because it avoids changing bases unless there is a compelling underrepresentation of a tile compared with its d-mutant tiles. Actual errors in read r cannot be corrected if r occurs in a very low coverage region of the genome or there exist multiple candidate d-mutant tiles, probably because of genome repetition. On the other hand, a tile may be miscorrected if it contains a minor variant of a highly repetitive element in the genome or it traverses a low coverage region that is similar to other regions with normal coverage. Our method is not unique in being challenged by non-uniform coverage on repetitive genomes. Error correction for highly repetitive genomes is essential for successfully assembling larger eukaryotic genomes but none of the existing methods successfully addresses this problem, including Reptile. Short-read mapping provides a reasonable method to evaluate error correction methods in well-assembled, low repetition genomes. Nevertheless, it is not possible to unambiguously determine all errors. There are natural polymorphisms among bacterial lines, and some presumed polymorphisms may be unrecognized assembly errors. Furthermore, the mapping software chooses among alternative mappings by invoking parsimony, but there is some chance that the true number of errors is less than the minimum. Lastly, mapping software cannot map reads that contain more than a constant number of substitutions, typically just two, with full sensitivity, although we considered 5 here and tested as many as 15 with similar results. Despite these limitations, we believe that most errors are correctly identified, and this approach can provide a fair comparison of error correction methods. We and others () have found that sequence quality scores provide valuable information. Our use of quality scores probably helped us account for the error patterns in nextgeneration sequencing data () without explicitly modeling them. However, it has been observed () that high quality scores may be too optimistic and low quality scores too pessimistic in estimating sequencing errors in Solexa data. Since quality scores may not be precise measures of misread probabilities, the current version of Reptile uses quality score information in a very simple manner, but can be modified to make more sophisticated use of quality scores if warranted. Finally, although quality scores are needed to run Reptile, it can be run effectively without scores by setting all quality scores and the threshold Q c to the same value. There remain several additional challenges in next-generation sequencing error correction. One challenge is to distinguish errors from polymorphisms, for example, single nucleotide polymorphisms (SNPs). Reptile could accommodate SNP prediction with modification in the tile correction stage (Algorithm 1), where ambiguities may indicate polymorphisms. Another challenge is the growing read length of upcoming high-throughput sequencers. Currently, we define tiles as concatenations of two kmers. it might prove useful to extend the tile definition to more than two kmers in order to address error correction in much longer reads.