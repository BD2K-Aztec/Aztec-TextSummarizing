Background: Two-dimensional electrophoresis is a crucial method in proteomics that allows the characterization of proteins function and expression. This usually implies the identification of proteins that are differentially expressed between two contrasting conditions, for example, healthy versus diseased in human proteomics biomarker discovery and stressful conditions versus control in animal experimentation. The statistical procedures that lead to such identifications are critical steps in the 2-DE analysis workflow. They include a normaliza-tion step and a test and probability correction for multiple testing. Statistical issues caused by the high dimensionality of the data and large-scale multiple testing have been a more active topic in transcrip-tomics than proteomics, especially in microarray analysis. We thus propose to adapt innovative statistical tools developed for microarray analysis and incorporate them in the 2-DE analysis pipeline. Results: In this article, we evaluate the performance of different nor-malization procedures, different statistical tests and false discovery rate calculation methods with both real and simulated datasets. We demonstrate that the use of statistical procedures adapted from microarrays lead to notable increase in power as well as a minimization of false-positive discovery rate. More specifically, we obtained the best results in terms of reliability and sensibility when using the mod-erate t-test from Smyth in association with classic false discovery rate from Benjamini and Hochberg. Availability: The methods discussed are freely available in the prot2D open source R-package from Bioconductor (http://www.bio conductor.org//) under the terms of the GNU General Public License
INTRODUCTIONComparative proteomics based on 2D-polyacrylamide gel electrophoresis aims at identifying significant biologically relevant proteins. In most cases, protein samples from two conditions are compared, e.g. healthy versus diseased in human proteomics biomarker discovery (), or stressful conditions versus control in animal experimentation (). Besides the laboratory bench, informatics takes a large place in such experiments with digitalization of gels, spots detection and matching, evaluation of spots' volumes and identification of differentially expressed proteins. A large variety of software designed for the analysis of 2D digitized images exist, both commercial (e.g. Delta2D from Decodon, SameSpot Progenesis from Nonlinear dynamics, PDQuest from Bio-rad laboratories) and custom researcherdeveloped (e.g. Pinnacle from). These programs perform three main tasks: identification of spots, matching of spots from different gels and evaluation of spots' volumes. Each program has its own way to perform these steps; therefore, software choice has a great impact on the result of the analysis (). A normalization step is also needed to remove the systemic variation before data analysis. An issue with commercial software is the lack of information concerning this critical step as well as the inability to customize the normalization procedure. Ultimately, once spots' volumes have been estimated and normalized across gels, proteins that are differentially expressed between groups are identified with software-specific methods. Normalization and identification are also essential steps in 2-DE-based proteomics analysis and, as compared with other critical steps of the 2-DE procedure (e.g. protein extraction, staining, image analysis), are less studied and under-reviewed in the literature. On the other hand, the same issues have been widely studied and reviewed for transcriptomic analysis, especially for microarray studies. As pointed out by some authors, the underlying statistical issues are similar between microarrayand 2-DE analyses. A number of the statistical tools developed for microarray analysis have begun to be incorporated in the 2-DE toolbox. More specifically, advances in normalization have been adapted to Difference Gel Electrophoresis (DIGE) analysis (). Statistical tests developed for microarrays have also been evaluated (). Finally, numerous authors highlight the need of correction for multiple testing, such as false discovery rate (FDR), but few actually evaluate the performance of the different procedures (). The aim of the present work is to evaluate different methods, initially developed for microarray analysis, to identify differential *To whom correspondence should be addressed. spots in 2-DE experiments. To compare these methods, real datasets as well as simulated data were used. We also compare methods for normalization of volumes' data before statistical analysis. By evaluating the key steps of the analysis workflow, from normalization to identification of differentially expressed spots, our motivation is to provide a simple and adapted workflow to non-statistics expert biochemists. All the methods discussed are available as a free, open-source R package (R Core Team, 2012) with highly customizable options.
CONCLUSIONThe 2-DE gel-based experiments are often used in comparative proteomics to identify differentially expressed, or accumulated, proteins between two or more conditions. The 2D gels classically allow the visualization of 5001000 proteins per gel, and replication of experiments is needed to minimize the effects of (i) biological variations in protein expression between individuals and (ii) known technical limits such as differential protein extraction); Strimmer (); PC (); Storey (). Threshold versus actual FDR for five statistical tests and four modes of calculation of FDR. Actual FDRs are calculated as the average of 100 simulations with 10 replicates per condition. For comparison purposes, a perfect correlation between threshold and actual FDR is represented as a dashed line. BH (); Strimmer (); PC (); Storey (efficiencies, comigration of proteins, lack of penetration of some proteins in gels or limit of detection of the staining procedure. Recently, different techniques based both on 2D gel (e.g. DIGE) and gel-free (e.g. iTRAQ) techniques have been developed to reduce these technical biases. However, it seems obvious that, whichever technique is used, statistical analysis remains a crucial step in the proteomics workflow. To date, only a few statistical studies have been dedicated to the specific needs of proteomics, and researchers often use the statistical tools offered in commercial software. The statistical possibilities are restricted, and researchers have to make decisions based only on a P-or q-value, without knowing the details of the statistical procedure. By contrast with proteomics, statistical tools have been widely developed for transcriptomics applications. From a statistician point of view, and notwithstanding different forms of data, the problem is similar in both applications, i.e. extracting statistically significant expression from huge datasets. In this article, we took advantage of many freely available open source statistical tools developed for transcriptomics, evaluated their performance to analyze both real and simulated 2-DE proteomics datasets and developed an R-package adapted to the specific needs of proteomists. This R-package, called 'prot2D', is freely available as part of Bioconductor (www.bioconductor.org) and includes functions implementing all the methods used in the present article. The Qt method, the FDR calculation method and the moderate t-test, that were shown in this article to be the best compromises to analyze proteomics data, are preset in the package with the optimal parameters we determined. For the FDR calculation mode, method from Benjamini and Hochberg and method from Strimmer were shown to be efficient and appropriate for 2-DE volume data. In all, as statistics is one of the most determining step in the comparative proteomics workflow, and paradoxically, one of the less studied to date, we hope that this new package will help improving future 2-DE-based proteomics studies.