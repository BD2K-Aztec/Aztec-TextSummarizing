Motivation: Supervised machine learning is commonly applied in gen-omic research to construct a classifier from the training data that is generalizable to predict independent testing data. When test datasets are not available, cross-validation is commonly used to estimate the error rate. Many machine learning methods are available, and it is well known that no universally best method exists in general. It has been a common practice to apply many machine learning methods and report the method that produces the smallest cross-validation error rate. Theoretically, such a procedure produces a selection bias. Consequently, many clinical studies with moderate sample sizes (e.g. n = 30â€“60) risk reporting a falsely small cross-validation error rate that could not be validated later in independent cohorts. Results: In this article, we illustrated the probabilistic framework of the problem and explored the statistical and asymptotic properties. We proposed a new bias correction method based on learning curve fitting by inverse power law (IPL) and compared it with three existing methods: nested cross-validation, weighted mean correction and Tibshirani-Tibshirani procedure. All methods were compared in simulation datasets, five moderate size real datasets and two large breast cancer datasets. The result showed that IPL outperforms the other methods in bias correction with smaller variance, and it has an additional advantage to extrapolate error estimates for larger sample sizes, a practical feature to recommend whether more samples should be recruited to improve the classifier and accuracy. An R package MLbias and all source files are publicly available.
INTRODUCTIONIn the past two decades, fast development in bioinformatics was accompanied by the rapid production of high-throughput genomic data, such as gene expression, genotyping and various types of next-generation sequencing data. Such high-dimensional data usually come with small sample sizes and a large number of genes/features (also known as 'large p, small n' problem) and pose many new challenges in statistical learning and data mining. In the content below, we focus on machine learning of gene expression profile data, but the concept and theoretical issues also apply to other high-throughput genomic (e.g. copy number variation, DNA methylation) or proteomic data. In gene expression profile analysis, it is of great interest to predict or diagnose a disease status (e.g. classify cases versus controls or treatment responders versus non-responders). Because no universally best machine learning method exists in general (), to fulfill this task, multiple models are often constructed with different combinations of features (genes), different machine learning methods as well as different tuning parameters in the methods. To choose among such a large number of classifiers (models), it is common practice to select the model with the smallest cross-validation error rate, called the minimal-error classifier (MEC), and report its associated error rate. The MEC error rate is, however, generally downward biased and an overly optimistic estimator of the true optimal classification error rate. This is because taking the minimum of cross-validation error rates, where the estimates are random variables, will inevitably yield a downward bias. Such a selection bias has great adverse impact in many biomedical pilot studies with moderate sample sizes (e.g. n = 3060). The problem, however, has often been overlooked in applications. For example, one can examine the small pilot data using $10 popular machine learning methods, and simultaneously choose among many different numbers of features and tuning parameters in each method. This easily increases the number of tested classifiers to several hundreds and selects the MEC with a falsely small error rate because of the selection bias. When the model proceeds to a large cohort validation for translational research, it will likely fail. In the Molecular Taxonomy of Breast Cancer International Consortium (METABRIC) example that will be demonstrated in Section 3.3, we will show that the MEC bias can mistakenly reduce the error rate from 28.2% to an overly optimistic 19.1% in early-and late-stage classification (i.e. a 9.1% error rate bias). Many researchers have recognized this problem (). Dupuy and Simon (2007) recommended to 'report the estimates *To whom correspondence should be addressed. y The authors wish it be known that, in their opinion, the first two authors should be regarded as Joint First Authors. for all the classification algorithms not just the minimal error rate'. Some proposed comparing the minimal error rate with the median error rate from the original datasets with permuted class labels (). These suggestions, however, did not provide a real solution.proposed an approach to estimate the bias by a multivariate Gaussian distribution assumption between the minimal estimated error rate and the true minimal error rate. The Gaussian assumption is, however, generally questionable, and the method may not be accurate with a small sample size. In this article, three applicable bias correction methods proposed in the literature will be compared with our proposed inverse power law (IPL) method: nested cross-validation (nestedCV) (), Tibshirani-Tibshirani procedure (TT) () and weighted mean correction methods (WMC/WMCS) (). Tibshirani and Tibshirani proposed a simple bias estimation method that is computationally efficient and could be calculated through a traditional K-fold cross-validation. They claimed that the bias is only an issue when p ) n where p is the number of genes and n is the number of samples. The nestedCV, proposed by Varma and Simon, introduced another outer loop of cross-validation, so that the model selection stage is wrapped in the training samples of the outer loop. This double loop procedure, which amounts to nested double leave-one-out cross-validation (LOOCV), is computationally expensive with complexity of O n 2   : WMC/WMCS () was proposed as a smooth analytical alternative to nestedCV based on subsampling, which yielded a competitive estimate compared with nestedCV at a much lower computational price. Theoretically, according to, the TT method does not apply subsampling in the bias correction, and its estimation target is the conditional error rate (conditional on the given samples). The nestedCV and WMC/WMCS (and the IPL method we will propose) target on the unconditional error rate by repeated subsampling. In addition, both nestedCV and WMC/WMCS methods target on the error rate of a wrapper algorithm (multiple algorithms and/or rules to decide which one shall be used), which is slightly different from the MEC error rate we discuss in this article. We, however, compare all methods side-by-side because biologically they all conceptually aim to correct MEC bias from many machine learning models. This article is structured as follows. We first illustrate the MEC bias by a 2D toy example and discuss its asymptotic theory and statistical properties. The performance of the nestedCV, WMC/WMCS and TT will be examined. A subsampling-based IPL method will be proposed for the bias correction and compared with the three existing methods in both simulated and real datasets. In real data evaluation, we will use five Gene Expression Omnibus (GEO) datasets and two large breast cancer datasets [the Cancer Genome Atlas (TCGA) and METABRIC].