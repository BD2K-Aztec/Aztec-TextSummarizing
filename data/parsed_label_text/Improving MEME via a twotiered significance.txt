Motivation: With over 9000 unique users recorded in the first half of 2013, MEME is one of the most popular motif-finding tools available. Reliable estimates of the statistical significance of motifs can greatly increase the usefulness of any motif finder. By analogy, it is difficult to imagine evaluating a BLAST result without its accompanying E-value. Currently MEME evaluates its EM-generated candidate motifs using an extension of BLASTs E-value to the motif-finding context. Although we previously indicated the drawbacks of MEMEs current significance evaluation, we did not offer a practical substitute suited for its needs, especially because MEME also relies on the E-value internally to rank competing candidate motifs. Results: Here we offer a two-tiered significance analysis that can replace the E-value in selecting the best candidate motif and in evaluating its overall statistical significance. We show that our new approach could substantially improve MEMEs motif-finding performance and would also provide the user with a reliable significance analysis. In addition, for large input sets, our new approach is in fact faster than the currently implemented E-value analysis.
INTRODUCTIONMotif finding is an essential tool for bioinformatics research. The identification of transcription factor binding sites, and more generally of cis-regulatory elements, often serves as a stepping stone for understanding the regulation of gene expression. Thus, it is not surprising that for the past 20 years many motif-finding tools have been described that can find short sequence motifs given only an input set of sequences (). One such particularly popular finder is MEME (), which relies on expectation maximization (EM) () in its search for the 'most significant motif' that is present in the input set of sequences. More specifically, MEME evaluates and ranks the candidate motifs returned by each EM run in terms of their E-value. The latter term was initially introduced by the immensely popular BLAST similarity search tool (). BLAST's E-value is successfully used to assess the significance of a reported alignment by estimating the expected number of alignments that will score at least as high as the observed score, assuming the query is independent of the database. The E-value notion was later incorporated into the motiffinding literature by Hertz and Stormo (1999) who defined it as the expected number of alignments (motifs) of the same dimension and with a score at least as high as the reported one, assuming the input set is random. More precisely, the score of a motif here is the information content/log likelihood ratio (llr)/ relative entropy, or Equation (1) in the, and a random input set is generated using an independent and identically distributed (iid) process. The latter definition of the E-value was adopted by MEME as well, albeit using a different E-value approximation scheme than the one originally suggested by Hertz and Stormo (1999). More details on the E-value and how it is evaluated in MEME are available in Supplementary Section S1.1.2. Although relying on the BLAST approach seemed like a reasonable idea, it turns out there are multiple issues with it. First, as we pointed out, in practice MEME's approximation of the E-value can be overly conservative, so real motifs may be rejected (). Moreover, ignoring the problematic approximation, even an accurately computed E-value can be highly conservative as explained later in the text (). There are two factors that combine to explain how the latter statement can be reconciled with the proven utility of the E-value in the BLAST context. First, using Altschul's own words: 'The BLAST programs report E-value rather than P-values because it is easier to understand the difference between, for example, E-value of 5 and 10 than P-values of 0.993 and 0.99995. However, when, P-values and E-value are nearly identical' (). This statement is valid for the pairwise alignment problem where the number of high-scoring random alignments has a Poisson distribution. However, it can be shown that the number of high-scoring alignments in the motif finder context follows a different distribution, and hence, Altschul's statement does not apply in MEME's context where the E-value can be as large as 5 or 10 while the P-value is still significant. The second factor is the inherent algorithmic difference between the two tools: BLAST almost invariably finds the optimal alignment, while this is generally not the case for MEME (which is reasonable given the differences between the underlying problems). Thus, when assigning significance to BLAST's output, we can restrict attention to the theoretical problem of the maximally scoring local alignment between two independently drawn sequences, whereas in the case of MEME, or any other motif finder, we need to evaluate the output relative to its capability or the significance estimate will be overly conservative (). Therefore, in spite of its immense popularity (MEME and MEME-ChIP had 413 000 unique users in 2012 and 49000 unique users through the first half of 2013), MEME's significance evaluation leaves room for improvement. In previous work, we described a computationally intensive alternative to the E-value that takes into account the finder's performance and avoids the above problems with E-values (,b). Specifically, for some motif finders including MEME, the null distribution of the score of the reported motif seems to be well approximated by the 3-parameter Gamma [The distribution function of a 3-parameter Gamma with  a, b,  is given by F s  F a, b s  , where F a, b is the Gamma distribution with it usual shape and scale parameters, and is the location parameter (, or 3-Gamma, family of distributions (). Relying on this empirical observation, we designed a parametric test that returns a point estimator of, as well as a conservative confidence bound on, the significance of the reported motif (). Having demonstrated the effectiveness of the 3-Gamma significance evaluation scheme (), and having bundled it with a Gibbs sampling finder (), we considered adopting it for MEME in lieu of the E-value. However, in addition to conveying to the user an overall measure of the statistical significance, the E-value is also used internally in MEME to rank competing candidate motifs of which often only the highest scoring one is reported. Although the 3-Gamma approach can be used, for example, to choose among competing motifs of different widths (), it then becomes forbiddingly computationally intensive for assigning an overall significance as well. This motivated our design of a two-tiered significance analysis that we introduce and explore in the remainder of this article. The first tier consists of statistical tests that replace the E-value in selecting the best candidate among competing motifs. The second tier consists of applying the 3-Gamma scheme to assign an overall statistical significance. The results we present indicate that we will be able to improve both motif quality and the accuracy of motif significance estimates while allowing MEME to handle larger datasets in reasonable time.
DISCUSSIONWe propose a two-tiered significance analysis to replace the E-value currently used in MEME to select the best among competing EM-generated motifs as well as to assign an overall statistical significance. We showed that our selective MHG or MW discriminative scores substantially increase the percentage of correct motif identifications by simply applying a more judicious selection criterion to choose the best of MEME's several EM generated PWMsno change in the search strategy is involved. As the complexity of our selection procedure is linear in the size of the input set (with a small constant), it can be integrated into MEME at a marginal computational cost. As the currently implemented computation of the E-value in MEME is cubic in the number of sequences, our selective MHG and MW schemes compare favorably against the E-value on that account as well, especially with ChIP-seq data with thousands of sequences in mind. The second part of our two-tiered analysis is associated with a substantial computational cost, as it requires running MEME on n randomly generated images of the input set (we recommend n  50). Our 3-Gamma significance analysis then uses these n runs to provide a parametric approximation to the P-value of the observed motif. Again we note that although a factor of 50 is a substantial runtime penalty, the current computation of the Evalue in MEME incurs an even greater penalty when studying thousands of sequences. In summary, our two-tiered analysis offers a substantial improvement in finding the correct motif without requiring any change to MEME's underlying EM motif search strategy. The difference between the signal to noise ratio (TP to FP) of the two-tiered approach and of the E-value approach is particularly striking in the more important region of low noise. We also showed that the E-value as currently implemented in MEME is not particularly well suited for selecting motifs of competing width: it did worse than the single best width. Also, it is not a good measurement of an overall significance: as a classifier comparing motifs from multiple datasets, it performed about as good as a random one. Taken together, we expect our two-tiered analysis will significantly improve the performance of MEME. Given MEME's popularity, this improvement can make a substantial practical impact on bioinformatics research. MEME assumes its input set is uniformly weighted. In cases where one can assign different weights to the input sequences, for example, the binding intensity of a probe, other methods that use such data might yield even better results (). We stress that although our two-tiered analysis was demonstrated in the context of MEME, it should be applicable more broadly. Certainly, the selective MHG or MW scores could in principle be applied to selecting one of several candidate motifs. Moreover, the associated computational cost is only linear in the size of the input set. The wider applicability of our 3-Gamma scheme is more tentative. It is important to understand that it is an approximation, and so, at the end of the day the question is whether there are better alternatives. Our experience shows that the 3-Gamma family is better than the normal and even the extreme value distributions at approximating the null distribution of the optimal motif score in the examples we considered (, b, and). Whether this applies to the user's choice of scoring function, motif finder and null model is something that can be looked at empirically. Although, Amadeus () also allows the user to apply an essentially two-tiered analysis through its bootstrap option, there are several differences between it and our proposed solution. First, Amadeus uses the MHG score to choose the best motif, which, as we saw, can be substantially inferior to the selective MHG score we propose. Second, when using the bootstrap option, Amadeus reports an overall significance using a normal approximation, which as we showed can substantially overestimate the true significance of the motif (and Supplementary). Whether one should choose to use the selective MW or the selective MHG score seems to depend on the problem: in the OOPS context, the MW had the advantage, while in the ZOOPS experiments, the MHG did better. None of these advantages was deemed statistically significant. The MHG score has one advantage over the MW score: in the ZOOPS mode, it can be used to determine which sequences contain a site, whereas with the MW score, some other method should be used for that purpose. Our future plans are to determine whether we can estimate a universal 3-Gamma distributions for DNA and protein motifs before incorporating our two-tiered approach into MEME. If this is not possible, we will incorporate the proposed two-tier approach as is, which is how we will incorporate it into GIMSAN (). Finally we note that the formula for the number of selected columns