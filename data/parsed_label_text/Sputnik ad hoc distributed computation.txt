Motivation: In bioinformatic applications, computationally demanding algorithms are often paral-lelized to speed up computation. Nevertheless, setting up computational environments for distributed computation is often tedious. Aim of this project were the lightweight ad hoc set up and fault-tolerant computation requiring only a Java runtime, no administrator rights, while utilizing all CPU cores most effectively. Results: The Sputnik framework provides ad hoc distributed computation on the Java Virtual Machine which uses all supplied CPU cores fully. It provides a graphical user interface for deployment setup and a web user interface displaying the current status of current computation jobs. Neither a permanent setup nor administrator privileges are required. We demonstrate the utility of our approach on feature selection of microarray data.
IntroductionWe introduce the Sputnik framework that manages parallelization of computational expensive algorithms to distributed inhomogeneous clusters of computing nodes. A task that is increasingly important in bioinformatic applications not only with large data sets but also with the post-processing and interpretation of the primary measurements. This framework is especially intended for parallelization of CPU-intensive computations. Sputnik accomplishes hereby two major goals: the actual fault-tolerant distributed computation and the lightweight ad hoc deployment of programs and data.illustrates the distributed computation with Sputnik. A program on the client creates a job consisting of many tasks and sends it to the server. The server schedules the tasks to the workers which execute them and send back the results. If a worker crashes, the server reschedules its assigned tasks to the other workers. The intended usage scenario of Sputnik does not involve huge amounts of input data unlike the default scenario of applications using Hadoop (hadoop.apache.org). Also unlike the JPPF framework (www.jppf.org) Sputnik achieves a full utilization of all available CPU cores during job execution through its batch-wise task distribution to the worker. This is achieved via task scheduling strategies that assign new tasks to workers upon completion of previous tasks almost immediately. Due to its minimal requirements (a Java runtime and no administrator privileges) Sputnik can be easily deployed to heterogeneous groups of machines with respect to hardware and software. We implemented a feature selection based on a genetic algorithm (GA) to show the applicability of Sputnik.
ConclusionWe devised and implemented a lightweight tool for code parallelization in shared and distributed memory. The tool support of Sputnik enables ad hoc on demand parallelization with a user interface for ease of configuration. The task as data paradigm of Sputnik allows decisions on parallelization at runtime. In our simulation experiments, we could successfully utilize the framework for biomarker selection. Furthermore, Sputnik also compares well both in setup and runtime to other frameworks. This supports the feasibility of our approach for applications in bioinformatics and systems biology that are demanding a high computational power and ease of setup.