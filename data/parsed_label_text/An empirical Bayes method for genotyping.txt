Motivation: The development of next generation sequencing technology provides an efficient and powerful approach to rare variant detection. To identify genetic variations, the essential question is how to quantity the sequencing error rate in the data. Because of the advantage of easy implementation and the ability to integrate data from different sources, the empirical Bayes method is popularly employed to estimate the sequencing error rate for SNP detection. Results: We propose a novel statistical model to fit the observed non-reference allele frequency data, and utilize the empirical Bayes method for both genotyping and SNP detection, where an ECM algorithm is implemented to estimate the model parameters. The performance of our proposed method is investigated via simulations and real data analysis. It is shown that our method makes less genotype-call errors, and with the parameter estimates from the ECM algorithm, it attains high detection power with FDR being well controlled. Availability and implementation: The proposed algorithm is wrapped in the R package ebGenotyping, which can be downloaded from http://cran.r-project.org/web/packages/ebGenotyping/.
IntroductionNext-generation sequencing (NGS) technology produces vast amount of sequencing data at an unprecedented low cost, which totally changes the landscape of identification of genetic variations (). Thanks to its high-throughput capability, NGS provides a direct and powerful approach to the detection of rare variants (). It makes it possible to explore the DNA sequence at nucleotide level and identify mutations through single-sample analysis. However, it is demonstrated that multi-sample sequencing can increase the detection power and has better false positive control than single-sample sequencing (), therefore, multi-sample sequencing is more widely used in the genomic research, and the analysis tools for multi-sample sequencing data are always in high demand. As the most common type of sequence variations, the single nucleotide polymorphism (SNP) plays an important role in genetic evolution. The existence of SNPs changes the genotypes of sequenced sample different from the reference genome, resulting in the nonreference alleles being observed in the alignment data. On the contrary, the genomic positions with frequent non-reference alleles indicate potential SNPs. Nevertheless, the NGS data analysis pipeline is a complex process. Many factors during this process may contribute to the non-reference alleles, including not only the sample preparation, and PCR amplification during the sequencing experiment, but also the algorithms used for base calling and alignment. All the alleles different from the genotype allele due to these factors are called as sequencing errors. The existence of sequencing errors makes SNP detection much more challenging than expected. The main task of SNP detection is to evaluate the sequencing error rate in the data, in order to distinguish SNPs from the sequencing errors. The base calling quality and mapping quality scores are widely used to quantity the sequencing error rate in the NGS data for SNP detection, such as GATK (), SAMtools (), SOAPsnp (), FreeBayes (https:// github.com/ekg/freebayes), Atlas-SNP2 (), etc. With an arbitrary prior, they employ the classical Bayes model to call the genotypes according to their posterior probabilities, and then call SNPs by comparing to the reference genome. Although the quality scores reflect the magnitude of the sequencing error rate to a great extent, they still have some limitations. First, the quality scores may not be able to fully account for the sequencing error rate due to the complexity of NGS data analysis pipeline.propose to incorporate the sample preparation error in single-sample analysis to evaluate the sequencing error rate. Their method, as well as the corresponding multi-sample method MultiGeMS (), outperforms other SNP callers. Second, processing the quality metrics is computationally intensive and those algorithms are usually not applicable across different experimental platforms. Third, using the quality scores to determine the sequencing error rate ignores the common information from repeated alleles, such as the sequencing error rate related to the local DNA content, which is shared by the alleles aligned to that DNA region from different samples (). Recently, more and more SNP callers based on the empirical Bayes method were proposed, where the sequencing error rate is set to be an unknown parameter and empirically estimated from the data.assume that different samples have the same sequencing error rate at each genomic locus, and use the allele frequency data from all of the samples to estimate it.employ a Dirichlet mixture model to fit the frequency vectors of four nucleotides at all the genomic loci of different samples, and combine all the data to estimate the model parameters.decompose the sequencing error rate into three types of variations, i.e. sample effect, positional effect and finite depth, and integrate the data across samples and genomic locations to estimate them. Besides, Zhou (2012) andutilize the empirical Bayes method for pooled sequencing data analysis. Comparing to the classical Bayes models, the empirical Bayes method can combine the information from different samples at different genomic sites to improve the estimation for model parameters (). In this paper, we focus on the multi-sample sequencing data from the diploid organism. At each genomic locus, only three possible genotypes are considered, i.e. homozygous reference (RR), which is non-SNP, heterozygous SNP (RV) and homozygous SNP (VV). Although this may cause the incorrect genotype calls at triallelic sites, it need not significantly affect the results but highly reduces the computational burden (, Supplementary Material). With this assumption, the Binomial model is a natural choice to fit the allele frequency, as didassume the independence between different genomic sites and estimate the sequencing error rate site-by-site, whileintroduce the sample effect and integrate the data not only across samples but also genomic sites to estimate the sequencing error rate. Comparing toimprove the statistical model to admit heterogeneity among samples. However, since their model is built to fit the sequencing error frequency which is not observable, they have to incorporate a pregenotyping step. Besides, due to the complexity of the model, they estimate the parameter using the median method and approximate the logit-normal by Beta distribution to calculate the posterior distribution. We modify the decomposition in Muralidharan et al. (2012a) and propose a novel statistical model for both of genotyping and SNP detection. The model is established to fit the observed allele frequency data, so we do not need any pre-processing analysis. Moreover, benefitting from the modification, instead of the approximation methods, we implement an ECM algorithm () to estimate the model parameters, and utilize the empirical Bayes method to genotype samples and call SNPs with false discovery rate (FDR) control. The rest of the paper is structured as follows. In Section 2, the statistical model and ECM algorithm are introduced. Their performance is illustrated via simulations in Section 3 and two real datasets in Section 4. Finally, we give a short discussion in Section 5.
DiscussionIn this paper, we propose a novel statistical method for both of genotyping and SNP detection using multi-sample NGS data. Instead of pooling the multi-sample data as single-sample or pooled sequencing data, we build the statistical model to integrate information across different samples and genomic sites, to make the genotype-call and identify SNP at each locus for each sample. This offers our method high detection power for both common and rare SNPs, as illustrated in the simulations and real data analysis. In the proposed model, the sample effect is a constant across all of the genomic sites. Sometimes, it may be not feasible, since as mentioned previously, the sequencing error rate may be affected by the local DNA contents, repetitive regions, etc. We suggest to cut the whole genome into small-pieced regions and analyze them in the piece-wise manner. This not only can solve the heterogeneity issue in the sample effect, but also helps to implement the computation in a parallel way, which will greatly reduce the computation duration for huge data analysis.