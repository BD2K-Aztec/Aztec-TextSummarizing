Motivation: In molecular biology, as in many other scientific fields, the scale of analyses is ever increasing. Often, complex Monte Carlo simulation is required, sometimes within a large-scale multiple testing setting. The resulting computational costs may be prohibitively high. Results: We here present MCFDR, a simple, novel algorithm for false discovery rate (FDR) modulated sequential Monte Carlo (MC) multiple hypothesis testing. The algorithm iterates between adding MC samples across tests and calculating intermediate FDR values for the collection of tests. MC sampling is stopped either by sequential MC or based on a threshold on FDR. An essential property of the algorithm is that it limits the total number of MC samples whatever the number of true null hypotheses. We show on both real and simulated data that the proposed algorithm provides large gains in computational efficiency. Availability: MCFDR is implemented in the Genomic HyperBrowser (http://hyperbrowser.uio.no/mcfdr), a web-based system for genome analysis. All input data and results are available and can be reproduced through a Galaxy Pages document at:
INTRODUCTIONThe development of novel experimental techniques is rapidly increasing the generation of data in many fields in biology, in particular in genomics with the advent of high-throughput sequencing (). Chromatin immunoprecipitation (ChIP) technology combined with nextgeneration sequencing generates high-resolution data along the genome on DNA methylation, histone modifications, transcription factor binding and more (). The large amount of data generated by these techniques opens up for statistical studies of relations between genomic properties, both globally and locally along the genome. An example of such a local analysis is the study of how the relation between histone modifications and repeating elements varies across chromosomes (). A natural approach to such an investigation is to split the genome into bins along the genome, e.g. one bin per chromosome, cytoband or gene, and then perform a statistical test of a null hypothesis H0 versus an alternative hypothesis H1 for each bin. At the same time, due to the complex structural properties of the genome, it is often inappropriate to make simplified assumptions that would enable analytic evaluation of significance (). Instead, Monte Carlo (MC) sampling is often needed, resorting to computationally expensive reshuffling of genomic elements for each MC sample. As a consequence, Monte Carlo in multiple testing settings is rapidly becoming important (). With tests being performed for a large number of bins locally along the genome, the computational requirements may become extremely high, as the effort needed is basically the multiple of a very large number of test by a (possibly also very large) number of MC samples. Several papers have considered ways to reduce the number of samples during MC-based P-value computation for individual tests.propose a sequential MC algorithm for P-value computation, reducing the needed number of MC samples for tests that are anyway insignificant. Other papers consider alternative ideas for P-value estimation, such as controlling resampling risk (), and prediction of P-values using Random Forest models (). Also, there has been some work on Monte Carlo approaches for multiple testing in cases where P-values can be calculated analytically (). In this article, we propose an algorithm that limits the total number of needed MC samples, regardless of how many tests are truly H0. In Section 2, we describe our algorithm, in which MC sampling is stopped either according to the sequential MC stopping rule or when we reach a given multiple testing significance threshold. Then, in Section 3, we show on both simulated and real data that this method can lead to a drastically reduced total number of MC samples. Finally, Section 4 presents a discussion and some conclusions. Further details are provided in the accompanying Galaxy Pages () document.