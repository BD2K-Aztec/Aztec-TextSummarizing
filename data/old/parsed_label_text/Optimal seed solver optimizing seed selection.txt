Motivation: Optimizing seed selection is an important problem in read mapping. The number of non-overlapping seeds a mapper selects determines the sensitivity of the mapper while the total frequency of all selected seeds determines the speed of the mapper. Modern seed-and-extend mappers usually select seeds with either an equal and fixed-length scheme or with an inflexible placement scheme, both of which limit the ability of the mapper in selecting less frequent seeds to speed up the mapping process. Therefore, it is crucial to develop a new algorithm that can adjust both the individual seed length and the seed placement, as well as derive less frequent seeds. Results: We present the Optimal Seed Solver (OSS), a dynamic programming algorithm that discovers the least frequently-occurring set of x seeds in an L-base-pair read in Oðx Â LÞ operations on average and in Oðx Â L 2 Þ operations in the worst case, while generating a maximum of OðL 2 Þ seed frequency database lookups. We compare OSS against four state-of-the-art seed selection schemes and observe that OSS provides a 3-fold reduction in average seed frequency over the best previous seed selection optimizations. Availability and implementation: We provide an implementation of the Optimal Seed Solver in Cþþ at: https://github.com/CMU-SAFARI/Optimal-Seed-Solver
IntroductionThe invention of high-throughput sequencing (HTS) platforms during the past decade triggered a revolution in the field of genomics. These platforms enable scientists to sequence mammalian-sized genomes in a matter of days, which have created new opportunities for biological research. For example, it is now possible to investigate human genome diversity between populations (1000 Genomes), find genomic variants likely to cause disease (), and study the genomes of ape species () and ancient hominids () to better understand human evolution. However, these new sequencing platforms drastically increase the computational burden of genome data analysis. First, billions of short DNA segments (called reads) are aligned to a long reference genome. Each read is aligned to one or more sites in the reference based on similarity with a process called read mapping (). Reads are matched to locations in the genome with a certain allowed number of errors: insertions, deletions, and substitutions (which usually constitute less than 5% of the read's length). Matching strings approximately with a certain number of allowederrors is a difficult problem. As a result, read mapping constitutes a significant portion of the time spent during the analysis of genomic data. Pigeonhole principle based seed-and-extend mappers are one kind of popular mappers that have been widely used to aid many biological applications (). In pigeonhole based seed-and-extend mappers such as mrFAST (), RazerS3 (), GEM (), SHRiMP () and Hobbes (), each read is partitioned into one or more short segments called seeds. Here we define seeds as substrings of a read. This definition is different from the 'spaced seeds' definition (which can be a subsequence, rather than a substring)a concept we will explain in the Related Works section. Seeds are used as indices into the reference genome to reduce the search space and speed up the mapping process. Since a seed is a substring of the read that contains it, every correct mapping for a read in the reference genome will also be mapped by the seed (assuming no errors in the seed). Therefore, mapping locations of the seeds generate a pool of potential mappings of the read. Mapping locations of seeds in the reference genome are pre-computed and stored in a seed database (usually implemented as a hash table or Burrows-Wheeler-transformation (BWT) (with FM-indexing ()) and can be quickly retrieved through a database lookup. When there are errors in a read, the read can still be correctly mapped as long as there exists one seed of the read that is error free. The error-free seed can be obtained by breaking the read into many non-overlapping seeds; in general, to tolerate e errors, a read is divided into e 1 seeds, and based on the pigeonhole principle, at least one seed will be error free. Alternatively, a mapper can use overlapping seeds. Such mappers follow the q-gram approach () in order to achieve full mapping sensitivity (finding all valid mappings that have fewer errors than permitted) or simply select overlapping seeds without guaranteeing the full mapping sensitivity under the given error threshold (e.g. bowtie2 (), BWA-MEM (). Compared to the pigeonhole principle (a special case of the q-gram approach), selecting overlapping seeds using the q-gram approach could generate longer, less frequent seeds. However, in order to guarantee full mapping sensitivity, this approach requires selecting a larger number of seeds, which may increase the total number of potential mappings, there by reducing the speed of a mapper. In this work, we focus on seed selection mechanisms based on the pigeonhole principle that provide full mapping sensitivity by selecting non-overlapping seeds. For each selected non-overlapping seed, its locations are further verified using weighted edit-distance calculation mechanisms (such as SmithWaterman () and Needleman Wunsch () algorithms), to examine the similarity between the read and the reference at each potential mapping site. Locations that pass this final verification step (i.e. contain fewer than e substitutions, insertions and deletions) are valid mappings and are recorded by the mapper for use in later stages of genomic analysis. Computing the edit-distance is an expensive operation and is the primary computation performed by most read mappers. In fact, speeding up this computation is the subject of many other works in this area of research, such as Shifted Hamming Distance (), Gene Myers' bit-vector algorithm () and SIMD implementations of edit-distance algorithms (). To allow edits, mappers must divide reads into multiple seeds. Each seed increases the number of locations that must be verified. Furthermore, to divide a read into more seeds, the lengths of seeds must be reduced to make space for the increased number of seeds; shorter seeds occur more frequently in the genome which requires the mapper to verify even more potential mappings. Therefore, the key to building a fast yet error tolerant mapper with high sensitivity is to select many seeds (to provide greater tolerance) while minimizing their frequency of occurrence (or simply frequency) in the genome to ensure fast operation. Our goal, in this work, is to lay a theoretically-solid foundation to enable techniques for optimal seed selection in current and future seed-and-extend mappers. Selecting the optimal set of non-overlapping seeds (i.e. the least frequent set of seeds) from a read is difficult primarily because the associated search space (all valid choices of seeds) is large and it grows exponentially as the number of seeds increases. A seed can be selected at any position in the read with any length, as long as it does not overlap with other seeds. We observe that there is a significant advantage to selecting seeds with unequal lengths, as possible seeds of equal lengths can have drastically different levels of frequencies. Our goal in this paper is to develop an inexpensive algorithm for seed-and-extend mappers based on the pigeonhole principle that derives the optimal placement and length of each seed in a read such that the overall sum of frequencies of all seeds is minimized. This paper makes the following contributions: @BULLET It examines the frequency distribution of seeds in the seed database and provides how often seeds of different frequencies are selected using a navenave seed selection scheme. We confirm the discovery of prior works () that frequencies are not evenly distributed among seeds and frequent seeds are selected more often under a navenave seed selection scheme. We further show that this phenomenon persists even when using longer seeds. @BULLET It provides an implementation of an optimal seed finding algorithm, Optimal Seed Solver, which uses dynamic programming to efficiently find the least-frequent non-overlapping seeds of a given read. We prove that this algorithm always provides the least frequently-occurring set of seeds in a read. @BULLET It provides a comparison of the Optimal Seed Solver and existing seed selection optimizations, including Adaptive Seeds Filter in the GEM mapper (), Cheap K-mer Selection in FastHASH (), Optimal Prefix Selection in the Hobbes mapper () and spaced seeds in PatternHunter (). We compare the complexity, memory traffic, and average frequency of selected seeds of Optimal Seed Solver with the above four state-of-the-art seed selection mechanisms. We show that the Optimal Seed Solver provides the least frequent set of seeds among all existing seed selection optimizations at reasonable complexity and memory traffic.
DiscussionAs shown in the Section 5, OSS requires OL 2  seed-frequency lookups in order to derive the optimal solution of a read. For a non-trivial seed database implementation such as BWT with FM-index, this can be a time consuming process. For reads that generate equally frequent seeds in OSS and other seed selection mechanisms, OSS could be less beneficial as it generates more queries of seed frequencies to the seed database without reducing the total seed frequency. When such reads are prevalent (very unlikely), OSS might not be the ideal seeding mechanism. One workaround under this event is to combine OSS with other greedy seed selection algorithms (e.g. CKS, OPS). In such a configuration, OSS will only be invoked when greedy seed selection algorithms fail to deliver infrequent seeds. However, how to combine different seeding mechanisms is beyond the scope of this paper and will be explored in our future research. The Optimal Seed Solver also revealed that there is still great potential in designing better greedy seed selection optimizations. From our experiment, we observe that the most effective greedy seed selection optimization still provides 3  more frequent seeds on average than optimal. Better greedy algorithms that provide less frequent seeds without a large number of database lookups are also part of our future research.
ConclusionOptimizing seed selection is an important problem in read mapping. The number of selected non-overlapping seeds defines the error tolerance of a mapper while the total frequency of all selected seeds in the reference genome determines the performance of the mapper. To build a fast yet error tolerant mapper, it is essential to select a large number of non-overlapping seeds while keeping each seed asOptimal seed solverinfrequent as possible. In this paper, we confirmed the frequent seed phenomenon discovered in previous works (), which suggests that in a navenave seed selection scheme, mappers tend to select frequent seeds from reads, even when using long seeds. To solve this problem, we proposed the Optimal Seed Solver (OSS), a dynamic-programming algorithm that finds the optimal set of seeds that has the minimum total frequency. We further introduced four optimizations to OSS: optimal divider cascading, early divider termination, divider sprinting and optimal solution forwarding. Using all four optimizations, we reduced the average-case complexity of OSS to Ox  L, where x is the total number of seeds and L is the length of the read; and achieved a Ox  L 2  worst-case complexity. We compared OSS to four prior studies, Adaptive Seeds Filter, Cheap K-mer Selection, Optimal Prefix Selection and spaced seeds and showed that OSS provided a 3-fold seed frequency reduction over the best previous seed selection scheme, Optimal Prefix Selection. We conclude that OSS is an efficient algorithm that can find the best set of seeds, which can potentially improve the performance of future read mappers.