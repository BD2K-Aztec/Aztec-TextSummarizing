Motivation: The growth of next-generation sequencing means that more effective and efficient archiving methods are needed to store the generated data for public dissemination and in anticipation of more mature analytical methods later. This article examines methods for compressing the quality score component of the data to partly address this problem. Results: We compare several compression policies for quality scores, in terms of both compression effectiveness and overall efficiency. The policies employ lossy and lossless transformations with one of several coding schemes. Experiments show that both lossy and lossless transformations are useful, and that simple coding methods, which consume less computing resources, are highly competitive, especially when random access to reads is needed.
INTRODUCTIONNext-generation sequencing (NGS) offers new directions in genome science by allowing entire genomes to be sequenced at lower costs. Given its rapid growth, the problem of economically storing and quickly restoring sequencing data is becoming a concern for both researchers and operators of data centers. The most notable examples of data repositories is the Sequence Read Archives (SRA) by the International Nucleotide Sequence Database Collaboration (INSDC) at NCBI, EBI and DDBJ, which helps in disseminating publicly funded data (). While the storing of raw data is infeasible, their hope is to be able to store at least the bases and their corresponding quality scores. On the other hand, as the amount of data continues to rise, it is conceivable that the burden of storing such data will gradually shift to research laboratories, hospitals or even individuals. Effective means of storing sequencing data will be needed in these cases as well, even though the resources available will differ greatly. * To whom correspondence should be addressed.The above trends suggest that economical representation of sequencing data is important. In response, compression of DNA sequences has been an active research topic for many years. In contrast, relatively little attention has been devoted to quality scores. The set of quality scores is far larger than the four DNA nucleotides; this has the potential to make the problem more difficult than sequence compression. Whenever the economical representation of quality scores was taken into account, the scores were considered together with all other components. Hence, it is not clear how well the quality scores component can be compressed. Note that the little attention given to quality scores does not mean that they are useless. In fact, they are slowly becoming a necessary part of many data analyses. They can be used to trim reads at either end [see the Galaxy tool () for an example] or be used for read mapping, as demonstrated by the MAQ software (). Other future applications may also be possible. In this article, we address the issue of economical representation of quality scores as a stand-alone component. This separation allows us to focus on the topic at hand, and does not limit us from combining our results with other works that are devoted to compressing DNA sequences alone. To have a clear understanding, and to supply different levels of economy trade-off, we break the process of economical representation into three independent and optional components: lossy transformation, lossless transformation and coding (or compression). Rather than advocating a single method for each component, we will explore various options.
CONCLUSIONIn this work, we have considered how to economically represent quality scores in NGS data as a combination of three main components: lossy transformation, lossless transformation and coding. Of them, the first two are optional, but they can considerably affect the whole process. By separating these components, we were able to see the effects each of them can bring, and also to identify the best settings in order to achieve good system performance. In our study, we proposed three lossy transformations, introduced or made use of three lossless transformations, investigated several by-value coding schemes and considered more conventional bysymbol methods. Moreover, we demonstrated how data blocking can affect both compression ratios and running times. Finally, we also proposed a method to assess the usability, or worthiness, of any lossy transformation by employing the read mapping tool MAQ. We found that while full-fledged compression systems such as libbzip2 are widely accepted for economical representation of NGS, they are not the best choice for quality scores. Here, simple codes such as the static code gamma and parameterized codes interp and golomb, when accompanied by the lossless transformation GapTranslating, are highly competitive: they can achieve similar levels of compression while using less time. In particular, unlike their counterparts that are effective only with large block sizes, the simple codes have the distinguished feature of being unaffected by this factor. This is an important point because it essentially removes the block size parameter from the process, and allows simple codes to greatly outperform their counterparts when small block sizes are in use. Note that small block sizes offer a number of advantages which we have not explored. First, peak memory usage is reduced. Second, since blocks are coded independently, errors in the compressed data stream can be isolated easily. Third, random access in compressed data can be supported at the additional low cost of an index before each block. Finally, independent blocks mean that our findings would apply to higher coverage datasets. As expected for the lossy transformations, compression ratios positively correlate with the number of distinct quality scores. Of the three proposed transformations, LogBinning is the most effectiveit achieves excellent relative mapping performance even when employing only a few distinct quality scores. With this choice, compression ratio is improved by around six times, while processing time, when coupled with by-symbol coding schemes, is reduced significantlyall suggesting that lossy transformations are useful. Our results for SRR032209 are supported by those of SRR070788_1, which appear in the Supplementary Material. Even though the reads are longer, the relative performance of the transformation and compression methods remain the same. Our view is that as NGS data continues to grow, lossy and lossless transformations can work in tandem. For example, NGS data can be compressed losslessly and kept in off-line storage (such as tape backup) while lossy versions of the data can be shared between users and research laboratories for daily use. Employing lossy transformations requires consideration since such changes are more easily noticeable and difficult to assess compared with images and video data ()our evaluation with MAQ is meant to address this issue. In the future, we plan to reorder the reads, as was done byfor the sequence bases, so that each block possesses reads that have similar quality score patterns. With respect to running time, we intend to parallelize some of our methods across blocks. Furthermore, the effect of lossy transformations on other applications of NGS data, such as RNA-Seq and SNP calling, also needs to be evaluated. Our implementation, dubbed QScores-Archiver, is available from http://www.cb.k.u-tokyo.ac.jp/asailab/members/ rwan under the Lesser General Public License version 3 or later to allow users to combine it with their FASTQ compression systems.