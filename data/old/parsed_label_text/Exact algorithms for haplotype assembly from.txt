Motivation: Haplotypes play a crucial role in genetic analysis and have many applications such as gene disease diagnoses, association studies, ancestry inference and so forth. The development of DNA sequencing technologies makes it possible to obtain haplotypes from a set of aligned reads originated from both copies of a chromosome of a single individual. This approach is often known as haplotype assembly. Exact algorithms that can give optimal solutions to the haplotype assembly problem are highly demanded. Unfortunately, previous algorithms for this problem either fail to output optimal solutions or take too long time even executed on a PC cluster. Results: We develop an approach to finding optimal solutions for the haplotype assembly problem under the minimum-error-correction (MEC) model. Most of the previous approaches assume that the columns in the input matrix correspond to (putative) heterozygous sites. This all-heterozygous assumption is correct for most columns, but it may be incorrect for a small number of columns. In this article, we consider the MEC model with or without the all-heterozygous assumption. In our approach, we first use new methods to decompose the input read matrix into small independent blocks and then model the problem for each block as an integer linear programming problem, which is then solved by an integer linear programming solver. We have tested our program on a single PC [a Linux (x64) desktop PC with i7-3960X CPU], using the filtered HuRef and the NA 12878 data-sets (after applying some variant calling methods). With the all-hetero-zygous assumption, our approach can optimally solve the whole HuRef data set within a total time of 31 h (26 h for the most difficult block of the 15th chromosome and only 5 h for the other blocks). To our knowledge, this is the first time that MEC optimal solutions are completely obtained for the filtered HuRef dataset. Moreover, in the general case (without the all-heterozygous assumption), for the HuRef dataset our approach can optimally solve all the chromosomes except the most difficult block in chromosome 15 within a total time of 12 days. For both of the HuRef and NA12878 datasets, the optimal costs in the general case are sometimes much smaller than those in the all-heterozygous case. This implies that some columns in the input matrix (after applying certain variant calling methods) still correspond to false-heterozygous sites. Availability: Our program, the optimal solutions found for the HuRef dataset available at http://rnc.r.dendai.ac.jp/hapAssembly.html. Contact:
INTRODUCTIONA haplotype is the sequence of SNPs in each of the two copies of a given chromosome in a diploid organism. Haplotypes are crucial for genetic analysis and have many applications such as gene disease diagnoses, association studies, ancestry inference, drug design and so forth (). Traditional approaches to obtaining haplotypes are based on genotype data from a set of individuals. The genotype data tell the status of both alleles at a position without distinguishing which one is on a specific copy of the chromosome. This approach is generally known as haplotype phasing. One can use various algorithms to infer the haplotypes (). A drawback of this approach lies in its weakness in identifying rare and novel SNPs (). Besides, it is hard to verify whether the inferred haplotype is completely correct. With the development of high-throughput sequencing technologies, an alternative way to obtain the haplotypes for an individual is to combine sequence fragments, which is known as haplotype assembly (). Given a set of aligned reads sequenced from the two copies of a given chromosome of a single individual, the goal of haplotype assembly is to correctly determine two haplotypes, each of which corresponding to one of the two copies of the chromosome. The haplotype assembly problem was first introduced by. Basically, when reads contain errors, the reads cannot be partitioned perfectly into two disjoint sets each of which consists of non-conflicting reads. To deal with errors when looking for the best reconstruction of haplotypes, one has to fix an objective function for evaluating candidate haplotypes. For this purpose, various functions such as Minimum Fragment Removal, Minimum SNP Removal, Longest Haplotype Reconstruction, Minimum Error Correction (MEC), Minimum Implicit SNP Removal and Minimum Implicit Fragment Removal have been subsequently proposed (). Recently,proposed the Minimum Weighted Edge Removal function, whereasproposed the Maximum Fragments Cut function. Of special interest among the proposed functions is *To whom correspondence should be addressed. MEC, which aims at minimizing the total number of conflicts (errors) between the reads and the constructed haplotypes h 1 , h 2 . The problem of minimizing MEC is NP hard (). For this problem,presented an exact algorithm based on the branch-andbound method and a genetic algorithm. A weighted version of this problem is considered by. In the remainder of this article, we only consider the problem of minimizing MEC.presented the first diploid genome sequence of an individual human, J. Craig Venter, using Sanger sequencing technology. They also designed a greedy heuristic method that concatenates the reads with minimum conflicts. Their method is fast but not accurate when errors appear in reads.developed a software package (named HapCUT), and their algorithm tries to minimize the MEC score of the reconstructed haplotypes by iteratively computing maxcuts in graphs derived from the sequenced fragments.designed a Markov chain Monte Carlo algorithm (named HASH). Both HASH and HapCut work well in practice, but there is no guarantee of finding optimal haplotypes. Recently,proposed a dynamic programming algorithm for the problem that runs in time O2 k mn, where k is the length of the longest read, m is the number of reads and n is the total number of SNPs in the haplotypes. Their experiments show that their algorithm works well when k 15. On the other hand, when k is large, they model the problem as a MaxSAT problem, which is then solved by a MaxSAT solver. To compare their MaxSAT approach with the previous methods, they use the filtered HuRef dataset fromover 22 chromosomes. Via experiments, they show that their program can construct better haplotypes than the previous programs by. It is worth pointing out that to solve the problem for the 22 chromosomes, their program takes a total time of $15h on a PC cluster. Moreover, their program does not solve the problem exactly because it excludes certain reads (3725 reads in total) from consideration. Furthermore, their program fails to find optimal haplotypes for a total of eight blocks of the 22 chromosomes. In this article, we develop a new approach to optimally solving the problem. In our approach, we first use new methods to decompose the input read matrix into small independent blocks and then model the problem for each block as an integer linear programming (ILP) problem, which is then solved by an ILP solver [such as CPLEX (IBM ILOG CPLEX Optimizer) and GLPK(GNU Linear Programming Kit)]. We have tested our program on a single PC [namely, a Linux (x64) desktop PC with i7-3960X CPU], using the filtered HuRef dataset. Our experimental results show that our program can optimally solve all the chromosomes within a total time of 31 h (26 h for the most difficult block of the 15th chromosome and only 5 h for the other blocks). To our knowledge, this is the first time that optimal haplotypes under the MEC model are completely obtained for the filtered HuRef dataset. Moreover, to find almost optimal haplotypes within much shorter time for the difficult blocks, we propose several powerful heuristic methods.have generalized the problem by removing the all-heterozygous assumption to handle the existence of a small number of homozygous sizes in the solution. The generalized problem is much harder because it allows many more candidate haplotypes. Nevertheless, we develop a program that can optimally solve the generalized problem for all the 22 chromosomes of the filtered HuRef dataset except the most difficult block of the 15th chromosome within a total time of 12 days. As far as we know, this is the first strike on computing optimal solutions for the HuRef dataset without the all-heterozygous assumption. Moreover, to find almost optimal haplotypes within much shorter time for the difficult blocks, we propose several powerful heuristic methods. Via experiments with the simulated dataset of Geraci (2010), we show that an optimal solution for the general case of the problem achieves a better reconstruction rate than an optimal solution for the all-heterozygous case of the problem.
DiscussionMultiple optimal solutions may exist for both the all-heterozygous and the general cases. If there is no error in the reads, the optimal solution is unique. If the error rate in reads is low, the chance that the optimal solution is unique is high. However, if the error rate is high, many optimal solutions may exist. In general, enumerating all optimal solutions are much harder and takes much longer time than computing a single optimal solution. From the experiments on simulated datasets, we can see that the single optimal solution found by our exact algorithm can achieve better reconstruction rate than the previously known heuristics in most cases. Still, it remains an open problem to handle multiple optimal solutions.. Evaluating our exact program using the simulated dataset of Geraci (2010) for those combinations ', c, e with ' 2 f100, 350g, c 2 f3, 5, 8, 10g and e  10%, where column 'prev RR' shows the best average reconstruction rate reported by Geraci (2010) and columns 'org score', 'score', 'time' and 'RR' show the average MEC score of the correct solution, the average MEC score of the solution found by our exact program, the average time (in minutes) taken by our exact program, and the average reconstruction rate of our program over the 100 instances in the dataset for a particular combination ', c, 10%, respectively. Evaluating our heuristics for the general case using the simulated dataset of Geraci (2010) for those combinations ', c, e with ' 2 f100, 350g, c 2 f3, 5, 8, 10g and e  10%, where the columns mean the same as in