Motivation: The statistical analysis of single-cell data is a challenge in cell biological studies. Tailored statistical models and computational methods are required to resolve the subpopulation structure, i.e. to correctly identify and characterize subpopulations. These approaches also support the unraveling of sources of cell-to-cell variability. Finite mixture models have shown promise, but the available approaches are ill suited to the simultaneous consideration of data from multiple experimental conditions and to censored data. The prevalence and relevance of single-cell data and the lack of suitable computational analytics make automated methods, that are able to deal with the requirements posed by these data, necessary. Results: We present MEMO, a flexible mixture modeling framework that enables the simultaneous, automated analysis of censored and uncensored data acquired under multiple experimental conditions. MEMO is based on maximum-likelihood inference and allows for testing competing hypotheses. MEMO can be applied to a variety of different single-cell data types. We demonstrate the advantages of MEMO by analyzing right and interval censored single-cell microscopy data. Our results show that an examination of censoring and the simultaneous consideration of different experimental conditions are necessary to reveal biologically meaningful subpopulation structures. MEMO allows for a stringent analysis of single-cell data and enables researchers to avoid misinterpretation of censored data. Therefore, MEMO is a valuable asset for all fields that infer the characteristics of populations by looking at single individuals such as cell biology and medicine. Availability and Implementation: MEMO is implemented in MATLAB and freely available via github (https://github.com/MEMO-toolbox/MEMO). Contacts
IntroductionCell-to-cell variability is omnipresent in biological systems (). Clonal populations can show quantitative differences in gene expression and qualitatively distinct cellular phenotypes and subpopulations (). The magnitude and nature of variability within a population can differ significantly depending on the system under consideration (). Accurate quantification relies on sophisticated statistical models which have to be tailored to the characteristics of the measurement technique (). One characteristic of experimental data, whose importance is often underestimated, is censoring (). Most experimental devices provide censored data due to limited resolution or experimental constraints (see Supplementary Material, Section S.1). Left and right censored data provide upper and lower bounds, respectively, while interval censored data provide an interval for a quantity of interest (). A quantity of interest might be the time to an event. If the event occurs before the start of the observation, the time to the event is left censored. Accordingly, the time to an event is right censored if the event does not occur during the observation or if a mutually exclusive event occurs before (). These censoring events may also be randomly distributed. If the system is observed at discrete time points, only the time interval in which the event occurs is known. In concentration measurements censoring can occur due to detection limits or limited resolution. If the quantity of interest can only be detected above a certain detection limit, this limit provides an upper bound for quantities below, leading to left censored data. Similarly, saturation effects of the detection method lead to right censoring, where the saturation threshold serves as a lower bound for quantities above. Limited resolution naturally leads to interval censoring. For example, limited time-resolution in single-cell microscopy experiments is due to phototoxicity and photobleaching, requiring long inter-observation intervals to avoid stress (). Statistical models accounting for censoring are well-established. A suitable framework is provided by mixture modeling. While most mixture modeling approaches do not account for censoring () others consider selected types of censoring () (see Supplementary Material, Section S.2). Unfortunately, the latter do not provide a comprehensive, easily accessible framework. Therefore, such models are infrequently applied in a biological context, which entails certain risks. In the presence of mutually exclusive (competing) biological events, for example, disregarding right censoring can result in an incorrect interpretation of experimental data such as correlations between actually uncorrelated data (). Hence, there is a need for simpleto-use computational methods to analyze censored population data. Besides censoring, another challenge for computational analysis methods of single-cell data is the integration of data from multiple experimental conditions (e.g. different strengths of stimuli or multiple sampling times after an intervention on the biological system at hand) or multiple technical and biological replicates. Established approaches use a two-step procedure for this purpose. First, individual samples are described independently with finite mixture models. Thereafter, matching-based methods are applied to link the different samples (), e.g. to decide upon the appearance of identical subpopulations. These methods rely on similarity between distributions under different conditions. In the case of large changes in the corresponding distribution between experimental conditions, matching methods are not able to map the populations. To address this shortcoming, a Joint Clustering and Matching (JCM) approach () has been introduced. JCM allows for a more rigorous matching across samples and the consideration of intersample variability. For that purpose, a template model is fitted to the pooled samples and the individual samples are modeled as instances of this template by adding random effect terms to the template parameters. This approach is well-suited for analyzing the size of different distinct subpopulations in different samples. However, in case of small changes due to altered experimental conditions the subpopulation structure remains difficult to quantify. Furthermore, the template is constructed without considering inter-sample variability and a rigorous comparison of different biological hypotheses is not straight forward. In order to cope with these challenges, we introduce MEMO, a Multi-Experiment mixture MOdeling framework which is able to analyze samples from different experimental conditions simultaneously, can account for censoring and compares competing model hypotheses. MEMO uses maximum-likelihood inference to determine the subpopulation structure and properties of heterogeneous cell populations. MEMO is implemented in MATLAB and freely available via github (https://github.com/MEMO-toolbox/MEMO). We expect that MEMO can be used for a broad spectrum of univariate, censored single-cell data, e.g. FACS, CyTOF, qPCR and timelapse microscopy data. The data should-as for other statistical analysis methods-be appropriately preprocessed and the interesting dimension can be determined using dimension reduction methods (see, e.g.). In this study, we evaluate our method using simulated and experimental data. In particular, we analyze time-to-event single-cell microscopy data from multiple yeast strains. These cells were observed at discrete time points and only for a certain duration. Hence the data are interval and right censored. We found that, in contrast to navenave approaches, MEMO inferred the correct subpopulation structure for cases in which it was known. In addition, for more complex datasets containing multiple experimental conditions, MEMO revealed the existence of subpopulations for certain strains, some of which inherit the phenotypic properties of wild type cells. We demonstrate that MEMO even enables testing of competing hypotheses about underlying molecular mechanisms of the phenotype. In a second application on single-cell protein level data () we demonstrate how mechanistic information can be integrated in MEMO. Overall, our results demonstrate the additional benefit of a multi-experiment modeling framework and the importance of accounting for censoring, independent of how little it might be.
DiscussionMixture modeling of single-cell data is receiving increasing attention due to a rising number), and several software packages are available. FLAME () and flowClust () enable Gaussian, t and skew t mixture modeling of flow cytometry data and can also be used for other data types. In these implementations, multiple samples are handled using metaclustering or distribution matching. JCM () improves upon that by constructing template models and matching the individual samples to the template models. This approach even allows for the consideration of inter-sample variability, at least in the matching step. However, JCM does not facilitate an automatic matching of subpopulations across different experimental conditions, and-like all other methods-does currently not incorporate hypothesis testing methods. Furthermore, these packages do not account for censoring, which might lead to misinterpretations (). In this study we show that disregarding censoring generally results in an overestimation of the number of subpopulations. In case of interval censoring the severity depends on the ratio of censoring interval and inter-cell variability (). Multi-experiment mixture modeling using MEMO enables accurate reconstruction of subpopulation structures and properties from interval, left and right censored data. Inter-sample variability can be modeled using sample-specific scaling and offset parameters. By simultaneously analyzing multiple experiments, MEMO facilitates the comparison of different regulatory mechanisms. Thus, mixture modeling is no longer restricted to data analysis, but also allows to formulate and compare hypotheses how subpopulations are linked across different experimental conditions. As demonstrated, MEMO can also be combined with mechanistic modeling approaches. Furthermore, the characterization of experiment-dependent subpopulations is improved, since variability quantification is enriched by the entire dataset from multiple experiments. The results of MEMO can be used for subsequent modeling (). Applications to a broad range of data types, e.g. single-cell time-lapse (Section 4.2), and single-cell protein level snapshot data (Section 4.3) are possible. The approach can also be used in medical studies, where patients are not observed continuously or may drop out from the study. The current implementation of MEMO supports analytical functions to link experimental conditions. These functions encode hypotheses and can be derived from measurement data or mechanistic models, such as for example ordinary differential equation (ODE) constrained mixture models (ODE-MM) as described in. ODE-MMs use mechanistic models of single cell behavior and subpopulation structure to integrate data collected under different experimental conditions (), and could be used to reconstruct differences between subpopulations. MEMO provides an extension to ODE-MM as censored data can be studied and knowledge about the signaling pathway is not required. This renders MEMO more flexible and easier to use for explorative data analysis. The mechanistic modeling of single-cell snapshot data using MEMO demonstrated its flexibility concerning the data types and established that causal relations can be extracted. Furthermore, it revealed that parameter estimates using different data resolutions are consistent. For the inference of model parameters, MEMO uses a maximumlikelihood method along with efficient gradient-based optimization. Expectation maximization (EM) algorithms suitable for multi-experiment mixture models with censored data could reduce the computation time further and add to the robustness. Existing EM methods for censored data (Lee and Scott, 2012) will have to be extended to a multi-experiment setting. Model selection criteria implemented in MEMO could be complemented by deviance information criteria and Bayesian model selection (). MEMO is currently restricted to the analysis of censored and uncensored univariate data. An extension of MEMO to truncated and multivariate data is possible, the latter poses however several challenges. Among other, the evaluation of the likelihood for censored data requires the calculation of multivariate integrals (), which is already computationally intensive for the bivariate case (). Potential solutions might be provided by sparse grids (see () and references therein). As the analysis of multivariate data is currently not possible with MEMO, MEMO needs to be combined with preprocessing and dimension reduction approaches (). Moreover, depending on the experimental setup, prior to analysis the data may have to be corrected for experimental biases that mask the biological population structure (). To facilitate the biological interpretation of the results, a hierarchical view on cell populations should be incorporated in MEMO (). We also note that a full exploitation of the possibilities of MEMO requires some expertise in the biological system. This concerns the choice of the number of subpopulations to start with and in particular the generation of hypotheses on the relations between different experimental conditions. Furthermore, the user must provide reasonable parameter bounds for the optimization procedure. In this sense MEMO is an advanced tool that is not fully automatic. Nevertheless, its modular concept and the symbolic programming make MEMO's basic functionality intuitively accessible. In summary, we introduced a computational method for the efficient and integrated analysis of censored data that allows for rigorous hypothesis testing. The implementation of this method, MEMO, can facilitate the coherent and reliable analysis of single-cell data across experimental platforms. Such standardized analysis pipelines are essential in the age of single-cell data ().