Motivation: Several applications in bioinformatics, such as genome assemblers and error corrections methods, rely on counting and keeping track of k-mers (substrings of length k). Histograms of k-mer frequencies can give valuable insight into the underlying distribution and indicate the error rate and genome size sampled in the sequencing experiment. Results: We present KmerStream, a streaming algorithm for estimating the number of distinct k-mers present in high-throughput sequen-cing data. The algorithm runs in time linear in the size of the input and the space requirement are logarithmic in the size of the input. We derive a simple model that allows us to estimate the error rate of the sequencing experiment, as well as the genome size, using only the aggregate statistics reported by KmerStream. As an application we show how KmerStream can be used to compute the error rate of a DNA sequencing experiment. We run KmerStream on a set of 2656 whole genome sequenced individuals and compare the error rate to quality values reported by the sequencing equipment. We discover that while the quality values alone are largely reliable as a predictor of error rate, there is considerable variability in the error rates between sequencing runs, even when accounting for reported quality values.
INTRODUCTIONk-mers are one of the most fundamental objects used when analyzing DNA sequencing data. Many assembly algorithms () start by constructing a de Bruijn graph, a graph containing all k-mers for some fixed k. Some of the most commonly used algorithms for aligning reads to a reference genome start by finding short exact matches of a fixed length k (commonly referred to as a seed); an index of all k-mers is constructed and from this index an initial alignment of a part of the read is found.In this work, we focus on the problem of estimating the number of distinct k-mers in a set of sequencing reads. This problem is related to k-mer counting, in the sense that if we can solve k-mer counting we can report the number of distinct k-mers. However, the methods we develop are an order of magnitude faster and use only a fraction of the memory compared with current k-mer counting software. We develop streaming algorithms to solve this problem, a framework first proposed by. A similar approach is used by KmerGenie () which samples kmers to approximate the frequency histogram of k-mer occurrences. Sequencing errors cause considerable problems for k-mer based algorithms for both assembly and read mapping; in assembly these may cause the assembly to become disconnected and increases both the memory usage and computational time. In read mapping it may lead to increased computational overhead and the true location of the read not being found. The removal or correction () of erroneous bases and erroneous fragments is therefore a common preprocessing step in the analysis of DNA sequences, in particular when doing de novo assembly or read mapping to a reference assembly. Several programs () use k-mers to explicitly fix or remove sequencing errors in the dataset and it is recommended to use them prior to assembly (). A number of software programs have been written for quality control of DNA sequencing data, including FastQC (http:// www.bioinformatics.babraham.ac.uk/projects/fastqc/). FastQC has a number of functionalities useful for quality control, including giving a distribution of the quality values assigned by the sequencer, quality distribution by position, N content and GC content, identifying overrepresented k-mers and sequence length distribution. However, the k-mers identified tend to be short, 6 basepairs by default, and although they are useful for identifying contaminants they are not unique enough in the underlying genome to be useful for assessing the sequencing error rate, independent of what is given by the DNA sequencers. The problem of k-mer counting for high throughput sequencing data sets has been well studied (), given a set of reads report the coverage of each k-mer, i.e. how many reads contain that k-mer. Current methods for obtaining aggregate statistics of k-mer data are based on keeping track of all k-mers in a set ofMuch work has been done on reducing memory requirements, based on exact or approximately correct methods of keeping track of a large set of k-mers, this work includes using succinct set representations () or probabilistic encodings such as Bloom filters (), whereas recent advances have focused on more speed (). Although the impact on memory usage is considerable, compared to previous approaches, these methods require storing all k-mers, explicitly or implicitly, in memory. Thus the amount of resources will grow linearly with the input size. Many methods also rely on having access to all the reads for multiple passes over the data or require additional disk space for storing intermediate results. Thus all of the above methods suffer from 'the curse of deep sequencing' () in which more sequencing can overwhelm the program in terms of memory usage and the algorithms simply fail to make use of increased amounts of data.
DISCUSSIONThe amount of data being gathered with modern sequencing methods continues to grow at a faster rate than our ability to analyze and store the data. An alternative view to the current state of the art is to consider technologies that sequence DNA 'on the fly'. In this case, the sequencing machine does not store all the results, but rather transmits the sequence reads as they aregenerated. Technologies that fit this framework have been proposed () and are currently in development, such as technologies from Oxford Nanopore, but technical details are limited at this point in time. Regardless of the exact technologies used, this new sequencing paradigm opens up new opportunities for online or streaming analysis of the data, where we bypass the storage requirements, and simply plug the sequencing directly into the analysis. One benefit of the algorithms we have developed is as follows; F 0  f 1 is a crude estimate of the number of k-mers that have been sequenced at least twice, when this number goes above a certain fraction of the genome size we can decide to stop sequencing. Another benefit is that when the error rate goes above some threshold we can decide to stop the experiment immediately, not wasting our time on failed experiments. The method presented here can be particularly useful when used for a species that has not been previously sequenced, allowing us to get an estimate the coverage of this genome while sequencing prior to assembly. When we condition on the error rate given by Illumina we see considerable variability in the error rate between individuals. Hence, it is not advisable to use the error rates in a model without considering differences between individuals. Our results show that although the base pair quality values given by the sequencing equipment are largely correct, there appears to be a considerable sample-dependent difference in the error rate conditioned on the base pair quality rate reported by the manufacturer. Our recommendation based on the results of sequencing 2656 individuals is to estimate both the number of k-mers F 0 as well as the coverage and k-mer error rate for multiple q-value thresholds and decide on a case by case basis.Conflict of interest: None declared.