Motivation: Label-free quantification is an important approach to identify biomarkers, as it measures the quantity change of peptides across different biological samples. One of the fundamental steps for label-free quantification is to match the peptide features that are detected in two datasets to each other. Although ad hoc software tools exist for the feature matching, the definition of a combinatorial model for this problem is still not available. Results: A combinatorial model is proposed in this article. Each pep-tide feature contains a mass value and a retention time value, which are used to calculate a matching weight between a pair of features. The feature matching is to find the maximum-weighted matching between the two sets of features, after applying a to-be-computed time alignment function to all the retention time values of one set of the features. This is similar to the maximum matching problem in a bipartite graph. But we show that the requirement of time alignment makes the problem NP-hard. Practical algorithms are also provided. Experiments on real data show that the algorithm compares favorably with other existing methods.
INTRODUCTIONIn proteomics, a quantification experiment compares two or more biological samples with discover peptides that have significant quantity changes across the samples (). Such an experiment can potentially reveal important biomarkers that are relevant to the condition change across the samples (such as comparing a group of disease samples with a control group), and it is becoming an important tool for modern health research. In the LCMS (liquid chromatographymass spectrometry) experiment for peptide quantification, the LC separates the peptides in the complex sample according to the peptides' hydrophobicity and elutes them at different retention time. Then the MS measures all the mass values (more precisely, the mass-to-charge ratio) of the co-eluting peptides and produces a mass spectrum at each scanned retention time. From the raw LCMS data, many 'peptide features' are detected computationally (). Each correctly detected feature corresponds to a peptide in the sample and mainly consists of three pieces of information: the mass, the retention time and the signal intensity. For the same peptide, the signal intensity is approximately proportional to the abundance of the peptide in the sample. Thus, if one can confidently match the two features of the same peptide in the two samples, the peptide's quantity change can be estimated from the intensity ratio. Two major experimental approaches exist for peptide quantification: isotopic labeling and label-free (). They differ mostly by how the peptide features from the two samples are matched. In the isotopic labeling approach, two samples are labeled with different isotopic reagents and mixed together before the LCMS experiment. For most commercially available labeling reagents, the same peptides from the two samples appear at almost the same retention time and their matching becomes computationally simple. Although the labelfree method does not label the samples, it measures the two samples in separate LCMS runs. Because no isotopic labeling step is needed, the complexity of the experiment is greatly reduced. However, this also imposes a greater computational challenge for the peptide feature matching. The main difficulty of the feature matching for the label-free method is rooted in the inadequate reproducibility of the LC retention time. Because of factors such as aging, packing and contamination of the LC column, together with additional variability during experiment such as temperature, gradient shape and mixing physics, the retention time from different runs often shows large shifts and distortions. To match peptide features by using their mass and retention time information, the shifts and distortions need to be corrected. This is usually carried out by finding a monotonically increasing function f that maps the time t of one sample to the time f(t) of another. This process is often called the retention time alignment, or simply, time alignment (). Note that if the feature matching is available, the time alignment can be solved by fitting the times of the matched features with a smooth function. On the other hand, if the time alignment is known, the feature matching can be carried out by comparing the mass and the corrected time differences between features in the two samples. Although this is still not a trivial problem because of the existence of noise and close by features, its solution is not dauntingly difficult. The real challenge of the feature matching problem lies in the mutual dependence between the time alignment function and the feature matching. In the literature, the time alignment and the feature matching are usually dealt with in two separate steps. Most researches in *To whom correspondence should be addressed. the literature used heuristic algorithms to find either an initial set of matched feature pairs, or an initial time alignment function. Then they are used to find a new time alignment function or a new set of matched feature pairs, respectively. Naturally, such a procedure can be repeated iteratively to, hopefully, get more and more accurate result. This approach was typified by), which matched features with similar m/z values as the initial feature matching.used the robust point matching method to find an initial feature matching, and then carried out smooth monotone regression to find time alignment. When there are significant time shifts and distortions, as well as the present of noisy false features, the finding of the initial set of feature matching in the aforementioned approaches can become challenging. Note that this problem can be solved if the peptides of all the features are known. Then the features can be matched confidently by checking their peptide identities. Such approaches have already been proposed in previous research (). However, this requires additional MS/MS duty cycles of the instrument, which produce the MS/ MS spectra for the identification of the peptides. This reduces the number of MS scans at the same time. As a result, many of the low-abundance peptides from the limited amount of biological samples may not produce strong enough signal in the LCMS data and become undetectable. Therefore, if time alignment can be achieved without requiring MS/MS, it is advantageous to perform quantification without MS/MS. The peptides can be identified in a separate LCMS/MS run after the quantification, possibly with an inclusion list that targets the quantified peptide features, and using a less precious sample. In fact, there are even proposals in the literature to identify peptides purely based on the m/z and the aligned retention time of a peptide feature (). This application definitely requires the time alignment without MS/MS. For these reasons, in this article, we assume the peptide identities are unknown to the alignment algorithm. Other researchers focused on finding an initial time alignment function.assumed that the time alignment is a linear function: ft  a  t  b. A pair of coefficients a i , b i  was calculated from every two pairs of possibly matched features. The correct coefficients (a,b) were estimated by finding a dense cluster of all the calculated a i , b i . Noticing the time alignment is usually non-linear, a number of publications () only assumed local linearity of the time alignment, and applied linear regression on each local time window of the data. These works mostly differ at the methods used for local linear regression, and for connecting the local linear regression results into a global time alignment function. Although many of these reviewed methods have been used in practice, none of them defined a clear optimization goal for the peptide feature matching problem. There were usually biological justifications for each step of these published methods. But the property of the final output of a method was unclear. The situation is different from the common practice in traditional algorithmic research, where the optimization goal is usually specified mathematically before the algorithm is being developed. This situation is not uncommon in many emerging bioinformatics areas (including peptide quantification) because the biologists often need to have a solution quickly once an experimental method is invented, in which case an ad hoc solution has its value. Moreover, given the complexity of biology, the formulation of a tidy mathematical model is often difficult. But there are certainly disadvantages about this ad hoc type of research. An immediate one is that the final outcome of the algorithms is unpredictable without running the software on a specific input. As such, the performance of the algorithm remains at the mercy of the implementation details such as the choice of (many) parameters and sometimes even special considerations hard-coded in the software by a junior programmer to handle a special case of the training (and testing) data. Consequently, a method developed in one laboratory has the tendency to overfit the data of the laboratory and may not work as well in another laboratory or on a future instrument. We advocate that whenever possible, a combinatorial problem should be clearly defined. The separation of the problem formulation, the algorithm development and the program implementation can help reduce the aforementioned overfitting tendency. The field knowledge of the biologists should be used extensively and (almost) exclusively during the problem formulation stage to specify the desired property of the solution. And the algorithm development should strive to compute a solution that meets the specified property, instead of fitting the data that happen to be in the researcher's hands. The first purpose of this article is to provide a clearly defined combinatorial model for the feature matching problem in Section 2. We will then prove that the feature matching problem is NP-hard in Section 3. In Section 4, a slightly modified optimization goal is proposed, under which a polynomial time algorithm is presented. We show that the solution of the modified problem helps determine an upper-bound and a lower-bound of the optimal solution of the feature matching problem. This results in a practical algorithm for the feature matching problem with a performance guarantee for each given instance. In Section 5, the optimization goal is amended to control the smoothness of the time alignment function for feature matching. A polynomial time algorithm is also presented. Finally, Section 6 examined the performance of the algorithm on real LCMS data. Not only is the proposed model tidy but the algorithm's performance also compares favorably with other existing methods.