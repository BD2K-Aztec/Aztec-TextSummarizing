Currently, the Gene Expression Omnibus (GEO) contains public data of over 1 million samples from more than 40 000 microarray-based functional genomics experiments. This provides a rich source of information for novel biological discoveries. However, unlocking this potential often requires retrieving and storing a large number of expression profiles from a wide range of different studies and platforms. The compendiumdb R package provides an environment for down-loading functional genomics data from GEO, parsing the information into a local or remote database and interacting with the database using dedicated R functions, thus enabling seamless integration with other tools available in R/Bioconductor. Availability and Implementation: The compendiumdb package is written in R, MySQL and Perl. Source code and binaries are available from CRAN (http://cran.r-project.org/web/packages/compen diumdb/) for all major platforms (Linux, MS Windows and OS X) under the GPLv3 license.
IntroductionPublic repositories such as the Gene Expression Omnibus (GEO) () and ArrayExpress () provide a large amount of functional genomics data from a wide range of studies performed in different organisms and on different (microarray) platforms. However, retrieving and systematically storing these datasets to extract novel biological information is often challenging. Several tools and web-based resources have been developed (expression data, sample and probe annotation to the relational database and (iii) convert experimental data from the database to an R/Bioconductor ExpressionSet.
DescriptionThe compendiumdb package has been developed around a MySQL database designed for storing data from GEO. The database schema is provided with compendiumdb and is described in detail at http:// wiki.bioinformaticslaboratory.nl/foswiki/bin/view/BioLab/Compen diumDB. After creating an empty database, one connects to it and loads the database schema: conn -connectDatabase (user " user " , password " passwd " , dbname " compendium " ) loadDatabaseSchema (conn,updateSchema  TRUE)By default, this establishes a connection to a database running on a local machine but using the argument host of connectDatabase one can also connect to a database on a remote server. This way the database can be conveniently deployed in a multi-user environment. Functional genomics datasets in the form of Simple Omnibus Format in Text (SOFT) files can be downloaded from GEO by specifying the GEO series record (GSE) identifier. The downloaded preprocessed expression data, sample and probe annotation can then be loaded into the database: downloadGEOdata(GSEid " GSE18290 " ) loadDataToCompendium(conn,GSEid " GSE18290 " ) Probe annotation is automatically retrieved from GEO platform records (GPL) and updated to the most recent annotation for those platforms listed on http://ftp://ftp.ncbi.nlm.nih.gov/pub/geo/DATA/ annotation/. Sample annotation is retrieved from the information provided in each GEO sample record (GSM). For those experiments that have been curated by GEO staff into a GEO dataset (GDS), the sample annotation is retrieved automatically from the GDS. Sample annotation as stored in the compendium database can be further curated and updated using the function updatePhenoData. Experimental data stored in the database can be extracted as an R/Bioconductor ExpressionSet enabling straightforward integration with other tools available in R/Bioconductor: esets -createESET(conn, " GSE18290 " )The function createESET conveniently parses the metadata provided for each sample into separate columns for each of the variables and stores them in the phenoData slot of the ExpressionSet, facilitating down-stream analysis. Using these functions, downloading 39 GSEs from GEO and loading the corresponding 7970 samples in the compendium database took 5.5 h on a single core of a Linux (Red Hat 4.4.7-9, 64-bit) server containing 10 Intel(R) Xeon(R) CPU E52690 v2 @ 3.00GHz processors having 64 GB of random access memory. Subsequent extraction as ExpressionSets took 0.3 h. For each GSE, a detailed breakdown of the time to download, load and extract data is given in Supplementary File S1. Next to the main functions described earlier, one can also tag experiments using keywords (tagExperiment), enabling easy extraction of a set of related experiments from the database, and extract a succinct overview of the experiments contained in the database (GSEinDB). Note that while the package conveniently shields the user from having to write SQL queries, the database can also be queried directly to extract information that is not easily accessible via the functions provided with the package. Further information on how to install compendiumdb, other functionalities and more detailed examples are provided in the package vignette (Supplementary File S2).