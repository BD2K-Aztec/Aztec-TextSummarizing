Motivation: Over the last decades, vast numbers of sequences were deposited in public databases. Bioinformatics tools allow homology and consequently functional inference for these sequences. New profile-based homology search tools have been introduced, allowing reliable detection of remote homologs, but have not been systematically benchmarked. To provide such a comparison, which can guide bioinformatics workflows, we extend and apply our previously developed benchmark approach to evaluate the next generation of profile-based approaches, including CS-BLAST, HHSEARCH and PHMMER, in comparison with the non-profile based search tools NCBI-BLAST, USEARCH, UBLAST and FASTA. Method: We generated challenging benchmark datasets based on protein domain architectures within either the PFAM Ã¾ Clan, SCOP/Superfamily or CATH/Gene3D domain definition schemes. From each dataset, homologous and non-homologous protein pairs were aligned using each tool, and standard performance metrics calculated. We further measured congruence of domain architecture assignments in the three domain databases. Results: CSBLAST and PHMMER had overall highest accuracy. FASTA, UBLAST and USEARCH showed large trade-offs of accuracy for speed optimization. Conclusion: Profile methods are superior at inferring remote homologs but the difference in accuracy between methods is relatively small. PHMMER and CSBLAST stand out with the highest accuracy , yet still at a reasonable computational cost. Additionally, we show that less than 0.1% of Swiss-Prot protein pairs considered homologous by one database are considered non-homologous by another, implying that these classifications represent equivalent underlying biological phenomena , differing mostly in coverage and granularity. Availability and Implementation: Benchmark datasets and all scripts are placed at (http://sonnham mer.org/download/Homology_benchmark).
IntroductionModern molecular biology relies on evolutionary conservation of properties between entities such as genes and proteins that are homologous, i.e. share descent from a common ancestor. As a historical property homology is unobservable but can be inferred from statistically significant similarity under the proper conditions (). Through homology relationships (and within them, specifically orthology relationships where common ancestry dates back to a species diversification rather than a gene duplication), insights into molecular function of whole sequences () or specific sites (), 3D structure (), () or context such as regulation can be transferred. Such transfer of results from direct experimentation to the components of the vast number of genomes for which only molecular data is available, courtesy of 'next-generation' nucleotide sequencing techniques, means homology inference forms a mainstay in bioinformatics research as well as in its applications in organismal, clinical and evolutionary biology. These methods started with the SmithWaterman algorithm () for exact computation of the minimal number of changes needed to convert one sequence into another. Gradually more complex probabilistic models were developed taking implicitly into account the structural constraints and codon properties of nucleic acid substitutions, insertions and deletions. Sequence alignment/homology search/homology scoring methods quickly became overwhelmed by computational complexity as database sizes increased, prompting development of heuristic tools like FASTA () or NCBI-BLAST () which function fast enough to screen the whole of the known sequence universe for similarity to a novel uncharacterized query. With heuristic approaches come increased risk of error, and given the potential importance of downstream applications such as function prediction, the need becomes clear to properly evaluate the reliability of homology inference tools. This is in itself not a trivial problem, since such benchmarking ideally should involve a 'gold standard' where homology statuswhether shared common ancestry holds or notshould be known with perfect certainty, which is in principle never the case. The existence of well-conserved 'building blocks' of protein sequence and structure, as in domain/gene families where in many cases subtle sequence similarity is supported by clearer similarity of the slower-evolving protein 3D structure (), makes for a potential workaround. Early on a preferred benchmark was evaluating single-domain sequences from same or different structural superfamilies as a proxy for certain positive or negative homology status (). This disregards the theoretical and practical difficulties which arise when domain rearrangement or other forms of horizontal evolution causes mosaic gene lineages (), where different regions have different homologs, which is a complexity that the approach described here also disregards. More tractable difficulties for homology inference arises either when sequences have diverged too far (risk of failing to detect homology) or are unexpectedly similar due to similar sequence composition biases and/or low-complexity region features (risk of falsely inferring homology). Several issues in creating benchmarking datasets have been discussed earlier (). Low-complexity regions occur relatively seldom within well-characterized single-domain sequences, but will occur elsewhere in proteins, making single-domain benchmarks underestimate the risk of false positives in genome-scale homology inference applications. To remedy this, we previously () described an approach for generating 'gold standard' test cases for homology inference by selecting pairs of multi-domain proteins where either all corresponding domains match at the super-family/clan level (positive gold standard) or where none of them do (negative gold standard). Using this approach, we compared different low-complexity filter settings for the NCBI-BLAST homology search tool, and found that compositional adjustment of score matrices allowed minimization of false positives, though sometimes at the price of truncated alignments. More recent developments in homology inference involve profile-based tools for detecting remote homologies, using profilespecific score matrices (PSSMs) (), Hidden Markov Models (HMMs) () or other techniques (). These 'next-generation' homology search tools may offer greater sensitivity and search speed (), and because of these promises, the need for formal evaluation of their reliability arises (). Consequently, we expanded on our previous benchmark approach to construct an updated evaluation dataset, then tested the latest versions of the 'next-generation' homology search tools for precision, accuracy and speed. Additionally, we applied our benchmarking method to all three major domain family databases: SUPERFAMILY (extending SCOP,), Gene3D (extending CATH, Lees et al., 2013) and Pfam (), where previously only Pfam was used. This was done with the intent that the similarity of benchmark results derived from different databases would provide a test of to what extent, beyond differences in scope or coverage, that these resources, built from different types of data and using different curation protocols, reflect the same underlying evolutionary entities seen through different definition schemes, a question which has been raised in some recent studies (). details on this set of genomes. Within this set of sequences, for each domain database, we considered each distinct protein multi-domain architecture (PMDA) separately. In the case of Pfam, consecutive repeat/motif-type domains, were collapsed to a single instance as in Forslund and Sonnhammer (2009), because repeat numbers are highly variable. Protein pairs were sampled to avoid biasing the analysis towards highly populated gene families. For each architecture, one (if only one exists) or two proteins with that architecture were randomly chosen from each genome in the benchmark, and the set of pairs these proteins define were included, aiming to ensure both within-species and across-species homologies at different evolutionary distance was sampled for each architecture. Negative test cases (pairs of non-homologous proteins) were sampled by choosing a protein from the architecture in question and another randomly selected architecture meeting the criterion for non-homology, i.e. no domains shared in any order even at clan or superfamily level, until there were as many negatives as positives for each PMDA. See Supplementaryfor details on the number of pairs generated for the final benchmark dataset. For each protein pair evaluated, each pair was aligned (i.e. one protein used as database, one as query) using each of the profilebased homology search tools CS-BLAST (), HHSEARCH () and PHMMER () as well as the non-profile based NCBI-BLAST (), USEARCH/UBLAST () and FASTA () for comparison. All methods were run with default parameters where not otherwise noted (see Supplementaryfor details). The recently developed DELTA-BLAST () was omitted, because it relies on a database of sequence families aside from what is provided at runtime via query and search database input. Similarly tools relying on iterative searches to build intermediate profiles from additional database sequences (e.g. PSIBLAST;; or CSI-BLAST) were not included, since their performance depends strongly on the number of iterations and the composition of the database relative to the query, making their evaluation in the present pairwise context difficult. While HHsearch primarily is intended for use with multiplesequence queries, here only its performance with single-sequence queries is evaluated, in line with the other methods testedperformance thus might be relatively better in a context other than pairwise sequence comparisons. The score of the best high-scoring segment pair (HSP) reported was used, with no attempt to merge together multiple hit fragments, which also matches the common use cases for these tools. Each tool was applied using default settings except for setting any inclusion/reporting thresholds maximally inclusive so as to be able to compare scores also for non-homologous pairs. Even so, some very divergent or non-homologous sequence pairs were not reported even as very poorly-scoring alignments. For these pairs, a maximally poor 'proxy' score (bit score  0) was assigned. When ordering pairs by score for comparisons (e.g. Receiver Operating Curves (ROC)) (), in cases of multiple pairs sharing the same score (either the not-found proxy or otherwise), positive and negative cases were evenly distributed within these stretches of pairs so as not to introduce artifacts. Seefor a schematic of the workflow as a whole.
DiscussionGiven the role of homology inference in genome-scale biology, validation and comparative benchmarking of the tools in use is important, even where it is difficult in both theory and practice to A B Cplots showing cumulative true and false positive counts as tested protein pairs (single-sequence query and search database for each pair) are sorted based on the bit scores provided by each method. The curves are ranked by corresponding Area Under Curve scores computed for the first 1000 false positives (AUC1000). Results are shown based on Pfam (A), SUPERFAMILY (B) and Gene3D (C). These benchmarks exclude any proteins with 50AA regions without domain assignments. SupplementaryC show corresponding plots for a dataset where this constraint is removed, leading to the inclusion of many more proteins with disordered regions; the here observed trends were largely replicated