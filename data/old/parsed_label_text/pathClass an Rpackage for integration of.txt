Prognostic and diagnostic biomarker discovery is one of the key issues for a successful stratification of patients according to clinical risk factors. For this purpose, statistical classification methods, such as support vector machines (SVM), are frequently used tools. Different groups have recently shown that the usage of prior biological knowledge significantly improves the classification results in terms of accuracy as well as reproducibility and interpretability of gene lists. Here, we introduce pathClass, a collection of different SVM-based classification methods for improved gene selection and classfication performance. The methods contained in pathClass do not merely rely on gene expression data but also exploit the information that is carried in gene network data. Availability: pathClass is open source and freely available as an R-Package on the CRAN repository at http://cran.r
INTRODUCTIONMicroarray studies are commonly used in clinical cancer research to investigate molecular profiles associated with tumor development and progression. Several thousand genes are measured to identify predictive or prognostic gene signatures comprising only a couple of genes. The goal is to use these gene signatures for stratification of patients according to clinical relevant endpoints. Classification algorithms are frequently used to identify gene signatures. The support vector machine (SVM,) is a well-known example of such a classification algorithm. Several groups have proposed the so-called feature / gene selection methods for the SVM since the algorithm does not offer an embedded feature selection mechanism. Despite the identification of biomarkers, the aim of feature selection is to reduce the dimensionality of the feature space in order to avoid the so-called curse of dimensionalty (), that is overfitting. Overfitting occurs when the number of features (genes) is large and the amount of samples (i.e. patients) is comparatively small, which is often the case when performing microarray studies. Thus, the algorithm can easily find a hyperplane that separates the training examples. However, the