We present a massively parallel stochastic simulation algorithm (SSA) for reaction-diffusion systems implemented on Graphics Processing Units (GPUs). These are designated chips optimized to process a high number of floating point operations in parallel, rendering them well-suited for a range of scientific high-performance computations. Newer GPU generations provide a high-level programming interface which turns them into General-Purpose Graphics Processing Units (GPGPUs). Our SSA exploits GPGPU architecture to achieve a performance gain of two orders of magnitude over the fastest existing implementations on conventional hardware. Availability: The software is freely available at
INTRODUCTIONTreating chemical reaction systems as spatially homogeneous is insufficient for many applications in a biological context. Often, spatial distributions play an important role in the dynamic evolution of biomolecular systems. The analysis of such systems requires accurate yet highly performant simulation algorithms that can handle spatially inhomogeneous reactiondiffusion (). Unfortunately, stochastic simulation methods for this problem are computationally extremely expensive and it thus becomes necessary to build parallel versions of existing algorithms (). GPGPUs can potentially provide high-performance computing resources to a broad audience and are consequently becoming increasingly popular for scientific computing. In the present article, we present a data-parallel GPGPU implementation of an SSA, which achieves significant performance gains over the fastest conventional implementations. To the best of our knowledge, this is the first time that a data-parallel GPGPU implementation of a quantitative SSA for spatially heterogeneous reaction-diffusion networks is reported. Several approaches to compute the stochastic time evolution of reactiondiffusion networks can be found in the literature, such as agent-based models (), first-passage kinetic * To whom correspondence should be addressed. Monte Carlo algorithms () or, on a mesoscopic level, compartment-based models, such as the Next-Subvolume Method (NSM) (). Not all these methods lend themselves equally well to a dataparallel implementation on GPGPUs. The standard algorithms, based on Gillespie's next reaction method (), perform an event-based simulation in which global communication is required to compute the next event time as well as to determine the corresponding reaction. Due to the high cost of global synchronization and inter-node communication, attempts to implement the Gillespie SSA directly on GPGPUs could only yield moderate performance gains (). Petzold andpursue a different approach by running many instances of the same model in parallel on a GPGPU. This technique allows immediate parallelization of sequential algorithms but cannot speed up individual runs and can thus only exploit the full hardware potential if a large number of simulations are required. For a full parallelization, methods that treat diffusion seperately from reactions appear to be more promising. Such methods are termed hybrid. One can distinguish between deterministic stochastic algorithms, where diffusion is handled in a deterministic manner (), and stochasticstochastic methods, which are preferable for cases where the diffusive species is not necessarily present in high densities. Two prominent examples of the latter type of hybrid algorithms are the Gillespie Multiparticle Method (GMP), first presented by, and the Multinomial Simulation Algorithm (MSA) (). In this article, we report a GPGPU implementation of GMP. Hybrid stochastic reactiondiffusion algorithms are an active and relatively recent field of research and no clear champion has emerged yet. Cellular automata methods are widely used to simulate reactiondiffusion systemsfor a comprehensive review]. In particular, the multiparticle lattice gas algorithm underlying GMP () has been successfully applied, for example, to problems in electrochemistry (). Its applicability to biochemical pathways has been shown in a number of studies, e.g. for the phosphoenolpyruvatedependent phosphotransferase (PTS) pathway in Escherichia coli (). We believe that MSA should in principle be just as well suited for a data-parallel implementation. However, the free availability of the source code made GMP our first choice. A detailed comparison of computational methods for reaction diffusion networks is given by. For completeness, we point out that the deterministic treatment of reactiondiffusion equations with GPGPUs has a long history in the context of computer graphics. The driving motivation behind
DISCUSSIONWe have described an implementation of the Gillespie Multiparticle Method (GMP) on GPGPUs. We report performance gains of two orders of magnitude compared with standard implementations of the (exact) inhomogeneous stochastic simulation algorithm and the (hybrid) serial implementation of GMP. Like any other hybrid method, GMP sacrifices some numerical accuracy for performance gains. This trade-off can in principle be arbitrarily adjusted through the choice of the diffusion time step. For a more detailed discussion, we refer the reader to Section 2.2.7 of the Supplementary Material. We provide a full simulation system (Inchman) that allows the user to run their models without any coding (on the Monash Sun Grid GPU cluster). Access to this system is via an easy-to-use web interface 3 that understands systems biology markup language (SBML) specifications, the lingua franca of systems biology. In addition, we provide a full implementation of the algorithm on our website. Researchers may use the C++ interface to construct their own reaction-diffusion model from scratch. The application programming interface (API) is designed to mimic the structure of SBML models, allowing the user to easily convert their models into GPGMP without having to deal with the internal details of the simulation algorithm. A variety of test problems that can be used as templates are part of the package. The full source code is included so the user can easily add the relevant GPU implementation into their own projects. Most scientific applications require a reasonable sample size to extract statistic information from the simulations. It is therefore necessary to perform multiple runs of the same problem, possibly with varying input parameters. We pursue a 2-fold approach to tackle this requirement. First, the standard implementation of GPGMP distributes the total number of runs over all available GPGPU cards. This works best if the host machine provides a one-to-one ratio of CPU cores to GPGPU cards. Second, we are integrating Inchman with Nimrod, 4 a toolkit to allow users to run parameter sweeps and parameter optimization and distribute runs over GPGPU clusters. This will become an integral part of the next release of Inchman.