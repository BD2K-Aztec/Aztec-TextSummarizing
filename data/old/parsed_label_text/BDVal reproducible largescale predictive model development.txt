High-throughput data can be used in conjunction with clinical information to develop predictive models. Automating the process of developing, evaluating and testing such predictive models on different datasets would minimize operator errors and facilitate the comparison of different modeling approaches on the same dataset. Complete automation would also yield unambiguous documentation of the process followed to develop each model. We present the BDVal suite of programs that fully automate the construction of predictive classification models from high-throughput data and generate detailed reports about the model construction process. We have used BDVal to construct models from microarray and proteomics data, as well as from DNA-methylation datasets. The programs are designed for scalability and support the construction of thousands of alternative models from a given dataset and prediction task.
INTRODUCTIONThe technical ability to assay levels of molecules in biological material has evolved dramatically in the last decade. Various technologies now make it possible to assay a large number of features in individual patients. These data can be used to train models to predict information of clinical interest (such as the response of a patient to a given treatment), or a specific biological attribute of a sample. Since it is not clear a priori which modeling approach will yield a competitive model for a given problem, several modeling approaches are often compared on the same dataset to yield estimates of future performance for each model that they produce. Performance estimation and model selection is often done with cross-validation (). Several authors have noted that complete cross-validation must be used to avoid optimistically biasing the estimates of performance that result from the evaluation (). In complete cross-validation, the feature selection approach is used within each fold of cross-validation to select features used to train the model. Performance estimates can also be biased when choosing a model with the parameters * To whom correspondence should be addressed. that maximize performance estimated from the training set (). Tibshirani and Tibshirani (2009) have recently described a practical and scalable approach to estimate such a parameter selection bias. In this application note, we present the BDVal suite of programs, a set of software tools designed to automate the process of developing and evaluating the performance of predictive classification models in high-throughput datasets. BDVal supports several modeling approaches, complete cross-validation and can estimate the Tibshirani and Tibshirani (2009) parameter selection bias.