
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:56+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structural bioinformatics Protein fold recognition using geometric kernel data fusion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Pooya</forename>
								<surname>Zakeri</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Engineering (ESAT)</orgName>
								<orgName type="department" key="dep2">STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics</orgName>
								<orgName type="institution">KU Leuven</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">iMinds Medical IT</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Ben</forename>
								<surname>Jeuris</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<postCode>3001</postCode>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Raf</forename>
								<surname>Vandebril</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<postCode>3001</postCode>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yves</forename>
								<surname>Moreau</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Electrical Engineering (ESAT)</orgName>
								<orgName type="department" key="dep2">STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics</orgName>
								<orgName type="institution">KU Leuven</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">iMinds Medical IT</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Structural bioinformatics Protein fold recognition using geometric kernel data fusion</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">13</biblScope>
							<biblScope unit="page" from="1850" to="1857"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu118</idno>
					<note type="submission">Advance Access publication March 3, 2014 Received on August 30, 2013; revised on January 31, 2014; accepted on February 22, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Belgium Associate Editor: Anna Tramontano Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Various approaches based on features extracted from protein sequences and often machine learning methods have been used in the prediction of protein folds. Finding an efficient technique for integrating these different protein features has received increasing attention. In particular, kernel methods are an interesting class of techniques for integrating heterogeneous data. Various methods have been proposed to fuse multiple kernels. Most techniques for multiple kernel learning focus on learning a convex linear combination of base kernels. In addition to the limitation of linear combinations, working with such approaches could cause a loss of potentially useful information. Results: We design several techniques to combine kernel matrices by taking more involved, geometry inspired means of these matrices instead of convex linear combinations. We consider various sequence-based protein features including information extracted directly from position-specific scoring matrices and local sequence alignment. We evaluate our methods for classification on the SCOP PDB-40D benchmark dataset for protein fold recognition. The best overall accuracy on the protein fold recognition test set obtained by our methods is $86.7%. This is an improvement over the results of the best existing approach. Moreover, our computational model has been developed by incorporating the functional domain composition of proteins through a hybridization model. It is observed that by using our proposed hybridization model, the protein fold recognition accuracy is further improved to 89.30%. Furthermore, we investigate the performance of our approach on the protein remote homology detection problem by fusing multiple string kernels. Availability and implementation: The MATLAB code used for our proposed geometric kernel fusion frameworks are publicly available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Knowledge on functions of proteins can be provided by information about their tertiary structure; hence, determining this structure is among the most essential objectives in molecular biology, cell biology, proteomics and bioinformatics. Structural information also provides a much better understanding of protein–protein interaction. Furthermore, this information is potentially useful for drug design studies. Unfortunately, experimentally identifying the 3D structure of proteins is expensive and time-consuming. By contrast, recent development in genome sequencing projects has tremendously increased the number of protein coding sequences. Because there is much slower growth in information on 3D structure, there is an increasing gap between the protein sequence information and protein structure information. Despite these problems, knowledge about protein folds can be useful in determining its structural properties. Because of the limitation of homology modelling methods, when there is no sequence similarity to homologous proteins of known structure, the taxonomic approach is usually considered as a trustworthy alternative. This approach is based on the assumption that the number of protein domain folds is restricted (<ref type="bibr" target="#b16">Dubchak et al., 1999;</ref><ref type="bibr" target="#b29">Murzin et al., 1995</ref>). Promising results are reported using taxonomic approaches (<ref type="bibr" target="#b14">Ding and Dubchak, 2001</ref>;<ref type="bibr" target="#b38">Shen and Chou, 2006;</ref><ref type="bibr" target="#b45">Yang et al., 2011</ref>), but they are still far from tackling the classification of protein folds completely. So, fold recognition or protein threading is still among the most challenging tasks in bioinformatics. In many bioinformatics tasks, it is worthwhile to consider several representations of the data, which will not always be vectors. In particular, we should be able to deal with them using the same algorithm, regardless whether they are represented as binary vectors, real vectors on different scales, sequences, graph data, etc. Various approaches based on features extracted from protein sequence and often machine learning approaches have been used to tackle the fold recognition problem. Several informative fold data sources can be constructed based on various representative models of protein features (PFs), such as primary structural information (<ref type="bibr" target="#b8">Chen and Kurgan, 2007;</ref><ref type="bibr" target="#b14">Ding and Dubchak, 2001;</ref><ref type="bibr" target="#b45">Yang et al., 2011</ref>), local pairwise sequence alignment-based feature spaces (<ref type="bibr" target="#b12">Damoulas and Girolami, 2008</ref>), physicochemical properties of constituent amino acids (<ref type="bibr" target="#b14">Ding and Dubchak, 2001;</ref><ref type="bibr" target="#b26">Lin et al., 2013</ref>) and sequence evolution information (<ref type="bibr" target="#b8">Chen and Kurgan, 2007;</ref><ref type="bibr" target="#b22">Kavousi et al., 2011;</ref><ref type="bibr" target="#b37">Sharma et al., 2013;</ref><ref type="bibr" target="#b40">Shen and Chou, 2009;</ref><ref type="bibr" target="#b45">Yang et al., 2011</ref>). More attention needs to be paid to finding an efficient and cost-effective technique for integrating these different discriminatory data sources for protein fold classification. Nevertheless, to deal with biological data, there are not only a lot of issues in machine learning algorithms but also a lot of difficulties in data analysis. Full integration and decision integration are common techniques for fusing protein fold data sources. In particular, full integration is a fast and easy way to fuse data sources. However, because of heterogeneity of the *To whom correspondence should be addressed. ß The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com biological data, combining data sources at the data level is not always feasible in practice. By contrast, fusing data sources at decision level, such as in the ensemble learning framework, is considered as an intuitive manner to deal with heterogeneous data. Various decision-based integration approaches have been proposed for protein fold classification (<ref type="bibr" target="#b22">Kavousi et al., 2011;</ref><ref type="bibr" target="#b26">Lin et al., 2013;</ref><ref type="bibr" target="#b30">Nanni, 2006;</ref><ref type="bibr">Chou, 2006, 2009;</ref><ref type="bibr" target="#b45">Yang et al., 2011</ref>). In addition to limitations of using ad hoc ensemble learning, the computational cost of decision-based approaches increases corresponding to the number of data sources. The heterogeneous biological data sources can also be integrated intelligently using partial integration, such as kernelbased data fusion. Using kernel methods is an elegant and versatile strategy because it decouples the original data from the machine learning algorithms by using a representation of the data as a kernel matrix. The main idea behind kernel methods is, rather than using original data directly, to use only a kernel matrix. Symmetric positive definite (SPD) kernel matrices are the non-linear extension of covariance/correlation matrices and encode the similarity between samples in their respective input space. This implies that the heterogeneous data (binary vectors, real vectors on different scales, graph data) can all be replaced by appropriately scaled kernel matrices, which all have the same size, and thus that the data heterogeneity disappears. Then other algorithms (such as classification, clustering and prioritization) can access the same data, which is currently not possible. Constructing the same representation for all datasets and integrating these representations systematically is the main intuition behind kernel fusion methods. In the simplest scenario, we can compute kernel matrices separately for each data source and then average them together. The standard approach for combining kernel matrices is to take the (weighted) arithmetic average. There are several methods for obtaining a valid and fitting kernel by tuning the kernel matrices weights (Go¨nen<ref type="bibr" target="#b18">Go¨nen and Alpaydin, 2011</ref>). Finding such weights from training data and replacing the single kernel by a linear combination of weighted base kernels is usually referred to as multiple kernel learning (MKL). These weights can also be interpreted as their corresponding importance in the fused kernel. During the past decades, several MKL methods have been proposed in the literature (<ref type="bibr" target="#b3">Bach et al., 2004;</ref><ref type="bibr">Lanckriet et al., 2004a,b;</ref><ref type="bibr" target="#b41">Sonnenburg et al., 2006;</ref><ref type="bibr" target="#b33">Rakotomamonjy et al., 2008;</ref><ref type="bibr" target="#b42">Vishwanathan et al., 2010</ref>) and are shown to yield good results in various applications, in particular in bioinformatics applications (<ref type="bibr" target="#b13">De Bie et al., 2007;</ref><ref type="bibr" target="#b24">Lanckriet et al., 2004b;</ref><ref type="bibr" target="#b47">Ying et al., 2009;</ref><ref type="bibr" target="#b48">Yu, 2011;</ref><ref type="bibr" target="#b50">Zien and Ong, 2007</ref>). Most of these approaches try to learn a linear combination of base kernels, which can be interpreted as the concatenation of the base kernel feature space or an 'OR' combination of the individual kernels. The kernel integration problem is often reduced to a convex optimization problem. In addition to the limitation of linear combinations, solving this optimization problem is only possible for a small number of kernels and small number of data points. Furthermore, because this type of averaging is often sensitive to deal with complementary and noisy kernels, it is not appropriate for biological data. In fact, going with such approaches could cause a loss of potentially useful latent information in the data. Recent biological applications have demonstrated that even using uniformly weighted kernel integration can boost the generalization capability of the decision function (<ref type="bibr" target="#b11">Daemen et al., 2009;</ref><ref type="bibr" target="#b13">De Bie et al., 2007;</ref><ref type="bibr" target="#b24">Lanckriet et al., 2004b;</ref><ref type="bibr" target="#b47">Ying et al., 2009</ref>). By contrast, the results obtained by using such averaging of the kernel matrices are comparable with the results of the best existing MKL approaches in general applications (<ref type="bibr" target="#b13">De Bie et al., 2007;</ref><ref type="bibr" target="#b24">Lanckriet et al., 2004b;</ref><ref type="bibr" target="#b47">Ying et al., 2009</ref>). Hence, using the uniformly weighted average of the base kernels can be considered as a reliable and computationally more scalable alternative. Uniformly weighted kernel integration can also be considered as the arithmetic mean (AM) of kernel matrices, which is always a generator of a valid Mercer kernel. Similar to the AM, other types of means of SPD matrices [such as the harmonic mean (HM), Log-Euclidean mean (LogEM;<ref type="bibr" target="#b2">Arsigny et al., 2007</ref>) and geometric mean (GM)] result in SPD kernels. In this study, we propose and develop several new techniques that combine the Mercer kernel matrices through other types of averaging than convex linear combination. Such averaging of the base kernels can be interpreted as a kind of fusion that expresses the non-linear relationship between the individual kernels. In particular, we focus on taking the matrix GM of base kernels. However, computing the GM of a general number of SPD matrices is a challenge. In fact, for a general number of SPD matrices, a proper definition of a GM with some natural properties has only recently been developed (<ref type="bibr" target="#b4">Bhatia, 2007</ref>). We present two methods for computing the GM. The first approach is focused on computing the actual GM using the definition of the Karcher mean (<ref type="bibr" target="#b20">Jeuris et al., 2012</ref>). The second, however, only computes a rough approximation of the actual GM using a proposed heuristic method based on Arithmetic-Geometric-Harmonic (AGH) mean. We show in the second section that it is a computationally scalable method for computing an approximate GM. We also consider the behaviour of combining kernels by taking HM and log-EM, where this last one can be seen as a consensus between the AM and GM. Moreover, our computational model has been developed by incorporating the functional domain information through the hybridization model. Experimental results on the SCOP PDB-40D benchmark dataset (<ref type="bibr" target="#b14">Ding and Dubchak, 2001</ref>) demonstrate that our integration technique can effectively improve the accuracy of the state-of-the-art kernel fusion model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GEOMETRIC KERNEL FUSION</head><p>To improve the efficiency of kernel data fusion through the convex combination of kernel matrices, there are several complex convex optimization-based approaches (<ref type="bibr" target="#b3">Bach et al., 2004;</ref><ref type="bibr" target="#b23">Lanckriet et al., 2004a;</ref><ref type="bibr" target="#b33">Rakotomamonjy et al., 2008;</ref><ref type="bibr" target="#b41">Sonnenburg et al., 2006;</ref><ref type="bibr" target="#b42">Vishwanathan et al., 2010</ref>) that try to optimize the kernel weights based on different optimization criteria. The optimized weights of kernel matrices reflect the relative importance of the different dataset in the fused kernel. It is expected that the kernel matrices that have more information than others receive higher weights in such weighted convex linear combination. However, convex combination of kernel matrices often leads to mixed results. Moreover, it has also been shown that optimization of weights causes an improvement in performance only when dealing with redundant or noisy kernel matrices (<ref type="bibr" target="#b24">Lanckriet et al., 2004b</ref>). Linear convex combination of kernel matrices often fails to fully capture all the information for kernels containing complementary non-redundant information. This is, however, a typical situation in biological applications. This is also affirmed by the equal weights theorem (<ref type="bibr" target="#b43">Wainer, 1976</ref>), which states when all optimized weights are uniformly distributed on the interval<ref type="bibr">[0.25; 0.75]</ref>, the performance is barely changed using equal weights. Therefore, when dealing with many data sources, which are all not informative, a more practical scenario could be to select the reliable data sources and discard the rest, then take an unweighted averaging between kernel matrices. Using the Euclidean distance on a convex cone whose interior contains all SPD matrices PðnÞ, we can obtain the AM. For a given set of SPD kernel matrices K 1 , K 2 , :::, K n , the AM is given by AðK 1 , K 2 , :::, K n Þ ¼ 1 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ð1Þ</head><p>This leads to the fusion of K 1 and K 2 as FðK 1 , K 2 Þ ¼ GðK 1 , K 2 Þ. The GM has several properties that make it useful, of which an important one is its invariance under inversion. On the contrary, the AM is not invariant under inversion, which means that if</p><formula>K ¼ 1 n P n i¼1 K i , then in general, K À1 6 ¼ 1 n P n i¼1 K À1 i .</formula><p>This property becomes interesting when kernel matrices are considered under analogy to covariance matrices of Gaussian distributions. In the Gaussian case, the covariance matrix K can be used as a positive semi-definite kernel representation of a data sources. But the covariance matrix is not the most interesting object to investigate. For a multivariate normal distribution, the precision matrix P (which is the inverse of the covariance matrix, P ¼ K À1 ) encodes independence relations between variables in the form of partial correlations. Zeros in the precision matrix indicate some notion of partial correlation independence between two variables. Some immediate manipulations result in equalities such as ðGðP 1 ,</p><formula>P 2 ÞÞ À1 ¼ GðP À1 1 , P À1 2 Þ ¼ GðK 1 , K 2 Þ and ðGðK 1 , K 2 ÞÞ À1 ¼ GðK À1 1 , K À1 2 Þ ¼ GðP 1 , P 2 Þ.</formula><p>Hence, computing the GM of the covariance matrices is equivalent to computing the GM between the precision matrices, which is a particularly attractive idea in the case of Gaussian distributions, and may thus be a valuable property when fusing kernels. For a general number of matrices, the fused kernel is obtained by taking the GM FðK 1 , K 2 ,. .. , K n Þ ¼ GðK 1 , K 2 ,. .. , K n Þ: ð2Þ</p><p>We describe our proposed methods for computing the GM of SPD matrices and some approximations in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Karcher mean and AGH mean</head><p>For two SPD matrices A and B, the GM is given by the explicit formula (1). However, for more than two matrices, a proper definition of a GM with some natural properties remained elusive for long. The most popular instance of the matrix GM is considered to be the Karcher mean (<ref type="bibr" target="#b20">Jeuris et al., 2012</ref>). The Karcher mean of SPD matrices A 1 ,. .. , A k is defined as the barycenter of these matrices on the manifold of SPD matrices with its Riemannian geometry. In practice, this is obtained by searching the minimizer of an optimization problem, given as follows:</p><formula>GðA 1 ,. .. , A k Þ ¼ min X2Pn X k i¼1 jj logðA À1=2 i XA À1=2 i Þjj 2 F , ð3Þ</formula><p>where P n represents the set of SPD n Â n matrices and jj:jj F is the Frobenius norm. To find the minimizer, we use manifold optimization (<ref type="bibr" target="#b0">Absil et al., 2008</ref>; for more details see the Supplementary Material). However, retrieving the Karcher mean can be computationally expensive, which is why we also discuss the AGH mean, which can be considered as an approximation to the Karcher mean. For every two positive scalars, alternatively computing the AM and HM repeatedly will converge to the GM. At the base of the AGH mean lies the observation that the GM of two matrices can be obtained by taking the AM and HM (for more details see the Supplementary Material) of the matrices and iteratively repeating this procedure with the new matrices (<ref type="bibr" target="#b17">Foster and Phillips, 1984</ref>). Generalizing this to more than two matrices, we duplicate the original set of matrices and combine both in arithmetic and harmonic operations, as illustrated by the matrices B i and C i in Algorithm 1. To counteract the decrease of speed of this technique, a randomization is introduced (last step in Algorithm 1). The result is a rapidly converging algorithm that provides a decent approximation to the Karcher mean. This approximate mean requires a computational cost of the order Oðn 2 logðnÞkÞ per iteration, which is an improvement when compared with the Karcher mean. The stopping criteria of the algorithm are the same as those of the Karcher mean, except when determining the distance between the consecutive iterations, where only the first of the B i-matrices is considered. The kernel fusion framework approaches using the Karcher and AGH mean are called Karcher-KF (geometric kernel fusion 1, GKF1) and AGH-KF (GKF2), respectively.</p><p>Algorithm 1 The approximate AGH mean algorithm where A denotes the AM and H the HM Let A 1 ,. .. , A k be SPD matrices</p><p>For all i set B i ¼ A i and C i ¼ A i ; while not converged For all i set ~ B i ¼ HðB i , C ði mod nÞþ1 Þ;</p><formula>For all i set ~ C i ¼ AðB i , C ði mod nÞþ1 Þ;</formula><p>For all i set C pðiÞ ¼ ~ C i , B pðiÞ ¼ ~ B i , with p a random permutation of ½1,. .. , n. end</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Log-Euclidean mean</head><p>In this section we describe a new approach (<ref type="bibr" target="#b2">Arsigny et al., 2007</ref>) to compute a mean of SPD matrices called the LogEM. Given SPD matrices S 1 ,. .. , S N , their Log-Euclidean Fre´chetFre´chet mean exists and is uniquely given by the explicit formula</p><formula>E LE ðS 1 ,. .. , S N Þ ¼ exp 1 N X N i¼1 log S i ð Þ ! : ð4Þ</formula><p>The LogEM is similarity-invariant, invariant by group multiplication, inversion and exponential-invariant. The LogEM also has outstanding behaviour with respect to the determinant (for more details see the Supplementary Material). Because of the nice properties of the LogEM and the high computational cost of GM, it will also be considered in our fusion framework for combining kernels (LogE-KF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MATERIAL AND METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Benchmark datasets</head><p>We use the benchmark dataset from Ding and Dubchak (DD) (<ref type="bibr" target="#b14">Ding and Dubchak, 2001</ref>), which has been widely used for evaluating protein fold recognition predictors. This benchmark dataset consists of 27 SCOP fold classes for 694 protein domains (311 proteins for the training set and 383 proteins for the test set). The identity between any two proteins in the training and test set is kept to 535% to get balance between the homologous bias and the size of the dataset. Supplementary<ref type="figure" target="#tab_1">Table S1</ref>lists a summary of training and test datasets belonging to the 27 protein domain folds of SCOP corresponding to all major structural classes: , , =, þ. We also developed the model based on the newer SCOP database (version 1.75; newDD) as it is used in (<ref type="bibr" target="#b45">Yang and Chen, 2011</ref>). This database version contains 3397 protein sequences in the 27 folds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature vectors</head><p>The first 12 PFs listed in Supplementary Material S2 are the most popular representative models of protein domains, which have been employed frequently for classification of DD protein domain folds. These PFs include six types of structural information<ref type="bibr">[</ref><ref type="bibr" target="#b12">Damoulas and Girolami, 2008</ref>). In addition, because these features were already considered by two kernel-based data integration approaches (<ref type="bibr" target="#b12">Damoulas and Girolami, 2008;</ref><ref type="bibr" target="#b47">Ying et al., 2009</ref>), we are able to compare and evaluate the performance of our approach more precisely using those results. Sequence evolution information. Recently, sequence evolution information is often used to perform protein fold classification (<ref type="bibr" target="#b22">Kavousi et al., 2011;</ref><ref type="bibr" target="#b37">Sharma et al., 2013;</ref><ref type="bibr" target="#b40">Shen and Chou, 2009;</ref><ref type="bibr" target="#b45">Yang and Chen, 2011</ref>) because good results can be obtained when using such information to determine protein secondary structure (<ref type="bibr" target="#b21">Kaur and Raghava, 2003</ref>), subcellular localization (<ref type="bibr" target="#b35">Rashid et al., 2007;</ref><ref type="bibr" target="#b44">Xie et al., 2005</ref>) and subnuclear localization (<ref type="bibr" target="#b39">Shen and Chou, 2007</ref>). In particular, promising results have been reported recently using only the sequence evolution information through a new feature extraction method (bi-gram;<ref type="bibr" target="#b37">Sharma et al., 2013</ref>) from position-specific scoring matrices (PSSM;<ref type="bibr" target="#b36">Schaffer et al., 2001</ref>). A protein sample P with L amino acid residues can be represented by its evolutionary information through PSSM or position-specific frequency matrices (PSFM) profiles (<ref type="bibr" target="#b34">Rangwala and Karypis, 2005</ref>), which both have L columns and 20 rows. Each row of PSSM (M i!: ) represents the log-likelihood of the residue substitution at the corresponding position in the protein sequence. In particular, the ði, jÞ-th entry of the PSSM matrix (M i!j ) represents the possibility of the amino acid type j appearing in the i-th position of the protein domain during the evolution process. The PSSM entries are obtained using the PSI-BLAST program to search the non-redundant protein database, like the Swiss-prot database, through three iterations with the E-value cut-off set to 0.001. We use four common profile-based representative models of protein sequences:</p><p>((4) The PsePSSM was originally introduced in (<ref type="bibr" target="#b9">Chou, 2001</ref>) to avoid complete loss of the sequence-order information (for more details see the Supplementary Material). Functional domain composition. To incorporate the available functional domain information (FunD) of proteins, we consider the FunD composition of protein sequences using integrated FunD databases, which contain protein sequences with noted FunD descriptions. A protein sequence can be summarized by its known functional domains. This representative model for a protein sequence was first introduced in (<ref type="bibr" target="#b5">Cai et al., 2002</ref><ref type="bibr" target="#b6">Cai et al., , 2003</ref>) and is also considered for protein fold classification (<ref type="bibr" target="#b40">Shen and Chou, 2009</ref>), protein structural recognition (<ref type="bibr" target="#b10">Chou and Cai, 2004</ref>), protein subcellular location prediction (<ref type="bibr" target="#b5">Cai et al., 2002</ref>) and prediction of protein submitochondria locations (<ref type="bibr" target="#b49">Zakeri et al., 2011</ref>). In fact, fold information is a useful clue in determining a protein's tertiary structure, which can facilitate the identification of its function. Hence, the FunD composition features are considered based on the rationale that the function of a protein is often correlated with its structural characteristics. For this purpose, we use the InterPro database (<ref type="bibr" target="#b1">Apweiler et al., 2001;</ref><ref type="bibr" target="#b19">Hunter et al., 2012</ref>), which is an integrated database of recognized protein families, domains and functional sites to functionally characterize a new protein sequence. Moreover, we use the Conserved Domain Database (CDD;<ref type="bibr" target="#b27">Marchler-Bauer et al., 2007</ref>), which is known as the integrated FunD database, to identify the putative function of a new protein sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULT AND DISCUSSION</head><p>In this section, we discuss the extensive study of integrating multiple informative fold data sources. First, we focus on the individual performance of each PF data source. We should note that the GM applies only to SPD matrices. Besides the flexibility of the radial basis function (RBF) kernel function and its good generalization through the non-linear mapping of the input space to the infinite-dimensional feature space, the RBF kernel function produces SPD matrix. Two types of Gaussian RBF kernel functions are used for these data sources. Then, classification is performed using a Gaussian support vector machine (SVM) model, and its performance is estimated on an independent test set. Parameter selection details are provided in Supplementary Material. A one-against-other SVM classifier is constructed based on each representative model of the protein samples. To train SVMs, we used LIBSVM-3.1 implementation of the SVM algorithm (<ref type="bibr" target="#b7">Chang and Lin, 2011</ref>). The performance of the individual classifiers on the test data is listed in Supplementary Table S2. Next, to see the advantage of fusing heterogeneous data sources for protein fold classification through intermediatebased data integration, we focus on combining 26 RBF kernel matrices derived from each view on protein domains. The kernel matrices are combined through various types of means like GKF1, GKF2, AM, HM and LogE. Afterwards, the combined kernel is used to determine the performance. The general architecture of the proposed approaches for classifying protein folds is shown in<ref type="figure">Figure 1</ref>. Furthermore, to compare the performance of our proposed approaches, we also consider three types of MKL approaches [MKLdiv-dc and MKLdiv-conv (<ref type="bibr" target="#b47">Ying et al., 2009</ref>) and SimpleMKL (<ref type="bibr" target="#b33">Rakotomamonjy et al., 2008)]</ref>, which have already been used for protein fold classification (<ref type="bibr" target="#b47">Ying et al., 2009</ref>). We also consider a heuristic and simple MKL method (<ref type="bibr" target="#b32">Qiu and Lane, 2009</ref>), which chooses the kernel weights based on the relationship between the kernel matrix and the covariance matrix of the target labels (AK-MKL) (for more details see the Supplementary Material). Then, a one-against-other SVM classifier is again constructed, now based on each of the combined kernels. The parameter C is chosen through 5-fold cross validation and is searched over a grid of values C ¼ f2 À1 , 2 0 ,. .. , 2 9 g.<ref type="figure" target="#tab_1">Table 1</ref>provides the total prediction accuracies of the existing approaches for classification of protein folds in the DD dataset.<ref type="figure" target="#tab_1">Table 1</ref><ref type="figure">Figure 2</ref>illustrates the behaviour of integrating kernel matrices using GKF1, GFK2 and LogE-KF. According to<ref type="figure" target="#tab_1">Table 1</ref>, the performance of GKF1, GKF2 and LogE-KF including all 26 sequence-based features achieves a test accuracy of 86.68, 86.16 and 81.72%, respectively. This implies that, in terms of similarity between protein samples, the fused kernel based on our proposed alternative algorithm (AGH mean) holds the same information as the fused kernel obtained using the Karcher mean, while the computational cost is lower. Also, promising results are achieved by our alternative fusion approach using the LogEM, which has an even lower computational cost. In<ref type="figure">Figure 2</ref>, we consider the effect of sequentially incorporating sequence-based features according to the decreasing order of their kernel performances. The performance of uniformly weighted linear combinations of base kernels increases slowly by varying degrees until we include the 16 most informative data sources, resulting in a best performance of 73.37%. By contrast, its performance decreases continuously if we continue to incorporate less informative PFs. However, there is a slight rise after adding PSp9, and then the performance decreases again when combining all kernels. This observation suggests that sequence-based PsePSSM features that reflect the effect of sequence order carry almost no complementary information with other PFs extracted from the PSSM profile (PS1, PS2, PS3 and PSp0). Similar trends are apparent for MKLdiv-dc, MKLdivconv and KA-MKL. Contrary to the previous methods, the performance of AGH-KF increases gradually even when adding kernels considered to carry non-complementary information by AM. Its success rate is consistently outperforming otheruniformly weighted kernel integration methods and almost always increases until the 26th kernel is included, resulting in the best performance of 86.68%.The experimental results on the SCOP PDB-40D benchmark dataset demonstrate that the geometric-based averaging of kernel matrices can effectively improve the accuracy of the state-of-the-art kernel fusion model. According to<ref type="figure" target="#tab_2">Table 2</ref>, promising test set accuracy is obtained using each individual FunD information-based feature (FunDcdd and FunD-InterPro). Now, our computational model (GeoFold) has been developed by incorporating these FunD compositions of proteins through the proposed hybridization model (FunGeoFlod), described in<ref type="figure">Figure 1</ref>. It is observed that by using this hybridization model, the protein fold recognition accuracy is improved to 89.30%, which is significant for this problem. Next, to compare the efficiency of the proposed formulations AGH-FK and LogE-KF with other MKL approaches, we consider 201 various convex combinations of two different kernels. For this purpose, we assign different weights to each kernel as follows:</p><formula>K i ¼ w i K 1 þ ð1 À w i ÞK 2 , 15i 201, ð5Þ</formula><p>where w ¼ ½1, 0:995, 0:99,. .. , 0. These weights can also be interpreted as their corresponding importance in the fused kernel. In fact, finding such weights is the objective of any MKL approach. As illustrated in<ref type="figure" target="#fig_6">Figure 3</ref>and Supplementary Material S2, we observe better success rates on the majority of the interval of kernel weight pairs for the new approaches. These results indicate the limitation of MKL approaches in terms of their sensitive behaviour in dealing with kernel weights. They also demonstrate that the best linear combination of two kernels usually is the one where we assign more weight to the kernel with a higher performance. This is particularly true when the difference between the performances of the two kernels is considerable. Our results show that the evolutionary-based features and either the S or C convey the considerable complementary information with respect to each other. Moreover, the evolutionary information extracted from PSSM profiles through Psp0 and PS2 carries complementary information with respect to other features. Moreover, we investigate the performance of our approach on the newer SCOP database (version 1.75;<ref type="bibr" target="#b45">Yang and Chen, 2011</ref>). As the results on the SCOP PDB-40D benchmark dataset suggest, it is interesting to consider only two PFs including predicted secondary structural information of the protein sequence and information extracted directly from PSSM. For this propose, the PS2 and predicted secondary structure results from NetSurfP (<ref type="bibr" target="#b31">Petersen et al., 2009</ref><ref type="figure">Fig. 2</ref>. The effect of sequentially incorporating PFs according to the decreasing order of their kernels performance. The results of sequentially adding sequence-based features are further discussed in the Supplemental Material</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1855</head><p>Protein fold recognition using geometric kernel data fusion transition and distribution descriptors as described in (<ref type="bibr" target="#b15">Dubchak et al., 1995</ref>) are used to construct the feature vector for the representation of S.<ref type="figure" target="#tab_3">Table 3</ref>provides the mean percentage accuracy with standard deviation from our proposed kernel data fusion methods using 10-fold cross validation for classification of protein folds in the newDD dataset (<ref type="bibr" target="#b45">Yang and Chen, 2011</ref>). It is observed that by incorporating the available functional domain information (nterPro) through our proposed hybridization model, we are almost able to completely crack the protein fold recognition problem for 27-folds. In addition, it is observed that using FunFold-cdd, FunFold-InterPro, LogEFold and GeoFold models, we achieve competitive results compared with the Taxfold webserver (<ref type="bibr" target="#b45">Yang and Chen, 2011</ref>). We also investigate the performance of our GKF approach on the protein remote homology detection problem (<ref type="bibr" target="#b25">Liao and Noble, 2003</ref>) by fusing multiple kernels. In the Supplementary Material, we report the competitive results on this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this study, we enhance the fold recognition results on the SCOP PDB-40D benchmark dataset through a novel kernel data fusion framework based on the GM of kernel matrices (GFK). We present two methods (Karcher-KF and AGH-KF) for computing the GM, where the second one is a computationally scalable method that computes an approximate GM. The experimental results demonstrate that the GM of kernel matrices can effectively improve the accuracy of the state-ofthe-art kernel fusion model. In addition, we obtain similar results using the LogEM, which is a more cost-effective technique for integrating different PFs. Our meta-predictor is developed by incorporating the available knowledge on functions of protein domains into our kernel data fusion framework, giving a promising total accuracy of 89.30%. Understanding the relationship between primary and tertiary structure in proteins is one of the main objectives of protein sequence analysis. This relation is still elusive, but our results suggest that combining the evolutionary and secondary structural information could be crucial to elucidate such a latent link. This claim is investigated on the newer SCOP database (version 1.75;<ref type="bibr" target="#b45">Yang and Chen, 2011</ref>), where our new methods again have good performance. In addition, by incorporating the available functional domain information using our FunGeoFold model, nearly exact protein fold recognition for 27-folds is achieved. Furthermore, the limitation of convex linear combinations in dealing with fusion of different PFs that carry complementary information is considered. Our proposed fusion frameworks, by contrast, can be used to detect these features with complementary information, which provides an insightful approach for fusing different features of other problems in bioinformatics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>Amino Acid composition (C), Predicted Secondary Structure (S), PseAAC ¼ 1 (L1), PseAAC ¼ 4 (L4), PseAAC ¼ 14 (L14) and PseAAC ¼ 30 (L30)], four kinds of physicochemical properties of constituent amino acids [Hydrophobicity (H), Polarity (P), van der Waals volume (V) and Polarizability] and two local pairwise sequence alignment-based feature spaces [based on Smith Waterman using BLOSUM62 (SWr1) and PAM50(SWr2)] (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>1) A 400 dimensional feature vector created by summing up each column of the same amino acid in the PSSM and dividing by the length of the protein domain, followed by a normalization 1 1þe Às h i that scales each score to the range of [0,1] (PS1). (2) A 20 dimensional feature vector created by summing up each column in the PSFM profile and dividing by the length of the domain (PS2). (3) A 20 dimensional feature vector created by summing up each column in the PSSM profile and dividing by the length of the domain (PS3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>also lists the success rates of our proposed kernel fusion approaches based on averaging of the kernel matrices. According to Table 1, classification results of the combined kernels using Karcher-KF, AGH-KF and LogE-KF show considerable improvement compared with the state-of-the-art.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Funding: Y.M. is a full professor at KU Leuven, Belgium. This research is supported by KUL GOA/10/09 MaNet, KUL PFV/ 10/016 SymBioSys, KUL IOF 3M120274 Immunosuppressive drugs. IWT TBM Haplotyping. Hercules Stichting: Hercules III PacBio RS. iMinds: SBO 2013. EU COST Action BM1006: NGS Data analysis network. FCT Neuroclinomics. The scientific responsibility is assumed by its authors. This work was partially supported by MIUR grant number 2002014121; by the Research Council KU Leuven, projects OT/11/055 (Spectral Properties of Perturbed Normal Matrices and their Applications), CoE EF/05/006 Optimization in Engineering (OPTEC); by the Fund for Scientific Research–Flanders (Belgium) project G034212N (Reestablishing Smoothness for Matrix Manifold Optimization via Resolution of Singularities); and by the Interuniversity Attraction Poles Programme, initiated by the Belgian State, Science Policy Office, Belgian Network DYSCO (Dynamical Systems, Control and Optimization).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fusing</head><figDesc>FunD−InterPro kernels and Geo−Fold kernels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.3.</head><figDesc>Fig. 3. The performance of convex linear combination of two different kernels using 201 different pairs weights of kernels (blue line). The relative performances of fused kernels through weighted LogEM (red line). The relative performances of fused kernels using weighted GM (for more details see the Supplementary Material) (magenta line)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 1. Comparison of proposed models with the existing predictor and meta-predictors</figDesc><table>Methods 
PERF Description 

SVM 
56 
(Ding and Dubchak, 2001) 
SE 
61.1 
(Nanni, 2006) 
PFP-Pred 
62.1 
(Shen and Chou, 2006) 
PFRES 
68.4 
(Chen and Kurgan, 2007) 
VBKC 
68.1 
(Damoulas and Girolami, 2008) 
MLKdiv-dc 
73.36 (Ying et al., 2009) 12 PFs 
MLKdiv-conv 
71.01 (Ying et al., 2009) 12 PFs 
MLKdiv-dc 
75.19 (Ying et al., 2009) 7 PFs 
PFP-FunDseqE 
70.5 
(Shen and Chou, 2009) 
Classifier Fusion 
67.02 (Kavousi et al., 2011) 
MarFold 
71.7 
(Yang et al., 2011) 
Tax-Fold 
71.5 
(Yang and Chen, 2011) 
Bi-grams 
69.5 
(Sharma et al., 2013) 
HPFP 
74.21 (Lin et al., 2013) 
MKLdiv-dc 
61.1 
26 PFs 
MKLdiv-conv 
63.70 26 PFs 
AK-MKL 
61.88 26 PFs 
SimpleMKL 
56.92 26 PFs 
Harmonic mean 
65.80 26 PFs 
Arithmetic mean 
60.57 26 PFs 
Karcher-KF (GeoFold1) 86.16 GFK1 (geometric mean) 26 PFs 
AGH-KF (GeoFold2) 
86.68 GFK2 (geometric mean) 26 PFs 
LogE-KF (LogEFold) 
81.72 LogE (Log-Euclidean mean) 26 PFs 

G 
E 
O 

M 
E 
A 
N 

O 
P 
E 
R 
A 
T 
O 
R 

Physicochemical 
Properres 

R 
B 
F 
K 
E 
R 
N 
E 
L 

G 
E 
O 

M 
E 
A 
N 

O 
P 
E 
R 
A 
T 
O 
R 

Predicted Secondary 
Structure 

Primary 
Structure 

Alignment Kernels 

PSSM 
Profile 

Funcconal Domain 
Composiion 

FunGeo 
Fold 

GeoFold 

Fig. 1. The architecture of our fusion model for protein fold recognition. 
GeoFold refers to the fusion model that uses 26 different data sources, 
and FunGeoFold refers to the kernel fusion model that incorporates the 
FunD information through GM between FunD kernel and fused kernel 
produced by GeoFold (GeoFold kernel) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. The results of incorporating the FunD composition</figDesc><table>Methods 
PERF 
Methods 
PERF 

FunFold-cdd 
69.94 
FunLogFold-cdd 
87.43 
FunFold-InterPro 
73.89 
FunLogFold-InterPro 
89.30 
FunFold-Combined 
76.50 
FunAmtFold-cdd 
77.2 
FunGeoFold-cdd 
87.71 
FunAmtFold-InterPro 
84.07 
FuncGeoFold-InterPro 
89.30 

FunLogEFold (FunAmFold) is referred to the kernel fusion model, which incorp-
orates the FunD information (extracted from CDD or InterPro) and GeoFold 
kernels through LogE(AM). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 3. Perfomance of our proposed data fusion approach on newDD dataset</figDesc><table>Methods 
Performance 
Protein features 

Tax-Fold 
90 
(Yang and Chen, 2011) 
PS2 
76:22 AE 0:0040 
Sequence evolution information 
S 
7 9 :05 AE 0:0025 
Predicted secondary structure 
FunFold-cdd 
86:82 AE 0:0023 
FunD-cdd 
FunFold-InterPro 
92:85 AE 0:0015 
FunD-InterPro 
GeoFold (AGH-KF) 
88:80 AE 0:0027 
PS2 and S 
FunGeogEFold-cdd 
94:36 AE 0:0009 
PS2,S,FunD-cdd 
FunGeoFold-InterPro 
96:88 AE 0:0012 
PS2,S,FunD-InterPro 
LogEFold (LogE) 
88:52 AE 0:0020 
PS2 and S 
FunLogEFold-cdd 
94:65 AE 0:0008 
PS2,S,FunD-cdd 
FunLogEFold-InterPro 
96:88 AE 0:0011 
PS2,S,FunD-InterPro </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Protein fold recognition using geometric kernel data fusion at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">n P n i¼1 K i. By contrast, because it has been shown that this type of averaging mixed the result and has usually sensitive behaviour in dealing with complementary and noisy kernels, Euclidean distance on SPD matrices might not be appropriate. Moreover, SPD matrices form a convex cone and not a vector space. This has an effect on the &apos;natural&apos; geometry of SPD matrices, which may not be Euclidean, but rather should rely on concepts from Riemannian geometry. This motivates us to think about other means between SPD matrices that are not relative to the Euclidean distance on PðnÞ and necessarily a linear combination of SPD matrices. For example, the mean corresponding to Riemannian distance on PðnÞ is the GM. For a given set of SPD kernel matrices K 1 , K 2 , :::, K n , the GM GðK 1 , K 2 , :::, K n Þ is the unique solution of the non-linear matrix equation P n i¼1 logðK À1 i KÞ ¼ 0. Because of the non-commutative property of matrix multiplication, the equation can not be solved in closed form. However, the GM of two SPD kernel matrices K 1 and K 2 can be defined explicitly as follows (Bhatia, 2007): GðK 1 , K 2 Þ ¼ K 1 2 1 K À 1 2 1 K 2 K À 1 2 1 1 2 K 1 2</note>

			<note place="foot">P.Zakeri et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title level="m" type="main">Optimization Algorithms on Matrix Manifolds</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Absil</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Princeton University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">The interpro database, an integrated documentation resource for protein families, domains and functional sites</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Apweiler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="37" to="40" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Geometric means in a novel vector space structure on symmetric positive-definite matrices</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Arsigny</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="328" to="347" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiple kernel learning, conic duality, and the SMO algorithm</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">R</forename>
				<surname>Bach</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Machine Learning (ICML). Omnipress</title>
		<meeting>the 21st International Conference on Machine Learning (ICML). Omnipress<address><addrLine>Banff, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Positive Definite Matrices</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Bhatia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Princeton Series in Applied Mathematics</title>
		<meeting><address><addrLine>Princeton</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Support vector machines for prediction of protein subcellular location by incorporating quasi-sequence-order effect</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">D</forename>
				<surname>Cai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cell. Biochem</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="343" to="348" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Support vector machines for predicting membrane protein types by using functional domain composition</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">D</forename>
				<surname>Cai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biophys. J</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="3257" to="3263" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Libsvm: a library for support vector machines</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">C</forename>
				<surname>Chang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">J</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="27" to="28" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Pfres: protein fold classification by using evolutionary information and predicted secondary structure</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Kurgan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2843" to="2850" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Prediction of protein cellular attributes using pseudo-amino acid composition</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="246" to="255" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Predicting protein structural class by functional domain composition</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">D</forename>
				<surname>Cai</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochem. Biophys. Res. Commun</title>
		<imprint>
			<biblScope unit="volume">321</biblScope>
			<biblScope unit="page" from="1007" to="1009" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A kernel-based integration of genome-wide data for clinical decision support</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Daemen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic multi-class multi-kernel learning: on protein fold recognition and remote homology detection</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Damoulas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Girolami</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1264" to="1270" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Kernel-based data fusion for gene prioritization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>De Bie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="125" to="132" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-class protein fold recognition using support vector machines and neural networks</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Ding</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Dubchak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="349" to="358" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Prediction of protein folding class using global description of amino acid sequence</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Dubchak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="8700" to="8704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Recognition of a protein fold in the context of the scop classification</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Dubchak</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="401" to="407" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">The arithmetic-harmonic mean</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Foster</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Phillips</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Comput</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="183" to="191" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Multiple kernel learning algorithms</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Go¨nengo¨nen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Alpaydin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2211" to="2268" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Interpro in 2011: new developments in the family and domain prediction database</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Hunter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="306" to="312" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey and comparison of contemporary algorithms for computing the matrix geometric mean</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Jeuris</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Trans. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="379" to="402" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">A neural-network based method for prediction of gamma-turns in proteins from multiple sequence alignment</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kaur</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Raghava</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="923" to="929" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A protein fold classifier formed by fusing different modes of pseudo amino acid composition via {PSSM}</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kavousi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biol. Chem</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning the kernel matrix with semi-definite programming</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">R G</forename>
				<surname>Lanckriet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="27" to="72" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">A statistical framework for genomic data fusion</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">R G</forename>
				<surname>Lanckriet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2626" to="2635" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Combining pairwise sequence similarity and support vector machines for detecting remote protein evolutionary and structural relationships</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Liao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Noble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="857" to="868" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical classification of protein folds using a novel ensemble classifier</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">56499</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">CDD: a conserved domain database for interactive domain family analysis</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Marchler-Bauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="237" to="240" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Cdd: conserved domains and protein threedimensional structure</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Marchler-Bauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="348" to="352" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Scop: a structural classification of proteins database for the investigation of sequences and structures</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">G</forename>
				<surname>Murzin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mol. Biol</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="page" from="536" to="540" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">A novel ensemble of classifiers for protein fold recognition</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nanni</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="2434" to="2437" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">A generic method for assignment of reliability scores applied to solvent accessibility predictions</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Petersen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Struct. Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">A framework for multiple kernel support vector regression and its applications to sirna efficacy prediction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Qiu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Lane</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinform</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="190" to="199" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rakotomamonjy</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2491" to="2521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Profile-based direct kernels for remote homology detection and fold recognition</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Rangwala</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Karypis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="4239" to="4247" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<analytic>
		<title level="a" type="main">Support vector machine-based method for predicting subcellular localization of mycobacterial proteins using evolutionary information and motifs</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Rashid</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">337</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Improving the accuracy of psi-blast protein database searches with composition-based statistics and other refinements</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Schaffer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2994" to="3005" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">A feature extraction technique using bi-gram probabilities of position specific scoring matrix for protein fold recognition</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sharma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="41" to="46" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Ensemble classifier for protein fold pattern recognition</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">B</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1717" to="1722" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Nuc-ploc: a new web-server for predicting protein subnuclear localization by fusing pseaa composition and psepssm</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">B</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Eng. Des. Sel</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="561" to="567" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<analytic>
		<title level="a" type="main">Predicting protein fold pattern with functional domain and sequential evolution information</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">B</forename>
				<surname>Shen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">C</forename>
				<surname>Chou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page" from="441" to="446" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b41">
	<analytic>
		<title level="a" type="main">Large scale multiple kernel learning</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sonnenburg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1531" to="1565" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b42">
	<analytic>
		<title level="a" type="main">Multiple kernel learning and the SMO algorithm</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">V N</forename>
				<surname>Vishwanathan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b43">
	<analytic>
		<title level="a" type="main">Estimating coefficients in linear models: it don&apos;t make no nevermind</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Wainer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Bull</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="213" to="217" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b44">
	<analytic>
		<title level="a" type="main">Locsvmpsi: a web server for subcellular localization of eukaryotic proteins using svm and profile of psi-blast</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Xie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b45">
	<analytic>
		<title level="a" type="main">Improving taxonomy-based protein fold recognition by using global and local features</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">Y</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2053" to="2064" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b46">
	<analytic>
		<title level="a" type="main">Margin-based ensemble classifier for protein fold recognition</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="12348" to="12355" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b47">
	<analytic>
		<title level="a" type="main">Enhanced protein fold recognition through a novel data integration approach</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Ying</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">267</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b48">
	<analytic>
		<title level="a" type="main">Kernel-based Data Fusion for Machine Learning-Methods and Applications in Bioinformatics and Text Mining</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Computational Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">345</biblScope>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b49">
	<analytic>
		<title level="a" type="main">Prediction of protein submitochondria locations based on data fusion of various features of sequences</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Zakeri</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Theor. Biol</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="page" from="208" to="216" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b50">
	<analytic>
		<title level="a" type="main">Multiclass multiple kernel learning</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Zien</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">S</forename>
				<surname>Ong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning, ICML&apos;07</title>
		<meeting>the 24th international conference on Machine learning, ICML&apos;07<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1191" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>