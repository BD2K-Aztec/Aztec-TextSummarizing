
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Integrating different data types by regularized unsupervised multiple kernel learning with application to cancer subtype discovery</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Nora</forename>
								<forename type="middle">K</forename>
								<surname>Speicher</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computational Biology and Applied Algorithmics</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep3">Graduate School of Computer Science</orgName>
								<orgName type="institution">Saarland University</orgName>
								<address>
									<addrLine>Campus</addrLine>
									<postCode>66123</postCode>
									<settlement>Saarbrü cken</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Nico</forename>
								<surname>Pfeifer</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computational Biology and Applied Algorithmics</orgName>
								<orgName type="department" key="dep2">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep3">Graduate School of Computer Science</orgName>
								<orgName type="institution">Saarland University</orgName>
								<address>
									<addrLine>Campus</addrLine>
									<postCode>66123</postCode>
									<settlement>Saarbrü cken</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">E1</forename>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Saarbrü</forename>
								<surname>Cken</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Saarbrü</forename>
								<surname>Cken</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Integrating different data types by regularized unsupervised multiple kernel learning with application to cancer subtype discovery</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv244</idno>
					<note>*To whom correspondence should be addressed.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Despite ongoing cancer research, available therapies are still limited in quantity and effectiveness, and making treatment decisions for individual patients remains a hard problem. Established subtypes, which help guide these decisions, are mainly based on individual data types. However, the analysis of multidimensional patient data involving the measurements of various molecular features could reveal intrinsic characteristics of the tumor. Large-scale projects accumulate this kind of data for various cancer types, but we still lack the computational methods to reliably integrate this information in a meaningful manner. Therefore, we apply and extend current multiple kernel learning for dimensionality reduction approaches. On the one hand, we add a regu-larization term to avoid overfitting during the optimization procedure, and on the other hand, we show that one can even use several kernels per data type and thereby alleviate the user from having to choose the best kernel functions and kernel parameters for each data type beforehand. Results: We have identified biologically meaningful subgroups for five different cancer types. Survival analysis has revealed significant differences between the survival times of the identified subtypes, with P values comparable or even better than state-of-the-art methods. Moreover, our resulting subtypes reflect combined patterns from the different data sources, and we demonstrate that input kernel matrices with only little information have less impact on the integrated kernel matrix. Our subtypes show different responses to specific therapies, which could eventually assist in treatment decision making. Availability and implementation: An executable is available upon request.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cancer is not only a very aggressive but also a very diverse disease. Therefore, a number of approaches aim to identify subtypes of cancer in a specific tissue, where subtypes refer to groups of patients with corresponding biological features or a correlation in a clinical outcome, e.g. survival time or response to treatment. Nowadays, most of these methods utilize single data types (e.g. gene expression). However, subtypes that are merely based on information from one level can hardly capture the subtleties of a tumor. Therefore, huge efforts are made to improve the comprehensive understanding of tumorigenesis in the different tissue types. Large-scale projects, e.g. The Cancer Genome Atlas (TCGA) (<ref type="bibr">The Cancer Genome Atlas, 2008</ref>), provide a massive amount of data generated by diverse platforms such as gene expression, DNA methylation and copy number data for various cancer types. Still, we require computational methods that enable the comprehensive analysis of these multidimensional data and the reliable integration of information generated from different sources. One simple and frequently applied method to combine biological data consists of clustering the samples using each data type separately and subsequently integrating the different cluster assignments. The latter step can be performed either manually or automatically, e.g. using consensus clustering (<ref type="bibr" target="#b6">Monti et al., 2003</ref>). Manual integration tends to be biased, leading to inconsistent results. However, both manual and automatic integration cannot capture correlated information between the data types because low signals might V C The Author 2015. Published by Oxford University Press.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i268</head><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com<ref type="bibr">Bioinformatics, 31, 2015</ref>, i268–i275 doi: 10.1093/bioinformatics/btv244 ISMB/ECCB 2015 already vanish during the initial clustering. Therefore, more advanced approaches bring forward the step of data integration to make use of weak but concordant structures in different data sources.<ref type="bibr">Shen et al. (2009</ref><ref type="bibr">Shen et al. ( , 2012</ref>) introduced iCluster, which allows for data integration and dimensionality reduction at the same time. The basis is a Gaussian latent variable model with regularization for sparsity, in which the cluster assignment can be derived from the latent variable vector. Because of the high computational complexity of this approach, preselection of the features is necessary, so the clustering result strongly depends on this preprocessing step. An approach that tackles both the problem of how to use correlation between the data types and the problem of feature preselection is Similarity Network Fusion (SNF) (<ref type="bibr">Wang et al., 2014</ref>). First, a similarity network of the samples is constructed from each input data type. These networks are then fused into one combined similarity network using an iterative approach based on message passing. This way, the networks are updated in each iteration such that they become more similar to each other, until the process converges. The resulting network is then clustered by Spectral Clustering (von<ref type="bibr">Luxburg, 2007</ref>). An approach that uses the same clustering algorithm is Affinity Aggregation for Spectral Clustering (<ref type="bibr" target="#b4">Huang et al., 2012</ref>). Here, the main idea is to extend Spectral Clustering to allow for several affinity matrices as input. The matrices are fused using a linear combination, with weights being optimized using multiple kernel learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We propose to apply and extend multiple kernel learning for data integration and subsequently perform cancer subtype identification. To this end, we adopt the multiple kernel learning for dimensionality reduction (MKL-DR) framework (<ref type="bibr" target="#b5">Lin et al., 2011</ref>) that enables dimensionality reduction and data integration at the same time. This way, the samples are projected into a lower dimensional, integrated subspace where they can be analyzed further. We show that this representation captures useful information that can be used for clustering samples, but other follow-up analyses are also possible from this data representation. Compared to previous approaches, this procedure offers several advantages: The framework provides high flexibility concerning the choice of the dimensionality reduction method, i.e. not only unsupervised but also supervised and semi-supervised methods can be adopted. Furthermore, the framework provides high flexibility concerning the input data type, i.e. since the first step is a kernelization of the input matrices, these can be of various formats, such as sequences or numerical matrices. Moreover, in case one does not have enough information from which to choose the best kernel function for a data type or the best parameter combination for a given kernel beforehand, it is possible to input several kernel matrices per data type, based on different kernel functions or parameter settings. The multiple kernel learning approach will automatically upweight the matrices with high information content while downweighting those with low information content. To avoid overfitting, especially in the scenario with many distinct input matrices, we extend the MKL-DR approach by adding a regularization term. We use five different cancer sets for the evaluation of our method. The resulting clusterings reflect characteristics from distinct input data types and reveal differences between the clusters concerning their response to specific treatments. Furthermore, we show that kernel matrices with less information have less influence on the final result. A comparison of the P values for survival differences between our clusters and the SNF clusters shows that our method yields comparable results while offering a lot more flexibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>To integrate several data types, we utilize multiple kernel learning, extending the MKL-DR approach (<ref type="bibr" target="#b5">Lin et al., 2011</ref>). This method is based, on the one hand, on multiple kernel learning, and, on the other hand, on the graph embedding framework for dimensionality reduction. We add a constraint that leads to the regularization of the vector controlling the kernel combinations, which, to our knowledge, is the first time this has been done for unsupervised multiple kernel learning. We call this method regularized multiple kernel learning for dimensionality reduction (rMKL-DR) in the following discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multiple kernel learning</head><p>In general, multiple kernel learning optimizes the weights b that linearly combine a set of input kernel matrices fK 1 ;. .. ; K M g to generate a unified kernel matrix K, such that</p><formula>K ¼ X M m¼1 b m K m ; b m !0:</formula><formula>(1)</formula><p>Here, each input data type is represented as an individual kernel matrix. Therefore, this approach can be used for data having different feature representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph embedding</head><p>MKL-DR is described upon the graph embedding framework for dimensionality reduction (<ref type="bibr">Yan et al., 2007</ref>), which enables the incorporation of a large number of dimensionality reduction methods. In this framework, the projection vector v (for the projection into a one-dimensional subspace) or the projection matrix V (for the projection into higher dimensions) is optimized based on the graph-preserving criterion:</p><formula>minimize v X N i;j¼1 jjv T x i À v T x j jj 2 w ij (2)</formula><p>subject to X N i¼1 jjv T x i jj 2 d ii ¼ const:; or</p><formula>(3)</formula><p>X N i;j¼1 jjv T x i À v T x j jj 2 w 0 ij ¼ const:</p><formula>(4)</formula><p>with v being the projection vector, W a similarity matrix with entries w ij and D (or W 0 ) a constraint matrix to avoid the trivial solution. The choice of the matrices W and D (or W and W 0 ) determines the dimensionality reduction scheme to be implemented. It also depends on this scheme whether the first or the second constraint is used. In the following, we will focus on the optimization problem with Constraint (3), but the constructions are analogous when using Constraint (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multiple kernel learning for dimensionality reduction</head><p>The kernelized version of the constrained optimization problem (2) can be derived using an implicit feature mapping of the data to a high-dimensional Hilbert space / : x i ! /ðx i Þ. Additionally, it can be shown that the optimal projection vector v lies in the span of theb m ! 0; m ¼ 1; 2;. .. ; M:</p><formula>(7)</formula><p>where</p><formula>a ¼ ½a 1 Á Á Á a N  T 2 R N ; (8)</formula><p>b ¼ ½b 1 Á Á Á b M  T 2 R M ;</p><formula>(9) K i ¼ K 1 ð1; iÞ ÁÁÁ K M ð1; iÞ .. . .. . .. . K 1 ðN; iÞ ÁÁÁ K M ðN; iÞ 0 B B B @ 1 C C C A 2 R NÂM : (10)</formula><p>Since we are applying several kernels and want to avoid overfitting, we add the constraint jjbjj 1 ¼ 1. Had we added the constraint jjbjj 1 1, this would amount to an Ivanov regularization. The corresponding Tikhonov regularization would be to directly add the regularization term kjjbjj 1 to the minimization problem. The full optimization problem for rMKL-DR is then:</p><formula>minimize a;b X N i;j¼1 jja T K i b À a T K j bjj 2 w ij (11)</formula><p>subject to X N i;j¼1 jja T K i bjj 2 d ij ¼ const:</p><formula>(12)</formula><formula>jjbjj 1 ¼ 1 (13)</formula><p>b m ! 0; m ¼ 1; 2;. .. ; M:</p><formula>(14)</formula><p>The optimization problem can easily be extended to the projection into more than one dimension. In that case, a projection matrix A ¼ ½a 1 Á Á Á a p  is optimized instead of the single projection vector a. Then, A is optimized at the same time as the kernel weight vector b according to a chosen dimensionality reduction method. Since the simultaneous optimization of these two variables is difficult, coordinate descent is employed, i.e. A and b are iteratively optimized in an alternating manner until convergence or a maximum number of iterations is reached. One can start either with the optimization of A, then b is initialized to equal weights for all kernel matrices summing up to one or with the optimization of b, then AA T is initialized to I. Using this framework, we apply the dimensionality reduction algorithm Locality Preserving Projections (LPP) (<ref type="bibr" target="#b2">He and Niyogi, 2004</ref>). This is an unsupervised local method that aims to conserve the distances of each sample to its k nearest neighbors. The neighborhood of a data point i is denoted as N ðiÞ. For LPP, the matrices W and D are then defined as w ij ¼ 1; if i 2 N k ðjÞ _ j 2 N k ðiÞ 0; else (</p><formula>(15)</formula><formula>d ij ¼ X N n¼1 w in ; if i ¼ j 0; else: 8 &lt; : (16)</formula><p>The rMKL-DR approach with LPP will be called rMKL-LPP from now on. The clustering process is performed using k-means. For the evaluation of the clusterings, we use the silhouette width (<ref type="bibr">Rousseeuw, 1987</ref>), a measure that indicates, for each data point, how well it fits into its own cluster, compared to how well it would fit into the best other cluster. When averaged over all data points, the resulting mean silhouette value gives a hint on how coherent a clustering is and how well the clusters are separated. The running time of the whole algorithm can be separated into the dimensionality reduction step and the k-means clustering. The dimensionality reduction is performed by iteratively updating the projection matrix A and the kernel weight vector b. The optimization of b uses semidefinite programming where the number of constraints is linear in the number of input kernel matrices and the number of variables is quadratic in the number of input kernel matrices. However, if M ( N, the bottleneck is the optimization of A. This involves solving a generalized eigenvalue problem that has a complexity of Oðn 3 Þ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Leave-one-out cross-validation</head><p>To assess the stability of the resulting clusterings, we applied a leave-one-out cross-validation approach, i.e. we apply the pipeline consisting of dimensionality reduction and subsequent clustering to a reduced dataset that does not include patient i. The projection of the left-out sample can be calculated using projðx i Þ ¼ A T K i b 2 R p , and this patient is assigned to the cluster with the closest group mean in the dimensionality reduced space. Finally, we compare this leave-one-out clustering to the clustering of the full dataset using the Rand index (<ref type="bibr">Rand, 1971</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Materials</head><p>We used data from five different cancer types from TCGA (<ref type="bibr">The Cancer Genome Atlas, 2008</ref>), preprocessed and provided by<ref type="bibr">Wang et al. (2014)</ref>. The cancer types comprise glioblastoma multiforme (GBM) with 213 samples, breast invasive carcinoma (BIC) with 105 samples, kidney renal clear cell carcinoma (KRCCC) with 122 samples, lung squamous cell carcinoma (LSCC) with 106 samples and colon adenocarcinoma (COAD) with 92 samples. For each cancer type, we used gene expression, DNA methylation and miRNA expression data in the clustering process. For the survival analysis, we used the same quantities as were used in<ref type="bibr">Wang et al. (2014)</ref>, this means, we used the number of days to the last follow-up, where available. For COAD, these were combined with the number of days to last known alive because of many missing values in the number of days to the last follow-up data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head><p>We applied rMKL-LPP to five cancer datasets. For each dataset, we ran the algorithm with both possible initializations, either starting with the optimization of A or with the optimization of b. For both dimensionality reduction results, the integrated data points were then clustered using k-means with k 2 f2; :::; 15g. We chose the optimal number of clusters using the average silhouette value of the clustering result. This criterion was then also utilized to select the best clustering among the two different initializations. In most cases, initializing b led to slightly better silhouette values, although the final results for both initializations were highly similar concerning the number of identified clusters and the cluster assignment. i270 N.K.Speicher and N.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pfeifer</head><p>As a consequence, the method has only two free parameters, the number of neighbors used in the dimensionality reduction method LPP and the number of dimensions of the projection subspace. Our initial analyses showed that the clusterings are fairly stable when choosing the number of nearest neighbors between 5 and 15 (data not shown). We chose 9 for all datasets to show the robustness of this parameter, although specific optimization would be feasible in terms of running time and memory requirements. The number of dimensions to project into was fixed to 5 for two reasons. First, because of the curse of dimensionality, samples with many dimensions tend to lie far apart from each other, leading to sparse and dispersed clusterings. Second, we wanted only a medium number of subtypes, such that very high dimensionality was not necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Comparison to state-of-the-art</head><p>For each data type, we used the Gaussian radial basis kernel function to calculate the kernel matrices and normalized them in the feature space. To investigate how well the method is able to handle multiple input kernels for single data types, we generated two scenarios. The first contained one kernel matrix per data type where c 1 was chosen according to the rule of thumb c ¼ 1 2d 2 , with d being the number of features of the data. Since this results in three kernels, the scenario is called 3K. For Scenario 2, we generated five kernel matrices per data type by varying the kernel parameter c such that c n ¼ c n c 1 , where c n 2 f10 À6 ; 10 À3 ; 1; 10 3 ; 10 6 g. This scenario is called 15K, consequently. We compared the resulting clusterings with the results of SNF in<ref type="figure" target="#tab_1">Table 1</ref>. Considering the P value for the log-rank test of the Cox regression model (<ref type="bibr" target="#b3">Hosmer et al., 2011</ref>), rMKL-LPP with one kernel per data type has a comparable performance to SNF. Only for KRCCC, the result was not significant when using one fixed value for c (significance level a ¼ 0:05). As can be seen in the last column, the significance for four out of the five datasets increased when using a set of different values for the kernel parameter c, indicating that the method is able to capture more information if provided. A further observation when moving from one to five different c values is the increase of the optimal number of clusters. A possible explanation for this could be that more detailed information is contributed by the different kernel matrices because, depending on the parameter setting, similarities between particular groups of patients can appear stronger while others diminish. Overall, the performance of rMKL-LPP with five kernel matrices was best. The median P value for this approach was 2.4E-4, whereas it was 0.0011 for SNF and 0.028 for rMKL-LPP with one kernel per data type. The product of all P values of each method showed a similar trend (rMKL-LPP 15K: 5.9E-19, SNF: 1.1E-13, rMKL-LPP 3K: 1.9E-10). Note that the higher number of clusters of rMKL-LPP is controlled in the calculation of the log-rank test P value by the higher number of degrees of freedom of the v 2 distribution. A further advantage of the rMKL-LPP method with five kernels per data type is that one does not have to decide on the best similarity measure for the data type beforehand, which makes this method more applicable out of the box. Additionally, the results suggest that it might even be beneficial in some scenarios to have more than one kernel matrix per data type to capture different degrees of similarity between data points (patients in this application scenario). As shown in<ref type="bibr">Wang et al. (2014)</ref>, the running time of iCluster scales exponentially in the number of genes, which makes the analysis of the cancer datasets infeasible if no gene preselection is performed. For SNF, this preprocessing step is not necessary, and it is significantly faster than iCluster. We compared the run time for the data integration in SNF and rMKL-LPP (15K), which precedes the clustering step in both methods. The SNF approach with the standard parameter settings completes the network fusion procedure for each cancer type within a few seconds, whereas the data integration with rMKL-LPP (15K) was slightly slower with running times up to one minute. However, just like SNF, rMKLLPP does not require a gene preselection, which suggests that using datasets with a higher number of samples and including more kernel matrices should be feasible in terms of running times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Contribution of individual kernel matrices to the combined kernel matrix</head><p>For rMKL-LPP with five kernels per data type,<ref type="figure" target="#fig_0">Figure 1</ref>shows the influence of every kernel matrix on the final integrated matrix. The top bar</p><formula>0E-2 (4) 2.2E-3 (2) 2.4E-4 (6) COAD 8.8E-4 (3) 2.8E-2 (2) 2.8E-3 (6)</formula><p>The numbers in brackets denote the number of clusters. For SNF, these are determined using the eigenrotation method (<ref type="bibr">Wang et al., 2014</ref>), and for rMKL-LPP, by the silhouette value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularized MKL for Dimensionality Reduction i271</head><p>shows what the graphic would look like for an equal contribution of all kernel matrices. In comparison to this, we can see that kernel matrices using high values for the parameter c ¼ c 1 Ã 10 6 have a very low impact for all cancer types. These results agree with the rule of thumb that c should be chosen in the order of magnitude of 1 2d 2 or lower, which was used for the choice of c 1 (<ref type="bibr">Gärtner et al., 2002</ref>). Furthermore, all data types contribute to the combined kernel matrix, and we can observe differences for the individual cancer types, e.g. for BIC, DNA methylation data has a higher impact, whereas for KRCCC, there is more information taken from the gene expression data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Robustness analysis</head><p>To assess the robustness of the approach to small changes in the dataset, we performed a leave-one-out cross-validation approach (cf. Section 3.4).<ref type="figure">Figure 2</ref>shows the stability of the clustering when using one kernel matrix per data source (Scenario 1) and five kernel matrices per data source (Scenario 2). Although we can observe for GBM and LSCC almost no perturbation in cluster structure in Scenario 1, for the other three cancer types, there is some deviation to the full clustering and some variance among the leave-one-out results. Especially for the COAD dataset, we observed for a number of leave-one-out clusterings that, compared with the full clustering, one of the clusters was split up into two distinct groups, which increases the overall number of clusters from two to three and leads to a decrease in the Rand index. The opposite happens for BIC, where we have a full clustering consisting of six groups, while in some of the leave-one-out runs, two of the groups are collapsed, resulting in five different clusters and, therefore, a lowered Rand index. However, when using five kernel matrices per data source, the results seem to be more stable, which appears, on the one hand, in the increased agreement with the full clustering and, on the other hand, in the reduced variance among the leave-one-out results. To further investigate the impact of the regularization constraint, we compared the robustness of the results obtained using rMKLLPP to the robustness of the results from MKL-LPP. In general, overfitting is expected especially for datasets with a small number of samples or a high number of predictors. Therefore, we generated from each cancer dataset smaller datasets using 50% of the samples. In this setting, the unregularized MKL-LPP showed some instabilities for GBM and KRCCC, with an increased variance among the clustering results compared to rMKL-LPP for most cancer types (cf.<ref type="figure">Fig. 3</ref>). This trend continued when the number of samples was further reduced, as shown in<ref type="figure">Figure 4</ref>. Although the results without regularization seem robust when using the complete dataset for each cancer type, we could observe that the robustness decreased when the number of samples decreased. The regularized approach, however, showed only a slight decrease in robustness when half the samples of each dataset were deleted and remained at this level when only one third or one quarter of the data were used. This suggests that rMKL-LPP has advantages in scenarios where MKL-LPP would overfit, while being comparable when no regularization is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison of clusterings to established subtypes</head><p>In the following, we look further into the results generated by the use of five kernel matrices per data type (Scenario 2) for the GBM dataset. For this cancer type, there exist four established subtypes determined by their gene expression profiles (<ref type="bibr">Verhaak et al., 2010</ref>) as well as one subtype called Glioma-CpG island methylator phenotype (G-CIMP), which is one out of three groups that emerged from a clustering of DNA methylation (<ref type="bibr" target="#b7">Noushmehr et al., 2010</ref>). The comparison of our GBM clustering to these existing subtypes (cf.<ref type="figure" target="#tab_2">Table 2</ref>) shows that our method does not only reflect evidence from one data type, but finds a clustering that takes both gene expression and DNA methylation information into account.<ref type="figure">Fig. 2</ref>. Robustness of clustering for leave-one-out datasets measured using Rand index. Each patient is left out once in the dimensionality reduction and clustering procedure and afterwards added to the cluster with the closest mean based on the learned projection for this data point, which is given by projðx i Þ ¼ A T K i b. The resulting cluster assignment is then compared with the clustering of the whole dataset. The error bars represent one standard deviation<ref type="figure">Fig. 4</ref>. Comparison of the robustness of the clustering generated with and without regularization averaged over all cancer types for datasets of different sizes. The percentage on the x-axis denotes, how many patients were used for generating a smaller dataset on which leave-one-out cross-validation was performed. For each cancer type and each fraction of patients, we repeated the process 20 times. The error bars represent one standard deviation i272 N.K.Speicher and N.Pfeifer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rand</head><p>We can observe that Cluster 1 is strongly enriched for the mesenchymal subtype, whereas Cluster 2 contains mainly samples that belong to the classical and the neural subtype. Samples of the proneural subtype are mainly distributed over Cluster 3 and Cluster 4, where these two clusters also reflect the G-CIMP status. While Cluster 3 consists almost only of G-CIMP positive samples, Cluster 4 contains samples that belong to the proneural subtype but are GCIMP negative. This shows that in this scenario, evaluating expression and DNA methylation data together can be very beneficial since an analysis based on gene expression data alone would have probably led to a union of Cluster 3 and Cluster 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Clinical implications from clusterings</head><p>To gain further insights into the biological consequences of the identified clusters, we have investigated how patients of the individual clusters respond to different treatments. Of the 213 glioblastoma patients, 94 were treated with Temozolomide, an alkylating agent which leads to thymine mispairing during DNA replication (<ref type="bibr" target="#b8">Patel et al., 2014</ref>).<ref type="figure" target="#fig_1">Figure 5</ref>shows for each cluster the survival time of patients treated versus those not treated with this drug. We can see that this treatment was effective only in a subset of the identified groups. Patients belonging to Cluster 5 had a significantly increased survival time when treated with Temozolomide (P value after Bonferroni correction &lt; 0:01). For Cluster 1 and Cluster 2, we can see a weaker tendency of treated patients living longer than untreated ones (P value after Bonferroni correction &lt; 0:05), whereas for the other clusters, we did not detect significant differences in survival time between treated and untreated patients after correcting for multiple testing. Survival analysis for other medications could show their effectiveness in different groups. Cluster 3 consists mainly of patients belonging to the proneural expression subtype and the G-CIMP methylation subtype. PatientsRegularized MKL for Dimensionality Reduction i273 from this cluster show in general an increased survival time; however, they do not benefit significantly from the treatment with Temozolomide. We have determined differentially expressed genes between these patients and all other patients using the Kruskal–Wallis rank sum test.<ref type="figure" target="#tab_3">Table 3</ref>(column 1) shows the top 15 terms of a Gene Ontology enrichment analysis of the set of overexpressed genes. The results are very similar to those found by<ref type="bibr" target="#b7">Noushmehr et al. (2010)</ref>for their identified G-CIMP positive subtype. In addition, we found the set of underexpressed genes to be highly enriched for processes associated to the immune system and inflammation [cf.<ref type="figure" target="#tab_3">Table 3</ref>. Since chronic inflammation is generally related to cancer progression and is thought to play an important role in the construction of the tumor microenvironment (<ref type="bibr" target="#b1">Hanahan and Weinberg, 2011</ref>), these downregulations might be a reason for the favorable outcome of patients from this cluster.Regularized MKL for Dimensionality Reduction i275</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. Contribution of the different kernel matrices to each entry in the unified ensemble kernel matrix. The three colors represent gene expression (blue), DNA methylation (yellow) and miRNA expression (red). The intensities represent the kernel parameter c, starting from c ¼ 1 2d 2 Ã 10 À6 (high intensity) to 1 2d 2 Ã 10 6 (low intensity)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.5.</head><figDesc>Fig. 5. Survival analysis of GBM patients for treatment with Temozolomide in the different clusterings. The numbers in brackets denote the number of patients in the respective group; the specified P values are corrected for multiple testing using the Bonferroni method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>(column 2)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Positive regulation of immune system process Nucleobase-containing compound biosynthetic process Inflammatory response Regulation of RNA metabolic process Positive regulation of response to stimulus Regulation of transcription, DNAtemplated Response to external biotic stimulus Regulation of nucleic acid-templated transcription Regulation of response to stimulus Regulation of macromolecule biosynthetic process Response to biotic stimulus Macromolecule biosynthetic process Cell activation Regulation of RNA biosynthetic process Leukocyte migration i274 N.K.Speicher and N.Pfeifer Rand,W.M. (1971) Objective criteria for the evaluation of clustering methods. J. Am. Stat. Assoc., 66, 847–850. Rousseeuw,P.J. (1987) Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. J. Comput. Appl. Math., 20, 53–65. Shen,R. et al. (2009) Integrative clustering of multiple genomic data types using a joint latent variable model with application to breast and lung cancer subtype analysis. Bioinformatics, 25, 2906–2912. Shen,R. et al. (2012) Integrative subtype discovery in glioblastoma using iCluster. PloS One, 7, :e35236. The Cancer Genome Atlas Network. (2006) The Cancer Genome Atlas. http:// cancergenome.nih.gov/. Verhaak,R.G.W. et al. (2010) Integrated genomic analysis identifies clinically relevant subtypes of glioblastoma characterized by abnormalities in PDGFRA, IDH1, EGFR, and NF1. Cancer Cell, 17, 98–110. von Luxburg,U. (2007) A tutorial on spectral clustering. Stat. Comput., 17, 395–416. Wang,B. et al. (2014) Similarity network fusion for aggregating data types on a genomic scale. Nat. Methods, 11, 333–337. Yan,S. et al. (2007) Graph embedding and extensions: a general framework for dimensionality reduction. IEEE Trans. Pattern Anal. Machine Intell., 29, 40–51.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Regularized MKL for Dimensionality Reduction i269 data points x i , thus v ¼ P N n¼1 a n /ðx n Þ. Together with the kernel function Kðx; x 0 Þ ¼ h/ðxÞ; /ðx 0 Þi and Formula (1), this yields the following optimization problem: minimize a;b</figDesc><table>X N 

i;j¼1 

jja T K i b À a T K j bjj 2 w ij 
(5) 

subject to 
X N 

i;j¼1 

jja T K i bjj 2 d ij ¼ const: 
(6) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Survival analysis of clustering results of similarity network fusion (SNF) and rMKL-LPP with one and five kernels per data type</figDesc><table>Cancer type 
SNF 
rMKL-LPP 
3K 
15K 

GBM 
2.0E-4 (3) 
4.5E-2 (5) 
6.5E-6 (6) 
BIC 
1.1E-3 (5) 
3.0E-4 (6) 
3.4E-3 (7) 
KRCCC 
2.9E-2 (3) 
0.23 (6) 
4.0E-5 (14) 
LSCC 
2.</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 2. Comparison of clusters identified by rMKL-LPP to gene expression and DNA methylation subtypes of GBM (Rand indices of 0.75 and 0.64, respectively) rMKL-LPP clusters</figDesc><table>Gene expression subtypes 
(Verhaak et al., 2010) 

DNA methylation subtypes 
(Noushmehr et al., 2010) 

Classical 
Mesenchymal 
Neural 
Proneural 
G-CIMPþ 
#2 
#3 

#1 
0 
36 
5 
1 
0 
7 
37 
#2 
31 
7 
13 
2 
0 
46 
6 
#3 
1 
0 
1 
15 
16 
1 
1 
#4 
1 
1 
5 
22 
0 
13 
27 
#5 
9 
8 
2 
3 
0 
19 
18 
#6 
6 
1 
2 
9 
3 
7 
9 

0 
500 
1000 
1500 
2000 
2500 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Cluster 1 

time [d] 

Survival rate 

treated (24) 
untreated (22) 

corr. p.value: 
2.65E−02 

0 
500 
1000 
1500 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Cluster 2 

time [d] 

Survival rate 

treated (17) 
untreated (36) 

corr. p.value: 
1.14E−02 

0 
500 1000 1500 2000 2500 3000 3500 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Cluster 3 

time [d] 

Survival rate 

treated (9) 
untreated (9) 

corr. p.value: 
1E+00 

0 
200 
400 
600 
800 
1000 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Cluster 4 

time [d] 

Survival rate 

treated (15) 
untreated (25) 

corr. p.value: 
1E+00 

0 
500 
1000 
1500 
2000 
2500 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Cluster 5 

time [d] 

Survival rate 

treated (16) 
untreated (21) 

corr. p.value: 
7.28E−03 

0 
500 
1000 
1500 
2000 
2500 

0.0 

0.2 

0.4 

0.6 

0.8 

1.0 

Cluster 6 

time [d] 

Survival rate 

treated (13) 
untreated (6) 

corr. p.value: 
1.18E−01 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><figDesc>Table 3.</figDesc><table>Top 15 enriched GO terms (FDR q value ( 0.001) from the 
category biological process of differentially expressed genes of 
Cluster 3 

GO enrichment of overexpressed 
genes 

GO enrichment of underex-
pressed genes 

Nucleic acid metabolic process 
Immune system process 
RNA biosynthetic process 
Defense response 
Transcription, DNA templated 
Response to external stimulus 
Nucleic acid templated transcription 
Response to stress 
RNA metabolic process 
Extracellular matrix 
organization 
Regulation of cellular macromol-
ecule biosynthetic process 

Extracellular structure 
organization 
Cellular macromolecule biosynthetic 
process 

Regulation of immune system 
process 
Nucleobase-containing compound 
metabolic process 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="5"> Conclusion Because of the large amount of different biological measurements, it is now possible to study diseases on many different levels such as comparing differences in DNA methylation, gene expression or copy number variation. For the unsupervised analysis of samples to detect interesting subgroups, it is not in general clear how to weight the importance of the different types of information. In this work, we have proposed to use unsupervised multiple kernel learning in this setting. For patient data from five different cancers, we have shown that our approach can find subgroups that are more interesting according to the log-rank test than are the ones found by state-of-the-art methods. Furthermore, we have demonstrated that we can even utilize several kernel matrices per data type, not only to improve performance but also to remove the burden of selecting the optimal kernel matrix from the practitioner. The visualizations of the contributions of the individual kernels suggest that using more than one kernel matrix per data type can even be beneficial, and the stability analysis shows that the method does not overfit when more kernels are added. In contrast to the unregularized MKL-DR, rMKL-DR remains stable also for small datasets. For a wide applicability of the method, this is especially important, since in many potential application scenarios the number of available samples is smaller than in this study. Furthermore, as we used the graph embedding framework, it is straightforward to perform semi-supervised learning (e.g. use the treatment data as labels where available and evaluate how unlabeled data points distribute over the different clusters). The clustering of GBM patients displayed concordance to previous clusterings based on expression as well as on DNA methylation data, which shows that our approach is able to capture this diverse information within one clustering. For the same clustering, we also analyzed the response of the patients to the drug Temozolomide, revealing that patients belonging to specific clusters significantly benefit from this therapy while others do not. The GO enrichments for the interesting clusters of the GBM patient samples showed, on the one hand, similar results to what was known from the biological literature and, on the other hand, down-regulation of the immune system in the subgroup of cancer patients who survived longer. This suggests that down-regulation of parts of the immune system could be beneficial in some scenarios. Further follow-up studies on the results of the different clusterings are necessary to assess their biological significance and implications.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The authors wish to thank Thomas Lengauer for helpful remarks and discussions during the course of this work. Conflict of Interest: none declared.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-instance kernels</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Gärtner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Machine Learning</title>
		<editor>Sammut,C. and Hoffmann,A.G.</editor>
		<meeting>the 19th International Conference on Machine Learning<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Hallmarks of cancer: the next generation</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Hanahan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">A</forename>
				<surname>Weinberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="646" to="674" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Locality preserving projections</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>He</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Niyogi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 16</title>
		<editor>Thrun,S. et al</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Applied Survival Analysis: Regression Modeling of Time to Event Data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">W</forename>
				<surname>Hosmer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Jr</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Affinity aggregation for spectral clustering</title>
		<author>
			<persName>
				<forename type="first">H.-C</forename>
				<surname>Huang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society</title>
		<meeting>the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society<address><addrLine>Washington DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="773" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Multiple kernel learning for dimensionality reduction</title>
		<author>
			<persName>
				<forename type="first">Y.-Y</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1147" to="1160" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Consensus clustering—a resampling-based method for class discovery and visualization of gene expression microarray data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Monti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<meeting><address><addrLine>Hingham, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer Academic Publishers</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="91" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Identification of a CpG island methylator phenotype that defines a distinct subgroup of glioma</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Noushmehr</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancer Cell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="510" to="522" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">The future of glioblastoma therapy: synergism of standard of care and immunotherapy</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Patel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cancers</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1953" to="1987" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>