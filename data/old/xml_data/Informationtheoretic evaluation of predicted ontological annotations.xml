
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Information-theoretic evaluation of predicted ontological annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Wyatt</forename>
								<forename type="middle">T</forename>
								<surname>Clark</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Informatics</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Predrag</forename>
								<surname>Radivojac</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Informatics</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<postCode>47405</postCode>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Information-theoretic evaluation of predicted ontological annotations</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="page" from="53" to="61"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt228</idno>
					<note>BIOINFORMATICS Contact: predrag@indiana.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: The development of effective methods for the prediction of ontological annotations is an important goal in computational biology , with protein function prediction and disease gene prioritization gaining wide recognition. Although various algorithms have been proposed for these tasks, evaluating their performance is difficult owing to problems caused both by the structure of biomedical ontologies and biased or incomplete experimental annotations of genes and gene products. Results: We propose an information-theoretic framework to evaluate the performance of computational protein function prediction. We use a Bayesian network, structured according to the underlying ontology, to model the prior probability of a protein&apos;s function. We then define two concepts, misinformation and remaining uncertainty, that can be seen as information-theoretic analogs of precision and recall. Finally, we propose a single statistic, referred to as semantic distance, that can be used to rank classification models. We evaluate our approach by analyzing the performance of three protein function predictors of Gene Ontology terms and provide evidence that it addresses several weaknesses of currently used metrics. We believe this framework provides useful insights into the performance of protein function prediction tools.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Ontological representations have been widely used in biomedical sciences to standardize knowledge representation and exchange (<ref type="bibr" target="#b18">Robinson and Bauer, 2011</ref>). Modern ontologies are typically viewed as graphs in which vertices represent terms or concepts in the domain of interest, and edges represent relational ties between terms (e.g. is-a, part-of). Although, in theory, there are no restrictions on the types of graphs used to implement ontologies, hierarchical organizations, such as trees or directed acyclic graphs, have been frequently used in the systematization of biological experiments, organismal phenotypes or structural and functional descriptions of biological macromolecules. In molecular biology, one of the most frequently used ontologies is the Gene Ontology (GO) (<ref type="bibr" target="#b4">Ashburner et al., 2000</ref>), which standardizes the functional annotation of genes and gene products. The development of GO was based on the premise that the genomes of all living organisms are composed of genes whose products perform functions derived from a finite molecular repertoire. In addition to knowledge representation, GO has also facilitated large-scale analyses and automated annotation of gene product function (<ref type="bibr" target="#b14">Radivojac et al., 2013</ref>). As the rate of accumulation of uncharacterized sequences far outpaces the rate at which biological experiments can be carried out to characterize those sequences, computational function prediction has become increasingly useful for the global characterization of genomes and proteomes as well as for guiding biological experiments via prioritization (<ref type="bibr" target="#b15">Rentzsch and Orengo, 2009;</ref><ref type="bibr" target="#b20">Sharan et al., 2007</ref>). The growing importance of tools for the prediction of GO annotations, especially for proteins, presents the problem of how to accurately evaluate such tools. First, because terms can automatically be associated with their ancestors in the GO graph, the task of an evaluation procedure is to compare the predicted graph with the true experimental annotation. Furthermore, the structure of the ontology introduces dependence between terms, which must be appropriately considered when comparing two graphs. Second, GO, as most current ontologies, is generally unfinished and contains a range of specificities of functional descriptions at the same depth of the ontology (<ref type="bibr">Alterovitz et al., 2010</ref>). Third, protein function is complex and context dependent; thus, a single biological experiment rarely results in complete characterization of a protein's function. This is particularly evident in cases when only high-throughput experiments are used for functional characterization, leading to shallow annotation graphs. This poses a problem in evaluation, as the ground truth is incomplete and noisy. Finally, different computational models produce different outputs that must be accounted for. For example, some models simply predict an annotation graph, possibly associating it with a numerical score, whereas others assign a score to potentially each node in the ontology, with an expectation that a good decision threshold would be applied to provide useful annotations. There are two important factors related to the development of evaluation metrics. First, because both the experimental and predicted annotation of genes can be represented as subgraphs of the generally much larger GO graph, it is unlikely that a given computational method will provide an exact prediction of the experimental annotation. Thus, it is necessary to develop metrics that facilitate calculating degrees of similarity between pairs of graphs and appropriately address dependency between nodes. Ideally, such a measure of similarity would be able to characterize not only the level of correct prediction of the true (albeit incomplete) annotation but also the level of misannotation. The second important factor related to the evaluation metric is its interpretability. This is because characterizing the predictor's performance should be meaningful to a downstream user. Ideally, an evaluation metric would have a simple probabilistic interpretation. In this article, we develop an information-theoretic framework for evaluating the prediction accuracy of computer-generated ontological annotations. We first use the structure of the *To whom correspondence should be addressed. ß The Author 2013. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com ontology to probabilistically model, via a Bayesian network, the prior distribution of protein experimental annotation. We then apply our metric to three protein function prediction algorithms selected to highlight the limitations of typically considered evaluation metrics. We show that our metrics provide added value to the current analyses of the strengths and weaknesses of computational tools. Finally, we argue that our framework is probabilistically well founded and show that it can also be used to augment already existing evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>The issue of performance evaluation is closely related to the problems of measuring similarity between pairs of graphs or sets. First, we note that a protein's annotation (experimental or predicted) is a graph containing a subset of nodes in the ontology together with edges connecting them. We use the term leaf node to describe a node that has no descendants in the annotation graph, although it is allowed to have descendants in the ontology. A set of leaf terms completely describes the annotation graph. We roughly group both graph similarity and performance evaluation metrics into topological and probabilistic categories and note that a particular metric may combine aspects from both. More elaborate distinctions are provided by<ref type="bibr" target="#b6">Guzzi et al. (2012) and</ref><ref type="bibr" target="#b12">Pesquita et al. (2009)</ref>. Topological metrics rely on the structure of the ontology to perform evaluation and typically use metrics that operate on sets of nodes and/or edges. A number of topological measures have been used, including the Jaccard and cosine similarity coefficients (the cosine approach initially maps the binary term designations into a vector space), the shortest path-based distances (<ref type="bibr" target="#b13">Rada et al., 1989</ref>) and so forth. In the context of classifier performance analysis, two common 2D metrics are the precision/recall curve and the Receiver Operating Characteristic (ROC) curve. Both curves are constructed based on the overlap in either edges or nodes between true and predicted terms and have been widely used to evaluate the performance of tools for the inference of GO annotations. They can also be used to provide a single statistic to rank classifiers through the maximum F-measure in the case of precision/recall curve or the area under the ROC curve. The area under the ROC curve has a limitation arising from the fact that the ontology is relatively large, but that the number of terms associated with a typical protein is relatively small. In practice, this results in specificities close to one, regardless of the prediction, as long as the number of predicted terms is relatively small. Although these statistics provide good feedback regarding multiple aspects of a predictor's performance, they do not always address node dependency or the problem of unequal specificity of functional annotations found at the same depth of the graph. Coupled with a large bias in the distribution of terms among proteins, prediction methods that simply learn the prior distribution of terms in the ontology could appear to have better performance than they actually do. The second class of similarity/performance measures is probabilistic or information-theoretic metrics. Such measures assume an underlying probabilistic model over the ontology and use a database of proteins to learn the model. Similarity is then assessed by measuring the information content of the shared terms in the ontology but can also take into account the information content of the individual annotations. Unlike with topological measures where updates to the ontology affect similarity between objects, information-theoretic measures are also affected by changes in the underlying probabilistic model even if the structure of the ontology remains the same. Probabilistic metrics closely follow and extend the methodology laid out by<ref type="bibr" target="#b16">Resnik (1995)</ref>, which is based on the notion of information content between a pair of individual terms. These measures overcome biases related to the structure of the ontology; however, they have several drawbacks of their own. One that is especially important in the context of analyzing the performance of a predictor is that they only report a single statistic, namely, the similarity or distance between two terms or sets of terms. This ignores the tradeoff between precision and recall that any predictor has to make. In the case of Resnik's metric, a prediction by any descendant of the true term will be scored as if it is an exact prediction. Similarly, a shallow prediction will be scored the same as a prediction that deviates from the true path at the same point, regardless of how deep the erroneous prediction might be. Although some of these weaknesses have been corrected in subsequent work (<ref type="bibr" target="#b7">Jiang and Conrath, 1997;</ref><ref type="bibr" target="#b9">Lin, 1998;</ref><ref type="bibr" target="#b19">Schlicker et al., 2006</ref>), there remains the issue that the available probabilistic measures of semantic similarity resort to ad hoc solutions to address the common situation where proteins are annotated by graphs that contain multiple leaf terms (<ref type="bibr" target="#b5">Clark and Radivojac, 2011</ref>). Various approaches have been taken, including averaging between all pairs of leaf terms (<ref type="bibr" target="#b10">Lord et al., 2003</ref>), finding the maximum among all pairs (<ref type="bibr" target="#b17">Resnik, 1999</ref>) or finding the best-match average, but each such solution lacks strong justification in general. For example, all-pair averaging leads to anomalies where the exact prediction of an annotation containing a single leaf term u would be scored higher than the exact prediction of an annotation containing two distinct leaf terms u and v of equal information content, when it is more natural to think that the latter prediction should be scored higher. Finally, certain semantic similarity metrics that incorporate pairwise matching between leaf terms tacitly assume that the objects to be compared are annotated by similar numbers of leaf terms. As such, they could produce undesirable solutions when applied to a wide range of prediction algorithms such as those outputting a large number of predicted terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>Our objective here is to introduce information-theoretic metrics for evaluating classification performance in protein function prediction. In this learning scenario, the input space X represents proteins, whereas the output space Y contains directed acyclic graphs describing protein function according to GO. Because of the hierarchical nature of GO, both experimental and computational annotations need to satisfy the consistency requirement, i.e. if an object x 2 X is assigned a node (functional term) v from the ontology, it must also be assigned all of the ancestors of v up to the root(s). Therefore, the task of a classifier is to assign the best consistent subgraph of the ontology to each new protein and output a prediction score for this subgraph and/or each predicted term. We only consider consistent subgraphs as descriptions of function and simplify the exposition by referring to such graphs as prediction or annotation graphs. In addition, we frequently treat consistent graphs as sets of nodes or functional terms and use set operations to manipulate them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i54</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>W.T.Clark and P.Radivojac</head><p>We now proceed to provide a definition for the information content of a (consistent) subgraph in the ontology. Then, using this definition, we derive information-theoretic performance evaluation metrics for comparing pairs of graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Calculating the information content of a graph</head><p>Let each term in the ontology be a binary random variable and consider a fixed but unknown probability distribution over X and Y according to which the quality of a prediction process will be evaluated. We shall assume that the prior distribution of a target can be factorized according to the structure of the ontology, i.e. we assume a Bayesian network as the underlying data generating process for the target variable. According to this assumption, each term is independent of its ancestors, given its parents and, thus, the full joint probability can be factorized as a product of individual terms obtained from the set of conditional probability tables associated with each term (<ref type="bibr" target="#b8">Koller and Friedman, 2009</ref>). Here, we are only interested in marginal probabilities that a protein is experimentally associated with a consistent subgraph T in the ontology. This probability can be expressed as</p><formula>PrðTÞ ¼ Y v2T PrðvjPðvÞÞ, ð1Þ</formula><p>where v denotes a node in a graph and PðvÞ is the set of parent nodes of v.</p><p>Here, Equation</p><p>(1) can be derived from the full joint factorization by first marginalizing over the leaves of the ontology and then moving towards the root(s) for all nodes not in T.</p><p>The information content of a subgraph can be thought of as the number of bits of information one would receive about a protein if it were annotated with that particular subgraph. We calculate the information content of a subgraph T in a straightforward manner as iðTÞ ¼ log 1 PrðTÞ and use a base 2 logarithm as a matter of convention. The information content of a subgraph T can now be expressed by combining the previous two equations as</p><formula>iðTÞ ¼ X v2T log 1 PrðvjPðvÞÞ ¼ X v2T iaðvÞ,</formula><p>where, to simplify the notation, we use ia(v) to represent the negative logarithm of PrðvjPðvÞÞ. Term ia(v) can be thought of as the increase, or accretion, of information obtained by adding a child term to a parent term, or set of parent terms, in an annotation. We will refer to ia(v) as information accretion (perhaps information gain would be a better term, but because it is frequently used in other applications to describe an expected reduction in entropy, we avoid it in this situation). A simple ontology containing five terms together with a conditional probability table associated with each node is shown in<ref type="figure" target="#fig_0">Figure 1A</ref>. Because of the graph consistency requirement, each conditional probability table is limited to a single number. For example, at node b in the graph, the probability Prðb ¼ 1ja ¼ 1Þ is the only one necessary because Prðb ¼ 0ja ¼ 1Þ ¼ 1 À Prðb ¼ 1ja ¼ 1Þ and because Prðb ¼ 1ja ¼ 0Þ is guaranteed to be 0. In<ref type="figure" target="#fig_0">Figure 1B</ref>, we show a sample dataset of four proteins functionally annotated according to the distribution defined by the Bayesian network. In<ref type="figure" target="#fig_0">Figure 1C</ref>, we show the total information content for each of the four annotation graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A</head><p>B C</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Measuring the quality of function prediction</head><p>A typical predictor of protein function usually outputs scores that indicate the strength (e.g. posterior probabilities) of predictions for each term in the ontology. To address this situation, the concepts of remaining uncertainty and misinformation need to be considered as a function of a decision threshold. In such a scenario, predictions with scores greater than or equal to are considered positive predictions, whereas the remaining associations are considered negative (if the strength of a prediction is expressed via P-values or E-values, values lower than the threshold would indicate positive predictions). Regardless of the situation, every decision threshold results in a separate pair of values corresponding to the remaining uncertainty ruðT, PðÞÞ and misinformation miðT, PðÞÞ. The remaining uncertainty and misinformation for a previously unseen protein can be calculated as expectations over the data generating probability distribution. Practically, this can be performed by averaging over the entire set of proteins used in evaluation, i.e.</p><formula>ruðÞ ¼ 1 n X n i¼1 ruðT i , P i ðÞÞ ð2Þ and miðÞ ¼ 1 n X n i¼1 miðT i , P i ðÞÞ ð3Þ</formula><p>where n is the number of proteins in the dataset, T i is the true set of terms for protein x i , and P i ðÞ is the set of predicted terms for protein x i , given decision threshold. Once the set of terms with scores greater than or equal to is determined, the set P i ðÞ is composed of the unique union of the ancestors of all predicted terms. As the decision threshold is moved from its minimum to its maximum value, the pairs of ðruðÞ, miðÞÞ will result in a curve in 2D space. We refer to such a curve using ðruðÞ, miðÞÞ. Removing the normalizing constant ( 1 n ) from the aforementioned equations would result in the total remaining uncertainty and misinformation associated with a database of proteins and a set of predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Weighted metrics One disadvantage of definitions in Equations</head><p>(2) and (3) is that an equal weight is given to proteins with low and high information content annotations when averaging. To address this, we assign a weight to each protein according to the information content of its experimental annotation. This formulation naturally downweights proteins with less informative annotations compared with proteins with rare, and therefore more informative (surprising), annotations. In biological datasets, frequently seen annotations have a tendency to be incomplete or shallow annotation graphs and arise owing to the limitations or high-throughput nature of some experimental protocols. We define weighted remaining uncertainty as</p><formula>wruðÞ ¼ P n i¼1 iðT i Þ Á ruðT i , P i ðÞÞ P n i¼1 iðT i Þ ð4Þ and weighted misinformation as wmiðÞ ¼ P n i¼1 iðT i Þ Á miðT i , P i ðÞÞ P n i¼1 iðT i Þ ð5Þ 3.3.2</formula><p>Semantic distance Finally, to provide a single performance measure, which can be used to rank and evaluate protein function prediction algorithms, we introduce semantic distance as the minimum distance from the origin to the curve ðruðÞ, miðÞÞ. More formally, the semantic distance S k is defined as</p><formula>S k ¼ min ðru k ðÞ þ mi k ðÞÞ 1 k , ð6Þ</formula><p>where k is a real number greater than or equal to one. Setting k ¼ 2 results in the minimum Euclidean distance from the origin. The preference for Euclidean distance (k ¼ 2) over say Manhattan distance (k ¼ 1) is to penalize unbalanced predictions with respect to the depth of predicted and experimental annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Precision and recall</head><p>To contrast the semantic distance-based evaluation with more conventional performance measures, in this section, we briefly introduce precision and recall for measuring functional similarity. As before, we consider a set of propagated experimental terms T and predicted terms PðÞ and define precision as the fraction of terms predicted correctly. More specifically, prðT, PðÞÞ ¼ jT \ PðÞj jPðÞj , where Á j j is the set cardinality operator. Only proteins for which the prediction set is non-empty can be used to calculate average precision. To address this issue, the root term is counted as a prediction for all proteins. Similarly, recall is defined as the fraction of experimental (true) terms, which were correctly predicted, i.e. rcðT, PðÞÞ ¼ jT \ PðÞj jTj :</p><p>As before, precision prðÞ and recall rcðÞ for the entire dataset are calculated as averages over the entire set of proteins [an alternative definition of precision and recall is given by<ref type="bibr" target="#b21">Verspoor et al. (2006)]</ref>. Finally, to provide a single evaluation measure, we use the maximum F-measure over all decision thresholds. For a particular set of terms T and PðÞ, F-measure is calculated as the harmonic mean of precision and recall. More formally, the final evaluation metric is calculated as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Information-theoretic weighted formulation</head><p>The definition of information accretion and the use of a probabilistic framework defined by the Bayesian network enables the straightforward application of information accretion to weight each term in the ontology. Therefore, it is easy to generalize the definitions of precision and recall from the previous section into a weighted formulation. Here, weighted precision and weighted recall can be expressed as wprðT, PðÞÞ ¼Weighted precision wprðÞ and recall wrcðÞ can then be calculated as weighted averages over the database of proteins, as in Equations (4) and (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS AND RESULTS</head><p>In this section, we fist analyze the average information content in a dataset of experimentally annotated proteins and then evaluate performance accuracy of different function prediction methods using both topological and probabilistic metrics. Each experiment was conducted on all three categories of the GO: Molecular Function (MFO), Biological Process (BPO) and Cellular Component (CCO) ontologies. To avoid cases where the information content of a term is infinite, a pseudo-count of one was added to each term, and the total number of proteins in the dataset was incremented when calculating term frequencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data, prediction models and evaluation</head><p>We first collected all proteins with GO annotations supported by experimental evidence codes (EXP, IDA, IPI, IMP, IGI, IEP, TAS, IC) from the January 2011 version of the Swiss-Prot database (29 699 proteins in MFO, 31 608 in BPO and 30 486 in CCO). We then generated three simple function annotation models: Naive, BLAST and GOtcha, to assess the ability of performance metrics to accurately reflect the quality of a predicted set of annotations. In addition to these three methods, we generated another set of 'predictions' by collecting experimental annotations for the same set of proteins from a database generated by the GO Consortium released at about the same time as our version of Swiss-Prot. This was done to quantify the variability of experimental annotation across different databases using the same set of metrics. In addition, this comparison can be used to estimate the empirical upper limit of prediction accuracy because the observed performance is limited by the noise in experimental data. All computational methods were evaluated using 10-fold cross-validation. The Naive model was designed to reflect biases in the distribution of terms in the dataset and was the simplest annotation model we used. It was generated by first calculating the relative frequency of each term in the training dataset. This value was then used as the prediction score for every protein in the test set; thus, every protein in the test partition was assigned an identical set of predictions over all functional terms. The performance of the Naive model reflects what one could expect when annotating a protein with no knowledge about that protein. The BLAST model was generated using local sequence identity scores to annotate proteins. Given a target protein sequence x, a particular functional term v in the ontology, and a set of sequences S v ¼ fs 1 , s 2 ,. . .g annotated with term v, we determine the BLAST predictor score for function v as maxfsidðx, sÞ : s 2 S v g, where sidðx, sÞ is the maximum sequence identity returned by the BLAST package (<ref type="bibr" target="#b3">Altschul et al., 1997</ref>) when the two sequences are aligned. We chose this method to mimic the performance one would expect if they simply used BLAST to transfer annotations between similar sequences. The third method, GOtcha (<ref type="bibr" target="#b11">Martin et al., 2004</ref>), was selected to incorporate not only sequence identity between protein sequences but also the structure of the ontology (technically, BLAST also incorporates structure of the ontology but in a relatively trivial manner). Specifically, given a target protein x, a particular functional term v, and a set of sequences S v ¼ fs 1 , s 2 ,. . .g annotated with function v, one first determines the r-score for function v as r v ¼ c À P s2Sv logðeðx, sÞÞ, where eðx, sÞ represents the E-value of the alignment between the target sequence x and sequence s, and c ¼ 2 is a constant added to the given quantity to ensure all scores were above 0. Given the r-score for function v, i-scores were then calculated by dividing the r-score of each function by the score for the root term i v ¼ r v =r root. As such, GOtcha is an inexpensive and robust predictor of function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Average information content of a protein</head><p>We first examined the distribution of the information content per protein for each of the three ontologies (<ref type="figure" target="#fig_4">Fig. 3</ref>). We observe a wide range of information contents in all ontologies, reaching over 128 bits in case of BPO (which corresponds to a factor of 128 in the probability of observing particular annotation graphs). The distributions for MFO and CCO show unusual peaks for low information contents, suggesting that a large fraction of annotation graphs in these ontologies are low quality. One such anomaly is created by the term 'binding' in MFO that is associated with 72% of proteins. Furthermore, 41% of proteins are annotated with its child 'protein binding' as a leaf term, and 26% are annotated with it as their sole leaf term. Such annotations, which are clearly a consequence of high-throughput experiments, present a significant difficulty in method evaluation. Previously, we showed that the distribution of leaf terms in protein annotation graphs exhibits scale-free tendencies (<ref type="bibr" target="#b5">Clark and Radivojac, 2011</ref>). Here, we also analyzed the average number of leaf terms per protein and compared it with the information content of that protein. We estimate the average number of leaf terms to be 1.6 (std. 1.0), 3.0 (std. 3.6) and 1.6 (std. 1.0) for MFO, BPO and CCO, respectively, and calculate Pearson correlation between the information content and the number of leaf terms for a protein (0.80, 0.92 and 0.71). Such high level of correlation suggests that proteins annotated with a small number of leaf terms are generally annotated by shallow graphs. This is particularly evident in the case of 'protein binding' annotations that can be derived from yeast-2-hybrid experiments but provide little insight into the functional aspects of these complexes when only viewed as GO annotations. We believe the wide range of information contents coupled i57</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Information-theoretic evaluation</head><p>with the fact that a large fraction of proteins were essentially uninformative, justifies the weighting proposed in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">2D plots</head><p>To assess how each metric evaluated the performance of the four prediction methods, we generated 2D plots.<ref type="figure">Figure 4</ref>shows the performance of each predictor using precision/recall and ru-mi curves, as well as their weighted variants [additional precision/ recall curves using the definition by<ref type="bibr" target="#b21">Verspoor et al. (2006)</ref>as well as additional ru-mi curves are provided in<ref type="bibr">Supplementary Materials]</ref>. The performance of the GO/Swiss-Prot annotation is represented as a single point because it compares two databases of experimental annotations. When looking at the precision/recall curves, we first observe an unusually high area under the curve associated with the Naive model. This is a result of a significant fraction of low information content annotations that are relatively easy to predict by simply using prior probabilities of terms as prediction values. In addition, these biases lead to a biologically unexpected result where the predictor based on the BLAST algorithm performs on par with the Naive model, e.g. F max (BLAST, MFO) ¼ 0:65 and F max (Naive, MFO) ¼ 0:60, whereas F max (BLAST, CCO) ¼ 0:63; F max (Naive, CCO) ¼ 0:64. The largest difference between the BLAST and Naive models was observed for BPO, which has a Gaussian-like distribution of information contents in the logarithmic scale (<ref type="figure" target="#fig_4">Fig. 3</ref>). The second column of plots in<ref type="figure">Figure 4</ref>shows the weighted precision/recall curves. Here, we observe large changes in the performance accuracy, especially for the Naive model, in MFO and CCO categories, whereas the BPO category was, for the most part, not impacted. We believe that the information-theoretic weighting of precision and recall resulted in more meaningful evaluation. The information-theoretic measures are shown in the last two columns of<ref type="figure">Figure 4</ref>. One useful property of ru-mi plots is that they explicitly illustrate how many bits of information are yet to be revealed about a protein (on average) as a function of misinformation that is introduced by over-prediction or misannotation. In all three categories, the amount of misinformation being introduced increases rapidly; quickly obtaining a rate that is twice the amount of expected information for an average protein. We believe these plots shed new light into how much information overload a researcher can be presented with by drawing predictions at a particular threshold. Looking from right to left in each plot, we observe an elbow in each of the curves (at $3 bits for MFO and CCO and 12 bits for BPO;<ref type="figure">Fig. 4</ref>) after which the remaining uncertainty barely decreases, whereas misinformation grows out of control.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparisons of single statistics</head><p>Here, we analyze the ability of the single measures to rank predictors and lead to useful evaluation insights. We compare the performance of semantic distance to several other methods that calculate either topological or semantic similarities. For each evaluation method, the decision threshold was varied for each of the prediction methods, and the threshold providing the best performance was selected as optimal. We then analyze and discuss the performance of these metrics at those optimal thresholds. We implemented the semantic similarity metrics of Jiang and</p><p>Conrath (1997), Lin (1998), Resnik (1995) and<ref type="bibr" target="#b19">Schlicker et al. (2006)</ref>, as detailed in Supplementary Materials. Because each of these measures is defined for a pair of terms in the ontology, scores between two protein annotation graphs (true graph T versus predicted graph P) were obtained by averaging scores over all pairs of leaf terms ðt, pÞ such that t 2 T and p 2 P. We refer to such scoring as all-pair averaging and note that the allpair averaging using Resnik's term similarity was implemented by<ref type="bibr" target="#b10">Lord et al. (2003)</ref>in the context of GO annotations. The results for a best-match averaging (also referred to as max-average method) are presented in the Supplementary Materials. In addition to these semantic measures, we also implemented the Jaccard similarity coefficient between the sets of vertices in the two annotation graphs (Supplementary Materials). In terms of precision/recall curve and ru-mi curve, we used F max and S 2 measures to obtain optimal thresholds.<ref type="figure">Table 1</ref>shows the maximum similarity, or minimum distance in the case of Jiang and Conrath's and semantic distance, that each metric obtained for each of our classification models. In addition to reporting the maximum similarity, we also report the decision threshold at which that value was obtained along with the associated level of remaining uncertainty and misinformation at that threshold. The first interesting observation is that all metrics, aside from that of Jiang and Conrath, obtain optimal thresholds that result in relatively similar levels of remaining uncertainty and misinformation for the GOtcha model. However, all metrics, aside from semantic distance and Jiang and Conrath's distance, seem to favor extremely high levels of misinformation at the reported decision thresholds for the BLAST model. For MFO and CCO, the semantic similarity measures of Lord et al., Lin and Sclicker et al. report misinformation levels that are more than twice the information content of the average protein in that ontology for the BLAST model. In BPO, those are even more extreme. We believe this is a direct consequence of the pairwise term averaging applied in these methods. It is particularly interesting to analyze the optimal thresholds obtained for the BLAST model. These thresholds can be interpreted as the level of sequence identity above which each metric reports functional transfer can be made. For example, because their optimal BLAST thresholds are relatively low, the levels of misinformation provided by the similarities of Lord et al., Lin and Schlicker et al. are rather large. F max and Jaccard approaches also report low threshold values for all ontologies, whereas Jiang and Conrath's distance selects the optimal threshold at an overly restrictive 100% sequence identity. We believe that the semantic distance S 2 provides more reasonable values for functional transfer, finding an optimal distance at 77, 88 and 78% for MFO, BPO and CCO, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B C</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A</head><p>B C<ref type="figure">Fig. 4</ref>. The 2D evaluation plots. Each plot shows three prediction methods: Naive (gray, dashed), BLAST (red, solid) and GOtcha (blue, solid) constructed using cross-validation. Green point labeled GO shows the performance evaluation between two databases of experimental annotations, downloaded at the same time. The rows show the performance for different ontologies (MFO, BPO, CCO). The columns show different evaluation metrics: ðprðÞ, rcðÞÞ , ðwprðÞ, wrcðÞÞ , ðruðÞ, miðÞÞ and ðwruðÞ, wmiðÞÞ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i59</head><p>Information-theoretic evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>In this work, we propose an information-theoretic framework for evaluating the performance of computational protein function prediction. We frame protein function prediction as a structured-output learning problem in which the output space is represented by consistent subgraphs of the GO graph. We argue that our approach directly addresses evaluation in cases where there are multiple true and predicted (leaf) terms associated with a protein by taking the structure of the ontology and the dependencies between terms induced by a hierarchical ontology into account. Our method also facilitates accounting for the high level of biased and incomplete experimental annotations of proteins by allowing for the weighting of proteins based on the information content of their annotations. Because we maintain an information-theoretic foundation, our approach is relatively immune to the potential dissociation between the depth of a term and its information content, a weakness of often-used topological metrics in this domain such as precision/ recall or ROC-based evaluation. At the same time, because we take a holistic approach to considering a protein's potentially large set of true or predicted functional associations, we resolve many of the problems introduced by the practice of aggregating multiple pairwise similarity comparisons common to existing semantic similarity measures. Although there is a long history (<ref type="bibr" target="#b17">Resnik, 1999</ref>) and a significant body of work in the literature regarding the use of semantic similarity measures (<ref type="bibr" target="#b6">Guzzi et al., 2012;</ref><ref type="bibr" target="#b12">Pesquita et al., 2009</ref>), to the best of our knowledge, all such metrics are based on singlestatistics and are unable to provide insight into the levels of remaining uncertainty and misinformation that every predictor is expected to balance. Therefore, the methods proposed in this work extend, modify and formalize several useful informationtheoretic metrics introduced during the past decades. In addition, both remaining uncertainty and misinformation have natural information-theoretic interpretations and can provide meaningful information to the users of computational tools. At the same time, the semantic distance based on these concepts facilitates not only the use of a single performance measure to evaluate and rank predictors but can also be exploited as a loss function during training. One limitation of the proposed approach is grounded in the assumption that a Bayesian network, structured according to the underlying ontology, will perfectly model the prior probability distribution of a target variable. An interesting anomaly with this approach is that the marginal probability, and subsequently the information content, of a single term (i.e. consistent graph with a single leaf term) calculated from a Bayesian network does not necessarily match the relative term frequency in the database (instead, the conditional probability tables are estimated as relative frequencies). Ad hoc solutions that maintain the term information content are possible but would result in sacrificed interpretability of the metric itself. One such solution can be obtained via a recursive definition iaðvÞ ¼ iðvÞ À P u2PðvÞ iaðuÞ and iaðrootÞ ¼ 0, where i(v) is estimated directly from the database. Finally, rationalizing between evaluation metrics is a difficult task. The literature presents several strategies where protein sequence similarity, protein–protein interactions or other data are used to assess whether a performance metric behaves according to expectations (<ref type="bibr" target="#b6">Guzzi et al., 2012</ref>). In this work, we took a somewhat different approach and showed that the demonstrably biased protein function data can be shown to provide surprising results with well-understood prediction algorithms and conventional evaluation metrics. Thus, we believe that our experiments provide evidence of the usefulness of the new evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors thank Prof. David Crandall for his comments on the manuscript, Prof. Iddo Friedberg for stimulating discussions about semantic similarity measures and four anonymous reviewers for their suggestions that improved the quality of this study.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. An example of an ontology, dataset and calculation of information content. (A) An ontology viewed as a Bayesian network together with a conditional probability table assigned to each node. Each conditional probability table is limited to a single number owing to the consistency requirement in assignments of protein function. Information accretion calculated for each node, e.g. iaðeÞ ¼ À log PrðejcÞ ¼ 2, are shown in gray next to each node. (B) A dataset containing four proteins whose functional annotations are generated according to the probability distribution from the Bayesian network. (C) The total information content associated with each protein found in panel (B); e.g. iðaceÞ ¼ iaðaÞþ iaðcÞ þ iaðeÞ ¼ 2. Note that iðabÞ ¼ 1 and iðabcdeÞ ¼ 4, although proteins with such annotation have not been observed in part (B)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>where</head><figDesc>prðÞ and rcðÞ are calculated by averaging over the dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. Illustration of calculating remaining uncertainty and misinformation, given a predicted annotation graph P and a graph of true annotations T. Graphs P and T are uniquely determined by the leaf nodes p 1 , p 2 , t 1 , and t 2 , respectively. Nodes colored in gray represent graph T. Nodes circled in gray are used to determine remaining uncertainty (ru; right side) and misinformation (mi; left side) between T and P</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Distribution of information content (in bits) over proteins annotated by terms for each of the three ontologies. The average information content of a protein was estimated at 10.9 (std. 10.2), 32.0 (std. 33.6) and 10.4 (std. 9.2) bits for MFO, BPO and CCO, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Funding:</head><figDesc>This work was supported by the National Science Foundation grant DBI-0644017 and National Institutes of Health grant R01 LM009722-06A1. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Performance evaluation of several information-theoretic and topological metrics</figDesc><table>Molecular Function 
Biological Process 
Cellular Component 

Lord et al. (2003) 
Max 
Threshold 
ru 
mi 
Max 
Threshold 
ru 
mi 
Max 
Threshold 
ru 
mi 

GOtcha 
2.34 
0.47 
6.34 
3.20 
1.95 
0.40 
23.36 
11.90 
1.80 
0.36 
5.88 
4.58 
BLAST 
1.61 
0.43 
4.69 
27.90 
1.40 
0.43 
16.73 
139.57 
1.27 
0.38 
4.42 
37.24 
Naive 
0.46 
0.09 
9.56 
4.23 
0.63 
0.01 
10.35 
504.88 
0.75 
0.07 
5.81 
16.34 

Lin (1998) 
Max 
Threshold 
ru 
mi 
Max 
Threshold 
ru 
mi 
Max 
Threshold 
ru 
mi 

GOtcha 
0.44 
0.52 
6.67 
2.67 
0.26 
0.46 
24.43 
9.40 
0.41 
0.50 
6.71 
2.76 
BLAST 
0.22 
0.43 
4.69 
27.90 
0.16 
0.43 
16.73 
139.57 
0.23 
0.40 
4.78 
30.45 
Naive 
0.37 
0.30 
10.39 
0.21 
0.12 
0.12 
24.92 
23.14 
0.26 
0.31 
8.98 
1.32 

Schlicker et al. (2006) 
Max 
Threshold 
ru 
mi 
Max 
Threshold 
ru 
mi 
Max 
Threshold 
ru 
mi 

GOtcha 
0.29 
0.51 
6.60 
2.76 
0.23 
0.42 
23.73 
10.99 
0.30 
0.43 
6.31 
3.56 
BLAST 
0.17 
0.44 
4.83 
25.39 
0.14 
0.43 
16.73 
139.57 
0.18 
0.43 
5.26 
23.26 
Naive 
0.14 
0.30 
10.39 
0.21 
0.08 
0.12 
24.92 
23.14 
0.13 
0.31 
8.98 
1.32 

Jiang and Conrath (1997) 
Min 
Threshold 
ru 
mi 
Min 
Threshold 
ru 
mi 
Min 
Threshold 
ru 
mi </table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3">.2 Comparing two annotation graphs We now consider a situation in which a protein&apos;s true and predicted function is represented by graphs T and P, respectively. We define two metrics that can be thought of as the information-theoretic analogs of recall and precision and refer to them as remaining uncertainty and misinformation, respectively. DEFINITION 1. The remaining uncertainty about the protein&apos;s true annotation corresponds to the information about the protein that is not yet provided by the graph P. More formally, we express the remaining uncertainty (ru) as ruðT, PÞ ¼ X v2TÀP iaðvÞ which is simply the total information content of the nodes in the ontology that are contained in true annotation T, but not in the predicted annotation P. In a slight abuse of notation, we apply set operations to graphs to manipulate only the vertices of these graphs. DEFINITION 2. The misinformation introduced by the classifier corresponds to the total information content of the nodes along incorrect paths in the prediction graph P. More formally, the misinformation is expressed as miðT, PÞ ¼ X v2PÀT iaðvÞ, which quantifies how misleading a predicted annotation is. Here, a perfect prediction (one that achieves P ¼ T) leads to ruðT, PÞ ¼ 0 and miðT, PÞ ¼ 0. However, both ruðT, PÞ and miðT, PÞ can be infinite in the limit. In practice, though, ruðT, PÞ is bounded by the information content of the particular annotation, whereas miðT, PÞ is only limited by the particular annotations a predictor chooses to return. To illustrate calculation of remaining uncertainty and misinformation, in Figure 2, we show a sample ontology where the true annotation of a protein T is determined by the two leaf terms t 1 and t 2 , whereas the predicted subgraph P is determined by the leaf terms p 1 and p 2 : The remaining uncertainty ruðT, PÞ and misinformation miðT, PÞ can now be calculated by adding the information accretion corresponding to the nodes circled in gray. Finally, this framework can be used to define the similarity between the protein&apos;s true annotation and the predicted annotation without relying on identifying an individual common ancestor between pairs of leaves (this node is usually referred to as the maximum informative common</note>

			<note place="foot">i61 Information-theoretic evaluation at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Max</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Max</forename>
				<surname>Threshold Ru Mi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Max</forename>
				<surname>Threshold Ru Mi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Max</forename>
				<surname>Threshold</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Mi</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">Min</forename>
				<surname>Threshold Ru Mi Min Threshold Ru Mi Min Threshold Ru Mi Gotcha</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Note: For each measure, the decision threshold was varied across the entire range of predictions to obtain the maximum or minimum value (shown in column 1) The threshold at which each method reached the best value is shown in column 2. Columns 3 and 4 show the remaining uncertainty (ru) and misinformation (mi) calculated according to the Bayesian network. Each semantic similarity metric was calculated according to the relative frequencies of observing each term in the database Ontology engineering</title>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<editor>i60 W.T.Clark and P.Radivojac REFERENCES Alterovitz,G. et al.</editor>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="128" to="130" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Altschul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3389" to="3402" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Gene ontology: tool for the unification of biology. The gene ontology consortium</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ashburner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Analysis of protein function and its prediction from amino acid sequence</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">T</forename>
				<surname>Clark</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Radivojac</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2086" to="2096" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic similarity analysis of protein data: assessment with biological features and issues</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">H</forename>
				<surname>Guzzi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="569" to="585" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic similarity based on corpus statistics and lexical taxonomy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">W</forename>
				<surname>Conrath</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Research in Computational Linguistics. Taiwan</title>
		<meeting>the International Conference on Research in Computational Linguistics. Taiwan</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="19" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Koller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">An information-theoretic definition of similarity</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Machine Learning</title>
		<meeting>the 15th International Conference on Machine Learning<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="296" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Investigating semantic similarity measures across the Gene Ontology: the relationship between sequence and annotation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">W</forename>
				<surname>Lord</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1275" to="1283" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">GOtcha: a new method for prediction of protein function assessed by the annotation of seven genomes</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">M</forename>
				<surname>Martin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">178</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Semantic similarity in biomedical ontologies</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Pesquita</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000443</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Development and application of a metric on semantic nets</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Rada</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="17" to="30" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">A large-scale evaluation of computational protein function prediction</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Radivojac</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="221" to="227" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Protein function prediction–the power of multiplicity</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Rentzsch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Orengo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Biotechnol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="210" to="219" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Using information content to evaluate semantic similarity in a taxonomy</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Resnik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 14th International Joint Conference on Artificial Intelligence<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="448" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic similarity in a taxonomy: an information-based measure and its application to problems of ambiguity in natural language</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Resnik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="95" to="130" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title level="m" type="main">Introduction to Bio-Ontologies</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">N</forename>
				<surname>Robinson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">A new measure for functional similarity of gene products based on gene ontology</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Schlicker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">302</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Network-based prediction of protein function</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Sharan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">88</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">A categorization approach to automated ontological function annotation</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Verspoor</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Protein Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1544" to="1549" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>