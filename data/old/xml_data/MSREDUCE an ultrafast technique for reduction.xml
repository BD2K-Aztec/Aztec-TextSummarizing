
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MS-REDUCE: an ultrafast technique for reduction of big mass spectrometry data for high-throughput processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Gul</forename>
								<surname>Muaaz</surname>
							</persName>
						</author>
						<author>
							<persName>
								<surname>Awan</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Fahad</forename>
								<surname>Saeed</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Western Michigan University</orgName>
								<address>
									<postCode>49008</postCode>
									<settlement>Kalamazoo</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MS-REDUCE: an ultrafast technique for reduction of big mass spectrometry data for high-throughput processing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btw023</idno>
					<note type="submission">Received on 27 October 2015; revised on 28 December 2015; accepted on 12 January 2016</note>
					<note>Systems biology *To whom correspondence should be addressed. Associate Editor: Jonathan Wren Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Modern proteomics studies utilize high-throughput mass spectrometers which can produce data at an astonishing rate. These big mass spectrometry (MS) datasets can easily reach peta-scale level creating storage and analytic problems for large-scale systems biology studies. Each spectrum consists of thousands of peaks which have to be processed to deduce the peptide. However, only a small percentage of peaks in a spectrum are useful for peptide deduction as most of the peaks are either noise or not useful for a given spectrum. This redundant processing of non-useful peaks is a bottleneck for streaming high-throughput processing of big MS data. One way to reduce the amount of computation required in a high-throughput environment is to eliminate non-useful peaks. Existing noise removing algorithms are limited in their data-reduction capability and are compute intensive making them unsuitable for big data and high-throughput environments. In this paper we introduce a novel low-complexity technique based on classification, quantization and sampling of MS peaks. Results: We present a novel data-reductive strategy for analysis of Big MS data. Our algorithm, called MS-REDUCE, is capable of eliminating noisy peaks as well as peaks that do not contribute to peptide deduction before any peptide deduction is attempted. Our experiments have shown up to 100Â speed up over existing state of the art noise elimination algorithms while maintaining comparable high quality matches. Using our approach we were able to process a million spectra in just under an hour on a moderate server. Availability and implementation: The developed tool and strategy has been made available to wider proteomics and parallel computing community and the code can be found at https://github. com/pcdslab/MSREDUCE</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Mass spectrometry (MS) is an analytical chemistry technique which is used for determining the type and amount of constituents of a mixture. MS has found its application in the field of biomedical research. Among all the applications of MS in biology and medicine (<ref type="bibr" target="#b9">Finehout and Lee, 2003</ref>) protein identification and quantization has proved to be the most widely used. MS based proteomics (<ref type="bibr" target="#b0">Aebersold and Mann, 2003</ref>) is very frequently used for profiling of exosomes (<ref type="bibr" target="#b23">Pisitkun et al., 2004</ref>), toxicological screening (K, 2013), evolutionary biology (<ref type="bibr" target="#b32">Zhao et al., 2012</ref>) and numerous other applications (<ref type="bibr" target="#b1">Awan and Saeed, 2015</ref>). Wide variety of computational techniques such as estimation of false positive rates (<ref type="bibr" target="#b7">Du et al., 2008</ref>), protein quantification from large datasets (<ref type="bibr" target="#b13">Hoffert et al., 2006</ref>), phosphopeptide filtering (<ref type="bibr" target="#b14">Jiang et al., 2010</ref>), phosphorylation site assignments (<ref type="bibr" target="#b26">Saeed et al., 2013b</ref>), spectrum-to-peptide matching (<ref type="bibr" target="#b8">Eng et al., 1994</ref>), (<ref type="bibr" target="#b22">Perkins et al., 1999</ref>) and denovo peptide identification (<ref type="bibr" target="#b3">Dancik et al., 1999</ref>) are required to make this MS data useful. With the introduction of modern mass spectrometers such as Thermo Orbitrap, thousands of spectra can be generated in just a single run of experiment (<ref type="bibr" target="#b12">AS et al., 2014</ref>). An MS2 spectrum consists of mass-to-charge ratio and associated intensities for each peak depicting their abundance in the sample under consideration. On an average total number of peaks for one spectrum may range up to 4000 (<ref type="bibr" target="#b1">Awan and Saeed, 2015</ref>) and for 60k human proteins the number of distinct peaks that need to be compared is close to 240 million (assuming that there is no redundancy). This number is just for a single human proteome and with projects like Peptide Atlas the number of distinct human observations are close to 35 000 which makes the total number of peaks equal to 8:4 Â 10 12. Note that this number does not include other species, distinct experimental conditions or novel post-translational modifications which exponentially increases the number of peaks that needs to be processed. The current computational analysis techniques have not been designed for such massive datasets. The current peptide identification techniques (e.g.<ref type="bibr">Sequest, Mascot;</ref><ref type="bibr" target="#b8">Eng et al., 1994;</ref><ref type="bibr" target="#b22">Perkins et al., 1999</ref>) assume that each peak that is encountered is useful in making peptide deductions. This leads to processing much more number of peaks than are necessary to make a peptide deduction (<ref type="bibr" target="#b1">Awan and Saeed, 2015;</ref><ref type="bibr" target="#b5">Ding et al., 2009;</ref><ref type="bibr" target="#b18">Mujezinovic et al., 2006;</ref><ref type="bibr" target="#b25">Saeed et al., 2013a</ref>). The processing of peaks that are noise and/or do not contribute in deduction of peptides makes the processing of these large datasets time consuming. We assert that in order to process big MS data we should be able to eliminate noisy peaks and the peaks that do not contribute to peptide deduction before an in-depth analysis of the spectra. This will clearly result in faster processing of the MS/MS spectra and will save overhead for peptide searches by reducing the number of peaks to be analyzed. Only processing the peaks that are useful rather than performing intensive per-peakcomputations will result in tremendous time and space-advantages. To the best of authors knowledge there is no algorithm available which can perform the noise removal function without performing an in-depth analysis on spectra. Further, we are not aware of any procedure that can eliminate non-noisy and yet non-essential peaks that do not contribute to peptide deduction. In this paper we introduce a novel algorithm, called MSREDUCE, for ultrafast reduction of MS/MS data in pre-processing stage. The proposed algorithm is a low-complexity procedure based on random sampling, approximate classification and quantization making it highly scalable with increasing number of spectra. Further, user defined reduction ratio makes it suitable for a variety and sizes of MS datasets. Our experiments show peptide deduction accuracy of up to 95% with reduction in the data size of up to 70%. Our results also indicate that we are able to process 1 000 000 spectra in under 1 h on a sequential machine making it highly efficient for big datasets. Comparable reduction tools took over 3 days for the same dataset on a similar machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Literature review</head><p>Spectral pre-processing has become an essential part of the MS based proteomics in recent years. Most of the spectral pre-processing techniques have a common objective i.e. to improve the reliability of the peptide to spectral matches assigned by a peptide search engine such as Sequest or Mascot. Some of the pre-processing methods that allow better identification of peptides include spectral clustering (<ref type="bibr" target="#b25">Saeed et al., 2013a</ref>), noise reduction in spectra (<ref type="bibr" target="#b5">Ding et al., 2009</ref>), quality assessment of spectra (<ref type="bibr" target="#b2">Bern et al., 2004</ref>) and precursor charge determination (<ref type="bibr" target="#b30">Wu et al., 2008</ref>). The prime objective of these techniques is to reduce the noise level in spectra which leads to better identification of peptide using standard search engines. It is also shown by several studies that reduction in data can also speedup the process of peptide identification in peptide search engines (<ref type="bibr" target="#b5">Ding et al., 2009</ref>). Below we will emphasize on the application of the existing work for reduction of Big Mass Spectrometry data. Note that we are not aware of any method that allows elimination of peaks that are not noise and may not contribute to peptide identification; with or without significant processing of the data. In the literature several noise reducing or spectral denoising algorithms are available. These algorithms identify the noisy peaks in a spectrum, depending upon the approach each algorithm uses these peaks are then either removed or their intensity is decreased to a certain value.<ref type="bibr" target="#b18">Mujezinovic et al. (2006)</ref>presented the MS Cleaner software for removing the unwanted peaks from the spectra to facilitate the peptide search engines. Their technique provided an added advantage of data reduction. They made use of numerical analysis and signal detection approach to form four different algorithms. Each algorithm looked for multiply charged ions, isotopic clusters of peaks, periodic background noise and detection of non-interpretable spectra. However, these methods are deemed to be too compute-intensive to be used as a big data pre-processing application especially for high-throughput put environments e.g. the authors report compute time per spectrum of 0.25s while treating 53 944 spectra. Their results show a total reduction of 15% to 39% in raw data. The same authors presented an upgrade of MS Cleaner software, a version 2.0 in 2010 (<ref type="bibr" target="#b19">Mujezinovic et al., 2010</ref>). The improved software employs a new algorithm for screening the interpretable spectra. It detects the peptide ladder sequence using a fixed number of most intense peaks from each spectrum. With this upgrade they claim to have reduced the data to up to 80%. Time per spectrum for newer version has been stated about 0.02–0.08 s per spectrum depending upon the dataset used. The method presented in<ref type="bibr" target="#b5">Ding et al. (2009)</ref>consists of two steps. In first; a peak intensity adjustment takes place based upon scores obtained from five different features. In the later stage a morphological reconstruction filter is employed to remove the noisy peaks based upon their adjusted intensity in the previous stage. This algorithm is able to reduce up to 69% of data but is extremely compute intensive to be used for high-throughput or parallel processing. Our experiments show a computational time of around 3 days for 1 000 000 spectra. Two other similar algorithms can be found in<ref type="bibr" target="#b31">Zhang et al. (2008) and</ref><ref type="bibr" target="#b10">Gentzel et al. (2003)</ref>. Like previously discussed algorithms they also suffer from huge number of per-peak calculations. The implementation of<ref type="bibr" target="#b10">Gentzel et al. (2003)</ref>takes approximately 1.7 s per spectrum and will take hours to process a million spectra. A quality assessment technique for spectra has been presented in<ref type="bibr" target="#b16">Lin et al. (2012)</ref>. The authors estimate the probability of a spectrum being a high quality one by treating this problem as a constraint optimization problem. Their results show that a total of 63–74% of low quality spectra were removed while losing 9–10% of high quality spectra in the process. In Na and Paek (2007) a new feature has been introduced for assessment of spectral quality which is based on cumulative intensity normalization. The results show a removal of about 60% spectra with a loss of losing 2% of high quality spectra. Some other spectral quality assessment algorithms have been presented in<ref type="figure">Tabb</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed MS-REDUCE algorithm</head><p>In this paper we present a highly efficient dimensionality reduction technique which allows massive reduction in number of peaks per spectra and in turn decrease the overall amount of data that needs to be processed. Our work builds upon a random sampling strategy that we presented earlier (<ref type="bibr" target="#b1">Awan and Saeed, 2015</ref>). The proposed algorithm, apart from being more accurate than previous strategies, has very low-computational complexity which makes it ideal for big data computations. Our classification and sampling strategy allows us to determine useful peaks before any peptide deduction calculations. Also in each stage calculations are performed on only a handful of peaks from each spectrum regardless of the size of individual spectrum. This makes processing for each spectrum a constant time operation resulting in linear-time algorithm. Here we formally introduce the problem. Notations will be introduced and defined wherever they occur first throughout the paper.Where p is a peak in a spectrum. Definition 2: If s 0 i denotes a spectrum after being processed by MS-REDUCE and the size of the processed spectrum be l 0 i then R is the reduction factor such that R ¼ ðl i 0 =l i Þ Ã 100 for each spectrum.</p><p>Each spectrum s in S needs to be reduced to obtain s 0 such that both s and s 0 correspond to the same peptide with a high confidence value. Note that there may be cases where s and s 0 do not correspond to a same peptide, in that case if the peptide match for s 0 has a confidence value better than the threshold value to qualify for a high confidence hit then that counts as a correct hit. For example a raw spectrum s might correspond wrongly to a peptide A but after being reduced using MS-REDUCE its noise level may get lowered and the reduced spectrum s 0 may correspond correctly to another peptide B or vice versa. The correctness of match is determined using quality assessment method discussed in Section 5.3. MS-REDUCE exploits the fact that about 90% of peaks in a spectrum are noisy or are not required for peptide deduction (<ref type="bibr" target="#b19">Mujezinovic et al., 2010</ref>). The sampling technique is dependent on the level of noise and intensity variation in a given spectrum. The algorithm comprises of a three stage pipeline. Each spectrum streams throught it while discarding the peaks that cannot pass through the last stage. The three stages of the pipeline are (i) Spectral Classification, (ii) Peak Quantization and (iii) Weighted Random Sampling.<ref type="figure" target="#fig_1">Figure 1</ref>shows the proposed three stage pipeline for MS-REDUCE algorithm. The spectral classification module is the first stage in the pipeline of MS-REDUCE. The main objective of this module is to determine an estimate of a spectrum's noise level. To this end, we present a novel metric, called Spectral Intensity Spread that allows us to bring about an approximate classification of spectra according to their noise level. The Intensity Spread of a spectrum roughly estimates how diverse the intensities of different peaks are. The module makes this plain assumption that larger the value for Intensity Spread, more noisy the spectrum is<ref type="bibr" target="#b29">Wells et al. (2011).</ref>Once a spectrum has been assigned a class based on its estimated noise level, it is sent forward to the Spectral Quantization module. Here the spectrum is quantized into several levels along the intensity axis. The number of quantization levels depends on the class of spectra that was assigned in previous stage. A noisier spectrum is quantized into larger number of quanta. This module distributes the peaks into different groups based upon their intensity levels thus making it much simpler and faster to access peaks based on their intensity levels. The quantized spectra is sent into the last module, where possible signal peaks are retained using random peak sampling on the quanta. The number of peaks to be retained are calculated based on the user defined reduction factor R. Weighted sampling rates are calculated for each quantum such that the sum of peaks gathered from each level equals to the percentage of peaks required. Here sampling rate is defined as the percentage of peaks to be retained in one quantization level. We give details of each module below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Spectral classification</head><p>Most pre-processing algorithms process the spectra without any regards to the quality of spectra i.e. spectra with better signal to noise ratio are processed in the same way spectra with poor S/N ratio. This results in a wastage of resources as a lot of redundant work is performed for the spectra already having higher S/N ratio. This module takes care of this issue by classifying spectra on the basis of approximate noise content in them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Intensity spread</head><p>The classification is performed by comparing each spectrums Intensity Spread with the Average Intensity Spread of the dataset.More formally: Definition 3: Let N be the total number of spectra in set S then S ¼ fs 1 ; s 2 ; s 3 ;. .. ; s n g here s i represents one spectrum. Then the intensity spread for spectrum s i can be calculated as:</p><formula>V i ¼ Max10Avgðs i Þ À Min10Avgðs i Þ (1)</formula><p>where V i is the Intensity spread of the spectrum i and Max10Avg(s i ) and Min10Avg(s i ) present the average of ten most and least intense peaks of the spectrum respectively. Similarly Average Intensity Spread for a dataset can be calculated as:</p><formula>V avg ¼ X N i¼1 ðMax10Avgðs i Þ À Min10Avgðs i Þ N (2)</formula><p>where V avg ¼ Average Intensity Spread N ¼ number of spectra in set S For each incoming spectrum the Intensity Spread value is calculated. As seen in Eq. (2), this calculation requires only twenty peaks from each spectrum regardless of its size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Classification</head><p>Spectra are classified in four different classes depending upon how much above or below the V avg their value of V lies. Details regarding the choice of number of classes can be found in Section 4.1 of supple mentary materials. Classes are named in increasing numerical order; higher classes contain spectra with larger value of V and vice versa. Threshold values for V to be assigned to a particular class are determined based on each dataset's V avg. More formally the threshold values for each class can be defined as follows:</p><p>Definition 4: Let x denote a class then for x ¼ {1, 2, 3}</p><formula>S x ¼ fs i jðx À 1Þ Ã 1 4 Ã V avg V i x Ã 1 4 Ã V avg g (3)</formula><p>and for x ¼ {4}:</p><formula>S x ¼ fs i j 3 4 Ã V avg V i g (4)</formula><p>where S x ¼ Class x containing spectra assigned to it.</p><p>It can be seen in<ref type="figure" target="#fig_3">Figure 2</ref>how spectrum 1 and 2 have very different range of intensities yet they have similar spectra spread hence have been assigned the same class. Algorithm 1 in supplementary ma terials presents a pseudo code for the classification module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Spectral quantization</head><p>In our proposed algorithm quantization of spectra takes place along the intensity axis. The intensity of a peak is simply compared with the upper and lower level of a quanta, if it lies within the limit, the peak is assigned to that quantum. This process provides us with different bins, each containing peaks of intensities within a specific range. The advantage of quantization is exploited in the following step, where useful peaks are just picked out from their quanta and added to the final reduced spectrum. Thus preventing the need of performing per peak computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Quantization levels</head><p>Number of quantization levels is chosen such that those spectra having wide Intensity Spread are quantized into larger number of levels while those having a narrow spread are processed using smaller number of quantization levels. Our in house experiments suggest that a spectrum with a smaller intensity spread yields no improvement if processed using larger number of quantization levels while increasing the processing time. In order to save time and space resources we use the smallest possible number of quantization levels necessary to perform the computation. Similarly the spectra with wider Intensity Spread needs more number of quantization levels to achieve similar accuracy. Classes 1, 2, 3 and 4 are assigned 5, 7, 9 and 11 levels of quantization respectively. These values have been chosen based upon an empirical study, details of which can be found in Section 4.2 of supplementary materials. The quantization process can be formally defined as:</p><p>Definition 5: Let n x be the maximum number of quantization levels for class x then we can have n 1 ¼ 5; n 2 ¼ 7; n 3 ¼ 9 and n 4 ¼ 11. q ij represents the quantum j of spectrum i. Then following equations are calculated for each spectrum s i , for each quantum j from 1 till n x. for j &lt; n x q ij ¼ fpj ðj À 1Þ n x Ã M10Aðs i Þ jjpjj j n x Ã M10Aðs i Þg</p><formula>(5)</formula><p>for j ¼ n x q ij ¼ fpj ðj À 1Þ n x Ã M10Aðs i Þ jjpjjg</p><formula>(6)</formula><p>where j ¼ quantization level under consideration q ij ¼ jth quantization level of ith spectrum n x ¼ number of quantization levels for class x jjpjj ¼ intensity of peak p M10Aðs i Þ ¼ Average Intensity of 10 most intense peaks of s i Eqs. (5) and (6) are computed for each value of n x ranging from 1 till n x. The quantum number assigned to each peak represents certain characteristics e.g. quantum 1 is the lowest and it contains the least intense peaks, similarly the quantum number 11 would be the highest for class 4 spectra and would contain the most intense peaks. The quanta are equally spaced rather than being of irregular spread because about 90% of the data is redundant so the probability that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Weighted random sampling</head><p>Rather than dealing with each peak, this step deals with quanta of peaks. Here this assumption is made that each peak within one quantization level has an equal probability of being a useful peak. Also because of the presence of more high intensity peaks, probability of finding a useful peak is greater in the higher quanta (<ref type="bibr" target="#b11">Havilio et al., 2003</ref>). In order to determine the number of peaks to be sampled from one quantum, sampling weights are determined as explained below (<ref type="figure" target="#fig_5">Fig. 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Weights calculation</head><p>First an estimate of number of peaks to be retained is calculated based upon the user defined reduction factor. Then a recursive method estimates the sampling weights for each quantum such that they satisfy the following equation:</p><formula>X nx i¼1 ð x i 100 Ã q i Þ ¼ p 0 (7)</formula><p>where x i ¼ sampling rate for quantization level i q i ¼ ith quantization level jjq i jj ¼ number of peaks at ith quantization level p 0 ¼ number of peaks required to satisfy the reduction factor Peaks are taken starting from the highest quantization level and continuing with lower levels until the required number of peaks is reached. If there are more peaks at a given quantization level than are needed to reach the required number of peaks, the sufficient peaks are chosen at random from that quantization level. Formally this can be presented by Eqs. (8) through (10): case 1: jjq nx jj ¼ p 0 x i ¼ 100; if i ¼ n x :</p><formula>0; otherwise: ( (8)</formula><p>case 2:</p><formula>jjq nx jj &gt; p 0 x i ¼ jjq i jj À ðjjq i jj À p 0 Þ jjq i jj ; if i ¼ n x : 0; otherwise: 8 &gt; &lt; &gt; : (9)</formula><p>case 3: Default x i ¼ 100; if p 0 À jjq j jj &gt; jjq jþ1 jj:<ref type="figure" target="#fig_5">Figure 4</ref>shows an example of weighted random sampling being performed on a class I spectrum. In the right half of the figure a reduced spectrum can be observed, it can be noticed that among the two peaks from fourth quantum only one appears in the final spectrum because of 50% sampling rate. This one peak is chosen totally at random.</p><formula>p 0 À X nx j¼iþ1 jjq j jj jjq i jj ; otherwise: 8 &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; :</formula><formula>(10)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental datasets and method</head><p>We made use of 13 datasets to carry out performance and speed evaluation of MS-REDUCE algorithm. The details of the datasets have been provided in Supplementary Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Performance evaluation</head><p>We carried out performance evaluation of MS-REDUCE in two phases. In first part we evaluate the time complexity and the speed up achieved in comparison to some of the existing algorithms. In the second part we perform the quality assessment experiments. This tests the quality of the peptide matches obtained after performing data reduction using MS-REDUCE. We also compare the quality assessment results of MS-REDUCE with the existing algorithms asquantum is assigned a weight of 100% while the fourth quantum is assigned a weight of 50%. Peaks from all other quanta are discarded owing to their zero sampling rate well as investigate the improvement achieved above the previous random sampling approach (<ref type="bibr" target="#b1">Awan and Saeed, 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Time complexity</head><p>Time complexity of the algorithm can be formulated by observing the working of each module closely and summing up the individual complexities of the modules. Theoretical time complexity for MSREDUCE comes out to be O(N). The step by step calculations to obtain this result can be found in supplementary materials. In order to verify this linear time complexity over datasets varying from conventionally sized to the modern big datasets we replicated UPS2 dataset several times to obtain datasets of desired sizes. We formed ten datasets with each subsequent set having 100 000 more spectra. The MS-REDUCE has been designed keeping in mind the challenges of big datasets from proteomics so it makes sense to use such huge datasets to perform time related experiments. For all the experiments discussed from here onwards we made use of a Linux based server with 24 CPUs, each operating at 1200 MHz.<ref type="figure" target="#fig_7">Figure 5</ref>shows the time taken by MS-REDUCE to process each datasets explained above. Currently the MS-REDUCE has been developed only as a single threaded program. To compensate for background tasks and other time delays we performed the experiment on each dataset about ten times and averaged the time taken. For these experiments we set the user defined reduction factor to 50 and 90. It can be observed from<ref type="figure" target="#fig_7">Figure 5</ref>that MS-REDUCE has a linear time complexity with respect to the number of spectra processed which is in agreement with our theoretical computational complexity. It can further be observed that a varying reduction factor does not significantly affect the running time efficiency of the algorithm. A reduction factor as described before determines the amount of data to be retained by the algorithm. It can be observed that the algorithm was able to retain its linear trend while being run with different values of Reduction Factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Speed comparison</head><p>We compared the processing speed of MS-REDUCE with the denoising algorithm presented in<ref type="bibr" target="#b5">Ding et al. (2009)</ref>. In order to compare the speed we define two metrics here. One is the conventional speed up calculation method while the other is spectra per second or SPS. Following equations describe both these metrics:</p><formula>S ¼ T other =T reduce (11)</formula><p>Where S is the speed up obtained, T other is the processing time of other algorithm under consideration while T reduce is the time taken by MS-REDUCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Comparison with De-noising algorithm</head><p>Both the algorithms were operated in similar environments for this study. As it was explained before, De-Noising algorithm makes use of four different scoring techniques to perform peak adjustments and then undesirable peaks are filtered out using a morphological filter.<ref type="figure">Table 1</ref>shows the results from timing experiments performed for comparing the time taken by the De-Noising Algorithm and MSREDUCE. The columns two and three show the processing time for algorithms in milliseconds. The De-Noising algorithm takes almost three days to process 1 million spectra. Poor scalability of such algorithms with increasing size of the datasets renders them unsuitable for high-throughput environments. The table shows MS-REDUCE takes around 47 min to process a million spectra thus achieving an average speed up of 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Quality assessment</head><p>In this section we investigate the quality of the peptide matches obtained from spectra that have been processed by MS-REDUCE. First we present the quality improvements achieved over the previous technique and then we compare the results with the two similar algorithms described before.<ref type="figure" target="#fig_8">Figure 6</ref>presents procedure for assessing the quality of peptide matches obtained after the application of MS-REDUCE algorithm. The raw spectra are fed into the MS-REDUCE or any other algorithm under observation. The processed spectra are then sent to the Tide (<ref type="bibr" target="#b4">Diament and Noble, 2011</ref>) search engine of Crux toolkit(<ref type="bibr" target="#b21">Park et al., 2008</ref>). Tide provides with the peptide spectral matches (PSMs) and decoy peptide matches based on a decoy database. These two datasets are then sent to the post processing tool known as the percolator (<ref type="bibr" target="#b15">Kall et al., 2007</ref>). The percolator computes a statistical confidence value based upon the PSMs and the decoy database matches which serve as a false discovery rate (FDR) and assigns it to each PSM. We calculated the number of PSMs for same FDR threshold obtained by using the datasets which had been treated by the test algorithm. Using this information we were able to calculate a percentage of high quality PSMs obtained by the processed spectra with respect to the number of high quality PSMs obtained using the raw spectra. This experiment was repeated for FDR values of 1%, 3%, 5%, 7% and 9%. We are taking FDR of 5% as a nominal value, so in the following experiments because of limited space we will only be presenting the results for FDR of 5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Comparison with random sampling of peaks</head><p>We performed the above explained experiment on all the thirteen datasets which have been explained in the supplementary materials and plotted the results for each dataset. The results are for FDR value of 5% but the results are extendible to other FDR values. Figures 7 and 8 present the results for quality assessment experiments performed on MS-REDUCE and and the random peak sampling method (<ref type="bibr" target="#b1">Awan and Saeed, 2015</ref>) using three HCD datasets and the UPS2 dataset. Results for remaining datasets can be found in supplementary materials (Figs 8, 9 and 10). The graphs have been plotted by varying the value of reduction factor for MS-REDUCE and Sampling rate of random peak sampling approach from 10% to 90%. The 100% presents the untreated raw dataset. MS-REDUCE presents significant improvement over the random sampling approach. For some datasets percentage matches are nearing 90% with a data reduction rate of only 20%. The results are also shown to be consistent for a given fragmentation type (HCD or CID) with MS-REDUCE doing a bit better for HCD due to better S/N ratio for HCD datasets (<ref type="bibr" target="#b27">Saeed et al., 2013c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Comparison with conventional algorithms</head><p>We also compared the quality of peptide matches for the data processed by MS-REDUCE with that processed by conventional noise reducing algorithms. The approach taken for these experiments was also the same as presented in<ref type="figure" target="#fig_8">Figure 6</ref>.<ref type="figure" target="#fig_11">Figure 9</ref>shows quality assessment plots of De-Noising Algorithm, MSCleaner 2.0 and performance of MS-REDUCE at reduction factors of 30, 60 and 90. MSREDUCE out performs MSCleaner 2.0 for all datasets except UPS2 while operating at nearly all the values of reduction factors. It out</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Analysis of high-throughput MS based proteomics data is an essential task in systems biology. Data from multiple experiments can scale from million to a billion spectra and this data volume can easily reach tera-to peta-byte level. The Big Data from modern mass spectrometers creates scaling problems for existing software designed for much smaller datasets. Although these algorithms are useful for interpretation of simple spectra, the search and match routine becomes computationally intractable for complex peptides. The big data volume that one gets from these high-throughput machines is enormous and low scalability of conventional tools cannot keep up with the rate of data generation. Hence dimensionality reduction techniques that can reduce the number of peaks that needs to be processed are essential for fast and efficient processing of MS data for system-wide studies. In this paper we presented a novel dimensionality reduction technique, called MS-REDUCE, for pre-processing big MS datasets. To our knowledge, the proposed strategy is first attempt at data reduction of MS data for high-throughput environments. Our low-computational cost strategy is based on classification, quantization and sampling of MS data peaks. An approximate classification of spectra followed by a quantization step results in binning of peaks. Each quantum of a spectrum contains peaks within a particular intensity range. Then a random sampling step is performed on these bins to obtain the peaks which form the final reduced spectrum. Our strategy is linear in time complexity with increasing number of spectra which is confirmed by our experiments. We also show that MSREDUCE can process up to a million spectra in 47 min as compared to the De-Noising Algorithm, which processes the same number of spectra in about 3 days. We performed rigorous testing of the algorithm using experimental datasets and compared its performance with two of the existing algorithms. The implemented software will be available for free academic use at the author's webpages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head><p>This work was partially funded by National Science Foundation grant NSF CCF-1464268. Conflict of Interest: none declared.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>et al. (2003), Bern et al. (2004), Purvine et al. (2004) and Ding et al. (2011). All of these algorithms take different approaches towards assessing the spectra. However, most of the approaches are compute intensive which makes them impractical and ineffective for evaluation of big datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition1:</head><figDesc>Let there be N number of spectra S ¼ fs 1 ; s 2 ;. .. ; s N g. If length of spectrum s i is l i then each spectrum can be represented as a series of peaks i.e. s i ¼ fp 1 ; p 2 ; p 3 ;. .. ; p l g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.1.</head><figDesc>Fig. 1. Figure showing the pipeline for MS-REDUCE algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Figure depicts a visual representation of classification stage. The shaded regions present the Spectral Spread (V), larger the shaded area larger the value of V and noisier the corresponding spectrum is considered</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Figure represents quantization of a class I spectrum with five different quantization levels. The red colored peaks are the most intense and belong to the fifth quantum while the light blue colored are the least intense and have been binned into the lowest quantum</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig.4.</head><figDesc>Fig. 4. Figure presents a visual representation of the random sampling module. In this figure the top most quantum is assigned a weight of 100% while the fourth quantum is assigned a weight of 50%. Peaks from all other quanta are discarded owing to their zero sampling rate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>(11) presents the conventional way of calculating speed up and the Eq. (12) presents spectra per second metric. Larger number of spectra per seconds would mean a faster processing rate for the algorithm. Here we will refer the algorithm in Ding et al. (2009) as De-Noising Algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.5.</head><figDesc>Fig. 5. Figure showing a graph between processing time of MS-REDUCE and the number of spectra processed at reduction factors of 10, 30, 60 and 90. The horizontal axis represents the number of spectra while the vertical axis represents time in milliseconds</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig.6.</head><figDesc>Fig. 6. Figure shows flow of quality assessment experiments. The Test Algorithm shown in top right corner is replaced by the algorithm under observation i.e. MS-REDUCE, MSCleaner 2.0 and Denoising Algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig.7.</head><figDesc>Fig. 7. Quality assessment plots for HCD-DS1, HCD-DS2 and HCD-DS3 datasets. The red colored plots represent the performance of MS-REDUCE while the blue colored plots represent the Random Sampled data. Three datasets have been differentiated using different symbols. The x-axis contains Reduction Factor i.e. amount of data retained. And the y-axis shows the percentage of accurate peptide hits obtained from the processed data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig.8.</head><figDesc>Fig. 8. Quality assessment plot for UPS2 dataset. The red plot represents the performance of MS-REDUCE while the blue plot represent the Random Sampled data. The x-axis contains Reduction Factor i.e. amount of data retained. And the y-axis shows the percentage of accurate peptide hits obtained from the processed data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig.9.</head><figDesc>Fig. 9. Figure showing quality assessment plots for De-Noising Algorithm Algorithm, MSCleaner 2.0 and MS-REDUCE. Quality Assessment plots for different Reduction Factor of MS-REDUCE can be observed. In the legend a numerical value with MS-REDUCE represents its reduction factor. X-axis contain the labels for the experimental datasets while Y-axis represents the percentage of peptide matches obtained from each dataset after being processed by each algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Speed achieved over the Denoising Algorithm</figDesc><table>Spectra 
T denoise (m) 
T reduce (m) 
Speed up 

9:61 Â 10 4 
2:35 Â 10 7 
2:25 Â 10 5 
103 
1:92 Â 10 5 
4:41 Â 10 7 
4:50 Â 10 5 
96 
2:89 Â 10 5 
6:49 Â 10 7 
6:78 Â 10 5 
94 
3:85 Â 10 5 
8:60 Â 10 7 
9:03 Â 10 5 
94 
4:81 Â 10 5 
1:09 Â 10 8 
1:12 Â 10 6 
95 
5:78 Â 10 5 
1:31 Â 10 8 
1:75 Â 10 6 
83 
6:74 Â 10 5 
1:55 Â 10 8 
2:0 Â 10 6 
86 
7:71 Â 10 5 
1:76 Â 10 8 
2:05 Â 10 6 
94 
8:67 Â 10 5 
1:97 Â 10 8 
2:29 Â 10 6 
94 
9:63 Â 10 5 
2:20 Â 10 8 
2:47 Â 10 6 
98 
1:06 Â 10 6 
2:43 Â 10 8 
2:81 Â 10 6 
99 

Table showing comparison between run runtimes of the De-Noising 
Algorithm denoted by T denoise and MS-REDUCE denoted by T reduce . </table></figure>

			<note place="foot">at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">M.G.Awan and F.Saeed at University of California, Los Angeles on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Mass spectrometry-based proteomics</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Aebersold</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Mann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">422</biblScope>
			<biblScope unit="page" from="198" to="207" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">On the sampling of big mass spectrometry data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">G</forename>
				<surname>Awan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Saeed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Bioinformatics and Computational Biology</title>
		<meeting>the 7th International Conference on Bioinformatics and Computational Biology</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="143" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic quality assessment of peptide tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bern</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="49" to="54" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">De novo peptide sequencing via tandem mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Dancik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="327" to="342" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Faster sequest searching for peptide identification from tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">J</forename>
				<surname>Diament</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">S</forename>
				<surname>Noble</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="3871" to="3879" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">A novel approach to denoising ion trap tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ding</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteome Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Svm-rfe based feature selection for tandem mass spectrum quality assessment</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ding</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Data Min. Bioinf</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="73" to="88" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Linear discriminant analysis-based estimation of the false discovery rate for phosphopeptide identifications</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Du</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2195" to="2203" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">An approach to correlate tandem mass spectral data of peptides with amino acid sequences in a protein database</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">K</forename>
				<surname>Eng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Soc. Mass Spectrom</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="976" to="989" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">An introduction to mass spectrometry applications in biological research</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Finehout</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biochem. Mol. Biol. Educ</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="93" to="100" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Preprocessing of tandem mass spectrometric data to support automatic protein identification</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gentzel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteomics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Intensity-based statistical scorer for tandem mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Havilio</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="435" to="444" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">The one hour yeast proteome</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">S</forename>
				<surname>Hebert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Cell Proteomics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="339" to="347" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Quantitative phosphoproteomics of vasopressin-sensitive renal cells: regulation of aquaporin-2 phosphorylation at two sites</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Hoffert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>. Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="7159" to="7164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Classification filtering strategy to improve the coverage and sensitivity of phosphoproteome analysis</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Jiang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="6168" to="6175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for peptide identification from shotgun proteomics datasets</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Kall</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="923" to="925" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">An unsupervised machine learning method for assessing quality of tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteome Sci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Toxicological screening and quantitation using liquid chromatography/time-of-flight mass spectrometry</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Linnet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Foren. Sci. Criminol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Cleaning of raw peptide ms/ms spectra: Improved protein identification following deconvolution of multiply charged peaks, isotope clusters, and removal of background noise</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Mujezinovic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteome Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="5117" to="5131" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Reducing the haystack to find the needle: improved protein identification after fast elimination of non-interpretable peptide ms/ms spectra and noise reduction</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Mujezinovic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Quality assessment of tandem mass spectra based on cumulative intensity normalization</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Na</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Paek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Rapid and accurate peptide identification from tandem mass spectra</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">Y</forename>
				<surname>Park</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Proteome Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3022" to="3027" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Probabioity-based protein idenitification by searching sequence database using mass spectrometry data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">N</forename>
				<surname>Perkins</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electrophoresis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="3551" to="3567" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Identification and proteomic profiling of exosomes in human urine</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pisitkun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci. USA</title>
		<meeting>. Natl. Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="13368" to="13373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Spectral quality assessment for high-throughput tandem mass spectrometry proteomics</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Purvine</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OMICS: J. Integr. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="255" to="265" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Cams-rs: clustering algorithm for large-scale mass spectrometry data using restricted search space and intelligent random sampling</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Saeed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinf</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="128" to="141" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">An efficient dynamic programming algorithm for phosphorylation site assignment of large-scale mass spectrometry data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Saeed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Bioinf. Biomed. Workshops (BIBMW)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="618" to="625" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Phossa: fast and accurate phosphorylation site assignment algorithm for mass spectrometry data</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Saeed</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteome Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Similarity among tandem mass spectra from proteomic experiments: Detection, significance, and utility</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">L</forename>
				<surname>Tabb</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Anal. Chem</title>
		<imprint>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<monogr>
		<title level="m" type="main">Why use signal-to-noise as a measure of ms performance when it is often meaningless?</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Wells</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Agilent. Technologies</note>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">An approach to assessing peptide mass spectral quality without prior information</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">X</forename>
				<surname>Wu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Funct. Inf. Person. Med</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="140" to="155" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">Peakselect: preprocessing tandem mass spectra for better peptide identification</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rapid Commun. Mass Spectrom</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1203" to="1212" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Cphos: a program to calculate and visualize evolutionarily conserved functional phosphorylation sites</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteomics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="3299" to="3303" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>