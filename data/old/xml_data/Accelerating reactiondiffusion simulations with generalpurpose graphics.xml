
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Accelerating reaction–diffusion simulations with general-purpose graphics processing units</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Matthias</forename>
								<surname>Vigelius</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">FIT Centre for Research in Intelligent Systems</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<addrLine>Clayton Victoria 3800</addrLine>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Aidan</forename>
								<surname>Lane</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">FIT Centre for Research in Intelligent Systems</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<addrLine>Clayton Victoria 3800</addrLine>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Bernd</forename>
								<surname>Meyer</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">FIT Centre for Research in Intelligent Systems</orgName>
								<orgName type="institution">Monash University</orgName>
								<address>
									<addrLine>Clayton Victoria 3800</addrLine>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Systems biology Accelerating reaction–diffusion simulations with general-purpose graphics processing units</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS APPLICATIONS NOTE</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="288" to="290"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq622</idno>
					<note type="submission">Received on July 21, 2010; revised on October 21, 2010; accepted on November 2, 2010</note>
					<note>[15:55 27/12/2010 Bioinformatics-btq622.tex] Page: 288 288–290 Associate Editor: Jonathan Wren Contact: matthias.vigelius@monash.edu Supplementary Information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a massively parallel stochastic simulation algorithm (SSA) for reaction-diffusion systems implemented on Graphics Processing Units (GPUs). These are designated chips optimized to process a high number of floating point operations in parallel, rendering them well-suited for a range of scientific high-performance computations. Newer GPU generations provide a high-level programming interface which turns them into General-Purpose Graphics Processing Units (GPGPUs). Our SSA exploits GPGPU architecture to achieve a performance gain of two orders of magnitude over the fastest existing implementations on conventional hardware. Availability: The software is freely available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Treating chemical reaction systems as spatially homogeneous is insufficient for many applications in a biological context. Often, spatial distributions play an important role in the dynamic evolution of biomolecular systems. The analysis of such systems requires accurate yet highly performant simulation algorithms that can handle spatially inhomogeneous reaction–diffusion (<ref type="bibr" target="#b2">Broderick and Rubin, 2006</ref>). Unfortunately, stochastic simulation methods for this problem are computationally extremely expensive and it thus becomes necessary to build parallel versions of existing algorithms (<ref type="bibr" target="#b0">Ballarini et al., 2009</ref>). GPGPUs can potentially provide high-performance computing resources to a broad audience and are consequently becoming increasingly popular for scientific computing. In the present article, we present a data-parallel GPGPU implementation of an SSA, which achieves significant performance gains over the fastest conventional implementations. To the best of our knowledge, this is the first time that a data-parallel GPGPU implementation of a quantitative SSA for spatially heterogeneous reaction-diffusion networks is reported. Several approaches to compute the stochastic time evolution of reaction–diffusion networks can be found in the literature, such as agent-based models (<ref type="bibr" target="#b1">Barrett et al., 2008</ref>), first-passage kinetic * To whom correspondence should be addressed. Monte Carlo algorithms (<ref type="bibr" target="#b6">Donev et al., 2010;</ref><ref type="bibr" target="#b14">Oppelstrup et al., 2009</ref>) or, on a mesoscopic level, compartment-based models, such as the Next-Subvolume Method (NSM) (<ref type="bibr" target="#b7">Elf et al., 2003</ref>). Not all these methods lend themselves equally well to a dataparallel implementation on GPGPUs. The standard algorithms, based on Gillespie's next reaction method (<ref type="bibr" target="#b8">Gillespie, 1976</ref>), perform an event-based simulation in which global communication is required to compute the next event time as well as to determine the corresponding reaction. Due to the high cost of global synchronization and inter-node communication, attempts to implement the Gillespie SSA directly on GPGPUs could only yield moderate performance gains (<ref type="bibr" target="#b4">Dittamo and Cangelosi, 2009</ref>). Petzold and<ref type="bibr" target="#b12">Li (2009)</ref>pursue a different approach by running many instances of the same model in parallel on a GPGPU. This technique allows immediate parallelization of sequential algorithms but cannot speed up individual runs and can thus only exploit the full hardware potential if a large number of simulations are required. For a full parallelization, methods that treat diffusion seperately from reactions appear to be more promising. Such methods are termed hybrid. One can distinguish between deterministic– stochastic algorithms, where diffusion is handled in a deterministic manner (<ref type="bibr" target="#b17">Rossinelli et al., 2008</ref>), and stochastic–stochastic methods, which are preferable for cases where the diffusive species is not necessarily present in high densities. Two prominent examples of the latter type of hybrid algorithms are the Gillespie Multiparticle Method (GMP), first presented by<ref type="bibr" target="#b16">Rodríguez et al. (2006)</ref>, and the Multinomial Simulation Algorithm (MSA) (<ref type="bibr" target="#b11">Lampoudi et al., 2009</ref>). In this article, we report a GPGPU implementation of GMP. Hybrid stochastic reaction–diffusion algorithms are an active and relatively recent field of research and no clear champion has emerged yet. Cellular automata methods are widely used to simulate reaction–diffusion systems<ref type="bibr">[see Takahashi et al. (2005)</ref>for a comprehensive review]. In particular, the multiparticle lattice gas algorithm underlying GMP (<ref type="bibr" target="#b3">Chopard et al., 1994</ref>) has been successfully applied, for example, to problems in electrochemistry (<ref type="bibr" target="#b12">Li et al., 2009</ref>). Its applicability to biochemical pathways has been shown in a number of studies, e.g. for the phosphoenolpyruvatedependent phosphotransferase (PTS) pathway in Escherichia coli (<ref type="bibr" target="#b16">Rodríguez et al., 2006</ref>). We believe that MSA should in principle be just as well suited for a data-parallel implementation. However, the free availability of the source code made GMP our first choice. A detailed comparison of computational methods for reaction– diffusion networks is given by<ref type="bibr" target="#b5">Dobrzyski et al. (2007)</ref>. For completeness, we point out that the deterministic treatment of reaction–diffusion equations with GPGPUs has a long history in the context of computer graphics. The driving motivation behind</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reaction–diffusion simulations with GPGPUs</head><p>these efforts is to realistically reproduce naturally occuring textures, for example of animals 1 or skin desease effects. 2 Likewise, agentbased reaction–diffusion simulations on GPUs have been performed before (<ref type="bibr" target="#b1">Barrett et al., 2008</ref>), but here the focus is, in contrast to our work, generally not on exact quantitative studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">IMPLEMENTATION AND PERFORMANCE</head><p>A detailed description of the algorithm and our parallelization approach can be found in the Supplementary Material. Here we can only give a brief overview. The computational domain of dimensionality d is divided into equally spaced, cubical subvolumes with sidelength λ. Each subvolume contains a number of particles of each species, which are assumed to be distributed homogeneously within the subvolume. In each time step, the diffusion part is treated separately from the reaction algorithm. This approach is termed operator-splitting (<ref type="bibr" target="#b16">Rodríguez et al., 2006</ref>). During each diffusion time step t, every subvolume independently handles all reactions employing the standard direct method (<ref type="bibr" target="#b9">Gillespie, 1977</ref>) until the simulation time for that particular subvolume exceeds t. One diffusion step is then simulated by redistributing particles among neighbouring subvolumes according to a probabilistic evolution rule which<ref type="bibr" target="#b3">Chopard et al. (1994)</ref>proved to asymptotically reproduce the macroscopic diffusion equation.<ref type="bibr" target="#b16">Rodríguez et al. (2006)</ref>demonstrated that this method correctly reproduces the literature results for a generic gene expression model and a phosphoenolpyruvate:glucose phosphotransferase system. We parallelize this algorithm by assigning one thread to each subvolume of the computational domain. Each GPU thread executes the same C function, termed a kernel, at the same time. Threads are arranged into independent blocks, which cannot be synchronized globally. Blocks of threads implicitly divide the computational domain into rectangular spatial areas. Threads corresponding to subvolumes at the boundaries of such areas must communicate across blocks to exchange particles in a diffusion event. We need to return from the kernel to the host function to synchronize globally across block boundaries. The main loop is thus executed on the CPU once per diffusion time step t. It calls three different kernels on the GPU. After choosing the species to be diffused next, we first perform the reactions for each subvolume independently in the Gillespie kernel before diffusing the corresponding species in the Diffusion kernel. Finally, we need to update the block boundaries in the Update kernel. Implementation details of the kernels can be found in the Supplementary Material. We evaluate the performance gain of our implementation by comparing it to MesoRD (<ref type="bibr" target="#b10">Hattne et al., 2005</ref>), the stochastic simulation compiler (SSC) (<ref type="bibr" target="#b13">Lis et al., 2009</ref>), which is a very efficient implementation of an SSA, and a serial implementation of GMP (<ref type="bibr" target="#b16">Rodríguez et al., 2006</ref>). We use two different setups to perform the scaling tests: a diffusion problem without reactions and an A+B annihilation problem. We initialize both on a quadratic domain and vary the number of subvolumes per dimension, while keeping the subvolume size constant (for a detailed explanation of the problems and parameters see the Supplementary Material). The serial code (MesoRD and GMP) is compiled with GCC 4.4.INTEL E6550 dual core CPU at 2.33 GHz using the Linux operating system UBUNTU (Version 10.04 LTS). We run GPGMP on our GPU cluster (equipped with NVIDIA Tesla S1070 GPUs) and an ordinary workstation (an Apple MacBookPro with an Intel Core2 Duo CPU running at 2.5 GHz and a GeForce 8600M GT graphics card).<ref type="figure" target="#fig_1">Figure 1</ref>shows the run time (in ms) for SSC (green, upward triangles), MesoRD (blue circles), serial GMP (magenta, downward triangles), GPGMP run on our GPU cluster (red squares), and GPGMP run on a workstation (red pentagons). GPGMP scales very well with the number of subvolumes. The Tesla T10 processor consists of 240 cores but, due to the thread-scheduling algorithm, no significant speed loss occurs until the total number of subvolumes exceeds ∼10 6. For the diffusion problem (left panel), with an integration domain consisting of 1024 × 1024 subvolumes, GPGMP outperforms the serial GMP implementation by a factor of 35. A test run with 4096 × 4096 subvolumes only takes about eight times longer than the same setup with 1024×1024 subvolumes. No comparison data can be given for this case, because the other implementations are unable to deal with such a large system size. We report similar speed gains for the homogeneous A+B annihilation problem (<ref type="figure" target="#fig_1">Fig. 1B</ref>). GPGMP outperforms serial GMP by a factor of ∼39 and MesoRD by ∼175. However, these speed gains can be lower if the problem is highly inhomogeneous and the workload is unevenly shared between all GPU threads. On a workstation, GPGMP performs slightly better than on the GPU cluster for low number of subvolumes (N 10 5 ) but saturates earlier. For high N 10 5 , the Tesla T10 processor on the cluster outperforms the workstation graphics card. The initial performance advantage of the standard workstation appears to be due to the fact that its CPU is superior to the cluster node CPU and that the proportion of the workload performed by the CPU becomes negligible only for large subvolume numbers. GPGMP scales with the number of subvolumes N as expected. For low N 10 4 , the runtime decreases with increasing N since the total workload (combined reaction and diffusion events) is shared among more threads. For 10 4 N 10 6 , the total runtime plateaus until the number of concurrently running threads saturates and the runtime scales linearly with N. Note again that the saturation point is higher than the number of GPU cores (240 for a Tesla T10 GPU) Page: 290 288–290</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">and run on an</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M.Vigelius et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>since</head><p>the the thread scheduler is very effective in hiding memoryaccess latency. After saturation, GPGMP scales linearly with N. On the other hand, MesoRD behaves as O(logN) and the runtime benefit of GPGMP decreases with increasing N. The saturation point can of course be shifted to higher N by using hardware with a larger number of cores, for example the next-generation NVIDIA Fermi architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DISCUSSION</head><p>We have described an implementation of the Gillespie Multiparticle Method (GMP) on GPGPUs. We report performance gains of two orders of magnitude compared with standard implementations of the (exact) inhomogeneous stochastic simulation algorithm and the (hybrid) serial implementation of GMP. Like any other hybrid method, GMP sacrifices some numerical accuracy for performance gains. This trade-off can in principle be arbitrarily adjusted through the choice of the diffusion time step. For a more detailed discussion, we refer the reader to Section 2.2.7 of the Supplementary Material. We provide a full simulation system (Inchman) that allows the user to run their models without any coding (on the Monash Sun Grid GPU cluster). Access to this system is via an easy-to-use web interface 3 that understands systems biology markup language (SBML) specifications, the lingua franca of systems biology. In addition, we provide a full implementation of the algorithm on our website. Researchers may use the C++ interface to construct their own reaction-diffusion model from scratch. The application programming interface (API) is designed to mimic the structure of SBML models, allowing the user to easily convert their models into GPGMP without having to deal with the internal details of the simulation algorithm. A variety of test problems that can be used as templates are part of the package. The full source code is included so the user can easily add the relevant GPU implementation into their own projects. Most scientific applications require a reasonable sample size to extract statistic information from the simulations. It is therefore necessary to perform multiple runs of the same problem, possibly with varying input parameters. We pursue a 2-fold approach to tackle this requirement. First, the standard implementation of GPGMP distributes the total number of runs over all available GPGPU cards. This works best if the host machine provides a one-to-one ratio of CPU cores to GPGPU cards. Second, we are integrating Inchman with Nimrod, 4 a toolkit to allow users to run parameter sweeps and parameter optimization and distribute runs over GPGPU clusters. This will become an integral part of the next release of Inchman.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>[15:55 27/12/2010 Bioinformatics-btq622.tex] Page: 289 288–290</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Runtime (in ms) versus number of subvolumes for the homogeneous diffusion problem (A) and the homogeneous A+B annihilation problem (B). The setup is detailed in Sections 2 and 3.4 of the Supplementary Material. Results are shown for MesoRD (blue circles), SSC (green, upward triangles), serial GMP (magenta, downward triangles), GPGMP run on a workstation (red pentagons) and GPGMP run on the GPU cluster (red squares). GPGMP outperforms all other implementations by two orders of magnitude.</figDesc></figure>

			<note place="foot">© The Author 2010. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> http://www.sci.utah.edu/~allen/reaction-diffusion.html 2 http://developer.download.nvidia.com/SDK/9.5/Samples/samples.html</note>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3"> http://www.csse.monash.edu.au/~berndm/inchman/ 4 https://messagelab.monash.edu.au/Nimrod Our implementation is currently limited to a constant diffusivity and vanishing drift field. We are working on extending the algorithm to incorporate spatially inhomogeneous diffusivity and drift. Funding: Australian Research Council (ARC DP0879239). Conflict of Interest: none declared.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Taming the complexity of biological pathways through parallel computing</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ballarini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief Bioinform</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="278" to="288" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Episimdemics: an efficient algorithm for simulating the spread of infectious disease over large realistic social networks</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Barrett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SC &apos;08: Proceedings of the 2008 ACM/IEEE conference on Supercomputing</title>
		<meeting><address><addrLine>Piscataway, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">The realistic modeling of biological systems: a workshop synopsis</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Broderick</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Rubin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complexus</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="217" to="230" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Multiparticle lattice gas automata for reaction diffusion systems</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Chopard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mod. Phy. C</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="47" to="63" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimized parallel implementation of gillespie&apos;s first reaction method on graphics processing units</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Dittamo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Cangelosi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Conf. Comput. Model. Simul</title>
		<imprint>
			<biblScope unit="page" from="156" to="161" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Computational methods for diffusion-influenced biochemical reactions</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Dobrzyski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1969" to="1977" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A first-passage kinetic monte carlo algorithm for complex diffusion-reaction systems</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Donev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Phys</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<biblScope unit="page" from="3214" to="3236" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Mesoscopic Reaction-Diffusion in Intracellular Signaling</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Elf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SPIE</title>
		<imprint>
			<biblScope unit="volume">5110</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">A general method for numerically simulating the stochastic time evolution of coupled chemical reactions</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">T</forename>
				<surname>Gillespie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Computat. Phys</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="403" to="434" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Exact stochastic simulation of coupled chemical reactions</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">T</forename>
				<surname>Gillespie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Phys. Chem</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="2340" to="2361" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Stochastic reaction-diffusion simulation with MesoRD</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hattne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2923" to="2924" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">The multinomial simulation algorithm for discrete stochastic simulation of reaction-diffusion systems</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lampoudi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page">94104</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Computational simulation of metastable pitting of stainless steel</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electrochimica Acta</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="6389" to="6395" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient stochastic simulation of reaction-diffusion processes via direct compilation</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2289" to="2291" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">First-passage kinetic monte carlo method</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Oppelstrup</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">66701</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient parallelization of stochastic simulation algorithm for chemically reacting systems on the graphics processing unit</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Petzold</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Journal of High Performance Computing Applications</title>
		<imprint>
			<biblScope unit="page" from="107" to="116" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Spatial stochastic modelling of the phosphoenolpyruvatedependent phosphotransferase (pts) pathway in escherichia coli</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">V</forename>
				<surname>Rodríguez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1895" to="1901" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Accelerated stochastic and hybrid methods for spatial simulations of reaction-diffusion systems</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rossinelli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chem. Phys. Lett</title>
		<imprint>
			<biblScope unit="volume">451</biblScope>
			<biblScope unit="page" from="136" to="140" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Space in systems biology of signaling pathways – towards intracellular molecular crowding in silico</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Takahashi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FEBS Lett</title>
		<imprint>
			<biblScope unit="volume">579</biblScope>
			<biblScope unit="page" from="1783" to="1788" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>