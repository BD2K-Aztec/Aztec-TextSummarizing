
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics Fast and robust optical flow for time-lapse microscopy using super-voxels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Fernando</forename>
								<surname>Amat</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit2">Janelia Farm Research Campus</orgName>
								<address>
									<postCode>20147</postCode>
									<settlement>Ashburn</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Eugene</forename>
								<forename type="middle">W</forename>
								<surname>Myers</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Max Planck Institute of Molecular Cell Biology and Genetics</orgName>
								<address>
									<postCode>01307</postCode>
									<settlement>Dresden</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Philipp</forename>
								<forename type="middle">J</forename>
								<surname>Keller</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Howard Hughes Medical Institute</orgName>
								<orgName type="institution" key="instit2">Janelia Farm Research Campus</orgName>
								<address>
									<postCode>20147</postCode>
									<settlement>Ashburn</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimage informatics Fast and robust optical flow for time-lapse microscopy using super-voxels</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">3</biblScope>
							<biblScope unit="page" from="373" to="380"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts706</idno>
					<note type="submission">Received on July 30, 2012; revised on November 16, 2012; accepted on December 7, 2012</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Optical flow is a key method used for quantitative motion estimation of biological structures in light microscopy. It has also been used as a key module in segmentation and tracking systems and is considered a mature technology in the field of computer vision. However, most of the research focused on 2D natural images, which are small in size and rich in edges and texture information. In contrast, 3D time-lapse recordings of biological specimens comprise up to several terabytes of image data and often exhibit complex object dynamics as well as blurring due to the point-spread-function of the microscope. Thus, new approaches to optical flow are required to improve performance for such data. Results: We solve optical flow in large 3D time-lapse microscopy datasets by defining a Markov random field (MRF) over super-voxels in the foreground and applying motion smoothness constraints between super-voxels instead of voxel-wise. This model is tailored to the specific characteristics of light microscopy datasets: super-voxels help registration in textureless areas, the MRF over super-voxels efficiently propagates motion information between neighboring cells and the background subtraction and super-voxels reduce the dimension-ality of the problem by an order of magnitude. We validate our approach on large 3D time-lapse datasets of Drosophila and zebrafish development by analyzing cell motion patterns. We show that our approach is, on average, 10 Â faster than commonly used optical flow implementations in the Insight Tool-Kit (ITK) and reduces the average flow end point error by 50% in regions with complex dynamic processes, such as cell divisions. Availability: Source code freely available in the Software section at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Automated computational techniques are essential for the quantitative analysis of cellular dynamics using time-lapse light microscopy. For example, to quantitatively reconstruct the development of large multi-cellular organisms such as entire Drosophila and zebrafish embryos, tens of thousands of cells need to be segmented and tracked at high spatial resolution (<ref type="bibr" target="#b26">McMahon et al., 2008;</ref><ref type="bibr" target="#b38">Tomer et al., 2012</ref>) (<ref type="figure" target="#fig_0">Fig. 1</ref>). Such analyses are of fundamental importance to understanding the development of biological tissues, to reconstructing functional defects in mutants and disease models and to quantitatively dissecting the mechanisms underlying the cellular building plan of entire complex organisms (<ref type="bibr" target="#b17">Keller et al., 2008</ref>). However, many computational challenges are encountered when performing key tasks, such as image registration, cell segmentation and cell tracking, in complex microscopy datasets (<ref type="bibr" target="#b18">Khairy et al., 2008;</ref><ref type="bibr" target="#b20">Li et al., 2007;</ref><ref type="bibr" target="#b24">Lou et al., 2011;</ref><ref type="bibr" target="#b30">Preibisch et al., 2010;</ref><ref type="bibr" target="#b33">Rubio-Guivernau et al., 2012</ref>). Optical flow computation is one of the central tasks used to perform quantitative motion estimation of biological structures in time-lapse light microscopy, from the subcellular level to the tissue scale (<ref type="bibr" target="#b0">Abramoff and Viergever, 2002;</ref><ref type="bibr" target="#b7">Buibas et al., 2010;</ref><ref type="bibr" target="#b9">Delpiano et al., 2011;</ref><ref type="bibr" target="#b32">Roberts et al., 2010</ref>). Optical flow is defined as the vector field capturing the motion of brightness patterns between adjacent volumes in time (<ref type="bibr" target="#b13">Horn and Schunck, 1981</ref>; since our examples are 3D images, we use the term 'volume' to refer to the datasets used in optical flow computation. However, our approach and code work also for 2D images). On the cellular level, optical flow information can theoretically be obtained from single-cell tracking data. However, comprehensive and accurate cell tracking in complex multicellular organisms is currently an open research problem (<ref type="bibr" target="#b38">Tomer et al., 2012</ref><ref type="bibr" target="#b24">, Lou et al., 2011</ref>). Here, optical flow methods can be useful for analyses of group dynamics, which do not require single-cell resolution, or, conversely, as the first module in a larger cell tracking framework. In this latter scenario, the flow information informs the tracking algorithm and helps improving results for regions exhibiting complex or fast cell dynamics. Optical flow computation has been the object of decades of research, and it is considered a mature technology in many computer vision applications (<ref type="bibr" target="#b3">Baker et al., 2011</ref>). However, most approaches have been tested in relatively small 2D natural images, which are dense and rich in edges and texture information. The Middlebury database (<ref type="bibr" target="#b3">Baker et al., 2011</ref>) used as a benchmark in the computer vision community is a good example of these types of images. Fluorescence microscopy volumes of biological structures are qualitatively very different from natural images (<ref type="figure" target="#fig_0">Fig. 1</ref>). They are sparse (in datasets similar to<ref type="figure" target="#fig_0">Figure 1</ref>, 80–95% of voxels are background; throughout the text, we use the term 'voxel' to generically refer to each intensity value in a dataset independent of the dimensionality of the data) and contain relatively textureless objects, which typically appear blurred *</p><p>To whom correspondence should be addressed. ß The Author 2012. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. owing to the point spread function of the microscope and the characteristics of commonly used fluorescent labeling strategies. Moreover, neighboring objects with similar appearance and multiple motions in the same volume are very common. Finally, microscopy volumes tend to be much larger than natural images, which demands computationally efficient approaches. Here, we present a new algorithm for optical flow estimation tailored to large fluorescence light microscopy 3D time-lapse datasets as the one shown in<ref type="figure" target="#fig_0">Figure 1</ref>. The key idea is to define a model that takes into account the specific characteristics of time-lapse microscopy data. In particular, we define a Markov random field (MRF) over super-voxels to improve registration in textureless areas, propagate motion information efficiently between neighboring structures and speed up computations by reducing the complexity of the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Optical flow techniques</head><p>In this paragraph, we highlight some of the fundamental insights introduced over the past few decades. We refer the reader to<ref type="bibr" target="#b3">Baker et al. (2011)</ref>for a recent comprehensive review. First,<ref type="bibr" target="#b25">Lucas and Kanade (1981)</ref>proposed a local approach by solving the optical flow independently in small rectangular regions that partition the entire volume. This approach produces a sparse field because it is ill posed for large regions with uniform appearance. In contrast, Horn and Schunck (1981) introduced a global method, where the flow is calculated at each voxel instead of a rectangular region by introducing smoothness constraints between adjacent voxels as a regularization strategy. This approach produces a dense field, but it cannot resolve motion discontinuities.<ref type="bibr" target="#b4">Black and Anandan (1996)</ref>introduced robust metrics, instead of the traditional L 2 norm, to improve results in motion discontinuity boundaries and regions with intensity changes between volumes.<ref type="bibr" target="#b6">Bruhn et al. (2005)</ref>merged the benefits of all of these previous approaches in a combined localto-global approach, where a robust Horn and Schunck formulation was solved at different spatial scales, effectively incorporating the benefits of the approach by Lucas and Kanade. Other relevant insights are the application of different weights to each of the smoothness terms to add robustness against motion discontinuities, the detection of occluded regions (<ref type="bibr" target="#b2">Ayvaci et al., 2010</ref>) and the application of a smoothing filter to the flow after each iteration of the optimization procedure (<ref type="bibr" target="#b36">Sun et al., 2010;</ref><ref type="bibr" target="#b37">Thirion, 1998</ref>) to improve accuracy. Over the years, there has also been progress on real-time optical flow, especially with recent Graphics Processing Unit (GPU) implementations (<ref type="bibr" target="#b39">Werlberger et al., 2009</ref>). Unfortunately, software incorporating the most recent advances is not publicly available, and it is not clear whether some of these techniques can be scaled to large 3D datasets according to the timing reported in the benchmarks by<ref type="bibr" target="#b3">Baker et al., (2011)</ref>. Most biomedical optical flow applications tend to implement and report results using similar methodologies to the ones explained earlier in the text without tailoring them to the characteristics of the data. For example,<ref type="bibr" target="#b29">Pock et al. (2007)</ref>presented a total variation (TV)-L 1 optical flow model for clinical datasets. However, even with the use of image pyramids to solve the problem efficiently, this approach was still slow for large 3D datasets, and it did not always outperform the Insight ToolKit (ITK) implementations. ITK is a multi-threaded Cþþ library for N-dimensional image registration and segmentation, and it is the most common baseline for comparing the performance and accuracy of new algorithms in the bioimaging domain. Many recent articles use similar strategies to target specifically time-lapse light microscopy datasets (<ref type="bibr" target="#b9">Delpiano et al., 2011;</ref><ref type="bibr" target="#b23">Lombardot et al., 2008;</ref><ref type="bibr" target="#b28">Pizarro et al., 2011</ref>), which demonstrate the general interest in applying optical flow to the type of datasets presented in this article. In the following sections, we present an optical flow formulation specifically tailored to solving optical flow for 3D time-lapse microscopy volumes. We show that our method is 10 Â faster and reduces the average flow end point error (EE) by 50% for complex dynamic processes, such as cell divisions, with respect to optical flow algorithms available in the ITK library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">APPROACH</head><p>First, we use a conservative foreground/background segmentation to consider only useful pixels. Background removal avoids the optical flow ambiguity in large uniform uninformative regions of the volume and improves computational efficiency. Second, we use a region-based approach to improve performance in the textureless objects.<ref type="bibr" target="#b12">Glocker et al. (2008)</ref>proposed a similar approach by dividing the image in a rectangular grid. However,as shown in<ref type="figure">Table 3</ref>, rectangular grids do not adapt well to sparse signals and degrade performance, as a single rectangular region can contain two objects with different dynamics.<ref type="bibr" target="#b31">Prinet et al. (2006) and</ref><ref type="bibr" target="#b40">Xu et al. (2008)</ref>also presented region-based approaches to optical flow. However, their segmentation assumptions cannot be applied to light microscopy images owing to the lack of edge and color information. Therefore, we use recent advances in fast super-voxel generation (<ref type="bibr" target="#b1">Achanta et al., 2012</ref>) to group flows into small subsets. We combine the foreground/background mask with non-adjacent super-voxel regions to generate a volume partition graph over the set of super-voxels. Then, all smoothness constraints are taken between neighboring super-voxels instead of adjacent voxels, which effectively propagate motion information between close-by cellular structures with similar motions. This graphical model effectively captures specific characteristic of time-lapse light microscopy data. Recently, Gkamas and Nikou (2011) also used super-voxels for optical flow estimation. They added super-voxels to the combined local-to-global framework to establish disconnected motion boundaries between different objects in dense natural images, which is opposite to the strategy in our MRF model for microscopy images, showing that time-lapse microscopy image should be treated differently. Aside from robustness, the model for optical flow presented here allows us to speed up the optimization by an order of magnitude. Finally, we show how standard procedures, such as robust metrics and multi-scale optimization schemes, are also effective in the microscopy imaging domain to improve performance. Our combined framework thus improves and extends optical flow to the application of large-scale time-lapse fluorescence light microscopy images.<ref type="figure" target="#fig_1">Figure 2</ref>summarizes the steps described in the next subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>Given two N-dimensional images of the same size, I t (source volume) and I tþ1 (target volume), our final goal is to estimate a motion field v p for each voxel p to register the target volume to the source volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image model</head><p>When most objects present in the volume are textureless and similar to each other, single voxels are not very informative. In other words, just trying to match single intensities leads to poor solutions. Most optical flow approaches try to guide the registration in textureless areas by imposing a smoothness constraint between adjacent voxels. Unfortunately, microscopy volumes tend to contain many background voxels, which also misguide the smoothness constraint. Thus, we need better partitioning of the volume to improve optical flow. First, we generate a foreground/background mask (<ref type="figure" target="#fig_2">Fig. 3B</ref>) to ignore voxels containing no information in the volume. This mask can be as simple as an intensity threshold or any other existing background detection method. Aside from removing non-informative voxels, the mask also helps speed up convergence, as it reduces the number of motion vectors v p we need to estimate. Data sparsity is problematic and advantageous at the same time, as it precludes the imposition of standard smoothing constraints but it allows a reduction in the size of the problem in the flow calculation. Once we have a set of foreground voxels, we want to apply the intuition from Xu et al. (2008) that region-based optical flow helps in textureless areas. Unfortunately, segmentation techniques tend to be computational costly in large 3D biomedical volumes, and color information is often not available. The connected components of foreground regions contain multiple cells (<ref type="figure" target="#fig_2">Fig. 3B</ref>), so we cannot use them directly for segmentation. Moreover, cellular structures change shape in a non-rigid manner from one time point to another. Thus, it is not advisable to segment full objects into a single region. Otherwise, the motion model would be too complex. We take advantage of recent advances by<ref type="bibr" target="#b1">Achanta et al. (2012)</ref>to generate fast super-voxels based on intensity and geometric distance in the volume. Simple linear iterative clustering (SLIC) super-voxels segment each nucleus into a small number of regions while usually respecting the boundaries between different objects (<ref type="figure" target="#fig_2">Fig. 3C</ref>). Thus, we can expect that all voxels within a super-voxel should have similar motion. Results in<ref type="figure">Table 3</ref>show that super-voxels outperform fixed-size rectangular regions similar to Lucas and Kanade (1981), as rectangles can sometimes lie in the middle of two objects with different dynamics and degrade performance. The super-voxels form a partition of the elements in the volume foreground. The final step needed to model the volume is to connect neighboring super-voxels to capture common dynamics between regions. We will define an edge between two super-voxels if their centers of mass are below a distance threshold d max. This definition forms an MRF (or equivalently a partition graph) over the foreground voxels (<ref type="figure" target="#fig_2">Fig. 3D</ref>), where we can directly impose smoothness constraints to calculate optical flow. This setup is necessary because often two regions with coherent dynamics are completely disconnected by background voxels, so traditional voxel-based regularizations are not as effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimization model</head><p>Most approaches in optical flow use the brightness constancy assumption</p><formula>8p 9v p s:t: I t p ¼ I tþ1 pþvp with p, v p 2 R N ð1Þ</formula><p>to pose optical flow as the following optimization problem:</p><formula>argmin v1, ..., vjPj X p2P D I t p À I tþ1 pþvp þ l X p2P X q2NðpÞ w p, q C v p À v q À Á ð2Þ</formula><p>where P is the set of voxels in the volume, NðpÞ are adjacent neighboring voxels in the volume (using 2N or 3 N À 1 connectivity) and D and C are robust cost functions such as Huber penalty, L 1 , TV or Lorentzian (<ref type="bibr" target="#b4">Black and Anandan, 1996</ref>). The first sum term in Equation (2) with D can be considered a unary potential or data term, in which we want to match the intensity between two volumes. In this context, robust metrics are important to allow fluctuations in the volume intensity. However, this term by itself does not offer enough constraints for the motion field v p. Thus, the second term in Equation (2), referred to as the pairwise potentials or smoothness term, is incorporated to regularize the solution. Here, robust metrics are important to allow for discontinuities in the flow field between different objects in the scene (<ref type="bibr" target="#b4">Black and Anandan, 1996</ref>). Finally, it is common to adapt the smoothness term at the pixel level by defining a weight w p, q based on edge intensity, effectively reducing the importance of the smoothness constraint in areas of possible motion discontinuities.Robust metrics alone and voxel-wise smooth flow assumptions are not enough to handle the challenges present in microscopy volumes: given the sparsity, the lack of distinct features between objects and the multiple dynamics in a single volume, the energy terms defined in Equation (2) are not strong enough to guide the optimization process to the right minimum, as shown in Section 4. Using Equation (2) as a model and the MRF over super-voxels constructed in Section 3.1, we can define a new optimization problem:</p><formula>argmin v1, ..., vj&lt;j X S2&lt; X p2S D I t p À I tþ1 pþvS þ l X S2&lt; X R2NðSÞ w R, S C v S À v R ð Þ ð 3Þ</formula><p>where &lt; is the set of super-voxels in the graph partition, and we calculate a single translation v S for each region. The modification to the data term helps further regularizing the solution in textureless regions to guide the optimization to the right solution. Moreover, we have reduced the dimensionality of the search by several orders of magnitude (j&lt;j55jPj). In this case, we decided not to use global affine transformation models, as they do not fit the large variability in cell dynamics. In contrast, we determined experimentally that a local affine model was not necessary to capture those dynamics, so we introduced a compromise with a local translational flow field for each super-voxel. Finally, we adapted the concept from Equation (2) of adaptively adjusting the weight w R, S of the smoothness constraint between connected regions in the graph. However, we cannot use edge information because regions may not be adjacent to each other. In our case, we define w R, S as follows:</p><formula>w R, S ¼ exp À0:5 d R, S d max 2 ( ) volðRÞ þ volðSÞ 2 max A2&lt; volðAÞ È É ð4Þ</formula><p>where d R, S is the distance between the center of masses of super-voxels R and S, and volðRÞ is the number of voxels contained in region R. Intuitively, the first term decreases interaction between super-voxels if regions are far apart, and the second term decreases interaction if they do not represent large sets of voxels. Even with this region-based regularization, the data term is still not powerful enough to always return the right solution (<ref type="figure" target="#tab_1">Table 1</ref>), as most of the objects in the volume look very similar (<ref type="figure" target="#fig_0">Fig. 1</ref>). In our case, the term NðSÞ connects entire neighboring regions (not only adjacent voxels), which agrees with the assumption that we have multiple cells with common dynamics in some areas. By connecting non-adjacent super-voxels, the smoothness constraint is imposed much more efficiently over non-connected objects with similar dynamics. Setting the correct value for NðSÞ is crucial to achieve good flow estimations. In our case, the size of NðSÞ is controlled by the parameter d S max , which defines the maximum distance (in voxels) between two region centroids to consider them neighbors or not. Intuitively, we have reduced the complexity of NðSÞ to one parameter per node that controls how global or local we expect object dynamics to be. We can determine an appropriate value for the d max parameter by qualitatively experimenting on different volumes or testing against some ground truth (<ref type="bibr" target="#b35">Sun et al., 2008</ref>). Tables 1 and 2 show that it is possible to find a single value that works well across very different motion regimens. However, if the user has a priori information of cell division locations or group motion, it is straightforward to locally set the appropriate d max for each region to improve accuracy results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Implementation details</head><p>To generate super-voxels, we use the available source code for SLIC super-voxels (<ref type="bibr" target="#b1">Achanta et al., 2012</ref>).<ref type="bibr" target="#b1">Achanta et al. (2012)</ref>is appealing, as we can control the expected size of each super-voxel and its complexity is linear in the number of voxels, making it a reasonable choice for large 3D volumes. Even if the volume consists of grayscale data, the generated super-voxels (<ref type="figure" target="#fig_2">Fig. 3C</ref>) still respect most object boundaries. Since we have a foreground mask, we tested two approaches: (i) first calculate super-voxels over the entire volume and then apply the mask; or (ii) first apply the mask and then calculate super-voxels only in the foreground. Empirically, both approaches provide similar results, so we use the second approach because it is faster. To solve the optimization in Equation (3), we use the Limited memory Broyden, Fletcher, Goldfarb and Shanno quasi-Newton method made available by<ref type="bibr" target="#b8">Byrd et al. (1994)</ref>. In particular, D and C are both defined with the Huber cost function (<ref type="bibr" target="#b14">Huber, 1981</ref>). Even though the Huber cost function has a discontinuous second derivative,<ref type="bibr" target="#b21">Li (1995)</ref>proved that the function is regular enough to converge using quasi-Newton methods. We use five-point finite difference along each dimension as well as tri-linear interpolation to compute derivatives with subvoxel accuracy at any point in the target volume. We filter the raw data with a small Gaussian ( ¼ 1:5) in each direction to smooth the gradient calculations. Finally, as suggested in previous studies, we use a Gaussian pyramid on the volumes to produce a coarse-to-fine solution of the flow. This pyramid not only helps avoiding local minima in the optimization to resolve larger displacements, but also speeds up convergence (<ref type="figure">Table 3</ref>). We also downsample the foreground/background mask and the super-voxels accordingly. All these calculations are performed using a scale parameter along each dimension, as it is common in microscopy volumes to have anisotropic sampling along different axes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We evaluate our approach in scanned light-sheet microscopy datasets. Light-sheet microscopy provides exceptionally high imaging speeds while minimizing the energy load on thebiological specimen, and has thus emerged as an essential tool for life sciences. This combination of capabilities is invaluable for live imaging applications and enables quantitative imaging of cellular dynamics throughout the development of complex organisms such as entire Drosophila and zebrafish embryos (<ref type="figure" target="#fig_0">Fig.  1 and videos</ref>in the Supplementary Material). Light-sheet microscopes often produce terabytes of image data per specimen, which need to be analyzed with efficient computational approaches. We tested our approach in two different biological model systems using previously published datasets of Drosophila (<ref type="bibr" target="#b38">Tomer et al., 2012</ref>) and zebrafish (<ref type="bibr" target="#b17">Keller et al., 2008</ref>). Two videos are included in the Supplementary Material to show the complete results of the optical flow estimation and how it allows analyzing different motion patterns for different groups of cells. Each volume of the Drosophila dataset consists of 602 Â 1386 Â 110 voxels (179 MB in UINT16), and each pair of time points was processed in 3 min with our method (all Central Processing Unit (CPU) running times reported in this article were determined on a workstation with Intel Õ Xeon Õ X5690 CPU with 3.47 GHz clock rate). In total, we processed 50 time points (9 GB of data) following a cell division wave in early development. Each volume of the zebrafish dataset consists of 1064 Â 1034 Â 500 voxels (379 MB in UINT16), and each pair of time points was processed in 9 min with our method. In total, we processed 220 time points (83 GB of image data) to follow epiboly and the formation of the body axis. Additional evaluation of the proposed and baseline methods using synthetic data is provided in the Supplementary Material. We simulate fluorescent nuclei images with different types of motion (linear, cell division and Brownian), different signal-to-noise ratios, different cell densities and different photobleaching settings to show that our method is applicable to different types of fluorescence microscopy techniques and cell dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline and ground truth</head><p>We compare our results with two common implementations of optical flow for 3D biomedical volumes available in the ITK (<ref type="bibr" target="#b16">Ibanez et al., 2003</ref><ref type="bibr" target="#b23">). Lombardot et al. (2008</ref>discussed these implementations in the context of time-lapse light microscopy for organism development at single-cell resolution. In particular, we use the multi-scale ITK-demon optical flow, which implements a multi-scale version of Thirion's demon algorithm (<ref type="bibr" target="#b37">Thirion, 1998</ref>), as our first baseline. The algorithm has complexity OðjPjÞ, where jPj is the number of voxels in the volume, and solves Equation (2) with C ðrÞ ¼ D ðrÞ ¼ r 2. The second baseline is a modification of the ITK-demon algorithm using regularization of the second derivative of the flow instead of the first order, which has been shown to provide better convergence properties for certain types of volumes (<ref type="bibr" target="#b10">Fischer and Modersitzki, 2004</ref>). This algorithm has complexity OðjPjlogjPjÞ, and we will refer to it as ITK-curvature throughout the text. Both implementations are written in Cþþ using multi-threaded and multi-scale techniques for efficient handling of large biomedical datasets. To quantitatively assess performance, we manually segmented nuclei in two different regions of adjacent time points in theEach entry in the table is equivalent to a data point in the plots from<ref type="figure" target="#fig_3">Figure 5B</ref>. EE X% ile indicates the X th percentile of the list of EE errors for all nuclei in the ground truth annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>377</head><p>Optical flow for time-lapse microscopy</p><p>Drosophila dataset using the software package Imaris (Bitflow). Each region represents different dynamic regimens (<ref type="figure">Fig. 4</ref>). We then manually assigned correspondences between segmented nuclei to calculate the displacement (<ref type="figure">Fig. 4</ref>). Given that the nuclei are textureless, we cannot assign unique voxel-to-voxel correspondences, and thus, our ground truth evaluates center of mass displacement for each nucleus. We use the flow EE metric</p><formula>EEðpÞ ¼ ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi X N n¼1 v GT p À v Ã p 2 v u u t ð5Þ</formula><p>defined by Otte and Nagel (1994) to measure accuracy. Here p is the center of mass for a given nucleus, v GT p is the ground truth flow at centroid p and v Ã p is the estimated flow for each individual algorithm. v Ã p is estimated as the mean flow of all voxels contained within the segmentation mask for each nucleus in the ground truth. Because a nucleus is usually split in several super-voxels, this estimation can be seen as a weighted average of the calculated optical flow for each super-voxel proportional to its size. Section 1.1 in the Supplementary Material contains statistics on the accuracy of the ground truth v GT p. Once we have EEðpÞ for all nuclei, we can compute different statistics to compare accuracy of different methods.<ref type="figure" target="#fig_3">Figure 5</ref>displays the full cumulative distribution of errors, while Tables 1, 2 and 3 display different figures of merit, summarizing the information in the cumulative distribution. In particular, we show several percentiles of the EEðpÞ distribution and the area under the curve (AUC). This last figure of merit is typically used in computer vision applications with precision-recall curves, as it summarizes the entire distribution in a single number. We normalize the maximum AUC to 1 to simplify the comparison. volume, whereas both ITK algorithms require $30 min for the same task. One of the main reasons for the speed improvement is the dimensionality reduction achieved with super-voxels. As an example, in this particular stack, there were 1 117 920 foreground voxels, which resulted in 19 274 super-voxels, reducing the size of the optimization problem $60-fold.<ref type="figure" target="#fig_3">Figure 5B</ref>shows a very different scenario from the same stack: in this part of the embryo, nuclei are synchronously dividing, and the motion field transitions very rapidly from smooth to non-smooth. In total, we performed a ground truth annotation for 309 cells with an average diameter of 10 voxels between time points 38 and 39. In this case, our method has an average EE (normalized by nuclei diameter) of 0.16, and the best ITK method has an average EE of 0.32.<ref type="figure">Figure 4A</ref>and<ref type="figure" target="#tab_2">Table 2</ref>also show that $1% of the nuclei are assigned to the wrong location using our method (Supplementary<ref type="figure" target="#fig_0">Fig. S1</ref>shows an enlarged view of the location exhibiting the largest error). This error is due to the fact that neighboring nuclei divide synchronously and two daughters from different mother cells collide, causing the MRF to pull one of them to the wrong location. This region of the volume pushes the limits of optical flow, as touching neighboring objects do not have a coherent motion and suffer displacements larger than the object size. Tables 1 and 2 show the stability of parameter NðSÞ in Equation (3). The accuracy results change gradually with the value of d max , and this allows us to use the same value for all regions and still outperform other approaches. The only exception is 1% of the nuclei in the first test region, which need an increase in the smoothness constraint to be guided to the correct location, especially at the edges of the MRF (<ref type="figure">Fig. 4A</ref>). In our case, we used d max ¼ 25 voxels for both the Drosophila and zebrafish dataset, which is slightly more than the expected nearest neighbor distance between adjacent nuclei (23 isotropic voxels). This result indicates that, in general, superior results are obtained by directly considering motion information between neighboring cells in the smoothness term, which cannot be achieved with the usual pixel-wise regularization approaches. However,<ref type="figure" target="#tab_2">Table 2</ref>also shows that in extreme cases of incoherent motion, such as during cell division, we could benefit from reducing d max to 10 voxels. In this particular case, a cell division detector (<ref type="bibr" target="#b15">Huh et al., 2011</ref>) could be used to detect such events and locally adjust the value of d max. Supplementary Tables S1 and S2 in the Supplementary Material present a more detailed analysis by decomposing the accuracy results in<ref type="figure" target="#tab_2">Table 2</ref>between dividing and non-dividing nuclei. An extended accuracy analysis using synthetic data is provided in the Supplementary Material, which further supports the conclusions of this section.<ref type="figure">Table 3</ref>shows that all elements introduced in Sections 3 and Section 3.3 are necessary to obtain the best accuracy and performance. In particular, a region-based (SLIC super-voxels in our case) and a multi-scale approach (of at least two levels) are critical to define an appropriate data term and to avoid local minima in Equation (3), respectively. Moreover, the use of super-voxels that adapt to the sparse signal instead of fixed-size rectangular-like regions [as suggested by<ref type="bibr" target="#b12">Glocker et al. (2008)]</ref>improves accuracy as long as the super-voxels have a minimum size. As the table entry using watershed shows, any oversegmentation method producing reasonable super-voxels adapted to the sparse data could be used within this framework. All results discussed in this section were obtained with fixed parameters. For our method, we use l ¼ 800, three levels in the pyramid and d max ¼ 25. For Huber penalty, we use D ¼ 40, which indicates intensity values are well preserved between frames, and C ¼ 3. Finally, for the SLIC super-voxels, we use STEP ¼ 5 and m ¼ 10<ref type="bibr">[see Achanta et al. (2012) for details]</ref>. For both ITK implementations, we performed an optimal parameter search using the ground truth to obtain the best performance. Additionally, we use three pyramid levels for their multi-scale scheme and applied the foreground mask filter for a fair comparison. Finally, we tested ITK algorithms on the raw stacks and on cubic interpolated stacks to generate isotropic sampled voxels to confirm that anisotropy in the data along the z-axis was not compromising performance. The final results (data not shown) were undistinguishable, so we performed all comparisons with the anisotropic data because execution time was shorter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>We developed and tested a new model for optical flow tailored to microscopy volumes, in which a large fraction of the objects are textureless and similar in appearance. Moreover, the information in the volume tends to be sparse because many voxels do not contain any information and cellular dynamics can be very variable. A key idea in our approach is to generate a volume partition graph over the foreground voxels, and to perform optical flow directly on that model instead of computing it at the voxel level. This model is tailored to the specific characteristics of time-lapse light microscopy datasets, as it provides the regularization needed to solve optical flow robustly for these types of volumes. At the same time, our method reduces the complexity of the problem by an order of magnitude, which is an invaluable advantage when working with large 3D datasets. In Section 4.1, we showed that the method might fail in some extreme cases for $1% of the nuclei, when neighboring nuclei move in opposite directions. In those scenarios, we are left only with the data term to determine the correct flow. Thus, a possible future direction would be to use different features or point descriptors in the volume intensity to increase robustness of the data term (<ref type="bibr" target="#b5">Brox and Malik, 2011;</ref><ref type="bibr" target="#b22">Liu et al., 2008</ref>). It is also possible to constrain the flow field to a diffeomorphism, as two objects cannot originate from the same source point. Finally, if a faster implementation is required, it is straightforward to parallelize the computation of the data term in Equation (3) for each super-voxel using GPU technology. At the moment, this operation takes $40% of the time for each function evaluation in the quasi-Newton method, and it is thus a primary candidate for code optimization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. (A) Rendering of 3D volume obtained with SiMView light-sheet microscopy (Tomer et al., 2012). Each of the objects represents a single cell nucleus marked by a fluorescent reporter in a Drosophila embryo. Dimensions are 602 Â 1386 Â 110 voxels per volume (0.4 Â 0.4 Â 2.0 mm 3 voxel size). The embryo is $550 mm long and 200 mm in diameter. (B) Optical slices of the volume visualized in (A). (C) Enlarged view of two superimposed consecutive time points. Multiple motions, such as cell divisions and cell migration, occur in the same volume</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.2.</head><figDesc>Fig. 2. Block diagram representing the pipeline described in this article to estimate optical flow. Optical flow is performed over a set of super-voxels in the volume foreground, and the smoothness constraints are imposed between neighboring (and possibly non-adjacent) super-voxels instead of between connected voxels. This approach guides the registration process of neighboring nuclei with similar dynamics to a better solution than previous approaches</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Step for constructing an MRF over the super-voxels on the volume foreground to partition the volume and perform robust optical flow. (A) 2D slice of raw data from Figure 1. We show only a slice to simplify the visualization, but the method is implemented in 3D. (B) Outline of the foreground mask obtained with a trained classifier in Ilastik (Sommer et al., 2011). Some connected components correspond to multiple nuclei. (C) Slice of 3D SLIC (Achanta et al., 2012) super-voxels calculated over the foreground. Super-voxels respect object boundaries of nuclei in the same foreground connected component. (D) Edges added between neighboring super-voxels to generate an MRF. Each node V i represents a super-voxel in panel C. This is the final volume partition model where we perform optical flow. We impose the smoothness conditions over entire super-voxels instead of voxelwise</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.5.</head><figDesc>Fig. 5. Optical flow results for light-sheet microscopy using different methods. See text for details on ground truth definition. X-axis represents the EE for each nucleus centroid normalized by the equivalent diameter of each nucleus. As a rule of thumb, values 5 0.5 are considered good for most quantitative applications, whereas values 4 1.0 are not good. Values between 0.5 and 1.0 are acceptable, but flow tracking has a higher error rate. Method labeled as 'None' represents the original displacement without flow estimation. Panel A shows results on data from Figure 4A and B. Panel B shows results on data from Figure 4D and E. Our method improves accuracy over all baselines in both scenarios, on average, by 23%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>Table 3.</figDesc><table>Resulting accuracy when not using some of the modeling and 
implementation techniques explained in Sections 3 and 3.3, for the test 
region with cell divisions (Fig. 4C) 

Method 
EE 
EE 
EE 
EE 
AUC Time (s) 
90%ile 95%ile 99%ile 100%ile 

None 
0.70 
0.93 
1.03 
1.35 
0.80 0 
Default 
0.47 
0.56 
0.84 
1.20 
0.92 185 
Pyramid levels ¼ 2 0.46 
0.57 
1.03 
1.11 
0.92 178 
Pyramid level ¼ 1 0.70 
1.01 
1.37 
1.61 
0.88 320 
L 2 
0.51 
0.62 
0.89 
1.21 
0.91 181 
Voxel-based 
0.94 
1.05 
1.39 
1.45 
0.81 1754 
SLIC step ¼ 3 
0.85 
0.98 
1.31 
1.19 
0.84 191 
SLIC step ¼ 7 
0.49 
0.61 
1.11 
1.76 
0.92 169 
Grid step ¼ 3 
0.93 
1.04 
1.29 
1.41 
0.83 170 
Grid step ¼ 5 
0.84 
0.97 
1.34 
1.42 
0.86 161 
Grid step ¼ 7 
0.69 
0.78 
1.31 
1.51 
0.88 153 
Watershed 
0.45 
0.55 
0.85 
1.40 
0.92 174 

The most significant improvement is obtained by moving from a voxel-based regis-
tration to a super-voxel–based registration. However, all elements described in this 
article improve optical flow accuracy. The default method refers to our method with 
the parameters defined in Section 4.2. Section 1.3 in the Supplementary Material 
contains a full description of implementation decisions involved in the deactivation 
of algorithmic modules for each row in this table. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 1.</figDesc><table>Stability and importance of parameter d max to improve accur-
acy, for the test region without cell divisions 

Method 
EE 
EE 
EE 
EE 
AUC 
90%ile 
95%ile 
99%ile 
100%ile 

None 
0.79 
0.89 
1.01 
2.19 
0.77 
Our, d max ¼ 10 
0.13 
0.34 
1.86 
2.27 
0.93 
d max ¼ 25 
0.12 
0.15 
0.39 
1.51 
0.98 
d max ¼ 40 
0.13 
0.16 
0.34 
0.48 
0.97 
ITK-demon 
0.19 
0.29 
0.45 
0.58 
0.97 
ITK-curvature 
0.41 
0.55 
0.83 
1.34 
0.89 

Each entry in the table is equivalent to a data point in the plots from Figure 5A. EE 
X% ile indicates the X th percentile of the list of EE errors for all nuclei in the ground 
truth annotation. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2.</figDesc><table>Stability and importance of parameter d max to improve accu-
racy, for the test region with cell divisions 

Method 
EE 
EE 
EE 
EE 
AUC 
90%ile 
95%ile 
99%ile 
100%ile 

None 
0.93 
1.03 
1.35 
1.47 
0.76 
Our, d max ¼ 10 
0.40 
0.51 
0.76 
1.23 
0.93 
d max ¼ 25 
0.47 
0.56 
0.84 
1.20 
0.92 
d max ¼ 40 
0.48 
0.58 
0.78 
1.08 
0.92 
ITK-demon 
0.86 
0.98 
1.28 
1.39 
0.84 
ITK-curvature 
0.81 
0.91 
1.28 
1.58 
0.82 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="4">.2 Results in light-sheet microscopy data For the purpose of a quantitative performance analysis, we selected two regions from two consecutive time points in the Drosophila dataset and performed a ground truth annotation for both of them. Figure 5A shows comparative results for the first test region between time points 39 and 40. This region comprises 214 cells with an average diameter of 11 voxels moving all in the same direction, although at different speeds. In this example, the motion between cells is coherent, and thus, smoothness constraints are sufficient in most voxels to compensate for lack of texture. In this case of simple dynamics, our method has an average EE of 0.07, whereas the best ITK method has an average EE (normalized by nuclei diameter) of 0.10. However, tested on the same hardware, our implementation is consistently 10 Â faster. In particular, it takes 3 min to converge for each 3D Fig. 4. (A) Motion field (black: ground truth, red: estimate by our approach) projected on the X–Y plane for a subregion of the volume in Figure 1 with smooth flow. Each arrow corresponds to a nucleus centroid. (B) Same as (A) for motion field estimated by the baseline method multi-scale ITK-demon (blue). (C) Enlarged subregion of (A) and (B). (D) Same as (A) for a subregion where cells are dividing, which translates into non-smooth dynamics for neighboring nuclei. Our approach is still able to predict the correct motion for 99% of the nuclei. Supplementary Movie S1 shows the raw data and the output of our optical flow algorithm side by side for the entire time series. (E) Same as (B) for the subregion presented in (D). The complex dynamics complicate setting a global motion smoothing parameter that works for all nuclei at the same time. (F) Enlarged subregion of (D) and (E). Most of the ITK flow (blue) results as zero because it cannot adapt to the complex motion pattern 378 F.Amat et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="379"> Optical flow for time-lapse microscopy at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="380"> F.Amat et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We would like to thank Kristin Branson for many helpful discussions and comments on the manuscript and the members of the Myers and Keller labs for helpful feedback, in particular Raju Tomer for the Drosophila dataset.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Computation and visualization of three-dimensional soft tissue motion in the orbit</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">D</forename>
				<surname>Abramoff</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Viergever</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="296" to="304" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Achanta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Occlusion detection and motion estimation with convex optimization</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ayvaci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS&apos;10</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A database and evaluation methodology for optical flow</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Baker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">131</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">The robust estimation of multiple motions: parametric and piecewise-smooth flow fields</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Black</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Anandan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="75" to="104" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Large displacement optical flow: descriptor matching in variational motion estimation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Brox</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Malik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="500" to="513" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Lucas/Kanade meets Horn/Schunck: combining local and global optic flow methods</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bruhn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comupt. Vis</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="211" to="231" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Mapping the spatiotemporal dynamics of calcium signaling in cellular neural networks using optical flow</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Buibas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2520" to="2531" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">A limited memory algorithm for bound constrained optimization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">H</forename>
				<surname>Byrd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Sci. Comput</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1190" to="1208" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Performance of optical flow techniques for motion analysis of fluorescent point signals in confocal microscopy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Delpiano</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Vis. Appl</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="675" to="689" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A unified approach to fast image registration and a new curvature based registration technique</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Fischer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Modersitzki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linear Algebra Appl</title>
		<imprint>
			<biblScope unit="volume">380</biblScope>
			<biblScope unit="page" from="107" to="124" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Guiding optical flow estimation using superpixels</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Gkamas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Nikou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Digital Signal Processing</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Dense image registration through MRFs and efficient linear programming</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Glocker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="731" to="741" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">K P</forename>
				<surname>Horn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">G</forename>
				<surname>Schunck</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aritifical Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="185" to="203" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<monogr>
		<title level="m" type="main">Robust Statistics</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Huber</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>1st. edn</note>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Automated mitosis detection of stem cell populations in Phase-Contrast microscopy images</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Huh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="586" to="596" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The ITK Software Guide: The Insight Segmentation and Registration Toolkit</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Ibanez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kitware Inc</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Reconstruction of zebrafish early embryonic development by scanned light sheet microscopy</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Keller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="page" from="1065" to="1069" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Detection of deformable objects in 3D images using Markov-Chain monte carlo and spherical harmonics</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Khairy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName>
				<surname>Springer-Verlag</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">/</forename>
				<surname>Berlin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Heidelberg</surname>
			</persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1075" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">3D cell nuclei segmentation based on gradient flow tracking</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Cell Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Numerical estimates for the huber M-Estimator problem</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Approximation Theory</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<monogr>
		<title level="m" type="main">SIFT flow: dense correspondence across different scenes</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Liu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="28" to="36" />
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Evaluation of four 3d non rigid registration methods applied to early zebrafish development sequences</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Lombardot</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIAAB MICCAI</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Deltr: digital embryo lineage tree reconstructor</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Lou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro</title>
		<meeting><address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1557" to="1560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">An iterative image registration technique with an application to stereo vision</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">D</forename>
				<surname>Lucas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kanade</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers</publisher>
			<date type="published" when="1981" />
			<biblScope unit="page" from="674" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic analyses of drosophila gastrulation provide insights into collective cell migration</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mcmahon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="page" from="1546" to="1550" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<monogr>
		<title level="m" type="main">Optical flow estimation: advances and comparisons</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Otte</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Nagel</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="51" to="60" />
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards dense motion estimation in light and electron microscopy</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Pizarro</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ISBI. Institute of Electrical and Electronics Engineers</title>
		<imprint>
			<biblScope unit="page" from="1939" to="1942" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">A duality based algorithm for TV-L1-optical-flow image registration</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Pock</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MICCAI</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="511" to="518" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Pt. . 2</note>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Software for bead-based registration of selective plane illumination microscopy data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Preibisch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="418" to="419" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">MRF modeling for optical flow computation from multi-structure objects</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Prinet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP. pp</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1093" to="1096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Estimating the motion of plant root cells from in vivo confocal laser scanning microscopy images</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Roberts</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Vis. Appl</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="921" to="939" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Wavelet-based image fusion in multi-view three-dimensional microscopy</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L</forename>
				<surname>Rubio-Guivernau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="238" to="245" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Ilastik: interactive learning and segmentation toolkit</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sommer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISBI. pp</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="230" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning optical flow</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Sun</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b36">
	<analytic>
		<title level="a" type="main">Secrets of optical flow estimation and their principles</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Sun</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. pp</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2432" to="2439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b37">
	<analytic>
		<title level="a" type="main">Image matching as a diffusion process: an analogy with maxwell&apos;s demons. Med</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Thirion</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Anal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="243" to="260" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b38">
	<analytic>
		<title level="a" type="main">Quantitative high-speed imaging of entire developing embryos with simultaneous multiview light-sheet microscopy</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Tomer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="755" to="763" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b39">
	<analytic>
		<title level="a" type="main">Anisotropic Huber-L1 optical flow</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Werlberger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b40">
	<monogr>
		<title level="m" type="main">A segmentation based variational model for accurate optical flow estimation</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Xu</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="671" to="684" />
			<pubPlace>Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>