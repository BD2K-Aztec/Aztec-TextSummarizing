
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis The human genome contracts again</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Dmitri</forename>
								<forename type="middle">S</forename>
								<surname>Pavlichin</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Tsachy</forename>
								<surname>Weissman</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Golan</forename>
								<surname>Yona</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Alfonso</forename>
								<surname>Valencia</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis The human genome contracts again</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">17</biblScope>
							<biblScope unit="page" from="2199" to="2202"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt362</idno>
					<note type="submission">Received on November 29, 2012; revised on May 30, 2013; accepted on June 18, 2013</note>
					<note>Associate Editor: Availability: Code is available at sourceforge.net/projects/genomezip/ Contact: golan.yona@stanford.edu Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The number of human genomes that have been sequenced completely for different individuals has increased rapidly in recent years. Storing and transferring complete genomes between computers for the purpose of applying various applications and analysis tools will soon become a major hurdle, hindering the analysis phase. Therefore, there is a growing need to compress these data efficiently. Here, we describe a technique to compress human genomes based on entropy coding, using a reference genome and known Single Nucleotide Polymorphisms (SNPs). Furthermore, we explore several intrinsic features of genomes and information in other genomic databases to further improve the compression attained. Using these methods , we compress James Watson&apos;s genome to 2.5 megabytes (MB), improving on recent work by 37%. Similar compression is obtained for most genomes available from the 1000 Genomes Project. Our biologically inspired techniques promise even greater gains for genomes of lower organisms and for human genomes as more genomic data become available.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With the constant advances in sequencing technologies, genome sequencing has become faster and more affordable. Although the main effort thus far has been to sequence the genomes of different organisms, the focus is gradually shifting toward sequencing different instances of the same genome (i.e. different individuals) to study the variations underlying phenotypic differences between individuals and to identify the variations that are associated with diseases and disorders. Consequently, the number of complete human genomes that have been sequenced is increasing rapidly. As the amount of and demand for genomic data grow, the cost of storage and transmission of these data is fast becoming a bottleneck for research and future medical applications. Thus, there is a growing need for compression algorithms suited to genomic data. Genome compression has been the subject of multiple studies in the past several years (see Supplementary Material for an overview of these related studies). The most successful methods are those that use reference genomes and code just the differences between the input genome and a reference genome (which, for humans, account for 50.2% of the genome's length). The best single-reference compression was reported in<ref type="bibr" target="#b1">Christley et al. (2009)</ref>, who compressed James Watson's genome to 4 MB by utilizing dbSNP (<ref type="bibr" target="#b5">Sherry et al., 2001</ref>) to represent more efficiently known SNPs in the difference map. In this work, we report further improvements to this scheme, which result in a significant reduction of 37% in the size of the compressed genome, for only 2.5 MB. Our work is motivated by two observations. First, entropy-coding techniques can be nearly optimal in exploiting known patterns in a dataset but have not been fully optimized on human genome data. Second, in finding patterns to exploit, a wealth of biological insight remains untapped. Our improved scheme is the result of incorporating multiple sources of information on the presence of haplotypes, tag SNPs, coding and non-coding regions and other biologically motivated modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>James Watson's genome is available (<ref type="bibr" target="#b7">Wheeler et al., 2008</ref>) as a difference map from the reference genome hg18 from the UCSC Genome Browser (<ref type="bibr" target="#b3">Kent et al., 2002</ref>). The difference map consists of three parts: (i) 3 321 840 SNPs, (ii) 156 556 deletions and (iii) 63 607 insertions. Our overall compression scheme is similar to that of<ref type="bibr" target="#b1">Christley et al. (2009)</ref>. The differences lie in the way we use the statistical properties of each type of variation, and the use of other sources of information. For consistency with the starting point in<ref type="bibr" target="#b1">Christley et al. (2009)</ref>, we first parse the input into an 84 MB ASCII file that removes text fields redundant with the reference genome. The next steps exploit data-specific distributions to reduce the number of bits needed to code each type of variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SNPs</head><p>The majority of the differences between Watson's genome and the reference genome are the SNPs, and the bulk of the final file size (76%) is devoted to storing the SNPs positions. For each SNP, we need to specify the position in the genome and the nucleotide value of the polymorphism. Most of the SNPs ($2.7 million, or 82% of all SNPs) in Watson's genome were already documented in version 129 of dbSNP [For the purpose of fair comparison with<ref type="bibr" target="#b1">Christley et al. (2009)</ref>, we used throughout this article (unless indicated otherwise) the same version of dbSNP used in that study, which is version 129]. The remaining 0.62 million SNPs are novel with respect to that version. Representing SNPs that appear in dbSNP can be done more efficiently, as explained in section 2.1.3.consecutive SNPs is sufficient to recover their absolute positions in the genome. Unlike<ref type="bibr" target="#b1">Christley et al. (2009)</ref>, we encode the distances by constructing an entropy code for the empirical SNP-to-SNP distance distribution. This distribution can be approximated with a mix of two power-law distributions (<ref type="figure" target="#fig_3">Fig. 1</ref>). The functional form of the double power-law distribution that we fit is (up to normalization):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Novel</head><formula>pðdÞ $ d þ d=d 0 ð Þ ð1Þ</formula><p>Where d is the distance in base pairs (bp) between consecutive SNPs, the parameters and give the slope to the left and right of the kink, d 0 is the position in bp of the kink, and controls the curvature of the function near the kink (for 550, 50). Thus, we need to store only the four numerical coefficients of the functional form, saving the need to store a ($0.15 MB) code table. Having a functional form further permits us to impute distance frequencies for other human genomes. For more details see Supplementary Material.[Starting from version 132, multiple subsets (tracks) of SNPs were made available through the UCSC Genome Browser, including the following:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Novel</head><p>(i) all SNPs and (ii) common SNPs (SNPs that appear in at least 1% of the population). Before version 132, dbSNP was available as a single set of (all)<ref type="bibr">SNPs]</ref>. Track 129 for hg18 from the UCSC table browser contains $9.6M SNPs, 2.7M of which appear in Watson's genome. Instead of using a vector representation of dbSNP indicating which SNPs exist in Watson's genome (as in<ref type="bibr" target="#b1">Christley et al., 2009</ref>), we use again the SNP-to-SNP distance distribution to encode known SNPs. The distances between the indices of Watson's SNPs in dbSNP are distributed approximately as the double power law in Equation (1), but with different parameters (see Section 2.4 of the Supplementary Material). We use an entropy code for this distribution to compress the list of Watson's SNPs in dbSNP by 22%. It should be noted that dbSNP contains also common deletions and insertions; however, there were few matches with Watson's genome to yield a benefit in compression; therefore, we ignored non-SNP dbSNP entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deletions and insertions</head><p>2.2.1 Deletions and insertions positions [space used: 370 KB, 14% of final file size]. Instead of encoding the positions separately, we merge the 157K deletion and 64K insertion positions with the SNP positions to generate a single distance distribution, resulting in shorter distances between consecutive changes (and therefore smaller code words). The combined distribution follows a double power-law distribution, as in Equation (1), from which we derive an entropy code for the distances. We use an arithmetic code to encode a list that labels each change as an SNP, a deletion or an insertion.quences. We construct a Huffman code for the insertion lengths, incurring a cost of 2.9 bits per insertion on average. To encode the inserted sequences, we concatenate them into one sequence. The distribution of nucleotide values in the set of insertion sequences is not uniform, with A and T occurring roughly twice as often as G and C. We use an arithmetic code for this distribution to compress the concatenated insertion sequence by 5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Deletion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Biologically motivated improvements</head><p>We exploit several observations about genomes to further improve the compression:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Conditioning on haplotype</head><p>Adjacent SNPs often co-occur in blocks called haplotypes. In most cases, a block can be uniquely characterized using a subset of the SNPs in the haplotype, called tag SNPs, with all the other SNPs determined from the tag SNPs values. Therefore, we can achieve compression of the set of non-novel SNPs (those already in dbSNP) by storing only the tag SNPs for each haplotype, sufficient to identify an individual's genome's haplotypes. If the tag SNPs do not perfectly predict the remaining SNPs (which may happen if the genome's haplotypes differ from those SNPs recorded in dbSNP), then we must store a (compressible) list of wrong predictions. As long as the tag SNPs have any predictive power at all, this will result in a smaller file than storing a list with one entry per SNP in dbSNP. In The International HapMap<ref type="bibr" target="#b6">Consortium et al. (2007)</ref>, it is estimated that 300 000 to 600 000 tag SNPs are sufficient to predict most of the 9.6M common SNPs in dbSNP. Thus, using tag SNPs potentially reduces the file size of non-novel SNPs by more than a factor of 10 and the file size for the entirety of Watson's genome by about a third. However, information on tag SNPs is sparse. In this study, we use the Illumina Bead Array HumanMap300k dataset, containing about 300K tag SNPs (<ref type="bibr" target="#b4">Pe'er et al., 2006</ref>). This dataset includes only 2.46M of the 9.6M SNPs in dbSNP. Only 1.56M of Watson's SNPs are associated with a tag SNP in the Illumina set (of which 88% are consistent with the predicted SNPs). This yields only $46 KB in savings, but is expected to improve once more data on haplotypes become available, and for genomes more consistent with the predicted SNPs. For details, see Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Conditioning on coding versus non-coding regions We use</head><p>the UCSC genes track for hg18 from the UCSC table browser and findare ¼ À0:25, ¼ À3:2, d 0 ¼ 780 and ¼ À2:7 that a nucleotide in an exon is $74% as likely to be an SNP as a nucleotide outside an exon. We can achieve some compression by constructing separate entropy codes for the positions of SNPs inside and outside exons. Given that exons make up $2.5% of the human genome, this amounts to only $0.01% savings in bits per SNP, but the savings would be larger for genomes that have more equal fractions of coding and non-coding elements, such as some bacterial genomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Conditioning</head><p>on context in sequence We observe that the probability of a nucleotide being an SNP depends on the local sequence that includes the nucleotide (the context). In the most extreme example, the sequence CGC (and complement) is the most SNP-prone, 12 times as likely to contain an SNP in the middle nucleotide compared with AAA (and complement), the least SNP-prone. This is consistent with the observed correlation of the chromatin structure with the composition of the DNA sequence. It has been shown that the chromatin is mostly open in GC-rich regions (<ref type="bibr" target="#b2">Dekker, 2007</ref>), suggesting that mutations are more likely in such regions. The context-based method yields $0.33 bits per SNP in savings (or $30 KB, 3% of the space devoted to storing novel SNPs). We find that conditioning on subsequences of length 5 maximizes savings after accounting for the overhead of storing a frequency table for each subsequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We applied our compression tool to each of the 1092 human genomes available from the 1000 Genomes Project (1000 Genomes<ref type="bibr">Project Consortium. et al., 2012</ref>), as of October 2012. The results are presented in<ref type="figure">Figure 2</ref>, showing the uncompressed file sizes (converted to the same uncompressed format as Watson's genome), and the compression ratios, labeled by population. These results confirm that the success of the algorithm in compressing genomes is not unique to Watson's genome. However, we notice a significant variation by population in both the uncompressed file size and the compression ratio achieved by our approach. Further analysis is required to understand the functional significance of the underlying differences. It should be noted that the 1000 Genomes Project provides allele-specific information on variations, while the publicly available difference map for Watson's genome combines the variations into a single list, without specifying which allele(s) they occur at. Therefore, we modified our algorithm to account for diploids, by introducing a vector indicating homo/heterozygosity (and which allele, in case of heterozygosity). This is done by using two bits per variation, which can take the value 11 (homozygosity, both alleles have the variation), 01 or 10. Coding the allele indicator vector takes $500 KB per genome, using a Huffman code for a Markov chain fit to the indicator vector (described in greater detail in the Supplementary Material). Another difference between the 1000 genomes and Watson's genome is that the 1000 Genomes Project lists indels in addition to SNPs, deletions and insertions. The number of indels per genome is small (on average, there are only 179 indels out of $3.8M variations per genome in the 1000 genomes data), and we represent each as a pair of an insertion and a deletion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>SNP positions [space used: 1.0 MB, or 41% of the final file size]. Instead of encoding the absolute position of an SNP (which can be a large number, comparable to the length of a chromosome), we use an approach similar to Christley et al. (2009) and encode the relative distance from the last SNP. Storing the distances between *To whom correspondence should be addressed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>SNP values [space used: 100 kilobytes (KB), 4% of final file size]. The nucleotide values of SNPs conditioned on the nucleotide values in the reference sequence are not uniformly distributed. We use an arithmetic code for this conditional distribution to compress the list of novel SNP values by 16%. 2.1.3 SNPs in dbSNP [space used: 920 KB, 35% of final file size]. We use the set of all SNPs from the NCBI dbSNP database</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>lengths [space used: 66 KB, 3% of final file size]. We construct a Huffman code for the deletion lengths, incurring a cost of 3.6 bits per deletion on average. 2.2.3 Insertion sequences [space used: 87 KB, 3% of final file size]. We separately encode the insertion lengths and the inserted se</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.1.</head><figDesc>Fig. 1. The empirical SNP-to-SNP distance distribution for James Watson's 3.3M SNPs follows a double power-law distribution as in Equation (1). Circles denote the empirical distribution, and the solid line corresponds to the fit used in constructing our entropy code. Dashed lines indicate limiting behavior of the fit to the left and right of the kink. Approximate parameter values in the notation of Equation (1) are ¼ À0:25, ¼ À3:2, d 0 ¼ 780 and ¼ À2:7</figDesc></figure>

			<note place="foot">ß The Author 2013. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">D.S.Pavlichin et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="4"> DISCUSSION We have applied several entropy-coding techniques to compress the difference map between James Watson&apos;s genome and a reference genome. Compared with the software of Christley et al. (2009), our software uses about twice as much time and memory (for details see Supplementary Material). However, it reduces the final file size to 2.5 MB, a new lower bound by 37% over previous work. Even better results were obtained when the analysis was repeated with a more recent version of dbSNP (version 130, which included more of Watson&apos;s SNPs), with the final file size dropping from 2.54 MB to 1.96 MB, or 23% improvement overall. (More recent versions of dbSNP use assembly hg19 of the human genome, whereas Watson&apos;s genome was given with reference to hg18. Therefore, we could not test Watson&apos;s genome with more recent versions of dbSNP.) Our tests on all genomes from the 1000 Genomes Project are consistent with these results and trends, with newer versions of dbSNP improving the compression ratio, as expected. Our approach requires the use of a reference genome and dbSNP, but the cost of storing these databases is amortized for other human genomes. We have implemented several biologically motivated techniques that offer a path to future savings in compressing human and non-human genomes. Our scheme becomes more efficient, as the external databases it uses are updated to include newly observed variations and tag SNPs, effectively letting us exploit a growing standardized collection of reference genomes.</note>

			<note place="foot">The human genome contracts again at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Genomes are sorted by the population they belong to (see population codes below) Because the 1000 genomes&apos; SNPs have been submitted to dbSNP starting with version 132, we compare the compression results for two versions of dbSNP: version 131, which is the latest before any of the new SNPs were recorded, and version 137 (common SNPs), which is the latest at the time of writing, and yields better compression results than version 137 (all SNPs) We also include results for Watson&apos;s genome on the same plot as a rough reference, although Watson&apos;s genome was compressed with respect to a different reference genome (hg18) and version of dbSNP (129) than the 1000 genomes data. Population codes (from http://www.1000genomes.org/about): ASW: African Ancestry in Southwest US, CEPH: Utah residents with Northern and Western European ancestry (CEU), CHB: Han Chinese in Beijing An integrated map of genetic variation from 1,092 human genomes</title>
	</analytic>
	<monogr>
		<title level="m">Fig. 2. Compression results for the 1000 Genomes Project. For each of the 1092 genomes, we plot the uncompressed size: Finnish from Finland, GBR: British from England and Scotland, IBS: Iberian populations in Spain, JPT: Japanese in Toyko: Puerto Rican in Puerto Rico, TSI: Toscani in Italy, TRI: Yoruba in Ibadan, Nigeria REFERENCES 1000 Genomes Project Consortium et</title>
		<meeting><address><addrLine>China, CHS ; Colombia, FIN ; Japan, LWK ; Webuye, Kenya, MXL ; Los Angeles, CA, PUR</addrLine></address></meeting>
		<imprint>
			<publisher>Han Chinese South Mexican Ancestry in</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="56" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Human genomes as email attachments</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Christley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="274" to="275" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">GC-and AT-rich chromatin domains differ in conformation and histone modification status and are differentially modulated by Rpd3p</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dekker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">116</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">The human genome browser at UCSC</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Kent</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="996" to="1006" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating and improving power in whole-genome association studies using fixed marker sets</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Pe &apos;er</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="663" to="667" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">dbSNP: the NCBI database of genetic variation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">T</forename>
				<surname>Sherry</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acid Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="308" to="311" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A second generation human haplotype map of over 3.1 million SNPs</title>
		<author>
			<persName>
				<forename type="first">The</forename>
				<surname>International</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Hapmap</forename>
				<surname>Consortium</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">449</biblScope>
			<biblScope unit="page" from="851" to="861" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">The complete genome of an individual by massively parallel DNA sequencing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Wheeler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">452</biblScope>
			<biblScope unit="page" from="872" to="876" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>