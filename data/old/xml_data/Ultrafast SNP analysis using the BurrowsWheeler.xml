
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ultrafast SNP analysis using the Burrows–Wheeler transform of short-read data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Kouichi</forename>
								<surname>Kimura</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Biosystems Research Department</orgName>
								<orgName type="laboratory">Central Research Laboratory</orgName>
								<orgName type="institution">Hitachi, Ltd</orgName>
								<address>
									<addrLine>1-280 Higashi-Koigakubo</addrLine>
									<postCode>185-8601</postCode>
									<settlement>Kokubunji</settlement>
									<region>Tokyo</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Asako</forename>
								<surname>Koike</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Biosystems Research Department</orgName>
								<orgName type="laboratory">Central Research Laboratory</orgName>
								<orgName type="institution">Hitachi, Ltd</orgName>
								<address>
									<addrLine>1-280 Higashi-Koigakubo</addrLine>
									<postCode>185-8601</postCode>
									<settlement>Kokubunji</settlement>
									<region>Tokyo</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ultrafast SNP analysis using the Burrows–Wheeler transform of short-read data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btv024</idno>
					<note type="submission">Received on September 11, 2014; revised on December 24, 2014; accepted on January 12, 2015</note>
					<note>Sequence analysis *To whom correspondence should be addressed. Associate Editor: John Hancock Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Sequence-variation analysis is conventionally performed on mapping results that are highly redundant and occasionally contain undesirable heuristic biases. A straightforward approach to single-nucleotide polymorphism (SNP) analysis, using the Burrows–Wheeler transform (BWT) of short-read data, is proposed. Results: The BWT makes it possible to simultaneously process collections of read fragments of the same sequences; accordingly, SNPs were found from the BWT much faster than from the mapping results. It took only a few minutes to find SNPs from the BWT (with a supplementary data, fragment depth of coverage [FDC]) using a desktop workstation in the case of human exome or transcrip-tome sequencing data and 20 min using a dual-CPU server in the case of human genome sequenc-ing data. The SNPs found with the proposed method almost agreed with those found by a time-consuming state-of-the-art tool, except for the cases in which the use of fragments of reads led to sensitivity loss or sequencing depth was not sufficient. These exceptions were predictable in advance on the basis of minimum length for uniqueness (MLU) and FDC defined on the reference genome. Moreover, BWT and FDC were computed in less time than it took to get the mapping results , provided that the data were large enough. Availability and implementation: A proof-of-concept binary code for a Linux platform is available on request to the corresponding</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since the advent of so-called next-generation DNA sequencers (NGSs), which rapidly and cost-effectively generate billions of short reads, large-scale analysis of sequence data of a few-hundred giga base pairs (Gbp), requiring a large computational resources, is not uncommon anymore. The first step to extract biologically meaningful information from sequence data often involves analysis of the variation (mutation) of that data in comparison with a reference genome sequence data. Billions of short reads are first mapped onto the reference genome, and unambiguous and recurrent mismatches between the short reads and the reference genome are identified as candidate mutations (<ref type="bibr" target="#b3">DePristo et al., 2011</ref>). This line of approach is hereafter referred to as the mapping-based approach. Although it is the most appreciated and most commonly used approach, it has the following basic weak points. (i) The computation of mapping is highly redundant because of large sequencing depth (typically ranging from 30Â to 100Â). (ii) Some mutations can be lost by mapping tools because such tools use certain heuristics of their own to resolve mapping ambiguities. (iii) It is not easy to switch from one reference genome to another after the computation of mapping has been completed. To address these weak points, an alternative solution, the dictionary-based approach, is proposed. The short-read data are converted into a dictionary of reads, so that numbers of occurrences of any sequence in the short-read data are immediately obtained. Then,mutations can be inferred on the basis of these numbers by means of querying genomic subsequences with and without the mutations (<ref type="figure" target="#fig_4">Fig. 1</ref>). The dictionary can be implemented efficiently by means of the Burrows–Wheeler transform (BWT) (<ref type="bibr" target="#b1">Burrows and Wheeler, 1994</ref>) [a.k.a. FM index (<ref type="bibr" target="#b4">Ferragina and Manzini, 2000)</ref>] because it is simple and particularly suitable for DNA sequences. Although the proposed approach appears to be too naı¨venaı¨ve, it has the following potential advantages. (i) Redundancy due to deep sequencing coverage is efficiently managed by the dictionary of reads. (ii) The dictionary of reads does not suffer information loss or heuristic bias because it is essentially constructed by means of sorting the data in alphabetical order. (iii) It is easy to switch from one reference genome to another one after the dictionary of reads is constructed. However, the following issues of the proposed approach remain to be addressed. 1. The construction of BWT for large data (more than 100 Gbp) is very time-consuming even with the fastest known algorithm, BCRext (<ref type="bibr" target="#b0">Bauer et al., 2011;</ref><ref type="bibr" target="#b2">Cox et al., 2012</ref>). 2. A large number of occurrences in the short-read data of a genomic subsequence with a candidate mutation do not necessarily imply the existence of the mutation because some of them might be derived from different genomic regions with similar subsequences. 3. To get useful information from the dictionary of reads, it is necessary to prepare effective queries that are likely to contain candidate mutations. Namely, it is necessary to locate genomic positions with a significant chance of finding mutations.</p><p>To address these issues, the following algorithm and concepts are introduced in this study. 1. BWT/WT, a modified and parallelized BCRext algorithm for computing the BWT of reads. 2. The minimum length for uniqueness (MLU), a simple criteria for evaluating the uniqueness of the subsequence. 3. The fragment depth of coverage (FDC), an estimate of sequencing depth of coverage on the basis of exact matching of read fragments at single-base resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dictionary-based approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notations</head><p>For any DNA sequence, A ¼ a 0 a 1 Á Á Á a LÀ1 ; A½i; j denotes the subsequence a i a iþ1 Á Á Á a j for 0 i j &lt; L, and A denotes the reverse complement. Let C 0 ; C 1 ;. .. ; C IÀ1 be the DNA sequences of chromosomes (or contigs) in the reference genome, where I is the number of them.</p><formula>Let G þ ¼ C 0 $C 1 $ Á Á Á C IÀ1 $ and G À ¼ C IÀ1 $ Á Á Á $C 1 $C 0 $ denote</formula><p>the concatenations on the positive and negative strand in mutually reverse order, where $ denotes a sentinel (punctuation) symbol. The whole-genome sequence on both strands is represented by</p><formula>G Ã ¼ G þ G À ,</formula><p>and the BWT, denoted by TðG Ã Þ, is used as the dictionary of the reference genome, where the alphabetical order $ &lt; A &lt; C &lt; G &lt; T &lt; N is assumed and $ does not to match any other symbols, including itself. Let L be the total length of the genome on a single strand including the sentinels; namely, L ¼ j G þ j ¼ j G À j. For a genomic coordinate, 0 x &lt; L, the reference base at x on the positive (negative) strand is given by G Ã ½x (G Ã ½x), where x ¼ 2L À 1 À x. Similarly, a genomic subsequence on the positive (negative) strand of length equal to ' with the left (right) end at x is given by G þ ðx; 'Þ ¼ G Ã ½x; x þ ' À 1 (G À ðx; 'Þ ¼ G Ã ½x; x þ ' À 1). Let r 1 ; r 2 ;. .. ; r J be the DNA sequences of the short reads, and R ¼ r 1 $r 2 $ Á Á Á $r J $ be the concatenation, where J denotes the number of reads. The BWT of R, denoted by TðRÞ, is used as the dictionary of the reads. For any DNA sequence, w, the number of occurrences of w in the reference genome and that in the short-read data, denoted by N G Ã ðwÞ and N R ðwÞ, are immediately computed from TðG Ã Þ and TðRÞ, respectively, by using rank functions (<ref type="bibr">Gonzá lez et al., 2005</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MLU</head><p>The MLU at x in the positive (negative) direction, denoted by k þ ðxÞ (k À ðxÞ), is defined as the minimum length of the subsequence with the left (right) end at x, such that the subsequence appears only once in both strands of the genome. Namely, k 6 ðxÞ ¼ min f' j N G Ã ðG 6 ðx; 'ÞÞ ¼ 1g:</p><formula>(1)</formula><p>MLU is closely related to the suffix array (SA) and the longest common prefix (LCP) array (<ref type="bibr" target="#b13">Manber and Myers, 1990</ref>) and is thereby computed efficiently (see Section 3). MLU varies with position on the genome and mostly takes a moderate value, except in the case of repetitive or duplicated regions. For example, MLU is 40 or less (more than 100) in 88.2% (3.9%) of the reference human genome, hg19, excluding long runs of N with more than 500 Kbp.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">FDC</head><p>When a genomic subsequence with the left end at x is taken as a query, namely, w ¼ G þ ðx; 'Þ, the number of occurrences of w in short-read data, N R ðwÞ, reflects the sequencing depth at x, provided that the length ' is properly chosen. If ' is less than k þ ðxÞ, the number is clearly overestimated because some of the occurrences come from different positions. If ' is equal to k þ ðxÞ, the number is expected to be a proper estimation of the sequencing depth because of the uniqueness condition. However, it is in fact prone to be affected by occasional contributions from reads [with sequencing errors or single-nucleotide polymorphisms (SNPs)] derived from different genomic regions with similar sequences. Therefore, ' somewhat larger than MLU should be taken. On the other hand, if ' is too large, the number is underestimated because of the finite read length. The FDC at x in the positive (negative) direction, denoted by d þ ðxÞ (d À ðxÞ), is defined as the number of occurrences of w in the short-read data when the length is chosen, such that ' ¼ k þ ðxÞ þ a (' ¼ k À ðxÞ þ a) for a small positive constant, a. Namely, d 6 ðxÞ ¼ N R ðGðx; ' 6 ðxÞÞÞ; ' 6 ðxÞ ¼ k 6 ðxÞ þ a:</p><formula>(2)</formula><p>As is clear from the above definitions, FDC has single-base resolution and is sensitive to direction (<ref type="figure">Fig. 2a</ref>). For example, FDCs in<ref type="figure" target="#fig_4">1</ref>. Basic concept of dictionary-based SNP analysis. Given a SNP candidate on the genome, appropriate genomic subsequences with and without the SNP, namely, q1 and q0, are chosen as queries. The numbers of occurrences of the queries in short read-data, n1 and n0, are immediately obtained from the dictionary of short reads. The candidate is evaluated on the basis of n1 and n0 as follows. (a) If both n0 and n1 are sufficiently large and almost equal, the candidate is likely to be a heterozygous SNP. (b) If n0 is sufficiently small, and n 1 is sufficiently large, the candidate is likely to be a homozygous SNP. (c) Conversely, if n0 is sufficiently large, and n1 is sufficiently small, the candidate is likely to be false both directions suddenly drop in the vicinity of a SNP in a characteristic pattern (<ref type="figure">Fig. 2b</ref>). Although FDC is an approximation of sequencing depths, it is progressively underestimated as MLU increases because of the finite read length. In particular, when MLU is greater than the read length, FDC is zero and useless. Otherwise, on the assumption that the sequencing errors are randomly distributed according to a Poisson distribution with an average frequency of r E per base, the underestimation factor is given by ð1 À ' 6 ðxÞ=' R Þe ÀrE' 6 ðxÞ , where ' R denotes read length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Overall scheme</head><p>The reference genome sequence and the short-read data are separately transformed into dictionaries (BWTs). The MLU is computed from the dictionary of the reference genome sequence alone. The FDC is computed from the dictionary of the short-read data and the MLU. These precomputations are necessary for genetic-variation analysis downstream (<ref type="figure" target="#fig_2">Fig. 3a</ref>). In contrast, as for the conventional mapping-based approach, the reference genome sequence is formatted into a convenient form, which is sometimes implemented by means of BWT (<ref type="bibr" target="#b11">Li and Durbin, 2009</ref>). The short reads are mapped onto the reference genome using the formatted data, and the results are sorted and indexed according to the positions on the genome (<ref type="bibr" target="#b11">Li et al., 2009</ref>). These precomputations are necessary for downstream analysis (<ref type="figure" target="#fig_2">Fig. 3b</ref>). In contrast to the mapping-based approach (by which reads are treated individually), the dictionary-based approach is expected to be efficient in the downstream-analysis phase because collections of read fragments with the same sequences can be processed simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Calculation of BWTs</head><p>Contigs separated by long runs of N (500 Kbp or more), C 1 ; C 2 ;. .. ; C I , are extracted from the reference genome sequence, and the concatenated genome sequence (on both strands), G Ã , is obtained. In the case of the reference human genome, hg19, I ¼ 47 contigs and G Ã of length 2L ' 5:75 Â 10 9 are thus obtained. The BWT and SA of G Ã are calculated using the induced-sorting algorithm (<ref type="bibr" target="#b14">Nong et al., 2011</ref>). The SA-IS code presented in<ref type="bibr" target="#b14">Nong et al. (2011)</ref>is modified, so that it can treat data larger than 4 Gbp and cope with multiple occurrences of sentinels. Large short-read data of more than 100 Gbp is beyond the scope of the induced-sorting algorithm. The BWT of short reads is incrementally calculated from smaller partial BWTs in a cache-oblivious manner, which basically follows the BCRext algorithm (<ref type="bibr" target="#b0">Bauer et al., 2011;</ref><ref type="bibr" target="#b2">Cox et al., 2012</ref>). The kth partial BWT is defined as the BWT of k-suffixes of reads, where the k-suffix is a suffix of length k (if the read length is larger than k) or the entire read otherwise. Both of the partial BWTs and the remaining prefix data are compactly encoded into wavelet trees (<ref type="bibr" target="#b6">Grossi et al., 2003</ref>), resulting in a memory requirement of about 0:6N GB for data of N Gbp. The incremental calculations are executed in parallel according to the first bases of the suffixes, thus accelerating the calculation three to four times. The modified BCRext algorithm is hereafter referred to as 'BWT/WT'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Calculation of MLU</head><p>The SA of both strands of the reference genome,is sorted alphabetically (<ref type="bibr" target="#b13">Manber and Myers, 1990</ref>). The LCP array of the genome,</p><formula>LCP G Ã ¼ ðLCP G Ã ½0; LCP G Ã ½1;. .. ; LCP G Ã ½2L À 1Þ (4)</formula><p>is an array of integers, where LCP G Ã ½i is the length of the LCP of suffixes G Ã ½j; 2L with j ¼ SA G Ã ½i and j ¼ SA G Ã ½i À 1 (<ref type="bibr" target="#b13">Manber and Myers, 1990</ref>). The LCP can be efficiently calculated from the SA and its relatives (for 0 x &lt; L, where SA À1 G Ã denotes the inverse suffix array, i.e. the inverse permutation of the SA. All of the values of the MLU are compactly encoded into a bit array as follows. Since G Ã ðx þ 1; k þ ðx þ 1ÞÞ occurs exactly once in both strands of the genome, its leftward one-base extension, G Ã ðx; k þ ðx þ 1Þ þ 1Þ, occurs at most once in both strands. This fact implies that k þ ðxÞ k þ ðx þ 1Þ þ 1 ð0 x &lt; LÞ;</p><formula>(7)</formula><p>and hence 2x þ k þ ðxÞ is strictly increasing with x. Similarly, k À ðxÞ k À ðx À 1Þ þ 1 ð0 x &lt; LÞ;</p><formula>(8)</formula><p>Fig. 2. FDC has base-level resolution and is sensitive to direction. (a) The FDCs at x in the positive and negative directions, d þ ðx Þ and d À ðx Þ, are defined as the number of occurrences in the short-read data of genomic fragments on the positive and negative strands starting at x with length ' þ ðx Þ and ' À ðx Þ, which are chosen to be larger than MLU: ' 6 ðx Þ ¼ k 6 ðx Þ þ a for a small positive constant a. (b) The FDC in the positive (negative) direction drops at a SNP position and in its left (right) vicinity because of the difference between the reference genome and short reads at the SNP position. The widths of drops are determined by the MLU and a. The depths of drops are halved when the SNP is heterozygousUltrafast SNP analysisand hence 2x þ k À ðxÞ is strictly decreasing with x. On the basis of these implications, the MLU values are compactly encoded into bit array M of length 4L as follows:</p><p>M½y ¼ 1 ðy ¼ 2x þ k þ ðxÞ for some 0 x &lt; LÞ; 1 ðy ¼ 2x þ k À ðxÞ for some 0 x &lt; LÞ; 0 ðotherwiseÞ:</p><formula>8 &gt; &gt; &lt; &gt; &gt; :</formula><formula>(9)</formula><p>Conversely, they are immediately decoded from M as follows:for 0 x &lt; L, where select M ðxÞ (i.e., the select function on M) gives the index of the xth occurrence of a set bit ('1') in M (Gonzá lez et al., 2005). The select function is efficiently calculated using the hierarchical binary strings (HBS) (<ref type="bibr" target="#b9">Kimura et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Calculation of FDC</head><p>The SA of the short reads (only in the direct strand),</p><formula>SA R ¼ ðSA R ½0; SA R ½1;. .. ; SA R ½N À 1Þ; (11)</formula><p>is a permutation of 0; 1;. .. ; N À 1, such that the sequence of suffixes, ðR½SA R ½i; N À 1Þ i¼0;1; .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.. ;NÀ1 ;</head><p>is sorted alphabetically, where N is the total length of the short-read data including sentinels, namely, N ¼ j R j. For any DNA sequence, w, a collection of all occurrences of w in the short-read data is represented by the SA interval of w (<ref type="bibr" target="#b11">Li and Durbin, 2009</ref>), ½I R ðwÞ; I R ðwÞ, which is defined by I R ðwÞ ¼ minf0 i &lt; N j w is a prefix of R½SA R ½i; N À 1g; (12)</p><p>I R ðwÞ ¼ maxf0 i &lt; N j w is a prefix of R½SA R ½i; N À 1g: (13)</p><p>The initial value for the empty sequence (w ¼ e) is given by ½IðeÞ; IðeÞ ¼ ½0; N À 1. It is then recursively calculated as follows.</p><p>I R ðawÞ ¼ CðaÞ þ rank TðRÞ ða; I R ðwÞ À 1Þ;</p><formula>(14) I R ðawÞ ¼ CðaÞ þ rank TðRÞ ða; I R ðwÞ þ 1Þ (15)</formula><p>for a ¼ A; C; G; T and N, where CðaÞ is the number of bases in R that are lexicographically smaller than a, and rank TðRÞ ða; iÞ is the number of occurrences of a in TðRÞ½0; i À 1. The rank function is efficiently computed using the HBS. Then, FDCs are given by the lengths of the SA intervals as follows:</p><formula>d 6 ðxÞ ¼ I R ðG 6 ðx; ' 6 ðxÞÞÞ À I R ðG 6 ðx; ' 6 ðxÞÞÞ þ 1; (16)</formula><p>for 0 x &lt; L. Therefore, FDCs are calculated using Equations (14–16). Moreover, the calculation is accelerated according to an idea similar to (<ref type="bibr">Kä rkkä inen et al., 2009</ref>). It is common for adjacent positions, x and x61, to have the subsequences, G 6 ðx; 'Þ and G 6 ðx61; 'Þ, in Equation (1), such that they have the same end position, namely x6k 6 ðxÞ ¼ x616k 6 ðx61Þ. Then, d 6 ðx61Þ is reducible in the sense that it is immediately given by<ref type="bibr">Equation (16)</ref>with the known values of I R and I R that are obtained during the calculation of d 6 ðxÞ using Equations (14–16).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Search for SNP candidates</head><p>Two methods for searching for SNP candidates, namely the dropscan method and the step-scan method, are proposed in the following. As for the drop-scan method, SNPs are searched for only around significant drops in the precomputed FDC (since they are unlikely to be found elsewhere). As for the step-scan method, the whole genome is exhaustively scanned by a sliding window of a fixed size, and reads with exactly matching subsequences around the window on either side are collected, and their extensions into the window are examined to find any SNPs therein. The latter method does not require the precomputed FDC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Drop-scan method</head><p>A simple criterion for genomic coordinate x to be a significant leftward (rightward) drop in the positive (negative) direction is</p><formula>d þ ðxÞ &lt; ð1 À rÞd þ ðx þ 1Þ d À ðxÞ &lt; ð1 À rÞd þ ðx À 1Þ (17)</formula><p>where 0 &lt; r &lt; 1 is a small constant, referred to as drop ratio. However, random fluctuations of the FDC may sometimes satisfy the criteria; besides, reads that are derived from different homologous genomic regions and altered by SNPs or sequencing errors may affect the criteria. The criteria are therefore made more stringent by the additional following procedures (<ref type="figure">Fig. 4</ref>). 1. Take s ¼ G 6 ðx61; ' 6 ðx61ÞÞ, a seed (of a sufficient length) adjacent on the right (left) of x, and collect all of its occurrences in the forward (reverse) reads. 2. Collect all possible leftward (rightward) extensions beyond x in a sufficient length, ' Ç ðx Ç 1Þ þ 1. 3. Align the extensions with the reference genome using a fast dynamic programming (DP) algorithm (<ref type="bibr" target="#b10">Kimura et al., 2012</ref>). 4. Select valid extensions that have at most n e mismatches or small indels (insertions or deletions), where n e is a positive constant integer. 5. Find any mismatches or small indels that are repeatedly observed in the alignments of the valid extensions in at least n m cases and with a relative frequency of at least r, where n m is a positive constant integer. 6. Filter out any mismatches or small indels that are not found consistently from both strands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Step-scan method</head><p>SNP candidates are located by using a sliding window of fixed length W along the genome in the following steps (<ref type="figure">Fig. 5</ref>).<ref type="figure">4</ref>. Drop-scan method. A leftward drop of the FDC at x in the positive direction, such that d þ ðx Þ &lt; ð1 À rÞd þ ðx þ 1Þ is located by scanning the whole genome, where 0 &lt; r &lt; 1 is the drop ratio. For such x, a seed is taken as a genomic subsequence on the positive strand started at x þ 1 and with length equal to ' þ ðx þ 1Þ. The occurrences of the seed in the short read-data and all possible leftward extensions are collected by using the dictionary of short reads. The extensions (including x and beyond) are aligned with the reference genome sequence, and repeatedly observed mismatches or small indels are extracted. Likewise, rightward drops of the FDC in the negative direction are considered. The mismatches and indels consistently extracted from both directions are then obtained as SNP candidates 1. Take a window of length W with the left end at x ¼ kW=2 for k ¼ 0; 1; 2;. .. ; b2L=Wc. 2. Take s ¼ G þ ðx þ W; ' þ ðx þ WÞÞ (s ¼ G À ðx À 1; ' À ðx À 1Þ), a seed (of a sufficient length) adjacent on the right (left) side of the window and collect all occurrences of s in the forward (reverse) reads. 3. Collect all possible leftward (rightward) extensions into the window. 4. Align the extensions with the reference genome using a fast DP algorithm. 5. Select valid extensions that have at most n e mismatches or small indels. 6. Find any mismatches or small indels that are repeatedly observed in the alignments of the valid extensions in at least n m cases and with a relative frequency of at least r. 7. Filter out any mismatches or small indels that are not found consistently from both strands.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head><p>The dictionary-based methods were implemented in Cþþ and Perl for proof-of-concept experiments. The test data included actual biological data downloaded from public websites and simulation data (<ref type="figure" target="#tab_1">Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Precomputation time</head><p>The BWT and MLU of both strands of the reference human genome sequence (hg19) were calculated once, and the calculation results were stored and reused. The total computation time was 2 h and 16 min by a single core of an Intel Xeon CPU (X7560, 2.3 GHz); and the maximum memory usage was 71.3 GB. The precomputation for short-read data was performed in parallel; 10 threads were used for the exome and transcriptome sequencing data, and 24 threads were used for the wholegenome sequencing data. In the case of transcriptome and genome sequencing data, the computation time was much shorter than that required by the conventional mapping-based method (<ref type="figure" target="#tab_2">Table 2</ref>). Although the computation time of BWT/WT was almost linear in relation to the data size, the computation time of FDC was mostly dominated by the length of the reference genome and was not much affected by the data size owing to the nature of the dictionary. Thus, the precomputation time for the smaller data size was largely occupied by the latter time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Example of FDC plots</head><p>Although FDC plots, as illustrated in<ref type="figure">Figure 2b</ref>, are informative and meaningful, they are usually degraded by noises induced by randomly matched sequences. However, as parameter a increases, the noise reduces rapidly, while the signal degrades slowly. Thus, a ¼ 3 was chosen tentatively so as to make the plots clear and sensitive. In the case of the exome data, the signals were apparently localized around captured regions and clearly dropped at SNPs. An example of actual biological data (E1) is shown in<ref type="figure">Figure 6</ref>. Similarly, in the case of transcriptome data, the signals were apparently localized inside exons; besides, considerable amounts of signals and noises, seemingly to reflect complex alternative splicing and other miscellaneous transcriptional activities, were also observed. In the case of theActual biological data were downloaded from the NCBI Sequence Read Archive. They were paired-ended reads of human samples obtained by Illumina Genome Analyzer II, IIx and HiSeq 2000. The simulation data were generated from the human reference genome sequence (hg19) around NCBI RefSeq coding exons with randomly introduced homozygous and heterozygous SNPs (0.1%) and sequencing errors (1%), each of which consists of single-base substitutions (98%), insertions (1%) and deletions (1%); the insertion lengths of the paired reads were assumed to be distributed normally with 300-bp mean and 20-bp standard deviation.<ref type="figure">Fig. 5</ref>. Step-scan method. The whole-genome region is scanned by a sliding window of length W at every W =2 bp position. Two adjacent seeds on the right and left sides, starting, respectively, at x þ W and x À 1, are taken on the positive and negative strand. Their lengths are, respectively, equal to ' þ ðx þ W Þ and ' À ðx À 1Þ. The occurrences of the right-hand (left-hand) seed in the short-read data and all possible leftward (rightward) extensions into the window are collected by using the dictionary of short reads. The extensions are aligned with the reference genome sequence, and consistent mismatches or small indels are extracted as SNP candidates<ref type="bibr" target="#b11">Li and Durbin, 2009</ref>) was used for the exome and genome data, and TopHat 2.0.7 (<ref type="bibr" target="#b8">Kim et al., 2013</ref>) was used for the transcriptome data; conversion into BAM files, sorting, and merging was done by SAMtools 0.1.19 (<ref type="bibr" target="#b11">Li et al., 2009</ref>). A Linux workstation with a single CPU (Intel Core i7-4930 K, 3.4 GHz) and 64-GB memory was used with 10 threads in parallel for the exome and transcriptome data; and a Linux server with double CPUs (Intel Xeon X7560, 2.3 GHz) and 256-GB memory was used with 24 threads in parallel for the genome data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ultrafast SNP analysis</head><p>whole-genome data, copy-number variations and loss of heterogeneity were also observed as expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Search for SNP candidates</head><p>Parameters n e ¼ 8; n m ¼ 2; r ¼ 0:2 and W ¼ 40 were chosen experimentally using simulation data (S1), so as to trade-off computation time and sensitivity. The sensitivities of finding homozygous and heterozygous single-base substitutions were 94.3% and 93.6% by the drop-scan method and 94.5% and 94.3% by the step-scan method. They were slightly smaller than 95.8% and 95.4% attained by a conventional mapping-based method, GATK (<ref type="bibr" target="#b3">DePristo et al., 2011</ref>). The primary reason for slightly lower sensitivity of the two proposed methods is thought to be the fact that the methods do not use full lengths of reads (with paired-end information); instead, they only use fragments of reads. It is expected that the sensitivity is prone to decrease as MLU increases. In fact, the sensitivity of the drop-scan method for the simulated exome data was 99.2% when MLU was at most 40 (93.3% of the cases), while it decreased to 26.9% when MLU was &gt;40 (6.7% of the cases). Times for searching for SNPs in the whole human genome by different methods are compared in<ref type="figure" target="#tab_3">Table 3</ref>. As expected, the drop-scan method is much faster than the step-scan method, and the latter is much faster than the conventional mapping-based method. The agreement of the results given by the proposed and conventional methods is assessed as follows. It is known that GATK is one of the most-sensitive mapping-based tools and that the ratio of agreement of results given by different tools is not generally high (<ref type="bibr" target="#b15">Pabinger et al., 2014</ref>). Therefore, the result given by the proposed method (the drop-scan method) and that given by GATK confidently (after Q-filtering, where the quality value was not &lt;300) in less repetitive (with M-filtering, where the MLU was at most 40 bp) and deeply covered (with D-filtering, where FDCs around the drops were at least 10) regions were compared (<ref type="figure" target="#tab_4">Table 4</ref>). As indicated by the relative sensitivity and specificity of the proposed method on the assumption that the results given by GATK were correct, high ratios of agreement were obtained.Precomputed FDC was used for the drop-scan method but not for the stepscan method. GenomeAnalysisTK 2.1-8 (<ref type="bibr" target="#b3">DePristo et al., 2011</ref>) and Picard tools 1.77 (http://picard.sourceforge.net/) were used. Each data were computed in parallel with the same number of threads by the same computer as for Table 2.<ref type="figure">Fig. 6</ref>. MLU and FDC plots in a captured region of exome sequencing data (E1). The MLUs on the positive and negative strand, k þ ðx Þ and k À ðx Þ, along the right-hand ordinate (in length), and the FDCs on the positive and negative strand, d þ ðx Þ and d À ðx Þ, along the left-hand ordinate (in count), are plotted against the relative coordinate in a genomic region (chr17:3 100 001-3 102 500 in hg19). The SNP candidates, located at sharp drops of FDCs, are indicated by downward arrowsNumbers indicate the number of SNP candidates (only for single-base substitutions) found by each method and those filtered under specified conditions. Q-filter removed those with a quality value &lt;300; M-filter removed those with MLU &gt; 40 and D-filter removed those with FDC around the drops &lt;10. The mappingbased results were obtained by GATK 2.1-8, and the dictionary-based results were obtained by the drop-scan method. The Q-filtering eliminates the SNP candidates to which GATK does not give high confidence. The M-filtering eliminates those in regions where the drop-scan method is known to be insensitive. The ratios of the numbers in the third and fourth columns are given in the fifth column; they are larger in the exome and transcriptome data than in the genome data (see text). The D-filtering eliminates those in regions where the sequencing coverage is not deep enough. a Final results given by the dictionary-based method. b Final results given by the mapping-based method, tentatively assumed to be correct. (TP: true positives, FP: false positives). The M-filtering eliminates the SNP candidates in regions where the dictionary-based methods are known to be insensitive. The reduction ratios (in the fifth column in<ref type="figure" target="#tab_4">Table 4</ref>) are generally larger for the exome and transcriptome data and smaller in the genome data in comparison to 88.2%, which is the proportion of genomic regions where MLU is 40 or less. This result seems to be reasonable because the former data mostly consist of reads from gene regions where MLU generally takes smaller values and because the latter data also contain many reads from repetitive regions where MLU is very large and mutation rate (including SNPs) is relatively high. Thus, the ratio of useful SNPs that are predicted to be undetectable by the drop-scan method is estimated to be around 10%. Similar results to those given in<ref type="figure" target="#tab_4">Table 4</ref>were also obtained by the step-scan method (Supplementary Information, Supplementary<ref type="figure" target="#tab_1">Table S1</ref>). The step-scan method generally gives higher relative accuracy than the drop-scan method for exome and genome sequencing data but not for transcriptome data. The primary reason for this lower accuracy in the latter case is thought to be the fact that the sliding windows often cross the exon boundaries, making it impossible to start effective searches from either side of the windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and future works</head><p>In contrast to the conventional mapping-based approach, a dictionary-based approach to sequence analysis is proposed. It is expected to be efficient because the dictionary (BWT) of short-read data makes it possible to simultaneously process collections of read fragments with the same sequences. In particular, SNPs were found from the dictionary much faster than from the mapping results. It was experimentally shown that it took only a few minutes to find SNPs from the BWT and FDC using a desktop workstation in the case of human exome or transcriptome sequencing data and 20 min using a double-CPU server in the case of human genome sequencing data. However, the use of read fragments (instead of full-lengths of reads with paired-end information) sometimes leads to sensitivity loss. Such cases are predictable in advance on the basis of MLU and are estimated to generally occupy about 10% of the cases; therefore, the proposed approach should be taken only in the majority of other cases. The SNPs obtained by the proposed methods mostly agreed with those obtained by a time-consuming state-of-the-art tool, except for the cases in which loss of sensitivity was predicted in advance on the basis of MLU or sequencing depth was estimated to be low on the basis of FDC. The dictionary of short-read data was computed in less time than it took to map them onto a reference genome and to sort the mapping results along the genome, provided that the data was large enough. It was free from heuristic bias or information loss, unlike the mapping results. Since it does not depend on any particular reference genome sequence, the dictionary-based approach will be advantageous when multiple reference sequences are available. Although this study focuses exclusively on SNP analysis, it is clear that the proposed approach is generally applicable to many other kinds of sequence analysis. In particular, straightforward and promising applications include:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.</head><figDesc>Fig. 1. Basic concept of dictionary-based SNP analysis. Given a SNP candidate on the genome, appropriate genomic subsequences with and without the SNP, namely, q1 and q0, are chosen as queries. The numbers of occurrences of the queries in short read-data, n1 and n0, are immediately obtained from the dictionary of short reads. The candidate is evaluated on the basis of n1 and n0 as follows. (a) If both n0 and n1 are sufficiently large and almost equal, the candidate is likely to be a heterozygous SNP. (b) If n0 is sufficiently small, and n 1 is sufficiently large, the candidate is likely to be a homozygous SNP. (c) Conversely, if n0 is sufficiently large, and n1 is sufficiently small, the candidate is likely to be false</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.3.</head><figDesc>Fig. 3. Comparison of the overall schemes. (a) Proposed approach. The reference genome sequence is transformed into the dictionary (BWT), and MLU is calculated. The short-read data are transformed into the dictionary (BWT), and FDC is calculated from the BWT and MLU. The calculation results are used in the genetic-variation analysis downstream. (b) Conventional approach. The reference genome sequence is formatted into a convenient form (sometimes BWT), and the short reads are mapped onto the reference genome. The mapping results are sorted and indexed and used in downstream analysis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.</head><figDesc>Fig. 4. Drop-scan method. A leftward drop of the FDC at x in the positive direction, such that d þ ðx Þ &lt; ð1 À rÞd þ ðx þ 1Þ is located by scanning the whole genome, where 0 &lt; r &lt; 1 is the drop ratio. For such x, a seed is taken as a genomic subsequence on the positive strand started at x þ 1 and with length equal to ' þ ðx þ 1Þ. The occurrences of the seed in the short read-data and all possible leftward extensions are collected by using the dictionary of short reads. The extensions (including x and beyond) are aligned with the reference genome sequence, and repeatedly observed mismatches or small indels are extracted. Likewise, rightward drops of the FDC in the negative direction are considered. The mismatches and indels consistently extracted from both directions are then obtained as SNP candidates</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1.</head><figDesc>Alternative splicing analysis of transcriptome data a. Sensitive detection of different combinations of exon junctions by means of consulting the dictionary of reads. b. Detection of novel alternative exons from FDC plots. 2. Structural variation analysis of genome data a. Sensitive detection of split reads (across break points associated with deletions or translocations) by means of consulting the dictionary of reads. b. Identification of insertions as extensions (by repeatedly performing LF mappings on the dictionary of reads) from partially mapped read fragments. c. Copy number variation analysis on the basis of FDC plots. MLU will be useful to avoid false detections in many of these applications. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><figDesc>V C The Author 2015. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com 1577 Bioinformatics, 31(10), 2015, 1577–1583 doi: 10.1093/bioinformatics/btv024 Advance Access Publication Date: 20 January 2015 Original Paper</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><figDesc>Table 1. Test data for experiments</figDesc><table>Data 
Source 
Type 
Size 
Read length 

S1 
(simulation) 
Exome 
10.0 Gbp 
100 bp 
E1 
SRX043462 
Exome 
6.7 Gbp 
120 bp 
E2 
SRX253902 
Exome 
12.4 Gbp 
100 bp 
E3 
SRX506949 
Exome 
16.8 Gbp 
100 bp 
E4 
SRX097050 
Exome 
22.9 Gbp 
101 bp 
T1 
SRX472980 
Transcriptome 
6.3 Gbp 
100 bp 
T2 
SRX588484 
Transcriptome 
14.3 Gbp 
100 bp 
T3 
SRX105217 
Transcriptome 
20.3 Gbp 
99 bp 
G1 
ERX009609 
Whole genome 
135.3 Gbp 
100 bp 
G2 
ERX069715 
Whole genome 
137.1 Gbp 
100 bp 
G3 
ERX168840 
Whole genome 
163.4 Gbp 
100 bp 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 2. Comparison of precomputation time for short-read data</figDesc><table>Data 
Dictionary-based method 
Mapping 
based method 
BWT/WT 
FDC 
Total 

S1 
31 m 22 s 1 h 06 m 49 s 
1 h 38 m 11 s 
41 m 14 s 
E1 
22 m 50 s 1 h 05 m 53 s 
1 h 28 m 43 s 
51 m 50 s 
E2 
33 m 25 s 1 h 12 m 29 s 
1 h 45 m 54 s 
1 h 57 m 38 s 
E3 
44 m 38 s 1 h 14 m 28 s 
1 h 59 m 06 s 
2 h 02 m 45 s 
E4 
1 h 11 m 37 s 1 h 14 m 22 s 
2 h 25 m 59 s 
2 h 53 m 05 s 
T1 
16 m 24 s 1 h 03 m 45 s 
1 h 20 m 09 s 
4 h 21 m 01 s 
T2 
32 m 30 s 1 h 10 m 50 s 
1 h 43 m 19 s 10 h 32 m 51 s 
T3 
48 m 41 s 1 h 22 m 25 s 
2 h 11 m 07 s 19 h 59 m 55 s 
G1 
11 h 46 m 19 s 1 h 16 m 37 s 13 h 02 m 56 s 32 h 02 m 33 s 
G2 
11 h 58 m 22 s 1 h 14 m 54 s 13 h 13 m 15 s 34 h 07 m 40 s 
G3 
13 h 42 m 13 s 1 h 18 m 16 s 15 h 00 m 29 s 56 h 57 m 17 s 

BWT/WT and FDC were computed as described in the text. As for the 
mapping-based method, BWA 0.7.8 mem (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><figDesc>Table 3. Comparison of times for searching for SNPs</figDesc><table>Data 
Dictionary-based method 
Mapping-based 
method (GATK, Picard) 
Drop-scan 
Step-scan 

S1 
1 m 14 s 
17 m 10 s 
3 h 11 m 08 s 
E1 
1 m 19 s 
15 m 56 s 
1 h 40 m 24 s 
E2 
2 m 18 s 
21 m 30 s 
2 h 31 m 37 s 
E3 
2 m 33 s 
24 m 56 s 
3 h 13 m 19 s 
E4 
6 m 21 s 
25 m 34 s 
12 h 28 m 20 s 
T1 
2 m 23 s 
16 m 22 s 
2 h 46 m 05 s 
T2 
2 m 31 s 
20 m 39 s 
9 h 35 m 13 s 
T3 
9 m 51 s 
32 m 48 s 
2 h 58 m 13 s 
G1 
19 m 41 s 
2 h 23 m 57 s 
39 h 34 m 19 s 
G2 
20 m 05 s 
2 h 24 m 17 s 
41 h 10 m 19 s 
G3 
14 m 24 s 
2 h 13 m 22 s 
44 h 01 m 33 s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 4. Agreement of SNPs found by the drop-scan method and the mapping-based method</figDesc><table>Data Mapping-based 
Dictionary-based 
Relative accuracy of ( a ) assuming that ( b ) is true 

All 
Q-filtered Q/M-filtered (ratio) 
Q/M/D-filtered b All 
D-filtered a TP 
FP 
Sensitivity 
Specificity 

S1 
133 361 
106 148 
100 977 (95.1%) 
79 506 
112 303 
79 186 
79 069 
117 
99.5% 
99.9% 
E1 
237 562 
75 692 
68 727 (90.8%) 
21 885 
67 820 
20 689 
20 457 
232 
93.5% 
98.9% 
E2 
442 788 
156 336 
135 716 (86.8%) 
58 027 
110 219 
51 561 
50 585 
976 
87.2% 
98.1% 
E3 
414 171 
103 431 
96 204 (93.0%) 
41 015 
87 588 
36 925 
36 576 
349 
89.2% 
99.1% 
E4 
222 419 
67 441 
61 609 (91.4%) 
33 053 
85 298 
28 234 
27 708 
526 
83.8% 
98.1% 
T1 
112 071 
26 742 
24 196 (90.5%) 
7891 
54 324 
7894 
7099 
795 
90.0% 
89.9% 
T2 
175 395 
44 654 
39 570 (88.6%) 
18 529 
73 207 
16 829 
15 848 
981 
85.5% 
94.2% 
T3 
579 699 
112 103 
103 636 (92.4%) 
32 402 
275 562 
35 005 
30 547 
4458 
94.3% 
87.3% 
G1 
5 043 802 4 522 189 3 817 262 (84.4%) 
2 869 000 
3 939 619 2 844 998 2 686 923 
158 075 
93.7% 
94.4% 
G2 
5 102 468 4 608 488 3 884 808 (84.3%) 
2 989 489 
3 988 886 2 961 803 2 799 135 
162 668 
93.6% 
94.5% 
G3 
4 289 853 3 915 819 3 264 571 (83.4%) 
2 773 595 
3 305 833 2 726 082 2 592 566 
133 516 
93.5% 
95.1% 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">K.Kimura and A.Koike at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Lightweight BWT construction for very large string collections</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>Giancarlo,R. and Manzini,G. Combinatorial Pattern Matching</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">6661</biblScope>
			<biblScope unit="page" from="219" to="231" />
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A block-sorting loss-less data compression algorithm</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Burrows</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Wheeler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SRC Res. Rep</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale compression of genomic sequence databases with the Burrows-Wheeler transform</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Cox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1415" to="1419" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A framework for variation discovery and genotyping using next-generation DNA sequencing data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Depristo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="491" to="498" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Opportunistic data structures with applications</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ferragina</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Manzini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Symposium on Foundations of Computer Science, Redondo Beach</title>
		<meeting>the 41st Annual Symposium on Foundations of Computer Science, Redondo Beach</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="390" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Practical implementation of rank and select queries</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>González</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Experimental and Efficient Algorithms (WEA&apos;05)</title>
		<meeting>the 4th International Workshop on Experimental and Efficient Algorithms (WEA&apos;05)<address><addrLine>Santorini</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">High-order entropy-compressed text indexes</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Grossi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA &apos;03</title>
		<meeting>the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA &apos;03<address><addrLine>Baltimore ; Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="841" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Permuted longest-common-prefix array</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kä Rkkä Inen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Combinatorial Pattern Matching</title>
		<editor>Kucherov,G. and Ukkonen,E.</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="181" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Tophat2: accurate alignment of transcriptomes in the presence of insertions, deletions and gene fusions</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Computation of rank and select functions on hierarchical binary string and its application to genome mapping problems for short-read DNA sequences</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kimura</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1601" to="1613" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A bit-parallel dynamic programming algorithm suitable for DNA sequence alignment</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kimura</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bioinform. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1250002</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast and accurate short read alignment with Burrows-Wheeler transform</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Durbin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1754" to="1760" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">The sequence alignment/map format and samtools</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2078" to="2079" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Suffix arrays: a new method for on-line string searches</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Manber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Myers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, SODA &apos;90</title>
		<meeting>the First Annual ACM-SIAM Symposium on Discrete Algorithms, SODA &apos;90<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Society for Industrial and Applied Mathematics</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="319" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Two efficient algorithms for linear time suffix array construction</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Nong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1471" to="1484" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey of tools for variant analysis of nextgeneration genome sequencing data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pabinger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="256" to="278" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>