
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incorporating prior information into association studies</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Gregory</forename>
								<surname>Darnell</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Dat</forename>
								<surname>Duong</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Buhm</forename>
								<surname>Han</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Eleazar</forename>
								<surname>Eskin</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Human Genetics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incorporating prior information into association studies</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="147" to="153"/>
							<date type="published" when="2012">2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts235</idno>
					<note>Copyedited by: TRJ MANUSCRIPT CATEGORY: [20:04 28/5/2012 Bioinformatics-bts235.tex] Page: i147 i147–i153 BIOINFORMATICS</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent technological developments in measuring genetic variation have ushered in an era of genome-wide association studies which have discovered many genes involved in human disease. Current methods to perform association studies collect genetic information and compare the frequency of variants in individuals with and without the disease. Standard approaches do not take into account any information on whether or not a given variant is likely to have an effect on the disease. We propose a novel method for computing an association statistic which takes into account prior information. Our method improves both power and resolution by 8% and 27%, respectively, over traditional methods for performing association studies when applied to simulations using the HapMap data. Advantages of our method are that it is as simple to apply to association studies as standard methods, the results of the method are interpretable as the method reports p-values, and the method is optimal in its use of prior information in regards to statistical power. Availability: The method presented herein is available at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The cost of collecting genetic information has been decreasing with advances in high-throughput genomic technology (<ref type="bibr" target="#b11">Matsuzaki et al., 2004</ref>). Over the last few years, hundreds of genes have been identified as being associated with common human disease (<ref type="bibr" target="#b16">Risch and Merikangas, 1996;</ref><ref type="bibr" target="#b18">Visscher et al., 2012</ref>). Traditionally, association studies are performed without making any assumptions about which variants are more or less likely to be involved in the disease. These methods evaluate an association statistic at each single nucleotide polymorphism (SNP), and only take into account one SNP at a time. The Bonferroni correction is often used to control the overall false-positive rate by uniformly limiting the significance threshold at each SNP (<ref type="bibr" target="#b7">Franke et al., 2010</ref>). Current standard approaches report a p-value for each variant and there is a good understanding in the community of what significance levels are required for genome-wide association (<ref type="bibr" target="#b13">Pe'er et al., 2008</ref>). Virtually all association studies report p-values as their results which allows investigators to interpret their findings in the context of other groups' findings. Although the lack of assumptions has the advantage of being unbiased in the search for variants involved in the disease, we know that not all SNPs contribute equally to the disease (<ref type="bibr" target="#b1">Adzhubei et al., 2010</ref>). Recent studies (<ref type="bibr" target="#b6">Eskin, 2008</ref>) have shown that incorporating † The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors. * To whom correspondence should be addressed.</p><p>prior information such as the results of functional studies (ENCODE Project<ref type="bibr">Consortium, 2007</ref>) can increase statistical power. Unfortunately, the methods for incorporating prior information are complicated and difficult to apply in practice. Methods that use prior information are typically Bayesian association study methods (<ref type="bibr" target="#b12">Pe'er et al., 2006;</ref><ref type="bibr" target="#b8">Fridley et al., 2010</ref>) and instead report Bayes factors which are not usually reported in other studies. Although standard methods do not take into account prior information, they do have the advantage of being simple. We present a novel method for performing association studies using prior information, which is as simple to apply as standard association statistics and reports p-values, yet, optimally incorporates prior information. We extend our method to take advantage of the correlation structure to consider multiple markers in a region (<ref type="bibr" target="#b3">de Bakker et al., 2005;</ref><ref type="bibr" target="#b4">Devlin and Risch, 1995</ref>). When considering multiple markers, we compute an association statistic at each SNP in the region, not only the collected SNPs. Incorporating prior SNP information increases power over traditional association studies while maintaining the same overall false-positive rate. Our method can be used in association studies to improve both the power and resolution of a study. When our method is applied to simulations using data from individuals in the HapMap, we demonstrate a significant increase in power and resolution compared with the methods used in a traditional association study. Our method also has the advantage of maintaining the inherent simplicity of a traditional association study. As a result, the computational complexity of our method matches that of a traditional association study. We measure resolution by calculating the distance between the location of the assumed causal SNP and the location of the SNP corresponding to the maximum-likelihood ratio. Our method increases the average resolution of the four HapMap populations by 27% and the average power by 8% over the traditional method. Our method has a connection to multithreshold associations presented in (<ref type="bibr" target="#b6">Eskin, 2008)</ref>. In this work, we show that the multithreshold association method which uses the prior information optimally to maximize statistical power can be interpreted as a likelihood ratio test (LRT). This is the key observation underlying our approach and allows us to propose a very simple method which is also optimal with respect to statistical power, but has the advantage of being simple and easy to interpret.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Traditional association studies</head><p>Traditional association studies collect m markers in N /2 case and N /2 control individuals. We assume a low-disease prevalence, however, our method can be easily extended to higher prevalence. For each marker i and relative risk γ , the true case allele frequency is defined as follows:</p><formula>p + i = γ f i /((γ −1)f i +1),</formula><p>Copyedited by: TRJ MANUSCRIPT CATEGORY:<ref type="bibr">[20:</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.Darnell et al.</head><p>where f i is the population allele frequency. The control allele frequency for the causal maker, p − i , is approximately equal to the population allele frequency, p − i ≈ f i. The non-causal markers have equal case and control allele frequencies, that is,</p><formula>p + i = p − i .</formula><p>The overall allele frequency in the case–control sample is,</p><formula>p i = (p + i +p − i )/2. LetˆpLetˆ Letˆp + i , ˆ p − i</formula><p>andˆpandˆ andˆp i be the observed values of the corresponding statistic. The statistic</p><formula>s i = ˆ p + i − ˆ p − i 2 N ˆ p i (1−ˆp1−ˆ 1−ˆp i )</formula><formula>(1)</formula><p>for each marker i is approximately normally distributed with variance 1 and mean non-centrality parameter</p><formula>λ i √ N = p + i −p − i √ 2/N p i (1−p i</formula><p>). The power of a standard association study to detect a significant association at a maker i, relies on the non-centrality parameter and is</p><formula>P s (t,λ i √ N ) = ( −1 (t/2)−λ i √ N ) +1−( −1 (1−t/2)−λ i √ N )</formula><p>where the value of t is the significance threshold, which serves to control the overall false-positive rate, and and −1 denote the cumulative density function (CDF) and the inverse of CDF of the standard normal distribution, respectively. The false-positive rate represents the probability of rejecting the null hypothesis for any marker, assuming there is no causal marker. In our case, we control this probability to α. If markers are assumed to be independent, the significance threshold is computed using the Bonferroni correction, α s = α/M. It is important to note that in traditional association studies, the significance threshold, α s , is fixed for all markers, M. When computing the overall power of a study, the power is first computed for each marker, P s (t,λ i √ N ). The overall power, defined as M</p><formula>i 1 M P s (t,λ i √ N )</formula><p>, is the average of the power computed at each marker. For clarity, we have assumed that only the markers are the causal variants, which is clearly not realistic; we drop this assumption below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Association studies with prior information</head><p>Obviously, we do not know which variant is causal and which variant is not causal. However, some variants are more likely involved in the disease than others based on information on how much of a molecular effect that variant has. Let us assume that a marker i has probability c i of being causal. We define a revised power function that includes prior probabilities</p><formula>M i c i c j P s (α s ,λ i √ N ) (2)</formula><p>where α s is set to control the overall false-positive rate to α.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Maximizing power in a multithreshold association study</head><p>One way to incorporate prior information into association studies is to use multithreshold association (<ref type="bibr" target="#b6">Eskin, 2008)</ref>. In this approach, we use a different significance threshold at each marker and these thresholds are set to maximize the statistical power taking into account prior information (<ref type="bibr" target="#b1">Adzhubei et al., 2010</ref>). We denote the new set of thresholds as variables t 1 ...t m. Overall power can be defined as a function of the thresholds</p><formula>t 1 ...t m. P(t 1 ...t m ) = c i c j P s (t i ,λ i √ N ) (3)</formula><p>By optimizing the threshold at each marker, we can increase the overall power of a standard association study. Our task is to find theThe objective function to maximize is</p><formula>P(t 1 ...t m ) = c i c j P s (t i ,λ i √ N )+l α − t i .</formula><p>We take the partial derivative of the objective function with respect to t i and l and set them equal to 0 to obtain</p><formula>∂ ∂t i P(t 1 ...t m ) = c i c j 0.5φ( −1 (t i /2);λ i √ N ,1) φ( −1 (t i /2);0,1) + 0.5φ( −1 (t i /2);−λ i √ N ,1) φ( −1 (t i /2);0,1) +l = 0 (4) ∂ ∂l P(t 1 ...t m ) =α − t i = 0,</formula><p>where φ is the probability density function (PDF) of the standard normal distribution. See Appendix for the detailed derivation. As (4) is true for all marker i ∈ 1...m, we set up the following equality:</p><formula>c 1 c j 0.5φ( −1 (t 1 /2);λ 1 √ N ,1) φ( −1 (t 1 /2);0,1) + 0.5φ( −1 (t 1 /2);−λ 1 √ N ,1) φ( −1 (t 1 /2);0,1) = ... = c m c j 0.5φ( −1 (t m /2);λ m √ N ,1) φ( −1 (t 1 /2);0,1) + 0.5φ( −1 (t m /2);−λ m √ N ,1) φ( −1 (t m /2);0,1)</formula><formula>(5)</formula><p>where t i = α. We can numerically find t * 1 ...t * m satisfying (5). We begin with a guess for c * , set it equal to (5), and solve for t 1 ...t m simultaneously. If t i &gt;α, we decrease c * (when t i &lt;α, we do otherwise) and repeat the process. The resulting t 1 ...t m satisfying the constraint t i = α are denoted t * 1 ...t * m. We gain intuition on our method by imagining that we have a total budget of α to distribute among a portfolio of i assets or stocks. Each asset has a certain return on investment, which depends on the t i , the fraction of the total budget that we allocate to the asset. In order to optimize the total return on our budget of α, we allocate our funds such that the marginal return on investment for each asset is equal. Intuitively, this is because if the marginal return is not equal between investments, we can always increase the overall return by taking out funds from the smaller return investment and put them into the larger return investment. In the case of power, the budget is our overall significance threshold, α. The power return for each marker again depends on the t i we allocate to each marker. In setting the optimal significance threshold for each marker, we consider the rate of return, or power, which depends on the amount invested, or significance threshold. In determining how to allocate the fraction of the overall significance threshold to each marker, we compute the partial derivative of the power function at each marker and set them equal to each other, which is equivalent to the investment-return analogy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Connection to LRT</head><p>The key observation in this article is that the multithreshold association has a close connection to the LRT. The LRT compares the likelihood ratio of a statistic with a given threshold C * , where the likelihood ratio is a direct comparison of the probability of observing the statistic under the null distribution versus the alternative distribution. It is possible to apply the LRT to determine an LRT statistic of a given marker, and thus determine a significance designation for that marker. Consider the probability of observing the statistic s i in Equation (1). The null distribution is s i ∼ N (0,1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i148</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incorporating information to association studies</head><p>and the alternative distribution is, given the non-centrality parameter</p><formula>λ i √ N , s i ∼ 0.5N (λ i √ N ,1)+0.5N (−λ i √ N ,1)</formula><p>where the 50:50 mixture is taken assuming that we do not know the direction of the effect (two-sided test). A standard LRT will reject the null hypothesis at s i if (0.5φ(</p><formula>s i ;λ i √ N ,1)+ 0.5φ(s i ;−λ i √ N ,1))/φ(s i ;0,1) &gt; C * . C * can</formula><p>be set to control the overall false-positive rate to α. For the purposes of a multithreshold association study, we will modify the likelihood ratio and the LRT such that the prior information is included,</p><formula>c i c j 0.5φ(s i ;λ i √ N ,1)+0.5φ(s i ;−λ i √ N ,1) φ(s i ;0,1)</formula><p>This likelihood ratio is exactly the same term found in (5). LRT in this case will be done by comparing this likelihood ratio to a number C * , where</p><formula>C * = c i c j 0.5φ( −1 (t * i /2);λ i √ N ,1)+0.5φ( −1 (t * i /2);−λ i √ N ,1) φ( −1 (t * i /2);0,1)</formula><p>where C * is the threshold that controls overall false-positive rate to α. Note that when observed value s i at marker i is &gt;− −1</p><formula>(t * i /2) or &lt; −1 (t * i /2), then c i c j 0.5φ(s i ;λ i √ N ,1)+0.5φ(s i ;−λ i √ N ,1) φ(s i ;0,1) &gt; C *</formula><p>and we can reject the null hypothesis at i. Thus, LRT and multithreshold association test are equivalent. When there are correlations between markers, we can still find a C * such that the chance of Â rejecting any of the null hypotheses is α. C * can be easily calculated using permutation (see Appendix).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Maximizing power for tag SNPs</head><p>Previously, we made the assumption that the markers themselves are causal. Usually, markers are more likely to be tags for the causal variation. Using this information, we can assign each potential polymorphism to the best marker, or tag. We use notation v k ∈ T i to associate each set of polymorphisms v k to a single marker i. The effect of non-centrality parameter of indirect association is reduced by a factor |r ki |, where |r ki | is the correlation coefficient between polymorphism k and marker i (<ref type="bibr" target="#b14">Pritchard and Przeworski, 2001</ref>). This correlation coefficient can be determined from reference data such as the (<ref type="bibr">HapMap et al., 2005</ref>). We can give each polymorphism a prior probability of being causal c k. If a polymorphism k is causal, the power function when observing marker i is P s (t i ,r ki λ k √ N ). Let us denote the total power captured by a marker i as P(t i ,T i ,N ). In our case, the total power function of the association study is</p><formula>P(t 1 ...t m ) = m i P(t i ,T i ,N ) = m i v k ∈T i c k c j P s (t i ,r ki λ k √ N )</formula><p>This power function can be maximized with respect to t 1 ...t m using the same approach as before. There is a constraint that</p><formula>t i = α. The objective function now becomes P(t 1 ...t m ) = m i v k ∈T i c k c j P s (t i ,r ki λ k √ N )+l α − t i</formula><p>We take partial derivatives of this objective function with respect to t i and α and set them equal to zero</p><formula>∂ ∂t i P(t 1 ...t m ) = l + v k ∈T i c k c j d dt i P s (t i ,r ki λ k √ N ) = 0 ∂ ∂l P(t 1 ...t m ) = α − t i = 0</formula><p>Similarly to Equation (A.3), we can obtain</p><formula>v k ∈T 1 c k c j 0.5φ( −1 (t 1 /2);r k1 λ k √ N ,1) φ( −1 (t 1 /2);0,1) + 0.5φ( −1 (t 1 /2);−r k1 λ k √ N ,1) φ( −1 (t 1 /2);0,1) = ... = v k ∈Tm c k c j 0.5φ( −1 (t m /2);r km λ k √ N ,1) φ( −1 (t 1 /2);0,1) + 0.5φ( −1 (t m /2);−r km λ k √ N ,1) φ( −1 (t m /2);0,1)</formula><formula>(6)</formula><p>In Section 2.4, when markers are assumed to be causal, we detect an association at marker i if the observed statistic s i at i satisfies</p><formula>c i c j 0.5φ(s i ;λ i √ N ,1)+0.5φ(s i ;−λ i √ N ,1) φ(s i ;0,1) &gt; C *</formula><p>Similarly, when makers themselves are not assumed to be causal, we determine an association at maker i if the statistic s i at i satisfies</p><formula>v k ∈T i c k c j 0.5φ(s i ;r ki λ k √ N ,1)+0.5φ(s i ;−r ki λ k √ N ,1) φ(s i ;0,1) &gt; M * M * is</formula><p>the threshold that controls false-positive rate to α, the overall significant threshold of the association study. We can determine this M * by permutation even when there are correlations between markers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Multiple-testing adjusted p-value</head><p>We can obtain multiple-testing adjusted p-values in our multithreshold association study as follows. In an association study with only one marker, we define the test to be significant if the observed statisticˆsstatisticˆ statisticˆs is greater than its threshold −1 (α/2). Then, we can usê s to compute a p-valuê α which measures how significant of an association we observed by using the relationship 2(ˆ s) = ˆ α. For example, in a traditional association study with one marker, if thê α is 0.05, then we can say that this marker strongly associates with the disease. In an association study with m markers, we identify the associated markers by comparing each of the observed statisticsˆsstatisticsˆ statisticsˆs 1 ,.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>..,ˆ s m against its corresponding cutoff</head><formula>−1 (t 1 /2),..., −1 (t m /2).</formula><p>To determine how significant the association at each marker is, we need to compute the p-value at that marker. As the cutoff values −1 (t 1 /2),..., −1 (t m /2) are usually not identical in our multithreshold association study, we compute the multiple-testing adjusted p-valuesˆαvaluesˆ valuesˆα 1 ,..., ˆ α m at m markers separately. The multiple-testing adjusted pvalue is the probability under the null hypothesis of observing a significant association at any marker. We compute the adjusted p-valuê α i at a marker i by using its observedˆs observedˆ observedˆs i. IfˆsIfˆ</p><formula>Ifˆs i = −1 (t i /2)</formula><p>, then the multiple-testing adjusted p-value is α.</p><formula>ForˆsForˆ Forˆs i &gt;&gt; −1 (t i /2</formula><p>), we need to find the p-valuê α i &lt;α. Estimating this significance level is equivalent to finding thê α i and a new set of thresholds</p><formula>t * 1 ,...,t * m</formula><p>such that when we maximize equation (3) with the constraint j t * j = ˆ α i , then the cutoff for marker i is 2(ˆ s i ). We denote the gradient in Equation (5) at the observed marker i asˆβasˆ asˆβ. As all the partial derivatives of Equation (3) are equal at the optimal solution [Equation</p><p>(5)], we can determine a new set</p><formula>t * 1 ,...,t * m , where t * i = 2(ˆ s i</formula><p>), by setting each of the gradients in Equation (5) equal tô β. Finally, the p-valuê α i is the sum ofThe marker corresponding to the lowest p-value is the one that is most strongly associated to the disease. Using this approach, we can report a p-value which is adjusted for prior information for each variant.</p><formula>t * 1 ,...,t * m. Once thê α 1 ,..., ˆ α m</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">New multivariate normal distribution method for correlated markers</head><p>In the previous sections, we assumed independent markers 1...m that are possibly correlated to causal variation. However, marker themselves can be</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.Darnell et al.</head><p>correlated to each other. If the markers are correlated, the statistics at the markers follow a multivariate normal distribution (MVN) with variance– covariance matrix , where the entries of are the correlation coefficients between the markers (<ref type="bibr" target="#b9">Han et al., 2009</ref>). Here, we propose a new LRT method designed for the situation that the markers are correlated. By using information from all the markers, we can have better resolution than when inspecting one of the markers. If variation i is causal and the marker j is correlated to i, the non-centrality parameter at marker j is r ij λ i √ N (<ref type="bibr" target="#b14">Pritchard and Przeworski, 2001</ref>). If we consider correlations between variation i and all the markers, the vector of non-centrality parameters with respect to causal variation i will be i</p><formula>√ N = (r i1 λ i √ N ,...,r im λ i √ N ).</formula><p>We modify the LRT of the previous section to take into account multiple correlated markers. Given a putative causal variation i, we have the following null hypothesis H 0 : i √ N = 0 and the alternate hypothesis H a : i √ N = 0 at markers 1...m. Let s = (s 1 ,...,s m ) be the vector of the observed statistics of all markers. The LRT is performed by comparing the probability of s under the null and alternative hypothesis, using the formula</p><formula>c i c j 0.5φ( s; i √ N ,,)+0.5φ( s;− i √ N ,,) φ( s; 0,,) &gt; C * (7)</formula><p>where C * is set to control the false-positive rate to α and can be found by permutation. φ is the PDF of the MVN distribution. Again, the 50:50 mixture of the distributions is taken for the alternative hypothesis to perform twosided test. When the condition in Equation (7) is satisfied, we have sufficient evidence to reject the null hypothesis at variation i. It should be noted that the new method is different from the methods we described previously in that the testing is performed per each putative causal variant instead of per each marker. The information of putative causal variants is obtained from the reference dataset, for example, by considering all known variants. This implies increased multiple-testing burden because the number of known variants is much greater than the number of markers in general. However, although the number of tests are considerably increased, the test statistics are highly correlated and therefore the actual multipletesting burden increases less steeply than the number of tests if we use permutation. Our results show that the new method outperforms previous methods in terms of both power and resolution even after we take into account the increased multiple testing burden.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Candidate gene study associations Project</head><p>We follow the evaluation protocol shown in (<ref type="bibr" target="#b3">de Bakker et al., 2005</ref>) to simulate association studies in a candidate gene-sized region using the HapMap data ENCODE (ENCODE Project<ref type="bibr">Consortium, 2007</ref>). In these simulations, we make case and control individuals by randomly sampling from the pool of haplotypes from HapMap samples in the ENCODE regions. The disease status for each individual is decided by randomly assigning an SNP from this region as causal with a certain relative risk. We assume the scenario where we are using a whole-genome genotyping product such as the Affymetrix 500k SNP chip (<ref type="bibr" target="#b11">Matsuzaki et al., 2004</ref>) and where a subset of SNPs from this region are collected as markers. Simulation studies are done over the four HapMap populations in each of the 10 ENCODE regions. We compare power of four different methods. The first method is the traditional association test where the Bonferroni correction is used. The second method is the multithreshold association test where the markers are assumed to be causal. Since this method only takes into account the non-centrality parameter at each marker, it is equivalent to accounting for the minor allele frequencies (MAFs) of the markers to determine the optimal multithresholds. We call this method multithreshold method with MAF prior. The third method is the multithreshold association test where we assume causal variants are in LD with markers. We use the HapMap data and assign each SNP to a marker by choosing the marker with the highest correlation coefficient with the SNP. This method takes into account not only the non-centrality parameters (or MAF) at the causal variants but also how many causal variants are assigned to each marker and how much the marker and the assigned causal variants are correlated. We call this method multithreshold method with LD and MAF prior. This method is equivalent to the method presented in (<ref type="bibr" target="#b6">Eskin, 2008</ref>). The fourth method is the new MVN method where we assume the markers are correlated. The testing is performed at each putative causal variant. To measure power of each method while correctly accounting for the multiple testing burden of each method, we perform the following simulation procedure. Assuming the null hypothesis of no association, we generate 1000 null panels. We compute the maximum statistic among all markers for all null panels to obtain the empirical null distribution of maximum statistic for each method. The top 5% quantile of the distribution gives us the empirically estimated threshold for α = 0.05. Then, we generate 1000 alternative panels assuming the disease model. The power is measured as the number of alternative panels whose maximum statistic exceeds the threshold corresponding to α = 0.05. This empirical procedure is shown to accurately control the false-positive rate nearly identical to permuting each panel (<ref type="bibr" target="#b3">de Bakker et al., 2005</ref>).<ref type="figure" target="#tab_1">Table 1</ref>shows the power of all four methods. In general, the multithreshold method with MAF prior does not show a better performance than the traditional method. This shows that taking into account only MAF and not the correlations between the marker and the causal variants can be not helpful. The multithreshold method with both LD and MAF prior increases power compared with the traditional method, on average by 1.2%. When we consider only the SNPs whose traditional method's power is in mid-range (between 0.1 and 0.9), the power is increased by a greater amount, 4.0%, which goes along with the results of (<ref type="bibr" target="#b6">Eskin, 2008</ref>). The power increase of the new MVN method is the greatest among all methods. It increases power by 8.3% on average when considering all SNPs and by 15.7% on average when considering the SNPs with mid-range power. The power increase is even as great as 24.7% in the YRI population for the SNPs with mid-range power. This shows that the new MVN method can be very helpful in detecting associations. We also look at the resolution, by how far the peak association statistic is located from the actual causal variant. We measure this distance in the unit of basepairs and report the results in<ref type="figure" target="#tab_2">Table 2</ref>. The multithreshold method with MAF prior does not help the resolution either. On the other hand, the multithreshold method with both LD and MAF prior improves the resolution by 2.4% on average for all SNPs and by 4.0% on average for SNPs with mid-range power. However, it failed to improve the resolution in one case (CEU population and for the SNPs with mid-range power). The new MVN method shows the greatest amount of improvement in resolution. The resolution is improved by 27.1% on average for all SNPs and by 44.5% on average for SNPs with mid-range power. This shows that the resolution is so dramatically improved that the distance between the peak association statistic and the causal variant became, on average, almost half compared i150</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incorporating information to association studies</head><formula>, n (%) n (%) n (%) n (%) n (%) n (%)</formula><p>CEUThe numbers in parentheses are the power gain compared with the traditional method</p><formula>Trad Mult (MAF), Mult (LD), MVN, Trad Mult (MAF), Mult (LD), MVN, n (%) n (%) n (%) n (%) n (%) n (%)</formula><p>CEUThe unit of resolution is basepairs. The numbers in parentheses are the improvement percentage in resolution compared with the traditional method with the traditional method in the case of the SNPs with mid-range power. We make an unrealistic assumption that we know the relative risk of the causal polymorphism to be 1.30 and use this assumption to determine the optimal thresholds. We measure the effect of an incorrect assumption by obtaining optimal thresholds at a relative risk of 1.30 and measure the power of these thresholds under a wide range of relative risks.<ref type="figure" target="#fig_2">Figure 1</ref>shows the total average power under different relative risks for the traditional method, the multithreshold method with LD and MAF prior, and the new MVN method. Even when the assumed relative risk is incorrect, the multithreshold method and the new MVN method outperform the traditional method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extrinsic information on candidate gene-sized regions</head><p>We measure the impact of extrinsic information on candidate gene-sized regions using the HapMap data ENCODE regions by simulating association studies with unequal priors at the polymorphisms. We first consider the assumption that causal SNPs can be anywhere in the genome, and randomly pick 10% of the variants. Then, we upweight the likelihoods of being causal of these polymorphisms by 25 times. We simulate association studies by picking the causal SNP among these polymorphisms. As we upweight the likelihood of being causal for the actual causal SNP in this simulation, we expect that the methods accounting for the prior information will show a better performance. In our results, the power increase of the multithreshold method with LD and MAF prior and the MVN method are 2.0% and 11.3% relative to the traditional method, respectively. The amount of power increase is greater compared with when no extrinsic</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.Darnell et al.</head><p>the resolution improvement of the MVN method relative to the traditional method is as great as 70.4% after incorporating the prior information. This shows that the use of correct prior information can help both the power and the resolution of the methods we proposed, especially the resolution of the MVN method. On the other hand, the power and resolution of the multithreshold method with only MAF prior did not benefit from the extrinsic prior information, possibly because the method only takes into account the markers and not the uncollected putative causal variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>We have presented a novel statistical method for incorporating prior information into association studies. The advantage of our method is that we can optimally incorporate prior information with respect to statistical power but still report p-values for each variant. By incorporating the correlation structure underlying the HapMap, we manipulate the significance threshold at each SNP to improve the overall power of a study. Experiments show that our method has a similar computational overhead yet greatly increased power and resolution to traditional association study methods. Our method has similarities with, the method presented in (<ref type="bibr" target="#b17">Roeder et al., 2007</ref>) and (<ref type="bibr" target="#b15">Roeder and Wasserman, 2009</ref>). The difference is that while<ref type="bibr">Roeder et al.</ref>present the general framework for optimally setting multithresholds for tests, our method is specifically focusing on the context of genetic association studies using available information of both MAF and LD. For example, if only the non-centrality parameter of the statistic at the tested markers is considered as presented in the general framework of Roeder et al., the method will be exactly equivalent to the multithreshold method with MAF prior that we examined in our simulations. We show that this method does not achieve a better performance than the traditional method in terms of both power and resolution. Moreover, we present the novel MVN method that assumes correlation between markers and that outperforms both the traditional method and the multithreshold method of (<ref type="bibr" target="#b6">Eskin, 2008</ref>), which is distinctive from the framework assuming independency between the tests. The new MVN method has some similarities with the weighted haplotype test (<ref type="bibr" target="#b19">Zaitlen et al., 2007</ref>) or imputation method (<ref type="bibr" target="#b10">Marchini et al., 2007</ref>). In both the new method and their methods, the unobserved causal variant is tested using the observed markers. However, the intrinsic difference is that our method takes into account prior information to optimally set significance thresholds differently to each causal variant in the context of multiple-testing correction. Moreover, the application of the method is much simpler than those methods, requiring only the MAF and LD information from the reference dataset but not the actual haplotype data. As we use prior information to improve power and resolution, the drawback is that the performance will not be optimal if the prior information is incorrect. For example, the MAF or LD information from the HapMap data can have sampling variation and the extrinsic information about the deleterious effect of the variant can be inaccurate. A possible approach dealing with inaccurate prior information can be explicitly accounting for the uncertainty. For example, we reduce the correlation coefficient estimated from the HapMap by a small amount because the likelihood of the MVN distribution becomes zero if the perfectly correlated markers in the reference is not perfectly correlated in the sample. A systematic approach dealing with prior uncertainty will be an interesting subject of the future research. However, we assume that the uncertainty in the prior information will be decreased in the future as the sample size of the reference dataset increases (1000 Genomes Project Consortium, 2010).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Incorporating information to association studies</head><p>When we take partial derivative with respect to t i and set it equal to 0, we observe</p><formula>∂ ∂t i P(t 1 ...t m ) = c i c i d dt i P s (t i /2,λ i √ N )+l = 0</formula><p>First, we present the definition of the CDF of the normal distribution:</p><formula>(x) = 1 √ 2π x −∞ e −t 2 /2 dt = 1 2 1+erf x √ 2 (A.1)</formula><p>Now, we present the properties of erf(x).</p><formula>erf (x) = 2 π x 0 e −t 2 dt d dx erf (x) = 2e −x 2 √ π (A.2)</formula><p>Now, we consider the power function</p><formula>P s (t,k) = ( −1 (t/2)−k)+1−( −1 (1−t/2)−k)</formula><p>where k is the non-centrality parameter. To maximize the power of a standard association study with respect to t, we find</p><formula>d dt P s (t,k) = d dt ( −1 (t/2)−k)+1−( −1 (1−t/2)−k) = d dt ( −1 (t/2)−k) − d dt ( −1 (1−t/2)−k)</formula><p>By applying (A.1), we get</p><formula>d dt P s (t,k) = d dt 1 2 1+erf −1 (t/2)−k √ 2 − d dt 1 2 1+erf −1 (1−t/2)−k √ 2 = 1 2 d dt erf −1 (t/2)−k √ 2 − 1 2 d dt erf −1 (1−t/2)−k √ 2 By using (A.2), we get d dt P s (t,k) = (1/2)(2/ √ 2π)e − −1 (t/2)−k √ 2 2 d dt −1 (t/2) −(1/2)(2/ √ 2π)e − −1 (1−t/2)−k √ 2 2 d dt −1 (1−t/2) = (1/ √ 2π)e −.5[ −1 (t/2)−k] 2 d dt −1 (t/2) −(1/ √ 2π)e −.5[ −1 (1−t/2)−k] 2 d dt −1 (1−t/2) (A.3)</formula><p>Equation (A.3) can be simplified using the property −1</p><formula>(1−t/2) =− −1 (t/2), d dt P s (t,k) = (1/ √ 2π)e −.5[ −1 (t/2)+k] 2 d dt −1 (t/2) −(1/ √ 2π)e −.5[ −1 (t/2)−k] 2 d dt − −1 (t/2) = (1/ √ 2π) e −.5[ −1 (t/2)+k] 2 +e −.5[ −1 (t/2)−k] 2 * d dt −1 (t/2) (A.4)</formula><p>Now, we solve for d dt −1 (t/2). We use the property:</p><formula>−1 (x) = √ 2[erf −1 (2x −1)] −1 (t/2) = √ 2[erf −1 (2(t/2)−1)] d dt −1 (t/2) = d dt √ 2erf −1 (t −1) (A.5)</formula><p>and the property:</p><formula>d dx [erf −1 (x)]= √ π 2 [e [erf −1 (x)] 2 ] d dt √ 2erf −1 (t −1) = √ 2 d dt erf −1 (t −1) = √ 2π 2 e [erf −1 (t−1)] 2 (A.6)</formula><p>Using, (A.5) and (A.6), we find</p><formula>d dt −1 (t/2) = √ 2π 2 e .5( −1 (t/2)) 2</formula><p>By plugging this into (A.4), we have d dt P s (t,k) = 0.5φ( −1 (t/2);k,1)+0.5φ( −1 (t/2);−k,1)</p><formula>φ( −1 (t/2);0,1) .</formula><p>This equation is the likelihood ratio of a random variable s at the value −1 (t/2) or equivalently at the value − −1 (t/2), between the alternative hypothesis s ∼ 0.5N (k,1)+0.5N (−k,1) and the null hypothesis s ∼ N (0,1). The 50:50 mixture of the two symmetrically positioned distributions under the alternative hypothesis can be considered due to the two-sided testing that we perform when we do not have any prior knowledge about the direction of the allele effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2. Controlling false-positive rate using permutation</head><p>When considering many correlated markers in an association study, we need to find a valid threshold of statistic, C * , to set the significance threshold for each test such that the overall falsepositive rate of the study is controlled to α. The following algorithm is the general method for the permutation procedure, for which the resulting vector allows us to determine a certain C * to limit the overall false-positive rate of the study. In our example, the 5% quantile of S yields an α level of 0.05. Initialize empty vector S for j = 1 → n do Randomly assign disease status of individuals for marker i = 1 → m do Obtain statistic s i at each marker i end for Keep max{s 1 ...s m } in S. end for Sort S. Take top 5% quantile of S. This value is C * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i153</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><figDesc>have been determined, these values are sorted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Copyedited by: TRJ MANUSCRIPT CATEGORY: [20:04 28/5/2012 Bioinformatics-bts235.tex] Page: i151 i147–i153</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.1.</head><figDesc>Fig. 1. Average power under varying relative risks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Funding: G.D., D.D., B.H. and E.E. are supported by National Science Foundation grants 0513612, 0731455, 0729049, 0916676 and 1065276, and National Institutes of Health grants K25HL080079, U01-DA024417, P01-HL30568 and PO1-HL28481. B.H. is supported by the Samsung Scholarship. Conflict of Interest: None declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>Copyedited by: TRJ MANUSCRIPT CATEGORY: [20:04 28/5/2012 Bioinformatics-bts235.tex] Page: i153 i147–i153</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>t * 1 ...t * m that maximizes (3) under the condition that t * i = α. This constrained optimization can be solved using the method of Lagrange multipliers, assuming the markers are not correlated. Below we show how to use this method to maximize our object function, and as a result find the per marker threshold, t * 1 ...t * m .</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 1.</figDesc><table>Summary of the power comparison among all 10 ENCODE regions 

Pop. 
No. of 
No. of 
All SNPs 
SNPs with power between 0.1 and 0.9 

tags 
SNPs 
Trad 
Mult (MAF), 
Mult (LD), 
MVN, 
Trad 
Mult (MAF), 
Mult (LD), 
MVN</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 2.</figDesc><table>Summary of the resolution comparison among all 10 ENCODE regions 

Pop. 
All SNPs 
SNPs with power between 0.1 and 0.9 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">α − t i  i152 at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A1. Maximizing power in a multithreshold association study</head><p>Our task is to find t * 1 ...t * m that maximize (3) under the condition t i = α. We use the method of Lagrange multipliers to find such</p><formula>t * 1 ...t * m .</formula><p>This is our objective function</p><formula>P(t 1 ...t m ) = c i c j P s (t i /2,λ i √ N )+l</formula></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">A map of human genome variation from population-scale sequencing</title>
	</analytic>
	<monogr>
		<title level="j">Genomes Project Consortium. Nature</title>
		<imprint>
			<biblScope unit="volume">467</biblScope>
			<biblScope unit="page" from="1061" to="1073" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A method and server for predicting damaging missense mutations</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">A</forename>
				<surname>Adzhubei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="248" to="249" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A haplotype map of the human genome</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Altshuler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">437</biblScope>
			<biblScope unit="page" from="1299" to="1320" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficiency and power in genetic association studies</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">I W</forename>
				<surname>De Bakker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1217" to="1223" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">A comparison of linkage disequilibrium measure for fine-scale mapping</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Devlin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Risch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genomics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="311" to="322" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Identification and analysis of functional elements in 1% of the human genome by the encode pilot project</title>
	</analytic>
	<monogr>
		<title level="j">ENCODE Project Consortium. Nature</title>
		<imprint>
			<biblScope unit="volume">447</biblScope>
			<biblScope unit="page" from="799" to="816" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Increasing power in association studies by using linkage disequilibrium structure and molecular function as prior information</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Eskin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="653" to="660" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Genome-wide meta-analysis increases to 71 the number of confirmed crohn&apos;s disease susceptibility loci</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Franke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1118" to="1125" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Bayesian mixture models for the incorporation of prior knowledge to inform genetic association studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Fridley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="418" to="426" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Rapid and accurate multiple testing correction and power estimation for millions of correlated markers</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Han</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A new multipoint method for genome-wide association studies by imputation of genotypes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="906" to="913" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Genotyping over 100,000 SNPS on a pair of oligonucleotide arrays</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Matsuzaki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="109" to="111" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluating and improving power in whole-genome association studies using fixed marker sets</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Pe &apos;er</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="663" to="667" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimation of the multiple testing burden for genomewide association studies of nearly all common variants</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Pe &apos;er</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="381" to="385" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Linkage disequilibrium in humans: models and data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Pritchard</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Przeworski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Genome-wide significance levels and weighted hypothesis testing</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Roeder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wasserman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="398" to="413" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The future of genetic studies of complex human diseases</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Risch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Merikangas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">273</biblScope>
			<biblScope unit="page" from="1516" to="1517" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving power in genome-wide association studies: weights tip the scale</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Roeder</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="741" to="747" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Five years of GWAS discovery</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">M</forename>
				<surname>Visscher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="7" to="24" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Leveraging the hapmap correlation structure in association studies</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Zaitlen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="683" to="691" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>