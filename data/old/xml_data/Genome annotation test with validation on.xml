
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genome analysis Genome annotation test with validation on transcription start site and ChIP-Seq for Pol-II binding data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Justin</forename>
								<surname>Bedo</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">National ICT Australia</orgName>
								<orgName type="institution" key="instit2">Victoria Research Laboratories</orgName>
								<orgName type="institution" key="instit3">The University of Melbourne</orgName>
								<address>
									<addrLine>VIC 3010</addrLine>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Informatique Biologie Intégrative et Systèmes Complexes</orgName>
								<address>
									<addrLine>Tour Evry II, 523 Place des Terrasses de l&apos;Agora</addrLine>
									<postCode>91000</postCode>
									<settlement>Evry</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Adam</forename>
								<surname>Kowalczyk</surname>
							</persName>
							<email>adam.kowalczyk@nicta.com.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">National ICT Australia</orgName>
								<orgName type="institution" key="instit2">Victoria Research Laboratories</orgName>
								<orgName type="institution" key="instit3">The University of Melbourne</orgName>
								<address>
									<addrLine>VIC 3010</addrLine>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genome analysis Genome annotation test with validation on transcription start site and ChIP-Seq for Pol-II binding data</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">12</biblScope>
							<biblScope unit="page" from="1610" to="1617"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btr263</idno>
					<note type="submission">Received on August 10, 2010; revised on April 14, 2011; accepted on April 15, 2011</note>
					<note>[13:14 14/5/2011 Bioinformatics-btr263.tex] Page: 1610 1610–1617 Associate Editor: Martin Bishop Supplementary Information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Many ChIP-Seq experiments are aimed at developing gold standards for determining the locations of various genomic features such as transcription start or transcription factor binding sites on the whole genome. Many such pioneering experiments lack rigorous testing methods and adequate &apos;gold standard&apos; annotations to compare against as they themselves are the most reliable source of empirical data available. To overcome this problem, we propose a self-consistency test whereby a dataset is tested against itself. It relies on a supervised machine learning style protocol for in silico annotation of a genome and accuracy estimation to guarantee, at least, self-consistency. Results: The main results use a novel performance metric (a calibrated precision) in order to assess and compare the robustness of the proposed supervised learning method across different test sets. As a proof of principle, we applied the whole protocol to two recent ChIP-Seq ENCODE datasets of STAT1 and Pol-II binding sites. STAT1 is benchmarked against in silico detection of binding sites using available position weight matrices. Pol-II, the main focus of this paper, is benchmarked against 17 algorithms for the closely related and well-studied problem of in silico transcription start site (TSS) prediction. Our results also demonstrate the feasibility of in silico genome annotation extension with encouraging results from a small portion of annotated genome to the remainder. Availability: Available from http://www.genomics.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The recent advances in microarray technologies (tiling arrays, SNP arrays, etc.) and more recently in high-throughput sequencing [next-generation sequencing (NGS)] allows for more complete genome-wide annotation of functional sites. The rapid increase in the data volumes has put pressure on the development of data analysis techniques capable of coping with large volumes of data that can reliably extract relevant knowledge. This article analyses and benchmarks techniques introduced in<ref type="bibr" target="#b13">Kowalczyk et al. (2010)</ref>based on supervised learning and the generalization capabilities of predictive models that are trained on part of the genome and tested * To whom correspondence should be addressed. on the remainder. Our approach consists of dividing the genome into small tiles and then allocating a binary label to each tile according to the observed phenomenon (e.g. the presence of a transcription factor binding site within the tile). A model is then trained on a portion of the genome to predict the labels from the DNA content of tiles and then tested on the whole genome. The prediction accuracy is then used to assess the properties of the assay. There are many interesting phenomena which can be analysed by this approach and we will now focus on two key examples:</p><p>(1) A quality test for ChIP-Seq experiment: we first discuss a quality test for ChIP-Seq experiments when there is no (independent) gold standard to assess the final results. In the paper by<ref type="bibr" target="#b13">Kowalczyk et al. (2010)</ref>, we compared a few sets of putative peaks for STAT1 and Pol-II binding sites generated by various analysis methods applied to the ChIPSeq experimental data of<ref type="bibr" target="#b14">Rozowsky et al. (2009)</ref>. As the 'gold standards' provided by the ENCODE project were extracted from the same experimental data and their putative peaks were a part of our comparative study, an independent and objective way of evaluating the various lists of peaks was required.<ref type="bibr" target="#b13">Kowalczyk et al. (2010)</ref>introduced a consistency benchmark: for each list of putative peaks ordered by the allocated P-values, a model was trained using only chromosome 22 to predict the overlap of a tile with a peak from the tile's DNA content. The model was then applied to the whole genome and its predictions compared with the list of putative peaks. The lists, and the peak calling algorithms generating them, that provided more consistent (accurate) predictions deemed to be more accurate. Significant differences in the peak calling algorithms were observed. The article is linked directly to those methods developed by<ref type="bibr" target="#b13">Kowalczyk et al. (2010)</ref>, for both Pol-II and STAT1, but here the focus is mainly on predicting Pol-II.</p><p>(2) An extension of annotation: a critical hurdle in the way to full 'mechanistic' interpretation of genetic data is extending the annotation of the human genome such that every regulatory sequence in the genome is identified along with known disease-associated genetic variations and changes. The analysis of the transcriptome by NGS methods generates novel genomic expression landscapes, state-specific expression, single-nucleotide polymorphisms (SNPs), the transcriptional activity of repeat elements and both known and new alternative splicing events. These all have an impact on current models of key signalling pathways '... suggesting thatPage: 1611 1610–1617</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pol-II binding data</head><p>our understanding of transcriptional complexity is far from complete' (<ref type="bibr" target="#b5">Cloonan et al., 2008</ref>). In particular, as transcripts are often state and cell type specific, the proper annotation of gene boundaries is compromised until all the conditions of all cells are properly profiled—a formidable molecular task. Moreover, as NGS is relatively recent many cell states and types have been profiled on tiling arrays or standard gene expression arrays covering only a relatively small part of the human genome and have not been analysed genome-wide using NGS. Thus, there is immediate benefit in developing tools that would extend key regulatory element mapping, such as the binding of STAT1 or transcriptional start sites, from a fraction of the genome where it was empirically explored, either using promoter arrays (Affymetrix, Nimblegen, etc.) or with ENCODE tools, through to the whole genome. Implementation of the above ideas rests on the assumption that robust and simple predictive models can be developed and their performance can be meaningfully measured against annotations with extreme class imbalances, where the positive classes are very sparse (which is the typical case for most genome functional annotations). The aim of this article is to demonstrate that such solutions are feasible and applicable to NGS genome-wide studies of current interest. The whole method depends critically on the generalization capabilities of a supervised learning predictor. To that end, we mainly focus on the performance of our method for predicting PolII binding and on the closely related task of (in silico) transcription start sites (TSS) prediction. This annotation (rather than STAT1) was chosen as it is well studied with high-quality data and in silico prediction results are readily available. A recent extensive comparative study of TSS in humans (<ref type="bibr" target="#b2">Abeel et al., 2009</ref>) has demonstrated that supervised learning techniques performed the best, with the SVM-based predictor ARTS (<ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>) being the clear winner. We demonstrate a successful technique with performance equivalent to ARTS at the coarse 500 bp resolution, but with much simpler training. As our method uses only a handful of generic features (k-mer frequencies) in a linear fashion, 1 it is also more universal. In order to demonstrate the generalization capabilities convincingly, we have used only data from the smallest autosomal human chromosome (chromosome 22, ∼ 1/60 th of the genome) for training, which is typically much less than the size of the active genome in a ChIP-Seq experiment. Chromosome 22 is often used for incomplete annotation experiments on the human genome (<ref type="bibr" target="#b11">Hartman et al., 2005</ref>). The algorithmic details and the formal derivation of the key metric (calibrated precision) can be found in the Supplementary Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GENOME ANNOTATION METHODOLOGY</head><p>We now outline the principles of the proposed methodology for genome annotation and the methods for measuring the performance. Technical details are available in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Genome segmentation</head><p>The genome was segmented into overlapping 500 bp tiles, shifted every 250 bp. Thus, each nucleotide is covered by exactly two tiles. Overlapping tiles are used to mitigate the effect of edges; for each nucleotide, the 250 bp neighbourhood centred around the nucleotide is fully contained in exactly one 500 bp tile. Thus, the whole human genome is composed of 10.72M different tiles. We have also analysed a reduced dataset containing 0.96M tiles (see<ref type="figure" target="#tab_1">Table 1</ref>, Column 'RefGeneEx'). Each dataset has its own set of binary labels y i =±1 allocated to each tile x i , see Section 3.1 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature extraction</head><p>For each tile x i the features for learning and classification were generated from its DNA content exclusively as the occurrence frequencies of k-mers. Previously, we have experimented with a few variations of the method, including different values of k (<ref type="bibr" target="#b4">Bedo et al., 2009;</ref><ref type="bibr" target="#b13">Kowalczyk et al., 2010</ref>). For this article, we exclusively used k = 4 and also combined the frequencies for forward and reverse complement pairs; such a summation simplifies the models with a marginal difference in performance. Furthermore, for notational convenience (see the next section) we add a constant feature of value 1. Thus, the feature vector function φ( x i ) ∈ R 137 maps each tile into a 1 2 (4 k +4 k 2 )+1 = 137-dimensional space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Supervised learning</head><p>We used a simple linear classifier in the feature space defined above:</p><formula>f ( x) := w·· x</formula><p>where x, w ∈ R 137. The weight vector w was obtained using a support vector machine combined with recursive feature elimination. Typically, only a fraction of features are used – i.e. they have weights w i = 0. The algorithm is referred to as a recursive support vector (RSV) machine and is described in Section 1 of the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Performance metrics</head><p>We first review two classical methods for the evaluation of model performance before we discuss our modifications. Let us consider a predictive model (hypothesis) f : X → R. As the decision threshold θ ∈ R is varied, we denote by</p><formula>n + r = n + r (θ) := |{ x i | f ( x i ) ≥ θ &amp; y i =+1}|,</formula><formula>(1)</formula><formula>n − r = n − r (θ) := |{ x i | f ( x i ) ≥ θ &amp; y i =−1}|,</formula><formula>(2)</formula><p>the number of positive and negative examples recalled – i.e. with scores not less than the threshold θ – or, equivalently, the number of true positive and false positive samples. The recall (aka sensitivity or true positive rate, TPR) is defined as the fraction ρ(θ) = TPR(θ) := n + r /n + and the precision is</p><formula>p(θ) := n + r n + r +n − r = n + r n r ,</formula><formula>(3)</formula><p>Page: 1612 1610–1617</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Bedo and A.Kowalczyk</head><p>where n r := n + r +n − r and n + and n − denote the total number of positive and negative examples, respectively. The precision–recall curve (PR curve or PRC) is simply the plot of the precision versus recall, as defined above. The area under the PRC (auPRC) is used as a general measure of performance across all thresholds (<ref type="bibr" target="#b2">Abeel et al., 2009;</ref><ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>). The second classical metric considered here is centred on the receiver operating characteristic (ROC) curve and the area under it (auROC) (<ref type="bibr" target="#b10">Hanley and McNeil, 1982</ref>). This is a well-established performance measure in machine learning, bioinformatics and statistics. We define the ROC curve as the plot of the specificity spec(θ) = 1−FPR(θ) := 1−n − r /n − versus the recall. Note that this curve is clockwise-rotated 90 @BULLET with respect to the typical ROC curve used by the machine learning community. The auROC has been shown to be equivalent to the probability of correctly ordering class pairs (<ref type="bibr" target="#b10">Hanley and McNeil, 1982</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Calibrated precision–recall</head><p>The PRC and ROC curve are typically used for comparing performance of predictors on a fixed benchmark. However, when one evaluates a novel ChIP-Seq experiment—see for example the Pol-II benchmark below—there is no other predictor or dataset to compare performance against. Thus, a form of 'calibration' is needed to evaluate the predictor performance in isolation to determine if a sufficient generalization level is achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 2.1. Let us consider two test datasets with radically different</head><p>positive samples prior probability:To resolve this problem, rather than analysing ratios as in the above example, we can ask a different question: what is the probability of observing a precision better than random guessing at a given recall? The smaller such a probability, the better the performance of the classifier, hence it is convenient to consider −log 10 of those probabilities. We call this the calibrated precision (CP); better classifiers will result in higher values of CP. The plot of CP as a function of recall is referred to as the calibrated precision–recall curve (CPRC). The explicit formula for CP is 2 :</p><formula>(A) n + /(n + +n − ) = 5% and (B) n + /(n + + n − ) =</formula><formula>CP(p,ρ) := −log 10 n − r x=0 n + n + −1 n + r −1 n − x (n + r +x) n n + r +x (4)</formula><formula>∼−log 10 n + n + −1 n + r −1 n − x * (n + r +x * ) n n + r +x * ,</formula><formula>(5)</formula><p>where</p><formula>x * := min n − r , (n + r −1)(n − +1) n + −1 ∼ min n − r ,pn − ,</formula><p>is the index of the maximal term in the sum (4), andprecise approximations of CP can be easily derived (see the Supplementary Material). CP(p,ρ) is precisely −log 10 of the probability that for a uniform random ordering of the test samples, the n + r th positive example is preceded by ≤ n − r negative examples. In other words, this is −log 10 of the P-value for a null hypothesis that the test data of n + positive and n − negative examples was randomly shuffled. This formula explicitly depends on values of n + and n − , thus different results are expected for different class sizes even if their ratio is preserved. Indeed, if we assume n = n + +n − = 10 3 , then the respective values of the calibrated precision for Example 2.1 are CP A = 3.74 and CP B = 4.85, while for n = 10 6 we get CP A = 904.3 and CP B = 2069.2. This is a trend which one should expect: intuitively, dealing with datasets containing hundreds of examples is far easier than dealing with dataset containing millions. More formally, in the latter case although we have the same proportion of correct guesses—i.e. the same precision at the same recall level—the absolute number of correct guesses is proportionally higher. This is much harder due to the central limit theorem of statistics as the average of a larger number of repeated samplings has a stronger tendency to converge to the mean with a variance inversely proportional to the number of trials. Thus, for larger datasets the same deviation from the mean is associated with a far smaller probability of occurrence. The above simple example vividly illustrates this principle, which is also clearly visible in the empirical test results in<ref type="figure" target="#fig_3">Figure 2B</ref>andand the area under the CPRC (auCPRC). The latter option is in line with areas under ROC and PRC and can be interpreted as the expected CP on the space of positively labelled test examples (see the Section 3 of Supplementary Material).</p><formula>p = n + r /(n + r +n − r ) and ρ = n + r /n</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>In Section 3.1–3.4 below, we cover the main experiments with detection of Pol-II binding and in silico TSS detection. In Section 3.5, we outline additional experiments with ChIP-Seq data for transcription factor STAT1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets for Pol-II and TSS</head><p>We used five different datasets for training and testing our classifiers. The first two were whole genome scans while the third was designed to be similar to the benchmark tests used by<ref type="bibr" target="#b2">Abeel et al. (2009) and</ref><ref type="bibr" target="#b15">Sonnenburg et al. (2006)</ref>; the last two are independent benchmark sets embedded in the software of<ref type="bibr" target="#b2">Abeel et al. (2009)</ref>.(2) RefGene: for this dataset, we have used human reference genome hg18 with RefGene annotations for transcribed DNA available through the UCSC browser. It annotates ∼32K TSSs including alternative gene transcriptions. More specifically, if a 500 bp tile was overlapping the first base of the first exon it was labelled +1, and if not it was labelled −1. This created n + = 43K positive and n − = 11M negative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 1613 1610–1617</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pol-II binding data</head><p>(3) RefGeneEx: this is an adaptation of the previous dataset to the methodology proposed by (<ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>) and adopted by<ref type="bibr" target="#b2">Abeel et al. (2009)</ref>in an attempt to generate more reliable negative labels. The difference is that all negative examples that do not overlap at least one gene exon are discarded. This gives n + = 43K positive and only n − = 0.55M negative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predictors</head><p>We used three different RSV predictors for Pol-II and TSS experiments, namely RSV Po2 , RSV RfG and RSV Ex , each trained on the intersection of chromosome 22 with one of the above datasets using the method described in Section 2.3 (with details in Section 1 of the Supplementary Material). The predictions for ARTS were downloaded (http://www.fml .tuebingen.mpg.de/raetsch/suppl/arts/) from a web site published by the authors of the algorithm (<ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>). These predictions contain scores for every 50 bp segment aligned against hg17. The liftOver tool (http://hgdownload.cse.ucsc.edu/ goldenPath/hg17/liftOver/) was used to shift the scores to hg18. For the results reported in<ref type="figure">Figures</ref><ref type="figure" target="#tab_1">Table 1</ref>. They are overlaps of the respective label sets with chromosome 22 only. In contrast, ARTS used carefully selected RefGene-annotated regions for hg16. This resulted in n + = 8.5K and n − = 85K examples for training, which contain roughly 2.5–8 times more positive examples than used to train our RSV models. Additionally, the negative examples for ARTS training were carefully chosen, while we have chosen all non-positive examples Page: 1614 1610–1617</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Bedo and A.Kowalczyk</head><p>on chromosome 22 for RSV training, believing that the statistical noise will be mitigated by the robustness of the training algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Benchmark against 17 promoter prediction tools</head><p>Our three predictors, RSV Po2 , RSV RfG and RSV Ex generated as described in Section 3.2, were compared against 17 dedicated promoter prediction algorithms evaluated by<ref type="bibr" target="#b2">Abeel et al. (2009)</ref>using the software provided by the authors. This software implements four different protocols: @BULLET 1A: Bin-based validation using the (preprocessed) CAGE dataset 3 as a reference. This protocol uses non-overlapping 500 bp tiles, with positive labels for tiles that overlap the centre of the transcription start site and negative labels for all remaining tiles. @BULLET 1B: this protocol is similar to 1A except it uses the RefGene set as a reference instead of CAGE. The tiles overlapping the start of the gene are labelled +1, the tiles that overlap the gene but not the gene start are labelled −1 and the remaining tiles are discarded. @BULLET 2A: this is a distance-based validation with the (pre-clustered) CAGE dataset as a reference. A prediction is deemed correct if it is within 500 bp from one of the 180 413 clusters obtained by grouping 4 874 272 CAGE tags (<ref type="bibr" target="#b2">Abeel et al., 2009</ref>, Section 2.1). For this and the following test, we have associated the RSV prediction for every tile with the centre of the tile, which is obviously suboptimal. @BULLET 2B: according to<ref type="bibr" target="#b2">Abeel et al. (2009)</ref>: 'this is a modification of protocol 2A to check the agreement between transcription start region (TSR) predictions and gene annotation. This method resembles the method used in the EGASP pilot-project (<ref type="bibr" target="#b3">Bajic, 2006</ref>).'</p><p>The results are summarized in<ref type="figure" target="#tab_2">Table 2</ref>, where we compare them to a subset of top performers reported by (<ref type="bibr" target="#b2">Abeel et al., 2009</ref>,<ref type="figure" target="#tab_2">Table 2</ref>). Only 1 of the 17 dedicated algorithms they evaluated— the supervised learning-based ARTS—performed better then our classifiers in terms of overall PPP score [the harmonic mean of four individual scores for tests 1A-2B introduced in<ref type="bibr" target="#b2">Abeel et al. (2009)]</ref>, and only three additional algorithms have shown performance better or equal to our predictors on any individual test. This is unexpected as those dedicated algorithms used a lot of special information other than the local raw DNA sequence; some of which were developed using carefully selected positive and negative examples covering the whole genome rather than only a small subset of it, as in the case of our RSV training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Self-consistency tests</head><p>The PR curves for all four predictors on three datasets are shown in<ref type="figure" target="#fig_1">Figure 1</ref>. The subplots A and B show results for the genomewide tests on Pol-II (<ref type="bibr" target="#b14">Rozowsky et al., 2009</ref>) and RefSeq database, respectively, while the third subplot, C, uses the restricted dataset RefSeqEx (covering ∼ 1/20 of the genome). The PRC curves on each subplot are very close to each other. Thus, RSV Po2 , RSV RfG , RSV Ex and also ARTS show very similar performance on allWe show the results for ProSOM (<ref type="bibr" target="#b0">Abeel et al., 2008a</ref>), EP3 (<ref type="bibr" target="#b1">Abeel, 2008b</ref>), Eponine (<ref type="bibr" target="#b8">Down and Hubbard, 2002</ref>) and ARTS. The results are sorted according to the PPP score, which is the harmonic mean of the four individual scores giving an overall figure of merit. All results better than our ChIP-Seq developed model RSV Po2 are marked in bold face; apart from ARTS there are only the two such results, both with the Eponine algorithm. The results for the remaining 13 algorithms have worse performance than every RSV for tests 1A–2B and can be found in<ref type="bibr" target="#b2">Abeel et al. (2009,</ref><ref type="figure" target="#tab_2">Table 2</ref>). benchmarks despite being trained on different datasets. However, there are significant differences in those curves across different testsets, with the curves for subplot C being much higher with visibly larger areas under them than for the other two cases— i.e. for the genome-wide tests. However, this does not translate to statistical significance. The background colour shows stratification of the precision–recall plane according to statistical significance— i.e. the calibrated precision CP(p,ρ) defined by</p><p>(4)—for which we have used the same colour scheme on all figures. We observe that curves in subplot A run over much more significant regions (closer to red) than the curves in C, with B falling in between. This is due to the following: in case A, we are detecting n + ∼ 160K samples in the background n − ∼ 11M samples. Thus, it is much harder task to achieve a particular level of precision for a particular recall than in case C, which deals with 'only' one-quarter of the positive samples, n + ∼ 43K, embedded into the 20-times smaller background of n − ∼ 550K negative cases. Note also that the most significant loci are different from the loci with the highest precision. In terms of<ref type="figure" target="#fig_1">Figure 1A</ref>and the RSV Po2 predictor, it means that the precision p ∼ 58.2% achieved at recall ρ ∼ 1% with CP ∼ 2.1K is far less significant than p ∼ 25% achieved at ρ ∼ 38%, which reaches a staggering CP ∼ 58.4K. To further quantify impact of the test data—i.e. the differences between genome-wide analysis and restriction to the exonic regions—we have combined in<ref type="figure" target="#fig_3">Figure 2</ref>the different benchmark sets for which we have evaluated the three metrics PRC, ROC and CPRC. The main difference between<ref type="figure" target="#fig_1">Figures 1 and 2</ref>is that, for clarity, in the latter figure we show for each RSV predictor the genome-wide test results only for annotations used in the training the predictor (on chromosome 22)—i.e. we do not show cross-dataset testing results as in<ref type="figure" target="#fig_1">Figure 1</ref>. In<ref type="figure" target="#fig_3">Figure 2A</ref>, we observe that PRC for RefGeneEx clearly dominates the other curves. The curves for RSV Po2 and ARTS Po2 seem to be much poorer, which is supported by the ROC curves in<ref type="figure" target="#fig_3">Figure 2C</ref>. However, the plots of CPRC in<ref type="figure" target="#fig_3">Figure 2B</ref><ref type="figure" target="#tab_3">Table 3</ref>shadings in<ref type="figure" target="#fig_1">Figure 1</ref>are now translated into the set of curves which clearly differentiate between the different test benchmark sets, allocating higher significance to the more challenging benchmarks. Some of those differences are also captured numerically in<ref type="figure" target="#tab_3">Table 3</ref>. We list here the area under the curves, auPRC, auCPRC and auROC, as well as the maximum calibrated precision max(CP) with the corresponding values of precision and recall. We list values for RSV classifiers and corresponding tests for ARTS. The most significant values are shown in boldface. The performance of RSV and ARTS are remarkably close, with ARTS slightly prevailing on the smallest test set RefGeneEx, which is the closest to the training set used for ARTS training, while RSV predictors are better on the two genome-wide benchmarks. However, those difference are minor, with the most striking observation being that all the classifiers are performing so well in spite of so many differences in their development. This should be viewed as a success for supervised learning which could robustly capture information hidden in the data (in a tiny fraction, 1/60th of the genome in the case of RSV). We observe that max(CP) is achieved by RSV Po2 for precision 25% and recall 38% positive samples out of n + = 160K. This corresponds to compressing n + r = 61K target patterns into the topscored n r = 243K samples out of n = 10.7M. In comparison, the top CP results for ARTS on RefGeneEx data resulted in compression of n + r = 25.3K of positive samples into the top scored n r = 47K out of a total of n = 0.59M. Note that in the test on RefGene the results are more impressive than for RefGeneEx: roughly the same number of positive samples n + = 23.4K was pushed into the top n r = 123K out of a total of n = 10.6M, which is ∼ 20 time larger. Note that<ref type="figure" target="#fig_3">Figure 2C</ref>shows that ROC is not discriminating well between performance of different predictors in the critical regimes of the highest precision, which inevitably occurs for low recall (ρ&lt;0.5). Thus, ROC and auROC have a limited utility in the genome-wide scans with highly unbalanced class sizes. Note also that the better precision at low recall shown by ARTS Po2 compared with RSV Po2 in<ref type="figure" target="#fig_1">Figure 1A</ref>,<ref type="figure" target="#fig_3">Figure 2A</ref>and<ref type="figure" target="#fig_3">Figure 2C</ref>did not translate to significantly better CP in<ref type="figure" target="#fig_3">Figure 2B</ref>. The better performance of RSV Po2 for higher recall has turned out to be much more significant resulting in higher auCPRC in<ref type="figure" target="#tab_3">Table 3</ref>. It is worth noting that the results for RSV Po2 and ARTS Po2 are not completely comparable as ARTS was trained on RefGene and not on the PolII labels and used more information, but was specifically aimed at the finer 50 bp resolution. Training ARTS on the Pol-II labels is not straightforward as the spatial structure of the DNA is not readily available and many Pol-II peaks are very wide, lacking the precision of RefGene TSS location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pol-II binding data</head><formula>n + r 61K/</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">A control experiment for STAT1</head><p>As we have stated already, the application of RSV predictors to assess different peak calling routines for STAT1 ChIP-Seq data [ENCODE data, published by<ref type="bibr" target="#b14">Rozowsky et al. (2009)]</ref>was presented by<ref type="bibr" target="#b13">Kowalczyk et al. (2010)</ref>, with a few small differences:<ref type="bibr" target="#b13">Kowalczyk et al. (2010)</ref>used non-overlapping tiles, the analysis was based purely on (un-calibrated) PRCs and peaks other than those identified in<ref type="bibr" target="#b14">Rozowsky et al. (2009)</ref>were used. In contrast in this article, we use only the original peak calls of<ref type="bibr" target="#b14">Rozowsky et al. (2009)</ref>for training our predictor RSV STAT 1 on chromosome 22 followed by testing on the whole genome. We also compare its performance against a number of position weight matrices (PWM) available for STAT1 from the TRANSFAC and JASPAR databases. Thus, our main novel contribution is the quantification of the performance of RSV STAT 1 in terms of CPR and benchmarking against the PWMs. Note that the global scans by PWMs, as well as the detection of 'weakly-binding' sites, are of direct interest for in silico cisregulatory module detection, so in this context the performance assessment of predictive models outside of the highest precision peaks is important. The ChIP-Seq dataset of<ref type="bibr" target="#b14">Rozowsky et al. (2009)</ref>for STAT1 consists of 36 998 peaks of varying sizes, between 1 bp and 86 514 bp with median 425 bp. Similar plots to those shown previously for RSV STAT 1 are shown in<ref type="figure">Figure 3</ref>. For a PWM scan, we allocated to each 500 bp tile the maximal score achieved by sliding the PWM over each base. We see that RSV STAT 1 dominates all PWMs apart from a few highly accurate peaks, which turned out to be statistically insignificant due to small recall (see CPRC plots in<ref type="figure">Figure 3B</ref>). This indicates that some PWMs are highly tuned to some small subclasses of binding sites, while RSV is capable of learning more global characteristics. Note, the performance of some PWMs is on the level of random ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>In this article, we aimed to demonstrate that ChIP-Seq results can be used to develop robust predictors by training on a small part of the annotated genome and then testing on the remainder, primarily for the purpose of cross-checking the consistency of the ChIP-Seq results and also for novel genome annotation. As a proof of principle, we have chosen two ENCODE ChIP-Seq datasets for binding of the transcription factor STAT1 and the Pol-II complex. STAT1 experiments have shown that RSV models are superior in learning global patterns compared with standard PWM-based approaches. For Pol-II, where PWMs are not applicable, we have compared against the best-of-class in silico TSS predictors ARTS as TSS is closely related to Pol-II binding. Though ARTS is our focus as a baseline, we also benchmarked against 16 other specialized algorithms using the methods of<ref type="bibr" target="#b2">Abeel et al. (2009)</ref>. Our predictors are created by a generic algorithm and not a TSS specific procedure Page: 1616 1610–1617with customized problem-specific input features; for instance, we do not take into account the directionality of the strands, which may improve performance, as such information is not available from empirical ChIP-Seq data. Nevertheless, we have demonstrated that the lack of such information does not prevent the development of accurate classifiers on-par with dedicated tools such as ARTS at the 500 bp resolution. For our aim of developing a generic and robust technique for genome annotation, ARTS, originally intended for higher 50 bp resolution, is too specialized and overly complex; indeed, ARTS uses five different sophisticated kernels—i.e. custom-developed techniques for feature extraction from DNA neighbourhood of ±1000 bp around the site of interest. This includes two spectrum kernels comparing the k-mer composition of DNA upstream (the promoter region) and down stream of the TSS, the complicated weighted degree kernel to evaluate the neighbouring DNA composition, and two kernels capturing the spatial DNA configuration (twisting angles and stacking energies). Consequently, ARTS is very costly to train and run: it takes ∼ 350 CPU hours (<ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>, Sec. 3.1) to train and scan the whole genome. Furthermore, for training the labels are very carefully chosen and cross-checked in order to avoid misleading clues (<ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>, Sec. 4.1). In contrast, our generic approach is intended to be applied to novel and less-studied DNA properties, thus we do not assume the availability of prior knowledge. Consequently, our model uses only standard and generic genomic features and all available labelled examples in the training set. It uses only a 137-dimensional, 4merbased vector of frequencies in a single 500 bp tile, which is further simplified using feature selection to ∼ 80 dimensions. This approach is generic and the training and evaluation is accomplished within 4 CPU hours (<ref type="bibr" target="#b4">Bedo et al., 2009</ref>We stress again that as stated in Section 3.1, for the sake of fairness, we have used not only ChIP-Seq trained RSV models, but also two different models RSV RfG and RSV Ex , which are trained using RefGene annotations only, which were used for training ARTS. However, while ARTS used all RefGene annotations available in hg16 resulting in n + = 8.5K positive and n − = 85K negative examples, we have used a much smaller training set, namely the sites residing on chromosome 22. In the case of RSV Ex , which is by design the closest to the annotation used in the original ARTS publication (<ref type="bibr" target="#b15">Sonnenburg et al., 2006</ref>), this results in only n + = 1K positive and n − = 12K negative examples, which is more than seven times less than ARTS' training used. Yet, as we see in<ref type="figure" target="#fig_1">Figure 1C</ref>and 2, the performance of ARTS and RSV Ex tested against RefGeneEx annotations are virtually equivalent. The same equivalent performance was seen testing RSV RfG on our RefGene annotation for hg18. Finally, note that model interpretation is very feasible as our RSV models are linear combinations of simple k-mer frequencies. This creates the potential for novel insights into the molecular mechanisms underpinning the phenomena of interest. We have not yet explored the utility of model interpretation but consider it an important area for future research. We have found that the ROC (<ref type="figure" target="#fig_3">Fig. 2C</ref>) do not discriminate well between the performance of different predictors with high precision, which inevitably occurs for low recall (ρ&lt;0.5). Similar features are shown by the ROC curves in<ref type="figure" target="#fig_3">Figure 2C</ref>for the high specificity regions. Thus, ROC and auROC are not informative for genomewide scans under highly unbalanced class sizes (<ref type="bibr" target="#b6">Davis and Goadrich, 2006</ref>). The same applies to enrichment scores (<ref type="bibr" target="#b16">Subramanian et al., 2005</ref>) and consequently Kolmogorov–Smirnov statistic (see the Section 6 in Supplementary Materials ). One curious point of note is the sharp decline in precision that can be observed as recall → 0 in<ref type="figure" target="#fig_1">Figures 1 and 2A</ref>. This can only be caused by the most confidently predicted samples being negatively labelled. One hypothesis is that these are in fact incorrectly labelled true positives. Support for this may be that the decline is not observable when using the exon-restricted negative examples in<ref type="figure" target="#fig_1">Figure 1C</ref>. This hypothesis has been confirmed by testing for human and mouse against annotations by (un-clustered) CAGE tags and is the focus of a follow-up paper. One of the most intriguing outcomes is the very good performance of the RSV Po2 predictor in the tests on the RefGene and RefGeneEx datasets and also on the benchmark of<ref type="bibr" target="#b2">Abeel et al. (2009)</ref>. After all, the RSV Po2 was trained on data derived from broad ChIP-Seq peak ranges on chromosome 22 only. This ChIP-Seq data (Rozowsky Page: 1617 1610–1617<ref type="bibr">et al., 2009</ref>) was derived from HeLa S3 cells (an immortalized cervical cancer-derived cell line) which differ from normal human cells. Those peaks should cover most of the TSS regions but, presumably, are also subjected to other confounding phenomena [e.g. Pol-II stalling sites (<ref type="bibr" target="#b9">Gilchrist et al., 2008)]</ref>. In spite of such confounding information, the training algorithm was capable of creating models distilling the positions of the carefully curated and reasonably localized TSS sites in RefGene. This warrants a follow-up investigation, which we intend to conduct in the near future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.Bedo and A.Kowalczyk</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pol-II binding data</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>[13:</head><figDesc>14 14/5/2011 Bioinformatics-btr263.tex]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Comparison of the PRCs grouped by test sets, with subfigures ordered in the descending order of (n + ,n − )-sizes: (A) for Pol-II (Rozowsky et al., 2009), (B) RefSeq TSS database and (C) RefSeqEx databases; see Table 1 for summary and Section 3.1 for details. We plot the PRCs for four different predictors as in Section 3.2. The background shading shows calibrated precision, CP(prec,recall), see (4); values in (A) and (B) are clipped at maximum 9×10 4 for better visualization across all figures (we use the same colour scale across them).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Comparison of three methods of evaluation for six different predictors: three versions of RSV developed as specified in Table 3 and ARTS tested on three datasets, as indicated by subscripts. (A) PRC; (B) CPRC; (C) ROC curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>tell a completely different story. The differences shown by the colour Page: 1615 1610–1617</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>.</head><figDesc>Numerical summary of the performance curves for the six predictors compared in Figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig</head><figDesc>Fig. 3. Comparison of RSV STAT1 and six scans of human DNA using different PWMs for STAT1 (M00224, M00492, M00496 and M01260 from TRANSFAC and MA0137.2 from JASPAR databases). (A) PRC; (B) CPRC; (C) ROC curves. There are n + = 211K positive and n − = 10.5M negative tiles in this case and the expected precision for random guessing is ∼ 2% which is approximately the level for some PWMs in subplot A. A numerical summary is presented in Supplementary Table S2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Dataset summary</figDesc><table>Label set 
Pol-II 
RefGene 
RefGeneEx 

Training sets for RSV(= intersections with chromosome 22) 
n + 
3.2K 
1.0K 
1.0K 
n − 
140K 
140K 
12K 

Test sets 
n + 
160K 
43K 
43K 
n − 
11M 
11M 
0.55M 
n + /(n + +n − ) 
0.015 
0.0039 
0.072 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>+ denote the precision and the recall. The error of the estimate (5) is between 0 and −log 10 n − r – in practice 1% of CP. More</figDesc><table>2 Derivation details are presented in Section 2 of the Supplementary Material. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>Table 3.</figDesc><table>As usual it is convenient to convert CPRC into a single number for 
easy comparisons. We use two options here: the maximal rise of CPRC 
[max(CP) := max ρ CP(p(ρ),ρ)] </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>A. a trivial case with n + = 2 and n − = 18, and B. a non-trivial case with n + = 200K and n − = 9×10 6 examples. In both cases, let us consider predictors achieving precision p = 50% at recall of ρ = 50%. Which predictor performs better? The priors of the positive classes are 10 and 20%, respectively, hence PE A (50%) = 5 &gt; PE B (50%) = 2.5 indicating A is the superior predictor. However, with a uniform random shuffling of the data, we achieve precision (p A ≥ 50%) ≡ (PE A ≥ 5) at p = 50% with probability &gt; 25%, while the analogous probability for p B ≥ 50% and (PE B &gt; 2.5) ≡ (p = 50%) is ≤ CP ∼ 10 −97408 .</figDesc><table>Remark 2.1. One simple method for compensating for the differences in 

test sets could be to calibrate the precision–recall curve by dividing it by 
the prior probability of the positive labels [this is the concept of precision 
enrichment (PE) and is discussed more in Section 5 of the Supplementary 
Material]. However, this may be a very bad solution if the test set sizes are 
different. 
To clarify the point, let us consider the following two extreme examples: 

Thus, the performance of B, 
being practically impossible to match or improve by chance, is superior. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 2. Results of testing our predictors using the four benchmarks protocols of Abeel et al. (2009) and then comparing against 17 algorithms they evaluated.</figDesc><table>Name 
1A 
1B 
2A 
2B 
PPP score 

Our results using software of Abeel et al. (2009) 
RSV Po2 
0.18 
0.28 
0.42 
0.55 
0.30 
RSV RfG 
0.18 
0.28 
0.41 
0.56 
0.30 
RSV Ex 
0.18 
0.28 
0.41 
0.56 
0.30 

Results in Abeel et al. (2009) with performance ≥ any RSV 
ARTS 
0.19 
0.36 
0.47 
0.64 
0.34 
ProSOM 
0.18 
0.25 
0.42 
0.51 
0.29 
EP3 
0.18 
0.23 
0.42 
0.51 
0.28 
Eponine 
0.14 
0.29 
0.41 
0.57 
0.27 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>and auROC denote the areas under the PRC, CPRC and ROC curves in Figure 2A, C &amp; D, in the format RSV dataSet /ARTS dataSet , respectively.</figDesc><table>54K 
24.3K/24.1K 
24.1K/25.3K 
n r 
243K/177K 
123K/120K 
47K/53K 

n 
10.7M 
10.7M 
0.59M 

The auPRC, auCPRC We 
show also max(CP), see (4) with the corresponding values of the arguments, i.e. 
precision and recall. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>). The success of such a simple model is surprising and one may hypothesize about the reasons: @BULLET Robust training procedure: this includes the primal descent SVM training and using auPRC rather than auROC as the objective function for model selection;</figDesc><table>@BULLET Simple, low dimensional feature vector; 

@BULLET Feature selection/reduction. 

</table></figure>

			<note place="foot">© The Author 2011. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="1"> Note that our aim here is to approximately locate TSS (at a resolution of 500 bp) but over the whole genome. This could be followed by a more precise location detection for specific subclasses of core promoters, see for instance Zhao et al. (2007) and Wang et al. (2008). In their terminology, we focus on Stage 1 (approximate position detection) while they focus on Stage 2 (precise refinement), so our results are not comparable.</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3"> CAGE (Cap Analysis of Gene Expression) is a high-resolution technology for mapping TSS (de Hoon and Hayashizaki, 2008; Kodzius et al., 2006)</note>

			<note place="foot" n="5"> CONCLUSIONS As a proof of feasibility for the proposed genome annotation test, we have shown that our generic supervised learning method (RSV ) is capable of learning and generalizing from small subsets of the genome (chromosome 22) at a 500 bp resolution. The RSV method has shown better performance than available PWMs for the in silico detection of STAT1 binding sites, and at this resolution RSV was on par with the dedicated in silico TSS predictor ARTS on several datasets tested, including a recent Pol-II ENCODE ChIP-Seq dataset (Rozowsky et al., 2009). Moreover, using the benchmark protocols of Abeel et al. (2009) we have shown that our classifier outperformed 16 other dedicated algorithms for TSS prediction. For analysis and performance evaluation of highly classimbalanced data typically encountered in genome-wide analysis, we recommend plain and calibrated precision-recall curves (PRC and CPRC). Each can be converted to a single number summarizing the overall performance by computing the AUC. The popular ROC curves, the area under the ROC, enrichment scores (ES) and KSstatistics were uninformative for whole genome analysis as they were unable to discriminate between performance under the critical high precision setting. Finally, we must stress that the end goal was to create a framework for generic annotation extension and self-validation of ChIP-Seq datasets. This is why it was important to have a generic robust supervised learning algorithm as the core, rather than a method tailored for a specific application, and a meaningful method of performance evaluation. Furthermore, the idea of self-validation and developed metrics can be applied to any learning method apart from RSV, provided it is able to capture generic relationships between the local sequence and the phenomenon of interest.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank Izhak Haviv, Bryan Beresford-Smith, Arun Konagurthu, Geoff Macintyre, Qiao Wang, Terry Caelli and Richard Campbell for help in preparation of this manuscript, reading drafts and helpful feedback. J.B. developed and implemented the supervised learning methodology and ran all experiments. A.K. developed and implemented the evaluation methodology. Both J.B. and A.K. co-authored this manuscript.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">ProSOM: core promoter prediction based on unsupervised clustering of DNA physical profiles</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Abeel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="24" to="31" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Generic eukaryotic core promoter prediction using structural features of DNA</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Abeel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="310" to="323" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Toward a gold standard for promoter prediction evaluation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Abeel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="313" to="320" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Performance assessment of promoter predictions on ENCODE regions in the EGASP experiment</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bajic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3" to="4" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Suppl. . 1</note>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple SVM based whole-genome segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bedo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Preced. [Epub ahead of print</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Stem cell transcriptome profiling via massive-scale mrna sequencing</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Cloonan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="613" to="619" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">The relationship between Precision-Recall and ROC curves</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Davis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Goadrich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning, ICML &apos;06</title>
		<meeting>the 23rd International Conference on Machine Learning, ICML &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep cap analysis gene expression (CAGE): genome-wide identification of promoters, quantification of their expression, and network inference</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>De Hoon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Hayashizaki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biotechniques</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="627" to="628" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Computational detection and location of transcription start sites in mammalian genomic DNA</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Down</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hubbard</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="458" to="461" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">NELF-mediated stalling of Pol II can enhance gene expression by blocking promoter-proximal nucleosome assembly</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Gilchrist</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genes Dev</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1921" to="1933" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">The meaning and use of the area under a receiver operating characteristic (ROC) curve</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">A</forename>
				<surname>Hanley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">J</forename>
				<surname>Mcneil</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="29" to="36" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Global changes in STAT target selection and transcription regulation upon interferon treatments</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Hartman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genes Dev</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2953" to="2968" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">CAGE: cap analysis of gene expression</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kodzius</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="211" to="222" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">The Poisson Margin Test for normalisation free significance analysis of NGS data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kowalczyk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lect. Notes Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">6044</biblScope>
			<biblScope unit="page" from="297" to="309" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">PeakSeq enables systematic scoring of ChIP-seq experiments relative to controls</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Rozowsky</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="66" to="75" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Arts: accurate recognition of transcription starts in human</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Sonnenburg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="423" to="480" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Subramanian</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="15545" to="15550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">High-resolution human core-promoter prediction with CoreBoost_HM</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="266" to="275" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Boosting with stumps for predicting transcription start sites</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Zhao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>