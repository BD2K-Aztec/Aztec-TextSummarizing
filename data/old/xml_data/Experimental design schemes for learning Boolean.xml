
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Experimental design schemes for learning Boolean network models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Nir</forename>
								<surname>Atias</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<postCode>69978</postCode>
									<settlement>Tel Aviv</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Michal</forename>
								<surname>Gershenzon</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<postCode>69978</postCode>
									<settlement>Tel Aviv</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Katia</forename>
								<surname>Labazin</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<postCode>69978</postCode>
									<settlement>Tel Aviv</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Roded</forename>
								<surname>Sharan</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<postCode>69978</postCode>
									<settlement>Tel Aviv</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Experimental design schemes for learning Boolean network models</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="445" to="452"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu451</idno>
					<note>BIOINFORMATICS</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>Contact: roded@posttauacil</keywords>
			</textClass>
			<abstract>
				<p>Motivation: A holy grail of biological research is a working model of the cell. Current modeling frameworks, especially in the protein–pro-tein interaction domain, are mostly topological in nature, calling for stronger and more expressive network models. One promising alternative is logic-based or Boolean network modeling, which was successfully applied to model signaling regulatory circuits in human. Learning such models requires observing the system under a sufficient number of different conditions. To date, the amount of measured data is the main bottleneck in learning informative Boolean models, underscoring the need for efficient experimental design strategies. Results: We developed novel design approaches that greedily select an experiment to be performed so as to maximize the difference or the entropy in the results it induces with respect to current best-fit models. Unique to our maximum difference approach is the ability to account for all (possibly exponential number of) Boolean models displaying high fit to the available data. We applied both approaches to simulated and real data from the EFGR and IL1 signaling systems in human. We demonstrate the utility of the developed strategies in substantially improving on a random selection approach. Our design schemes highlight the redundancy in these datasets, leading up to 11-fold savings in the number of experiments to be performed. Availability and implementation: Source code will be made available upon acceptance of the manuscript.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Network analysis tools have become over the last decade the method of choice for studying genome-wide data, yielding important insights into gene function, interaction and evolution. Nevertheless, most of these tools, especially in the protein–protein interaction domain, have been limited to pure topological analysis of the pertaining networks, calling for stronger and more expressive network models (<ref type="bibr" target="#b6">Huang and Fraenkel, 2009;</ref><ref type="bibr">YegerLotem et al., 2009;</ref><ref type="bibr" target="#b21">Yosef et al., 2009</ref>). Recently, Boolean network modeling has been successfully attempted at signaling networks, yielding a qualitative functional understanding of signaling pathways and the ability to predict their behavior under different perturbations and environmental cues (<ref type="bibr" target="#b14">Mitsos et al., 2009;</ref><ref type="bibr" target="#b16">Saez-Rodriguez et al., 2009;</ref><ref type="bibr" target="#b18">Sharan and Karp, 2012</ref>). However, because of the sparsity of the currently available data, learning such models de novo remains a formidable task, requiring computational strategies to efficiently prioritize experimental conditions that will best reveal the underlying model. We refer the reader to<ref type="bibr" target="#b9">Karlebach and Shamir (2008)</ref>for a comprehensive survey of Boolean modeling.</p><p>An alternative modeling technique for signaling pathways dynamics based on ordinary differential equations (ODEs) was thoroughly studied (<ref type="bibr" target="#b7">Hughey et al., 2010</ref>). These equations offer a mechanistic chemically based view on the change in the level of cellular species as a function of the levels of their interactors. The dependency of such a detailed modeling on the availability of experimental data has triggered two lines of work of algorithmic experimental design (<ref type="bibr" target="#b11">Kreutz and Timmer, 2009</ref>): the first addressing the challenge in parameter estimation (<ref type="bibr" target="#b1">Balsa-Canto et al., 2008;</ref><ref type="bibr" target="#b2">Bandara et al., 2009</ref>) and the second addressing the model identification problem (<ref type="bibr" target="#b0">Apgar et al., 2008;</ref><ref type="bibr" target="#b5">Harrington et al., 2012;</ref><ref type="bibr" target="#b10">Kremling et al., 2004;</ref><ref type="bibr" target="#b13">M elyk uti et al., 2010</ref>). Nevertheless, the application of this formalism to largescale modeling is limited by the large number of required parameters whose estimation is difficult (<ref type="bibr" target="#b4">Gutenkunst et al., 2007</ref>). In contrast to the relatively rich literature on ODEs, experimental design algorithms for Boolean networks are scarce.<ref type="bibr" target="#b8">Ideker et al. (2000)</ref>proposed an experimental design scheme involving two principal entities: a predictor that generates models given an experimental data and a chooser that selects the next experiment to be conducted based on information theoretic principles. These two entities were used in an iterative manner to learn a genetic network from gene expression data. A similar entropy-based criterion was used by<ref type="bibr" target="#b19">Szczurek et al. (2009)</ref>to learn regulatory relations downstream to a given signaling pathway.<ref type="bibr" target="#b3">Barrett and Palsson (2006)</ref>proposed an experimental design algorithm for learning regulatory networks that maximizes at each step an estimate of the expected information gain. In the context of signaling networks, we have previously sketched a maximum entropy-based experimental design scheme (<ref type="bibr" target="#b18">Sharan and Karp, 2012</ref>), but the scheme was not completely defined nor its utility was tested. Here we propose two comprehensive experimental design strategies. The first realizes the maximum entropy principle to guide the selection of experiments in the context of Boolean networks learning. The second strategy learns de novo experiments that maximize the disagreement between current best-fit models, a criterion that we term maximum difference. For this optimization task, we propose a novel algorithm that considers the entire space of candidate models and possible experiments. We implement and test these strategies on simulated and real experimental data using two detailed Boolean models for EGFR and IL1 signaling. We show that both strategies can be used to prioritize experiments and discover redundancies among them, considerably outperforming a random-choice scheme. In particular, we find that the maximum difference criterion is superior to all other approaches in all the settings we tested, leading to 5–11fold savings in the number of experiments to be performed with respect to the available experiment sets. *To whom correspondence should be addressed. ß The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data retrieval</head><p>To evaluate a design scheme, we applied it to prioritize experiments in the context of two signaling systems in human: EGFR signaling, which regulates cellular growth, proliferation, differentiation and motility; and IL1 signaling, which is involved in coordinating the immune response upon bacterial infection and tissue injury. Both systems are well studied, and detailed manual models exist for them. In particular,<ref type="bibr" target="#b17">Samaga et al. (2009)</ref>have constructed a comprehensive Boolean model of the EGFR system, which contains 112 molecular species and their associated Boolean functions;<ref type="bibr" target="#b15">Ryll et al. (2011)</ref>have created a Boolean model of the IL1 system with 121 molecular species. We retrieved these models from the CellNetAnalyzer repository (http://www.mpi-magdeburg.mpg.de/proje cts/cna/repository.html). To learn logical models for these systems, we used data published by the above authors on the activity (phosphorylation) levels of certain proteins under different cellular conditions. Specifically, Samaga et al. measured within the EGFR system the activity levels of 11 proteins under 34 distinct conditions in Hep2G cells. Similarly, Ryll et al. measured within the IL1 system the activity levels of nine proteins under 14 distinct conditions in primary hepatocytes. Following Ryll et al. (2011) and<ref type="bibr" target="#b17">Samaga et al. (2009)</ref>, we focused our analysis on the measurements at the 30 min time point, representing the early response of each system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experimental design criteria</head><p>Previously, an optimal algorithm for learning Boolean models given experimental data was introduced by Sharan and Karp (2012). However, because of the sparsity of experimental data, the learning procedure yields many models, each explaining the data equally well. To overcome this difficulty in model identification, additional experimental data are needed. Here, we studied two strategies to elucidate informative experiments: the first based on a maximum entropy criterion and the other based on a novel criterion, termed maximum difference criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Maximum entropy criterion</head><p>In information theory, the entropy statistic is a standard scoring method that quantifies the information encoded in a given random variable, where higher entropy implies a more informative distribution. An experimental design scheme based on the maximum entropy approach has been previously studied in different settings, such as the identification of regulatory interactions (<ref type="bibr" target="#b8">Ideker et al., 2000</ref>) and regulatory functions downstream to signaling pathways (<ref type="bibr" target="#b19">Szczurek et al., 2009</ref>). We have sketched a maximum entropy-based strategy for experimental design of Boolean network (<ref type="bibr" target="#b18">Sharan and Karp, 2012</ref>) but did not implement or demonstrate the utility of this approach. Here we implement an experimental design strategy based on a maximum entropy approach. At the heart of this strategy is the evaluation of the entropy of a candidate experiment e according to the predicted response of different models. Formally, let r e be the response vector of some model to the experimental conditions set in e. Denote by pðr e Þ the probability of observing the response r e across all the candidate models. Then, the entropy of the experiment is given by</p><formula>EntropyðeÞ= À X r pðr e Þ Á log pðr e Þ ð 1Þ</formula><p>The maximum entropy strategy prioritizes the experiment with the highest entropy from a set of candidate experiments. Note that computing the entropy requires the calculation of pðr e Þ, the distribution of responses over all models that fit the currently available data well. However, enumeration of all such models is intractable. Previous approaches assumed that a set of possible models is given or that the model space can be sampled. In this work, we adopt the latter approach and sample up to a fixed number of best-fit models. Specifically, we solve an integer linear program (ILP) to infer a best-fit model and use the ILP solver to enumerate multiple solutions. The actual number of solutions is varied to study its impact on the performance of our strategy (see below). Other sampling approaches use Monte Carlo simulations; however, these are often computationally intensive and require large running times (<ref type="bibr" target="#b11">Kreutz and Timmer, 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Maximum difference criterion We propose and implement an</head><p>intuitive criterion for experimental design strategy based on maximum difference. This criterion is defined as the Hamming distance between two Boolean response vectors. Formally, given an experiment e, let r M1;e ; r M2;e be the response vectors of two models to the experimental conditions defined in e. Then, the difference criterion is defined bypreviously experimented with an approach based on similar intuition in the context of ODE models. The maximum difference strategy prioritizes experiments resulting in the highest difference between a pair of models that equally agree with the available experimental data. While considering the difference induced by only two models, this criterion is amenable to efficient computation via an integer linear programming formulation, allowing us to learn a de novo experiment that maximizes this criterion over all optimal models, eliminating the need to enumerate models or to suggest candidate experiments a priori as in the maximum entropy approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Maximum difference learning algorithm</head><p>We develop an algorithm to learn an experiment that maximizes the difference criterion over the entire space of optimal models. The input to the algorithm consists of a directed acyclic network over a set of nodes V and a set of experiments E whose outcome is already known. The algorithm uses the learning algorithm by Sharan and Karp (2012) as a building block and its outline is as follows (see<ref type="figure">Fig. 1</ref>): (i) Duplicate the ILP of Sharan and Karp so that each copy holds a distinct model; these models (M 1 , M 2 ) are used to evaluate the maximum difference criterion. (ii) Use the term for the objective as defined in the Sharan and Karp formulation and its corresponding optimal value (OPT) to further constrain the copies of the program to describe solutions that optimally agree with the experimental data. (iii) Add to the resulting program new variables and corresponding constraints to represent the experiment to learn ( ^ e) as well as its readouts under each copy (r M1; ^ e ; r M2; ^ e ). Finally, (iv) define a new objective to maximize the difference between readouts, as per Equation (2). An optimal solution to this linear program details a maximum difference experiment. Moreover, to maximize the objective, the corresponding variables of the duplicated programs describe two different models. uses constraints to ensure that the activity level of a species v is (i) compatible with the activity levels of its predecessors and its Boolean function; or (ii) determined by the experimental conditions so that a e;v = I e ðvÞ 8v 2 I e , where I e (v) is the activity level of species v as under the experimental conditions of e. To generate a program for learning a maximum difference experiment, we first duplicate the variables and constraints in the above program and add the constraint c T x OPT to each copy, where OPT is the value of the objective for an optimal solution to the original program. Thus, the integral variables t ð1Þ v and t ð2Þ v represent two models, each of which is optimal with respect to the available experimental data. We also introduce the variables a ð1ÞThe complete ILP is as follows (the constraints for Boolean function adherence are omitted for brevity):We use the restricted version of the algorithm in the application to the real datasets where the set of experimental conditions was predefined. We also note that, in a similar fashion, additional constraints may be imposed on the algorithm to exclude experiments that are hard or impossible to conduct in a real setting. Finally, we solve both the restricted and unrestricted versions of the ILP using CPLEX.</p><formula>min X v2V Àja ð1Þ ^ e;v À a ð2Þ</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">If</head><p>then operator using ILP Our construction uses 'if-then' clauses to model relationships between constraints. These may be expressed as follows:</p><p>If a T 1 x b 1 then a T 2 x b 2 ð15Þ or, equivalently, by</p><formula>a T 1 x4b 1 À Á ∨ a T 2 x b 2 À Á ð16Þ</formula><p>To express this operator using ILP, let y 2 f0; 1g be a binary variable and C 1 , C 2 be two large constants and consider the following constraints:</p><formula>a T 1 x4b 1 À C 1 Á y ð17Þ a T 2 x b 2 +C 2 Á ð1 À yÞ ð 18Þ</formula><p>when y = 0, the first constraint holds while a T 2 x is, in practice, free to assume any feasible value; similarly, when y = 1, the second constraint must hold, and a T 1 x is not constrained. In practice, we model 'if-then' operators and absolute value terms using the CPLEX built-in facilities.<ref type="figure">Fig. 1</ref>. Overview of the experiment learning algorithm. We start from an ILP (<ref type="bibr" target="#b18">Sharan and Karp, 2012</ref>) that learns a Boolean network model M whose readouts have OPT disagreements with the experimental data. In our formulation, this program is duplicated so that two models M 1 and M 2 are learned simultaneously. The models are further constrained so that: they both have at most OPT disagreements with the experimental data and are therefore optimal and that they both simulate an unknown experiment ^ e. The objective optimizes the difference between the readouts of the models (r M1; ^ e ; r M2; ^ e , resp.) as per Equation (2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>i447</head><p>Experimental design for Boolean networks</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Simulation process</head><p>For a given signaling system, let m* be a Boolean model that is known in advance, and let E v be a set of experiments for validation. Given an experimental design strategy and some initial subset of experiments E 0 , we measured the performance of the strategy by the number of additional experiments it used until a model whose predictions perfectly match the validation dataset (E v ) was learned. We call such a model an optimal model. We summarize our results using the third quartile (75th percentile) of the additional experiments distribution, which is robust to outliers in the data. To generate the simulated datasets, we started with the known model m* and a subset of the nodes whose function we wished to learn. We repeatedly simulated experimental data by randomly setting the experimental conditions, i.e. assigning random binary values to a random subset of the nodes and calculating the readouts according to m*. As mentioned above, the validation set, E v , was generated independently from the other sets. Additionally, we generated a different set of experiments, E list , to prioritize out of which the set of initial experiments, E 0 , was selected. The entire set of experiments in E list , but not their readouts, was available to design schemes that prioritize experiments (such as the maximum entropy scheme), whereas only E 0 was available to methods that infer experiments de novo, namely, to the maximum difference scheme and then random control scheme. To ensure a fair comparison between the different methods E list was sufficiently large to uncover an optimal model. To study the different approaches in heterogeneous, yet realistic settings, we varied number of unknown functions in the range 10, 15, 16, 17, 18 and 20 species (the original data contained 16 unknown functions). Similarly, the sets of perturbed and measured species were constrained to a subset of the species of equal size. For our evaluation, we used initial subsets, E 0 , ranging in size from 1 to 8 to account for different amounts of prior knowledge pertaining to the system at hand. Initial subsets for which the learned model performed as well as a model that was derived from the entire dataset were omitted. For each size of the initial subset, up to 30 random subsets were repeatedly sampled from E list , and the third quartile of the number of additional experiments required to construct an optimal model was reported. We repeat these analyses with 10 simulated datasets. To study the effect of the number of available models on the performance of the maximum entropy design, we fixed the number of unknown species to 16 while increasing the number of available models over 10, 30, 50, 70, 100 and up to 200. To evaluate the stopping criteria, once an experiment was chosen, we enumerated such multiple models for all experimental design strategies and stopped when at least one optimal model was found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Significance assessment</head><p>We assess the significance of the hypothesis that one strategy requires less experiments relative to another to arrive at an optimal model using a onesided Wilcoxon paired test as implemented in R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Quartiles standard error</head><p>We estimate the standard error using Maritz–Jarrett standard error estimation method (<ref type="bibr" target="#b12">Maritz and Jarrett, 1978</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental design schemes for Boolean models</head><p>We propose and implement two experimental design schemes for Boolean network models. The first scheme is based on maximum entropy approach, an accepted information theoretic criterion for model selection. Despite its appealing theoretical properties, computing the entropy depends on the challenging task of estimating the distribution of the responses across candidate models and on the availability of a list of candidate experiments. The second scheme, termed maximum difference, is an intuitive and novel criterion maximizing the disagreement between two candidate models. Using an ILP formulation, we optimally solve this model and uncover a de novo experiment maximizing this criterion. Unique to our approach is its ability to implicitly consider all candidate models and experiments alleviating the need to specify them a priori.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation with simulated data</head><p>Given a known Boolean model for a signaling system, an experimental design strategy and an initial set of experiments, we measure the performance of the strategy by the number of additional experiments it uses until an optimal model is learned and report the third quartile of the additional attempts in each dataset. Here, an optimal model is one agreeing with the known model on a set of experiments that were not initially available to the experimental design strategy. The simulation procedure (see Section 2) generated experimental conditions uniformly at random to provide an unbiased sample of the experimental space. In contrast, in real published datasets, the choice of experimental conditions is guided and may impact the relative performance of design schemes. We compared the running times of the maximum difference and maximum entropy strategies when suggesting a single experiment to be conducted (<ref type="figure" target="#fig_3">Fig. 2</ref>). Expectedly, the time of the maximum entropy approach grew with the number of models being enumerated, whereas the performance of the maximum</p><formula>0 2000 4000 6000 8000 10000 0 1 2 3 4 5 Models Running Time (sec) * * * * * o o o o o * * * * * o o o o o * o * o</formula><p>MaxDifference (EGFR) MaxEntropy (EGFR) MaxDifference (IL1) MaxEntropy (IL1)difference approach was not affected by it, underscoring its advantage in handling complex problems that admit (for a given experimental dataset) many optimal solutions. We used the EGFR Boolean model by Samaga et al. and the IL1 model by Ryll et al. to compare the performance of four design strategies: (i) a naive approach choosing experiments at random, (ii) a maximum entropy approach based on a sample of models, (iii) a minimum entropy approach serving as a control and (iv) a maximum difference approach. First, we sought to study the effect that the number of available models has on the performance of the maximum entropybased strategy. Therefore, we applied the above evaluation scheme while increasing the number of models. When the simulated data were generated from the EGFR Boolean network model, we found that when only a handful of models were available, the maximum entropy approach performed worse than randomly choosing an experiment, requiring two additional experiments. However, as more models were available the performance relative to the random approach improved. With 200 models available for the evaluation of the entropy, the performance of this approach was comparable with the maximum difference scheme. In our tests, the maximal margin relative to random was obtained when 50 models were available, leading to an improvement of three experiments (see<ref type="figure">Fig. 3A</ref>). The minimum entropy approach performed worse than all other methods; the performance of the method did not vary much when using 30 models or more. Remarkably, the maximum difference approach significantly outperformed all other methods, across the parameter space (P53:72 Â 10 À16 relative to maximum entropy, the next best method, on 70 models). Notably, the advantage in implicitly considering all optimal models was evident as the performance of the method was constant across the parameter range. We obtained similar results when the simulated datasets were generated using the IL1 signaling model (<ref type="figure">Fig. 3B</ref>). In this case, the maximum entropy approach performed better than the random approach even when only few models were available. Again, only when 200 models where available for the estimation of the entropy criterion the performance of the method was comparable with that of the maximum difference approach. In this dataset, a maximal margin of five experiments relative to random was obtained when 200 models were available. Again, the maximum difference approach outperformed all other methods across the entire parameter space (P51:73 Â 10 À18 relative to maximum entropy on 100 models). Next, we examined the effect of the size of the learning task (i.e. the number of Boolean functions that need to be learned) on the performance of the different methods. To this end, we applied our evaluation scheme while fixing the number of models and varying the number of unknown functions in the range of 10–20, guided by the 16 unknown functions in the EGFR model. When simulating the datasets through the EGFR model, the performance of the maximum entropy approach was closer to the random scheme than to the maximum difference design scheme (<ref type="figure" target="#fig_4">Fig. 4A</ref>). Still, maximum entropy designs were consistently better than random (P51:75 Â 10 À3 for 18 unknown functions) with a margin of two experiments. Additionally, with higher uncertainty, the number of additional experiments grew. For 10 unknown functions the maximum entropy strategy also performed similar to random. However, in this case, the space of possible models was greatly reduced to a point where even the random selection required four experiments for convergence, thus, room for improvement was limited to begin with. Notably, the maximum difference approach significantly outperformed all other methods while increasing the marginal<ref type="figure">Fig. 3</ref>. Sensitivity to the number of available models. The estimation of entropy was dependent on the number of available models. In contrast, the maximum difference learning algorithm optimized over all candidate models. In both panels, the x-axis denotes the number of available models for entropy estimation, and the y-axis denotes the third quartile of the number of experiments required to obtain an optimal model (lower is better). Error bars denote standard error. (A) Simulation with EFGR signaling. (B) simulation with IL1 signaling i449</p><p>Experimental design for Boolean networks gap as the number of functions increased (P59:32 Â 10 À26 relative to maximum entropy for 15 unknown functions). For example, the reduction in required experiments relative to maximum entropy, which was the next best-performing method increased from one experiment for 15 unknown functions to five experiments for 18 unknown functions. A similar behavior was observed when simulating the datasets through the IL1 model. Again, the maximum entropy approach performed significantly better than the random design scheme (P57:71 Â 10 À25 for 20 unknown functions). Still the maximum difference approach was superior to the maximum entropy scheme in all but a single scenario where 17 functions were predicted. Notably, the maximum difference approach required as little as half of the experiments required by the maximum entropy approach, which was the next best method, to converge when running the simulation with 10, 16, 18 and 20 missing functions. Furthermore, the performance of the maximum difference approach was nearly constant regardless of the size of the learning task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Application to real data</head><p>To examine the utility of the different approaches in a more realistic setting, we applied them to the available datasets of phosphorylation measurements under different experimental conditions for the EGFR (34 experiments) and IL1 (14 experiments) systems. We ran the different design strategies with increasing subsets of the data as starting points and measured the number of experiments needed to obtain a model that was as good as the one learned from all the available experiments. The results are depicted in<ref type="figure" target="#fig_6">Figure 5</ref>. In this setting, we could not apply the maximum difference and random strategies in a straightforward manner, as we cannot simulate de novo experiments. Instead, we applied restricted versions of these strategies, allowing them to choose only experiments that were included in the available data. A key difference between the maximum difference and maximum entropy strategies in this setting is that the former implicitly considered all possible models where the later required a sample of models to evaluate the maximum entropy criterion. In both datasets, the maximum difference approach performed best, regardless of the number of initial experiments. On the EGFR dataset, maximum difference performed best with a significant advantage over the maximum entropy approach (P55:6 Â 10 À118 ; 1.75 average difference between third quartiles). Both methods significantly outperformed the random selection with margins of 1:5 ðP51:4 Â 10 À44 Þ experiments for maximum entropy and 3:25 ðP55:3 Â 10 À191 Þ experiments for the maximum difference design. Similar results were obtained for the IL1 system, where data for only 14 experimental conditions were available. Even with this small amount of data the reduction in the number of additional experiments that were required by the maximum difference strategy was statistically significant. Specifically, the maximum difference approach required on average 1.25 less experiments than both the maximum entropy approach ðP51:5 Â 10 À73 Þ and the random approach ðP55:1 Â 10 À71 Þ. Interestingly, the maximum entropy design performed comparably with the random approach in this dataset. The analyses of the real datasets revealed that the maximum difference approach required less than three experimentsto learn an optimal model, achieving a 5–11-fold improvement over the respective sets of available experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>In this article, we studied two approaches for experimental design in Boolean networks. Our main contribution is in the development of an algorithm to optimally solve the maximum difference design criterion while exploring the space of all optimal models under all possible experiments. In addition, we implemented a method based on the well-studied criterion of maximum entropy and demonstrated its utility over a random selection of experiment as well as its limitations under varying conditions. Our evaluation of these schemes indicated that under many conditions, especially in the face of scarce data and increasing complexity of the underlying system, our novel maximum difference approach outperforms the maximum entropy scheme. Our findings suggest that current studies might suffer from redundant experimentation with respect to the available models of the systems at hand. Furthermore, results on simulated data suggest that by adopting an experimental design scheme, much of the redundancy may be eliminated. Thus, our approach should be beneficial for the study of systems whose underlying model is sufficiently detailed and may be formalized as a Boolean network. On the methodological side, the maximum difference approach is limited to considering the differences between pairs of models, calling for a generalized approach that considers multiple models. Additionally, in our current sampling procedure, we rely on the ILP solver to retrieve a diverse family of models. Maximum entropy and similar approaches should benefit from the development of other strategies that better sample the model space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>jr</head><figDesc>M1;e ðiÞ À r M2;e ðiÞj ð2Þ where jÁj denotes absolute value. We note that M elyk uti et al. (2010) have</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>represent the activity states under a maximum difference experiment ^ e. Additionally, we introduce integral variables s v 2 f0; 1; 2g for every species v indicating whether v is maintained at an inactive state (0), active state (1) or not perturbed (2) in this maximum difference experiment. We then add the following constraints to the ILP: (i) constraints to maintain the Boolean functions in ^ e as in the original program and (ii) constraints to ensure that the activity level of species v matches the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>version of the algorithm additionally receives a set of experiments E list =ðe 1 ;. .. ; e k Þ to choose from. In this version, an additional integral variable 2 ½1; k is introduced to the formulation indicating the chosen experiment. Then, the following constraints are added to the program: =i ) s v =I ei ðvÞ 8i=1::k; v 2 I e ð14Þ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.2.</head><figDesc>Fig. 2. Runtime comparison. A comparison of the running times of the maximum difference and maximum entropy approaches. Running times are given on two datasets (EGFR and IL1) when computing a single experiment to be conducted as a function of the number of available optimal models</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Sensitivity to the number of unknown functions. Increasing the number of unknown functions led to increment in the number of experiments that are required to uncover the underlying model in all but the maximum difference strategy, which retained an almost constant performance. In both panels, the x-axis denotes the number of unknown functions, and the y-axis denotes the third quartile of the number of experiments required to obtain an optimal model (lower is better). Error bars denote standard error. (A) Simulation with EGFR signaling. (B) Simulation with IL1 signaling</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig.5.</head><figDesc>Fig. 5. Performance evaluation on real data. The x-axis denotes the number of initial experiments, and the y-axis denotes the third quartile of the number of additional experiments required to reconstruct a model fitting the data as well as a model obtained from the all the available experimental data. (A) Results on the EGFR system. (B) Results on the IL1 system</figDesc></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="2">.3.1 Implementation details We first formulate the problem using an ILP and subsequently solve it with a dedicated solver. Generally, an ILP assumes the following form: min c T x ð3Þ s:t: Ax b ð4Þ x 2 f0; 1g ð 5Þ Given a directed acyclic graph G with a set of vertices V, each representing a molecular species, Sharan and Karp (2012) learn an optimal model with respect to a given experimental dataset E using an ILP formulation with variables x = (a,t) where a e,v is a binary variable denoting the activity level of species v in an experiment e, and t v represent the Boolean function associated with v. Additionally, their formulation i446 N.Atias et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Stimulus design for model selection and validation in cell signaling</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">F</forename>
				<surname>Apgar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Computational procedures for optimal experimental design in biological systems</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Balsa-Canto</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="163" to="172" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Optimal experimental design for parameter estimation of a cell signaling model</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bandara</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000558</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Iterative reconstruction of transcriptional regulatory networks: an algorithmic approach</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">L</forename>
				<surname>Barrett</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">O</forename>
				<surname>Palsson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Universally sloppy parameter sensitivities in systems biology models</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">N</forename>
				<surname>Gutenkunst</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1871" to="1878" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Parameter-free model discrimination criterion based on steady-state coplanarity</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">A</forename>
				<surname>Harrington</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="15746" to="15751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Integrating proteomic, transcriptional, and interactome data reveals hidden components of signaling and regulatory networks</title>
		<author>
			<persName>
				<forename type="first">S.-S</forename>
				<surname>Huang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Fraenkel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Signal</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Computational modeling of mammalian signaling networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Hughey</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdiscip. Rev. Syst. Biol. Med</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="194" to="209" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Discovery of regulatory interactions through perturbation: inference and experimental design</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">E</forename>
				<surname>Ideker</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac. Symp. Biocomput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="305" to="316" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Modelling and analysis of gene regulatory networks</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Karlebach</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Shamir</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Mol. Cell Biol</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="770" to="780" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">A benchmark for methods in reverse engineering and model discrimination: problem formulation and solutions</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kremling</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1773" to="1785" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Systems biology: experimental design</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Kreutz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Timmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FEBS J</title>
		<imprint>
			<biblScope unit="volume">276</biblScope>
			<biblScope unit="page" from="923" to="942" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A note on estimating the variance of the sample median</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Maritz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">G</forename>
				<surname>Jarrett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="194" to="196" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminating between rival biochemical network models: three approaches to optimal experiment design</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Elyk Uti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Identifying drug effects via pathway alterations using an integer linear programming optimization formulation on phosphoproteomic data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mitsos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000591</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Large-scale network models of IL-1 and IL-6 signalling and their hepatocellular specification</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ryll</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Biosyst</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3253" to="3270" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Discrete logic modelling as a means to link protein signalling networks with functional analysis of mammalian signal transduction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Saez-Rodriguez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">331</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">The logic of EGFR/ErbB signaling: theoretical properties and analysis of high-throughput data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Samaga</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000438</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Reconstructing boolean models of signaling</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Sharan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">M</forename>
				<surname>Karp</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Annual international conference on Research in Computational Molecular Biology. RECOMB&apos;12</title>
		<meeting>the 16th Annual international conference on Research in Computational Molecular Biology. RECOMB&apos;12<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>SpringerVerlag</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="261" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Elucidating regulatory mechanisms downstream of a signaling pathway using informative experiments</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Szczurek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">287</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Bridging high-throughput genetic and transcriptional data reveals cellular responses to alpha-synuclein toxicity</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Yeger-Lotem</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="316" to="323" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Toward accurate reconstruction of functional protein networks</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Yosef</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mol. Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">248</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Atias</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>