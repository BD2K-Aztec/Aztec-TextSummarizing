
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining A novel feature-based approach to extract drug–drug interactions from biomedical text</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Quoc-Chinh</forename>
								<surname>Bui</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center Rotterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Peter</forename>
								<forename type="middle">M A</forename>
								<surname>Sloot</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>The Netherlands</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Complexity Institute</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">ITMO University</orgName>
								<address>
									<addrLine>St. Petersburg</addrLine>
									<country key="RU">Russian Federation</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Erik</forename>
								<forename type="middle">M</forename>
								<surname>Van Mulligen</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center Rotterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jan</forename>
								<forename type="middle">A</forename>
								<surname>Kors</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center Rotterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining A novel feature-based approach to extract drug–drug interactions from biomedical text</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">23</biblScope>
							<biblScope unit="page" from="3365" to="3371"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu557</idno>
					<note type="submission">Received on April 9, 2014; revised on August 11, 2014; accepted on August 12, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Knowledge of drug–drug interactions (DDIs) is crucial for health-care professionals to avoid adverse effects when co-administering drugs to patients. As most newly discovered DDIs are made available through scientific publications, automatic DDI extraction is highly relevant. Results: We propose a novel feature-based approach to extract DDIs from text. Our approach consists of three steps. First, we apply text preprocessing to convert input sentences from a given dataset into structured representations. Second, we map each candidate DDI pair from that dataset into a suitable syntactic structure. Based on that, a novel set of features is used to generate feature vectors for these candidate DDI pairs. Third, the obtained feature vectors are used to train a support vector machine (SVM) classifier. When evaluated on two DDI extraction challenge test datasets from 2011 and 2013, our system achieves F-scores of 71.1% and 83.5%, respectively, outper-forming any state-of-the-art DDI extraction system. Availability and implementation: The source code is available for academic use at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Drug–drug interaction (DDI) is a situation when one drug increases or decreases the effect of another drug (<ref type="bibr" target="#b18">Tari et al., 2010</ref>). Information about DDIs is crucial for drug administration to avoid adverse drug reactions or therapeutic failure (van<ref type="bibr" target="#b23">Roon et al., 2009</ref>). For example, a recent study reports that DDIs are a significant cause of hospital admissions (<ref type="bibr" target="#b6">Dechanont et al., 2014</ref>). While specialized databases are available for finding known DDIs, such as DrugBank (http://www.drugbank.ca) or Micromedex (http://micromedex.com), their coverage is limited and there are discrepancies in DDI listing between existing databases (<ref type="bibr" target="#b24">Wong et al., 2008</ref>). As a consequence, most of newly discovered DDIs need to be extracted from scientific publications (<ref type="bibr" target="#b10">Herrero-Zazo et al., 2013</ref>). Text-mining techniques such as automatic relation extraction have been applied successfully in large-scale experiments to extract various types of relations [e.g. protein–protein interactions (PPIs), gene-disease] efficiently (<ref type="bibr" target="#b8">Hahn et al., 2012;</ref><ref type="bibr" target="#b14">Rebholz-Schuhmann et al., 2012</ref>). Therefore, automatic DDI extraction methods can be particularly relevant to effectively extract DDIs and corresponding evidence from the scientific literature. To develop and evaluate automatic DDI extraction methods, a DDI corpus has been created by<ref type="bibr" target="#b10">Herrero-Zazo et al. (2013)</ref>. This corpus was manually annotated with 18 502 pharmacological substances, mainly consisting of generic and brand names, and 5028 DDIs. With the availability of this corpus and the introduction of two DDI extraction challenges in 2011 and 2013 (<ref type="bibr" target="#b16">Segura-Bedmar et al., 2011a</ref>), several approaches have been proposed to extract DDIs from biomedical text. In both challenges, systems built on machine learning (ML) approaches were dominant and achieved the best results (<ref type="bibr" target="#b16">Segura-Bedmar et al., 2011a</ref>). In these systems, the DDI extraction tasks are modeled as classification problems where each candidate DDI pair is classified as an interacting pair or not. To build the classification models, data from annotated DDI corpora are often transformed into more structural representations using various natural language processing (NLP) tools. Among these ML-based systems, support vector machine (SVM) methods are the most popular (<ref type="bibr" target="#b15">Segura-Bedmar et al., 2013</ref>). In general, ML-based DDI extraction systems can be categorized into two groups, namely feature-and kernel-based methods. In feature-based systems, each data instance is represented as a feature vector in an n-dimensional space. The main focus in these systems is to define features that potentially best represent the data characteristics. For DDI extraction tasks, various feature types have been used ranging from lexical to syntactic and semantic information. For example, Segura<ref type="bibr" target="#b17">Bedmar et al. (2011b)</ref>developed a system using bag-of-words and local context features. To improve the performance of feature-based systems, some authors combine multiple types of features with the hope that these features can complement each other.<ref type="bibr" target="#b9">He et al. (2013)</ref>introduced a system that uses lexical, semantic and domain knowledge features. Chowdhury and Lavelli (2013a) proposed a system that combines heterogeneous features. Their system comprises lexical, syntactic, semantic and negation features derived from sentences and their corresponding parse trees. In kernel-based systems, the structural representations of data instances, e.g. syntactic parse trees or dependency graphs, are exploited. Various kernels have been proposed to quantify the similarities between two instances by computing the similarities of their representations. These kernels differ from each other *To whom correspondence should be addressed. ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com based on how syntactic representations are used and how similarity functions are calculated (<ref type="bibr" target="#b21">Tikk et al., 2013</ref>). For the DDI extraction challenges, the use of kernels varies between the participating systems. Among them, the most commonly used kernels are all-paths graph kernel (<ref type="bibr" target="#b0">Airola et al., 2008</ref>), shallow linguistic kernel (<ref type="bibr" target="#b7">Giuliano et al., 2006</ref>) and path-enclose tree kernel (<ref type="bibr" target="#b12">Moschitti, 2004</ref>). As the proposed kernels exploit different types of structural representations and similarity functions, they all have pros and cons. To compensate for the weakness of each individual kernel, kernel combination is often used. For example, Chowdhury and Lavelli (2013b) proposed a hybrid kernel, which combines three different kernels. Their system achieved the best results in the DDI extraction 2013 challenge (Task 2). Furthermore, the combination can take place at the output level (ensemble approach) where the output of multiple systems is combined using a voting scheme.<ref type="bibr" target="#b19">Thomas et al. (2011)</ref>developed a system that combines the output of two kernel-based systems and a case-based reasoning system using a majority voting scheme. This system yielded the best result in the DDI extraction 2011 challenge. Although systems using feature-based kernels alone did not yield the best performance in the DDI extraction challenges, feature-based kernels still play an important role in relation extraction tasks. In fact, the winning teams of the DDI extraction 2011 and 2013 challenges both incorporate feature-based kernels proposed by<ref type="bibr" target="#b7">Giuliano et al. (2006)</ref>as part of their systems. Furthermore,<ref type="bibr" target="#b11">Miwa et al. (2009)</ref>have shown that their featurebased PPI extraction system achieved state-of-the-art results on five PPI corpora. A recent study by<ref type="bibr" target="#b21">Tikk et al. (2013)</ref>on the performance of various types of kernels for PPI extraction tasks also suggests that to improve the performance of the current PPI extraction systems, novel feature sets should be explored over novel kernel functions. This suggestion may also apply to the DDI extraction tasks, as most current approaches to extract DDI pairs have also previously been used to extract PPI pairs. In this article, we propose a novel feature-based approach to extract DDIs from biomedical text. Our approach differs from existing approaches in two ways. First, we partition candidate DDI pairs into five groups based on their syntactic structures. Second, we apply a set of novel features that is optimized for each group based on the syntactic properties. Our results show that the proposed system achieves the best results in terms of F-scores and performance efficiency when compared with the state-of-the-art DDI extraction systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>Our method consists of three steps. First, we apply text preprocessing to convert input sentences into structured representations. Second, a feature vector for each candidate DDI pair is extracted from the corresponding structured representation using predefined feature sets. In the last step, the obtained feature vectors are used to train an SVM classifier to generate a predictive model, which is used to classify candidate DDI pairs of the test dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Text preprocessing</head><p>The text preprocessing step consists of filtering out irrelevant sentences, entity blinding, word tokenizing, part-of-speech (POS) tagging and parsing sentences with a shallow parser. We manually created a list of 292 trigger words by combining a list of trigger words previously used to extract PPIs (<ref type="bibr" target="#b1">Bui et al., 2011</ref>) and some trigger words specific to DDI taken from the training dataset. Sentences that contain one drug or have no trigger word are filtered out. Next, to improve generalization of the input sentences, all drug names are blinded by assigning names as DRUGi where i is the drug index. Each sentence is then tokenized and POS tagged with the LingPipe NLP toolkit (http://alias-i.com/lingpipe). Finally, the tokens and their tags are used as input for the OpenNLP shallow parser (https://opennlp.apache.org/) to produce chunks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Structured representation</head><p>We adapt the structured representation proposed by Bui and Sloot (2012) to express candidate DDI pairs. This structured representation, which consists of three syntactic layers (chunk, phrase and clause), is generated based on the chunks outputted from the shallow parser. As there are many cases where DDI pairs span into more than one single clause, we represent these cases using multiple single clauses. We modify the structured representation as follows: Phrase: consists of a list of chunks (i.e. the output of the shallow parser).<ref type="figure" target="#fig_1">Figure 1b</ref>shows examples of phrases (dashed boxes), which consist of noun chunks (NCs; plain boxes) connected by preposition chunks (PCs; shadowed boxes). Clause: consists of a verb chunk and two phrases that are located in the left and in the right of the verb chunk. Complex sentences are represented by multiple clauses. For example,<ref type="figure" target="#fig_1">Figure 1a</ref>shows a clause that has a verb chunk connected with the left phrase (subject) and the right phrase (object).<ref type="figure" target="#fig_1">Figure 1c</ref>shows a complex sentence that consists of three clauses. Furthermore, to reduce the number of clauses generated for each input sentence, only verb chunks that belong to the main clauses are used to construct the structured representation. With the proposed structured representation, we can express relationship of almost all drug pairs.<ref type="figure" target="#fig_1">Figures 1a</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>...</head><p>(a)</p><formula>(b) (c)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Features</head><p>In this section, we describe a set of novel features that are specifically designed to exploit the strength of the structured representations. To generate features for each candidate DDI pair, we find the smallest syntactic container (e.g. a phrase, a clause or clauses) from the structured representation containing that pair. For example, the smallest syntactic container of the DRUG1–DRUG2 pair in<ref type="figure" target="#fig_1">Figure 1b</ref>is a phrase, whereas the smallest syntactic container of the DRUG2–DRUG3 pair in<ref type="figure" target="#fig_1">Figure 1c</ref>encloses two clauses. Given a candidate DDI pair and its syntactic container, we check whether the syntactic container contains any trigger words. If the syntactic container functions as a subject, we also check its right verb chunk for trigger words, as there are cases in which trigger words do not belong to the subjects but to their right verb chunks. If no trigger word is detected, then the candidate DDI pair is skipped, otherwise the following features are generated depending on its container type (e.g., subject, clause): Lexical features: are used to capture relations between each drug of the candidate DDI pair and its surrounding tokens. These relations might reveal the syntactic role of the drug within the phrase containing it, such as whether the drug is a part of the coordination or is an abbreviation of another drug. Lexical features of each drug are three tokens on the left and three tokens on the right of that drug. Left and right tokens are distinguished by adding _L and _R suffixes, respectively. In addition, if a token is a drug (e.g. DRUG1 or DRUG2) then that token is replaced by 'arg'. For example, lexical features of the DRUG2 in<ref type="figure" target="#fig_1">Figure 1b</ref>are: of_L, arg_L, with_L. As DRUG2 is the last token of that phrase, there is no feature extracted from the right side.Here prep are prepositions connecting chunks that contain the trigger and the DDI pair. Arg1 and arg2 are drugs of the (ordered) candidate DDI pair. The '*' indicates that zero or more prepositions are required. Based on the obtained case, corresponding features are generated to represent the position between the trigger and the candidate DDI pair (i.e. left, middle or right) and to indicate which prepositions are used to connect the trigger and the target pair as well as the chunks between the drugs of the target pair. For example, features generated for the DRUG1–DRUG2 pair in<ref type="figure" target="#fig_1">Figure 1b</ref>are use_of_arg1 and arg1_with_arg2_case1. Furthermore, if there is a negative modifier (e.g. no, not) which belongs to the same chunk that contains a trigger, we insert the modifier as the prefix for that trigger. As it is non-trivial to automatically determine which trigger actually has a relation with (i.e. governs) the candidate DDI pair, all detected triggers are used to generate phrase features. Verb features: are bag-of-words (unigrams and bigrams) generated from the verb chunk of the clause to which the candidate DDI pair belongs. The verb features indicate how the drug in the left phrase (subject) and the drug in the right phrase (object) are related. Syntactic features: are designed to capture the surrounding syntactic structure of each drug of the candidate DDI pair within the phrase to which it belongs. To do this, we assign indices for all preceding noun and preposition chunks which connect to the noun chunk containing that drug. Furthermore, we also check whether there is any drug succeeding that drug and which prepositions are used to connect them. For example, the syntactic features generated for DRUG1 in<ref type="figure" target="#fig_1">Figure 1b</ref>are NC1, PC2, has_more_args and with_arg. Together with verb features, syntactic features particularly help to distinguish between DDI pairs that have a drug governed by its preceding noun chunks and DDI pairs that have drugs spanning into two phrases (i.e. subject and object) of a clause. For example, consider the positive DRUG1–DRUG2 pair in<ref type="figure" target="#fig_1">Figure 1a</ref>and the negative DRUG2–DRUG3 pair in<ref type="figure" target="#fig_1">Figure 1b</ref>. Although both pairs have the same sequence of tokens, if the syntactic structure is used then DRUG1 in<ref type="figure" target="#fig_1">Figure 1a</ref>and DRUG2 in<ref type="figure" target="#fig_1">Figure 1b</ref>have completely different syntactic features. Auxiliary features: consist of three features that capture information related to the drugs of the target pair. In particular, the first feature keeps track if drug names of the pair are real names versus pronouns (e.g. these drugs, this drug). The second feature denotes whether the drugs have the same name, and the third feature indicates whether the target drugs are in the same chunk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Partitioning DDI pairs</head><p>In a previous study,<ref type="bibr" target="#b1">Bui et al. (2011)</ref>showed that partitioning candidate PPI pairs based on syntactic properties and selecting partition-specific feature improved the performance of their PPI extraction system. Following this strategy, we categorize candidate DDI pairs into different groups based on their syntactic containers. To reduce the number of syntactic groups being generated, we only consider candidate DDI pairs that span over at most two clauses. For example, the DRUG1– DRUG3 pair in<ref type="figure" target="#fig_1">Figure 1c</ref>is ignored, as it spans over three clauses. This partitioning process results in five syntactic groups, namely subject, object, clause, clause_2 and NP. Here clause_2 denotes a syntactic structure that spans over two clauses, and NP denotes an input sentence that contains only a phrase. Owing to space limitations, we refer to the Supplementary source code for more details on text preprocessing and feature generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Machine learning</head><p>Recent relation extraction competitions have shown that the use of SVMs in relation extraction systems is dominant and systems that use SVMs achieved the best performance (N<ref type="bibr" target="#b13">edellec et al., 2013;</ref><ref type="bibr" target="#b16">Segura-Bedmar et al., 2011a</ref>). In this study, we use the LIBSVM classifier with a default RBF kernel (http://www.csie.ntu.edu.tw/ cjlin/libsvm/) for classification of DDI pairs. All individual features extracted for each DDI pair are normalized and combined into a single feature vector as proposed by<ref type="bibr" target="#b11">Miwa et al. (2009)</ref>. To find the best parameter C and gamma for each model, we use the CVParameterSelection function from the WEKA toolbox (http://www.cs.waikato.ac.nz/ml/weka/).<ref type="figure" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Transformation of datasets</head><p>When applying the text preprocessing and partitioning steps for each dataset, we obtain a transformed dataset where irrelevant DDI pairs are filtered out and the original dataset is split into five groups. Tables 2 and 3 show statistics of the transformed datasets for training and test datasets, respectively. The data in these tables indicate that the text preprocessing has effectively filtered out significant numbers of negative instances (TNs) with a small cost of missing positive instances (FNs). Overall, numbers of filtered instances vary from 2.5 to 4.1% for FNs and from 27.9 to 33.8% for TNs on the DrugBank datasets. However, numbers of FNs on the Medline dataset are unexpectedly high, ranging from 8.6 to 17.9.0%. Furthermore, a small number of positive instances are ignored during the partition step owing to their complex syntactic structures. These numbers are shown in Tables 2 and 3 as ignored cases. In addition, the data from Tables 2 and 3 show that the numbers of instances vary significantly between groups of each dataset and across datasets. This indicates that the performance on each group might also differ accordingly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation settings</head><p>We use the standard evaluation measures (Precision, Recall and F-score) proposed by the DDI extraction challenge to evaluate the performance of our system (<ref type="bibr" target="#b15">Segura-Bedmar et al., 2013</ref>). As our method mainly focuses on the detection of interaction pairs, we ignore the interaction types annotated in the DDI-2013 dataset. (The detection of DDI pairs is an important step in the extraction pipeline of most of the systems that participated in the DDI extraction 2013 challenge, including the top two systems). In addition, because we partition each dataset into five groups, we need to train the classifier separately for each group. To find the optimal feature sets for these groups, we tried various combinations of the proposed features. The best feature sets for each group are shown in<ref type="figure" target="#tab_4">Table 4</ref><ref type="figure" target="#tab_5">Table 5</ref>shows the results of our system evaluated on the DDI2011 and DDI-2013 test datasets. To understand its performance on different document types (i.e. DrugBank and Medline abstracts), we present the results of the DDI-2013 sub datasets separately. Furthermore, to calculate recall, all positive instances missed by the previous preprocessing steps are considered as FNs. Besides reporting the overall performance of the whole dataset, we also present the performances of individual groups. Recall for each group is calculated using data from<ref type="figure" target="#tab_3">Table 3</ref>(which do not take into account filtered and ignored instances), whereas the recall for the overall performance for each test dataset is calculated using data from<ref type="figure" target="#tab_1">Table 1</ref>. The results in<ref type="figure" target="#tab_5">Table 5</ref>show that our system performs well on the DB-2013 and DDI-2011 test datasets with F-scores of 83.5 and 71.1%, respectively. However, its performance decreases on the Medline test dataset with an F-score of 59.2%, which is 24.3 points lower than that of the DB-2013 test dataset. This performance decrease stems from the low recall, which can partly be explained by the loss of positive instances during the preprocessing steps. In addition, for each dataset, the performance on each group also differs significantly. These performance differences might be due to three factors. First, the ratio of the positive and negative instances varies among all groups (see<ref type="figure" target="#tab_2">Tables 2  and 3</ref>). This causes the performance degradation for groups that have smaller positive/negative ratios (<ref type="bibr" target="#b22">Van Hulse et al., 2007</ref>). Second, the selection of different feature sets for various syntactic groups may also account for the differences in performance. Third, the annotation quality of the DB-2013 is better than that of DB-2011, which was annotated automatically without any manual revision (<ref type="bibr" target="#b10">Herrero-Zazo et al., 2013</ref>).<ref type="figure" target="#tab_6">Table 6</ref>shows the performance comparison between our system (BioSem) and the top-performance systems participating in the DDI-2013 extraction challenge (Task 2). The data show that our system outperforms the top five systems on the DB-2013 test dataset with an F-score increase ranging from 0.8 to 13.2 points. While the recall of our system is lower than the best system (81.2 versus 83.8%), its precision is significantly higher (85.9 versus 81.6%). Furthermore, our system also yields better results when compared with these systems on the ML-2013 test dataset. The results in<ref type="figure" target="#tab_7">Table 7</ref>show that the BioSem achieves an F-score of 59.2%, which is higher than the other systems 6.2–17.1 points. It is worth noting that the systems that participated in the challenges had to be developed under strict time constraints, which may have affected their performance. Nevertheless, the authors of the top-performing systems have participated in the DDI-2011 extraction challenge and thus were familiar with the task and could fine-tune their systems using the DDI-2011 test dataset. To provide a fair performance comparison, we present the evaluation results of the best known systems that run on the DDI-2011 post-challenge test dataset in<ref type="figure" target="#tab_8">Table 8</ref>. We also provide the results of the best system of the DDI-2011 extraction challenge for reference. The data show that post-challenge systems achieve higher performance in terms of F-scores as compared with the best system of the DDI-2011 extraction challenge. These performance improvements might stem from the fact that these systems have a better design and/or could be finetuned on the available test dataset. Compared with these post-challenge systems, our system yields better results with F-score improvements ranging from 1.9 to 2.2 points. It is worth noting that the system proposed by Chowdhury and Lavelli (2013b) is the same system that achieved the best results in DDI-2013 challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Performance of DDI extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Performance analysis</head><p>In this section, we address some issues related to the performance of the proposed system as well as discuss its complexity with respect to the state-of-the-art systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Performance variation on different datasets</head><p>In the previous section, we have mentioned that the ratio of positive and negative instances might directly contribute to the differences in performance between syntactic groups (e.g. subject, object, etc.) of each dataset. This phenomenon can also be observed in the same groups across different datasets. For example, on the DB2013 dataset, the ratios of positive/negative instances of the clause group are 0.83 and 1.20 for training and test datasets, whereas on the DDI-2011 dataset these values are 0.39 and 0.38, respectively (see Tables 2 and 3). These differences might explain why precision and recall of the clause group differs between these two datasets: 86.1 versus 65.8% for precision and 94.4 versus 84.8% for recall. Furthermore, this might also explain the high precision of the subject group on the ML-2013 testNotes. Pos. and Neg. denote positive and negative instances, respectively.dataset, as the positive/negative ratios between training and test datasets are 0.11 and 1.05, respectively. Another issue that might affect the system performance is the size of the datasets. This is clearly visible for the ML-2013 dataset, which is significantly smaller (14 times) than the DB-2013 dataset. Moreover, learning a model from a small training set is one of the challenges of an ML-based approach. This problem is even harder in our case since we further split the training set into five sub datasets. For example, when we used the ML-2013 dataset alone for training, our system achieved an F-score of 35.4% on the ML-2013 test dataset (data not shown). However, when trained on the combined DB-2013 and ML2013 training datasets and evaluated on the ML-2013 test set, the F-score increases to 59.2%. This indicates that even though there are differences in structure between the document types (<ref type="bibr" target="#b5">Cohen et al., 2010</ref>) of two datasets, increasing the size of the ML-2013 training set by adding training instances from the DB2013 set, to some extent, helps improving the performance of our system on this test dataset.</p><formula>Subject X X X X X Object X X X X Clause X X X X Clause-2 X X X X NP X X X</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Contribution of the proposed feature sets</head><p>When applying an ML-based approach for relation extraction tasks, each candidate pair is classified independently as being a true interaction pair or not. The benefit of this approach is that it can easily be used with any (binary) classifier. However, when each candidate DDI pair is considered independently, it is taken out of context. In other words, the dependencies between the drugs of the candidate DDI pair and their neighboring drugs might be missed, which might lead to a wrong classification. For example, consider a positive DRUG1–DRUG2 pair and two negative DRUG1–DRUG3 and DRUG2–DRUG3 pairs in the sentence 'Concurrent use of DRUG1 with DRUG2 may increase the effect of DRUG3' as shown in<ref type="figure" target="#fig_1">Figure 1b</ref>. For the DRUG2–DRUG3 pair, if only lexical features are used then one may miss the information that DRUG2 has already participated in a relation with DRUG1. For the DRUG1–DRUG3 pair, even if a dependency tree is used, one might still miss the information that DRUG1 has a relation with DRUG2. To address this problem, previous systems usually combine various types of features so that they can complement each other. In our system, we explicitly tackle this problem by introducing three novel feature sets, namely verb, phrase and syntactic features.<ref type="figure" target="#tab_9">Table 9</ref>shows the contributions of the phrase, syntactic and verb features on the performance of our system when evaluated on the DB-2013 test dataset. The data show that when the verb features are removed, the performance in terms of F-score degrades 3.56% compared with that of the whole feature set. While removing the phrase or syntactic feature alone decreases the performance slightly, removing both phrase and syntactic features results in the performance decreases 1.53%. This means that one of these features may only be suitable for certain groups. This phenomenon is clearly visible when we apply the optimized feature sets from<ref type="figure" target="#tab_4">Table 4</ref>to the test dataset, resulting in an increase of 0.95% on the F-score compared with that of the whole feature sets. In addition, by mapping each candidate DDI pair into a syntactic container before generating features, we can enhance the lexical features by not generating unnecessary tokens surrounding each drug of the candidate DDI pair. For example, the number of lexical features generated for DRUG2 in<ref type="figure" target="#fig_1">Figure 1b</ref>is three features instead of six features for systems that use a flat structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.3">Computational performance and complexity To</head><p>increase the performance of DDI extraction systems, most of top-performing systems use either ensemble approaches (<ref type="bibr" target="#b19">Thomas et al., 2011</ref><ref type="bibr" target="#b20">Thomas et al., , 2013</ref>) or kernel combination approaches (<ref type="bibr" target="#b4">Chowdhury and Lavelli, 2013b;</ref><ref type="bibr" target="#b9">He et al., 2013</ref>). While they manage to increase the performances, the computational resources and the complexity of their systems also increase. Furthermore, some systems also incorporate domain knowledge (<ref type="bibr" target="#b9">He et al., 2013;</ref><ref type="bibr" target="#b20">Thomas et al., 2013</ref>) to enhance the performance, but this hinders the adaptation of these systems to new relation extraction tasks. In contrast, our proposed feature-based system uses a small set of features to generate feature vectors from a simple syntacticNotes. The results are evaluated on the DB-2013 test dataset. Verb features are not applicable to NP group, and phrase features are not applicable to clause and clause2 groups. Lex, Aux, P, R and F denote lexical, auxiliary, precision, recall and F-score, respectively. representation. It uses a shallow parser for analyzing input sentences and requires only a single kernel to build predictive models. Therefore, it is simpler and requires less computational time compared with the other ML-based systems. For example, our system requires 51 s to process the DB-2013 dataset (22 s for the text preprocessing step and 29 s for training and classifying instances). This experiment was performed on a laptop with an Intel Core i7-2640 M, 2.8 GHz processor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.4">Error analysis To identify</head><p>the main sources of error of our system, we analyze all errors [118 false positives (FPs), 130 FNs] produced by our system when evaluated on the DB-2013 test dataset. Overall, these errors (both FPs and FNs) can be categorized into four groups. The first group of errors (22 FPs, 39 FNs) is caused by parser errors or incorrect construction of structured representations. These errors lead to the wrong categorization of candidate DDI pairs. The second error group (34 FPs) is caused by a non-deterministic context, where the syntactic containers of the candidate DDI pairs alone are not enough to determine the outcome. The third error group (42 FPs, 91 FNs) is caused by unusual syntactic structures of the input sentences, anaphora problems and the long distance between two drugs (measured by the number of chunks) of the candidate DDI pairs. The fourth error group (20 FPs) consists of cases where candidate DDI pairs syntactically seem to be true DDI pairs. While most of the errors are non-trivial, the errors caused by input sentences with special syntactic structures can be tackled if rules are defined to convert these input sentences into a form that can be handled by the structured representation. For the other errors, substantial changes in the system are needed to further improve the current performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSIONS</head><p>In this study, we have proposed a novel feature-based approach to extract DDIs from text. The key factors of our approach are the combination of the novel feature sets and the partition of the datasets. By partitioning the original dataset into subsets based on their syntactic properties, we obtain more consistent sub datasets and can optimize feature selection for each sub dataset. Furthermore, by combining the strength of various types of features, our system is robust and generalizes well on different datasets. The evaluation results show that our system achieves better performance than the state-of-the-art systems on various test datasets. Our approach is simple and more efficient in terms of computational time than other ML-based systems, as it uses a small set of features and a default SVM kernel. Furthermore, the proposed feature sets are generic, except for the auxiliary feature set. While the system is initially proposed to extract DDIs, it can easily be adapted to other binary relation extraction tasks, such as PPIs and gene–disease relations. Funding: PMAS is partially supported by Russian Scientific Foundation, proposal #14-21-0037.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Structured representation for DDI pairs. (a) Examples of positive DDI pairs expressed by a clause. (b) Examples of a positive DDI pair expressed by a phrase (subject) and of negative DDI pairs, indicated by dashed lines, expressed by a clause. (c) An example of a complex sentence, which consists of multiple clauses. DRUG1–DRUG2 and DRUG2– DRUG3 pairs span over two clauses, whereas the DRUG1–DRUG3 pair spans over three clauses</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>Phrase features: are applicable for a candidate DDI pair of which the syntactic container is a phrase. These features are designed to capture relations of the candidate DDI pair and trigger words that belong to the phrase containing that pair. For each trigger word, we determine its relative position within the phrase by checking the following cases: Trigger [prep]* arg1 [prep]* arg2 (case 1) Arg1 [prep]* trigger [prep]* arg2 (case 2) Arg1 [prep]* arg2 [prep]* trigger (case 3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>We use the DDI extraction 2011 and 2013 datasets (hereafter referred to as DDI-2011 and DDI-2013) provided by the DDI extraction 2011 and 2013 challenges to evaluate our extraction method. Each dataset consists of two parts, a training dataset and a test dataset. There are differences between the two challenge datasets. The DDI-2011 datasets contain documents selected from the DrugBank database, whereas the DDI-2013 datasets consist of documents selected from the DrugBank database and Medline abstracts. Furthermore, in the DDI-2011 dataset, each drug pair was annotated either as a true interaction (positive instance) or no interaction (negative instance), whereas the DDI-2013 datasets have more fine-grained annotations with different interaction types. Statistics of the datasets are shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><figDesc>. These features were determined based on the DB-2013 training set but used for all evaluations. We evaluate the performance of our system on each test dataset after training on the corresponding training dataset, except for the ML-2013 test dataset. For this test dataset, the system is trained on the combined DB-2013 and the ML-2013 training datasets as suggested by Chowdhury and Lavelli (2013b) and Thomas et al. (2013).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>.80%) (38.20%) (8.60%) (37.70%) (4.10%) (33.80%) Notes. Pos. and Neg. denote positive and negative instances, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>Conflict of interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. Statistics of the DDI-2011 and DDI-2013 training and test datasets</figDesc><table>Corpus 
Training 
Testing 

Sen. 
Pos. 
Neg. 
Sen. 
Pos. 
Neg. 

DDI-2011 
4267 
2402 
21 425 
1539 
755 
6271 
DB-2013 
5675 
3788 
22 217 
973 
884 
4426 
ML-2013 
1031 
232 
1555 
326 
95 
365 

Notes. The DDI-2013 datasets are split into two subsets (DB-2013 and ML-2013) 
based on document types. Sen., Pos. and Neg. denote numbers of input sentences, 
positive instances and negative instances, respectively. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 2. Statistics of the transformed training datasets after applying text preprocessing steps</figDesc><table>Group 
DB-2013 
ML-2013 
DDI-2011 

Pos. 
Neg. 
Pos. 
Neg. 
Pos. 
Neg. 

Subject 
876 
4301 
29 
250 
600 
4488 
Object 
356 
4797 
13 
271 
203 
3770 
Clause 
1852 
2238 
121 
211 
1240 
3212 
Clause_2 
341 
871 
12 
85 
163 
1324 
NP 
197 
1039 
27 
102 
74 
713 
Total 
3622 
13 246 
202 
919 
2280 
13507 
(known 
cases) 

(96%) 
(60%) 
(87%) 
(59%) 
(95%) 
(63%) 

Ignored 
cases 

60 
479 
10 
50 
24 
676 

Filtered 
out/ 
skipped 

106 
8492 
20 
586 
98 
7242 
(2</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><figDesc>Table 3. Statistics of the transformed test datasets after applying text preprocessing steps</figDesc><table>Group 
DB-2013 
ML-2013 
DDI-2011 

Pos. 
Neg. 
Pos. 
Neg. 
Pos. 
Neg. 

Subject 
156 
782 
21 
20 
179 
1000 
Object 
90 
1174 
16 
77 
78 
1429 
Clause 
504 
429 
36 
58 
376 
997 
Clause_2 
37 
229 
2 
26 
54 
280 
NP 
61 
367 
3 
23 
34 
567 
Total 
848 
2981 
78 
204 
721 
4273 
(known 
cases) 

(96%) (68%) 
(82%) 
(57%) 
(96%) (68%) 

Ignored cases 14 
178 
0 
4 
4 
131 
Filtered 
out/skipped 

22 
1222 
17 
148 
30 
1867 
(2.50%) (27.90%) (17.90%) (41.60%) (4.00%) (29.80%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 4. Optimized features for each syntactic group</figDesc><table>Group 
Lexical 
Phrase 
Verb 
Syntactic 
Auxiliary 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 5. Evaluation results on the DDI-2011 and DDI-2013 test datasets</figDesc><table>Group 
DB-2013 
ML-2013 
DDI-2011 

P (%) R (%) P (%) R (%) P (%) R (%) 

Subject 
83.92 
76.92 
86.67 
61.90 
75.65 
81.56 
Object 
84.72 
67.78 
54.55 
37.50 
81.43 
73.08 
Clause 
86.08 
94.44 
71.79 
77.78 
65.77 
84.84 
Clause_2 
91.67 
59.46 
100.00 50.00 
76.19 
29.62 
NP 
88.64 
63.93 
25.00 
66.67 
64.29 
26.47 
Overall performance 
Precision (%) 85.88 
67.57 
69.85 
Recall (%) 
81.22 
52.63 
72.45 
F-score (%) 
83.48 
59.17 
71.13 

Notes. The DDI-2013 test datasets are split into two subsets (DB-2013 and ML-
2013) based on document types. P and R denote precision and recall, respectively. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 6.</figDesc><table>Performance comparison with the top five systems participating 
in the DDI-2013 extraction challenge on the DB-2013 test dataset 

Team 
Precision (%) 
Recall (%) 
F-score (%) 

FBK-irst 
81.6 
83.8 
82.7 
WBI 
81.4 
75.5 
78.3 
SCAI 
79.6 
68.1 
73.4 
UTurku 
84.3 
63.8 
72.6 
UC3M 
65.6 
75.8 
70.3 
BioSem 
85.9 
81.2 
83.5 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 7. Performance comparison with the top five systems participating in the DDI-2013 extraction challenge on the ML-2013 test dataset</figDesc><table>Team 
Precision (%) 
Recall (%) 
F-score (%) 

FBK-irst 
55.8 
50.5 
53.0 
WBI 
62.5 
42.1 
50.3 
UWM-TRIADS 
38.7 
63.0 
47.9 
SCAI 
43.1 
52.6 
47.4 
UC3M 
31.3 
64.2 
42.1 
BioSem 
67.6 
52.6 
59.2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>Table 8.</figDesc><table>Performance comparison of systems on the post-challenge DDI-
2011 test dataset 

Team 
Precision (%) Recall (%) F-score (%) 

WBI (1 st 2011) 
60.5 
71.9 
65.7 
Chowdhury and Lavelli (2013b) 63.5 
75.2 
68.9 
He et al. (2013) 
66.2 
72.6 
69.2 
BioSem 
69.9 
72.5 
71.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><figDesc>Table 9.</figDesc><table>Contribution of phrase, syntactic and verb features to the per-
formance of our system 

Features 
P (%) R (%) F (%) 

Lex + Aux + Phrase + Syntactic + Verb (1) 85.64 
79.63 
82.53 
(1) -Verb 
81.9 
76.24 
78.97 
(1) -Phrase 
84.63 
79.75 
82.12 
(1) -Syntactic 
83.06 
81 
82.01 
(1) -Phrase -Syntactic 
81.7 
80.32 
81 
Optimized feature sets 
85.88 
81.22 
83.48 

</table></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Q.-C.Bui et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">A novel feature-based approach to extract DDIs at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Airola</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl. . 11</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">A hybrid approach to extract protein-protein interactions</title>
		<author>
			<persName>
				<forename type="first">Q.-C</forename>
				<surname>Bui</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="259" to="265" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">A robust approach to extract biomedical events from literature</title>
		<author>
			<persName>
				<forename type="first">Q.-C</forename>
				<surname>Bui</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">M A</forename>
				<surname>Sloot</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2654" to="2661" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting the scope of negations and heterogeneous features for relation extraction: a case study for drug-drug interaction extraction</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chowdhury</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lavelli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="765" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">FBK-irst: a multi-phase kernel based approach for drug-drug interaction detection and classification that exploits linguistic information</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chowdhury</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Lavelli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="351" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">The structural and content aspects of abstracts versus bodies of full text journal articles are different</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">B</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">492</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Hospital admissions/visits associated with drug-drug interactions: a systematic review and meta-analysis</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Dechanont</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pharmacoepidemiol. Drug Saf</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="489" to="497" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploiting shallow linguistic information for relation extraction from biomedical literature</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Giuliano</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2006</title>
		<meeting>ACL 2006<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Mining the pharmacogenomics literature—a survey of the state of the art</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Hahn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="460" to="494" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Extracting drug-drug interaction from the biomedical literature using a stacked generalization-based approach</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">65814</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">The DDI corpus: an annotated corpus with pharmacological substances and drug-drug interactions</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Herrero-Zazo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="914" to="920" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A rich feature vector for protein-protein interaction extraction from multiple corpora</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Miwa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in NLP. ACL, Singapore</title>
		<meeting>the 2009 Conference on Empirical Methods in NLP. ACL, Singapore</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">A study on convolution kernels for shallow semantic parsing</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Moschitti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics-ACL&apos;04. ACL</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics-ACL&apos;04. ACL<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="335" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Overview of BioNLP shared task 2013</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Edellec</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP Shared Task 2013 Workshop</title>
		<meeting>the BioNLP Shared Task 2013 Workshop<address><addrLine>Sophia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Text-mining solutions for biomedical research: enabling integrative biology</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rebholz-Schuhmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="829" to="839" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Semeval-2013 task 9: extraction of drug-drug interactions from biomedical texts</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Segura-Bedmar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">The 1st DDIExtraction-2011 challenge task: extraction of drug-drug interactions from biomedical texts</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Segura-Bedmar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Challenge task on Drug-Drug Interaction Extraction (DDI Extraction</title>
		<meeting>the First Challenge task on Drug-Drug Interaction Extraction (DDI Extraction<address><addrLine>Huelva, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Using a shallow linguistic kernel for drug-drug interaction extraction</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Segura-Bedmar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="789" to="804" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Discovering drug-drug interactions: a text-mining and reasoning approach based on properties of drug metabolism</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Tari</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="547" to="553" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Relation extraction for drug-drug interactions using ensemble learning</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Thomas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Challenge task on Drug-Drug Interaction Extraction (DDI Extraction</title>
		<meeting>the First Challenge task on Drug-Drug Interaction Extraction (DDI Extraction<address><addrLine>Huelva, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">WBI-DDI: drug-drug interaction extraction using majority voting</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Thomas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="628" to="635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">A detailed error analysis of 13 kernel methods for proteinprotein interaction extraction</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Tikk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Experimental Perspectives on Learning from Imbalanced Data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Van Hulse</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Machine Learning, ICML&apos;07</title>
		<meeting>the 24th International Conference on Machine Learning, ICML&apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">An evidence-based assessment of the clinical significance of drug-drug interactions between disease-modifying antirheumatic drugs and non-antirheumatic drugs according to rheumatologists and pharmacists</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">N</forename>
				<surname>Van Roon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Ther</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1737" to="1746" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Clinically significant drug-drug interactions between oral anticancer agents and nonanticancer agents: profiling and comparison of two drug compendia</title>
		<author>
			<persName>
				<forename type="first">C.-M</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Pharmacother</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1737" to="1748" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>