
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data and text mining A hybrid approach to extract protein–protein interactions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2011">2011</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Quoc-Chinh</forename>
								<surname>Bui</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Computational Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Sophia</forename>
								<surname>Katrenko</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Theory of Computer Science</orgName>
								<orgName type="department" key="dep2">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<addrLine>Science Park 904</addrLine>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Peter</forename>
								<forename type="middle">M A</forename>
								<surname>Sloot</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Computational Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Data and text mining A hybrid approach to extract protein–protein interactions</title>
					</analytic>
					<monogr>
						<title level="j" type="main">BIOINFORMATICS ORIGINAL PAPER</title>
						<imprint>
							<biblScope unit="volume">27</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="259" to="265"/>
							<date type="published" when="2011">2011</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btq620</idno>
					<note>[13:34 16/12/2010 Bioinformatics-btq620.tex] Page: 259 259–265 Associate Editor: Jonathan Wren Contact:</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Protein–protein interactions (PPIs) play an important role in understanding biological processes. Although recent research in text mining has achieved a significant progress in automatic PPI extraction from literature, performance of existing systems still needs to be improved. Results: In this study, we propose a novel algorithm for extracting PPIs from literature which consists of two phases. First, we automatically categorize the data into subsets based on its semantic properties and extract candidate PPI pairs from these subsets. Second, we apply support vector machines (SVMs) to classify candidate PPI pairs using features specific for each subset. We obtain promising results on five benchmark datasets: AIMed, BioInfer, HPRD50, IEPA and LLL with F-scores ranging from 60% to 84%, which are comparable with the state-of-the-art PPI extraction systems. Furthermore, our system achieves the best performance on cross-corpora evaluation and comparative performance in terms of computational efficiency. Availability: The source code and scripts used in this article are available for academic use at</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Extraction of protein–protein interactions (PPIs) from literature is an important research topic in the field of biomedical natural language processing (NLP;<ref type="bibr" target="#b18">Miwa et al., 2010</ref>). Numerous PPIs have been manually curated and stored into databases, such as BIND, HDPR and IntAct. However, this task has been proven time and resource consuming. As a consequence, most data on PPIs can only be found in literature (<ref type="bibr" target="#b6">Cusick et al., 2009</ref>). Several approaches for extracting PPIs from biomedical text have been reported. These methods range from co-occurrence to more sophisticated machine learning (ML) systems augmented by NLP techniques. Co-occurrence is the simplest approach, which results in high recall but low precision. Rule-or pattern-based approaches can increase precision but significantly lower recall. In addition, these rule sets are derived from training data and are therefore not always applicable to other data they are not developed for (<ref type="bibr" target="#b1">Ananiadou et al., 2006;</ref><ref type="bibr" target="#b11">Kabiljo et al., 2009</ref>). * To whom correspondence should be addressed.</p><p>Recently, many ML-based methods have employed NLP techniques such as shallow parsing or full parsing (<ref type="bibr" target="#b2">Björne et al., 2010;</ref><ref type="bibr" target="#b9">Giles and Wren 2008;</ref><ref type="bibr" target="#b10">Giuliano et al., 2006;</ref><ref type="bibr" target="#b18">Miwa et al., 2010</ref>). Since full parsing produces more elaborate syntactic information than shallow parsing, PPI extraction systems based on full parsing can potentially yield better results (<ref type="bibr" target="#b19">Miyao et al., 2009</ref>). The output of the parser can be represented either as constituent trees or dependency trees. In this case, the PPI extraction task is treated as a binary classification problem which requires a formal protein pair representation and a suitable ML method. A protein pair (an instance) can be represented by a set of features, which are derived from the sentence or its syntactic structure. A ML method is then used to distinguish between positive and negative instances (<ref type="bibr">Niu et al., 2010;</ref><ref type="bibr" target="#b24">Saetre et al., 2010</ref>). Many linguistic features and ML methods have been proposed for the PPI extraction task. Based on feature types, these approaches can be divided into three groups. The first group focuses on lexical and word context features.<ref type="bibr" target="#b4">Bunescu and Mooney (2005)</ref>designed a subsequence kernel which uses the following information in a sentence: before the first protein, between two proteins and after the second protein, and combined these features to obtain patterns.<ref type="bibr" target="#b10">Giuliano et al. (2006)</ref>extended this approach by using a bag-ofwords (BOWs) and adding a local context kernel. The second group exploits syntactic features of a sentence.<ref type="bibr" target="#b23">Saetre et al. (2007)</ref>used various syntactic path features and context features related to words before, between and after two interacting entities.<ref type="bibr" target="#b12">Katrenko and Adriaans (2007)</ref>proposed a method based on information found in the predefined levels of the dependency trees, such as local dependency contexts of the protein names and tree's roots.<ref type="bibr" target="#b13">Kim et al. (2008)</ref>enhanced previous work by proposing a walk kernel which explores the shortest dependency path between two proteins and a modified dependency tree with the parts-of-speech (POS) features. As an alternative to previous approaches,<ref type="bibr" target="#b0">Airola et al. (2008)</ref>introduced an all-paths graph kernel. They represented a sentence with a dependency graph and considered dependencies connecting two entities outside the shortest path as well as on the shortest path. Along with the proposed methods,<ref type="bibr" target="#b7">Fayruzov et al. (2009</ref><ref type="bibr">), Niu et al. (2010</ref><ref type="bibr" target="#b25">) and Van Landeghem et al. (2008</ref>also studied individual impact of a variety of feature types on the PPI extraction task. In addition, a study of<ref type="bibr" target="#b19">Miyao et al. (2009)</ref>has shown that the accuracy of syntactic parsers also contributes to the overall performance of the PPI systems. To compensate for the limitations of each individual feature set and parser errors,<ref type="bibr">Miwa et al. (2009a, b)</ref>proposed a method that combines all the lexical and parsing features using multiple kernels and parsers. Their system achieved the state-ofthe-art performance on a number of benchmark datasets. However,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q.-C.Bui et al.</head><p>the studies by<ref type="bibr" target="#b7">Fayruzov et al. (2009) and</ref><ref type="bibr" target="#b14">Kim et al. (2010)</ref>also demonstrated that if two feature types have overlapping rather than complimentary effects, dropping one of them can result in a computationally more efficient method and potentially make a mining algorithm more robust. This argument was also confirmed in the work of<ref type="bibr" target="#b17">Miwa et al. (2009b)</ref>who showed that excluding the BOWs feature leads to better performance on the AIMed corpus. Although many approaches have been proposed in the past, the problem of finding the most suitable features for extracting PPIs remain. Adding more features might sometimes improve performance, but they can introduce noise in other cases, or require more computational resources (<ref type="bibr" target="#b14">Kim et al., 2010</ref>). In this study, we propose a novel method that consists of two phases. First, we apply semantic rules to partition the dataset into subsets according to its semantic properties and extract candidate PPI pairs from these subsets. Second, we introduce enhanced feature sets for use with a ML classifier to classify these extracted PPI pairs. To the best of our knowledge, this is the first method that categorizes data into subsets and selects the most appropriate features for each subset. As a result, we increase the robustness of the learning method and make it computationally effective. In general, a PPI extraction system consists of two subtasks: recognizing protein names (NER) and extracting PPI pairs. However, this study only focuses on the PPI extraction task with an assumption that relevant named entities were given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>The workflow of the proposed system is as follows:</p><p>(1) Text preprocessing.</p><p>(2) Extracting candidate PPI pairs.</p><p>(3) Classifying extracted PPI pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text preprocessing</head><p>Text preprocessing includes converting protein names using a predefined rule set, filtering out input sentences with only one protein, splitting input sentences contain multiple clauses, and parsing sentences using the Stanford lexical parser (<ref type="bibr" target="#b15">Klein and Manning, 2003</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Processing protein names</head><p>In order to improve accuracy of the parser, we replace all mentioned protein names with a place holder, i.e. PRO1, PRO2 (we refer to them as PRO*). We define a rule set to resolve the problem with embedded protein names (e.g. AIMed corpus), protein names that share prefix or suffix (e.g. AIMed and BioInfer corpora) and protein names including multiple positions. After this process, the number of proteins in the sentence is not changed. The list of original protein names for each sentence is maintained for reference purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Replacing parenthetical remarks and splitting a sentence</head><p>If no word inside parentheses is a protein name, then all words and the parentheses are removed. In case the sentence consists of multiple clauses, the system splits it into clauses. The resulting sentence is referred to as a simplified sentence. In the last step of text preprocessing, a simplified sentence that contains at least two protein names is analyzed with the Stanford lexical parser to produce a syntactic tree. All parse trees are stored in a local database for later use. An example of a sentence and its output after text-preprocessing step is given below:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extracting candidate PPI pairs</head><p>Previous studies (<ref type="bibr" target="#b3">Bui et al., 2010;</ref><ref type="bibr" target="#b8">Fundel et al., 2007;</ref><ref type="bibr" target="#b22">Rinaldi et al., 2010</ref>) have shown that, in biomedical text, relation between two entities (protein– protein, protein–gene, drug–mutation and others) can be expressed in the following abstract forms:Here, REL is a cue word (interaction, inhibit, etc.) and can be a noun or a verb, word * are tokens between PRO* and REL. PRO i and PRO j can be any protein pair with j ≥ i+1 (e.g. &lt;PRO1, PRO2&gt;). In addition, a closer look at the annotated corpora (e.g. AIMed and BioInfer) reveals that we can define two more forms: Form 4 (compound form): PRO i /PRO i+1 or PRO i PRO i+1 or PRO i-PRO i+1 , if two entities appear in the sentence with the patterns above, they seem to have interaction.Form 4 is expressed as a pattern and requires an exact match. For other forms, there might be one or more tokens between &lt;PRO i , REL&gt;, &lt;REL, PRO j &gt; or &lt;PRO i , PRO j &gt;. Based on these basic forms, we now map the semantic relations of these forms into parse trees. For convenience, we define the following patterns:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example: PRO1/PRO2 binding; PRO1-PRO2 compound.</head><p>(a)Here S (clause), NP (noun phrase), VP (verb phrase), PP (prepositional phrase) and SBAR (subclause) are constituents of the parse tree, PRO* is a place holder for a protein name, and REL is a cue word of the input sentence. All patterns above are written using the Tregex syntax (http://nlp.stanford.edu/software/tregex.shtml), which is developed within the Stanford parser package.<ref type="figure" target="#fig_4">Figure 1</ref>illustrates some parse trees with the patterns mentioned above, e.g. the parse tree in<ref type="figure" target="#fig_4">Figure 1a</ref>shows a full clause,<ref type="figure" target="#fig_4">Figue 1b</ref>shows a NP pattern and<ref type="figure" target="#fig_4">Figure 1c</ref>shows a subclause.In the following section, we describe the procedures and algorithm to extract candidate PPI pairs from a parse tree or a simplified sentence: Procedure for Form 1: this procedure requires a parse tree which contains full clause, partial clause or subclause patterns. The procedure is as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Relation list</head><p>(a) Check a head word of VP that corresponds to satisfied pattern. If this verb belongs to the relation list, use it as REL.</p><p>((c) parse tree satisfies subclause pattern. Some features (D1, D2, H1, H2) and paths from the join node connecting a given protein pair (PRO1, PRO2) are also shown in (a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A hybrid approach to extract PPI</head><formula>(c)</formula><p>Create a left_keys list: use all keys in NP if a satisfied pattern is full clause or subclause. If a pattern is partial clause, then find a sister NP immediately preceding VP.</p><p>(d) Form candidate PPI pairs: enumerate the left_keys and right_keys to compose a triple &lt;PRO i-REL-PRO j &gt;.</p><p>Procedure for Form 2: form candidate PPI pairs from a simplified sentence if they satisfy the following form: PRO i word * REL word * PRO j. Procedure for Form 3: this procedure requires a parse tree which contains NP pattern. The procedure is as follows:</p><p>(a) Check a head word of NP that corresponds to satisfied pattern. If this noun belongs to the relation list, use it as REL.</p><p>(b) Find a proposition as a splitter in pattern's PP phrase in order to create left_keys and right_keys lists.</p><p>(Procedure for Form 5: form candidate PPI pairs from a simplified sentence if they satisfy the following form: PRO i word * PRO j word * REL,and if the distance from the PRO i to the REL is shorter than five tokens. For these procedures, the extracted candidate PPI pairs obtained from the same procedure are grouped together, i.e. outputs from Form 1 are grouped into group 1. Among these groups, group 2 overlaps group 1 when REL is a verb, with the purpose to recover PPI pairs that the group 1 failed to extract due to the parser errors (<ref type="bibr" target="#b19">Miyao et al., 2009</ref>). As a consequence, in some cases, a PPI pair may belong to more than one group. Therefore, the order in which patterns are applied is important (as described in the Algorithm 1 below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Features</head><p>In this section, we propose feature sets for ML classification. Our feature sets are combinations of some features that were previously proposed by<ref type="bibr" target="#b5">Chowdhary et al. (2009</ref><ref type="bibr" target="#b10">), Giuliano et al. (2006</ref><ref type="bibr" target="#b16">), Miwa et al. (2009a</ref>) and<ref type="bibr">Niu et al. (2010)</ref>. For each candidate PPI pair extracted from an input sentence, the system outputs a triple, e.g. &lt;PRO i , REL, PRO j &gt; then the following features are generated: Keyword: is a relation word (REL) from the extracted triple. In addition, we also count the number of protein names (C1) and relation words (C2) in each simplified sentence. Distance: we use two features: D1, D2 (<ref type="figure" target="#fig_4">Fig. 1a</ref>) to measure the distance (number of words/tokens) between PRO i-REL and REL-PRO j (or between REL-PRO i and PRO i-PRO j for group 3). Height: we use two features: H1, H2 (<ref type="figure" target="#fig_4">Fig. 1a</ref>) to measure the distance from the joint node connecting PRO i and PRO j in the parse tree. These features are similar to D1 and D2 except that they measure the number of nodes on the paths from a local root to PRO i and PRO j. POS: we use two lists: Pos1, Pos2 (<ref type="figure" target="#fig_4">Fig. 1a</ref>) to store POS and syntactic features from the joint node connecting PRO i and PRO j in the parse tree, respectively. Lexical: this feature is a modification of a BOWs. Instead of using all tokens, we only consider tokens that belong to the relation list and a list of prepositions: and, or, by, through, in, of, to and between. If a token is a protein (PRO*), then its value is replaced with 'KEY'. We use four lists of tokens: L1: a list of tokens between PRO i and REL, or between REL and PRO i for group 3. L2: a list of tokens between REL and PRO j , or between PRO i and PRO j for group 3.Selection of features for each individual group: the important benefit of partitioning data into subsets is that we can select the most appropriate features for each subset. Let us consider the following two cases: a PPI pair in form 4 (compound form) and a PPI pair in form 1 (full clause). For a PPI pair in a compound form, e.g. PRO1-PRO2, the shortest path features proposed in the previous work become useless because no feature can be extracted from this path. In this case, the BOW features seem to be the most appropriate ones. In contrast, for the PPI pairs in form 1, e.g. PRO1 interacts with PRO2, the shortest path, and the tokens between PRO1 and PRO2, play an important role. Based on the properties of each group of extracted PPI pairs, we manually select features that are potentially suitable for that group.<ref type="figure" target="#tab_1">Table 1</ref>shows the list of features corresponding to each group. Furthermore, we also use the Ranker (attribute selection) method from the WEKA ML package (<ref type="bibr" target="#b26">Witten and Frank, 2005</ref>) to determine the length of the POS and lexical lists, which are limited to maximum six attributes. ML method: Support vector machines (SVMs) have been widely used in the PPI extraction task, and has shown competitive performance over other learning methods (<ref type="bibr" target="#b14">Kim et al., 2010;</ref><ref type="bibr" target="#b24">Saetre et al., 2010</ref>). In this work, we use SVM classifier with a default RBF kernel and tune the complexity parameter C by using CVParameterSelection function from the WEKA. All individual features mentioned above are combined into a single feature vector for the classification task. Depending on each group of PPI candidates, the number of features ranges from 14 to 26 as shown in<ref type="figure" target="#tab_1">Table 1</ref>. For example, for a candidate PPI pair &lt;PRO1, PRO2&gt; extracted from group 1 (as shown in<ref type="figure" target="#fig_4">Fig. 1a</ref>), the following features are generated: REL: mediate; D1: 1, D2: 6; C1: 3, C2: 2; H1: 5, H2: 4; L1: null, null, null; L2: association, with, null; Pos1: NP, PP, NP, NN, null, null; Pos2: VB, PP, NP, NN, null, null, true. For more details on text preprocessing, PPI extraction and feature generation steps, see Supplementary source code provided in this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 262 259–265</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q.-C.Bui et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We use five corpora (http://mars.cs.utu.fi/PPICorpora/GraphKernel .html) which have been converted into a unified format and are provided by<ref type="bibr" target="#b21">Pyysalo et al. (2008)</ref>: AIMed, BioInfer, HPDR50, IEPA and LLL.<ref type="figure" target="#tab_2">Table 2</ref>shows the quantitative information of all five corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation methods</head><p>We perform two types of evaluation, a single corpus test and a cross-corpora test. In the single corpus test, we evaluate the performance of the proposed method by 10-fold abstract-wise crossvalidation (CV), and use the one-answer-per-occurrence criterion (<ref type="bibr" target="#b17">Miwa et al., 2009b</ref>). We split the corpora as recommended by Airola<ref type="bibr">et al. (2008)</ref>in order to directly compare our results against the performance of other systems. In the cross-corpora test, we conduct two experiments. First, we use one corpus for training and test the system on the four remaining corpora. Second, we use four corpora (ALL) for training and test on the remaining corpus. Precision, recall and F-score are used as evaluation metrics. Let TP denote numbers of true positives, FP denote the number of false positives and FN denote the numbers of false negatives. The measures are defined as follows:<ref type="figure" target="#tab_3">Table 3</ref>shows the results of the PPI extraction algorithm on five corpora. In order to calculate recall for each corpus, we use the number of original positive pairs from<ref type="figure" target="#tab_1">Table 1</ref>(e.g. for AIMed, TP + FN = 1000, for BioInfer, TP + FN = 2534). It is worth noting that, in some systems (<ref type="bibr" target="#b0">Airola et al., 2008;</ref><ref type="bibr" target="#b14">Kim et al., 2010</ref>), selfinteraction pairs are removed prior to the evaluation; therefore, the F-score can be higher if we adopt these settings.<ref type="figure" target="#tab_3">Table 3</ref>also presents the properties of each extracted group in each corpus and the differences between corpora. Clearly, group 1 is the most common among all corpora and accounts for &gt;50% of TP pairs of all corpora except for BioInfer. The first three groups are also common for all five corpora and account for &gt;80% of the extracted pairs. However, groups 4 and 5 are more corpus-specific and can be found mostly in AIMed and BioInfer corpora. This information provides more insight for understanding the properties of five corpora studied previously by<ref type="bibr" target="#b21">Pyysalo et al. (2008</ref>).The results in<ref type="figure" target="#tab_3">Table 3</ref>demonstrate that the proposed algorithm is capable of extracting of &gt;80% of positive pairs (recall &gt; 80%) on AIMed, HPRD50, IEPA and LLL corpora. This means that these four corpora share some common patterns or the same annotation policy. However, our method can only extract 67% positive pairs from BioInfer. To find out why our algorithm has lower recall on the BioInfer corpus, we examine sample sentences from BioInfer which the system failed to extract. By analyzing these sentences, we discovered that in some cases, BioInfer has a special annotation policy. Consider, for example, the following sentence:</p><formula>Recall = TP/(TP + FN) Precision = TP/(TP + FP) F-score = 2 * Recall * Precision/(Recall + Precision)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Performance of PPI extraction algorithm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A hybrid approach to extract PPI</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BioInfer.d436.s0: Moreover, ectopic expression of PRO0 and PRO1 can stimulate the PRO2 promoter in an PRO3-dependent manner, and this is inhibited by coexpression of the PRO4 (PRO5) PRO6.</head><p>For this input sentence, our system extracts only four TP pairs, but the number of positive PPI pairs provided by the BioInfer corpus is 11 (see sentence BioInfer.d436.s0 in BioInfer corpus for more detail). Therefore, to increase recall on BioInfer, additional study of this corpus is needed.<ref type="figure" target="#tab_3">Table 3</ref>also shows that the performance of algorithm 1 is comparable with other ML-based systems. Moreover, it outperforms the best rule-based system on all five corpora<ref type="bibr">[see Kabiljo et al. (2009)</ref>for more details].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Single corpus evaluation</head><p>With the extracted PPI pairs obtained in the previous step, we use a standard SVM classifier to classify them. Comparing with the original data from<ref type="figure" target="#tab_1">Table 1</ref>, the number of positive and negative instances of the AIMed and BioInfer corpora are quite balanced (<ref type="figure" target="#tab_3">Table 3</ref>). To calculate the F-score, we accumulated all TP and FP pairs from the 10-fold CV test (reported by WEKA via the confusion matrix). For TP + FN values, similarly to Section 3.3, we use the original positive pairs of each corpus in<ref type="figure" target="#tab_1">Table 1</ref>. For the IEPA, HPRD50 and LLL corpora, however, we only use the first three groups of extracted pairs because the number of candidate pairs in the groups 4 and 5 is too small for the 10-fold CV.<ref type="figure" target="#tab_4">Table 4</ref>shows the performance of the classifier on five corpora. The results indicate that by using our feature vectors, the classifier can further boost the performance of the overall system. When comparing precision on each corpus before and after applying classification, we can see a significant increase in precision (P values). Among all corpora, the AIMed corpus gains the most increase in precision with P of 14%. Even on a small corpus like LLL, with already very high precision, the final precision still gains<ref type="figure" target="#tab_4">Table 4</ref>shows that our system achieves the best performance on three corpora: IEPA, HPRD50 and LLL using 10-fold CV when compared with other results reported so far. To study the benefit of filtering data (obtained after applying rules on the full dataset) and partitioning data, we conduct the experiment in which the full dataset and the filtered dataset use all features in<ref type="figure" target="#tab_1">Table 1</ref>. However, in this experiment the REL feature is not available, D1 and D1 features are replaced by D1+D2 and L1 and L2 features are merged.<ref type="figure" target="#tab_5">Table 5</ref>summarizes the performance of the system on the full dataset (all PPI pairs), filtered dataset and partitioned dataset. The results from<ref type="figure" target="#tab_5">Table 5</ref>show that when evaluating on filtering dataset, the system has better performance on all five corpora compared with full dataset. In addition, the performance further improve on three largest corpora (AIMed,</p><p>BioInfer and IEPA) when we partition data and select feature specific for each sub-dataset. This clearly shows the benefit of our hybrid approach that combines rule with partition data.<ref type="figure" target="#tab_6">Table 6</ref>illustrates a comparison of our system (BKS) against recent work on the AIMed corpus, which is considered the de facto benchmark for the PPI extraction task. However, the comparison may not be straightforward because these PPI systems can use different text preprocessing and learning methods. The results show that our system with its F-score of 61.2% is comparable with the state-of-the-art systems proposed by<ref type="bibr" target="#b16">Miwa et al. (2009a) and</ref><ref type="bibr" target="#b24">Saetre et al. (2010)</ref>. In addition, our approach significantly outperforms other methods based on one parser's output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Cross-corpora evaluation</head><p>In addition to the standard 10-fold CV, recent studies also suggested to test existing approaches to PPI extraction using cross-corpora. This type of evaluation can show whether a system trained on one corpus can perform equally well on other corpora, with an Page: 264 259–265Columns correspond to training and rows correspond to testing corpora. ALL refers to a situation where four corpora are used for training and the remaining corpus for testing. Precision (P) and F-score (F) are shown in percentage (%). assumption that these corpora addressed the same PPI task. In this setting, one corpus is used for training and the remaining corpora are used for testing. For the evaluation, we only use the two largest corpora, i.e. AIMed and BioInfer, for training since the other corpora are too small after partitioning onto five groups. Furthermore, we conduct the experiment proposed by<ref type="bibr" target="#b7">Fayruzov et al. (2009) and</ref><ref type="bibr" target="#b11">Kabiljo et al. (2009)</ref>, in which four corpora are used for training and the remaining corpus for testing.<ref type="figure" target="#tab_7">Table 7</ref>shows the results of the cross-corpora evaluation on five corpora. Here, the columns correspond to the training set and the rows correspond to test sets.<ref type="figure" target="#tab_7">Table 7</ref>illustrates that our system achieves the best performance when BioInfer is used as the training set. Note that we do not use data from group 4 to group 5 due to theirs corpus-specific properties; therefore, the performance might be higher if these groups are used. This finding is also consistent with the evaluation results by<ref type="bibr" target="#b16">Miwa et al. (2009a) and</ref><ref type="bibr" target="#b0">Airola et al. (2008)</ref>. In their work, better performance is also obtained with BioInfer being used for training. Interestingly,<ref type="figure" target="#tab_7">Table 7</ref>shows that even though the F-score on each corpus in the cross-corpora test is lower than F-score in the single corpus test, the precision is significantly higher when compared against the initial values in<ref type="figure" target="#tab_3">Table 3</ref>. This means that performance on all corpora can be boosted when precision is given a priority. This also implies that the classifier is able to learn from crosscorpora training data. In other words, the proposed feature vectors are compatible across the corpora.<ref type="figure" target="#tab_8">Table 8</ref>shows the performance of our system (BKS) in the crosscorpora setting compared with other approaches. The results in<ref type="figure" target="#tab_8">Table 8</ref>demonstrate that BKS outperforms others when AIMed and BioInfer corpora are used as training sets. In addition, for all evaluation tests, we use the same settings for training corpora except for the complexity term (C parameter of the RBF kernel). This is one step closer to the real world situation. However,<ref type="bibr" target="#b17">Miwa et al. (2009b)</ref>have obtained higher performance compared with ours by applying corpus weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q.-C.Bui et al.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Computational performance</head><p>Another important aspect in PPI extraction is the computational time taken to train and test the system. A previous study by<ref type="bibr" target="#b25">Van Landeghem et al. (2008)</ref>has shown that in order to reduce the number of computational resources used by ML, one has to consider a trade-off between performance (in this case measured by the F-score) and the computational time required by ML. Despite thisfact, only few systems report on how many computational resources their systems use for training and testing.<ref type="bibr" target="#b17">Miwa et al. (2009b)</ref>demonstrate that by using suitable features as well as a learning method, they can improve the performance of their previously proposed system (<ref type="bibr" target="#b16">Miwa et al., 2009a</ref>). In addition, Fayruzov et al.</p><p>(2009) have pointed out that the more kernels the system uses the more computational resources are needed.<ref type="figure" target="#tab_9">Table 9</ref>shows the running time of our system on the full dataset compared against partitioned dataset of the AIMed corpus. The system runs much faster on the partitioned dataset with both RBF kernels from WEKA and LibSVM (http://www.csie.ntu.edu. tw/∼cjlin/libsvm/). In addition, since our method partitions data into five groups, we also test it in a node with eight CPUs (Xeon 3.0 GHz). In this test, we use the RBF kernel from LibSVM and the classifiers are run in parallel. The maximum time used by the system is 12 s. This means that our system not only runs fast on a single PC, but can also be used in parallel, which is particularly suited for large-scale experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSIONS</head><p>In this article, we propose a novel method for extracting PPI pairs from literature. Our approach combines the strength of both semantic rules and ML classification. The evaluation on five benchmark corpora has shown that our system achieves results comparable with the best PPI extraction methods on a single corpus. It outperforms other systems on cross-corpora test and has fast running time. The proposed method consists of two phases: partitioning data into subsets then extract candidate PPI pairs from these subsets, and classifying extracted PPI pairs. The advantages of this method are</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Page: 265 259–265</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A hybrid approach to extract PPI</head><p>4-fold. First, it filters out a significant amount of negative (noninteraction) PPI pairs, thus balancing the number of positive and negative pairs in training data. Second, by partitioning data into subsets, we can select the most appropriate features for each subset, which potentially improves the final performance. Third, our system only uses a small set of features and therefore performs the best in terms of computational resources. Finally, the classifier can be run in parallel on each subset, which is desirable for the large-scale experiments. In addition, our method uses five semantic rules; therefore, it is generic and can be easily applied to new datasets. Furthermore, it is easy to set-up because it only uses publicly available NLP tools and a standard ML package. In addition, the proposed method can also be extended to extract new relation types in biomedical text, e.g. complex event extraction (<ref type="bibr" target="#b2">Björne et al., 2010</ref><ref type="bibr" target="#b18">, Miwa et al., 2010</ref><ref type="bibr" target="#b22">, Rinaldi et al., 2010</ref>). For future work, we plan to integrate a NER tagger into our system in order to study the effect of its performance when a gold-standard NER is not given. In addition, the performance of the overall PPI extraction task largely depends on the output of the extraction phase. Increasing recall in this phase would further boost the performance, especially in case of the BioInfer corpus.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Form</head><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Full clause: S &lt; ((NP PRO*) $++ (VP PRO*)) (b) Partial clause: VP&lt; ((NP PRO*) $++ (S &lt; (VP PRO*))) (c) Subclause: S &lt; ((NP PRO*) $++ (VP &lt; (S|SBAR PRO*))) (d) NP pattern: NP&lt; ((NP # REL) $++ (PP PRO*))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><figDesc>We created a relation list by combining the relation lists used in the previous work by Chowdhary et al. (2009), Fundel et al. (2007) and Niu et al. (2010).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.1.</head><figDesc>Fig. 1. Examples of parse trees output from the Stanford lexical parser: (a) parse tree satisfies full clause pattern, (b) parse tree satisfies NP pattern and (c) parse tree satisfies subclause pattern. Some features (D1, D2, H1, H2) and paths from the join node connecting a given protein pair (PRO1, PRO2) are also shown in (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm1.</head><figDesc>// Algorithm to extract candidate PPI pairs. Input: simplified sentence, parse tree and the relation list Output: list of candidate PPI pairs of corresponding groups Init: used_list = null // store extracted pairs to avoid overlap since one pair can satisfy more than one pattern. For a list of subsentence/parse tree For form from 1 to 5 Extract candidate pairs from parse tree or simplified sentence If candidate pairs found For each candidate pair Check whether this pair in the used_list If not found Store this pair to the corresponding group Store this pair to the used_list End if End for End if End for End for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><figDesc>[13:34 16/12/2010 Bioinformatics-btq620.tex] Page: 263 259–265</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Form 1: PRO i word * REL (verb) word * PRO j Example: PRO1 interacts with PRO2. Form 2: PRO i word * REL (noun/verb) word * PRO j Example: PRO1 has a weak interaction with PRO2. Form 3: REL (noun) word * PRO i word * PRO j Example: interaction between PRO1 and PRO2.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>5 (complex form): PRO i word * PRO j word * REL</figDesc><table>Example: PRO1, PRO2 interact; in PRO1, PRO2 complex. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><figDesc>b) Create a right_keys list: use all keys in VP as right_keys.</figDesc><table>[13:34 16/12/2010 Bioinformatics-btq620.tex] 

Page: 261 259–265 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>c) Form candidate PPI pairs: enumerate the left_keys and right_keys to compose a triple &lt;PRO i-REL-PRO j &gt;. Procedure for Form 4: form candidate PPI pairs from a simplified sentence if they satisfy any of the following forms: PRO i /PRO i+1 ; PRO i PRO i+1 ; PRO i-PRO i+1 .</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><figDesc>Table 1. List of features and their usage for each group</figDesc><table>Feature 
Keyword 
Distance 
Height 
POS 
Lexical 

Group 1 
Rel, C1, C2 
D1, D2 
H1, H2 
Pos1,2 
L1, L2 
Group 2 
Rel 
D1, D2 
H1, H2 
L1, L2 
Group 3 
Rel, C1, C2 
D1, D2 
H1, H2 
Pos1,2 
L1, L2 
Group 4 
C1, C2 
L3, L4 
Group 5 
Rel C1, C2 
D1, D2 
L3, L4 

L3: a list of tokens before PRO i . 

L4: a list of tokens after PRO j . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 2. Statistics on five corpora</figDesc><table>Corpus 
AIMed 
BioInfer 
HPRD50 
IEPA 
LLL 

Positive pairs 
1000 
2534 
163 
335 
164 
All pairs 
5834 
9666 
433 
817 
330 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><figDesc>Table 3. Results of PPI extraction algorithm on five corpora</figDesc><table>Corpus 
AIMed 
BioInfer 
HPRD50 
IEPA 
LLL 

TP FP 
TP 
FP 
TP FP 
TP FP TP FP 

Group 1 
500 701 849 648 101 38 
170 78 106 13 
Group 2 
143 112 215 154 
14 10 
26 26 
2 4 
Group 3 
113 322 330 529 
17 23 
92 61 
32 11 
Group 4 
22 55 170 
73 
0 8 
4 3 
0 2 
Group 5 
39 192 134 182 
6 5 
3 6 
0 1 

Total 
817 1382 1698 1586 138 84 
295 174 140 31 
Recall (%) 
81.7 
67 
84.7 
88.1 
85.4 
Precision (%) 37.2 
51.7 
62.2 
62.9 
81.9 
F-score (%) 51.1 
58.4 
71.7 
73.4 
83.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><figDesc>Table 4. Results of the 10-fold abstract-wise CV on five corpora P and F show the increase in precision and F-score compared with their corresponding values in Table 3. The values are shown in percentage (%).</figDesc><table>Corpus 
Precision 
P 
Recall 
F-score 
F 

AIMed 
55.3 
18 
68.5 
61.2 
10 
BioInfer 
61.7 
10 
57.5 
60.0 
2 
HPRD50 
70.2 
8 
77.9 
73.8 
2 
IEPA 
67.4 
5 
83.9 
74.7 
1 
LLL 
84.1 
2 
84.1 
84.1 
1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="true"><figDesc>Table 5. Performance comparison between full dataset, filtered dataset and partitioned dataset using 10-fold CV on five corpora</figDesc><table>Corpus 
AIMed 
BioInfer 
HPRD50 
IEPA 
LLL 

Full dataset 
52.5 
58.7 
68.6 
72 
83.6 
Filtered dataset 
55.2 
59.6 
76.0 
72.9 
84.4 
Partitioned dataset 
61.2 
60.0 
73.8 
74.7 
84.1 

Full dataset and filtered dataset use the same feature sets. The performance is measured 
by the F-score (%). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="true"><figDesc>Table 6. Performance comparison with other systems on AIMed</figDesc><table>System 
Description 
F-score (%) 

Saetre (2010) 
Feature-based, two parsers 
64.2 
Miwa (2009a) 
Multiple kernels, two parsers 
60.8 
Kim (2010) 
Walk-weighted subsequence 
kernels, one parser 

56.6 

Airola (2008) 
All-paths graph kernel, one parser 
56.4 
Niu (2010) 
Linear kernel, one parser 
53.5 
BKS 
RBF kernel, one parser 
61.2 

2%. For each corpus, recall decreases after applying classification 
but the final F-scores increase for all corpora and range from 1% 
to 10%. Furthermore, </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="true"><figDesc>Table 7. Results of the cross-corpora test on five corpora</figDesc><table>Corpus 
AIMed 
BioInfer 
ALL 

P 
F 
P 
F 
P 
F 

AIMed 
– 
– 
44.4 
55.2 
44.1 
55.1 
BioInfer 
57.1 
54.4 
– 
– 
64.3 
50.5 
HPRD50 
67.0 
72.3 
69.9 
74.0 
68.8 
70.8 
IEPA 
67.3 
73.6 
68.6 
73.8 
70.1 
72.9 
LLL 
85.7 
83.0 
85.0 
82.4 
86.0 
80.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="true"><figDesc>Table 8. Performance comparison with other systems using cross-corpora evaluation</figDesc><table>AIMed 
BioInfer 

BKS 
Miwa 
Airola 
BKS 
Miwa 
Airola 
(2009a) 
(2008) 
(2009a) 
(2008) 

AIMed 
– 
– 
– 
55.2 
49.6 
47.2 
BioInfer 
54.4 
53.1 
47.1 
– 
– 
– 
HPRD50 
72.3 
68.3 
69.0 
74.0 
68.3 
63.9 
IEPA 
73.6 
68.1 
67.4 
73.8 
71.4 
68.0 
LLL 
83.0 
73.5 
74.5 
82.4 
76.9 
78.0 

Columns correspond to training and rows correspond to test sets. The performance is 
measured by the F-score (%). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><figDesc>Table 9.</figDesc><table>Computational time for 10-fold CV of full and partitioned dataset 
of the AIMed corpus 

Dataset 
WEKA – RBF 
LibSVM -RBF 

Full dataset (s) 
10 812 
194 
Partitioned dataset (s) 
77 
39 

These values exclude time for parsing and text preprocessing. Two RBF kernels from 
WEKA and LibSVM are used. The experiment is run on a PC with an Intel 3.2 GHz 
processor and 4 GB of RAM. 

</table></figure>

			<note place="foot">at :: on August 31, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors sincerely thank Dr Makoto Miwa and Rick Quax for their useful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">All-paths graph kernel for protein-protein interaction extraction with evaluation of cross-corpus learning</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Airola</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Text mining and its potential applications in systems biology</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ananiadou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Biotechnol</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="571" to="579" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Complex event extraction at PubMed scale</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Björne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="382" to="390" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Extracting causal relations on HIV drug resistance from literature</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<forename type="middle">C</forename>
				<surname>Bui</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="issue">11 101</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Subsequence kernels for relation extraction</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Bunescu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mooney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th conference on Neural Information Processing Systems</title>
		<meeting>the 19th conference on Neural Information Processing Systems<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Bayesian inference of protein-protein interactions from biological literature</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Chowdhary</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1536" to="1542" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Literature-curated protein interaction datasets</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Cusick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Linguistic feature analysis for protein interaction extraction</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Fayruzov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">374</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">RelEx-Relation extraction using dependency parse trees</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Fundel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="365" to="371" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-scale directional relationship extraction and resolution</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Giles</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wren</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploiting shallow linguistic information for relation extraction from biomedical literature</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Giuliano</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Conference of the European Chapter</title>
		<meeting>the 11th Conference of the European Chapter<address><addrLine>Trento</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A realistic assessment of methods for extracting gene/protein interactions from free text</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kabiljo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">233</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Relations from Biomedical Corpora Using Dependency Trees</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Katrenko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Adriaans</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Discov. Emerg. Compl. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">4366</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Kernel approaches for genic interaction extraction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="118" to="126" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Walk-weighted subsequence kernels for protein-protein interaction extraction</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Fast Exact Inference with a Factored Model for Natural Language Parsing</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Klein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Manning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Protein–protein interaction extraction by leveraging multiple kernels and parsers</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Miwa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Med. Inform</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="39" to="46" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">A rich feature vector for protein-protein extraction from multiple corpora</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Miwa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Event extraction with complex event classification using rich features</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Miwa</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bioinform. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="131" to="146" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluating contributions of natural language parsers to proteinprotein interaction extraction</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Miyao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="394" to="400" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of linguistic features useful in extraction of interactions from PubMed; Application to annotating known, high-throughput and predicted interactions in I2D</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Niu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="111" to="119" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Comparative analysis of five protein-protein interaction corpora</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pyysalo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">OntoGene in BioCreative II.5</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Rinaldi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="472" to="480" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Syntactic features for protein-protein interaction extraction</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Saetre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Symposium on Languages in Biology and Medicine</title>
		<meeting>the 2nd International Symposium on Languages in Biology and Medicine<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Extracting Protein-Interactions from Text with the Unified AkaneRE Event Extraction System</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Saetre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. Comput. Biol. Bioinform</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="442" to="453" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Extracting protein-protein interactions from text using rich feature vectors and feature selection</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Van Landeghem</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Symposium on Semantic Mining in Biomedicine</title>
		<meeting>the Third International Symposium on Semantic Mining in Biomedicine<address><addrLine>Turku, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Data Mining: Practical Machine Learning Tools and Techniques</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<forename type="middle">H</forename>
				<surname>Witten</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Frank</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>