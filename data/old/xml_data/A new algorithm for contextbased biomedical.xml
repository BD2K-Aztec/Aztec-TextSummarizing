
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bioimage informatics A new algorithm for context-based biomedical diagram similarity estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013">2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Songhua</forename>
								<surname>Xu</surname>
							</persName>
							<email>songhua.xu@njit.edu,</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Information Systems Department</orgName>
								<orgName type="department" key="dep2">College of Computing Sciences</orgName>
								<orgName type="institution" key="instit1">New Jersey Institute of Technology</orgName>
								<orgName type="institution" key="instit2">University Heights</orgName>
								<address>
									<postCode>07102</postCode>
									<settlement>Newark</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jianqiang</forename>
								<surname>Sheng</surname>
							</persName>
							<email>shengjianqiang@163.com or lnslxn@ mail.sysu.edu.cn.</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">National Engineering Research Center of Digital Life</orgName>
								<orgName type="department" key="dep2">State-Province Joint Laboratory of Digital Home Interactive Applications</orgName>
								<orgName type="department" key="dep3">School of Information Science and Technology</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Xiaonan</forename>
								<surname>Luo</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">National Engineering Research Center of Digital Life</orgName>
								<orgName type="department" key="dep2">State-Province Joint Laboratory of Digital Home Interactive Applications</orgName>
								<orgName type="department" key="dep3">School of Information Science and Technology</orgName>
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<postCode>510006</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bioimage informatics A new algorithm for context-based biomedical diagram similarity estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">29</biblScope>
							<biblScope unit="issue">6</biblScope>
							<biblScope unit="page" from="780" to="789"/>
							<date type="published" when="2013">2013</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btt030</idno>
					<note type="submission">Received on May 27, 2012; revised on January 11, 2013; accepted on January 17, 2013</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Jonathan Wren</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Diagrams embedded in the biomedical literature convey rich contents, which often concisely and intuitively highlight key thesis of a research article. Despite their vital importance and informative clues for biomedical literature navigation and retrieval; currently, we miss an effective computational method for automatically understanding and accessing these valuable resources. Proposed Method: To address the aforementioned gap, we propose a novel context-based algorithm for estimating the similarity between a pair of biomedical diagrams. The main difference of the proposed algorithm with respect to the existing methods lies in the new algorithm&apos;s incorporation of the semantic context associated with diagrams in their source documents into the diagram similarity estimation process. In addition, the new approach also performs a series of advanced image processing and text mining operations to comprehensively extract the semantic content graphically encoded inside diagram images. Results: The new algorithm can be deployed as a reusable component providing a fundamental function for building many advanced, semantic-aware applications on biomedical diagram processing. As a case study, in our experiments, we demonstrate the advantage of the new algorithm for diagram retrieval. A set of biomedical diagram search and ranking experiments were conducted, where the performance of the new method was compared with that of five peer methods. The comparison results demonstrate the performance superiority of the new algorithm with all peer methods with statistical significance. Contact:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Diagrams are widely used graphical vehicles for illustrating ideas, explaining hypotheses and reporting findings. They provide a powerful communication device for visually sharing key information supplied in a document. These visual elements are well received by readers—people often like to overview key contents of a document through browsing its embedded diagrams, if any. Such a diagram browsing-based practice for document navigation has been popularly adopted in reality by many biomedical researchers to cope with the exploding amount of biomedical literature in existence today. In this article, we propose a new diagram similarity estimation method, which exploits the context information of a diagram latent in its source document for deriving a high-level understanding over the diagram's intended semantic messages. As image similarity is of fundamental importance for many biomedical diagram image processing, understanding and retrieval tasks, our new similarity estimation method can be used for many advanced semantic computing applications relating to diagram images, such as searching, ranking, clustering and categorizing diagrams, to name a few. One important extended application of our algorithm is to apply the algorithm to empower search engines and digital library systems, so that they can more capably return diagrams and the corresponding source documents to meet users' needs and interests in diagram searching and diagram browsing-based visual literature navigation. Because of space limit, we will only report the results of our experiments that demonstrate the advantage of our method for diagram retrieval and ranking. In this article, we introduce a new method for context-based diagram similarity estimation via a probabilistic reasoning approach. Based on the new method, we build an algorithmic framework for deriving context-based diagram similarity, including procedures to detect nodes and edges from an input diagram image using off-the-shelf computer vision tools, a method to represent the extracted nodes and edges from the input diagram image as a graph and the procedure to apply the new method for deriving pairwise diagram similarity through cross-referencing the diagrams' graph representations and their source documents (see<ref type="figure" target="#fig_0">Fig. 1</ref>for an example). In the end, we also present extensive experimental results for validating the effectiveness of our new method in the application context of diagram retrieval and ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We will now briefly look at two aspects of work closely related to our study here, including (i) diagram similarity estimation and (ii) context-based image retrieval. Diagram similarity estimation. Significant efforts have been dedicated to designing algorithms and methods for estimating pairwise diagram similarity, most of which focus on processing *To whom correspondence should be addressed. y The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors. a specific type of diagram. For example, within the software engineering community, statecharts are a specialized type of diagrams widely used for illustrating calling logics in a software architecture design.<ref type="bibr" target="#b21">Nejati et al. (2007)</ref>studied the problem of optimally matching statecharts, where they offered a specialpurpose image similarity metric for measuring statechart similarity.<ref type="bibr" target="#b30">Wombacher (2006)</ref>validated a number of metrics for measuring the similarity between a pair of workflow diagrams, where each workflow is represented as finite state automata. All the metrics he evaluated can be broadly categorized into language and structure-based approaches. His study suggested that the relatively simple n-gram sets-based approach achieves the best performance among all peer methods.<ref type="bibr" target="#b10">Li et al. (2008)</ref>proposed a structural approach using high-level change operations for measuring similarity between two process model diagrams. Their idea is to find a minimum set of addition, deletion and moving operations to transform one diagram into another diagram, where the minimum number of transformation steps needed is used as the pairwise diagram distance.<ref type="bibr" target="#b3">Dijkman et al. (2011)</ref>experimentally compared three classes of similarity measurement methods for business process model diagrams—label similarity, structural similarity and behavioural similarity (element labels and causal relations captured in a process model). Their result shows that structural similarity attains the best performance.<ref type="bibr" target="#b4">Ehrig et al. (2007)</ref>introduced a method for measuring the similarity between a pair of business process model diagrams. Their method derives diagram similarity from three aspects: syntactic, linguistic and structural measures.<ref type="bibr" target="#b19">Minor et al. (2007)</ref>studied the problem of workflow diagram similarity estimation and retrieval by introducing a structure-based approach using a weighted graph edit distance.<ref type="bibr" target="#b18">Melnik et al. (2002)</ref>proposed a versatile graph matching algorithm, called 'similarity flooding', for matching data schema diagrams. Their algorithm first derives a similarity propagation graph to denote pairwise node similarities between two diagrams and then performs a similarity spreading process in the graph for deriving an optimal matching between the two diagrams.<ref type="bibr" target="#b16">Madhusudan et al. (2004)</ref>introduced a structural method using Artificial Intelligence (AI) planning techniques for comparing diagrams illustrating workflow models. Their method first uses a domain-independent AI planning-based approach to represent diagrams of business workflow models as cases and then adopts a case-based reasoning framework for deriving pairwise diagram similarity. Context-based information retrieval. A decade ago, Lawrence (2000) pointed out the importance of context in web search. Recently,<ref type="bibr" target="#b1">Belkin (2008)</ref>discussed the challenges associated with characterizing context for building information retrieval applications. Within the image retrieval field, people have explored contextual information for image processing, annotation and retrieval, e.g.<ref type="bibr" target="#b28">Sinha and Jain (2008)</ref>;<ref type="bibr" target="#b15">Luo et al. (2009)</ref>; O'Hare and Smeaton (2009);<ref type="bibr" target="#b14">Lopes (2009)</ref>; Segev and Toch (2009);<ref type="bibr" target="#b34">Yang et al. (2010)</ref>; Fisher and Hanrahan (2010);<ref type="bibr" target="#b2">Choi et al. (2010)</ref>;<ref type="bibr" target="#b33">Yang et al. (2011)</ref>. For the diagram retrieval problem, textual information carried inside a diagram only intends to shed highlights rather than to provide detailed explanation over the diagram's content; in addition, the caption of a diagram does not always cover every message illustrated in the diagram. Both factors incur computational difficulties for automatic diagram understanding and retrieval. In the bioinformatics literature,<ref type="bibr" target="#b17">Meekers and Rahaim (2005)</ref>observed the importance of socioeconomic context when developing social marketing models for improving reproductive health.<ref type="bibr" target="#b20">Moskovitch et al. (2007)</ref>designed a context-sensitive search method for retrieving medical text with better accuracy.Sinha and Jain (2008) described an unsupervised context analysis method for inferring context-specific gene regulatory networks from publicly available gene expression data. Rodriguez-Esteban and Iossifov (2009) introduced a figure mining method that jointly leverages image understanding, text mining and optical character recognition (OCR) techniques to retrieve tables and figures embedded in the biomedical literature that match a certain user-prescribed image type. Among all the methods surveyed earlier in the text, none has looked into the contextual information of diagrams as a clue for estimating diagram similarities. To develop more comprehensive and accurate understanding over a diagram's semantic contents, we propose to acquire supplementary contextual information of a diagram from its source document for estimating diagram similarity in a semantically meaningful way. Our proposed approach is also applicable for processing other generic types of figures, such as statecharts and workflow diagrams, even though our method works particularly effectively with biomedical contents because of the prevalence of diagrams in biomedical publications. To the best of our knowledge, no published efforts have previously pursued this idea in the biomedical informatics field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">REPRESENTING A DIAGRAM WITH ITS DOCUMENT CONTEXT AS A GRAPH</head><p>Given a diagram G embedded in its source document D, in our method, we represent it as an attributed undirected graph. Each entity in G is represented as a node in the graph; each visually illustrated relationship between entities in G is represented as an edge in the graph. When no ambiguity arises, we will not differentiate the diagram from its graph representation. We can formally characterize G as ðNðGÞ, EðGÞ, WðGÞÞ, where NðGÞ ¼ fN i jN i 2 Gg is the set of nodes in G; EðGÞ ¼ fE i, j jN i , N j 2 NðGÞ, E i, j 2 Gg is the set of edges in G; WðGÞ is a weighted adjacency matrix, which describes whether two nodes in the diagram are connected, and if so, how intensively the source document D discusses the semantic relationship represented by the edge, or how saliently the semantic relationship is embodied in D. We will look at how to derive WðGÞ later. As from the matrix WðGÞ, we can readily understand the node connectivity information, we can more compactly characterize a diagram as ðNðGÞ, WðGÞÞ, without losing any information.<ref type="figure" target="#fig_0">Figure 1</ref>gives an example of two sample diagrams' graph representations constructed by our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Detecting nodes from a diagram</head><p>Given an input diagram G in the form of a static image, we detect its nodes and edges through a set of image processing steps as follows. We first apply the Gaussian filter function offered by the OpenCV 2.2.0 package (http://sourceforge.net/projects/opencvlibrary) to remove local image noise from G. We then detect from G a collection of basic shape elements, including quadrilaterals, circles and ellipses. In our current implementation, we adopt the method proposed in the study by<ref type="bibr" target="#b25">Qin et al. (2010)</ref>to detect these elements. For each detected shape element, we further attempt to recognize any text that may be carried inside the interior image region of the shape. This text recognition task is accomplished by parsing the image region to the OCR tool provided in the Microsoft Office 2007 Document Imaging package. In our OCR process, currently, we only process English contents. For each recognized word from the OCR process, we match the word against the full text of the diagram's source document D. Only words that occur in D will be retained; the rest of the words will be considered OCR errors and, hence, discarded. For all remaining OCR result words, we further remove stop words. Finally, we perform a stemming process to restore each word to its basic root form. Each shape element detected previously will be represented as a node N i. In this way, we establish our node set NðGÞ ¼ fN 1 , N 2 , Á Á Ág, where each N i is a shape element. After this step, we remove from the image G all the detected shape elements, including their interior image regions, to make the downstream image processing steps more reliable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Detecting edges from a diagram</head><p>To construct the edge set EðGÞ for representing the node connectivity information in the diagram, we first detect arrows and line pieces, the latter of which are composed of one or multiple line segments in the image G (see<ref type="figure" target="#fig_0">Fig. 1</ref>for an example). To detect line pieces in G, we applied the application programming interface (API) named 'cvHoughLines2' in the OpenCV 2.2.0 package; to detect arrows in G, we adopted the algorithm proposed in the study by<ref type="bibr" target="#b29">Wendling and Tabbone (2003)</ref>, which is relatively easy to implement and is capable of producing satisfying performance in our experiments. Occasionally, line pieces and arrows in a diagram may be accompanied by annotation text. To capture such text, we first remove from G all recognized line pieces and arrows. For the remaining image region, we then perform a text detection procedure using the method suggested in the study by<ref type="bibr" target="#b31">Xu and Krauthammer (2010)</ref>. For each recognized text region, we will anchor the text region onto its nearest line piece or arrow according to the Euclidean distance. Finally, we will call another OCR procedure to recognize these annotation text strings. For each line piece or arrow detected previously, we need to associate both its end points to their respective closest shape elements according to the Euclidean distance. In our work, we define the distance between a line piece or an arrow to a shape element as the minimum distance between one end point of the line piece or arrow and a pixel on the contour of the shape element. As each shape element has been represented as a node N i , any pair of nodes commonly pointed to by a line piece or an arrow are considered linked, in which case, we will introduce an edge to connect the two nodes in G. Through the aforementioned process, we construct our edge set EðGÞ for G. The aforementioned procedure of transforming an input diagram image into its corresponding structural graph representation is implemented as a fully automatic module in our prototype system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Identify counterpart text for diagram nodes</head><p>For each node N i detected from G, we need to identify text fragments in the source document D that embody the semantics represented by N i 's corresponding visual symbol on the diagram. To locate a text position in a document, we use a sentence's sequence number in the document as the location index. For text appearing in the main body of an article, we separate it into sentences according to the presence of punctuation marks in the text; in particular, for text occurring in the title of an article, an article section or sub-section, as long as the source document allows automatic detection of these title regions, we treat all text displayed in one title region as a single sentence. Let the set of sentences semantically related to the node N i be S i ¼ fs i, 1 , s i, 2 , Á Á Ág, where each s i, j is a sentence in D that explains or discusses the meanings of N i. Each s i, j is associated with a significance score i, j 2 ½0, 1 that indicates the semantic relatedness between s i, j and N i. For an arbitrary sentence s x 2 D, to measure its semantic relatedness with N i , we compare the alignment of the semantics represented by s x and N i , respectively, according to their text. Recall that the text of the node N i has been previously recovered through the OCR process. To estimate the aforementioned semantic alignment, we use the algorithm proposed in the study by<ref type="bibr" target="#b12">Li et al. (2006)</ref>, which is specifically designed for measuring semantic similarity between two pieces of short text. To determine the sentence set S i for a given node N i , we start with an empty set and scan all sentences in D. We respectively derive each sentence's semantic relatedness with N i following the aforementioned procedure. If the detected semantic relatedness exceeds an empirically chosen threshold (0.05 in all our experiments), we consider the sentence noticeably related to the node and collect the sentence into the set S i. In this document sentence scanning procedure, we consider all sentences in the full text of the document, including those in the document's title, abstract, footnotes and figure captions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Identify counterpart text for diagram edges</head><p>Once we have identified the counterpart text in D for every node in G, we can further identify the corresponding text in D that reflects the semantic meanings denoted by each edge in the diagram. Our edge counterpart text detection procedure is based on the node counterpart text detection result. Recall that Eði, jÞ is the edge that connects the nodes N i and N j in G; N i , and N j 's counterpart text in D is organized as two sentence sets S i and S j , respectively. To locate counterpart text for the edge Eði, jÞ, we essentially pair sentences from S i and S j , one from each set. Let jS x j be the number of sentences in the sentence set S x. Our aforementioned edge counterpart text identification procedure leads to jS i j Â jS j j instances of the counterpart text for Eði, jÞ. For the sentence pair s i, u 2 S i and s j, v 2 S j , we estimate its significance in representing the semantic meanings of Eði, jÞ as i, u j, v ðs i, u , s j, v Þ. Recall that i, u and j, v are the significance of the sentences s i, u and s j, v in embodying meanings of the nodes N i and N j , respectively; ðs i, u , s j, v Þ is a newly introduced measure that quantifies how likely the two sentences s i, u and s j, v embody the semantic meanings intended by the edge Eði, jÞ. We assume the farther apart the two sentences are, the less likely the pair of sentence describes the relationship represented by the edge. Note that s i, u and s j, v may both refer to the same sentence, in which case, it is most likely the meanings of the edge Eði, jÞ are reflected by the sentence. In our current design, ðs i, u , s j, v Þ is estimated as follows: ðs i, u , s j, v Þ ¼ expðÀ disðsi, u , sj, v Þ ave disðDÞ Þ, where disðs i, u , s j, v Þ is the number of non-stop words separating the two sentences s i, u and s j, v ; ave disðDÞ is the average number of non-stop words in a sentence in the document D. We further introduce a function %ðs i, u , s j, v , t i, j Þ 2 ½0, 1 to measure the degree of relevance (the larger, the more relevant) between text of the two sentences s i, u and s j, v and the annotation text of the edge t i, j. Recall that we mentioned earlier that occasionally a line piece or an arrow in a diagram may be accompanied by some annotation text. We empirically define %ðs i, u , s j, v , t i, j Þ as follows:</p><formula>%ðs i, u , s j, v , t i, j Þ ¼ maxfðw a j wa2ti, j , w b j w b 2si, u [sj, v Þg, ð1Þ</formula><p>where ðw a , w b Þ 2 ½0, 1 computes the semantic relatedness between a pair of words, w a and w b , according to WordNet::Similarity (http://search.cpan.org/dist/WordNetSimilarity/doc/intro.pod). If the edge does not have any anchoring text, i.e. t i, j ¼ ;, %ðs i, u , s j, v , t i, j Þ ¼ 1. The reason why we made such a value assignment is due to the following logic: if an edge does not carry any anchoring text, no particular semantic relationship is specified to govern the edge's two end nodes. Hence, we give the benefit of doubt by assuming any text can be relevant in some way to the relationship represented by the edge. If there is indeed some anchoring text associated with the edge, then only those counterpart text instances that embody the same semantic relationship specified by the anchoring text shall be considered well matched and relevant to the edge. Based on the significance of each sentence pair, we can further estimate the significance of the edge Eði, jÞ embodied in the entire document D by aggregating the significance of all its counterpart sentence pairs across the document as follows:</p><formula>w i, j ¼ 1 z X si, u 2Si, sj, v 2Sj i, u j, v ðs i, u , s j, v Þ%ðs i, u , s j, v , t i, j Þ, ð2Þ</formula><p>where z is a scaling factor to ensure the significance value for the most significant edge in G is 1. Based on the estimated significance for each edge in G, we can construct a weighted adjacency matrix WðGÞ, for characterizing whether two nodes in the graph are connected, and if so, how saliently this connection is embodied in the source document D. Let W i, j ðGÞ be the element on the i-th row and j-th column of the matrix WðGÞ; we define WðGÞ as follows: W i, j ðGÞ ¼ w i, j if E i, j 2 EðGÞ and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MEASURING DIAGRAM SIMILARITY BY LEVERAGING DOCUMENT CONTEXT</head><p>Given two diagrams G 1 and G 2 , to measure their similarity, we need to compute an optimal matching between these two diagrams. Let jNðG 1 Þj and jNðG 2 Þj, respectively, be the number of nodes in the two diagrams. We can then represent any matching relationship between G 1 and G 2 using a jNðG 1 Þj Â jNðG 2 Þj dimensional matching matrix MðG 1 , G 2 Þ. The element on the i-th row and j-th column of MðG 1 , G 2 Þ, denoted as M i, j ðG 1 , G 2 Þ 2 ½0, 1, represents the matching degree between the i-th node in G 1 and the j-th node in G 2. Note that M i, j ðG 1 , G 2 Þ can be any number between 0 and 1, which implies one node from a diagram can match to one, multiple or no node in the other diagram. Such a fuzzy matching mechanism allows our method to deal with a wide range of diagram matching scenarios without enforcing a strict one-to-one matching between two diagrams' nodes, the situation of which does not always exist in reality. For simplicity, we will abbreviate MðG 1 , G 2 Þ for M from now on when no ambiguity arises. Also, we will abbreviate WðG 1 Þ and WðG 2 Þ as W 1 and W 2 , respectively, for easy notation. In the following, we will introduce a method for deriving an optimal matching relationship matrix b M for an arbitrary pair of diagrams G 1 and G 2. The optimality in the matching relationship matrix refers to the estimation of the optimal matching degree between two matrices using our heuristic-based estimation framework. We first introduce a heuristic function HðG 1 , G 2 , MÞ to represent the semantic relatedness between two diagrams G 1 and G 2 , assuming that nodes in the two diagrams are matched according to the correspondence relationship M. Intuitively, the more semantically related the two diagrams are, the larger the value of HðG 1 , G 2 , MÞ becomes. This modelling perspective is inspired by the work of Li and Hsu (2008), who studied a related problem of content-based natural image retrieval with relevance feedback using a graph-theoretic region correspondence estimation method. Given the aforementioned function HðG 1 , G 2 , MÞ, we can search for the optimal matching relationship matrix b M as follows:</p><formula>b M ¼ arg max M HðG 1 , G 2 , MÞ: ð3Þ</formula><p>As mentioned earlier, a diagram G can be characterized using its node set NðGÞ and its weighted adjacency matrix WðGÞ. Working with this premise, we empirically assume that:</p><formula>HðG 1 , G 2 , MÞ / Y jNðG1Þj i¼1 Y jNðG2Þj j¼1 P Mi, j ðN i ðG 1 Þ, N j ðG 2 Þ, W 1 , W 2 , MÞ, ð4Þ</formula><p>where HðN i ðG 1 Þ, N j ðG 2 Þ, W 1 , W 2 , MÞ estimates the pairwise node matching score between N i ðG 1 Þ and N j ðG 2 Þ. Recall that N i ðG x Þ is the i-th node in the node set NðG x Þ, and M i, j is the element on the i-th row and j-th column of the matching matrix M. It shall be noted that the above property is heuristically assumed. Intuitively, the pairwise graph similarity can be estimated according to the pairwise similarities between corresponding nodes in the two graphs. The higher such node similarities collectively are, the more semantically related the two graphs may be perceived as assumed by our heuristic. Note that if M i, j 6 ¼ 0, it means that the node N i ðG 1 Þ from NðG 1 Þ matches the node N j ðG 2 Þ from NðG 2 Þ according to the matching relationship M. The reason why we raise the pairwise node matching score function HðN i ðG 1 Þ, N j ðG 2 Þ, W 1 , W 2 , MÞ to the power of M i, j is because the matching degree M i, j can be any number between 0 and 1 to emulate the fuzzy nature of such non-binary matching decision. Again, this power factor is empirically introduced, whose effectiveness will be proved through our experimental results to be presented later in this article. Next, to estimate HðN i ðG 1 Þ, N j ðG 2 Þ, W 1 , W 2 , MÞ, we take into account two clues: (i) self similarity, i.e. how closely the two nodes' carrying text are; (ii) context similarity, i.e. how similar the two nodes' surrounding nodes are in terms of their text similarity. To measure the self similarity ðN i ðG 1 Þ, N j ðG 2 ÞÞ between a pair of nodes N i ðG 1 Þ and N j ðG 2 Þ, we first implement a method for estimating content similarity between a pair of sentences. Let ðs i , s j Þ 2 ½0, 1 be the semantic similarity for an arbitrary pair of sentences s i and s j. ðs i , s j Þ ¼ 1 indicates the two sentences deliver the same semantics, whereas ðs i , s j Þ ¼ 0 shows the two sentences share no semantic overlap. To derive the value of ðs i , s j Þ, in our current implementation, we adopt the sentence similarity estimation algorithm proposed in the study by<ref type="bibr" target="#b12">Li et al. (2006)</ref>because of the algorithm's leading performance among the peer methods. Based on the function of ðs i , s j Þ, we can now estimate ðN i ðG 1 Þ, N j ðG 2 ÞÞ. Assume N i ðG 1 Þ and N j ðG 2 Þ's counterpart sentence sets detected from diagrams G 1 and G 2 's source documents D 1 and D 2 , are S i ðG 1 Þ and S j ðG 2 Þ, respectively. Also recall that the significance for a sentence s i, u (s j, v ) in S i ðG 1 Þ ðS j ðG 2 Þ) to embody the meanings intended by the node N i ðG 1 Þ ðN j ðG 2 Þ) is i, s ð j, v ). We can now estimate ðN i ðG 1 Þ, N j ðG 2 ÞÞ as follows:</p><formula>ðN i ðG 1 Þ, N j ðG 2 ÞÞ ¼ 1 ZðG 1 , G 2 Þ X si, u 2SiðG1Þ X sj, v 2SjðG2Þ</formula><p>i, u j, v ðs i, u , s j, v Þ ð5Þ where ZðG 1 , G 2 Þ is a normalization term to ensure the maximum pairwise node similarity across the two graphs G 1 and G 2 is 1. To estimate the context similarity of the pair of nodes N i ðG 1 Þ and N j ðG 2 Þ, we first consider the similarity of the two nodes' immediately adjacent neighbours, which is denoted as # 1, 1 ðN i ðG 1 Þ, N j ðG 2 ÞÞ, as follows:</p><formula># 1, 1 ðN i ðG 1 Þ, N j ðG 2 ÞÞ ¼ X NuðG1Þ2NðG1Þ X NvðG2Þ2NðG2Þ W 1, i, u W 2, j, v ðN u ðG 1 Þ, N v ðG 2 ÞÞ, ð6Þ</formula><p>where W 1, i, u and W 2, j, v are the short notations for W i, u ðG 1 Þ and W j, v ðG 2 Þ, respectively. Similarly, we can estimate the similarity between one node's immediate neighbour node and the other node's second-level neighbour node. In analogy to the definition of # 1, 1 ðN i ðG 1 Þ, N j ðG 2 ÞÞ, we can further define # 1, 2 ðN i ðG 1 Þ, N j ðG 2 ÞÞ and # 2, 1 ðN i ðG 1 Þ, N j ðG 2 ÞÞ as follows:</p><formula># 1, 2 ðN i ðG 1 Þ, N j ðG 2 ÞÞ ¼ X NuðG1Þ2NðG1Þ X NvðG2Þ2NðG2Þ X NxðG2Þ2NðG2Þ ðW 1, i, u W 2, j, v W 2, v, x ðN u ðG 1 Þ, N x ðG 2 ÞÞÞ, ð7Þ # 2, 1 ðN i ðG 1 Þ, N j ðG 2 ÞÞ ¼ X NuðG1Þ2NðG1Þ X NxðG1Þ2NðG1Þ X NvðG2Þ2NðG2Þ ðW 1, i, u W 1, u, x W 2, j, v ðN x ðG 1 Þ, N v ðG 2 ÞÞÞ: ð8Þ</formula><p>Similarly, we can further define # 2, 2 ðN i ðG 1 Þ, N j ðG 2 ÞÞ, whose explicit form is omitted because of space limit. By aggregating all the aforementioned sub-estimates, we can derive the context similarity for the pair of nodes N i ðG 1 Þ and N j ðG 2 Þ, denoted as #ðN i ðG 1 Þ, N j ðG 2 ÞÞ, as follows:</p><formula>#ðN i ðG 1 Þ, N j ðG 2 ÞÞ ¼ X u¼1, 2 X v¼1, 2 # u, v ðN i ðG 1 Þ, N j ðG 2 ÞÞ: ð9Þ</formula><p>In our method, we do not calculate # u, v ðN i ðG 1 Þ, N j ðG 2 ÞÞ for u42 or v42 because their values are almost always 0.</p><p>Finally, by combining ðN i ðG 1 Þ, N j ðG 2 ÞÞ and #ðN i ðG 1 Þ, N j ðG 2 ÞÞ, we can estimate HðN i ðG 1 Þ, N j ðG 2 Þ, W 1 , W 2 , MÞ as follows:</p><formula>HðN i ðG 1 Þ, N j ðG 2 Þ, W 1 , W 2 , MÞ ¼ expfðN i ðG 1 Þ, N j ðG 2 ÞÞ þ #ðN i ðG 1 Þ, N j ðG 2 ÞÞg, ð10Þ</formula><p>where is a fixed constant. Substituting Equation (10) into Equation (4), we further have:</p><formula>arg max M HðNðG 1 Þ, NðG 2 Þ, W 1 , W 2 , MÞ ¼ arg max M X jNðG1Þj i¼1 X jNðG2Þj j¼1 M i, j logðHðN i ðG 1 Þ, N j ðG 2 Þ,W 1 ,W 2 ,MÞÞ ¼ arg max M X jNðG1Þj i¼1 X jNðG2Þj j¼1 M i, j ðlog þ ðN i ðG 1 Þ, N j ðG 2 ÞÞ þ #ðN i ðG 1 Þ, N j ðG 2 ÞÞÞ: ð11Þ</formula><p>To calculate the optimal matching matrix b M, we first create a jNðG 1 Þj Â jNðG 2 Þj dimensional matrix @, whose element on the i-th row and j-th column, @ i, j , takes the value of log þ ðN i ðG 1 Þ, N j ðG 2 ÞÞ þ #ðN i ðG 1 Þ, N j ðG 2 ÞÞ. We thus have:</p><formula>b M ¼ arg max M X jNðG1Þj i¼1 X jNðG2Þj j¼1 M i, j @ i, j : ð12Þ</formula><p>As M is a matching matrix, it has the property that P j M i, j 1 and P i M i, j 1 for all i and j. The inequality in the constraints is introduced for handling the situation that an element from a diagram shall not be matched to any element in the other diagram to yield an optimal matching between the two diagrams. To solve the aforementioned optimization problem, we can use linear programming to find the optimal matching matrix, b M, that maximizes</p><formula>P jNðG1Þj i¼1 P jNðG2Þj j¼1 M i, j @ i</formula><p>, j. Once we derive b M, we can further derive the value of HðG 1 , G 2 , b MÞ as the similarity between the two diagrams G 1 and G 2. For information retrieval tasks that only care about rankings where the absolute similarity value is not important, it suffices to use the optimized target function value yielded in the linear programming procedure, i.e.</p><formula>P jNðG1Þj i¼1 P jNðG2Þj j¼1 ^ M i, j @ i, j , as</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment set-up</head><p>To explore the effectiveness of our new diagram similarity estimation method for diagram retrieval, we conducted a set of evaluation experiments using a PC equipped with a Core i3 2.93 GHz CPU and 4 GB main memory, which ran the Windows XP operating system. To carry out our experiments, we first constructed a diagram image corpus where each diagram is accompanied by its corresponding source document. We acquired these images and their source documents through both downloading from PubMed Central (PMC) and using Google Image Search as follows:</p><p>(i) we first downloaded all the publicly accessible images from PMC where each image is always accompanied by its source document. We then applied the diagram image recognition algorithm proposed in the study by<ref type="bibr" target="#b25">Qin et al. (2010)</ref>to identify diagrams from all downloaded images. This procedure lets us acquire 12 500 diagrams. (ii) We then randomly selected 50 diagrams downloaded from PMC in the first step and fed the captions of these images, respectively, as queries into Google Image Search. For each search result image, Google always provides a back link to its source webpage. Following the back link, we can check whether the search result image is associated with a meaningful source document. In this operation, we first removed all the advertisement and navigation content from an image's source webpage using the algorithm proposed in the study by<ref type="bibr" target="#b22">Ntoulas et al. (2006)</ref>. If the filtered webpage contains4500 words, we then consider the webpage as a meaningful document. Otherwise, we discard the search result image. For all the images that passed the preceding test, we ran the algorithm of<ref type="bibr" target="#b25">Qin et al. (2010)</ref>to detect and select all images of the diagram type and added them into our diagram corpus. Using the second approach, we acquired $3000 additional diagrams through Google Image Search. To experimentally explore the performance of a diagram retrieval method, we conducted a collection of diagram image search sessions, which were organized into 16 groups of queries, where each query group consists of multiple query sessions on a common theme. The 16 querying themes are, respectively, as follows, for which we also specify the number of query sessions performed for each theme group using a number in the bracket following the theme's topic phrase—a: breast cancer (9), b: gastric cancer (9), c: non-Hodgkin's lymphoma (9), d: multiple myeloma (9), e: HIV (8), f: detection of chronic kidney (9), g: heart block (9), h: malaria (8), i: thrombosis (8), j: angiogenesis (8), k: tumour angiogenesis (8), l: ochrobactrum (8), m: gene expression (8), n: cardiomyopathy (8), o: respiratory syndrome (9) and p: bone metastase (9). Query theme groups a–c primarily consist of images acquired through Google Image Searches; query theme groups d–m mostly consist of images downloaded from PubMed; the remaining query theme groups, i.e. groups n, o and p, contain images acquired through both means more evenly. For each query session, we randomly selected an image from our diagram corpus whose caption matches the session's theme phrase as the query input image. We then performed diagram retrieval against the whole diagram corpus (excluding the selected query input image) using a retrieval method whose performance is to be evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental results</head><p>After the aforementioned procedure, we then applied the new diagram similarity estimation method introduced in this article for diagram retrieval and ranking. In each query session, we rank all the retrieved diagram search results according to each result diagram's estimated relatedness to the query diagram. We then recruited five subjects and asked each of them to independently label the relatedness of each search result diagram to the input query diagram according to each subject's personal judgment regarding the two diagrams' semantic similarity. The numeric label ranges from 0 (entirely irrelevant) to 1 (extremely related). We then took an average of the five user labels as the image's overall user-rated query relevance score. Based on this score, we further calculated the normalized discounted cumulative gain (NDCG) to measure the quality of diagram retrieval and ranking for the query session. To understand the definition of NDCG, we first need to introduce the notation of discounted cumulative gain (DCG), which measures the information retrieval quality of a ranked search result set. DCG takes into consideration the query-relevance of each search result document along with its ranking position in the result list. The DCG score at a particular rank position p can be computed as:</p><formula>DCG p ¼ X p i¼1</formula><p>To further verify our method's performance superiority to the peer methods, we calculated P-values for the paired t-test following the well-established procedure in statistic hypothesis testing. We tested a series of null hypotheses that the performance of our method and that of a specific peer method is statistically equal. In<ref type="figure" target="#tab_1">Table 1</ref>, we report the P-values as results of two-tailed paired ttests for diagram querying experiments of 16 theme groups. More concretely, for each query theme group, we executed all its constituent query sessions using our method and the five peer retrieval methods, respectively. Without loss of generality, let's focus on the first peer method PM1 initially. For every query session, we paired the NDCG scores for the top 20 diagram retrieval results obtained by our method with those returned by PM1 according to their respective rank positions. That is, every query session will produce 20 pairs of NDCG scores. For each query session in the first query theme group, we repeated the same process and collected all the resultant NDCG score pairs. This gave us 180 pairs of NDCG scores because there are nine query sessions in the first query theme group. Given these NDCG score pairs, we can then derive the P-values for the two-tailed paired t-test comparing the retrieval quality of our method and that of PM1 for the whole query theme group. The aim is to test the statistical significance of the superiority of our method with respect to PM1. The result is reported in the tabular cell under the column 'Ours-PM1' and on the row for the first query theme group in<ref type="figure" target="#tab_1">Table 1</ref>. To fill the entire table, we repeated the aforementioned procedure for comparisons against all the peer methods and query theme groups. In Table 2, we further report P-values for both onetailed and two-tailed t-tests for all 16 theme groups of query experiments. To calculate the P-values, this time we collected all paired NDCG scores comparing our method and one of the peer methods across all query sessions in all query themes. Overall, among all P-values reported in<ref type="figure" target="#tab_1">Table 1</ref>, almost all of them are 50.05, except for a few ones that are marked in bold. In<ref type="figure" target="#tab_2">Table 2</ref>, all calculated P-values both for the one-tailed and twotailed t-tests are50.05. These small P-values consistently indicate a statistically significant superiority of our method with respect to the peer methods in retrieving diagrams semantically relevant to the input query diagram. To explore the diversity in the search result diagrams, we further calculate the distributions of co-author distances among top ranked diagram retrieval results returned by our method. The purpose is to verify that the new algorithm is capable of retrieving diagrams composed by people sharing weak or no collaboration relationships. That is, the algorithm will indeed retrieve diagrams according to their semantic similarity rather than common diagram composition styles or practice shared by people who are academically closely related. Let D author ðA x , A y Þ be the co-author distance between a pair of authors A x and A y. In this work, we derive the co-author distance between a pair of authors by checking all the publication records in the open access portion of the PubMed corpus. D author ðA x , A y Þ ¼ 0 if and only if A x is the same person as A y ; D author ðA x , A y Þ ¼ 1 if A x and A y at least co-author one article as captured in the corpus; for the general case, we used the classic Dijkstra's shortest distance algorithm to compute D author ðA x , A y Þ. Based on the notation of D author ðA x , A y Þ, we</p><formula>be A x ¼ fA x1 , A x2 , Á Á Á , A xn g and A y ¼ fA y1 , A y2 , Á Á Á , A ym g, respectively. We then define D image ðI x , I y Þ to be D image ðI x , I y Þ ¼min Ax2Ax, Ay2Ay D author ðA x , A y Þ</formula><p>. For each of the 16 theme groups of query sessions conducted in our experiments, we collected all images that were ranked among the top 20 search results by our method in at least one of the query sessions. We then computed the distribution of image co-author distances between the input diagrams and their corresponding search result diagrams for all executed query sessions. In<ref type="figure" target="#fig_4">Figure 4</ref>, we report the percentage distribution of image co-author distances for each query theme group, respectively. From the reported results, we can clearly see that the new algorithm is able to retrieve semantically related diagrams regardless of whether these diagrams are composed by people that are closely related academically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND DISCUSSIONS</head><p>We propose a novel context-based method for estimating diagram similarity. The method augments concepts and their relationships illustrated in a diagram by leveraging the contextual information provided by the full text of the diagram's source document. As a diagram usually highlights rather than explains its intended message, expanding the concisely encoded message by cross-referring to the diagram's source document can supply rich supplementary context for more accurately and comprehensively understanding the diagram's intended semantic meanings. The comparative experiments demonstrate the superiority of our new method for semantically oriented diagram similarity estimation with respect to traditional image similarity metrics, which do not explore such context information. Our enhanced diagram similarity estimation can benefit many information retrieval tasks dealing with diagrams, e.g. improving user experiences with digital library systems for diagram searching and diagram browsing-based visual literature navigation. The main challenge of estimating the similarity of diagrams embedded in the biomedical literature lies in the following two aspects: (i) unlike diagrams used in the software engineering and many other engineering disciplines that are typically composed of parametric objects using the Unified Modelling Language (UML) or other specialized languages or software packages and, hence, amenable to automatic computer processing, diagrams in the biomedical literature are typically released as bitmap images with no high-level descriptive representation. Therefore, detecting, extracting and automatically understanding entities and their mutual relationships graphically encoded in these bitmap images present a non-trivial technical challenge. To address this issue, we introduce a series of advanced image processing procedures in Section 3.2. For diagrams embedded in the biomedical literature, we witness the novel opportunity of observing and borrowing the context in a diagram's source document to acquire informative semantic clues for enhancing automatic diagram understanding and similarity estimation. Such an opportunity is unique for diagrams carried inside a peer-reviewed research publication because the document usually contains high-quality text that explains its embedded diagrams (such property does not always exist for diagrams from other sources, e.g. those included on casual webpages, as they usually do not have rich and quality explanation text). To leverage the aforementioned opportunity for enhancing automatic biomedical diagram understanding and similarity estimation, we thus introduced a novel and advanced diagram similarity estimation method by incorporating the rich semantic context information supplied in a diagram's source document (see Section 4). Finally, in terms of the applicability of our method, even though the new method aims to process diagrams embedded in the biomedical literature, it can be applied for dealing with diagrams in the literature of other science or technology fields. Nevertheless, we notice that many science and technology fields do not use diagrams as intensively as by the broad biomedical discipline, which affects the potential of our method in processing diagrams in these fields. One fundamental limitation of our method is that it does not work with stand-alone diagrams that do not have accompanying source documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. (a and b) are two diagrams commonly related to the query theme of gastric cancer, where (a) is Figure 1 in the article of Liu et al. (2010), and (b) is Figure 1 in the article of Qiao and Feng (2012); (c and d) are the two diagrams' respective attributed graph representations extracted by the method introduced in this article; (e and f) are the two diagrams' respective weighted adjacency matrices Ws constructed by our method according to their respective source documents; (g) is the optimal matching matrix b M computed for the two diagrams</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>the estimated similarity for the two diagrams G 1 and G 2. Figure 1 gives an example of the optimized matching matrix constructed by our method for a pair of sample input diagrams.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. NDCG scores for all querying experiments of 16 theme groups performed using our method and the peer methods, respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>Funding: National Natural Science Foundation of China (NSFC) (60903132); National Key Basic Research and Development Program of China (973) (2013CB329505); NSFCGuangdong Joint Fund (U1201252, U1135003 and U0935004);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.4.</head><figDesc>Fig. 4. Distributions of image co-author distances among top diagram search results by our method. We derive the image co-author distances between an input diagram and its top 20 search results returned by our method. For all query sessions in a query theme group, we compute the percentage distribution of these distances. The upper sub-figure shows such distributions for the query theme groups 1–8 (labelled as 's1'–'s8', respectively), and the bottom sub-figure shows results for the query theme groups 9–16 (labelled as 's9'–'s16', respectively). The horizontal axis indicates a specific image co-author distance range, where the last (rightmost) one corresponds to the distance value range of (20, 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 1. P-values for two-tailed, paired t-tests for search results of 16 query themes using our method and the five peer methods</figDesc><table>Theme 
number 

Ours-PM1 Ours-PM2 Ours-PM3 Ours-PM4 Ours-PM5 

1 
6.72E-6 
9.77E-6 
0.00418 
9.84E-8 
4.02E-7 
2 
4.69E-6 
8.54E-8 
0.42255 
9.62E-8 
0.00025 
3 
2.03E-5 
7.47E-7 
1.33E-6 
1.52E-6 
1.96E-7 
4 
0 . 0 2 7 0 7 
0.0502 
0.96529 
0.00092 
3.14E-5 
5 
0.52284 
0.09693 
0.06315 
0.53414 
0.00039 
6 
7.35E-6 
1.53E-9 
2.42E-10 
4.60E-8 
3.03E-9 
7 
7.26E-10 
0.27657 
0.21753 
0.0039 
0.0074 
8 
6.69E-10 
1.42E-9 
1.97E-8 
1.88E-8 
6.28E-12 
9 
3.17E-7 
2.68E-9 
9.58E-8 
3.48E-11 
1.46E-12 
10 
0.00074 
0.00174 
4.15E-5 
1.26E-5 
6.17E-7 
11 
1.19E-6 
8.51E-9 
4.88E-7 
2.04E-7 
1.42E-8 
12 
1.46E-11 
3.20E-11 
4.16E-6 
6.03E-8 
5.82E-10 
13 
3.59E-8 
3.83E-8 
6.36E-7 
3.28E-8 
1.08E-8 
14 
2.08E-5 
0.00708 
0.00651 
0.45278 
2.98E-5 
15 
8.76E-8 
1.14E-6 
0.0017 
6.16E-7 
5.29E-7 
16 
5.05E-6 
8.63E-8 
4.20E-6 
4.88E-7 
8.42E-8 

The first column lists the query theme number. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><figDesc>Table 2.</figDesc><table>P-values of paired t-tests with both one-tailed and two-tailed 
settings 

Type 
Ours-P1 
Our-P2 
Ours-P3 
Ours-P4 
Ours-P5 

One-tailed 
0.00475 
0.00631 
0.02423 
0.00239 
0.00117 
Two-tailed 
0.00949 
0.01263 
0.04845 
0.00478 
0.00234 </table></figure>

			<note place="foot">Biomedical diagram similarity estimation at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">S.Xu et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="2"> reli À 1 log 2 ði þ 1Þ , ð13Þ where rel i is the average user-rated query relevance of the search result item ranked at the position i in the list. Based on the notation of DCG p , we can further calculate the NDCG score for a ranked search result set at a particular rank position p as follows: NDCG p ¼ DCG p IDCG p , ð14Þ where IDCG p is the ideal (maximum) DCG score at the rank position p reachable by the current search result set. For more thorough discussions on the NDCG metric, readers are referred to Ja¨rvelinJa¨rvelin and Kekaïaïnen (2002). In this article, we adopted NDCG as our retrieval performance metric following the predominant practice in the information retrieval research field because such metric gives weighted considerations to search result items at different ranking positions, prioritizing those displayed at the top positions of the list. Plenty of information retrieval research, e.g. Ja¨rvelinJa¨rvelin and Kekaïaïnen (2002), has pointed out that the NDCG metric can better reflect the search quality perceived by end users than the traditional precision-based evaluation, which ignores rank positions. For all our experiments reported in this article, we use NDCG 20 as the metric, as we empirically find it behaves most representatively among all versions of the NDCG scores for our application. For comparison purposes, we also applied the following peer image search methods to repeat the image search experiments described earlier in the text—Peer Method (PM) 1: each image is represented using its caption text. We then used the text search engine Lucene to retrieve and rank images, whose ranking mechanism is described with details in the study by Hatcher and Gospodnetic (2004). PM 2: the method is to use the text present in title, description and tags of the images for improving the results obtained with a standard content-based search (Barrios et al., 2009). PM 3: each image is represented using its caption text and its visually embedded text, as well as the image&apos;s anchoring text, i.e. the sentence(s) in the source document that directly quotes the image. This is the image search method proposed in Xu et al. (2008). The weighting for mixing the three types of text in the ranking process is also manually tuned to maximize the total NDCG score of the method for all our tested queries. PM 4: the biomedical image metadata manager system proposed by Korenblum et al. (2011) that retrieves similar biomedical images using semantic metadata features. PM 5: a state-of-the-art process model diagram search method proposed by Li and Hsu (2008). When conducting all sessions of our comparative experimental studies, we used the same target diagram corpus when executing the five peer methods and our algorithm to ensure fair comparison among all methods. To explore the diagram retrieval performance of the new method with respect to the five peer methods, we conducted a series of diagram search experiments using the aforementioned 16 theme groups of diagram query sessions. Figure 2 reports NDCG scores of both our method and that of the five peer methods in all these experiments, where the NDCG score of each method for every query is individually reported. We also congregated these individual NDCG scores to derive the distributions of all NDCG scores attained by our method and the five peer methods in all our querying experiments, whose distributions are reported in Figure 3 using boxplots. All the aforementioned experiment results clearly show that our new diagram similarity estimation method performs significantly superior to all peer methods for searching and ranking diagram images.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Text-based and content-based image retrieval on flickr: Demo</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Barrios</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Second International Workshop on Similarity Search and Applications</title>
		<meeting>the 2009 Second International Workshop on Similarity Search and Applications</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="156" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Some (what) grand challenges for information retrieval</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Belkin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="47" to="54" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic face annotation in personal photo collections using context-based unsupervised clustering and face information fusion</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Choi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1292" to="1309" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">Similarity of business process models: metrics and evaluation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Dijkman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="498" to="516" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Measuring similarity between semantic business process models</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ehrig</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Asia-Pacific Conference on Comceptual Modelling</title>
		<meeting>the Fourth Asia-Pacific Conference on Comceptual Modelling</meeting>
		<imprint>
			<publisher>Australian Computer Society, Inc</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Context-based search for 3d models</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hanrahan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">182</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<monogr>
		<title level="m" type="main">Lucene in Action</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Hatcher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Gospodnetic</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Manning Publications</publisher>
			<pubPlace>Greenwich, CT</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ja¨rvelinja¨rvelin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kekaïaïnen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Managing biomedical image metadata for search and retrieval of similar images</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Korenblum</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Digit. Imaging</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="739" to="748" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Context in web search</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lawrence</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Image retrieval with relevance feedback based on graph-theoretic region correspondence estimation</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Hsu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimed</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="447" to="456" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">On measuring process model similarity based on high-level change operations</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Conceptual Modeling (ER &apos;08</title>
		<meeting>the 27th International Conference on Conceptual Modeling (ER &apos;08<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="248" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Sentence similarity based on semantic nets and corpus statistics</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowledge Data Eng</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1138" to="1150" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Interleukin-8-251 a/t gene polymorphism and gastric cancer susceptibility: a meta-analysis of epidemiological studies</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cytokine</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="328" to="334" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Context-based health information retrieval</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Lopes</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="845" to="845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Integration of context and content for multimedia management: an introduction to the special issue</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Luo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimed</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="193" to="195" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">A case-based reasoning framework for workflow model management</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Madhusudan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Knowledge Eng</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="87" to="115" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">The importance of socio-economic context for social marketing models for improving reproductive health: evidence from 555 years of program experience</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Meekers</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Rahaim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Public Health</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Similarity flooding: a versatile graph matching algorithm and its application to schema matching</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Melnik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 18th International Conference on Data Engineering</title>
		<meeting>. 18th International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Representation and structure-based similarity assessment for agile workflows In: Case-Based Reasoning Research and Development Lecture Notes in Computer Science</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Minor</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="224" to="238" />
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">A comparative evaluation of full-text, concept-based, and context-sensitive search</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Moskovitch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="164" to="174" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Matching and merging of statecharts specifications</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Nejati</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Software Engineering</title>
		<meeting>the 29th International Conference on Software Engineering</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="54" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Detecting spam web pages through content analysis</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ntoulas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on World Wide Web</title>
		<meeting>the 15th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">Context-aware person identification in personal photo collections</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>&apos;hare</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Smeaton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimed</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="220" to="228" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Genetic variations of prostate stem cell antigen (PSCA) contribute to the risk of gastric cancer for eastern Asians: a meta-analysis based on 16792 individuals</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Qiao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Feng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gene</title>
		<imprint>
			<biblScope unit="volume">493</biblScope>
			<biblScope unit="page" from="83" to="91" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">A unified approach based on hough transform for quick detection of circles and rectangles</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Qin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Image Graph</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="109" to="115" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">Figure mining for biomedical research</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Rodriguez-Esteban</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Iossifov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2082" to="2084" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Context-based matching and ranking of web services for composition</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Segev</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Toch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Serv. Comput</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="210" to="222" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantics in digital photos: a contextual analysis</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Sinha</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Jain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Semantic Computing. IEEE</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">Recognition of arrows in line drawings based on the aggregation of geometric criteria using the choquet integral</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Wendling</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Tabbone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2003. Proceedings. Seventh International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="299" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluation of technical measures for workflow similarity based on a pilot study</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Wombacher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Confederated International Conference On the Move to Meaningful Internet Systems: CoopIS, DOA, GADA, and ODBASE (ODBASE&apos;06</title>
		<meeting>the 2006 Confederated International Conference On the Move to Meaningful Internet Systems: CoopIS, DOA, GADA, and ODBASE (ODBASE&apos;06<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="255" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">A new pivoting and iterative text detection algorithm for biomedical images</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Xu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Krauthammer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="924" to="931" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b32">
	<analytic>
		<title level="a" type="main">Yale image finder (YIF): a new search engine for retrieving biomedical images</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Xu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1968" to="1970" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b33">
	<analytic>
		<title level="a" type="main">Object retrieval using visual query context</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimed</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1295" to="1307" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b34">
	<analytic>
		<title level="a" type="main">Mobile image search with multimodal context-aware queries</title>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Yang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>