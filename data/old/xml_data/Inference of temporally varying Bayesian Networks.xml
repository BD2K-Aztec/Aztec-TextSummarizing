
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Systems biology Inference of temporally varying Bayesian Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2012">. 24 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Thomas</forename>
								<surname>Thorne</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre of Integrative Systems Biology and Bioinformatics</orgName>
								<orgName type="department" key="dep2">Division of Molecular Biosciences</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Michael</forename>
								<forename type="middle">P H</forename>
								<surname>Stumpf</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre of Integrative Systems Biology and Bioinformatics</orgName>
								<orgName type="department" key="dep2">Division of Molecular Biosciences</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Olga</forename>
								<surname>Troyanskaya</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre of Integrative Systems Biology and Bioinformatics</orgName>
								<orgName type="department" key="dep2">Division of Molecular Biosciences</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Systems biology Inference of temporally varying Bayesian Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">28</biblScope>
							<biblScope unit="page" from="3298" to="3305"/>
							<date type="published" when="2012">. 24 2012</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/bts614</idno>
					<note type="submission">Received on March 5, 2012; revised on October 4, 2012; accepted on October 11, 2012</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: We apply our method to existing microarray expression data as well as demonstrating is efficacy on simulated test data. Contact: thomas.thorne@imperial.ac.uk</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: When analysing gene expression time series data, an often overlooked but crucial aspect of the model is that the regulatory network structure may change over time. Although some approaches have addressed this problem previously in the literature, many are not well suited to the sequential nature of the data. Results: Here, we present a method that allows us to infer regulatory network structures that may vary between time points, using a set of hidden states that describe the network structure at a given time point. To model the distribution of the hidden states, we have applied the Hierarchical Dirichlet Process Hidden Markov Model, a non-parametric extension of the traditional Hidden Markov Model, which does not require us to fix the number of hidden states in advance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The analysis of gene expression data in the field of systems biology is a challenging problem for a number of reasons, not least because of the high dimensionality of the data and relative dearth of data points. A number of approaches have been taken to inferring regulatory interactions from such data, often using graphical models or sparse regression techniques Lè bre, 2009; Opgen<ref type="bibr" target="#b23">Rhein and Strimmer, 2007;</ref><ref type="bibr" target="#b29">Scha¨ferScha¨fer and Strimmer, 2005</ref>). These problems are further compounded by the nature of the biological systems under consideration, owing to the influence of unobserved actors that may alter the behaviour of the system. Often experiments are performed for long periods during which it is natural to expect the regulatory interactions at work to change. The time scales of regulatory responses to stimuli often differ from those of signalling and metabolic responses, and so it may be that responses to stimuli, around which experiments are often designed, take place in several phases each having different time scales. Previous studies have attempted to address this problem by introducing changepoints in the time series, allowing the inferred network structure to differ between the resulting segments of the time series. For example in<ref type="bibr">Lè bre et al. (2010)</ref>, a changepoint model is applied in which Dynamic Bayesian Networks are inferred for each segment of the time series. However, such approaches may place strong prior assumptions on the number of changepoints that can be observed, and do not adjust for the complexity of the observed data automatically. Instead in<ref type="bibr" target="#b15">Grzegorczyk et al. (2008)</ref>, an allocation sampler is used in combination with Bayesian Networks to assign each observation to a group, but unlike changepoint models, this method treats the observations as being exchangeable, ignoring the fact that the data are sequential. The similar methodology in Ickstadt (2011) uses a more flexible non-parametric prior on group assignments, applied to the modelling of molecular interactions using Bayesian Networks, but suffers the same drawbacks in not recognizing the sequential nature of the data. A solution to the related, but different problem of inferring networks from multiple datasets that may vary in their underlying structure owing to changes in conditions, is presented in<ref type="bibr" target="#b24">Penfold et al. (2012)</ref>. By applying a hierarchical model, it is possible to model the interactions that may be shared for a number of different experimental conditions while also modelling the interactions specific to certain cases. However, this method treats the whole time series for a condition as a single static network, rather than allowing the network structure to change within a time series. Here, we present a methodology that allows us to infer network structures that may change between observations in a nonparametric framework while modelling the sequential nature of the data. To that end, we have used the infinite hidden Markov model of<ref type="bibr" target="#b2">Beal et al. (2002)</ref>, also known as the hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) (<ref type="bibr">Teh and Jordan, 2010</ref>), in particular the 'Sticky' extension of<ref type="bibr" target="#b9">Fox et al. (2009)</ref>, in conjunction with a Bayesian network model of the gene regulatory network structure. The HDP-HMM allows the number of different states of the network structure to adapt as necessary to explain the observed data, including a potentially infinite number of states, of course restricted in practice by the finite number of experimental observations. In the previous work of<ref type="bibr" target="#b27">Rodriguez et al. (2010)</ref>, it was demonstrated that the HDP-HMM outperforms a Dirichlet Process mixture for Gaussian graphical models on heterogeneous time series. We apply our methodology to both simulated data and gene expression data for Arabadopsis thaliana and Drosophila melanogaster, demonstrating its effectiveness in detecting changes in network structure from time series data, and compare its performance and accuracy to existing methods. We also consider the biological implications of our results and present hypotheses as to their significance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">APPROACH</head><p>Given gene expression time series data over m genes at n time points, we denote the observations as the n Â m matrix *To whom correspondence should be addressed. ß The Author 2012. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/3.0/), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited. X ¼ ðx 1 ,. .. , x n Þ T , where x j ¼ ðx j1 ,. .. , x jm Þ T , the column vector of expression levels for each of the m genes at time point j. We formulate our model as a HDP-HMM, a stochastic process, whereby a set of hidden states s 1 ,. .. , s n governs the parameters of some emission distribution F over a sequence of time points 1. .. n. Each observation x j is then generated from a corresponding emission distribution Fð k Þ, where s j ¼ k. For our emission distributions, F, we use a Bayesian Network model over the m variables to represent the regulatory network structures corresponding to each hidden state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>In the following, we will consider the problem of network inference in a Bayesian framework, aiming to draw samples from the distribution of the model parameters , given some observed data X, P(jX), known as the posterior distribution. By application of Bayes rule, it can be shown that for a given model</p><formula>PðjXÞ ¼ PðXjÞPðÞ PðXÞ , ð1Þ</formula><p>where the term P(X), commonly called the evidence, is constant with respect to the parameters , and so PðjXÞ / PðXjÞPðÞ. The prior distribution P() over the parameters summarizes our knowledge of the model parameters before we have observed the data, and so it should be consistent with any data we could potentially observe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Dirichlet Process</head><p>Bayesian non-parametrics aims to ensure that the prior of a model remains appropriate for a wide range of data, allowing the complexity of an inferred model to adapt in light of the observed data. One particular Bayesian non-parametric formulation, known as the Dirichlet Process (an extension of the Dirichlet distribution as described below), has been used extensively as a prior in clustering and mixture modelling, as it is able to adapt the complexity of the model to best fit the number of components in the data, without resorting to schemes such as reversible jump Markov Chain Monte Carlo (MCMC) (<ref type="bibr" target="#b14">Green, 1995</ref>), as used in Lè bre et al. (2010). The Dirichlet Process is a non-parametric extension of the Dirichlet distribution (<ref type="bibr" target="#b12">Gelman et al., 2004</ref>), which can be constructed in a number of ways. Conventionally, the Dirichlet distribution is defined for M dimensional vectors x under the constraint that all x i 40 and P M x i ¼ 1, and takes parameters i , for i 2 1,. .. , M:</p><formula>pðxjaÞ ¼ Y M i¼1 x iÀ1 i : ð2Þ</formula><p>As the x i sums to one, they can be interpreted as specifying a discrete probability distribution over a set of outcomes 1,. .. , M. Using the Dirichlet distribution as the prior for a set of multinomial observations, i can be interpreted as the number of a priori observations of outcome i (<ref type="bibr" target="#b12">Gelman et al., 2004</ref>). The Dirichlet Process can then be obtained as the limit of a symmetrical Dirichlet distribution with dimension M and concentration parameters M as M !1. One construction of the Dirichlet Process is the 'stick breaking' construction of<ref type="bibr" target="#b31">Sethuraman (1994)</ref>, whereby an infinite sequence of discrete probability atoms are drawn from the underlying distribution, known as the base measure. These points are weighted by coefficients i , that are defined as</p><formula>i ¼ 0 i Y iÀ1 j¼1 ð1 À 0 j Þ, ð3Þ with 0 j $ Betað1, Þ, ð4Þ</formula><p>for some concentration parameter. The i can thus be seen as lengths broken from a stick of unit length, 1 taking a length of 0 1 , 2 taking a fraction 0 2 of the remaining stick (which has length) 1 À 0 1 and so on. Larger values of will result in smaller values of 0 and thus many atoms i with similar weights i. The distribution of the i dependent on is referred to as $ GEMð&#x0D;Þ. Then for a Dirichlet Process with concentration parameter and base measure H, written DP(&#x0D;,H), and G $ DPð&#x0D;, HÞ, we have</p><formula>G ¼ X 1 i¼1 i i , ð5Þ</formula><p>with i $ H and $ GEMð&#x0D;Þ. As we will see with the application of the HDP to HMMs, the ability of Bayesian non-parametric methods to adaptively explain the complexity of the observed data makes them a valuable tool in the statistical analysis of data when we wish to make few a priori assumptions. The HDP is constructed simply by taking a Dirichlet Process as the base measure of another Dirichlet Process. Then we have that</p><formula>G 0 $ DPð, HÞ, ð6Þ G $ DPð&#x0D;, G 0 Þ, ð7Þ</formula><p>and using the stick breaking construction,</p><formula>$ GEMðÞ, ð8Þ G 0 ¼ X 1 i¼1 i i , ð9Þ G ¼ X 1 i¼1 i i , ð10Þ</formula><p>where i $ H, $ GEMðÞ and $ DPð&#x0D;, Þ. For a derivation of this form of the HDP, we refer the reader to<ref type="bibr">Teh et al. (2006</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">HDP-HMMs</head><p>To model a hidden state sequence that evolves over time, we apply the methodology first introduced in<ref type="bibr" target="#b2">Beal et al. (2002)</ref>, whereby a finite state Hidden Markov Model (HMM), consisting of a set of hidden states s 1 ,. .. , s n over some alphabet 1. .. K, is extended so that K !1. In a classical HMM (<ref type="bibr" target="#b3">Bishop, 2006</ref>), the number of states K is typically specified in advance, and states follow a Markov process, whereby transitions are made between states with probability kl ¼ pðs j ¼ ljs jÀ1 ¼ kÞ so that the next state in the sequence depends only on the previous state. The HDP-HMM (<ref type="bibr" target="#b2">Beal et al., 2002;</ref><ref type="bibr">Teh et al., 2006</ref>; Teh and Jordan, 2010) instead applies a Dirichlet Process prior to the transition probabilities p kÁ out of each of the states k, and uses a hierarchical structure to couple the distributions between the individual states to ensure a shared set of potential states into which transitions can be made across all of the p. This allows for an unlimited number of potential states, of course limited in practice by the number of observed data points. More formally, each hidden state k possesses a Dirichlet Process distributed G k , from which the next state is drawn, and a common (discrete) base measure G 0 is shared between these Dirichlet Processes so that G k $ DPð, G 0 Þ. As a result, transitions are made into a discrete set of states shared across all of the G k and drawn from G 0. The base measure G 0 is in turn drawn from a Dirichlet Process, G 0 $ DPð&#x0D;, HÞ, H being our prior over parameters for the emission distributions F k. Then using the stick-breaking construction of<ref type="bibr" target="#b31">Sethuraman (1994)</ref>for G 0 and drawing l independently from H, we have that G 0 ¼ P 1 l l l ,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3299</head><p>Inference of temporally varying Bayesian Networks with $ GEMð&#x0D;Þ, and so G k ¼ P 1 l kl l with p k $ DPð, Þ. The resulting model is outlined in<ref type="figure" target="#fig_0">Figure 1</ref>. For a comprehensive introduction to the construction of the HDP-HMM, we refer the reader to the excellent and extensive description in<ref type="bibr" target="#b9">Fox et al. (2009)</ref>. However, in a biological system, it is more realistic to assume that only a subset of the large variety of potential behaviours of the hidden state sequence is relevant, as behaviour such as rapid cycling between states at adjacent time points would a priori seem to be unlikely to be observed in most gene expression datasets. Thus, we choose to apply the Sticky HDP-HMM (<ref type="bibr" target="#b8">Fox et al., 2008</ref><ref type="bibr" target="#b9">Fox et al., , 2009</ref>), which introduces an extra parameter that biases the prior probability of transitions between states towards remaining in the current state rather than transitioning to a differing one. Adding such a prior assumption simply states that we expect the state of the system to remain the same between successive time points; this is both parsimonious and would seem to be justified in the case of gene expression datasets, where we might only expect to observe a small number of transitions to differing states across the time series. This modification to the HDP-HMM gives us a model generating observed data points x j as (<ref type="bibr" target="#b9">Fox et al., 2009</ref>)</p><formula>j $ GEMð&#x0D;Þ, ð11Þ p kÁ j, , $ DP þ , þ k þ , ð12Þ s j js jÀ1 , p $ p sjÀ1Á , ð13Þ</formula><p>$ H, ð14Þ x j js j $ Fð sj Þ ð 15Þ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Gibbs sampling for the Sticky HDP-HMM</head><p>To sample from the hidden state sequence, we have used a Gibbs sampling procedure (<ref type="bibr" target="#b26">Robert and Casella, 2005</ref>) based on the conditional probabilities for the hidden state s i, given the remaining hidden states s Ài as described in<ref type="bibr" target="#b8">Fox et al. (2008)</ref>, updating each hidden state individually in a sweep over the n states,</p><formula>pðs j ¼ kjs Àj , , , Þ / ½N Àj sjÀ1k þ k þ sjÀ1 ðkÞ N Àj ksjþ1 þ sjþ1 þ sjþ1 ðkÞ þ sjÀ1 ðkÞ sjþ1 ðkÞ þ N Àj kÁ þ þ sjÀ1 ðkÞ ! pðX jÁ jX iÁ : s i ¼ k, i 6 ¼ j, F k Þ, ð16Þ</formula><p>where s Àj denotes the state sequence s 1 ,. .. , s n excluding s j , N Àj kl indicates the number of observed transitions from state k to state l within the hidden state sequence s Àj , and N Àj kÁ the total number of transitions from state k within s Àj. Briefly, to update the hidden state sequence s, iterating over each j, pðs j ¼ kjs Àj , , , Þ is calculated for all k, and a weighted sample taken from these to decide the updated value of s j. The full process is described in Algorithm 1. We use standard vague prior parameters for and (<ref type="bibr" target="#b5">Dunson, 2010</ref>), and set so as to prefer sequences of identical consecutive states. It is possible in principle to further extend the method by adding priors on the hyperparameters , and , but in most cases, the HDP-HMM already exhibits the required flexibility without this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Bayesian Network emission distributions</head><p>To model the regulatory network structure corresponding to the hidden states of the HDP-HMM, we have applied a Bayesian Network methodology to capture the relationships between the genes represented in our data. Thus, each hidden state has a unique Bayesian Network describing the interactions occurring between the genes at the time points corresponding to a particular state. Bayesian Networks are probabilistic models, whereby a directed graph defines the conditional independence relationships between a set of random variables (<ref type="bibr" target="#b18">Koski and Noble, 2009</ref>). For the model to remain consistent, the graph structure G, with nodes u 2 N G representing random variables and directed edges ðv, uÞ 2 E G representing conditional probability relationships between them, must be acyclic. For a given Bayesian network structure, G, and model parameters, , the joint distribution pðXjG, Þ factorizes as a product of local distributions for each node,</p><formula>pðXjG, Þ ¼ Y u2N pðx Áu jpa G ðuÞ, u Þ, ð17Þ</formula><p>where for each observation, the value x iu of a node u is dependent on the values of its set of parent nodes pa G ðuÞ ¼ fv 2 Njðv, uÞ 2 Gg and some parameters u. Here, we have used a Gaussian Bayesian Network (BGe) model (<ref type="bibr" target="#b11">Geiger and Heckerman, 2002</ref>) that allows the variables to take continuous values and defines the local distributions for each observation i 2 1,. .. , m of a gene u as</p><formula>x iu $ N u þ X v2pa G ðuÞ b uv ðx iv À v Þ, 2 u 0 @ 1 A , ð18Þ</formula><p>with parameters u ¼ u , b u , 2 u. With a Wishart distribution, the conjugate before the multivariate Normal distribution, this simplifies the form of the resulting equations, and we can calculate the local marginal likelihoods p½x u jpa G ðuÞ as described in Geiger and Heckerman (2002) and from these derive the joint probability pðXjGÞ. Unfortunately, owing to the restriction of the network structure to that of a directed acyclic graph (DAG), it is difficult to explore the space of possible network structures. Several MCMC schemes have been proposed, including those of Grzegorczyk and Husmeier (2008) and<ref type="bibr" target="#b21">Madigan et al. (1995)</ref>, but performing random walks over DAG network structures faces the problem that proposing moves that maintain the DAG structure can be complex and time consuming, and mixing of the Markov chain can be slow. However, as noted in<ref type="bibr" target="#b10">Friedman and Koller (2003)</ref>, a DAG structure G corresponds to a partial ordering on the nodes and so induces a (non-unique) total ordering, and allows us to perform a random walk over total orderings of the nodes. This Markov chainefficiently explores the space of possible graph structures, improving the mixing properties of the chain. Although this introduces a bias in the prior distribution over graph structures (<ref type="bibr" target="#b15">Grzegorczyk and Husmeier, 2008</ref>), it greatly simplifies the computational complexity of the MCMC procedure, and such a bias may be justified by arguments of parsimony, as graphs consistent with more orderings are more likely to be sampled. Furthermore, the uniform prior on DAG structures is not uniform over Markov equivalent graphs, and so also introduces a different kind of bias in the results. Finally, a trivial modification of the algorithm of Friedman and Koller (2003) allows for a correction of the bias (<ref type="bibr" target="#b7">Ellis and Wong, 2008</ref>). Thus, in our methodology, we apply the MCMC sampler of Friedman and Koller (2003) to infer Bayesian Network structures for each hidden state of the HDP-HMM by sampling over total orderings of the nodes 0, given the data points corresponding to the state in question. It is easy to calculate the likelihood of an ordering 0 using the formula given in Friedman and Koller (2003)</p><formula>H θ k γ β α π k· s 0 s 1 s 2 s n x 1 x 2 x n ∞ ∞</formula><formula>pðXj 0Þ ¼ Y u2NG X k2pa 0 G ðuÞ pðx Áu , kÞ, ð19Þ</formula><p>where pa 0 G denotes the set of possible parent sets over the nodes of G consistent with the ordering 0. Then we can use a Metropolis Hastings sampler to sample from the posterior of orderings pð0 jXÞ ¼ pðXj 0Þpð0Þ (<ref type="bibr" target="#b7">Ellis and Wong, 2008</ref>), by beginning with an initial ordering and proposing and accepting new orderings 0 0 , distributed as qð0 0 j 0Þ with probability according to the Metropolis Hastings acceptance probability p acc ¼ min 1, pðXj 0 0 Þpð0 0 Þqð0 j 0 0 Þ pðXj 0Þpð0Þqð0 0 j 0Þ , ð20Þ over a number of iterations. We choose to propose changes by swapping nodes in the ordering rather than more complex schemes such as 'deck cutting', as these were found to have little impact on performance in previous studies (<ref type="bibr" target="#b7">Ellis and Wong, 2008</ref>;<ref type="bibr" target="#b10">Friedman and Koller, 2003</ref>). Proposals 0 0 $ qðÁj 0Þ are thus drawn by selecting two nodes within the ordering uniformly at random and exchanging their positions to produce a new ordering. In the absence of a compelling alternative, we take the prior over orderings pð0Þ as the uniform distribution. Then for our emission distribution for a given state k, we apply a Bayesian Network ordering 0 k generating observed data points X k distributed as pðX k j 0 k Þ where by X k we denote the subset of X ij , including only rows i corresponding to states s i ¼ k. The full method is outlined in Algorithm 1 and combines Gibbs updates of the hidden state sequence with Metropolis Hastings updates of the node orderings of the Bayesian Networks for each state at every iteration. To sample hidden state sequences and orderings from the posterior distribution, the algorithm is first run for a number of burn-in iterations, after which samples are collected. As a single iteration of our algorithm combines a full Gibbs update sweep along with an update of the Bayesian Network orderings over a number of Metropolis Hastings steps, in practice a comparatively small number of iterations of the algorithm are required to reach the posterior. To reduce the computational complexity of the Bayesian Network inference, we restrict the number of potential parents of a gene to be 2. Even in such a case, we still face a large number of possible parent sets, of size P</p><formula>mÀ1 i¼2 i 2 þ P mÀ1 i¼1 i 1 , and so</formula><p>in the analyses presented below, we restrict our dataset to a subset of genes of special interest, as is commonly the case in gene expression data analysis. Given that the parent set for a given group of genes will be of sizeFinally, once we have inferred the hidden state sequence and generated a posterior sample of orderings corresponding to each state, we can then easily sample DAG structures from the posterior by first sampling an order from the posterior of a given state, and then sampling from the graphs consistent with this ordering, weighting the choice of parents by the local scores, and optionally attempting to account for the bias in the prior as described in Ellis and Wong (2008).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Example—simulated data</head><p>To evaluate the efficacy of our method, we generated simulated data from three different Bayesian network structures and interleaved the data points into a single time series. Applying our methodology to this data, we then attempted to recover the hidden state sequence. Three different Bayesian Networks of 10 nodes each having random structures and parameters were used, with the restriction that each node had at most two parents. Such a restriction is realistic for real world biological networks and reduces the computational complexity of the Bayesian network inference, as the number of potential sets of parents of each node is greatly reduced by constraining the search. A total of 100 data points were used, consisting of a sequence of 25 generated by the first network, 25 by a second network structure, another 25 from a third network structure and finally a further 25 data points generated by the second network structure. The Gibbs sampling MCMC scheme outlined in Algorithm 1 was applied over 500 iterations after a 1000 iteration burn in, with 100 MCMC iterations of the Bayesian network order sampler run on each network structure between each Gibbs sweep. We performed a comparison of the true hidden state sequence with the state sequences for the 500 samples from the Gibbs sampler, and found that our method perfectly recreates the original hidden state sequence, correctly identifying that the network structure is the same between two separate segments of the time series. To assess the accuracy of our method, we compared its performance to the Auto Regressive TIme VArying (ARTIVA) method ofLè bre et al. (2010). Although ARTIVA was able to infer change points at the appropriate time points for one of the genes, all of the remaining genes had no predicted changepoints, despite the fact that their interactions change during the time series.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Drosophila melanogaster midgut development gene expression data</head><p>Applying our method to real world gene expression data, we took the publicly available gene expression dataset of Li and White (2003), as stored in the Gene Expression Omnibus database (<ref type="bibr" target="#b6">Edgar et al., 2002</ref>). This dataset gives tissue specific expression levels for genes in D. melanogaster midgut at time points before and after puparium formation, taken at 11 time points. A subset of genes to analyse was chosen by selecting genes having the highest variance across the time series, using the genefilter R package in Bioconductor www.bioconductor.org (<ref type="bibr" target="#b13">Gentleman et al., 2007;</ref><ref type="bibr">R Development Core Team, 2011</ref>). This resulted in a dataset of 23 genes at 11 time points. This allows us to apply our approach without having to consider the additional issues arising from the 'large-p-small-n' problem.</p><p>The results shown in<ref type="figure" target="#fig_2">Figure 2</ref>identify two regions of the time series having different network structures, with a change occurring after the 0 hour time point at which puparium formation occurs. This suggests that a different structure of regulatory interactions is at work during the midgut development after the puparium formation begins. The networks inferred for each of the different states are also shown in<ref type="figure" target="#fig_2">Figure 2</ref>, illustrating a clear change between differing network structures. A main objective of this type of approach is to distill new mechanistic hypotheses from such data, and the temporally resolved and varying network structures do, indeed, deliver candidates for further analysis. Looking at the inferred network structures, e.g. we see a number of genes whose interaction patterns change over the course of the time series. Perhaps most interesting amongst these are the genes Jonah 65Aiv (Jon65Aiv) and Jonah 99Ciii (Jon99Ciii), which are known to be expressed in the D. melanogaster midgut during development (<ref type="bibr" target="#b0">Akam and Carlson, 1985</ref>), but whose function is not fully understood. It appears that Jonah 99Ciii is involved in development before puparium formation, whereas Jonah 65Aiv develops several interactions after puparium formation. The gene alphaTry seems to be involved in development before and after puparium formation, whereas nimrod C4 (nimC4) seems to interact only before puparium formation. In addition to this, a number of relatively unknown genes appear to have differing regulatory interactions between the time points. Given only gene expression data, it is not feasible, however, to identify potential mechanisms of the changes taking place, as many different factors may affect the presence or absence of regulatory interactions. The inferred network structure before puparium formation is based on a small number of time points, and so may not be entirely robust. However, such cases are bound to arise when considering time varying networks without a priori knowledge of the time varying structure, and should be treated as indications that further experimental work is needed if closer investigation of the network structure is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Transcriptome of starch metabolism during A. thaliana diurnal cycle</head><p>We have also analysed the gene expression dataset of<ref type="bibr">Smith et al. (2004)</ref>, as included in the GeneNet (<ref type="bibr" target="#b28">Schafer and Opgen-Rhein, 2006</ref>) R package (R Development Core Team,). The dataset consists of expression levels for 800 genes encoding enzymes involved in starch synthesis and in conversion of starch to maltose and Glc, at 11 time points for 12 h, transitioning from dark to light. The first 5 time points were collected during a dark period after which a switch to a light period was made, with time points spaced so that expression is measured at 0, 1, 2, 4 and 8 h after the switch to the dark period, and the same intervals after the switch to the light period (<ref type="bibr">Smith et al., 2004</ref>), as well as a final 24-h time point at the switch back to the dark period. A reduced subset of the 800 genes in the dataset was selected using the genefilter R package, as described previously, giving a subset of 40 genes that were analysed using our method. In<ref type="figure">Figure 3</ref>, we show the results generated by our method, clearly indicating two distinct phases within the time series. It appears that one phase is detected from 1 to 12 h, with a second phase inferred between 13 and 24 h that is also represented at the initial time point. This is consistent with the design of the experiment, as a change in expression would perhaps not be expected to be observed immediately at the point at which the switch between light and dark takes place, but rather later at a subsequent time point, as is observed here. As the 24-h time point was taken under the same conditions as the initial time point, one would expect these two time points to be grouped together using our method. The networks inferred for the two different phases, shown in<ref type="figure">Figure 3</ref>, again demonstrate a clear change in the network structure, with the two networks having distinct topologies. Several of the genes, e.g. COL2 and CCA1, appear to interact both during the light and dark phases, and both are known to be involved in circadian regulation (<ref type="bibr">Alabadıét al., 2001;</ref><ref type="bibr" target="#b19">Ledger et al., 2001</ref>). A gene showing a clear differentiation in its interactions between the dark and light phases is LHY1, with no interaction inferred during the dark phase, followed by a proliferation of interactions in the light phase. It is known that LHY1 is expressed at peak levels at dawn (<ref type="bibr" target="#b30">Schaffer et al., 1998</ref>) and involved in flowering, and mutants cause late flowering (<ref type="bibr" target="#b4">Coupland et al., 1998</ref>). AFR appears to be regulated by LHY1 during the light phase, and AFR is known to be involved in far-red light signalling (The Arabidopsis Information Resource (TAIR), www.arabidopsis.org).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3305</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.1.</head><figDesc>Fig. 1. The HDP-HMM represented as a graphical model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>Oðm 3 Þ, the computational complexity of performing Gibbs sampling over each of the data points will be OðKnm 3 Þ, where K is the number of hidden states.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.2.</head><figDesc>Fig. 2. (Left) Inferred network structure corresponding to the first hidden state. (Middle) Inferred network structure corresponding to the second hidden state. (Right) Posterior distribution of states at each time point inferred by our method applied to the D. melanogaster midgut development expression data (Li and White, 2003). States are represented by colours, and frequencies of their appearance for each time point in the posterior samples are plotted. The first state is coloured blue, the second red</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><figDesc>et al. (2004) Diurnal changes in the transcriptome encoding enzymes of starch metabolism provide evidence for both transcriptional and posttranscriptional regulation of starch metabolism in arabidopsis leaves. Plant Physiol., 136, 2687–2699. Teh,Y.W. et al. (2006) Hierarchical dirichlet processes. J. Am. Stat. Assoc, 101, 1566–1581. Teh,Y.W. and Jordan,M.I. (2010) Hierarchical Bayesian nonparametric models with applications. In Bayesian Nonparametrics. Cambridge University Press, Cambridge, pp. 158–207. Van Gael,J. et al. (2008) Beam sampling for the infinite hidden Markov model. In ICML '08: Proceedings of the 25th international conference on Machine learning. ACM.</figDesc></figure>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="3301"> Inference of temporally varying Bayesian Networks at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot" n="5"> DISCUSSION From our simulated data, it appears that the HDP-HMM Bayesian Network sampler we have constructed accurately infers the hidden state sequences governing Bayesian Networks that capture how the regulatory organization of a biological system, here observed at the level of mRNA data, changes with time. By delivering time-resolved predictions of regulatory interactions, our method generates biological hypotheses that can be tested more robustly through the use of e.g. conditional knock-downs and RNAi. Further to this, network structures that are adopted for a small number of samples can identify segments of the time series, focussing on which would improve the modelling of the system, thus suggesting experiments that will deliver increased understanding of the biological system being examined. The accuracy of our method on test data lends hope that it will perform well on real world datasets, and the existence of more sophisticated and demonstrably more efficient samplers indicates that there is room for even further improvement and computational efficiency. For example, the beam sampler of Van Gael et al. (2008) and the Hierarchical Chinese Restaurant Process formalism of Makino et al. (2011) show improved mixing and perform better than standard Gibbs samplers, especially on time series, such as those we examine here where neighbouring states are likely to be correlated. We would like to emphasize that it is essential to consider the fluid nature of regulatory network structures when inferring networks from datasets where such change is likely. Performing an analysis on data using a model with a fixed network structure, when it is known or believed that the network structure will change (this possibility should really never be discarded), is inherently incorrect, and thus will introduce unnecessary bias into the results. Although it may be possible to infer correct results from an incorrect model, it would not seem wise to rely on such approaches when alternatives exist. Our methodology crucially accounts for the sequential nature of the data, something that has previously been ignored (Ickstadt, 2011; Grzegorczyk et al., 2008), but we feel is crucial to the modelling of gene expression time series datasets. Furthermore, our methodology has an advantage over changepoint models that data may be shared between distinct segments Fig. 3. (Left) Inferred network structure corresponding to the first hidden state. (Middle) Inferred network structure corresponding to the second hidden state. (Right) Posterior distribution of states at each time point inferred by our method applied to the A. thaliana diurnal cycle expression data (Smith et al., 2004). States are represented by colours, and frequencies of their appearance for each time point in the posterior samples are plotted. The first state is coloured blue, the second red 3303 Inference of temporally varying Bayesian Networks at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">T.Thorne and M.P.H.Stumpf at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">The detection of Jonah gene transcripts in Drosophila by in situ hybridization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Akam</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Carlson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMBO J</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="155" to="161" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">Reciprocal regulation between TOC1 and LHY/CCA1 within the Arabidopsis circadian clock</title>
		<author>
			<persName>
				<forename type="first">Alabadı´</forename>
				<surname>Alabadı´</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">D</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="page" from="880" to="883" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">The Infinite Hidden Markov Model</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Beal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Ghahramani</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">E</forename>
				<surname>Rasmussen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Dietterich,T, Becker,S. and Ghahramani,Z.</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="577" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<monogr>
		<title level="m" type="main">Pattern Recognition and Machine Learning</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Bishop</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, Inc. Secaucus, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">The regulation of flowering time by daylength in Arabidopsis</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Coupland</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symp. Soc. Exp. Biol</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Nonparametric Bayes applications to biostatistics</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dunson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Nonparametrics</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="223" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">Gene Expression Omnibus: NCBI gene expression and hybridization array data repository</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Edgar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="207" to="210" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning causal Bayesian network structures from experimental data</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Ellis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">H</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="778" to="789" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">An HDP-HMM for systems with state persistence</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B</forename>
				<surname>Fox</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;08: Proceedings of the 25th international conference on Machine learning</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<monogr>
		<title level="m" type="main">A sticky HDP-HMM with application to speaker diarization</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B</forename>
				<surname>Fox</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Koller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<meeting><address><addrLine>Mach. Lear</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="95" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Parameter priors for directed acyclic graphical models and the characterization of several probability distributions</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Geiger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Heckerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1412" to="1440" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<monogr>
		<title level="m" type="main">Bayesian Data Analysis</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gelman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">Genefilter: genefilter: methods for filtering genes from microarray experiments</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Gentleman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>R. package version 1.34.0</note>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Reversible jump Markov chain Monte Carlo computation and Bayesian model determination</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Green</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="711" to="732" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving the structure MCMC sampler for Bayesian networks by introducing a new edge reversal move</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Grzegorczyk</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Husmeier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="265" to="305" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Modelling non-stationary gene regulatory processes with a non-homogeneous Bayesian network and the allocation sampler</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Grzegorczyk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2071" to="2078" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Nonparametric Bayesian Networks (with discussion)</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ickstadt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bayesian Statistics 9</title>
		<editor>Bernardo,J. et al.</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="135" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian Networks: An Introduction (Wiley Series in Probability and Statistics), 1st edn Inferring dynamic genetic networks with low order independencies Statistical inference of the time-varying structure of gene-regulation networks</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Koski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Noble</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Ltd</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Uk</forename>
				<surname>Chichester</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">S</forename>
				<surname>Lè Bre</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Appl. Genet. Mol. Biol. BMC Syst. Biol</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">130</biblScope>
			<date type="published" when="2009" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
	<note>Article. 9. Lè bre,</note>
</biblStruct>

<biblStruct   xml:id="b19">
	<analytic>
		<title level="a" type="main">Analysis of the function of two circadian-regulated CONSTANS-LIKE genes</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">S</forename>
				<surname>Ledger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plant J</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="15" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Tissue-specific gene expression and ecdysone-regulated genomic networks in Drosophila</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">R</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">P</forename>
				<surname>White</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dev. Cell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="59" to="72" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">Bayesian Graphical Models for Discrete Data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Madigan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Stat. Rev</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="215" to="232" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">Restricted Collapsed Draw: Accurate Sampling for Hierarchical Chinese Restaurant Process Hidden Markov Models</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Makino</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">arXiv.org. stat.ML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Opgen-Rhein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Syst. Biol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonparametric Bayesian inference for perturbed and orthologous gene regulatory networks</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">A</forename>
				<surname>Penfold</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="233" to="241" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Development</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Core</forename>
				<surname>Team</surname>
			</persName>
		</author>
		<imprint>
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<monogr>
		<title level="m" type="main">Monte Carlo Statistical Methods Springer texts in statistics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">P</forename>
				<surname>Robert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Casella</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>2nd. edn</note>
</biblStruct>

<biblStruct   xml:id="b27">
	<monogr>
		<title level="m" type="main">Sparse covariance estimation in heterogeneous samples</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rodriguez</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<monogr>
		<title level="m" type="main">Reverse engineering genetic networks using the GeneNet package</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schafer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Opgen-Rhein</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="50" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b29">
	<analytic>
		<title level="a" type="main">An empirical Bayes approach to inferring large-scale gene association networks</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Scha¨ferscha¨fer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Strimmer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="754" to="764" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b30">
	<analytic>
		<title level="a" type="main">The late elongated hypocotyl mutation of Arabidopsis disrupts circadian rhythms and the photoperiodic control of flowering</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">R</forename>
				<surname>Schaffer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1219" to="1229" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b31">
	<analytic>
		<title level="a" type="main">A constructive definition of Dirichlet priors</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sethuraman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="639" to="650" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>