
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probabilistic single-individual haplotyping</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Volodymyr</forename>
								<surname>Kuleshov</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Probabilistic single-individual haplotyping</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="page" from="379" to="385"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu484</idno>
					<note>BIOINFORMATICS Contact: kuleshov@stanford.edu</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Accurate haplotyping—determining from which parent particular portions of the genome are inherited—is still mostly an un-resolved problem in genomics. This problem has only recently started to become tractable, thanks to the development of new long read sequencing technologies. Here, we introduce ProbHap, a haplotyping algorithm targeted at such technologies. The main algorithmic idea of ProbHap is a new dynamic programming algorithm that exactly optimizes a likelihood function specified by a probabilistic graphical model and which generalizes a popular objective called the minimum error correction. In addition to being accurate, ProbHap also provides confidence scores at phased positions. Results: On a standard benchmark dataset, ProbHap makes 11% fewer errors than current state-of-the-art methods. This accuracy can be further increased by excluding low-confidence positions, at the cost of a small drop in haplotype completeness. Availability: Our source code is freely available at: https://github.com/ kuleshov/ProbHap.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Although modern sequencing technology has led to rapid advances in genomics over the past decade, it has largely been unable to resolve an important aspect of human genetics: genomic phase. Each human chromosome comes in two copies: one inherited from the mother, and one inherited from the father. Despite the fact that differences between these copies play an important biological role, until recently, decoding these differences (a process known as haplotyping or genome phasing) has been a major technological challenge. In recent years, however, we have seen an emergence of new long read technologies (<ref type="bibr" target="#b10">Kaper et al., 2013;</ref><ref type="bibr" target="#b12">Kitzman et al., 2010;</ref><ref type="bibr">Peter et al., 2012;</ref><ref type="bibr" target="#b18">Voskoboynik et al., 2013</ref>) that may one day enable routine cost-effective haplotyping. Because a long read comes from a single chromosome copy, it reveals the phase of all heterozygous genomic positions that it covers. By connecting long reads at their overlapping heterozygous positions, it is possible to extend this phase information into haplotype blocks, in a process referred to as single-individual haplotyping (SIH) (<ref type="bibr" target="#b2">Browning and Browning, 2011</ref>). Although from the molecular biology side, routine haplotyping seems close to becoming a reality, dealing with long read data remains non-trivial computationally. Under most formulations of the problem, it is NP-hard to recover the optimal haplotypes from noisy sequencing reads (<ref type="bibr" target="#b7">Gusfield, 2001</ref>). This has led to a vast literature on heuristics for dealing with this problem as accurately as possible. Here, we propose a new algorithm, PROBHAP, which offers an 11% improvement in accuracy over the current leading method, REFHAP. Unlike most other algorithms, PROBHAP also provides confidence scores in addition to genomic phase. These scores can be used to prune low-accuracy positions and further improve haplotype quality, at the cost of phasing fewer variants. The main algorithmic ideas of PROBHAP are a new dynamic programming algorithm and a probabilistic graphical model. The dynamic programming algorithm determines the haplotypes that maximize the likelihood function Pðreadsjtrue haplotypesÞ specified by the probabilistic model as well as the probability that these haplotypes are correct. It can be seen as a special case of the well-known variable elimination algorithm (<ref type="bibr" target="#b13">Koller and Friedman, 2009</ref>). From a theoretical point of view, the likelihood function specified by our probabilistic model generalizes a well-known objective called the minimum error correction (MEC). Previously proposed exact dynamic programming algorithms for the MEC can be easily derived as special cases of the general variable elimination algorithm within our model. More interestingly, alternative formulations of this algorithm (corresponding to different variable orderings) result in novel exact algorithms that are significantly faster than previous ones. Thus, our work generalizes several previous approaches and provides a systematic way of deriving new haplotyping algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Most phasing algorithms solve a formally defined computational problem called SIH, in which the goal is to minimize an objective called the MEC (see Section 5). This objective is NP-hard (<ref type="bibr" target="#b7">Gusfield, 2001</ref>); therefore, most early work on the SIH problem involved simple greedy methods (<ref type="bibr" target="#b6">Geraci, 2010</ref>). More recently, these methods have been superseded by more sophisticated heuristics such as RefHap (<ref type="bibr" target="#b5">Duitama et al., 2012</ref>) or HapCut (<ref type="bibr" target="#b0">Bansal and Bafna, 2008</ref>) that involve solving a Max-Cut problem as a subroutine. There is also an exact dynamic programming solution to the SIH problem; its running time is exponential in the length of the longest read (<ref type="bibr" target="#b8">He et al., 2010</ref>). Several probabilistic approaches have also been previously proposed, including HASH (<ref type="bibr" target="#b0">Bansal et al., 2008</ref>), MixSIH (<ref type="bibr" target="#b15">Matsumoto and Kiryu, 2013</ref>) and an algorithm used for reconstructing the diploid genome of Ciona intestinalis (<ref type="bibr" target="#b11">Kim et al., 2007</ref>). These methods optimize an objective function similar to that of PROBHAP using heuristics based on Markov chain Monte Carlo (MCMC). They differ in the way in which they implement MCMC. In addition, MixSIH (<ref type="bibr" target="#b15">Matsumoto and Kiryu, 2013</ref>) is to our knowledge the only package that also provides confidence scores at phased positions. Probabilistic graphical models are widely used in the statistical phasing literature to determine haplotypes from a panel of individuals using linkage disequilibrium patterns. However, the vast majority of statistical methods do not use the partial phase information provided by long reads, and are not applicable to our setting. A notable exception is a recent method called Hap-Seq (<ref type="bibr" target="#b9">He et al., 2012</ref>); without its statistical component it reduces to the well-known exact exponential-time algorithm mentioned above (<ref type="bibr" target="#b8">He et al., 2010</ref>). Also, there exists an extensive literature on the SIH problem from the perspective of combinatorial optimization (<ref type="bibr" target="#b14">Lippert et al., 2002</ref>). Research in this field is aimed at optimizing combinatorial objectives such as minimum fragment removal, minimum SNP removal or MEC. This research is of a more theoretical nature and aims at providing a rigorous theoretical understanding of the SIH problem (<ref type="bibr" target="#b14">Lippert et al., 2002</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of PROBHAP</head><p>PROBHAP is based on a new exact dynamic programming solution for the SIH problem, which makes it more accurate than many existing methods. Its main drawback is a higher computational cost: its worst-case running time increases exponentially with the read coverage. Fortunately, modern long read technologies cover the genome at a relatively low depth (<ref type="bibr" target="#b5">Duitama et al., 2012;</ref><ref type="bibr" target="#b12">Kitzman et al., 2010</ref>), making it possible to apply our algorithm to such data. In cases when the coverage is extremely high, PROBHAP also uses a preprocessing heuristic to merge similar reads (see Section 4). In our experience, PROBHAP handles long read coverages of up to 20Â; however, it is not appropriate for higher coverage short read datasets. The output of PROBHAP is a set of haplotype blocks in the format of RefHap and HapCut. In addition, PROBHAP also produces at each position three confidence scores that can be used to identify locations where the phasing results are less accurate. The posterior score represents the probability of correctly determining the phase of a SNP with respect to the first SNP in the block. The transition score represents the probability of correctly determining the phase of a SNP with respect to the previous one. Finally, the emission score is often helpful in finding sequencing errors and other issues with the underlying data. Whenever the transition score is too low, we suggest breaking the haplotype block at a position. Whenever the posterior or the emission scores are low, we suggest leaving that position unphased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison methodology</head><p>We compared PROBHAP to three state-of-the art algorithms— RefHap (<ref type="bibr" target="#b4">Duitama et al., 2010</ref>), FastHare (<ref type="bibr" target="#b16">Panconesi and Sozio, 2004</ref>) and DGS (<ref type="bibr" target="#b16">Panconesi and Sozio, 2004</ref>) as well as to HapCut (<ref type="bibr" target="#b0">Bansal and Bafna, 2008</ref>), a historically important phasing package, and to MixSIH (<ref type="bibr" target="#b15">Matsumoto and Kiryu, 2013</ref>), the only method that we know that produces confidence scores. Previous studies (<ref type="bibr" target="#b5">Duitama et al., 2012;</ref><ref type="bibr" target="#b6">Geraci, 2010</ref>) have identified the above methods as being the current state-of-the-art in single-individual haplotype phasing. Note that we do not compare our method to HapSeq (<ref type="bibr" target="#b9">He et al., 2012</ref>) because this package additionally uses populationbased statistical phasing techniques to improve accuracy. We also do not consider previously proposed exact dynamic programming methods (<ref type="bibr" target="#b8">He et al., 2010</ref>), as they do not scale to long reads: their running time increases exponentially in the number of variants in a read, and some of the reads in our datasets have 450 variants. The heuristics we consider work as follows. In brief, FastHare sorts the input reads, and then traverses this ordering once, greedily assigning each read to its most probable chromosome given what has been seen so far. The DGS method is equally simple: it iterates until convergence between assigning each fragment to its closest chromosome, and recomputing a set of consensus haplotypes. The RefHap and Hapcut algorithms construct a graph based where each vertex is either associated with a position (HapCut) or with a sequencing read (RefHap); then, the algorithms approximately solve a MaxCut problem on this graph. We test the above methods on a long read dataset from HapMap sample NA12878 that was produced using a fosmidbased technology (<ref type="bibr" target="#b5">Duitama et al., 2012</ref>). The long reads have an average length of $40 kb and cover the genome at a depth of $3Â. This dataset is a standard benchmark for SIH algorithms (<ref type="bibr" target="#b5">Duitama et al., 2012;</ref><ref type="bibr" target="#b15">Matsumoto and Kiryu, 2013</ref>) in part because HapMap sample NA12878 has also been phased multiple times based on the genomes of its parents. In this work, we take the trio-phased variant calls from the GATK resource bundle (<ref type="bibr" target="#b3">DePristo et al., 2011</ref>); these provide accurate phase at 1 342 091 heterozygous variants that are also present in the long read dataset. We measure performance using the concept of a switch error (<ref type="bibr" target="#b2">Browning and Browning, 2011</ref>). A switch error is said to occur when the true parental provenance of SNPs on a haplotype changes with respect to the previous position. For example, if the true SNP origins of a phased block can be written as MMFF, then we say there is a switch error at the third position. In this analysis, we differentiate between two types of switches: a long switch corresponds to an inversion that lasts for more than one position (e.g. MMFF); a short switch, on the other hand, affects only a single position (e.g. MMFM). Switch accuracy is defined as the number of positions without switch errors, divided by the number of positions at which such errors could be measured. Long switch accuracy is defined accordingly in terms of long switch errors. We also measure accuracy in terms of switches per megabase (Sw./Mb). Finally, a block N50 length of x signifies that at least 50% of all phased SNPs were placed within blocks containing x SNPs or more. The percentage of SNPs phased was defined as the number of SNPs in blocks of length two or more, divided by the total number of SNPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Given comparable phasing rates and N50 block lengths, PROBHAP produced haplotype blocks with more accurate longrange phase: the long-range switch error of PROBHAP was 11% lower than that of the second best algorithm, RefHap (<ref type="figure" target="#tab_1">Table 1</ref>). In addition, PROBHAP also produced 6% fewer short switch errors than RefHap. Note that long switch accuracy is substantially more important than short switch accuracy, as it drastically changes the global structure of haplotypes. Short switch errors, on the i380</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V.Kuleshov</head><p>other hand, introduce relatively small amounts of noise in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluating confidence scores</head><p>In addition to being more accurate, PROBHAP is also one of the few algorithms which can provide estimates of their accuracy in the form of confidence scores. As an example of how such scores might be used, we pruned phased positions that were deemed by PROBHAP to be uncertain and measured the resulting accuracy. More specifically, we defined thresholds for each of the three confidence scores reported by PROBHAP. Whenever the posterior or emission scores were lower than a threshold, we treated that position as unphased. Whenever the transition probability was below a threshold, we split the phased block into two parts at that position.<ref type="figure" target="#fig_1">Figure 1</ref>shows that after pruning, one obtains phased blocks that are 30–40% more accurate than the unpruned blocks (recall that we describe them in<ref type="figure" target="#tab_1">Table 1</ref>); the price to pay is a drop of 10–25% in N50 and phasing rate. The particular numbers shown in<ref type="figure" target="#fig_1">Figure 1</ref>were achieved by fixing the posterior and transition cutoffs to 0.6 and 10 À5 , respectively, and setting the emission cutoff to 10 À5 ; 10 À4 ; 10 À3 ; 10 À2 , 0.05, 0.1, 0.4 and 0.99. Next, we compared the pruned regions from PROBHAP to those of MixSIH, the only other package that allows the user to exclude low-confidence positions. We chose thresholds so as to keep either the N50 or the phasing rate constant across both algorithms, and measured how accuracy varied with the remaining non-fixed parameter. We present the results of our experiment in<ref type="figure" target="#fig_0">Figure 2</ref>. Overall, we see that given the same level of haplotype completeness, the pruned blocks of PROBHAP contain 20–30% fewer switching errors than those from MixSIH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Running time</head><p>We measured the running times of the algorithms on a laptop computer (<ref type="figure" target="#tab_2">Table 2</ref>). We did not include HapCut in this comparison, as it is several orders of magnitude slower that the other methods (<ref type="bibr" target="#b5">Duitama et al., 2012</ref>). Although the three heuristics ran faster than PROBHAP and MixSIH, a major reason for their speed was due to not having to compute confidence scores. In fact, PROBHAP spends roughly two-thirds of its running time</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Notation</head><p>Formally, an instance of the SIH problem is defined by a pair of n Â m matrices M, Q, whose columns correspond to heterozygous positions (indexed by j=1;. .. ; m), and whose rows correspond to reads (indexed by i=1;. .. ; n). We refer to M as the phasing matrix; its entries take values in the set f0; 1; Àg. These values indicate the allele carried by a read at a given position: for example, M ij = 0 signifies that read i covers position j and carries allele 0 at j. A value of – indicates that read i did not cover position j. See<ref type="figure" target="#tab_3">Table 3</ref>for an example of a 2 Â 4 phasing matrix. The n Â m matrix Q 2 ½0; 1 nÂm is referred to as the q-score matrix; it encodes the probability of observing a sequencing error at a given position in a read. Such scores are available on virtually all sequencing platforms. A solution to an instance of the SIH problem consists of a pair of vectors h 2 f0; 1g m and r 2 f0; 1g n. The former determines the subject's haplotypes: at each genomic position j, it specifies an allele h j 2 f0; 1g. We consider only one haplotype, as the second is always the complement h of the first. The second vector r 2 f0; 1g n indicates the true provenance r i 2 f0; 1g of each read i (i.e. whether i was obtained from the 'maternal' or the 'paternal' copy; because we do not have information to determine which copy comes from which parent, we refer to them as 0, 1). We also use</p><formula>h j ðr i Þ= h j if r i =0 h j if r i =1 (</formula><p>to denote alleles on the haplotype from which read i originated. Next, let PoðiÞ=fjjM ij 6 ¼ Àg denote the set of positions covered by read i. Let also H i =fh j jmin PoðiÞ j max PoðiÞg be the set of haplotype variables spanned by read i and let R j =fr i jmin PoðiÞ j max PoðiÞg be the set of read provenance variables spanning a position j. We will use this notation to simplify several expressions throughout the article. In particular, if position j is spanned by, say, reads 2, 3, then we will use the notation max</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Probabilistic model</head><p>We define the probability Pðr; h; oÞ over haplotypes h 2 f0; 1g m , assignments of reads r 2 f0; 1g n and observed data o 2 f0; 1; Àg nÂm to be a product of factors</p><formula>Pðr; h; oÞ= Y n i=1 Y j:j2PoðiÞ Pðo ij jr i ; h j Þ Y n i=1 Pðr i Þ Y m j=1 Pðh j Þ;</formula><p>where( is the probability of observing the allele on the j-th position in read i, and the factors Pðr i Þ and Pðh j Þ are priors that we leave as uniform, except for Pðh 1 =0Þ=1. This last choice eliminates the ambiguity stemming from the fact that a solution h can be always replaced with its complement h; it resolves this ambiguity by always choosing the solution with h 1 =0. Finally, note that the r and h variables are hidden, while the o variables are observed; the observed values are defined by the matrix M. The dependency structure of P can be represented in terms of a Bayesian network whose topology mirrors the two-dimensional structure of the matrix M. See<ref type="figure" target="#fig_4">Figure 3</ref>for the Bayesian network associated with the phasing matrix in<ref type="figure" target="#tab_3">Table 3</ref>, which we gave earlier as an example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Maximum likelihood haplotypes</head><p>We determine maximum-likelihood haplotypes h Ã =arg max h log Pðo= MjhÞ using the belief propagation algorithm, also known as max-sum message passing over a junction tree (<ref type="bibr" target="#b13">Koller and Friedman, 2009</ref>). In brief, this algorithm involves groups of variables passing each other information about their most likely assignment; a well-known special case of this method is the Viterbi algorithm for hidden Markov models (HMMs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Definition of max-sum message passing We start by briefly</head><p>defining the max-sum message passing algorithm for graphical models. Readers familiar with the subject may skip this subsection. DEFINITION 1. Let P be a probability over a set of variables X=fx 1 ;. .. ; x n g that is a product of k factors P= Y k i=1 i ðX i Þ, with each factor i being defined over a subset of variables X i X. A junction tree T over P is a tree whose set of nodes is a family of subsets C=fC 1 ;. .. ; C m g, with C j X and that satisfies the following properties:</p><p>(1) For each factor i , there is a cluster c(i) such that X i C cðiÞ .</p><p>(2) (Running intersection) If x 2 C i and x 2 C j , then x 2 C k for all C k on the unique path from C i to C j in T.</p><p>Given this definition, we now define max-sum message passing. We restrict our definition to the case when the junction tree T is a path, which is going to be the case for our model. DEFINITION 2. Let P be a probability distribution as in Definition 1. Let T be a junction tree over clusters C j for j=1;. .. ; m connected into a path and ordered by j, with C m serving as the root. The max-sum message from C j to C j+1 is a function M j defined over the variables in C j \ C j+1 asThe actual assignment that maximizes P can be found by storing the variable assignments that maximize each M j. Unfortunately, proving the correctness of this algorithm is beyond the scope of this article. For a complete discussion that holds for arbitrary junction trees, we refer the reader to a textbook on graphical models (<ref type="bibr" target="#b13">Koller and Friedman, 2009</ref>).C j =fr i ; h j ; o ij jmin PoðiÞ j max PoðiÞg for j=1;. .. ; m connected into a path ordered by j, with C m serving as the root.</p><p>Each cluster C j contains h j and all the o ij and r i variables associated with reads that span across position j. For an example of one such cluster, see<ref type="figure">Figure</ref>PROOF. It is easy to check that the scope of each factor of P is in a unique cluster. We therefore focus on proving that T has the running intersection property. Let C x , C y be two clusters in T with x y, and let C z be a cluster on the path between C x and C y. Because T is a path, we must have x z y. We need to show that C y \ C x C z. Observe that by construction C y \ C x can only contain r-variables. Let r l 2 C y \ C x be one such variable. We need to show that r l 2 C z , i.e. that min PoðlÞ z max PoðlÞ. From r l 2 C y \ C x , we have that PoðlÞ y x max PoðlÞ. Because we also have x z y, our claim follows. Now let R j\j+1 =R j \ R j+1 and R jnj+1 =R j nR j+1. The interested reader may verify that the message from cluster j to cluster j + 1 during a run of max-sum message passing with C m as the root of T equals for j41,</p><formula>M j ðR j\j+1 Þ = max hj max Rjnj+1 X i:ri2Rj log Pðo ij jr i ; h j Þ+M jÀ1 ðR jÀ1\j Þ 0 @ 1 A ; ð1Þ and for j = 1, M 1 ðR 1\2 Þ=max R1n2 X i:ri2C1 log Pðo i1 jr i ; h 1 =0Þ</formula><p>. Note that we disregard the priors Pðr i Þ; Pðh j Þ in all messages except the first because they are uniform. Intuitively, MðR j\j+1 Þ represents the maximum likelihood of the data at positions 1;. .. ; j assuming that reads spanning both j and j + 1 have provenances specified by R j\j+1. The maximum of P is computed using the recursion max</p><formula>hm max Rm X i:ri2Rm log Pðo im jr i ; h m Þ+M mÀ1 ðR mÀ1\m Þ ! :</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Running time</head><p>The above algorithm computes one message for each of m. A message specifies a value for each assignment of variables in R j\j+1 ; this value is the maximum over all assignments to h j and to R jnj+1 , and for each such assignment, we need to compute P i:ri2Rj log P ðo ij jr i ; h j Þ in OðjR j jÞ time. Therefore, computing a message requires jR j j Â2 Â 2 jRj\j+1j Â 2 jRjnj+1j =jR j j2 jRjj+1 iterations. Thus, the total running time of the algorithm is Oðm2 +1 Þ, where =max j jR j j is the maximal coverage across all the positions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Confidence scores</head><p>Next, we turn our attention to deriving confidence estimates for genomic regions. As an example of why such estimates are useful, we show in<ref type="figure" target="#tab_4">Table 4</ref>that, somewhat counter-intuitively, two SNPs may be unphased even when they are connected by accurate reads.<ref type="figure" target="#tab_4">Table 4</ref>, the data contains sequencing errors at position 3 or 4. If the error occurs at position 3 (in either row), then the two reads come from the same haplotype and the correct solution is h = 00000. If, on the other hand, the error occurs at position 4, then the two reads come from different chromosomes and the true haplotype is h = 00111. If the quality scores are the same at all positions, the four errors are equally likely, and the haplotypes h = 00000, h = 00111 have the same probability. Simple optimization-based algorithms would likely produce a single haplotype in the above example; our probabilistic model, however, would assign a transition probability of 0.5 to position 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Motivating example In</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Dynamic programming recursion</head><p>We again perform probabilistic inference in our model using belief propagation. Our particular implementation of this method is inspired by the sum-product message passing algorithm (<ref type="bibr" target="#b13">Koller and Friedman, 2009</ref>) over the previously defined junction tree T. In sum-product message passing, clusters of variables pass to each other information about their local probability distribution; after two rounds of message passing (referred to as 'forwards' and 'backwards'), the clusters become calibrated and can be queried for various probabilities. A well-known special case of this method is the forwards–backwards algorithm for HMMs. More concretely, we compute for each node j two factors, F½h j ; R j  and B½h j ; R j , using the dynamic programming recursions below.</p><formula>F½h j ; R j  = X hjÀ1 X RjÀ1$Rj F½h jÀ1 ; R jÀ1 PðO j jh j ; R j ÞPðR j ÞPðh j Þ ð2Þ B½h j ; R j  = X hj+1 X Rj+1$Rj B½h j+1 R j+1 PðO j+1 jh j+1 ; R j+1 ÞPðR j+1 ÞPðh j+1 Þ ð3Þ</formula><p>The notation R j $R jÀ1 indicates that the r i variables common to both R j and R jÀ1 have been assigned the same value, and PðO j jh j ; R j Þ is shorthand forwhere O k:l =fo ij jk j lg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Computing confidence probabilities From (4)</head><p>, (5), we can now easily compute confidence scores. One such score is the posterior probability Pðh j jO 1:m Þ. It represents the probability that h j was determined correctly with respect to h 1 and can be computed as Pðh j jO 1:m Þ= P Rj Pðh j ; R j jo 1:m Þ, where Pðh j ; R j jO 1:m Þ=PðO 1:j ; h j ; R j ÞPðO j+1:m jh j ; R j Þ=PðO 1:m Þ: Next, the transition probability Pðh j jh jÀ1 ; O 1:m Þ represents the probability of consecutive SNPs being phased correctly; it can be used to detect potential errors like the one shown in<ref type="figure" target="#tab_4">Table 4</ref>. We compute this value using the identity Pðh j jh jÀ1 ; O 1:m Þ=Pðh j ; h jÀ1 jO 1:m Þ=Pðh jÀ1 jO 1:m Þ, where the denominator is the posterior probability and the numerator is computed as</p><formula>Pðh j ; h jÀ1 jO 1:m Þ= P Rj;RjÀ1 Pðh j ; h jÀ1 ; R j ; R jÀ1 ; O 1:m Þ PðO 1:m Þ = P hj;Rj PðO j+1:m jh j ; R j ÞTðh j ; R j ; O j Þ PðO 1:m Þ ; where Tðh j ; R j ; O j Þ= X hjÀ1;RjÀ1 PðO j jh j ; R j ÞPðh j ÞPðR j ÞPðO 1:j ; h j ; R j Þ</formula><p>Additionally, we found that the emission probability PðO j jh j R j Þ was useful in detecting errors in the data. Computing this value only involves the expression PðO j jh j R j Þ= Q i:j2PoðiÞ Pðo ij jr i ; h j Þ. Finally, note that in general, one can compute any set of probabilities Pðh k jh l ; O 1:m Þ in the model. However, this involves doing potentially up to a full run of message passing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">A merging heuristic</head><p>The exact dynamic programming algorithm described above is practical for coverages of up to 10–12Â. For deeper or for highly uneven coverages, we propose a simple preprocessing heuristic. The heuristic consists in reducing the coverage by repeatedly merging reads that are likely to come from the same haplotypes until there are no reads that we can confidently merge. To determine whether to merge reads k, l, we consider the ratiowhere Pðo kj ; x; yÞ is shorthand for Pðo k j; r k =x; h j =yÞ. Intuitively, the denominator is associated with the likelihood that the two reads come from the same haplotype and the numerator is associated with the likelihood that the reads' origins are different. Both terms are estimated by a heuristic formula that decomposes over each position. If reads k, l are merged, then position j of the resulting new read is assigned the allele that has the highest q-score in the initial reads k, l (i.e. arg max k;l fQ kj ; Q lj g); the q-score at that position is set to the difference of the initial reads' q-scores (i.e. jQ kj À Q lj j). In practice, one may select a confidence threshold for (6) and only merge reads that are below this threshold. We found empirically a value of 1 À 10 À9 to work well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">A post-processing heuristic</head><p>In addition, PROBHAP admits an extra post-processing heuristic for adjusting the optimal haplotypes h Ã. This heuristic was initially proposed for the algorithm RefHap; PROBHAP currently uses it by default, although it can be disabled. The heuristic starts with the optimal read assignments r Ã and determines at each position j a pair of sets</p><formula>S j;0 =fijðr i =0 \ M ij =0Þ [ ðr i =1 \ M ij =1Þg S j;1 =fijðr i =0 \ M ij =1Þ [ ðr i =1 \ M ij =0Þg:</formula><p>It then outputs a new haplotype h new defined as h new j = 0 if jS j;0 j4jS j;1 j 1 if jS j;0 j5jS j;1 j À otherwise:</p><formula>8 &gt; &gt; &lt; &gt; &gt; :</formula><p>We found that this heuristic increases the short switch accuracy of PROBHAP on the NA12878 dataset; the long switch accuracy remains the same. We suggest using this heuristic in settings where the quality scores may not be well calibrated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION: THEORETICAL ASPECTS</head><p>Interestingly, the probabilistic framework of PROBHAP generalizes the SIH formalism on which most existing methods are based. This allows us to easily derive well-known exact dynamic programming algorithms as special cases of the variable elimination algorithm for graphical models. More interestingly, the variable elimination algorithm with different variable orderings results in novel exact algorithms that are far more efficient than existing ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Generalizing the SIH framework</head><p>In its standard formulation, the SIH problem consists in finding a haplotype h that minimizes the MEC criterion:</p><formula>MECðh; MÞ = X n i=1 min X j:j2PoðiÞ IðM ij =h j Þ; X j:j2PoðiÞ IðM ij =h j Þ " # ;</formula><p>where I : fTrue; Falseg ! f0; 1g is the indicator function, and the remaining notation is the same as defined in the Section 4. The MEC measures the total number of positions within all the reads that need to be corrected to make the reads consistent with a haplotype h. It is easy to show that the MEC objective can be recovered as a special case of our framework. Indeed, if we define the factors ðo ij ; r i ; h j Þ (which we have previously set to Pðo ij jr i ; h j Þ) in a way that ðo ij ; r i ; h j Þ= exp ð1Þ if o ij 6 ¼ h j ðr i Þ exp ð0Þ if o ij =h j ðr i Þ; ( then log PðM; r; hÞ equals MEC(h, M), although P is no longer a probability. Thus, our dynamic programming algorithms can also produce exact solutions to the MEC objective, and just as interestingly, they can produce confidence probabilities associated with the MEC. i384</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V.Kuleshov</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rederiving existing SIH algorithms</head><p>Interestingly, we can easily recover an existing dynamic programming algorithm (<ref type="bibr" target="#b8">He et al., 2010</ref>) for the MEC as a special case of variable elimination in our graphical model. Indeed, consider the junction tree defined by n variable clusters C i =fr i ; h j ; o ij j j 2 PoðiÞg connected into a path ordered by i. If we assume for simplicity that the data have no contained reads, then the message from cluster i – 1 to cluster i during a run of max-sum message passing with C n as the junction tree root equals precisely</p><formula>MðH i\i+1 Þ = max ri max Hini+1 X j:hj2Hi log Pðo ij jr i ; h j Þ+MðH iÀ1\i Þ 0 @ 1 A ; ð7Þ</formula><p>where H i\i+1 =H i \ H i+1 and H ini+1 =H i nH i+1. This is essentially the well-known dynamic programming recursion (<ref type="bibr" target="#b8">He et al., 2010</ref>) we were looking to find. Unfortunately, the time to compute the above recursion increases exponentially in the length of the reads, which is precisely the data we want to use for phasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Deriving novel SIH algorithms</head><p>Fortunately, as we have seen, we can derive from our framework exact algorithms that are suitable for long read data. Interestingly, these methods are in a sense dual to equation (7): the structure of the probabilistic model P is entirely symmetric in r, h. If we reverse h and r in Section 4, we obtain recursion (7). Potentially, our framework allows deriving other exact algorithms by defining alternative junction trees for the max-sum message passing algorithm. One way to do this involves using minimizing their tree-width using some well-known heuristics (<ref type="bibr" target="#b13">Koller and Friedman, 2009</ref>). Because the running time maxsum message passing is exponential in the tree-width of a junction tree, this would lead to much faster running times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In summary, we have introduced a new single-individual phasing algorithm, PROBHAP, that offers an 11% improvement in accuracy over the current state-of-the-art method, RefHap. In addition, it is one of the only methods to provide the user with confidence scores at every position; these confidence scores can be used to prune positions whose phase is uncertain and thus substantially increase the overall accuracy. The advances behind PROBHAP are made possible by framing the phasing problem within a probabilistic graphical models framework. This framework makes it particularly easy to reason about the problem; in fact, all our algorithms are special cases of standard procedures for optimizing graphical models. On the theoretical side, this work generalizes the MEC criterion used by existing methods. Our approach allows us to obtain existing algorithms as special cases of well-known optimization procedures, and also easily derive new, more efficient algorithms; it may thus serve as a foundation for further algorithmic insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>We thank Sivan Berovici for important suggestions regarding the model definition, as well as Dmitry Pushkarev and Michael Kertesz for helpful discussions. This research was partly done at Moleculo Inc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig.2.</head><figDesc>Fig. 2. Comparison of the accuracy/completeness trade-off of PROBHAP and MixSIH. The top panel compares the trade-off between the N50 and the phasing accuracy; the phasing rate was the same for both algorithms at each point. Similarly, the bottom panel examines the phasing rate trade-off</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig.1.</head><figDesc>Fig. 1. Accuracy/completeness trade-off for PROBHAP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3. LEMMA1.</head><figDesc>The tree T in Definition 3 is a valid junction tree for the distribution P defined in Section 4.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig.3.</head><figDesc>Fig. 3. Bayesian network associated with the problem instance defined in Table 3. The shaded nodes represent hidden variables; unshaded variables are observed. Variables belonging to cluster C 3 of the associated junction tree are shown in bold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><figDesc>Funding: This work was partly funded by NIH/NHGRI grant T32 HG000044. Conflict of Interest: none declared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Comparison of algorithm performance</figDesc><table>Algorithm 
Long sw./Mb 
Short sw./Mb 
% phased 
N50 

PROBHAP 
1.07 
3.70 
91.83 
227 
Refhap 
1.20 
3.91 
91.75 
226 
FastHare 
1.32 
4.03 
91.76 
227 
DGS 
1.48 
4.18 
91.66 
227 
HapCut 
1.61 
4.93 
91.61 
227 
MixSIH 
1.41 
5.43 
92.64 
229 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><figDesc>Table 2.</figDesc><table>Running time of each algorithm on chromosome 22 

Refhap 
FastHare 
DGS 
MixSIH 
PROBHAP 

Running time 
3.65 s 
1.85 s 
1.99 s 
274.82 s 
58.53 s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><figDesc>Table 3. Example of a 2 Â 4 phasing matrix M, in which two reads cover three positions each</figDesc><table>1 
2 
3 
4 

R e a d 1 
0 
1 
0 
– 
R e a d 2 
– 
1 
0 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><figDesc>Table 4.</figDesc><table>Example of a sequencing error that confounds the long-range 
structure of the haplotypes 

1 
2 
3 
4 
5 

R e a d 1 
0 
0 
1 
0 
– 
R e a d 2 
– 
– 
0 
0 
0 

Note. If the quality scores are the same at all positions, the haplotypes h = 00000, 
h = 00111 have the same probability. 

</table></figure>

			<note place="foot">ß The Author 2014. Published by Oxford University Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/3.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">HapCUT: an efficient and accurate algorithm for the haplotype assembly problem</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bafna</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="153" to="159" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b1">
	<analytic>
		<title level="a" type="main">An MCMC algorithm for haplotype assembly from wholegenome sequence data</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Bansal</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1336" to="1346" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b2">
	<analytic>
		<title level="a" type="main">Haplotype phasing: existing methods and new developments</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Browning</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Browning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="703" to="714" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">A framework for variation discovery and genotyping using next-generation DNA sequencing data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Depristo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="491" to="498" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">ReFHap: a reliable and fast algorithm for single individual haplotyping</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Duitama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First ACM International Conference on Bioinformatics and Computational Biology</title>
		<meeting>the First ACM International Conference on Bioinformatics and Computational Biology<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Fosmid-based whole genome haplotyping of a HapMap trio child: evaluation of Single Individual Haplotyping techniques</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Duitama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2041" to="2053" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A comparison of several algorithms for the single individual SNP haplotyping reconstruction problem</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Geraci</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2217" to="2225" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Inference of haplotypes from samples of diploid populations: complexity and algorithms</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gusfield</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="305" to="323" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimal algorithms for haplotype assembly from whole-genome sequence data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">Hap-seq: an optimal algorithm for haplotype phasing with imputation using sequencing data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>He</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RECOMB&apos;12: Proceedings of the 16th Annual international conference on Research in Computational Molecular Biology</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Whole-genome haplotyping by dilution, amplification, and sequencing</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Kaper</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl Acad. Sci. USA</title>
		<meeting>. Natl Acad. Sci. USA</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="5552" to="5557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">Diploid genome reconstruction of Ciona intestinalis and comparative analysis with Ciona savignyi</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">H</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1101" to="1110" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Haplotype-resolved genome sequencing of a Gujarati Indian individual</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">O</forename>
				<surname>Kitzman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Biotechnol</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="59" to="63" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models: Principles and Techniques-Adaptive Computation and Machine Learning</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Koller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Friedman</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">Algorithmic strategies for the single nucleotide polymorphism haplotype assembly problem</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lippert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="23" to="31" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">MixSIH: a mixture model for single individual haplotyping</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Matsumoto</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kiryu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Genomics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Suppl. . 2</note>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast hare: a fast heuristic for single individual snp haplotype reconstruction</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Panconesi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sozio</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<editor>Jonassen,I. and Kim,J.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Accurate whole-genome sequencing and haplotyping from 10 to 20 human cells</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">A</forename>
				<surname>Peters</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">487</biblScope>
			<biblScope unit="page" from="190" to="195" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<monogr>
		<title level="m" type="main">The genome sequence of the colonial chordate</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Voskoboynik</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>