
<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/joey/Project/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.2-SNAPSHOT" ident="GROBID" when="2017-08-10T23:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Genetics and population analysis FISH: fast and accurate diploid genotype imputation via segmental hidden Markov model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014">2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Lei</forename>
								<surname>Zhang</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Shaanxi</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Bioinformatics</orgName>
								<orgName type="institution">Tulane University</orgName>
								<address>
									<settlement>New Orleans</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yu-Fang</forename>
								<surname>Pei</surname>
							</persName>
							<affiliation key="aff0">
								<orgName type="department">School of Public Health</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong University</orgName>
								<address>
									<settlement>Shaanxi</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Bioinformatics</orgName>
								<orgName type="institution">Tulane University</orgName>
								<address>
									<settlement>New Orleans</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Xiaoying</forename>
								<surname>Fu</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Bioinformatics</orgName>
								<orgName type="institution">Tulane University</orgName>
								<address>
									<settlement>New Orleans</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yong</forename>
								<surname>Lin</surname>
							</persName>
							<affiliation key="aff2">
								<orgName type="department">Center of System Biomedical Sciences</orgName>
								<orgName type="institution">University of Shanghai for Science and Technology</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Yu-Ping</forename>
								<surname>Wang</surname>
							</persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Bioinformatics</orgName>
								<orgName type="institution">Tulane University</orgName>
								<address>
									<settlement>New Orleans</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName>
								<forename type="first">Hong-Wen</forename>
								<surname>Deng</surname>
							</persName>
							<email>hdeng2@tulane. edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Biostatistics and Bioinformatics</orgName>
								<orgName type="institution">Tulane University</orgName>
								<address>
									<settlement>New Orleans</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Genetics and population analysis FISH: fast and accurate diploid genotype imputation via segmental hidden Markov model</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">30</biblScope>
							<biblScope unit="issue">13</biblScope>
							<biblScope unit="page" from="1876" to="1883"/>
							<date type="published" when="2014">2014</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/btu143</idno>
					<note type="submission">Received on March 11, 2013; revised on March 1, 2014; accepted on March 5, 2014</note>
					<note>BIOINFORMATICS ORIGINAL PAPER Associate Editor: Dr Jeffrey Barrett Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivation: Fast and accurate genotype imputation is necessary for facilitating gene-mapping studies, especially with the ever increasing numbers of both common and rare variants generated by high-throughput-sequencing experiments. However, most of the existing imputation approaches suffer from either inaccurate results or heavy computational demand. Results: In this article, aiming to perform fast and accurate genotype-imputation analysis, we propose a novel, fast and yet accurate method to impute diploid genotypes. Specifically, we extend a hidden Markov model that is widely used to describe haplotype structures. But we model hidden states onto single reference haplotypes rather than onto pairs of haplotypes. Consequently the computational complexity is linear to size of reference haplotypes. We further develop an algorithm &apos;merge-and-recover (MAR)&apos; to speed up the calculation. Working on compact representation of segmental reference haplotypes, the MAR algorithm always calculates an exact form of transition probabilities regardless of partition of segments. Both simulation studies and real-data analyses demonstrated that our proposed method was comparable to most of the existing popular methods in terms of imputation accuracy, but was much more efficient in terms of computation. The MAR algorithm can further speed up the calculation by several folds without loss of accuracy. The proposed method will be useful in large-scale imputation studies with a large number of reference subjects. Availability: The implemented multi-threading software FISH is freely available for academic use at https://sites.google.com/site/lzhangho-mepage/FISH. Contact:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Genotype imputation refers to a process in which missing genotypes at un-typed markers in a test sample are statistically inferred by knowledge of genotypes observed at the same markers in a reference sample (<ref type="bibr" target="#b13">Li et al., 2009;</ref><ref type="bibr" target="#b17">Marchini and Howie, 2010</ref>). The principle underlying genotype imputation is that modern human genomes share segments of haplotypes with each other, as reflected by linkage disequilibrium (LD) patterns (<ref type="bibr" target="#b24">Reich et al., 2001</ref>). Imputed genotypes have been widely used to fill sporadic missing genotypes, to integrate multiple studies with different genotyping platforms into meta-analysis, and to finemap causal, but un-typed, disease loci. Genotype imputation has significant potential to greatly enhance our capacity to integrate and extend the scope of current existing datasets at no additional expense. Consequently, it has become a standard toolkit in largescale genetic-association studies, and this has facilitated the discovery of a remarkable number of genetic loci responsible for a variety of complex traits and diseases (<ref type="bibr" target="#b13">Li et al., 2009;</ref><ref type="bibr" target="#b17">Marchini and Howie, 2010</ref>). A variety of statistical methods, including MACH (<ref type="bibr" target="#b14">Li et al., 2010</ref>), IMPUTE (versions 1 and 2) (<ref type="bibr" target="#b11">Howie et al., 2009;</ref><ref type="bibr" target="#b18">Marchini et al., 2007</ref>), BEAGLE (<ref type="bibr" target="#b4">Browning and Browning, 2007</ref>) and others (<ref type="bibr" target="#b5">Chi et al., 2013;</ref><ref type="bibr" target="#b16">Liu et al., 2013;</ref><ref type="bibr" target="#b19">Pasaniuc et al., 2012;</ref><ref type="bibr" target="#b21">Purcell et al., 2007;</ref><ref type="bibr" target="#b26">Scheet and Stephens, 2006</ref>), have been developed and used widely for genotype imputation. These methods provide excellent accuracy for imputing common variants (minor allele frequency (MAF)45%) derived from genomewide association studies (<ref type="bibr">Duan et al., 2013a, b;</ref><ref type="bibr" target="#b20">Pei et al., 2008</ref>). However, as next-generation sequencing technology is getting mature and more widely applied, an increasing number of less common (1%5MAF55%) and rare variants (MAF51%) have been uncovered. It has been hypothesized that these less common and rare genetic variants represent another potential mechanism by which variations in the human genome influence complex diseases. Consequently, it has become increasingly important to be able to impute fast and accurately this increasing number of these variants in existing genome-wide association studies in order to facilitate gene-mapping studies and to study a variety of genomic structures. The accuracy of genotype imputation is influenced greatly by the size of reference panel (<ref type="bibr" target="#b20">Pei et al., 2008</ref>); larger reference samples increase imputation accuracy. When imputing common variants, reference panels of small to moderate size (e.g. 200) may be sufficient to attain an acceptable level of imputation accuracy. When imputing less common or rare variants, however, the accuracy of imputation will be considerably lower than that for common variants with reference panels of small to moderate size. Consequently, it is critical to use an expanded reference panel when imputing less common or rare variants in order to attain an acceptable level of accuracy. Fortunately, a continuously increasing resource of reference datasets based on next generation sequencing, e.g. 1000 genomes project (<ref type="bibr" target="#b3">Abecasis et al., 2012</ref>), is becoming publicly available. Eventually, these well-validated datasets will provide a comprehensive set of reference samples that can support accurate genotype imputation of an extensive range of genetic variants, from common to rare ones. One practical limitation of existing imputation methods is that they can be computationally intensive when operating with large reference samples. For example, both MACH and IMPUTE have quadratic computational complexity to the number of reference haplotypes used in the hidden Markov model (HMM), a level of complexity which actually prohibits them from making full use of all available reference haplotypes. In practice, both MACH and IMPUTE (version 2) compensate for this limitation by selecting only a subset of reference haplotypes to use for imputation. Obviously, this approach may cause a potential loss of accuracy under certain conditions, and this loss of accuracy may become particularly severe when imputing less common and particularly rare variants. Alternatively, they both have a haploid model implementation with linear complexity, which is achieved by imputing on pre-phased haplotypes rather than diplotypes (<ref type="bibr" target="#b10">Howie et al., 2012</ref>). Nonetheless, phasing diplotypes into haplotypes introduces additional computation demanding as well as phasing uncertainty (<ref type="bibr" target="#b10">Howie et al., 2012</ref>). In the context of a growing number of large sequencing datasets, it is becoming critically important to develop computationally efficient imputation methods that can use large reference datasets in order to retain imputation accuracy, particularly for rare variants, at a reasonably high level. Though a variety of alternative solutions have been proposed (<ref type="bibr" target="#b5">Chi et al., 2013;</ref><ref type="bibr" target="#b10">Howie et al., 2012;</ref><ref type="bibr" target="#b19">Pasaniuc et al., 2012</ref>), they fall short regard to either accuracy or extensive computational demand. Both MACH and IMPUTE are based on Li and Stephen's haploid HMM (<ref type="bibr" target="#b12">Li and Stephens, 2003</ref>). Their heavy computational demand in imputing diplotypes is attributable to modeling hidden states on pairs of reference haplotypes rather than on single haplotypes. In the present article, we propose an alternative and efficient model to impute diplotypes with linear complexity. Basically, we extend the same HMM, but we model hidden states on single haplotypes so that the computational complexity is 'linear' to the size of reference haplotypes. We take into account unphased genotypes through marginalization and decomposition. In addition, we develop an efficient computing algorithm to further speed up the execution of the proposed method. Through simulation as well as real data analyses, we show convincingly that the proposed method is much faster than existing methods, and yet is comparable in terms of imputation accuracy. A typical genome-wide imputation analysis for thousands of individuals, using the largest reference panel derived from the 1000 genomes project and routine computing devices can be accomplished within only a few hours with the method we developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Definitions</head><p>Let H R ¼ {h 1 ,. .. , h R } be a set of R haplotype vectors in the reference sample, each of which is fully genotyped at L markers, h r ¼ {h r1 ,. .. , h rL }, where h rl 2 {0, 1}, r ¼ 1,. .. , R, l ¼ 1,. .. , L. Let G T ¼ {g 1 ,. .. , g T } be a set of T diplotype vectors in the test sample, each of which is partially genotyped at the same L markers, g t ¼ {g t1 ,. .. , g tL }, t ¼ 1,. .. , T.<ref type="figure" target="#tab_2">2</ref>{0, 1, missing} and g tl 2 {0, 1, 2, missing}. When g tl is heterozygous, h ðpÞ tl and h m ð Þ tl may be ambiguous between alleles 0 and 1. Given the above sample structure, our mission is to infer missing genotypes in each element of G T with information of H R. We infer every element in turn and focus on a single element in the following. For simplicity, we omit the subject subscript and denote the diplotype and haplotype vectors as g ¼ {g 1 ,. .. , g L }, h (p) ¼ {h p ð Þ 1 ,. .. , h p ð Þ L } and h (m) ¼ {h m ð Þ 1 ,. .. , h m ð Þ L }. We will first review the haploid imputation model based on the Li and Stephen's HMM, and will then extend the model to impute diploid genotypes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Haploid model</head><p>When the phases of h (p) and h (m) are a priori known, the two haplotype vectors are independent and could be imputed separately. Here we work on a single haplotype for illustration and denote it as h ¼ {h 1 ,. .. , h L }. The HMM assumes that h emerges from an imperfect mosaic of haplotypes in H R , i.e. emitted from a sequence of hidden states that transit along haplotypes in H R (<ref type="bibr" target="#b12">Li and Stephens, 2003</ref>). Let s ¼ {s 1 ,. .. , s L } be a vector of hidden states emitting h, where s l ¼ 1,. .. , R indexes which reference haplotype is the hidden state at the l-th marker. We aim to sample s from its posterior distribution given the observed h and H R , which is defined as,</p><formula>P sjh, H R ð Þ/P s, hjH R ð Þ¼P s 1 ð Þ Y L l¼2 P s l js lÀ1 ð Þ Y L l¼1 P h l js l ð Þ: ð1Þ</formula><p>In the above formula, the initial probability P(s 1 ) has the following form</p><formula>P s 1 ¼ i ð Þ¼ 1 R : ð2Þ</formula><p>The transition probability P(s l js l – 1 ) has the following form</p><formula>P s l ¼ ijs lÀ1 ¼ j ð Þ ¼ 1 À lÀ1 ð Þþ lÀ1 R , if i ¼ j lÀ1 R , otherwise ; ( ð3Þ where l – 1</formula><p>is a locus specific parameter modeling genetic recombination events. At last, the emission probability P(h l js l ) has the following form</p><formula>P h l js l ¼ i ð Þ¼ 1 À e l , if h l ¼ h il e l , otherwise ; &amp; ð4Þ</formula><p>where e l is a locus specific parameter modeling mutation events. Similar extensions of the above model have been implemented in IMPUTE (version 2) and presumably in the haploid implementation of the MACH algorithm MINIMAC (<ref type="bibr" target="#b10">Howie et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Diploid model</head><p>When the phases of h (p) and h (m) are a priori unknown, imputation could not be performed on them directly. Some of the existing methods, including MACH and IMPUTE, avoid this uncertainty by taking pairs of reference haplotypes as hidden states, i.e., modeling on R 2 hidden states. Obviously, this strategy introduces additional computational complexity and may become prohibit in settings of large reference panels. Here we propose a new method that models on the R haploid hidden states even for the diploid genotype vector g so that the computational complexity remains linear to R. Similarly, let</p><formula>s (p) ¼ {s p ð Þ 1 ,. .. , s p ð Þ L } and s (m) ¼{s m ð Þ 1 ,. .. , s m ð Þ</formula><p>L } be two vectors of hidden states emitting h (p) and h (m) , respectively. We aim to sample the sequences of s (p) and s (m) from their posterior distribution given g and H R , that is,</p><formula>P(s (p) , s (m) jg, H R ).</formula><p>The joint posterior distribution of s (p) and s (m) given g and H R is defined as</p><formula>P s ðpÞ , s m ð Þ jg, H R À Á / P s p ð Þ , s m ð Þ , gjH R À Á ¼ P s p ð Þ 1 , s m ð Þ 1 Y L l¼2 P s p ð Þ l , s m ð Þ l js p ð Þ lÀ1 , s m ð Þ lÀ1 Y L l¼1 P g l js p ð Þ l , s m ð Þ l : ð5Þ</formula><p>Under the assumption of random mating, the prior distributions of two parental haplotypes are independent, and so are the two hidden states. Therefore,</p><formula>P s p ð Þ 1 , s m ð Þ 1 ¼ P s p ð Þ 1 p s m ð Þ 1 , ð6Þ</formula><p>and,</p><formula>P s p ð Þ l , s m ð Þ l js p ð Þ lÀ1 , s m ð Þ lÀ1 ¼ P s p ð Þ l js p ð Þ lÀ1 P s m ð Þ l js m ð Þ lÀ1 : ð7Þ</formula><p>The non-missing genotype g l is the sum of two parental alleles</p><formula>g l ¼ h p ð Þ l þ h m ð Þ l. Conditioning on h p ð Þ l and h m ð Þ l , each of the two states s p ð Þ l and s m ð Þ l</formula><p>is independent with the other and with the other parental allele. Therefore,</p><formula>P g l js p ð Þ l , s m ð Þ l ¼ P h p ð Þ l ¼ g l 2 js p ð Þ l ð Þ P h m ð Þ l ¼ g l 2 js m ð Þ l ð Þ , if gl¼0 or 2 P 1 g 0 ¼0 P h p ð Þ l ¼g0js p ð Þ l ð Þ P h m ð Þ l ¼glÀg0js m ð Þ l ð Þ È É , otherwise : ( ð8Þ Terms in probabilities (6)–(8)</formula><p>have the same forms as those in equations (2)–(4), respectively. Sampling from the above HMM is performed with standard forward–backward algorithm (<ref type="bibr" target="#b22">Rabiner, 1989</ref>). We adopt a forward-calculation-backward-selection approach. In the forward pass, the joint prior</p><formula>probabilities P(s p ð Þ l , s m ð Þ l jg 1 ,. .. , g l – 1 ) and posterior probabilities P(s p ð Þ l , s m ð Þ l jg 1</formula><p>,. .. , g l ) at each non-missing marker are of interest. To achieve a linear computational complexity, we decompose them into functions of marginal prior and posterior distributions of s p ð Þ l and s m ð Þ l. Under the random mating assumption and large reference sample size, the following equation approximately holds (see Supplementary Material S1 for details)</p><formula>P s p ð Þ l , s m ð Þ l jg 1 ,. .. , g lÀ1 ¼ P s p ð Þ l jg 1 ,. .. , g lÀ1 P s m ð Þ l jg 1 ,. .. , g lÀ1 , ð9Þ where, P s p ð Þ l ¼ ijg 1 , :::, g lÀ1 ¼ X R r¼1 P s p ð Þ l ¼ ijs p ð Þ lÀ1 ¼ r P s p ð Þ lÀ1 ¼ rjg 1 , :::, g lÀ1 : ð10Þ P(s m ð Þ l jg 1 ,. .. , g l – 1</formula><p>) is calculated in the same way, and is equals to</p><formula>P(s m ð Þ l jg 1 ,. .. , g l – 1 )</formula><p>due to the symmetry. Rather than calculating the posterior distribution</p><formula>P(s p ð Þ l , s m ð Þ l jg 1 ,. .. , g l )</formula><p>directly, we calculate the marginal posterior distributions</p><formula>P(s p ð Þ l jg 1 ,. .. , g l ) and P(s m ð Þ l jg 1 ,. .. , g l ). Let P 0 ¼ P r, hrl¼0 Pðs ðpÞ l ¼ r g 1 ,. .. , g lÀ1 Þ and P 1 ¼ P r, hrl Pðs ðmÞ l ¼ r g 1</formula><p>,. .. , g lÀ1 Þ, then (see Supplementary Material S2 for details)</p><formula>P s p ð Þ l jg 1 ,. .. , g l / P s p ð Þ l jg 1 ,. .. , g lÀ1 P 0 Á P g l js p ð Þ l , 0 þ P 1 Á P g l js p ð Þ l , 1 n o : ð11Þ</formula><p>In the backward pass, a pair of hidden states at each non-missing marker is sampled according to either of the following two probabilities:</p><formula>(i) P(s p ð Þ L , s m ð Þ L jg 1 ,. .. , g L ) or (ii) P(s p ð Þ l , s m ð Þ l jg 1 ,. .. , g l , s p ð Þ l þ1 , s m ð Þ lþ1 ).</formula><p>The first probability is decomposed into two forms that can be sampled sequentially. For example (Supplementary Material S3),</p><formula>P s p ð Þ L , s m ð Þ L jg 1 , :::, g L ¼ P s p ð Þ L jg 1 , :::, g L Á P s m ð Þ L js p ð Þ L , g 1 , :::, g L : ð12Þ</formula><p>The second probability has the form</p><formula>P s p ð Þ l ¼ i 1 , s m ð Þ l ¼ j 1 jg 1 , :::, g l , s p ð Þ lþ1 ¼ i 0 , s m ð Þ lþ1 ¼ j 0 / P s p ð Þ l ¼ i 1 , s m ð Þ l ¼ j 1 jg 1 , :::, g lÀ1 Â P s p ð Þ lþ1 ¼ i 0 , s m ð Þ lþ1 ¼ j 0 js p ð Þ l ¼ i 1 , s m ð Þ l ¼ j 1 P g l js p ð Þ l ¼ i 1 , s m ð Þ l ¼ j 1 ð13Þ</formula><p>To sample, all individual probabilities are summarized into four possible events: (i) neither parental haplotype recombines P nn ; (ii) only paternal haplotype recombines P rn ; (iii) only maternal haplotype recombines P nr ; and (iv) both parental haplotypes recombine P rr. An event is sampled first and then a new pair of hidden states is updated/ sampled accordingly (Supplementary Material S4). Model parameters including recombination parameters and mutation parameters e could be set in accordance with (<ref type="bibr" target="#b12">Li and Stephens, 2003</ref>), or fitted by the data (<ref type="bibr" target="#b14">Li et al., 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Compact representation of reference haplotypes</head><p>Both of the above haploid and diploid models have a linear computational complexity to reference haplotype size. Since different reference haplotypes may have the same type, they could be merged together and represented in a more compact manner (<ref type="bibr" target="#b6">Delaneau et al., 2012</ref>) so that the size of states used in the HMM could be reduced further. Here we adopt the compact representation proposed by<ref type="bibr" target="#b6">Delaneau et al. (2012)</ref>. Briefly, a chromosome is partitioned into multiple non-overlapping segments. Within each segment, haplotypes with the same type are merged together, which we call a block. In partitioning segments, a sliding window starts at the first marker. The window size increases step-wise until the number of blocks within the window exceeds the preset size. A segment is then determined by the window's boundaries. The window starts at the next marker, and the same process repeats until arriving at the last marker. HMM are primarily performed on merged blocks rather than on original individual haplotypes. However, the unit of transition is still individual haplotypes. At block-wise level, two types of transition are involved: within-segmental and between-segmental. Let B ¼ {h 1 ,. .. , h c } and B 0 be two particular blocks within a same segment. In the Supplementary Material S5, we prove that the within-segmental transition probability has the form</p><formula>P s l 2 B s lÀ1 2 B 0 À Á ¼ 1 À lÀ1 ð Þþ clÀ1 R , if B ¼ B 0 , clÀ1 R , o t h e r w i s e &amp; ð14Þ</formula><p>which is essentially the equation used in the<ref type="bibr" target="#b6">Delaneau et al. (2012)</ref>. For between-segmental transition,<ref type="bibr" target="#b6">Delaneau et al. (2012)</ref>used the same transition formula, which is equivalent to assigning equal probabilities to all the c individual haplotypes when leaving the segment. Nonetheless, individual haplotypes may have different probabilities when entering the segment, so their probabilities will not necessarily be equal when leaving the segment. Consequently, this formula could only provide an approximation for between-segmental transitions, and the performance may vary for different partitionings of segments. To overcome this limitation, we here develop a different and improved algorithm to always obtain an exact form of transition probabilities regardless of how segments are partitioned. In the Supplementary Material S6, we show that block transition probability is composed of two components: one contributed by each haplotype equally and the other contributed by each haplotype proportionally to its probability when entering the segment. We therefore develop a corresponding mergeand-recover (MAR) algorithm. Specifically, we merge individual haplotypes into blocks and use Equation (14) to calculate within-segmental transition probabilities; but we record the two probability components separately. We recover individual haplotypes' probabilities by the two components at the end of the segment. We then calculate between-segmental transition probabilities at individual haplotype level with Equation (3). At the beginning of the next segment, individual haplotypes are again merged into blocks, and initial block probabilities are summarized according to individual haplotype probabilities (<ref type="figure" target="#fig_2">Fig. 1</ref>). Our algorithm keeps transition probabilities exact regardless of how segments are partitioned so that the accuracy will not be affected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Implementation</head><p>Both of the haploid and diploid models have been implemented in a userfriendly java package: fast imputation via segmental HMM (FISH). It has a variety of useful features, including support of multiple input/ output data formats and support of multi-threading. The software is publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Simulation study</head><p>To evaluate the performance of the proposed method, we conducted a series of simulation studies. We randomly selected one genomic region of one mega base (MB) length on the human genome, and simulated population sequencing data with the software cosi (<ref type="bibr" target="#b25">Schaffner et al., 2005</ref>). Specifically, we used the 'best-fit' model of the software and generated a pool of 10 000 population haplotypes. Two haplotypes were randomly selected from the pool to generate genotype of a simulated subject. Two samples, reference sample and test sample, were simulated each with 1000 subjects. SNPs failed to pass the Hardy–Weinberg equilibrium (HWE) test (P50.05) were removed from both samples. In the test sample, SNPs with MAF55% were removed, and were further removed randomly to retain the final number to $300 so that the marker density is scalable to 1 million per genome, a reasonable density for commercial genotyping arrays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Real dataset</head><p>The real dataset that we analyzed was from the 1000 genomes project phase 1 release (as of June 2012). We focused on 379 subjects of European ancestry and analyzed the entire chromosome 22. We adopted the leave-one-out strategy and imputed each subject by the reference panel formed by remaining 378 subjects. We filtered out rare variants (MAF51%) because of the limited sample size. SNPs failed to pass the HWE test (P50.05) were also removed. To model a typical GWAS sample, SNPs that existed in the Affymetrix SNP6.0 genotyping array were kept in the to-be-imputed subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Comparison with other methods</head><p>We included three most popular methods for comparison: MACH, IMPUTE2 and BEAGLE. They are widely used in the community and usually outperform other methods under a variety of settings. For a fair comparison, all methods including FISH run on 100 iterations. Most of the other parameter settings were set to the default of the software. We keep in mind that these settings may not represent their best performance. Commands were listed as following:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9">Comparison criteria</head><p>We evaluated the performance of various methods by imputation accuracy and running time. Two imputation accuracy measures were used: the first one was r 2 , which was defined as the correlation coefficient between true genotype and imputed allele dosage; the second one was genotype discordance rate (GDR), which was defined as the proportion of genotypes whose type is incorrectly inferred (<ref type="bibr" target="#b18">Marchini et al., 2007</ref>). Running time was measured on a unified computing configuration of Intel Xeon 2.4GHz CPU E5620.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>In this section, we investigated the performance of the proposed method, namely FISH, as well as compared it with several existing popular methods, through simulated and real datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simulated dataset</head><p>Basic characteristics of the simulated dataset are presented in<ref type="figure" target="#tab_1">Table 1</ref>(left). We first compared the imputation accuracy r 2 between diploid and haploid models. For the haploid model, in order to study the effect of phasing uncertainty on imputation accuracy, we simulated phased haplotypes with different levels of haplotyping switch error rate, which was defined as the proportion of heterozygote positions whose phase is incorrectly inferred relative to the previous heterozygote position (<ref type="bibr" target="#b15">Lin et al., 2002;</ref><ref type="bibr" target="#b27">Stephens and Scheet, 2005</ref>). While the accuracy of the diploid model was not affected by switch error, the accuracy of the haploid model was dependent upon switch error in that imputation accuracy dropped consistently as switch error rate increased (<ref type="figure">Fig. 2</ref>). The diploid model was more accurate than the haploid model under most conditions tested. When switch error rate was below 0.2%, the diploid model was slightly inferior to the haploid model, and under these conditions, haplotypes were nearly perfectly inferred. Thus, when using the haploid model, the accuracy of pre-phase haplotypes is critical.As stated earlier, the MAR algorithm that we developed calculated an exact form of transition probability matrix regardless of the structure of compact representation of haplotypes. Therefore, compact representation did not affect imputation accuracy; what was being affected was running time. Here, we studied the reduction in running time from compact versus uncompact representation when all reference haplotypes were used for imputation. Both representations used the total number of R reference haplotypes. The uncompact representation therefore had an constant state size R and running time; it served as a benchmark. The running time for both models is displayed in<ref type="figure" target="#fig_3">Figure 3</ref>. For both diploid and haploid models, running time under compact representation decreased initially then increased, as the number of states increased. The gain in computational efficiency was highly correlated with compact ratio (see Section 4 for details). Shortest running times for both diploid and haploid models were approximately equal, and were observed in the range between $50 and 300 states. Compared to uncompact representation, compact representation could decrease running time by $3-fold under its best performance. Running time also elevated moderately as state size fell below 50, and MAR event occurred frequently under these conditions. Consequently, for most practical applications, we recommended an intermediate value of 50–100 states in order to optimize computational efficiency.</p><p>The imputation accuracies of various methods are presented in<ref type="figure" target="#tab_2">Table 2</ref>. As a benchmark, we also imputed with the haploid model on the simulated haplotypes of the test sample so that haplotypes were perfectly phased, and we considered this analysis an 'Ideal' model as we expected it to give the highest accuracy. BEAGLE and FISH used all the R reference haplotypes, so they were not influenced by state size. The performance of MACH got better as state size increased. Interestingly, the performance of IMPUTE2 was less sensitive to state size. Its accuracy was only observed to get better slightly when state size increased from 50 to 100. For common variants (MAF45%), all methods had very high accuracies that was close to the 'Ideal' model of imputation on perfectly phased haplotypes, though the performance of MACH was inferior slightly at very low state sizes. For less common variants (1%5MAF 5%), FISH again had an accuracy close to the 'Ideal' model regardless of state size, while MACH achieved a high accuracy at state sizes 4400. We observed a slight loss of accuracy for BEAGLE compared to the other methods; with the exception of MACH at low state sizes (5400). For rare variants (MAF 1%), FISH again had an accuracy that was close to the 'Ideal' model. Among the other methods, the performance of MACH was highly dependent on state size in that a size of 4800 states was required to retain a comparable accuracy. Again, BEAGLE was slightlyreference haplotypes. Uncompact representation severs as a benchmark. The x-axis was only for compact representation. Difference partitionings of segments produced different on average numbers of blocks within segment, which were the states used in the HMM<ref type="figure">Fig. 2</ref>. Diploid versus haploid imputation accuracies on the simulated dataset. A total of 1000 reference subjects and 1000 test subjects were simulated. Haplotypes in the reference samples were assumed known. For the diploid model, imputations were performed on diploid genotypes. For the haploid model, imputations were performed on haploid genotype. We simulated haplotypes in the test sample with various levels of switch error inferior to almost all of the other methods with the exception being its superiority to MACH with state sizes below $200. The accuracy of IMPUTE2 achieved to a level close to the ideal one at a size of as small as 50 states for all the three MAF intervals.<ref type="figure">Figure 4</ref>plotted running time of various methods on the simulated dataset. BEAGLE had a constant running time of $91.9 h based on its default settings. The relationship between state size and running time was quadratic for both MACH and IMPUTE2, while IMPUTE2 took slightly more time than MACH. Imputation on 1000 states took $74.8 and $66.7 h for IMPUTE2 and MACH, respectively. Most impressively, FISH took considerably less time than any of the other methods. Even when modeling the full set of 2000 reference haplotypes, FISH took only $1 min at its best performance. This gain in running time could be as high as hundreds to thousands fold compared to the other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Real dataset</head><p>In order to compare the various imputation methods with a real dataset, we analyzed the entirety of chromosome 22 of the 379 sequenced European subjects from the 1000 genomes project phase 1 release (as of June 04, 2012). Basic characteristics of the data are listed in<ref type="figure" target="#tab_1">Table 1</ref>(right). Because of the relatively limited sample size, we did not include rare variants (MAF51%) into the analysis. Adopting a leave-one-out strategy, we imputed each subject in turn and summarized results together. Haplotypes of all subjects were a priori inferred and were assumed known. As a benchmark, we also imputed each subject with the haploid model on the inferred haplotypes as if the subject was perfectly phased. We again called this analysis the 'Ideal' model. The results are summarized in<ref type="figure">Table 3</ref>. As expected, the 'Ideal' model analysis gave the highest r 2 (88.2% and 66.3%) and lowest GDR (4.0% and 1.8%) for common and less common variants, respectively. The performance of both FISH and BEAGLE was not affected by state size. Their r 2 were 87.0 and 64.6 and 86.9% and 59.8%, respectively, under the two MAF categories, while the GDR were 4.5 and 2.0 and 4.5% and 2.1%. The accuracy of MACH increased with increased state size, while the GDR decreased. At 200 states, its accuracy (87.1% for r 2 and 4.4% for GDR) for common variants was slightly higher than both FISH and BEAGLE; however those (62.9 and 2.0%) for less common variants was intermediate between FISH and BEAGLE. Increasing state size beyond 200 may increase its accuracy further. The performance of IMPUTE2 was influenced slightly by state size, with almost no differences observed with common variants and minor differences with less common variants. IMPUTE2 also produced the highest r 2 (87.6 and 65.2% at 200 states) and lowest GDR (4.3 and 1.9%) among all the methods, though the differences between IMPUTE2 and FISH are relatively minor. To estimate running time, we imputed the 379 subjects together by the reference sample formed by the same subjects.h, respectively. Clearly, FISH was most computationally efficient among all the methods investigated. Notably, its implementation had a multi-threading feature so that the computation could be further sped up on a routine computing cluster node with multiple CPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>In this article, we have proposed a new method for performing diploid genotype imputation based on the HMM. We have also developed an algorithm MAR for efficient execution of the proposed method. Our method is comparable to most of the existing popular methods in terms of imputation accuracy and GDR, and is much preferable in terms of computational efficiency. We model hidden states on single reference haplotypes rather than on pairs of haplotypes. Consequently, the computational complexity reduces from quadratic to linear to the number of reference haplotypes. To achieve the linear complexity, we define the Equation (9), which assumes the independence of</p><formula>P(s p ð Þ lÀ1 jg 1 ,. .. , g l–1 ) and P(s m ð Þ lÀ1 jg 1 ,. .. , g l–1 ). Under</formula><p>the random mating assumption, this independence equation holds as long as the total reference haploytypes serve as the entire population from which the test subject is sampled. In practice, it will hold approximately under large reference sample size, a condition for which our method was proposed. The computational improvement is qualitatively and quantitatively dramatic. We take into account haploid genotype uncertainty at each marker by weighted sum of both possible configurations. Our simulation studies, as well as real data analyses, showed no significant loss of accuracy compared to conventional methods modeled on pairs of reference haplotypes. In the context of high-throughput sequencing datasets, an urgent priority for genotype imputation is to improve computational efficiency. Several alternative solutions have been proposed, one of which is to pre-phase genotypes in the test sample into haplotypes, then to impute on the inferred haplotypes (<ref type="bibr" target="#b10">Howie et al., 2012</ref>). This reduces the computational complexity so that it is linear to the number of reference haplotypes. However, haplotype phasing itself is a computation-demanding process in large-scale settings. Moreover, the success of imputation on phased haplotypes relies largely on the availability and accuracy of statistical inference of haplotypes and may lose accuracy in certain conditions (<ref type="bibr" target="#b10">Howie et al., 2012</ref>), though recent developments on haplotype phasing may ease this limitation (<ref type="bibr" target="#b6">Delaneau et al., 2012</ref><ref type="bibr" target="#b7">Delaneau et al., , 2013</ref><ref type="bibr" target="#b23">Rao et al., 2013;</ref><ref type="bibr" target="#b28">Williams et al., 2012</ref>). Compared to the pre-phasing approach, our proposed method does not require haplotypes to be known. It has another potential to impute on data types that could not be pre-phased, though we did not consider that situation in the current study. Another recent development includes imputing via matrix operation (<ref type="bibr" target="#b5">Chi et al., 2013</ref>). However this method may cause some potential loss of accuracy, though it may lead to increased speed of computation. Equation (14) provides an approximation of between-segmental transition probability calculation. When operating on long segments in which recombination events dominate probability calculations, such approximations may provide reasonable accuracy because individual haplotypes within a block receive the same probabilities regarding recombination. When operating on short segments in which initial haplotype probability dominates probability calculations, however, the loss of accuracy may become severe. An ideal requirement would be that the way to split segments will influence only computational efficiency, but not the imputation accuracy. The developed MAR algorithm meets this requirement, which allows us to optimize the minimal computation without concerns on accuracy. The improvement of computation by compact representation depends on how reference haplotypes could be merged, and essentially, on MAF and LD patterns. Suppose that the total L markers are partitioned into L s segments, and there are on average n s blocks within segments. The computational complexity without compact representation is c 1 ¼ L Â R (for a single individual), and that with compact representation isthat the improvement in computation was highly correlated with this ratio. In summary, we have proposed a new statistical model and method for fast and accurate genotype imputation. Our method is suitable for large-scale dataset analyses. The implemented software FISH is publicly available for academic use.</p><formula>c 2 ¼ n s Â (L – L s þ 1) þ (L s – 1) Â R. A</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><figDesc>MACH mach1-d test.dat-p test.ped-snps ref.snp –haps ref.hap –states states –burnin 10 –rounds 100 –dosage –geno –quality IMPUTE2 impute2-g test.geno-m rec.txt-int 0 100000000-allow_large_regions-h ref.hap-l ref.map-k states-burnin 10-iter 100 BEAGLE java-jar beagle.jar unphased¼test.geno out¼''out'' niterations¼100 phased¼ref.hap markers¼ref.map</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig.1.</head><figDesc>Fig. 1. Illustration of the MAR algorithm. Two haplotypes are presented for simplicity. They are of same type and are merged into one block b. Initially the two haplotypes have the probability p 1 and p 2. Initial block probability is the sum of the two haplotype probabilities p 1 þ p 2. Withinsegmental HMMs are performed on the block. Block probability is partitioned into two components p 3 and 2p 4. The contribution of each haplotype in p 3 is proportional to its initial probability, and the contribution in p 4 is equal. At the end of the segment, the two haplotype probabilities are recovered with p 3 and p 4. Between-segmental HMM is then performed on individual haplotypes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.3.</head><figDesc>Fig. 3. Running time of compact representation of reference haplotypes on the simulated dataset. Both compact and un-compact used the total number of R ¼ 2000 reference haplotypes. Uncompact representation severs as a benchmark. The x-axis was only for compact representation. Difference partitionings of segments produced different on average numbers of blocks within segment, which were the states used in the HMM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><figDesc>Table 1. Characteristics of the simulated and real datasets</figDesc><table>Simulated 
Real 

Reference sample 
Test sample 
Reference sample 
Test sample 

Length (MB) 
1.0 
1.0 
35.2 
35.2 
Numbe r of subjects (N) 
1000 
1000 
379 
379 
Number of SNPs 
6894 
282 
109 721 
9406 
MAF45% 
2392 
282 
75 995 
8396 
MAF41% 
1045 
– 
33 726 
1010 
MAF51% 
3457 
– 
– 
– 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><figDesc>Table 2. Imputation accuracies on the simulated dataset</figDesc><table>MAF 
States 
r 2 (%) 
GDR (%) 

Ideal 
FISH 
IMPUTE2 
MACH 
BEAGLE 
Ideal 
FISH 
IMPUTE2 
MACH 
BEAGLE 

(0.00,0.01] 
50 
78.71 
75.46 
75.89 
14.18 
46.16 
0.14 
0.15 
0.15 
0.53 
0.29 
100 
78.71 
75.46 
76.15 
27.49 
46.16 
0.14 
0.15 
0.15 
0.52 
0.29 
200 
78.71 
75.46 
76.37 
41.74 
46.16 
0.14 
0.15 
0.15 
0.46 
0.29 
400 
78.71 
75.46 
76.65 
55.96 
46.16 
0.14 
0.15 
0.15 
0.39 
0.29 
800 
78.71 
75.46 
76.80 
67.64 
46.16 
0.14 
0.15 
0.15 
0.27 
0.29 

(0.01,0.05] 
50 
92.67 
89.68 
91.02 
61.90 
85.26 
0.41 
0.55 
0.47 
3.17 
0.76 
100 
92.67 
89.68 
91.23 
72.72 
85.26 
0.41 
0.55 
0.46 
1.81 
0.76 
200 
92.67 
89.68 
91.38 
79.56 
85.26 
0.41 
0.55 
0.45 
1.28 
0.76 
400 
92.67 
89.68 
91.42 
84.58 
85.26 
0.41 
0.55 
0.45 
0.92 
0.76 
800 
92.67 
89.68 
91.46 
88.60 
85.26 
0.41 
0.55 
0.44 
0.62 
0.76 

(0.05–0.50] 
50 
97.22 
96.46 
96.98 
87.84 
95.65 
0.86 
1.22 
1.01 
4.22 
1.41 
100 
97.22 
96.46 
97.07 
90.93 
95.65 
0.86 
1.22 
0.99 
3.14 
1.41 
200 
97.22 
96.46 
97.12 
93.02 
95.65 
0.86 
1.22 
0.98 
2.38 
1.41 
400 
97.22 
96.46 
97.16 
94.72 
95.65 
0.86 
1.22 
0.96 
1.80 
1.41 
800 
97.22 
96.46 
97.18 
96.10 
95.65 
0.86 
1.22 
0.95 
1.27 
1.41 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><figDesc>Table 3. Performance of various methods on the real dataset</figDesc><table>Method 
States 
r 2 (%) 
GDR (%) 
Running time (h) 

MAF ! 5% 
MAF55% 
MAF ! 5% 
MAF55% 

Ideal 
50 
88.2 
66.3 
4.0 
1.8 
0.3 
FISH 
50 
87.0 
64.6 
4.5 
2.0 
0.3 
BEAGLE 
86.9 
59.8 
4.5s 
2.1 
73.2 
MACH 
50 
84.4 
52.8 
5.3 
2.8 
3.0 
100 
85.9 
58.7 
4.8 
2.3 
8.4 
200 
87.1 
62.9 
4.4 
2.0 
27.3 
IMPUTE2 
50 
87.5 
64.2 
4.2 
1.9 
18.2 
100 
87.6 
64.9 
4.3 
1.9 
25.2 
200 
87.6 
65.2 
4.3 
1.9 
51.7 </table></figure>

			<note place="foot">ß The Author 2014. Published by Oxford University Press. All rights reserved. For Permissions, please e-mail: journals.permissions@oup.com at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">Fast and accurate diploid genotype imputation at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">L.Zhang et al. at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>

			<note place="foot">at :: on August 30, 2016 http://bioinformatics.oxfordjournals.org/ Downloaded from</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We gratefully thank Dr Christopher J. Papasian and the two anonymous referees for their constructive comments during the preparation of this article.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct   xml:id="b0">
	<analytic>
		<title level="a" type="main">Funding: National Natural Science Foundation of China (project 31100902 to L.Z. and 31301092 to Y.L., in part)</title>
	</analytic>
	<monogr>
		<title level="j">National Institutes of Health</title>
		<imprint/>
	</monogr>
	<note>and. R03TW008221 to H.W.D.. in. part</note>
</biblStruct>

<biblStruct   xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Franklin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">/</forename>
				<surname>Dickson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Endowment</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Edward</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
	<note>Schlieder. Endowment (to H.W.D., in part</note>
</biblStruct>

<biblStruct   xml:id="b2">
	<monogr>
		<title level="m" type="main">Conflict of Interest: none declared</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b3">
	<analytic>
		<title level="a" type="main">An integrated map of genetic variation from 1,092 human genomes</title>
		<author>
			<persName>
				<forename type="first">References</forename>
				<surname>Abecasis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">R</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">491</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b4">
	<analytic>
		<title level="a" type="main">Rapid and accurate haplotype phasing and missing-data inference for whole-genome association studies by use of localized haplotype clustering</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">R</forename>
				<surname>Browning</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">L</forename>
				<surname>Browning</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1084" to="1097" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b5">
	<analytic>
		<title level="a" type="main">Genotype imputation via matrix completion</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">C</forename>
				<surname>Chi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="509" to="518" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b6">
	<analytic>
		<title level="a" type="main">A linear complexity phasing method for thousands of genomes</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Delaneau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="179" to="181" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved whole-chromosome phasing for disease and population genetic studies</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Delaneau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="5" to="6" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b8">
	<analytic>
		<title level="a" type="main">Imputation of coding variants in African Americans: better performance using data from the exome sequencing project</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Duan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2744" to="2749" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b9">
	<analytic>
		<title level="a" type="main">A comprehensive SNP and indel imputability database</title>
		<author>
			<persName>
				<forename type="first">Q</forename>
				<surname>Duan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="528" to="531" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast and accurate genotype imputation in genome-wide association studies through pre-phasing</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="955" to="959" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b11">
	<analytic>
		<title level="a" type="main">A flexible and accurate genotype imputation method for the next generation of genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">N</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Genet</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1000529</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling linkage disequilibrium and identifying recombination hotspots using single-nucleotide polymorphism data</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="2213" to="2233" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b13">
	<analytic>
		<title level="a" type="main">Genotype imputation</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Genom. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="387" to="406" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b14">
	<analytic>
		<title level="a" type="main">MaCH: using sequence and genotype data to estimate haplotypes and unobserved genotypes</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="816" to="834" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b15">
	<analytic>
		<title level="a" type="main">Haplotype inference in random population samples</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1129" to="1137" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b16">
	<analytic>
		<title level="a" type="main">MaCH-admix: genotype imputation for admixed populations</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">Y</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genet. Epidemiol</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="25" to="37" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b17">
	<analytic>
		<title level="a" type="main">Genotype imputation for genome-wide association studies</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Howie</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Rev. Genet</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="499" to="511" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b18">
	<analytic>
		<title level="a" type="main">A new multipoint method for genome-wide association studies by imputation of genotypes</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marchini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Genet</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="906" to="913" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b19">
	<monogr>
		<title level="m" type="main">Fast and accurate 1000 Genomes imputation using summary statistics or low-coverage sequencing data. In: The 62nd American Society of Human Genetics</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Pasaniuc</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>The American Society of Human Genetics</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b20">
	<analytic>
		<title level="a" type="main">Analyses and comparison of accuracy of different genotype imputation methods</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">F</forename>
				<surname>Pei</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3551</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b21">
	<analytic>
		<title level="a" type="main">PLINK: a tool set for whole-genome association and population-based linkage analyses</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Purcell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="559" to="575" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b22">
	<analytic>
		<title level="a" type="main">A tutorial on hidden Markov models and selected applications in speech recognition</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">R</forename>
				<surname>Rabiner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE</title>
		<meeting>. IEEE</meeting>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="257" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b23">
	<analytic>
		<title level="a" type="main">High-resolution whole-genome haplotyping using limited seed data</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Rao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="6" to="7" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b24">
	<analytic>
		<title level="a" type="main">Linkage disequilibrium in the human genome</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">E</forename>
				<surname>Reich</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">411</biblScope>
			<biblScope unit="page" from="199" to="204" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b25">
	<analytic>
		<title level="a" type="main">Calibrating a coalescent simulation of human genome sequence variation</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">F</forename>
				<surname>Schaffner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1576" to="1583" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b26">
	<analytic>
		<title level="a" type="main">A fast and flexible statistical model for large-scale population genotype data: applications to inferring missing genotypes and haplotypic phase</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Scheet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="629" to="644" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b27">
	<analytic>
		<title level="a" type="main">Accounting for decay of linkage disequilibrium in haplotype inference and missing-data imputation</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Scheet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="449" to="462" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct   xml:id="b28">
	<analytic>
		<title level="a" type="main">Phasing of many thousands of genotyped samples</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Williams</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. J. Hum. Genet</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="238" to="251" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>